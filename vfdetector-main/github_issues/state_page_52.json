[{"number": 42204, "title": "Add random shear to keras.layers.experimental.preprocessing", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.3\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\nRight now, keras.layers.experimental.preprocessing contains layers for random contrast, width, height, rotation etc but not for random shears. Wouldn't this be a good home for a preprocessing layer that randomly shears an image?\r\n\r\n**Will this change the current api? How?**\r\nIt will add another class to the public outward facing tf.keras.layers.experimental.preprocessing namespace, something along the lines of `class RandomShear`\r\n\r\n**Who will benefit with this feature?**\r\nUsers who build image preprocessing into their networks. A layer like this one will allow users to easily preprocess images with random shears, rather than creating custom layers.\r\n\r\n**Any Other info.**\r\n", "comments": []}, {"number": 42180, "title": "While Tensorflow usually uses GatherV2, TFLite only supports Gather", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): v2.3.0\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nWhile TensorFlow converts tf.gather to GatherV2, TFlite only supports Gather.\r\nSo we cannot directly convert tf.gather to TFlite. I think it doesn't make sense.\r\n(Flex delegate somehow works, though)\r\nI argue that TFLite should support GatherV2.\r\n\r\n**Will this change the current api? How?**\r\nSince it only requires to modify the underlying kernel, user API would not be changed.\r\n\r\n**Who will benefit with this feature?**\r\nThe one who wants to use gather and convert their model to TFlite\r\n**Any Other info.**\r\n", "comments": ["By the way, TFLite currently supports GatherV2 only when batch_dims = 0 and axis is constant.", "Is there an tflite OpenCL kernel for either Gather or GatherV2?", "@hamlatzis \r\nNo. Gather is not supported by GPU delegate.\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/delegates/gpu"]}, {"number": 42150, "title": "Keras plot_model bug when rendering to svg", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 2.3.0\r\n- Python version: 3.7.7\r\n\r\n\r\n**Describe the current behavior**\r\nThe tf.keras.utils.plot_model() function (and by extension the tf.keras.utils.model_to_dot() function) when specifying the file extension as svg creates an svg with an incorrectly set 'view'. Only the view is incorrect, as the model is correctly plotted, just partly outside the visible range. \r\nThe reason for this bug is that the dpi standard value of 96 prevents graphviz from figuring out the correct svg view window itself. If the dpi is set to 'None', graphviz figures out the correct view. I am uncertain if this bug also occurs with other vector graphic formats, I however tested it with pdfs and it seemed fine.\r\n\r\nGraphviz is set to figure out the correct dpi by itself anyway and applies standard values as 96 to bitmap formats by default [1]. Offering a standard value in the keras plot_model function overwrites that functionality.\r\nThe problem can be solved by setting the dpi default value in the plot_model/model_to_dot function to None and letting graphviz figure out the correct dpi; or by checking for edge cases when converting to special formats such as svg. As I am unaware of the default-value policy of tensorflow did I not want to create an unnecessary pull request, though I would gladly help in the bug fix [2].\r\n\r\n[1] https://graphviz.org/doc/info/attrs.html#d:dpi\r\n[2] mail@paulpauls.de\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nThe code is not reproducible within a jupyter notebook / Google colab, as IPython does not support svg display. Therefore am I attaching minimal reproducing code below:\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import models, layers\r\n\r\nprint(tf.__version__)\r\n\r\nmodel = models.Sequential()\r\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\r\nmodel.add(layers.MaxPooling2D((2, 2)))\r\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\nmodel.add(layers.MaxPooling2D((2, 2)))\r\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\n\r\ntf.keras.utils.plot_model(model, to_file='./model.png')\r\n\r\ntf.keras.utils.plot_model(model, to_file='./model_96DPI.svg')\r\n\r\ntf.keras.utils.plot_model(model, to_file='./model_NoneDPI.svg', dpi=None)\r\n```\r\n", "comments": ["Was able to reproduce the issue with [TF v2.3](https://colab.research.google.com/gist/amahendrakar/97522b7a131ac82284ab0fa91ce99a03/42150.ipynb#scrollTo=W3EvU_efS0lS) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/6b728ee61d04e9dc2196c06b601e3534/42150.ipynb). Please find the attached gist. \r\n\r\nSaving the image as `svg` throws a `ValueError`, but the image is saved on disk.\r\n\r\n- Output of `plot_model(model, to_file='./model_96DPI.svg')`\r\n![model_96DPI](https://user-images.githubusercontent.com/57165142/89752025-36865180-daf0-11ea-9225-621f73dcf35d.png)\r\n\r\n- Output of `plot_model(model, to_file='./model_NoneDPI.svg', dpi=None)`\r\n![model_NoneDPI](https://user-images.githubusercontent.com/57165142/89752079-78af9300-daf0-11ea-8ef3-191533278871.png)\r\n\r\n\r\nThanks!", "\r\nI could reproduce the issue with TF 2.5 .Please, find the gist [here](\r\nhttps://colab.research.google.com/gist/Saduf2019/4ce54a15776dfb50c0096c200ce65bc0/untitled589.ipynb).Thanks!\r\n\r\n", "Was able to reproduce the issue in TF 2.6.0-dev20210529,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/7211a26c91ceff1c16959305566b9cc8/untitled99.ipynb#scrollTo=5kAfupf3TM2z)..Thanks !"]}, {"number": 42144, "title": "Docs on using TPUs with custom training loop can be misleading", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/guide/tpu#train_a_model_using_custom_training_loop\r\n\r\n## Description of issue (what needs changing):\r\nAfter reading the docs on how to use a TPU with a custom training loop, I went ahead and tried training my model on the TPU.\r\nThe training loop I implemented looked like:\r\n```\r\n    for step in range(steps_per_epoch):\r\n      train_step(train_iterator)\r\n      if step % 1000 == 0:\r\n        print(step)\r\n```\r\nWhen I ran this with my model, I would see steps printed very quickly, but then after a while I saw an OOM error, since my model didn't fit in memory. I spent a long time trying to figure out how I could get an OOM error after successfully training for 1000s of steps. Eventually, I realized that train_step (with its internal strategy.run call) doesn't block on completion of the training step, and if I instead ran the following loop:\r\n```\r\n    for step in range(steps_per_epoch):\r\n      train_step(train_iterator)\r\n      if step % 1000 == 0:\r\n        print(optimizer.iterations.numpy())\r\n```\r\nI would see the OOM before any steps completed as expected.\r\n\r\nWhen initially reading the docs it was not at all clear to me this would happen, so I think it would be nice if the docs mentioned that strategy.run is non-blocking. I'm pretty new to tf 2.* so maybe I missed some docs that would've given me this understanding, and if that's the case I apologize. ", "comments": ["@JamesMBartlett,\r\n\r\nWe are checking to see if this is still an issue, Can you take a look at this [updated documentation](https://www.tensorflow.org/guide/tpu#train_the_model_using_a_custom_training_loop) and let us know if you still find it misleading? Thanks! ", "This section hasn't changed since it was written by @rxsang. So I think this issue is still valid.\r\n\r\nRuoxin are you able to clarify the expected behavior here?", "Yeah the default behavior is async indeed, will enhance the documentation to mention that. Thanks @JamesMBartlett."]}, {"number": 42138, "title": "Make Transactional API methods pure virtual", "body": "This PR makes Transactional API methods pure virtual to match previous behavior and move new Filesystems to transactional API.", "comments": ["Needs manual change of internal filesystems, I think I'll manage the manual import later today/early tomorrow", "@mihaimaruseac, Any update on this PR? Please. Thanks!", "Still need to change several internal filesystems. Unfortunately, this period is busy with a lot of other things, so unfortunately this will be delayed until mid next week", "@mihaimaruseac, Any update on this PR? Please. Thanks!", "As team got halved with people leaving, modular work has been downprioritized. Will still happen but there are other issues taking my time at the moment so I didn't have time to manually import.", "@mihaimaruseac, Any update on this PR? Please. Thanks!", "@mihaimaruseac, Any update on this PR? Please. Thanks!", "@mihaimaruseac, Any update on this PR? Please. Thanks!", "@mihaimaruseac Any update on this PR? Please. Thanks!", "@mihaimaruseac Any update on this PR? Please. Thanks!", "All modular TF work is currently stalled. If PR does not pass tests we don't have cycles to import at the moment", "@samikama Can you please check @mihaimaruseac's comments and keep us posted ? Thanks!", "@mihaimaruseac Any update on this PR? Please. Thanks!", "> @mihaimaruseac Any update on this PR? Please. Thanks!\r\n\r\nThe dismissal above the comment states the status. Cannot do any update until things change", "@mihaimaruseac Any update on this PR? Please. Thanks!", "https://github.com/tensorflow/tensorflow/pull/42138#issuecomment-955553325 is still true"]}, {"number": 42128, "title": "Add __name__ property to optimizer classes", "body": "\r\n**System information**\r\n- TensorFlow version (you are using): 1.15.3\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nAdd __name__ property to optimizer classes (and potentially others) for easy access at runtime. \r\n\r\nCurrent behavior:\r\n`opt = SGD()`\r\n`opt.__name__`\r\nAttributeError: 'Adam' object has no attribute '__name__'\r\n\r\nSuggested behavior: \r\n`opt = SGD()`\r\n`opt.__name__`\r\n\"SGD\"\r\n\r\n**Will this change the current api? How?**\r\n\r\nWill allow quick access to class name as string.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nResearchers compiling results from models using several different optimizers. \r\n\r\n**Any Other info.**\r\n", "comments": ["`type(opt).__name__` ?\r\n\r\n```\r\nimport tensorflow as tf\r\nopt = tf.keras.optimizers.SGD()\r\nprint(type(opt).__name__)  # prints: SGD\r\n```"]}, {"number": 42127, "title": "TimeDistributed layer does not (always) propagate mask", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.3.0\r\n- Python version: 3.8.2\r\n- CUDA/cuDNN version: CUDA 10.1.243, cuDNN 7.6.5.32\r\n\r\n**Describe the current behavior**\r\nThe TimeDistributed layer does not propagate a given mask when a custom wrapped layer is used. In the source code (https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/keras/layers/wrappers.py#L192-L245) it shows, that if the \"_always_use_reshape\" property of the the TimeDistributed layer is false, an RNN-implementation is used, which does not seem to propagate the given mask correctly. \"_always_use_reshape\" is set to false, if the wrapped layer is a custom one. \r\nThe following simple example shows a custom layer, which simply reduces the last dimension of the input by its sum and multiplies the result by the mask. Note that the mask argument in its call function is not optional (in order to show by a thrown exception that the mask is not propagated).\r\n\r\n**Describe the expected behavior**\r\nRunning the example code as it is shown in the following, will result in the exception: \"_call() missing 1 required positional argument: 'mask'_\". This is not expected since a mask is provided in the call of the TimeDistributed layer. However if the \"_always_use_reshape\" property is set to True, the example works as expected without an exception.\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\n\r\nclass TestLayer(tf.keras.layers.Layer):\r\n    def __init__(self):\r\n        super(TestLayer, self).__init__()\r\n        self.supports_masking = True\r\n\r\n    def call(self, input, mask):\r\n        # simply sum last dimension\r\n        return tf.reduce_sum(input, axis=-1) * tf.cast(mask, tf.float32)\r\n        \r\n    def compute_output_shape(self, input_shape):\r\n        return input_shape[:-2] + input_shape[-1]\r\n    \r\n    \r\nlayer = tf.keras.layers.TimeDistributed(TestLayer())\r\n\r\n# By commenting in the following line, this example works properly\r\n# layer._always_use_reshape = True \r\n\r\nresult_ones_mask  = layer(tf.random.normal([1,8,4]), mask=tf.ones ([1,8], dtype=tf.bool))\r\nresult_zeros_mask = layer(tf.random.normal([1,8,4]), mask=tf.zeros([1,8], dtype=tf.bool))\r\n\r\n\r\nprint(result_ones_mask.numpy())  # expected 1x8-tensor with random numbers\r\nprint(result_zeros_mask.numpy()) # expected 1x8-tensor with zeros\r\n```\r\n\r\n\r\n", "comments": ["@yetanotheryeti \r\nI ran the code shared and it seems incomplete please share all dependencies such that we can replicate the issue faced, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/ed4ca48cc24c61b7e1fb301d8582a32a/untitled350.ipynb) for the same. If possible share a colab gist with the issue faced.", "Hi @Saduf2019 \r\n\r\nthis is the issue I am talking about. Your gist shows exactly the problem. The code (which really is very basic) does not work since the call function requires the mask argument. I thought I made that clear in my description.\r\n\r\nNote: As I said, I made the mask argument not optional on purpose to show that it is not set by the TimeDistributed layer. If we set it optional the resulting values in the last code line are not zeros as expected.", "Another follow-up to clarify, that custom layers are problematic with TimeDistributed:\r\nBelow a custom layer is constructed, which acts as a \"clone\" of the GlobalAveragePooling1D layer, by instantiating one internally and only propagating function calls to it.\r\n\r\nSwitching on the line with our custom layer \"ClonedGlobalAveragePooling1D\"\r\n`layer = tf.keras.layers.TimeDistributed(ClonedGlobalAveragePooling1D())   # does NOT work`\r\nwill result in an error: \"Incompatible shape for value ((1, 4)), expected ((1, 1))\"\r\n\r\nwhile instead switching on the line\r\n`layer = tf.keras.layers.TimeDistributed(tf.keras.layers.GlobalAveragePooling1D())   # does work`\r\nworks as expected without any issue. \r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nclass ClonedGlobalAveragePooling1D(tf.keras.layers.Layer):\r\n    def __init__(self):\r\n        super(ClonedGlobalAveragePooling1D, self).__init__()        \r\n        self.supports_masking = True\r\n        \r\n    def build(self, input_shape):\r\n        self.l = tf.keras.layers.GlobalAveragePooling1D()\r\n        self.l.build(input_shape)\r\n\r\n    def call(self, input, mask=None):\r\n        return self.l(input, mask=mask)\r\n    \r\n    def compute_mask(self, inputs, mask=None):\r\n        return self.l.compute_mask(inputs, mask=mask)\r\n        \r\n    def compute_output_shape(self, input_shape):\r\n        return self.l.compute_output_shape(input_shape)\r\n    \r\n    def compute_output_signature(self, input_shape):\r\n        return self.l.compute_output_signature(input_shape)\r\n        \r\n\r\nlayer = tf.keras.layers.TimeDistributed(ClonedGlobalAveragePooling1D())   # does NOT work\r\n# layer = tf.keras.layers.TimeDistributed(tf.keras.layers.GlobalAveragePooling1D())   # does work\r\n\r\nresult_ones_mask = layer(tf.random.normal([1,8,4,1]), mask=tf.ones([1,8,4], dtype=tf.bool))\r\nresult_zeros_mask = layer(tf.random.normal([1,8,4,1]), mask=tf.zeros([1,8,4], dtype=tf.bool))\r\n\r\nprint(result_ones_mask.numpy(), result_ones_mask.shape)\r\nprint(result_zeros_mask.numpy(), result_zeros_mask.shape)\r\n```\r\n", "Thanks for filing the issue. Let me clarify some of the question you have:\r\n\r\n1. For the https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/keras/layers/wrappers.py#L192-L245, it is propagating the mask correctly since it pass the mask to K.rnn function, which will processing the masking under the hood.\r\n\r\n2. In your first example, the mask is created as a required parameter, which makes it incompatible with the TimeDistributed wrapper. By definition, the wrapped layer will see one timestep at a time. It shouldn't need to aware of the mask, since the output value should be auto masked/filtered by the wrapper itself. \r\n\r\n3. In the second example, the mask value you passed is a 3D tensor (1 , 8, 4) which is actually not correct. From the docstring, the mask shape should be a 2D tensor [batch, timestep]. If you change the mask value to tf.zeros([1, 8]), then the code will run correctly.\r\n\r\n4. If I change the second example to run with tf.keras.layers.GlobalAveragePooling1D() and mask shape [1, 8], it will actually fail, which is a bug in the current code. I will address that in a change later.", "Hey, qlzh727!\r\n\r\n### 1.\r\n\r\nI see. So the behavior then differs from the non-rnn version:\r\n- rnn-version: mask gets propagated implicitly by the inner rnn function.\r\n- non-rnn-version: mask gets propagated to the wrapped layer. \r\n\r\nTherefore the input for the wrapped layer also varies depending on the version. See code excursion at the end of this post.\r\n\r\nThis makes sense, but is still interesting to know and to keep in mind (at least for me). Nevertheless, the argument description for the mask is then confusing, in my opinion, as it says that the mask is propagated to the wrapped layer:\r\n> mask: Binary tensor of shape `(samples, timesteps)` indicating whether a given timestep should be masked. This argument is passed to the wrapped layer (only if the layer supports this argument).\r\n\r\n### 2.\r\n\r\n> By definition, the wrapped layer will see one timestep at a time. It shouldn't need to aware of the mask, since the output value should be auto masked/filtered by the wrapper itself.\r\n\r\nThanks for the clarification. This matches the preceding observation of the [2 4] input shape in the rnn-version.\r\n\r\n### 3.\r\n\r\nOh, yes, my bad.\r\n\r\n### 4.\r\n\r\nGreat! Thanks for looking into the problem and for your effort!\r\n\r\n---\r\nCode excursion, clarifying the different behaviours of the rnn- vs non-rnn-version regarding the input shape and mask passed to the wrapped layer:\r\n\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nclass TestLayer(tf.keras.layers.Layer):\r\n    def __init__(self):\r\n        super(TestLayer, self).__init__()\r\n        self.supports_masking = True\r\n\r\n    def call(self, input, mask=None):\r\n        tf.print(\"input shape:\", tf.shape(input), \"; mask:\", mask)        \r\n        return input\r\n\r\nlayer = tf.keras.layers.TimeDistributed(TestLayer())\r\n\r\nlayer._always_use_reshape = True \r\n\r\n_ = layer(tf.random.normal([2,8,4]), mask=tf.ones ([2,8], dtype=tf.bool))\r\n```\r\nWith `layer._always_use_reshape = True` (and thus _non-rnn_) the printed result is: `input shape: [16 4] ; mask: [1 1 1 ... 1 1 1]`\r\nWithout it (and thus _rnn_) the printed result is: `input shape: [2 4] ; mask: None` multiple times (one for each time step).", "Was able to reproduce the issue in TF v2.5,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/4b0e2c3e68cd434b993a320cd0a81747/untitled101.ipynb)..Thanks !"]}, {"number": 42120, "title": "Slow iteration/converting of tensors to vector<float> via Python C API", "body": "**System information**\r\n- Have I written custom code: **Yes**\r\n- OS Platform and Distribution: **Windows 10 Build 19041 and Docker version 19.03.12**\r\n- TensorFlow installed from: **binary**\r\n- TensorFlow version: **v2.3.0-rc2-23-gb36436b087 2.3.0**\r\n- Python version: **3.6.9**\r\n- CUDA/cuDNN version: **No GPU**\r\n- GPU model and memory: **No GPU**\r\n\r\n**Describe the current behavior**\r\n\r\nCurrently iteration/converting of tensor to `vector<float>` via Python C API is extremely slow - it takes from 13 seconds to a minute to convert 100 tensors (with shape `(1792,)`) into c++ `vector<float>`.\r\n\r\nIf the tensor is converted into ndarray with `numpy()` call beforehand the operation is performed instantaneously. \r\n\r\n**Describe the expected behavior**\r\n\r\nThe speed of tensor conversion and the speed of ndarray conversion is the same (or similar). \r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n[Collab Notebook](https://colab.research.google.com/drive/1ISRM-9Vr0hcM6xrPtCMZLQpjvQ2T_OcS)\r\n\r\n```python\r\nfrom annoy import AnnoyIndex\r\nimport tensorflow as tf\r\nfrom time import perf_counter\r\n\r\ntf.compat.v1.enable_eager_execution()\r\n\r\ndims = 1792\r\ntrees = 10000\r\nfeatures = []\r\n\r\nfor key in range(0, 100):\r\n    features.append(tf.random.uniform([dims]))\r\n\r\nt1 = perf_counter()\r\n\r\nt = AnnoyIndex(dims, metric='angular')\r\n\r\nfor key, feature in enumerate(features):\r\n    # t.add_item(key, feature.numpy())\r\n    t.add_item(key, feature)\r\n\r\nt2 = perf_counter()\r\n\r\nprint(f\"Vector add: {t2 - t1:.2f}\")\r\n```\r\n\r\n**Other info / logs**\r\n\r\nThe issue is present in both Tensorflow 1 and 2. Tested in Docker.\r\n\r\n- Tensorflow: 2.3.0 (`tensorflow/tensorflow:latest-jupyter`): Vector add: 28.09\r\n- Tensorflow: 2.3.0 with `numpy()` call (`tensorflow/tensorflow:latest-jupyter`): Vector add: 0.02\r\n- Tensorflow: 1.15.2 (`tensorflow/tensorflow:1.15.2-py3-jupyter`): Vector add: 29.82\r\n\r\n\r\nSame issue in [annoy library](https://github.com/spotify/annoy/issues/498).\r\n[Maybe relevant Tensorflow issue](https://github.com/tensorflow/tensorflow/issues/27692). I tested on Numpy 1.19.1 and it did not help.\r\n\r\nAnnoy library call hierarchy:\r\n- [add_item](https://github.com/spotify/annoy/blob/master/src/annoymodule.cc#L534)\r\n- [py_an_add_item](https://github.com/spotify/annoy/blob/master/src/annoymodule.cc#L369)\r\n- [convert_list_to_vector](https://github.com/spotify/annoy/blob/master/src/annoymodule.cc#L295)\r\n   - `int z` - cycle iterator\r\n   - `int f` - tensor length\r\n   - `PyObject* v` - tensor\r\n   - `PyObject *pf` - one tensor value\r\n\r\n```c\r\n  for (int z = 0; z < f; z++) {\r\n    PyObject *key = PyInt_FromLong(z);\r\n    PyObject *pf = PyObject_GetItem(v, key);\r\n    (*w)[z] = PyFloat_AsDouble(pf);\r\n    Py_DECREF(key);\r\n    Py_DECREF(pf);\r\n  }\r\n```", "comments": ["@eduard93 \r\nI ran the above code for 1.15 and 2.2 please find gist here for[ tf 1.15](https://colab.research.google.com/gist/Saduf2019/b8bea650b9c93bea85aadfdd233836dc/untitled341.ipynb) and [tf 2.2](https://colab.research.google.com/gist/Saduf2019/40be552f9d746367e35304e93a1e3315/untitled342.ipynb) please let us know if this confirms your issue.", "@Saduf2019 it does.", "@eduard93,\r\nCould reproduce the issue with **`Tensorflow Version 2.5`**. Please find [the Gist](https://colab.research.google.com/gist/rmothukuru/a586d6f9466a4f51a1faf95fb5f0d804/untitled342.ipynb). Thanks! ", "@rmothukuru yes, the issue is still present."]}, {"number": 42119, "title": "autograph fails inside keras model train_step including a for loop over a tensor", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linus Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\n- TensorFlow installed from (source or binary): binary (docker image latest-gpu-py3)\r\n- TensorFlow version (use command below): 2.3\r\n- Python version: Python 3.6.9\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: V100\r\n\r\n**Describe the current behavior**\r\n\r\nWhen writing a python \"for\" loop inside a tf.keras.Model.train_step I get the following error:\r\n\r\nOperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\r\n\r\nThe same function works correctly when outside of a keras model but still decorated with tf.function. \r\n\r\n**Describe the expected behavior**\r\n\r\nautograph should support iterating over a tensor also inside a keras model\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nt = tf.Variable(0)\r\n\r\n@tf.function()\r\ndef foo():\r\n    for n in tf.range(tf.constant(10)):\r\n        t.assign_add(n)\r\n    return t\r\n\r\nnt = foo()\r\nnt #  <tf.Tensor: shape=(), dtype=int32, numpy=45>\r\n\r\nclass mymodel(tf.keras.Model):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.t = tf.Variable(0)\r\n    def train_step(self, data):\r\n        for n in tf.range(tf.constant(10)):\r\n            t.assign_add(n)\r\n        return {\"loss\": t}\r\n\r\nmm = mymodel()\r\nmm.compile()\r\nmm.fit(np.random.random((5)), steps_per_epoch=1) # this doesn't work see trace below\r\n```\r\n\r\n**Other info / logs** \r\n\r\nOperatorNotAllowedInGraphErrorTraceback (most recent call last)\r\n<ipython-input-18-c68155fbb474> in <module>\r\n----> 1 mm.fit(np.random.random((5)), steps_per_epoch=1)\r\n\r\n~usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)\r\n    106   def _method_wrapper(self, *args, **kwargs):\r\n    107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access\r\n--> 108       return method(self, *args, **kwargs)\r\n    109 \r\n    110     # Running inside `run_distribute_coordinator` already.\r\n\r\n~usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n   1096                 batch_size=batch_size):\r\n   1097               callbacks.on_train_batch_begin(step)\r\n-> 1098               tmp_logs = train_function(iterator)\r\n   1099               if data_handler.should_sync:\r\n   1100                 context.async_wait()\r\n\r\n~usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    778       else:\r\n    779         compiler = \"nonXla\"\r\n--> 780         result = self._call(*args, **kwds)\r\n    781 \r\n    782       new_tracing_count = self._get_tracing_count()\r\n\r\n~usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    821       # This is the first call of __call__, so we have to initialize.\r\n    822       initializers = []\r\n--> 823       self._initialize(args, kwds, add_initializers_to=initializers)\r\n    824     finally:\r\n    825       # At this point we know that the initialization is complete (or less\r\n\r\n~usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)\r\n    695     self._concrete_stateful_fn = (\r\n    696         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n--> 697             *args, **kwds))\r\n    698 \r\n    699     def invalid_creator_scope(*unused_args, **unused_kwds):\r\n\r\n~usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n   2853       args, kwargs = None, None\r\n   2854     with self._lock:\r\n-> 2855       graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n   2856     return graph_function\r\n   2857 \r\n\r\n~usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   3211 \r\n   3212       self._function_cache.missed.add(call_context_key)\r\n-> 3213       graph_function = self._create_graph_function(args, kwargs)\r\n   3214       self._function_cache.primary[cache_key] = graph_function\r\n   3215       return graph_function, args, kwargs\r\n\r\n~usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   3073             arg_names=arg_names,\r\n   3074             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 3075             capture_by_value=self._capture_by_value),\r\n   3076         self._function_attributes,\r\n   3077         function_spec=self.function_spec,\r\n\r\n~usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    984         _, original_func = tf_decorator.unwrap(python_func)\r\n    985 \r\n--> 986       func_outputs = python_func(*func_args, **func_kwargs)\r\n    987 \r\n    988       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n~usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)\r\n    598         # __wrapped__ allows AutoGraph to swap in a converted function. We give\r\n    599         # the function a weak reference to itself to avoid a reference cycle.\r\n--> 600         return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    601     weak_wrapped_fn = weakref.ref(wrapped_fn)\r\n    602 \r\n\r\n~usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    971           except Exception as e:  # pylint:disable=broad-except\r\n    972             if hasattr(e, \"ag_error_metadata\"):\r\n--> 973               raise e.ag_error_metadata.to_exception(e)\r\n    974             else:\r\n    975               raise\r\n\r\nOperatorNotAllowedInGraphError: in user code:\r\n\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\r\n        return step_function(self, iterator)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\r\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\r\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\r\n        return self._call_for_each_replica(fn, args, kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\r\n        return fn(*args, **kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\r\n        outputs = model.train_step(data)\r\n    <ipython-input-12-62f0dcb0797d>:6 train_step\r\n        for n in tf.range(tf.constant(10)):\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:503 __iter__\r\n        self._disallow_iteration()\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:496 _disallow_iteration\r\n        self._disallow_when_autograph_enabled(\"iterating over `tf.Tensor`\")\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:474 _disallow_when_autograph_enabled\r\n        \" indicate you are trying to use an unsupported feature.\".format(task))\r\n\r\n    OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["any update on this?", "@klaimans \r\n\r\nCould you please check [this comment](https://github.com/tensorflow/tensorflow/issues/33308#issuecomment-542565633) from a similar issue and let us know if it works? Thanks!", "I have tried in colab with TF version 2.3, nightly version (`2.4.0-dev20200831`) and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/9f6070bd493f21cff47d50d2a43e630b/untitled283.ipynb). Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@jvishnuvardhan \r\n\r\nany updates on this? The above suggestion from @ravikyram did not resolve the issue. ", "@klaimans Sorry for the late response. Can you please add @tf.function as shown below.\r\n\r\n```\r\nclass mymodel(tf.keras.Model):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.t = tf.Variable(0)\r\n    @tf.function()\r\n    def train_step(self, data):\r\n        for n in tf.range(tf.constant(10)):\r\n            self.t.assign_add(n)\r\n        return {\"loss\": self.t}\r\n\r\n```\r\n\r\nWith the above modification, everything worked as expected. Please take a look at the gist [here](https://colab.research.google.com/gist/jvishnuvardhan/f21761ce1629afd96a22e66658b3f80c/untitled283.ipynb). Thanks!\r\n\r\nAlso, I guess you need to replace `t` with `self.t` as I updated above. Thanks!\r\n\r\nPlease verify once and close the issue if this was resolved for you. Thanks!", "@jvishnuvardhan, thank you very much for your reply. Indeed I had a small typo in the example code but this was not responsible for the error I saw. \r\n\r\nThe reason seems to be the specific decoration of the train_step method with @tf.function. This is in contrast to the documentation under https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit and https://www.tensorflow.org/api_docs/python/tf/keras/Model#test_step where it specifically says: \r\n\r\n\"Configuration details for how this logic is run (e.g. tf.function and tf.distribute.Strategy settings), should be left to Model.make_train_function, which can also be overridden.\"\r\n\r\nWithout the decoration I still get the same error as before. Did I misunderstand the documentation in this case? \r\n", "@klaimans Forgot to delete part of the gist. Please check [this gist](https://colab.research.google.com/gist/jvishnuvardhan/5d73b1a5af3dd9674ee0f91f9521125c/untitled283.ipynb) which shows same result with or without tf.function. Please let me know what you think? Thanks!", "@jvishnuvardhan \r\n\r\nIt still fails for me without the explicit tf.function decorator when running tensorflow inside a docker container using the tensorflow/tensorflow:latest-gpu-jupyter image (tf version 2.3.0). I also tried using the nightly version on my mac and that fails as well with the same error (version '2.4.0-dev20200926').\r\n\r\nNow for the interesting part, directly on the Ubuntu Server it seems to work (although I have a mismatch in cuda versions 10.0 vs 10.1 which is required for the current version). I tried with nightly ('2.4.0-dev20200928'), 2.3 and 2.3.1. Any ideas? \r\n\r\n\r\n\r\n\r\n\r\n", "@klaimans I am not sure about the docker build but I ran the same code that I shared above on my Mac and it runs and output same results from the two models. My TF version is `'2.4.0-dev20200819'` Thanks!", "@jvishnuvardhan \r\n\r\nI finally found the difference between our tests. In your last gist (where it runs without the decorator) you changed the original example so that the **for loop** iterates over the python object **range(10)** rather than the original **tf.range(tf.constant(10))** which is what leads to the issue and the original error I reported above. Changing back to the original example leads to the original issue. Thanks!\r\n\r\n", "@klaimans Please close the issue if this was resolved for you. Thanks!", "@jvishnuvardhan\r\n\r\nI have to admit I am a bit confused. The recommendation is to use tf.range(tf.constant(10)) but this leads to an autograph failure. Are you saying we should use range? Wouldn't this lead to retracing? And why does it work for functions outside a keras model and only fails there?  ", "Hi @klaimans, just to clarify, it seems that the following works:\r\n\r\n```\r\nclass mymodel(tf.keras.Model):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.t = tf.Variable(0)\r\n    @tf.function()\r\n    def train_step(self, data):\r\n        for n in tf.range(tf.constant(10)):\r\n            self.t.assign_add(n)\r\n        return {\"loss\": self.t}\r\n```\r\n\r\nSo, the main question here is why @tf.function is necessary when customizing `train_step` and using `model.fit` since the docs seem to imply that is not necessary (and that function runs without @tf.function when not in a keras model). Am I summarizing correctly?\r\n\r\nI'm looking at the [Autograph guide here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/common_errors.md#operatornotallowedingrapherror-iterating-over-tftensor) which states the exception is `only raised when graph execution is active, for example inside a @tf.function with AutoGraph turned off.` So seems to me that somewhere (I don't know where/why) `autograph` is being set to False. And you can override that by explicitly decorating with `@tf.function`, which will make the code work.", "Hi @nikitamaia, yes that is exactly correct. ", "Sorry, but I am facing quite a similar problem and I didn't manage to solve it just by the solutions provided here.\r\n\r\n**Describe the current behavior**\r\nI am trying to call a c++ function through _cython_ inside each training step of tf. My cython function takes an array as input, transforms it into a c++ vector and calculates a c++ function that takes this vector as input. When Tensorflow calls the cython function in the training phase, it passes a tf.Tensor as parameter (basically because it vectorizes the function for many calls). Therefore, when I try to set c++ vector = tf.tensor it complains saying that I am iterating over `tf.Tensor`\r\n\r\n**Describe the expected behavior**\r\nI wish I could vectorize with my \"for\" in cython with no problems.\r\n\r\n**My codes**\r\n\r\nwrapper.pyx\r\n```\r\ncdef extern from \"eft.h\":\r\n    double integrand_1l(double * c_array)\r\n\r\ndef integrand_1d_python(array_test):\r\n    output = []\r\n    cdef Py_ssize_t i\r\n    cdef Py_ssize_t n = array_test.shape[0]\r\n    cdef double [2] c_array\r\n    for i in tf.range(n):\r\n        c_array = array_test[i]\r\n        output.append(integrand_1l(c_array) )\r\n    return output \r\n```\r\n\r\nfile.py in which I train the NN\r\n```\r\nclass TestFunctions:\r\n\r\n    def __init__(self, ndims, alpha, **kwargs):\r\n        self.ndims = ndims\r\n        self.alpha = alpha\r\n        self.variables = kwargs\r\n        self.calls = 0\r\n\r\n    def loop1(self, x):\r\n        self.calls += 1 \r\n        my_new_temp = tf.cast(wrapper.integrand_1d_python(x), dtype=tf.float64) \r\n\r\n        return my_new_temp\r\n\r\n```\r\n**The log I get: (same as @klaimans )**\r\n\r\nOperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\r\n\r\n**What I have tried so far (with no success)**\r\n- adding @tf.function()\r\n- transform from vector to numpy array\r\n- using tf.map_fn \r\n\r\n\r\n   \r\n\r\n", "Was able to replicate the issue in TF v2.5,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/f962f871d13e99593d845c26171e3f75/untitled102.ipynb)..Thanks !", "Same problem here.\r\n\r\nWhen decorating train_step with `@tf.function` and run on CPU, the model.fit works fine.\r\n\r\nBut when train on multi-GPU with `tf.distribute.MirroredStrategy`, the train_step with `@tf.function` will cause error:\r\n\r\n_RuntimeError: `merge_call` called while defining a new graph or a tf.function. This can often happen if the function `fn` passed to `strategy.run()` contains a nested `@tf.function`, and the nested `@tf.function` contains a synchronization point, such as aggregating gradients (e.g, optimizer.apply_gradients), or if the function `fn` uses a control flow statement which contains a synchronization point in the body. Such behaviors are not yet supported. Instead, please avoid nested `tf.function`s or control flow statements that may potentially cross a synchronization boundary, for example, wrap the `fn` passed to `strategy.run` or the entire `strategy.run` inside a `tf.function` or move the control flow out of `fn`. If you are subclassing a `tf.keras.Model`, please avoid decorating overridden methods `test_step` and `train_step` in `tf.function`._ \r\n\r\nThis error said:\r\n\r\n> please avoid decorating overridden methods `test_step` and `train_step` in `tf.function`\r\n\r\nif we remove `@tf.function` from train_step, we will get error like:\r\n\r\n_OperatorNotAllowedInGraphError: iterating over tf.Tensor is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature._\r\n\r\nThis is extremely confusing..."]}, {"number": 42106, "title": "tf.keras.models.load_model unable to load model in TF 2.3.0 - \"int() argument must be a string, a bytes-like object or a number, not 'NoneType' \"", "body": "My first time posting a GitHub issue, so excuse me if I leave something out.\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nMac OSX 10.12.6\r\n- TensorFlow installed from (source or binary):\r\nBinary\r\n- TensorFlow version (use command below):\r\n2.3.0\r\n- Python version:\r\n3.7\r\n\r\n**Describe the current behavior**\r\nEvery time I call `tf.keras.models.load_model` on my SavedModel in version 2.3.0, the model fails to load. I had saved the model with tensorflow 2.0.0 installed, and I could load it with 2.0.0, but when I upgraded to 2.3.0, I got the following error:\r\n\r\n```python\r\nTraceback (most recent call last):\r\n  File \"../python/recommender.py\", line 501, in <module>\r\n    new_topics=args.new_topic_path)\r\n  File \"../python/recommender.py\", line 51, in load_data\r\n    add_to_matrix(tdf, vdf, save_matrix, corr_matrix, new_values, new_topics)\r\n  File \"../python/recommender.py\", line 352, in add_to_matrix\r\n    df2 = get_corrs(ntdf, vdf)\r\n  File \"../python/recommender.py\", line 401, in get_corrs\r\n    model = load_model(model_dir, None)\r\n  File \"/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py\", line 187, in load_model\r\n    return saved_model_load.load(filepath, compile, options)\r\n  File \"/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py\", line 121, in load\r\n    path, options=options, loader_cls=KerasObjectLoader)\r\n  File \"/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\", line 633, in load_internal\r\n    ckpt_options)\r\n  File \"/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py\", line 194, in __init__\r\n    super(KerasObjectLoader, self).__init__(*args, **kwargs)\r\n  File \"/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\", line 130, in __init__\r\n    self._load_all()\r\n  File \"/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py\", line 215, in _load_all\r\n    self._layer_nodes = self._load_layers()\r\n  File \"/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py\", line 315, in _load_layers\r\n    layers[node_id] = self._load_layer(proto.user_object, node_id)\r\n  File \"/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py\", line 341, in _load_layer\r\n    obj, setter = self._revive_from_config(proto.identifier, metadata, node_id)\r\n  File \"/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py\", line 359, in _revive_from_config\r\n    self._revive_layer_from_config(metadata, node_id))\r\n  File \"/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py\", line 445, in _revive_layer_from_config\r\n    built = self._try_build_layer(obj, node_id, build_input_shape)\r\n  File \"/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py\", line 482, in _try_build_layer\r\n    obj.build(build_input_shape)\r\n  File \"/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/layers/wrappers.py\", line 685, in build\r\n    self.forward_layer.build(input_shape)\r\n  File \"/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py\", line 581, in build\r\n    self.cell.build(step_input_shape)\r\n  File \"/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\", line 323, in wrapper\r\n    output_shape = fn(instance, input_shape)\r\n  File \"/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py\", line 2367, in build\r\n    caching_device=default_caching_device)\r\n  File \"/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 614, in add_weight\r\n    caching_device=caching_device)\r\n  File \"/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\", line 750, in _add_variable_with_custom_getter\r\n    **kwargs_for_getter)\r\n  File \"/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\", line 145, in make_variable\r\n    shape=variable_shape if variable_shape else None)\r\n  File \"/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 260, in __call__\r\n    return cls._variable_v1_call(*args, **kwargs)\r\n  File \"/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 221, in _variable_v1_call\r\n    shape=shape)\r\n  File \"/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 199, in <lambda>\r\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\r\n  File \"/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 2597, in default_variable_creator\r\n    shape=shape)\r\n  File \"/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 264, in __call__\r\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n  File \"/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1518, in __init__\r\n    distribute_strategy=distribute_strategy)\r\n  File \"/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1651, in _init_from_args\r\n    initial_value() if init_from_fn else initial_value,\r\n  File \"/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/keras/initializers/initializers_v2.py\", line 397, in __call__\r\n    return super(VarianceScaling, self).__call__(shape, dtype=_get_dtype(dtype))\r\n  File \"/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/ops/init_ops_v2.py\", line 545, in __call__\r\n    fan_in, fan_out = _compute_fans(scale_shape)\r\n  File \"/Users/aditya/Documents/Internships/phoenix/recommender/venv/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py\", line 1425, in _compute_fans\r\n    return int(fan_in), int(fan_out)\r\nTypeError: int() argument must be a string, a bytes-like object or a number, not 'NoneType'\r\n```\r\n\r\n**Describe the expected behavior**\r\nIdeally, I should be able to load up my model and just use it from there.\r\n\r\n**Standalone code to reproduce the issue**\r\nI could reproduce this with the model in [model.zip](https://github.com/tensorflow/tensorflow/files/5037874/model.zip) and with the following code:\r\n\r\n```bash\r\npython3\r\n>>> import tensorflow as tf\r\n>>> tf.keras.models.load_model('model/')\r\n```", "comments": ["I have not analyzed your model but can you verify if it is compliant with `saved_model` [documented compatibility constrains](https://www.tensorflow.org/guide/versions#compatibility_of_savedmodels_graphs_and_checkpoints)?", "@bhack how would we go about finding the `GraphDef` version? I didn't use any deprecated APIs, so I'd assume that that's the problem, if it is indeed incompatiblity.", "@adityapaul,\r\nI was able to reproduce the issue. Facing an error while loading the model with [TF v2.3](https://colab.research.google.com/gist/amahendrakar/9b4eae0b61ca33c70e4ccb0a68c470ea/42106-2-3.ipynb), whereas the code runs fine on [TF v2.0](https://colab.research.google.com/gist/amahendrakar/c022e29a8c2021eabd2d0ea575a96fd1/42106.ipynb). Please find the attached gist. \r\n\r\nIn order to expedite the trouble-shooting process, could you please provide the code you had to used to build the model. Thanks!", "Yes It could be useful to double check \"non-deprecated, non-experimental, non-compatibility APIs\"", "@bhack Thanks for that! I'll take a look and see what exactly I was doing and make sure I wasn't using anything non-compatible. I was able to load the model in TF 2.1.0, but my code still didn't entirely work. However, I imagine that it's probably  something wrong with my code then rather than an underlying TensorFlow issue.\r\n\r\n@amahendrakar Here's the code that I used to train the model. Let me know if you need anything else!\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nclass LuongAttention(tf.keras.Model):\r\n    def __init__(self, input_dim=max_len, att_type='dot'):\r\n        super(LuongAttention, self).__init__()\r\n        w_init = tf.random_normal_initializer()\r\n        self.att_type = att_type\r\n        self.W = tf.Variable(\r\n            initial_value = np.identity(input_dim, dtype='float32'),\r\n            trainable=False\r\n        )\r\n        self.WLayer = tf.keras.layers.Dense(input_dim, \r\n                                           kernel_regularizer=tf.keras.regularizers.l2(0.01))\r\n        if self.att_type == 'general':\r\n            self.W = tf.Variable(\r\n                initial_value=w_init(shape=(input_dim, input_dim), dtype=\"float32\"),\r\n                trainable=True\r\n            )\r\n        self.loss = 1e-5 * tf.nn.l2_loss(self.W)\r\n    def call(self, inputs):\r\n        self.add_loss(self.loss)\r\n        if self.att_type == 'concat':\r\n            score = tf.matmul(inputs[0], self.WLayer(inputs[1]), transpose_b=True)\r\n            alignment = tf.nn.softmax(score, axis=2)\r\n        else:\r\n            score = tf.matmul(self.W, inputs[1])\r\n            score = tf.matmul(inputs[0], score, transpose_b=True)\r\n            alignment = tf.nn.softmax(score, axis=2)\r\n        return alignment\r\n\r\n# Build the model\r\nfrom tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Attention\r\nfrom tensorflow.keras.layers import Dense, Concatenate, Reshape\r\nfrom tensorflow.keras.activations import linear\r\nfrom tensorflow.keras.regularizers import l1, l2, l1_l2\r\nfrom tensorflow.keras.models import Model\r\n\r\nin1 = Input((max_len,))\r\nin2 = Input((max_len,))\r\n\r\nemb = Embedding(len(tokenizer.word_index) + 1, \r\n                embedding_dim, \r\n                input_length=max_len)\r\nif use_embedding: \r\n    emb = Embedding(len(tokenizer.word_index) + 1, \r\n                    embedding_dim, \r\n                    weights=[embedding_matrix],\r\n                    input_length=max_len, \r\n                    trainable=emb_trainable)\r\n\r\n# First sequence branch\r\nbranch1 = emb(in1)\r\nbranch1l = Bidirectional(LSTM(25, \r\n                              activation='elu', \r\n                              return_sequences=True, \r\n                              kernel_regularizer=l2(0.01)))(branch1)\r\n\r\n# Second sequence branch\r\nbranch2 = emb(in2)\r\nbranch2l = Bidirectional(LSTM(25, \r\n                              activation='elu', \r\n                              return_sequences=True, \r\n                              kernel_regularizer=l2(0.01)))(branch2)\r\n\r\n# Concatenate with Luong attention (eventually add word embedding as value)\r\nattention1 = LuongAttention(input_dim=max_len, \r\n                            att_type='general')([branch1, branch2])\r\nattention2 = LuongAttention(input_dim=max_len, \r\n                            att_type='general')([branch1l, branch2l])\r\nconcat = Concatenate(axis=-1)([attention1, attention2])\r\n\r\n# Process concatenated output\r\nout = Bidirectional(LSTM(80, activation='elu', kernel_regularizer=l2(0.01)))(concat)\r\nout = Dense(1, activation='sigmoid')(out)\r\n\r\nmodel = Model(inputs=[in1, in2], outputs=[out])\r\nmodel.compile(loss='mean_squared_error', \r\n              optimizer='adam', metrics=['mean_absolute_error'])\r\nmodel.summary()\r\n\r\n# Fit the model\r\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\r\n\r\nmy_callbacks = [\r\n    ReduceLROnPlateau(factor=0.25, mode=\"min\")\r\n]\r\n\r\nhistory2 = model.fit([X_train[:, 0, :], X_train[:, 1, :]],\r\n                    y_train, \r\n                    epochs=epochs, \r\n                    validation_split=0.2,\r\n                    use_multiprocessing=True,\r\n                    sample_weight=sample_weights,\r\n                    callbacks=my_callbacks)\r\n```", "@adityapaul  In the behaviour statement you have written \"elu\" instead of \"relu\" in the activation section !\r\nThis might help!", "@sarthak3248 Hmmm, I had used ELU activations in the two models that were portable to TF 2.3, so I'm not too sure if that's the problem I'm facing. Thank you though!", "@sarthak3248,\r\nOn running the code, I am facing an error stating `NameError: name 'max_len' is not defined`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/1ad2d0ac60ece6190c4fe1f37b606cb8/42106.ipynb). \r\n\r\nCould you please provide the complete code and the dataset you are using to save the model? Thanks!", "Sure. The full code is here:\r\n\r\n```python\r\nimport csv\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\n# read in sentence dataset\r\nwith open('SICK.txt', 'r') as file:\r\n    sdf = pd.read_table(file)\r\n\r\n# re-edit scores so that it's a single relatedness measure\r\nscoreAB = []\r\nscoreBA = []\r\nfor pair in sdf.iterrows():\r\n    if pair[1]['entailment_AB'] == 'A_entails_B':\r\n        scoreAB.append(pair[1]['relatedness_score'] - 1)\r\n    elif pair[1]['entailment_AB'] == 'A_neutral_B':\r\n        scoreAB.append(pair[1]['relatedness_score'] - 3)\r\n    else:\r\n        scoreAB.append(1 - pair[1]['relatedness_score'])\r\n    if pair[1]['entailment_BA'] == 'B_entails_A':\r\n        scoreBA.append(pair[1]['relatedness_score'] - 1)\r\n    elif pair[1]['entailment_BA'] == 'B_neutral_A':\r\n        scoreBA.append(pair[1]['relatedness_score'] - 3)\r\n    else:\r\n        scoreBA.append(1 - pair[1]['relatedness_score'])\r\nsdf['relatedness_score_AB'] = scoreAB\r\nsdf['relatedness_score_BA'] = scoreBA\r\n\r\n# define hyperparameters\r\nvocab_size = None\r\noov_tok = '<OOV>'\r\nmax_len = 75\r\npad_pos = 'post'\r\ntrunc_pos = 'post'\r\nembedding_dim = 50\r\nepochs = 25\r\nemb_trainable = False\r\nuse_embedding = True\r\ndim_factor = 0.7\r\nout_range = (0, 1)\r\n\r\n# A little bit of preprocessing\r\n\r\n# First, add beginning and end of string words\r\ntrim = lambda x: x #\"<BOS> \" + x + \" <EOS>\" if \"<BOS>\" not in x else x\r\n\r\nsdf['sentence_A'] = sdf['sentence_A'].apply(trim)\r\nsdf['sentence_B'] = sdf['sentence_B'].apply(trim)\r\nsdf['sentence_A_original'] = sdf['sentence_A_original'].apply(trim)\r\nsdf['sentence_B_original'] = sdf['sentence_B_original'].apply(trim)\r\n\r\nfrom tensorflow.keras.preprocessing.text import Tokenizer\r\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\r\n\r\ntokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\r\ntokenizer.fit_on_texts(sdf['sentence_A'] + \r\n                       sdf['sentence_B'] + \r\n                       sdf['sentence_A_original'] + \r\n                       sdf['sentence_B_original'])\r\nsa = tokenizer.texts_to_sequences(sdf['sentence_A'])\r\nsb = tokenizer.texts_to_sequences(sdf['sentence_B'])\r\nsao = tokenizer.texts_to_sequences(sdf['sentence_A_original'])\r\nsbo = tokenizer.texts_to_sequences(sdf['sentence_B_original'])\r\n\r\nsa = pad_sequences(sa, maxlen=max_len, padding=pad_pos, truncating=trunc_pos)\r\nsb = pad_sequences(sb, maxlen=max_len, padding=pad_pos, truncating=trunc_pos)\r\nsao = pad_sequences(sao, maxlen=max_len, padding=pad_pos, truncating=trunc_pos)\r\nsbo = pad_sequences(sbo, maxlen=max_len, padding=pad_pos, truncating=trunc_pos)\r\n\r\n# construct sentence dataset\r\nds_pairs = (sa, \r\n            sb, \r\n            sdf['relatedness_score_AB'])\r\norig_pairs = (sao, \r\n              sbo, \r\n              [dim_factor * x for x in sdf['relatedness_score_AB']])\r\n\r\n# construct reversed semantic relationships\r\nds_pairs_reversed = (sb, \r\n                     sa, \r\n                     sdf['relatedness_score_BA'])\r\norig_pairs_reversed = (sbo,\r\n                       sao,\r\n                       [dim_factor * x for x in sdf['relatedness_score_BA']])\r\n\r\n\"\"\"\r\nuncomment to include reversed semantic relationships in dataset\r\n\"\"\"\r\n# ds_pairs = np.concatenate([ds_pairs, ds_pairs_reversed])\r\n# orig_pairs = np.concatenate([orig_pairs, orig_pairs_reversed])\r\n\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.preprocessing import MinMaxScaler\r\n\r\n# set up\r\nX_ds = np.transpose(np.array([ds_pairs[0], ds_pairs[1]]), axes=(1,0,2))\r\nX_orig = np.transpose(np.array([orig_pairs[0], orig_pairs[1]]), axes=(1,0,2))\r\ny_ds = np.array(ds_pairs[2])\r\ny_orig = np.array(orig_pairs[2])\r\n\r\n# normalize the output values for the sake of everything\r\nscaler = MinMaxScaler(feature_range=out_range)\r\nscaler.fit(np.concatenate([y_ds, y_orig]).reshape(-1, 1))\r\ny_ds = scaler.transform(y_ds.reshape(-1, 1)).transpose()[0, :]\r\ny_orig = scaler.transform(y_orig.reshape(-1, 1)).transpose()[0, :]\r\n\r\n\"\"\"\r\nUncomment to incorporate original sentences into training set.\r\nNot recommended, because semantic relationships aren't as strong.\r\nTune hyperparameter dim_factor to establish how much you want to edit score.\r\n\"\"\"\r\n# X = np.concatenate([X_ds, X_orig])\r\n# y = np.concatenate([y_ds, y_orig])\r\n\r\n# Split up \r\nX = X_ds\r\ny = y_ds\r\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None)\r\n\r\n# We define the embedding layer here.\r\nimport os\r\n\r\nembeddings_index = {}\r\nf = open(os.path.join('./glove', 'glove.6B.50d.txt'))\r\nfor line in f:\r\n    values = line.split()\r\n    word = values[0]\r\n    coefs = np.asarray(values[1:], dtype='float32')\r\n    embeddings_index[word] = coefs\r\nf.close()\r\n\r\nprint('Found %s word vectors.' % len(embeddings_index))\r\n\r\nembedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embedding_dim))\r\nfor word, i in tokenizer.word_index.items():\r\n    embedding_vector = embeddings_index.get(word)\r\n    if embedding_vector is not None:\r\n        # words not found in embedding index will be all-zeros.\r\n        embedding_matrix[i] = embedding_vector\r\n\r\n# Build the model\r\nfrom tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Attention\r\nfrom tensorflow.keras.layers import Dense, Concatenate, Reshape\r\nfrom tensorflow.keras.activations import linear\r\nfrom tensorflow.keras.regularizers import l1, l2, l1_l2\r\nfrom tensorflow.keras.models import Model\r\n\r\nin1 = Input((max_len,))\r\nin2 = Input((max_len,))\r\n\r\nemb = Embedding(len(tokenizer.word_index) + 1, \r\n                embedding_dim, \r\n                input_length=max_len)\r\nif use_embedding: \r\n    emb = Embedding(len(tokenizer.word_index) + 1, \r\n                    embedding_dim, \r\n                    weights=[embedding_matrix],\r\n                    input_length=max_len, \r\n                    trainable=emb_trainable)\r\n\r\n# First sequence branch\r\nbranch1 = emb(in1)\r\nbranch1l = Bidirectional(LSTM(25, \r\n                              activation='elu', \r\n                              return_sequences=True, \r\n                              kernel_regularizer=l2(0.01)))(branch1)\r\n\r\n# Second sequence branch\r\nbranch2 = emb(in2)\r\nbranch2l = Bidirectional(LSTM(25, \r\n                              activation='elu', \r\n                              return_sequences=True, \r\n                              kernel_regularizer=l2(0.01)))(branch2)\r\n\r\n# Concatenate with Luong attention (eventually add word embedding as value)\r\nattention1 = Attention(use_scale=True)([branch1, branch2])\r\nattention2 = Attention(use_scale=True)([branch1l, branch2l])\r\nconcat = Concatenate(axis=-1)([attention1, attention2])\r\n\r\n# Process concatenated output\r\nout = Bidirectional(LSTM(80, activation='elu', kernel_regularizer=l2(0.01)))(concat)\r\nout = Dense(1, activation='sigmoid')(out)\r\n\r\nmodel = Model(inputs=[in1, in2], outputs=[out])\r\nmodel.compile(loss='mean_squared_error', \r\n              optimizer='adam', \r\n              metrics=['kullback_leibler_divergence'])\r\nmodel.summary()\r\n\r\n# Fit the model\r\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\r\n\r\nmy_callbacks = [\r\n    ReduceLROnPlateau(factor=0.25,\r\n                      mode=\"min\")\r\n]\r\n\r\nhistory1 = model.fit([X_train[:, 0, :], X_train[:, 1, :]],\r\n                    y_train, \r\n                    epochs=epochs, \r\n                    validation_split=0.2,\r\n                    callbacks=my_callbacks)\r\n\r\nmodel.evaluate([X_test[:, 0, :], X_test[:, 1, :]], y_test, batch_size=25)\r\n```\r\n\r\nThe SICK dataset is attached [here](https://github.com/tensorflow/tensorflow/files/5065041/SICK.txt). The 50-dimensional GloVe vectors are too large to upload here, but can be downloaded with\r\n\r\n```bash\r\nwget http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\r\nunzip glove.6B.zip -d glove/\r\nrm glove.6B.zip\r\n```", "@adityapaul,\r\nThank you for the update. \r\n\r\n@jvishnuvardhan,\r\nI was able to reproduce the issue with TF v2.3 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/25901ff72e3e0acd95aafc418e0d0941/42106.ipynb#scrollTo=maIk1n0vuAML). Thanks!", "@adityapaul I see a deprecation warning on your model save:\r\n> WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\nINFO:tensorflow:Assets written to: saved_model/my_model/assets\r\n", "Was able to replicate the issue in TF 2.6.0-dev20210603,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/0dd9026dab55cbaf2a9c22cc564ba409/untitled219.ipynb)..Thanks !"]}, {"number": 42098, "title": "[Tensorflow Lite] MobileBert Inferencing Latency on mobile device significantly slower than expected", "body": "I am trying to run the BERT Question and Answer demo outlined on [this page](https://www.tensorflow.org/lite/models/bert_qa/overview), which demonstrates inferencing MobileBert on a mobile device.\r\n\r\nI have cloned the relevant Android repository code found [here](https://github.com/tensorflow/examples/tree/master/lite/examples/bert_qa/android), and deployed the project to my Pixel 3 device.\r\n\r\nThe demo runs, however it takes significantly longer than expected: according to this [blog post](https://blog.tensorflow.org/2020/04/whats-new-in-tensorflow-lite-from-devsummit-2020.html), model latency should be around 74ms, however I'm seeing latency on the order of 500ms.\r\n\r\nCan someone please advise if there's some setting/configuration that I'm missing? I have noted that the supplied MobileBert model is Float32 and so hasn't been quantised which means it won't use any hardware acceleration. I've also noted that no delegate has been specified to leverage any dedicated hardware acceleration (e.g. GPU).\r\n\r\nNote: I'm submitting this issue here, as there's no option to submit issues under the relevant [examples](https://github.com/tensorflow/examples) repository. Please do let me know if I should be raising this query elsewhere.\r\n\r\nThanks in advance for any assistance/advice you can provide :)\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Pixel 3\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: n/a\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n**Describe the current behavior**\r\n\r\nQuery inferencing time is ~500ms.\r\n\r\n**Describe the expected behavior**\r\n\r\nQuery inference time should be closer to 74ms.\r\n\r\n**Standalone code to reproduce the issue**\r\nI used the code from the example project repository verbatim (without any changes/customisations).", "comments": ["Just checking in to see if anyone has had an opportunity to look at this issue?\r\n\r\nI also have an update from our side:\r\n\r\nwe updated to Tensorflow 2.3.0 on the mobile device, and found that the inference time for Albert dropped down to ~800 ms, while the inference time for MobileBERT remained the same (~500ms).\r\n\r\nFurther, I noted that the authors of [SqeezeBERT](https://arxiv.org/pdf/2006.11316.pdf) obtained similar inference latencies to us, also using a Pixel 3 device.", "Renjie, Can you please help check what is wrong with the setup\r\n\r\nThanks", "Hi, \r\n\r\nThe blog post is benchmarking for a 128 seq_len model on pixel4 with 4 threads.\r\n\r\nFor the qa task app, it's using a 384 seq_len model, and I don't think it's using 4 threads.\r\n\r\nAlso, pixel4 is faster than pixel3, so I guess the number is expected."]}, {"number": 42075, "title": "Hello World example project's generated binary is empty for Bluepill", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOs Catalina version 10.15.3\r\n- TensorFlow installed from (source or binary): source\r\n- Tensorflow version (commit SHA if source): 89851a6a7725d92735e9817ee6a1f551dd7492ab\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): Bluepill\r\n\r\n**Describe the problem**\r\nWhen I build the Hello World Tensorflow Lite example project for the blue pill microcontroller, the resulting binary is empty. This is demonstrated when I objdump the resulting ELF file:\r\n\r\n```\r\nbluepill_cortex-m3/bin/hello_world:     file format elf32-littlearm\r\n\r\n\r\n\r\n\r\nDisassembly of section ._user_heap_stack:\r\n\r\n\r\n20000000 <._user_heap_stack>:\r\n    ...\r\n\r\n```\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\nBuild the Hello World binary by specifying the bluepill as target:\r\n```\r\ngmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=bluepill hello_world_bin\r\n```\r\nThen see the objdump of the ELF:\r\n```\r\ntensorflow/tensorflow/lite/micro/tools/make/downloads/gcc_embedded/arm-none-eabi/bin/objdump tensorflow/tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/bin/hello_world -D\r\n```\r\n", "comments": []}, {"number": 42070, "title": "Universal Multiple Optimizer Wrapper with Layer Assignment", "body": "I am proposing a universal wrapper for a layer-wise set of distinct optimizers. This will allow each optimizer in a set of optimizers to apply the gradient to its layer-wise variables. This will enable discriminative layer training. It will also enable any training method that applies any combination of optimizers to any combination of layers at any combination of hyperparameters for those optimizers.\r\n\r\nThe optimizer wrapper will consume a list of instantiated optimizers and layers, referred to as an optimizer spec. For each optimizer spec, it will allocate the correct gradients and variables and then call the apply_gradients method for the optimizer. This allows the optimizer wrapper to leverage all implementations of optimizer specific operations, notably the resource apply methods. \r\n\r\nA prototype of the optimizer wrapper is available at this link. [link](https://colab.research.google.com/drive/1NKAsrjj1qcls6p8S5dvJT1PkdC2Ieazc?usp=sharing)\r\n\r\nThe prototype works on both TPU and CPU. \r\n\r\nI am willing to contribute this code. \r\n\r\nThis will not change any existing classes. Instead, it will act as a wrapper that allows a model to use multiple optimizers. \r\n\r\nDiscriminative layer training is most beneficial for fine tuning pretrained models. Users looking to apply existing technology will benefit in reduced training time and improved transfer learning. \r\n\r\n", "comments": []}, {"number": 42066, "title": "[Docs] RAM usage when building from source", "body": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/install/source\r\n\r\n## Description of issue (what needs changing):\r\nAproximately the RAM that used when compiling. IMO, \"Building TensorFlow from source can use **a lot of** RAM\", is not clear how \"a lot of\" is how many GB. I have VM with 6vCPU 10GB RAM and I frequently run out of memory. This run out of memory is not only slowing down the compiling, but also make system freeze/unresponsive, Every this happens, I need to increase the RAM by 500MB to unlock the system.\r\n\r\n### Clear description\r\nWhy we need this? Because we don't want to sleep with the machine compiling overnight. And when we wakes up, it turns out the compiling failed, or the machine frozen, and it's really waste of time. This \"aproximately RAM usage\" should help anticipate this though.\r\n\r\n### How about `--local_ram_resources`?\r\nWell, I already tried with this flag `--local_ram_resources=HOST_RAM*.2` as described from [here](https://docs.bazel.build/versions/master/user-manual.html#flag--local_{ram,cpu}_resources). Is this mean the building process will only take 20% RAM? Is this global or for every thread? Is this flag supported on the `v2.3.0` tag on this repo? I watched `htop` and seen many tasks at once using more than 20%. I run out of memory again even with this, this is ridiculous. \ud83d\ude2d \r\n\r\n### Submit a pull request?\r\nTo this [repo](https://github.com/tensorflow/docs)? Yes if I can get how aproximately the RAM usage... I think it's max around 3GB per CPU core? Correct me if I'm wrong.\r\n\r\n### Other information\r\nWell it seems I got a lot of RAM, but I running out of memory. The VM is live CD (not installed), and also the swap.... yeah it's zram (5GB) instead of swapfile. Because... uh..., I don't want to kill the SSD :(\r\n\r\n### Related issue\r\n#30047", "comments": ["https://community.arm.com/developer/ip-products/processors/b/ml-ip-blog/posts/building-bazel-and-tensorflow-2-x-on-aarch64\r\n> Using --local_ram_resources=1600 won't limit gcc or clang building individual kernels and can cause an unrecoverable compiler crash on machines with less than 4GB \r\n\r\n/cc @gunan", "@bhack, I think that is a common issue for all build frameworks, no?\r\nIf there is a compiler flag, you can always set the flag to limit compiler memory usage with `--copt`\r\nHow does cmake/make handle this?", "@gunan Other than globally reducing jobs (or going ahead to explore `--copt` for finentuing compiler settings) I think that there could be some \"clustering tricks\" if you have some domain information. E.g. see Blender with Ninja https://developer.blender.org/D4780?id=", "@gunan Do you know some internals of the Bazel (very crude) estimates heuristic on the single job?\r\n\r\nhttps://docs.bazel.build/versions/master/user-manual.html#flag--jobs\r\n\r\n> Note that the number of concurrent jobs that Bazel will run is determined not only by the --jobs setting, but also by Bazel's scheduler, which tries to avoid running concurrent jobs that will use up more resources (RAM or CPU) than are available, based on some (very crude) estimates of the resource consumption of each job. The behavior of the scheduler can be controlled by the --local_ram_resources option. ", "Eh alternatively, I could futher reduce the RAM usage by using `--local_cpu_resources` instead of `--local_ram_resources`. I think this should be mentioned on the install documentation?", "@Smankusors I don't know if in your case there is a specific error on this API call cause you are inside the virtual machine. If you see this line of code the exception don't print any warning:\r\nhttps://github.com/bazelbuild/bazel/blob/master/src/main/java/com/google/devtools/build/lib/actions/ResourceManager.java#L392", "@Smankusors Can you test with `--experimental_local_memory_estimate`?", "I do not know about the internal bazel heuristics, but bazel by default sets the value of jobs to value of CPU.\r\nI have seen (similarly with cmake) that for smaller systems this is still too much, so you have to further limit, by doing --jobs=1 or 2\r\n", "I have 64 GB, i never run out of Memory, it hovers around 14 to 15 GB when building. If you have 10GB, that may be low, because bazel server alone takes about 10G and check your Swap as well.", "> @Smankusors Can you test with `--experimental_local_memory_estimate`?\r\n\r\nHmm... I will try this later\r\n\r\n> I have 64 GB, i never run out of Memory, it hovers around 14 to 15 GB when building. If you have 10GB, that may be low, because bazel server alone takes about 10G and check your Swap as well.\r\n\r\nInteresting, how many CPU cores do you have? I see mine around 2-3 GB used by Bazel server", "@Smankusors 24 threads", "The MacPorts project has been suffering from this problem for a long time: https://trac.macports.org/ticket/58932\r\n\r\n> bazel server alone takes about 10G.\r\n\r\nThat would be an absolutely batshit crazy requirement.", "Have you explored all the solutions in https://docs.bazel.build/versions/master/memory-saving-mode.html?", "I'll suggest that to our maintainer of tensorflow. However it is not, as that page says, that we \"may want Bazel to use minimal memory\". I would be delighted for Bazel to use all of the available memory, but currently it uses much more than the available memory, and I am guessing that the swapping that this incurs is what is slowing down our builds. Don't you think that using almost all of the available memory, but not more than that, would be a good default behavior for the build system to have?", "In that case we are more in bazel domain and Its repo than in TF. \nYou need to check also Bazel scheduler performance for the parallel build. See https://docs.bazel.build/versions/master/user-manual.html#flag--jobs", "See also https://jmmv.dev/2019/12/bazel-local-resources.html for extra details.", "I know how `--jobs` works and I read the other document before I found this bug report. Nobody wants to set twelve flags to unknown magic values to get the build system to do what it should do by default.", "> I know how `--jobs` works and I read the other document before I found this bug report. Nobody wants to set twelve flags to unknown magic values to get the build system to do what it should do by default.\n\nIt could be ok but I don't think we could solve this here. Probably you need to open a bazel ISSUE or comment on an exsisting one in its repo if you want to improve bazel heuristics. "]}, {"number": 42049, "title": "Binary won't build for hello world.", "body": "**System information**\r\n\r\n-Catalina \r\n-System default Python 3.8.5\r\n-Spark edge 1\r\n-Make version 4.3\r\n\r\n**Describe the problem**\r\n\r\nWhile trying to build for the hello world binary, I get the following error. \r\n\r\n```\r\nmake: tensorflow/lite/experimental/micro/tools/make/Makefile: No such file or directory\r\n\r\nmake: *** No rule to make target 'tensorflow/lite/experimental/micro/tools/make/Makefile'.\r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n-My make version was lower than 3.2, so I changed my make version to 4.3.\r\n\r\n-make -f tensorflow/lite/micro/tools/make/Makefile \\\r\n  TARGET=sparkfun_edge hello_world_bin\r\n\r\n**Any other info / logs**\r\n\r\n-Please help. I need to get this working. I really want to learn this. \r\n\r\n@dansitu", "comments": ["@ymodak do you have any suggestions? ", "Did you change your directory to tensorflow before running make command?\r\n`cd tensorflow`\r\n`make -f tensorflow/lite/micro/tools/make/Makefile TARGET=sparkfun_edge hello_world_bin`", "@ymodak yes...this is what its tells me. \r\n\r\n```\r\nadammazurick@Adams-Mac-Pro ~ % cd tensorflow\r\nadammazurick@Adams-Mac-Pro tensorflow % make -f tensorflow/lite/micro/tools/make/Makefile TARGET=sparkfun_edge hello_world_bin\r\ntensorflow/lite/micro/tools/make/Makefile:2: *** \"Requires make version 3.82 or later (current is 3.81)\".  Stop.\r\nadammazurick@Adams-Mac-Pro tensorflow % make --version\r\nGNU Make 3.81\r\nCopyright (C) 2006  Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.\r\nThere is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A\r\nPARTICULAR PURPOSE.\r\n\r\nThis program built for i386-apple-darwin11.3.0\r\nadammazurick@Adams-Mac-Pro tensorflow % \r\n```", "Looks like your make version is not updated as you mentioned in issue thread. Can you please try upgrading your make version as mentioned in the logs? Thanks!", "So this is the thing. I tried upgrading Make from 3.8 to 4.1 using this method. https://stackoverflow.com/questions/43175529/updating-make-version-4-1-on-mac It does not work. ", "`adammazurick@Adams-Mac-Pro ~ % brew install homebrew/core/make\r\nWarning: make 4.3 is already installed and up-to-date\r\nTo reinstall 4.3, run `brew reinstall make`\r\nadammazurick@Adams-Mac-Pro ~ % `", "@ymodak So the default make is 3.81 but it's installed. So what should I do? ", "Homebrew installs dependencies in a directory tree that needs to be added to the PATH before they will work. Right now your system is only able to see its own version of make, not Homebrew's version.\r\n\r\nYou can get some help on system set-up by running `brew doctor`.", "@dansitu \r\nFirst, your book is awesome. It has lots of helpful tutorials and documentation. \r\n\r\nSecond, I have a 2020 Mac Pro Tower and Lamda Labs machine that I configured for Machine Learning tasks. On both Machines, it fails.\r\n\r\nBoth machines are for grad research, practice and model architecture, design and training. \r\n\r\nThe Mac Pro tower came with a 3.8 version of Python installed as the default. I believe it was a 3.8 release. I was surprised to see a 3.8 default python version in the fresh factory unit. I downgraded and then changed all sorts of settings in the terminal to try to fix the make version issue. \r\n\r\nSo sadly, the issue is not resolved. I feel its best to reformat one machine and start the labs from scratch trying what @dansitu mentioned. \r\n\r\nI may reach out next week with further questions. Thank you for your help. ", "Thanks for your kind words, @mazurick!\r\n\r\nIf you don't want to do a full reformat, maybe you could try running in a Docker container where you can play with the dependencies freely? An Ubuntu container should work, and you can presumably use aptitude to install the right version of Make.", "Thanks @dansitu. Would you use Stable or Edge in my case? https://www.docker.com/products/docker-desktop", "I think Stable should be fine!", "Hey Daniel,\r\n\r\nSadly I had to reformat my device so this is a fresh machine. The actual support ticket at Apple was mad. Something I did was horribly wrong. I hope now to proceed and continue tests on a fresh machine using containers.\r\n\r\nI\u2019m a little new to containerization with docker.\r\n\r\nI\u2019ve completed Chapter 5 and I\u2019m moving into Chapter 6 and I hope to deploy to my SparkFun Edge\r\n\r\n#29524 (comment)\r\n\r\nI\u2019m at the point in the book where you ask us to install the dependencies.\r\n\r\npip3 install pycrypto pyserial --user\r\n\r\n8 days ago I got this tip here.\r\n\r\n#29524 (comment)\r\n\r\nShould I take the following steps\r\n\r\n1. Set-up a container.\r\n2. Put pycrypto and related dependencies including the Tensorflow directory into the container?\r\n3. Build the binary\r\nDid I get that right? How would I proceed knowing the information you gave me today above and what @joslefaure said in the above link?", "If you could provide itemized steps I would be so thankful. \r\n", "Yep, it sounds like you're on the right track! Just shell into your Docker\ncontainer and run all the commands in there. Bear in mind that the\nprocesses might have changed a little since the book was printed, so check\nthe readmes in the TensorFlow repo for the most up to date info. For\nexample:\n\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/hello_world/README.md\n\nOn Mon, Sep 7, 2020 at 10:08 AM Adam Mazurick <notifications@github.com>\nwrote:\n\n> Hey Daniel,\n>\n> Sadly I had to reformat my device so this is a fresh machine. The actual\n> support ticket at Apple was mad. Something I did was horribly wrong. I hope\n> now to proceed and continue tests on a fresh machine using containers.\n>\n> I\u2019m a little new to containerization with docker.\n>\n> I\u2019ve completed Chapter 5 and I\u2019m moving into Chapter 6 and I hope to\n> deploy to my SparkFun Edge\n>\n> #29524 <https://github.com/tensorflow/tensorflow/issues/29524> (comment)\n>\n> I\u2019m at the point in the book where you ask us to install the dependencies.\n>\n> pip3 install pycrypto pyserial --user\n>\n> 8 days ago I got this tip here.\n>\n> #29524 <https://github.com/tensorflow/tensorflow/issues/29524> (comment)\n>\n> Should I take the following steps\n>\n>    1. Set-up a container.\n>    2. Put pycrypto and related dependencies including the Tensorflow\n>    directory into the container?\n>    3. Build the binary\n>    Did I get that right? How would I proceed knowing the information you\n>    gave me today above and what @joslefaure\n>    <https://github.com/joslefaure> said in the above link?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/42049#issuecomment-688441075>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAC4SY4MEIMXCFEPBZTTZXTSEUHQNANCNFSM4PU4QEIQ>\n> .\n>\n\n\n-- \nDaniel Situnayake\nFounding TinyML Engineer, Edge Impulse <http://edgeimpulse.com/>\ndan@edgeimpulse.com\n+1 415-940-2607\nTwitter <http://twitter.com/dansitu> | LinkedIn\n<http://linkedin.com/in/situnayake>\n", "There are lots of walkthroughs in the readme:\n\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/hello_world/README.md#deploy-to-sparkfun-edge\n\nOn Mon, Sep 7, 2020 at 10:11 AM Adam Mazurick <notifications@github.com>\nwrote:\n\n> If you could provide itemized steps I would be so thankful.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/42049#issuecomment-688442422>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAC4SY4YSGBFGQMPL44L5IDSEUH53ANCNFSM4PU4QEIQ>\n> .\n>\n\n\n-- \nDaniel Situnayake\nFounding TinyML Engineer, Edge Impulse <http://edgeimpulse.com/>\ndan@edgeimpulse.com\n+1 415-940-2607\nTwitter <http://twitter.com/dansitu> | LinkedIn\n<http://linkedin.com/in/situnayake>\n", "Thanks @dansitu \r\n\r\n//Steps Adam has/is taking to get running\r\n\r\n//Step 1: Use containers and docker. \r\n\r\nWhat I've done is I've taken a quick tutorial this afternoon to learn containerization. I wasn't familiar with the commands of docker and how to start-up a container. I'm almost done this now. I'm making dummy containers for learning purposes.  \r\n\r\n//Step 2: Shell into docker container ***Adam is here now\r\n\r\nI believe what you are referencing here is the 'docker exec' command. From what I've learned, this command is sort of like 'ssh-ing' into the container. It lets us \"jump\" into the detached container running in the background as if we were in our shell?\r\n\r\n//Step 3: Install dependencies. \r\n\r\npip install pycrypto pyserial --user\r\n\r\nI'm not to sure about how to manage this yet. I guess I would download this into the container and not at the user level. I like this idea because it's a large dependency and I want to use containers more. It's sound advice. \r\n\r\nI'm assuming I would change the user flag to a directory command and location. \r\n\r\n//Step 4:  Clone the TensorFlow repository, and then change into its directory in Docker. \r\n\r\n\r\n//Step 5: Docker build? \r\n\r\nI will try steps 1-5 and see how it goes. ", "@dansitu I am very thankful for your help and will reference the documentation. ", "Sounds good\u2014you can also use a regular VM if it's simpler than figuring out\nDocker, which is a fairly confusing experience.\n\nOn Mon, Sep 7, 2020 at 11:21 AM Adam Mazurick <notifications@github.com>\nwrote:\n\n> @dansitu <https://github.com/dansitu> I am very thankful for your help\n> and will reference the documentation.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/42049#issuecomment-688464639>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAC4SY4VW2DGVW5GJ3FVZ4LSEUQEFANCNFSM4PU4QEIQ>\n> .\n>\n\n\n-- \nDaniel Situnayake\nFounding TinyML Engineer, Edge Impulse <http://edgeimpulse.com/>\ndan@edgeimpulse.com\n+1 415-940-2607\nTwitter <http://twitter.com/dansitu> | LinkedIn\n<http://linkedin.com/in/situnayake>\n", "Hey @dansitu , \r\n\r\nI decided to Spin-up a VM instead of using Docker as per your suggestion. \r\nI\u2019m at the build the binary stage, I use the following command from the git repo you shared earlier. \r\n\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=sparkfun_edge hello_world_bin\r\n\r\nThe output is here.\r\n\r\ntensorflow/lite/micro/tools/make/Makefile:2: *** \"Requires make version 3.82 or later (current is 3.81)\". Stop.\r\n\r\nWhat should I do?", "I appear to have fixed the make issue using brew and changing my commands to Gmake as is required by documentation. That said, I'm trying to deploy and got the following...\r\n", "python3 /Users/maz/Desktop/tiny/tensorflow/tensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/tools/apollo3_scripts/uart_wired_update.py -b ${921600} ${usbserial-1440} -r 1 -f main_nonsecure_wire.bin -i 6\r\n/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.7/Resources/Python.app/Contents/MacOS/Python: can't open file '/Users/maz/Desktop/tiny/tensorflow/tensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/tools/apollo3_scripts/uart_wired_update.py': [Errno 2] No such file or directory\r\n(ll_env) maz@Adams-Mac-Pro tiny % python3 /Users/maz/Desktop/tiny/tensorflow/tensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/tools/apollo3_scripts/uart_wired_update.py -b ${921600} ${usbserial-1440} -r 1 -f main_nonsecure_wire.bin -i 6\r\nusage: uart_wired_update.py [-h] [-b BAUD] [--raw RAW] [-f BINFILE]\r\n                            [-i {0,1,2,3,4,5,6,7,32,255}] [-o OTADESC]\r\n                            [-r {0,1,2}] [-a {0,1,-1}] [--split SPLIT]\r\n                            port\r\nuart_wired_update.py: error: the following arguments are required: port\r\n(ll_env) maz@Adams-Mac-Pro tiny % python3 /Users/maz/Desktop/tiny/tensorflow/tensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/tools/apollo3_scripts/uart_wired_update.py -b ${921600} ${usbserial-1440} -r 1 -f main_nonsecure_wire.bin -i 6\r\nusage: uart_wired_update.py [-h] [-b BAUD] [--raw RAW] [-f BINFILE]\r\n                            [-i {0,1,2,3,4,5,6,7,32,255}] [-o OTADESC]\r\n                            [-r {0,1,2}] [-a {0,1,-1}] [--split SPLIT]\r\n                            port\r\nuart_wired_update.py: error: the following arguments are required: port\r\n(ll_env) maz@Adams-Mac-Pro tiny % \r\n\r\n", "Glad you've gotten further! It looks like you are using some funky syntax in the line where you are running `wired_update.py`. Can you try removing the `${}` that is wrapping a couple of the arguments?", "Also: I'm not sure how USB and virtual machines interact, but if the upload fails it's possible you might have to run this on the host machine, not the VM.", "> @ymodak So the default make is 3.81 but it's installed. So what should I do?\r\n\r\nAfter installing the newest version of make, run this in your terminal: `export PATH=\"/usr/local/opt/make/libexec/gnubin:$PATH\"`", "Is your problem solved?\r\nI have a similar problem.\r\n\r\nThe code I entered is:\r\n  PS E:\\> cd tensorflow\r\n  PS E:\\tensorflow> make -f tensorflow/lite/micro/tools/make/Makelifile test_hello_world_test\r\nThe results show \r\n  make: tensorflow/lite/micro/tools/make/Makelifile: No such file or directory\r\n  make: *** No rule to make target 'tensorflow/lite/micro/tools/make/Makelifile'.  Stop.\r\nI am using Windows system\uff0cmake version is 3.82.90.\r\nHow can I solve this problem?", "Noticed the typo `Makelifile`? Should be `Makefile`. Tell us if it doesn't work.", "> Noticed the typo ? Should be . Tell us if it doesn't work.`Makelifile``Makefile`\r\n\r\n\r\nprocess_begin: CreateProcess(NULL, uname -m, ...) failed.\r\n\u6b64\u65f6\u4e0d\u5e94\u6709 -m\u3002\r\nFIND: \u53c2\u6570\u683c\u5f0f\u4e0d\u6b63\u786e\r\nFIND: \u53c2\u6570\u683c\u5f0f\u4e0d\u6b63\u786e\r\n\u547d\u4ee4\u8bed\u6cd5\u4e0d\u6b63\u786e\u3002\r\nprocess_begin: CreateProcess(NULL, bash E:\\tensorflow\\tensorflow\\lite\\micro\\tools\\make\\flatbuffers_download.sh tensorflow/lite/micro/tools/make/downloads, ...) failed.\r\ntensorflow/lite/micro/tools/make/Makefile:403: *** Something went wrong with the flatbuffers download: .  Stop."]}, {"number": 42035, "title": "hang in recursive call of google::protobuf::DescriptorPool::FindFileByName", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.3.0\r\n- Python version: 3.8.0\r\n- Bazel version (if compiling from source): 3.1\r\n- GCC/Compiler version (if compiling from source): 5.4\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: -\r\n\r\n**Describe the current behavior**\r\n\r\nTensorFlow hangs at import (`import tensorflow`).\r\nThe only output I see is:\r\n```\r\n2020-08-04 17:42:26.693993: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nTensorFlow should not hang at import.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\nimport tensorflow\r\n```\r\n\r\n**Other info / logs**\r\n\r\nI attached GDB, and the stacktrace is interesting. I posted it [here](https://gist.github.com/albertz/f46a19276c95af5900833c98f47742a8).\r\n\r\nThe relevant part:\r\n```\r\n#0  __lll_lock_wait () at ../sysdeps/unix/sysv/linux/x86_64/lowlevellock.S:135\r\n#1  0x00007ffff7620dbd in __GI___pthread_mutex_lock (mutex=0xe6cfb0) at ../nptl/pthread_mutex_lock.c:80\r\n#2  0x00007fffd03f5d91 in google::protobuf::DescriptorPool::FindFileByName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const ()\r\n   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#3  0x00007fffd044328e in google::protobuf::(anonymous namespace)::AssignDescriptorsImpl(google::protobuf::internal::DescriptorTable const*) ()\r\n   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#4  0x00007ffff7625a99 in __pthread_once_slow (\r\n    once_control=0x7fffd0ee5d74 <descriptor_table_google_2fprotobuf_2fdescriptor_2eproto_once>, \r\n    init_routine=0x7fffed339ac0 <std::__once_proxy()>) at pthread_once.c:116\r\n#5  0x00007fffd0436d46 in google::protobuf::internal::AssignDescriptors(google::protobuf::internal::DescriptorTable const*)\r\n    ()\r\n   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#6  0x00007fffd0405590 in google::protobuf::FileOptions::GetMetadata() const ()\r\n   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#7  0x00007fffd0461e98 in google::protobuf::Message::GetTypeName[abi:cxx11]() const ()\r\n   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#8  0x00007fffd050a178 in google::protobuf::(anonymous namespace)::ByteSizeConsistencyError(unsigned long, unsigned long, unsigned long, google::protobuf::MessageLite const&) [clone .constprop.38] ()\r\n   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#9  0x00007fffd050b61c in google::protobuf::MessageLite::AppendPartialToString(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*) const ()\r\n   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#10 0x00007fffd050b92e in google::protobuf::MessageLite::SerializeAsString[abi:cxx11]() const ()\r\n   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#11 0x00007fffd03ecd12 in void google::protobuf::DescriptorBuilder::AllocateOptionsImpl<google::protobuf::FileDescriptor>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, google::protobuf::FileDescriptor::OptionsType const&, google::protobuf::FileDescriptor*, std::vector<int, std::allocator<int> > const&) ()\r\n   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#12 0x00007fffd03ed02c in google::protobuf::DescriptorBuilder::AllocateOptions(google::protobuf::FileOptions const&, google::protobuf::FileDescriptor*) ()\r\n   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#13 0x00007fffd03f495b in google::protobuf::DescriptorBuilder::BuildFileImpl(google::protobuf::FileDescriptorProto const&)\r\n    ()\r\n   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#14 0x00007fffd03f57de in google::protobuf::DescriptorBuilder::BuildFile(google::protobuf::FileDescriptorProto const&) ()\r\n   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#15 0x00007fffd03f5be5 in google::protobuf::DescriptorPool::BuildFileFromDatabase(google::protobuf::FileDescriptorProto const&) const ()\r\n   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#16 0x00007fffd03f5d3b in google::protobuf::DescriptorPool::TryFindFileInFallbackDatabase(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const ()\r\n   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#17 0x00007fffd03f5e34 in google::protobuf::DescriptorPool::FindFileByName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const ()\r\n   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#18 0x00007fffd044328e in google::protobuf::(anonymous namespace)::AssignDescriptorsImpl(google::protobuf::internal::DescriptorTable const*) ()\r\n   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#19 0x00007ffff7625a99 in __pthread_once_slow (\r\n    once_control=0x7fffd0ee9354 <descriptor_table_tensorflow_2fcore_2fframework_2fop_5fdef_2eproto_once>, \r\n    init_routine=0x7fffed339ac0 <std::__once_proxy()>) at pthread_once.c:116\r\n#20 0x00007fffd0436d46 in google::protobuf::internal::AssignDescriptors(google::protobuf::internal::DescriptorTable const*)\r\n    ()\r\n   from /work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2\r\n#21 0x00007fffd059ea10 in tensorflow::OpList::GetMetadata() const ()\r\n```\r\n\r\nI noticed that `google::protobuf::DescriptorPool::FindFileByName` occurs twice in this stacktrace.\r\nMaybe `google::protobuf::DescriptorPool::FindFileByName` locks the same mutex twice? That would explain the hang.\r\nThis is the only thread running at this point.\r\n", "comments": ["@albertz \r\n\r\nProvide the exact sequence of commands / steps that you executed before running into the problem.\r\nYou also try running the below code in virtual environment and check if it works.\r\n```\r\nimport tensorflow as tf \r\nprint(tf.__version__)\r\n```\r\nThanks!", "The exact steps to execute are just this single command:\r\n```\r\nimport tensorflow\r\n```\r\nYou see that in the stacktrace as well.\r\nI cannot run your code because it hangs already in the first command.\r\n\r\nI think the problem becomes clear when looking at the C stacktrace I posted.", "@albertz As mentioned here, can you please try sing GCC Compiler 7.3.1 and let me know if the issue still persists. Thanks!", "From the stacktrace, I don't think this is an issue with the GCC version. Why do you think that?\r\nAlso, I want to use GCC 5.4 in this case. So that is not really an option for me. But again, I don't see why that matters for this issue?", "@albertz Are you still facing this issue?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@gowthamkpr Yes, nothing has changed.\r\n\r\n(For myself: This is my Python 3.8 env + TF 2.3 installation, where it happens: `/work/tools/asr/python/3.8.0_tf_2.3-v1-generic+cuda10.1/bin/python3`)\r\n", "I still have this issue.", "I found [this (building protobuf without RTTI support)](https://groups.google.com/g/protobuf/c/w6uwDA2PQH4) which might be related.", "Hi @albertz! \r\nWe are checking to see whether you still need help in this issue. Have you checked this [comment ](https://github.com/tensorflow/tensorflow/issues/43193#issuecomment-691732806)of similar [issue ](https://github.com/tensorflow/tensorflow/issues/43193) yet? Thanks!", "@mohantym Thanks for the response.\r\n\r\nYes, we still need this.\r\n\r\nYour linked issues are not related to this.\r\n\r\nAlso, from the current information, this might be some race condition, and just out of luck it does not get triggered with newer GCC versions. This would be a serious issue and should be investigated."]}, {"number": 42033, "title": "Add deterministic tf.image.crop_and_resize backprop", "body": "Note: I am willing and able to implement this feature but I don't know when I will get to it. My intention in creating this issue is to clearly reproduce and document the current nondeterministic functionality for the community and to allow for someone else to address it, if they have available bandwidth.\r\n\r\n**System information**\r\n- TensorFlow version: nondeterminism reproduced using version 2.3.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\nSee nondeterminism repro code at the end of this comment.\r\n- Backprop to `image` is nondeterministic on both CPU and GPU. CPU variance is much higher.\r\n- Backprop to `boxes` is nondeterministic on GPU.\r\n\r\n**Will this change the current api? How?**\r\n**No**. Existing environment variable `TF_DETERMINISTIC_OPS=1` will enable deterministic operation for `tf.image.crop_and_resize`\r\n\r\n**Who will benefit with this feature?**\r\nUsers who care about determinism in TensorFlow, which includes users running safety-critical applications or anyone who wants to save time and compute cycles spent re-running nondeterministic processes for reproing, debugging, experimentation, and regression testing. This current feature request was prompted by framework-determinism [issue 18](https://github.com/NVIDIA/framework-determinism/issues/18).\r\n\r\n**Any Other info.**\r\nA solution will look similar to [PR 39243](https://github.com/tensorflow/tensorflow/pull/39243), from me, in this current repo. A solution will require new CUDA kernels in `crop_and_resize_op_gpu.cu.cc`. The existing kernels utilize CUDA `atomicAdd` in such a way as to introduce nondeterminism.\r\n\r\n**Test / Repro Code**\r\n```\r\nimport os\r\nimport tensorflow as tf\r\n\r\n# Force-disable GPU:\r\n# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\r\n\r\n# The following line is how determinism will be enabled, but is not expected\r\n# to currently have any effect on the output.\r\nos.environ['TF_DETERMINISTIC_OPS'] = '1'\r\n\r\nbatch_size = 16\r\ninput_height = 64\r\ninput_width = 64\r\ndepth = 1\r\ninput_shape = (batch_size, input_height, input_width, depth)\r\ntf.random.set_seed(456)\r\nimage = tf.random.uniform(\r\n    input_shape, minval=-1.0, maxval=1.0, dtype=tf.float32)\r\n\r\n# Image Gradients:\r\n#\r\n# Upsampling of a crop, leading to three or more output pixels being derived\r\n# from an input pixel, will contribute to nondeterminism in the gradient\r\n# associated with that input pixel location.\r\n#\r\n# Note that the number of boxes can be less than, equal to, or greater than\r\n# the batch size. Three or more crops overlapping on the same input image pixel\r\n# can independently contribute to nondeterminism in the image gradient\r\n# associated with that input pixel location. This is independent of\r\n# contributions caused by the upsampling of any given crop.\r\n#\r\n# Boxes Gradients:\r\n#\r\n# If the input and output dimensions are the same, then the boxes gradients\r\n# will be deterministically zero, otherwise they will contain nondeterminism\r\n# weather there is upsampling or downsampling and whether or not there are\r\n# overlapping crops.\r\n\r\nbox_count = 4 * batch_size\r\nboxes = tf.random.uniform(\r\n  (box_count, 4), minval=0.0, maxval=1.01, dtype=tf.float32)\r\n\r\nbox_indices = tf.random.uniform(\r\n  (box_count, ), minval=0, maxval=batch_size, dtype=tf.int32)\r\n\r\ncrop_size = [input_height*2, input_width*2]\r\noutput_shape = (box_count, *crop_size, depth)\r\n\r\ninjected_gradients = tf.random.uniform(\r\n    output_shape, minval=-0.001, maxval=0.001, dtype=tf.float32)\r\n\r\ndef gradients():\r\n  with tf.GradientTape() as tape:\r\n    tape.watch([image, boxes])\r\n    output = tf.image.crop_and_resize(\r\n        image, boxes, box_indices, crop_size, method='bilinear')\r\n    upstream = output * injected_gradients\r\n  return tape.gradient(upstream, [image, boxes])\r\n\r\ndef sum(tensor):\r\n  return tf.reduce_sum(tensor)\r\n\r\nfor device in ['gpu', 'cpu']:\r\n  print(\"\\n# Running on {}:\\n\".format(device))\r\n  print(\"#         Image Gradients |  Boxes Gradients\")\r\n  print(\"#        -----------------+------------------\")\r\n  msg = \"# Run {:d}: {:15.13f} | {:16.13f}\"\r\n  with tf.device(\"/{}:0\".format(device)):\r\n    for i in range(8):\r\n      image_gradients, boxes_gradients = gradients()\r\n      print(msg.format(i+1, sum(image_gradients), sum(boxes_gradients)))\r\n\r\nprint(\"\")\r\n\r\n# Example output (running on TensorFlow 2.3.0):\r\n\r\n# Running on gpu:\r\n\r\n#         Image Gradients |  Boxes Gradients\r\n#        -----------------+------------------\r\n# Run 1: -1.2592203617096 | -55.5643386840820\r\n# Run 2: -1.2592202425003 | -55.5643081665039\r\n# Run 3: -1.2592201232910 | -55.5643692016602\r\n# Run 4: -1.2592203617096 | -55.5644264221191\r\n# Run 5: -1.2592200040817 | -55.5643730163574\r\n# Run 6: -1.2592201232910 | -55.5644035339355\r\n# Run 7: -1.2592202425003 | -55.5643386840820\r\n# Run 8: -1.2592201232910 | -55.5643272399902\r\n\r\n# Running on cpu:\r\n\r\n#         Image Gradients |  Boxes Gradients\r\n#        -----------------+------------------\r\n# Run 1: -1.2608621120453 | -55.5644989013672\r\n# Run 2: -1.2792857885361 | -55.5644989013672\r\n# Run 3: -1.2577195167542 | -55.5644989013672\r\n# Run 4: -1.2553272247314 | -55.5644989013672\r\n# Run 5: -1.2539256811142 | -55.5644989013672\r\n# Run 6: -1.2622516155243 | -55.5644989013672\r\n# Run 7: -1.2515500783920 | -55.5644989013672\r\n# Run 8: -1.2537302970886 | -55.5644989013672\r\n```", "comments": ["@duncanriach,\r\nAs per your statement,\r\n\r\n> I am willing and able to implement this feature \r\n\r\nCan you please let us know if you are planning to implement this feature? Thanks!", "I'm sorry, @rmothukuru, but I cannot give an ETA for a deterministic GPU solution right now. However, deterministic functionality on CPU will (almost certainly) be in TF 2.6 (see PR [48905](https://github.com/tensorflow/tensorflow/pull/48905)).\r\n\r\n## Additional Information\r\n\r\nI maintain a publicly-visible status for progress on GPU-determinism of this op [here](https://github.com/NVIDIA/framework-determinism/blob/master/doc/tensorflow_status.md#crop-and-resize).\r\n\r\nPR [48905](https://github.com/tensorflow/tensorflow/pull/48905), which will almost certainly be represented in TF 2.6, adds deterministic CPU functionality for this op plus exception-throwing (if determinism is expected) on GPU.\r\n\r\nOur focus right now is on implementing [RFC: Enabling Determinism in TensorFlow](https://github.com/tensorflow/community/blob/master/rfcs/20210119-determinism.md), which adds exception-throwing for all nondeterministic GPU-op paths (if determinism is expected) and also GPU-determinism for the segment reduction ops and the softmax/cross-entropy loss functions.", "@duncanriach Is this still an issue? I have seen your contributions (in other GitHub issues) related to determinism. Also, this TF page also mentions about running ops deterministically https://www.tensorflow.org/api_docs/python/tf/config/experimental/enable_op_determinism.\r\n\r\nShould we still keep this open? Thanks!", "Hi @jvishnuvardhan, this is one of several ops that do still need to have deterministic GPU implementations added. I do intend to get to this at some point, but it's not currently my highest priority. It is still an issue, but I cannot give an ETA for resolution. Do you think it should be closed, or left open?", "@duncanriach We will leave it open. Thanks!", "Hi @duncanriach ! This issue is not replicating in the[ 2.8 version](https://colab.sandbox.google.com/gist/mohantym/e2001b7736944f43ccb7722ddf2314e9/git_42033.ipynb#scrollTo=ErHklkwlKfFn) (2.6.3 too) anymore. Can this issue be closed now?", "@mohantym, nothing has changed since TF 2.6, as reported in my 2021-05-06 [comment](https://github.com/tensorflow/tensorflow/issues/42033#issuecomment-833869754) above. Since TF 2.6, the CPU functionality has been deterministic, and the GPU functionality throws an exception to alert the user that op-determinism is not yet available on GPU. This is also as reported in [this status](https://github.com/NVIDIA/framework-determinism/blob/master/doc/tensorflow_status.md#crop-and-resize).\r\n\r\nTo demonstrate, I took [the original repro code](https://github.com/tensorflow/tensorflow/issues/42033#issue-672761931) and put it into [this colab](https://colab.research.google.com/drive/1M6Ud6vge8z7pB50Ho8sfa2lfR---00uh?usp=sharing), with some updates and enhancements. Here is the output from that:\r\n\r\n```\r\n# TensorFlow version: 2.8.0\r\n\r\n# Running on gpu:\r\n\r\n#         Image Gradients |  Boxes Gradients\r\n#        -----------------+------------------\r\n#        UnimplementedError: Deterministic GPU implementation of CropAndResizeBackpropImage not available. [Op:CropAndResizeGradImage]\r\n\r\n# Running on cpu:\r\n\r\n#         Image Gradients |  Boxes Gradients\r\n#        -----------------+------------------\r\n# Run 1: -1.2592202425003 | -55.5644302368164\r\n# Run 2: -1.2592202425003 | -55.5644302368164\r\n# Run 3: -1.2592202425003 | -55.5644302368164\r\n# Run 4: -1.2592202425003 | -55.5644302368164\r\n# Run 5: -1.2592202425003 | -55.5644302368164\r\n# Run 6: -1.2592202425003 | -55.5644302368164\r\n# Run 7: -1.2592202425003 | -55.5644302368164\r\n# Run 8: -1.2592202425003 | -55.5644302368164\r\n```\r\n\r\n**Update 1**: I'm sorry. I missed your link to your colab. It looks like your repro was not run on a machine containing a GPU. If there is no GPU, then `tf.device('gpu')` falls back to using the CPU silently.\r\n**Update 2**: I modified [my colab](https://colab.research.google.com/drive/1M6Ud6vge8z7pB50Ho8sfa2lfR---00uh?usp=sharing) so that it will not produce any results if run on a machine that does not contain a GPU."]}, {"number": 42018, "title": "Sparse input name missing in exported model", "body": "### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**: Yes\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: CentOS\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**: No\r\n-   **TensorFlow installed from (source or binary)**: binary\r\n-   **TensorFlow version (use command below)**: 2.3.0\r\n-   **Python version**: 3.6.11\r\n-   **Bazel version (if compiling from source)**: not used\r\n-   **GCC/Compiler version (if compiling from source)**: not used\r\n-   **CUDA/cuDNN version**: not used\r\n-   **GPU model and memory**: not used\r\n-   **Exact command to reproduce**:  please check below descriptions\r\n\r\n### Describe the problem\r\nWhen using tf.keras.Input with 'sparse=True', the input tensor info names are unreadable in serving signatures, such as args_0, args_0_1, args_0_2. As a result, it is very hard to distinguish when multiple sparse inputs are used in one model.\r\n\r\n### Source code / logs\r\n**[produce model]**\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\n\r\ninputs =  keras.Input(shape=(10,), sparse=True, name='input')  # use a sparse input\r\ndense = layers.Dense(64, activation=\"relu\")\r\noutputs = dense(inputs)\r\nmodel = keras.Model(inputs=inputs, outputs=outputs, name=\"model\")\r\n\r\ntf.keras.models.save_model(model, \"exported_model\", overwrite=True, include_optimizer=False)\r\n\r\n**[examine exported_model]**\r\n$ saved_model_cli show --dir exported_model/ --tag_set serve --signature_def serving_default\r\noutput:\r\nThe given SavedModel SignatureDef contains the following input(s):\r\n  **inputs['args_0'] tensor_info:**\r\n      dtype: DT_INT64\r\n      shape: (-1, 2)\r\n      **name: serving_default_args_0:0**\r\n  **inputs['args_0_1'] tensor_info:**\r\n      dtype: DT_FLOAT\r\n      shape: (-1)\r\n      **name: serving_default_args_0_1:0**\r\n  **inputs['args_0_2'] tensor_info:**\r\n      dtype: DT_INT64\r\n      shape: (2)\r\n      **name: serving_default_args_0_2:0**\r\nThe given SavedModel SignatureDef contains the following output(s):\r\n  outputs['dense'] tensor_info:\r\n      dtype: DT_FLOAT\r\n      shape: (-1, 64)\r\n      name: StatefulPartitionedCall:0\r\nMethod name is: tensorflow/serving/predict", "comments": ["I have tried in colab with TF version 2.3,nightly version and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/5b84fee554f77abd68df912ff8d2e9bb/untitled216.ipynb).Thanks!", "any updates?", "any updates? +1", "any updates? +1", "any updates? +1", "any updates? +1", "I ran into the same problem, have you solved it?", "is there any updates on this issue?", "Still an issue in 2.5 rc3 any updates on the subject ?", "Was able to replicate the issue in TF 2.6.0-dev20210530,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/828257b5977439dea95ee3d48bcab242/untitled105.ipynb).Thanks !"]}, {"number": 41968, "title": "Looking for Post-training Quantization for int 16 in TF2/TF Lite", "body": "**System information**\r\n- TensorFlow version (you are using): TF 2.2.0\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nDear TF developers, I'm looking for a 16-bits integer Post-training Quantization (PQ) solution. I noticed that we have 16-bit Quantization Aware Training (QAT) APIs for TF2 (which is great!), while for PQ, INT16 is not supported in TF Lite. \r\n\r\nOr do you know any framework that can achieve int16 PQ currently?\r\n\r\n**Will this change the current api? How?**\r\nYes or No. For the tf.lite.TFLiteConverter.from_keras_mode, we need to import another parameter in order to indicate the quantization bits. Or we can create a new api to fit this method. \r\n\r\n**Who will benefit with this feature?**\r\nPlatforms that have a nice 16 bits calculation support. This will save more calculation \r\n\r\n**Any Other info.**\r\n", "comments": ["We currently have an [experimental integer quantization (16-bit activations with 8-bit weights)](https://www.tensorflow.org/lite/performance/post_training_quantization). Does this work for you? [Note: weights are still in int8]", "> We currently have an [experimental integer quantization (16-bit activations with 8-bit weights)](https://www.tensorflow.org/lite/performance/post_training_quantization). Does this work for you? [Note: weights are still in int8]\r\n\r\nHi Meghna, \r\nThanks for the reply :) Actually no... since we're hoping to carry out 16bits (int) calculation as much as we can. Do you have any future plans for INT 16 post-training quantization?", "@YiranCdr Probably not in the near future. Will let @suharshs answer that. :)", "> @YiranCdr Probably not in the near future. Will let @suharshs answer that. :)\r\n\r\nThanks!"]}, {"number": 41957, "title": "Model performs differently for model.fit and custom training loop", "body": "**System information**\r\n\r\n- Os platform Linux Ubuntu 16.04\r\n- TensorFlow version used - 2.2.0\r\n- Python version: 3.6.9\r\n\r\n**Custom Training Loop vs Model.fit code**\r\n\r\n```\r\nmodel=model()\r\noptimizer=tf.keras.optimizers.Adam()\r\nbatch_size=opt.b_size\r\nn_batches = int(len(train_set) / opt.b_size)\r\n\r\nfor i in range(opt.epochs):\r\n    loss_t=0\r\n    loss_vt=0\r\n    it=0\r\n    for j in range(n_batches):\r\n        with tf.GradientTape() as tape:\r\n            tape.watch(model.trainable_variables)\r\n            curr=train_set[it:it+batch_size]\r\n            forward=model(curr,True)\r\n            loss=tf.keras.losses.MeanAbsoluteError()(y_train[it:it+batch_size],forward)\r\n            loss_t += loss\r\n\r\n        grads=tape.gradient(loss,model.trainable_variables)\r\n        optimizer.apply_gradients(zip(grads,model.trainable_variables))\r\n        it+=batch_size\r\n\r\n    # shuffling the test set \r\n    index = np.arange(0, len(test_set))\r\n    np.random.shuffle(index)\r\n    test_set = test_set[index]\r\n    y_test = y_test[index]\r\n    loss_t=loss_t.numpy()\r\n    \r\n    # calculating the validation loss\r\n    forward_v = model(test_set[:batch_size], False)\r\n    loss_v = tf.keras.losses.MeanAbsoluteError()(y_test[:batch_size], forward_v)\r\n    loss_v=loss_v.numpy()\r\n    loss_t /= n_batches\r\n    print(\"Loss: {} Validation loss: {} \".format( round(loss_t,4) , round(loss_v,4) ) )\r\n```\r\nThe above mentioned code is the custom training loop of a model.\r\n```\r\nmodel=model()\r\nmodel.compile(tf.keras.optimizers.Adam(),tf.keras.losses.MeanAbsoluteError(),metrics=['accuracy'])\r\nmodel.fit(train_set,y_train,batch_size=opt.b_size,epochs=opt.epochs,validation_data=(test_set,y_test))\r\n```\r\nThe above code uses model.fit method for training.\r\n\r\n\r\n**Behaviour and code  to replicate the Results**\r\nBut when I run the same code on the same train dataset and validation dataset with all the same parameters, the validation loss obtained is very different in the two cases.\r\n- Here is the [google colab gist](https://colab.research.google.com/drive/1AuvfArBWjowMT-2Eydw6FBDpo1mspPn1?usp=sharing) to replicate the results.\r\n- Alternatively, to replicate results locally, please run  **train.py** and **train2.py** on [my github](https://github.com/arshagarwal/outlier-experiment) using the following code after cloning the repository to reproduce the results:\r\n1.  `bash import_weights.sh`\r\n2. `python train.py --n_samples 1000 --epochs 100  --b_size 50` for model.fit\r\n3. `python train2.py --n_samples 1000 --epochs 100  --b_size 50` for custom training\r\n\r\n", "comments": ["@arshagarwal \r\nCan you please provide the issue faced in a colab gist for us to analyse the issue reported.", "> @arshagarwal\r\n> Can you please provide the issue faced in a colab gist for us to analyse the issue reported.\r\n\r\nThanks for taking the time, here is the [google colab gist](https://colab.research.google.com/drive/1AuvfArBWjowMT-2Eydw6FBDpo1mspPn1?authuser=1).", "@arshagarwal \r\nI ran the code shared,please find the [gist here](https://colab.research.google.com/gist/Saduf2019/6435a924960d7155a6603fe778066a2b/untitled325.ipynb).\r\nPlease confirm if this replicates the issue.", "> @arshagarwal\r\n> I ran the code shared,please find the [gist here](https://colab.research.google.com/gist/Saduf2019/6435a924960d7155a6603fe778066a2b/untitled325.ipynb).\r\n> Please confirm if this replicates the issue.\r\n\r\nYes, this is exactly what I am trying to report.", "Was able to replicate the issue in TF 2.7.0,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/39e0a7e951eb6c54c1e0ed26d7a31ca4/untitled106.ipynb#scrollTo=TdRIUvPK4_Rn)..Thanks !"]}, {"number": 41940, "title": "AOT compiled graph is 2-7x slower than Python", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.2\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): \r\n- GCC/Compiler version (if compiling from source): \r\n- CUDA/cuDNN version: -\r\n- GPU model and memory: -\r\n\r\n**Describe the current behavior**\r\n\r\nFor `tf.matmul` and `tf.linalg.triangular_solve` AOT is much slower (2-7x) than the equivalent TF-Python version. For `triangular_solve`, which is easy to hand-code, this also applies wrt bespoke C implementation.\r\n\r\n**Describe the expected behavior**\r\n\r\nI expect that the computation time of the AOT compiled graph is better than the Python counterpart.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nThe graph is the following:\r\n\r\n```python\r\ndef trisolve(A, b):\r\n    \"\"\" Builds a graph. A is a lower-triangular MxM matrix, b is a Mx1 column vector \"\"\"    \r\n    res = tf.linalg.triangular_solve(A, b, lower=True)    \r\n    return res\r\n\r\nM = 2048\r\npredict_fn = tf.function(trisolve,\r\n        input_signature=[tf.TensorSpec(shape=[M,M], dtype=tf.float64, name='A'),\r\n        tf.TensorSpec(shape=[M,1], dtype=tf.float64, name='b')], experimental_compile=False)\r\n    \r\nmodule_to_save = tf.Module()\r\nmodule_to_save.predict = predict_fn\r\ntf.saved_model.save(module_to_save, 'saved_model', signatures={'serving_default': module_to_save.predict})\r\n```\r\n\r\nThe graph is then compiled with:\r\n```bash\r\n$ cd saved_model\r\n$ saved_model_cli aot_compile_cpu --checkpoint_path .\\variables\\variables --dir . --signature_def_key serving_default --target_triple x86_64-none-windows --cpp_class trisolve --output_prefix libs64/libtrisolve --tag_set serve\r\n```\r\n\r\nand is linked to a simple cpp file that just runs the model for benchmark.\r\n\r\n```cpp\r\n#include <iostream>\r\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\r\n#include \"libtrisolve.h\" // generated\r\n#include <chrono>\r\n#include <fstream>\r\n\r\nusing namespace std::chrono;\r\n\r\n#define M 2048\r\n\r\nint main(int argc, char** argv) {  \r\n  trisolve model;  \r\n\r\n  int i, j, idx;\r\n  double *test_A;   // Initialize with a MxM lower triangular matrix\r\n  double *test_b;   // Initialize with a Mx1 vector\r\n\r\n  std::copy(test_A, test_A+M*M, model.arg0_data());\r\n  std::copy(test_b, test_b+M, model.arg1_data());\r\n  \r\n  int N = 1000;\r\n  auto tStart = high_resolution_clock::now(); \r\n  for (int i = 0; i < N; i++)\r\n    model.Run();\r\n  auto tEnd = high_resolution_clock::now();\r\n  auto duration = duration_cast<microseconds>((tEnd - tStart)/N); \r\n  std::cout << \"Time TF Compiled: \" << duration.count() << \"us\" << std::endl;\r\n\r\n  return 0;\r\n}\r\n```\r\n\r\n**Performance Issue:**\r\n\r\nTriangular Solve (as above):\r\n- A very simple single-threaded C++ implementation takes just 2ms;\r\n- Running the triangular solve from the Python code, takes ~3ms;\r\n- Running the compiled executable, instead, takes 17ms.\r\n\r\nMatMul (multiplication of two square matrices 2048x2048):\r\n- Python version takes ~150ms\r\n- Compiled version takes ~370ms\r\n", "comments": ["Hi @ymodak  ,\r\n\r\nHave you been able to replicate the issue? Do you need any further information?\r\n\r\nBest Regards,\r\n\r\nMarco", "This isn't too surprising for triangular solve since XLA has fairly naive implementation.\r\n\r\nFor GEMM this is quite surprising.  Maybe the AOT compiled GEMM is using only one thread?  Can you try passing `--enable_multithreading` to `saved_model_cli aot_compile_cpu`?\r\n\r\nCC @ebrevdo ", "For `aot_compile_cpu` if I remember correctly we explicitly disable this because we avoid adding additional external dependencies on things like `libnsync`.  If you look at the docstring for `enable_multithreading` you'll see it's not supported.", "I can confirm that `--enable_multithreading` raises this exception:\r\n\r\n`NotImplementedError: Multithreading is not currently supported because it requires additional dependencies in the AOT runtime.`\r\n\r\nHowever I think multithreading is not the problem for triangular solve in this case because, as I stated above, a very simple single-threaded implementation in C is ~8 times faster than the tf compiled version.\r\n\r\nThis is my implementation of triangular solve:\r\n```cpp\r\nvoid Solve(double* A, double* b, double* ret, int S) {\r\n    // A is SxS, b is size S, ret is size S\r\n    \r\n    for (int i = 0; i < S; i++) {\r\n        double acc = 0.0;\r\n        for (int j = 0; j < i; j++) {\r\n            acc += *(A+i*S+j) * (*(ret + j));\r\n        }\r\n        *(ret + i) = (*(b + i) - acc) / (*(A + i*S + i));\r\n    }\r\n\r\n}\r\n```", "Hi @battuzz,\r\n\r\nI believe this issue reported two issues:\r\n\r\n * TriangularSolve is much slower than expected.  This has nothing to with multi-threading, XLA CPU just does not have an optimized triangular solve implementation today.\r\n * Matrix multiply is much slower than expected.  In this case I believe the Python version is using multiple threads while XLA isn't.  XLA does support multi-threaded matrix multiplies, but that isn't exposed via the `saved_model_cli` interface.  @ebrevdo I was not able to see how tfcompile depends on nsync.", "@sanjoy I agree with you about the matrix multiplication. I tried with a smaller matrix (256x256) and the performance is similar to the Python version.\r\n\r\nHowever, for the triangular solve, I don't believe that the cause of such slowdown is a missing optimized implementation, since it is really easy to make one that goes much faster.\r\n\r\nIs there the possibility that something else is going on?", "> Is there the possibility that something else is going on?\r\n\r\nCurrently XLA CPU lowers TriangularSolve to a fairly [loop](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/xla/service/triangular_solve_expander.cc) of HLO instructions.  It is slightly surprising but entirely possible that a naively written C++ implementation will be faster.  Would you be willing to contribute a C++ implementation to XLA?\r\n\r\n@hawkinsp does JAX have an optimized custom-call implementation for `triangular-solve`?", "Hi @sanjoy , \r\n\r\nI've checked the XLA CPU implementation of TriangularSolve and honestly I think some weird stuff is going on, because apparently it is calculating unnecessary matrix inversions that take a lot of time. \r\nHowever my experience with XLA and C++ is very limited to be able to contribute directly. I wrote a graph implementation of triangular solve, instead, that leverages dot products between rows of L and the solution vector x, and works for N-dimensional inputs:\r\n\r\n```python\r\ndef triangular_solve(L,b):\r\n    \"\"\" Solves the equation Lx = b given that L is lower triangular\r\n    \r\n    Parameters:\r\n        - L: a tensor with dimensions [..., M, M]\r\n        - b: a tensor with dimensions [..., M, N]\r\n    \"\"\"\r\n    # Make all matrices with unitary diagonal\r\n    d = tf.linalg.diag_part(L)\r\n    d = tf.expand_dims(tf.pow(d,-1), axis=-1)\r\n    b = b*d\r\n    L = L*d\r\n\r\n    M = tf.shape(b)[-2]\r\n    x = tf.TensorArray(tf.float64, size=M, clear_after_read=False, dynamic_size=False)\r\n    \r\n    # Move last two axis in front    \r\n    b = tf.einsum(\"...ij->ij...\", b)\r\n    L = tf.einsum(\"...ij->ij...\", L)\r\n    \r\n    x = x.unstack(tf.zeros_like(b))                \r\n    L = tf.expand_dims(L, 2)\r\n\r\n    def body_fn(i, x):\r\n        coeffsum = tf.reduce_sum(tf.multiply(tf.gather_nd(L, [i]), x.stack()), axis=0)\r\n        x = x.write(i, tf.gather_nd(b, [i]) - coeffsum)\r\n        i = i+1\r\n        return i,x\r\n    \r\n    cond_fn = lambda i,*_: tf.less(i, M)\r\n    _,x = tf.while_loop(cond_fn, body_fn, (tf.constant(0), x))\r\n\r\n    return tf.einsum(\"ij...->...ij\", x.stack())\r\n```\r\n\r\nWhen compiled in XLA, this implementation is fast for small matrices (~ 5-10 times faster than `tf.linalg.triangular_solve` for a matrix 256x256), but slows down when the matrix is large, probably due to the TensorArray stack() use in the loop...\r\n\r\nI hope this may help in optimizing the performance of `tf.linalg.triangular_solve` in XLA. Is there someone able to do that?\r\n\r\nThanks", "Hi @sanjoy \r\n\r\nWhile searching for a workaround for the poor runtime performance of `tf.linalg.triangular_solve`, I have just found another problem that may be correlated with this issue (otherwise, you can tell me and I'll create a new issue for this).\r\n\r\nConsider the following class:\r\n```python\r\nclass ModelA():\r\n    def __init__(self, L):\r\n        \"\"\" L is a lower triangular MxM matrix \"\"\"\r\n        self.L = L\r\n        M = self.L.shape[-1]\r\n        self.invL = tf.linalg.triangular_solve(self.L, tf.eye(M, dtype=tf.float64), lower=True)    # Computes the inverse of L\r\n    \r\n    def predict(self, b):        \r\n        \"\"\" b is a Mx1 vector \"\"\"                \r\n        return tf.matmul(self.invL, b)\r\n```\r\n\r\nThis works just fine, and the compiled graph for `predict` is just the `matmul` operation.\r\n\r\nHowever, if I move the `tf.linalg.triangular_solve` operation in the predict function in this way:\r\n```python\r\nclass ModelA1():\r\n    def __init__(self, L):\r\n        \"\"\" L is a lower triangular MxM matrix \"\"\"\r\n        self.L = L\r\n    \r\n    def predict(self, b):        \r\n        \"\"\" b is a Mx1 vector \"\"\"                \r\n        M = self.L.shape[-1]\r\n        invL = tf.linalg.triangular_solve(self.L, tf.eye(M, dtype=tf.float64), lower=True)    # Computes the inverse of L\r\n        return tf.matmul(invL, b)\r\n```\r\nthe compiled graph shouldn't change as `invL` is constant and can be optimized away. Unfortunately this does not happen with `modelA1`. \r\nI believe this is a problem specifically for `tf.linalg.triangular_solve` because, if I compute the inverse using `tf.linalg.inv` instead (as in `modelB` herebelow), the optimization procedure works just fine and the compiled `predict` function only performs the `matmul` and not the inverse.\r\n\r\n```python\r\nclass ModelB():\r\n    def __init__(self, L):\r\n        \"\"\" L is a lower triangular MxM matrix \"\"\"\r\n        self.L = L\r\n    \r\n    def predict(self, b):        \r\n        \"\"\" b is a Mx1 vector \"\"\"                \r\n        invL = tf.linalg.inv(self.L)    # Computes the inverse of L\r\n        return tf.matmul(invL, b)\r\n```\r\n", "@sanjoy On CPU, JAX uses a CustomCall to invoke LAPACK for triangular solves. I guess the closest equivalent in TF would be to call Eigen.\r\n\r\nThe HLO TriangularSolve implementation being called here was never particularly intended for CPU use (more GPU and TPU, primarily TPU).", "> the compiled graph shouldn't change as invL is constant and can be optimized away. Unfortunately this does not happen with modelA1.\r\n\r\nI didn't quite follow this -- isn't `invL` dependent on `L` which is a runtime variable value (i.e. not a constant)?", "`L` should become a constant when compiling only function `predict`, as there is no possibility of modifying `L` from the resulting graph.\r\n\r\nThis is the resulting graph for `modelA1`.\r\n\r\n![image](https://user-images.githubusercontent.com/456857/91410139-bf1e2500-e846-11ea-877d-43ee7c7a2aa5.png)\r\n\r\nWhile this is the resulting graph for `modelB` that does the same thing, but with `tf.linalg.inv` instead of `tf.linalg.triangular_solve`. In this case the inverse is precomputed..\r\n\r\n![image](https://user-images.githubusercontent.com/456857/91410600-6e5afc00-e847-11ea-8d65-cd7b5507be0b.png)\r\n\r\n", "Hi @sanjoy \r\n\r\nI have an update on this last issue: I thought the culprit was the `tf.linalg.triangular_solve`, but now I think the issue is with `tf.eye`. In fact, this `modelC` below behaves exactly like `modelB` and will be optimized:\r\n\r\n```python\r\nimport numpy as np\r\n\r\nclass ModelC():\r\n    def __init__(self, L):\r\n        \"\"\" L is a lower triangular MxM matrix \"\"\"\r\n        self.L = L\r\n    \r\n    def predict(self, b):        \r\n        \"\"\" b is a Mx1 vector \"\"\"                \r\n        M = self.L.shape[-1]\r\n        eye = tf.constant( np.eye(M) , dtype=tf.float64)   # Use numpy to generate an eye matrix\r\n        invL = tf.linalg.triangular_solve(self.L, eye, lower=True)    # Computes the inverse of L\r\n        return tf.matmul(invL, b)\r\n```\r\n\r\nI believe that the output of `tf.eye(N)`, when `N` is constant, sometimes is not treated as constant, and thus may break constant propagation.", "@battuzz \r\nIt looks like you are using an older Version of Tensorflow. Many bugs have been fixed in the latest version. Can you please execute your code using Latest Version 2.7.0 and let us know if the issue still persists? Thanks!", "@sushreebarsa  Thank you for your reply, I'll have a look as soon as possible!", "@sushreebarsa Here I am with some results!\r\nI ran some tests with Tensorflow 2.7.0 and here are the results divided by the problems I've found:\r\n\r\n1) The CPU implementation of `triangular_solve` is still very very slow. For my tests I used a matrix 2048x2048 and I measured the following inference times:\r\n\r\n- Naive implementation in pure C (I used the code above, single thread):    **~1ms**\r\n- `tf.linalg.triangular_solve` from Python:  (multithread)   **~3ms**\r\n- AOT compiled version of `tf.linalg.triangular_solve` (single thread):        **~13ms**\r\n- AOT compiled version of `my_triangular_solve` (single thread):             **~4ms**      \r\n\r\nHere is the naive implementation of `my_triangular_solve` (I'm sure something better can be done):\r\n```python\r\ndef my_triangular_solve(A, b):\r\n    S = tf.shape(A)[0]\r\n    ret = tf.zeros(S, dtype=tf.float64)\r\n\r\n    for i in tf.range(S):\r\n        acc = tf.reduce_sum(A[i,:] * ret)\r\n        ret = tf.tensor_scatter_nd_update(ret, [[i]], (b[i] - acc) / A[i,i])\r\n    \r\n    return tf.reshape(ret, (1,-1))\r\n```\r\n\r\nNow, I know it will be hard to obtain the same performance of a pure C implementation (even though it would be amazing), but the current implementation is way slower than expected... \r\n\r\n\r\n2) I compared the `ModelA` vs `ModelA1` classes listed above in this thread and their performance is now similar, so the `triangular_solve` operation will be precomputed as expected."]}, {"number": 41929, "title": "TF 2.3 broken hierarchical functional model loading (e.g. HAN) [ValueError: Unknown layer: Functional]", "body": "System information\r\n\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\nTensorFlow installed from (source or binary): binary\r\nTensorFlow version (use command below): v2.3\r\nPython version: 3.6.9\r\nCUDA/cuDNN version: v10.2\r\nGPU model and memory: GeForce GTX 1070 - 8117MiB\r\n\r\nDescribe the current behavior:\r\nI cannot load a model trained with TF 2.3 in TF 2.2 -> **breaking change**\r\nIn TF 2.3 the release notes mention the following: \r\n`Functional models now get constructed if any tensor in a layer call's arguments/keyword arguments comes from a keras input. Previously the functional api would only work if all of the elements in the first argument to the layer came from a keras input.`\r\n\r\nI have a hierarchical attention model, trained either with TF2.2 with the following underlying config: \r\n```\r\n{'name': 'HAN_DocSent', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 150, None), 'dtype': 'int32', 'sparse': False, 'ragged': False, 'name': 'input_1'}, 'name': 'input_1', 'inbound_nodes': []}, {'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed', 'trainable': True, 'dtype': 'float32', 'layer': {'class_name': 'Model', 'config': {'name': 'HAN_SentWord', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, None), 'dtype': 'int32', 'sparse': False, 'ragged': False, 'name': 'word/sentence_input'}, 'name': 'word/sentence_input', 'inbound_nodes': []}, {'class_name': 'Embedding', 'config': {'name': 'word_embedding', 'trainable': True, 'batch_input_shape': (None, None), 'dtype': 'float32', 'input_dim': 20002, 'output_dim': 300, 'embeddings_initializer': {'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': True, 'input_length': None}, 'name': 'word_embedding', 'inbound_nodes': [[['word/sentence_input', 0, 0, {}]]]}, {'class_name': 'Bidirectional', 'config': {'name': 'bidirectional', 'trainable': True, 'dtype': 'float32', 'layer': {'class_name': 'GRU', 'config': {'name': 'gru', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'time_major': False, 'units': 100, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.25, 'recurrent_dropout': 0.25, 'implementation': 1, 'reset_after': True}}, 'merge_mode': 'concat'}, 'name': 'bidirectional', 'inbound_nodes': [[['word_embedding', 0, 0, {}]]]}, {'class_name': 'HierarchicalAttention', 'config': {'name': 'word_attention', 'trainable': True, 'dtype': 'float32'}, 'name': 'word_attention', 'inbound_nodes': [[['bidirectional', 0, 0, {}]]]}], 'input_layers': [['word/sentence_input', 0, 0]], 'output_layers': [['word_attention', 0, 0]]}}}, 'name': 'time_distributed', 'inbound_nodes': [[['input_1', 0, 0, {}]]]}, {'class_name': 'Bidirectional', 'config': {'name': 'bidirectional_1', 'trainable': True, 'dtype': 'float32', 'layer': {'class_name': 'GRU', 'config': {'name': 'gru_1', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'time_major': False, 'units': 100, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.25, 'recurrent_dropout': 0.25, 'implementation': 1, 'reset_after': True}}, 'merge_mode': 'concat'}, 'name': 'bidirectional_1', 'inbound_nodes': [[['time_distributed', 0, 0, {}]]]}, {'class_name': 'HierarchicalAttention', 'config': {'name': 'sentence_attention', 'trainable': True, 'dtype': 'float32'}, 'name': 'sentence_attention', 'inbound_nodes': [[['bidirectional_1', 0, 0, {}]]]}, {'class_name': 'Dense', 'config': {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 31, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'name': 'dense_2', 'inbound_nodes': [[['sentence_attention', 0, 0, {}]]]}], 'input_layers': [['input_1', 0, 0]], 'output_layers': [['dense_2', 0, 0]]}\r\n```\r\nYet in TF 2.3 the saved config is differently wrapped with \"Functional\": \r\n```\r\n{\"class_name\": \"Functional\", \"config\": {\"name\": \"HAN_DocSent\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 30, null], \"dtype\": \"int32\", \"sparse\": false, \"ragged\": false, \"name\": \"input_1\"}, \"name\": \"input_1\", \"inbound_nodes\": []}, {\"class_name\": \"TimeDistributed\", \"config\": {\"name\": \"time_distributed\", \"trainable\": true, \"dtype\": \"float32\", \"layer\": {\"class_name\": \"Functional\", \"config\": {\"name\": \"HAN_SentWord\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, null], \"dtype\": \"int32\", \"sparse\": false, \"ragged\": false, \"name\": \"word/sentence_input\"}, \"name\": \"word/sentence_input\", \"inbound_nodes\": []}, {\"class_name\": \"Embedding\", \"config\": {\"name\": \"word_embedding\", \"trainable\": true, \"batch_input_shape\": [null, null], \"dtype\": \"float32\", \"input_dim\": 20000, \"output_dim\": 50, \"embeddings_initializer\": {\"class_name\": \"RandomUniform\", \"config\": {\"minval\": -0.05, \"maxval\": 0.05, \"seed\": null}}, \"embeddings_regularizer\": null, \"activity_regularizer\": null, \"embeddings_constraint\": null, \"mask_zero\": true, \"input_length\": null}, \"name\": \"word_embedding\", \"inbound_nodes\": [[[\"word/sentence_input\", 0, 0, {}]]]}, {\"class_name\": \"Bidirectional\", \"config\": {\"name\": \"bidirectional\", \"trainable\": true, \"dtype\": \"float32\", \"layer\": {\"class_name\": \"GRU\", \"config\": {\"name\": \"gru\", \"trainable\": true, \"dtype\": \"float32\", \"return_sequences\": true, \"return_state\": false, \"go_backwards\": false, \"stateful\": false, \"unroll\": false, \"time_major\": false, \"units\": 100, \"activation\": \"tanh\", \"recurrent_activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"recurrent_initializer\": {\"class_name\": \"Orthogonal\", \"config\": {\"gain\": 1.0, \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"recurrent_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"recurrent_constraint\": null, \"bias_constraint\": null, \"dropout\": 0.5, \"recurrent_dropout\": 0.25, \"implementation\": 1, \"reset_after\": true}}, \"merge_mode\": \"concat\"}, \"name\": \"bidirectional\", \"inbound_nodes\": [[[\"word_embedding\", 0, 0, {}]]]}, {\"class_name\": \"HierarchicalAttention\", \"config\": {\"name\": \"word_attention\", \"trainable\": true, \"dtype\": \"float32\"}, \"name\": \"word_attention\", \"inbound_nodes\": [[[\"bidirectional\", 0, 0, {}]]]}], \"input_layers\": [[\"word/sentence_input\", 0, 0]], \"output_layers\": [[\"word_attention\", 0, 0]]}}}, \"name\": \"time_distributed\", \"inbound_nodes\": [[[\"input_1\", 0, 0, {}]]]}, {\"class_name\": \"Bidirectional\", \"config\": {\"name\": \"bidirectional_1\", \"trainable\": true, \"dtype\": \"float32\", \"layer\": {\"class_name\": \"GRU\", \"config\": {\"name\": \"gru_1\", \"trainable\": true, \"dtype\": \"float32\", \"return_sequences\": true, \"return_state\": false, \"go_backwards\": false, \"stateful\": false, \"unroll\": false, \"time_major\": false, \"units\": 100, \"activation\": \"tanh\", \"recurrent_activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"recurrent_initializer\": {\"class_name\": \"Orthogonal\", \"config\": {\"gain\": 1.0, \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"recurrent_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"recurrent_constraint\": null, \"bias_constraint\": null, \"dropout\": 0.5, \"recurrent_dropout\": 0.25, \"implementation\": 1, \"reset_after\": true}}, \"merge_mode\": \"concat\"}, \"name\": \"bidirectional_1\", \"inbound_nodes\": [[[\"time_distributed\", 0, 0, {}]]]}, {\"class_name\": \"HierarchicalAttention\", \"config\": {\"name\": \"sentence_attention\", \"trainable\": true, \"dtype\": \"float32\"}, \"name\": \"sentence_attention\", \"inbound_nodes\": [[[\"bidirectional_1\", 0, 0, {}]]]}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 5, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"name\": \"dense_2\", \"inbound_nodes\": [[[\"sentence_attention\", 0, 0, {}]]]}], \"input_layers\": [[\"input_1\", 0, 0]], \"output_layers\": [[\"dense_2\", 0, 0]]}}'\r\n```\r\nThe error, of course, relates to the internal model which now compiles to a \"Functional\" model: \r\n`ValueError: Unknown layer: Functional`\r\nThe errors occurs in this line: \r\n```/media/hdd/.virtualenvs/arkham/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py(177)load_model_from_hdf5()\r\n-> model = model_config_lib.model_from_config(model_config, ...)\r\n```\r\n\r\nDescribe the expected behavior:\r\nModel loading stays stable between releases...\r\n\r\nStandalone code to reproduce the issue\r\nI cannot share the code due to proprietary rights... yet since it is reported in the release, it should be straightforward to find a solution.\r\nE.g. should I change the way I load my model? \r\n", "comments": ["@Jordy-VL,\r\n>I cannot share the code due to proprietary rights... yet since it is reported in the release, it should be straightforward to find a solution.\r\n\r\nCould you please provide a dummy model or a minimal working example to reproduce the issue reported here? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@amahendrakar The similar errors has been recenlty reported in TF mailing list as well as at SO: https://stackoverflow.com/questions/63068639/valueerror-unknown-layer-functional", "Exacty as @lithuak mentions. However, the solution proposed to recompile and only load the weights does not solve the issue... ", "@Jordy-VL Thanks for reporting this issue. Can you please provide a standalone code to reproduce the issue? Thanks!", "> @Jordy-VL Thanks for reporting this issue. Can you please provide a standalone code to reproduce the issue? Thanks!\r\n\r\nI'll start on a dummy model first thing tomorrow. Thanks!", "@Jordy-VL Can you please share a simple standalone code to reproduce the issue? Thanks!\r\n", "> @Jordy-VL Can you please share a simple standalone code to reproduce the issue? Thanks!\r\n\r\nsorry, something came in-between. Is it an option to share a dummy model trained with the proprietary code? (without sharing the actual code).", "@Jordy-VL I am not sure how much we can resolve without looking at the model creation code as the current error is \"Unknown layer\". But, let's try it. Thanks!", "Sorry for the delay @jvishnuvardhan \r\n\r\nFor best resolution, I created a colab gist with the model creation code; instructions are contained inside. \r\nhttps://colab.research.google.com/drive/1fL9q5-ThAbYXJ_EgALhAHQ3x2OXb99jd?usp=sharing \r\n\r\nThanks for nudging me to complete this model gist ;) I was a bit too swamped the last days. ", "@Jordy-VL Why do you `backend.symbolic_learning_phase()`? When we define a keras function, we need to provide input and output of the model but you are providing `learning_phase` also.\r\n\r\nwhen I removed `learning_phase` from the keras function, it didn't throw any error. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/97dbf53f88a7223d437d95480e81a5a4/functionlayer2-3.ipynb). Thanks!\r\n\r\n`model_mc = tf.keras.backend.function([new_model.input], [out_layer])`\r\n", "I need it to use MonteCarlo Dropout, where you activate learning rate to simulate dropout at inference time. If you know of an alternative, do tell :)", "Hi , i am getting similar issue while training a model. \r\n![image](https://user-images.githubusercontent.com/63651642/92575159-a16ca900-f2a5-11ea-97ea-f24d2752c1c7.png)\r\n\r\nproject link:- https://github.com/kairess/eye_blink_detector\r\n\r\nfirst run preprocess.ipynb and the train.ipynb, after this model is trained and stored .\r\nNow when i try to load model as below, gives above error\r\n![image](https://user-images.githubusercontent.com/63651642/92575596-248dff00-f2a6-11ea-9e25-e045a34b64df.png)\r\n", "Issue resolved , actually problem was that while training i was using tensorflow 2.3.0, while running i was using tensorflow 2.2.0.\r\nHence this issue occured.\r\nLater i tried compiling and running with tensorflow 2.2.0 only and it got through.\r\n", "Still happening during loading (tf 2.2) h5 model trained in colab (tf 2.4)\r\n\r\nShouldn't this be fixed in a way that even older versions of models tf2+ (2.0, 2.1, 2.2) are compatible with tf 2.3, tf 2.4 +?", "I do not think make the training TF version same with the  prediction TF version is a good idea. I met this issue because i have deployed the prediction model to our customer site with TF version 2.2, but out training system recently upgrade TF version to 2.4. Therefore, our new trained model cannot be used on our clients' site. Upgrade TF libs of all our clients are infeasible, nor keep our GPU training system to TF 2.2 is a good idea i suppose. \r\n\r\nCould we add an args to model.save() to export model in old format? ", "Was able to replicate the issue in TF 2.6.0-dev20210530,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/a24796e1da830332ed3df755c7236e51/untitled107.ipynb)..Thanks !"]}, {"number": 41894, "title": "Add \"CIRCULAR\" mode padding to tensorflow.pad()", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.2.0-rc3\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nThe requested feature would enable tensorflow.pad() to perform circular padding, which is of importance in several signal processing applications.\r\nFollowing the example in the [documentation for tf.pad()](https://www.tensorflow.org/api_docs/python/tf/pad) for other modes (\"CONSTANT\", \"SYMMETRIC\", \"REFLECT\"), the circular padding should result in a tensor like this:\r\n```python\r\nt = tf.constant([[1, 2, 3], [4, 5, 6]])\r\npaddings = tf.constant([[1, 1,], [2, 2]])\r\n\r\ntf.pad(t, paddings, \"CIRCULAR\")  # [[5, 6, 4, 5, 6, 4, 5],\r\n                                 #  [2, 3, 1, 2, 3, 1, 2],\r\n                                 #  [5, 6, 4, 5, 6, 4, 5],\r\n                                 #  [2, 3, 1, 2, 3, 1, 2]]\r\n```\r\n**Will this change the current api? How?**\r\nI think it should not, as this will simply be another option for the mode argument. Of course, the backend must be modified to provide the functionality.\r\n\r\n**Who will benefit with this feature?**\r\nAs stated before, circular padding often occurs in signal processing applications. Another example would be images that stem from e.g. a cylindric or circular domain. \r\nIMHO this feature would enable higher-level APIs, e.g. the convolutional layers in Keras to add an option for \"circular\" padding, which in turn should enable easier use for the specific tasks mentioned above. Making the feature available to the higher-level API will benefit the mentioned signal processing applications.\r\n\r\n**Any Other info.**\r\nThe functionality is implemented in Pytorch, where the [padding mode for Convolutional layers](https://pytorch.org/docs/master/generated/torch.nn.Conv1d.html#torch.nn.Conv1d) can be set to `circular`.\r\n> padding_mode (string, optional) \u2013 'zeros', 'reflect', 'replicate' or 'circular'. Default: 'zeros'", "comments": ["Would also very much appreciate that! As @st0nedB mentioned, this would make life so much easier for people working e.g. in medical data science. "]}, {"number": 41893, "title": "Try RecursivelyCreateDir Except os.makedirs solution to Create Missing Path", "body": "Previous version hits a bug when trying to run tensorflow wrapped in other scripts. \r\nE.g. while replicating [UberAI Plato](https://github.com/uber-research/plato-research-dialogue-system#running-plato) project, will hit the following error:\r\n\r\n`tensorflow.python.framework.errors_impl.NotFoundError: Failed to create a directory: models/camrest_nlu/sys\\experiment_run_0\\model\\log\\train; No such file or directory`\r\n\r\nWith os method, it quickly resolves the issue.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F41893) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F41893) for more info**.\n\n<!-- ok -->", "What operating system do you get the failure on? The API is supposed to match the python one, it seems there is an issue with `/` and `\\` confusion.", "Hi @mihaimaruseac , I'm using Windows 10. Yes should be something to do with the slashes... I see similar problems faced by others on [this thread](https://github.com/ibab/tensorflow-wavenet/issues/255).", "I assigned a bug internally for me to fix this. Unfortunately, I won't be able to send a fix in the next 2 weeks due to overworking :(", "Yep no worries! Thanks for looking into it. Let me know if I can help with anything.", "@mihaimaruseac  Any update on this PR? Please. Thanks!", "@mihaimaruseac Any update on this PR? Please. Thanks!", "@mihaimaruseac Any update on this PR? Please. Thanks!", "@mihaimaruseac Any update on this PR? Please. Thanks!", "@mihaimaruseac Any update on this PR? Please. Thanks!", "@mihaimaruseac Any update on this PR? Please. Thanks!", "@mihaimaruseac Any update on this PR? Please. Thanks!", "@mihaimaruseac Any update on this PR? Please. Thanks!", "@mihaimaruseac Any update on this PR? Please. Thanks!", "@mihaimaruseac Any update on this PR? Please. Thanks!", "@mihaimaruseac Any update on this PR? Please. Thanks!", "@mihaimaruseac Any update on this PR? Please. Thanks!"]}, {"number": 41873, "title": "Pylint E1121 caused by arguments to reshape method.", "body": "When I run pylint (with provided rc file) on Tensorflow, lot of E1121 popped up. Looking over the code I found lines like this to be the cause:\r\nhttps://github.com/tensorflow/tensorflow/blob/206ed7a37f0e5e80b1f62e2172f96a9a2f7041c8/tensorflow/python/kernel_tests/parsing_ops_test.py#L449-L454\r\n\r\nSpecifically the reshape method. Now tests run just fine as they are and it's just a style issue. \r\nIt's completely possible that this was a conscious choice on part of people involved, but if so it might be good idea to adjust relevant parts of projects style definition.\r\n\r\nEspecially because most of the numpy docs seem to show tuple as a way to pass new shape to the method:\r\nhttps://numpy.org/doc/stable/reference/generated/numpy.reshape.html#numpy.reshape\r\n\r\nIf this is an oversight I can open a PR with fix for at least several files. Alternatively I can take a look at the style definition adjustment. ", "comments": ["This has slipped through cracks, apologies for the long delay. Please send a PR to fix this.", "Is this still an issue with newest TF?"]}, {"number": 41850, "title": "TF r2.3 Bad Address build issue on windows", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows Server 2019 Standard\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: - \r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: r2.3\r\n- Python version: 3.6.8\r\n- Installed using virtualenv? pip? conda?: - \r\n- Bazel version (if compiling from source): 3.3.1\r\n- GCC/Compiler version (if compiling from source): MSVC 2019 v16.6.5 Microsoft (R) C/C++ Optimizing Compiler Version 19.26.28806 for x64\r\n- CUDA/cuDNN version: CUDA v10.2, cudnn-10.2-windows10-x64-v7.6.5.32\r\n- GPU model and memory: - \r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nI have created a docker image for TF build on Windows Server 2019 host with `mcr.microsoft.com/windows/servercore:ltsc2019` base image. I have a problem with building when I would like to build a version with CUDA support. When I configure the build for CPU without CUDA everything build fine. With the CUDA support turned on I got `Bad address` error for bash commands like this.\r\n\r\n> ERROR: C:/tensorflow/tensorflow/core/framework/BUILD:1107:31: Executing genrule //tensorflow/core/framework:attr_value_proto_text_srcs failed (Exit 126): bash.exe failed: error executing command\r\n  cd C:/users/containeradministrator/_bazel_containeradministrator/xv6zejqw/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/cuda/v10.2\r\n    SET PATH=C:\\tools\\msys64\\usr\\bin;C:\\tools\\msys64\\bin;C:\\Windows;C:\\Windows\\System32;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\r\n    SET PYTHON_BIN_PATH=C:/Python36/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Python36/lib/site-packages\r\n    SET RUNFILES_MANIFEST_ONLY=1\r\n    SET TF2_BEHAVIOR=1\r\n    SET TF_CONFIGURE_IOS=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=3.5,7.0\r\n    SET TF_CUDA_PATHS=C:/cuda/v10.2,C:/cudnn/cuda\r\n    SET TF_CUDA_VERSION=10\r\n    SET TF_CUDNN_VERSION=7\r\n    SET TF_ENABLE_XLA=1\r\n    SET TF_NEED_CUDA=1\r\n  C:/tools/msys64/usr/bin/bash.exe -c source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/x64_windows-opt-exec-50AE0418/bin/tensorflow/tools/proto_text/gen_proto_text_functions bazel-out/x64_wi\r\nndows-opt/bin/tensorflow/core/framework tensorflow/core/framework/ tensorflow/core/framework/attr_value.proto tensorflow/core/framework/resource_handle.proto tensorflow/core/framework/tensor.proto tensorflow/cor\r\ne/framework/tensor_shape.proto tensorflow/core/framework/types.proto tensorflow/tools/proto_text/placeholder.txt\r\nExecution platform: @local_execution_config_platform//:platform\r\n/usr/bin/bash: bazel-out/x64_windows-opt-exec-50AE0418/bin/tensorflow/tools/proto_text/gen_proto_text_functions: Bad address\r\nTarget //tensorflow:libtensorflow_cc.so failed to build\r\nERROR: C:/tensorflow/tensorflow/core/framework/BUILD:1107:31 Executing genrule //tensorflow/core/framework:attr_value_proto_text_srcs failed (Exit 126): bash.exe failed: error executing command\r\n  cd C:/users/containeradministrator/_bazel_containeradministrator/xv6zejqw/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/cuda/v10.2\r\n    SET PATH=C:\\tools\\msys64\\usr\\bin;C:\\tools\\msys64\\bin;C:\\Windows;C:\\Windows\\System32;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\r\n    SET PYTHON_BIN_PATH=C:/Python36/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Python36/lib/site-packages\r\n    SET RUNFILES_MANIFEST_ONLY=1\r\n    SET TF2_BEHAVIOR=1\r\n    SET TF_CONFIGURE_IOS=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=3.5,7.0\r\n    SET TF_CUDA_PATHS=C:/cuda/v10.2,C:/cudnn/cuda\r\n    SET TF_CUDA_VERSION=10\r\n    SET TF_CUDNN_VERSION=7\r\n    SET TF_ENABLE_XLA=1\r\n    SET TF_NEED_CUDA=1\r\n  C:/tools/msys64/usr/bin/bash.exe -c source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/x64_windows-opt-exec-50AE0418/bin/tensorflow/tools/proto_text/gen_proto_text_functions bazel-out/x64_wi\r\nndows-opt/bin/tensorflow/core/framework tensorflow/core/framework/ tensorflow/core/framework/attr_value.proto tensorflow/core/framework/resource_handle.proto tensorflow/core/framework/tensor.proto tensorflow/cor\r\ne/framework/tensor_shape.proto tensorflow/core/framework/types.proto tensorflow/tools/proto_text/placeholder.txt\r\nExecution platform: @local_execution_config_platform//:platform\r\nINFO: Elapsed time: 8.666s, Critical Path: 5.56s\r\nINFO: 96 processes: 96 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nCommands executed on host:\r\n`docker run -it -v \"C:\\Users\\Administrator\\Downloads\\cudnn-10.2-windows10-x64-v7.6.5.32\":C:\\cudnn -v \"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\":C:\\cuda  tf-build`\r\n\r\nCommands executed inside the container:\r\n`git clone -b r2.3 https://github.com/tensorflow/tensorflow.git`\r\n`cd tensorflow`\r\n`C:\\Python36\\python.exe configure.py`\r\n`bazel build --config=opt --define=no_tensorflow_py_deps=true //tensorflow:libtensorflow_cc.so`\r\n\r\n**Any other info / logs**\r\nContent of .tf_configure.bazelrc file\r\n```\r\nbuild --action_env PYTHON_BIN_PATH=\"C:/Python36/python.exe\"\r\nbuild --action_env PYTHON_LIB_PATH=\"C:/Python36/lib/site-packages\"\r\nbuild --python_path=\"C:/Python36/python.exe\"\r\nbuild --config=xla\r\nbuild --action_env TF_CUDA_VERSION=\"10\"\r\nbuild --action_env TF_CUDNN_VERSION=\"7\"\r\nbuild --action_env TF_CUDA_PATHS=\"C:/cuda/v10.2,C:/cudnn/cuda\"\r\nbuild --action_env CUDA_TOOLKIT_PATH=\"C:/cuda/v10.2\"\r\nbuild --action_env TF_CUDA_COMPUTE_CAPABILITIES=\"3.5,7.0\"\r\nbuild --config=cuda\r\nbuild:opt --copt=/arch:AVX\r\nbuild:opt --define with_default_optimizations=true\r\nbuild --define=override_eigen_strong_inline=true\r\ntest --flaky_test_attempts=3\r\ntest --test_size_filters=small,medium\r\ntest:v1 --test_tag_filters=-benchmark-test,-no_oss,-no_windows,-no_windows_gpu,-no_gpu,-oss_serial\r\ntest:v1 --build_tag_filters=-benchmark-test,-no_oss,-no_windows,-no_windows_gpu,-no_gpu\r\ntest:v2 --test_tag_filters=-benchmark-test,-no_oss,-no_windows,-no_windows_gpu,-no_gpu,-oss_serial,-v1only\r\ntest:v2 --build_tag_filters=-benchmark-test,-no_oss,-no_windows,-no_windows_gpu,-no_gpu,-v1only\r\nbuild --action_env TF_CONFIGURE_IOS=\"0\"\r\n```\r\n\r\nDockerfile:\r\n```\r\nFROM mcr.microsoft.com/windows/servercore:ltsc2019\r\n\r\nLABEL description=\"Tensorflow build\"\r\n\r\nUSER ContainerAdministrator\r\n\r\n# Install choco\r\nENV chocolateyUseWindowsCompression=false\r\n\r\nRUN powershell -Command \\\r\n    iex ((new-object net.webclient).DownloadString('https://chocolatey.org/install.ps1')); \\\r\n    choco feature disable --name showDownloadProgress\r\n\r\n\r\n# Download the Visual Studio 2019 Build Tools bootstrapper.\r\nRUN powershell -Command Invoke-WebRequest \"https://aka.ms/vs/16/release/vs_buildtools.exe\" -OutFile C:\\vs_buildtools.exe\r\n\r\n# Use the latest release channel.\r\nRUN powershell -Command Invoke-WebRequest \"https://aka.ms/vs/16/release/channel\" -OutFile C:\\VisualStudio.chman\r\n\r\n# For help on command-line syntax:\r\n# https://docs.microsoft.com/en-us/visualstudio/install/use-command-line-parameters-to-install-visual-studio\r\n# Install MSVC C++ compiler, CMake, and MSBuild.\r\nRUN C:\\vs_buildtools.exe \\\r\n    --quiet --wait --norestart --nocache \\\r\n    --channelUri C:\\VisualStudio.chman \\\r\n    --installChannelUri C:\\VisualStudio.chman \\ \r\n    --add Microsoft.VisualStudio.Workload.VCTools;includeRecommended \\\r\n    --add Microsoft.Component.MSBuild \\\r\n    || IF \"%ERRORLEVEL%\"==\"3010\" EXIT 0\r\n\r\n# Install Git\r\nRUN choco install git -y\r\n\r\n# Install pacakages for Tensorflow build\r\nRUN choco install python --version=3.6.8 -y\r\nRUN choco install msys2 --params \"/NoUpdate\" -y\r\nRUN setx /M PATH \"%PATH%;C:/tools/msys64/usr/bin\"\r\nRUN choco install bazel -y\r\nRUN setx /M PATH \"%PATH%;C:/ProgramData/chocolatey/lib/bazel\"\r\nRUN pip3 install six numpy wheel\r\nRUN pip3 install keras_applications==1.0.6 --no-deps\r\nRUN pip3 install keras_preprocessing==1.0.5 --no-deps\r\n\r\nRUN pacman -S git patch unzip nano --noconfirm\r\n```\r\n", "comments": ["@zabomate,\r\nCould you please check if you are able to build TensorFlow with CUDA 10.1 and cuDNN 7.4, and let us know if you are facing the same issue.\r\n\r\nPlease take a look at the [tested build configuration](https://www.tensorflow.org/install/source_windows#gpu) for reference. Thanks!", "@amahendrakar I've tried with CUDA 10.1 and cuDNN 7.4.2 and I still got the bad address error.", "GPUs are not accessible inside windows-on-windows docker containers.\r\nCould you try natively trying to build?\r\n\r\nI also cannot see the exact command output, could you share your full output using pastebin, or a similar service?", "@gowthamkpr @gunan I tried to build without docker but I got the same issue. I put the content of the command.log file to this [pastebin link](https://pastebin.com/CK0VxEcF) I hope that's what you need if its not enough please let me know.", "I also have the same Error with \r\n-Windows 10 Pro\r\n-GTX 1060 3gb\r\n-compute capabilities 6.1\r\n-Python 3.6\r\n-Tensorflow 2.3\r\n-bazel 3.1.0\r\n-CUDA 10.1\r\n-cuDNN SDK 7.6\r\n-TensorRT 6.0\r\n-using AVX2", "i also tried it with cuDNN 7.4 as suggested still same Error", "Any updates on this? I have the same error. @gunan ", "Looks like the owner of the tool has left TF.\r\nHowever, I am not sure if we still need this tool.\r\nBrian, could you take a look at what this tool does, and if we can just use what protobuf team offers instead of this?", "why is this closed now i still have that issue??????", "I also have the same issue ...\r\n\r\n```console\r\nPS C:\\tensorflow> bazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package\r\nWARNING: The following configs were expanded more than once: [cuda, using_cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=157\r\nINFO: Reading rc options for 'build' from c:\\tensorflow\\.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Options provided by the client:\r\n  'build' options: --python_path=C:/Python/CPython38/python.exe\r\nINFO: Reading rc options for 'build' from c:\\tensorflow\\.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2\r\nINFO: Reading rc options for 'build' from c:\\tensorflow\\.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=C:/Python/CPython38/python.exe --action_env PYTHON_LIB_PATH=C:/Python/CPython38/lib/site-packages --python_path=C:/Python/CPython38/python.exe --config=xla --action_env TF_CUDA_VERSION=10.1 --action_env TF_CUDNN_VERSION=7.6.5 --action_env TF_CUDA_PATHS=C:/tools/cuda,C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1 --action_env CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1 --action_env TF_CUDA_COMPUTE_CAPABILITIES=3.8 --config=cuda --define=override_eigen_strong_inline=true --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:v2 in file c:\\tensorflow\\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:xla in file c:\\tensorflow\\.bazelrc: --action_env=TF_ENABLE_XLA=1 --define=with_xla_support=true\r\nINFO: Found applicable config definition build:cuda in file c:\\tensorflow\\.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true\r\nINFO: Found applicable config definition build:using_cuda in file c:\\tensorflow\\.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain\r\nINFO: Found applicable config definition build:opt in file c:\\tensorflow\\.tf_configure.bazelrc: --copt=/arch:AVX --define with_default_optimizations=true\r\nINFO: Found applicable config definition build:cuda in file c:\\tensorflow\\.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true\r\nINFO: Found applicable config definition build:using_cuda in file c:\\tensorflow\\.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain\r\nINFO: Found applicable config definition build:windows in file c:\\tensorflow\\.bazelrc: --copt=/w --copt=/D_USE_MATH_DEFINES --host_copt=/D_USE_MATH_DEFINES --cxxopt=/std:c++14 --host_cxxopt=/std:c++14 --config=monolithic --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --linkopt=/DEBUG --host_linkopt=/DEBUG --linkopt=/OPT:REF --host_linkopt=/OPT:REF --linkopt=/OPT:ICF --host_linkopt=/OPT:ICF --experimental_strict_action_env=true --verbose_failures --distinct_host_configuration=false\r\nINFO: Found applicable config definition build:monolithic in file c:\\tensorflow\\.bazelrc: --define framework_shared_object=false\r\nWARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/llvm/llvm-project/archive/7e825abd5704ce28b166f9463d4bd304348fd2a9.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nWARNING: C:/tensorflow/tensorflow/core/BUILD:1749:11: in linkstatic attribute of cc_library rule //tensorflow/core:lib_internal: setting 'linkstatic=1' is recommended if there are no object files. Since this rule was created by the macro 'cc_library', the error might have been caused by the macro implementation\r\nWARNING: C:/tensorflow/tensorflow/core/BUILD:2161:16: in linkstatic attribute of cc_library rule //tensorflow/core:framework_internal: setting 'linkstatic=1' is recommended if there are no object files. Since this rule was created by the macro 'tf_cuda_library', the error might have been caused by the macro implementation\r\nWARNING: Download from https://mirror.bazel.build/github.com/aws/aws-sdk-cpp/archive/1.7.336.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nWARNING: C:/tensorflow/tensorflow/core/BUILD:1774:11: in linkstatic attribute of cc_library rule //tensorflow/core:lib_headers_for_pybind: setting 'linkstatic=1' is recommended if there are no object files. Since this rule was created by the macro 'cc_library', the error might have been caused by the macro implementation\r\nWARNING: C:/tensorflow/tensorflow/python/BUILD:4662:11: in py_library rule //tensorflow/python:standard_ops: target '//tensorflow/python:standard_ops' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nWARNING: C:/tensorflow/tensorflow/python/BUILD:115:11: in py_library rule //tensorflow/python:no_contrib: target '//tensorflow/python:no_contrib' depends on deprecated target '//tensorflow/python/ops/distributions:distributions': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.distributions will not receive new features, and will be removed by early 2019. You should update all usage of `tf.distributions` to `tfp.distributions`.\r\nINFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded, 0 targets configured).\r\nINFO: Found 1 target...\r\nERROR: C:/tensorflow/tensorflow/core/framework/BUILD:1107:31: Executing genrule //tensorflow/core/framework:attr_value_proto_text_srcs failed (Exit 126): bash.exe failed: error executing command\r\n  cd C:/users/{user}/_bazel_{user}/xv6zejqw/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1\r\n    SET PATH=C:\\msys64\\usr\\bin;C:\\msys64\\bin;C:\\WINDOWS;C:\\WINDOWS\\System32;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\r\n    SET PYTHON_BIN_PATH=C:/Python/CPython38/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Python/CPython38/lib/site-packages\r\n    SET RUNFILES_MANIFEST_ONLY=1\r\n    SET TF2_BEHAVIOR=1\r\n    SET TF_CONFIGURE_IOS=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=3.8\r\n    SET TF_CUDA_PATHS=C:/tools/cuda,C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1\r\n    SET TF_CUDA_VERSION=10.1\r\n    SET TF_CUDNN_VERSION=7.6.5\r\n    SET TF_ENABLE_XLA=1\r\n    SET TF_NEED_CUDA=1\r\n  C:/msys64/usr/bin/bash.exe -c source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/x64_windows-opt-exec-50AE0418/bin/tensorflow/tools/proto_text/gen_proto_text_functions bazel-out/x64_windows-opt/bin/tensorflow/core/framework tensorflow/core/framework/ tensorflow/core/framework/attr_value.proto tensorflow/core/framework/resource_handle.proto tensorflow/core/framework/tensor.proto tensorflow/core/framework/tensor_shape.proto tensorflow/core/framework/types.proto tensorflow/tools/proto_text/placeholder.txt\r\nExecution platform: @local_execution_config_platform//:platform\r\n/usr/bin/bash: bazel-out/x64_windows-opt-exec-50AE0418/bin/tensorflow/tools/proto_text/gen_proto_text_functions: Bad address\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nERROR: C:/tensorflow/tensorflow/python/BUILD:1419:27 Executing genrule //tensorflow/core/framework:attr_value_proto_text_srcs failed (Exit 126): bash.exe failed: error executing command\r\n  cd C:/users/{user}/_bazel_{user}/xv6zejqw/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1\r\n    SET PATH=C:\\msys64\\usr\\bin;C:\\msys64\\bin;C:\\WINDOWS;C:\\WINDOWS\\System32;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\r\n    SET PYTHON_BIN_PATH=C:/Python/CPython38/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Python/CPython38/lib/site-packages\r\n    SET RUNFILES_MANIFEST_ONLY=1\r\n    SET TF2_BEHAVIOR=1\r\n    SET TF_CONFIGURE_IOS=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=3.8\r\n    SET TF_CUDA_PATHS=C:/tools/cuda,C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1\r\n    SET TF_CUDA_VERSION=10.1\r\n    SET TF_CUDNN_VERSION=7.6.5\r\n    SET TF_ENABLE_XLA=1\r\n    SET TF_NEED_CUDA=1\r\n  C:/msys64/usr/bin/bash.exe -c source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/x64_windows-opt-exec-50AE0418/bin/tensorflow/tools/proto_text/gen_proto_text_functions bazel-out/x64_windows-opt/bin/tensorflow/core/framework tensorflow/core/framework/ tensorflow/core/framework/attr_value.proto tensorflow/core/framework/resource_handle.proto tensorflow/core/framework/tensor.proto tensorflow/core/framework/tensor_shape.proto tensorflow/core/framework/types.proto tensorflow/tools/proto_text/placeholder.txt\r\nExecution platform: @local_execution_config_platform//:platform\r\nINFO: Elapsed time: 3.038s, Critical Path: 0.39s\r\nINFO: 21 processes: 17 internal, 4 local.\r\nFAILED: Build did NOT complete successfully\r\n```"]}, {"number": 41836, "title": "Is this a functionality that is possible?", "body": "I have created an operation that has a custom gradient. Then I use it to define a new Keras Model, out of layers:\r\n\r\n```python\r\nimport numpy as np\r\nimport numba\r\nimport tensorflow as tf\r\n\r\n@numba.jit(nopython = True)\r\ndef func(param, input):\r\n    return param*input**2\r\n\r\n@numba.jit(nopython = True)\r\ndef gradfunc(param, input):\r\n    return input**2\r\n\r\n@tf.custom_gradient\r\ndef func_tf(param, input):\r\n    def grad(dy):\r\n        return tf.numpy_function(gradfunc, (param.numpy(), input.numpy()), tf.float32), 2*param*input\r\n    return tf.numpy_function(func, (param.numpy(), input.numpy()), tf.float32), grad\r\n\r\nclass myLayer(tf.keras.layers.Layer):\r\n    def __init__(self):\r\n        super().__init__()\r\n        \r\n    def build(self, input_shape):\r\n        self.param = self.add_weight(\"param\")\r\n        \r\n    def call(self, input):\r\n        return func_tf(self.param, input)\r\n    \r\nclass myModel(tf.keras.Model):\r\n    def __init__(self, num_layers):\r\n        super().__init__(name='')\r\n        self._layers = [myLayer() for _ in range(num_layers)]\r\n        \r\n    def call(self, input_tensor):\r\n        for layer in self._layers:\r\n            input_tensor = layer(input_tensor)\r\n        return input_tensor\r\n    \r\nmodel = myModel(3)\r\nprint(model(1.5)) # <-- this works\r\n```\r\nThis, however fails:\r\n```python\r\ndef loss(target, output):\r\n    tf.abs(tf.reduce_sum(target - output))**2\r\n\r\nmodel.compile(\r\n    optimizer=tf.keras.optimizers.Adam(),\r\n    loss=loss,\r\n    metrics=[loss])\r\n\r\nmodel.fit([0.1], [0.4], batch_size=None)\r\n```\r\n\r\nBecause `model.fit` uses `@tf.function` under the hood, so the calls to `.numpy()` in `func` and `gradfunc` are not possible (see #40508)\r\n\r\nI have found [this answer](https://stackoverflow.com/questions/41132633/can-numba-be-used-with-tensorflow) on SO, but I think that works only if `param` were not an input to `func` and `gradfunc`.\r\n\r\nHow do I make it work?", "comments": []}, {"number": 41827, "title": "TF 2.3 training slowed down by 15% compared to 2.2", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.3.0, 2.4.0.dev20200728\r\n- Python version: 3.7.8\r\n- CUDA/cuDNN version: 10.1 / 7.6.5.32\r\n- GPU model and memory: NVIDIA V100 on 12 vCPUs, 40 GB memory GCP node\r\n\r\n**Describe the current behavior**\r\n\r\nWhen upgrading from TensorFlow 2.2.0 to 2.3.0 we observed a 15 - 18% slow down in training speed for our workloads. Unfortunately I wasn't able to find an easy to reproduce example before the stable release was cut, but below is a code example that illustrates the performance degradation.\r\n\r\nWhen running the training script on a single NVIDIA V100 a 15% performance loss compared to 2.2 can be observed which still is noticable in the latest nightly:\r\n\r\nversion | epoch time | step time | GPU idle time\r\n--- | ---  | --- | ---\r\n2.2.0 | 34 s | 124.3 ms | 19.7 ms (15.6 %)\r\n2.3.0 | 39 s | 141.9 ms | 37.2 ms (26.1 %)\r\n2.4.0.dev20200728 | 38s | 136.2 ms | 31.6 ms (23.2 %)\r\n\r\n**On Device: total self-time (grouped by type)**\r\n2.2.0 | 2.3.0 | 2.4.0.dev20200728\r\n--- | --- | ---\r\n<img width=\"395\" alt=\"Screenshot 2020-07-28 at 17 45 02\" src=\"https://user-images.githubusercontent.com/13285808/88689213-80d3ff80-d0fa-11ea-88ec-3feda0cf9c24.png\"> | <img width=\"375\" alt=\"Screenshot 2020-07-28 at 17 45 15\" src=\"https://user-images.githubusercontent.com/13285808/88689219-829dc300-d0fa-11ea-99bb-5d406805a6e8.png\"> | <img width=\"359\" alt=\"Screenshot 2020-07-28 at 17 46 08\" src=\"https://user-images.githubusercontent.com/13285808/88689223-83365980-d0fa-11ea-91aa-46ec7659fe64.png\">\r\n\r\n\r\nThe example uses auto mixed precision, but the slowdown can also be observed when running in `float32` or in multi-GPU training. When looking at the [generated execution profile](https://github.com/tensorflow/tensorflow/files/4989125/tb-profile.zip) the slowdown can be explained by an increased idle time of the GPU. Since the training data is cached in memory there should be no IO bottleneck so I am not sure if this performance regression is caused by `tf.data` or by the runtime itself.\r\n\r\n**Describe the expected behavior**\r\n\r\nTensorFlow 2.3 should show equally fast training performance compared to 2.2.\r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow_datasets as tfds\r\n\r\nbatch_size = 64\r\n\r\n\r\ndef _decode_and_center_crop(image_bytes):\r\n    \"\"\"Crops to center of image with padding then scales image_size.\"\"\"\r\n    shape = tf.image.extract_jpeg_shape(image_bytes)\r\n    image_height, image_width, image_size = shape[0], shape[1], 224\r\n\r\n    padded_center_crop_size = tf.cast(\r\n        (\r\n            (image_size / (image_size + 32))\r\n            * tf.cast(tf.minimum(image_height, image_width), tf.float32)\r\n        ),\r\n        tf.int32,\r\n    )\r\n\r\n    offset_height = ((image_height - padded_center_crop_size) + 1) // 2\r\n    offset_width = ((image_width - padded_center_crop_size) + 1) // 2\r\n    crop_window = tf.stack(\r\n        [offset_height, offset_width, padded_center_crop_size, padded_center_crop_size]\r\n    )\r\n    image = tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)\r\n    return tf.image.resize(image, [image_size, image_size], method=\"bicubic\")\r\n\r\n\r\ndef preprocessing(data):\r\n    return (\r\n        tf.cast(_decode_and_center_crop(data[\"image\"]), tf.float32),\r\n        data[\"label\"],\r\n    )\r\n\r\n\r\ndataset = tfds.load(\r\n    \"imagenette\", decoders={\"image\": tfds.decode.SkipDecoding()}, split=\"train\",\r\n)\r\n\r\ndataset = (\r\n    dataset.cache()\r\n    .repeat(2)  # Artificially increase time per epoch to make it easier to measure\r\n    .map(preprocessing, num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\n    .batch(batch_size)\r\n    .prefetch(1)\r\n)\r\n\r\nwith tf.distribute.MirroredStrategy().scope():\r\n    model = tf.keras.applications.ResNet50(weights=None)\r\n\r\n    model.compile(\r\n        optimizer=tf.train.experimental.enable_mixed_precision_graph_rewrite(\r\n            tf.keras.optimizers.Adam(), loss_scale=\"dynamic\"\r\n        ),\r\n        loss=\"sparse_categorical_crossentropy\",\r\n    )\r\n\r\ntb_cbk = tf.keras.callbacks.TensorBoard(f\"logs/{tf.__version__}\", profile_batch=300)\r\nmodel.fit(dataset, verbose=2, epochs=3, callbacks=[tb_cbk])\r\n```\r\n\r\n**Other info / logs**\r\n\r\nTensorBoard profiles for the runs mentioned above are available at [tb-profile.zip](https://github.com/tensorflow/tensorflow/files/4989125/tb-profile.zip)\r\n\r\n@mihaimaruseac @jsimsa @guptapriya do you mind taking a look at this?", "comments": ["I was able to reproduce the issue. Here is the [gist](https://colab.research.google.com/gist/geetachavan1/6208ca2c63fe8d3f58d0928b23585d0b/untitled.ipynb#scrollTo=8KXFXJIsBjS-)..", "Thanks for the report @lgeiger . We will look more into this. The code sample uses MirroredStrategy - so I wanted to clarify when you said this regression is noticed on a single GPU as well - is that with or without MirroredStrategy? If latter, we would start investigating that case first (i.e. 1 GPU, no distribution, no mixed precision).\r\n\r\n", "@guptapriya Thanks for looking into this.\r\n\r\n> The code sample uses MirroredStrategy - so I wanted to clarify when you said this regression is noticed on a single GPU as well - is that with or without MirroredStrategy?\r\n\r\nSorry about that, I missed that since I copied the example from a past issue I had with multi-GPU. I ran a few more benchmarks with the above example on a single GPU machine:\r\n\r\nversion | FP32 | FP32 Mirrored | FP16 | FP16 Mirrored\r\n--- | --- | --- | --- | ---\r\n2.2.0 | 55 s | 55 s | 36s | 34 s\r\n2.3.0 | 54 s | **58 s** | 37 s | **39 s**\r\n\r\nIndeed, it looks like whether mirrored strategy is used or not has a large influence. I am not sure why there is a difference in execution speed for mixed precision with and without a strategy, although I think that might be a seperate issue.\r\n\r\nOne thing to note is that 2.3 logs the following deprecation warning when used with mirrored strategy which wasn't present before, but that might be unrelated as well:\r\n```\r\nWARNING:tensorflow:From ~/.local/lib/python3.7/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Iterator.get_next_as_optional()` instead.\r\n```\r\n\r\nNote that this slowdown is more noticable with mixed precision as the kernel execution time is smaller so the increased idle time is easier to spot.", "Thanks @lgeiger for the update, that helps a lot. I can confirm that we have verified the regression (looks like it happened sometime back in April)\r\nWe will update here when we have info into the root cause and fixes. ", "@guptapriya Thank you very much the fast response, I am glad that you were able to verify the regression.\r\n\r\n> I can confirm that we have verified the regression (looks like it happened sometime back in April)\r\n\r\nApril sounds like a long time for the regression to stay unnoticed. Am I doing something abnormal in the example or am I missing a best practice here?", "Actually now we are no longer sure about the timing because the benchmark I used to get the timing was actually changed in April. So we are now looking into the timing of regression again. It may have come up later. \r\nOnce we determine the root cause, we should be able to tell if there is anything in your code that makes this show up or simply on TF side that somehow went unnoticed.\r\nIn your experience, when did you start noticing the regression?\r\n\r\n", "Makes sense, thanks for the help.\r\n\r\n>  In your experience, when did you start noticing the regression?\r\n\r\nI usually stay on the stable versions of TensorFlow for production workloads so I first noticed it around 2.3 RC 0 or 1 when running our internal ImageNet sanity check before upgrading TF version. But it took some time to find an reliably reproducible example that I could use to open the issue.", "@lgeiger thanks for providing the tensorboard profile. We have some observations in your profiles which use fp16. You mentioned that the regression also happens on fp32 (and multi-gpu). Do you happen to have the fp32 profiles of TF 2.2 and 2.3? Thanks.", "@zongweiz Sure, I reran the above code example (float32 with mirrored strategy) to generate these profiles: \r\n[tb-profile-fp32.zip](https://github.com/tensorflow/tensorflow/files/4997769/tb-profile-fp32.zip)\r\n", "I hope the profiles are helpful for debugging, do you have any news on the resolution of this issue?", "@jaingaurav is looking into a potential fix I believe.", "Yes, we found some unintended host to device copies caused by a previous change, that I am trying to eliminate. ", "i also found that tensorflow 2.3 mixed precision didn't speed-up training as tensorflow 2.2.0 does :)). The only improvement on tensorflow2.3 i see is the less overhead time of multi-gpu training ", "> Yes, we found some unintended host to device copies caused by a previous change, that I am trying to eliminate.\r\n\r\n@jaingaurav Thanks for looking into it. Do you know if this fix will make it into the 2.4 release?", "@lgeiger: Yes this is currently planned for the 2.4 release. However the fix is still being worked on.", "@jaingaurav I just checked with the new release candidate and CUDA 11, but unfortunately this issue still exists and the increased idle time is clearly visible in the profiles.\r\n\r\nBelow are the numbers for `2.4.0rc0` including the [profiles for the runs](https://github.com/tensorflow/tensorflow/files/5478729/logs.zip):\r\n\r\nversion | FP32 | FP32 Mirrored | FP16 | FP16 Mirrored | Keras FP16 | Keras FP16 Mirrored\r\n--- | --- | --- | --- | --- | --- | ---\r\n2.4.0rc0 | 54s | **60s** | 40s | **41s** | 35s | **39s**\r\n\r\n", "cc: @rohan100jain, @zongweiz looks like the fix in 673b993 didn't quite work as well as we'd hoped.", "Thanks for looking into it. I also updated the table with measurements using the new [Keras mixed precision API](https://github.com/tensorflow/community/pull/293) which makes the slowdown easier to spot.", "@rohan100jain Has there been any progress on this? From briefly skimming the changes in RC1, it looks like it doesn't include a fix for this.\r\n\r\nThis bug has been blocking me from upgrading to 2.3 so it would be great to get this resolved in 2.4. Please let me know if there anything that I could do from my side to help you debug this further?", "I double checked and the issue still exists in tf-nightly 2.5.0-dev20201110.", "@rohan100jain @zongweiz @jaingaurav I did a bit more testing with `2.4.0rc1` and it looks like when using `.batch(batch_size, drop_remainder=True)` instead of `.batch(batch_size)`, both mirrored strategy and normal training behave the same in float32 and the slowdown is significantly reduced for mixed precision training.\r\n\r\nI am a bit confused why keeping the remainder results in such a significant performance degradation, but I didn't look into it in detail yet. The mixed precision training runs are still show a high idle time, but slow down for mirrored strategy isn't as significant as before. [Here are the TensorBoard profiles](https://github.com/tensorflow/tensorflow/files/5555716/logs.zip) for the measurements shown below:\r\n\r\nversion | FP32 | FP32 Mirrored | Keras FP16 | Keras FP16 Mirrored\r\n--- | --- | --- | --- | --- \r\n2.4.0rc1 (`drop_remainder=True`) | 54s | **54s** | 34s | **35s**", "@lgeiger Thanks very much for your information. Yes, your observation matches what we found. We have tracked down the performance issue to a tf.cond inside Keras batch norm layer (which is to handle empty batches). Setting drop_remainder=True avoids empty/partial batches and works around the problem. @rohan100jain is working on a fix and will give an update very soon.\r\n\r\nI think the reason we see more regression on FP16 is because: the above problem is more significant when the workload has higher overhead in launching GPU kernels, fp16 makes some compute kernels more efficient and makes the workload more kernel launch bound.", "@zongweiz Thanks for looking into it. Looking forward to a fix.", "@rohan100jain Do you have any updates whether a fix will make it into the 2.4 release?", "@rohan100jain @zongweiz @jaingaurav Sorry for pinging you again. Do you have any updates on whether the fix will make it into the 2.4 stable release?", "Hey @lgeiger i believe the fix did not make it to 2.4 unfortunately. @rohan100jain @zongweiz @goldiegadde  please correct if that is not the case. ", "> Hey @lgeiger i believe the fix did not make it to 2.4 unfortunately.\r\n\r\nThanks for the response, that's really unfortunate since the regression has been there since 2.2. But at least we can now upgrade to 2.4 when enabling `drop_remainder=True` as a workaround until a fix lands.", "@guptapriya has there been any progress on this issue? It would be good if a fix would make it into TF 2.5 since in our current workloads running on 4 GPUs we are seeing slowdowns of 30-80% due to this bug compared to TF 2.2 (using XLA makes this regression even more dramatic).", "@lgeiger It looks like the last fix that was tried in November did not fix the issue and I don't see any other updates since then. Checking with @rohan100jain , will update when I know more. ", "Apologies but I tried fixing it last year and that change had to be rolled back / didn't do what we expected to. We'll continue to work on it and get a fix out by 2.5", "@rohan100jain Thanks for the update. Let me know when a fix lands and I am can rerun the benchmarks to verify.", "I'm sorry we looked into this issue and there isn't really any easy way of fixing this without rolling back a change (https://github.com/tensorflow/tensorflow/commit/f0d0485b0de521ff273c8d91acbb2fbabe57baa7) that enhances dtype coverage of our GPU ops and improves the consistency of Tensorflow in general. This issue has exposed some problems we need to fix with our device placement that we're planning to work on and will have an RFC for it. I'll therefore recommend that you continue to use the drop_remainder=True workaround for now.", "Thanks for the update. I will continue using `drop_remainder=True` for now as a workaround. I hope there will be a fix for it soon since I think `MirroredStrategy` together with the default batching is a quite common use case for people running on GPUs.\r\n\r\nIt would be awesome if it is possible to add this example (or a similar one using MirroredStrategy and a large cached dataset) to your internal regression testing suite. In a lot of the TF version upgrades I have done in the past I discovered some sort of memory issue or performance regression that was reproducible with code very similar the example mentioned above (See #36240, #38617, #38655). It would be excellent if issues like that would be caught automatically so they don't make it into the stable releases."]}, {"number": 41808, "title": "Golang Tensorflow v2.3.0 installation fails", "body": "### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**: No\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux-4.19.0-9-amd64-x86_64-with-debian-10.4\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**: \r\n-   **TensorFlow installed from (source or binary)**: Not installed (golang go command pull tensorflow from github)\r\n-   **TensorFlow version (use command below)**: 2.3.0 (same bug in 2.2.0)\r\n-   **Python version**:  2.7.16 (but python 3.7 is installed too)\r\n-   **Bazel version (if compiling from source)**: 3.1.0\r\n-   **GCC/Compiler version (if compiling from source)**:\r\n-   **CUDA/cuDNN version**:\r\n-   **GPU model and memory**:\r\n-   **Exact command to reproduce**: go get github.com/tensorflow/tensorflow/tensorflow/go\r\n\r\n\r\n### Describe the problem\r\nBUG --- As in tensorflow-go@v2.2.0, tensorflow-go@v2.3.0 fail at installation.\r\n\r\n### Source code / logs\r\nFrom inside GOPATH:\r\ngo: found github.com/tensorflow/tensorflow/tensorflow/go in github.com/tensorflow/tensorflow v2.3.0+incompatible\r\ngo: finding module for package github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto\r\ngo: finding module for package github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto\r\n../../go/pkg/mod/github.com/tensorflow/tensorflow@v2.3.0+incompatible/tensorflow/go/saved_model.go:25:2: module github.com/tensorflow/tensorflow@latest found (v2.3.0+incompatible), but does not contain package github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto\r\n\r\nFrom inside a go.mod compliant directory:\r\ngo: found github.com/tensorflow/tensorflow/tensorflow/go in github.com/tensorflow/tensorflow v2.3.0+incompatible\r\ngo: finding module for package github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto\r\ngo: finding module for package github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto\r\n../../go/pkg/mod/github.com/tensorflow/tensorflow@v2.3.0+incompatible/tensorflow/go/saved_model.go:25:2: module github.com/tensorflow/tensorflow@latest found (v2.3.0+incompatible), but does not contain package github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto\r\n\r\nLooks like exactly the same old bug from tensorflow@v2.2.0 from this issue: https://github.com/tensorflow/tensorflow/issues/39307", "comments": ["Happened the same for me... in order to use go with tensorflow I used the 1.15.0 as go dependency.\r\n\r\nBut still, it seems that there is a dependency issue on the 2.2+... and for python 3.8 it should use 2.2+", "I can confirm this occurs for me as well. For the time being I am using the 2.3.0 C library with the 2.1.0 Go module. There are warnings at link time but it seems to function for all my usage. If this needs further debugging I'm happy to help out to expedite the process. I'd prefer to keep the library and module versions in sync", "confirmed, urgently need fix", "this broke the whole go tensorflow", "Same issue here :( \r\nAnd it is not happening only in 2.3. It is affecting all 2.* versions.\r\n\r\nI found discussions https://github.com/tensorflow/tensorflow/issues/39744 and here https://github.com/tensorflow/tensorflow/pull/40752\r\n\r\nThere was a PR (https://github.com/tensorflow/tensorflow/commit/e5e495db7bee77cd0fd5dda3b06bd743cbcf1ef8) the supposedly would fix the issue, but I checkout master and tested it, and I got the same error.\r\n\r\n@jhseu since your changes are not in a tag yet, I tested using master branch. I got the same error.\r\nI followed the steps in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/go/README.md, and I did not found the proto files in the Go code (in src/github...), they were generated inside Bazel cache directories.\r\n\r\nI believe the problem is that Bazel is generating the files, so they are created inside Bazel building dirs (bazel-tensorflow/tensorflow/go/vendor/github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto).\r\n\r\nShould we have a script to generate the files within the golang code?\r\nI am trying to make it work in my environment by generating the proto files, but I am having other issues because the importing path from other libs... \r\n\r\nHelp, please :(  \r\n\r\n", "Well, it is working for me now, but I had to do some hacks to make it works.\r\n\r\nFirst, differently of what I said in the comment above, we do have a script that generates the proto files outside Bazel dir, however it only generates inside a vendor dir (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/go/genop/generate.sh#L70).\r\n\r\nThese are the steps I followed to make it works in my environment\r\n\r\n0. Follow the steps described on https://github.com/tensorflow/tensorflow/blob/master/tensorflow/go/README.md#build\r\n0. The `3.a` (Copying it to a system location) step will fail, you must copy `libtensorflow_framework.so.2` instead of `libtensorflow_framework.so` \r\n0. The step 4 (generate **and** test) also will fail, but no worries, keep going...\r\n0. Now run these commands inside `${GOPATH}/src/github.com/tensorflow/tensorflow/`\r\n   ```\r\n   cp -R tensorflow/go/vendor/github.com/tensorflow/tensorflow/tensorflow/go/core tensorflow/go/core\r\n   cp -R tensorflow/go/vendor/github.com/tensorflow/tensorflow/tensorflow/go/stream_executor tensorflow/go/\r\n   ```\r\n0. Run the tests again `go test github.com/tensorflow/tensorflow/tensorflow/go`, if you get the error saying \"_libtensorflow.so.2: cannot open shared object file: No such file or directory_\", may need to execute the step 3.b instead of the 3.a\r\n\r\nAssuming the test is passing, you may continue.\r\n\r\nIf your Go project is using Go modules ON, you will have to:\r\n\r\n0. Force Go to use the local directory instead of importing it. So, add this to your go.mod file:\r\n   ```\r\n   replace github.com/tensorflow/tensorflow => [your absolute Gopath]/src/github.com/tensorflow/tensorflow\r\n   ```\r\n0. Force `github.com/tensorflow/tensorflow` looks like a Go module project. \r\n   ```\r\n   cd  ${GOPATH}/src/github.com/tensorflow/tensorflow/\r\n   go mod init github.com/tensorflow/tensorflow\r\n   ```\r\n\r\nJust keep in mind that it is a workaround. I did it because the bug was blocking me.\r\n\r\n\r\n\r\n", "^^ i don't undestand why tensorflow makes problems? golang is product from google, tensorflow is product from google :/ \r\nMy question is, is the problem so hard that the bug fix takes so long time?", "This is actually fixed at master following the instructions at (just ran the commands just now to verify):\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/go/README.md\r\n\r\nThe fix didn't make it into TensorFlow 2.3. (The `go get -d` command will warn about package not found, but you can ignore it since it's built with `go generate`)\r\n\r\nNote that you _must_ build an updated version of libtensorflow.so as indicated in the instructions, otherwise you'll get errors.", "> This is actually fixed at master following the instructions at (just ran the commands just now to verify):\r\n> https://github.com/tensorflow/tensorflow/blob/master/tensorflow/go/README.md\r\n> \r\n> The fix didn't make it into TensorFlow 2.3. (The `go get -d` command will warn about package not found, but you can ignore it since it's built with `go generate`)\r\n> \r\n> Note that you _must_ build an updated version of libtensorflow.so as indicated in the instructions, otherwise you'll get errors.\r\n\r\nDo you have a plan for: \r\n- make the fix into a release\r\n- offer a new libtensorflow.so in [google cloud platform](https://console.cloud.google.com/storage/browser/vml-tf-lib;tab=objects?project=dev-vml-cm&prefix=&forceOnObjectsSortingFiltering=false)\r\n\r\n", "I hope this can be easily go gettable soon....", "Hi, when I follow the build instructions, I get ` libtensorflow_framework.2.5.0.dylib` and `libtensorflow_framework.2.dylib` but no `libtensorflow_framework.2.so` in my `${GOPATH}/src/github.com/tensorflow/tensorflow/bazel-bin/tensorflow/` directory and i'm not sure why, has anyone had this problem?\r\nEdit: for me, everything after step 4 fails with \r\n\r\n```\r\ntensorflow/go/saved_model.go:25:2: cannot find package \"github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto\" in any of:\r\n\t/usr/local/go/src/github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto (from $GOROOT)\r\n\t/Users/<user>/go/src/github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto (from $GOPATH)\r\n```", "yeah folks, we need this library  **go gettable**", "can we please fix this, i don't want to do any of these hacks on prod", "How hard to release this? it has been a while for this issue.", "Yes please. I spent most of the day trying to build this and am stuck. Proto compiler refuses to use the include directory on my computer to find those common protos (like Any, etc). Help!", "> Hi, when I follow the build instructions, I get ` libtensorflow_framework.2.5.0.dylib` and `libtensorflow_framework.2.dylib` but no `libtensorflow_framework.2.so` in my `${GOPATH}/src/github.com/tensorflow/tensorflow/bazel-bin/tensorflow/` directory and i'm not sure why, has anyone had this problem?\r\n> Edit: for me, everything after step 4 fails with\r\n> \r\n> ```\r\n> tensorflow/go/saved_model.go:25:2: cannot find package \"github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto\" in any of:\r\n> \t/usr/local/go/src/github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto (from $GOROOT)\r\n> \t/Users/<user>/go/src/github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto (from $GOPATH)\r\n> ```\r\n\r\n@iliailmer did you try the steps I suggested above? I got the same error too. Those steps should work around that.", "> > Hi, when I follow the build instructions, I get ` libtensorflow_framework.2.5.0.dylib` and `libtensorflow_framework.2.dylib` but no `libtensorflow_framework.2.so` in my `${GOPATH}/src/github.com/tensorflow/tensorflow/bazel-bin/tensorflow/` directory and i'm not sure why, has anyone had this problem?\r\n> > Edit: for me, everything after step 4 fails with\r\n> > ```\r\n> > tensorflow/go/saved_model.go:25:2: cannot find package \"github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto\" in any of:\r\n> > \t/usr/local/go/src/github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto (from $GOROOT)\r\n> > \t/Users/<user>/go/src/github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto (from $GOPATH)\r\n> > ```\r\n> \r\n> @iliailmer did you try the steps I suggested above? I got the same error too. Those steps should work around that.\r\n\r\nhi @rubens21, how did you get the protobuf to build?\r\n\r\n```\r\n\u2718-1 ~/go/src/github.com/tensorflow/tensorflow [master \u2193\u00b781|\u202648]\r\n10:48 $ go generate github.com/tensorflow/tensorflow/tensorflow/go/op\r\ngoogle/protobuf/any.proto: File not found.\r\ngoogle/protobuf/duration.proto: File not found.\r\ntensorflow/core/protobuf/autotuning.proto:10:1: Import \"google/protobuf/any.proto\" was not found or had errors.\r\ntensorflow/core/protobuf/autotuning.proto:11:1: Import \"google/protobuf/duration.proto\" was not found or had errors.\r\ntensorflow/core/protobuf/autotuning.proto:61:3: \"google.protobuf.Duration\" is not defined.\r\ntensorflow/core/protobuf/autotuning.proto:74:3: \"google.protobuf.Any\" is not defined.\r\n../genop/generate.go:19: running \"bash\": exit status 1\r\ntensorflow/go/op/generate.go:17: running \"go\": exit status 1\r\n```\r\n\r\nMy /usr/local/include has the right paths (`google/protobuf/any.proto` etc)", "I finally got the protobuf to build by copying the `/usr/local/include/google` directory (which has the protobuf include files) to my `${GOPATH}/src/github.com/tensorflow/tensorflow` directory. I don't know why it needs to look there, or why it wasn't there. However, I get another error:\r\n\r\n```\r\n15:27 $ go generate github.com/tensorflow/tensorflow/tensorflow/go/op\r\ndyld: Symbol not found: __ZN10tensorflow10FileSystem10FilesExistERKNSt3__16vectorINS1_12basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEENS6_IS8_EEEEPNS2_INS_6StatusENS6_ISD_EEEE\r\n  Referenced from: /usr/local/lib/libtensorflow.2.dylib\r\n  Expected in: /usr/local/lib/libtensorflow_framework.2.dylib\r\n in /usr/local/lib/libtensorflow.2.dylib\r\nsignal: abort trap\r\ntensorflow/go/op/generate.go:18: running \"go\": exit status 1\r\n```\r\n\r\nSomeone please help! Is this not go gettable in any architecture? ", "@domino14 protoc looks at all the paths passed to protoc with the -I option, in this case it's called from the bash script in `genop/generate.sh` - you can always adjust the include paths there.\r\n\r\nSymbol errors like this are often mismatches between header files and compiled binaries, make sure you used a released version instead of building from master.\r\n\r\nSince you've been at it for quite some time, I can share the temporary solution that we're using until the issue is fixed - I basically [forked the bindings and included the generated protos](https://github.com/zia-ai/tensorflow-go), if it helps you feel free to use it and replace the dep inside your go.mod file as such:\r\n\r\n```\r\nreplace github.com/tensorflow/tensorflow v2.3.1 => github.com/zia-ai/tensorflow-go v2.3.1\r\n```\r\n\r\nThere's a matching [official pre-built C library](https://www.tensorflow.org/install/lang_c) available.\r\n", "@mrene thank you. I did that and got this error:\r\n\r\n```\r\n/src/go.mod:19: replace github.com/zia-ai/tensorflow-go: version \"v2.3.1\" invalid: module contains a go.mod file, so major version must be compatible: should be v0 or v1, not v2\r\n```", "you have to change the tag to v1.0.0 that worked for me somehow go does not pick up on the v2.3.1 zia-ai git tag.\r\nThanks for the effort @mrene !", "Hey, I just want to share.\r\n> \"libtensorflow.so.2: cannot open shared object file: No such file or directory\"\r\n\r\nTo resolve this error, you need setting LIBRARY_PATH/LD_LIBRARY_PATH point to `/usr/local/lib`. I found this instruction from stackoverflow https://stackoverflow.com/a/57156500", "Hey, has there been any progress on this? It would be really nice if this was fixed in the official TF repo so it's usable OOTB - I'd rather not use forks or mess with building protobufs by myself.", "Since this issue isn't getting fixed, I decided to maintain a fork: https://github.com/galeone/tensorflow\r\n\r\n```\r\ngo get github.com/galeone/tensorflow/tensorflow/go@r2.4-go\r\n```\r\n\r\nYou can also use [tfgo](https://github.com/galeone/tfgo) that depends on the fork and it allows a simplified usage of the Go bindings:\r\n\r\n```\r\ngo get github.com/galeone/tfgo\r\n```", "I am using tensorflow 2.4.0, this one worked for me.\r\n\r\nWhile configuring the env variables for linker from https://www.tensorflow.org/install/lang_c. instead try Absolute path as below\r\n```\r\nexport LIBRARY_PATH=/mydir/lib\r\nexport DYLD_LIBRARY_PATH=/mydir/lib\r\n```\r\n\r\nThis worked for me, caching the go package here.\r\n```\r\nshankernaik$ go test github.com/tensorflow/tensorflow/tensorflow/go\r\n# github.com/tensorflow/tensorflow/tensorflow/go.test\r\nld: warning: directory not found for option '-L/Users/shankernaik/Users/shankernaik/libtensorflow-cpu-darwin-x86_64-2.4.0'\r\nok  \tgithub.com/tensorflow/tensorflow/tensorflow/go\t(cached)\r\n```", "@galeone @jhseu is this a correct summary of the issue and work-around?\r\n\r\nSome of the modules that are required for using TF from Go are artifacts that are generated during the TF build process (therefore, NOT checked into the repository). Go module processing expects to \"get\" those modules from their \"import\" paths;  but, obviously, it can't find them.  The work-around is to build the library, and generate the Go modules, locally and map the well-known path to the local copy using go.mod \"replace\".\r\n", "Hi, I have some comments to share.\r\n\r\nFirst, I started my application by try to use TensorFlow API directly in Go. In development environment, I used [DevContainer to run Go code](https://github.com/giautm/tensorflow-go-example) with TensorFlow in binary. But, when I trying to deploy my application to production mode. I realize that TensorFlow is too big to be deployed with the same application. (Docker image contain TensorFlow & application will have > 1.2GB for size).\r\n\r\nSo, I try to using another way to use TensorFlow in my app. `tensorflow/serving:2.4.0` has 76.62 MB for size, then with GPU is 3.44 GB. It's a great option to deploy your app to production environment. (76.62MB for TensorFlow + ~10 MB for application). ;)\r\n\r\nhttps://www.tensorflow.org/tfx/serving/docker", "2021 is half past", "> 2021 is half past\r\n\r\nHere's the working available solution: https://github.com/tensorflow/tensorflow/issues/41808#issuecomment-779766175", "Speechless.", "right?", "> Speechless.\r\n\r\nyup. And disappointing.", "@jhseu Well done. \ud83d\ude44\ud83d\ude44", "Not works.", "Having the same issue :/\r\nYes can be worked around but still not pleasant", "> Having the same issue :/ Yes can be worked around but still not pleasant\r\n\r\n```\r\ngo get github.com/galeone/tfgo\r\n```\r\n\r\nThis project depends on the fork I maintain (galeone/tensorflow) that is go-gettable\r\n", "See:\r\n-  #53549", "`go: finding module for package github.com/tensorflow/tensorflow/tensorflow/go\r\ngo: found github.com/tensorflow/tensorflow/tensorflow/go in github.com/tensorflow/tensorflow v2.7.0+incompatible\r\ngo: finding module for package github.com/tensorflow/tensorflow/tensorflow/go/core/framework/types_go_proto\r\ngo: finding module for package google.golang.org/protobuf/proto\r\ngo: finding module for package github.com/tensorflow/tensorflow/tensorflow/go/core/framework/tensor_shape_go_proto\r\ngo: finding module for package github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto\r\ngo: found google.golang.org/protobuf/proto in google.golang.org/protobuf v1.27.1\r\ngo: finding module for package github.com/tensorflow/tensorflow/tensorflow/go/core/framework/tensor_shape_go_proto\r\ngo: finding module for package github.com/tensorflow/tensorflow/tensorflow/go/core/framework/types_go_proto\r\ngo: finding module for package github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto\r\ngolang/database imports\r\n\tgithub.com/tensorflow/tensorflow/tensorflow/go imports\r\n\tgithub.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto: module github.com/tensorflow/tensorflow@latest found (v2.7.0+incompatible), but does not contain package github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto\r\ngolang/database imports\r\n\tgithub.com/tensorflow/tensorflow/tensorflow/go tested by\r\n\tgithub.com/tensorflow/tensorflow/tensorflow/go.test imports\r\n\tgithub.com/tensorflow/tensorflow/tensorflow/go/core/framework/tensor_shape_go_proto: module github.com/tensorflow/tensorflow@latest found (v2.7.0+incompatible), but does not contain package github.com/tensorflow/tensorflow/tensorflow/go/core/framework/tensor_shape_go_proto\r\ngolang/database imports\r\n\tgithub.com/tensorflow/tensorflow/tensorflow/go tested by\r\n\tgithub.com/tensorflow/tensorflow/tensorflow/go.test imports\r\n\tgithub.com/tensorflow/tensorflow/tensorflow/go/core/framework/types_go_proto: module github.com/tensorflow/tensorflow@latest found (v2.7.0+incompatible), but does not contain package github.com/tensorflow/tensorflow/tensorflow/go/core/framework/types_go_proto\r\n`\r\n\r\ngo version go1.17.6 darwin/arm64\r\n\r\nIs there any solution yet?\r\n\r\n", "There's no prebuilt C library for arm64: https://www.tensorflow.org/install/lang_c\r\n\r\nHence not even [tfgo](https://github.com/galeone/tfgo) supports this"]}, {"number": 41798, "title": "S3 ParseURI supporting query parameters", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\nCurrently, when I pass query parameters as a part of my request to `TFRecordDataset`  the query becomes a part of the object name. For example:\r\n```\r\nfilenames = [\"s3://bucketname/path/to/file1.tfrecord?uuid=<UUID>\",\r\n             \"s3://bucketname/path/to/file2.tfrecord?uuid=<UUID>\"]\r\ndataset = tf.data.TFRecordDataset(filenames)\r\n```\r\nOn the server-side, we then see `path/to/file1.tfrecord?uuid=<UUID>` as the path with the `query params` as empty which should not be the case, as `?` is a query param delimiter and should be treated as such.\r\n\r\n**Will this change the current api? How?**\r\n\r\nNo. But it will eliminate the need for a hack on the storage side to parse/strip URL query from object names. Thus, it will enhance TensorFlow <=> Cloud storage integration - which is a good thing.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nPeople who run TensorFlow against datasets hosted by Object/Cloud storages. In our case, we are a team at NVIDIA, working on the open-source https://github.com/NVIDIA/aistore where TensorFlow is one of the critical client apps that we want to support.\r\n\r\nIt will be of great help, as the feature would be free of hacks.\r\n\r\n**Any Other info.**", "comments": ["I think this support would be implemented by modifying [s3_file_system.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/s3/s3_file_system.cc), as opposed to making a change within `TFRecordDataset`. Reassigning to Mihai, who is more familiar with the filesystem level.", "I agree with Andrew, this is an issue in the current implementation. I'll take a look at this in ~1 week or so, unfortunately I cannot before. However, PRs are welcome, if you can get a fix earlier.", "Adding additional information. I think tensorflow is dependent on the [aws-sdk-cpp](https://github.com/aws/aws-sdk-cpp) and the sdk doesn't support sending custom query parameters. https://sdk.amazonaws.com/cpp/api/LATEST/class_aws_1_1_transfer_1_1_transfer_manager.html#a4c1aec774f4338acee2fd8d90ed052eb Think it makes more sense to raise an issue there ? ", "@mihaimaruseac any comments you would have ?", "Let's raise the issue to aws-sdk-cpp repo. TF could add a layer to strip the query parameters in the AWS filesystem too, if you want to send a PR. But I think it's better to raose the issue to the sdk first."]}]