[{"number": 19886, "title": "saving tensorflow models in hdf5", "body": "Hi Everyone\r\n\r\nWhile using tensorflow, how to save the model in hdf5 file format (like keras does using model.save) .  \r\n\r\nMost of the documentation I found online is for saving models in tensorflow with a checkpoint using saver.save\r\n\r\nWhile trying \r\ntf.keras.models.save_model('model.h5',filepath='Desktop/')\r\nin my mnist code in tensorflow, I get the following error\r\n\r\nOSError: Unable to create file (unable to open file: name = 'Desktop/', errno = 22, error message = 'Invalid argument', flags = 13, o_flags = 302)", "comments": ["raghavgurbaxani@ the first argument to save_model is the model instance itself and the second argument (i.e \"filepath\" parameter) is the path where you want to save the file, e.g: \"Desktop/model.h5\".  [Here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/saving.py#L51) is a link to where the call is defined.\r\nCan you try this change and see if you still get an error?", "Hi @anj-s , thanks that worked.\r\n\r\nAlso wanted to ask if there is a way to store weights in hdf5 without using tf.keras as I am trying to use float 16 ,uint 8  and uint16 operations for my research that keras doesn't support.\r\n\r\n\r\nI want to try the data types mentioned here https://www.tensorflow.org/versions/r1.2/programmers_guide/dims_types and save tensorflow model as hdf5. \r\n \r\nThanks ", "@reedwm could you help out with saving tensorflow models using hdf5 (without using a keras interface) ?", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 19885, "title": "Tf summary merge all may cause issues", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A\r\n- **TensorFlow installed from (source or binary)**: N/A\r\n- **TensorFlow version (use command below)**: N/A\r\n- **Python version**: N/A\r\n- **Bazel version (if compiling from source)**:N/A\r\n- **GCC/Compiler version (if compiling from source)**:N/A\r\n- **CUDA/cuDNN version**:N/A\r\n- **GPU model and memory**:N/A\r\n- **Exact command to reproduce**:N/A\r\n\r\n\r\n\r\nThere are cases in which separate summaries would be good to have, e.g. for a graph that has more than one networks that are somewhat independent. \r\n\r\nIn this case, having individual summaries so that they can be individually used is helpful. Most times , scalars + data (images or text) are needed to be logged, so calling `tf.summary.merge` and having to maintain a handle on all the summary requires a lot of code. \r\n\r\ncalling `tf.summary.merge_all()` requires the data to be present for ALL possible summaries, which may introduce bugs and cause unnecessary computation. \r\n\r\nMy proposal is to use a context manager and add the summaries to that context, which can be merged automatically. \r\n\r\nSomewhat along the lines of : \r\n\r\n```python\r\nwith tf.merged_summaries() as merged: \r\n    merged.add_summary(tf.summary.scalar('dropout_keep_probability', keep_prob)) # add scalar\r\n    merged.add_summary(tf.summary.Image('dropout_keep_probability', some_image)) # add image\r\n```\r\nthen after this block is done , `merged` can be used somewhat like this : \r\n\r\n```python\r\ntraining_only_summary_op = merged.get_op()  # will call `tf.summary.merge()` internally \r\n```\r\n\r\nI can make a pull request for this if this idea is worth exploring \r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "For each `tf.summary` call you can choose the collection to put it into, and then in `merge_all` you can choose which collection to merge. I don't like this solution but it's one way to go.\r\n\r\nI think this reflects a design issue with the normal global-collection-based workflow. A similar issue comes with UPDATE_OPS collection: if I want to train two networks alternatively, I'll need to maintain two separate UPDATE_OPS collection.", "My suggestion will remove the requirement for searching the graph keys by strings. In my opinion something like my solution will make tensorboard cleaner to use by clustering similar summaries together ", "Nagging Assignee @jart: It has been 78 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @jart: It has been 93 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 19884, "title": "Providing resource variables to feed_dict can be confusing", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:Binary\r\n- **TensorFlow version (use command below)**:1.8\r\n- **Python version**:3.6.2 \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:None\r\n- **GPU model and memory**:CPU\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nAccording to the documentation, the Tf.contrib.eager has classes that can be used both in Eager and Graph modes. However the results are not consistent when we pass feed_dict to a variable.\r\n\r\n### Source code / logs\r\n\r\n```\r\nimport tensorflow as tf\r\ntfe = tf\r\nx = tfe.Variable(4)\r\ny = x * x\r\nwith tf.Session() as sess:\r\n     sess.run(tf.global_variables_initializer())\r\n     print(sess.run(y, feed_dict={x: 15}))  # Prints 225 which is correct\r\n\r\ntfe = tf.contrib.eager\r\nx = tfe.Variable(4)\r\ny = x * x\r\n\r\nwith tf.Session() as sess:\r\n     sess.run(tf.global_variables_initializer())\r\n     print(sess.run(y, feed_dict={x: 15}))  #Prints 16, which is not consistent with 225 above\r\n\r\n```", "comments": ["Hi @ecvgit. I am not too familiar with eager execution; however, I believe you have to enable it on the start of your program. Also, why are you using `tf.contrib.eager`? All you need to do is enable eager execution with `tf.enable_eager_execution()` and everything should work spectacularly. \r\n\r\nThe point of eager execution is to evaluate directly like with normal Python objects, so I also believe you don't need to execute it within a `tf.Session()`. Hope this helps. ", "In this case, I am not using eager execution at all. I am using graph execution using the tf.Variable and tfe.Variable. My understanding is that if I use tfe.Variable (instead of tf.Variable), then I should be able to switch out graph and eager modes easily. In order for this work, the results should be consistent between tf.Variable and tfe.Variable. As the above example shows, they are not. If this is expected behavior, it is not clear from the documentation.", "Hmm, I'm not sure I understand this. I'll let someone else pick up this Issue. Perhaps the assigned @tatianashp can help you. ", "@asimshankar Do you have any thoughts?", "Thanks for bringing this up, I can understand the confusion.\r\n\r\nTo be clear, the intention is that symbols in the `tf.contrib.eager` namespace can be used in both eager and graph execution, not that they are equivalent to other symbols in the `tf` namespace. So, `tfe.Variable` works with both graph and eager execution, but its behavior is not always the same as `tf.Variable`.\r\n\r\nIn fact, `tfe.Variable` is a different implementation of variables called \"resource variables\" in the implementation (introduced independently of eager execution), which have more clearly defined memory semantics. We're in the process of making resource variables more prevalent (and in fact, they are required for TPUs as well) because of the [saner memory model](https://github.com/tensorflow/tensorflow/blob/212ba3e9ef934d0b2a3b09740bd238cda0394fad/tensorflow/python/ops/variables.py#L126).\r\n\r\nNow, when it comes to `feed_dict`, the intention there is to be able to feed values for `Tensor`s, not `Variable`s. The fact that it works for variables is more of an accident :). We perhaps should make that be an error (at least for resource variables) instead of the seemingly mysterious behavior you see (CC @alextp - who is also writing up some documentation around this).\r\n\r\nThe program you've described above:\r\n```python\r\nx = tfe.Variable(4)\r\ny = x * x\r\n```\r\n\r\nis essentially shorthand for the program:\r\n\r\n```python\r\nx = tfe.Variable(4)\r\nx_1 = x.read_value()  # Return a Tensor corresponding to the current value of the Variable\r\ny = x_1 * x_1\r\n```\r\n\r\nAnd when expressed like this, you could use `feed_dict`:\r\n\r\n```python\r\nimport tensorflow as tf\r\ntfe = tf.contrib.eager\r\n\r\nx = tfe.Variable(4)\r\nx_1 = x.read_value()\r\ny = x_1 * x_1\r\n\r\nwith tf.Session() as sess:\r\n     sess.run(tf.global_variables_initializer())\r\n     print(sess.run(y, feed_dict={x_1: 15})) # Will print 225\r\n```\r\n\r\nThough this works, in general, do you typically include variables in the feed_dict?\r\n\r\nI understand this is confusing, hopefully the explanation makes sense.\r\nThe bug itself isn't about eager, so I'm going to go ahead and adjust the title of the bug to reflect that while we figure out how to more clearly make this an error.\r\n\r\nHope that sounds reasonable. Thanks!", "Nagging Assignee @tatianashp: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tatianashp: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tatianashp: It has been 44 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 19883, "title": "tf-nightly: cannot import tensorflow", "body": "As of today (2018-06-09), the reproduction steps are:\r\n\r\n```sh\r\npip install -U tf-nightly\r\n```\r\n\r\n```python\r\nimport tensorflow as tf\r\n```\r\n\r\nThe error stack looks like:\r\n\r\n> ~/venv_cpu_py3/lib/python3.5/site-packages/tensorflow/__init__.py in <module>()\r\n>      20 \r\n>      21 # pylint: disable=g-bad-import-order\r\n> ---> 22 from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n>      23 from . import app\r\n>      24 from . import bitwise\r\n> \r\n> ~/venv_cpu_py3/lib/python3.5/site-packages/tensorflow/python/__init__.py in <module>()\r\n>      79 # Bring in subpackages.\r\n>      80 from tensorflow.python import data\r\n> ---> 81 from tensorflow.python import keras\r\n>      82 from tensorflow.python.estimator import estimator_lib as estimator\r\n>      83 from tensorflow.python.feature_column import feature_column_lib as feature_column\r\n> \r\n> ~/venv_cpu_py3/lib/python3.5/site-packages/tensorflow/python/keras/__init__.py in <module>()\r\n>      22 from __future__ import print_function\r\n>      23 \r\n> ---> 24 from tensorflow.python.keras import activations\r\n>      25 from tensorflow.python.keras import applications\r\n>      26 from tensorflow.python.keras import backend\r\n> \r\n> ~/venv_cpu_py3/lib/python3.5/site-packages/tensorflow/python/keras/activations/__init__.py in <module>()\r\n>      20 \r\n>      21 # Activation functions.\r\n> ---> 22 from tensorflow.python.keras._impl.keras.activations import elu\r\n>      23 from tensorflow.python.keras._impl.keras.activations import hard_sigmoid\r\n>      24 from tensorflow.python.keras._impl.keras.activations import linear\r\n> \r\n> ~/venv_cpu_py3/lib/python3.5/site-packages/tensorflow/python/keras/_impl/keras/__init__.py in <module>()\r\n>      19 from __future__ import print_function\r\n>      20 \r\n> ---> 21 from tensorflow.python.keras._impl.keras import activations\r\n>      22 from tensorflow.python.keras._impl.keras import applications\r\n>      23 from tensorflow.python.keras._impl.keras import backend\r\n> \r\n> ~/venv_cpu_py3/lib/python3.5/site-packages/tensorflow/python/keras/_impl/keras/activations.py in <module>()\r\n>      21 import six\r\n>      22 \r\n> ---> 23 from tensorflow.python.keras._impl.keras import backend as K\r\n>      24 from tensorflow.python.keras._impl.keras.utils.generic_utils import deserialize_keras_object\r\n>      25 from tensorflow.python.layers.base import Layer\r\n> \r\n> ~/venv_cpu_py3/lib/python3.5/site-packages/tensorflow/python/keras/_impl/keras/backend.py in <module>()\r\n>      35 from tensorflow.python.framework import ops\r\n>      36 from tensorflow.python.framework import sparse_tensor\r\n> ---> 37 from tensorflow.python.layers import base as tf_base_layers\r\n>      38 from tensorflow.python.ops import array_ops\r\n>      39 from tensorflow.python.ops import clip_ops\r\n> \r\n> ~/venv_cpu_py3/lib/python3.5/site-packages/tensorflow/python/layers/base.py in <module>()\r\n>      23 from tensorflow.python.framework import dtypes\r\n>      24 from tensorflow.python.framework import ops\r\n> ---> 25 from tensorflow.python.keras.engine import base_layer\r\n>      26 from tensorflow.python.ops import variable_scope as vs\r\n>      27 from tensorflow.python.ops import variables as tf_variables\r\n> \r\n> ~/venv_cpu_py3/lib/python3.5/site-packages/tensorflow/python/keras/engine/__init__.py in <module>()\r\n>      19 from __future__ import print_function\r\n>      20 \r\n> ---> 21 from tensorflow.python.keras.engine.base_layer import InputSpec\r\n>      22 from tensorflow.python.keras.engine.base_layer import Layer\r\n>      23 from tensorflow.python.keras.engine.input_layer import Input\r\n> \r\n> ~/venv_cpu_py3/lib/python3.5/site-packages/tensorflow/python/keras/engine/base_layer.py in <module>()\r\n>      31 from tensorflow.python.framework import tensor_shape\r\n>      32 from tensorflow.python.framework import tensor_util\r\n> ---> 33 from tensorflow.python.keras import backend\r\n>      34 from tensorflow.python.keras import constraints\r\n>      35 from tensorflow.python.keras import initializers\r\n> \r\n> ~/venv_cpu_py3/lib/python3.5/site-packages/tensorflow/python/keras/backend/__init__.py in <module>()\r\n>      20 \r\n>      21 # pylint: disable=redefined-builtin\r\n> ---> 22 from tensorflow.python.keras._impl.keras.backend import abs\r\n>      23 from tensorflow.python.keras._impl.keras.backend import all\r\n>      24 from tensorflow.python.keras._impl.keras.backend import any\r\n>\r\n> ImportError: cannot import name 'abs'\r\n\r\nNote that the same error does *not* happen in tensorflow 1.8.0 or 1.9.0rc0.", "comments": ["cc @gunan @fchollet ", "cc @case540 As we discussed, this problem seems to happen only if one tries to upgrade from an older version of tensorflow (e.g., 1.8.0) to tf-nightly circa 2018-06-09. It doesn't happen if you installed the said version of tf-nightly directly in a clean virtualenv, or if you upgrade from tensorflow 1.8.0 to 1.9.0rc0. It may have to do with how pip cleans up old files and how it treats the relation between the two pip packages with different names, 'tensorflow' and 'tf-nightly'.", "Nagging Assignee @poxvoculi: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@caisq @case540 is this still happening?", "ping?", "Also see #20484 ", "I upgraded from 1.8 to 1.9.0rc0 and the issue persists.", "Nagging Assignee @gunan: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This is the same issue as https://github.com/tensorflow/tensorflow/issues/20778\r\nWhat happens is, you end up with leftover files in your pip tensorflow directory, and when you install a new version, you have a corrupt installation.\r\nThis is a bug in pip itself, and a workaround you may use is to uninstall TF first, clear the \"tensorflow\" directory under your site-packages directory, and then reinstall tensorflow after that.", "Closed as a duplicate."]}, {"number": 19882, "title": "Merge weight column of duplicated indices for indicator_column", "body": "Fix #19876 . cc @ispirmustafa \r\n\r\n", "comments": ["Nagging Assignee @drpngx: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@drpngx  Internal CI infrastructure error. Could you restart all tests? Thanks."]}, {"number": 19881, "title": "Unable to install Tensorflow following documentation", "body": "### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\nUnable to install Tensorflow using the official documentation.  On the documentation its says install VirtualEnv. https://www.tensorflow.org/install/install_mac.  When you folllow the first instruction:\r\n`sudo easy_install pip` it returns the following error message: \r\n```Not a recognized archive type: pip```\r\n\r\nIts not clear what the correct method to install - but it should be indicated in the documentation to not confuse new users. \r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["Hi @grantkemp. I'm sorry you weren't able to install TensorFlow. I'll try my best to help you. \r\n\r\nFrom the link you provided, it appears that you are using a Mac. I use a Mac as well and have never seen this error before. Can you make sure you have Python installed and working on your machine? You can check this by running `python` in the Terminal app. \r\n \r\nUpdate this Issue when you've verified that. \r\n\r\nTo clarify the documentation: TensorFlow can be installed many different ways. VirtualEnv (the method they recommend) is the safest because it is a virtual python environment - This means that whatever dependencies TensorFlow has will not touch your existing Python environment. There is no \"correct\" way to install TensorFlow. It depends solely on your purpose. ", "Hi @marshalhayes \r\n\r\nThanks . - you are correct.  Apparently Mac high sierra comes with Python installed but not pip ( presumably you installed it on an older version?) . \r\nI installed the latest python binary - and then I ran. \r\n`sudo -H python -m ensurepip` which seems to have got it working. \r\n\r\nI am onto the next step - but it doesn't seem very clear. Ideally in getting started tutorials the docs should walk users through the basics ideally using copy/ paste commands and ideally it would be cool to have a seperate tab for specific implementation like Google do for swift/ Objective C \r\n\r\n ( I have updated the documentation below to try help others. )\r\n```Create a Virtualenv environment by issuing a command of one of the following formats:\r\n\r\n $ virtualenv --system-site-packages ~/tensorflow, # for Python 2.7\r\n\r\nActivate the Virtualenv environment by issuing one of the following commands:\r\n\r\n$ cd targetDirectory\r\n$ source ./bin/activate      # If using bash, sh, ksh, or zsh\r\n$ source ./bin/activate.csh  # If using csh or tcsh \r\nThe preceding source command should change your prompt to the following:\r\n\r\n (tensorflow)$ ```\r\n\r\nIdeally the documentation should add the lines: \r\n\r\n1. Check what version of python you are running by typing `python` into the terminal\r\n2. If you are running version 2.7 then you can install tensorflow using this command `virtualenv --system-site-packages ~/tensorflow`\r\n3. cd `~/tensorflow`\r\n4. Activate your Tensorflow Virtual Environment by typing `source ./bin/activate ` ( you do this each time you want to use Tensorflow ( its not clear how I tell if I am using bash, sh, ksh, or zsh / csh as there are no links to help me decide.)\r\n5. You will then see the prompt for command has changed to: `(tensorflow)YOURACCOUNT:tensorflow YOURACCOUNT$ `\r\n\r\n6.  etc..```\r\n\r\nAfter that I managed to get it working..( so far!)\r\n\r\n\r\n\r\n\r\n", "I will close this ticket as its sorted for me. Thanks for initial response @marshalhayes "]}, {"number": 19880, "title": "tf.image.resize_* gives negative results", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**:  v1.8.0-7-g3b85959 1.8.0\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**: 0.14.0\r\n- **GCC/Compiler version (if compiling from source)**: 5.4.0\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\nI am trying to segment images using Pascal VOC 2012. I converted indexed pngs to grayscale, replaced pixels with value 255 with 0 and written them to tfrecord. Then when reading image with tf.data.Dataset i want to resize all images to constant scale at min dim and then randomly crop to square. Problem is that when i am resizing label tensor with tf.image.resize_bicubic some values are negative but in input tensor threre is no negative values.\r\n\r\n**UPD**: Bicubc not only gives negative values but also changes it where it should not\r\nLook at the right image:\r\n![image](https://user-images.githubusercontent.com/13236173/41194731-12a93bc0-6c29-11e8-8793-2b40f7fa6e0d.png)\r\n\r\n\r\n### Source code / logs\r\nHere is run log:\r\n```\r\nuint8_label_after_decode[0]\r\nuint8_label_after_decode[0]\r\nuint8_label_after_decode[0]\r\nuint8_label_after_decode[0]\r\nuint8_label_after_resize[-2.43790507]\r\nuint8_label_after_resize[-0.208821028]\r\nuint8_label_after_resize[-3.43527746]\r\nuint8_label_after_resize[-2.6129365]\r\n2018-06-09 19:45:09.765736: W tensorflow/core/framework/op_kernel.cc:1318] OP_REQUIRES failed at sparse_xent_op.cc:90 : Invalid argument: Received a label value of -2 which is outside the valid range of [0, 21). \r\n```\r\n\r\n```\r\ndef resize_image_keep_aspect_ratio(image, max_height, max_width, use_min_ratio, use_nn_interpolation=False):\r\n    def compute_new_dims(height, width, max_height, max_width, use_min_ratio):\r\n        # If use_min_ratio is set to true than image will be resized to max of smaller dim\r\n        height_float = tf.cast(height, tf.float32)\r\n        width_float = tf.cast(width, tf.float32)\r\n        max_height_float = tf.cast(max_height, tf.float32)\r\n        max_width_float = tf.cast(max_width, tf.float32)\r\n\r\n        height_ratio = height_float / max_height_float\r\n        widht_ratio = width_float / max_width_float\r\n\r\n        if use_min_ratio:\r\n            ratio = tf.minimum(height_ratio, widht_ratio)\r\n        else:\r\n            ratio = tf.maximum(height_ratio, widht_ratio)\r\n\r\n        new_height = tf.cast(tf.floor(height_float / ratio), tf.int32)\r\n        new_width = tf.cast(tf.floor(width_float / ratio), tf.int32)\r\n\r\n        return (new_height, new_width)\r\n\r\n    shape = tf.shape(image)\r\n    height = shape[0]\r\n    width = shape[1]\r\n\r\n    new_height_and_width = compute_new_dims(height, width, max_height, max_width, use_min_ratio=use_min_ratio)\r\n\r\n    image = tf.expand_dims(image, 0)\r\n    if use_nn_interpolation:\r\n        image = tf.image.resize_nearest_neighbor(image, tf.stack(new_height_and_width), align_corners=True)\r\n    else:\r\n        image = tf.image.resize_bicubic(image, tf.stack(new_height_and_width), align_corners=True)\r\n    image = tf.squeeze(image, [0])\r\n    return image\r\n\r\n\r\n# Here I am decoding image in tf.data.Dataset\r\nlabel = tf.image.decode_image(example_parsed['label'], channels=1)\r\nlabel = tf.Print(label, [tf.reduce_min(label)], 'uint8_label_after_decode')\r\nlabel = tf.cast(label, tf.float32)\r\nlabel = resize_image_keep_aspect_ratio(label, image_size[0], image_size[1], use_min_ratio=True, \r\n  use_nn_interpolation=False)\r\nlabel = tf.Print(label, [tf.reduce_min(label)], 'uint8_label_after_resize')\r\nimage_and_label = tf.concat([image, label], axis=2)\r\ncropped_image_and_label = tf.random_crop(image_and_label, [image_size[0], image_size[1], 4])\r\nimage, label = tf.split(cropped_image_and_label, [3, 1], axis=2)\r\nimage = tf.cast(image, float_type) * (2.0 / 255.0) - 1.0\r\nlabel = tf.cast(label, tf.int64)\r\n```", "comments": ["Hi @Luonic -- I'm having trouble interpreting what exactly the problem is here. bicubic_resize would be expected to change the values in the input tensor, as the same image is represented in fewer pixels. Can you provide a minimal example, using just the resize_* method you think has a bug, to demonstrate the problem?", "@karmel when we resizing image that have no negative values we expect result resized image to not have them too because linear interpolation just interpolates values beetween two non-negative values in source tensor. In my example we see that after resize we have negative values in result tensor but in source tensor all values were positive.\r\nSo here is minimal example:\r\n```\r\nimport tensorflow as tf\r\n\r\nimage = tf.random_uniform((1, 512, 512, 1), minval=0, maxval=255, dtype=tf.float32)\r\nimage = tf.Print(image, [tf.reduce_min(image)], 'min of source image')\r\nimage = tf.image.resize_bicubic(image, [256, 256], align_corners=True)\r\nimage = tf.Print(image, [tf.reduce_min(image)], 'min of result image')\r\n\r\nsess = tf.Session()\r\nimage.eval(session=sess)\r\n```\r\n\r\nAnd output is:\r\n```\r\nmin of source image[9.11951065e-05]\r\nmin of result image[-47.5840836]\r\n```\r\nWhy do we have -47.5840836 in our resized image?\r\n", "@cwhipkey - any thoughts on whether this is an expected output for resize_bicubic?", "I'm not an expert, but I think that this can happen because of overshooting\nas described on the wikipedia page for bicubic interpolation:\nhttps://en.wikipedia.org/wiki/Bicubic_interpolation#Use_in_computer_graphics\n.\n\nOn Wed, Jun 27, 2018 at 2:56 PM Karmel Allison <notifications@github.com>\nwrote:\n\n> @cwhipkey <https://github.com/cwhipkey> - any thoughts on whether this is\n> an expected output for resize_bicubic?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/19880#issuecomment-400840875>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AQw4wamlUWlKViuLxhm8dDhVsTTzQf2Vks5uA_96gaJpZM4UhaSV>\n> .\n>\n", "@shlens -- any chance you have some insight on the expected output of bicubic interpolation in this case?", "I agree with @cwhipkey. This is potentially expected behavior with bicubic interpolation and a known limitation. This could be verified by running the same minimal test in OpenCV which has a well-tested version of bicubic interpolation and see if you observe the same result.", "Great-- @Luonic , have you checked the results with OpenCV?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!", "Hi, how do you fix this annoying problem? my image is between [0-255] (min 5, max 248), when interpole bicubic, it change between [no idea, to no idea] (and my min become -3 and max 260), \r\nit loose the relationship, this NOT happen if us NEAREST_NEIGHBOR"]}, {"number": 19879, "title": "tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM", "body": "I am not sure if my GPU is insufficient or not.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n    Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n    Windows 8.1\r\n- **TensorFlow installed from (source or binary)**:\r\n\r\n   binary\r\n\r\n- **TensorFlow version (use command below)**:\r\n     b'v1.8.0-0-g93bc2e2072' 1.8.0\r\n\r\n- **Python version**: \r\nPython 3.6.5\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n9.0 / **cudnn-9.0-windows7-x64-v7**\r\n\r\n\r\n- **GPU model and memory**:\r\nNVIDIA GT 640\r\nStandard Memory Config | 2048 MB\r\n-- | --\r\n\r\n\r\n\r\n- **Exact command to reproduce**:\r\n\r\nCode I am running is exactly https://github.com/mohanr/Machine-Learning/blob/master/Generative%20Adversarial%20Networks/gan.py\r\n\r\nBut I also add\r\n\r\nconfig = tf.ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.4\r\nsess = tf.Session(config=config)\r\n\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\n\r\nThe logs indicate that there isn't memory. But I couldn't describe it as I am not an expert.\r\n\r\n### Source code / logs\r\n2018-06-09 22:00:47.481495: I T:\\src\\github\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2018-06-09 22:00:47.666325: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1356] Found device 0 with properties: \r\nname: GeForce GT 640 major: 3 minor: 0 memoryClockRate(GHz): 0.797\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 4.00GiB freeMemory: 3.63GiB\r\n2018-06-09 22:00:47.666754: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1435] Adding visible gpu devices: 0\r\n2018-06-09 22:00:47.924601: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-06-09 22:00:47.924881: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:929]      0 \r\n2018-06-09 22:00:47.925054: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:942] 0:   N \r\n2018-06-09 22:00:47.925320: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1638 MB memory) -> physical GPU (device: 0, name: GeForce GT 640, pci bus id: 0000:01:00.0, compute capability: 3.0)\r\n(?, 256, 256, 3)\r\n2018-06-09 22:00:52.119015: W T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.17GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2018-06-09 22:00:52.780020: W T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.05GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2018-06-09 22:00:53.025879: W T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.32GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2018-06-09 22:01:01.698819: W T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 640.00MiB.  Current allocation summary follows.\r\n2018-06-09 22:01:01.700407: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:630] Bin (256): \tTotal Chunks: 63, Chunks in use: 63. 15.8KiB allocated for chunks. 15.8KiB in use in bin. 4.9KiB client-requested in use in bin.\r\n2018-06-09 22:01:01.702825: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:630] Bin (512): \tTotal Chunks: 13, Chunks in use: 13. 6.8KiB allocated for chunks. 6.8KiB in use in bin. 6.5KiB client-requested in use in bin.\r\n2018-06-09 22:01:01.704767: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:630] Bin (1024): \tTotal Chunks: 9, Chunks in use: 9. 9.3KiB allocated for chunks. 9.3KiB in use in bin. 9.0KiB client-requested in use in bin.\r\n2018-06-09 22:01:01.706630: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:630] Bin (2048): \tTotal Chunks: 4, Chunks in use: 4. 14.0KiB allocated for chunks. 14.0KiB in use in bin. 13.5KiB client-requested in use in bin.\r\n2018-06-09 22:01:01.708750: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:630] Bin (4096): \tTotal Chunks: 5, Chunks in use: 5. 20.0KiB allocated for chunks. 20.0KiB in use in bin. 20.0KiB client-requested in use in bin.\r\n2018-06-09 22:01:01.710645: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:630] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-06-09 22:01:01.712622: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:630] Bin (16384): \tTotal Chunks: 5, Chunks in use: 4. 120.0KiB allocated for chunks. 96.0KiB in use in bin. 96.0KiB client-requested in use in bin.\r\n2018-06-09 22:01:01.714509: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:630] Bin (32768): \tTotal Chunks: 1, Chunks in use: 0. 36.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-06-09 22:01:01.716503: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:630] Bin (65536): \tTotal Chunks: 8, Chunks in use: 8. 552.0KiB allocated for chunks. 552.0KiB in use in bin. 544.0KiB client-requested in use in bin.\r\n2018-06-09 22:01:01.718590: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:630] Bin (131072): \tTotal Chunks: 11, Chunks in use: 11. 1.38MiB allocated for chunks. 1.38MiB in use in bin. 1.38MiB client-requested in use in bin.\r\n2018-06-09 22:01:01.720586: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:630] Bin (262144): \tTotal Chunks: 1, Chunks in use: 0. 384.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-06-09 22:01:01.722504: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:630] Bin (524288): \tTotal Chunks: 4, Chunks in use: 4. 2.10MiB allocated for chunks. 2.10MiB in use in bin. 2.00MiB client-requested in use in bin.\r\n2018-06-09 22:01:01.724539: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:630] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-06-09 22:01:01.726418: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:630] Bin (2097152): \tTotal Chunks: 1, Chunks in use: 1. 2.50MiB allocated for chunks. 2.50MiB in use in bin. 2.50MiB client-requested in use in bin.\r\n2018-06-09 22:01:01.727636: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:630] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-06-09 22:01:01.728533: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:630] Bin (8388608): \tTotal Chunks: 3, Chunks in use: 3. 39.81MiB allocated for chunks. 39.81MiB in use in bin. 37.50MiB client-requested in use in bin.\r\n2018-06-09 22:01:01.729490: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:630] Bin (16777216): \tTotal Chunks: 2, Chunks in use: 1. 34.75MiB allocated for chunks. 16.00MiB in use in bin. 12.50MiB client-requested in use in bin.\r\n2018-06-09 22:01:01.730439: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:630] Bin (33554432): \tTotal Chunks: 1, Chunks in use: 0. 47.34MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-06-09 22:01:01.731351: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:630] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-06-09 22:01:01.732233: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:630] Bin (134217728): \tTotal Chunks: 1, Chunks in use: 0. 128.00MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-06-09 22:01:01.733148: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:630] Bin (268435456): \tTotal Chunks: 3, Chunks in use: 1. 1.25GiB allocated for chunks. 640.00MiB in use in bin. 640.00MiB client-requested in use in bin.\r\n2018-06-09 22:01:01.734096: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:646] Bin for 640.00MiB was 256.00MiB, Chunk State: \r\n2018-06-09 22:01:01.734682: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:652]   Size: 256.00MiB | Requested Size: 196.89MiB | in_use: 0\r\n2018-06-09 22:01:01.735323: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:652]   Size: 384.00MiB | Requested Size: 216.28MiB | in_use: 0, prev:   Size: 640.00MiB | Requested Size: 640.00MiB | in_use: 1\r\n2018-06-09 22:01:01.736201: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500C60000 of size 1280\r\n2018-06-09 22:01:01.736747: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500C60500 of size 256\r\n2018-06-09 22:01:01.737303: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500C60600 of size 256\r\n2018-06-09 22:01:01.737855: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500C60700 of size 256\r\n2018-06-09 22:01:01.738393: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500C60800 of size 256\r\n2018-06-09 22:01:01.738929: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500C60900 of size 256\r\n2018-06-09 22:01:01.739470: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500C60A00 of size 256\r\n2018-06-09 22:01:01.740032: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500C60B00 of size 3584\r\n2018-06-09 22:01:01.740592: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500C61900 of size 256\r\n2018-06-09 22:01:01.741145: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500C61A00 of size 256\r\n2018-06-09 22:01:01.741715: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500C61B00 of size 256\r\n2018-06-09 22:01:01.742269: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500C61C00 of size 73728\r\n2018-06-09 22:01:01.742820: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500C73C00 of size 256\r\n2018-06-09 22:01:01.743368: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500C73D00 of size 256\r\n2018-06-09 22:01:01.743919: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500C73E00 of size 1024\r\n2018-06-09 22:01:01.744454: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500C74200 of size 65536\r\n2018-06-09 22:01:01.745001: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500C84200 of size 256\r\n2018-06-09 22:01:01.745556: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500C84300 of size 256\r\n2018-06-09 22:01:01.746094: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500C84400 of size 256\r\n2018-06-09 22:01:01.746639: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500C84500 of size 1024\r\n2018-06-09 22:01:01.747178: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500C84900 of size 256\r\n2018-06-09 22:01:01.747734: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500C84A00 of size 256\r\n2018-06-09 22:01:01.748285: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500C84B00 of size 131072\r\n2018-06-09 22:01:01.748741: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500CA4B00 of size 131072\r\n2018-06-09 22:01:01.749387: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500CC4B00 of size 256\r\n2018-06-09 22:01:01.749938: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500CC4C00 of size 256\r\n2018-06-09 22:01:01.750481: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500CC4D00 of size 256\r\n2018-06-09 22:01:01.751026: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500CC4E00 of size 512\r\n2018-06-09 22:01:01.751579: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500CC5000 of size 512\r\n2018-06-09 22:01:01.752165: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500CC5200 of size 512\r\n2018-06-09 22:01:01.752704: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500CC5400 of size 256\r\n2018-06-09 22:01:01.753251: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500CC5500 of size 4096\r\n2018-06-09 22:01:01.753790: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500CC6500 of size 256\r\n2018-06-09 22:01:01.754337: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500CC6600 of size 256\r\n2018-06-09 22:01:01.754882: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500CC6700 of size 256\r\n2018-06-09 22:01:01.755435: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500CC6800 of size 512\r\n2018-06-09 22:01:01.755981: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500CC6A00 of size 256\r\n2018-06-09 22:01:01.756520: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500CC6B00 of size 627968\r\n2018-06-09 22:01:01.756996: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000500D60000 of size 16777216\r\n2018-06-09 22:01:01.757281: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D60000 of size 256\r\n2018-06-09 22:01:01.757550: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D60100 of size 256\r\n2018-06-09 22:01:01.757825: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D60200 of size 256\r\n2018-06-09 22:01:01.758105: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D60300 of size 24576\r\n2018-06-09 22:01:01.758347: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D66300 of size 256\r\n2018-06-09 22:01:01.758588: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D66400 of size 256\r\n2018-06-09 22:01:01.758818: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D66500 of size 256\r\n2018-06-09 22:01:01.759166: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D66600 of size 256\r\n2018-06-09 22:01:01.759406: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D66700 of size 256\r\n2018-06-09 22:01:01.759641: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D66800 of size 256\r\n2018-06-09 22:01:01.759915: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D66900 of size 256\r\n2018-06-09 22:01:01.760163: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D66A00 of size 256\r\n2018-06-09 22:01:01.760391: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D66B00 of size 3584\r\n2018-06-09 22:01:01.760623: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D67900 of size 3584\r\n2018-06-09 22:01:01.760884: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D68700 of size 1024\r\n2018-06-09 22:01:01.761132: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D68B00 of size 256\r\n2018-06-09 22:01:01.761369: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D68C00 of size 256\r\n2018-06-09 22:01:01.761603: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D68D00 of size 256\r\n2018-06-09 22:01:01.761841: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D68E00 of size 256\r\n2018-06-09 22:01:01.762122: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D68F00 of size 256\r\n2018-06-09 22:01:01.762356: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D69000 of size 256\r\n2018-06-09 22:01:01.762593: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D69100 of size 256\r\n2018-06-09 22:01:01.762829: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D69200 of size 256\r\n2018-06-09 22:01:01.763127: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D69300 of size 256\r\n2018-06-09 22:01:01.763366: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D69400 of size 256\r\n2018-06-09 22:01:01.763606: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D69500 of size 256\r\n2018-06-09 22:01:01.763859: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D69600 of size 256\r\n2018-06-09 22:01:01.764145: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D69700 of size 256\r\n2018-06-09 22:01:01.764386: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D69800 of size 73728\r\n2018-06-09 22:01:01.764625: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D7B800 of size 73728\r\n2018-06-09 22:01:01.764839: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D8D800 of size 73728\r\n2018-06-09 22:01:01.765172: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D9F800 of size 1024\r\n2018-06-09 22:01:01.765410: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501D9FC00 of size 1024\r\n2018-06-09 22:01:01.765655: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501DA0000 of size 1024\r\n2018-06-09 22:01:01.765943: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501DA0400 of size 65536\r\n2018-06-09 22:01:01.766192: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501DB0400 of size 65536\r\n2018-06-09 22:01:01.766427: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501DC0400 of size 4096\r\n2018-06-09 22:01:01.766663: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501DC1400 of size 24576\r\n2018-06-09 22:01:01.766950: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Free  at 0000000501DC7400 of size 36864\r\n2018-06-09 22:01:01.767188: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501DD0400 of size 256\r\n2018-06-09 22:01:01.767432: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501DD0500 of size 256\r\n2018-06-09 22:01:01.767668: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501DD0600 of size 256\r\n2018-06-09 22:01:01.767946: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501DD0700 of size 1024\r\n2018-06-09 22:01:01.768188: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501DD0B00 of size 1024\r\n2018-06-09 22:01:01.768426: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501DD0F00 of size 256\r\n2018-06-09 22:01:01.768672: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501DD1000 of size 768\r\n2018-06-09 22:01:01.768950: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501DD1300 of size 131072\r\n2018-06-09 22:01:01.769195: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501DF1300 of size 131072\r\n2018-06-09 22:01:01.769432: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501E11300 of size 131072\r\n2018-06-09 22:01:01.769674: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501E31300 of size 131072\r\n2018-06-09 22:01:01.769978: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501E51300 of size 131072\r\n2018-06-09 22:01:01.770220: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501E71300 of size 131072\r\n2018-06-09 22:01:01.770463: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000501E91300 of size 15527168\r\n2018-06-09 22:01:01.770708: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000502D60000 of size 131072\r\n2018-06-09 22:01:01.771008: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000502D80000 of size 131072\r\n2018-06-09 22:01:01.771255: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000502DA0000 of size 256\r\n2018-06-09 22:01:01.771500: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000502DA0100 of size 256\r\n2018-06-09 22:01:01.771740: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000502DA0200 of size 13107200\r\n2018-06-09 22:01:01.772027: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000503A20200 of size 256\r\n2018-06-09 22:01:01.772267: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000503A20300 of size 256\r\n2018-06-09 22:01:01.772505: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000503A20400 of size 256\r\n2018-06-09 22:01:01.772744: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000503A20500 of size 512\r\n2018-06-09 22:01:01.773014: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000503A20700 of size 512\r\n2018-06-09 22:01:01.773257: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000503A20900 of size 512\r\n2018-06-09 22:01:01.773491: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000503A20B00 of size 512\r\n2018-06-09 22:01:01.773722: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000503A20D00 of size 512\r\n2018-06-09 22:01:01.774009: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000503A20F00 of size 256\r\n2018-06-09 22:01:01.774190: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000503A21000 of size 256\r\n2018-06-09 22:01:01.774394: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000503A21100 of size 524288\r\n2018-06-09 22:01:01.774629: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Free  at 0000000503AA1100 of size 19656448\r\n2018-06-09 22:01:01.774861: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000504D60000 of size 256\r\n2018-06-09 22:01:01.775296: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000504D60100 of size 4096\r\n2018-06-09 22:01:01.775477: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000504D61100 of size 4096\r\n2018-06-09 22:01:01.775656: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000504D62100 of size 4096\r\n2018-06-09 22:01:01.775836: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000504D63100 of size 512\r\n2018-06-09 22:01:01.776253: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000504D63300 of size 512\r\n2018-06-09 22:01:01.776449: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000504D63500 of size 512\r\n2018-06-09 22:01:01.776642: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000504D63700 of size 524288\r\n2018-06-09 22:01:01.776839: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000504DE3700 of size 524288\r\n2018-06-09 22:01:01.777219: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000504E63700 of size 131072\r\n2018-06-09 22:01:01.777400: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Free  at 0000000504E83700 of size 393216\r\n2018-06-09 22:01:01.777581: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000504EE3700 of size 256\r\n2018-06-09 22:01:01.777759: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000504EE3800 of size 256\r\n2018-06-09 22:01:01.777977: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000504EE3900 of size 256\r\n2018-06-09 22:01:01.778177: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000504EE3A00 of size 24576\r\n2018-06-09 22:01:01.778396: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000504EE9A00 of size 24576\r\n2018-06-09 22:01:01.778615: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Free  at 0000000504EEFA00 of size 24576\r\n2018-06-09 22:01:01.778834: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000504EF5A00 of size 3584\r\n2018-06-09 22:01:01.779416: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000504EF6800 of size 73728\r\n2018-06-09 22:01:01.779665: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000504F08800 of size 13107200\r\n2018-06-09 22:01:01.779921: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000505B88800 of size 2621440\r\n2018-06-09 22:01:01.780190: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Free  at 0000000505E08800 of size 49641472\r\n2018-06-09 22:01:01.780438: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Free  at 0000000508F60000 of size 134217728\r\n2018-06-09 22:01:01.780678: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Free  at 0000000510F60000 of size 268435456\r\n2018-06-09 22:01:01.780961: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Chunk at 0000000521260000 of size 671088640\r\n2018-06-09 22:01:01.781212: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:665] Free  at 0000000549260000 of size 402653184\r\n2018-06-09 22:01:01.781460: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:671]      Summary of in-use Chunks by size: \r\n2018-06-09 22:01:01.781702: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:674] 63 Chunks of size 256 totalling 15.8KiB\r\n2018-06-09 22:01:01.781999: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:674] 12 Chunks of size 512 totalling 6.0KiB\r\n2018-06-09 22:01:01.782236: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:674] 1 Chunks of size 768 totalling 768B\r\n2018-06-09 22:01:01.782469: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:674] 8 Chunks of size 1024 totalling 8.0KiB\r\n2018-06-09 22:01:01.782715: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:674] 1 Chunks of size 1280 totalling 1.3KiB\r\n2018-06-09 22:01:01.782979: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:674] 4 Chunks of size 3584 totalling 14.0KiB\r\n2018-06-09 22:01:01.783221: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:674] 5 Chunks of size 4096 totalling 20.0KiB\r\n2018-06-09 22:01:01.783468: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:674] 4 Chunks of size 24576 totalling 96.0KiB\r\n2018-06-09 22:01:01.783714: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:674] 3 Chunks of size 65536 totalling 192.0KiB\r\n2018-06-09 22:01:01.784012: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:674] 5 Chunks of size 73728 totalling 360.0KiB\r\n2018-06-09 22:01:01.784259: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:674] 11 Chunks of size 131072 totalling 1.38MiB\r\n2018-06-09 22:01:01.784509: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:674] 3 Chunks of size 524288 totalling 1.50MiB\r\n2018-06-09 22:01:01.784748: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:674] 1 Chunks of size 627968 totalling 613.3KiB\r\n2018-06-09 22:01:01.785036: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:674] 1 Chunks of size 2621440 totalling 2.50MiB\r\n2018-06-09 22:01:01.785281: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:674] 2 Chunks of size 13107200 totalling 25.00MiB\r\n2018-06-09 22:01:01.785523: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:674] 1 Chunks of size 15527168 totalling 14.81MiB\r\n2018-06-09 22:01:01.785770: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:674] 1 Chunks of size 16777216 totalling 16.00MiB\r\n2018-06-09 22:01:01.786086: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:674] 1 Chunks of size 671088640 totalling 640.00MiB\r\n2018-06-09 22:01:01.786348: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:678] Sum Total of in-use chunks: 702.48MiB\r\n2018-06-09 22:01:01.786587: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:680] Stats: \r\nLimit:                  1717986918\r\nInUse:                   736602368\r\nMaxInUse:               1369154816\r\nNumAllocs:                     242\r\nMaxAllocSize:            671088640\r\n\r\n2018-06-09 22:01:01.787109: W T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:279] ******___________________________*******************************************________________________\r\n2018-06-09 22:01:01.787472: W T:\\src\\github\\tensorflow\\tensorflow\\core\\framework\\op_kernel.cc:1318] OP_REQUIRES failed at conv_grad_input_ops.cc:924 : Resource exhausted: OOM when allocating tensor with shape[40,64,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\nTraceback (most recent call last):\r\n  File \"C:\\Anaconda3\\envs\\ame\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1322, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\Anaconda3\\envs\\ame\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1307, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"C:\\Anaconda3\\envs\\ame\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1409, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[40,64,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[Node: generator/conv2d_transpose/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 2, 2], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](generator/conv2d_transpose/conv2d_transpose-0-VecPermuteNHWCToNCHW-LayoutOptimizer/_51, generator/conv2d_transpose/kernel/read, generator/conv2d_transpose/conv2d_transpose-2-TransposeNHWCToNCHW-LayoutOptimizer)]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\t [[Node: Mean_1/_123 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_357_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:/Users/spatial/PycharmProjects/TensorFlow/gan.py\", line 166, in <module>\r\n    main()\r\n  File \"C:/Users/spatial/PycharmProjects/TensorFlow/gan.py\", line 162, in main\r\n    train()\r\n  File \"C:/Users/spatial/PycharmProjects/TensorFlow/gan.py\", line 148, in train\r\n    summary,_ = sess.run([merge,D_optimizer], feed_dict={Z : samplefromuniformdistribution(20,100), X: X_batch, keep_prob: keep_prob_value, is_training:True})\r\n  File \"C:\\Anaconda3\\envs\\ame\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 900, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\Anaconda3\\envs\\ame\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1135, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\Anaconda3\\envs\\ame\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1316, in _do_run\r\n    run_metadata)\r\n  File \"C:\\Anaconda3\\envs\\ame\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1335, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[40,64,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[Node: generator/conv2d_transpose/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 2, 2], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](generator/conv2d_transpose/conv2d_transpose-0-VecPermuteNHWCToNCHW-LayoutOptimizer/_51, generator/conv2d_transpose/kernel/read, generator/conv2d_transpose/conv2d_transpose-2-TransposeNHWCToNCHW-LayoutOptimizer)]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\t [[Node: Mean_1/_123 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_357_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\n", "comments": ["Nagging Assignee @aselle: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @aselle: It has been 31 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "A 2GB card is probably not big enough. Try something like a GTX 1080."]}, {"number": 19878, "title": "Require same shape for `x` and `y` in shape function of `ApproximateEqual`", "body": "In the kernel implementation of `ApproximateEqual` the shape of inputs\r\n`x` and `y` should be the same. Though in the shape function of `ApproximateEqual`\r\nthere was no such validation. This fix adds the shape validation in the\r\nshape function to make sure `x` and `y` are of the same shape, if they are known.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Could we have a small test for that?", "Thanks @drpngx for the review. The PR has been updated."]}, {"number": 19877, "title": "Incompatibility between Estimator evaluation and BestExporter in 1.9.0-rc0 (cherry-pick request)", "body": "### System information\r\n- **Have I written custom code**: Yes\r\n- **OS Platform and Distribution**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from**: binary\r\n- **TensorFlow version**: `1.9.0-rc0`\r\n- **Python version**:  2.7\r\n- **Bazel version**: N/A\r\n- **GCC/Compiler version**: N/A\r\n- **CUDA/cuDNN version**: 9.0\r\n- **GPU model and memory**: GTX 1060 (6GB)\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\nSorry if that is already planned, but this fix https://github.com/tensorflow/tensorflow/commit/ece5f512538f66b69db52b8a5b6f9669ae10a3d9 should be part of the 1.9 release for the `tf.estimator.BestExporter` to work. The incompatibility was introduced by https://github.com/tensorflow/tensorflow/commit/b183563d0bfed9fce2b623b3bff3fa3bdeccad54 (released in `1.9.0-rc0`) which writes the checkpoint path in the event file, a case not handled by the `BestExporter` that always fails with error below.\r\n\r\n### Source code / logs\r\n```text\r\n  File \"<python>/local/lib/python2.7/site-packages/tensorflow/python/estimator/exporter.py\", line 156, in _loss_smaller\r\n    'current_eval_result cannot be empty or no loss is found in it.')\r\nValueError: current_eval_result cannot be empty or no loss is found in it.\r\n```\r\n\r\nThanks!", "comments": []}, {"number": 19876, "title": "tf.feature_column.indicator_column lack of hash_bucket conflict resolver", "body": "Here is my code:\r\n\r\n```\r\n\r\nimport tensorflow as tf\r\n\r\nfeatures = {'color': [['R','A'], ['A','G'], ['A','G'], ['G','B'],['B','R']],\r\n            'weight': [[1.0,2.0], [0.1,4.0], [5.0,1.0], [8.0,7.0],[3.0,2.0]]}\r\n\r\ncolor_feature = tf.feature_column.categorical_column_with_hash_bucket(\r\n                key = \"color\",\r\n                hash_bucket_size = 10,\r\n                dtype=tf.string)\r\n\r\ncolumn = tf.feature_column.weighted_categorical_column(color_feature, 'weight',dtype = tf.float32)\r\n\r\nindicator = tf.feature_column.indicator_column(column)\r\ntensor = tf.feature_column.input_layer(features, [indicator])\r\n\r\nwith tf.Session() as session:\r\n    session.run(tf.global_variables_initializer())\r\n    session.run(tf.tables_initializer())\r\n    print(session.run([tensor]))\r\n\r\n```\r\n\r\nthen, got the error as follow:\r\n\r\n\r\n\r\n```\r\nD:\\ProgramData\\Anaconda3\\python.exe E:/wnd_test/test.py\r\nD:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\n2018-06-09 20:54:36.683625: I T:\\src\\github\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2018-06-09 20:54:36.699225: W T:\\src\\github\\tensorflow\\tensorflow\\core\\framework\\op_kernel.cc:1318] OP_REQUIRES failed at sparse_to_dense_op.cc:126 : Invalid argument: indices[9] = [4,8] is repeated\r\n2018-06-09 20:54:36.699225: W T:\\src\\github\\tensorflow\\tensorflow\\core\\framework\\op_kernel.cc:1318] OP_REQUIRES failed at sparse_to_dense_op.cc:126 : Invalid argument: indices[9] = [4,8] is repeated\r\nTraceback (most recent call last):\r\n  File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1322, in _do_call\r\n    return fn(*args)\r\n  File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1307, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1409, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: indices[9] = [4,8] is repeated\r\n\t [[Node: input_layer/color_weighted_by_weight_indicator/SparseToDense = SparseToDense[T=DT_FLOAT, Tindices=DT_INT64, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](input_layer/color_weighted_by_weight_indicator/SparseSlice, input_layer/color_weighted_by_weight_indicator/SparseSlice:2, input_layer/color_weighted_by_weight_indicator/SparseSlice:1, input_layer/color_weighted_by_weight_indicator/SparseToDense/default_value)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"E:/wnd_test/test.py\", line 55, in <module>\r\n    print(session.run([tensor]))\r\n  File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 900, in run\r\n    run_metadata_ptr)\r\n  File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1135, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1316, in _do_run\r\n    run_metadata)\r\n  File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1335, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: indices[9] = [4,8] is repeated\r\n\t [[Node: input_layer/color_weighted_by_weight_indicator/SparseToDense = SparseToDense[T=DT_FLOAT, Tindices=DT_INT64, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](input_layer/color_weighted_by_weight_indicator/SparseSlice, input_layer/color_weighted_by_weight_indicator/SparseSlice:2, input_layer/color_weighted_by_weight_indicator/SparseSlice:1, input_layer/color_weighted_by_weight_indicator/SparseToDense/default_value)]]\r\n\r\nCaused by op 'input_layer/color_weighted_by_weight_indicator/SparseToDense', defined at:\r\n  File \"E:/wnd_test/test.py\", line 50, in <module>\r\n    tensor = tf.feature_column.input_layer(features, [indicator])\r\n  File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\", line 277, in input_layer\r\n    trainable, cols_to_vars)\r\n  File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\", line 202, in _internal_input_layer\r\n    trainable=trainable)\r\n  File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\", line 3302, in _get_dense_tensor\r\n    return inputs.get(self)\r\n  File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\", line 2100, in get\r\n    transformed = column._transform_feature(self)  # pylint: disable=protected-access\r\n  File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\", line 3244, in _transform_feature\r\n    return sparse_ops.sparse_tensor_to_dense(weighted_column)\r\n  File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\sparse_ops.py\", line 1011, in sparse_tensor_to_dense\r\n    name=name)\r\n  File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\sparse_ops.py\", line 791, in sparse_to_dense\r\n    name=name)\r\n  File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_sparse_ops.py\", line 3268, in sparse_to_dense\r\n    name=name)\r\n  File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\r\n    op_def=op_def)\r\n  File \"D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): indices[9] = [4,8] is repeated\r\n\t [[Node: input_layer/color_weighted_by_weight_indicator/SparseToDense = SparseToDense[T=DT_FLOAT, Tindices=DT_INT64, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](input_layer/color_weighted_by_weight_indicator/SparseSlice, input_layer/color_weighted_by_weight_indicator/SparseSlice:2, input_layer/color_weighted_by_weight_indicator/SparseSlice:1, input_layer/color_weighted_by_weight_indicator/SparseToDense/default_value)]]\r\n\r\n\r\nProcess finished with exit code 1\r\n\r\n```\r\n\r\n\r\n\r\nThe ```InvalidArgumentError``` is caused by the fact that feature \"B\" and feature  \"R\" are hashed into the same hash_bucket.  \r\nIt'll be great if a ```combiner``` argument (as in ```tf.feature_column.embedding_column```) can be implemented in the ```tf.feature_column.indicator_column``` funciton.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "System information:\r\n\u00b7 Have I written custom code: No\r\n\u00b7 OS Platform and Distribution: Win7-x64\r\n\u00b7 TensorFlow installed from: pip install tensorflow\r\n\u00b7 TensorFlow version: 1.5.0\r\n\u00b7 Bazel version: No\r\n\u00b7 CUDA/cuDNN version: No\r\n\u00b7 GPU model and memory: No\r\n. Exact command to reproduce: python test.py", "Nagging Assignee @rohan100jain: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 19875, "title": "stats_calculator.cc:185:13: error: no member named 'emplace' ", "body": "### System information\r\nDarwin newbmac753702.local 17.4.0 Darwin Kernel Version 17.4.0: Sun Dec 17 09:19:54 PST 2017; root:xnu-4570.41.2~1/RELEASE_X86_64 x86_64\r\nMac OS X 10.13.3\r\n\r\n   ANDROID_BUILD_TOOLS_VERSION=27.0.3 \\\r\n    ANDROID_NDK_API_LEVEL=15 \\\r\n    ANDROID_SDK_API_LEVEL=27 \\\r\n    PYTHON_BIN_PATH=/Users/aruiz/miniconda3/bin/python \\\r\n    PYTHON_LIB_PATH=/Users/aruiz/miniconda3/lib/python3.6/site-packages \\\r\n\r\nHi. I am trying to build an .apk following the steps in the android samples readme\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/README.md however when running\r\nbazel build -c opt //tensorflow/examples/android:tensorflow_demo \r\nthe following errors are thrown.\r\n\r\n### Source code / logs\r\ntensorflow/core/util/stats_calculator.cc:142:24: warning: range-based for loop is a C++11 extension [-Wc++11-extensions]\r\n  for (const auto& det : details_) {\r\n                       ^\r\ntensorflow/core/util/stats_calculator.cc:181:72: error: a space is required between consecutive right angle brackets (use '> >')\r\n  std::priority_queue<std::pair<int64_t, std::pair<std::string, int64_t>>>\r\n                                                                       ^~\r\n                                                                       > > \r\ntensorflow/core/util/stats_calculator.cc:183:14: warning: 'auto' type specifier is a C++11 extension [-Wc++11-extensions]\r\n  for (const auto& node_type : node_type_map_time) {\r\n             ^\r\ntensorflow/core/util/stats_calculator.cc:183:30: warning: range-based for loop is a C++11 extension [-Wc++11-extensions]\r\n  for (const auto& node_type : node_type_map_time) {\r\n                             ^\r\ntensorflow/core/util/stats_calculator.cc:185:13: error: no member named 'emplace' in 'std::priority_queue<std::pair<long long, std::pair<std::basic_string<char>, long long> >, std::vector<std::pair<long long, std::pair<std::basic_string<char>, long long> >, std::allocator<std::pair<long long, std::pair<std::basic_string<char>, long long> > > >, std::less<std::pair<long long, std::pair<std::basic_string<char>, long long> > > >'\r\n    timings.emplace(node_type.second,\r\n    ~~~~~~~ ^\r\ntensorflow/core/util/stats_calculator.cc:200:5: warning: 'auto' type specifier is a C++11 extension [-Wc++11-extensions]\r\n    auto entry = timings.top();\r\n    ^\r\n\r\nI am able to solve the issue with the  > > spaces but not the emplace not found. Any ideas?\r\n\r\nThanks a lot", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It looks like you have an old compiler that doesn't support cxx11 properly.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 19874, "title": "why set TF_BUILD_BAZEL_CLEAN=1 in ci_parameterized_build.sh", "body": "Hi, \r\n\r\nI found TF_BUILD_BAZEL_CLEAN is always set to 1 in ci_parameterized_build.sh\r\nhttps://github.com/tensorflow/tensorflow/blob/a6a265b61a9ad9510f45cf4c9032778bf2e042b9/tensorflow/tools/ci_build/ci_parameterized_build.sh#L99\r\n\r\nThis was introduced about 11 months ago.\r\nThe comment says this is temporary and will be removed later.\r\n\r\nSo is that still required?\r\nThanks.\r\n\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Yeah, it's not needed anymore. Sent a change internally to delete it.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are not using ci_parameterized_build.sh internally anymore.\r\nSo that script is rotting, with such pieces of code accumulating in it.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "This is now fixed."]}, {"number": 19873, "title": "Tensorflow Testing Problem", "body": "Hi,\r\nI am working on Tensorflow with Python. I have a new idea about the pooling method. Currently there are two pooling methods  (max-pooling, avg-pooling). I want to do some experiment by some new idea about pooling method. \r\nBut for that i need to find the current pooling functions. But unfortunately i could not find that. Can anyone please help me to do this experiment and help me to find the exact flow of pooling because i am not so much fluent to Python.\r\n\r\n Thanks.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "@poxvoculi Hi\r\nI am working on Tensorflow with Python. I have a new idea about the pooling method. Currently there are two pooling methods  (max-pooling, avg-pooling). I want to do some experiment by some new idea about pooling method. \r\nBut for that i need to find the current pooling functions. But unfortunately i could not find that. Can anyone please help me to do this experiment and help me to find the exact flow of pooling because i am not so much fluent to Python.\r\n\r\n Thanks.", "@tensorflowbutler ,  I don't know where to fill the fields you asked. So I am providing you information about these fields here:\r\nHave I written custom code:    yes\r\nOS Platform and Distribution:   Windows 10\r\nTensorFlow installed from:      using pip\r\nTensorFlow version:    1.7.0\r\nBazel version:   N/A\r\nCUDA/cuDNN version:   8.0\r\nGPU model and memory:     memory 24 GB\r\nExact command to reproduce  N/A", "@tensorflowbutler \r\nPlease help to implement my idea about pooling.\r\nRegards", "The pooling op source is in \r\n[pooling_ops_common.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/pooling_ops_common.cc)\r\n\r\nand several similar files.  Look in core/kernels/* for anything with \"pooling\" in the name.\r\n\r\nIn the future, this sort of question is better asked on StackOverflow.  This forum is primarily for bug reports.\r\n"]}, {"number": 19872, "title": "Strange TF runtime error", "body": "ignore this issue", "comments": []}, {"number": 19871, "title": "Dynamic ops", "body": "With this PR, we introduce dynamically generated TRTEngines, that is TRT Engine construction time is postponed to execution time to support graphs where shape inference fails. ", "comments": ["Is that related or flaky?\r\n\r\n```\r\n147/375 Test #144: T:/src/github/tensorflow/tensorflow/python/kernel_tests/fifo_queue_test.py ..............................................***Failed   24.19 sec\r\n......................................................................FF.........\r\n======================================================================\r\nFAIL: testResetOfBlockingOperation (__main__.FIFOQueueTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"T:/src/github/tensorflow/tensorflow/python/kernel_tests/fifo_queue_test.py\", line 1299, in testResetOfBlockingOperation\r\n    t.join()\r\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 1032, in join\r\n    self._testcase.fail(\"Error in checkedThread: %s\" % str(self._exception))\r\nAssertionError: Error in checkedThread: Exception of type <class 'tensorflow.python.framework.errors_impl.CancelledError'>: Session has been closed.\r\n======================================================================\r\nFAIL: testResetOfBlockingOperation (__main__.FIFOQueueTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 738, in tearDown\r\n    thread.check_termination()\r\n  File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\test_util.py\", line 1065, in check_termination\r\n    self._testcase.fail(\"A checked thread was not joined.\")\r\nAssertionError: A checked thread was not joined.\r\n----------------------------------------------------------------------\r\n```", "@drpngx it is very unlikely the error is because of this PR. This module is disabled on Windows builds.", "Thanks for checking! Let's see what @aaroey has to say.", "@aaroey I am getting issues with model tests but these seem to be related with current state of the master. FATALs are happening during execution of native graphs. Our tests pass fine."]}, {"number": 19870, "title": "Fix logging issue in remapper.cc and Linking issue with scoped_allocator_optimizer", "body": "This PR replaces std::cout with VLOG(1) in remapper.cc and removes scoped_allocator_ops_op_lib dependency from ScopedAllocator. This dependency is already satisfied through other libraries in core and causes a fatal for libraries that uses meta_optimizer due to double registration of _ScopedAllocator op due to double inclusion of static objects.", "comments": []}, {"number": 19869, "title": "[Intel MKL] Remove use of absl::string_view", "body": "Reverting 4a1889c0da16132da78805c3ea6790b18efe8f6d\r\n\r\n\"absl is not yet ready for use by open source TensorFlow. :-(\"\r\n\r\nSee https://github.com/tensorflow/tensorflow/commit/b33ba9a8e7e20e4b2378937204fe74af69982906#diff-9084ba4c479fbfe6d4994438fad11d47\r\n\r\n@tatianashp Can you look at this? The absl change to mkl_util.h broke our MKL builds.", "comments": ["There's still a `tensorflow::StringPiece`, could we maybe use that?", "@drpngx Done.", "Hmm not sure where this came from but `GetKey()` should return a const string ref, not a copy of the string. Maybe some other PR.", "@gzmkl FYI"]}, {"number": 19868, "title": "tflite tensorflow/contrib/lite/examples/minimal/minimal.cc compilation error  ", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: tflite example \r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:MacOS High Serria (10.13.3)\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**:1.5.0\r\n- **Python version**: 3.6.5\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:clang-900.0.39.2 \r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:g++ --std=c++11 -Itensorflow/contrib/lite -I. tensorflow/contrib/lite/examples/minimal/minimal.cc -Lbazel-bin/tensorflow/contrib/lite -ltflite\r\n\r\n\r\nTrying to compile minimal.cc in tflite examples, Added the following lines in tensorflow/contrib/lite/BUILD \r\n\r\n    cc_binary( \r\n       name = \"libtflite.so\",\r\n       deps = [\":framework\"],\r\n       linkshared=1\r\n    )\r\nthen made a shared library with ```bazel build //tensorflow/contrib/lite:framework```\r\n\r\nand compiled tensorflow/contrib/lite/examples/minimal/minimal.cc  with the command\r\n```g++ --std=c++11 -Itensorflow/contrib/lite -I. tensorflow/contrib/lite/examples/minimal/minimal.cc -Lbazel-bin/tensorflow/contrib/lite -ltflite```\r\n\r\nbut the compilation failed, it gives following errors.\r\n\r\n``` In file included from tensorflow/contrib/lite/examples/minimal/minimal.cc:15:\r\nIn file included from ./tensorflow/contrib/lite/model.h:37:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/memory:640:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/cstring:61:\r\nIn file included from tensorflow/contrib/lite/string.h:19:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/string:470:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/string_view:171:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/__string:56:\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:1722:9: error: no\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0member named 'memmove' in namespace 'std::__1'; did you mean 'wmemmove'?\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0_VSTD::memmove(__result, __first, __n * sizeof(_Up));\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^~~~~~~\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/__config:392:15: note: \r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0expanded from macro '_VSTD'\r\n#define _VSTD std::_LIBCPP_NAMESPACE\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^\r\n/usr/include/wchar.h:153:10: note: 'wmemmove' declared here\r\nwchar_t *wmemmove(wchar_t *, const wchar_t *, size_t);\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^\r\nIn file included from tensorflow/contrib/lite/examples/minimal/minimal.cc:15:\r\nIn file included from ./tensorflow/contrib/lite/model.h:37:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/memory:640:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/cstring:61:\r\nIn file included from tensorflow/contrib/lite/string.h:19:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/string:470:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/string_view:171:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/__string:56:\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:1760:9: error: no\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0member named 'memmove' in namespace 'std::__1'; did you mean 'wmemmove'?\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0_VSTD::memmove(__result, __first, __n * sizeof(_Up));\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^~~~~~~\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/__config:392:15: note: \r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0expanded from macro '_VSTD'\r\n#define _VSTD std::_LIBCPP_NAMESPACE\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^\r\n/usr/include/wchar.h:153:10: note: 'wmemmove' declared here\r\nwchar_t *wmemmove(wchar_t *, const wchar_t *, size_t);\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^\r\nIn file included from tensorflow/contrib/lite/examples/minimal/minimal.cc:15:\r\nIn file included from ./tensorflow/contrib/lite/model.h:37:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/memory:640:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/cstring:61:\r\nIn file included from tensorflow/contrib/lite/string.h:19:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/string:470:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/string_view:171:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/__string:56:\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:1861:9: error: no\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0member named 'memmove' in namespace 'std::__1'; did you mean 'wmemmove'?\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0_VSTD::memmove(__result, __first, __n * sizeof(_Up));\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^~~~~~~\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/__config:392:15: note: \r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0expanded from macro '_VSTD'\r\n#define _VSTD std::_LIBCPP_NAMESPACE\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^\r\n/usr/include/wchar.h:153:10: note: 'wmemmove' declared here\r\nwchar_t *wmemmove(wchar_t *, const wchar_t *, size_t);\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^\r\nIn file included from tensorflow/contrib/lite/examples/minimal/minimal.cc:15:\r\nIn file included from ./tensorflow/contrib/lite/model.h:37:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/memory:640:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/cstring:61:\r\nIn file included from tensorflow/contrib/lite/string.h:19:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/string:470:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/string_view:171:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/__string:56:\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:1899:9: error: no\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0member named 'memmove' in namespace 'std::__1'; did you mean 'wmemmove'?\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0_VSTD::memmove(__result, __first, __n * sizeof(_Up));\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^~~~~~~\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/__config:392:15: note: \r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0expanded from macro '_VSTD'\r\n#define _VSTD std::_LIBCPP_NAMESPACE\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^\r\n/usr/include/wchar.h:153:10: note: 'wmemmove' declared here\r\nwchar_t *wmemmove(wchar_t *, const wchar_t *, size_t);\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^\r\nIn file included from tensorflow/contrib/lite/examples/minimal/minimal.cc:15:\r\nIn file included from ./tensorflow/contrib/lite/model.h:37:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/memory:640:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/cstring:61:\r\nIn file included from tensorflow/contrib/lite/string.h:19:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/string:470:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/string_view:171:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/__string:56:\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:2020:9: error: no\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0member named 'memset' in namespace 'std::__1'; did you mean 'wmemset'?\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0_VSTD::memset(__first, (unsigned char)__value_, (size_t)(__n));\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^~~~~~~\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/__config:392:15: note: \r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0expanded from macro '_VSTD'\r\n#define _VSTD std::_LIBCPP_NAMESPACE\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^\r\n/usr/include/wchar.h:154:10: note: 'wmemset' declared here\r\nwchar_t *wmemset(wchar_t *, wchar_t, size_t);\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^\r\nIn file included from tensorflow/contrib/lite/examples/minimal/minimal.cc:15:\r\nIn file included from ./tensorflow/contrib/lite/model.h:37:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/memory:640:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/cstring:61:\r\nIn file included from tensorflow/contrib/lite/string.h:19:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/string:470:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/string_view:171:\r\nIn file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/__string:56:\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3343:9: error: \r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0unknown type name '__destruct_n'\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0__destruct_n __d(0);\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3344:9: error: \r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0use of undeclared identifier 'unique_ptr'\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0unique_ptr<value_type, __destruct_n&> __h(__p.first, __d);\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3344:20: error: \r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0unexpected type name 'value_type': expected expression\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0unique_ptr<value_type, __destruct_n&> __h(__p.first, __d);\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3344:32: error: \r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0use of undeclared identifier '__destruct_n'\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0unique_ptr<value_type, __destruct_n&> __h(__p.first, __d);\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3344:45: error: \r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0expected expression\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0unique_ptr<value_type, __destruct_n&> __h(__p.first, __d);\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3410:71: error: \r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0no type named 'return_temporary_buffer' in namespace 'std::__1'; did you mean '__return_temporary_buffer'?\r\n\u00a0\u00a0\u00a0\u00a0_LIBCPP_INLINE_VISIBILITY void operator()(_Tp* __p) const {_VSTD::return_temporary_buffer(__p);}\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0~~~~~~~^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3407:8: note: \r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0'__return_temporary_buffer' declared here\r\nstruct __return_temporary_buffer\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3410:95: error: \r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0redefinition of '__p'\r\n\u00a0\u00a0\u00a0\u00a0_LIBCPP_INLINE_VISIBILITY void operator()(_Tp* __p) const {_VSTD::return_temporary_buffer(__p);}\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3410:52: note: \r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0previous definition is here\r\n\u00a0\u00a0\u00a0\u00a0_LIBCPP_INLINE_VISIBILITY void operator()(_Tp* __p) const {_VSTD::return_temporary_buffer(__p);}\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3434:5: error: \r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0use of undeclared identifier 'unique_ptr'\r\n\u00a0\u00a0\u00a0\u00a0unique_ptr<value_type, __return_temporary_buffer> __h;\r\n\u00a0\u00a0\u00a0\u00a0^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3434:16: error: \r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0unexpected type name 'value_type': expected expression\r\n\u00a0\u00a0\u00a0\u00a0unique_ptr<value_type, __return_temporary_buffer> __h;\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3437:22: error: \r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0no member named 'get_temporary_buffer' in namespace 'std::__1'\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0__p = _VSTD::get_temporary_buffer<value_type>(__len);\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0~~~~~~~^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3437:43: error: \r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0unexpected type name 'value_type': expected expression\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0__p = _VSTD::get_temporary_buffer<value_type>(__len);\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3438:9: error: \r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0use of undeclared identifier '__h'; did you mean '__p'?\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0__h.reset(__p.first);\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3433:34: note: \r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0'__p' declared here\r\n\u00a0\u00a0\u00a0\u00a0pair<value_type*, ptrdiff_t> __p(0, 0);\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3473:9: error: \r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0unknown type name '__destruct_n'\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0__destruct_n __d(0);\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3474:9: error: \r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0use of undeclared identifier 'unique_ptr'\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0unique_ptr<value_type, __destruct_n&> __h(__p.first, __d);\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0^\r\nfatal error: too many errors emitted, stopping now [-ferror-limit=]\r\n20 errors generated.  </details> ```\r\n", "comments": ["\r\na minimal `BUILD` for this one is something like below. Note that `lite:framework` is not enough\r\n\r\n```\r\nload(\"//tensorflow:tensorflow.bzl\", \"tf_cc_binary\")\r\n\r\ntf_cc_binary(\r\n    name = \"minimal\",\r\n    srcs = [\r\n        \"minimal.cc\",\r\n    ],\r\n    deps = [\r\n        \"//tensorflow/contrib/lite:framework\",\r\n        \"//tensorflow/contrib/lite/kernels:builtin_ops\",\r\n    ],\r\n)\r\n```", "Hi @freedomtan, \r\nI added build file to tensorflow/contrib/lite/examples/minimal, then build with\r\n```bazel build //tensorflow/contrib/lite/examples/minimal:minimal``` command but bazel also builds core, stream_excecutors ( these are not the part of tensorflow lite )\r\n\r\nwhen I try to compile its shows same errors. I think these errors are because of apple's clang which is slightly different from gcc.\r\n\r\n", "hmm, I don't have such problem on High Sierra with latest Xcode 9 (9.4, 9F1027a). I guess it's not the problem of Xcode or the clang came with Xcode.", "Nagging Assignee @petewarden: It has been 22 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "How would one compile this from a standalone toolchain?\r\n\r\nI compile libtensorflow.so with \r\n\r\n```\r\ncc_binary(\r\n    name = \"libtensorflowlite.so\",\r\n    linkopts=[\r\n        \"-shared\",\r\n        \"-Wl,-soname=libtensorflowlite.so\",\r\n    ],  \r\n    linkshared = 1,\r\n    copts = tflite_copts(),\r\n    deps = [ \r\n        \":framework\",\r\n        \"//tensorflow/lite/kernels:builtin_ops\",\r\n    ],  \r\n)\r\n```\r\n\r\nand call it like \r\n```\r\nbazel build //tensorflow/contrib/lite:libtensorflowLite.so --crosstool_top=//external:android/crosstool --cpu=arm64-v8a --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --cxxopt=\"-std=c++11\"\r\n```\r\n\r\nAfter compiling flatbuffers I try and compile minimal.cc like\r\n```\r\nandroid-toolchain/bin/clang++  -std=c++11 -Igit/tensorflow-android -Igit/flatbuffers/include -Lgit/tensorflow-android -Lgit/flatbuffers/build minimal.cc -ltensorflowlite -lflatbuffers\r\n```\r\n\r\nBut get an error \r\n```\r\nundefined reference to 'tflite::InterpreterBuilder::operator()(std::__ndk1::unique_ptr<tflite::Interpreter, std::__ndk1::default_delete<tflite::Interpreter> >*)'\r\n``` \r\nFails with both ndk15c and 16b\r\n\r\n"]}, {"number": 19867, "title": "1.9-rc0 cherry-pick request: Keras symbol visibility, and `Dataset` evaluation fixes.", "body": "The first two commits fix visibility for various Keras symbols.\r\nThe last one fixes Dataset-evaluation in eager mode (was only running 1 step regardless of steps-argument).\r\n\r\ncl/199161696\r\ncl/199198086\r\ncl/199645638\r\n", "comments": ["This is not in master, better @yifeif handle this.", "> This is not in master, better @yifeif handle this.\r\n\r\nI made this with the cherry-picker tool, will that let you cherry-pick something that isn't in master?\r\n\r\nAll three of the source commits are in master now:\r\n\r\ncl/199161696 -->  https://github.com/tensorflow/tensorflow/commit/5f315a292a65bd898a736cd305152f348846718a\r\ncl/199198086 --> https://github.com/tensorflow/tensorflow/commit/6b2a088fb263af2428ca672a62088646a7f54219\r\ncl/199645638 --> https://github.com/tensorflow/tensorflow/commit/086d96aea3d6b3272b2746359e13f4156072ff8b", "No, the cherrypicker.py util script should only be able to cherrypick commits from github master.", "Thanks Mike."]}, {"number": 19866, "title": "Update RELEASE.md (r1.9) for tfdbg and XLA", "body": "", "comments": ["@av8ramit I removed the item on XLA. There seems to be no update for XLA in this release. It's better to not have an empty item."]}, {"number": 19865, "title": "Fixing copy_binary script.", "body": "Allowing for copy_binary to have the minor version to have double digits.", "comments": ["```\r\nFAIL: Found 1 non-whitelited pylint errors:\r\ntensorflow/tools/ci_build/copy_binary.py:36: [C0330(bad-continuation), ] Wrong continued indentation (remove 1 space).\r\n```"]}, {"number": 19864, "title": "No dtype for array of arrays into tf.keras.Input", "body": "I would like to input an array of arrays into `tf.keras.Input()`, however that requires me to specify a dtype to ensure it doesn't default to expecting a float. However it doesn't appear as though there is a viable dtype for an array of arrays. For an array by itself, `dtype=float32_ref` appears to work, however this does not work for an array of arrays. `tf.keras.backend.dtype()` throws an error if I attempt to put in an array to see it's type as well. Does this dtype not exist?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Have I written custom code: Yes\r\nOS Platform and Distribution: Linux Ubuntu 16.04\r\nTensorFlow installed from: Conda\r\nTensorFlow version: 1.5.0\r\nBazel version: N/A\r\nCUDA/cuDNN version: N/A\r\nGPU model and memory: N/A\r\nExact command to reproduce: N/A", "@fchollet can you comment on array-of-arrays support? ", "@Chasearmer Is this still an issue with the latest TF versions? If yes, can you provide a standalone code to reproduce the issue? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "The following issue is somewhat related which may help. We can track the progress in that issue.\r\nhttps://github.com/keras-team/keras/issues/15778"]}, {"number": 19863, "title": "Wrong calculation for conv2d_transpose outpu shape with stride != 1", "body": "I work on convolutional auto encoder and recognized that the calculation of the conv2d_transpose output shape for a stride > 1 is wrong.  \r\n\r\nConsidering an input shape of [2, 74, 74, 16], a kernel of [3, 3], a stride of (2,2) and the 24 output filter the following code for a minimal AE would be this:\r\n\r\n\r\n``conv_input = tf.placeholder(\"float32\", [2, 74, 74, 16])``\r\n``print(conv_input)``\r\n``conv = tf.layers.conv2d(conv_input, 24, [3,3],strides=(2,2))``\r\n``print(conv)``\r\n``deconv = tf.layers.conv2d_transpose(conv, 16, [3, 3], strides=(2,2))``\r\n``print(deconv)``\r\n\r\nThe output is:\r\n\r\n![grafik](https://user-images.githubusercontent.com/17809849/41171901-62425888-6b52-11e8-8117-5ec0df63b859.png)\r\n\r\nShould not the transpose operation restore the original shape or does this only appy on stride =1?\r\nI also calculated the output shape by hand and get the same result. So not 100% sure if this is a bug.", "comments": ["see #2118 to understand why the shape of the output of conv2d_transpose is ambiguous with stride > 1"]}, {"number": 19862, "title": "Branch 199809082", "body": "", "comments": ["@akshayka Could you take a quick look at `script_ops.py` and `py_func_test.py`? I merged them manually.", "Fails:\r\n```\r\n//tensorflow/compiler/xla/tests:convolution_test_gpu\r\n//tensorflow/compiler/xla/tests:convolution_test_gpu_alternative_layout_gpu\r\n```\r\nAnd\r\n`//tensorflow/contrib/data/python/kernel_tests:optimize_dataset_op_test` (timeout - flakey)", "Looks like the XLA failure was fixed in cl/199814523.", "All passed.", "Could I get another approval?", "Re: py_func_test.py:testCleanup, I believe the LHS of the diff (i.e,. the implementation that calls gc.collect()) is more recent than the RHS --- it was added in https://github.com/tensorflow/tensorflow/pull/19085. We probably shouldn't revert it --- does that test no longer pass?\r\n\r\nBesides that function, LGTM.\r\n", "oh, ok, I got confused in the merge. Thanks!", "Closing stale push PR."]}, {"number": 19861, "title": "using tf.contrib.model_pruning. but how to save pruning model??", "body": "I run the demo of model_pruning module. I got the following:\r\n```\r\n-rw-r--r--  1 Jeff  staff    81B  6  8 21:47 checkpoint\r\n-rw-r--r--  1 Jeff   staff   1.3M  6  8 21:48 events.out.tfevents.1528465664.MacBook-Pro.local\r\n-rw-r--r--  1 Jeff   staff   790K  6  8 21:47 graph.pbtxt\r\n-rw-r--r--  1 Jeff   staff   4.1M  6  8 21:47 model.ckpt-100000.data-00000-of-00002\r\n-rw-r--r--  1 Jeff   staff   8.2M  6  8 21:47 model.ckpt-100000.data-00001-of-00002\r\n-rw-r--r--  1 Jeff   staff   1.6K  6  8 21:47 model.ckpt-100000.index\r\n-rw-r--r--  1 Jeff   staff   365K  6  8 21:47 model.ckpt-100000.meta\r\n```\r\nbut I did not get the pruning model?? Dose the model_pruning module work??", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n", "Asking here is useless, no one will answer you question , very angry ..."]}, {"number": 19860, "title": "Skipped the check that fails due to overflow error as float128 dataty\u2026", "body": "\u2026pe is same as float64 instead of longdouble on platforms like Power - Issue# 19694", "comments": []}, {"number": 19859, "title": "Fixes #19858", "body": "This PR removes spaces from the `equation` argument to the `tf.einsum` function, such that the function can handle spaces in the same way as `np.einsum` does.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Could you add a test for that?", "Sure, I can do that. Shall I use `tf.test` for it? Where do I add the test?", "I think you just need to add something here:\r\nhttps://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/special_math_ops_test.py#L155", "Ok, I did that.", "Thanks!", "I see, the testing framework assumes that there are no spaces while figuring out the shapes of the tensors that are randomly generated as inputs for the tests. Let me try to fix this...", "Can you run the tests again?", "Oh, this was sent against `1.8`. You have to send it against master. Could you do that in another PR and CC me on it? Thanks.", "Oops, sorry for that. I created a PR into master in #19980.", "Nagging Assignee @drpngx: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This was settled in PR #19980."]}, {"number": 19858, "title": "tf.einsum does not support spaces in equation", "body": "In the numpy implementation, the `einsum` function supports spaces in the equations, but in TensorFlow it does not. I believe that spaces make the equations more readable.\r\nFor instance in this example, the numpy function call works well, while the TF function call throws a kind of cryptic ValueError:\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nX = np.random.random(size=(100,100))\r\nX_tensor = tf.constant(X)\r\n\r\neinsum_example_np = np.einsum(\"ij, jk -> ik\", X, X)\r\n\r\neinsum_example_tf = tf.einsum(\"ij, jk -> ik\", X_tensor, X_tensor)\r\n```\r\n\r\nBy changing the last line to `einsum_example_tf = tf.einsum(\"ij,jk->ik\", X_tensor, X_tensor)` it can be made to work.\r\nI think that this behavior can be confusing to people who are used to the handling of einsum equations in the numpy implementation. I would suggest to make the TF implementation also support spaces. This could probably be done by just stripping all spaces from the input to the equation argument.", "comments": ["I opened a PR that removes the spaces from the `equation` argument. I think this should solve the issue."]}, {"number": 19857, "title": "Tensorflow Backend error on Pycharm", "body": "**Using Tensorflow backend** \r\nI have set anaconda environment on pycharm and also installed keras and tensorflow packages but it shows error **Using Tensorflow Backend**\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "@tensorflowbutler I switched from Pycharm to JupyterNotebook and it works fine on it. I am going to close this issue. Thanks for your co-operation!!!"]}]