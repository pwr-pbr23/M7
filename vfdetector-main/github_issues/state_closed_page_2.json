[{"number": 55533, "title": "r2.9 cherry-pick: 8ea604d4c2c \"Don't build nightly wheels on macos release\"", "body": "Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/8ea604d4c2c911e8957e45e0a67293b961316ff2", "comments": []}, {"number": 55532, "title": "Bullet Points missing", "body": "![image](https://user-images.githubusercontent.com/63838746/162250635-d3786b74-37f7-417d-855b-7c5647b7f4f1.png)\r\n", "comments": ["the bullets points are visible only if the sentence has any special character ", "@devendra-rgb \r\nIn order to expedite the trouble-shooting process here,could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose),\r\nThanks!", "Hey sushreebarsa the isse is that the in markup language the points are written but they are not showing in preview if we are appending any special characters to the sentence it is working \r\n\r\nthis is the normal one \r\n![image](https://user-images.githubusercontent.com/63838746/162252398-6ba0d69d-e9c8-4666-9c2e-068bbb513a34.png)\r\n![image](https://user-images.githubusercontent.com/63838746/162252458-f5c0dfff-f921-40a7-83b9-2267ebc6ab10.png)\r\n\r\nafter adding space it is like this \r\n\r\n![image](https://user-images.githubusercontent.com/63838746/162252667-9ca74204-a0a7-4980-bafb-b66f5e28c8a4.png)\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/63838746/162252710-2f1f80d1-3165-4e6d-9d56-9acfc04fad29.png)\r\n", "These are just placeholders, have no significance in the rich text editor", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 55531, "title": "buil", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55531\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55531\">No</a>\n", "Template empty, nothing to act on"]}, {"number": 55529, "title": "Register Not differentiable RandomShuffle", "body": "https://github.com/tensorflow/tensorflow/issues/6269#issuecomment-267615674", "comments": ["/cc @wangpengmit Do you know who can review this?", "I can review this.", "Do we need the kokoro label?", "As `Py+CPP Test Suite - Ubuntu CPU, Python 3.9` job is required is it failing cause this change or is it broken for something else?", "Are you able to see the log? The error message I saw is\r\n```\r\ntensorflow/python/eager/pywrap_gradient_exclusions.cc: In function \u2018absl::lts_20211102::optional<tensorflow::gtl::FlatSet<int> > OpGradientUnusedOutputIndices(const string&)\u2019:\r\ntensorflow/python/eager/pywrap_gradient_exclusions.cc:914:4: error: too many initializers for \u2018std::__array_traits<{anonymous}::OpIndexInfo, 482>::_Type\u2019 {aka \u2018{anonymous}::OpIndexInfo [482]\u2019}\r\n  914 |   }};\r\n      |    ^\r\n```\r\nLooks like somehow 482 is not enough. Strange. (Or does it exceed C++'s limit?)", "But I've not changed line 914 in `pywrap_gradient_exclusions.cc:914`", "It seems that master is now already at 482", "> But I've not changed line 914\r\n\r\n914 is the end of the \"logical line\". The error is in the middle of the logical line.\r\n\r\n> It seems that master is now already at 482\r\n\r\nThen it's just a merging conflict. Changing 482 to 483 should fix it.", "Seems auto-merge is not happening but the changes are merged into master now, so we can close this. Thank you for the PR."]}, {"number": 55526, "title": "Unable to load packages inside docker. All mirrors are down", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version:\r\n- Python version: 3\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source): 0.16.1\r\n- GCC/Compiler version (if compiling from source): 7.5.0\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nI am testing tensorflow-lite example with my project. I am able to run tensorflow-lite along with my project on baremetal and it works fine. But when i run the same steps inside docker container, it throws the error 0 Package Loaded and all mirrors are down.\r\n\r\nPlease tell me what settings should be enabled in my docker environment to run this example\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\ncd tensorflow && /root/bin/bazel build tensorflow/contrib/lite/examples/label_image\r\n\r\n**Any other info / logs**\r\nStarting local Bazel server and connecting to it...\r\nERROR: error loading package '': Encountered error while reading extension file 'closure/defs.bzl': no such package '@io_bazel_rules_closure//closure': Error downloading [https://mirror.bazel.build/github.com/bazelbuild/rules_closure/archive/dbb96841cc0a5fb2664c37822803b06dab20c7d1.tar.gz, https://github.com/bazelbuild/rules_closure/archive/dbb96841cc0a5fb2664c37822803b06dab20c7d1.tar.gz] to /intel/.cache/bazel/_bazel_root/98545780cf4453991b5570835db641da/external/io_bazel_rules_closure/dbb96841cc0a5fb2664c37822803b06dab20c7d1.tar.gz: All mirrors are down: []\r\nERROR: error loading package '': Encountered error while reading extension file 'closure/defs.bzl': no such package '@io_bazel_rules_closure//closure': Error downloading [https://mirror.bazel.build/github.com/bazelbuild/rules_closure/archive/dbb96841cc0a5fb2664c37822803b06dab20c7d1.tar.gz, https://github.com/bazelbuild/rules_closure/archive/dbb96841cc0a5fb2664c37822803b06dab20c7d1.tar.gz] to /intel/.cache/bazel/_bazel_root/98545780cf4453991b5570835db641da/external/io_bazel_rules_closure/dbb96841cc0a5fb2664c37822803b06dab20c7d1.tar.gz: All mirrors are down: []\r\nINFO: Elapsed time: 57.362s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n", "comments": ["@anjalirai-intel We see that you are using an older version of Bazel (0.16.1) , we recommend you to kindly upgrade to the latest TF v2.8.0 and Bazel 4.2.1.Please refer this [link](https://www.tensorflow.org/install/source#tested_build_configurations) for more details on tested build configurations.Thanks!\r\n\r\n\r\n\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55526\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55526\">No</a>\n"]}, {"number": 55523, "title": "[oneDNN] Windows CI Set python path env vars if not already set", "body": null, "comments": []}, {"number": 55521, "title": "Hi", "body": "Hi I've been trying to train tflite pose classifiers to work with your movenet pi example\r\nhttps://github.com/tensorflow/examples/tree/master/lite/examples/pose_estimation/raspberry_pi\r\n\r\nI've used the suggested tutorial and colab \r\nhttps://www.tensorflow.org/lite/tutorials/pose_classification\r\nand carefully followed the example yoga pose dataset (with train and test examples) but the classification results seem almost random (2 classifiers out 4 successfully classify a pose about 50% of the time).\r\n\r\nMy dataset is here\r\nhttps://github.com/roddicki/movenet-pi-dataset\r\n\r\nThe training in the colab works well with a confusion matrix with no errors. The model accuracy is also high (0.9977) and the increasing accuracy through the training epochs looks as expected. I wondered if anyone has used this colab with success?\r\n\r\nThanks!\r\n\r\n", "comments": ["Hi. Please use [TF forum](https://discuss.tensorflow.org/) for these types of questions. GitHub is for bugs related to the code or feature requests.", "Ok thanks"]}, {"number": 55518, "title": "Integrating cuBLASLt into XLA", "body": "Adds support for the cuBLASLt library for GEMM operations to XLA. The library can be activated by setting the XLA flag `xla_gpu_enable_cublaslt=true`.\r\n\r\n@SandSnip3r can you run the test _before_ merging?", "comments": ["@philipphack Can you please resolve conflicts? Thank you!", "FYI @philipphack, this was merged. I'm not sure why this PR hasn't been updated.", "Seems auto-merge is not happening but the changes are merged into master now, so we can close this. Thank you for the PR."]}, {"number": 55517, "title": "Update README.md", "body": "Removed two unnecessary commas", "comments": ["Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nFor more information, open the [CLA check for this pull request](https://github.com/tensorflow/tensorflow/pull/55517/checks?check_run_id=5855040200).", "Please use a better title and commit message: https://cbea.ms/git-commit/\r\n\r\nThe commas are instances of what is called an oxford comma, they are ok as they are.\r\n\r\nWhen fixing typos, please fix all in a file/directory, instead of just a few. We need hours of CI to test each change, so let's try to minimize the CI hours/letters changed metrics :)\r\n\r\nThank you for your contribution, but we cannot accept this one."]}, {"number": 55516, "title": "r2.9 cherry-pick: c2c81d8a45f \"call_with_layout shall pin to the mesh of the layout.\"", "body": "Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/c2c81d8a45f17f4d83adf7872f925c46a9302bac", "comments": []}, {"number": 55514, "title": "[Pfor] Fix string format", "body": null, "comments": ["/cc @wangpengmit "]}, {"number": 55512, "title": "Converting models to TFLite is not deterministic", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac 11.5.2\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.7.1\r\n- Python version: 3.8.8\r\n- GPU model and memory: AMD Radeon Pro 5300M 4 GB, Intel UHD Graphics 630 1536 M\r\n\r\n**Describe the current behavior**\r\nI have a keras model that I convert into a tflite model using `tf.lite.TFLiteConverter.from_keras_model`.\r\nI then save the converted tflite model. I noticed that the output of the conversion is not bit-exact. That means if I save the same converted tflite model twice, the two files may have different hashes.\r\n\r\n**Describe the expected behavior**\r\nI would expect the output tflite model file to always have the same hash. I need this so I will be able to know if the model changed.\r\n\r\n**Standalone code to reproduce the issue**\r\nThis behavior doesn't reproduce every time, but it happens pretty often\r\n\r\n```\r\nimport os\r\nimport tensorflow as tf\r\n\r\ndef create_model():\r\n    inputs = tf.keras.Input(shape=[5, 5, 3])\r\n    x = tf.keras.layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\r\n    x = tf.keras.layers.BatchNormalization()(x)\r\n    model = tf.keras.Model(inputs, x)\r\n    return model\r\n\r\n\r\nmodel = create_model()\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.experimental_new_converter = True\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_types = [tf.float16]\r\n\r\ntflite_model1 = converter.convert()\r\n\r\ntflite_model2 = converter.convert()\r\n\r\nwith open(\"model1.tflite\", \"wb\") as f:\r\n    f.write(tflite_model1)\r\n\r\nwith open(\"model2.tflite\", \"wb\") as f:\r\n    f.write(tflite_model2)\r\n\r\nprint(os.system(\"diff model1.tflite model2.tflite\"))\r\n\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.experimental_new_converter = True\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_types = [tf.float16]\r\n\r\ntflite_model3 = converter.convert()\r\n\r\nwith open(\"model3.tflite\", \"wb\") as f:\r\n    f.write(tflite_model3)\r\n\r\nprint(os.system(\"diff model1.tflite model3.tflite\"))\r\n```\r\n", "comments": ["Hi @nitsanh ! I am able to get deterministic result  by using tf.random.set_seed() in 2.8 version . Attaching [gist ](https://colab.sandbox.google.com/gist/mohantym/04440e592dc4b95534f274be7fb1e8cc/git_55512.ipynb#scrollTo=4Tg-ibeGOaTQ)for reference . Thanks!", "Hi @mohantym, thanks for the quick reply! I ran your gist again and received non-deterministic output when using a seed and version 2.8.0 [here](https://colab.research.google.com/gist/nitsanh/dc970085a2bd9829f13e1086e0505458/git_55512.ipynb)", "Sorry @nitsanh ! I used[ tf.config.experimental.enable_op_determinism ](https://www.tensorflow.org/api_docs/python/tf/config/experimental/enable_op_determinism) later to get deterministic results . It did replicate in [2.8](https://colab.sandbox.google.com/gist/mohantym/a2786086d2cab11291a30b35bb4f3f31/git_55512.ipynb) though , but seems to be resolved in the [nightly](https://colab.sandbox.google.com/gist/mohantym/98b552b6f6aec62686c7602380f73674/git_55512.ipynb#scrollTo=rVnvTAzfXam6) version.  Can you let us know from your end too? Thanks!", "Hi @mohantym, it seems to be deterministic on my end as well using the nightly version. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55512\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55512\">No</a>\n"]}, {"number": 55511, "title": "R0.7", "body": null, "comments": ["Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nFor more information, open the [CLA check for this pull request](https://github.com/tensorflow/tensorflow/pull/55511/checks?check_run_id=5847763152)."]}, {"number": 55509, "title": "Ggadde 1 15 rc3 version", "body": null, "comments": ["Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nFor more information, open the [CLA check for this pull request](https://github.com/tensorflow/tensorflow/pull/55509/checks?check_run_id=5847026298).", "Please don't spam with bad PRs. We never merge release branches back into main branch"]}, {"number": 55508, "title": "Fix Issue #53164 : Multiple matches are not allowed unless one is unambiguously more specialized", "body": "Fix Issue #53164 : Multiple matches are not allowed unless one is unambiguously more specialized\r\n\r\n    Fix 'Illegal ambiguous match' on s390x with --config=nogcp\r\n\r\nSigned-off-by: potula-chandra <chpotula@in.ibm.com>", "comments": ["Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nFor more information, open the [CLA check for this pull request](https://github.com/tensorflow/tensorflow/pull/55508/checks?check_run_id=5846389059).", "@potula-chandra Can you please sign CLA. Thank you!", "@gbaned I am working with authorized signatory of our company. Thank you!", "Looks like there was a problem in adding my mail id <chandra.shekhar@in.ibm.com> to the google group managed by our company. so I have provided alias id <chpotula@in.ibm.com>,  which has been added to the company google group. In the author list it is now showing to two mail id's. \r\n\r\nAny suggestion on what can be done now ? Thanks !", "You have to sign CLA with both emails.", "@gbaned  @mihaimaruseac Now CLA check has been passed. "]}, {"number": 55507, "title": "Added space to make bullet point visible", "body": null, "comments": ["In preview of release.me the bullet point is only visible the sentence is not visible to get rid of bug I added a white space ", "This is just a snippet. The space doesn't bring anything.\r\n\r\nWhen making typo fixes PRs please fix through the entire file/directory.", "> This is just a snippet. The space doesn't bring anything.\r\n> \r\n> When making typo fixes PRs please fix through the entire file/directory.\r\n\r\nThanks! for responding did you see the preview of the edited one ", "Yes, but these are just placeholders, they don't mean anything in the rich view", "> Yes, but these are just placeholders, they don't mean anything in the rich view\r\n\r\nThankyou! mihaimaruseac got the point \ud83d\ude01"]}, {"number": 55506, "title": "Remove empty bullet point", "body": "I removed an empty bullet point", "comments": ["Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nFor more information, open the [CLA check for this pull request](https://github.com/tensorflow/tensorflow/pull/55506/checks?check_run_id=5846042637)."]}, {"number": 55504, "title": "Enable XLA test of tf.tensor_scatter_nd_update", "body": "See [this conversation](https://github.com/tensorflow/tensorflow/pull/55460#discussion_r842286085) with @reedwm. XLA JIT compiled functions that utilize the `Scatter` HLO are deterministic since 2.8.0, which I have confirmed for `array_ops.tensor_scatter_update`, the entry point used for this test.", "comments": []}, {"number": 55502, "title": "Using model.predict(X) gives me \"InternalError: Failed copying input tensor from CPU to GPU in order to run _EagerConst: Dst tensor is not initialized.\"", "body": "**System information**\r\n- OS Platform and Distribution (Linux Ubuntu 20.04):\r\n- TensorFlow installed from Docker (tensorflow/tensorflow):\r\n- TensorFlow version: 2.8.0\r\n- Python version: Python 3.8.10\r\n- GPU model and memory: NVIDIA GeForce MX110 2048 MB\r\n\r\nI have built a neural network model with TensorFlow Probability and when trying to predict values as in \r\n`pred_train = model.predict(X_train)`\r\n it gives me this error, most of the times \r\n`InternalError: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.`\r\nand sometimes it runs ok without errors.\r\n\r\nThe same data/code was used with different models and works just fine. The problem seems to appear only with models built with TensorFlow Probability ", "comments": ["@caliari-italo \r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "I manage to contour the problem by disabling my GPU by removing `--gpus all` when running the docker image\r\n\r\n`sudo docker run -it --rm --gpus all image_name python3 code.py`\r\nto\r\n`sudo docker run -it --rm image_name python3 code.py`", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55502\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55502\">No</a>\n"]}, {"number": 55501, "title": "Tweak the lower bound for the keras to include Rc0", "body": "Adjusting the lower bound for the keras to also include Rc0", "comments": []}, {"number": 55500, "title": "High memory usage while training with tflite_model_maker", "body": "**System information**\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): True\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 / Ubuntu 18.04\n- TensorFlow installed from (source or binary): binary\n- TensorFlow version (use command below): 2.8.0\n- Python version: 3.7.13\n- CUDA/cuDNN version: CUDA 11.1\n- GPU model and memory: Tesla K80 (Colab GPU) 24 GB GDDR5\n\n**Describe the current behavior**\n\nNo errors, however upon increasing `batch_size` past 1 or 2 an OOM error is incurred. Even when keeping `batch_size` to 1, OOM occurs when using more than 1 epoch. When using 1 `batch_size` and 1 `epoch`, after execution of epochs, the memory usage grows until eventually crashing. \n\n**Describe the expected behavior**\n\nNo errors, the training ends without crashing.\n\n**Standalone code to reproduce the issue**\n[colab](https://colab.research.google.com/drive/1bMpah_j9tyyK_cg3uL0KuFv8BBO3k4Iu?usp=sharing)", "comments": ["Hi @LQR471814 ! The Dataset in the above notebook contains images  of songs from different composers . Won't it be more suitable for image classification ? if you are looking for image classification of different compositions , you can put the respective images in respective composer's folder and  follow instructions from [here](https://www.tensorflow.org/lite/tutorials/model_maker_image_classification). Thanks!", "Thanks for your response!\r\nThe purpose of the model is to detect the location of musical measures within each score so I used an object detection architecture.\r\nSomething like this, sorry I didn't make this clearer in the issue.\r\n![model_example](https://user-images.githubusercontent.com/42160088/161872388-d504d091-58a8-453d-8348-8c8365c772c2.png)\r\n\r\n", "@LQR471814 ! I was getting an Attribute error saying **'NoneType' object has no attribute 'label_map'**  in[ Colab environment](https://colab.sandbox.google.com/gist/mohantym/c5e0e96825428b69867e537e8abb2859/measure-detection.ipynb#scrollTo=dYHaqerGBlwI).   Can you refer to this [document ](https://cloud.google.com/vision/automl/object-detection/docs/create-datasets)to create your Dataset properly (could not locate labelled images there)? Thanks!", "Looks like I misconfigured some paths when editing the script for colab, I have fixed it could you try again?", " @chunduriv ! Could you please look at this issue? Attaching gist in [2.8](https://colab.sandbox.google.com/gist/mohantym/14308f15f0d78cb86fd0245b3294ffdc/measure-detection.ipynb#scrollTo=_ecaUeQAXoSz) for reference.", "well, I've solved the problem myself, so here's some things to watch out for when training your datasets in terms of memory usage.\r\n1. `model.evaluate` for some reason, this uses a lot of memory. so if you're sure you can skip this step then try doing so.\r\n1. the number of images used in the dataset (usually using more than 400 images will end up causing my script to crash)\r\n1. `batch_size`, it's better if you use a larger batch size coupled with a larger epoch count in terms of general model accuracy. however you can decrease it to free up memory usage.\r\n1. model type, the tflite model maker `object_detector` currently only supports `efficientdet_lite` models, however within this category, note that increasing the level of the `efficientdet_lite` model (ex. `efficientdet_lite0` -> `efficientdet_lite4`) will increase memory usage as well\r\n\r\nanother thing to watch out for, if you're using a `.csv` file, make sure you provide a label for the data and that the coordinates are normalized from `0-1`. failure to do so will not result in an error, but rather absurd results during inference that will leave you scratching your head for hours on end.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55500\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55500\">No</a>\n"]}, {"number": 55499, "title": "TFlite conversion from concrete function returns \"ValueError: This converter can only convert a single ConcreteFunction. Converting multiple functions is under development.\"", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installation (pip package or built from source): Pip\r\n- TensorFlow library (version, if pip package or github SHA, if built from source): tensorflow==2.8.0\r\n\r\n### 2. Code\r\n\r\nProvide code to help us reproduce your issues using one of the following options:\r\n\r\n#### Option A: Reference colab notebooks\r\n\r\n1)  Reference [TensorFlow Model Colab]\r\n\r\nhttps://colab.research.google.com/drive/1n3xeAtFU0xRxtMDEdw3k_xsyHHnsVnP7#scrollTo=Nbvrn_9uaCSY\r\n\r\n### 3. Failure after conversion\r\nConversion fails with \" ValueError: This converter can only convert a single ConcreteFunction. Converting multiple functions is under development.\"\r\n\r\n", "comments": ["The Conversion from", "Duplicate"]}, {"number": 55496, "title": "Unit test //tensorflow/core/kernels:conv_ops_benchmark_test_cpu fails to build on non-mkl build", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: git HEAD\r\n- Python version: 3.8.12\r\n- Installed using virtualenv? pip? conda?: no\r\n- Bazel version (if compiling from source): 5.1.0\r\n- GCC/Compiler version (if compiling from source): 10.2.1\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nBuild of unit test //tensorflow/core/kernels:conv_ops_benchmark_test_cpu fails with \r\n\r\nERROR: /tmp/workspace/tensorflow-git/tensorflow/core/kernels/BUILD:1836:16: Compiling tensorflow/core/kernels/conv_ops_benchmark_test.cc failed: undeclared inclusion(s) in rule '//tensorflow/core/kernels:conv_ops_benchmark_test_cpu':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/core/kernels/conv_ops_benchmark_test.cc':\r\n  'tensorflow/core/graph/mkl_graph_util.h'\r\nTarget //tensorflow/core/kernels:conv_ops_benchmark_test_cpu failed to build\r\nINFO: Elapsed time: 50.018s, Critical Path: 46.01s\r\nINFO: 314 processes: 74 internal, 240 local.\r\nFAILED: Build did NOT complete successfully\r\n//tensorflow/core/kernels:conv_ops_benchmark_test_cpu           FAILED TO BUILD\r\n\r\nFAILED: Build did NOT complete successfully\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nbazel test --test_timeout=300,500,-1,-1 --flaky_test_attempts=3 --test_output=all --cache_test_results=no --config=nonccl --verbose_failures --build_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --test_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --jobs=75 --build_tests_only -- //tensorflow/core/kernels:conv_ops_benchmark_test_cpu\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nIntroduced by https://github.com/tensorflow/tensorflow/commit/3a0c3b215c969ea5f1a9d59f11b4c628b8c4b22f", "comments": ["@cfRod @nSircombe ", "Could you please help check if this has been fixed by https://github.com/tensorflow/tensorflow/commit/3fb057af1b930e30cd8f42fd91f722354eaba0e0? Thank you!", "Yes, now fixed, thanks.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55496\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55496\">No</a>\n"]}, {"number": 55494, "title": "Pip package build broken by removal of declare of RUY LICENSE", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 11\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: git HEAD\r\n- Python version: 3.9.2\r\n- Installed using virtualenv? pip? conda?: no\r\n- Bazel version (if compiling from source): 5.1.0\r\n- GCC/Compiler version (if compiling from source): 10.3.0\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nBuild fails with error\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nbazel build --config=nonccl --verbose_failures -- //tensorflow/tools/pip_package:build_pip_package\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n$ bazel build --config=nonccl --verbose_failures -- //tensorflow/tools/pip_package:build_pip_package\r\nStarting local Bazel server and connecting to it...\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=131\r\nINFO: Reading rc options for 'build' from /home/debian-j13-x86-05/src/tensorflow/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /home/debian-j13-x86-05/src/tensorflow/.bazelrc:\r\n  'build' options: --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library\r\nINFO: Reading rc options for 'build' from /home/debian-j13-x86-05/src/tensorflow/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/home/debian-j13-x86-05/venv_py39/bin/python3 --action_env PYTHON_LIB_PATH=/home/debian-j13-x86-05/venv_py39/lib/python3.9/site-packages --python_path=/home/debian-j13-x86-05/venv_py39/bin/python3\r\nINFO: Reading rc options for 'build' from /home/debian-j13-x86-05/src/tensorflow/.bazelrc:\r\n  'build' options: --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/ir,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils\r\nINFO: Found applicable config definition build:short_logs in file /home/debian-j13-x86-05/src/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /home/debian-j13-x86-05/src/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:nonccl in file /home/debian-j13-x86-05/src/tensorflow/.bazelrc: --define=no_nccl_support=true\r\nINFO: Found applicable config definition build:linux in file /home/debian-j13-x86-05/src/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes\r\nINFO: Found applicable config definition build:dynamic_kernels in file /home/debian-j13-x86-05/src/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS\r\nWARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/tensorflow/runtime/archive/73ef596c0dba3638242bcb57e895d4163e31da64.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found\r\nERROR: /home/debian-j13-x86-05/src/tensorflow/tensorflow/tools/pip_package/BUILD:182:10: no such target '@ruy//:LICENSE': target 'LICENSE' not declared in package ''; however, a source file of this name exists.  (Perhaps add 'exports_files([\"LICENSE\"])' to /BUILD?) defined by /home/debian-j13-x86-05/.cache/bazel/_bazel_debian-j13-x86-05/6dfc29351d9ac80b1cbc1c3ca56d5b08/external/ruy/BUILD.bazel and referenced by '//tensorflow/tools/pip_package:licenses'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: \r\nINFO: Elapsed time: 130.450s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (272 packages loaded, 3958 targets configured)\r\n    Fetching @local_jdk; fetching\r\n\r\nIntroduced by https://github.com/tensorflow/tensorflow/commit/57226b829ef6f3fddb3579ce6cf2fb7af0ca90ba\r\n", "comments": ["@cfRod @nSircombe ", "Resolved by commit https://github.com/tensorflow/tensorflow/commit/8f1a282ce58853a5152d2edda2f56a055d2ca419", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55494\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55494\">No</a>\n"]}, {"number": 55492, "title": "is there tensorflow-gpu available for cuda 11.4\uff1f", "body": "<em>I was wandering whether there is a available tensorflow-gpu version for cuda 11.4\uff0c when i install the latest version 2.8.0\uff0cwhen i import the tensorflow\uff0ci got this\r\n\r\n\uff1a\"W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib:/usr/local/cuda/lib:\r\n2022-04-05 11:20:15.733394: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\",  \r\n\r\ni see the version attached to cuda latest is 11.2\uff0cbut i have no authority to downgrad the cuda version, thanks for your attention!</em>\r\n\r\n**System information**\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version:2.8.0\r\n- Python version:3.8.0\r\n- Installed using virtualenv? pip? conda?:conda\r\n- CUDA/cuDNN version:11.4\r\n\r\n", "comments": ["@colaaaaaa ,\r\nEvery TensorFlow release is compatible with a certain version, for more information can you please take a look at the tested build [configurations](https://www.tensorflow.org/install/source_windows#gpu).In this case, can you please try installing TensorFlow v2.8 with CUDA 11.2 and cuDNN 8.1 and check if you are facing the same error. Thanks!", "TensorFlow is built and tested with CUDA 11.2, but it also works with CUDA 11.4.\r\n\r\nI see you have `/usr/local/cuda/lib` in your `LD_LIBRARY_PATH`, but I don't think CUDA has a directory called `lib`. Try adding `/usr/local/cuda/lib64` to your `LD_LIBRARY_PATH`.", "> TensorFlow is built and tested with CUDA 11.2, but it also works with CUDA 11.4.\r\n> \r\n> I see you have `/usr/local/cuda/lib` in your `LD_LIBRARY_PATH`, but I don't think CUDA has a directory called `lib`. Try adding `/usr/local/cuda/lib64` to your `LD_LIBRARY_PATH`.\r\nThanks for your advice\u263a\u263a\u263a, but i have checked that the machine has made a soft link form lib to \"lib64\", so the path is \"lib\", so this wouldnt work, and i finally reinstalled tensorflow 2.4.0 by install cudatoolkit 11.0  and cudnn 8.1.1.33 without sudo permission \ud83d\ude34\ud83d\ude34\ud83d\ude34\r\n", "> @colaaaaaa , Every TensorFlow release is compatible with a certain version, for more information can you please take a look at the tested build [configurations](https://www.tensorflow.org/install/source_windows#gpu).In this case, can you please try installing TensorFlow v2.8 with CUDA 11.2 and cuDNN 8.1 and check if you are facing the same error. Thanks!\r\n\r\ni looked it before and found that the newst cuda version supported is 11.4\uff0c and i finally reinstalled tensorflow 2.4.0 by install cudatoolkit 11.0 and cudnn 8.1.1.33 without sudo permission . and thanks for you kind and quick response!!!\ud83d\ude01\ud83d\ude01\ud83d\ude01", "> > @colaaaaaa , Every TensorFlow release is compatible with a certain version, for more information can you please take a look at the tested build [configurations](https://www.tensorflow.org/install/source_windows#gpu).In this case, can you please try installing TensorFlow v2.8 with CUDA 11.2 and cuDNN 8.1 and check if you are facing the same error. Thanks!\r\n> \r\n> i looked it before and found that the newst cuda version supported is 11.4\uff0c and i finally reinstalled tensorflow 2.4.0 by install cudatoolkit 11.0 and cudnn 8.1.1.33 without sudo permission . and thanks for you kind and quick response!!!\ud83d\ude01\ud83d\ude01\ud83d\ude01\r\n\r\n> > TensorFlow is built and tested with CUDA 11.2, but it also works with CUDA 11.4.\r\n> > I see you have `/usr/local/cuda/lib` in your `LD_LIBRARY_PATH`, but I don't think CUDA has a directory called `lib`. Try adding `/usr/local/cuda/lib64` to your `LD_LIBRARY_PATH`.\r\n> > Thanks for your advice\u263a\u263a\u263a, but i have checked that the machine has made a soft link form lib to \"lib64\", so the path is \"lib\", so this wouldnt work, and i finally reinstalled tensorflow 2.4.0 by install cudatoolkit 11.0  and cudnn 8.1.1.33 without sudo permission \ud83d\ude34\ud83d\ude34\ud83d\ude34\r\n\r\n\r\n\r\n> > TensorFlow is built and tested with CUDA 11.2, but it also works with CUDA 11.4.\r\n> > I see you have `/usr/local/cuda/lib` in your `LD_LIBRARY_PATH`, but I don't think CUDA has a directory called `lib`. Try adding `/usr/local/cuda/lib64` to your `LD_LIBRARY_PATH`.\r\n> > Thanks for your advice\u263a\u263a\u263a, but i have checked that the machine has made a soft link form lib to \"lib64\", so the path is \"lib\", so this wouldnt work, and i finally reinstalled tensorflow 2.4.0 by install cudatoolkit 11.0  and cudnn 8.1.1.33 without sudo permission \ud83d\ude34\ud83d\ude34\ud83d\ude34\r\n\r\nand still the cuda version is 11.4, so tf truly worked with cuda 11.4~", "@colaaaaaa ,\r\nGlad the issue is resolved for you, please feel free to move this to closed status.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55492\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55492\">No</a>\n"]}, {"number": 55490, "title": "r2.9 cherry-pick: 4f736fe226f \"Add mesh_util and tpu_util functions to public dtensor API.\"", "body": "Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/4f736fe226f910cbc5bb9767df1408148e824945", "comments": []}, {"number": 55489, "title": "Update lower bound for estimator to also include RC0", "body": "Updating the version for estimator lower bound for 2.9 release", "comments": ["For future, please don't use \"update <file>\" title/commits. See https://cbea.ms/git-commit/"]}, {"number": 55488, "title": "Update versions for estimator and Keras", "body": "Updating the setup.py to update estimator and keras versions for 2.9 release-", "comments": []}, {"number": 55487, "title": "https://www.tensorflow.org/tutorials/generative/autoencoder", "body": "On define convolution encoder: encoded_imgs = autoencoder.encoder(x_test).numpy()\r\n\r\nHere the input data is supposed to be \" x_test_noisy\"", "comments": ["Hello @koushik1234 ,\r\nThis issue will move to closed status once the PR is merged.Thanks!\r\n", "Thank you so much @koushik1234 @tilakrayal Let's discuss this in a similar earlier issue https://github.com/tensorflow/tensorflow/issues/53357 and PR https://github.com/tensorflow/docs/pull/1986 (approved). Feel free to reopen! \ud83d\ude4f "]}, {"number": 55486, "title": "Memory Leak in Example/Tutorial Documentation", "body": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/tensorboard/image_summaries#logging_arbitrary_image_data\r\n\r\n## Description of issue (what needs changing):\r\nListed example needs to be corrected as to avoid memory leaks.\r\n\r\n### Clear description\r\nIt appears that the example is creating `tf.image.decode_png`  and `tf.expand_dims` layers within `plot_to_image` which is being repeatedly called by a `tf.keras.callbacks.LambdaCallback`.  These layers are filling VRAM or system RAM, depending on whether or not the example is running on GPU or not.  ", "comments": ["@tokotchd \r\nCould you please share more details on the issue and provide some use cases on this ?\r\nI was able to run the example tutorial  successfully on colab using TF v2.8.0 ,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/210475c9617c4cd9a90fa76fdcbd8464/image_summaries.ipynb) for reference.Thanks! ", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}]