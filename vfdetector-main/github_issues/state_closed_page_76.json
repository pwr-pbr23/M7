[{"number": 52908, "title": "WARNING : tensorflow:AutoGraph could not transform", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.6.0\r\n- Python version: 3.9\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: cudnn-11.4-windows-x64-v8.2.4.15 and cuda_11.4.2_471.41_win10\r\n- GPU model and memory: N/A\r\n-PyCharm details: PyCharm 2021.3 EAP (Community Edition)\r\n\r\n\r\n\r\n**Describe the problem**\r\nThe issue occurs when creating an executable in PyCharm using TensorFlow. When running the program in the PyCharm IDE, no errors occur, but when the executable runs, this error and warning occurs:\r\n\r\n2021-11-02 00:26:13.629314: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\r\n\r\nWARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000015EDA772670> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: Unable to locate the source code of <function Model.make_train_function.<locals>.train_function at 0x0000015EDA772670>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\n4333/4352 [============================>.] - ETA: 0s - loss: 0.0565 - accuracy: 0.9866WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000015EDA8F0A60> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: Unable to locate the source code of <function Model.make_test_function.<locals>.test_function at 0x0000015EDA8F0A60>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nCreated a project in Python using TensorFlow. Converted the .py file to an executable using: pyinstaller --onefile xxxxxxx.py\r\nWhen the executable runs, the warning/error occurs.\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n[TensorFlowBugReport.txt](https://github.com/tensorflow/tensorflow/files/7458622/TensorFlowBugReport.txt)\r\n[TensorFlowPythonCode.txt](https://github.com/tensorflow/tensorflow/files/7458624/TensorFlowPythonCode.txt)\r\n\r\n", "comments": ["You could silence the warning by decorating with  the function `@tf.autograph.experimental.do_not_convert`", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52908\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52908\">No</a>\n"]}, {"number": 52906, "title": "[TF-TRT] Support for IdentityN added", "body": "@bixia1 @meena-at-work for review\r\n\r\nThis PR modifies the Identity Converter to accepts arbitrary number of inputs and convert the IdentityN layer", "comments": []}, {"number": 52905, "title": "tf.repeat fails with jit_compile when repeats is a tensor!", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**: \r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 20.04.3\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):compiled from source\r\n- TensorFlow version (use command below):2.5.6\r\n- Python version:3.8\r\n- Bazel version (if compiling from source):bazel 4.2.1\r\n- GCC/Compiler version (if compiling from source):9.3.0\r\n- CUDA/cuDNN version:NA\r\n- GPU model and memory:NA\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\ntf.repeat fails if the repeats argument is a tensor\r\n**Describe the expected behavior**\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow_probability as tfp\r\nimport numpy as np\r\n\r\n\r\n####\r\n#### test repeat within jit_compile\r\n####\r\n\r\nrepeats = tf.constant([10, 5, 1])\r\n\r\n@tf.function(jit_compile = True)\r\ndef repeat_vector(x):\r\n    return tf.repeat(x, repeats, axis=-1)\r\n\r\nx = [1., 2., 3.] \r\nrepeat_vector(x)\r\n```\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n```\r\n2021-11-01 19:00:56.491404: I tensorflow/compiler/xla/service/service.cc:171] XLA service 0x221bf60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2021-11-01 19:00:56.491446: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (0): Host, Default Version\r\n2021-11-01 19:00:56.496213: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at xla_ops.cc:247 : Invalid argument: Detected unsupported operations when trying to compile graph __inference_repeat_vector_58[_XlaMustCompile=true,config_proto=\"\\n\\007\\n\\003CPU\\020\\001\\n\\007\\n\\003GPU\\020\\0002\\002J\\0008\\001\\202\\001\\000\",executor_type=\"\"] on XLA_CPU_JIT: Where (No registered 'Where' OpKernel for XLA_CPU_JIT devices compatible with node {{node Repeat/boolean_mask/Where}}){{node Repeat/boolean_mask/Where}}\r\nThe op is created at: \r\nFile \"test_repeat.py\", line 20, in <module>\r\n  repeat_vector(x)\r\nFile \"test_repeat.py\", line 14, in repeat_vector\r\n  return tf.repeat(x, repeats, axis=-1)\r\nTraceback (most recent call last):\r\n  File \"test_repeat.py\", line 20, in <module>\r\n    repeat_vector(x)\r\n  File \"/home/mabba/tf_cpu_source/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 885, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/home/mabba/tf_cpu_source/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 956, in _call\r\n    return self._concrete_stateful_fn._call_flat(\r\n  File \"/home/mabba/tf_cpu_source/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 1963, in _call_flat\r\n    return self._build_call_outputs(self._inference_function.call(\r\n  File \"/home/mabba/tf_cpu_source/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 591, in call\r\n    outputs = execute.execute(\r\n  File \"/home/mabba/tf_cpu_source/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Detected unsupported operations when trying to compile graph __inference_repeat_vector_58[_XlaMustCompile=true,config_proto=\"\\n\\007\\n\\003CPU\\020\\001\\n\\007\\n\\003GPU\\020\\0002\\002J\\0008\\001\\202\\001\\000\",executor_type=\"\"] on XLA_CPU_JIT: Where (No registered 'Where' OpKernel for XLA_CPU_JIT devices compatible with node {{node Repeat/boolean_mask/Where}}){{node Repeat/boolean_mask/Where}}\r\nThe op is created at: \r\nFile \"test_repeat.py\", line 20, in <module>\r\n  repeat_vector(x)\r\nFile \"test_repeat.py\", line 14, in repeat_vector\r\n  return tf.repeat(x, repeats, axis=-1) [Op:__inference_repeat_vector_58]\r\n\r\n```\r\n", "comments": ["Hi @sanatmpa1! Could you please look at this issue ? It's replicating in [2.5](https://colab.sandbox.google.com/gist/mohantym/ce936b3de46b2a1b4ca88a6abbaa94cd/github_52905.ipynb#scrollTo=PUBnLDhStk5G),[2.6](https://colab.sandbox.google.com/drive/1PKuqXyhgob9oFsK_phrguptAcJf1kGT6?resourcekey=0-rknXJyWPxX_dTBg3sXh8ow#scrollTo=PUBnLDhStk5G) and [nightly](https://colab.sandbox.google.com/gist/mohantym/9e0d3cc296f5b87faf83c9bd186e6445/github_52905_2-6.ipynb#scrollTo=PUBnLDhStk5G).", "@MedAbdelkaderAbba,\r\n\r\nCan you take a look at this [documentation](https://www.tensorflow.org/xla#explicit_compilation_with_tffunctionjit_compiletrue) which says,\r\n\r\n> The jit_compile API has must-compile semantics: either the entire function is compiled with XLA, or an errors.InvalidArgumentError exception is thrown.  \r\n\r\nAs per the error trace, it says that `No registered 'Where' OpKernel for XLA_CPU_JIT devices compatible with node` and since you have an unsupported operation, `InvalidArgumentError` is thrown which is expected. Can you try using auto-clustering for your case and try if it helps? Thanks!", "@sanatmpa1,\r\nI am not sure I understand the auto-clustering part. I tried to set the following options in the code but nothing changed:\r\n```\r\nimport os\r\n  os.environ['TF_XLA_FLAGS'] = '--tf_xla_auto_jit=2 --tf_xla_cpu_global_jit``\r\n```\r\nAlso, my concern is that the above code workd fine when the argument ''repeats\" was a list\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow_probability as tfp\r\nimport numpy as np\r\nimport os\r\nos.environ['TF_XLA_FLAGS'] = '--tf_xla_auto_jit=2 --tf_xla_cpu_global_jit'\r\n####\r\n#### test repeat within jit_compile\r\n####\r\n\r\n#repeats = tf.constant([10,5,1])\r\nrepeats = [10,5,1]\r\n@tf.function(jit_compile = True)\r\ndef repeat_vector(x):\r\n    return tf.repeat(x, repeats)\r\n\r\n\r\nx = tf.constant([1., 5., 10.])\r\ntf.print(repeat_vector(x))\r\n```\r\nthis behavior is counter intuitive. ", "The support for Where op in XLA was added recently and should be available in TF nightly. \r\n@MedAbdelkaderAbba Could you please try to run the original code snippet again to check if this is resolved?\r\n\r\nThanks!", "@MedAbdelkaderAbba This issue is not replicating in the latest TF versions, could you please refer to the attached [gist](https://colab.research.google.com/gist/sushreebarsa/84a9115a22ef18b875a277f558b9c1cd/52905.ipynb) and confirm the same?\r\nThanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52905\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52905\">No</a>\n"]}, {"number": 52904, "title": "[ROCm] skip randomized_tests_mlir_seeded", "body": "Disable randomized_tests_mlir_seeded tests on ROCm\r\n\r\n@cheshire @chsigg @deven-amd @reza-amd", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F52904) for more info**.\n\n<!-- need_author_consent -->", "@googlebot I consent.", "@cheshire gentle nudge on this one. thx!", "@gbaned this PR seems to have been stuck in the merge pipeline....let us know if we can do anything on our end to help \r\n\r\nthanks", "I will pull it manually. Thanks.", "So this PR is comically hitting every branch while falling out of the copybara tree. Anything I can do to help it? Is it being rejected on import as too small of a change, or mistaken for a cosmetic change?", "@jayfurmanek Can you please address Ubuntu Sanity errors? Thanks!", "Seems auto-merge is not happening but the changes are merged into master now, so we can close this. Thank you for the PR."]}, {"number": 52903, "title": "Fix 16-bit Softmax legalization", "body": "Old 16-bit softmax tfl.softmax legalization is lowered incorrectly with illegal TOSA operators.\r\nNew legalization fixes it.\r\nAlso add 16-bit softmax legalization test\r\n", "comments": ["Tagging @rsuderman and @stellaraccident for reviewing."]}, {"number": 52902, "title": "[oneDNN] Avoid converting memory layout for second matrix in the MatMul op.", "body": "This PR reverts a small change in the _FusedMatMul op kernel that has caused regression in some smaller models, particularly when the second tensor to the kernel is not constant.\r\n", "comments": []}, {"number": 52901, "title": "[ROCm] skip testCategoricalIsInRange", "body": "This failure was introduced in commit 7de9cf4 in a weekly sync.\r\nDisable this test for now on ROCm.\r\n\r\n@cheshire @chsigg @deven-amd @reza-amd ", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F52901) for more info**.\n\n<!-- need_author_consent -->", "@googlebot I consent."]}, {"number": 52900, "title": "Added shape inference support to a lot of the tf-to-tosa legalization", "body": "Added the shape inference utility support so that during tensorflow lowering\r\nit is possible to infer intermediate shapes. This does not handle all cases but\r\ndoes handle hte most straight forward cases.", "comments": []}, {"number": 52899, "title": "[oneDNN] Remove transpose elimination for NHWC/NDHWC conv/maxpool3d ops", "body": "This change removes the part of the code in mkl_layout_pass.cc, where we eliminate following transpose operation and replace conv2d(nhwc) / conv3d(ndhwc) / maxpool3d(ndhwc) with mklConv2d(nchw) / mklConv3d(ncdhw) / mklMaxpool3d(ncdhw) respectively :\r\n\r\nFor ex. we eliminate this graph rewrite : \r\ntranposeToNDHWC -> Conv3d(NDHWC) -> transposeToNCDHW -------> _mklConv3D(NCDHW)\r\n\r\nFor NHWC ,in case of conv2d, and NDHWC ,for conv3d / maxpool3d, oneDNN uses AMX kernels, which has significant higher performance than gemm kernels (used for NCHW conv2d or NCDHW conv3d/maxpool3d) and reorder kernel (for tranpose operations) combined.\r\n", "comments": ["@penpornk Can you please review this PR ? Thanks!"]}, {"number": 52898, "title": "Update Keras Model Docs for dataset dictionaries", "body": "Update the documentation for fit and evaluate to specifically note that datasets returning dictionaries is NOT supported.\r\n\r\nThis is important since previous versions of TF allowed dictionary inputs from datasets, where the name of the input variable was matched to the dictionaries keys.  But this is not longer supported by Keras.\r\n\r\nThis matter is confusing since fit does seem to accept dictionary inputs, but I'm told by Rick Chao that this is not supported.  Passing a dictionary to evaluate gives a weird error message.  \r\n\r\nBetter to be explicit.", "comments": ["It looks like your PR relates to the Keras component. Please submit it to the github.com/keras-team/keras repository instead. Thankyou.\r\n@fchollet, @qlzh727"]}, {"number": 52897, "title": "Illegal instruction (core dumped)", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 18.04.5 LTS x86_64\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version:2.6.0\r\n- Python version:3.6.9\r\n- Installed using virtualenv? pip? conda?: virtualenv\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source): 7.5.0\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: VMware SVGA II Adapter, 16035MiB\r\n\r\n\r\n![Screenshot at 2021-11-01 20-31-51](https://user-images.githubusercontent.com/55286282/139698557-1530fd25-fc97-4aa1-bb44-9a240c6f9009.png)\r\n![Screenshot at 2021-11-01 20-55-10](https://user-images.githubusercontent.com/55286282/139698566-a21d34f8-e85d-479e-a0f2-77bdc87e6c95.png)\r\n![Screenshot at 2021-11-01 20-56-47](https://user-images.githubusercontent.com/55286282/139698570-675ead7b-48d0-4a72-a939-a34c16db435b.png)\r\n\r\n**Describe the problem**\r\ni am using latest tensorflow and i am getting error. kindly help me to fix this issue.\r\ni saw some fixes they said me to use tensorflow version 1.5 but i have to use tensorflow version 2 is there any other ways to fix it?\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nimport tensorflow as tf\r\n", "comments": ["@Mohammedirfan25 \r\nCan you please run below code and share the output [also please share text in place of screenshots next time which will help ither users as well]\r\n\r\nimport tensorflow as tf\r\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\r\n\r\n\r\nPlease refer to this [comment](https://github.com/tensorflow/tensorflow/issues/47245#issuecomment-786245812), and similar issues :[link](https://github.com/tensorflow/tensorflow/issues/40814#issuecomment-663838196), #47002.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "It seems impossible to run \r\n\r\n    print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\r\n\r\nif the tensorflow import breaks already.\r\n\r\nI have that on a node without any GPUs.\r\n\r\n\r\n    - tensorflow==2.6.2\r\n    - tensorflow-estimator==2.6.0", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52897\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52897\">No</a>\n"]}, {"number": 52895, "title": "How to install tensorflow to ARM32 Windows platform? Is there any solution for this problem?", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- ARM32 Windows10\r\n- GPU model and memory:16G\r\n\r\n\r\n\r\n**Describe the problem**\r\nARM base Windows system can't install tensorflow?\r\nIs there any solution for this?\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nCan't install tensorflow\r\n\r\n**Any other info / logs**\r\nCan't install tensorflow on ARM32  Windows10", "comments": ["Hi @alenandry ! Could you check out these threads ? [link1](https://www.tensorflow.org/install/source_windows#install_python_and_the_tensorflow_package_dependencies),[link2](https://stackoverflow.com/questions/45228059/tensorflow-on-32-bit-windows-10-is-not-a-supported-wheel-on-this-platform-pack),[link3](https://stackoverflow.com/questions/52178508/cant-install-tensorflow-on-windows-7-32-bit). Please post on Stackoverflow/[TF forum](https://discuss.tensorflow.org/) for further assistance.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "We don't support ARM architectures at the moment", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52895\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52895\">No</a>\n"]}, {"number": 52894, "title": "Bug: SomeTimes Coredumped using tfjob", "body": "hello, iam using tfjob to train keras model.\r\n\r\nmost of times, they work fine. But some times, it will crash  after train and savemodel.\r\n\r\nour partial train code is here:\r\n\r\n```python\r\n    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"/workspace/model/fit_logs/\", histogram_freq=1)\r\n\r\n    model.fit(\r\n        dataset,\r\n        epochs=epochs,\r\n        verbose=2#,\r\n#         validation_data=test_dataset#,\r\n#         callbacks = [tensorboard_callback]\r\n#         callbacks=[EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)]\r\n    )\r\n\r\n    # checkpoint_path = '/'.join((args.checkpoint_path, save_day, save_hour))\r\n    # if TASK_INDEX == 0:\r\n    #    checkpoint_path = checkpoint_path\r\n    # else:\r\n        # Save to a path that is unique across workers.\r\n    #    checkpoint_path = checkpoint_path + '/worker_tmp_' + str(TASK_INDEX)\r\n\r\n    inputs = tf.keras.layers.Input(shape=(input_length,), dtype=tf.int64, name='input')\r\n    outs = model(inputs)\r\n    mymodel = tf.keras.Model(inputs, outs)\r\n    mymodel.save(checkpoint_path)\r\n\r\n    if TASK_INDEX == 0:\r\n        # tf2onnx\r\n        try:\r\n            onnx_args = OnnxArgs()\r\n            onnx_args.saved_model = checkpoint_path\r\n            onnx_args.output = checkpoint_path + '/deepfm.onnx'\r\n            onnx_args.tag = 'serve'\r\n\r\n\r\n            parse2onnx(onnx_args)\r\n            logging.info(\"Success\")\r\n            logging.info(onnx_args.saved_model)\r\n        except Exception as e:\r\n            logging.error(\"Failed convert\")\r\n            logging.error(str(e))\r\n```\r\nAnd the log is:\r\n![image](https://user-images.githubusercontent.com/10629930/139662542-31221f80-a0de-4c76-b4f5-cfd017612de4.png)\r\n\r\nI get the coredumpe file;\r\n\r\nit show this:\r\n![image](https://user-images.githubusercontent.com/10629930/139662656-6a26ea88-2d49-4472-a1b3-e5b07d801654.png)\r\n\r\n\r\nthe operator log is :\r\n\r\ni don't know the reason and don't know whether it is a tensorflow bug...\r\n![image](https://user-images.githubusercontent.com/10629930/139662899-d21133db-6b1c-4567-ac5d-6811f41f00f4.png)\r\n\r\nAny help will be appreciated... Thanks alot \r\n", "comments": ["Tensorflow Version is 2.6\uff0c and i also try 2.7dev.  But some times They both occur the same coredumped....", "@berlinsaint \r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThank you!", "> @berlinsaint Please post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues) To know more see; https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999 Thank you!\r\n\r\ni thinks it may not be the keras problem...\r\n\r\ni have the same  symptom as the [issue-50853](https://github.com/tensorflow/tensorflow/issues/50853)", "@berlinsaint \r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "> @berlinsaint \n> In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\n> \ni dont know how to reproduce it\uff0cit's strange!  Just in distributed training . And it has nearly the same stack as https://github.com/tensorflow/tensorflow/issues/50853\n\n", "@berlinsaint Without the reproducible code it is difficult for us to replicate the issue from our end. Could you please open this issue in [TF discussion forum](https://discuss.tensorflow.org/) as there is a larger community to help.Thank you!\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52894\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52894\">No</a>\n"]}, {"number": 52893, "title": "Tensorflow2.4 matmul returns different result(CPU)  comparing  numpy & torch matmul", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.4.0\r\n- Python version: 3.6.9\r\n\r\n**Describe the current behavior**\r\n```\r\n>>> tf.matmul(inputs, kernel)\r\n<tf.Tensor: shape=(1, 27, 512), dtype=float32, numpy=\r\narray([[[ 0.28822073, -1.4294956 , -0.98417675, ..., -1.3555392 ,\r\n          1.3087683 ,  1.0613352 ],\r\n        [-0.2037763 ,  0.5733212 ,  0.13983761, ..., -0.27103314,\r\n         -0.47976002, -1.5966026 ],\r\n        [-0.20868134,  0.33820766,  0.3898036 , ...,  0.09645928,\r\n         -0.34314552, -0.85622734],\r\n        ...,\r\n        [ 0.7347749 , -0.20192856, -0.6455916 , ...,  0.8365166 ,\r\n         -0.14322701,  0.32350197],\r\n        [-0.02274738,  0.2568301 ,  0.39510253, ..., -0.6229611 ,\r\n          1.9619648 , -0.9404138 ],\r\n        [ 0.2989933 , -1.4857576 , -1.4279732 , ..., -2.0946026 ,\r\n          1.0505235 ,  0.51986885]]], dtype=float32)>\r\n\r\n>>> np.matmul(inputs, kernel)\r\narray([[[ 0.28822058, -1.4294958 , -0.9841767 , ..., -1.3555391 ,\r\n          1.308768  ,  1.061335  ],\r\n        [-0.20377651,  0.5733212 ,  0.13983764, ..., -0.27103332,\r\n         -0.47975984, -1.5966021 ],\r\n        [-0.20868114,  0.33820775,  0.38980353, ...,  0.09645933,\r\n         -0.34314537, -0.8562276 ],\r\n        ...,\r\n        [ 0.7347748 , -0.20192836, -0.6455917 , ...,  0.83651644,\r\n         -0.14322703,  0.3235021 ],\r\n        [-0.02274731,  0.25683013,  0.39510256, ..., -0.6229611 ,\r\n          1.9619651 , -0.94041383],\r\n        [ 0.29899323, -1.4857576 , -1.4279728 , ..., -2.0946023 ,\r\n          1.0505236 ,  0.5198687 ]]], dtype=float32)\r\n# And in torch\r\n>>> input.matmul(weight.t()).numpy()\r\narray([[[ 0.28822058, -1.4294958 , -0.9841767 , ..., -1.3555391 ,\r\n          1.308768  ,  1.061335  ]],\r\n       [[-0.20377651,  0.5733212 ,  0.13983764, ..., -0.27103332,\r\n         -0.47975984, -1.5966021 ]],\r\n       [[-0.20868114,  0.33820775,  0.38980353, ...,  0.09645933,\r\n         -0.34314537, -0.8562276 ]],\r\n       ...,\r\n       [[ 0.73477507, -0.20192847, -0.6455916 , ...,  0.83651686,\r\n         -0.14322712,  0.32350177]],\r\n       [[-0.02274727,  0.25683028,  0.39510256, ..., -0.62296104,\r\n          1.9619647 , -0.94041365]],\r\n       [[ 0.29899323, -1.4857576 , -1.427973  , ..., -2.0946026 ,\r\n          1.0505236 ,  0.51986873]]], dtype=float32)\r\n```\r\nAs we can see, the number in seventh decimal is different.  TF is 0.28822073, torch and numpy are both 0.28822058.\r\nThe function is very important.I want to know why the error appears and how to fix it. Thank you.\r\n**Describe the expected behavior**\r\nThe results are all the same.\r\nIf someone wants the data(input & weight), I can upload.\r\nps: input shape is 27 * 512, weight shape is 512 * 512\r\n\r\n", "comments": ["@lxsyz ,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code and dataset to reproduce the issue reported here.", "@tilakrayal I'm sorry I can't upload entire code and model. I have uploaded test code and weights in this repo\r\n[https://github.com/lxsyz/temp](https://github.com/lxsyz/temp)\r\njust run `test.py`, and you will see the result is different.\r\n", "@lxsyz ,\r\nI was able to execute the code without any issues.Please find the metrics in gist [here](https://colab.research.google.com/gist/tilakrayal/e2b4e12e4815f9b3a89ccbc057b45e07/52893.ipynb).I was not able to find the mentioned issue(0.28822073) in v2.6.Requesting to test your code in latest tf v2.6.Thanks", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52893\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52893\">No</a>\n"]}, {"number": 52892, "title": "Explanation of tf.keras.layers.CategoryEncoding output_mode='multi_hot' behavior", "body": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/CategoryEncoding\r\n\r\n## Description of issue (what needs changing):\r\n\r\nNeed clarification on the statement below about multi hot encoding.\r\n\r\n> \"multi_hot\": Encodes each sample in the input into a single array of num_tokens size, containing a 1 for each vocabulary term present in the sample. Treats the last dimension as the sample dimension, if input shape is (..., sample_length), output shape will be (..., num_tokens).\r\n\r\n## Clarification\r\n\r\nPlease help understand the definition of **multi hot encoding** of tf.keras.layers.CategoryEncoding and the behavior of ```output_mode='multi_hot'```.\r\n\r\n### Background \r\nAccording to [What exactly is multi-hot encoding and how is it different from one-hot?](https://stats.stackexchange.com/a/467672):\r\n\r\n> If you would use multi-hot-encoding you would first label-encode your classes, thus having only a single number which represents the presence of a class (e.g. 1 for 'dog') and then convert the numerical labels to binary vectors of size log2(5)=3.  \r\n> Examples:\r\n> ```\r\n> 'cat'  = [0,0,0]  \r\n> 'dog'  = [0,0,1]  \r\n> 'fish' = [0,1,0]  \r\n> 'bird' = [0,1,1]  \r\n> 'ant'  = [1,0,0]   \r\n> ```\r\n\r\n### Behaviour of [tf.keras.layers.CategoryEncoding][2]\r\n\r\nThe document says ```num_tokens``` is the total number of tokens the layer should support. \r\n\r\n> ### args\r\n> #### num_tokens\r\n> The total number of tokens the layer should support. All inputs to the layer must integers in the range 0 <= value < num_tokens, or an error will be thrown.\r\n> #### output_mode\r\n> * \"one_hot\": Encodes each individual element in the input into an array of num_tokens size, containing a 1 at the element index. If the last dimension is size 1, will encode on that dimension. If the last dimension is not size 1, will append a new dimension for the encoded output.\r\n> * \"multi_hot\": Encodes each sample in the input into **a single array of num_tokens size, containing a 1 for each vocabulary term present in the sample**. Treats the last dimension as the sample dimension, if input shape is (..., sample_length), output shape will be (..., num_tokens).\r\n\r\nAccording to the definitions of multi hot encoding above, I expected ```tf.keras.layers.CategoryEncoding(num_tokens=5, output_mode=\"multi_hot\")``` encodes 5 tokens into an array of size 3. \r\n\r\nHowever, the document says \"multi_hot\" encodes each sample into **a single array of num_tokens size**, containing a 1 for each vocabulary term present in the sample, and behaves as such.\r\n\r\n\r\n```\r\ndataset = tf.data.Dataset.from_tensor_slices(tf.constant(['cat', 'dog', 'fish', 'bird']))\r\n\r\nlookup = tf.keras.layers.StringLookup(max_tokens=5, oov_token='[UNK]')\r\nlookup.adapt(dataset)\r\nlookup.get_vocabulary()\r\n---\r\n['[UNK]', 'fish', 'dog', 'cat', 'bird']\r\n\r\nmhe = tf.keras.layers.CategoryEncoding(num_tokens=lookup.vocabulary_size(), output_mode=\"multi_hot\")\r\nprint(f\"cat: {mhe(lookup(tf.constant('cat'))).numpy()}\")\r\nprint(f\"dog: {mhe(lookup(tf.constant('dog'))).numpy()}\")\r\n---\r\ncat: [0. 0. 0. 1. 0.]\r\ndog: [0. 0. 1. 0. 0.]\r\n```\r\n\r\nWhich has no difference from One Hot En coding.\r\n\r\n```\r\nohe = tf.keras.layers.CategoryEncoding(num_tokens=lookup.vocabulary_size(), output_mode=\"one_hot\")\r\nprint(f\"cat: {ohe(lookup(tf.constant('cat'))).numpy()}\")\r\nprint(f\"dog: {ohe(lookup(tf.constant('dog'))).numpy()}\")\r\n---\r\ncat: [0. 0. 0. 1. 0.]\r\ndog: [0. 0. 1. 0. 0.]\r\n```\r\n\r\nFor multi value inputs, multi_hot only handles the 1st value.\r\n```\r\nprint(ohe(lookup(tf.constant(['cat', 'dog']))).numpy())\r\n---\r\n[[0. 0. 0. 1. 0.]\r\n [0. 0. 1. 0. 0.]]\r\n\r\nprint(mhe(lookup(tf.constant(['cat', 'dog']))).numpy())\r\n---\r\n[0. 0. 1. 1. 0.]\r\n```\r\n\r\nTo handle multiple inputs, need to be 2D array.\r\n```\r\nprint(mhe(lookup(tf.constant([['cat'], ['dog']]))).numpy())\r\n---\r\n[[0. 0. 0. 1. 0.]\r\n [0. 0. 1. 0. 0.]]\r\n```\r\n\r\nApparently the definition of **mluti hot encoding** of ```tf.keras.layers.CategoryEncoding``` is not the same with the one in [What exactly is multi-hot encoding and how is it different from one-hot?](https://stats.stackexchange.com/a/467672).\r\n\r\n\r\n  [1]: https://www.tensorflow.org/tutorials/structured_data/preprocessing_layers\r\n  [2]: https://www.tensorflow.org/api_docs/python/tf/keras/layers/CategoryEncoding", "comments": ["Hi @Saduf2019 ! Could you please look into this issue ?", "@oonisim \r\nThe Document clearly says: Encodes each sample in the input into a single array of num_tokens size, containing a 1 for each vocabulary term present in the sample. Treats the last dimension as the sample dimension, if input shape is (..., sample_length), output shape will be (..., num_tokens)\r\n\r\nthis is not a bug or feat Request please close this issue in case of further queries please create one in tf discussion forum as there is a larger community there to response.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 52891, "title": "Add security updates to relnotes", "body": null, "comments": []}, {"number": 52890, "title": "Remove six.PY2", "body": null, "comments": ["Can you do this for all files, please?\r\n\r\nIf it gets too large, then we can split per directory, maybe around 10 files per PR?", "Hm. This might be too large now.\r\nBefore I do that, can you please trigger CI on this PR? I cannot build from source, and just want to make sure everything works.", "This looks good to me and not too large. So let's try first with just one PR."]}, {"number": 52889, "title": "Upper bound `tensorflow_estimator` to match release", "body": null, "comments": []}, {"number": 52888, "title": "Handpose model doesn't get image data from React Native Canvas", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- Expo, Windows\r\n- Xiaomi Redmi note 9 pro 5g\r\n\r\npackage.json:\r\n`{\r\n  \"main\": \"node_modules/expo/AppEntry.js\",\r\n  \"scripts\": {\r\n    \"start\": \"expo start\",\r\n    \"android\": \"expo start --android\",\r\n    \"ios\": \"expo start --ios\",\r\n    \"web\": \"expo start --web\",\r\n    \"eject\": \"expo eject\"\r\n  },\r\n  \"dependencies\": {\r\n    \"@react-native-async-storage/async-storage\": \"~1.15.0\",\r\n    \"@tensorflow-models/handpose\": \"^0.0.7\",\r\n    \"@tensorflow/tfjs\": \"^3.9.0\",\r\n    \"@tensorflow/tfjs-backend-webgl\": \"^3.9.0\",\r\n    \"@tensorflow/tfjs-converter\": \"^3.9.0\",\r\n    \"@tensorflow/tfjs-core\": \"^3.9.0\",\r\n    \"@tensorflow/tfjs-react-native\": \"^0.7.0\",\r\n    \"async-storage\": \"^0.1.0\",\r\n    \"base-64\": \"^1.0.0\",\r\n    \"expo\": \"~42.0.1\",\r\n    \"expo-camera\": \"~11.2.2\",\r\n    \"expo-gl\": \"^10.4.2\",\r\n    \"expo-gl-cpp\": \"~10.4.1\",\r\n    \"expo-image-picker\": \"~10.2.2\",\r\n    \"expo-status-bar\": \"~1.0.4\",\r\n    \"react\": \"16.13.1\",\r\n    \"react-dom\": \"16.13.1\",\r\n    \"react-native\": \"https://github.com/expo/react-native/archive/sdk-42.0.0.tar.gz\",\r\n    \"react-native-canvas\": \"^0.1.38\",\r\n    \"react-native-fs\": \"^2.18.0\",\r\n    \"react-native-get-real-path\": \"https://github.com/Wraptime/react-native-get-real-path.git\",\r\n    \"react-native-web\": \"~0.13.12\",\r\n    \"react-native-webview\": \"11.6.2\",\r\n    \"three\": \"^0.133.1\"\r\n  },\r\n  \"devDependencies\": {\r\n    \"@babel/core\": \"^7.9.0\",\r\n    \"@types/react\": \"~16.9.35\",\r\n    \"@types/react-native\": \"~0.63.2\",\r\n    \"@types/react-native-canvas\": \"^0.1.8\",\r\n    \"@types/three\": \"^0.133.0\",\r\n    \"typescript\": \"~4.0.0\"\r\n  },\r\n  \"private\": true\r\n}\r\n`\r\n\r\ncode:\r\n`\r\nimport React, {Component} from 'react';\r\nimport {Image, ScrollView, StatusBar, View, StyleSheet, Button, Platform} from 'react-native';\r\nimport * as ImagePicker from 'expo-image-picker';\r\n\r\nimport Canvas, {Image as CanvasImage} from 'react-native-canvas';\r\n\r\nimport * as tf from '@tensorflow/tfjs';\r\nimport '@tensorflow/tfjs-react-native';\r\nimport * as handpose from \"@tensorflow-models/handpose\";\r\nimport {decode as atob, encode as btoa} from \"base-64\";\r\n\r\nconst Example = ({children}) => (\r\n    <View style={styles.example}>\r\n        <View style={styles.exampleLeft}>{children}</View>\r\n    </View>\r\n);\r\n\r\nexport default class App extends Component {\r\n    constructor(props) {\r\n        super(props);\r\n\r\n        this.state = {\r\n            image: null,\r\n            tfIsReady: false, model: null\r\n        };\r\n\r\n        this.handleImageData = this.handleImageData.bind(this);\r\n        this.pickImage = this.pickImage.bind(this);\r\n        this.processImage = this.processImage.bind(this);\r\n        this.canvas = React.createRef();\r\n    }\r\n\r\n    async componentDidMount() {\r\n        await (async () => {\r\n            if (Platform.OS !== 'web') {\r\n                const {status} = await ImagePicker.requestMediaLibraryPermissionsAsync();\r\n                if (status !== 'granted') {\r\n                    alert('Sorry, we need camera roll permissions to make this work!');\r\n                }\r\n            }\r\n        })();\r\n\r\n        await tf.ready();\r\n        // Signal to the app that tensorflow.js can now be used.\r\n        this.setState({\r\n            isTfReady: true,\r\n        });\r\n\r\n        console.log(\"tfReady\");\r\n\r\n        this.setState({model: await handpose.load()});\r\n\r\n        console.log(\"handposeLoad\");\r\n    };\r\n\r\n    handleImageData() {\r\n        const image = this.state.image;\r\n        const canvas = this.canvas.current;\r\n        const model = this.state.model;\r\n\r\n        if (canvas && image && model) {\r\n\r\n            if (!(canvas instanceof Canvas)) {\r\n                return;\r\n            }\r\n\r\n            console.log(\"Drawing picture\");\r\n            const img = new CanvasImage(canvas);\r\n            let aspectRatio = image.width / image.height;\r\n\r\n            let width = 200;\r\n            let height = 200;\r\n\r\n            canvas.width = width;\r\n            canvas.height = height;\r\n\r\n            const context = canvas.getContext('2d');\r\n\r\n\r\n            img.src = 'data:image/png;base64,' + image.base64;\r\n            img.addEventListener('load', () => {\r\n                context.drawImage(img, 0, 0, width, height);\r\n            });\r\n\r\n        }\r\n    };\r\n\r\n    async processImage() {\r\n        const canvas = this.canvas.current;\r\n        const model = this.state.model;\r\n        const image = this.state.image;\r\n\r\n        if (model && canvas) {\r\n            console.log()\r\n            const context = canvas.getContext('2d');\r\n\r\n            let imageData = await context.getImageData(0, 0, image.width, image.height);\r\n\r\n            const hand = await model.estimateHands(imageData);\r\n            console.log(hand);\r\n        }\r\n    }\r\n\r\n    async pickImage() {\r\n        let result = await ImagePicker.launchImageLibraryAsync({\r\n            mediaTypes: ImagePicker.MediaTypeOptions.All,\r\n            allowsEditing: true,\r\n            quality: 1,\r\n            base64: true\r\n        });\r\n\r\n        console.log(result.width);\r\n\r\n        if (!result.cancelled) {\r\n            this.setState({image: result})\r\n        }\r\n    };\r\n\r\n    render() {\r\n        return (\r\n            <View style={styles.container}>\r\n                <StatusBar hidden={true}/>\r\n                <Button title=\"Pick an image from camera roll\" onPress={this.pickImage}/>\r\n                <Button title=\"Draw image\" onPress={this.handleImageData}/>\r\n                <Button title=\"Process image\" onPress={this.processImage}/>\r\n                <ScrollView style={styles.examples}>\r\n                    <Example>\r\n                        <Canvas ref={this.canvas}/>\r\n                    </Example>\r\n                </ScrollView>\r\n            </View>\r\n        );\r\n    }\r\n}\r\n\r\nconst commonStyles = StyleSheet.create({\r\n    full: {\r\n        left: 0,\r\n        width: '100%',\r\n        height: '100%',\r\n    },\r\n    cell: {\r\n        flex: 1,\r\n        padding: 10,\r\n        justifyContent: 'center',\r\n        alignItems: 'center',\r\n    },\r\n});\r\n\r\nconst styles = StyleSheet.create({\r\n    container: {\r\n        backgroundColor: 'white',\r\n        ...commonStyles.full,\r\n    },\r\n    examples: {\r\n        ...commonStyles.full,\r\n        padding: 5,\r\n        paddingBottom: 0,\r\n    },\r\n    example: {\r\n        paddingBottom: 5,\r\n        flex: 1,\r\n        flexDirection: 'row',\r\n    },\r\n    exampleLeft: {\r\n        ...commonStyles.cell,\r\n    },\r\n    exampleRight: {\r\n        ...commonStyles.cell,\r\n    },\r\n});\r\n\r\n`\r\n\r\n**Describe the current behavior**\r\nGot error: \r\n`[Unhandled promise rejection: Error: pixels passed to tf.browser.fromPixels() must be either an HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData in browser, or OffscreenCanvas, ImageData in webworker or {data: Uint32\r\nArray, width: number, height: number}, but was ImageData]\r\nat node_modules\\@tensorflow\\tfjs-core\\dist\\tf-core.node.js:8871:14 in fromPixels_\r\nat node_modules\\@tensorflow\\tfjs-core\\dist\\tf-core.node.js:5406:25 in f2\r\nat node_modules\\@tensorflow-models\\handpose\\dist\\index.js:170:40 in tf.tidy$argument_0\r\nat node_modules\\@tensorflow\\tfjs-core\\dist\\tf-core.node.js:4394:23 in scopedRun$argument_2\r\nat node_modules\\@tensorflow\\tfjs-core\\dist\\tf-core.node.js:4404:23 in Engine.prototype.scopedRun\r\nat node_modules\\@tensorflow-models\\handpose\\dist\\index.js:168:32 in __generator$argument_1\r\nat node_modules\\@tensorflow-models\\handpose\\dist\\index.js:48:17 in step\r\nat node_modules\\@tensorflow-models\\handpose\\dist\\index.js:23:13 in <anonymous>\r\nat node_modules\\react-native\\node_modules\\promise\\setimmediate\\core.js:45:6 in tryCallTwo\r\nat node_modules\\react-native\\node_modules\\promise\\setimmediate\\core.js:200:22 in doResolve\r\nat node_modules\\react-native\\node_modules\\promise\\setimmediate\\core.js:66:11 in Promise\r\nat node_modules\\@tensorflow-models\\handpose\\dist\\index.js:19:11 in <anonymous>\r\nat App.tsx:98:31 in processImage\r\nat node_modules\\regenerator-runtime\\runtime.js:63:36 in tryCatch\r\nat node_modules\\regenerator-runtime\\runtime.js:294:29 in invoke\r\nat node_modules\\regenerator-runtime\\runtime.js:63:36 in tryCatch\r\nat node_modules\\regenerator-runtime\\runtime.js:155:27 in invoke\r\nat node_modules\\regenerator-runtime\\runtime.js:165:18 in PromiseImpl.resolve.then$argument_0\r\nat node_modules\\react-native\\node_modules\\promise\\setimmediate\\core.js:37:13 in tryCallOne\r\nat node_modules\\react-native\\node_modules\\promise\\setimmediate\\core.js:123:24 in setImmediate$argument_0\r\nat node_modules\\react-native\\Libraries\\Core\\Timers\\JSTimers.js:130:14 in _callTimer\r\nat node_modules\\react-native\\Libraries\\Core\\Timers\\JSTimers.js:181:14 in _callImmediatesPass\r\nat node_modules\\react-native\\Libraries\\Core\\Timers\\JSTimers.js:441:30 in callImmediates\r\nat node_modules\\react-native\\Libraries\\BatchedBridge\\MessageQueue.js:387:6 in __callImmediates\r\nat node_modules\\react-native\\Libraries\\BatchedBridge\\MessageQueue.js:135:6 in __guard$argument_0\r\nat node_modules\\react-native\\Libraries\\BatchedBridge\\MessageQueue.js:364:10 in __guard\r\nat node_modules\\react-native\\Libraries\\BatchedBridge\\MessageQueue.js:134:4 in flushedQueue\r\n`\r\n\r\n**Describe the expected behavior**\r\nIt should happen estimation hands on Image Data\r\n", "comments": ["@svzj95 \r\nIn order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose),Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52888\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52888\">No</a>\n"]}, {"number": 52886, "title": "Temporal Attention on LSTM Layer?", "body": "Hi, \r\n\r\n**I want to implement Attention on LSTM layer. Let me put the detail description:**\r\n\r\nwe analyze the 8 hidden states of the LSTM that represent the embeddings for the different parts of an input frame. We consider the first 7 hidden states as the historical temporal\r\ncontext and learn 7 weights corresponding to these states:\r\npast context = [h1;h2;h3;:::h7] (1) \r\n\r\ncurrent = h8 (2)\r\n\r\ntransformed context = tanh(W1 \u00d7past context + b1) (3)\r\n\r\nweights = softmax(W2 \u00d7transformed context + b2) (4)\r\n\r\nfinal embedding = past context\u00d7weights + current (5)\r\n\r\nb1 and b2 denote the biases in the two linear layers, and W1 and\r\nW2 represent the 2D matrices in the linear layers. We initially\r\napply a linear transformation accompanied by a tanh linearity\r\ntransforming each of these seven vectors of size 128 into seven\r\nnew vectors of size 128 (Eq. 3). Another linear transformation\r\nconverts these 8 vectors each to size 1 essentially giving us\r\nscores for each of the hidden states. These scores are then\r\npassed through a softmax to give the final set of weights (Eq.\r\n4). These weights are used to calculate a weighted sum of all\r\nthe 8 hidden states to give the final embedding for the past\r\ncontext. This past context is added to the last hidden state\r\nto give the final embedding for the input frame (Eq. 5). This\r\nfinal embedding is used for classification.\r\n\r\n**Please verify my code according to description. Is it right?**\r\n\r\n\r\n    from tensorflow.keras.layers import Input, Dense, Lambda, Dot, Activation, Concatenate\r\n    from tensorflow.keras.layers import Layer\r\n    import tensorflow as tf\r\n    \r\n    \r\n    def attention(lstm_hidden_status):  # Tensor(\"lstm_1/transpose_1:0\", shape=(?, 8, 128), dtype=float32)\r\n        hidden_size = lstm_hidden_status.get_shape().as_list()  # get all dimensions all list\r\n        hidden_size = int(hidden_size[2]) # 128\r\n        # feed to Forward Neural Network\r\n        h_t = Lambda(lambda x: x[:, -1, :], output_shape=(hidden_size,), name='last_hidden_state')(lstm_hidden_status) # Tensor(\"last_hidden_state/strided_slice:0\", shape=(?, 128), dtype=float32)\r\n        transformed_context = Dense(hidden_size, use_bias=True, activation='tanh', name='transformed_context_vec')(\r\n            lstm_hidden_status) # Tensor(\"transformed_context_vec/Tanh:0\", shape=(?, 8, 128), dtype=float32)\r\n\r\n        score = Dot(axes=[1, 2], name='attention_score')([h_t, transformed_context]) # Tensor(\"attention_score/Squeeze:0\", shape=(?, 8), dtype=float32)\r\n        attention_weights = Dense(8, use_bias=True, activation='softmax', name='attention_weight')(score) # Tensor(\"attention_weight/Softmax:0\", shape=(?, 8), dtype=float32)\r\n        context_vector = Dot(axes=[1, 1], name='context_vector')([lstm_hidden_status, attention_weights]) # Tensor(\"context_vector/Squeeze:0\", shape=(?, 128), dtype=float32)\r\n        new_context_vector = context_vector + h_t # Tensor(\"add:0\", shape=(?, 128), dtype=float32)\r\n        return new_context_vector \r\n\r\nSpecifically, I am confused here in line `score = Dot(axes=[1, 2], name='attention_score')([h_t, transformed_context])`, Why we are taking Dot product? All the debug outputs are attached with each line. ", "comments": ["Hi @Nafees-060 ! \r\nThis is not a bug or feature request, for any further queries you may open this issue in tf discussion [forum ](https://discuss.tensorflow.org/)as there is a larger community there.Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52886\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52886\">No</a>\n"]}, {"number": 52885, "title": "Addition of a new activation function: Mish in comps", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.6.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.** Addition of a new activation function Mish.\r\n\r\n**Will this change the current api? How?**Yes. Addition of a new activation function in the comps API. \r\n\r\n**Who will benefit with this feature?**As described in the following paper, Mish acts as a better activation function in comparison to LeakyReLU and outperforming it in some scenarios. Addition of this new activation functions for user to use in various models will be a huge advantage.\r\n[Link to paper](https://arxiv.org/pdf/1908.08681.pdf)\r\n\r\n**Any Other info.**\r\n", "comments": ["As of now `Mish` is already available in [Tensorflow Addons](https://www.tensorflow.org/addons/api_docs/python/tfa/activations/mish), and you can still make use of the same for now.\r\nMoving this to core could take some time and few factors like below.\r\n`TensorFlow Addons is a repository of contributions that conform to well-established API patterns, but implement new functionality not available in core TensorFlow. TensorFlow natively supports a large number of operators, layers, metrics, losses, and optimizers. However, in a fast moving field like ML, there are many interesting new developments that cannot be integrated into core TensorFlow (because their broad applicability is not yet clear, or it is mostly used by a smaller subset of the community).`\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n"]}, {"number": 52884, "title": "Ability of flow, flowFromDirectory and flowFromDataFrame in ImageDataGenerator to self generate class weights", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.6.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.** Addition of new attribute to generator in order to compute class weights in case of a class imbalanced dataset.\r\n\r\n**Will this change the current api? How?** Yes. It will add a new attribute to the flow, flowFromDirectory, flowFromDataFrame and a method that will compute class weights based on strategy provided by the user as in scikitlearn compute class weights.\r\n\r\n**Who will benefit with this feature?** It will benefit users with an imbalanced dataset to be able to compute the class weights within TensorFlow and not rely on any other library to compute class weights. \r\n\r\n**Any Other info.** Will be really helpful for users.\r\n", "comments": ["@MrinalTyagi ,\r\nCan you please elaborate about your Feature. Also, please specify the Use Cases for this feature. Thanks!", "Addition of a new attribute and a method that will be available to the objects of this class. If the user wants to use class weights in model training then this attribute can directly be used rather than relying on any other library like scikit learn or method to compute class weights. This will be very useful in case of class imbalanced dataset as it will fasten up the process of training a model as well as they don't have to spend time searching how to get class weights. It will be also helpful for beginners who have very less knowledge regarding class imbalance issue and how to solve it.", "Hi, Thanks for this feature request, could you please open this feature request in [keras repo](https://github.com/keras-team/keras/issues) since `ImageDataGenerator` comes under tf.keras and we can track this separately there. ", "sure"]}, {"number": 52883, "title": "AttributeError in tensorflowjs wizard with tensorflow_estimator version 2.7.0 (but can be fixed by downgrading modules)", "body": "**System information**\r\n- Manjaro Linux x86_64\r\n- TensorFlow installed from anaconda (implicitly thorugh `pip install \"tensorflowjs[wizard]\"`)\r\n- TensorFlow version : 2.6.0\r\n- Python version: 3.6.13\r\n- CUDA/cuDNN version: cuda_11.4.r11.4\r\n- GPU model and memory: NVIDIA GeForce GTX 1660 Ti, 6GB memory\r\n\r\n**Current Behavior**\r\nWhen I execute `tensorflowjs_wizard`, I get the following output:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/raka/.conda/envs/tfjs_error/bin/tensorflowjs_wizard\", line 5, in <module>\r\n    from tensorflowjs.converters.wizard import pip_main\r\n  File \"/home/raka/.conda/envs/tfjs_error/lib/python3.6/site-packages/tensorflowjs/__init__.py\", line 21, in <module>\r\n    from tensorflowjs import converters\r\n  File \"/home/raka/.conda/envs/tfjs_error/lib/python3.6/site-packages/tensorflowjs/converters/__init__.py\", line 21, in <module>\r\n    from tensorflowjs.converters.converter import convert\r\n  File \"/home/raka/.conda/envs/tfjs_error/lib/python3.6/site-packages/tensorflowjs/converters/converter.py\", line 37, in <module>\r\n    from tensorflowjs.converters import tf_saved_model_conversion_v2\r\n  File \"/home/raka/.conda/envs/tfjs_error/lib/python3.6/site-packages/tensorflowjs/converters/tf_saved_model_conversion_v2.py\", line 39, in <module>\r\n    import tensorflow_hub as hub\r\n  File \"/home/raka/.conda/envs/tfjs_error/lib/python3.6/site-packages/tensorflow_hub/__init__.py\", line 88, in <module>\r\n    from tensorflow_hub.estimator import LatestModuleExporter\r\n  File \"/home/raka/.conda/envs/tfjs_error/lib/python3.6/site-packages/tensorflow_hub/estimator.py\", line 62, in <module>\r\n    class LatestModuleExporter(tf.compat.v1.estimator.Exporter):\r\n  File \"/home/raka/.conda/envs/tfjs_error/lib/python3.6/site-packages/tensorflow/python/util/lazy_loader.py\", line 62, in __getattr__\r\n    module = self._load()\r\n  File \"/home/raka/.conda/envs/tfjs_error/lib/python3.6/site-packages/tensorflow/python/util/lazy_loader.py\", line 45, in _load\r\n    module = importlib.import_module(self.__name__)\r\n  File \"/home/raka/.conda/envs/tfjs_error/lib/python3.6/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"/home/raka/.conda/envs/tfjs_error/lib/python3.6/site-packages/tensorflow_estimator/__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator._api.v1 import estimator\r\n  File \"/home/raka/.conda/envs/tfjs_error/lib/python3.6/site-packages/tensorflow_estimator/_api/v1/estimator/__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator._api.v1.estimator import experimental\r\n  File \"/home/raka/.conda/envs/tfjs_error/lib/python3.6/site-packages/tensorflow_estimator/_api/v1/estimator/experimental/__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator.python.estimator.canned.dnn import dnn_logit_fn_builder\r\n  File \"/home/raka/.conda/envs/tfjs_error/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py\", line 27, in <module>\r\n    from tensorflow_estimator.python.estimator import estimator\r\n  File \"/home/raka/.conda/envs/tfjs_error/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 70, in <module>\r\n    @doc_controls.inheritable_header(\"\"\"\\\r\nAttributeError: module 'tensorflow.tools.docs.doc_controls' has no attribute 'inheritable_header'\r\n```\r\n\r\n**Expected Behavior**\r\nThe expected behavior is the output of the `tensorflowjs_wizard`  command as documented [here](https://github.com/tensorflow/tfjs/blob/master/tfjs-converter/README.md)\r\nThe error seems to have been caused by `inheritable_header` which is called from `tensorflow_estimator.python.estimator` as seen by log above. [This commit](https://github.com/tensorflow/estimator/commit/1cf920e090b02c6b3186b66a2bb2e0114476db40) shows, that the call from the estimator module was recently added with the 2.7.0 version which released yesterday.\r\n\r\n**How I currently solved it for me**\r\n\r\nThrough downgrading tensorflow-estimator to 2.6.0 and tensorflowjs to 3.9.0 I was able to get the command `tensorflowjs_wizard` to **behave as expected**. I downgraded the python packages with the following command:\r\n\r\n```\r\npip install --upgrade tensorflow-estimator==2.6.0\r\npip install --upgrade tensorflowjs==3.9.0\r\n```\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\nI don't know how to fix this issue because how I solved my issue was through manual downgrading. Maybe someone who knows the code better knows what to do.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```bash\r\n# Assuming you have already installed conda and are currently in no environment\r\nconda create --name tfjs python=3.6\r\nconda activate tfjs\r\npip install tensorflowjs[wizard]\r\n# Here you have to refresh the terminal somehow\r\ntensorflowjs_wizard\r\n```\r\n[edit: forgot to add the tensorflow version]", "comments": ["Looks the problem is in wrong dependency in tensorflow 2.6.0. It has tensorflow-estimator~=2.6, while it shall be tensorflow-estimator~=2.6.0.\r\nSimilar thing will happen to keras, when it is not in rc phase anymore, as the same dependency (~=2.6) is set there", "This is also breaking our TFX pipeline in BigQueryExampleGen running in dataflow -- do you know if this is going to be fixed by just releasing tensorflow 2.7, or will the version be pinned in 2.6?", "Hi @Rakagami! Please look at these similar issues . [link1](https://stackoverflow.com/questions/69794473/module-tensorflow-tools-docs-doc-controls-has-no-attribute-inheritable-header),[link2](https://stackoverflow.com/questions/69788776/problem-importing-tensorflow-hub-module-tensorflow-tools-docs-doc-controls-ha) please post this issue here in[ tfjs ](https://github.com/tensorflow/tfjs)repository to proceed further. Thank you.", "The behavior changed a bit since the dependency was changed. `pip install tensorflowjs[wizard]` now installs `tensorflow-estimator` 2.6.0 on default. `tensorflowjs_wizard` still throws an error which I documented in [this new issue](https://github.com/tensorflow/tfjs/issues/5805) in the tfjs repository. I think this issue can be closed here.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52883\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52883\">No</a>\n"]}, {"number": 52882, "title": "tf.nn.batch_normalization and tf.keras.layers.BatchNormalization outputs gives a diff (10^-2) range", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 20.04\r\n\r\nI have implemented a classification model , which has Batchnormalization layers into it. While training the model , i used ```tf.keras.layers.BatchNormalization``` layer for training. Then manually extracted the bn weights (gamma, beta, mean , var) from checkpoint file and called the bn using ```tf.nn.batch_normalization``` layer using above statistics for inference. I observed a drop in testing accuracy (~75%) as compared to the scenario where i load the weights in the model using keras itself ```model.load_weights(chkpnt_file)``` (~92%).   \r\nThough if i replace the ```tf.nn.batch_normalization``` call to keras bn layer call by calling ```set_weights``` function , both the cases gived 0.0 diff, which apprently led me to beleive that there is diff in both the calls while the input and bn_weights are exactly same. epsilon is also same.  \r\n\r\n**Standalone code to reproduce the issue**\r\nPlease refer to this colab notebook(https://colab.research.google.com/drive/1nysYyCR5Ay_jkPlh1WD9A1Mf01eVvhMu? usp=sharing) for a small example. Here the error is coming to be a margin of 10^-2 (which i think is also big given all inputs are same) , but in my project there is huge diff.", "comments": ["@yogeesh-alphaics \r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThank you!", "okay thanks for the update @sushreebarsa ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52882\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52882\">No</a>\n"]}, {"number": 52881, "title": "Disable failing test", "body": null, "comments": []}, {"number": 52880, "title": "Disable failing test", "body": null, "comments": []}, {"number": 52878, "title": "Disable failing test", "body": null, "comments": []}, {"number": 52877, "title": "Update version numbers for TensorFlow 2.5.2", "body": "Before merging this PR, please double check that it has correctly updated\n`core/public/version.h`, `tools/pip_package/setup.py`, and\n`tensorflow/tensorflow.bzl`. Also review the execution notes below:\n\n```\nMajor: 2 -> 2\nMinor: 5 -> 5\nPatch: 1 -> 2\n\nNo lingering old version strings \"2.5.1\" found in source directory \n\"tensorflow/\". Good.\nNo lingering old version strings \"2.5.1\" found in source directory \n\"tensorflow/\". Good.\n```", "comments": []}, {"number": 52876, "title": "Update version numbers for TensorFlow 2.4.4", "body": "Before merging this PR, please double check that it has correctly updated\n`core/public/version.h`, `tools/pip_package/setup.py`, and\n`tensorflow/tensorflow.bzl`. Also review the execution notes below:\n\n```\nMajor: 2 -> 2\nMinor: 4 -> 4\nPatch: 3 -> 4\n\nWARNING: Below are potentially instances of lingering old version string \n\"2.4.3\" in source directory \"tensorflow/\" that are not updated by this script. \nPlease check them manually!\ntensorflow/lite/tools/pip_package/setup_with_bazel.py:69:2.4.3\ntensorflow/lite/tools/pip_package/setup.py:223:2.4.3\ntensorflow/lite/g3doc/tutorials/model_maker_question_answer.ipynb:287:2.4.3\ntensorflow/lite/g3doc/tutorials/model_maker_image_classification.ipynb:210:2.4.3\ntensorflow/lite/g3doc/tutorials/model_maker_text_classification.ipynb:207:2.4.3\ntensorflow/workspace.bzl:1138:2.4.3\ntensorflow/workspace.bzl:1139:2.4.3\ntensorflow/workspace.bzl:1142:2.4.3\n\nWARNING: Below are potentially instances of lingering old version string \n\"2.4.3\" in source directory \"tensorflow/\" that are not updated by this script. \nPlease check them manually!\ntensorflow/lite/tools/pip_package/setup_with_bazel.py:69:2.4.3\ntensorflow/lite/tools/pip_package/setup.py:223:2.4.3\ntensorflow/lite/g3doc/tutorials/model_maker_question_answer.ipynb:287:2.4.3\ntensorflow/lite/g3doc/tutorials/model_maker_image_classification.ipynb:210:2.4.3\ntensorflow/lite/g3doc/tutorials/model_maker_text_classification.ipynb:207:2.4.3\ntensorflow/workspace.bzl:1138:2.4.3\ntensorflow/workspace.bzl:1139:2.4.3\ntensorflow/workspace.bzl:1142:2.4.3\n```", "comments": []}, {"number": 52875, "title": "Update version numbers for TensorFlow 2.6.1", "body": "Before merging this PR, please double check that it has correctly updated\n`core/public/version.h`, `tools/pip_package/setup.py`, and\n`tensorflow/tensorflow.bzl`. Also review the execution notes below:\n\n```\nMajor: 2 -> 2\nMinor: 6 -> 6\nPatch: 0 -> 1\n\nWARNING: Below are potentially instances of lingering old version string \n\"2.6.0\" in source directory \"tensorflow/\" that are not updated by this script. \nPlease check them manually!\ntensorflow/python/keras/__init__.py:33:2.6.0\ntensorflow/java/maven/tensorflow-hadoop/pom.xml:17:2.6.0\ntensorflow/tools/ci_build/release/requirements_common.txt:27:2.6.0\ntensorflow/tools/ci_build/release/requirements_common.txt:28:2.6.0\ntensorflow/tools/ci_build/release/requirements_common.txt:29:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:80:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:149:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:155:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:161:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:227:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:334:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:355:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:356:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:357:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:358:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:359:2.6.0\ntensorflow/workspace2.bzl:1051:2.6.0\ntensorflow/workspace2.bzl:1052:2.6.0\ntensorflow/workspace2.bzl:1055:2.6.0\n\nWARNING: Below are potentially instances of lingering old version string \n\"2.6.0\" in source directory \"tensorflow/\" that are not updated by this script. \nPlease check them manually!\ntensorflow/python/keras/__init__.py:33:2.6.0\ntensorflow/java/maven/tensorflow-hadoop/pom.xml:17:2.6.0\ntensorflow/tools/ci_build/release/requirements_common.txt:27:2.6.0\ntensorflow/tools/ci_build/release/requirements_common.txt:28:2.6.0\ntensorflow/tools/ci_build/release/requirements_common.txt:29:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:80:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:149:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:155:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:161:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:227:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:334:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:355:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:356:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:357:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:358:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:359:2.6.0\ntensorflow/workspace2.bzl:1051:2.6.0\ntensorflow/workspace2.bzl:1052:2.6.0\ntensorflow/workspace2.bzl:1055:2.6.0\n```", "comments": []}]