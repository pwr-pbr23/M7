[{"number": 51210, "title": "Add missing validation to `RaggedTensorToSparse`.", "body": "There needs to be a check that the splits allow for valid ragged tensors.\r\n\r\nPiperOrigin-RevId: 387712169\r\nChange-Id: I2499175324b82b65d159a260c7f83b98ceb5cc7d", "comments": []}, {"number": 51209, "title": "Can Mask_rcnn being converted into fully integer quantized TF Lite model?  Got error: Some ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select  TF Select ops: CropAndResize during converting.", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution:  Linux Ubuntu 18.04\r\n- TensorFlow installation: pip package\r\n- TensorFlow library version: 2.7.0-dev20210804\r\n\r\n### 2. Code\r\n\r\nProvide code to help us reproduce your issues using one of the following options:\r\n\r\n#### Option B: provide a link to a custom end-to-end colab\r\n\r\n\r\nPlease see code to reproduce the issue in Colab [here](https://colab.research.google.com/drive/1cHh5BYiKkm1At6eStDQnwcg9xDK5E3Ci#scrollTo=bXcd5l9x6A07)\r\n\r\nPretrained mask_rcnn model is downloaded from: [link](https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1)\r\n\r\n### 5. (optional) Any other info / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\nConverterError: <unknown>:0: error: loc(callsite(callsite(\"CropAndResize/CropAndResize@__inference___call___39142\" at \"StatefulPartitionedCall@__inference_signature_wrapper_44195\") at \"StatefulPartitionedCall\")): 'tf.CropAndResize' op is neither a custom op nor a flex op\r\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\r\n<unknown>:0: note: loc(callsite(callsite(\"CropAndResize/CropAndResize@__inference___call___39142\" at \"StatefulPartitionedCall@__inference_signature_wrapper_44195\") at \"StatefulPartitionedCall\")): Error code: ERROR_NEEDS_FLEX_OPS\r\n<unknown>:0: error: loc(callsite(callsite(\"CropAndResize_1/CropAndResize@__inference___call___39142\" at \"StatefulPartitionedCall@__inference_signature_wrapper_44195\") at \"StatefulPartitionedCall\")): 'tf.CropAndResize' op is neither a custom op nor a flex op\r\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\r\n<unknown>:0: note: loc(callsite(callsite(\"CropAndResize_1/CropAndResize@__inference___call___39142\" at \"StatefulPartitionedCall@__inference_signature_wrapper_44195\") at \"StatefulPartitionedCall\")): Error code: ERROR_NEEDS_FLEX_OPS\r\n<unknown>:0: error: failed while converting: 'main': \r\nSome ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select \r\nTF Select ops: CropAndResize\r\nDetails:\r\n\ttf.CropAndResize(tensor<1x64x64x1088xf32>, tensor<?x4xf32>, tensor<100xi32>, tensor<2xi32>) -> (tensor<100x17x17x1088xf32>) : {T = f32, device = \"\", extrapolation_value = 0.000000e+00 : f32, method = \"bilinear\"}\r\n\ttf.CropAndResize(tensor<1x64x64x1088xf32>, tensor<?x4xf32>, tensor<300xi32>, tensor<2xi32>) -> (tensor<300x17x17x1088xf32>) : {T = f32, device = \"\", extrapolation_value = 0.000000e+00 : f32, method = \"bilinear\"}\r\n```\r\n", "comments": ["Please consider using the Select TF option. https://www.tensorflow.org/lite/guide/ops_select", "> Please consider using the Select TF option. https://www.tensorflow.org/lite/guide/ops_select\r\n\r\nUsing select TF option in\r\n`converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8, tf.lite.OpsSet.SELECT_TF_OPS]`\r\nsolved the error during converting. But the converted model failed to be compiled by `edgutpu_compiler`, the output is \r\n`Edge TPU Compiler version 15.0.340273435\r\nERROR: Didn't find op for builtin opcode 'FILL' version '3'\r\n\r\nERROR: Registration failed.\r\n\r\nInvalid model: model_int_quantized.tflite\r\nModel could not be parse`", "Could you file a separate issue for the edge tpu issue at the coral project?", "> Could you file a separate issue for the edge tpu issue at the coral project?\r\n\r\nActually, I found the converted TFLite model couldn't run through the TFLite interpreter with the error: \r\n\r\n`Traceback (most recent call last):\r\n  File \"converter.py\", line 100, in <module>\r\n    interpreter.invoke()\r\n  File \"/home/dev/.local/lib/python3.6/site-packages/tensorflow/lite/python/interpreter.py\", line 858, in invoke\r\n    self._interpreter.Invoke()\r\nRuntimeError: Input tensor 1283 lacks data\r\n`\r\n\r\nAnd below is the code I run the interpreter:\r\n\r\n```\r\ninterpreter = tf.lite.Interpreter(model_path=\"mask_rcnninception_resnet_1024_int.tflite\")\r\ninterpreter.allocate_tensors()\r\n\r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\n\r\ninput_shape = input_details[0]['shape']\r\ninput_data = np.array(np.random.random_sample(input_shape), dtype=np.uint8)\r\ninterpreter.set_tensor(input_details[0]['index'], input_data)\r\n\r\ninterpreter.invoke()\r\n\r\noutput_data = interpreter.get_tensor(output_details[0]['index'])\r\nprint(output_data)\r\n```\r\n\r\n\r\nDo you know what does this error means?"]}, {"number": 51208, "title": "Fix heap OOB due to dimension mismatch in `ResourceScatterUpdate`", "body": "PiperOrigin-RevId: 388292801\r\nChange-Id: Id9bd7244d98d41b1517d4771850b32782c0cc949", "comments": []}, {"number": 51207, "title": "Fix heap OOB due to dimension mismatch in `ResourceScatterUpdate`", "body": "PiperOrigin-RevId: 388292801\r\nChange-Id: Id9bd7244d98d41b1517d4771850b32782c0cc949", "comments": []}, {"number": 51206, "title": "Fix heap OOB due to dimension mismatch in `ResourceScatterUpdate`", "body": "PiperOrigin-RevId: 388292801\r\nChange-Id: Id9bd7244d98d41b1517d4771850b32782c0cc949", "comments": []}, {"number": 51205, "title": "Fix heap OOB due to dimension mismatch in `ResourceScatterUpdate`", "body": "PiperOrigin-RevId: 388292801\r\nChange-Id: Id9bd7244d98d41b1517d4771850b32782c0cc949", "comments": []}, {"number": 51204, "title": "Prevent heap oob access in `resource_variable_ops.cc`", "body": "PiperOrigin-RevId: 387936433\r\nChange-Id: I9e71ddaa8dbd51ec6afbf163a6b3b591f193b4f6", "comments": []}, {"number": 51203, "title": "Prevent heap oob access in `resource_variable_ops.cc`", "body": "PiperOrigin-RevId: 387936433\r\nChange-Id: I9e71ddaa8dbd51ec6afbf163a6b3b591f193b4f6", "comments": []}, {"number": 51202, "title": "Prevent heap oob access in `resource_variable_ops.cc`", "body": "PiperOrigin-RevId: 387936433\r\nChange-Id: I9e71ddaa8dbd51ec6afbf163a6b3b591f193b4f6", "comments": []}, {"number": 51200, "title": "Prevent division by 0 in `resource_variable_ops.cc`", "body": "PiperOrigin-RevId: 387939939\r\nChange-Id: Ib04902d63756633999959a70613f2eaa30c2c151", "comments": []}, {"number": 51199, "title": "Prevent division by 0 in `resource_variable_ops.cc`", "body": "PiperOrigin-RevId: 387939939\r\nChange-Id: Ib04902d63756633999959a70613f2eaa30c2c151", "comments": []}, {"number": 51198, "title": "Prevent division by 0 in `resource_variable_ops.cc`", "body": "PiperOrigin-RevId: 387939939\r\nChange-Id: Ib04902d63756633999959a70613f2eaa30c2c151", "comments": []}, {"number": 51197, "title": "Prevent use after free.", "body": "A very old version of the code used `result` as a simple pointer to a resource. Two years later, the pointer got changed to a `unique_ptr` but author forgot to remove the call to `Unref`. Three years after that, we finally uncover the UAF.\r\n\r\nPiperOrigin-RevId: 387924872\r\nChange-Id: I70fb6f199164de49fac20c168132a07b84903f9b", "comments": []}, {"number": 51196, "title": "Prevent use after free.", "body": "A very old version of the code used `result` as a simple pointer to a resource. Two years later, the pointer got changed to a `unique_ptr` but author forgot to remove the call to `Unref`. Three years after that, we finally uncover the UAF.\r\n\r\nPiperOrigin-RevId: 387924872\r\nChange-Id: I70fb6f199164de49fac20c168132a07b84903f9b", "comments": []}, {"number": 51195, "title": "Prevent use after free.", "body": "A very old version of the code used `result` as a simple pointer to a resource. Two years later, the pointer got changed to a `unique_ptr` but author forgot to remove the call to `Unref`. Three years after that, we finally uncover the UAF.\r\n\r\nPiperOrigin-RevId: 387924872\r\nChange-Id: I70fb6f199164de49fac20c168132a07b84903f9b", "comments": []}, {"number": 51194, "title": "Validate dimensions of input tensor in `FractionalAvgPoolGrad`", "body": "PiperOrigin-RevId: 388286227\r\nChange-Id: Ieb7566155e92acc8993a2212c76deacadc0edc8a", "comments": []}, {"number": 51193, "title": "Validate dimensions of input tensor in `FractionalAvgPoolGrad`", "body": "PiperOrigin-RevId: 388286227\r\nChange-Id: Ieb7566155e92acc8993a2212c76deacadc0edc8a", "comments": []}, {"number": 51192, "title": "Validate dimensions of input tensor in `FractionalAvgPoolGrad`", "body": "PiperOrigin-RevId: 388286227\r\nChange-Id: Ieb7566155e92acc8993a2212c76deacadc0edc8a", "comments": []}, {"number": 51191, "title": "Validate dimensions of input tensor in `FractionalAvgPoolGrad`", "body": "PiperOrigin-RevId: 388286227\r\nChange-Id: Ieb7566155e92acc8993a2212c76deacadc0edc8a", "comments": []}, {"number": 51190, "title": "Fix segfault/heap buffer overflow in `{Experimental,}DatasetToTFRecor\u2026", "body": "\u2026d` where dataset is numeric.\r\n\r\nCode assumes only strings inputs and then interprets numbers as valid `tstring`s. Then, when trying to compute the CRC of the record this results in heap buffer overflow.\r\n\r\nPiperOrigin-RevId: 387675909\r\nChange-Id: I7396b9b8afc1ac744112af7c0b1cd7bb41e0f556", "comments": []}, {"number": 51189, "title": "Fix segfault/heap buffer overflow in `{Experimental,}DatasetToTFRecor\u2026", "body": "\u2026d` where dataset is numeric.\r\n\r\nCode assumes only strings inputs and then interprets numbers as valid `tstring`s. Then, when trying to compute the CRC of the record this results in heap buffer overflow.\r\n\r\nPiperOrigin-RevId: 387675909\r\nChange-Id: I7396b9b8afc1ac744112af7c0b1cd7bb41e0f556", "comments": []}, {"number": 51188, "title": "Fix segfault/heap buffer overflow in `{Experimental,}DatasetToTFRecor\u2026", "body": "\u2026d` where dataset is numeric.\r\n\r\nCode assumes only strings inputs and then interprets numbers as valid `tstring`s. Then, when trying to compute the CRC of the record this results in heap buffer overflow.\r\n\r\nPiperOrigin-RevId: 387675909\r\nChange-Id: I7396b9b8afc1ac744112af7c0b1cd7bb41e0f556", "comments": []}, {"number": 51187, "title": "Ensure validation sticks in `save_restore_v2_ops.cc`", "body": "PiperOrigin-RevId: 387924206\r\nChange-Id: I6156842eb3230076b5812c0815f3e66bd5241454", "comments": []}, {"number": 51186, "title": "Ensure validation sticks in `save_restore_v2_ops.cc`", "body": "PiperOrigin-RevId: 387924206\r\nChange-Id: I6156842eb3230076b5812c0815f3e66bd5241454", "comments": []}, {"number": 51185, "title": "Ensure validation sticks in `save_restore_v2_ops.cc`", "body": "PiperOrigin-RevId: 387924206\r\nChange-Id: I6156842eb3230076b5812c0815f3e66bd5241454", "comments": []}, {"number": 51184, "title": "Prevent nullptr deref in SparseTensorSliceDataset", "body": "The arguments must determine a valid sparse tensor. This means that when indices are empty then the values must be empty too (and the reverse).\r\n\r\nAlso added test, by modifying existing test with empty sparse tensor to now run with an invalid sparse tensor input.\r\n\r\nPiperOrigin-RevId: 388562757\r\nChange-Id: Id8b54cd7c2316025b4f9a77292c8fb5344d17609", "comments": []}, {"number": 51183, "title": "Prevent nullptr deref in SparseTensorSliceDataset", "body": "The arguments must determine a valid sparse tensor. This means that when indices are empty then the values must be empty too (and the reverse).\r\n\r\nAlso added test, by modifying existing test with empty sparse tensor to now run with an invalid sparse tensor input.\r\n\r\nPiperOrigin-RevId: 388562757\r\nChange-Id: Id8b54cd7c2316025b4f9a77292c8fb5344d17609", "comments": []}, {"number": 51182, "title": "Prevent nullptr deref in SparseTensorSliceDataset", "body": "The arguments must determine a valid sparse tensor. This means that when indices are empty then the values must be empty too (and the reverse).\r\n\r\nAlso added test, by modifying existing test with empty sparse tensor to now run with an invalid sparse tensor input.\r\n\r\nPiperOrigin-RevId: 388562757\r\nChange-Id: Id8b54cd7c2316025b4f9a77292c8fb5344d17609", "comments": []}, {"number": 51181, "title": "Prevent nullptr deref in SparseTensorSliceDataset", "body": "The arguments must determine a valid sparse tensor. This means that when indices are empty then the values must be empty too (and the reverse).\r\n\r\nAlso added test, by modifying existing test with empty sparse tensor to now run with an invalid sparse tensor input.\r\n\r\nPiperOrigin-RevId: 388562757\r\nChange-Id: Id8b54cd7c2316025b4f9a77292c8fb5344d17609", "comments": []}, {"number": 51179, "title": "Inference is slower on Densenet121 when using XLA ", "body": "Hi,\r\n\r\nWhen running the Densenet121 model using **XLA** on Imagenet dataset, the inference is about 5-7 seconds slower than normal on GPU.\r\n\r\n**Environment**:\r\nTensorflow 2.5.0\r\nkeras-nightly==2.5.0.dev2021032900\r\nPython 3.7\r\nOS: Ubuntu 18.04\r\nCUDA 11.1\r\nGPUs: 8 Nvidia GA100\r\n\r\n**Current behaviour**:\r\nRunning inference using Densenet121 without XLA takes ~14s on 10000 images\r\nRunning inference using Densenet121 with XLA takes ~20s on 10000 images\r\n\r\n**Expected behaviour**:\r\nTimes should be similar or XLA should be faster!\r\n\r\nMy code is currently quite complex. If needed, I can try to provide a simplified version. Please let me know if you need any additional information.\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["@crawlingcub,\r\n\r\nPlease provide the reproducible standalone code to expedite the trouble shooting process. Thanks!", "Hi, \r\n\r\nPlease find the code to reproduce the bug below. You will need to download the imagenet validation dataset and pre-sort it. Change the directory from `'./imagenet/val` to where you downloaded. \r\n\r\nDownload the model files from [here](https://drive.google.com/file/d/1AMnRXvEpmIIxVtM7xsHWloDlcSTuBLQ0/view?usp=sharing), untar, and run the script below with the path to the directory.\r\n\r\n\r\n```python\r\nimport os\r\nimport sys\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\r\nos.environ['XLA_FLAGS']=\"--xla_gpu_cuda_data_dir=/usr/local/cuda-11.1\"\r\nimport tensorflow.keras as keras\r\nimport tensorflow as tf\r\ntf.keras.backend.set_image_data_format('channels_first')\r\n\r\n\r\ndef load_dataset(data_format, target):\r\n    val_ds = keras.preprocessing.image_dataset_from_directory(\r\n                    directory='./imagenet/val',\r\n                    labels=\"inferred\",\r\n                    label_mode=\"categorical\",\r\n                    class_names=[],\r\n                    image_size=(224,224),\r\n                    batch_size=100,\r\n                    validation_split=0.2,\r\n                    subset=\"validation\",\r\n                    seed=1234\r\n                )\r\n\r\n    val_ds = val_ds.map(lambda x, y: (tf.transpose(x, [0, 3, 1, 2]), y))\r\n    val_ds = val_ds.map(lambda x, y:\r\n                        (keras.applications.imagenet_utils.preprocess_input(\r\n                            x,\r\n                            data_format=data_format,\r\n                            mode=target), y))\r\n    return val_ds\r\n\r\n\r\nimg_input = keras.layers.Input(shape=(3,224,224))\r\ntest_ds = load_dataset('channels_first', 'torch')\r\nprint(\"Data loaded\")\r\nmodel = keras.models.load_model(sys.argv[1])\r\nopt = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9, decay=1e-6)\r\nmodel.compile(optimizer=opt,\r\n             loss='categorical_crossentropy',\r\n             metrics=['accuracy', tf.keras.metrics.AUC(from_logits=True)])\r\n\r\nmodel.evaluate(test_ds, verbose=1)\r\n\r\n# enable xla\r\ntf.keras.backend.clear_session()\r\ntf.config.optimizer.set_jit(True)\r\n\r\nprint(\"xla\")\r\nmodel = keras.models.load_model(sys.argv[1])\r\nopt = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9, decay=1e-6)\r\nmodel.compile(optimizer=opt,\r\n             loss='categorical_crossentropy',\r\n             metrics=['accuracy', tf.keras.metrics.AUC(from_logits=True)])\r\n\r\nmodel.evaluate(test_ds, verbose=1)\r\n```\r\n\r\nRunning this script produces the following output, where XLA is slower than normal execution!\r\n\r\nOutput:\r\n```\r\nFound 50000 files belonging to 1000 classes.\r\nUsing 10000 files for validation.\r\nData loaded\r\n100/100 [==============================] - 14s 75ms/step - loss: 0.4465 - accuracy: 0.7186 - auc: 0.9826\r\nxla\r\n100/100 [==============================] - 22s 87ms/step - loss: 0.4465 - accuracy: 0.7185 - auc: 0.9826\r\n```\r\n\r\n\r\nHope this helps. Let me know if you need more info.", "@crawlingcub,\r\n\r\nThanks for sharing the code, Can you also share the sample data as well to reproduce the issue from our end.", "Hi, I am using the imagenet dataset. I don't think I can directly share the imagenet dataset. You can download it from https://image-net.org/download.php ", "I also reproduced the same problem with cifar10. Please find the code below and the model [here](https://drive.google.com/file/d/19Vhn-jLTAwQY3i19SP93cMLU-9mOWBSK/view?usp=sharing): \r\n\r\nHope this unblocks you.\r\n\r\n```python\r\nimport os\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\r\nos.environ['XLA_FLAGS']=\"--xla_gpu_cuda_data_dir=/usr/local/cuda-11.1\"\r\n\r\nimport tensorflow.keras as keras\r\nimport tensorflow as tf\r\ntf.keras.backend.set_image_data_format('channels_first')\r\n\r\n\r\ndef load_cifar():  \r\n    (x, y), (x_test, y_test) = keras.datasets.cifar10.load_data()\r\n    x_test = keras.applications.imagenet_utils.preprocess_input(x_test, data_format='channels_first', mode='torch')\r\n    y_test = keras.utils.to_categorical(y_test, num_classes=10)\r\n    x = keras.applications.imagenet_utils.preprocess_input(x, data_format='channels_first', mode='torch')\r\n    y = keras.utils.to_categorical(y, num_classes=10)\r\n    train_ds = tf.data.Dataset.from_tensor_slices((x, y)).batch(100)\r\n    test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(100)\r\n    return train_ds, test_ds\r\n\r\n\r\ntrain_ds, test_ds = load_cifar()\r\n\r\n\r\nimg_input = keras.layers.Input(shape=(3,32,32))\r\nmodel = keras.models.load_model('bugmodel')\r\nopt = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9, decay=1e-6)\r\nmodel.compile(optimizer=opt,\r\n             loss='categorical_crossentropy',\r\n             metrics=['accuracy', tf.keras.metrics.AUC(from_logits=True)])\r\n\r\nmodel.evaluate(test_ds, verbose=1)\r\n\r\ntf.keras.backend.clear_session()\r\ntf.config.optimizer.set_jit(True)\r\nprint(\"xla\")\r\nmodel = keras.models.load_model('bugmodel')\r\nopt = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9, decay=1e-6)\r\nmodel.compile(optimizer=opt,\r\n             loss='categorical_crossentropy',\r\n             metrics=['accuracy', tf.keras.metrics.AUC(from_logits=True)])\r\n\r\nmodel.evaluate(test_ds, verbose=1)\r\n\r\n```\r\n\r\nOutput\r\n```\r\n100/100 [==============================] - 8s 21ms/step - loss: 8.9364 - accuracy: 0.5511 - auc: 0.7836\r\nxla\r\n100/100 [==============================] - 10s 18ms/step - loss: 8.9355 - accuracy: 0.5511 - auc: 0.7837\r\n```\r\n\r\n", "@crawlingcub,\r\n\r\nWhen I tried extracting the tar file of bug model provided, I am getting `ReadError: unexpected end of data` and I am not able to use the model that you created, [gist here](https://colab.research.google.com/gist/sanatmpa1/9538a075bf83bf823a2dfb9a370fa7be/51179.ipynb). Can you share the reproduced colab gist of the issue? Thanks!", "can you just extract the folder using command line: `tar -xvf bugmodel.tar.gz` and then use that folder to read the model?", "@crawlingcub,\r\n\r\nI am able to reproduce the code in colab with GPU and take a look at this [gist](https://colab.research.google.com/gist/sanatmpa1/9538a075bf83bf823a2dfb9a370fa7be/51179.ipynb#scrollTo=5ZnEJYZL_22p). I am not seeing slower inference when using XLA as both the evaluation takes similar time. Can you try updating to latest stable version `2.6.0` and let me know if the issue persists? Thanks!", "Hi,\r\n\r\nI think the issue was more apparent with imagenet dataset. I cannot share the dataset directly due to distribution restrictions. Can you try it out? It can be obtained from [here](https://image-net.org/download.php)", "@crawlingcub,\r\n\r\nAre you able to update your tensorflow version to `2.6.0` and check if the same issue persists? because the one that I reproduced in colab is with TF 2.6.0 and I see the issue reported by you is with `TF 2.5.0`.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51179\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51179\">No</a>\n"]}]