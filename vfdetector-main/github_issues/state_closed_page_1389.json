[{"number": 11392, "title": "GPUDirect RDMA Out-of-Band Tensor Transport", "body": "Introduction\r\n===\r\n\r\nThis PR implements GDR out-of-band transport for TensorFlow distributed runtime, complementary to current gRPC transport. It uses gRPC as control plane to setup rendezvous for each tensor transmission, and utilizes [GPU Direct RDMA](https://developer.nvidia.com/gpudirect) whenever possible to transmit tensors in remote GPU memory through network interface card (NIC), bypassing host memory and CPU entirely. It gracefully falls back to ordinary RDMA or even gRPC when GDR is not available.\r\n\r\nDesign\r\n===\r\n\r\nThe GDR out-of-band transport is designed to avoid any unnecessary memory copies, especially for large tensors (>100MB). That typically requires registration of tensor buffers to NIC on the fly, which is rather slow as described in the design trade-off of the verbs runtime. The verbs runtime thus chooses to manage its own NIC-registered buffers and copy the tensors from/to those buffers for every single tensor transfer.\r\n\r\nWe show that, however, such design trade-off is not always relevant. In this patch, we manage both computation and communication buffers in a unified manner. By pre-registration of large buffers to NIC and allocating small tensors from the buffer pool using a BFC allocator, it is possible to avoid both buffer registration on the fly and memory copies all together.\r\n\r\nFor the actual tensor transport, we rely on gRPC to transmit the remote buffer information. This greatly simplifies our design, and there are only 2 types of RDMA messages: a single READ to retrieve the tensor data (bypassing remote CPU), and another invalidate using WRITE with IMM to release the tensor buffer on the remote side. The remote side will only be polling the invalidate message and `Unref` the tensor buffers that read by its peer.\r\n\r\nEnvironment\r\n===\r\n\r\nTo fully utilize GDR, the target environment has to meet 3 conditions:\r\n\r\n1. There is an RDMA capable device with corresponding [OFED package](https://www.openfabrics.org/index.php/overview.html) installed (detailed information is available from your [Infiniband/RoCE](http://www.mellanox.com/page/products_dyn?product_family=116)/[iWarp](http://www.chelsio.com/gpudirect-rdma/) vendor), which could be verified through `ibv_devinfo`, e.g.\r\n\r\n```\r\n$ ibv_devinfo\r\nhca_id:\tmlx4_0\r\n\ttransport:\t\t\tInfiniBand (0)\r\n\tfw_ver:\t\t\t\t2.40.7000\r\n\tnode_guid:\t\t\t248a:0703:00f6:3370\r\n\tsys_image_guid:\t\t\t248a:0703:00f6:3370\r\n\tvendor_id:\t\t\t0x02c9\r\n\tvendor_part_id:\t\t\t4099\r\n\thw_ver:\t\t\t\t0x1\r\n\tboard_id:\t\t\tMT_1090110023\r\n\tphys_port_cnt:\t\t\t2\r\n\tDevice ports:\r\n\t\tport:\t1\r\n\t\t\tstate:\t\t\tPORT_ACTIVE (4)\r\n\t\t\tmax_mtu:\t\t4096 (5)\r\n\t\t\tactive_mtu:\t\t1024 (3)\r\n\t\t\tsm_lid:\t\t\t0\r\n\t\t\tport_lid:\t\t0\r\n\t\t\tport_lmc:\t\t0x00\r\n\t\t\tlink_layer:\t\tEthernet\r\n\r\n\t\tport:\t2\r\n\t\t\tstate:\t\t\tPORT_ACTIVE (4)\r\n\t\t\tmax_mtu:\t\t4096 (5)\r\n\t\t\tactive_mtu:\t\t1024 (3)\r\n\t\t\tsm_lid:\t\t\t0\r\n\t\t\tport_lid:\t\t0\r\n\t\t\tport_lmc:\t\t0x00\r\n\t\t\tlink_layer:\t\tEthernet\r\n```\r\n\r\n2. There is a GDR capable GPU, i.e. of Fermi, Kepler or later architecture with [corresponding driver](http://docs.nvidia.com/cuda/gpudirect-rdma/index.html) installed. The PCI-e topology could be confirmed by `nvidia-smi topo -m`. For example, in the following topology, `GPU2` and `GPU3` are adjacent to `mlx4_0`, and tensors on these devices could benefit from GDR in current implementation.\r\n\r\n```\r\n$ nvidia-smi topo -m\r\n\tGPU0\tGPU1\tGPU2\tGPU3\tmlx4_0\tCPU Affinity\r\nGPU0\t X \tPHB\tSOC\tSOC\tSOC\t0-5\r\nGPU1\tPHB\t X \tSOC\tSOC\tSOC\t0-5\r\nGPU2\tSOC\tSOC\t X \tPHB\tPHB\t6-11\r\nGPU3\tSOC\tSOC\tPHB\t X \tPHB\t6-11\r\nmlx4_0\tSOC\tSOC\tPHB\tPHB\t X\r\n\r\nLegend:\r\n\r\n  X   = Self\r\n  SOC  = Connection traversing PCIe as well as the SMP link between CPU sockets(e.g. QPI)\r\n  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)\r\n  PXB  = Connection traversing multiple PCIe switches (without traversing the PCIe Host Bridge)\r\n  PIX  = Connection traversing a single PCIe switch\r\n  NV#  = Connection traversing a bonded set of # NVLinks\r\n```\r\n\r\n3. The [`nv_peer_mem`](https://github.com/Mellanox/nv_peer_memory) kernel module is installed.\r\n\r\nHow to build and run in GDR mode\r\n===\r\n\r\nTo test it out on a GDR capable environment, choose to enable GDR in your configure script.\r\n\r\n```\r\nDo you wish to build TensorFlow with GDR support? [y/N]: y\r\nGDR support will be enabled for TensorFlow.\r\n```\r\n\r\nChange your `protocol` to `grpc+gdr` to enable GDR in your deployment.\r\n\r\n```\r\nserver = tf.train.Server(cluster, job_name=\"local\", task_index=0, protocol='grpc+gdr') # default protocol is 'grpc'\r\n```\r\n\r\nCurrently the out-of-band transport service listens to the same IP and port address as specified in gRPC.\r\n\r\nA successful initialization looks like this:\r\n\r\n```\r\n2017-08-05 19:10:38.601718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40m, pci bus id: 0000:02:00.0)\r\n2017-08-05 19:10:38.601728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K40m, pci bus id: 0000:03:00.0)\r\n2017-08-05 19:10:38.601736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:2) -> (device: 2, name: Tesla K40m, pci bus id: 0000:82:00.0)\r\n2017-08-05 19:10:38.601742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:3) -> (device: 3, name: Tesla K40m, pci bus id: 0000:83:00.0)\r\n2017-08-05 19:10:39.591026: I tensorflow/contrib/gdr/gdr_memory_manager.cc:235] RDMA server is listening on 10.40.2.200:5001\r\n2017-08-05 19:10:39.591071: I tensorflow/contrib/gdr/gdr_memory_manager.cc:285] Instrumenting CPU allocator cuda_host_bfc\r\n2017-08-05 19:10:39.591083: I tensorflow/contrib/gdr/gdr_memory_manager.cc:285] Instrumenting CPU allocator cpu_pool\r\n2017-08-05 19:10:39.591095: I tensorflow/contrib/gdr/gdr_memory_manager.cc:285] Instrumenting CPU allocator cpu_rdma_bfc\r\n2017-08-05 19:10:39.591278: I tensorflow/contrib/gdr/gdr_memory_manager.cc:78] NUMA node for device: mlx4_0 is 1\r\n2017-08-05 19:10:39.740253: I tensorflow/contrib/gdr/gdr_memory_manager.cc:296] Instrumenting GPU allocator with bus_id 2\r\n```\r\n\r\nThe last line suggests that the GPUs with bus id 2 (mapped to pci bus id prefixed 0000:8) will benefit from GDR and host memory bypass, which is `/gpu:2` and `/gpu:3` in this case.\r\n\r\nCaveats\r\n===\r\n\r\nIn current implementation, only tensors that reside in host memory or in GPU memory such that the GPU is adjacent to an RDMA capable NIC will use direct RDMA as its transport. When RDMA is available but not GDR, a temporary tensor copy on host memory will be used as RDMA source/destination (and copied from/to the target device). When there is no RDMA device present, it can even fallback to the original gRPC runtime. While it is theoretically possible to mix GDR enabled TF with non-GDR deployments in the same job, make sure the environment is properly setup so the GDR mode is enabled whenever possible (i.e. do not fall back to gRPC when it is not absolutely necessary).", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "Are you depending on a host RDMA library to be installed?\r\n\r\n```\r\ntensorflow/core/distributed_runtime/rpc/rdma.cc:13:27: fatal error: rdma/rdma_cma.h: No such file or directory\r\n #include <rdma/rdma_cma.h>\r\n```", "@drpngx Yes, as in case of CUDA, we assume an OFED package is installed with all the drivers and user space libraries for RDMA to properly function. `libibverbs` and `librdmacm` are included in any OFED package.\r\n\r\nI agree that we need some sort of compile switch, but I haven't figure out the best way to do it. Alternatively we could add [linux-rdma/rdma-core](https://github.com/linux-rdma/rdma-core) as a third party compile dependency, and detect whether the GDR environment is available only at runtime.", "I have done some investigations and would like to purpose adding [`librdmacm`](https://www.openfabrics.org/downloads/rdmacm/) and [`libibverbs`](https://git.kernel.org/pub/scm/libs/infiniband/libibverbs.git) as third party dependencies (`librdmacm` depends on `libibverbs`). All of these compile on latest Linux without any hardware requirements. For the runtime, one could simply call `ibv_get_device_list(3)` and check if the target environment requirements are met.\r\n\r\nNow of course all of these are Linux specific, so we need an extra compatibility layer against non-Linux platforms. I do know there are [RDMA APIs](https://docs.microsoft.com/en-us/windows-hardware/drivers/network/overview-of-network-direct-kernel-provider-interface--ndkpi-) available on Windows, but I don't have a Windows box, so this has to be left to future contributors.\r\n\r\nAnd for the functional testing, we could use [Software RDMA over Ethernet](https://github.com/torvalds/linux/blob/master/drivers/infiniband/sw/rxe/Kconfig) as a software emulated RDMA layer that runs on any platform. It does require upstream Linux kernel version [at least 4.8](https://github.com/torvalds/linux/commit/8700e3e7c4857d28ebaa824509934556da0b3e76) to enable such feature, so we do need to [setup a separated CI environment](https://github.com/linux-rdma/rdma-core/blob/master/Documentation/rxe.md) for that purpose.", "@shamoya Any interests on this patch? I would certainly appreciate any help from Mellanox on testing and setting up CI environment with GDR (and possibly RoCE).", "@gunan\n\nOn Jul 10, 2017 3:32 AM, \"Bairen Yi\" <notifications@github.com> wrote:\n\n> @shamoya <https://github.com/shamoya> Any interests on this patch? I\n> would certainly appreciate any help from Mellanox on testing and setting up\n> CI environment with GDR (and possibly with RoCE).\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/11392#issuecomment-314068122>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbYeP7V3-l2Duo9aG9508zR3sQb1Yks5sMf2ugaJpZM4OSCMo>\n> .\n>\n", "buldifier checks are failing here. Thus all the other tests are blocked.\r\n\r\n```\r\nRunning do_buildifier on 204 files\r\n\r\ntensorflow/core/distributed_runtime/rpc/BUILD # reformat callsort listsort unsafesort sort:tf_cuda_library.deps\r\n\r\nbuildifier took 1 s\r\n\r\nFAIL: buildifier found errors and/or warnings in above BUILD files.\r\nbuildifier suggested the following changes:\r\n248a249,254\r\n>     linkopts = select({\r\n>         \"//conditions:default\": [\r\n>             \"-libverbs\",\r\n>             \"-lrdmacm\",\r\n>         ],\r\n>     }),\r\n250d255\r\n<         \"//tensorflow/core/distributed_runtime:rdma\",\r\n254a260\r\n>         \"//tensorflow/core/distributed_runtime:rdma\",\r\n256,258d261\r\n<     linkopts = select({\r\n<         \"//conditions:default\": [\"-libverbs\", \"-lrdmacm\"],\r\n<     }),\r\nPlease fix manually or run buildifier <file> to auto-fix.\r\n```\r\n\r\nCould you look into this failure, so that the rest of our CI tests can run?", "@gunan Yes, I am looking into it. Will ping you after it's resolved.", "I am working on introducing the [RDMA user space libraries](https://github.com/linux-rdma/rdma-core) as third party dependencies, but I am not familiar with converting Makefile or CMake rules into bazel BUILD files. A similar case #5349 of integrating cURL seems to be a much larger effort than I expected. Would appreciate if @jart or @gunan could give some suggestions on this.", "Jenkins, test this please.", "@drpngx Sorry I was pushing the wrong commit. Could you ask Jenkins to test it again?", "Jenkins, test this please.\n\nOn Jul 10, 2017 10:55 AM, \"Bairen Yi\" <notifications@github.com> wrote:\n\n> @drpngx <https://github.com/drpngx> Sorry I was pushing the wrong commit.\n> Could you ask Jenkins to test it again?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/11392#issuecomment-314183441>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbVW1ng50wP9vJmxxwfvJZTEFypiQks5sMmWcgaJpZM4OSCMo>\n> .\n>\n", "Seems a rebase is needed.", "Thanks @byronyi \r\nLet me take a look at this patch and get back to you soon.\r\nWe thought of GDR in the context of the verbs code till now, so this is interesting.\r\nAdding the RDMA libraries as third party is a good idea, good also for the grpc+verbs protocol flow.", "@shamoya Glad to have your prompt reply. The last commit turns out to be a unsuccessful attempt to introduce RDMA dependency. If you would like to try out the patch on a machine with OFED installed, you could revert the last commit and build it from source.\r\n\r\nUpdate: I've reverted it myself so it should work by just checking out from this branch.", "The libraries in third_party are linked statically to the code right ?\r\nIn general, how can one provide a different library version then the one in third_party (grpc for example) ?    ", "My initial attempt was to include only RDMA headers, which apparently is not runnable as it isn't linked against the actual library. I haven't figured it out how to use bazel to build rdma-core; they are using CMake and it's hard to port it to bazel in general. I guess we need to consult someone in the TF team on platform and portability issues.\n\nRegarding to the version of specific third party library, I think it is hardcoded into the compilation directives. Google seems to compile everything from source for their projects, and I guess this isn't a issue for them.", "Jenkins, test this please.", "@drpngx I am still working on resolving the build issues...maybe we should wait for review from @poxvoculi first?", "OK. I usually prefer to review when everything builds and tests properly.\nCan you summarize what your questions are?\n\nOn Tue, Jul 11, 2017 at 9:46 AM, Bairen Yi <notifications@github.com> wrote:\n\n> @drpngx <https://github.com/drpngx> I am still working on resolving the\n> build issues...maybe we should wait for review from @poxvoculi\n> <https://github.com/poxvoculi> first?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/11392#issuecomment-314503570>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbSZTqPDhgHxUFwIp2qRQXqKnumSoks5sM6bKgaJpZM4OSCMo>\n> .\n>\n", "Current CI doesn't have GDR environment so we are specifically testing the \"fallback to gRPC\" behaviour.\r\n\r\nI've already implemented such logic in my code ([here](https://github.com/tensorflow/tensorflow/pull/11392/files#diff-3dd79508fcea22184e8086c24dae0deaR349) and [there](https://github.com/tensorflow/tensorflow/pull/11392/files#diff-c404e67a9906d0e4749fd1f718ea3c73R137)); but GDR environment requires RDMA user space libraries, which are currently not linked into the TF core library. Currently I am stuck by adding them as a third-party dependency (porting CMake based project to bazel).\r\n\r\nAlternatively I could make it a separated runtime (like grpc+verbs and grpc+mpi), but that will defeat the whole point of being able to fallback to gRPC.", "Or I could just add a compiler directive in `configure` and disable everything that's useful.", "@drpngx I've tested my non-RDMA box and everything works just fine. It does require the box to have `librdmacm` and `libibverbs` installed, though. It falls back to gRPC correctly as suggested.\r\n\r\nIs there anyway to setup a CI environment with those two libraries? They are available on all Linux distros I know of. After we confirm everything builds and tests properly, we can arrange a review on my patch.", "@gunan The buildifier complaint is fixed. ", "As discussed in linux-rdma/rdma-core#163, I have to give up adding the RDMA libraries as third party dependencies, and rely on target environment for building GDR. This means an extra compile switch in the `configure` file, and also a macro that shadow all the RDMA API calls.\r\n\r\nI will start to migrate my patch in the next few days.", "@drpngx I tested locally with my non-RDMA box and it works. Would appreciate if you could let Jenkins test it again.", "Jenkins, test this please.\n\nOn Jul 12, 2017 9:22 PM, \"Bairen Yi\" <notifications@github.com> wrote:\n\n@drpngx <https://github.com/drpngx> I tested locally with my non-RDMA box\nand it works. Would appreciate if you could let Jenkins test it again.\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\n<https://github.com/tensorflow/tensorflow/pull/11392#issuecomment-314966557>,\nor mute the thread\n<https://github.com/notifications/unsubscribe-auth/AT_SbQygoshznNR4EcTPgAgEvOo9DG7Hks5sNZtxgaJpZM4OSCMo>\n.\n", "@drpngx Tests are blocked by sanity checks. I've auto-fixed all of them using clang-format and buildifier. Mind to let Jenkins test again?", "Jenkins, test this please.", "@byronyi We haven't written a Bazel config for rdma-core internally. What I would probably do if I were you is see you can run its standard cmake/ninja build and get it to output the actual gcc/etc. commands it's running (in Bazel that's `bazel build -s //foo`) Then follow loosely the same pattern we did with our third party build files. You can add me as a reviewer once you come up with a PR that does this. Thank you, by the way.", "@drpngx While I will be working to resolve the failing Windows/MacOS/Py3 tests, could we arrange a review as Linux CPU/GPU already builds and tests well?", "Yes, I think @poxvoculi is OK with it in principle, I will let him approve.", "@drpngx That would be great. I would definitely appreciate if there are any comments on the overall design or styling issue from @poxvoculi.", "Seems the patch could be further refactored using `DeviceLocality` that present in `RecvTensorRequest`. See the commit 79228c74e64a639aeb5692b442522d4aa279f885.", "Jenkins, test this please.", "My main initial review question is why this PR modifies so many files in core.   We're trying to keep alternate RPC implementations in contrib for the time being.  Are there any special difficulties with putting this stuff into contrib?", "No, at least I couldn't think of any specific difficulties preventing us from moving it to contrib. Let's just say we register a separated server protocol `grpc+gdr`, and override specific behaviors like what's currently done for verbs and MPI.\n\nDo you have any other comments before I start migrating this patch?", "No, other than the disruption to core it looks pretty good.  Our long term design goal is to enable a diversity of distributed I/O solutions to be used in a modular fashion with minimal impact on binaries that don't need them.  While we're still gaining experience with alternate solutions, we want to keep them in contrib.", "@byronyi I assume you're still working on this?  Just want to keep tabs :)", "@vrv \n\nYes, I was busy on something else for the past week. I will try to finish the migration and hopefully get this PR into rc1 or rc2. We don't want to miss the 1.3 release :)", "I got this error more than once when using this patch to run benchmarks code.\r\n```\r\n2017-07-28 11:22:43.361608: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:330] Started server with target: grpc://localhost:39799\r\n2017-07-28 11:23:28.395109: I tensorflow/core/distributed_runtime/master_session.cc:998] Start master session ec37ba189b6f7f05 with config: intra_op_para\r\nllelism_threads: 1 gpu_options { force_gpu_compatible: true } allow_soft_placement: true\r\n2017-07-28 11:23:34.103612: I tensorflow/core/distributed_runtime/rpc/rdma.cc:435] Accepted new RDMA connection\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1285, in _do_call\r\n    return fn(*args)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1264, in _run_fn\r\n    status, run_metadata)\r\n  File \"/usr/lib/python3.5/contextlib.py\", line 66, in __exit__\r\n    next(self.gen)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.InternalError: WhereOp: Could not launch cub::DeviceReduce::Sum to count number of true indices, status: invalid \r\nresource handle\r\n         [[Node: report_uninitialized_variables/boolean_mask/Where = Where[_device=\"/job:worker/replica:0/task:0/gpu:0\"](report_uninitialized_variables/b\r\noolean_mask/Reshape_1_S4219)]]\r\n\r\n```", "The above error is fixed by recent commits on master branch.", "@byronyi , I did some test on benchmarks code using `distributed_replicated` mode and `gpu` as `local_param_device`.\r\nI find sometimes I got ``` 2017-07-31 17:09:05.880231: W tensorflow/core/distributed_runtime/rpc/rdma.cc:129] No RDMA device found ```, maybe my ib driver has some problem.\r\nI also got ```*** Error in `python3': free(): invalid pointer: 0x00007f47740066d0 ***``` sometimes, detail is on [gist](https://gist.github.com/suiyuan2009/434b8abaf98ad9f81e39905df0a98db2).\r\nAnd my 1 worker to 4 workers speedup ratio is a little strange(small).\r\n", "@poxvoculi While the migration to contrib is still ongoing, I have removed most modifications to core. Those left are the ones may lead to substantial duplicate code if removed. I'd like to seek for your opinion on whether these changes are acceptable for core, so I will have a solid ground for the contrib part.", "@suiyuan2009 Thanks for raising those issues. \r\n\r\nWhen `No RDMA device found` prints [here](https://github.com/red-bird/tensorflow/blob/0cb5019de7329b10d60a8d74f6c4665169578400/tensorflow/core/distributed_runtime/rpc/rdma.cc#L129) it probably means there is no available IB device present. It is a fairly simple API call (`rdma_get_devices`) without any dependency, so it itself is unlikely to go wrong. Let me know if this issue persists; I could take a closer look to your environment.\r\n\r\nWe have seen the invalid free during our development process, and while we haven't figured out the reasons behind, some suggested it might because of incompatible build/runtime environment, such as python or malloc version (#9328). I suspect it might because the virtualenv that you used to build TF is different from the runtime (as once in our case), but I am not sure. I will come back to this one after tidying up the current mess.\r\n\r\nAbout the slow speedup, could you elaborate?", "@drpngx I've finished migration to contrib. Mind to kick off Jenkins for test?", "@suiyuan2009 I've finished the migration, and several potential inconsistencies in `rdmacm` API calls have been fixed. Would you mind to test your code again and see if your issue persists?", "Jenkins, test this please.", "Seems to be the same issue mentioned [here](https://github.com/tensorflow/tensorflow/pull/8943#issuecomment-292676004). Fixed by a macro wrapping up the external rdma headers.", "@byronyi , I meet `tensorflow.python.framework.errors_impl.UnavailableError: Cannot bind to rdma://10.9.38.144:50543` error, [gist log](https://gist.github.com/suiyuan2009/1c7f54908b121227d01914548ffe3bdb#file-gdr-patch-test-L16). I also meet `tensorflow.python.framework.errors_impl.UnavailableError: Cannot find pinned memory region` error, [gist log](https://gist.github.com/suiyuan2009/1c7f54908b121227d01914548ffe3bdb#file-gdr-patch-test-L249). I meet error everytime.", "@suiyuan2009 I am trying to fix this problem, thank you for your log! It helps a lot to locate the bug.\r\n\r\nI've refactored the code a lot and going through all these manual test cycles every single time. Maybe I should write some unit tests for the patch to save all these efforts, but I have not figured out the best way to organize it. Any ideas are more than welcomed :)", "@poxvoculi After several rounds of refactoring, this patch is finally ready for review. Please let me know if there is any issue. ", "I still got `tensorflow.python.framework.errors_impl.UnavailableError: Cannot bind to rdma://10.9.0.196:41368` sometimes.", "@suiyuan2009 I've pushed a new commit that improves error handling by including `errno` in the reporting error status. Mind to check again?", "I've been communicating with @suiyuan2009 via another channel, and he confirms that the above binding error is an environment issue of their IB devices. ", "@vrv Kindly ping you for kicking off the testing again.", "@tensorflow-jenkins test this please", "Apart from docs, the only remaining issue I am not sure about are the CPU-only allocators. The way it is handled now is a bunch of hacks:\r\n\r\n1. it overrides the default CPU allocator, which allocates 100% of all CPU RAM tensors \r\n2. it re-introduces a `BasicCPUAllocator` which is exactly the same with the one in `gpu/pool_allocator.h` (I actually copied directly from there)\r\n3. it could not co-exists with `MKLCPUAllocator` as it precedes the latter one with a higher priority\r\n\r\nThe main rationale of these hacks is that the current [default cpu allocator](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/allocator.cc#L71) is not visitable, so my patch will fail at [this line](https://github.com/red-bird/tensorflow/blob/955764316dd9c796db874ae2034e336a48b1fb46/tensorflow/contrib/gdr/gdr_memory_manager.cc#L257). The entire `BFCRdmaAllocator` is introduced to avoid this failure.\r\n\r\nNote that MKL suffers from the exact same problem, and they uses the exactly [same hacks](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/mkl_cpu_allocator.h): \r\n\r\n1. it overrides the default CPU allocator\r\n2. it re-introduces a `MklSubAllocator` that is equivalent to the `BasicCPUAllocator`\r\n3. it could not co-exists with other CPU allocators\r\n\r\nThe tentative fix I will propose is just to make the current default cpu allocator subclasses from `VisitableAllocator`, which save all my hacks to re-introduce a visitable default cpu allocator.\r\n\r\nI tried to find the commit that introduces the initial `cpu_allocator`, but it actually dated back to the very first commit of TF. Maybe @benoitsteiner or @martinwicke could give some comments here?", "It just came to my mind that I don't need to precede the MKL allocator; it's visitable (BFCAllocator) by default. I just need to precede the non-MKL default allocator, which is not visitable as in current stage.\r\n\r\nI haven't tested it yet, but presumably the interference issue should be resolved with a lower allocator registration priority than that of MKL (higher than default).", "I think it makes sense to try to make the default CPUAllocator visitable, but maybe not in this PR.  I may not understand the difficulties of doing so.  I'll open up a discussion with @vrv and @zheng-xq about it. ", "@tensorflow-jenkins test this please", "Seems the Windows build is broken perhaps because of a crashed build earlier:\r\n```\r\n11:51:15 Another git process seems to be running in this repository, e.g.\r\n11:51:15 an editor opened by 'git commit'. Please make sure all processes\r\n11:51:15 are terminated then try again. If it still fails, a git process\r\n11:51:15 may have crashed in this repository earlier:\r\n11:51:15 remove the file manually to continue.\r\n11:51:15 From https://github.com/tensorflow/tensorflow\r\n11:51:15  ! [new ref]               refs/pull/5992/head -> origin/pr/5992/head  (unable to update local ref)\r\n11:51:15 error: cannot lock ref 'refs/remotes/origin/pr/915/head': Unable to create 'c:/tf_jenkins/home/workspace/tensorflow-pr-win-cmake-py/.git/refs/remotes/origin/pr/915/head.lock': File exists.\r\n```", "Jenkins, test this please.\n\nOn Aug 4, 2017 1:17 PM, \"Paul Tucker\" <notifications@github.com> wrote:\n\n> *@poxvoculi* approved this pull request.\n>\n> This change looks fine to me. I'm not an expert on the OS config & BUILD\n> changes but they look consistent with existing practice.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/11392#pullrequestreview-54467368>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbR4bGnTyjSawhZaYGXyhdX5oOdCZks5sU3xzgaJpZM4OSCMo>\n> .\n>\n", "Thanks @poxvoculi. I have learned a lot as it is my first patch to OSS implementing an end to end feature. I really appreciate you for taking time reviewing my code. \r\n\r\nI am glad we could finally catch up with the 1.3 release :)\r\n\r\nBy the way, this patch is an effort I have worked on for a long time. As a grad student, it would not be possible without the funding from my lab (System Networking Lab in HKUST). I personally spent quite some time convincing my supervisor to open source it, given the condition that our credit may be acknowledged in the release notes. That would be immensely helpful to us.", "@byronyi This is a nice contribution and I'm glad you were able to take the time to do it.  I look forward to hearing from appreciative users.  I don't know anything about how OS contributors may be acknowledged in the release notes.  Do you wish to inquire about that?", "We have discussed that internally, and I think a simple note similar to e8082d5780c8763b3aefd27a90b632eef832eb1c would suffice :)", "This message was created automatically by mail delivery software.\n\nA message that you sent could not be delivered to one or more of its\nrecipients. This is a temporary error. The following address(es) deferred:\n\n  mazecreator@gmail.com\n    Domain mazecreator.com has exceeded the max emails per hour (26/25 (104%)) allowed.  Message will be reattempted later\n\n------- This is a copy of the message, including all the headers. ------\nReceived: from o10.sgmail.github.com ([167.89.101.201]:21026)\n\tby server2.lowesthostingrates.com with esmtps (TLSv1.2:ECDHE-RSA-AES128-GCM-SHA256:128)\n\t(Exim 4.89)\n\t(envelope-from <bounces+848413-e6d9-mazecreator=mazecreator.com@sgmail.github.com>)\n\tid 1ddkcm-0000Km-IE\n\tfor mazecreator@mazecreator.com; Fri, 04 Aug 2017 16:59:46 -0500\nDKIM-Signature: v=1; a=rsa-sha1; c=relaxed/relaxed; d=github.com; \n\th=from:reply-to:to:cc:in-reply-to:references:subject:mime-version:content-type:content-transfer-encoding:list-id:list-archive:list-post:list-unsubscribe; \n\ts=s20150108; bh=I+XY5aaYnuMYWTkL8rLESL+Ai/o=; b=QWInvodHLYIV/qbF\n\th0C5AqJM6BqWPNHh0SI8YuK47PGgmls6iQqgTbtnkrUwe83GllX/QhCZ44CQpVo7\n\tqTiWgT4UZl3756f65pVDtEKrQsleWcMSpjrODHwrN3N8/UH++xSBzVd4MBQT57kE\n\tog+6KQnjpyNfqPFjQGbCPUSNWo8=\nReceived: by filter0454p1mdw1.sendgrid.net with SMTP id filter0454p1mdw1-1327-5984F0B4-49\n        2017-08-04 22:09:56.68207495 +0000 UTC\nReceived: from github-smtp2b-ext-cp1-prd.iad.github.net (github-smtp2b-ext-cp1-prd.iad.github.net [192.30.253.17])\n\tby ismtpd0024p1mdw1.sendgrid.net (SG) with ESMTP id okXsfIqdRkmaL3TXzA__Zg\n\tfor <mazecreator@mazecreator.com>; Fri, 04 Aug 2017 22:09:56.621 +0000 (UTC)\nDate: Fri, 04 Aug 2017 22:09:56 +0000 (UTC)\nFrom: Bairen Yi <notifications@github.com>\nReply-To: tensorflow/tensorflow <reply@reply.github.com>\nTo: tensorflow/tensorflow <tensorflow@noreply.github.com>\nCc: Subscribed <subscribed@noreply.github.com>\nMessage-ID: <tensorflow/tensorflow/pull/11392/c320363773@github.com>\nIn-Reply-To: <tensorflow/tensorflow/pull/11392@github.com>\nReferences: <tensorflow/tensorflow/pull/11392@github.com>\nSubject: Re: [tensorflow/tensorflow] GPU Direct RDMA Out-of-Band Tensor\n Transport (#11392)\nMime-Version: 1.0\nContent-Type: multipart/alternative;\n boundary=\"--==_mimepart_5984f0b44e908_53463fb17ec05c3c4330ac\";\n charset=UTF-8\nContent-Transfer-Encoding: 7bit\nPrecedence: list\nX-GitHub-Sender: byronyi\nX-GitHub-Recipient: Mazecreator\nX-GitHub-Reason: subscribed\nList-ID: tensorflow/tensorflow <tensorflow.tensorflow.github.com>\nList-Archive: https://github.com/tensorflow/tensorflow\nList-Post: <mailto:reply@reply.github.com>\nList-Unsubscribe: <mailto:unsub+0118f3a0843ba2fc495f1964d46d10d5794eebb6403661a992cf00000001159cb2b492a169ce0e65489b@reply.github.com>,\n <https://github.com/notifications/unsubscribe/ARjzoBwn_ZD3a6exA3J9GnQmlq0OfNKMks5sU5a0gaJpZM4OSCMo>\nX-Auto-Response-Suppress: All\nX-GitHub-Recipient-Address: mazecreator@mazecreator.com\nX-SG-EID: BJ4qYjf5a3yL0lCrdDNghY4YYR+k1a+cluU6wEX1Jqyv7dGeOfMFLtMqikiOeYzSQYcJgmp02pY69C\n COLADrME8QZnUyZ0S9YnWWOGSyqJsLH2WJRrGsMl/d+bUTAzJXKalRdebXFVFTIP7SW53k3Gi1rPTC\n A/HZttqngETr0mM59GY5BiBWZ4PdBUK4qWfog2SPOwfNZS89RiCXtbPfdinktm1FQHhNAOAgp43OzG\n I=\nX-Spam-Status: No, score=\nX-Spam-Score:\nX-Spam-Bar:\nX-Ham-Report:\nX-Spam-Flag: NO\n\n----==_mimepart_5984f0b44e908_53463fb17ec05c3c4330ac\nContent-Type: text/plain;\n charset=UTF-8\nContent-Transfer-Encoding: 7bit\n\nWe have discussed that internally, and I think a simple note similar to e8082d5780c8763b3aefd27a90b632eef832eb1c would suffice :)\n\n-- \nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub:\nhttps://github.com/tensorflow/tensorflow/pull/11392#issuecomment-320363773\n----==_mimepart_5984f0b44e908_53463fb17ec05c3c4330ac\nContent-Type: text/html;\n charset=UTF-8\nContent-Transfer-Encoding: 7bit\n\n<p>We have discussed that internally, and I think a simple note similar to <a href=\"https://github.com/tensorflow/tensorflow/commit/e8082d5780c8763b3aefd27a90b632eef832eb1c\" class=\"commit-link\"><tt>e8082d5</tt></a> would suffice :)</p>\n\n<p style=\"font-size:small;-webkit-text-size-adjust:none;color:#666;\">&mdash;<br />You are receiving this because you are subscribed to this thread.<br />Reply to this email directly, <a href=\"https://github.com/tensorflow/tensorflow/pull/11392#issuecomment-320363773\">view it on GitHub</a>, or <a href=\"https://github.com/notifications/unsubscribe-auth/ARjzoLdWdMOJGl2zHAVrJfSXqJwViyI-ks5sU5a0gaJpZM4OSCMo\">mute the thread</a>.<img alt=\"\" height=\"1\" src=\"https://github.com/notifications/beacon/ARjzoNsNWYUQAFFD5PCoMIESS74uRwHaks5sU5a0gaJpZM4OSCMo.gif\" width=\"1\" /></p>\n<div itemscope itemtype=\"http://schema.org/EmailMessage\">\n<div itemprop=\"action\" itemscope itemtype=\"http://schema.org/ViewAction\">\n  <link itemprop=\"url\" href=\"https://github.com/tensorflow/tensorflow/pull/11392#issuecomment-320363773\"></link>\n  <meta itemprop=\"name\" content=\"View Pull Request\"></meta>\n</div>\n<meta itemprop=\"description\" content=\"View this Pull Request on GitHub\"></meta>\n</div>\n\n<script type=\"application/json\" data-scope=\"inboxmarkup\">{\"api_version\":\"1.0\",\"publisher\":{\"api_key\":\"05dde50f1d1a384dd78767c55493e4bb\",\"name\":\"GitHub\"},\"entity\":{\"external_key\":\"github/tensorflow/tensorflow\",\"title\":\"tensorflow/tensorflow\",\"subtitle\":\"GitHub repository\",\"main_image_url\":\"https://cloud.githubusercontent.com/assets/143418/17495839/a5054eac-5d88-11e6-95fc-7290892c7bb5.png\",\"avatar_image_url\":\"https://cloud.githubusercontent.com/assets/143418/15842166/7c72db34-2c0b-11e6-9aed-b52498112777.png\",\"action\":{\"name\":\"Open in GitHub\",\"url\":\"https://github.com/tensorflow/tensorflow\"}},\"updates\":{\"snippets\":[{\"icon\":\"PERSON\",\"message\":\"@byronyi in #11392: We have discussed that internally, and I think a simple note similar to e8082d5780c8763b3aefd27a90b632eef832eb1c would suffice :)\"}],\"action\":{\"name\":\"View Pull Request\",\"url\":\"https://github.com/tensorflow/tensorflow/pull/11392#issuecomment-320363773\"}}}</script>\n----==_mimepart_5984f0b44e908_53463fb17ec05c3c4330ac--\n", "I meet stuck problem on 1080ti today twice, first time I got warning says `tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_2_bfc) ran out of memory trying to allocate 2.29GiB. The call`, this time I got nothing, I see cpu and memory are still being used but gpu utility is 0%, this tf benchmarks program has run 3 hours...", "@poxvoculi Would you mind to review the last commit again? I have fixed several issues under VLOG, some of the rationale could be found [here](https://github.com/tensorflow/tensorflow/commit/ec1403e7dc2b919531e527d36d28659f60621c9e#commitcomment-23432313).", "After adding checksum support in VLOG, I found GDR will result in increasing loss for GPU when checksum is disabled. It seems that some synchronisation is required for truly direct DMA between NIC and GPU, and the stream executor seems to be place for me to look into.\r\n\r\nI am looking into the GDR docs [here](http://docs.nvidia.com/cuda/gpudirect-rdma/index.html#sync-behavior). \r\n\r\n@poxvoculi Any comments?", "Seems a merge is needed. Mind to kickoff testing again? ", "@poxvoculi We discussed a little bit internally and agree that getting GDR shipped on 1.3 is our priority. Would you mind putting GDR on the release notes and getting this PR merged? That would be great for potential users out there.", "1.3 has been cut a while ago, and we won't put additional features in this\nlate (we're already at RC2). This will have to wait until 1.4.\n", "So this PR will not be merged until 1.3 is released? \n\nI'm fine with it per se, but would it be possible for you guys to let us know when will be the merge window cutdown in the future releases? \n\nIt would be great for us (and all other contributors) to make better planning ahead, instead of struggling for missed deadlines.", "No, we can merge this PR any time, but it won't be in the 1.3 branch, and\nif anyone installs the 1.3 binary they won't see it's effects.\n\nThe branches are cut every 6 weeks or so. I don't want to encourage aiming\nfeatures at specific releases. The deadline is usually not good for\nquality. But if you say loud and early that you think a feature should be\nin the next release (and if it is ready), then we can plan for that. This\nfeature wasn't ready in time for 1.3 (~2 weeks ago) anyway, so not much\npoint in hurrying too much.\n", "You mentioned about the binary shipped, but this PR is in contrib and not built by default. The users have to turn on the related compile switch and build it from source themselves. Does the release policy apply to source release as well?", "There is no source release other than getting the source code from GitHub.\nSo once we merge this it's available for people to use.\n\nHowever if someone specifically asks to build the 1.3 branch, they will get\nthe source code which builds the 1.3 binary, which would not include this\nchange.\n", "Thanks for clarification! I actually just realized that :)", "@tensorflow-jenkins test this please", "@tensorflow-jenkins test this please", "Can one of the admins verify this patch?", "I thought I will make some further improvements, but @rmlarsen seems to be eager to merge this. Alright then, I think I will leave them to the future \ud83d\ude06 \r\n\r\nGood job guys, thank you all for all the feedbacks in this thread. Hope we could have some users soon so we could hear back from them.", "Thank you @byronyi for the contribution!\r\nI hope we'll start testing it soon (+ @bkovalev)\r\nJ", "I find first gpu's forward propagation is much slower than other gpus on same machine when training resnet101 using `grpc+gdr` on a 4 gpus worker machine (`grpc` may have same problem, but `grpc` is much slower so it may hide the problem.), I have run many times, trace file is in [here](https://drive.google.com/file/d/0B6phHPK0iUvdSk9hV2NIY1hkZ3M/view?usp=sharing).", "@byronyi I keep getting an error: `UnavailableError: No such device: cannot bind to rdma://hsw215:2302`\r\n\r\nNo matter what port I've tried I get that error. The hsw215 is a compute node. This is my cluster spec:\r\n```\r\nCLUSTER_SPEC_DICT: {'ps': ['hsw215:2300'], 'worker': ['hsw215:2301', 'hsw215:2302', 'hsw215:2303', 'hsw215:2304']}\r\n```\r\n\r\nI compiled TF 1.4 with GDR, and I have nv_peer_mem running:\r\n```\r\n$ ibv_devinfo\r\nhca_id: mlx5_0\r\n        transport:                      InfiniBand (0)\r\n        fw_ver:                         10.16.1006\r\n        node_guid:                      e41d:2d03:0006:ae40\r\n        sys_image_guid:                 e41d:2d03:0006:ae40\r\n        vendor_id:                      0x02c9\r\n        vendor_part_id:                 4113\r\n        hw_ver:                         0x0\r\n        board_id:                       MT_1210110019\r\n        phys_port_cnt:                  2\r\n        Device ports:\r\n                port:   1\r\n                        state:                  PORT_ACTIVE (4)\r\n                        max_mtu:                4096 (5)\r\n                        active_mtu:             4096 (5)\r\n                        sm_lid:                 1\r\n                        port_lid:               16\r\n                        port_lmc:               0x00\r\n                        link_layer:             InfiniBand\r\n\r\n                port:   2\r\n                        state:                  PORT_DOWN (1)\r\n                        max_mtu:                4096 (5)\r\n                        active_mtu:             4096 (5)\r\n                        sm_lid:                 0\r\n                        port_lid:               65535\r\n                        port_lmc:               0x00\r\n                        link_layer:             InfiniBand\r\n\r\n\r\n$ service nv_peer_mem status\r\nnv_peer_mem module is loaded.\r\n```\r\n\r\nMy code runs fine with `protocol='grpc+verbs'`. I get messages like:\r\n```\r\nI tensorflow/contrib/verbs/rdma_mgr.cc:56] connecting to remote node /job:worker/replica:0/task:0\r\n```\r\nRdma runs well, but I can't get the gdr working. Maybe I'm doing something stupid, but it's not clear from the README what else needs to be done. Thanks.\r\n", "@avolkov1 The GDR runtime binds to whatever IP you assigned, even if it is not an IB device. Please check with IP address first. Sometimes it resolves to different IP for the same host on different machines.", "@byronyi Thank you. Made some progress. I'm getting `Unavailable: Cannot find pinned memory region` errors. Have you come across that? I'm trying to run multigpu training. Again, this worked with `grpc+verbs`. Are there some gotchas with parameter servers on CPU.\r\n\r\nI get the RDMA GDR endpoints working:\r\n```\r\n1: 2017-10-19 11:17:07.804151: I tensorflow/contrib/gdr/gdr_memory_manager.cc:333] Accepted new RDMA connection\r\n2: 2017-10-19 11:17:07.803164: I tensorflow/contrib/gdr/gdr_memory_manager.cc:678] RDMA endpoint connected to rdma://hsw215.ib.cluster:2301\r\n0: 2017-10-19 11:17:08.033571: I tensorflow/contrib/gdr/gdr_memory_manager.cc:678] RDMA endpoint connected to rdma://hsw215.ib.cluster:2301\r\n1: 2017-10-19 11:17:08.033677: I tensorflow/contrib/gdr/gdr_memory_manager.cc:333] Accepted new RDMA connection\r\n1: 2017-10-19 11:17:21.449746: I tensorflow/contrib/gdr/gdr_memory_manager.cc:678] RDMA endpoint connected to rdma://hsw216.ib.cluster:2300\r\n2: 2017-10-19 11:17:21.448892: I tensorflow/contrib/gdr/gdr_memory_manager.cc:333] Accepted new RDMA connection\r\n3: 2017-10-19 11:17:21.455124: I tensorflow/contrib/gdr/gdr_memory_manager.cc:678] RDMA endpoint connected to rdma://hsw216.ib.cluster:2300\r\n2: 2017-10-19 11:17:21.455214: I tensorflow/contrib/gdr/gdr_memory_manager.cc:333] Accepted new RDMA connection\r\n1: 2017-10-19 11:17:22.995750: I tensorflow/contrib/gdr/gdr_memory_manager.cc:678] RDMA endpoint connected to rdma://hsw215.ib.cluster:2300\r\n0: 2017-10-19 11:17:22.995812: I tensorflow/contrib/gdr/gdr_memory_manager.cc:333] Accepted new RDMA connection\r\n2: 2017-10-19 11:17:29.572063: I tensorflow/contrib/gdr/gdr_memory_manager.cc:678] RDMA endpoint connected to rdma://hsw216.ib.cluster:2301\r\n3: 2017-10-19 11:17:29.572255: I tensorflow/contrib/gdr/gdr_memory_manager.cc:333] Accepted new RDMA connection\r\n3: 2017-10-19 11:17:29.572637: I tensorflow/contrib/gdr/gdr_memory_manager.cc:678] RDMA endpoint connected to rdma://hsw215.ib.cluster:2300\r\n0: 2017-10-19 11:17:29.573710: I tensorflow/contrib/gdr/gdr_memory_manager.cc:333] Accepted new RDMA connection\r\n0: 2017-10-19 11:17:38.169948: I tensorflow/contrib/gdr/gdr_memory_manager.cc:678] RDMA endpoint connected to rdma://hsw216.ib.cluster:2301\r\n3: 2017-10-19 11:17:38.169127: I tensorflow/contrib/gdr/gdr_memory_manager.cc:333] Accepted new RDMA connection\r\n1: 2017-10-19 11:17:49.647909: I tensorflow/contrib/gdr/gdr_memory_manager.cc:333] Accepted new RDMA connection\r\n3: 2017-10-19 11:17:49.646921: I tensorflow/contrib/gdr/gdr_memory_manager.cc:678] RDMA endpoint connected to rdma://hsw215.ib.cluster:2301\r\n```\r\nI'm running this on slurm. The first number above is the task id. Here's my cluster setup:\r\n```\r\nCLUSTER_SPEC_DICT: {'ps': ['hsw215.ib.cluster:2300', 'hsw216.ib.cluster:2300'], 'worker': ['hsw215.ib.cluster:2301', 'hsw216.ib.cluster:2301']}\r\n# slurm task 0 - hsw215.ib.cluster:2300 - ps 0\r\n# slurm task 1 - hsw215.ib.cluster:2301 - worker 0\r\n# slurm task 2 - hsw216.ib.cluster:2300 - ps 1\r\n# slurm task 3 - hsw216.ib.cluster:2301 - worker 1\r\n```\r\nThe parameter servers run on cpu and each worker has 4 GPUs. Devices list:\r\n```\r\n['/job:ps/task:0', '/job:ps/task:1']\r\n['/job:worker/task:0/device:GPU:0', '/job:worker/task:0/device:GPU:1', '/job:worker/task:0/device:GPU:2', '/job:worker/task:0/device:GPU:3', '/job:worker/task:1/device:GPU:0', '/job:worker\r\n/task:1/device:GPU:1', '/job:worker/task:1/device:GPU:2', '/job:worker/task:1/device:GPU:3']\r\n```\r\nERRORS:\r\n```\r\n1:       [[Node: _recv_concatenate_1_target_0_S581 = _Recv[client_terminated=false, recv_device=\"/job:ps/replica:0/task:0/device:GPU:0\", send_device=\"/job:worker/replica:0/task:0/device:CPU:0\", send_device_in\r\ncarnation=1867630968541887687, tensor_name=\"edge_3354__recv_concatenate_1_target_0\", tensor_type=DT_FLOAT, _device=\"/job:ps/replica:0/task:0/device:GPU:0\"]()]]\r\n1:       [[Node: training/RMSprop/gradients/concatenate_1/concat_grad/Slice_2_S699 = _Recv[client_terminated=false, recv_device=\"/job:worker/replica:0/task:0/device:GPU:2\", send_device=\"/job:ps/replica:0/task\r\n:0/device:CPU:0\", send_device_incarnation=-1707922374272032114, tensor_name=\"edge_1755_training/RMSprop/gradients/concatenate_1/concat_grad/Slice_2\", tensor_type=DT_FLOAT, _device=\"/job:worker/replica:0/task:\r\n0/device:GPU:2\"]()]]\r\n1: 2017-10-19 11:17:49.641150: W tensorflow/core/framework/op_kernel.cc:1192] Unavailable: Cannot find pinned memor\r\n1: y region\r\n1:       [[Node: _recv_concatenate_1_target_0_S581 = _Recv[client_terminated=false, recv_device=\"/job:ps/replica:0/task:0/device:GPU:0\", send_device=\"/job:worker/replica:0/task:0/device:CPU:0\", send_device_in\r\ncarnation=1867630968541887687, tensor_name=\"edge_3354__recv_concatenate_1_target_0\", tensor_type=DT_FLOAT, _device=\"/job:ps/replica:0/task:0/device:GPU:0\"]()]]\r\n1:       [[Node: training/RMSprop/gradients/concatenate_1/concat_grad/Slice_2_S699 = _Recv[client_terminated=false, recv_device=\"/job:worker/replica:0/task:0/device:GPU:2\", send_device=\"/job:ps/replica:0/task\r\n:0/device:CPU:0\", send_device_incarnation=-1707922374272032114, tensor_name=\"edge_1755_training/RMSprop/gradients/concatenate_1/concat_grad/Slice_2\", tensor_type=DT_FLOAT, _device=\"/job:worker/replica:0/task:\r\n0/device:GPU:2\"]()]]\r\n1: 2017-10-19 11:17:49.641155: W tensorflow/core/framework/op_kernel.cc:1192] Unavailable: Cannot find pinned memory region\r\n1:       [[Node: _recv_concatenate_1_target_0_S581 = _Recv[client_terminated=false, recv_device=\"/job:ps/replica:0/task:0/device:GPU:0\", send_device=\"/job:worker/replica:0/task:0/device:CPU:0\", send_device_in\r\ncarnation=1867630968541887687, tensor_name=\"edge_3354__recv_concatenate_1_target_0\", tensor_type=DT_FLOAT, _device=\"/job:ps/replica:0/task:0/device:GPU:0\"]()]]\r\n1:       [[Node: training/RMSprop/gradients/concatenate_1/concat_grad/Slice_2_S699 = _Recv[client_terminated=false, recv_device=\"/job:worker/replica:0/task:0/device:GPU:2\", send_device=\"/job:ps/replica:0/task\r\n:0/device:CPU:0\", send_device_incarnation=-1707922374272032114, tensor_name=\"edge_1755_training/RMSprop/gradients/concatenate_1/concat_grad/Slice_2\", tensor_type=DT_FLOAT, _device=\"/job:worker/replica:0/task:\r\n0/device:GPU:2\"]()]]\r\n\r\n3: 2017-10-19 11:18:25.395597: E tensorflow/contrib/gdr/gdr_rendezvous_mgr.cc:71] Cannot find pinned memory region from allocator cpu_pool\r\n3: 2017-10-19 11:18:25.395852: E tensorflow/contrib/gdr/gdr_rendezvous_mgr.cc:71] Cannot find pinned memory region from allocator cuda_host_bfc\r\n3: 2017-10-19 11:18:25.395913: E tensorflow/contrib/gdr/gdr_rendezvous_mgr.cc:71] Cannot find pinned memory region from allocator cpu_pool\r\n3: 2017-10-19 11:18:25.396150: E tensorflow/contrib/gdr/gdr_rendezvous_mgr.cc:71] Cannot find pinned memory region from allocator cpu_pool\r\n3: 2017-10-19 11:18:25.396200: E tensorflow/contrib/gdr/gdr_rendezvous_mgr.cc:71] Cannot find pinned memory region from allocator cpu_pool\r\n```\r\n", "@avolkov1 I suspect it is because of the limit on page locked memory size. Check with `ulimit -l` or `ulimit -a` to see the limit of your current user. \r\n\r\nEDIT: you might need your sysadmin to modify the ulimit. Usually it shall be set `unlimited` with your IB driver installation, but it does depend on your vendor. See `man limits.conf` for explanation.", "@byronyi Thanks. I looked at it. It seems to be unlimited.\r\n```\r\nhsw228$ ulimit -l\r\nunlimited\r\nhsw228$ ulimit -a\r\ncore file size          (blocks, -c) 0\r\ndata seg size           (kbytes, -d) unlimited\r\nscheduling priority             (-e) 0\r\nfile size               (blocks, -f) unlimited\r\npending signals                 (-i) 1031351\r\nmax locked memory       (kbytes, -l) unlimited\r\nmax memory size         (kbytes, -m) unlimited\r\nopen files                      (-n) 4096\r\npipe size            (512 bytes, -p) 8\r\nPOSIX message queues     (bytes, -q) 819200\r\nreal-time priority              (-r) 0\r\nstack size              (kbytes, -s) unlimited\r\ncpu time               (seconds, -t) unlimited\r\nmax user processes              (-u) 4096\r\nvirtual memory          (kbytes, -v) unlimited\r\nfile locks                      (-x) unlimited\r\n```\r\n", "@avolkov1 I failed to reproduce your issue on a fresh installation of vendor provided OFED on my testbed. Would you mind to paste the full log?", "@byronyi Will do. Thank you very much. Give me a day or two (busy with work related stuff). I'll post the error log and the code I use to run.\r\n"]}, {"number": 11391, "title": "\" argument unused '-mcpu=native' \" makes logs 3 times larger", "body": "### System information\r\n\r\n- macOS 10.12.4\r\n- Building from source according to the docs\r\n- 'v1.2.0-1874-g75f56f0bd' 1.2.1\r\n- Python 3.6.1 :: Anaconda 4.4.0 (x86_64)\r\n- bazel: stable 0.5.2\r\n- no cuda\r\n- clang: Apple LLVM version 8.1.0 (clang-802.0.42)\r\n\r\n### Description\r\n\r\nWhen building TF on macOS I get lots of these warnings:\r\n```\r\nclang: warning: argument unused during compilation: '-mcpu=native' [-Wunused-command-line-argument]\r\n```\r\nIt makes the log three times larger\r\nIs it clang only issue? How to fix it? Is it enough just to check [here](https://github.com/tensorflow/tensorflow/blob/master/configure#L301-L306) if compiler is clang?\r\n\r\n", "comments": []}, {"number": 11390, "title": "I used TensorFlow to build a deep learning training network and test network, and I was going to use the weights in the training network to use as the weight of the test network, where the training network and the test network were not the same, how should I solve?", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttp://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 11389, "title": "CUDA_ERROR_LAUNCH_FAILED", "body": "I'm useing CNN like Tutorials\r\ntensorflow-gpu 1.2.1\r\nCUDA Toolkit 8.0\r\ncuDNN 5.1\r\npython 3.5.2\r\nwindows10\r\n![image](https://user-images.githubusercontent.com/15059661/27991248-2b1ca360-64a3-11e7-802e-d50dd64acc64.png)\r\nwhen it run :\r\n> 2017-07-09 11:51:59.107178: W c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-09 11:51:59.107569: W c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-09 11:51:59.107982: W c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-09 11:51:59.108244: W c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-09 11:51:59.108549: W c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-09 11:51:59.109679: W c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-09 11:51:59.408255: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:940] Found device 0 with properties: \r\nname: GeForce GTX 1080 Ti\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.721\r\npciBusID 0000:01:00.0\r\nTotal memory: 11.00GiB\r\nFree memory: 9.12GiB\r\n2017-07-09 11:51:59.408712: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:961] DMA: 0 \r\n2017-07-09 11:51:59.408892: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:971] 0:   Y \r\n2017-07-09 11:51:59.409056: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0)\r\n3153\r\n2017-07-09 11:52:04.245057: E c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:1068] failed to synchronize the stop event: CUDA_ERROR_LAUNCH_FAILED\r\n2017-07-09 11:52:04.245474: E c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\stream_executor\\cuda\\cuda_timer.cc:54] Internal: error destroying CUDA event in context 000001A873C64B60: CUDA_ERROR_LAUNCH_FAILED\r\n2017-07-09 11:52:04.245791: E c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\stream_executor\\cuda\\cuda_timer.cc:59] Internal: error destroying CUDA event in context 000001A873C64B60: CUDA_ERROR_LAUNCH_FAILED\r\n2017-07-09 11:52:04.246154: F c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\stream_executor\\cuda\\cuda_dnn.cc:1961] failed to enqueue convolution on stream: CUDNN_STATUS_MAPPING_ERROR\r\n[Finished in 19.7s]\r\n\r\nif i use tensorflow without gpu, it's ok\r\n", "comments": ["It is possible our latest (1.2.1) binaries are built against cudnn 6.\r\nis it possible to try and upgrade cudnn on your machine?\r\n\r\n@av8ramit FYI I think this has been a side effect of our efforts to upgrade our CI to cudnn6. We were not able to add support for multiple cudnn versions on the CI machines.", "@gunan \r\ni changed my cudnn to 6\r\nand error code:\r\n\r\n> 2017-07-11 13:24:16.891625: W c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-11 13:24:16.892008: W c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-11 13:24:16.892356: W c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-11 13:24:16.892652: W c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-11 13:24:16.892934: W c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-11 13:24:16.893191: W c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-11 13:24:17.194076: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:940] Found device 0 with properties: \r\nname: GeForce GTX 1080 Ti\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.721\r\npciBusID 0000:01:00.0\r\nTotal memory: 11.00GiB\r\nFree memory: 9.08GiB\r\n2017-07-11 13:24:17.194444: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:961] DMA: 0 \r\n2017-07-11 13:24:17.194632: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:971] 0:   Y \r\n2017-07-11 13:24:17.194824: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0)\r\nDevice mapping:\r\n/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0\r\n2017-07-11 13:24:17.523773: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\direct_session.cc:265] Device mapping:\r\n/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0\r\n\r\n3153\r\nb2_c1: (VariableV2): /job:localhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:17.608387: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] b_c1: (VariableV2)/job:localhost/replica:0/task:0/gpu:0\r\nb_c1/Assign: (Assign): /job:localhost/r2eplica:0/task:0/gpu:0\r\n017-07-11 13:24:17.608758: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] b_c1/Assign: (Assign)/job:localhost/replica:0/task:0/gpu:0\r\nW2_c1: (VariableV2): /job:localhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:17.609212: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] W_c1: (VariableV2)/job:localhost/replica:0/task:0W/gpu:0\r\n_c1/Initializer/random_normal/RandomStandardNormal: (RandomStandardNormal): /job:localhost/replica:02017-07-11 13:24:17.60957/task:0/gpu:01: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gp\r\nu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] W_c1/Initializer/random_normal/RandomStandardNormal: (RandomStandardNormal)/job:localhost/replicWa:0/task:0/gpu:0\r\n_c1/Initializer/random_normal/mul: (Mul): /job:localhost/replica:0/task:0/gp2017-07-11 13:24:17.60993u:0\r\n2: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] W_c1/Initializer/random_normal/mul: (Mul)/job:localhost/replica:0/taWsk:0/gpu:0\r\n_c1/Initializer/random_normal: (Add): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:17.610274: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] W_c1/Initializer/random_normal: (Add)/job:localhost/repWlica:0/task:0/gpu:0\r\n_c1/Assign: (Assign): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:17.610573: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] W_c1/Assign: (Assign)/job:localhost/replica:0/task:0/gpu:0\r\ninit: (NoOp): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:17.610858: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] init: (NoOp)/job:localhost/replica:0/task:0/gpu:0\r\nb_c1/Initializer/Const: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:17.611179: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] b_c1/IW_c1/Initializer/randnitializer/Const: (Const)/job:localhost/replica:0/task:0/gpu:0\r\n2om_normal/stddev: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:17.611490: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] W_c1/Initializer/random_normal/stddev: (Const)/job:localhost/replica:0/task:0/gpu:0\r\nW_c1/Initializer/random_normal/mean: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:17.611837: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] W_c1/Initializer/random_normal/mean: (Const)/job:localhost/replica:0/task:0/gpu:0W\r\n_c1/Initializer/random_normal/shape: (Const2): /job:localhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:17.612156: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] W_c1/Initializer/random_normal/shape: (Const)/job:localhost/replica:0/task:0/gpu:0\r\nD2ecodePng: (DecodePng): /job:localhost/replica:0/task:0/cpu:0\r\n017-07-11 13:24:18.370208: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng: (DecodePng)/job:localhost/replicRa:0/task:0/cpu:0\r\neshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:18.370547: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape: (Reshape)/job:localhost/repl_ica:0/task:0/gpu:0\r\nretval_Reshape_0_0: (_Retval): /job:localhost/replica:0/task:0/cpu:0\r\n2017-07-11 13:24:18.370879: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] _retval_ResRhape_0_0: (_Retval)/job:localhost/replica:0/task:0/cpu:0\r\neshape/shape: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:18.371138: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape/shape: (Const)/job:localhost/replica:0/task:0/gpu:0D\r\necodePng/contents: (Const): /job:loc2alhost/replica:0/task:0/cpu:0\r\n017-07-11 13:24:18.371430: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng/contents: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nD2ecodePng_1: (DecodePng): /job:localhost/replica:0/task:0/cpu:0\r\n017-07-11 13:24:18.424440: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_1: (DecodePng)/job:localhost/replica:0/task:0R/cpu:0\r\neshape_1: (Reshape): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:18.424824: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_1: (Reshape)/job:localhost/replica:0/task:0/gpu:0\r\n_2retval_Reshape_1_0_0: (_Retval): /job:localhost/replica:0/task:0/cpu:0\r\n017-07-11 13:24:18.425118: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] _retval_Reshape_1_0_0: (_Retval)/job:loRcalhost/replica:0/task:0/cpu:0\r\neshape_1/shape: (Const): /job:localhost/replica:0/task:0/gpu:0\r\nD2017-07-11 13:24:18.425444: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_1/shape: (Const)/job:localhost/replecodePng_1/contents: (Const): /ica:0/task:0/gpu:0\r\njob:localhost/replica:0/task:0/cpu:02\r\n017-07-11 13:24:18.425741: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_1/contents: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nD2017-07-11 13:24:18.470674: I c:\\tf_jenkins\\home\\workspace\\releasecodePng_2: (DecodePng): /job:localhost/replica:0/task:0/cpu:0\r\ne-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_2: (DecodePng)/job:localhost/replica:0/task:0/cpu:0\r\nReshape_2: (Reshape): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:18.471169: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_2: (Reshape)/job:localhost/replica:0/task:0/gpu:0\r\n_retval_Reshape_2_0_0: (_Retval): /job:localhost/replica:0/task:0/cpu:0\r\n2017-07-11 13:24:18.471446: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] _retval_Reshape_2_0_0: (_Retval)/job:localhost/replica:0/task:0/cpu:0\r\nReshape_2/shape: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:18.471739: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_2/shape: (Const)/job:localhost/replica:0/task:0/gpu:0\r\nDecodePng_2/contents: (Const): /job:localhost/replica:0/task:0/cpu:0\r\n2017-07-11 13:24:18.472012: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_2/contents: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nD2ecodePng_3: (DecodePng): /job:localhost/replica:0/task:0/cpu:0\r\n017-07-11 13:24:18.509055: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_3: (DecodePng)/job:localhost/replica:0/task:0/cpuR:0\r\neshape_3: (Reshape): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:18.509371: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_3: (Reshape)/job:localhost/replica:0/tas_k:0/gpu:0\r\nretval_Reshape_3_0_0: (_Retval): /job:localhos2t/replica:0/task:0/cpu:0\r\n017-07-11 13:24:18.509647: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] _retval_Reshape_3_0_0: (_Retval)/job:localhost/replica:0/task:0/cpu:0\r\nReshape_3/shape: (Const): /job:localhost/replica:0/task:02017-07-11 13:24:18.509941: I c:\\tf_jenkin/gpu:0\r\ns\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_3/shape: (Const)/job:localhost/replica:0/task:0/gpu:0\r\nD2ecodePng_3/contents: (Const): /job:localhost/replica:0/task:0/cpu:0\r\n017-07-11 13:24:18.510188: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_3/contents: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nD2ecodePng_4: (DecodePng): /job:localhost/replica:0/task:0/cpu:0\r\n017-07-11 13:24:18.546810: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_4: (DecodePng)/job:localhost/replica:0/task:0/cpu:0\r\nReshape_4: (Reshape): /job:localhost/replica:0/task:0/gpu:20\r\n_017-07-11 13:24:18.547270: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_4: (Reshape)/job:localhost/replica:0/task:0/gpu:0\r\nretval_Reshape_4_0_0: (_Ret2017-07-11 13:24:18.547593: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\val): /job:localhost/replica:0/task:0/cpu:0\r\n35\\tensorflow\\core\\comRmon_runtime\\simple_placer.cc:847] _retval_Reshape_4_0_0: (_Retval)/job:localhost/replica:0/task:0/cpu:0\r\neshape_4/shape: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:18.547888: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_4/shape: (Const)/job:localhost/replica:0/task:0/gpu:D0\r\necodePng_4/contents: (Const): /job:localhost/replica:0/task:0/cpu:0\r\n2017-07-11 13:24:18.548207: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_4/contents: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nD2ecodePng_5: (DecodePng): /job:localhost/replica:0/task:0/cpu:0\r\n017-07-11 13:24:18.595629: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_5: (DecodePng)/job:localhost/replica:0/task:0/cpu:0\r\nR2eshape_5: (Reshape): /job:localhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:18.596045: I c:\\tf_jenkins\\_home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_5: (Reshape)/job:localhost/replica:0/task:0/gpu:0\r\nretval_Reshape_5_0_0: (_Retval): /job:localhost/replica:0/task:0/cpu:0\r\n2017-07-11 13:24:18.596337: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847]R _retval_Reshape_5_0_0: (_Retval)/job:localhost/replica:0/task:0/cpu:0\r\neshape_5/shape: (Const): /jo2017-07-11 13:24:18.596631: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorb:localhost/replica:0/task:0/gpu:0\r\nflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_5/shape: (Const)/job:localhost/replica:0/task:0/gpu:0\r\nDecodePng_5/contents: (Const): /job:localhost/replica:0/task:0/cpu:0\r\n2017-07-11 13:24:18.596924: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_5/contents: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nD2ecodePng_6: (DecodePng): /job:localhost/replica:0/task:0/cpu:0\r\n017-07-11 13:24:18.637777: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_6: (DecodePng)/job:localhost/replica:0/task:0/cpu:0\r\nReshape_6: (Reshape): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:18.638232: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_6: (Reshape)/job:localhost/replica:0/task:0/gpu:0\r\n_2retval_Reshape_6_0_0: (_Retval): /job:localhost/replica:0/task:0/cpu:0\r\n017-07-11 13:24:18.638522: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] _retval_Reshape_6_0_0: (_ReRtval)/job:localhost/replica:0/task:0/cpu:0\r\neshape_6/shape: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:18.638820: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_6/shDape: (Const)/job:localhost/replica:0/task:0/gpu:0\r\n2ecodePng_6/contents: (Const): /job:localhost/replica:0/task:0/cpu:0\r\n017-07-11 13:24:18.639152: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_6/contents: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nD2ecodePng_7: (DecodePng): /job:localhost/replica:0/task:0/cpu:0\r\nReshape_7: (Reshape): /job:localhost/replica:0/task:0/gpu:0\r\n_retval_Reshape_7_0_0: (_Retval): /job:localhost/replica:0/ta017-07-11 13:24:18.665326: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_7: (DecodePng)/job:localhost/replica:0/task:0/cpu:0\r\n2017-07-11 13:24:18.665600: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_7: (Reshape)/job:localhost/replica:0/task:0/gpu:0\r\nsk:0/cpu:0\r\n2017-07-11 13:24:18.665930: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] _retval_Reshape_7_0_0: (_Retval)/job:localhost/replica:0/task:0/cpu:0\r\nReshape_7/shape: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:18.666262: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_7/shape: (Const)/job:localhost/replica:0/task:0/gpu:0\r\nDecodePng_7/contents: (Const): /job:localhost/replica:0/task:0/cp2u:0\r\n017-07-11 13:24:18.666612: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_7/contents: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nD2ecodePng_8: (DecodePng): /job:localhost/replica:0/task:0/cpu:0\r\n017-07-11 13:24:18.718294: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_8: (DecodePng)/job:localhost/replica:0/tasRk:0/cpu:0\r\neshape_8: (Reshape): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:18.718708: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common__retval_Reshape_8_0_0: (_Retval): /job:localhost/replicaruntime\\simple_placer.cc:847] Reshape_8: (Reshape)/job:localhost/replica:0/task:0/gpu:0\r\n:0/task:0/cpu:0\r\n2017-07-11 13:24:18.719101: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] _retval_Reshape_8_0_0: (_Retval)/job:localhost/replica:0/task:0/cpu:0\r\nReshape_8/shape: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:18.719403: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_8/shape: (Const)/job:localhost/replica:0/task:0/gpu:0\r\nDecodePng_8/contents: (Const): /job:localhost/replica:0/task:0/2cpu:0\r\n017-07-11 13:24:18.719683: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_8/contents: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nD2ecodePng_9: (DecodePng): /job:localhost/replica:0/task:0/cpu:0\r\n017-07-11 13:24:18.753886: I c:\\tf_jenkins\\home\\workspace\\release-win\\mReshape_9: (Reshape): \\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_9: (DecodePng)/job:localhost/replica:0/task:0/cpu:0\r\n/job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:18.754228: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-g_retval_Reshape_9_0_0: (_Retval): /job:localhost/replica:0/task:0/cpu:0\r\npu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_9: (Reshape)/job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:18.754612: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtimeR\\simple_placer.cc:847] _retval_Reshape_9_0_0: (_Retval)/job:localhost/replica:0/task:0/cpu:0\r\neshape_9/shape: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:18.754912: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] RDeshape_9/shape: (Const)/job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:18.755338: I c:\\tf_jenkins\\home\\worecodePng_9/contents: (Const): /job:localhost/replica:0/task:0/kspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\commcpu:0\r\non_runtime\\simple_placer.cc:847] DecodePng_9/contents: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nD2017-07-11 13:24:18.795384: I c:\\tf_jenkins\\home\\workspace\\releecodePng_10: (DecodePng): /job:localhost/replica:0/task:0/cpu:0\r\nase-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_10: (DecodePng)/job:localhost/replica:0/task:0/cpu:0\r\nR2017-07-11 13:24eshape_10: (Reshape): /job:localhost/replica:0/task:0/gpu:0\r\n:18.795762: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_10: (Reshape)/job:localhos_t/replica:0/task:0/gpu:0\r\nretval_Reshape_10_0_0: (_Retval): /job:localhost/replica:0/task:0/cpu:0\r\n2017-07-11 13:24:18.796094: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] _retval_Reshape_10_0_0: (_RetvalR)/job:localhost/replica:0/task:0/cpu:0\r\n2eshape_10/shape: (Const): /job:localhost/replica:0/task:017-07-11 13:24:18.796432: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\w0/gpu:0\r\nindows-gpu\\py\\D35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_10/shape: (Const)/job:localhost/replica:0/task:0/gpu:0\r\necodePng_10/contents: (Const): /job:l2ocalhost/replica:0/task:0/cpu:0\r\n017-07-11 13:24:18.796721: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_10/contents: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nD2ecodePng_11: (DecodePng): /job:localhost/replica:0/task:0/cpu:0\r\n017-07-11 13:24:18.871950: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_11: (DecodePng)/job:localhost/replica:0/task:0/cpRu:0\r\n2017-07-11 13:24:18.872705: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_11: (Reshape)/job:eshape_11: (Reshape): /job:localhost/replica:0/task:0/gpu:0\r\nl_ocalhost/replica:0/task:0/gpu:0\r\nretval_Reshape_11_0_0: (_Retval): /job:localhost/replica:0/task:0/cpu:0\r\n2017-07-11 13:24:18.873339: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] _retvalR_Reshape_11_0_0: (_Retval)/job:localhost/replica:0/task:0/cpu:0\r\n2017-07-11 13:24:18.874083: I c:\\tf_jenkins\\home\\workspace\\release-wieshape_11/shape: (Const): /job:localhost/replica:0/task:0/gpu:0\r\nDecodePng_11/contents: (Const): /jn\\m\\windows-ob:localhost/replica:0/task:0/cpu:0\r\ngpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_11/shape: (Const)/job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:18.874608: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_11/contents: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nD2017-07-11 13:24:18.933798: I c:\\tf_jenkins\\home\\workecodePng_12: (DecodePng): /job:localhost/replica:0/task:0/cpu:0\r\nsReshape_12: (Reshape): /job:localhost/replica:0/task:0/gppace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_12: (DecodePng)/job:localhost/replica:0/task:0/cpu:0\r\nu:0\r\n2017-07-11 13:24:18.934164: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\_retval_Reshape_12_0_0: (_common_runtime\\simple_placer.cc:847] Reshape_12: (Reshape)/job:localhost/replica:0/task:0/gpu:0\r\n2Retval): /job017-07-11 13:24:18:localhost/replica:0/task:0/cpu:0\r\n.934545: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] _retval_Reshape_12_0_0: (_Retval)/job:localhost/replica:0/task:0/cpu:0\r\nReshape_12/shape: (Const): /job:localhost/replica:0/2task:0/gpu:0\r\n017-07-11 13:24:18.934891: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_12/shape: (Const)/job:localhost/replica:0/task:0/gpu:0\r\nD2ecodePng_12/contents: (Const): /job:localhost/replica:0/task:0/cpu:0\r\n017-07-11 13:24:18.935230: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_12/contents: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nDecodePng_13: (DecodePng): /job:localhost/replica:0/task:0/cpu:0\r\n2017-07-11 13:24:18.983237: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placeRr.cc:847] DecodePng_13: (DecodePng)/job:localhost/replica:0/task:0/cpu:0\r\neshape_13: (Reshape): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:18._retval_Reshape_13_0_0: (_Retval): /job983646: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_13: (Reshape)/job:localhost/replica:0/task:0/gpu:0\r\n:localhost/replica:0/task:0/cpu:0\r\n2017-07-11 13:24:18.983970: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] _retval_Reshape_1R3_0_0: (_Retval)/job:localhost/replica:0/task:0/cpu:0\r\neshape_13/shape: (Const): /job:localhost/replica:0/2task:0/gpu:0\r\n017-07-11 13:24:18.984383: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_13/shape: (Const)/job:localhost/replica:0/task:0/gpu:0\r\nDecodePng_13/contents: (Const): /job:localhost/replica:0/task:0/cpu:02\r\n017-07-11 13:24:18.984735: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_13/contents: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nDecodePng_14: (DecodePng): /job:localhost/replica:0/task:0/cpu:0\r\n2017-07-11 13:24:19.039637: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_14:R (DecodePng)/job:localhost/replica:0/task:0/cpu:0\r\neshape_14: (Reshape): /job:localhost/replica:0/task:0/gpu:20\r\n017-07-11 13:24:19.040020: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_14: (Reshape)/job:localhost_/replica:0/tretval_Reshape_14_0_0: (_Retval): /job:localhoask:0/gpu:0\r\nst/replica:0/task:0/cpu:0\r\n2017-07-11 13:24:19.040404: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\teReshape_14/shape: (Const): /job:localhost/rnsorflow\\core\\common_runtime\\simple_placer.cc:847] _retval_Reshape_14_0_0: (_Retval)/job:localhost/replica:0/task:0/cpu:0\r\n2017-07-11 1eplica:0/task:0/gpu:0\r\n3:24:19.040743: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_14/shape: (Const)/job:localhost/replica:0/task:0/gpu:0\r\nDecodePng_14/contents: (Const): /job:localhost/replica:0/task:0/cpu:0\r\n2017-07-11 13:24:19.041522: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_14/contents: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nD2017-07-11 13:24:19.095289: I cecodePng_15: (DecodePng): /job:localhost/replica:0/task:0/cpu:0\r\n:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_15: (DecodePnRg)/job:localhost/replica:0/task:0/cpu:0\r\neshape_15: (Reshape): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.095658: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847]_ Reshape_15: (Reshape)/job:localhost/replica:0/task:0/gpu:0\r\n2retval_Reshape_15_0_0: (_Retval): /job:localhost/replica:0/task:0/cpu:0\r\n017-07-11 13:24:19.095917: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] _retval_Reshape_15_0_0: (_Retval)/job:localhost/replica:0/task:0/cpu:0\r\nReshape_15/shape: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.096193: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_15/shape: (Const)/job:localhost/replica:0/task:0/gpu:0\r\nDecodePng_15/contents: (Const): /job:localhost/replica:0/task:0/cpu:0\r\n2017-07-11 13:24:19.096515: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_15/contents: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nD2017-07-11 13:24:19.143994: I ecodePng_16: (DecodePng): /job:localhost/replica:0/task:0/cpu:0\r\nc:\\tf_jenkins\\Reshape_16: (Reshape): /job:localhost/replica:0/task:0/gpu:0\r\n_retval_Reshape_16_0_0: (_Retval): /job:localhost/replica:0/task:0/cpu:0\r\nhome\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_16: (DecodePng)/job:localhost/replica:0/task:0/cpu:0\r\n2017-07-11 13:24:19.144309: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_16: (Reshape)/job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.144585: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] _retval_Reshape_16_0_0: (_Retval)/joRb:localhost/replica:0/task:0/cpu:0\r\n2eshape_16/shape: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:19.144992: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_16/shape: (Const)/job:localhost/replica:0/task:0/gpu:0\r\nDecodePng_16/contents: (Const): /job:localhost/replica:0/task:0/cpu:0\r\n2017-07-11 13:24:19.145290: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_16/contents: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nD2017-07-11 13:24:19.199906: I c:\\tf_jenkins\\home\\wecodePng_17: (DecodePng): /job:localhost/replica:0/task:0/cpu:0\r\norkspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_17: (DecodePng)/job:localhost/replica:0/task:0/cpu:0\r\n2017-07-11 13:24R:19.200290: eshape_17: (Reshape): /job:localhost/replica:0/task:0/gpu:0\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_17: (Reshape)/job:l_ocalhost/replica:0/task:0/gpu:0\r\nretval_Reshape_17_0_0: (_Retval): /job:localhost/replica:0/task:0/cpu:0\r\n2017-07-11 13:24:19.200565: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] _retval_Reshape_17_0_0: (_Retval)/job:localhost/replica:0/task:0/Rcpu:0\r\neshape_17/shape: (Co2nst): /job:localhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:19.200854: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Reshape_17/shape:DecodePng_17/contents: (Const): /job:localhost/replica:0/task:0/cpu:0\r\n (Const)/job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.201178: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] DecodePng_17/contents: (Const)/job:localhost/replica:0/task:0/cpu:0\r\ng2radients/Sum_grad/Fill: (Fill): /job:localhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:19.247153: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Sum_grad/Fill: (Fill)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Sum_grad/range: (Range): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.247574: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradiengts/Sum_grad/range: (Range)/job:localhost/replica:0/task:0/gpu:0\r\n201radients/Mean_grad/Prod_1: (Prod): /job:localhost/replica:0/task:0/gpu:0\r\n7-07-11 13:24:19.247946: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Mean_grad/Prod_1: (Prod)/job:localhost/replicag:0/task:0/gpuradients/Mean_grad/Maximum: (Maximum): /job:localhost/replica:0/task:0/gpu:0\r\n:0\r\n2017-07-11 13:24:19.248270: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Mean_grad/Maximum: g(Maximum)/job:localhost/replica:0/task:0/gpu:0\r\nradients/sub_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/gpu:2017-07-11 13:24:19.248705: I c:\\tf_0\r\njenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/sub_grad/BroadcastGradientArgs: (BroadcastGradientArgs)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Maximum_grad/zeros: (Fill): 2/017-07-11 13:24:19.249079: job:localhost/replica:0/task:0/gpu:0\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Maximum_grad/zeros: (Fill)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Maximum_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.249394: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Maximum_grad/BroadcastGradientArgs: (BroadcastGradientArgs)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Sum_grad/add: (Add): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.249733: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Sum_grad/add: (Add)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Sum_grad/mod: (FloorMod): /job:localhost/replica:0/task:0/gpu:0\r\n2b_c1: (VariableV2): /job:localhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:19.250031: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Sum_grad/mod: (FloorMod)/job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.250251: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windbows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] b_c1: (VariableV2)/job:localhost/replica:0/task:0/gpu:0\r\n_c1/read: (Identity): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.250651: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] b_c1/read: (Identity)/job:localhost/replica:0/task:0/gpu:0\r\nW_c1: (VariableV2): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.250926: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windoWws-gpu\\py\\35\\tensorflow\\_c1/read: (Identity): /job:localhost/replica:0/task:0/gpu:0\r\ncore\\common_runtime\\simple_placer.cc:847] W_c1: (VariableV2)/job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.251173: I c:\\tf_jengkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:radients/mul_grad/Shape: (847] W_c1/read: (Identity)/job:localhost/replica:0/task:0/gpu:0\r\nShape): /job:localhost/rep2lica:0/task:0/cpu:0\r\n017-07-11 13:24:19.251460: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/mul_grad/Shape: (Shape)/job:localhost/replica:0/task:0/cpu:0\r\ngradients/mul_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localho2st/replica:0/task:0/gpu:0\r\n017-07-11 13:24:19.251808: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/mul_grad/BroadcastGradientArgs: (BroadcastGradientArgs)/job:localhost/replica:0/task:0/gpu:0\r\nsub_1: (Sub): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.252140: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] sub_1: (Sub)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/mul_1_grad/Shape: (Shape): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.252492: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847]gr gradients/mul_1_grad/Shape: (Shape)/job:localhost/replica:0/task:0/gpu:0\r\nadients/mul_1_grad/BroadcastGradientAr20gs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/gpu:0\r\n17-07-11 13:24:19.252849: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/mul_1_grad/Broagradients/imagdcastGradientArgs: (BroadcastGradientArgs)/job:localhost/replica:0/task:0/gpu:0\r\ne_filters/conv1_1/Conv2D_grad/Shape: (S2017-07-11 13:24:19.hape): /job:localhost/replica:0/task:0/cpu:0\r\n253258: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1_1/Conv2D_grad/Shape: (Shape)/job:localhost/replica:0/task:0/cpu:0\r\nimage_filters/conv1_1/Conv2D: (Conv2D): /job:lo2calhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:19.253618: I c:\\tf_jenkins\\home\\workspgace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] image_filters/conv1_1/Conv2D: (Conv2D)/job:localhost/replica:0/task:0/gpu:0\r\nradients/image_filters/conv1_1/add_grad/Shape: (Shape): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.253911: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/imageg_filters/conv1_1/add_grad/Shape: (Shape)/job:localhost/replica:0/task:0/gpu:0\r\nradients/image_filters/conv1_1/add_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhos2t/replica:0/task:0/gpu:0\r\n017-07-11 13:24:19.254287: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1_1/add_grad/BroadcastGradientArgs: (BroadcastGradientArgs)/job:localhost/replica:0/task:0/gpu:0\r\ni2mage_filters/conv1_1/add: (Add): /job:localhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:19.254622: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] image_filters/conv1_1/add: (Add)/job:localhost/replica:0/task:0/gpu:0\r\nimage_filters/conv1_1/Relu: (Relu): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.254932: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] image_filters/conv1_1/Relu: (Relu)/job:localhost/replica:0/task:0/gpu:0\r\nimage_filters/conv1_1/MaxPool: (MaxPool): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.255352: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] image_filters/conv1_1/MaxPool: (MaxPool)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/SquaredDifference_grad/Shape_1: (Shape): /job:localhost/replica:2017-07-11 13:24:19.2550/task:0/gpu:0\r\n698: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/SquaredDifference_grad/Shape_1: (Shape)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/image_filters/conv1/Conv2D_g2rad/Shape: (Shape): /job:localhost/replica:0/task:0/cpu:0\r\n017-07-11 13:24:19.256060: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1/Conv2D_grad/Shape: (Shape)/job:localhost/replica:0/task:0/cpu:0\r\nimage_filters/conv1/Conv2D: (Conv2D): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.256397: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] image_filters/conv1/Conv2D: (Conv2D)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/image_filters/conv1/add_grad/Shape: 2(Shape): /job:localhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:19.256719: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1/add_ggrad/Shape: (Shape)/job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.257062radients/image_filters/conv1/add_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/gpu:0\r\n: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1/add_grad/BroadcastGradientArgs: (BroadcastGradientArgs)/job:localhost/replica:0/task:0/gpu:0\r\nimage_filters/conv1/add: (Add): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.257462: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] image_filters/conv1/add: (Add)/job:localhost/replica:0/task:0/gpu:0\r\nimage_filters/conv1/Relu: (Relu): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.257779: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] image_filters/conv1/Relu: (Relu)/job:locimage_filters/conv1/MaxPoolalhost/replica:0/task:0/gpu:0\r\n: (MaxPool): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.258108: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] image_filters/conv1/MaxPool: (MaxPool)/job:localhost/replicga:0/task:0/gpu:0\r\nradients/SquaredDifference_grad/Shape: (Shape): /job:localhost/replic2a:0/task:0/gpu:0\r\n017-07-11 13:24:19.258461: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/SquaredDifference_grad/Shape: (Shape)/job:localhost/replica:0/gtask:0/gpu:0\r\nradients/SquaredDifference_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.258817: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/SquaredDifference_grad/BroadcastGradientArgs: (BroadcastGradientArgs)/job:localhost/replica:0/task:0/gpu:0\r\nSquaredDifference: (SquaredDifference): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.259200: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\cSqrt: (Sqrt): /job:localhost/replore\\common_runtime\\simple_placer.cc:847] SquaredDifference: (SquaredDifference)/job:localhost/replica:0/task:0/gpu:0\r\nica:0/task:0/gpu:0\r\ngradients/Sum_grad/S2017-07-11 13:24:19.259486: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Sqrt: (Sqrt)/job:localhost/replica:0/task:0/gpu:0\r\nhape: (2Shape): /job:localhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:19.259744: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Sum_grad/Shape: (Shape)/job:localhosgt/replica:0/task:0/gpu:0\r\nradients/Sum_grad/DynamicStitch: (DynamicStitch): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.260076: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Sum_grad/DynamicStitch: (DynamicStitch)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Sum_grad/Maximum: (Maximum): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.260382: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Sum_grad/Maximum: (Maximum)/job:lgocalhost/replica:0/task:0/gpu:0\r\nradients/Sum_grad/floordiv: (FloorDiv): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.260666: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Sum_grad/floordiv: (FloorDiv)/joSb:localhost/replica:0/task:0/gpu:0\r\num: (Sum): /job:localhost/replica:02/task:0/gpu:0\r\n017-07-11 13:24:19.260940: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Sum: (Sum)/job:localhost/replica:0/task:0/gpu:0\r\ng2radients/Mean_grad/Shape_1: (Shape): /job:localhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:19.261218: I c:\\tf_gradients/Mean_grad/Prod: (Prod): /job:localhost/replica:0/task:0/gpu:0\r\njenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Mean_grad/Shape_1: (Shape)/job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.261496: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Mean_grad/Prod: (Prod)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Mean_grad/floordiv: (Fl2oorDiv): /job:localhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:19.261927: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Mean_grad/floordiv: (FloorDiv)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Mean_grad/Cast: (Cast): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.262288: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Mean_grad/Cast: (Cast)/job:lgocalhost/replica:0/task:0/gpu:0\r\nradients/Mean_grad/Shape: (Shape): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.262621: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Mean_grad/Shape: (Shape)/job:localhost/replMica:0/task:0/gpu:0\r\nean: (Mean): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.262932: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Mean: (Mean)/job:localhost/replica:0/task:0/gpu:0\r\nmul_1: (Mul): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.263207: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] mul_1: (Mul)/job:localhost/replica:0/task:0/gpu:0\r\ng2radients/add_grad/Shape_1: (Shape): /job:localhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:19.263484: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/add_grad/Shape_1: (Shape)/job:localhost/replica:0/task:0/gpu:0\r\nsub: (Sub): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.263770: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\commgradients/Maximum_grad/GreaterEqual: (Greateron_runtime\\simple_placer.cc:847] sub: (Sub)/job:localhost/replica:0/task:0/gpu:0\r\nEqual): /job:localhost/replica:0/task:0/g2pu:0\r\n017-07-11 13:24:19.264059: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Maximum_grad/GreaterEqual: (GreaterEqual)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Maximum_grad/LogicalNot: (LogicalNot): /job:localhost/replica:02/task:0/gpu:0\r\n017-07-11 13:24:19.264412: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Maximum_grad/LogicalNot: (LogicalNot)/job:localhost/repMlica:0/task:0/gpu:0\r\naximum: (Maximum): /job:localhost/replica:0/task:0/gpu:0\r\n2mul: (Mul): /job:localhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:19.264740: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Maximum: (Maximum)/job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.264948: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gradients/add_grad/Shape: (Shape): /job:localhost/replica:gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] mul: (Mul)/job:localhost/replica:0/task:0/gpu:0\r\n0/task:0/gpu:0\r\n2017-07-11 13:24:19.265252: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/add_grad/Shape: (Shape)/job:localhost/replica:0/task:0/gpu:0\r\ng2017-07-11 13:24:19.radients/add_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/gpu:0\r\nadd: (Add): /job:localhost/replica:0/task:0/gpu:0\r\n265605: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/add_grad/BroadcastGradientArgs: (BroadcastGradientArgs)/job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.265860: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] add: g(Add)/job:localhost/replica:0/task:0/gpu:0\r\nradients/Shape: (Shape): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.266170: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Shape: (Shape)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Fill: (Fill): /job:localhost/replica:0/task:02/gpu:0\r\n017-07-11 13:24:19.266455: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Fill: (Fill)/job:localghost/replica:0/task:0/gpu:0\r\nradients/add_grad/Sum_1: (Sum): /job:localhost/re2017plica:0/task:0/gpu:0\r\n-07-11 13:24:19.266741: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/add_grad/Sum_1: (Sum)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/add_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.267054: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/add_grad/Reshape_1: (Reshape)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/add_grad/Sum: (Sum): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.267378: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\gradients/add_grad/Reshape: (Reshape): /job:simple_placer.cc:847] gradients/add_grad/Sum: (Sum)/job:localhost/replica:0/task:0/gpu:0\r\nlocalhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.267683: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradiengts/add_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0\r\nradients/add_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.268018: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/add_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/gpgu:0\r\nradients/add_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.268396: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/add_grad/tuple/cgontrol_dependency_1: (Identity)/job:localhost/replica:0/task:0/gpu:0\r\nradients/mul_1_grad/mul_1: (Mul): /job:localhos2t017-07-11 13:24:19.268752: I c/replica:0/task:0/gpu:0\r\n:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/mul_1_grad/mul_1: (Mul)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/mul_1_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.269053: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/mul_1_grad/Sum_1: (Sum)/job:localhost/replica:0/task:g0/gpu:0\r\nradients/mul_1_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:02/gpu:0\r\n017-07-11 13:24:19.269422: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windgows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/mul_1_graradients/mul_1_grad/mul: (d/Reshape_1: (Reshape)/job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:1Mul): /job:localhost/replica:0/task:0/gpu:0\r\n9.269741: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/mul_1_grad/mul: (Mul)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/mul_1_grad/Sum: (Sum): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.270059: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/mul_1_grad/Sum: (Sum)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/mul_1_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0\r\n2gradients/mul_1_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:19.270373: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/mul_1_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.270647: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradgients/mul_1_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/gpu:0\r\nradients/mul_1_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.271101: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/add_grad/tuple/control_depegradients/mul_1_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/gpu:0\r\nndency: (Identity): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.271477: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\cogradients/mul_grad/mul_1: (Mul): /job:localhost/mmon_runtime\\simple_placer.cc:847] gradients/add_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.271785: I c:\\tf_jenkireplica:0/task:0/gpu:0\r\nns\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/mul_gragd/mul_1: (Mul)/job:localhost/replica:0/task:0/gpu:0\r\nradients/mul_g2rad/Sum_1: (Sum): /job:localhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:19.272057: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/mul_grad/Sum_1: (Sum)/job:localhost/replica:0/task:0/gpu:0\r\ng2017-07-11 13:24:19.272329: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\wiradients/mul_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/gpu:0\r\nndows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/mul_grad/Reshape_1: (Reshape)/job:localhost/replica:0/task:0/ggpu:0\r\nradients/mul_grad/mul: (Mul): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.272656: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/mul_grad/mul: (Mul)/job:localhogst/replica:0/task:0/gpu:0\r\nradients/mul_grad/Sum: (Sum): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.272970: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/mul_grad/Sum: (Sum)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/mul_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.273289: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/mul_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/mul_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.273630: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/mul_grad/tuple/group_depgradients/mul_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/gpu:0\r\ns: (NoOp)/job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.273977: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/mul_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Maximum_grad/Select_1: (Select): /job:l2ocalhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:19.274331: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Maximum_grad/Select_1: (Select)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Maximum_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.274633: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Maximum_grad/Sum_1: (gradients/Maximum_grad/ResShum)/job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.275016: I c:\\tf_jeape_1: (Reshape): /job:localhost/replica:0/task:0/gpu:0\r\nnkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.gradients/Maximum_grad/Select: (Select): /job:localhoscc:847] gradients/Maximum_grad/Reshape_1: (Reshape)/job:localhost/replica:0/task:0/gpu:0\r\nt/replica:0/task:02/gpu:0\r\n017-07-11 13:24:19.275319: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Maximum_grad/Select: (Select)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Maximum_grad/Sum: (Sum): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.275626: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Maximum_grad/Sum: (Sum)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Maximum_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.275963: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Maximum_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Maximum_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.276290: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placgradients/Maximum_grad/tuple/coer.cc:847] gradients/Maximum_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/gpu:0\r\nntrol_dependency_1: (Identity): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.276629: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_plagradients/sub_grad/Sum_1:cer.cc:847] gradients/Maximum_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/gpu:0\r\n (Sum): /job:localhost/replica:0/task:0/gpu:0\r\n2gradients/sub_grad/Neg: (Ne017-07-11 13:24:19.276983: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/sub_grad/Sum_1: (Sum)/job:localhost/replica:0/task:0/gpu:0\r\ng): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.277217: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/sub_grad/Neg: (Neg)/jogb:localhost/replica:0/task:0/gpu:0\r\nradients/sub_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.277575: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensogradients/sub_grad/Sum: (Sum): /job:localhorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/sub_grad/Reshape_1: (Reshape)/job:localhost/replica:0/task:0/gpu:0\r\nst/replica:0/task2:0/gpu:0\r\n017-07-11 13:24:19.277865: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.gradients/sub_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0\r\ncc:847] gradients/sub_grad/Sum: (Sum)/job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.278175: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/sub_grad/Reshape: (Reshape)/job:localhost/repglradients/sub_grad/tuple/gica:0/task:0/gpu:0\r\nroup_deps: (NoOp): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.278602: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/sub_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0g/gpu:0\r\nradients/sub_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.279048: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/sub_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/AddN: (AddN): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.279388: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/AddN: (AddN)/job:localhost/replica:0/task:0/gpug:0\r\nradients/Mean_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.279803: I c:\\tf_jenkins\\home\\workspace\\release-wgradients/Mean_grad/Tile: (Tile): /job:localhost/replica:0/task:0/gpu:0\r\nin\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Mean_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.280058: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Mean_grad/Tile: (Tile)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Mean_grad/truediv: (RealDiv): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.280480: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Mean_grad/truediv: (RealDiv)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Sum_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.280949: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Sum_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Sum_grad/Tile: (Tile): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.281386: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Sum_grad/Tile: (Tile)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Sqrt_grad/SqrtGrad: (SqrtGrad): /job:lo2calhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:19.281727: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\cogradients/SquaredDimmon_runtime\\simple_placer.cc:847] gradients/Sqrt_grad/SqrtGrad: (SqrtGrad)/job:localhost/replica:0/task:0/gpu:0\r\nfference_grad/sub: (Sub): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.282144: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/SquaredDifference_grad/sub: (Sub)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/SquaredDifference_grad/mul: (Mul): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.282gradients/SquaredDifference_grad/mul_1: (576: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/SquaredDifference_grad/mul: (Mul)/job:localhost/replica:0/task:0/gpu:0\r\nMul):2 /job:localhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:19.282875: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/SquaredDifference_grad/mul_1: (Mul)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/SquaredDifference_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.283314: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/SquaredDifference_grad/Sum_1: (Sum)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/SquaredDifference_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.283757: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/SquaredDifference_grad/Reshape_1: (Reshape)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/SquaredDifference_grad/Neg: (Neg): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.284191: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/SquaredDifference_grad/Neg: (Neg)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/SquaredDifference_grad/Sum: (Sum): /job:localhost/replica:0/task:0/gp2u:0\r\n017-07-11 13:24:19.284588: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/SquaredDifference_grad/Sum: (Sum)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/SquaredDifference_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.285023: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/SquaredDifference_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/SquaredDifference_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.285431: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/SquaredDifference_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/SquaredDifference_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.285844: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/SquaredDifference_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/image_filters/conv12_1/MaxPool_grad/MaxPoolGrad: (MaxPoolGrad): /job:localhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:19.286261: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1_1/MaxPool_grad/MaxPoolGrad: (MaxPoolGrad)/job:localhost/replica:0/task:0/gpu:0\r\ng2017-07-11 13:24:19.radients/image_filters/conv1_1/Relu_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/gpu:0\r\n286711: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1_1/Relu_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/image_filters/conv1_1/add_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.287092: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1_1/add_grad/Sum_1: (Sum)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/image_filters/conv1_1/add_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.287440: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1_1/add_grad/Reshape_1: (Reshape)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/image_filters/conv1_1/add_grad/Sum: (Sum): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.287863: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1_1/add_grad/Sum: (Sum)/job:localhost/replica:0/task:0/gpu:0\r\ng2radients/image_filters/conv1_1/add_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:19.288162: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1_1/add_grad/Reshagpe: (Reshape)/job:localhost/replica:0/task:0/gpu:0\r\nradients/image_filters/conv1_1/add_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.288542: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847gradients/image_filters/conv1_1/add_grad] gradients/image_filters/conv1_1/add_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/gpu:0\r\n/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.288927: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflgow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1_1/add_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.289260: I c:\\tf_jeradients/image_filters/conv1_1/add_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/gpu:0\r\nnkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1_1/add_grad/tupgle/control_dependency: (Identity)/job:localhost/replica:0/task:0/gpu:0\r\nradients/image_filters/conv1_1/Conv2D_grad/Conv2DBackpr2017-07-11 13:24:19.289661: IopFilter: (Conv2DBackpropFilter): /job:localhost/replica:0/task:0/gpu:0\r\n c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1_1/Conv2D_grad/Conv2DBackpropFilter: (Conv2DBackpropFilter)/job:localhost/replica:0/task:0/gpu:0\r\ng2017-07-11 13:24:19.290081: I c:\\tf_radients/image_filters/conv1_1/Conv2D_grad/Conv2DBackpropInput: (Conv2DBackpropInput): /job:localhost/replica:0/task:0/gpu:0\r\njenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1_1/Conv2D_grad/Conv2DBackpropInput: (Conv2DBackpropInput)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/image_filters/conv1_1/Conv2D_grad/tuple/group_deps: (NoOp): /job:localhost/repl2ica:0/task:0/gpu:0\r\n017-07-11 13:24:19.290503: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1_1/Conv2D_grad/tuple/group_deps: (NoOp)/job:localhost/replicga:0/task:0/gpu:0\r\nradients/image_filters/conv1_1/Conv2D_grad/tuple/control2017-07-11 13:24:19.290864: I c:\\_dependency_1: (Identity): /job:localhost/replica:0/task:0/gpu:0\r\ntf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1_1/Conv2D_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/SquaredDifference_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.291265: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/SquaredDifference_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/image_filters/conv1/MaxPool_grad/MaxPoolGrad: (MaxPoolGrad): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.291662: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1/MaxPool_grad/MaxPoolGrad: (MaxPoolGrad)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/image_filters/conv1/Relu_grad/ReluGrad: (ReluGrad): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.292039: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1/Relu_grad/ReluGrad: (ReluGrad)/job:localhost/replica:0/task:0/gpu:0\r\ng2radients/image_filters/conv1/add_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:19.292391: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1/add_grad/Sum_1: (Sum)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/image_filters/conv1/add_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.292780: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1/add_grad/Reshape_1: (Reshape)/jogb:localhost/replica:0/task:0/gpu:0\r\nradients/image_filters/conv1/add_grad/Sum: (Sum): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.293135: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placegradients/image_filters/conv1/addr.cc:847] gradients/image_filters/conv1/add_grad/Sum: (Sum)/job:localhost/replica:0/task:0/gpu:0\r\n_grad/Reshape: 2(Reshape): /job:localhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:19.293433: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1/add_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/image_filters/conv1/add_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.293785: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1/add_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/image_filters/conv1/add_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.294188: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1/add_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/AddN_1: (AddN): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.294536: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/AddN_1: (AddN)/job:localhost/replica:0/task:0/gpu:0\r\nGradientDescent/update_b_c1/ApplyGradientDescent: (ApplyGradientDescent): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.294888: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] GradientDescent/update_b_c1/ApplyGradientDescent: (ApplyGradientDescent)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/image_filters/conv1/add_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.295306: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1/add_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/image_filters/conv1/Conv2D_grad/Conv2DBackpropFilter: (Conv2DBackpropFilter): /job:localhost/rep2017-07-11 13:24:19.295715: I c:\\tf_jenkilica:0/task:0/gpu:0\r\ngradients/image_filters/conv1/Conv2D_grad/Conv2DBackpropInput: (Conv2DBackpropInput): /job:locns\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1/Conv2D_grad/Conv2DBackpropFilter: (Conv2DBackpropFilter)/job:localhost/replica:0/task:0/gpu:0\r\nalhost/replica:0/task:02/gpu:0\r\n017-07-11 13:24:19.296072: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1/Conv2D_grad/Conv2DBackpropInput: (Conv2DBackpropInput)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/image_filters/conv1/Conv2D_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.296469: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1/Conv2D_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/image_filters/conv1/Conv2D_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.296889: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1/Conv2D_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/AddN_2: (AddN): /job:localhost/replic2a:0/task:0/gpu:0\r\n017-07-11 13:24:19.297243: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/AddN_2: (AGddN)/job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.297549: I c:\\tf_jenkins\\home\\workspace\\releradientDescent/update_W_c1/ApplyGradientDescent: (ApplyGradientDescent): /job:localhost/replica:0/task:0/gpu:0\r\nase-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] GradientDesGradientDescent: (NoOp): /job:cent/update_W_c1/ApplyGradientDescent: (ApplyGradientDescent)/job:localhost/replica:0/task:0/gpu:0\r\n2localhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:19.297883: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] GradientDes_cent: (NoOp)/job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.298156: Iarg_Placeholder_0_0: (_Arg): /job:localhost/replica:0/task:0/cpu:0\r\n c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] _arg_Placeholder_0_0: (_Arg)/job:localhost/replica:0/task:0/cpu:0\r\n_arg_Placeholder_1_0_1: (_Arg): /job:localhost/replica:0/task:0/cpu:0\r\n2017-07-11 13:24:19.298500: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] _arg_Placeholder_1_0_1: (_Arg)/job:localhost/replica:0/task:0/cpu:0\r\n_arg_Placeholder_2_0_2: (_Arg): /job:localh2ost/replica:0/task:0/cpu:0\r\nGradientDescent/learning_rate: (Const):017-07-11 13:24:19.298797: I /job:localhost/replica:0/task:0/gpu:0\r\n c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] _arg_Placeholder_2_0_2: (_Arg)/job:localhost/replica:0/task:0/cpu:0\r\n2017-07-11 13:24:19.299035: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\wgradients/image_filters/conv1_1/Conv2D_grad/Shape_1: (Const)indows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] GradientDescent/learning_rate: (Const)/job:localhost/replica:0/task:0/gpu:0\r\n: /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.299385: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1_1/Conv2D_grad/Shape_1: (Const)/jogb:localhost/replica:0/task:0/gpu:0\r\nradients/image_filters/conv1/Conv2D_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.299727: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1/Conv2D_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/image_filters/conv1_1/add_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.300088: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/image_filters/conv1_1/add_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/image_filters/conv1/add_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.300446: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placgradients/Sum_grad/Maximum/y: (er.cc:847] gradients/image_filters/conv1/add_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/gpu:0\r\nConst): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.300768: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Sum_grad/Maximum/y: (Const)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Sum_grad/Fill/value: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.301086: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_rungtime\\simple_placer.cc:847] gradients/Sum_grad/Fill/value: (Const)/job:loradients/Sum_grad/range/deltacalhost/replica:0/task:0/gpu:0\r\n: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.301441: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Sum_grad/range/gdelta: (Const)/job:localhost/replica:0/task:0/gpu:0\r\nradients/Sum_grad2/range/start: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:19.301721: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Sum_grad/range/start: (Const)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Sum_grad/Shape_1: (Const): /2job:localhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:19.302145: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Sum_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Sum_grad/Size: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.302468: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Sum_grad/Size: (Const)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Mean_grad/Maximum/y: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.302817: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Mean_grad/Maximum/y: (Const)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Mean_grad/Const_1: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.303149: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Mean_grad/Const_1: (Const)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Mean_grad/Const: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.303468: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Mean_grad/Const: (Const)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Mean_grad/Shape_2: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.303782: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Mean_grad/Shape_2: (Const)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Mean_grad/Reshape/shape: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.304103: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Mean_grad/Reshape/shape: (Const)/job:localhost/replica:0/task:0/gpu:0g\r\nradients/sub_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.304452: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/sub_grad/Shape_1: (Const)/job:localhost/replica:0/tgask:0/gpu:0\r\nradients/sub_grad/Shape: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.304725: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/sub_grad/Shape: (Const)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Maximum_grad/zeros/Const: (Const): 2/job:localhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:19.305020: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Maximum_grad/zeros/Const: (Const)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Maximum_grad/Shape_2: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.305385: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Maximum_grad/Shape_2: (Const)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/Maximum_grad/Shape_1: (Const): /job:loca2lhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:19.305734: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Maximgum_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/gpu:0\r\nradients/Maximum_grad/Shape: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.306072: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Maximum_grad/Shape: (Const)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/mul_1_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.306378: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/mul_1_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/mul_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.306671: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpgu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/mul_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/gpu:0\r\nradients/Const: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.307007: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/Const: (Const)/job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.307328: I c:\\tf_jenkins\\home\\workspace\\release-win\\sm\\windows-gpu\\pub_1/x: (Const): /job:localhost/replica:0/task:0/gpu:0\r\ny\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] sub_1/x: (Const)/job:localhost/replica:0/task:0/gpu:0\r\nM2aximum/x: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n017-07-11 13:24:19.307561: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35s\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Maximum/x: (Const)/job:localhost/replica:0/task:0/gpu:0\r\nub/x: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.307794: I c:\\tf_jenkins\\home\\workspace\\release-win\\Const: (Const): /job:localhost/replica:0/task:0/gpu:0\r\nm\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] sub/x: (Const)/job:localhost/replica:0/task:0/gpu:0\r\nS2017-07-11 13:24:19.308022: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Const: (Const)/job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.30um/reduction_indices: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n8225: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] Sum/reduction_indices: (Const)/job:localhost/replica:0/task:0/gpu:0\r\ngradients/SquaredDifference_grad/scalar: (Const): /job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:19.308572: I c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\core\\common_runtime\\simple_placer.cc:847] gradients/SquaredDifference_grad/scalar: (Const)/job:localhost/replica:0/task:0/gpu:0\r\n2017-07-11 13:24:22.708625: E c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:1068] failed to synchronize the stop event: CUDA_ERROR_LAUNCH_FAILED\r\n2017-07-11 13:24:22.709120: E c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\stream_executor\\cuda\\cuda_timer.cc:54] Internal: error destroying CUDA event in context 00000273916D5930: CUDA_ERROR_LAUNCH_FAILED\r\n2017-07-11 13:24:22.709414: E c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\stream_executor\\cuda\\cuda_timer.cc:59] Internal: error destroying CUDA event in context 00000273916D5930: CUDA_ERROR_LAUNCH_FAILED\r\n2017-07-11 13:24:22.709759: F c:\\tf_jenkins\\home\\workspace\\release-win\\m\\windows-gpu\\py\\35\\tensorflow\\stream_executor\\cuda\\cuda_dnn.cc:1961] failed to enqueue convolution on stream: CUDNN_STATUS_MAPPING_ERROR\r\n[Finished in 31.7s]\r\n", "Looks like with cudnn6, you are able to run longer, but still run into the same issue.\r\n\r\n@guschmue @mrry have you seen this error on windows before?", "I haven't seen this error before... it doesn't seem to be Windows-specific, so someone with more CUDA expertise probably needs to take a look.", "yes, same here, don't think this is a windows specific thing. There are a bunch of references to the CUDNN_STATUS_MAPPING_ERROR mostly hinting at resource problems with large convolutions but without clear root cause. If your model is a large cnn you could try a smaller batch size and see if this makes a difference.\r\nIs there a way that I can run this model myself?\r\nFor windows/1.2.1: just ran some tests with a larger cnn on a 1080 and it was happy.", "FYI we got another Windows cuDNN related issue in https://github.com/tensorflow/tensorflow/issues/11401.", "Received the same error using a GTX 1080 ti on Ubuntu 16.04 while working through the MNIST tutorial.\r\n\r\n`\r\n>>> init = tf.global_variables_initializer()\r\n>>> sess = tf.Session()\r\n2017-07-14 20:32:21.186294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0)\r\n>>> sess.run(init)\r\n2017-07-14 20:32:34.666827: E tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED\r\n2017-07-14 20:32:34.666873: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:203] Unexpected Event status: 1\r\nAborted (core dumped)\r\n`\r\n", "It seems my issue was because I was using cuDNN 6.0 and was forcing tensorflow to use this version. Issue resolved when I resorted back to cuDNN 5.0.", "Ok, somehow I encountered same problem. I have two graphics cards (1070 and 1080ti) on my machine. When I am not specifying the CUDA_VISIBLE_DEVICES or only use 1080ti. I have the CUDA_STATUS_MAPPING_ERROR. When I am using my 1070. The error disappeared. Any idea?", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Closing due to lack of activity, assuming this has been fixed by installing the correct cudnn. Please reopen if it's still a problem."]}, {"number": 11388, "title": "[Feature Request] Tensor::DebugString for GPU backed tensors", "body": "Currently it crashes when calling ``Tensor::SummarizeValue`` and ``Tensor::DebugString`` in GPU backed tensors. I am wondering if there is a better way to debug when writing GPU code.", "comments": ["Just discovered ``GPUUtil::MemoryDebugString`` for the exact feature I asked for."]}, {"number": 11387, "title": "Unable to install Tensorflow on Windows - Anaconda error trace", "body": "I posted this issue on Stack Overflow, I seem to always have problems related to Anaconda dependencies, even related to my Mac. I'm on Python 3.6 which came with an auto-install when I installed Visual Studio. Do I just need to downgrade to get this to work? I'm also on the latest version of CUDA/cuDNN and have a TitanX. \r\n\r\nI'm on a new PC deep learning rig now, and installed CUDA, afterward I ran some of the pip install commands. I received the error below. \r\n\r\n`python -m pip install --upgrade pip`\r\n\r\nThen this printed out:\r\n\r\n`Successfully built protobuf markdown html5lib\r\nInstalling collected packages: protobuf, backports.weakref, html5lib, bleach, ma                               rkdown, tensorflow\r\nException:\r\nTraceback (most recent call last):\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\pip\\basecommand.py\", line 2                               15, in main\r\n    status = self.run(options, args)\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\pip\\commands\\install.py\", l                               ine 342, in run\r\n    prefix=options.prefix_path,\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\pip\\req\\req_set.py\", line 7                               84, in install\r\n    **kwargs\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\pip\\req\\req_install.py\", li                               ne 851, in install\r\n    self.move_wheel_files(self.source_dir, root=root, prefix=prefix)\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\pip\\req\\req_install.py\", li                               ne 1064, in move_wheel_files\r\n    isolated=self.isolated,\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\pip\\wheel.py\", line 345, in                                move_wheel_files\r\n    clobber(source, lib_dir, True)\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\pip\\wheel.py\", line 323, in                                clobber\r\n    shutil.copyfile(srcfile, destfile)\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\shutil.py\", line 115, in copyfile\r\n    with open(dst, 'wb') as fdst:\r\nPermissionError: [Errno 13] Permission denied: 'C:\\\\Program Files\\\\Anaconda3\\\\Li                               b\\\\site-packages\\\\protobuf-3.3.0-py3.6-nspkg.pth'\r\n`\r\n", "comments": ["Now I tried installing via `pip -install -user tensorflow-gpu` as suggested, but after running the `activate tensorflow-gpu` command I receive this error `source activate envname` which I enter and still nothing? ", "All I get are the same trace back errors after `source activate envname`\r\n\r\n`$ source activate envname\r\nTraceback (most recent call last):\r\n  File \"C:\\Program Files\\Anaconda3\\Scripts\\conda-script.py\", line 5, in <module>\r\n    sys.exit(conda.cli.main())\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\conda\\cli\\main.py\", line 15                                  4, in main\r\n    activate.main()\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\conda\\cli\\activate.py\", lin                                  e 160, in main\r\n    prefix = prefix_from_arg(sys.argv[3], shelldict=shelldict)\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\conda\\cli\\activate.py\", lin                                  e 60, in prefix_from_arg\r\n    prefix = locate_prefix_by_name(context, arg.replace('/', os.path.sep))\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\conda\\base\\context.py\", lin                                  e 538, in locate_prefix_by_name\r\n    raise CondaEnvironmentNotFoundError(name)\r\nconda.exceptions.CondaEnvironmentNotFoundError: Could not find environment: envn                                  ame .\r\nYou can list all discoverable environments with `conda info --envs`.\r\n`", "If you are on windows, you usually need to start a terminal as an administrator.\r\nThis is due to anaconda directories being only writable by administrator.", "@gunan I tried what you said but still got this error after the prompts `activate tensorflow` and `pip install --ignore-installed --upgrade <url>`\r\n\r\nSays it's not supported wheel on this platform. I'm on Windows 10?\r\n![tf-error](https://user-images.githubusercontent.com/3184381/28039500-65fc42d6-6577-11e7-8077-b077241c15b5.png)\r\n", "@gunan also tried installing a different version since I'm on Python 3.6, Anaconda 4.3 (64 bit version on Windows)\r\n\r\n![tf-36-error](https://user-images.githubusercontent.com/3184381/28040455-b86b2728-657a-11e7-8b59-aca27acf202b.png)\r\n\r\nBut still didn't work either. Referring to this other [post](https://github.com/tensorflow/tensorflow/issues/6533). \r\n\r\n", "by any chance, are you on a 32 bit OS?", "@erinjerri the `pip install --ignore-installed --upgrade <url>` didn't work for me either, so, what I end doing was installed locally downloading the wheel directly from the link provided in the Installation section:\r\n\r\n*Windows GPU: Python 3.5 64-bit (build history) / **Python 3.6 64-bit (build history)**\r\n\r\nOnce I downloaded I used `pip install --ignore-installed --upgrade <PC url>` and the **not supported wheel on this platform** error didn't appear again, unfortunately there where other error when i try to import tensorflow to my code. I try different things until I got frustrated and end going back to python 3.5.2 with anaconda 4.2.0. I also have a 64x win 10 and a CUDA compatible card. ", "@gunan I have a 64 bit, my issues are like the same as @Jose30. I tried also installing Keras (same issue, only odd bc I thought they only supported up to Python 3.5, and of course need to install Tensorflow along with that0. I really don't want to have to downgrade to another version of Python or Anaconda if the support is there for Tensorflow and Keras and this is just some random Anaconda error. If it's a common one, I'm wondering what moves folks are making to help fix or update in next version of Tensorflow or Keras? =T I just installed Python with my default Visual Studio when I built my new PC rig so it's kinda frustrating to downgrade to another version even if it's not quite beta just to get something to work lol, just want write my code for my models already (impatient). ", "@gunan: \r\n\r\nSo I got it working half way until I hit this error upon the command `import tensorflow as tf`\r\n\r\n`  import numpy as np\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\__init__.py\", line 142, in <module>\r\n    from . import add_newdocs\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\add_newdocs.py\", line 13, in <module>\r\n    from numpy.lib import add_newdoc\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\lib\\__init__.py\", line 8, in <module>\r\n    from .type_check import *\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\lib\\type_check.py\", line 11, in <module>\r\n    import numpy.core.numeric as _nx\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\core\\__init__.py\", line 26, in <module>\r\n    raise ImportError(msg)\r\nImportError:\r\nImporting the multiarray numpy extension module failed.  Most\r\nlikely you are trying to import a failed build of numpy.\r\nIf you're working with a numpy git repo, try `git clean -xdf` (removes all\r\nfiles not under version control).  Otherwise reinstall numpy.\r\n\r\nOriginal error was: DLL load failed: The specified procedure could not be found.`\r\n\r\nI tried reinstalling numpy but still got more errors. Thoughts? Is this an Anaconda related error? ", "@gunan \r\n\r\nOkay so I reinstalled Numpy successfully then got this error which told me to put in the entire trace after I ran the same `import tensorflow as tf` command:\r\n\r\n`C:\\Users\\erinj>python\r\nPython 3.6.0 |Anaconda 4.3.0 (64-bit)| (default, Dec 23 2016, 11:57:41) [MSC v.1900 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\core\\__init__.py\", line 16, in <module>\r\n    from . import multiarray\r\nImportError: DLL load failed: The specified procedure could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\erinj\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Users\\erinj\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\__init__.py\", line 47, in <module>\r\n    import numpy as np\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\__init__.py\", line 142, in <module>\r\n    from . import add_newdocs\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\add_newdocs.py\", line 13, in <module>\r\n    from numpy.lib import add_newdoc\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\lib\\__init__.py\", line 8, in <module>\r\n    from .type_check import *\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\lib\\type_check.py\", line 11, in <module>\r\n    import numpy.core.numeric as _nx\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\core\\__init__.py\", line 26, in <module>\r\n    raise ImportError(msg)\r\nImportError:\r\nImporting the multiarray numpy extension module failed.  Most\r\nlikely you are trying to import a failed build of numpy.\r\nIf you're working with a numpy git repo, try `git clean -xdf` (removes all\r\nfiles not under version control).  Otherwise reinstall numpy.\r\n\r\nOriginal error was: DLL load failed: The specified procedure could not be found.\r\n\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\erinj\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 978, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 961, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 950, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 648, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 560, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 205, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\erinj\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\erinj\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\erinj\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\erinj\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Users\\erinj\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\erinj\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 52, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\erinj\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 978, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 961, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 950, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 648, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 560, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 205, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\erinj\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\erinj\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\erinj\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Program Files\\Anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.`", "@Jose30 @gunan thanks for your help, it turns out that a lot of this stemmed from two issues:\r\n\r\n1) Had to delete extra dll files that were a part of 1-3 different Anaconda + Miniconda installs \r\n2) Reinstalling Numpy a few times. \r\n3) Adding CUDNN and Anaconda into my environment variables path. \r\n4) Having the wrong version of CUDNN installed (was on 6.0 instead of 5.1) which threw everything off. \r\n\r\nSome best practices to remember:\r\nRun CMD as administrator (I forget this often on Windows bc Mac is just whatever).", "Hi @erinjerri , I believe I have the same issue. Can you share where / how to check for:\r\n\r\n1. Different anaconda install file dlls that should be removed?\r\n2. How to be sure that I properly removed and reinstalled Numpy\r\n3. Have all the correct variables added to my path (\r\n![image of my path variables](https://user-images.githubusercontent.com/5164642/29240391-6ee2de80-7f64-11e7-91a3-98264fbd030d.png)\r\n\r\n4. Install the correct version of CUDNN? (Is this just replacing the files in the /../cuda/ folder?)", "Running Power shell as administrator and then following https://www.tensorflow.org/install/install_windows for Anaconda resolved my issues for not being able to import tensorflow as tf\r\n\r\nHowever, I had to do pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.3.0-cp36-cp36m-win_amd64.whl\r\nfor step number 4 \r\n![image](https://user-images.githubusercontent.com/1151365/29639184-de6d87b6-8827-11e7-9b28-2cdd4c5c8e61.png)\r\n\r\n", "when i run pip install tensorflow in anoconda prompt in windows 10,i got an error as:\r\n\r\n\r\n(C:\\ProgramData\\Anaconda3) C:\\Users\\Hensal>pip install tensorflow\r\nCollecting tensorflow\r\nException:\r\nTraceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\basecommand.py\", line 215, in main\r\n    status = self.run(options, args)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\commands\\install.py\", line 335, in run\r\n    wb.build(autobuilding=True)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\wheel.py\", line 749, in build\r\n    self.requirement_set.prepare_files(self.finder)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\req\\req_set.py\", line 380, in prepare_files\r\n    ignore_dependencies=self.ignore_dependencies))\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\req\\req_set.py\", line 554, in _prepare_file\r\n    require_hashes\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\req\\req_install.py\", line 278, in populate_link\r\n    self.link = finder.find_requirement(self, upgrade)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\index.py\", line 465, in find_requirement\r\n    all_candidates = self.find_all_candidates(req.name)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\index.py\", line 423, in find_all_candidates\r\n    for page in self._get_pages(url_locations, project_name):\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\index.py\", line 568, in _get_pages\r\n    page = self._get_page(location)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\index.py\", line 683, in _get_page\r\n    return HTMLPage.get_page(link, session=self.session)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\index.py\", line 811, in get_page\r\n    inst = cls(resp.content, resp.url, resp.headers)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\index.py\", line 731, in __init__\r\n    namespaceHTMLElements=False,\r\nTypeError: parse() got an unexpected keyword argument 'transport_encoding'\r\n\r\nwhat is the solution of such problem?", "Please see this stackoverflow question:\r\nhttps://stackoverflow.com/questions/46499808/pip-throws-typeerror-parse-got-an-unexpected-keyword-argument-transport-enco", "1) Update conda\r\n\r\n> Run the anaconda prompt as administrator\r\n\r\n    conda update -n base -c defaults conda\r\n\r\n2) Create an environment for python new version say, 3.6\r\n\r\n`   conda create --name py36 python=3.6\r\n`\r\n3) Activate the new environment\r\n\r\n`    conda activate py36\r\n`\r\n4) Upgrade pip\r\n\r\n`    pip install --upgrade pip\r\n`\r\n5) Install tensorflow\r\n\r\n   ` pip install https://testpypi.python.org/packages/db/d2/876b5eedda1f81d5b5734277a155fa0894d394a7f55efa9946a818ad1190/tensorflow-0.12.1-cp36-cp36m-win_amd64.whl\r\n`\r\nIf it doesn't work\r\n> If you have problem with wheel at the environment location, or pywrap_tensorflow problem,\r\n\r\n     pip install tensorflow --upgrade --force-reinstall\r\n", "If you are in windows, Just open the Anaconda with Administrator privilege, that's it"]}, {"number": 11386, "title": "[XLA] Add DT_HALF to the list of floating point types", "body": "This should not affect the existing CPU and GPU devices, as they do not claim support for D_HALF, and the final registration for each device is the intersection of their advertised list and the global lists.\r\n\r\nThis merely adds DT_HALF as a kind of floating point number, which will allow MatMul to work with DT_HALF. \r\n\r\nLots of other arithmetic ops don't restrict themselves to any specific types, so they accept DT_HALF by default.\r\n\r\nWhy isn't Convolution restricted to kFloatTypes?  I don't see why convolution and matmul are not very similar in backend implementation?\r\n\r\n[I can't imagine why I had not spotted this before]", "comments": ["Can one of the admins verify this patch?", "@frankchn Would be good to get this one run through the unit tests.  I suspect it will be good, but it is a bit of a risk.\r\n", "Jenkins, test this please.", "thanks.  i suspect that the failure to build is something to do with a dependency management error by someone else.\r\n\r\nthe only file that i have changed is xla_op_registry.h and this is not mentioned.  xla_op_registry.cc is mentioned, but only because of the old favourite 'tensorflow/compiler/xla/service/hlo_instruction.h' producing a signed/unsigned comparison warning.\r\n\r\nhopefully if I merge in master then this error will go away.\r\n", "@DavidNorman The tests have been flaky lately, but can you rebase to the latest master and push again? I am happy to retest it.\r\n\r\n@hawkinsp ping on review.", "@frankchn done :)\r\n", "Jenkins, test this please."]}, {"number": 11385, "title": "Skip environment check if config is from core", "body": "Since core `RunConfig` doesn't have `environment`. ", "comments": ["Any update on the review of this yet? Would be nice to get this fix in before the release. ", "Oh just saw the conflicts. Seems like more elegant fix from internal has been pushed. Closing now.", "I re-opened this since it doesn't seem to have been fixed in 1.3.0. Resolved conflicts. Could anyone take a look? ", "@xiejw can you take a look?", "@terrytangyuan is it not fixed because the fix didn't make it into 1.3?", "@martinwicke There was some changes in the same location but I realized later it was a fix for some other issue instead of this.", "Jenkins, test this please.", "Test failure seems unrelated? ", "Yes, it's a transient failure that we get now and then. Since we want to test against windows still, I'll try again.\r\n\r\nJenkins, test this please."]}, {"number": 11384, "title": "Upgrading to 1.2 Causes Issue with CUDA", "body": "I don't know how to describe my problem any better than that, unfortunately. Previously, I was running TensorFlow 1.0, and I could successfully use CUDA:\r\n\r\n```\r\nubuntu@ip-10-0-2-117:~$ /usr/bin/python2.7 /home/ubuntu/src/tensorflow/tensorflow/examples/tutorials/mnist/fully_connected_feed.py\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.7.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.7.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.7.5 locally\r\nSuccessfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\r\nExtracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\r\nSuccessfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\r\nExtracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\r\nSuccessfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\r\nExtracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\r\nSuccessfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\r\nExtracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: Tesla K80\r\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\r\npciBusID 0000:00:1e.0\r\nTotal memory: 11.17GiB\r\nFree memory: 11.11GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0)\r\nStep 0: loss = 2.32 (0.463 sec)\r\n```\r\n\r\netc. However, my new code relies on TensorFlow 1.2, so I upgraded. However, this seems to have somehow disconnected TensorFlow from CUDA:\r\n\r\n```\r\nubuntu@ip-10-0-2-117:~/deep-basecaller$ /usr/bin/python2.7 /home/ubuntu/src/tensorflow/tensorflow/examples/tutorials/mnist/fully_connected_feed.py\r\nExtracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\r\nExtracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\r\nExtracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\r\nExtracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\r\n2017-07-08 18:27:35.208170: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-08 18:27:35.208209: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-08 18:27:35.208218: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-08 18:27:35.208225: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-08 18:27:35.208234: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\nStep 0: loss = 2.31 (0.098 sec)\r\n```\r\n\r\nWhat can I do to fix this problem?", "comments": ["It seems you probably installed the non-gpu version of tensorflow. Try downloading the wheel manually and make sure to choose the gpu version.", "From what it looks like, you have cuda 7.5 installed. If you are trying to use prebuilt tensorflow pip packages, we build these against cuda 8.0.\r\n\r\nSo you either need to upgrade cuda, or install from sources.", "I do have cuda 7.5 installed. Thanks for clarifying what causes the issue and how to fix it!"]}, {"number": 11383, "title": "Feeding TensorArray when running a session using feed_dict", "body": "Currently there is no way to define a placeholder for a `tf.TensorArray`. A solution is to zero-pad a `tf.Tensor` and then unstack and slice it into a `tf.TensorArray`. However, this adds unpadding overhead which would have to be done for every batch.\r\n\r\nA possible change would be to add a new placeholder type for feeding a `tf.TensorArray` to the graph, for example called `tf.tensor_array_placeholder`.\r\n\r\nThis could work as follows:\r\n```python\r\n# Define an input TensorArray with three elements\r\nta_input = tf.tensor_array_placeholder(dtype=tf.float32, size=3)\r\n# Take the second element from the TensorArray\r\nta_second = ta.read(1)\r\n# Sum its values\r\nresult = tf.reduce_sum(ta_second)\r\n\r\nwith tf.Session() as sess:\r\n    run_result = sess.run(\r\n        [result],\r\n        # Feed raw values into ta_input. These could also be NumPy arrays\r\n        { ta_input: [[1, 2, 3], [4, 5], [6, 7, 8, 9]] })\r\n\r\n   print(run_result)  # Should print 9\r\n```", "comments": ["@ebrevdo Here's a feature request relating to TensorArray.", "The unstacking would have to be done even if you use a special placehoder, because TensorArray internal representation is unstacked.  You wouldn't win anything in terms of performance.  Anyway you don't need to pad your input array... Just feed the placeholders tf.shape(placeholder)[0] as the size of the TensorArray you create and unstack.", "Oh I see, you want to feed varying shape entries all at once.  Since all inputs into tensorflow must be representable as a numpy array, and numpy arrays don't allow this, I don't see how it would work.", "Yes exactly - this is a feature request.\r\n\r\nWould it not be possible to feed a python array of numpy arrays to the proposed `tf.tensor_array_placeholder`? Or something similar? I understand this could be quite a niche use case that might require quite a large change, but when working with TensorFlow tools such as `tf.while_loop` that use TensorArrays heavily this could be very useful.", "You can get something similar by creating some N write operations, like so:\r\n\r\n``` python\r\nta = tf.TensorArray(size=placeholder_size)\r\nta_arr = []\r\nta_arr.append(tf.cond(placeholder_size >= 1, lambda: ta.write(0, placeholders[0]), lambda: ta))\r\nta_arr.append(tf.cond(palceholder_size >= 2, lambda: ta.write(1, placeholders[1]), lambda: ta_arr[-1])\r\n...\r\nta_arr.append(tf.cond(placeholder_size >= n, lambda: ta.write(n - 1, placeholders[n-1], lambda: ta_arr[-1]))\r\n\r\n# do computations on ta_arr[-1]\r\n```\r\n\r\nand then feed in placeholder_size and as many placeholders[i] as you want.\r\n\r\ncan even wrap this in a helper function call, probably.", "Hi @ebrevdo, sorry I've just gotten time to try this out.\r\n\r\nThis approach seems to work, but could you speak for how fast this compared to the usual method of feeding single placeholder for Tensors that don't have varying sizes? I am concerned that this method, while clean once inside a helper function call, might be slow when training."]}, {"number": 11382, "title": "test for partial_run_setup with no feeds passed", "body": "", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please", "Getting the following error:\r\n\r\n```Traceback (most recent call last):\r\n  File \"/var/lib/jenkins/workspace/tensorflow-pull-requests-cpu/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/workspace/bazel-out/local-opt/bin/tensorflow/python/session_partial_run_test.runfiles/org_tensorflow/tensorflow/python/client/session_partial_run_test.py\", line 203, in testPartialRunSetupNoFeedsPassed\r\n    h = sess.partial_run_setup([r1])\r\n  File \"/var/lib/jenkins/workspace/tensorflow-pull-requests-cpu/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/workspace/bazel-out/local-opt/bin/tensorflow/python/session_partial_run_test.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 1011, in partial_run_setup\r\n    raise e\r\nTypeError: Cannot interpret feed_list key as Tensor: Can not convert a NoneType into a Tensor.\r\n\r\n======================================================================\r\nERROR: testPartialRunSetupNoFeedsPassed (__main__.PartialRunWithCApiTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/var/lib/jenkins/workspace/tensorflow-pull-requests-cpu/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/workspace/bazel-out/local-opt/bin/tensorflow/python/session_partial_run_test.runfiles/org_tensorflow/tensorflow/python/client/session_partial_run_test.py\", line 203, in testPartialRunSetupNoFeedsPassed\r\n    h = sess.partial_run_setup([r1])\r\n  File \"/var/lib/jenkins/workspace/tensorflow-pull-requests-cpu/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/workspace/bazel-out/local-opt/bin/tensorflow/python/session_partial_run_test.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 1011, in partial_run_setup\r\n    raise e\r\nTypeError: Cannot interpret feed_list key as Tensor: Can not convert a NoneType into a Tensor.```", "@JKurland could you please take a look at the failing tests?", "@tensorflow-jenkins test this please", "The test fails with:\r\n\r\n======================================================================\r\nERROR: testPartialRunSetupNoFeedsPassed (__main__.PartialRunTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/var/lib/jenkins/workspace/tensorflow-pull-requests-cpu/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/workspace/bazel-out/local-opt/bin/tensorflow/python/session_partial_run_test.runfiles/org_tensorflow/tensorflow/python/client/session_partial_run_test.py\", line 203, in testPartialRunSetupNoFeedsPassed\r\n    h = sess.partial_run_setup([r1])\r\n  File \"/var/lib/jenkins/workspace/tensorflow-pull-requests-cpu/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/workspace/bazel-out/local-opt/bin/tensorflow/python/session_partial_run_test.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 1005, in partial_run_setup\r\n    raise e\r\nTypeError: Cannot interpret feed_list key as Tensor: Can not convert a NoneType into a Tensor.\r\n\r\n======================================================================\r\nERROR: testPartialRunSetupNoFeedsPassed (__main__.PartialRunWithCApiTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/var/lib/jenkins/workspace/tensorflow-pull-requests-cpu/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/workspace/bazel-out/local-opt/bin/tensorflow/python/session_partial_run_test.runfiles/org_tensorflow/tensorflow/python/client/session_partial_run_test.py\", line 203, in testPartialRunSetupNoFeedsPassed\r\n    h = sess.partial_run_setup([r1])\r\n  File \"/var/lib/jenkins/workspace/tensorflow-pull-requests-cpu/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/workspace/bazel-out/local-opt/bin/tensorflow/python/session_partial_run_test.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 1005, in partial_run_setup\r\n    raise e\r\nTypeError: Cannot interpret feed_list key as Tensor: Can not convert a NoneType into a Tensor.\r\n\r\n----------------------------------------------------------------------\r\nRan 50 tests in 6.631s\r\n\r\nFAILED (errors=2)\r\n", "Hi,\r\nSorry about the delay. Yeah this is the error the patch is meant to fix.\r\nJosh", "@JKurland OK, can you ping this thread when you have a fix?", "The solution is here\r\nhttps://github.com/tensorflow/tensorflow/pull/11353\r\nCan you combine the two pull requests now, I'm afraid I don't really have time", "@JKurland Can't you just move the test to #11353 and close this PR? Doesn't seem like it would take more than 10 minutes.", "ok added the patch", "Jenkins, test this please", "```\r\ntensorflow/compiler/tf2xla/xla_cpu_backend.cc: In function 'bool tensorflow::CpuOpFilter(tensorflow::KernelDef*)':\r\ntensorflow/compiler/tf2xla/xla_cpu_backend.cc:23:11: error: invalid use of incomplete type 'class tensorflow::KernelDef'\r\n   if (kdef->op() == \"RandomStandardNormal\") {\r\n           ^\r\nIn file included from ./tensorflow/core/framework/op_kernel.h:27:0,\r\n                 from ./tensorflow/core/common_runtime/device.h:41,\r\n                 from ./tensorflow/core/common_runtime/local_device.h:19,\r\n                 from ./tensorflow/compiler/tf2xla/xla_op_registry.h:25,\r\n                 from tensorflow/compiler/tf2xla/xla_cpu_backend.cc:16:\r\n./tensorflow/core/framework/kernel_def_builder.h:27:7: error: forward declaration of 'class tensorflow::KernelDef'\r\n class KernelDef;\r\n```\r\n\r\nSeems to be unrelated.\r\n\r\nJenkins, test this please.", "Jenkins, test this please."]}, {"number": 11381, "title": "test for partial_run_setup with no feeds passed", "body": "", "comments": ["Can one of the admins verify this patch?"]}, {"number": 11380, "title": "Error while slicing with int64", "body": "This is similar to #11318 but with a slice instead of an individual index. I upgraded to the latest version using `pip3 install --user --upgrade tensorflow-gpu`.\r\n\r\n```\r\n>>> import tensorflow as tf\r\n>>> tf.__version__\r\n'1.2.1'\r\n>>> i = tf.constant(1, dtype=tf.int64)\r\n>>> a[i:i+1]\r\n<long stack trace>\r\nTypeError: Input 'strides' of 'StridedSlice' Op has type int32 that does not match type int64 of argument 'begin'.\r\n```", "comments": ["It is known that int 64 index support is not well supported in many of our ops. the workaround is to cast to tf.int32 (with tf.cast) or in this case since it is a constant use  tf.int32. If you are using over 2 billion entry tensors, then you might need to work on adding the support. @vrv, has some ideas on how to handle this more elegantly.\r\n", "Pretty sure this is another bug in SliceHelper. Probably in the first if\ncondition when iterating over the slice objects. I'll try to take a look\nlater.\n\nOn Sat, Jul 8, 2017, 6:47 PM Andrew Selle <notifications@github.com> wrote:\n\n> It is known that int 64 index support is not well supported in many of our\n> ops. the workaround is to cast to tf.int32 (with tf.cast) or in this case\n> since it is a constant use tf.int32. If you are using over 2 billion entry\n> tensors, then you might need to work on adding the support. @vrv\n> <https://github.com/vrv>, has some ideas on how to handle this more\n> elegantly.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/11380#issuecomment-313892044>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAcTeXgm0y8G1BPTi4lMIxu1T6y6w93Pks5sMDE8gaJpZM4ORxaF>\n> .\n>\n", "Yup, bug in SliceHelper -- I'm submitting a fix with tests, and it'll be in probably early this week."]}, {"number": 11379, "title": "TFrecord reading time very high ", "body": "#I have divided a dataset into 10 tfrecords files and I want to read 100 data points from each to create a batch of 10 sequence of 100 data points. I use the following function to do that. The data loading time from the tfrecords start off slow and then reaches to around 0.65s and after 100-200 sess.run calls it increases to around 10s. Can you please point out any mistake or suggestion which might help to reduce the read time ? Also, the behaviour I mentioned becomes more erratic sometimes.\r\n\r\n    def get_data(mini_batch_size):\r\n      data = []\r\n      for i in range(mini_batch_size):\r\n        filename_queue = tf.train.string_input_producer([data_path + 'Features' + str(i) + '.tfrecords'])\r\n        reader = tf.TFRecordReader()\r\n        _, serialized_example = reader.read(filename_queue)\r\n        batch_serialized_example = tf.train.batch([serialized_example], batch_size=step_size, num_threads=8, capacity=step_size)\r\n        features = tf.parse_example(batch_serialized_example,features={'feature_raw': tf.VarLenFeature(dtype=tf.float32)})\r\n        feature = features['feature_raw'].values\r\n        feature = tf.reshape(feature,[step_size, ConvLSTM.H, ConvLSTM.W, ConvLSTM.Di])\r\n        data.append(feature)\r\n      return tf.stack(data)\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 11378, "title": "Disable more timeseries py tests failing under GPU PIP", "body": "", "comments": []}, {"number": 11377, "title": "Optimizers in the C++ API - Issue 9837", "body": "This pull request adds the Optimizer base class and the GradientDescentOptimizer class to the C++ API.\r\nMore details here: https://github.com/tensorflow/tensorflow/issues/9837", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "@theflofly please fix the following sanity check failure (https://ci.tensorflow.org/job/tensorflow-pull-requests-sanity/5149/consoleFull):\r\n\r\n=== Sanity check step 3 of 8: do_buildifier (buildifier check) ===\r\n\r\nRunning do_buildifier on 204 files\r\n\r\ntensorflow/cc/BUILD # reformat listsort unsafesort sort:cc_library.srcs sort:tf_cc_test.deps\r\n\r\nbuildifier took 0 s\r\n\r\nFAIL: buildifier found errors and/or warnings in above BUILD files.\r\nbuildifier suggested the following changes:\r\n589d588\r\n<         \":testutil\",\r\n590a590\r\n>         \":testutil\",\r\n602a603\r\n>         \"training/gradient_descent_optimizer.cc\",\r\n604,605c605\r\n<         \"training/gradient_descent_optimizer.cc\"\r\n<         ],\r\n---\r\n>     ],\r\n606a607\r\n>         \"training/gradient_descent_optimizer.h\",\r\n608,609c609\r\n<         \"training/gradient_descent_optimizer.h\"\r\n<         ],\r\n---\r\n>     ],\r\n617c617\r\n< )\r\n\\ No newline at end of file\r\n---\r\n> )\r\nPlease fix manually or run buildifier <file> to auto-fix.", "I made edits following your comments. Just the part about checking that the variables are trainable, I don't know exactly how we can do it as we don't have a list of trainable vars currently. If you have an idea?", "@theflofly Thanks for addressing my comments. Regarding trainable vs untrainable variables, there are untrainable variables in the Python API, such as global step. I'm not entirely sure whether this is also the case in the C++ API. @suharshs is the expert on this topic and he should be able to provide more insight.", "Also I'll complete the API guide explaining how to use the Optimizer in the C++ API once the code and method names are validated.", "Hi  you compiled c++ with g++ or bazel?", "@yjl9122 Both I'd say, bazel is a build tool not a compiler. I am using mac os and ubuntu, so bazel is either using llvm or gcc regarding the os (I guess). FYI: Debugging with llvm and bazel is not working currently (https://github.com/bazelbuild/bazel/issues/2537).", "I don't think the c_api has support for trainable variables (not sure what the plan is), because it doesn;t have collections AFAIK. I think for now we can add a TODO for this.\r\n@asimshankar may have more information about this.", "Can anybody tell me the current status of this PR? Is it correct, that the problem is that we do not know whether a variable is a trainable one or not? Can anyone share how it is made in Python?\r\n\r\nI am asking it, because I am about to start tackling the issue and have some ideas of how to do it, but firstly I would like to know the current status.", "@DimanNe the current status is: we are waiting for someone from Google to review the code and merge. \r\n\r\nI don't see untrainable variable in the C++ API, do you ? Even if there was, the check would be nice but not mandatory. If there are such variables, I will do the check (don't bother yourself :)).\r\n\r\nI don't think there is something to add to this PR unless someone from google says otherwise. What do you think ?\r\n\r\n@asimshankar could you review this PR please ?", "@theflofly : Sorry for the delay. I will plan on taking a look at this later this week.", "@asimshankar: No worries, FYI I will not be available for the next 7 days. ", "@asimshankar Now available :)", "@asimshankar could you review this, please?", "@theflofly : Apologies for the late response here. Honestly, I was struggling with the choice between adding optimizers to each language API (i.e., this one for C++ and other implementations for other languages), or figuring out a scheme to share the optimizers across languages (for example, by providing a C API for them that all language bindings, including Python, will build on).\r\n\r\nThe fear with implementing higher level constructs in each language is that we will be unable to provide adequate support for all, and more importantly they will diverge over time. \r\n\r\nGiven that, I'm tempted to not merge this PR.\r\nI really do appreciate the effort you've put into this PR though.\r\n\r\nDo you think it could be packaged as an \"extension\" in your own Github repository?", "@asimshankar: Surprising. In that case tensorflow/cc/gradients should be removed too no? Because this PR is merely calls to already existing code in the gradient directory.", "@asimshankar: Also, as the TensorFlow core (kernels) are developed in C++, the base Optimizers should too no? Why C?\r\n\r\nThree months ago you clearly gave a go for that functionality, and here we are. I would be surprised that at Google you rewrite all the stuff done in Python and then use only bindings for the python itself, even if clearly it would be the best solution to maintains only one implementation and not one by language (and it should have been done from the beginning). Is this in the roadmap or just a thought for now? \r\n\r\nI mean, I am totally okay about discarding this PR for a greater good, even work on that greater good.", "@josh11b can you comment on this?", "FYI @josh11b and @asimshankar are both on vacation. Asim should be back sometime next week and Josh in two weeks.", "@theflofly : Firstly, I'd like to thank you for the PR and for pursuing this. I think there is some misunderstanding, so let me try to clarify my postings a bit. There were two points I wanted to make:\r\n\r\n- I didn't mean to suggest that optimizers be _implemented_ in C, but they _be accessible_ from the C API. I meant to suggest that we think through the path to making these features accessible to other language APIs (even if we don't get to implementing it all immediately). Perhaps the right solution still involves your C++ Optimizer class made accessible via C API calls (just like we do for other runtime constructs in the C API implementation), but let's think it through. I do apologize though, this is something I should probably have pointed out earlier in the discussion in #9837. \r\n\r\n- On an unrelated note: The ecosystem would benefit from the ability to have extensions to the TensorFlow APIs built, owned and hosted by contributors so that ideas (particularly in early stages) are not slowed down by unavailable bandwidth from the TensorFlow maintainers. It appeared to me (but perhaps I'm wrong) that this particular feature would have been a great way to demonstrate that as it is purely additive over existing C++ APIs (though, maybe some of the changes you require could be split out into their own PR). But, I do admit that this idea is somewhat orthogonal to the content of the PR itself. \r\n\r\nRegarding other points you have raised since: I would argue that the C++ gradients should not be removed precisely because they are providing a path to constructing the gradient graph in other languages (`TF_AddGradients`). And in fact, internally we have even discussed ways in which gradient functions defined in one language can be made accessible to others. So while the implementation isn't quite there yet (and isn't on the top of the priority list yet), I feel comfortable with the thought put into the plan for gradient functions.\r\n\r\nRegarding this PR, it would be helpful to chart out the full plan in a document before worrying about specifically the C++ code for a gradient descent optimizer. Again, it's okay if we don't get to implementing everything right away, but it would be helpful to have a design and plan charted out and agreed upon. That would also allow for others in the community interested in this area to productively contribute. \r\n\r\nDoes that sound reasonable to you? If so, I'm happy to engage on charting a path out in a document. If not, I'd be glad to hear your concerns.\r\n", "@asimshankar: Thanks for answering whereas you are in vacation (apparently). If the C++ gradients are used by other languages, yes it makes sense to keep them (the C thing confused me).\r\n\r\n* I am okay about drafting a document, even if I am not sure about the question it will answer, from my understanding: \"Steps to create base gradients and optimizers to be used by others languages\"?\r\n\r\n* Should not the gradients (and optimizers in the future) be moved in the core dir so it is clear that they are the base and other languages should use them (this can be answered in the document)?\r\n\r\n* For the plugin thing I agree for exotic things such as LBFGS for instance, but for basic stuff like backprop (and optimizers for a higher level), I think it should be part of the TensorFlow project else you can't train using the C++ API.\r\n\r\n* Finally what should we do about this PR?", "@asimshankar Because I have c++ code I want to reuse in a new project. I don't know if it is worth rewriting old code for python or wait for c++ API in order to use tensorflow. is it there an estimated time for when c++ API is going to usable for training ? How can we contribute to this end ? ", "**[UNRELATED TO THE PR]**\r\n\r\n@dguerra I will focus on the missing gradient operations. Once the missing gradients are added the training is possible, just not as easy.", "@theflofly Once you have one example of gradient implementation for a binary operation I'll be happy to add more operations myself. Being able to train any kind of neural networks (although very simple ones) would be a nice start", "**[UNRELATED TO THE PR]**\r\n\r\n@dguerra Someone beat me at it. @rmlarsen merged 19 hours ago. You now have:\r\n\r\n* AddGrad\r\n* SubGrad\r\n* MulGrad\r\n* DivGrad\r\n* RealDivGrad\r\n* SquaredDifferenceGrad\r\n\r\nin `tensorflow/cc/gradients/math_grad.cc`. You code should now run smoothly.\r\n\r\nThe thing that bother me is that for instance, in core we have:\r\n```\r\nStatus AddGrad(const AttrSlice& attrs, FunctionDef* g) {\r\n  // clang-format off\r\n  return GradForBinaryCwise(g, {\r\n      {{\"gx\"}, \"Identity\", {\"dz\"}},\r\n      {{\"gy\"}, \"Identity\", {\"dz\"}},\r\n  });\r\n  // clang-format on\r\n}\r\nREGISTER_OP_GRADIENT(\"Add\", AddGrad);\r\n```\r\nand in the cc/gradient we have:\r\n```\r\nStatus AddGrad(const Scope& scope, const Operation& op,\r\n                const std::vector<Output>& grad_inputs,\r\n                std::vector<Output>* grad_outputs) {\r\n   // y = x_1 + x_2\r\n   // dy/dx_1 = dy/dx_2 = 1\r\n   auto gx_1 = Identity(scope, grad_inputs[0]);\r\n   auto gx_2 = Identity(scope, grad_inputs[0]);\r\n   return BinaryGradCommon(scope, op, grad_outputs, gx_1, gx_2);\r\n }\r\n REGISTER_GRADIENT_OP(\"Add\", AddGrad);\r\n```\r\nSo I am wondering if there is a way to use the kernel code instead of redefining it in the gradient API.", "**[UNRELATED TO THE PR]**\r\n\r\n@dguerra: Actually it still does not work because of the Assign node. I made some changes to gradients.cc in this PR, I'll make another PR with only these changes so that we can use AddSymbolicGradients.", "@theflofly It works well now for me. I tried both methods: AddSymbolicGradients and explicit gradient formula and it gives same results. In my example \"Assign\" node is only called once for initialization so not need to go through it when backpropagating the error. I will go now for a neural network with few layers and then convolutional nets to see what happens", "**[UNRELATED TO THE PR]**\r\n\r\n@dguerra: Really ?\r\nDo you give a Assign node or a Var node as input to an op ?\r\nIf you have:\r\n```\r\nauto w1 = Variable(scope, {3, 3}, DT_FLOAT);\r\nauto assign_w1 = Assign(scope, w1, Const(scope, ...));\r\n```\r\nthen are you doing this: `Tanh(scope, w1);`(1) or `Tanh(scope, assign_w1);`(2) ? Because if you are using assign_ node as in (2) everywhere, your variables will never change, as at each step the const value is reassigned. If you are using var as in (1) the gradient graph will not be correct because of an error that I solved.\r\nI am replacing the tests from Const to Var and I will do a PR.\r\nIf you are able to train a network (add ApplyGradientDescent nodes to you graph) and it works please share your code because I may be wrong but I did not succeed to train without editing gradients.cc.\r\nAlso we should stop polluting this PR I guess.", "@theflofly yes sure, I've used variables as inputs to the ops.\r\n\r\nShall we start a new thread or platform for conversation about general usage and development of Tensorflow C++ API ?\r\n\r\n\r\n```\r\n#include \"tensorflow/cc/client/client_session.h\"\r\n#include \"tensorflow/cc/ops/standard_ops.h\"\r\n#include \"tensorflow/cc/framework/gradients.h\"\r\n#include \"tensorflow/core/framework/tensor.h\"\r\n\r\n\r\nint main()\r\n{\r\n  using namespace tensorflow;\r\n  using namespace tensorflow::ops;\r\n  Scope root = Scope::NewRootScope();\r\n  \r\n  auto W = Variable(root.WithOpName(\"W\"), {3,1}, DT_DOUBLE);\r\n\r\n  auto x = Placeholder(root.WithOpName(\"x\"), DT_DOUBLE);\r\n  auto y = Placeholder(root.WithOpName(\"y\"), DT_DOUBLE);\r\n\r\n  auto d = Subtract(root, y, MatMul(root, x, W));\r\n  \r\n  // Compute gradients\r\n  auto dd = MatMul(root, d, d, MatMul::TransposeA(true));\r\n  // auto half = Const(root, {0.5});\r\n  auto loss = MatMul(root, dd, {{0.5}}); \r\n\r\n  double learning_rate = 0.1;\r\n \r\n\r\n  std::vector<Output> grad_outputs;\r\n  TF_CHECK_OK(AddSymbolicGradients(root, {loss}, {W}, &grad_outputs));\r\n\r\n  //Explicit gradient formula:\r\n  //auto grad_W = Subtract(root, MatMul(root, MatMul(root, x, x, MatMul::TransposeA(true)), W), MatMul(root, x, y,  MatMul::TransposeA(true)));\r\n  \r\n  // apply either: the ouput from AddSymbolicGradients or explicit gradient formula\r\n  auto apply_grad_W = ApplyGradientDescent(root, W, learning_rate,  grad_outputs[0]);\r\n\r\n  //Initialize variables\r\n  auto init_W = Assign(root, W, {{1.0},{1.0},{1.0}});\r\n\r\n  std::vector<Tensor> outputs;\r\n  ClientSession session(root);\r\n\r\n  //Run variable initializers\r\n  session.Run({init_W}, &outputs);\r\n\r\n  for(unsigned int i=0;i<200;++i)\r\n  {\r\n    //y = 3.0 * x1 + 4.0 * x2 + 5.0\r\n    TF_CHECK_OK(session.Run( { {x,{{1.0,-1.0,3.0}, {1.0,2.0,1.0}, {1.0,-2.0,-2.0}, {1.0,0.0,2.0}}}, {y,{{14.0}, {15.0}, {-9.0}, {13.0}}} } , {loss, apply_grad_W}, &outputs));\r\n    std::cout << std::string(\"loss: \") << outputs[0].scalar<double>() << std::endl << std::string(\"weights: \")<< outputs[1].matrix<double>() << std::endl;\r\n  }\r\n  return 0;\r\n}\r\n\r\n```\r\n", "**[UNRELATED TO THE PR]**\r\n\r\n@dguerra: I see :). It is because you are creating the Assign node after the call to AddSymbolicGradients, as it is not here during the gradient graph creation, there is no problem.\r\n\r\nPut it right after the declaration of W and it will not work anymore. Was it on purpose or random luck ?\r\n\r\nMy code for a var looks more like:\r\n\r\n```\r\n\r\n// weights init\r\nauto w1 = Variable(scope, {3, 3}, DT_FLOAT);\r\nauto assign_w1 = Assign(scope, w1, Const(scope, {{0.1f, 0.1f, 0.1f}, {0.2f, 0.2f, 0.2f}, {0.2f, 0.2f, 0.2f}}));\r\n```\r\nIn that case it does not work, so I'll make a PR anyway. I don't know where we could talk about that, I'll add **[UNRELATED TO THE PR]** before my comments, so that the person reviewing the PR will focus on important ones.", "@theflofly Variable initialization should go in a different branch of the graph so when you \"run\" the initialization part it does not execute the rest and vice versa. I think it is done in a similar manner in Python. I haven't been able to apply random initialization to a variable yet. Have you?", "**[UNRELATED TO THE PR]**\r\n\r\n@dguerra: Did you try https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/random-normal ?\r\n\r\nIn python we call `w1 = tf.Variable(tf.random_normal([3, 3]), name=\"W1\")` and if you read the code, it says \"This constructor creates both a `variable` Op and an `assign` Op to set the\r\n    variable to its initial value.\". So the Var an Assign op are added to the graph at the same level, not after the gradients call.\r\nI agree the init run on the apply ops must be done before the run on the graph (and only once). A Variable Op in C++ that create a Var + Assign would be nice, so would be the same kind of mechanism: `tf.global_variables_initializer()`.", "[UNRELATED TO THE PR]\r\n\r\n@dguerra: The PR is there finally: https://github.com/tensorflow/tensorflow/pull/12397", "@theflofly some kind of variable initializer would be a useful addition. In addition it would be useful as well to add some kind of function to get the set of trainable variable in the graph. Such as trainable_variable() or get_collection() in Python. What do you think?", "@dguerra: Totally, I'll maybe work on it when I will be done with my gradients operations.\r\nI guess we should have a Variable(...) that allows to create a var, a const and an assign node automatically all in one call. This Variable(...) would also complete a list of trainable var and a list of assign node. The list of Assign node would then be used during the init step.", "Catching up on this now that I'm back. Seems like there has been a bunch of discussion unrelated to this specific PR :). Perhaps, as @dguerra suggested, this discussion can be moved off this PR into a separate issue? \r\n\r\n@theflofly : Responses to your [comments above](https://github.com/tensorflow/tensorflow/pull/11377#issuecomment-321402783):\r\n\r\n- The document would outline a plan for making optimizers available in other languages. Most likely this would consist of at least two parts: (1) Detailed design of the C++ API (such as handling of sparse gradients, [slots](https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/python/training/optimizer.py#L235)), perhaps even an introduction of a `Variable` class in the API and (2) Design of a C API for optimizers (which will likely wrap over the C++ API), sample outlines of the implementation in one or two language to provide confidence that the API is sufficient, discussion of if/how users in other languages can add new optimizers and how they can be made available across languages (or does doing so require a C++ implementation) etc. I think it might be best for someone on the TensorFlow team who has experience with other language bindings to start on such a draft and share it here for comments/suggestions/improvements/discussion. I will try to get this going on our end, but do not have a timeline yet.\r\n\r\n- There is some confusion about the gradients in `core/` vs `cc/`, @suharshs knows the details, but long story short, the gradients in `cc/` *are* accessible in other languages. They are the ones picked up by `TF_AddGradients`. So, that mechanism is already setup (the unfortunate directory structure confusion notwithstanding).\r\n\r\n- I agree that ultimately Optimizers should be part of the API. However, a separate plugin/repository for now was a suggestion to allow for rapid progress that doesn't block on us (TensorFlow maintainers) from being to have the bandwidth to provide support for it.\r\n\r\nA technical detail regarding variables: We should be using resource variables ([`class ResourceVariable` in Python](https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/python/ops/resource_variable_ops.py#L38)) instead of reference variables, as they have more clearly defined semantics. We're aiming to switch [Python to that as well](https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/python/ops/variable_scope.py#L254) in upcoming releases. For example, this would mean using [`ResourceApplyGradientDescent`](https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/resource-apply-gradient-descent) instead of the [`ApplyGradientDescent`](https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/apply-gradient-descent) operation. I apologize that this distinction isn't well documented (it has been mostly an implementation detail, but now that we're seeing contributions for other languages, it is an implementation detail that more people will be interested in :)\r\n\r\nRegarding this PR itself: Even if we were to ignore the C API and other languages and think only of a C++ Optimizer, there are some broader design considerations that need to be thought through - sparse gradients, slots, reference variables. \r\n\r\nA starting point might be a write-up that looks at the features required to implement the various optimizers that exist in Python today and their handling of dense and sparse variables. \r\n\r\nAs you've noted, any PRs to help improve coverage of the C++ gradient registry are also greatly appreciated.", "@asimshankar: Ok. Maybe you should create the document (google drive I guess :)) and add me on it, my email address being floriancourtial@gmail.com. Also shouldn't I close this PR? Because the result in the end will be far away from what has been done here I'd say.", "Thanks for your understanding @theflofly . Will close the PR for now and keep you in the loop.\r\nIn the mean time, please do feel encouraged to make other contributions like you've been doing to the gradient functions and the bug fixes. Much appreciated", "@asimshankar Should I close the original issue https://github.com/tensorflow/tensorflow/issues/9837 or keep it to track the work in progress on Optimizers?"]}, {"number": 11376, "title": "py_func does not properly", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nUbuntu 14.04\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n- **TensorFlow version (use command below)**:\r\n1.2\r\n- **Python version**: \r\n3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\nCudnn v5.1\r\n- **GPU model and memory**:\r\nPascal Titan X\r\n- **Exact command to reproduce**:\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndef fun(x):\r\n    return np.ones([5]), np.ones([5])\r\n\r\n\r\naa, b = tf.py_func(fun, [1], tf.uint8)\r\n```\r\n\r\n### Describe the problem\r\nThe `py_func` does work properly\r\n\r\n### Source code / logs\r\n```\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 9, in <module>\r\n    a, b = ab\r\n  File \"/home/jrmei/lib/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 541, in __iter__\r\n    raise TypeError(\"'Tensor' object is not iterable.\")\r\nTypeError: 'Tensor' object is not iterable.\r\n```\r\n", "comments": ["I met a similar problem,\r\nafter reshape a tensor,  py_func raise TypeError(\"'Tensor' object is not iterable.\")\r\nhow did you solve this problem?", "@ilovin \r\nIt should be\r\n```\r\na, b = tf.py_func(fun, [params], [tf.uint8, tf.uint8])\r\n```"]}, {"number": 11375, "title": "tensorflow-\"ValueError: Operation 'init' has been marked as not fetchable\" Plz Help", "body": "I started working with LSTMs for conversation modelling. I have got a sample piece of code with a persistent error. The code is given below.\r\n\r\n'''\r\nA Dynamic Recurrent Neural Network (LSTM) implementation example using\r\nTensorFlow library. This example is using a toy dataset to classify linear\r\nsequences. The generated sequences have variable length.\r\nLong Short Term Memory paper: http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf\r\nAuthor: Aymeric Damien\r\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\r\n'''\r\n\r\nfrom __future__ import print_function\r\n\r\nimport tensorflow as tf\r\nimport random\r\ndata_path=\"C:/Users/AnacondaProjects/Convmodels/CleanedData/embeddings/\"\r\n\r\n\r\n# ====================\r\n#  TOY DATA GENERATOR\r\n# ====================\r\nclass ToySequenceData(object):\r\n    def __init__(self, n_samples=100, max_seq_len=10, min_seq_len=2):\r\n        self.data = []\r\n        self.labels = []\r\n        self.seqlen = []\r\n        dummy_vector=[float(0.0) for i in range(300)]\r\n        for i in range(n_samples):\r\n            with open(data_path+str(i)+\".txt\",\"r\",encoding=\"utf-8\") as inp:\r\n                input_line=[[float(i) for i in line.split()] for line in inp]\r\n                current_input=[]\r\n                for j in range(min(10,len(input_line)-1)):\r\n                    current_input.append(input_line[j])\r\n                    temp_data=current_input[:]\r\n                    temp_data=temp_data+[dummy_vector[:] for k in range(max_seq_len-j-1)]\r\n                    current_input=temp_data[:]\r\n                    self.data.append(temp_data)\r\n                    self.labels.append(input_line[j+1])\r\n                    self.seqlen.append(j+1)\r\n                i=i+(min(10,len(input_line)-1)-1)\r\n        self.batch_id = 0\r\n\r\n    def next(self, batch_size):\r\n        \"\"\" Return a batch of data. When dataset end is reached, start over.\r\n        \"\"\"\r\n        if self.batch_id == len(self.data):\r\n            self.batch_id = 0\r\n        batch_data = (self.data[self.batch_id:min(self.batch_id +\r\n                                                  batch_size, len(self.data))])\r\n        batch_labels = (self.labels[self.batch_id:min(self.batch_id +\r\n                                                  batch_size, len(self.data))])\r\n        batch_seqlen = (self.seqlen[self.batch_id:min(self.batch_id +\r\n                                                  batch_size, len(self.data))])\r\n        self.batch_id = min(self.batch_id + batch_size, len(self.data))\r\n        return batch_data, batch_labels, batch_seqlen\r\n\r\n\r\n# ==========\r\n#   MODEL\r\n# ==========\r\n\r\n# Parameters\r\nlearning_rate = 0.01\r\ntraining_iters = 1000\r\nbatch_size = 128\r\ndisplay_step = 10\r\n\r\n# Network Parameters\r\nseq_max_len = 10 # Sequence max length\r\nn_hidden = 64 # hidden layer num of features\r\nn_classes = 300 # linear sequence or not\r\n\r\ntrainset = ToySequenceData(n_samples=100, max_seq_len=seq_max_len)\r\ntestset = ToySequenceData(n_samples=20, max_seq_len=seq_max_len)\r\n\r\n# tf Graph input\r\nx = tf.placeholder(\"float\", [None, seq_max_len, n_classes])\r\ny = tf.placeholder(\"float\", [None, n_classes])\r\n# A placeholder for indicating each sequence length\r\nseqlen = tf.placeholder(tf.int32, [None])\r\n\r\n# Define weights\r\nWeights = {\r\n    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\r\n}\r\nBiases = {\r\n    'out': tf.Variable(tf.random_normal([n_classes]))\r\n}\r\n\r\n\r\ndef dynamicRNN(x, seqlen, Weights, Biases):\r\n\r\n    # Prepare data shape to match `rnn` function requirements\r\n    # Current data input shape: (batch_size, n_steps, n_input)\r\n    # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\r\n    \r\n    # Unstack to get a list of 'n_steps' tensors of shape (batch_size, n_input)\r\n    x = tf.unstack(x, seq_max_len, 1)\r\n    \r\n    # Define a lstm cell with tensorflow\r\n    with tf.variable_scope('lstm_cell_def'):\r\n        lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden)\r\n\r\n    # Get lstm cell output, providing 'sequence_length' will perform dynamic\r\n    # calculation.\r\n    with tf.variable_scope('rnn_cell_def',reuse=True): \r\n        outputs, states = tf.contrib.rnn.static_rnn(lstm_cell, x, dtype=tf.float32,\r\n                            sequence_length=seqlen)\r\n\r\n    # When performing dynamic calculation, we must retrieve the last\r\n    # dynamically computed output, i.e., if a sequence length is 10, we need\r\n    # to retrieve the 10th output.\r\n    # However TensorFlow doesn't support advanced indexing yet, so we build\r\n    # a custom op that for each sample in batch size, get its length and\r\n    # get the corresponding relevant output.\r\n\r\n    # 'outputs' is a list of output at every timestep, we pack them in a Tensor\r\n    # and change back dimension to [batch_size, n_step, n_input]\r\n    outputs = tf.stack(outputs)\r\n    outputs = tf.transpose(outputs, [1, 0, 2])\r\n\r\n    # Hack to build the indexing and retrieve the right output.\r\n    batch_size = tf.shape(outputs)[0]\r\n    # Start indices for each sample\r\n    index = tf.range(0, batch_size) * seq_max_len + (seqlen - 1)\r\n    # Indexing\r\n    outputs = tf.gather(tf.reshape(outputs, [-1, n_hidden]), index)\r\n\r\n    # Linear activation, using outputs computed above\r\n    return tf.matmul(outputs, Weights['out']) + Biases['out']\r\n\r\npred = dynamicRNN(x, seqlen, Weights, Biases)\r\n\r\n# Define loss and optimizer\r\ncos_dist=tf.losses.cosine_distance(predictions=pred,labels=y,dim=1)\r\n#cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\r\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cos_dist)\r\n\r\n# Evaluate model\r\n#correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\r\nnormalize_pred = tf.nn.l2_normalize(pred,1)        \r\nnormalize_y = tf.nn.l2_normalize(y,1)\r\ncorrect_pred=(1+tf.reduce_sum(tf.multiply(normalize_pred,normalize_y)))/2\r\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\r\n\r\n# Initializing the variables\r\ninit = tf.global_variables_initializer()\r\n\r\n# Launch the graph\r\nwith tf.Session() as sess:\r\n    sess.run(init)\r\n    step = 1\r\n    # Keep training until reach max iterations\r\n    while step * batch_size < training_iters:\r\n        batch_x, batch_y, batch_seqlen = trainset.next(batch_size)\r\n        # Run optimization op (backprop)\r\n        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\r\n                                       seqlen: batch_seqlen})\r\n        if step % display_step == 0:\r\n            # Calculate batch accuracy\r\n            acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y,\r\n                                                seqlen: batch_seqlen})\r\n            # Calculate batch loss\r\n            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y,\r\n                                             seqlen: batch_seqlen})\r\n            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\r\n                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\r\n                  \"{:.5f}\".format(acc))\r\n        step += 1\r\n    print(\"Optimization Finished!\")\r\n\r\n    # Calculate accuracy\r\n    test_data = testset.data\r\n    test_label = testset.labels\r\n    test_seqlen = testset.seqlen\r\n    print(\"Testing Accuracy:\", \\\r\n        sess.run(accuracy, feed_dict={x: test_data, y: test_label,\r\n                                      seqlen: test_seqlen}))\r\n\r\nWhen I run this, it get \" ValueError: Operation 'init' has been marked as not fetchable \" and pointing to line: \" sess.run(init) \" Please kindly help! Thanks in advance.", "comments": []}, {"number": 11374, "title": "bazel build //tensorflow/examples/android:tensorflow_demo", "body": "when i run  bazel build //tensorflow/examples/android:tensorflow_demo.i get the result as follow:\r\n\r\nINFO: Found 1 target...\r\nERROR: missing input file '@androidsdk//:build-tools/24.0.3/lib/dx.jar'.\r\nERROR: /home/zhu/tensorflow/tensorflow/examples/android/BUILD:63:1: //tensorflow/examples/android:tensorflow_demo: missing input file '@androidsdk//:build-tools/24.0.3/lib/dx.jar'.\r\nTarget //tensorflow/examples/android:tensorflow_demo failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nERROR: /home/zhu/tensorflow/tensorflow/examples/android/BUILD:63:1 1 input file(s) do not exist.\r\nINFO: Elapsed time: 18.794s, Critical Path: 0.60s\r\n", "comments": ["You may did a mistake in this step https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android#edit-workspace\r\nDid you provide the right path?", "This issue is automatically closed due to lack of activity. Please re-open if this is still an issue for you. Thanks!"]}, {"number": 11373, "title": "[Slim] Training accuracy is increasing very slowly", "body": "Hi,\r\n\r\nI feel something odd is happening with my Inception_Resnet_v2 training. I am what I'm seeing is correct but it seems the training will take forever at the current rate. \r\n\r\nI am training slim against the full Imagenet dataset approx 14M images. The training is running on 8GPUs and the batch size is the default 32. If my calculations are correct this means that each epoch should consist of approximately (54,000 steps):\r\n\r\n14,000,000 / (8 * 32) \r\n\r\nThe training has been running for 800,000 steps so far (approx 15 epochs) yet the accuracy just reached 22%.\r\n\r\nI have been evaluating the model after each 100,000 steps and at the start, the accuracy used to increase by 5% after each 100,000 step up until 500,000 steps, yet now it seems to be rapidly slowing down as now I am getting in approximate 0.8% increase every 100,000 steps after reaching the 500,000 steps mark.\r\n\r\nI am not sure if this is expected as I do not have any data to compare it with but at this rate it can take several months, maybe even years to reach a viable accuracy rate. I am trying to reach somewhere above 70% at least.\r\n\r\nNow is this expected? Are there any ways to speed up training beside adding GPUs? And if the latter is my only option, is it possible to continue training on the same checkpoints once the number of GPUs has increased?\r\n\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 11372, "title": "RecordInput blocks if file_pattern returns no files.", "body": "The `tensorflow.python.ops.data_flow_ops.RecordInput()` blocks forever if the first input argument with keyword `file_pattern` is a pattern that does not point to (an) existing file(s).\r\n\r\nIt does not seem to be waiting for that file to appear either, because if I make it appear after the launch it's still blocked, leading me to believe this is a bug.\r\n\r\nReproduce:\r\n```python\r\nsess = tf.Session()\r\nrecord_input = data_flow_ops.RecordInput(file_pattern=\"foo\")\r\nyield_op = record_input.get_yield_op()\r\nsess.run(tf.global_variables_initializer())\r\nsess.run(yield_op)\r\n```", "comments": ["@ekelsen it looks as if RecordYielder main loop will exit immediately with an error if the fileset is empty, which should cause the yield op to return immediately with an error. Not sure why the above behavior is being reported.", "Version is 1.2.1 from pypi (Both macOS and Ubuntu14.04).\n\nOn Mon, 10 Jul 2017 at 19:13, Michael Isard <notifications@github.com>\nwrote:\n\n> @ekelsen <https://github.com/ekelsen> it looks as if RecordYielder main\n> loop will exit immediately with an error if the fileset is empty, which\n> should cause the yield op to return immediately with an error. Not sure why\n> the above behavior is being reported.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/11372#issuecomment-314171810>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AHXSRJpMO_2abvap60up7Oe4nO67viWVks5sMlumgaJpZM4ORtds>\n> .\n>\n", "Bug identified, should be fixed internally soon.", "Thank you sir. Can you check out if you can fix #11396 while you're at it?"]}, {"number": 11371, "title": "Placeholder with shape=(None, 1024) gives an error when used with tf.cond", "body": "I'm using TensorFlow v1.2.0. Here is a simple example that shows the problem.\r\nIf a dimension of a placeholder is None I get the following error:\r\n\r\n```\r\nInvalidArgumentError (see above for traceback): Shape [-1,1024] has negative dimensions\r\n\t [[Node: cond/Placeholder = Placeholder[dtype=DT_FLOAT, shape=[?,1024], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](^cond/switch_t)]]\r\n```\r\n\r\nIf I set the shape to None or to (1024, 1024) it gives no error. \r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nrand_array = np.random.rand(1024, 1024)\r\n\r\nx_c = tf.constant(rand_array, dtype=tf.float32)\r\n\r\npy_flag = False\r\nflag = tf.constant(py_flag, tf.bool)\r\n\r\ndef pl():\r\n    return tf.placeholder(dtype=tf.float32, shape=(None, 1024))\r\n\r\nx = tf.cond(flag, pl, lambda: x_c)\r\n\r\ny = tf.matmul(x, x)\r\n\r\nwith tf.Session() as sess:\r\n    if py_flag:\r\n        print(sess.run(y, feed_dict={x: rand_array}))\r\n    else:\r\n        print(sess.run(y))\r\n```", "comments": ["if py_flag == True, then session run. But palceholder cannot find the feed_dict. Then error happened.\r\nThere is possibility in other places you call the op without feed_dict. Have a try, good look.", "It looks as if this is fixed in the master branch: would you try there?", "I'm having troubles installing the latest version of Bazel unfortunately. It only let me install version 0.1.3 and I can't build TensorFlow as it requires version 0.4.5 (on a Mac). I would suggest though that if you tested my example and it works in the master branch then we can mark this as closed. Thank you.", "I am having a very similar problem to this one. Tf cond does not seem to affect my input placeholder to which I want to ad some salt and pepper noise. Consider the following code:\r\n\r\n    def noise_mask(input, keep_prob):    \r\n        return tf.zeros_like(input)\r\n    def binary_noise(input, keep_prob=0.05, is_training=True):\r\n        is_training = tf.Variable(is_training)\r\n        return tf.cond(is_training, lambda: noise_mask(input, keep_prob), lambda: tf.identity(input))\r\n\r\nThis simple version sets all tensor values to zero if desired, i.e. if is training == true.\r\nThen I apply this to the output layer:\r\n\r\n`\r\nself.out = utils.binary_noise(tf.add(tf.matmul(self.hidden, self.weights['w2']), self.weights['b2']), is_training=True)`\r\n\r\nAs expected, the loss stagnates as the output layer is not able to pass the gradient through.\r\nEpoch:   1      Cost:0.693194389        Loss:0.692861199\r\nEpoch:   2      Cost:0.693194389        Loss:0.692861199\r\nEpoch:   3      Cost:0.693194389        Loss:0.692861199\r\n\r\nNow, I would like to apply this function to the input to add binary noise.\r\nConsider:\r\n\r\n    self.x_input = tf.placeholder(tf.float64, [None, self.n_input])\r\n    self.x = utils.binary_noise(self.x_input, keep_prob=0.05, is_training=False)`\r\n\r\nHowever the loss changes as well, when is_training == True. I have no idea why this is the case.", "I am able to replicate the error of the first post.\r\n```\r\nself.x_input = tf.placeholder(tf.float64, [None, self.n_input])\r\nself.x = utils.binary_noise(self.x_input, self.is_training)\r\n\r\n```\r\nAs I change \"None\" for 100 everything works fine.\r\n\r\n> InvalidArgumentError (see above for traceback): Shape [-1,2000] has negative dimensions\r\n> \t [[Node: AEC/Placeholder_1 = Placeholder[dtype=DT_DOUBLE, shape=[?,2000], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]", "@zeis If you have trouble getting Bazel on your system, you could always try installing the nightly. For example, one such URL: `pip install --upgrade https://ci.tensorflow.org/view/Nightly/job/nightly-matrix-cpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=cpu-slave/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-1.2.1-cp27-none-linux_x86_64.whl`. Could you please confirm that it solves the problem for you?", "Thanks @jart.\r\n\r\nI've just tested it using the following nightly build and it worked!\r\n\r\nhttps://ci.tensorflow.org/view/Nightly/job/nightly-matrix-cpu/548/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=mac-slave/artifact/pip_test/whl/tensorflow-1.2.1-cp35-cp35m-macosx_10_11_x86_64.whl", "That's great to hear; thank you for confirming. I'll close this one out now.", "@jart I would add a test case to the repository to confirm that the issue is solved and to have it in the future for regression testing, before closing the issue itself. "]}, {"number": 11370, "title": "Feature Request: Include Depthwise Convolution in graph_transforms fold_batch_norms", "body": "Hi!\r\n\r\nCurrently, the graph_transforms tool includes only `Conv2D` and `MatMul` ops when folding batch normalization scaling/multiplication into its weights, as in `fold_batch_norms.cc`. Google's Mobilenet example uses depthwise convolution extensively, so it would be nice to include this feature for the `DepthwiseConv2dNative` operation. The problem here is that weights are ordered differently for this operation and contain the `channel_muliplier` which would need to be checked when trying to bake subsequent multiplications. \r\n", "comments": ["This may be a bit tricky to implement, since as mentioned the depthwise convolution does its math a bit differently from the standard version. I'd like to see this added too, but I'm not sure of a timeframe on when we'll get to it, so adding to contributions welcome as well.", "Would this be the right approach in general? Or doesn't this work with the depthwise-convolution math?\r\n\r\nSo `Conv2D` has its filters as\r\n    [filter_height, filter_width, in_channels, out_channels]\r\n\r\nwhile `DepthwiseConv2dNative` has \r\n    [filter_height, filter_width, in_channels, channel_multiplier]\r\n\r\nSo in the simple case of `channel_multiplier=1`, we have `out_channels=in_channels`, and `mul_values.shape().dim_size(0) == in_channels` and something like\r\n\r\n    auto weights_mapped = weights.tensor<float, 4>();\r\n    auto scaled_weights_mapped = scaled_weights.tensor<float, 4>();\r\n\r\n    for (int64 cm = 0; cm < weights.dim_size(3); ++cm) {\r\n      for (int64 ic = 0; ic < weights.dim_size(2); ++ic) {\r\n        for (int64 w = 0; w < weights.dim_size(1); ++w) {\r\n          for (int64 h = 0; h < weights.dim_size(0); ++h) {\r\n            scaled_weights_mapped(h,w,ic,cm) = weights_mapped(h,w,ic,cm) * mul_values.flat<float>()(ic);\r\n          }\r\n        }\r\n      }\r\n    }\r\n\r\n", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you.", "We also need this in our project. We will really appreciate it if you give timeline when it will be added (if at all). We need to know if it is not planned for the near future. In this case we need to develop it in our code.\r\nI'll appreciate your quick reply.\r\nThanks", "This script may help you. https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/quantize/python/fold_batch_norms.py . In deed, if you run tf 1.9, grappler always optimize batch normalization when possible. ", "Closing as this is resolved", "@petewarden I see this issue was closed without a fix being added to the Graph Transform Tool. Would you be interested in a PR that adds depthwise convolution support to the C++ implementations of the `fold_batch_norms` and `fold_old_batch_norms` rewrites?\r\n\r\nI've already implemented depthwise convolution support in my own Python version of `fold_*_batch_norms`; code is [here](https://github.com/CODAIT/graph_def_editor/blob/5695fdc9381ee0f935d1ece7547e5bf111cae25e/graph_def_editor/rewrite.py#L194)."]}, {"number": 11369, "title": "TFRecord parse multiple times using parse_example", "body": "In order to parse a sequence of example, I am using the following code in tensorflow.\r\n    \r\n    sequence_len = 10\r\n    filename_queue = tf.train.string_input_producer(['foo.tfrecords'])\r\n    reader = tf.TFRecordReader()\r\n    _, seralized_example = reader.read_up_to(filename_queue,sequence_len)\r\n    features = tf.parse_example(seralized_example,features={'feature_raw': tf.VarLenFeature(dtype=tf.float32)})\r\n    feature = features['feature_raw'].values\r\n\r\nThis will give me a sequence of 10 examples. But I want to read the first 10 example sequence in on gpu the next one in the next gpu and so on. However, when I do that using tf.device() as follows, I get the same data in all the gpus. \r\n    \r\n    sequence_len = 10\r\n    data = []\r\n    filename_queue = tf.train.string_input_producer(['foo.tfrecords'])\r\n    reader = tf.TFRecordReader()\r\n    for g in range(num_gpus):\r\n      with tf.device('/gpu:%d' % g):\r\n        _, seralized_example = reader.read_up_to(filename_queue,sequence_len)\r\n        features = tf.parse_example(seralized_example,features={'feature_raw': tf.VarLenFeature(dtype=tf.float32)})\r\n        feature = features['feature_raw'].values\r\n        data.append(feature)\r\n\r\nHow to deal with this ?\r\n\r\n\r\n", "comments": ["This seems counter-intuitive. I looked at the docs. Is it possible that the following explain this behavior and help you solve the problem?\r\n\r\n```\r\n    shared_name: (optional). If set, this queue will be shared under the given\r\n      name across multiple sessions. All sessions open to the device which has\r\n      this queue will be able to access it via the shared_name. Using this in\r\n      a distributed setting means each name will only be seen by one of the\r\n      sessions which has access to this operation.\r\n```\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/python/training/input.py#L199\r\n\r\n> N.B. Queue methods (such as q.enqueue(...)) must run on the same device as the queue. Incompatible device placement directives will be ignored when creating these operations.\r\n\r\nhttps://www.tensorflow.org/programmers_guide/threading_and_queues", "This issue is automatically closed due to lack of activity. Please re-open if this is still an issue for you. Thanks!"]}, {"number": 11368, "title": "Feature : Tensorflow works on ubuntu12.04", "body": "Hi,all:\r\nI have a computing cluster,with a master and some slaves. \r\nI want to tran the AI model on master, and then send to slaves for calculation\u3002\r\nBut\uff0cfor some reason, part of slaves works on ubuntu12.04, and i can not update them to 14.04. \r\nso, how can i get a lite tensorflow or a saved model lib, than can be restored on ubuntu12.04 slaves.\r\nMany thanks!", "comments": ["How about using docker?\r\nCan you get docker running on these machines?\r\n\r\nSince ubuntu 12.04 is quite old, and even canonical does not support the OS, and do not push the latest compiler/glibc updates on the machines it would be difficult for us to support this version of the operating system.\r\nSo I will have to decline this feature request.\r\n\r\nHowever, you can try building TF from sources on a machine or a docker container that has ubuntu 12.04, and if there are issues, we are happy to accept fixes into our repository."]}, {"number": 11367, "title": "saver will cause crash,error message:\"InvalidArgumentError: Shape [xx] has negative dimensions\"", "body": "### It should be a bug of tensorflow\r\nadd the saver will cause the procedure crash. error message is strange, as following:\r\n_### InvalidArgumentError (see above for traceback): Shape [-1,32,32,3] has negative dimensions\r\n\t [[Node: x = Placeholder[dtype=DT_FLOAT, shape=[?,32,32,3], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]_\r\n\r\nthe added part is:\r\n            if (i % 1000 == 0) or (i == num_iterations - 1):\r\n                # Save all variables of the TensorFlow graph to a\r\n                # checkpoint. Append the global_step counter\r\n                # to the filename so we save the last several checkpoints.\r\n                saver.save(sess,\r\n                           save_path=save_dir,\r\n                           global_step=train_step)\r\n\r\n### System information\r\n== cat /etc/issue ===============================================\r\nDarwin zhangdeMacBook-Pro.local 16.6.0 Darwin Kernel Version 16.6.0: Fri Apr 14 16:21:16 PDT 2017; root:xnu-3789.60.24~6/RELEASE_X86_64 x86_64\r\nMac OS X 10.12.5\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nApple LLVM version 8.1.0 (clang-802.0.42)\r\nTarget: x86_64-apple-darwin16.6.0\r\nThread model: posix\r\nInstalledDir: /Library/Developer/CommandLineTools/usr/bin\r\n\r\n== uname -a =====================================================\r\nDarwin zhangdeMacBook-Pro.local 16.6.0 Darwin Kernel Version 16.6.0: Fri Apr 14 16:21:16 PDT 2017; root:xnu-3789.60.24~6/RELEASE_X86_64 x86_64\r\n\r\n== check pips ===================================================\r\nnumpy (1.13.0)\r\nprotobuf (3.3.0)\r\ntensorflow (1.2.1)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.2.1\r\ntf.GIT_VERSION = v1.2.0-5-g435cdfc\r\ntf.COMPILER_VERSION = v1.2.0-5-g435cdfc\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\n\r\n== cuda libs  ===================================================\r\n\r\nTensorflow version:\r\nv1.2.0-5-g435cdfc 1.2.1\r\n\r\n\r\n\r\n\r\n### Source code / logs\r\nsource code:\r\n```python\r\n#coding=utf-8\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport cifar10\r\nimport preprocess\r\nfrom six.moves import xrange\r\nimport os\r\n\r\nimg_size = 32\r\nimg_height = img_size\r\nimg_width = img_size\r\nimg_channel = 3\r\n\r\nfirst_conv_feamap = 16\r\nfilter_size = 5\r\npool_size = 4\r\n\r\nsecond_conv_feamap = 32\r\n\r\nfcn1_size = 1024\r\n\r\nepoch = 60\r\nbatch_size = 50\r\n\r\n\r\ndef weight_variable(shape):\r\n    \"\"\"weight_variable generates a weight variable of a given shape.\"\"\"\r\n    initial = tf.truncated_normal(shape, stddev=0.1)\r\n    return tf.Variable(initial)\r\n\r\ndef bias_variable(shape):\r\n    initial = tf.constant(0.1,shape=shape)\r\n    return tf.Variable(initial)\r\n\r\ndef conv2d(x, W):\r\n  \"\"\"conv2d returns a 2d convolution layer with full stride.\"\"\"\r\n  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\r\n\r\ndef max_pool_2x2(x):\r\n  \"\"\"max_pool_2x2 downsamples a feature map by 2X.\"\"\"\r\n  #ksize\u662f\u7a97\u53e3\u5927\u5c0f\uff0cstride\u662f\u6b65\u957f\uff0c4->1\u6b65\u957f\u6b63\u597d\u662f2\r\n  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\r\n                        strides=[1, 2, 2, 1], padding='SAME')\r\n\r\n\r\ndef sequence_batch(images, labels, idx,_batch_size):\r\n\r\n    # Use the random index to select random images and labels.\r\n    x_batch = images[idx:idx+_batch_size, :, :, :]\r\n    y_batch = labels[idx:idx+_batch_size, :]\r\n\r\n    return x_batch, y_batch\r\n\r\n#Procedure start now!\r\n\r\nimages,training_class,labels = cifar10.load_training_data()\r\n\r\ntest_images,test_class,test_labels = cifar10.load_test_data()\r\n\r\n\r\nlog_dir = os.getcwd() + '/log'\r\nprint('log_dir is ' + log_dir)\r\nif not os.path.exists(log_dir):\r\n    os.makedirs(log_dir)\r\n\r\n\r\nsave_dir = os.getcwd() + '/checkpoints'\r\nprint('save_dir is ' + save_dir)\r\nif not os.path.exists(save_dir):\r\n    os.makedirs(save_dir)\r\n\r\n\r\nx = tf.placeholder(tf.float32, shape=[None,img_height,img_width,img_channel], name='x')\r\ny_ = tf.placeholder(tf.float32, shape=[None, 10], name='y_')\r\ny_cls = tf.argmax(y_, dimension=1)\r\n\r\nx = tf.reshape(x, shape=[-1, img_height, img_width, img_channel])\r\n\r\nwith tf.name_scope('conv1'):\r\n    w_conv1 = weight_variable([filter_size, filter_size, img_channel, first_conv_feamap])\r\n    b_conv1 = bias_variable([first_conv_feamap])\r\n\r\n    h_conv1 = tf.nn.relu(conv2d(x, w_conv1) + b_conv1)\r\n    h_pool1 = max_pool_2x2(h_conv1)\r\n\r\nwith tf.name_scope('conv2'):\r\n    w_conv2 = weight_variable([filter_size, filter_size, first_conv_feamap, second_conv_feamap])\r\n    b_conv2 = bias_variable([second_conv_feamap])\r\n\r\n    h_conv2 = tf.nn.relu(conv2d(h_pool1, w_conv2) + b_conv2)\r\n    h_pool2 = max_pool_2x2(h_conv2)\r\n\r\nconv2_size = 8\r\n\r\nwith tf.name_scope('fcn1'):\r\n    w_fcn1 = weight_variable([conv2_size * conv2_size * second_conv_feamap, fcn1_size])\r\n    b_fcn1 = bias_variable([fcn1_size])\r\n\r\n    # change with the image size and convlo\r\n    h_pool2_flat = tf.reshape(h_pool2, [-1, conv2_size * conv2_size * second_conv_feamap])\r\n    h_fcn1 = tf.nn.relu(tf.matmul(h_pool2_flat, w_fcn1) + b_fcn1)\r\n\r\n    keep_prob = tf.placeholder(tf.float32)\r\n    h_fcn1_drop = tf.nn.dropout(h_fcn1, keep_prob)\r\n\r\nwith tf.name_scope('fcn2'):\r\n    w_fcn2 = weight_variable([fcn1_size, 10])\r\n    b_fcn2 = bias_variable([10])\r\n\r\n    y_cnn = tf.matmul(h_fcn1_drop, w_fcn2) + b_fcn2\r\n\r\n\r\n\r\ncross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_,logits=y_cnn))\r\n\r\ntrain_step = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cross_entropy)\r\n\r\ncorrect_prediction = tf.equal(tf.arg_max(y_cnn,1),tf.arg_max(y_,1))\r\n\r\naccuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\r\n\r\n\r\n\r\nsaver = tf.train.Saver()\r\n\r\n\r\n\r\nwith tf.Session() as sess:\r\n    init = tf.global_variables_initializer()\r\n    sess.run(init)\r\n\r\n\r\n    num_iterations = int(len(images)/batch_size)\r\n\r\n    idx = 0\r\n\r\n    for j in xrange(60):\r\n        for i in xrange(num_iterations):\r\n\r\n\r\n            x_batch,y_batch = sequence_batch(images,labels,idx,batch_size)\r\n\r\n            print(\"x_batch shape: \" + str(x_batch.shape))\r\n            print(\"y_batch shape: \" + str(y_batch.shape))\r\n\r\n            train_step.run(\r\n                feed_dict={\r\n                    x: x_batch,\r\n                    y_: y_batch,\r\n                    keep_prob: 0.5\r\n                }\r\n            )\r\n\r\n            idx = idx + batch_size\r\n\r\n            if i%100 == 0:\r\n                training_feed_dict = {\r\n                    x: images,\r\n                    y_: labels,\r\n                    keep_prob: 1.0\r\n                }\r\n\r\n                test_feed_dict = {\r\n                    x: test_images,\r\n                    y_: test_labels,\r\n                    keep_prob: 1.0\r\n                }\r\n\r\n\r\n\r\n                train_accuracy = accuracy.eval(\r\n                    feed_dict=training_feed_dict\r\n                )\r\n                print('step %d, training accuracy %g' % (i, train_accuracy))\r\n\r\n                test_accuracy = accuracy.eval(\r\n                    feed_dict=test_feed_dict\r\n                )\r\n                print('step %d, test accuracy %g' % (i, test_accuracy))\r\n\r\n            if (i % 1000 == 0) or (i == num_iterations - 1):\r\n                # Save all variables of the TensorFlow graph to a\r\n                # checkpoint. Append the global_step counter\r\n                # to the filename so we save the last several checkpoints.\r\n                saver.save(sess,\r\n                           save_path=save_dir,\r\n                           global_step=train_step)\r\n\r\n                print(\"Saved checkpoint.\")\r\n\r\n\r\n    print('test accuracy in every epoch %g' % accuracy.eval(\r\n        feed_dict={\r\n            x: test_images,\r\n            y_: test_labels,\r\n            keep_prob: 1.0\r\n        }\r\n        )\r\n    )\r\n\r\n```\r\n\r\n\r\n\r\n\r\n", "comments": ["Now i found the cause. If I remove the global_step=train_step when saving the saver, error will disappear. \r\nSo the reason should be train_step been wrongly run without feed_dict. It easily mislead developer wasting a lot of time checking the data-loading process.\r\nNow I closed it. But i think this message of the issue is still useful to other developers.", "I got the same error when i use this code `summary,test_accuracy = sess.run([merged, accuracy], feed_dict={x: test_data, y: test_labels, input_seq_len: test_seq_len, keep_prob: 1})`\r\n\r\n Info\r\n- OS: Ubuntu 16.04LTS\r\n- TF version : Release 1.2.1 \r\n- Python: 3.5.3\r\n\r\nSource code & error log\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib import rnn\r\nimport numpy as np\r\nimport random\r\n\r\n#==========\r\n# Data Set\r\n#==========\r\nclass HandriseData(object):\r\n    \"\"\"\r\n    Load train-set and test-set from csv file\r\n    \"\"\"\r\n    def __init__(self):\r\n        self.data = []\r\n        self.labels = []\r\n        self.seq_len = []\r\n\r\n        self.test_data = []\r\n        self.test_labels = []\r\n        self.test_seq_len = []\r\n        \r\n        with open(\"./dataset/train/train.csv\", 'r', newline=\"\") as csv_file:\r\n            train_sets = [np.array(line.split(\",\"), np.float).tolist() for line in csv_file]\r\n\r\n            for i in range(0, len(train_sets), 3):\r\n                tmp_len = len(train_sets[i])\r\n                self.seq_len.append(tmp_len)\r\n\r\n                train_sets[i].extend([0 for j in range(0, 80 - tmp_len)])\r\n                train_sets[i + 1].extend([0 for j in range(0, 80 - tmp_len)])\r\n                train_sets[i + 2].extend([0 for j in range(0, 80 - tmp_len)])\r\n                self.data.append(np.array(train_sets[i : i + 3]).flatten())\r\n                \r\n            self.labels = np.loadtxt(\"./dataset/train/train.label.csv\", dtype = np.int).tolist()\r\n\r\n    def next(self, batch_size = 100):\r\n        \"\"\"\r\n        input: batch_size\r\n        output: (x_batch, y_batch, seq_len)\r\n        \"\"\"\r\n        if batch_size <= 0:\r\n            return;\r\n        \r\n        x_batch = []\r\n        y_batch = []\r\n        #real length\r\n        seq_len = []\r\n        \r\n        rand_list = random.sample(range(0, len(self.data)), batch_size)\r\n        for j in rand_list:\r\n            x_batch.append(self.data[j])\r\n            y_batch.append(self.labels[j])\r\n            seq_len.append(self.seq_len[j])\r\n            \r\n        return (x_batch, y_batch, seq_len)\r\n    \r\n    def get_test_set(self):\r\n        \"\"\"\r\n        Get test set\r\n        \"\"\"\r\n        with open(\"./dataset/test/test.csv\", 'r', newline=\"\") as csv_file:\r\n            test_sets = [np.array(line.split(\",\"), np.float).tolist() for line in csv_file]\r\n\r\n            for i in range(0, len(test_sets), 3):\r\n                tmp_len = len(test_sets[i])\r\n                self.test_seq_len.append(tmp_len)\r\n\r\n                test_sets[i].extend([0 for j in range(0, 80 - tmp_len)])\r\n                test_sets[i + 1].extend([0 for j in range(0, 80 - tmp_len)])\r\n                test_sets[i + 2].extend([0 for j in range(0, 80 - tmp_len)])\r\n                self.test_data.append(np.array(test_sets[i : i + 3]).flatten())\r\n                \r\n            self.test_labels = np.loadtxt(\"./dataset/test/test.label.csv\", dtype = np.int).tolist()\r\n        return (self.test_data, self.test_labels, self.test_seq_len)\r\n#==========\r\n# MODEL\r\n#==========\r\n\r\n#Parameter\r\ntraining_iters = 1001\r\nbatch_size = 100\r\nlearning_rate = 0.01\r\n\r\nn_steps = 80 #max steps\r\nn_input = 3 #input\r\nn_hidden_unis = 128 #hidden neurons\r\nn_class = 2 #label (0,1)\r\n\r\n\r\n#Graph input\r\nx = tf.placeholder(tf.float32, [None, n_steps, n_input], name=\"x_input\") #input \r\ny = tf.placeholder(tf.int32, [None], name=\"y_label\") #real label\r\ny_ = tf.one_hot(y, 2) #one hot vector\r\ninput_seq_len = tf.placeholder(tf.int32, [None], name=\"input_seq_len\")\r\nkeep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\r\n\r\n#define weight\r\nweights = {\r\n    #(n_input,n_hidden_unis)\r\n    'in': tf.Variable(tf.random_normal([n_input, n_hidden_unis],stddev=0.1)),\r\n    #(n_hidden_unis,n_class)\r\n    'out': tf.Variable(tf.random_normal([n_hidden_unis, n_class],stddev=0.1))\r\n}\r\n#define bias\r\nbiases = {\r\n    #(n_hidden_unis, )\r\n    'in': tf.Variable(tf.constant(0.1, shape=[n_hidden_unis, ])),\r\n    #(n_class, )\r\n    'out': tf.Variable(tf.constant(0.1, shape=[n_class, ]))\r\n}\r\n\r\n#Define RNN(LSTM) neuron networks\r\ndef LSTM_RNN(x, weights, biases, seq_len, keep_prob = 1, activation_function = tf.nn.softmax):\r\n    #hidden layer for input to cell\r\n    #==> (batch_size * n_steps, n_input)\r\n    x = tf.reshape(x, [-1, n_input])\r\n    #==>(batch_size * n_steps, n_hidden_unis)\r\n    x_in = tf.matmul(x, weights['in']) + biases['in']\r\n    #==>(batch_size, n_steps, n_hidden_unis)\r\n    x_in = tf.reshape(x_in, [-1, n_steps, n_hidden_unis])\r\n\r\n    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden_unis, forget_bias=1.0, state_is_tuple=True, reuse=True)\r\n    _init_state = lstm_cell.zero_state(batch_size, dtype = tf.float32)\r\n\r\n    outputs, states = tf.nn.dynamic_rnn(lstm_cell, x_in, time_major=False, sequence_length=seq_len, dtype=tf.float32)\r\n\r\n    Wx_plus_b = tf.matmul(states[1], weights['out'] + biases['out'])\r\n    \r\n    output = activation_function(Wx_plus_b)\r\n    \r\n    output = tf.nn.dropout(output, keep_prob)\r\n    return output\r\n\r\n#==========\r\n# TRAIN\r\n#==========\r\ndef train():\r\n    pred = LSTM_RNN(x, weights, biases, input_seq_len, keep_prob, tf.nn.softmax)\r\n    tf.summary.histogram('out',pred)\r\n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y_))\r\n    tf.summary.scalar('loss', cost) \r\n    \r\n    train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\r\n    \r\n    correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y_,1))\r\n    pred_output = tf.cast(correct_pred, tf.int32, name=\"pred_output\")\r\n    \r\n    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\r\n    \r\n    merged = tf.summary.merge_all()\r\n    init = tf.global_variables_initializer()\r\n    \r\n    saver = tf.train.Saver(max_to_keep=5)\r\n    with tf.Session() as sess:\r\n\r\n        file_writer = tf.summary.FileWriter('./tensorboard', sess.graph)\r\n        \r\n        sess.run(init)\r\n        train_accuracys = []\r\n        test_accuracys = []\r\n        \r\n        hand_rise = HandriseData()\r\n       \r\n        test_data, test_labels, test_seq_len = hand_rise.get_test_set()\r\n        test_data = np.array(test_data).reshape([-1, n_steps, n_input])\r\n        \r\n        for step in range(1, training_iters):\r\n            x_batch, y_batch, seq_len = hand_rise.next(batch_size)\r\n            x_batch = np.array(x_batch).reshape([-1, n_steps, n_input])\r\n            \r\n            if step % 100 == 0:\r\n                train_accuracy = sess.run(accuracy, feed_dict={x: x_batch, y: y_batch, input_seq_len: seq_len, keep_prob: 1})\r\n                train_accuracys.append(train_accuracy)\r\n                \r\n                summary,test_accuracy = sess.run([merged,accuracy], feed_dict={x: test_data, y: test_labels, input_seq_len: test_seq_len, keep_prob: 1})\r\n                test_accuracys.append(test_accuracy)\r\n                \r\n                file_writer.add_summary(summary, step)\r\n                \r\n                print(\"step:\" + str(step) + \",accuracy:\" + str(train_accuracy))\r\n                \r\n            else:\r\n                sess.run(train_op, feed_dict={x: x_batch, y: y_batch, input_seq_len: seq_len, keep_prob: 0.5})\r\n                \r\n        file_writer.close()       \r\n        print(\"Final test accuracy is \" + str(test_accuracys[-1]))\r\n        \r\n        #save checkpoint file\r\n        saver.save(sess, 'model/model.ckpt', global_step=step)\r\n        #save pb file\r\n        output_graph_def = tf.graph_util.convert_variables_to_constants(sess, sess.graph_def, output_node_names=['pred_output'])\r\n        with tf.gfile.FastGFile(\"model/handrise.pb\", mode = 'wb') as f:\r\n            f.write(output_graph_def.SerializeToString())\r\n```\r\nerror\r\n```\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1138     try:\r\n-> 1139       return fn(*args)\r\n   1140     except errors.OpError as e:\r\n\r\n/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)\r\n   1120                                  feed_dict, fetch_list, target_list,\r\n-> 1121                                  status, run_metadata)\r\n   1122 \r\n\r\n/home/ksq/anaconda3/lib/python3.5/contextlib.py in __exit__(self, type, value, traceback)\r\n     65             try:\r\n---> 66                 next(self.gen)\r\n     67             except StopIteration:\r\n\r\n/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py in raise_exception_on_not_ok_status()\r\n    465           compat.as_text(pywrap_tensorflow.TF_Message(status)),\r\n--> 466           pywrap_tensorflow.TF_GetCode(status))\r\n    467   finally:\r\n\r\nInvalidArgumentError: Shape [-1,80,3] has negative dimensions\r\n\t [[Node: x_input_1 = Placeholder[dtype=DT_FLOAT, shape=[?,80,3], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-7-a64368429fdf> in <module>()\r\n    223     plt.show()\r\n    224 \r\n--> 225 train()\r\n\r\n<ipython-input-7-a64368429fdf> in train()\r\n    186                 train_accuracys.append(train_accuracy)\r\n    187 \r\n--> 188                 summary,test_accuracy = sess.run([merged,accuracy], feed_dict={x: test_data, y: test_labels, input_seq_len: test_seq_len, keep_prob: 1})\r\n    189                 test_accuracys.append(test_accuracy)\r\n    190 \r\n\r\n/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    787     try:\r\n    788       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 789                          run_metadata_ptr)\r\n    790       if run_metadata:\r\n    791         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n    995     if final_fetches or final_targets:\r\n    996       results = self._do_run(handle, final_targets, final_fetches,\r\n--> 997                              feed_dict_string, options, run_metadata)\r\n    998     else:\r\n    999       results = []\r\n\r\n/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1130     if handle is None:\r\n   1131       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\r\n-> 1132                            target_list, options, run_metadata)\r\n   1133     else:\r\n   1134       return self._do_call(_prun_fn, self._session, handle, feed_dict,\r\n\r\n/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1150         except KeyError:\r\n   1151           pass\r\n-> 1152       raise type(e)(node_def, op, message)\r\n   1153 \r\n   1154   def _extend_graph(self):\r\n\r\nInvalidArgumentError: Shape [-1,80,3] has negative dimensions\r\n\t [[Node: x_input_1 = Placeholder[dtype=DT_FLOAT, shape=[?,80,3], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\nCaused by op 'x_input_1', defined at:\r\n  File \"/home/ksq/anaconda3/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/home/ksq/anaconda3/lib/python3.5/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\r\n    app.launch_new_instance()\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\r\n    app.start()\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\r\n    ioloop.IOLoop.instance().start()\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\r\n    super(ZMQIOLoop, self).start()\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\r\n    handler_func(fd_obj, events)\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\r\n    self._handle_recv()\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\r\n    self._run_callback(callback, msg)\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\r\n    callback(*args, **kwargs)\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\r\n    return self.dispatch_shell(stream, msg)\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\r\n    handler(stream, idents, msg)\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\r\n    user_expressions, allow_stdin)\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\r\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\r\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\r\n    if self.run_code(code, result):\r\n  File \"/home/ksq/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-2-55a42d5b2ae9>\", line 104, in <module>\r\n    x = tf.placeholder(tf.float32, [None, n_steps, n_input], name=\"x_input\") #input\r\n  File \"/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1530, in placeholder\r\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\r\n  File \"/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1954, in _placeholder\r\n    name=name)\r\n  File \"/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n  File \"/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/home/ksq/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): Shape [-1,80,3] has negative dimensions\r\n\t [[Node: x_input_1 = Placeholder[dtype=DT_FLOAT, shape=[?,80,3], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\n```", "I find what caused the error,  I delete this line `_init_state = lstm_cell.zero_state(batch_size, dtype = tf.float32)` in `LSTM_RNN()` function of source. and running successfully."]}, {"number": 11366, "title": "Problems with AOT-Compiled Inception V3 model (runtime crash / nonsense output)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X 10.12.5\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: ('v1.2.0-rc2-21-g12f033d', '1.2.0')\r\n- **Python version**: 2.7.13\r\n- **Bazel version (if compiling from source)**: bazel release 0.5.1-homebrew\r\n- **CUDA/cuDNN version**: n/a (CPU only build)\r\n- **GPU model and memory**: n/a\r\n- **Exact command to reproduce**: See description below.\r\n\r\n### Describe the problem\r\nI've successfully built the AOT compiler and all its tests pass fine. I'm trying to do the analogous thing as in the matmul example to build an AOT-compiled library for a frozen Inception V3 graph: specifically, `inception_v3_2016_08_28_frozen.pb`, which I hope to incorporate into my larger C++ project.\r\n\r\nThe bazel build goes fine, and I get a (large) library and header file. I can successfully compile and link that into my larger project. When I `Run()` it, however, I get a `EXC_BAD_ACCESS` on this line of disassembly:\r\n```\r\n0x10143f55f <+143>: movq   (%rax), %rax\r\n```\r\nwith this stack trace from a call to `Run()`:\r\n```\r\n#0\t0x000000010143f55f in Eigen::TensorEvaluator<Eigen::TensorContractionOp<Eigen::array<Eigen::IndexPair<long long>, 1ul> const, Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>::Context<Eigen::internal::gemm_pack_lhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0, Eigen::MakePointer>, 8, 4, 0, false, false>, Eigen::internal::gemm_pack_rhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0, Eigen::MakePointer>, 4, 0, false, false>, Eigen::internal::gebp_kernel<float, float, long, Eigen::internal::blas_data_mapper<float, long, 0, 0>, 8, 4, false, false>, Eigen::internal::TensorContractionInputMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0, Eigen::MakePointer>, Eigen::internal::blas_data_mapper<float, long, 0, 0> >::enqueue_packing_helper(long, long, long, bool) ()\r\n#7\t0x00000001012ff70b in __tensorflow_aot_test__aot_test ()\r\n```\r\n\r\nFurthermore, when I write my own simple binary, separate from my larger project, along the lines of the matmul test example for AOT, I can build and run it without the above crash, but no matter what input I feed in, I get the same output: the 1001-element results vector is all zeros except entry 429, which is exactly 1.0. My guess was that the image data I'm feeding in was somehow garbage, but I've verified (?) that I can read in the same binary blob of pre-processed image data in Matlab and it looks reasonable. (Pre-processing here includes resizing the image to the required size (299x299), dividing each element by 255, and storing as floats.)\r\n\r\nIs something going wrong in AOT-compiling the graph here, or am I doing something wrong or missing something totally stupid? Is there something used in the Inception architecture that's not supported? Should I be trying with another frozen graph? Note that I'm on the `r1.2` branch, but may try switching to master next to see if it's something that's been changed/fixed since `r1.2`. See below for source. \r\n\r\n### Source code / logs\r\n\r\n`BUILD` file for my `aot_test` library and a simple binary to run it:\r\n```\r\nload(\"//tensorflow/compiler/aot:tfcompile.bzl\", \"tf_library\")\r\n\r\ntf_library(\r\n    name = \"aot_test\",\r\n    cpp_class = \"TF_TestAOT\",\r\n    graph = \"inception_v3_2016_08_28_frozen.pb\",\r\n    config = \"aot_test.config.pbtxt\",\r\n)\r\n\r\ncc_binary(\r\n    name = \"my_binary\",\r\n    srcs = [\r\n        \"my_binary.cc\", \r\n    ],\r\n    deps = [\r\n        \":aot_test\",  \r\n        \"//third_party/eigen3\",\r\n    ],\r\n    # I've tried with or without this\r\n    #linkopts = [\r\n    #      \"-lpthread\",\r\n    #]\r\n)\r\n```\r\n\r\nContents of `aot_test.config.pbtxt` referenced above:\r\n```\r\nfeed {\r\n  id { node_name: \"input\" }\r\n  shape {\r\n    dim { size: 1   }\r\n    dim { size: 299 }\r\n    dim { size: 299 }\r\n    dim { size: 3   }\r\n  }\r\n}\r\n\r\nfetch {\r\n  id { node_name: \"InceptionV3/Predictions/Reshape_1\" }\r\n}\r\n```\r\n\r\nContents of `my_binary.cc` referenced above:\r\n```\r\n#define EIGEN_USE_THREADS\r\n#define EIGEN_USE_CUSTOM_THREAD_POOL\r\n\r\n#include <cstdlib>\r\n#include <iostream>\r\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\r\n#include \"tensorflow/aot_test/aot_test.h\" // generated\r\n\r\nint main(int argc, char** argv) {\r\n  Eigen::ThreadPool tp(1);  // Size the thread pool as appropriate. (I've tried various options here)\r\n  Eigen::ThreadPoolDevice device(&tp, tp.NumThreads());\r\n\r\n  TF_TestAOT test;\r\n  test.set_thread_pool(&device);\r\n\r\n  // Set up args and run the computation. \r\n  // Printing out the data shows it is valid. I've also tried random input data and multiple images.\r\n  FILE* file = fopen(\"/tmp/img_norm.bin\", \"rb\");\r\n  const size_t n = fread(test.arg0_data(), sizeof(float), 299*299*3, file); \r\n  fclose(file);\r\n  std::cout << \"Read \" << n << \" floats\" << std::endl;\r\n  \r\n  test.Run();\r\n\r\n  std::cout << \"Status: \" << test.error_msg() << std::endl;\r\n  \r\n  // Check result\r\n  const float* output_data = test.result0_data();\r\n  float maxScore = -1.f;\r\n  int maxIndex = -1;\r\n  for(int i=0; i<1001; ++i)\r\n  {\r\n     // If I print this, i'll see all zeros except entry 429, which is one\r\n    //std::cout << \"Score[\" << i << \"]=\" << output_data[i] << std::endl;\r\n    if(output_data[i] > maxScore)\r\n    {\r\n      maxScore = output_data[i];\r\n      maxIndex = i;\r\n    }\r\n  }\r\n\r\n  std::cout << \"Max score = \" << maxScore << \" at index \" << maxIndex << std::endl;\r\n\r\n  return 0;\r\n}\r\n```\r\n\r\n", "comments": ["One other note (since I mentioned I'm on `r1.2`): I did add this `target_llvm_triple()` definition to `tfcompile.bzl` as well, having found that in another issue about using AOT on OSX (which appears to have since been merged to master): `x86_64-none-darwin`", "@tatatodd, do you have any thoughts?", "Update: I rebuilt from master (pulled this morning) and sent in the same two images I was testing with. It seems to be reporting reasonable results now using my standalone binary. So either I was doing something wrong on my r1.2 branch or the root cause has been fixed.\r\n\r\n_However_, I'm still getting the `BAD ACCESS` crash when linking into my larger project, so any suggestions there would be much appreciated. I assume you'd need more information about the project to help diagnose what the issue is (threading related perhaps?), but I'm not sure what's most helpful to provide. In the mean time, I'm still investigating...", "Also note that my \"larger project\" is being built with Xcode. I'm adding all the flags and `force_loads` I see when running bazel with `-s` to my build settings in Xcode, but still no luck.\r\n```\r\nbazel-out/darwin_x86_64-opt/bin/tensorflow/aot_test/libaot_test.a \r\n-Wl,-force_load,bazel-out/darwin_x86_64-opt/bin/tensorflow/compiler/tf2xla/kernels/libgather_op_kernel_float_int32.lo \r\n-Wl,-force_load,bazel-out/darwin_x86_64-opt/bin/tensorflow/compiler/tf2xla/kernels/libgather_op_kernel_float_int64.lo \r\n-Wl,-force_load,bazel-out/darwin_x86_64-opt/bin/tensorflow/core/kernels/libgather_functor.lo \r\n-Wl,-force_load,bazel-out/darwin_x86_64-opt/bin/tensorflow/compiler/tf2xla/kernels/libindex_ops_kernel_argmax_float_1d.lo \r\n-Wl,-force_load,bazel-out/darwin_x86_64-opt/bin/tensorflow/compiler/tf2xla/kernels/libindex_ops_kernel_argmax_float_2d.lo \r\nbazel-out/darwin_x86_64-opt/bin/tensorflow/compiler/aot/libruntime.a \r\nbazel-out/darwin_x86_64-opt/bin/tensorflow/compiler/xla/service/cpu/libruntime_conv2d.a \r\nbazel-out/darwin_x86_64-opt/bin/tensorflow/compiler/xla/service/cpu/libruntime_matmul.a \r\nbazel-out/darwin_x86_64-opt/bin/tensorflow/compiler/xla/service/cpu/libruntime_single_threaded_conv2d.a \r\nbazel-out/darwin_x86_64-opt/bin/tensorflow/compiler/xla/service/cpu/libruntime_single_threaded_matmul.a \r\nbazel-out/darwin_x86_64-opt/bin/tensorflow/compiler/xla/libexecutable_run_options.a \r\n-undefined dynamic_lookup \r\n-headerpad_max_install_names \r\n-no-canonical-prefixes\r\n```", "Hi  @andrew-anki , I'm making the practice of compiling inception model into binary file with XLA aot, could you sends me your testing image (img_norm.bin)?\r\nThanks", "Hi, @andrew-anki, I try it following your instruction and code,  use it to recognize a tabby cat picture, however the result of classification is incorrect. So do you have solve this problem? ", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 11365, "title": "seq2seq.AttentionWrapper cannot implement Bahdanau model (RNNsearch)", "body": "\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, but there is no stock example script\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OSX 10.12.5\r\n- **TensorFlow installed from (source or binary)**: source (via virtualenv/pip3)\r\n- **TensorFlow version (use command below)**:v1.2.0-5-g435cdfc 1.2.1\r\n- **Python version**: 3.6.1\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:  N/A\r\n\r\n### Describe the problem\r\n[RNNsearch](https://arxiv.org/pdf/1409.0473.pdf) has two different RNN cells in it (the encoder and decoder). At a given time step, the inputs to the attention mechanism are all the encoder's outputs (the \"annotations\" in the Bahdanau paper, aka the `memory` of the `BahdanauAttention` constructor) and the decoder's previous state.\r\n\r\nCrucially, `AttentionWrapper.call` is running its input through the passed in `cell` before applying `AttentionMechanism` to the cell's output. ([Docstring](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/AttentionWrapper#call); source confirms this.)\r\n\r\nThis precludes the encoder cell from being passed to AttentionWrapper, because AttentionWrapper depends on BahdanauAttention, whose `memory` depends on the encoder cell's output. (So you would need to run the encoder once to get the `memory` and `AttentionWrapper` would run it again.)\r\n\r\nBut the decoder cell can also not be the cell passed in, because in the Bahdanau paper, the decoder's output is not used by the attention mechanism at all. Moreover, neither cell takes the previous step's attention (in Bahdanau).\r\n\r\nI'm hoping I've misunderstood, but currently the API doesn't seem like it can be made to align with the paper, which would be sort of curious \u2013 but perhaps intentional!\r\n\r\n### Source code / logs\r\n    bahdanau = tf.contrib.seq2seq.BahdanauAttention(\r\n        num_units=params['ATTENTION_SIZE'],\r\n        memory=annotations,  # annotations, _ = tf.nn.static_rnn(encoder, time_major_input)\r\n        normalize=False,\r\n        name='BahdanauAttention')\r\n    decoder = tf.nn.rnn_cell.BasicLSTMCell(\r\n        params['DECODER_SIZE'],\r\n        forget_bias=1.0)\r\n    attn_cell = tf.contrib.seq2seq.AttentionWrapper(\r\n        cell=decoder,\r\n        attention_mechanism=bahdanau,\r\n        output_attention=False,\r\n        name=\"AttentionWrappedDecoder\")\r\n", "comments": ["@ebrevdo I'm noticing you've worked on seq2seq recently. Here's a well-communicated issue for you.", "You're meant to wrap the decoder cell in the AttentionWrapper.  The previous attention is passed via the *state* of the AttentionWrapper if you set the argument `output_attention=False` ([here](https://github.com/tensorflow/tensorflow/blob/afa03e2fd91a2d4a7dc960c5ec4ee448c808d026/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py#L994)).  In practice we haven't seen too much of a difference when training if using one or the other.", "My training results have not shown the difference to be that big either, but the edge cases worried me.\r\n\r\nThe difference at the first step (step1) of decoding is between:\r\n```\r\nstate1 = cell((context1=attn(state0)), state0) # RNNSearch\r\ncontext1 = attn((state1 = cell(context0, state0))) # AttentionWrapper\r\n```\r\n(assuming, as in GRU cells, that states and outputs are the same)\r\n\r\nOn further inspection, the two turn out to be the same if I provide the initial state for AttentionWrapper as:\r\n```\r\nAttentionWrapperState(\r\n    attention=attn(_cell.zero_state()) # score with bahdanau and calculate context from alignments\r\n    cell_state=_cell.zero_state())\r\n```\r\nLeaving the note for posterity. Thanks for the clarification!"]}, {"number": 11364, "title": "Error on tf.contrib.training.stratified_sample", "body": "I made a small example to illustrate, which makes some synthetic data with unbalanced classes and tries to take balanced samples from it:\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.python.framework import ops\r\nfrom tensorflow.python.framework import dtypes\r\n\r\nbatch_size = 10\r\ndata = ['a']*9990+['b']*10\r\nlabels = [1]*9990+[0]*10\r\ndata_tensor = ops.convert_to_tensor(data, dtype=dtypes.string)\r\nlabel_tensor = ops.convert_to_tensor(labels)\r\ntarget_probs = [0.5,0.5]\r\ndata_batch, label_batch = tf.contrib.training.stratified_sample(\r\n    data_tensor, label_tensor, target_probs, batch_size,\r\n    queue_capacity=2*batch_size)\r\n\r\nwith tf.Session() as sess:\r\n    d,l = sess.run(data_batch,label_batch)\r\nprint('percentage \"a\" = %.3f' % (np.sum(l)/len(l)))\r\n```\r\n\r\nThis gives the error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/jason/code/scrap.py\", line 59, in <module>\r\n    test_stratified_sample()\r\n  File \"/home/jason/code/scrap.py\", line 50, in test_stratified_sample\r\n    label_tensor, target_probs, batch_size, queue_capacity=2*batch_size)\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/training/python/training/sampling_ops.py\", line 191, in stratified_sample\r\n    with ops.name_scope(name, 'stratified_sample', tensors + [labels]):\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/math_ops.py\", line 829, in binary_op_wrapper\r\n    y = ops.convert_to_tensor(y, dtype=x.dtype.base_dtype, name=\"y\")\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 676, in convert_to_tensor\r\n    as_ref=False)\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 741, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/constant_op.py\", line 113, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/constant_op.py\", line 102, in constant\r\n    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/tensor_util.py\", line 374, in make_tensor_proto\r\n    _AssertCompatible(values, dtype)\r\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/tensor_util.py\", line 302, in _AssertCompatible\r\n    (dtype.name, repr(mismatch), type(mismatch).__name__))\r\nTypeError: Expected string, got list containing Tensors of type '_Message' instead.\r\n```\r\n\r\nAll the searching I did on this TypeError message returned legitimate bugs, not user errors, so I'm putting this here. For completeness:\r\n`python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` gives ('v1.2.0-0-g12f033d', '1.2.0')", "comments": ["It looks to me like stratified_sample takes a list of tensors, not a single tensor for the \"tensors\" argument. \r\nI tried editing the call from stratified_sample(data_tensor,...) to stratified_sample([data_tensor],...), and things got farther but still failed with a shape mismatch error. \r\n\r\nSo, a couple of thoughts: first, do you have a known-working example of stratified_sample that you're starting from? \r\n\r\nSecond, for the shape mismatch that I'm getting after the list fix: \r\nValueError: Shapes must be equal rank, but are 1 and 2 for 'stratified_sample/AssignAdd' (op: 'AssignAdd') with input shapes: [2], [10000,2].\r\nis it possible that target_probs is being passed in with the wrong shape? ", "1. I don't have a known working example, either from myself or anywhere else on the net. Nothing came up when I searched for one. Hence, I started by trying to make the simplest example I could before I try to use this in an actual project (at which point the data tensor would be filenames to be loaded further on in the input pipeline).\r\n\r\n2. From the documentation: `target_probs: Target class proportions in batch. An object whose type has a registered Tensor conversion function` so I believe a list of the same length as the number of classes should work. I can't think of what else would be suitable, given the purpose of the function.", "@joel-shor, might you be able to point @jrbtaylor at a publicly visible working example code? It'd help a bunch if we could use stratified_sample as intended. ", "I got an answer on [stackoverflow](https://stackoverflow.com/questions/44978255/tensorflow-stratified-sample-error). Both use cases (batch and single example inputs) are covered. I'd suggest improving the documentation accordingly.", "Sorry for the delay.\r\n\r\nI've improved the documentation, and improved the error message for non-iterable input. Please reopen if this is still an issue."]}, {"number": 11363, "title": "tf.parse_single_example parses labels incorrectly", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, but only slightly--I'm using the Inception v3 framework but made some minor modifications to the inception_eval.py code (none around the image processing script)\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux 16.04\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: 1.1.0\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: 0.5.1\r\n- **CUDA/cuDNN version**: 8.0.61\r\n- **GPU model and memory**: Cirrus Logic GD 5446, 16GB\r\n- **Exact command to reproduce**: bazel-bin/inception/imagenet_eval --checkpoint_dir=$HOME/train --eval_dir=$HOME/eval\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\n\r\nThe parse_single_example function in parsing_ops.py seems to be incorrectly parsing encoded protobufs written into a TFRecord. Specifically, I have been trying to classify images into categories labelled \"1\", \"2\", \"3\", and \"4\". Up until the point in my neural network where the images and associated label are turned into a protobuf serialized image, the labels associated with the images are correct--tf.train.Feature successfully turns each label into an associated integer consistently matching the label. However, after being serialized and then written to a TFRecord and compressed, and then decoded through tf.parse_single_example, the label for each image becomes some random integer between 1 and 9 and no longer matches the label number, with no discernable pattern.\r\n\r\nI've traced the issue through the Inception code, and this problem is not happening in Inception--the bug is somewhere between my images are converted from a jpeg with labels to a serialized protobuf through tf.train.Example(features=tf.train.Features(features)) and when the protobuf is decoded through tf.parse_single_example. The label in outputs created by outputs = _parse_single_example_raw within tf.parse_single_example is already incorrect, and the int64 object for each label, created by passing label values into tf.train.Feature(int64_list=tf.train.Int64List(value=label)), that is passed into tf.train.Example(features=tf.train.Features(features)) to create the serialized protobuf that is parsed by tf.parse_single_example still correctly matches the original labels. Therefore, the problem must be happening somewhere between the serialization and the parsing, both of which occur within tensorflow.\r\n\r\nEDIT/UPDATE: Upon further examination, the bug seems to occur in some combination of when the image is serialized and when it is written to a TFRecord. I used protoc to manually compile example.proto and used that to manually parse parse the protobufs created by calling tf.train.Example on a Features tensor and encoding them with the SerializeToString method of the example.proto, and while the image/class/text and filename seemed to be correct, the label was missing. After the encoded protobufs are written to a TFRecord, compressed, and then parsed from the TFRecord through, tf.parse_single_example, and they are incorrect--the image/class/label seems to be missing, the image/class/text is no longer correct either, even though it was correct before being passed in, and the beginning of the protobuf has some really wonky encoding going on that example.proto's ParseFromString doesn't seem to be able to read and convert into a string. Additionally, I tried decoding the protobufs parsed from the TFRecord with tf.parse_single_example from latin1 manually, and the labels were still incorrect and matched the incorrect labels from using example.proto's ParseFromString, indicating that the problem isn't happening in the decoding. The parsed protobufs created by image_processing.py have been attached below. \r\n\r\nFURTHER EDIT: Issue has been updated to reflect new information\r\n\r\n### Source code / logs\r\n\r\nThe relevant inception code that calls the aformentioned tensorflow functions is shown below:\r\n\r\n**For serializing images+labels into a protobuf**:\r\n\r\n```\r\ndef _convert_to_example(filename, image_buffer, label, text, height, width):\r\n  \"\"\"Build an Example proto for an example.\r\n\r\n  Args:\r\n    filename: string, path to an image file, e.g., '/path/to/example.JPG'\r\n    image_buffer: string, JPEG encoding of RGB image\r\n    label: integer, identifier for the ground truth for the network\r\n    text: string, unique human-readable, e.g. 'dog'\r\n    height: integer, image height in pixels\r\n    width: integer, image width in pixels\r\n  Returns:\r\n    Example proto\r\n  \"\"\"\r\n\r\n  colorspace = 'RGB'\r\n  channels = 3\r\n  image_format = 'JPEG'\r\n\r\n  example = tf.train.Example(features=tf.train.Features(feature={\r\n      'image/height': _int64_feature(height),\r\n      'image/width': _int64_feature(width),\r\n      'image/colorspace': _bytes_feature(tf.compat.as_bytes(colorspace)),\r\n      'image/channels': _int64_feature(channels),\r\n      'image/class/label': _int64_feature(label),\r\n      'image/class/text': _bytes_feature(tf.compat.as_bytes(text)),\r\n      'image/format': _bytes_feature(tf.compat.as_bytes(image_format)),\r\n      'image/filename': _bytes_feature(tf.compat.as_bytes(os.path.basename(filename))),\r\n      'image/encoded': _bytes_feature(tf.compat.as_bytes(image_buffer))}))\r\n  return example\r\n```\r\n\r\n```\r\ndef _int64_feature(value):\r\n  \"\"\"Wrapper for inserting int64 features into Example proto.\"\"\"\r\n  if not isinstance(value, list):\r\n    value = [value]\r\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\r\n```\r\n\r\n**For parsing a protobuf**\r\n```\r\n\r\ndef parse_example_proto(example_serialized):\r\n  \"\"\"Parses an Example proto containing a training example of an image.\r\n\r\n  The output of the build_image_data.py image preprocessing script is a dataset\r\n  containing serialized Example protocol buffers. Each Example proto contains\r\n  the following fields:\r\n\r\n    image/height: 462\r\n    image/width: 581\r\n    image/colorspace: 'RGB'\r\n    image/channels: 3\r\n    image/class/label: 615\r\n    image/class/synset: 'n03623198'\r\n    image/class/text: 'knee pad'\r\n    image/object/bbox/xmin: 0.1\r\n    image/object/bbox/xmax: 0.9\r\n    image/object/bbox/ymin: 0.2\r\n    image/object/bbox/ymax: 0.6\r\n    image/object/bbox/label: 615\r\n    image/format: 'JPEG'\r\n    image/filename: 'ILSVRC2012_val_00041207.JPEG'\r\n    image/encoded: <JPEG encoded string>\r\n\r\n   Args:\r\n     example_serialized: scalar Tensor tf.string containing a serialized\r\n       Example protocol buffer.\r\n\r\n   Returns:\r\n     image_buffer: Tensor tf.string containing the contents of a JPEG file.\r\n     label: Tensor tf.int32 containing the label.\r\n     bbox: 3-D float Tensor of bounding boxes arranged [1, num_boxes, coords]\r\n       where each coordinate is [0, 1) and the coordinates are arranged as\r\n       [ymin, xmin, ymax, xmax].\r\n     text: Tensor tf.string containing the human-readable label.\r\n   \"\"\"\r\n   # Dense features in Example proto.\r\n   feature_map = {\r\n       'image/encoded': tf.FixedLenFeature([], dtype=tf.string,\r\n                                           default_value=''),\r\n       'image/class/label': tf.FixedLenFeature([1], dtype=tf.int64,\r\n                                               default_value=-1),\r\n       'image/class/text': tf.FixedLenFeature([], dtype=tf.string,\r\n                                              default_value=''),\r\n   }\r\n   sparse_float32 = tf.VarLenFeature(dtype=tf.float32)\r\n  # Sparse features in Example proto.\r\n   feature_map.update(\r\n       {k: sparse_float32 for k in ['image/object/bbox/xmin',\r\n                                    'image/object/bbox/ymin',\r\n                                    'image/object/bbox/xmax',\r\n                                    'image/object/bbox/ymax']})\r\n\r\n   features = tf.parse_single_example(example_serialized, feature_map)\r\n   label = tf.cast(features['image/class/label'], dtype=tf.int32)\r\n\r\n   xmin = tf.expand_dims(features['image/object/bbox/xmin'].values, 0)\r\n   ymin = tf.expand_dims(features['image/object/bbox/ymin'].values, 0)\r\n   xmax = tf.expand_dims(features['image/object/bbox/xmax'].values, 0)\r\n   ymax = tf.expand_dims(features['image/object/bbox/ymax'].values, 0)\r\n\r\n   # Note that we impose an ordering of (y, x) just to make life difficult.\r\n   bbox = tf.concat(axis=0, values=[ymin, xmin, ymax, xmax])\r\n\r\n   # Force the variable number of bounding boxes into the shape\r\n   # [1, num_boxes, coords].\r\n   bbox = tf.expand_dims(bbox, 0)\r\n   bbox = tf.transpose(bbox, [0, 2, 1])\r\n\r\n   return features['image/encoded'], label, bbox, features['image/class/text']\r\n```\r\n\r\n**Protobufs created by parsing from byte-encoded protobufs compressed and written to a TFRecord and then uncompressed and read with tf.parse_single_example, and decoded with example.proto's ParseFromString**:\r\n```\r\n\ufffd\u000b\r\n\ufffd\t\r\nimage/encoded\u0012\ufffd\t\r\n\ufffd\t\r\n\ufffd\t\ufffd\ufffd\ufffd\ufffd\ufffd\u0010JFIF\ufffd\u0001\u0001\u0001\u0001,\u0001,\ufffd\ufffd\ufffd\ufffd\ufffdC\ufffd\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\ufffd\ufffd\ufffdC\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\ufffd\ufffd\ufffd\ufffd\u001c\ufffd\u001c\u0003\u0001\"\ufffd\u0002\u0011\u0001\u0003\u0011\u0001\ufffd\ufffd\ufffd\u001f\ufffd\ufffd\u0001\u0005\u0001\u0001\u0001\u0001\u0001\u0001\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u0001\u0002\u0003\u0004\u0005\u0006\t\r\n\u000b\ufffd\ufffd\ufffd\ufffd\u0010\ufffd\u0002\u0001\u0003\u0003\u0002\u0004\u0003\u0005\u0005\u0004\u0004\ufffd\ufffd\u0001}\u0001\u0002\u0003\ufffd\u0004\u0011\u0005\u0012!1A\u0006\u0013Qa\u0007\"q\u00142\ufffd\ufffd#B\ufffd\ufffd\u0015R\ufffd\ufffd$3br\ufffd\t\r\n\u0016\u0017\u0018\u0019\u001a%&'()*456789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u001f\u0001\ufffd\u0003\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u0001\u0002\u0003\u0004\u0005\u0006\t\r\n\u000b\ufffd\ufffd\ufffd\ufffd\u0011\ufffd\u0002\u0001\u0002\u0004\u0004\u0003\u0004\u0007\u0005\u0004\u0004\ufffd\u0001\u0002w\ufffd\u0001\u0002\u0003\u0011\u0004\u0005!1\u0006\u0012AQ\u0007aq\u0013\"2\u0014B\ufffd\ufffd\ufffd\ufffd\t#3R\ufffd\u0015br\ufffd\r\n\ufffd%\ufffd\ufffd\ufffd\ufffd\ufffd\ufffdn_\ufffd\u007f\ufffd\ufffd\ufffd\u07cb\ufffd\u0010~;|\u001e\ufffd\r\n<g\ufffd\ufffd\ufffd\u000f\ufffd!\ufffd_\ufffd\ufffd\u0011\ufffd\ufffdW\ufffdZo\ufffd\ufffd\ufffdo\r\n\ufffd[x\u0003\ufffd\ufffd\ufffd\ufffd\ufffd)\ufffd\ufffd\ufffd\ufffd\ufffd>)|I\ufffd-\ufffdk~)\ufffd\u0017\ufffd[_\ufffd^(\ufffdm\ufffd\ufffd\ufffd\u0013\ufffd/\ufffd\ufffd\ufffd\u000f\u000e\ufffdb\ufffd\ufffd\ufffdF\ufffd\ufffd\u001a\ufffdu\u06db\ufffd}4Y\ufffd]k\ufffdk\u0007\u066dM\ufffd\ufffd\ufffd\ufffd\u0014P\u0007\ufffd\ufffd\r\n\u0015\r\n\fimage/height\u0012\u0005\u001a\u0003\r\n\u0001\u001c\r\n\u001a\r\n\u0011image/class/label\u0012\u0005\u001a\u0003\r\n\u0001\u0007\r\n\u0019\r\n\u0010image/class/text\u0012\u0005\r\n\u0003\r\n\u00016\r\n\u0017\r\n\u000eimage/channels\u0012\u0005\u001a\u0003\r\n\u0001\u0003\r\n\u0014\r\n\u000bimage/width\u0012\u0005\u001a\u0003\r\n\u0001\u001c\r\n\u001d\r\n\u000eimage/filename\u0012\u000b\r\n\t\r\n\u0007368.png\r\n\u0018\r\n\fimage/format\r\n\u0006\r\n\u0004JPEG\r\n\u001b\r\n\u0010image/colorspace\u0012\u0007\r\n\u0005\r\n\u0003RGB\r\n\r\n\ufffd\u000b\r\n\ufffd\r\n\r\nimage/encoded\u0012\ufffd\r\n\r\n\ufffd\t\r\n\ufffd\t\ufffd\ufffd\ufffd\ufffd\ufffd\u0010JFIF\ufffd\u0001\u0001\u0001\u0001,\u0001,\ufffd\ufffd\ufffd\ufffd\ufffdC\ufffd\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\ufffd\ufffd\ufffdC\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\ufffd\ufffd\ufffd\ufffd\u001c\ufffd\u001c\u0003\u0001\"\ufffd\u0002\u0011\u0001\u0003\u0011\u0001\ufffd\ufffd\ufffd\u001f\ufffd\ufffd\u0001\u0005\u0001\u0001\u0001\u0001\u0001\u0001\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u0001\u0002\u0003\u0004\u0005\u0006\t\r\n\u000b\ufffd\ufffd\ufffd\ufffd\u0010\ufffd\u0002\u0001\u0003\u0003\u0002\u0004\u0003\u0005\u0005\u0004\u0004\ufffd\ufffd\u0001}\u0001\u0002\u0003\ufffd\u0004\u0011\u0005\u0012!1A\u0006\u0013Qa\u0007\"q\u00142\ufffd\ufffd#B\ufffd\ufffd\u0015R\ufffd\ufffd$3br\ufffd\t\r\n\u0016\u0017\u0018\u0019\u001a%&'()*456789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u001f\u0001\ufffd\u0003\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u0001\u0002\u0003\u0004\u0005\u0006\t\r\n\u000b\ufffd\ufffd\ufffd\ufffd\u0011\ufffd\u0002\u0001\u0002\u0004\u0004\u0003\u0004\u0007\u0005\u0004\u0004\ufffd\u0001\u0002w\ufffd\u0001\u0002\u0003\u0011\u0004\u0005!1\u0006\u0012AQ\u0007aq\u0013\"2\u0014B\ufffd\ufffd\ufffd\ufffd\t#3R\ufffd\u0015br\ufffd\r\n#\ufffd2\ufffd\ufffd?\ufffd\u000f\ufffd,\ufffd\ufffd\u000f\ufffd,\ufffd\ufffd\u001f\ufffdN\ufffd\ufffd\ufffd\ufffd\ufffd%|\u007f\ufffd\ufffdS'\ufffd\ufffd\ufffd;\u01bf\u001a\ufffdj/\ufffd~\u0007\ufffdn\u0013\ufffd\u068f\u014dF\ufffd\ufffdW^\u001e\ufffd\u05c2\ufffd\ufffd\ufffdwD\u0563\ufffd\ufffd\u23cc-u\ufffd\ud89a\udeeb\ufffd6\ufffdh^\u0019\ufffd\ufffdR\ufffd\ufffdr\ufffd\ufffdE\ufffd?\ufffd\ufffd(\ufffd\u000f\ufffd\ufffd\r\n\u001b\r\n\u0010image/colorspace\u0012\u0007\r\n\u0005\r\n\u0003RGB\r\n\u0017\r\n\u000eimage/channels\u0012\u0005\u001a\u0003\r\n\u0001\u0003\r\n\u0014\r\n\u000bimage/width\u0012\u0005\u001a\u0003\r\n\u0001\u001c\r\n\u0015\r\n\fimage/height\u0012\u0005\u001a\u0003\r\n\u0001\u001c\r\n\u001a\r\n\u0011image/class/label\u0012\u0005\u001a\u0003\r\n\u0001\u0006\r\n\u001e\r\n\u000eimage/filename\u0012\f\r\n\r\n\r\n\r\n5852.png\r\n\u0018\r\n\fimage/format\r\n\u0006\r\n\u0004JPEG\r\n\u0019\r\n\u0010image/class/text\u0012\u0005\r\n\u0003\r\n\u00015\r\n\r\n\ufffd\f\r\n\ufffd\r\n\r\nimage/encoded\u0012\ufffd\r\n\r\n\ufffd\r\n\r\n\ufffd\r\n\ufffd\ufffd\ufffd\ufffd\ufffd\u0010JFIF\ufffd\u0001\u0001\u0001\u0001,\u0001,\ufffd\ufffd\ufffd\ufffd\ufffdC\ufffd\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\ufffd\ufffd\ufffdC\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\ufffd\ufffd\ufffd\ufffd\u001c\ufffd\u001c\u0003\u0001\"\ufffd\u0002\u0011\u0001\u0003\u0011\u0001\ufffd\ufffd\ufffd\u001f\ufffd\ufffd\u0001\u0005\u0001\u0001\u0001\u0001\u0001\u0001\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u0001\u0002\u0003\u0004\u0005\u0006\t\r\n\u000b\ufffd\ufffd\ufffd\ufffd\u0010\ufffd\u0002\u0001\u0003\u0003\u0002\u0004\u0003\u0005\u0005\u0004\u0004\ufffd\ufffd\u0001}\u0001\u0002\u0003\ufffd\u0004\u0011\u0005\u0012!1A\u0006\u0013Qa\u0007\"q\u00142\ufffd\ufffd#B\ufffd\ufffd\u0015R\ufffd\ufffd$3br\ufffd\t\r\n\u0016\u0017\u0018\u0019\u001a%&'()*456789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u001f\u0001\ufffd\u0003\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u0001\u0002\u0003\u0004\u0005\u0006\t\r\n\u000b\ufffd\ufffd\ufffd\ufffd\u0011\ufffd\u0002\u0001\u0002\u0004\u0004\u0003\u0004\u0007\u0005\u0004\u0004\ufffd\u0001\u0002w\ufffd\u0001\u0002\u0003\u0011\u0004\u0005!1\u0006\u0012AQ\u0007aq\u0013\"2\u0014B\ufffd\ufffd\ufffd\ufffd\t#3R\ufffd\u0015br\ufffd\r\n]\ufffdCk\u001aKq\ufffd\ufffd;\ufffd\u0003\ufffd\u000e\ufffd\ufffd\u001f\ufffdn\ufffdd\ufffd\ufffd!\ufffd\ufffd\ufffd\ufffdm_R{}J(\ufffd\ufffdkv\ufffd\ufffd?\ufffd\ufffd(\u0003\ufffdS\ufffd\r\n\u000e]oP\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\r\n\u001b\r\n\u0010image/colorspace\u0012\u0007\r\n\u0005\r\n\u0003RGB\r\n\u0017\r\n\u000eimage/channels\u0012\u0005\u001a\u0003\r\n\u0001\u0003\r\n\u0014\r\n\u000bimage/width\u0012\u0005\u001a\u0003\r\n\u0001\u001c\r\n\u0015\r\n\fimage/height\u0012\u0005\u001a\u0003\r\n\u0001\u001c\r\n\u001a\r\n\u0011image/class/label\u0012\u0005\u001a\u0003\r\n\u0001\u0006\r\n\u001e\r\n\u000eimage/filename\u0012\f\r\n\r\n\r\n\r\n7602.png\r\n\u0018\r\n\fimage/format\r\n\u0006\r\n\u0004JPEG\r\n\u0019\r\n\u0010image/class/text\u0012\u0005\r\n\u0003\r\n\u00015\r\n\r\n\ufffd\t\r\n\ufffd\u0007\r\nimage/encoded\u0012\ufffd\u0007\r\n\ufffd\u0007\r\n\ufffd\u0007\ufffd\ufffd\ufffd\ufffd\ufffd\u0010JFIF\ufffd\u0001\u0001\u0001\u0001,\u0001,\ufffd\ufffd\ufffd\ufffd\ufffdC\ufffd\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\ufffd\ufffd\ufffdC\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\ufffd\ufffd\ufffd\ufffd\u001c\ufffd\u001c\u0003\u0001\"\ufffd\u0002\u0011\u0001\u0003\u0011\u0001\ufffd\ufffd\ufffd\u001f\ufffd\ufffd\u0001\u0005\u0001\u0001\u0001\u0001\u0001\u0001\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u0001\u0002\u0003\u0004\u0005\u0006\t\r\n\u000b\ufffd\ufffd\ufffd\ufffd\u0010\ufffd\u0002\u0001\u0003\u0003\u0002\u0004\u0003\u0005\u0005\u0004\u0004\ufffd\ufffd\u0001}\u0001\u0002\u0003\ufffd\u0004\u0011\u0005\u0012!1A\u0006\u0013Qa\u0007\"q\u00142\ufffd\ufffd#B\ufffd\ufffd\u0015R\ufffd\ufffd$3br\ufffd\t\r\n\u0016\u0017\u0018\u0019\u001a%&'()*456789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u001f\u0001\ufffd\u0003\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u0001\u0002\u0003\u0004\u0005\u0006\t\r\n\u000b\ufffd\ufffd\ufffd\ufffd\u0011\ufffd\u0002\u0001\u0002\u0004\u0004\u0003\u0004\u0007\u0005\u0004\u0004\ufffd\u0001\u0002w\ufffd\u0001\u0002\u0003\u0011\u0004\u0005!1\u0006\u0012AQ\u0007aq\u0013\"2\u0014B\ufffd\ufffd\ufffd\ufffd\t#3R\ufffd\u0015br\ufffd\r\n\u0016$4\ufffd%\ufffd\u0017\u0018\u0019\u001a&'()*56789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\f\u0003\u0001\ufffd\u0002\u0011\u0003\u0011\ufffd?\ufffd\ufffd\ufffd?\ufffd\ufffdO\ufffd\t\ufffd\ufffd\u0015x\ufffd\ufffd\r\n\u0015\ufffd^|\u001f\ufffd\ufffd<\t\ufffdj~\u001f\u053e(\ufffd\u0017\ufffdz\ufffd\ufffdl|\u001f\ufffd\ufffd\ufffd\ufffd\ufffd\u001a\u0006\ufffd\ufffd^j:\ufffd\ufffd\ufffdG\ufffd\ufffd\ufffdL\ufffd\ufffd(\ufffd\ufffd\u016a\ufffd\u0013\ufffd\u0010Y\ufffd\ufffdL&\ufffd\ufffd\ufffd\ufffd.~,\ufffd\ufffd\ufffd\ufffd\f\ufffd\ufffd_\ufffdQ\ufffd\ufffd\u000b\ufffd\fw\ufffd\ufffd\ufffd>\ufffd\ufffd<t\u001bK{r\ufffdTo\u0011|R\ufffdI\u001c{n\ufffd\ufffd[Aht\ufffd\\\u001b{\ufffd0\ufffd\u0005\ufffd\\\u0003\ufffdO\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u0005>+\ufffdO\ufffd5\ufffdT\ufffd\ufffd\ufffd_\t>!\ufffd\ufffd\u15cbc\ufffdn\ufffd\ufffdNO\u0013\ufffd\u000b\u011a\ufffd\ufffdu\u4c3dEE\ufffd\ufffd]WJ\ufffd[[\ufffdE[\ufffd\u0004s*\ufffdp\u0007\ufffdWs\ufffd?\ufffdz\ufffd\ufffd/\ufffd\u007f\u0010\ufffd&\ufffd\u0011,\u001a\ufffd\ufffd_\u001c\ufffd\ufffd\ufffdz\ufffd\"C\ufffdx\ufffd_\ufffd<A}\u0012\ufffd\u001c\u0016\ufffd\u0231\ufffdj\u0012\ufffd\ufffd[[\ufffd\ufffd\u0019`\ufffdH\ufffdxj\ufffd+\ufffd\ufffd\ufffd\ufffd\ufffdA\ufffdC\ufffdh?\ufffdS\ufffd+\ufffdkv\u001a5\ufffd\ufffd\ufffd\u0010\ufffds\ufffd\ufffdjZ\ufffd\ufffd\ufffd\u0005\ufffd\u054f\ufffd~\u0011k2A\u0010\ufffd\ufffd(\ue9f3\ufffdt\ufffdWUx\ufffdI%\ufffd\ufffda\ufffd_0Kk[\ufffdc\ufffdWh\ufffd\u0002\ufffd(\ufffd\u000f\ufffd\ufffd\r\n\u001b\r\n\u0010image/colorspace\u0012\u0007\r\n\u0005\r\n\u0003RGB\r\n\u0017\r\n\u000eimage/channels\u0012\u0005\u001a\u0003\r\n\u0001\u0003\r\n\u0014\r\n\u000bimage/width\u0012\u0005\u001a\u0003\r\n\u0001\u001c\r\n\u0015\r\n\fimage/height\u0012\u0005\u001a\u0003\r\n\u0001\u001c\r\n\u001a\r\n\u0011image/class/label\u0012\u0005\u001a\u0003\r\n\u0001\u0002\r\n\u001d\r\n\u000eimage/filename\u0012\u000b\r\n\t\r\n\u0007663.png\r\n\u0018\r\n\fimage/format\r\n\u0006\r\n\u0004JPEG\r\n\u0019\r\n\u0010image/class/text\u0012\u0005\r\n\u0003\r\n\u00011\r\n\r\n\ufffd\f\r\n\ufffd\u000b\r\nimage/encoded\u0012\ufffd\u000b\r\n\ufffd\u000b\r\n\ufffd\r\n\ufffd\ufffd\ufffd\ufffd\ufffd\u0010JFIF\ufffd\u0001\u0001\u0001\u0001,\u0001,\ufffd\ufffd\ufffd\ufffd\ufffdC\ufffd\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\ufffd\ufffd\ufffdC\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\ufffd\ufffd\ufffd\ufffd\u001c\ufffd\u001c\u0003\u0001\"\ufffd\u0002\u0011\u0001\u0003\u0011\u0001\ufffd\ufffd\ufffd\u001f\ufffd\ufffd\u0001\u0005\u0001\u0001\u0001\u0001\u0001\u0001\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u0001\u0002\u0003\u0004\u0005\u0006\t\r\n\u000b\ufffd\ufffd\ufffd\ufffd\u0010\ufffd\u0002\u0001\u0003\u0003\u0002\u0004\u0003\u0005\u0005\u0004\u0004\ufffd\ufffd\u0001}\u0001\u0002\u0003\ufffd\u0004\u0011\u0005\u0012!1A\u0006\u0013Qa\u0007\"q\u00142\ufffd\ufffd#B\ufffd\ufffd\u0015R\ufffd\ufffd$3br\ufffd\t\r\n\u0016\u0017\u0018\u0019\u001a%&'()*456789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u001f\u0001\ufffd\u0003\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\u0001\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u0001\u0002\u0003\u0004\u0005\u0006\t\r\n\u000b\ufffd\ufffd\ufffd\ufffd\u0011\ufffd\u0002\u0001\u0002\u0004\u0004\u0003\u0004\u0007\u0005\u0004\u0004\ufffd\u0001\u0002w\ufffd\u0001\u0002\u0003\u0011\u0004\u0005!1\u0006\u0012AQ\u0007aq\u0013\"2\u0014B\ufffd\ufffd\ufffd\ufffd\t#3R\ufffd\u0015br\ufffd\r\n\u0016$4\ufffd%\ufffd\u0017\u0018\u0019\u001a&'()*56789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\f\u0003\u0001\ufffd\u0002\u0011\u0003\u0011\ufffd?\ufffd\ufffd\ufffd?\ufffd\ufffd\ufffd\u007fa\u001f\ufffd6#\ufffd\r\n\ufffd\u057e\u0013\ufffd+7\ufffdM\ufffd\ufffd\u0005&\ufffd\ufffd\ufffd\ufffd[\ufffd\u001f\ufffd[\ufffd\ufffd\ufffd[\ufffd\u001f\ufffd?\ufffdG\ufffd\u007f\ufffdcP\ufffdK\ufffd\ufffd)i\ufffd\u001b\ufffd\ufffd\ufffd\ufffdqk\ufffdj\ufffd\ufffd\u03edM\u0fc6:u\ufffd\ufffd \ufffd\u0016\ufffd\ufffd\u0005\ufffd\u0016>'\ufffd\u0010i\ufffd[\ufffd\ufffd\ufffdu\ufffd\u0003\\\ufffd\ufffd{\ufffd\ufffd\ufffd_\ufffdN_\ufffd{\ufffd\t\ufffd\ufffd\ufffd\ufffd\ufffd\u0007\ufffdM\ufffd\ufffd\u000e\ufffd~+\u057c'a\ufffd\t\ufffd\ufffd\u000b\ufffd\u001d\ufffd\ufffd\ufffd\u0017\ufffdO\u0007j:\ufffd\ufffd\ufffdA\ufffd\ufffd\u007fX\ufffd\u000b\u001b\ufffd=gA\ufffd\ufffd\ufffd\ufffd#\ufffd\u001aF\ufffd\ufffd\u001b\u0019-#\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u001d*\ufffd\ufffd\ufffd\ufffd:\ufffd\ufffdF?\ufffd:\ufffd\ufffdO\ufffd\ufffd\u007fm?\ufffd3\ufffd\ufffd\ufffd\u0016\u0013\ufffd\u000f\ufffd\ufffd\ufffd\u0010\ufffd\ufffd\ufffd7\ufffd\u007f\ufffd\ufffd:\ufffd\u00114=3\ufffd\u007f\u010f\ufffd\u007f\u0012\ufffd%^Z\ufffd\ufffd\ufffd\ufffd#\ufffd\ufffd\ufffd\ufffd>![\ufffd\ufffdMk\ufffd\ufffd\ufffd\ufffd\ufffd\ufffdj\ufffd\ufffd\ufffd\u07c7\ufffdY\ufffdm\ufffd\u001b\u0001\ufffd\ufffd\ufffd\u0015\ufffd\ufffd\ufffdP\u0007\ufffd\ufffd\u0012\ufffd\ufffd\t\ufffd\ufffd\u0007\ufffd\r\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffdv\u0017VW\ufffd\ufffd\ufffd\ufffd\ufffdu\ufffdh\ufffd\ufffd6\ufffdP2K\ufffd\ufffd\ufffdb\ufffd\ufffd\ufffd\ufffd?\ufffd\ufffd\u007f\ufffdjW\ufffd\u007f\ufffd\u0016_\u0019\ufffd\ufffd?\ufffdY\ufffd\ufffd\u001f\ufffd\ufffd\ufffd\ufffd?e\ufffd\ufffd\ufffd\ufffd\ufffdrXx{\ufffdO\ufffdu\ufffd\u000e\ufffd\ufffdbX\u0268\ufffdk\u0016\ufffd\ufffd\u001f\u0014\ufffdkC\ufffd\ufffdh\ufffd\ufffd;+Y4\ufffd\ufffd\ufffd:\u043cK\ufffd\u001f\ufffdO{w\ufffd\ufffd\ufffd\ufffd\ufffdu[+I\ufffd\u001f\ufffd\ufffd\ufffd=\ufffd\ufffd\u00cdhx\ufffd\ufffd\ufffd<Y\ufffd/\u0010\ufffdY\ufffdF\ufffd\ufffd\ufffd\u0011\ufffd\u001e\u0017\u0585\ufffd\u044c\ufffdY\ufffdSC\ufffd\ufffd\ufffd\u0016\ufffd&(\ufffd\ufffd\ufffd\u007f&c\u001cfDm\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u001d\ufffdC~\ufffdW\ufffdj\u007f\u001e\ufffd<|f\ufffd\u0769[I\u0014\ufffd\u068f\ufffd\ufffd\u001e7\ufffd\ufffd}o,\u001a}\ufffd\ufffd\u0004\ufffd]\ufffd\ufffd\\\u05ae\"\ufffd\u001d*\ufffd\ufffdL\ufffd\ufffdZ=>\ufffd\ufffd\ufffd\ufffd\ufffd4\ufffd\ufffd\ufffd?\ufffd\ufffd/\ufffd-\ufffd\ufffd\ufffd\u06ff\u00bf\u0007\ufffd\ufffda\ufffd\ufffdk\u00da\ufffd\ufffd\ufffd\ufffdbo\ufffd\ufffd\ufffdK\ufffd\ufffdU\ufffdtk\ufffd\r\n\u000f\ufffd\ufffd\ufffd\ufffd\ufffdtMC\ufffd\ufffd\u0003\ufffd\ufffd~\u001d\ufffd\u069ek\u000f\ufffd\ufffd\u0011\ufffdu\u00ef\ufffd\ufffd|W\ufffdi\ufffd)\ufffd\ufffd\ufffd\u0017\ufffd\ufffd^\ufffd\ufffdu\ufffd\u0017\u001f\ufffd-\u0014P\u0007\ufffd\ufffd\r\n\u0019\r\n\u0010image/class/text\u0012\u0005\r\n\u0003\r\n\u00013\r\n\u0015\r\n\fimage/height\u0012\u0005\u001a\u0003\r\n\u0001\u001c\r\n\u001a\r\n\u0011image/class/label\u0012\u0005\u001a\u0003\r\n\u0001\u0004\r\n\u001b\r\n\u0010image/colorspace\u0012\u0007\r\n\u0005\r\n\u0003RGB\r\n\u001e\r\n\u000eimage/filename\u0012\f\r\n\r\n\r\n\r\n7763.png\r\n\u0018\r\n\fimage/format\r\n\u0006\r\n\u0004JPEG\r\n\u0017\r\n\u000eimage/channels\u0012\u0005\u001a\u0003\r\n\u0001\u0003\r\n\u0014\r\n\u000bimage/width\u0012\u0005\u001a\u0003\r\n\u0001\u001c\r\n```", "comments": ["There's a lot of information here and I'm having a hard time following. Does this happen if the code is unmodified? Are you using the standard imagenet dataset? Did you create records for a new dataset by hand?", "Apologies for the clutter, I kept changing stuff on as I explored the issue more and definitely should have formatted the additions better.\r\n\r\nThe same thing has been happening both with the unmodified Inception code and with the minor alterations that I've made to it. I've had the same issue using both the MNIST datset and custom datasets I created (the exact error I get as a result of this is that labels[0] is out of bounds in tf.nn.in_top_k, which is happening because the labels are being messed up), but I have not tried this on the standard imagenet dataset. \r\n\r\n", "If you're giving inception/imagenet_eval a custom dataset, is it possible that there's a bug on your end, in creating that dataset?\r\n\r\nAlso take into consideration that Inception:\r\n\r\n1. Feeds dataset images through a `tf.RandomShuffleQueue`.\r\n2. Hard-codes `0` as the background label. Your labels are \u22651.\r\n\r\nIs it possible that those things are what resulted in the confusion? If not, please help us out with a minimal example we can run to reproduce the bug.", "I tried using the standard MNIST dataset, so a dataset issue seems unlikely. You should be able to replicate my problem by trying to classify MNIST images of numbers 1-4. If you set the number of classes in imagenet_data.py as 4, reflecting the size of this dataset, it should cause the error I'm encountering.\r\n\r\nThe 0 as background class doesn't seem to be causing a problem--tensorflow *is* able to correctly create and assign int64 labels to each label, and the same problem happens when I use words for labels, not just numbers. Could you explain how the tf.RandomShuffleQueue could cause a problem? ", "I'm sorry I wish I could reproduce this but I'm not sure I understand what you're doing. The mnist dataset has 10 classes, one for each digit. I also know it's encoded to a very specific binary format and I don't know off the top of my head if that's the format inception wants. I will re-open this issue provided new evidence of the specific bug.", "I converted the MNIST images into PNGs using a script available online (which was successful--the images appeared correct) and then deleted the directories for all but 4 of it's classes (the numbers 1 through 4) to reflect the number of classes I had in my actual data. I then fed those 4 classes of PNGs into the neural network, which produced the error that I was describing in my issue. \r\n\r\nIs there specific additional information that I could provide that could help make the bug more clear? I can provide the protobufs before and after serialization as well (to complement the one included in my bug report, which is read from the TFRecord using tf.parse_single_example)", "Additionally, if the MNIST data is insufficient, I can also provide the code I used to generate another dataset that I fed into the neural network and encountered the same issue with below:\r\n\r\n```\r\nfrom PIL import Image\r\nimport random\r\n\r\nbase = [250, 180, 100, 30]\r\ndct = [\"A\", \"C\", \"G\", \"T\"]\r\n\r\nfor n in range(4):\r\n    for k in range(256):\r\n        data = []\r\n        ref = [(base[random.randint(0,3)], 60, 70) for _ in range(298)]\r\n        for _ in range(5):\r\n            for i in range(149):\r\n                data.append(ref[i])\r\n            data.append((base[n], 60, 70))\r\n            for i in range(149):\r\n                data.append(ref[i+149])\r\n        for i in range(299*294):\r\n            data.append((0,0,0))\r\n        im = Image.new(\"RGB\", (299,299))\r\n        im.putdata(data)\r\n        print(dct[n] + str(k))\r\n        im.save(\"bug_demo/training/\" + dct[n] + \"/\" + str(k) + dct[n] + \".png\", \"PNG\")\r\n    for k in range(256):\r\n        data = []\r\n        ref = [(base[random.randint(0,3)], 60, 70) for _ in range(298)]\r\n        for _ in range(5):\r\n            for i in range(149):\r\n                data.append(ref[i])\r\n            data.append((base[n], 60, 70))\r\n            for i in range(149):\r\n                data.append(ref[i+149])\r\n        for i in range(299*294):\r\n            data.append((0,0,0))\r\n        im = Image.new(\"RGB\", (299,299))\r\n        im.putdata(data)\r\n        print(dct[n] + str(k))\r\n        im.save(\"bug_demo/training/\" + dct[n] + \"/\" + str(k) + dct[n] + \".png\", \"PNG\")\r\n\r\n```\r\nThis code is meant to generate simulated images (in PNG) of DNA reads converted into a image, and is meant to determine whether Tensorflow is capable of identifying and classifying based on a particular reference base. There are four classes named \"A\", \"C\", \"G\", and \"T\" and 1024 examples for both training and validation. I have already attempted to run tensorflow on this dataset, and I have encountered the same error with labels being changed by tf.parse_single_example", "I meet the same problem too\r\n", "I have the same issue with my own dataset which has 15 classes. The images are being converted correctly but the labels keep changing anytime i convert them to tfrecords using tf.parse_single_example. ", " I am trying to convert a random numpy array to tf.records. but it seems to be not doing it correctly. The label conversion is fine but the image conversion does not give back the original image. \r\n\r\nAt the end, it prints False, True, whereas it should be True, True. I was wondering why is that? Is this a tensorflow or am I missing something.\r\n\r\n    import tensorflow as tf\r\n    import numpy as np\r\n    \r\n    \r\n    def wrap_bytes(value):\r\n        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\r\n    \r\n    \r\n    def wrap_int64(value):\r\n        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\r\n    \r\n    \r\n    def convert(images, labels, out_path):\r\n    \r\n        num_images = len(labels)\r\n        with tf.python_io.TFRecordWriter(out_path) as writer:\r\n            for i in range(num_images):\r\n    \r\n                label_ = labels[i]\r\n                # the same problem persists whether or not we flatten\r\n                image = images[i].flatten()\r\n                image_bytes = image.tostring()\r\n                features = \\\r\n                    {\r\n                        'image': wrap_bytes(tf.compat.as_bytes(image_bytes)),\r\n                        'label': wrap_int64(label_)\r\n                    }\r\n    \r\n                feature = tf.train.Features(feature=features)\r\n                example = tf.train.Example(features=feature)\r\n                serialized = example.SerializeToString()\r\n                writer.write(serialized)\r\n    \r\n    \r\n    def parse(serialized):\r\n        features = \\\r\n            {\r\n                'image': tf.FixedLenFeature([], tf.string),\r\n                'label': tf.FixedLenFeature([], tf.int64),\r\n            }\r\n    \r\n        parsed_example = \\\r\n            tf.parse_single_example(\r\n                serialized=serialized,\r\n                features=features)\r\n    \r\n        image_raw = parsed_example['image']\r\n        label_raw = parsed_example['label']\r\n        image_ = tf.decode_raw(image_raw, tf.int32)\r\n        image_reshaped = tf.reshape(image_, (5, 5))\r\n    \r\n        return image_reshaped, label_raw\r\n    \r\n    \r\n    def input_fn(filenames, batch_size):\r\n    \r\n        dataset = tf.data.TFRecordDataset(filenames=filenames)\r\n        dataset = dataset.map(parse)\r\n        # dataset = dataset.repeat(1)\r\n        dataset = dataset.batch(batch_size)\r\n        iterator = dataset.make_one_shot_iterator()\r\n        batch_images_tf, batch_labels_tf = iterator.get_next()\r\n    \r\n        return batch_images_tf, batch_labels_tf\r\n\r\n    \r\n    n = 10\r\n    num_classes = 15\r\n    batch_size = 2\r\n    out_path = 'bug.tfrecords'\r\n    labels = np.random.randint(0, num_classes, n)\r\n\r\n    image_shape = (5, 5)\r\n    images_ = np.int32(np.random.randint(0, 255, 5*5*n).reshape(n, 5, 5))\r\n    \r\n    convert(images_, labels, out_path)\r\n    \r\n    batch_images_tf, batch_labels_tf = input_fn(out_path, batch_size)\r\n    \r\n    sess = tf.Session()\r\n    batch_labels_np = sess.run(batch_labels_tf)\r\n    batch_images_np = sess.run(batch_images_tf)\r\n    \r\n    # checking whether the converted data is the same as the original\r\n    print(np.array_equal(batch_images_np, images_[0:batch_size]))\r\n    print(np.array_equal(batch_labels_np, labels[0:batch_size]))"]}]