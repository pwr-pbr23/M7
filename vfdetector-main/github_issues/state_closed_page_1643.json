[{"number": 3618, "title": "gcc: error: unrecognized command line option '-fno-canonical-system-headers'", "body": "when I run : \nbazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer --verbose_failures\n then the output is \n\nduan@duan:~/tensorflow$ bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer --verbose_failures\nWARNING: /home/duan/.cache/bazel/_bazel_duan/9f3780f2ce96d65830e33f06d4dd8a47/external/protobuf/WORKSPACE:1: Workspace name in /home/duan/.cache/bazel/_bazel_duan/9f3780f2ce96d65830e33f06d4dd8a47/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.\nWARNING: /home/duan/.cache/bazel/_bazel_duan/9f3780f2ce96d65830e33f06d4dd8a47/external/highwayhash/WORKSPACE:1: Workspace name in /home/duan/.cache/bazel/_bazel_duan/9f3780f2ce96d65830e33f06d4dd8a47/external/highwayhash/WORKSPACE (@__main__) does not match the name given in the repository's definition (@highwayhash); this will cause a build error in future versions.\nWARNING: /home/duan/.cache/bazel/_bazel_duan/9f3780f2ce96d65830e33f06d4dd8a47/external/re2/WORKSPACE:1: Workspace name in /home/duan/.cache/bazel/_bazel_duan/9f3780f2ce96d65830e33f06d4dd8a47/external/re2/WORKSPACE (@__main__) does not match the name given in the repository's definition (@re2); this will cause a build error in future versions.\nINFO: Found 1 target...\nERROR: /home/duan/.cache/bazel/_bazel_duan/9f3780f2ce96d65830e33f06d4dd8a47/external/protobuf/BUILD:111:1: C++ compilation of rule '@protobuf//:protobuf' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command \n  (cd /home/duan/.cache/bazel/_bazel_duan/9f3780f2ce96d65830e33f06d4dd8a47/execroot/tensorflow && \\\n  exec env - \\\n    PATH=/home/duan/bin:/usr/local/cuda-8.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/duan/.bazel/bin \\\n  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -g0 '-std=c++11' '-frandom-seed=bazel-out/host/bin/external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/message.o' -iquote external/protobuf -iquote bazel-out/host/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/host/genfiles/external/bazel_tools -isystem external/protobuf/src -isystem bazel-out/host/genfiles/external/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -DHAVE_PTHREAD -Wall -Wwrite-strings -Woverloaded-virtual -Wno-sign-compare '-Wno-error=unused-function' -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fno-canonical-system-headers -MD -MF bazel-out/host/bin/external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/message.d -c external/protobuf/src/google/protobuf/message.cc -o bazel-out/host/bin/external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/message.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\ngcc: error: unrecognized command line option '-fno-canonical-system-headers'\nTarget //tensorflow/cc:tutorials_example_trainer failed to build\nINFO: Elapsed time: 0.784s, Critical Path: 0.14s\n", "comments": ["This sounds like a bazel issue, rather than TensorFlow.  Please ask your question at https://github.com/bazelbuild/bazel/issues\n", "I come with the same problem. Have you solved already?"]}, {"number": 3617, "title": "Python style, added spaces between arguments", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I'm a Googler.\n", "What's your LDAP?\n", "Found it.\n", "@tensorflow-jenkins test this please\n", "Can you use your google email on the commit instead?\n", "Is this tested on tensorflow-jenkins ? \n", "(Closing, re-open if you can amend your commits with the right email)\n"]}, {"number": 3616, "title": "ImportError: libcudart.so.7.0: cannot open shared object file: No such file or directory", "body": "I installed Cuda 7.5 and cudnn v4. after making the symlinks for cudnn and changing the path variables, when I import tensorflow I get the error : ImportError: libcudart.so.7.0: cannot open shared object file: No such file or directory. ?\n\nAny advice on how to proceed?\n", "comments": ["when you ran ./configure, did you specify 7.5 as cuda version?\nAlso a work-around for this kind of issue could be to find your\nlibcudart.so (maybe in /usr/lib/cuda) and symlink it to libcudart.so.7.0\n\nOn Tue, Aug 2, 2016 at 7:06 PM, Deepak notifications@github.com wrote:\n\n> I installed Cuda 7.5 and cudnn v4. after making the symlins and changing\n> the path variables, when I import tensorflow I get the error : ImportError:\n> libcudart.so.7.0: cannot open shared object file: No such file or\n> directory. ?\n> \n> Any advice on how to proceed?\n> \n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3616, or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AABaHE2z7MBUAMUFzT8YCrsObKWRXUb4ks5qb_eKgaJpZM4JbOvB\n> .\n", "I only have libcudart.so.7.5 at /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcudart.so.7.5\n. I do not have libcudart.so.7.0. \nAlso I did not install tensorflow from source.\n", "You could \"ln -s\" your libcudart.so.7.5 to libcudart.so.7.0\n\nOn Tue, Aug 2, 2016 at 7:17 PM, Deepak notifications@github.com wrote:\n\n> I only have libcudart.so.7.5 at\n> /usr/local/cuda-7.5/targets/x86_64-linux/lib/libcudart.so.7.5\n> . I do not have libcudart.so.7.0.\n> Also I did not install tensorflow from source.\n> \n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3616#issuecomment-237113677,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AABaHBXLX85Qr2S-CCjDrjMwGv9fIdTxks5qb_pVgaJpZM4JbOvB\n> .\n", "I reinstalled tensorflow, it worked, though a strange thing happened now. Tensorflow runs fine in the ipython shell, but if I execute the python  program  from the terminal I get the following error : \n\n`  File \"<stdin>\", line 1, in <module>\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/**init**.py\", line 23, in <module>\n    from tensorflow.python import *\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/**init**.py\", line 58, in <module>\n    raise ImportError(msg)\nImportError: Traceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/**init**.py\", line 52, in <module>\n    from tensorflow.core.framework.graph_pb2 import *\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py\", line 6, in <module>\n    from google.protobuf import descriptor as _descriptor\nImportError: No module named google.protobuf\n\nError importing tensorflow.  Unless you are using bazel,\nyou should not try to import tensorflow from its source directory;\nplease exit the tensorflow source tree, and relaunch your python interpreter\nfrom there.\n`\n\nI saw a fix at [https://github.com/tensorflow/tensorflow/issues/1415](url). But why does this only occur when I execute the python program and not in the ipython shell ?\n\nThanks!\n", "Your ipython and Python have different values for sys.path\n\nBasically you can have multiple Python distributions with their own sets of\nlibraries, so your Python and ipython probably come from different\ndistributions\n\nOn Aug 2, 2016 7:32 PM, \"Deepak\" notifications@github.com wrote:\n\n> I reinstalled tensorflow, it worked, though a strange ting happened now.\n> Tensorflow runs fine in the ipython shell, but if I execute the python\n> program from the terminal I get the following error :\n> \n> ` File \"\", line 1, in\n> File \"/usr/local/lib/python2.7/dist-packages/tensorflow/_init_.py\", line\n> 23, in\n> from tensorflow.python import *\n> File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/_init_.py\",\n> line 58, in\n> raise ImportError(msg)\n> ImportError: Traceback (most recent call last):\n> File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/_init_.py\",\n> line 52, in\n> from tensorflow.core.framework.graph_pb2 import *\n> File\n> \"/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py\",\n> line 6, in\n> from google.protobuf import descriptor as _descriptor\n> ImportError: No module named google.protobuf\n> \n> Error importing tensorflow. Unless you are using bazel,\n> you should not try to import tensorflow from its source directory;\n> please exit the tensorflow source tree, and relaunch your python\n> interpreter\n> from there.\n> `\n> \n> I saw a fix at https://github.com/tensorflow/tensorflow/issues/1415\n> http://url. But why does this only occur when I execute the python\n> program and not in the ipython shell ?\n> \n> Thanks!\n> \n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3616#issuecomment-237116337,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AABaHCixEPbKPbByga_55cy4vkSge0Giks5qb_2ygaJpZM4JbOvB\n> .\n", "I thought that would be the case, but my Python path is set to /usr/local/lib/python2.7/dist-packages. its where google/protobuf is.\n\nWhy is it not finding it?\n", "Package loading is done by traversing entries in sys.path until there's a\nmatch. So if os.getcwd() and sys.path are identical between Python and\nipython, your package loading should be the same.\n\nOn Aug 2, 2016 7:38 PM, \"Deepak\" notifications@github.com wrote:\n\n> I thought that would be the case, but my Python path is set to\n> /usr/local/lib/python2.7/dist-packages. its where google/protobuf is.\n> \n> \u2014\n> You are receiving this because you commented.\n> \n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3616#issuecomment-237117351,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AABaHGdOxLmfHSZHGaQCERLxnx-vWBCqks5qb_8BgaJpZM4JbOvB\n> .\n", "I had to un install miniconda and anaconda , though it is working now. Although I double checked, there were no conflicts with protobuf from miniconda or anaconda, it  was'nt working with them installed. Does tensorflow has some other conflicts with anacondas or miniconda?\n", "This stackoverflow thread\nhttp://stackoverflow.com/questions/33646541/tensorflow-and-anaconda-on-ubuntu\ndiscusses some issues that can cause trouble between TF and anaconda on ubuntu.\n", "Thanks , I have exactly the same issue. Anyways I installed some of the anaconda packages by pip and its working fine now. \nThanks @yaroslavvb  and @poxvoculi  for your help. \n"]}, {"number": 3615, "title": "Add missing imports in TF learn examples", "body": "", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins Test this please\n", "LGTM\n"]}, {"number": 3614, "title": "Fix prototype mismatch of ByteCount in env.cc", "body": "Currently, makefile build is broken due to the prototype mismatch of ByteCount.  This change fixes that build error.\n\nError log:\ntensorflow/core/platform/env.cc:304:9: error: conflicting return type specified for \u2018virtual tensorflow::int64 tensorflow::{anonymous}::FileStream::ByteCount() const\u2019\n   int64 ByteCount() const override { return pos_; }\n         ^\nIn file included from ./tensorflow/core/platform/default/protobuf.h:26:0,\n                 from ./tensorflow/core/platform/protobuf.h:31,\n                 from ./tensorflow/core/platform/file_system.h:28,\n                 from ./tensorflow/core/platform/env.h:27,\n                 from tensorflow/core/platform/env.cc:23:\n/usr/local/google/home/satok/tmpstorage/Develop/src-tf-git/tensorflow2/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/include/google/protobuf/io/zero_copy_stream.h:172:17: error:   overriding \u2018virtual google::protobuf::int64 google::protobuf::io::ZeroCopyInputStream::ByteCount() const\u2019\n   virtual int64 ByteCount() const = 0;\n                 ^****\n", "comments": ["Can one of the admins verify this patch?\n", "@satok16 \nHi, I have the same problem, #3620 .  And same solution as you.\nSince you have fixed it, my issue should be closed.\n\nThank you.\n", "@tensorflow-jenkins test this please\n", "@tensorflow-jenkins test this please\n", "@satok16 try to update your email to your google.com address so the CLA check passes.  Thanks!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "@tensorflow-jenkins test this please\n", "@tensorflow-jenkins test this please\n", "@tensorflow-jenkins test this please\n"]}, {"number": 3613, "title": "Running LinearClassifier.fit with SparseTensor", "body": "I'm trying to create a LinearClassifer with a sparse binary numpy coo matrix (reports) using a SparseTensor.  This is with TensorFlow 0.9.0\n\nI do this as follows:\n\n```\nreports_indices = list()\nrows,cols = reports.nonzero()\nfor row,col in zip(rows,cols):\n   reports_indices.append([row,col])\n\nx_sparsetensor = tf.SparseTensor(\n  indices=reports_indices,\n  values=[1] * len(reports_indices),\n  shape=[reports.shape[0],reports.shape[1]])\n```\n\nThe dimensions of reports is 10K by 1.5K.\n\nI then setup the LinearClassifier as follows:\n\n```\nm = tf.contrib.learn.LinearClassifier()\n\nm.fit(x=drug_cols,y=(1*y_vec).todense(),input_fn=None)\n```\n\nThis results in the following error:\n`TypeError: object of type 'Tensor' has no len()\n`\n\nIs my construction incorrect for some reason?  Thanks in advance for any help.\n", "comments": ["Unless there's evidence of a TF bug, this sort of user program debugging question is more properly asked on stackoverflow, tagged as 'tensorflow'.  It would likely help to give more information so that the error is reproducible, and also the full error stack trace.\n"]}, {"number": 3612, "title": "Cuda error: creating context when one is currently active", "body": "### Environment info\n- Operating System: Ubuntu 14.04, \n- GPU server with 8 **Tesla K80** GPUs,\n- Python 2.7 (Anaconda)\n\nInstalled version of CUDA and cuDNN: \n- Cuda 7.5, cuDNN v4\n\nIf installed from binary pip package, provide:\n1. Pip package: GPU-enabled, Python 2.7\n   https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`:\n\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\n0.9.0\n### Steps to reproduce\n\n```\nimport tensorflow as tf\nsess = tf.Session()\n```\n\nyields the error:\n**W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active;**\nsee the detailed logs below please:\n### What have you tried?\n1. I checked the output of the `nvidia-smi`. There are other processes run by other users currently. Below is the output.\n2. I re-installed tensorflow again using pip, it didn't solve the problem.\n\n```\n+------------------------------------------------------+                       \n| NVIDIA-SMI 352.39     Driver Version: 352.39         |                       \n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  Tesla K80           Off  | 0000:05:00.0     Off |                    0 |\n| N/A   33C    P0    59W / 149W |    190MiB / 11519MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  Tesla K80           Off  | 0000:06:00.0     Off |                    0 |\n| N/A   30C    P8    30W / 149W |     22MiB / 11519MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   2  Tesla K80           Off  | 0000:09:00.0     Off |                    0 |\n| N/A   25C    P8    27W / 149W |     22MiB / 11519MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   3  Tesla K80           Off  | 0000:0A:00.0     Off |                    0 |\n| N/A   28C    P8    31W / 149W |     22MiB / 11519MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   4  Tesla K80           Off  | 0000:84:00.0     Off |                    0 |\n| N/A   24C    P8    28W / 149W |     22MiB / 11519MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   5  Tesla K80           Off  | 0000:85:00.0     Off |                    0 |\n| N/A   54C    P0   106W / 149W |  11461MiB / 11519MiB |     58%      Default |\n+-------------------------------+----------------------+----------------------+\n|   6  Tesla K80           Off  | 0000:88:00.0     Off |                    0 |\n| N/A   49C    P0   134W / 149W |  11461MiB / 11519MiB |     97%      Default |\n+-------------------------------+----------------------+----------------------+\n|   7  Tesla K80           Off  | 0000:89:00.0     Off |                    0 |\n| N/A   69C    P0   131W / 149W |  11462MiB / 11519MiB |     57%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0    155948    C   ../../../build/tools/caffe                      82MiB |\n|    0    196261    C   .build_release/test/test_all.testbin            81MiB |\n|    5     19542    C   python                                       11436MiB |\n|    6     18802    C   python                                       11436MiB |\n|    7     85515    C   python                                       11437MiB \n```\n### Logs\n\n```\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: Tesla K80\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\npciBusID 0000:05:00.0\nTotal memory: 11.25GiB\nFree memory: 11.00GiB\nW tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x2f85bd0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: \nname: Tesla K80\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\npciBusID 0000:06:00.0\nTotal memory: 11.25GiB\nFree memory: 11.16GiB\nW tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x339e320\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 2 with properties: \nname: Tesla K80\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\npciBusID 0000:09:00.0\nTotal memory: 11.25GiB\nFree memory: 11.16GiB\nW tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x37b5f60\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 3 with properties: \nname: Tesla K80\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\npciBusID 0000:0a:00.0\nTotal memory: 11.25GiB\nFree memory: 11.16GiB\nW tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x3bd1860\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 4 with properties: \nname: Tesla K80\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\npciBusID 0000:84:00.0\nTotal memory: 11.25GiB\nFree memory: 11.16GiB\nW tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x3ff0cd0\nSegmentation fault (core dumped)\n```\n", "comments": ["Ok, by reading through the discussion in [152](https://github.com/tensorflow/tensorflow/issues/152), I figured out that Tensorflow tries to grab all the GPUs it sees from the system. The SegFault probably occurs when there is not enough memory on one or more of the GPUs since Tensorflow tries to grab it anyway.\n\nThe workaround in [152](https://github.com/tensorflow/tensorflow/issues/152) is to check nvidia-smi to see which GPUs are free and set CUDA_VISIBLE_DEVICES to these GPUs. When I do this, I do not get any SegFaults error anymore and everthing seems to work fine. I just want to know if there is any way to automate this issue by polling the GPUs beforehand to determine the available ones, or a try-catch kind of script which prevents Tensorflow from segfaulting.\n", "Closing as duplicate of #152 \n"]}, {"number": 3611, "title": "Feature request: Support for non-minibatch data for intrinsic functions", "body": "Some functions in the TensorFlow standard library makes an assumption that we're always feeding minibatches. \n\nOne example is `tf.nn.softmax` which assumes a 2-D input of shape `[batch_size, num_classes]`. It would be nice to have a second API to such subroutines that work also without an assumption of a minibatch dimension in the input tensor.\n", "comments": ["Could you give some more concrete examples of exactly what you'd like to do, and clarify whether it's merely awkward or impossible?\n", "Say `out` is a vector (one dimension tensor) and I would like to define a softmax output from it called `pi`:\n\nThe way I am doing it now:\n\n```\npi = tf.squeeze(tf.nn.softmax(tf.expand_dims(out, 0)), [0], name=\"pi\")\n```\n\nThe way I would like to do it:\n\n```\npi = tf.nn.softmax(out, name=\"pi\")\n```\n", "Thanks for clarifying.   This sounds like it could be useful, but is not urgent at the present time.  So it's a good candidate for a community contribution.\n"]}, {"number": 3610, "title": "Graph optimization and other features", "body": "I've been using Theano for about 4 years now and love its flexibility due to the many available low-level ops that allow me to implement complicated and possibly non-standard models without needing to write C++/CUDA code (most of the time). In addition, I can focus almost exclusively on the model design and don't need to think much about numerical stability or suboptimal graph design leading to increased execution times because the graph optimization framework takes care of this. One common example is computing the log-loss of a categorical classifier which I can express na\u00efvely in Theano, but in most (all?) other tools including TensorFlow I need to use an op like `tf.nn.softmax_cross_entropy_with_logits`. In my opinion, the fact that I need to call these kinds of specialized ops **manually**, i.e. I need to know about them and think about when and how to use them in all kinds of situations, takes away many of the advantages of TensorFlow. Similarly, implementing model optimizers in C++/CUDA directly introduces unnecessary implementation complexity and does not take advantage of the fact that (most likely) all mathematical ops needed to specify the update formulas are already available (CPU and GPU kernels).\n\nI believe TensorFlow has a superior framework design in terms of keeping C++ and Python clearly separated and the inherent multi-device computing capabilities, but the aspects I described above make me very hesitant to use TensorFlow. Are there any plans to add a proper graph optimization framework similar to the one in Theano? And what are your reasons for implementing the model optimizers as individual kernels instead of reusing ops (like using the updates-dictionary in Theano)?\n", "comments": ["Thanks for your comments.  These are interesting issues, however design and feature issues like these are more appropriately addressed on stackoverflow, tagged 'tensorflow'.  This forum is  for bug reports and similar.  \n", "@poxvoculi This is a feature request.  He's suggesting that TensorFlow improve the graph optimizer and he provided a motivating example.  Feature requests for TensorFlow belong on Github \u2014 not StackOverflow.\n", "We do have plans for further graph optimization, and @NeilGirdhar is correct that design discussions do not belong on StackOverflow.  However, we do not have plans for fixing numerical issues with graph optimization, so I'm going to close the issue for now to keep the issue tracker focused.\n", "@girving So one thing which is not very clear for instance this - https://github.com/renmengye/tensorflow-forward-ad/issues/2 - a valid question is would tensorflow optimize away the auxiliary variables created. Or in other contexts, would it do operator-fusion. I assume that some of this (especially the second one) is part of XLA, but in general, many of this is part of the graph optimizations. Currently, the documentation talks only about pipelining data and that tensorflow have \"many fused Ops\" without explicitly listing them. This makes me at least quite uneasy on not knowing what has optimized away and what should I actually bother to write correctly myself. "]}, {"number": 3609, "title": "bug fix: the benchmark only run FLAGS.num_batches-1 times", "body": "I found that if I set num_batches = 100, then it only runs 99 batches.\nBecause i is [0, 110), and it starts to count the time when i > 10, so valid i is (10, 110), it only contains 99 elements. So i should be [10, 110), which means '> ' in line 179 should be changed with '>='. \n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n\nOn Tue, Aug 2, 2016 at 2:16 PM, googlebot notifications@github.com wrote:\n\n> Thanks for your pull request. It looks like this may be your first\n> contribution to a Google open source project. Before we can look at your\n> pull request, you'll need to sign a Contributor License Agreement (CLA).\n> \n> \ud83d\udcdd _Please visit https://cla.developers.google.com/\n> https://cla.developers.google.com/ to sign._\n> \n> Once you've signed, please reply here (e.g. I signed it!) and we'll\n> \n> ## verify. Thanks.\n> - If you've already signed a CLA, it's possible we don't have your\n>   GitHub username or you're using a different email address. Check your\n>   existing CLA data https://cla.developers.google.com/clas and verify\n>   that your email is set on your git commits\n>   https://help.github.com/articles/setting-your-email-in-git/.\n> - If you signed the CLA as a corporation, please let us know the\n>   company's name.\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/3609#issuecomment-236810190,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ADt9wwZSR_TQJFff1JGIlbZ-egbdW3C9ks5qbuDEgaJpZM4JaRtB\n> .\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "LGTM.\n\n@tensorflow-jenkins, test this please\n", "@tensorflow-jenkins test this please\n"]}, {"number": 3608, "title": "How To Upgrade Tensorflow", "body": "I have tensorflow v 0.9. How I can upgrade it without uninstall it?  \n", "comments": ["use pip --upgrade, if you want two version both exist, use conda or virtualenv\n"]}, {"number": 3607, "title": "missing doc for SyncReplicasOptimizer", "body": "doc not found in official website, description is in `tensorflow/python/training/sync_replicas_optimizer.py`\n", "comments": ["We have a new doc, so this is obsolete or soon-to-be obsolete."]}, {"number": 3606, "title": "Restore a working CMake build on Linux", "body": "Updates CMake build files as follows:\n- Adds giflib dependency.\n- Adds support for the new C++ codegen API.\n- Adds support for the `tensorflow/core/debug` libraries.\n", "comments": ["N.B. The CMake Docker build is broken, but this works locally, on a machine with protobuf correctly installed.\n", "Adding @vrv for review. Please feel free to redirect if necessary.\n", "LGTM\n"]}, {"number": 3605, "title": "scikit flow - race condition when trying to fit", "body": "I'm probably missing something obvious but I did a fresh build tonight and when trying to run the MNIST examples, every time I run them I'm getting the below errors. I have tried a few of the examples and can't seem to get around it (even when updating the depreciated bits still in the examples.) Am I missing something?\n\nCode:\n`\nfrom **future** import absolute_import\nfrom **future** import division\nfrom **future** import print_function\n\nfrom sklearn import metrics\nimport tensorflow as tf\nfrom tensorflow.contrib import learn\nimport numpy as np\n### Download and load MNIST data.\n\nmnist = learn.datasets.load_dataset('mnist')\ny = np.array(mnist.train.labels, dtype='int32')\n### Linear classifier.\n\nfeature_columns = learn.infer_real_valued_columns_from_input(mnist.train.images)\nclassifier = learn.TensorFlowLinearClassifier(\n    feature_columns=feature_columns, n_classes=10, batch_size=100, steps=1000,\n    learning_rate=0.01)\nclassifier.fit(mnist.train.images,y)\nscore = metrics.accuracy_score(\n    mnist.test.labels, classifier.predict(mnist.test.images))\nprint('Accuracy: {0:f}'.format(score))\n`\n\nError:\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:839] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 750M, pci bus id: 0000:07:00.0)\nE tensorflow/c/c_api.cc:485] WhereOp: Race condition between counting the number of true elements and writing them.  When counting, saw 1287 elements; but when writing their indices, saw 7 elements.\n     [[Node: report_uninitialized_variables/Where = Where[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](report_uninitialized_variables/Reshape_1)]]\n     [[Node: report_uninitialized_variables/Where/_28 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_30_report_uninitialized_variables/Where\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n", "comments": ["Turns out my environment had a stale Jupyter image and after updating it's fine. The code worked as a script but threw the race condition in notebooks. Sorry\n"]}, {"number": 3604, "title": "Added esn cell", "body": "I wrote an Echo State Network cell for my personal need, hope that this can be useful to someone else. I tried to be compliant with the project coding style, let me know if I missed something\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "About the CLA: I've signed it as a corporation (Biobeats) and it result in the CLAs page. Do I need to edit my commits in order to have the company email which is in the CLA google group ? I thought it was enough to have it in the github account.\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "Adding @ebrevdo for review. \n", "Hi, this is a good contribution to tf.contrib.rnn.  can you move the class there?  Also please add better documentation including literature reference in the doc string, and use contrib.layers instead of _linear.  Do you have any unit tests?\n", "Moved to tf.contrib. As soon as I can I'll improve the doc (sorry but I'm doing this in the spare time after work).\nI've written no unit testing, I just tested it on MackeyGlass dataset. I'm not sure about how to write effective unit testing since it's mostly based on randomness, however if it's needed I can try to write something. \n", "Here's a suggestion for now as a smoke test:\n1. create inputs with np.random (use a seed) and use a non-random\n   initializer for the variables\n2. create a small ESA cell and run it forward a few time steps & save to\n   file the output & final state numbers\n3. write your test to ensure that the same random seeds & deterministic\n   initializer lead to the exact same output as you had before (use\n   self.assertAllClose with the tensor values you saved from step #2)\n\nthis will ensure that future changes to ESA cell do not break its numeric\nbehavior.\n\nOn Wed, Aug 3, 2016 at 1:53 PM, Michele Colombo notifications@github.com\nwrote:\n\n> Moved to tf.contrib. As soon as I can I'll improve the doc (sorry but I'm\n> doing this in the spare time after work).\n> I've written no unit testing, I just tested it on MackeyGlass dataset. I'm\n> not sure about how to write effective unit testing since it's mostly based\n> on randomness, however if it's needed I can try to write something.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/3604#issuecomment-237369750,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABtim1RCzxxzxJk20rP5y0Koote6Mu77ks5qcP_NgaJpZM4JaET2\n> .\n", "So I improved the docs and added a smoke test using tf.test.TestCase, hope everything's allright :)\n", "Will likely get to this on Monday.\n\nOn Aug 5, 2016 7:15 AM, \"Michele Colombo\" notifications@github.com wrote:\n\n> So I improved the docs and added a smoke test using tf.test.TestCase, hope\n> everything's allright :)\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/3604#issuecomment-237861610,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABtimwXSbk1sI8iXMe5ULYnySMtE4FHrks5qc0V_gaJpZM4JaET2\n> .\n", "@ebrevdo when do you think you'll be able to review this?\n", "@ebrevdo PTAL\n", "@tensorflow-jenkins Test this please\n", "After looking at the contribution guidelines, I realized that without an internal maintainer for this architecture, we cannot accept this type of submission. It is probably a better fit in its own dedicated repository.\n", "@vrv, can you confirm that my understanding is correct?\n", "Yeah, this is a cool contribution, but best for an external repository -- if it became critical for state-of-the-art models, we'd probably want to integrate it then.  In the meantime, feel free to point us at where you are maintaining this and we can link to it somewhere!\n", "I took the contribution out of TF and put in a [repository](https://github.com/m-colombo/Tensorflow-EchoStateNetwork) by it self. \n"]}, {"number": 3603, "title": "RC 0.10 3X Slower than 0.9 and Error Compiling From Source Under Certain Conditions", "body": "This issue is a follow-up to [this posting](http://stackoverflow.com/questions/38704095/tensorflow-rc-0-10-3x-slower-than-0-9) on stack overflow. As noted, the 0.10 version is ~3x slower than version 0.9 for a particular training script I am using. The same slow-down is observed when using the pip version with CuDNN4 or with a version compiled from source and CuDNN 5.1.\n\nI'm not sure what information about the training script would help. It is a fairly complex script that is training a network for object detection using methods similar to YOLO and SSD. It won't be possible to post the entire set of code, but if there is a way to isolate the source of the delay I may be able to modify it and post that portion.\n\nWhile trying to get insight into the source of the slow-down I also noted that I wasn't able to compile from source using CuDNN4 as noted in the SO posting. This is a secondary issue, but may also warrant investigation.\n", "comments": ["Could you produce a timeline and share that?  \n\nI think this might be the current best how-to on how to produce timelines :) if anyone knows of a better one please share that:\nhttps://github.com/tensorflow/tensorflow/issues/1824#issuecomment-225754659\n\nI think that it's going to be hard to help without seeing your code. Would you be able to post your graph protobuf? \n", "@rryan I've attached the timelines named appropriately. Each was generated with the identical code running under either tf0.9 or tf0.10rc. The elapsed times for 100 training steps were 4:20 and 14:36, respectively. \n[timelines.tar.gz](https://github.com/tensorflow/tensorflow/files/397146/timelines.tar.gz)\nFor some reason, the timing routine gave repeated error messages when running under 0.9 but not for 0.10. The 0.9 message was: \n\n> W tensorflow/core/common_runtime/gpu/gpu_tracer.cc:513] Unhandled API Callback for 2 41\n\nI've not used the timing functionality before. Let me know if I've done something incorrectly.\n\nAlso, what's the best way to generate a graph protobuf?\n\nThanks\n", "@rryan: Not sure if it matters but I've attached two other timelines taken in loops in which summary operations are not being performed\n[timelines2.tar.gz](https://github.com/tensorflow/tensorflow/files/397509/timelines2.tar.gz)\n", "@rob-rowe -- thanks! The easiest way to get a graph proto is probably to insert some code into your training script to write the graph to a file.\n\nOnce you're done building your graph, right where you would start your session (maybe with a supervisor, etc.) -- you could do this:\n\n``` python\n# If you don't already have a handle to your graph:\ng = tf.get_default_graph() \n\nwith open('/tmp/graph.pbtxt', 'w') as f:\n  f.write(str(g.as_graph_def()))\n```\n", "One thing that sticks out from the traces are these Sum ops associated with your batch norms:\n- net_cnn/conv1/cbn/moments/moments/mean_ss\n- net_cnn/conv1/cbn/moments/moments/var_ss\n- net_cnn/conv2/cbn/moments/moments/mean_ss\n- net_cnn/conv2/cbn/moments/moments/var_ss\n\nThey take a handful of millis in 0.9 but up to 700ms in 0.10. I would potentially chalk that up to a tracing noise (e.g. your Sum ops could waiting on some dependency that isn't ready yet -- hard to know w/o seeing the graph) but in your second trace it looks like every Sum op is taking much longer than normal. \n\n@prb12 I'm not super used to interpreting Chrome tracing timelines -- any gotchas to be aware of when interpreting this?\n\n@rmlarsen Are you aware of any change to Eigen between 0.9 and 0.10 that could cause Sum (@rob-rowe -- is this float32? float16?) to do this with a Tesla K40c (mentioned in the Stack Overflow post)?\n", "@rryan --\ngraph proto attached. \n[graph.pbtxt.tar.gz](https://github.com/tensorflow/tensorflow/files/397621/graph.pbtxt.tar.gz)\nThe batch norm variables you mention are all default data types (float32)\n", "@rryan Nop - these traces make it pretty clear that there is a perf regression in the Sum reduction kernel on GPU.  I think it would be useful to compare what CUDA launch parameters are being used for the reduction.  The quickest way to do that is to run the program under nvprof as follows:\n\n`nvprof --print-gpu-trace program args....`  \nor \n`nvprof -o /tmp/nvprof.out program args...`  to produce a trace which can be loaded into `nvvp`\n\nI think that the Eigen `FullReductionKernel` was probably changed btw 0.9 and 0.10.   \n", "@bsteiner may know more about this.\n", "@rryan, @prb12  -- I've attached nvprof.out files for each of the two cases. I ran the profiling for just 5 batches to keep the files from getting too large but they're still too big to upload here. Please let me know if [this link](https://1drv.ms/u/s!AnX4PArwPRXWg9dmWvZieqWqQqCQbw) doesn't work\n", "Unfortunately both those files seem to be corrupted - it looks like the process didn't exit cleanly.  Did you Ctrl-C ?  (I think that to get a clean nvprof trace you need to exit gracefully)\n", "Odd, I did let the process end on it's own. I used your nvprof - o method and waited until the cursor returned, which was a multisecond delay after the training finished which I assume was file IO. The raw files here seem to be able to be consumed by nvprof -i I think (see attached). Perhaps compression failed? I uploaded the files uncompressed to google drive at [this link](https://drive.google.com/open?id=0BwIAwD4S8krbZ1VDU0NtOVRGMjg). Please let me know if this doesn't work and if so perhaps an alternative method. Thanks\n[nvprof_out_tf9.txt](https://github.com/tensorflow/tensorflow/files/397882/nvprof_out_tf9.txt)\n[nvprof_out_tf10.txt](https://github.com/tensorflow/tensorflow/files/397883/nvprof_out_tf10.txt)\n", "I've also just rerun both cases and confirmed they seem to be ending cleanly: \n\n> ==28091==Generated result file: /tmp/nvprof_tf0.10.0rc0_v2.out\n\nBoth of these 'v2' files are in the same google drive folder as previous\n", "Sorry -- the tf0.10.0rc0_v2 file is wrong (I didn't switch TF versions) I'll re-upload momentarily\n", "nvprof_tf0.10.0rc0_v2.out is now correct\n", "Just chiming in to say that I also experience heavy slowdowns using TF 0.10 RC0. In My case, the slowdown is even more severe: ~10x when using a ResNet-like architecture, on Python 3.5 using cuDNN 4 and CUDA 7.5.\n", "Same here. 10X slowdown\n", "I can confirm that the SumOp kernel is much slower in 0.10.0 than it used to be in 0.9.0 on an Nvidia Titan X.\n", "@rob-rowe Thanks for the nvprof output - it looks like there are two common shapes of Sum reduction ops in your trace and one of them is being evaluated very differently by Eigen in 0.10 resulting in much less GPU parallelism and about a 60x slowdown!  (3.3ms -> 178ms)\n\nIt would help us to make a quick repro if we knew the shapes of the operands to these ops...  \nDo you happen to have this information to hand?  If not, we could either get if from the GraphDef or the StepStats proto.\n\nYou can save a graphdef with shape annotations using code like this:\n`tf.train.write_graph(g.as_graph_def(add_shapes=True),  '/tmp', 'graphdef.pbtxt')`\n\n(Since you have timelines, you already have the code to capture the stepstats proto - this can be written to a .pbtxt file.  It contains the runtime shapes of all of the Tensors.) \n", "@prb12 the graphdef with shape annotations is attached\n[graph_with_shapes.pbtxt.tar.gz](https://github.com/tensorflow/tensorflow/files/400073/graph_with_shapes.pbtxt.tar.gz)\n", "@prb12 here is the runtime metadata jic that is helpful\n\n[metadata.pbtxt.tar.gz](https://github.com/tensorflow/tensorflow/files/400094/metadata.pbtxt.tar.gz)\n", "I think I found the source of the problem. A fix is on the way. I'll update this thread once the fix is merged.\n", "@rob-rowe Thanks for the diagnostics.\n\nFor future reference, it looks like the first example of the slow Sum is this one:\n\n```\nnode {\n  name: \"net_cnn/conv1/cbn/moments/moments/mean_ss\"\n  op: \"Sum\"\n  input: \"net_cnn/conv1/Conv2D\"\n  input: \"net_cnn/conv1/cbn/moments/moments/mean_ss/reduction_indices\"\n```\n\nWhere reduction indices are [0,1,2] and the first input has shape [100, 127, 127, 30]\n", "@prb12 A convolutional batch norm factor in the first layer --- yeah, I can see why that would cause a major slow down if the sum op is slow! I'm looking forward to the fix. Thanks\n", "@benoitsteiner any updates on this?\n", "I have just started one last round of testing. If everything comes back clean this time I'll be able to submit the fix first tomorrow morning.\n", "The performance regression should have been fixed by https://github.com/tensorflow/tensorflow/commit/0e12a0b0dbcf17da880402bc01d8511aa4568cda. Please reopen if you still find that RC 0.10 is slower than 0.9 on your GPU.\n", "@benoitsteiner  is the fix be picked into branch r0.10?\n", "https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/core/kernels/cwise_ops.h the fix doesn't seem to be in 0.10 branch.\n", "It should be now.\n"]}, {"number": 3602, "title": "Changed visibility of protos_cc to public", "body": "The only tensorflow package that is private and preventing us from creating custom kernels (with a custom set of operations), is the protos_cc. If we make this public, we can make our own kernels outside of the tensorflow repo, which means for Android/iOS we can make compact libraries with just the right amount of kernel ops.\n\nThere seems to be another approach which is `SELECTIVE_REGISTRATION`, but firstly according to #3549 no one has managed to provide a working example for it (tried myself but was not able to yet), and it also seems to be Android only. For the meantime, it seems the best method is to define our own kernel and therefore our own tensorflow_lib bazel files, but to do this we need to changes protos_cc to public.\n", "comments": ["Can one of the admins verify this patch?\n", "Adding @josh11b to review this change.\n", "Sorry for the delay. `//tensorflow/core:framework_headers_lib` is already public and should give you all the headers you need to build a custom op. Is that not working for some reason?\n", "The use case here is not for building a custom op, rather it is a building a custom kernel, containing a specific collection of ops. The current kernels all seem to depend on `protos_cc`.\n", "My previous question applies equally to custom kernels. By current kernels, if you mean kernels that are part of core, then sure, all of them have a `bazel` dependency of `protos_cc`. But that doesn't mean they are really using any from `protos_cc`. Custom kernels are supposed to build with just the headers in `framework_headers_lib`. Have you tried building with just that dependency?\n", "But isn't `framework_headers_lib` just a collection of headers? Right now I'm including also all the core tensorflow code for example from `//tensorflow/core:android_tensorflow_lib_lite`.\n\nHere's my example build file, do you mean that I can replace all the deps with just `framework_headers_lib`?\n\n```\ncc_library(\n    name = \"myapp_android_tensorflow_lib\",\n    srcs = if_android([\"@org_tensorflow//tensorflow/core:android_op_registrations_and_gradients\"]),\n    copts = tf_copts(),\n    visibility = [\"//visibility:public\"],\n    deps = [\n        \"@org_tensorflow//tensorflow/core:android_tensorflow_lib_lite\",\n        \"@org_tensorflow//tensorflow/core:protos_cc\",\n        \"@org_tensorflow//third_party/eigen3\",\n        \":myapp_android_tensorflow_kernels\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"myapp_android_tensorflow_kernels\",\n    srcs = select({\n        \"@org_tensorflow//tensorflow:android\": [\n            \":android_myapp_ops\",\n            \"@org_tensorflow//tensorflow/core/kernels:android_core_ops\",\n            \"@org_tensorflow//tensorflow/core/kernels:android_extended_ops\",\n        ],\n        \"//conditions:default\": [],\n    }),\n    copts = tf_copts(),\n    visibility = [\"//visibility:public\"],\n    deps = [\n        \"@org_tensorflow//tensorflow/core:android_tensorflow_lib_lite\",\n        \"@org_tensorflow//tensorflow/core:protos_cc\",\n        \"@org_tensorflow//third_party/eigen3\",\n    ],\n    alwayslink = 1,\n)\n```\n", "Btw, this is related to issue #3549 which is about how to correctly build a custom collection of ops right now.\n", "@lingz Yes, you would only need the headers to build your custom collection of ops and kernels.\n", "@lingz Any update on this?\n", "Yep so I tried and you can replace everything except android_tf_lib_lite with dramework_headers_lib.\n", "@lingz Could you show me the complete code about how to use SELECTIVE_REGISTRATION feature or how to correctly build a custom collection of ops ? \n", "I was not able to make it work. I would like to see a working example also.\n\nOn Mon, Sep 26, 2016, 12:17 PM F notifications@github.com wrote:\n\n> @lingz https://github.com/lingz Could you show me the complete code\n> about how to use SELECTIVE_REGISTRATION feature?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/3602#issuecomment-249506694,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ADAFzTIaEyGfqtO68gubTyfX5vVhvdNdks5qt39-gaJpZM4JZ9Bo\n> .\n", "@keveman I tried to build a native library with just the headers in `framework_headers_lib`. However, the following error occurs:\n\n> bazel-out/arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/genfiles/tensorflow/core/framework/graph.pb.h:9:42: fatal error: google/protobuf/stubs/common.h: No such file or directory\n>  #include <google/protobuf/stubs/common.h>\n>                                          ^\n> compilation terminated.\n\nCould you give an example about how to use SELECTIVE_REGISTRATION feature or how to correctly build a custom collection of ops ?\n"]}, {"number": 3601, "title": "Tensorflow basic_rnn_seq2seq TypeError: Expected int32, got -0.1 of type 'float' instead", "body": "Original issue here: http://stackoverflow.com/q/38695086/2082009\n", "comments": ["This question is appropriate for StackOverflow, not for this forum, which is for bugs and installation issues.\n"]}, {"number": 3600, "title": "failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED", "body": "With the current master branch I receive the following error 20% of the time when training an RNN.\n\n> I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \n> name: GeForce GTX TITAN X\n> major: 5 minor: 2 memoryClockRate (GHz) 1.076\n> pciBusID 0000:83:00.0\n> Total memory: 12.00GiB\n> Free memory: 11.86GiB\n> I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \n> I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \n> I tensorflow/core/common_runtime/gpu/gpu_device.cc:843] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:83:00.0)\n> E tensorflow/stream_executor/cuda/cuda_blas.cc:367] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n> W tensorflow/stream_executor/stream.cc:1334] attempting to perform BLAS operation using StreamExecutor without BLAS support\n> I tensorflow/stream_executor/stream.cc:1282] stream 0x76b6890 did not wait for stream: 0x76b5d60\n> I tensorflow/stream_executor/stream.cc:3732] stream 0x76b6890 did not memcpy host-to-device; source: 0x204570900\n> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\n> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\n> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\n> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\n> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\n> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\n> I tensorflow/stream_executor/stream.cc:3732] stream 0x76b6890 did not memcpy host-to-device; source: 0x204570b00\n> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\n> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\n> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\n> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\n> W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12\n>          [[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]\n> F tensorflow/core/common_runtime/gpu/gpu_util.cc:343] CPU->GPU Memcpy failed\n### Environment info\n\nScientific Linux 7\ncuda 7.5.18\ncudnn 5.0.5\n\n$ bazel version\n....\nBuild label: 0.3.0\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Fri Jun 10 11:38:23 2016 (1465558703)\nBuild timestamp: 1465558703\nBuild timestamp as int: 1465558703\n$ git rev-parse HEAD\n88d9bc16d6a16e5b660cda548b74944f27ddcd1b\n\n$ nvidia-smi -L\nGPU 0: GeForce GTX TITAN X\n", "comments": ["Thanks for the report.  Our supported OS's unfortunately do not include yours.  We have verified support for cudnn 4, but I'm not aware of whether cudnn 5 is supported.  If possible, you might try running in docker, for a better supported version.\n\nYou say you see the error about 20% of the time; have you noticed correspondence of failures with anything else, like concurrent use of the GPU by another application, or delay since last invocation? \n\nI'm cc'ing someone else who may have more experience with this problem.\n@zheng-xq \n", "@mccajm, Cudnn V5 is definitely supported. Your specific problem comes from this line:\n\n> > E tensorflow/stream_executor/cuda/cuda_blas.cc:367] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n\nThis seems to indicate that the call to cublasCreate_v2 has failed. Please check the Cuda and Cublas installation on your machine. Also adding @jhen, the owner of stream-executor, in case he has more comments. \n\nPlease try the simple matrixMulCUBLAS that comes with the Cuda SDK, and see if the Cuda installation itself works well. \n", "Automatically closing due to lack of recent activity. Please reopen when further information becomes available.\n", "I am getting the following error, i am using using cuda-7.5 sdk, cudnn 5.1.3, tf 0.12.1, \r\n![image](https://cloud.githubusercontent.com/assets/8722074/23991200/7f3b3514-0a5e-11e7-9f16-4cf4ad36f607.png)\r\n", "@zheng-xq @aselle  I am facing this problem - \r\n**E tensorflow/stream_executor/cuda/cuda_blas.cc:367] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED**\r\n\r\nTill now I have found 5-6 tensorflow issues with this same problem but no reasonable solution/fix I was able to find in those issues.  It will be helpful if someone can post the link to the solution of this issue. \r\nThank You.\r\n\r\n**EDIT** I solved this issue by uninstalling tensorflow 1.4 and installing tensorflow 1.2. Earlier I had Cuda 8.0.61 with Cudnn 7 and python 2.7 on ubuntu 16.04.\r\nsudo pip install tensorflow-gpu==1.2", "I also faced the problem just now. I fixed it by adding \"sudo\" before the command. :P\r\n\r\nEDIT\uff1asudo rm -rf ~/.nv/ "]}, {"number": 3599, "title": "Use Retrained categories in Android Camera Demo", "body": "GitHub issues are for bugs / installation problems / feature requests.  \nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\n\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\n### Environment info\n\nOperating System: Docker on Windows\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`)\n2. The output of `bazel version`\n### Steps to reproduce\n1. Successfully retrain new data with Docker. Get the two retrained files retrained_graph.pb and retrained_labels.txt\n   https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/index.html?index=..%2F..%2Findex#5\n2. Try to install Bazel on windows but failed. But I found an Android Demo which doesn't need Bazel. This one works well on Windows. It can recognize images into 1000 classes provided by ImageNet in an Android real-time camera.\n   https://github.com/miyosuda/TensorFlowAndroidDemo\n### What have you tried?\n\nReference\uff1b https://github.com/tensorflow/tensorflow/issues/1269\nBased on the suggestions, I tried the following things:\n1.Find the coded_stream.h in the google/protobuf section of your tensorflow build and modify the 64 to 256 in the following line:\nstatic const int kDefaultTotalBytesLimit = 64 << 20; // Change the 64 to 256 MB\n2.Modify only the input_size to 299 and the image_mean to 128 in the TensorflowImageListener.java\n3.Go to tensorflow_jni.cc in the android demo and modify as follows:\n\n```\n  input_tensor_mapped(0, i, j, 0) =\n      (static_cast<float>(src->red) - g_image_mean)/g_image_mean;\n  input_tensor_mapped(0, i, j, 1) =\n      (static_cast<float>(src->green) - g_image_mean)/g_image_mean;\n  input_tensor_mapped(0, i, j, 2) =\n      (static_cast<float>(src->blue) - g_image_mean)/g_image_mean;\n  ++src;\n```\n\nstd::vector<std::pair<std::string, tensorflow::Tensor> > input_tensors(\n      {{\"Mul\", input_tensor}});\n\nstd::vectorstd::string output_names({\"softmax\"});\n4.Do the following changes in TensorflowImageListerner.java:\n private static final String MODEL_FILE = \"file:///android_asset/retrained_graph.pb\";\n  private static final String LABEL_FILE =\n      \"file:///android_asset/retrained_labels.txt\";\n5. Build the android demo \n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n08-01 17:36:50.015 14978-15121/org.tensorflow.tensorflowdemo A/native: jni_utils.cc:107 Check failed: message->ParseFromZeroCopyStream(&adaptor) \n08-01 17:36:50.015 14978-15121/org.tensorflow.tensorflowdemo A/libc: Fatal signal 6 (SIGABRT), code -6 in tid 15121 (ImageListener)\n\nI know this is a problem due to the incompatible variables of Inception v3 and Inception 5h. The Android Demo model I use is Inception 5h, But the model I used to train my new data is Inception 3v.  I've tried to edit the variables mentioned here: https://github.com/tensorflow/tensorflow/issues/1269.\nBut I still get the same errors. Anyone could help me explain how to adapt my new trained data running in the Android Demo?\n", "comments": ["This sort of question is better asked on StackOverflow.  This forum is for bug reports and similar.  Please ask your question there, tagging with 'tensorflow'.   \n\nIf you're having trouble with bazel, you might try [tensorflow makefile](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile).\n"]}, {"number": 3598, "title": "gather_nd doesnt work for batched slicing,(even for documented examples)", "body": "gather_nd doesn't work for batched slicing\nSteps to Reproduce\n\nRun the following code\n\n``` python\nimport tensorflow as tf\ncons_indices=tf.constant([[[1]], [[0]]])\nbatch=tf.constant([['a', 'b'], ['c', 'd']])\ngathered=tf.gather_nd(batch,cons_indices)\nsess = tf.Session()\nresult = sess.run(gathered)\nprint(result)\nsess.close()\n```\n\nAlways gives an error regarding incompatible dimensions.\n\nEither the documentation needs to be updated to indicate proper argument format or function implementation is buggy\n", "comments": ["When I run your program I get:\n\n[[['c' 'd']] [['a' 'b']]]\n\nwhich I believe is correct.  Could you provide more information on your version and installation, and the exact error message?\n", "Closing due to lack of response.  We are happy to reopen if more details emerge!\n", "In TFv1.0 it tf.gather_nd seems to produce errors for same cases. \r\nCheckout [here](http://stackoverflow.com/questions/43007410/tensorflow-unexpected-tf-gather-nd-behaviour-bug) \r\nFocus on the fact that the error message is in contradiction with both documentation and itself."]}, {"number": 3597, "title": "Use tf.contrib.layers.conv2d instead of learn.ops.conv2d which is dep\u2026", "body": "Use tf.contrib.layers.conv2d instead of learn.ops.conv2d which is deprecated and the code will be removed after 2016-08-15.\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins Test this please\n"]}, {"number": 3596, "title": "Unable to run the tensorflow/tensorflow/examples/skflow/multipul_gpu.py ", "body": "Hi, \n\nwhen i run the tensorflow/tensorflow/examples/skflow/multipul_gpu.py example, I got the following error. Any helps would be great!\n\n```\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 723, in _do_run\n    target_list, options, run_metadata)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 743, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'save/ShardedFilename_2': Could not satisfy explicit device specification '/device:GPU:2' be$\nColocation Debug Info:\nColocation group had the following types and devices:\nIdentity: CPU\nShardedFilename: CPU\n         [[Node: save/ShardedFilename_2 = ShardedFilename[_device=\"/device:GPU:2\"](save/Const, save/ShardedFilename_2/shard, save/num_shards)]]\nCaused by op u'save/ShardedFilename_2', defined at:\n  File \"multiple_gpu.py\", line 39, in <module>\n    classifier.fit(X_train, y_train)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.py\", line 166, in fit\n    monitors=monitors)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 577, in _train_model\n    max_steps=max_steps)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 232, in train\n    max_steps)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 309, in _train_internal\n    saver=_make_saver(graph, keep_checkpoint_max),\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 95, in _make_saver\n    max_to_keep=keep_checkpoint_max)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 854, in __init__\n    restore_sequentially=restore_sequentially)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 512, in build\n    save_tensor = self._AddShardedSaveOps(filename_tensor, per_device)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 232, in _AddShardedSaveOps\n    filename_tensor, shard, num_shards_tensor)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 200, in sharded_filename\n    return gen_io_ops._sharded_filename(filename_tensor, shard, num_shards)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 460, in _sharded_filename\n    shard=shard, num_shards=num_shards, name=name)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2298, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1232, in __init__\n    self._traceback = _extract_stack()\n\n```\n### Environment info\n\nOperating System:  Ubuntu 16.04\n\nInstalled version of CUDA and cuDNN: CUDA 8.0, cuDNN 5\n\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\n```\n/usr/local/cuda/lib64/libcudadevrt.a\n/usr/local/cuda/lib64/libcudart.so\n/usr/local/cuda/lib64/libcudart.so.8.0\n/usr/local/cuda/lib64/libcudart.so.8.0.27\n/usr/local/cuda/lib64/libcudart_static.a\n/usr/local/cuda/lib64/libcudnn.so\n/usr/local/cuda/lib64/libcudnn.so.5\n/usr/local/cuda/lib64/libcudnn.so.5.0.5\n```\n\nIf installed from sources, provide the commit hash:\ne95f4e760c6b6713b6b686ebeff9a1586a5831dd\n### Steps to reproduce\n1. run multipul_gpu.py\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n", "comments": ["The error message says:\ntensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'save/ShardedFilename_2': Could not satisfy explicit device specification '/device:GPU:2' be$\n\nThat is, the graph produced for the model assigns a particular Op ('save/ShardedFilename_2') to GPU:2.  GPUs are indexed starting with 0.  Do you actually have 3 GPUs on the machine you using?  \n", "@poxvoculi , \nYes indeed, here is my nvidia-smi out put\n\n```\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 367.35                 Driver Version: 367.35                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 1080    Off  | 0000:05:00.0      On |                  N/A |\n| 40%   61C    P2    40W / 180W |    198MiB /  8110MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  GeForce GTX 1080    Off  | 0000:06:00.0     Off |                  N/A |\n| 39%   59C    P2    40W / 180W |    116MiB /  8113MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   2  GeForce GTX 1080    Off  | 0000:09:00.0     Off |                  N/A |\n| 36%   55C    P2    39W / 180W |   7772MiB /  8113MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n```\n", "shouldn't tensorflow use the first gpu:0 as default? \nalso, I can run scripts with only one GPU.\n", "Yes, typically TF will start using GPUs from 0, in order, only as many as you tell it to.  Do you have some more complete logs output?  I'm less familiar with the open source logs output, but the internal Google version will log the available GPUs, their IDs and attributes prior to attempting to use them.  Do you see anything like that in your logs?  Does it successfully assign any nodes to GPU0 first?   If not, can you post the command you're using to invoke examples/skflow/multipul_gpu.py and any modifications you may have made?\n", "yes:)\nthe command simply (in examples/skflow/ directory):\n\n```\n python multiple_gpu.py \n```\n\nthe full output is \n\n```\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\nWARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpTKqGxV\nWARNING:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(4)]), is_sparse=False)\nWARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(3)]), is_sparse=False)\nWARNING:tensorflow:dnn (from tensorflow.contrib.learn.python.learn.ops.dnn_ops) is deprecated and will be removed after 2016-08-01.\nInstructions for updating:\nPlease use tf.contrib.layers.stack instead.\nWARNING:tensorflow:learn.ops.dnn is deprecated,     please use contrib.layers.dnn.\nWARNING:tensorflow:dropout (from tensorflow.contrib.learn.python.learn.ops.dropout_ops) is deprecated and will be removed after 2016-08-15.\nInstructions for updating:\nPlease use tf.contrib.layers.dropout instead.\nWARNING:tensorflow:dropout (from tensorflow.contrib.learn.python.learn.ops.dropout_ops) is deprecated and will be removed after 2016-08-15.\nInstructions for updating:\nPlease use tf.contrib.layers.dropout instead.\nWARNING:tensorflow:dropout (from tensorflow.contrib.learn.python.learn.ops.dropout_ops) is deprecated and will be removed after 2016-08-15.\nInstructions for updating:\nPlease use tf.contrib.layers.dropout instead.\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GeForce GTX 1080\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335\npciBusID 0000:09:00.0\nTotal memory: 7.92GiB\nFree memory: 7.81GiB\nW tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x309c420\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: \nname: GeForce GTX 1080\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335\npciBusID 0000:06:00.0\nTotal memory: 7.92GiB\nFree memory: 7.81GiB\nW tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x36c9920\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 2 with properties: \nname: GeForce GTX 1080\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335\npciBusID 0000:05:00.0\nTotal memory: 7.92GiB\nFree memory: 7.73GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 2 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y Y Y \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   Y Y Y \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 2:   Y Y Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:09:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 1080, pci bus id: 0000:06:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:2) -> (device: 2, name: GeForce GTX 1080, pci bus id: 0000:05:00.0)\nWARNING:tensorflow:dnn (from tensorflow.contrib.learn.python.learn.ops.dnn_ops) is deprecated and will be removed after 2016-08-01.\nInstructions for updating:\nPlease use tf.contrib.layers.stack instead.\nWARNING:tensorflow:learn.ops.dnn is deprecated,     please use contrib.layers.dnn.\nWARNING:tensorflow:dropout (from tensorflow.contrib.learn.python.learn.ops.dropout_ops) is deprecated and will be removed after 2016-08-15.\nInstructions for updating:\nPlease use tf.contrib.layers.dropout instead.\nWARNING:tensorflow:dropout (from tensorflow.contrib.learn.python.learn.ops.dropout_ops) is deprecated and will be removed after 2016-08-15.\nInstructions for updating:\nPlease use tf.contrib.layers.dropout instead.\nWARNING:tensorflow:dropout (from tensorflow.contrib.learn.python.learn.ops.dropout_ops) is deprecated and will be removed after 2016-08-15.\nInstructions for updating:\nPlease use tf.contrib.layers.dropout instead.\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:09:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 1080, pci bus id: 0000:06:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:2) -> (device: 2, name: GeForce GTX 1080, pci bus id: 0000:05:00.0)\nE tensorflow/core/client/tensor_c_api.cc:485] Cannot assign a device to node 'save/ShardedFilename_2': Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and devices: \nIdentity: CPU \nShardedFilename: CPU \n     [[Node: save/ShardedFilename_2 = ShardedFilename[_device=\"/device:GPU:2\"](save/Const, save/ShardedFilename_2/shard, save/num_shards)]]\nTraceback (most recent call last):\n  File \"multiple_gpu.py\", line 40, in <module>\n    score = metrics.accuracy_score(y_test, classifier.predict(X_test))\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.py\", line 243, in predict\n    return self._predict(x, axis=axis, batch_size=batch_size)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.py\", line 217, in _predict\n    feed_fn=predict_data_feeder.get_feed_dict_fn())\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 686, in _infer_model\n    restore_checkpoint_path=checkpoint_path)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 680, in run_feeds\n    _restore_from_checkpoint(session, g, restore_checkpoint_path)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 106, in _restore_from_checkpoint\n    saver.restore(session, checkpoint_path)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1114, in restore\n    {self.saver_def.filename_tensor_name: save_path})\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 382, in run\n    run_metadata_ptr)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 655, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 723, in _do_run\n    target_list, options, run_metadata)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 743, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'save/ShardedFilename_2': Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and devices: \nIdentity: CPU \nShardedFilename: CPU \n     [[Node: save/ShardedFilename_2 = ShardedFilename[_device=\"/device:GPU:2\"](save/Const, save/ShardedFilename_2/shard, save/num_shards)]]\nCaused by op u'save/ShardedFilename_2', defined at:\n  File \"multiple_gpu.py\", line 40, in <module>\n    score = metrics.accuracy_score(y_test, classifier.predict(X_test))\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.py\", line 243, in predict\n    return self._predict(x, axis=axis, batch_size=batch_size)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.py\", line 217, in _predict\n    feed_fn=predict_data_feeder.get_feed_dict_fn())\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 686, in _infer_model\n    restore_checkpoint_path=checkpoint_path)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 680, in run_feeds\n    _restore_from_checkpoint(session, g, restore_checkpoint_path)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 104, in _restore_from_checkpoint\n    saver = saver or _make_saver(graph)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 96, in _make_saver\n    max_to_keep=keep_checkpoint_max)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 854, in __init__\n    restore_sequentially=restore_sequentially)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 512, in build\n    save_tensor = self._AddShardedSaveOps(filename_tensor, per_device)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 232, in _AddShardedSaveOps\n    filename_tensor, shard, num_shards_tensor)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 200, in sharded_filename\n    return gen_io_ops._sharded_filename(filename_tensor, shard, num_shards)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 460, in _sharded_filename\n    shard=shard, num_shards=num_shards, name=name)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2298, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1232, in __init__\n    self._traceback = _extract_stack()\n```\n\nTo get more log_device_placement info. I first changed a few lines around line:318 in file\n\n```\n~/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\n```\n\nto \n\n```\n  config = tf.ConfigProto(allow_soft_placement = True, log_device_placement=False)\n  session = supervisor.PrepareSession(master=supervisor_master,\n                                      start_standard_services=True, config=config)\n```\n\nthen, I ran the multipul_gpu.py in the same way. I got the following message:\n(sorry..its really long.)\n\n```\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\nWARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpgWxaA6\nWARNING:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(4)]), is_sparse=False)\nWARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(3)]), is_sparse=False)\nWARNING:tensorflow:dnn (from tensorflow.contrib.learn.python.learn.ops.dnn_ops) is deprecated and will be removed after 2016-08-01.\nInstructions for updating:\nPlease use tf.contrib.layers.stack instead.\nWARNING:tensorflow:learn.ops.dnn is deprecated,     please use contrib.layers.dnn.\nWARNING:tensorflow:dropout (from tensorflow.contrib.learn.python.learn.ops.dropout_ops) is deprecated and will be removed after 2016-08-15.\nInstructions for updating:\nPlease use tf.contrib.layers.dropout instead.\nWARNING:tensorflow:dropout (from tensorflow.contrib.learn.python.learn.ops.dropout_ops) is deprecated and will be removed after 2016-08-15.\nInstructions for updating:\nPlease use tf.contrib.layers.dropout instead.\nWARNING:tensorflow:dropout (from tensorflow.contrib.learn.python.learn.ops.dropout_ops) is deprecated and will be removed after 2016-08-15.\nInstructions for updating:\nPlease use tf.contrib.layers.dropout instead.\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GeForce GTX 1080\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335\npciBusID 0000:09:00.0\nTotal memory: 7.92GiB\nFree memory: 7.81GiB\nW tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x3eb04e0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: \nname: GeForce GTX 1080\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335\npciBusID 0000:06:00.0\nTotal memory: 7.92GiB\nFree memory: 7.81GiB\nW tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x44dd520\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 2 with properties: \nname: GeForce GTX 1080\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335\npciBusID 0000:05:00.0\nTotal memory: 7.92GiB\nFree memory: 7.73GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 2 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y Y Y \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   Y Y Y \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 2:   Y Y Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:09:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 1080, pci bus id: 0000:06:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:2) -> (device: 2, name: GeForce GTX 1080, pci bus id: 0000:05:00.0)\nDevice mapping:\n/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX 1080, pci bus id: 0000:09:00.0\n/job:localhost/replica:0/task:0/gpu:1 -> device: 1, name: GeForce GTX 1080, pci bus id: 0000:06:00.0\n/job:localhost/replica:0/task:0/gpu:2 -> device: 2, name: GeForce GTX 1080, pci bus id: 0000:05:00.0\nI tensorflow/core/common_runtime/direct_session.cc:175] Device mapping:\n/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX 1080, pci bus id: 0000:09:00.0\n/job:localhost/replica:0/task:0/gpu:1 -> device: 1, name: GeForce GTX 1080, pci bus id: 0000:06:00.0\n/job:localhost/replica:0/task:0/gpu:2 -> device: 2, name: GeForce GTX 1080, pci bus id: 0000:05:00.0\n\ninit_all_tables: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] init_all_tables: /job:localhost/replica:0/task:0/gpu:0\ninit_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] init_1: /job:localhost/replica:0/task:0/gpu:0\ngroup_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] group_deps: /job:localhost/replica:0/task:0/gpu:0\nConst: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] Const: /job:localhost/replica:0/task:0/cpu:0\nreport_uninitialized_variables/Shape: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] report_uninitialized_variables/Shape: /job:localhost/replica:0/task:0/cpu:0\nreport_uninitialized_variables/Slice: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] report_uninitialized_variables/Slice: /job:localhost/replica:0/task:0/gpu:0\nreport_uninitialized_variables/concat: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] report_uninitialized_variables/concat: /job:localhost/replica:0/task:0/gpu:0\nreport_uninitialized_variables/Reshape: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] report_uninitialized_variables/Reshape: /job:localhost/replica:0/task:0/cpu:0\nsave/num_shards: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/num_shards: /job:localhost/replica:0/task:0/gpu:0\nsave/Const: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/Const: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_21: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_21: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_20: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_20: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_19: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_19: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_18: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_18: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_17: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_17: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_16: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_16: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_15: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_15: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_14: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_14: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_13: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_13: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_12: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_12: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_11: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_11: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_10: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_10: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_9: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_9: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_8: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_8: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_7: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_7: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_6: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_6: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_5: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_5: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_4: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_4: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_3: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_3: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_2: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_2: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_1: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_1: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice: /job:localhost/replica:0/task:0/cpu:0\nsave/ShardedFilename_2: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/ShardedFilename_2: /job:localhost/replica:0/task:0/cpu:0\nsave/ShardedFilename_1: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/ShardedFilename_1: /job:localhost/replica:0/task:0/cpu:0\nsave/ShardedFilename: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/ShardedFilename: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/logistic_regression/bias/Adagrad: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/logistic_regression/bias/Adagrad: /job:localhost/replica:0/task:0/gpu:2\nIsVariableInitialized_21: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] IsVariableInitialized_21: /job:localhost/replica:0/task:0/gpu:2\nsave/Assign_18: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/Assign_18: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/logistic_regression/bias/Adagrad/read: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/logistic_regression/bias/Adagrad/read: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/logistic_regression/bias/Adagrad/Assign: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/logistic_regression/bias/Adagrad/Assign: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/logistic_regression/weights/Adagrad: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/logistic_regression/weights/Adagrad: /job:localhost/replica:0/task:0/gpu:2\nIsVariableInitialized_20: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] IsVariableInitialized_20: /job:localhost/replica:0/task:0/gpu:2\nsave/Assign_19: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/Assign_19: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/logistic_regression/weights/Adagrad/read: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/logistic_regression/weights/Adagrad/read: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/logistic_regression/weights/Adagrad/Assign: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/logistic_regression/weights/Adagrad/Assign: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/dnn/layer2/fully_connected/bias/Adagrad: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/dnn/layer2/fully_connected/bias/Adagrad: /job:localhost/replica:0/task:0/gpu:1\nIsVariableInitialized_19: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] IsVariableInitialized_19: /job:localhost/replica:0/task:0/gpu:1\nsave/Assign_7: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/Assign_7: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/dnn/layer2/fully_connected/bias/Adagrad/read: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/dnn/layer2/fully_connected/bias/Adagrad/read: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/dnn/layer2/fully_connected/bias/Adagrad/Assign: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/dnn/layer2/fully_connected/bias/Adagrad/Assign: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/dnn/layer2/fully_connected/weights/Adagrad: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/dnn/layer2/fully_connected/weights/Adagrad: /job:localhost/replica:0/task:0/gpu:1\nIsVariableInitialized_18: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] IsVariableInitialized_18: /job:localhost/replica:0/task:0/gpu:1\nsave/Assign_8: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/Assign_8: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/dnn/layer2/fully_connected/weights/Adagrad/read: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/dnn/layer2/fully_connected/weights/Adagrad/read: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/dnn/layer2/fully_connected/weights/Adagrad/Assign: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/dnn/layer2/fully_connected/weights/Adagrad/Assign: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/dnn/layer1/fully_connected/bias/Adagrad: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/dnn/layer1/fully_connected/bias/Adagrad: /job:localhost/replica:0/task:0/gpu:1\nIsVariableInitialized_17: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] IsVariableInitialized_17: /job:localhost/replica:0/task:0/gpu:1\nsave/Assign_5: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/Assign_5: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/dnn/layer1/fully_connected/bias/Adagrad/read: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/dnn/layer1/fully_connected/bias/Adagrad/read: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/dnn/layer1/fully_connected/bias/Adagrad/Assign: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/dnn/layer1/fully_connected/bias/Adagrad/Assign: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/dnn/layer1/fully_connected/weights/Adagrad: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/dnn/layer1/fully_connected/weights/Adagrad: /job:localhost/replica:0/task:0/gpu:1\nIsVariableInitialized_16: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] IsVariableInitialized_16: /job:localhost/replica:0/task:0/gpu:1\nsave/Assign_6: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/Assign_6: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/dnn/layer1/fully_connected/weights/Adagrad/read: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/dnn/layer1/fully_connected/weights/Adagrad/read: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/dnn/layer1/fully_connected/weights/Adagrad/Assign: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/dnn/layer1/fully_connected/weights/Adagrad/Assign: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/dnn/layer0/fully_connected/bias/Adagrad: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/dnn/layer0/fully_connected/bias/Adagrad: /job:localhost/replica:0/task:0/gpu:1\nIsVariableInitialized_15: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] IsVariableInitialized_15: /job:localhost/replica:0/task:0/gpu:1\nsave/Assign_3: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/Assign_3: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/dnn/layer0/fully_connected/bias/Adagrad/read: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/dnn/layer0/fully_connected/bias/Adagrad/read: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/dnn/layer0/fully_connected/bias/Adagrad/Assign: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/dnn/layer0/fully_connected/bias/Adagrad/Assign: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/dnn/layer0/fully_connected/weights/Adagrad: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/dnn/layer0/fully_connected/weights/Adagrad: /job:localhost/replica:0/task:0/gpu:1\nIsVariableInitialized_14: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] IsVariableInitialized_14: /job:localhost/replica:0/task:0/gpu:1\nsave/Assign_4: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/Assign_4: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/dnn/layer0/fully_connected/weights/Adagrad/read: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/dnn/layer0/fully_connected/weights/Adagrad/read: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/dnn/layer0/fully_connected/weights/Adagrad/Assign: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/dnn/layer0/fully_connected/weights/Adagrad/Assign: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/learning_rate: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/learning_rate: /job:localhost/replica:0/task:0/gpu:0\nIsVariableInitialized_13: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] IsVariableInitialized_13: /job:localhost/replica:0/task:0/gpu:0\nsave/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/Assign: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/learning_rate/read: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/learning_rate/read: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/learning_rate/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/learning_rate/Assign: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/avg/AssignMovingAvg/sub: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/avg/AssignMovingAvg/sub: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/value/avg: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/value/avg: /job:localhost/replica:0/task:0/gpu:0\nIsVariableInitialized_12: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] IsVariableInitialized_12: /job:localhost/replica:0/task:0/gpu:0\nsave/Assign_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/Assign_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/value/avg/read: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/value/avg/read: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/ScalarSummary: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/ScalarSummary: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/value/avg/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/value/avg/Assign: /job:localhost/replica:0/task:0/gpu:0\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select/t: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select/t: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select_grad/zeros_like: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select_grad/zeros_like: /job:localhost/replica:0/task:0/gpu:0\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Const: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Const: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Squeeze: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Squeeze: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Equal: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Equal: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/bias/Initializer/random_uniform/min: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/bias/Initializer/random_uniform/min: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/bias/Initializer/random_uniform/sub: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/bias/Initializer/random_uniform/sub: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/bias/Initializer/random_uniform/RandomUniform: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/bias/Initializer/random_uniform/RandomUniform: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/bias/Initializer/random_uniform/mul: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/bias/Initializer/random_uniform/mul: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/bias/Initializer/random_uniform: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/bias/Initializer/random_uniform: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/bias: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/bias: /job:localhost/replica:0/task:0/gpu:2\nIsVariableInitialized_11: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] IsVariableInitialized_11: /job:localhost/replica:0/task:0/gpu:2\nsave/Assign_20: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/Assign_20: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/bias/read: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/bias/read: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/HistogramSummary_21: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_21: /job:localhost/replica:0/task:0/cpu:0\nlogistic_regression/HistogramSummary_3: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/HistogramSummary_3: /job:localhost/replica:0/task:0/cpu:0\nlogistic_regression/bias/Assign: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/bias/Assign: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/weights/Initializer/random_uniform/min: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/weights/Initializer/random_uniform/min: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/weights/Initializer/random_uniform/sub: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/weights/Initializer/random_uniform/sub: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/weights/Initializer/random_uniform/RandomUniform: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/weights/Initializer/random_uniform/RandomUniform: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/weights/Initializer/random_uniform/mul: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/weights/Initializer/random_uniform/mul: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/weights/Initializer/random_uniform: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/weights/Initializer/random_uniform: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/weights: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/weights: /job:localhost/replica:0/task:0/gpu:2\nIsVariableInitialized_10: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] IsVariableInitialized_10: /job:localhost/replica:0/task:0/gpu:2\nsave/Assign_21: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/Assign_21: /job:localhost/replica:0/task:0/gpu:2\nsave/restore_shard_2: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_shard_2: /job:localhost/replica:0/task:0/gpu:2\nsave/restore_all/NoOp_2: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_all/NoOp_2: /job:localhost/replica:0/task:0/gpu:2\nsave/save_2: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/save_2: /job:localhost/replica:0/task:0/cpu:0\nsave/control_dependency_2: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/control_dependency_2: /job:localhost/replica:0/task:0/cpu:0\nlogistic_regression/weights/read: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/weights/read: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/HistogramSummary_18: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_18: /job:localhost/replica:0/task:0/cpu:0\nlogistic_regression/HistogramSummary_2: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/HistogramSummary_2: /job:localhost/replica:0/task:0/cpu:0\nlogistic_regression/weights/Assign: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/weights/Assign: /job:localhost/replica:0/task:0/gpu:2\ninit/NoOp_2: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] init/NoOp_2: /job:localhost/replica:0/task:0/gpu:2\ndnn/layer2/prob: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/prob: /job:localhost/replica:0/task:0/gpu:1\nIsVariableInitialized_9: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] IsVariableInitialized_9: /job:localhost/replica:0/task:0/gpu:1\nsave/Assign_17: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/Assign_17: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/prob/read: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/prob/read: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/prob/Assign: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/prob/Assign: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/Squeeze: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/Squeeze: /job:localhost/replica:0/task:0/cpu:0\ndnn/layer2/cond/pred_id: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/cond/pred_id: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/cond/dropout/Dropout/dropout/add/Switch: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/cond/dropout/Dropout/dropout/add/Switch: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/cond/dropout/Dropout/dropout/Inv: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/cond/dropout/Dropout/dropout/Inv: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/cond/Switch: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/cond/Switch: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/cond/switch_f: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/cond/switch_f: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/cond/switch_t: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/cond/switch_t: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/cond/dropout/Dropout/dropout/random_uniform/min: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/cond/dropout/Dropout/dropout/random_uniform/min: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/cond/dropout/Dropout/dropout/random_uniform/sub: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/cond/dropout/Dropout/dropout/random_uniform/sub: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/fully_connected/bias: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/fully_connected/bias: /job:localhost/replica:0/task:0/gpu:1\nIsVariableInitialized_8: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] IsVariableInitialized_8: /job:localhost/replica:0/task:0/gpu:1\nsave/Assign_15: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/Assign_15: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/fully_connected/bias/read: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/fully_connected/bias/read: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/HistogramSummary_15: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_15: /job:localhost/replica:0/task:0/cpu:0\ndnn/layer2/fully_connected/bias/Assign: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/fully_connected/bias/Assign: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/fully_connected/weights/Initializer/random_uniform/min: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/fully_connected/weights/Initializer/random_uniform/min: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/fully_connected/weights/Initializer/random_uniform/sub: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/fully_connected/weights/Initializer/random_uniform/sub: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/fully_connected/weights/Initializer/random_uniform/RandomUniform: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/fully_connected/weights/Initializer/random_uniform/RandomUniform: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/fully_connected/weights/Initializer/random_uniform/mul: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/fully_connected/weights/Initializer/random_uniform/mul: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/fully_connected/weights/Initializer/random_uniform: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/fully_connected/weights/Initializer/random_uniform: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/fully_connected/weights: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/fully_connected/weights: /job:localhost/replica:0/task:0/gpu:1\nIsVariableInitialized_7: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] IsVariableInitialized_7: /job:localhost/replica:0/task:0/gpu:1\nsave/Assign_16: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/Assign_16: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/fully_connected/weights/read: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/fully_connected/weights/read: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/HistogramSummary_12: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_12: /job:localhost/replica:0/task:0/cpu:0\ndnn/layer2/fully_connected/weights/Assign: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/fully_connected/weights/Assign: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/prob: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/prob: /job:localhost/replica:0/task:0/gpu:1\nIsVariableInitialized_6: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] IsVariableInitialized_6: /job:localhost/replica:0/task:0/gpu:1\nsave/Assign_14: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/Assign_14: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/prob/read: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/prob/read: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/prob/Assign: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/prob/Assign: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/Squeeze: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/Squeeze: /job:localhost/replica:0/task:0/cpu:0\ndnn/layer1/cond/pred_id: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/cond/pred_id: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/cond/dropout/Dropout/dropout/add/Switch: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/cond/dropout/Dropout/dropout/add/Switch: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/cond/dropout/Dropout/dropout/Inv: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/cond/dropout/Dropout/dropout/Inv: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/cond/Switch: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/cond/Switch: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/cond/switch_f: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/cond/switch_f: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/cond/switch_t: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/cond/switch_t: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/cond/dropout/Dropout/dropout/random_uniform/min: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/cond/dropout/Dropout/dropout/random_uniform/min: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/cond/dropout/Dropout/dropout/random_uniform/sub: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/cond/dropout/Dropout/dropout/random_uniform/sub: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/fully_connected/bias: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/fully_connected/bias: /job:localhost/replica:0/task:0/gpu:1\nIsVariableInitialized_5: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] IsVariableInitialized_5: /job:localhost/replica:0/task:0/gpu:1\nsave/Assign_12: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/Assign_12: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/fully_connected/bias/read: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/fully_connected/bias/read: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/HistogramSummary_9: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_9: /job:localhost/replica:0/task:0/cpu:0\ndnn/layer1/fully_connected/bias/Assign: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/fully_connected/bias/Assign: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/fully_connected/weights/Initializer/random_uniform/min: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/fully_connected/weights/Initializer/random_uniform/min: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/fully_connected/weights/Initializer/random_uniform/sub: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/fully_connected/weights/Initializer/random_uniform/sub: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/fully_connected/weights/Initializer/random_uniform/RandomUniform: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/fully_connected/weights/Initializer/random_uniform/RandomUniform: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/fully_connected/weights/Initializer/random_uniform/mul: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/fully_connected/weights/Initializer/random_uniform/mul: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/fully_connected/weights/Initializer/random_uniform: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/fully_connected/weights/Initializer/random_uniform: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/fully_connected/weights: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/fully_connected/weights: /job:localhost/replica:0/task:0/gpu:1\nIsVariableInitialized_4: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] IsVariableInitialized_4: /job:localhost/replica:0/task:0/gpu:1\nsave/Assign_13: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/Assign_13: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/fully_connected/weights/read: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/fully_connected/weights/read: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/HistogramSummary_6: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_6: /job:localhost/replica:0/task:0/cpu:0\ndnn/layer1/fully_connected/weights/Assign: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/fully_connected/weights/Assign: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/prob: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/prob: /job:localhost/replica:0/task:0/gpu:1\nIsVariableInitialized_3: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] IsVariableInitialized_3: /job:localhost/replica:0/task:0/gpu:1\nsave/Assign_11: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/Assign_11: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/prob/read: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/prob/read: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/prob/Assign: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/prob/Assign: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/Squeeze: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/Squeeze: /job:localhost/replica:0/task:0/cpu:0\ndnn/layer0/cond/pred_id: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/cond/pred_id: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/cond/dropout/Dropout/dropout/add/Switch: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/cond/dropout/Dropout/dropout/add/Switch: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/cond/dropout/Dropout/dropout/Inv: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/cond/dropout/Dropout/dropout/Inv: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/cond/Switch: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/cond/Switch: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/cond/switch_f: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/cond/switch_f: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/cond/switch_t: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/cond/switch_t: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/cond/dropout/Dropout/dropout/random_uniform/min: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/cond/dropout/Dropout/dropout/random_uniform/min: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/cond/dropout/Dropout/dropout/random_uniform/sub: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/cond/dropout/Dropout/dropout/random_uniform/sub: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/fully_connected/bias: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/fully_connected/bias: /job:localhost/replica:0/task:0/gpu:1\nIsVariableInitialized_2: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] IsVariableInitialized_2: /job:localhost/replica:0/task:0/gpu:1\nsave/Assign_9: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/Assign_9: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/fully_connected/bias/read: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/fully_connected/bias/read: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/HistogramSummary_3: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_3: /job:localhost/replica:0/task:0/cpu:0\ndnn/layer0/fully_connected/bias/Assign: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/fully_connected/bias/Assign: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/fully_connected/weights/Initializer/random_uniform/min: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/fully_connected/weights/Initializer/random_uniform/min: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/fully_connected/weights/Initializer/random_uniform/sub: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/fully_connected/weights/Initializer/random_uniform/sub: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/fully_connected/weights/Initializer/random_uniform/RandomUniform: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/fully_connected/weights/Initializer/random_uniform/RandomUniform: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/fully_connected/weights/Initializer/random_uniform/mul: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/fully_connected/weights/Initializer/random_uniform/mul: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/fully_connected/weights/Initializer/random_uniform: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/fully_connected/weights/Initializer/random_uniform: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/fully_connected/weights: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/fully_connected/weights: /job:localhost/replica:0/task:0/gpu:1\nIsVariableInitialized_1: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] IsVariableInitialized_1: /job:localhost/replica:0/task:0/gpu:1\nsave/Assign_10: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/Assign_10: /job:localhost/replica:0/task:0/gpu:1\nsave/restore_shard_1: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_shard_1: /job:localhost/replica:0/task:0/gpu:1\nsave/restore_all/NoOp_1: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_all/NoOp_1: /job:localhost/replica:0/task:0/gpu:1\nsave/save_1: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/save_1: /job:localhost/replica:0/task:0/cpu:0\nsave/control_dependency_1: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/control_dependency_1: /job:localhost/replica:0/task:0/cpu:0\ndnn/layer0/fully_connected/weights/read: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/fully_connected/weights/read: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/HistogramSummary: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary: /job:localhost/replica:0/task:0/cpu:0\ndnn/layer0/fully_connected/weights/Assign: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/fully_connected/weights/Assign: /job:localhost/replica:0/task:0/gpu:1\ninit/NoOp_1: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] init/NoOp_1: /job:localhost/replica:0/task:0/gpu:1\noutput: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] output: /job:localhost/replica:0/task:0/gpu:0\nlogistic_regression/HistogramSummary_1: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/HistogramSummary_1: /job:localhost/replica:0/task:0/cpu:0\ninput: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] input: /job:localhost/replica:0/task:0/gpu:0\ndnn/layer0/fully_connected/MatMul: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/fully_connected/MatMul: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/fully_connected/BiasAdd: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/fully_connected/BiasAdd: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/Relu: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/Relu: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/gradients/Switch_5: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/Switch_5: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/Shape_6: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/Shape_6: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/zeros_5: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/zeros_5: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/Shape/Switch_grad/cond_grad: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/Shape/Switch_grad/cond_grad: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/Switch_4: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/Switch_4: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/Shape_5: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/Shape_5: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/zeros_4: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/zeros_4: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/cond/Switch_1_grad/cond_grad: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/Switch_1_grad/cond_grad: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/AddN_2: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/AddN_2: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/Relu_grad/ReluGrad: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/Relu_grad/ReluGrad: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/fully_connected/BiasAdd_grad/BiasAddGrad: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/fully_connected/BiasAdd_grad/BiasAddGrad: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/fully_connected/BiasAdd_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/fully_connected/BiasAdd_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/fully_connected/BiasAdd_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/fully_connected/BiasAdd_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm/L2Loss_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm/L2Loss_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/fully_connected/BiasAdd_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/fully_connected/BiasAdd_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/fully_connected/MatMul_grad/MatMul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/fully_connected/MatMul_grad/MatMul_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/fully_connected/MatMul_grad/MatMul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/fully_connected/MatMul_grad/MatMul: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/fully_connected/MatMul_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/fully_connected/MatMul_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/fully_connected/MatMul_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/fully_connected/MatMul_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm/L2Loss: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm/L2Loss: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/fully_connected/MatMul_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/fully_connected/MatMul_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ndnn/layer0/cond/Switch_1: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/cond/Switch_1: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/cond/Merge: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/cond/Merge: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/fully_connected/MatMul: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/fully_connected/MatMul: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/fully_connected/BiasAdd: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/fully_connected/BiasAdd: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/Relu: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/Relu: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/gradients/Switch_3: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/Switch_3: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/Shape_4: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/Shape_4: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/zeros_3: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/zeros_3: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/Shape/Switch_grad/cond_grad: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/Shape/Switch_grad/cond_grad: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/Switch_2: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/Switch_2: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/Shape_3: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/Shape_3: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/zeros_2: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/zeros_2: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/cond/Switch_1_grad/cond_grad: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/Switch_1_grad/cond_grad: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/AddN_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/AddN_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/Relu_grad/ReluGrad: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/Relu_grad/ReluGrad: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/fully_connected/BiasAdd_grad/BiasAddGrad: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/fully_connected/BiasAdd_grad/BiasAddGrad: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/fully_connected/BiasAdd_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/fully_connected/BiasAdd_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/fully_connected/BiasAdd_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/fully_connected/BiasAdd_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm/L2Loss_3: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm/L2Loss_3: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/fully_connected/BiasAdd_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/fully_connected/BiasAdd_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/fully_connected/MatMul_grad/MatMul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/fully_connected/MatMul_grad/MatMul_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/fully_connected/MatMul_grad/MatMul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/fully_connected/MatMul_grad/MatMul: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/fully_connected/MatMul_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/fully_connected/MatMul_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/fully_connected/MatMul_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/fully_connected/MatMul_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm/L2Loss_2: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm/L2Loss_2: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/fully_connected/MatMul_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/fully_connected/MatMul_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/cond/Merge_grad/cond_grad: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/Merge_grad/cond_grad: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/cond/Merge_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/Merge_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/cond/Merge_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/Merge_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/cond/Merge_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/Merge_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ndnn/layer1/cond/Switch_1: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/cond/Switch_1: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/cond/Merge: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/cond/Merge: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/fully_connected/MatMul: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/fully_connected/MatMul: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/fully_connected/BiasAdd: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/fully_connected/BiasAdd: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/Relu: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/Relu: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/gradients/Switch_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/Switch_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/Shape_2: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/Shape_2: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/zeros_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/zeros_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/Shape/Switch_grad/cond_grad: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/Shape/Switch_grad/cond_grad: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/Switch: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/Switch: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/zeros: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/zeros: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/cond/Switch_1_grad/cond_grad: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/Switch_1_grad/cond_grad: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/AddN: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/AddN: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/Relu_grad/ReluGrad: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/Relu_grad/ReluGrad: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/fully_connected/BiasAdd_grad/BiasAddGrad: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/fully_connected/BiasAdd_grad/BiasAddGrad: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/fully_connected/BiasAdd_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/fully_connected/BiasAdd_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/fully_connected/BiasAdd_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/fully_connected/BiasAdd_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm/L2Loss_5: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm/L2Loss_5: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/fully_connected/BiasAdd_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/fully_connected/BiasAdd_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/fully_connected/MatMul_grad/MatMul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/fully_connected/MatMul_grad/MatMul_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/fully_connected/MatMul_grad/MatMul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/fully_connected/MatMul_grad/MatMul: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/fully_connected/MatMul_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/fully_connected/MatMul_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/fully_connected/MatMul_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/fully_connected/MatMul_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm/L2Loss_4: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm/L2Loss_4: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/fully_connected/MatMul_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/fully_connected/MatMul_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/cond/Merge_grad/cond_grad: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/Merge_grad/cond_grad: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/cond/Merge_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/Merge_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/cond/Merge_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/Merge_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/cond/Merge_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/Merge_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ndnn/layer2/cond/Switch_1: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/cond/Switch_1: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/cond/Merge: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/cond/Merge: /job:localhost/replica:0/task:0/gpu:1\nlogistic_regression/softmax_classifier/xw_plus_b/MatMul: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/xw_plus_b/MatMul: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/xw_plus_b: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/xw_plus_b: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/xentropy: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/xentropy: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/gradients/zeros_like: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/zeros_like: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_grad/Shape: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_grad/Shape: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Size: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Size: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/ToFloat_2: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/ToFloat_2: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/Neg: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/Neg: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/Shape: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/Shape: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Shape: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Shape: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Slice: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Slice: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Reshape: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Reshape: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Reshape_1: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Reshape_1: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/ones: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/ones: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_1_grad/Shape: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_1_grad/Shape: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/ToFloat_3: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/ToFloat_3: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/Square: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/Square: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/truediv_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/truediv_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_1_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_1_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_1_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_1_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_1: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_1: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_2_grad/Shape: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_2_grad/Shape: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_2: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_2: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/ones_like/Shape: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/ones_like/Shape: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/ones_like: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/ones_like: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select_1_grad/zeros_like: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select_1_grad/zeros_like: /job:localhost/replica:0/task:0/gpu:0\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Equal_1: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Equal_1: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select_1: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select_1: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/Square: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/Square: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Greater: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Greater: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_grad/Shape: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_grad/Shape: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_1: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_1: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_3: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_3: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/Neg: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/Neg: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/truediv_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/truediv_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/Shape: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/Shape: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/zeros_like: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/zeros_like: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/value_grad/zeros_like: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/value_grad/zeros_like: /job:localhost/replica:0/task:0/gpu:0\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/value: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/value: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/avg/AssignMovingAvg/sub_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/avg/AssignMovingAvg/sub_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/avg/AssignMovingAvg/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/avg/AssignMovingAvg/mul: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/avg/AssignMovingAvg: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/avg/AssignMovingAvg: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/avg: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/avg: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/control_dependency: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/control_dependency: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/CheckNumerics: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/CheckNumerics: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/ScalarSummary_1: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/ScalarSummary_1: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/gradients/Shape: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/Shape: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/gradients/Fill: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/Fill: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/value_grad/Select_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/value_grad/Select_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/value_grad/Select: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/value_grad/Select: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/value_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/value_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/value_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/value_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/value_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/value_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/truediv: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/truediv: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select_1_grad/Select_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select_1_grad/Select_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select_1_grad/Select: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select_1_grad/Select: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select_1_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select_1_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select_1_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select_1_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_2_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_2_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_2_grad/Tile: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_2_grad/Tile: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_1_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_1_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_1_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_1_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_1_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_1_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_1_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_1_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_1_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_1_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_1_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_1_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_1_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_1_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_1_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_1_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select_grad/Select_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select_grad/Select_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select_grad/Select: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select_grad/Select: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/truediv: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/truediv: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_1_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_1_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/ones_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/ones_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select_1_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Select_1_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/ones_like_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/ones_like_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Div_1_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_3_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_3_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_3_grad/Tile: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_3_grad/Tile: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_1_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_1_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_1_grad/Tile: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_1_grad/Tile: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Mul_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_grad/Tile: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_grad/Tile: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/xentropy_grad/ExpandDims: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/xentropy_grad/ExpandDims: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/xentropy_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/xentropy_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/xw_plus_b_grad/BiasAddGrad: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/xw_plus_b_grad/BiasAddGrad: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/xw_plus_b_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/xw_plus_b_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/xw_plus_b_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/xw_plus_b_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm/L2Loss_7: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm/L2Loss_7: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/xw_plus_b_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/xw_plus_b_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/xw_plus_b/MatMul_grad/MatMul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/xw_plus_b/MatMul_grad/MatMul_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/xw_plus_b/MatMul_grad/MatMul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/xw_plus_b/MatMul_grad/MatMul: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/xw_plus_b/MatMul_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/xw_plus_b/MatMul_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/xw_plus_b/MatMul_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/xw_plus_b/MatMul_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm/L2Loss_6: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm/L2Loss_6: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm/pack: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm/pack: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm/Sum: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm/mul: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm/global_norm: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm/global_norm: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/clip_by_global_norm/truediv: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/clip_by_global_norm/truediv: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/clip_by_global_norm/Minimum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/clip_by_global_norm/Minimum: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/clip_by_global_norm/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/clip_by_global_norm/mul: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/clip_by_global_norm/mul_8: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/clip_by_global_norm/mul_8: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_7: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_7: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/train/update_logistic_regression/bias/ApplyAdagrad: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/train/update_logistic_regression/bias/ApplyAdagrad: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/global_norm_8/L2Loss: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_8/L2Loss: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_8/pack: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_8/pack: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_8/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_8/Sum: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_8/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_8/mul: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_8/global_norm: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_8/global_norm: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/HistogramSummary_23: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_23: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/HistogramSummary_22: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_22: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/clip_by_global_norm/mul_7: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/clip_by_global_norm/mul_7: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_6: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_6: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/train/update_logistic_regression/weights/ApplyAdagrad: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/train/update_logistic_regression/weights/ApplyAdagrad: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/train/update/NoOp_1: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/train/update/NoOp_1: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/global_norm_7/L2Loss: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_7/L2Loss: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_7/pack: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_7/pack: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_7/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_7/Sum: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_7/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_7/mul: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_7/global_norm: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_7/global_norm: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/HistogramSummary_20: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_20: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/HistogramSummary_19: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_19: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/clip_by_global_norm/mul_6: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/clip_by_global_norm/mul_6: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_5: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_5: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/train/update_dnn/layer2/fully_connected/bias/ApplyAdagrad: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/train/update_dnn/layer2/fully_connected/bias/ApplyAdagrad: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/global_norm_6/L2Loss: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_6/L2Loss: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_6/pack: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_6/pack: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_6/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_6/Sum: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_6/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_6/mul: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_6/global_norm: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_6/global_norm: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/HistogramSummary_17: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_17: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/HistogramSummary_16: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_16: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/clip_by_global_norm/mul_5: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/clip_by_global_norm/mul_5: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_4: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_4: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/train/update_dnn/layer2/fully_connected/weights/ApplyAdagrad: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/train/update_dnn/layer2/fully_connected/weights/ApplyAdagrad: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/global_norm_5/L2Loss: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_5/L2Loss: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_5/pack: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_5/pack: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_5/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_5/Sum: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_5/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_5/mul: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_5/global_norm: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_5/global_norm: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/HistogramSummary_14: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_14: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/HistogramSummary_13: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_13: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/clip_by_global_norm/mul_4: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/clip_by_global_norm/mul_4: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_3: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_3: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/train/update_dnn/layer1/fully_connected/bias/ApplyAdagrad: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/train/update_dnn/layer1/fully_connected/bias/ApplyAdagrad: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/global_norm_4/L2Loss: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_4/L2Loss: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_4/pack: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_4/pack: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_4/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_4/Sum: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_4/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_4/mul: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_4/global_norm: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_4/global_norm: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/HistogramSummary_11: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_11: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/HistogramSummary_10: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_10: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/clip_by_global_norm/mul_3: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/clip_by_global_norm/mul_3: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_2: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_2: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/train/update_dnn/layer1/fully_connected/weights/ApplyAdagrad: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/train/update_dnn/layer1/fully_connected/weights/ApplyAdagrad: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/global_norm_3/L2Loss: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_3/L2Loss: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_3/pack: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_3/pack: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_3/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_3/Sum: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_3/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_3/mul: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_3/global_norm: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_3/global_norm: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/HistogramSummary_8: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_8: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/HistogramSummary_7: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_7: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/clip_by_global_norm/mul_2: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/clip_by_global_norm/mul_2: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/train/update_dnn/layer0/fully_connected/bias/ApplyAdagrad: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/train/update_dnn/layer0/fully_connected/bias/ApplyAdagrad: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/global_norm_2/L2Loss: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_2/L2Loss: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_2/pack: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_2/pack: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_2/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_2/Sum: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_2/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_2/mul: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_2/global_norm: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_2/global_norm: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/HistogramSummary_5: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_5: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/HistogramSummary_4: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_4: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/clip_by_global_norm/mul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/clip_by_global_norm/mul_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_0: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_0: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/train/update_dnn/layer0/fully_connected/weights/ApplyAdagrad: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/train/update_dnn/layer0/fully_connected/weights/ApplyAdagrad: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/train/update/NoOp: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/train/update/NoOp: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/train/update: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/train/update: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_1/L2Loss: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_1/L2Loss: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_1/pack: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_1/pack: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_1/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_1/Sum: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_1/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_1/mul: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_1/global_norm: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_1/global_norm: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/HistogramSummary_2: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_2: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/HistogramSummary_1: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_1: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/xw_plus_b/MatMul_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/xw_plus_b/MatMul_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/cond/Merge_grad/cond_grad: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/Merge_grad/cond_grad: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/cond/Merge_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/Merge_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/cond/Merge_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/Merge_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/cond/Merge_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/Merge_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nlogistic_regression/softmax_classifier/Softmax: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/Softmax: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/HistogramSummary: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/HistogramSummary: /job:localhost/replica:0/task:0/cpu:0\nMergeSummary/MergeSummary: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] MergeSummary/MergeSummary: /job:localhost/replica:0/task:0/cpu:0\ndnn/layer2/cond/dropout/Dropout/dropout/Shape/Switch: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/cond/dropout/Dropout/dropout/Shape/Switch: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_grad/Shape: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_grad/Shape: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\ndnn/layer2/cond/dropout/Dropout/dropout/mul: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/cond/dropout/Dropout/dropout/mul: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_1_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_1_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_1_grad/Shape: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_1_grad/Shape: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/cond/dropout/Dropout/dropout/Shape: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/cond/dropout/Dropout/dropout/Shape: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/cond/dropout/Dropout/dropout/random_uniform/RandomUniform: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/cond/dropout/Dropout/dropout/random_uniform/RandomUniform: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/cond/dropout/Dropout/dropout/random_uniform/mul: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/cond/dropout/Dropout/dropout/random_uniform/mul: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/cond/dropout/Dropout/dropout/random_uniform: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/cond/dropout/Dropout/dropout/random_uniform: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/cond/dropout/Dropout/dropout/add: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/cond/dropout/Dropout/dropout/add: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/cond/dropout/Dropout/dropout/Floor: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/cond/dropout/Dropout/dropout/Floor: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_1_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_1_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_1_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_1_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_1_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_1_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_1_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_1_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_1_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_1_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_1_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_1_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_1_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_1_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_1_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_1_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_1_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_1_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_1_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_1_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer2/cond/dropout/Dropout/dropout/mul_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ndnn/layer2/cond/dropout/Dropout/dropout/mul_1: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/cond/dropout/Dropout/dropout/mul_1: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/cond/dropout/Dropout/dropout/Shape/Switch: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/cond/dropout/Dropout/dropout/Shape/Switch: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_grad/Shape: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_grad/Shape: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\ndnn/layer1/cond/dropout/Dropout/dropout/mul: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/cond/dropout/Dropout/dropout/mul: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_1_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_1_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_1_grad/Shape: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_1_grad/Shape: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/cond/dropout/Dropout/dropout/Shape: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/cond/dropout/Dropout/dropout/Shape: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/cond/dropout/Dropout/dropout/random_uniform/RandomUniform: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/cond/dropout/Dropout/dropout/random_uniform/RandomUniform: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/cond/dropout/Dropout/dropout/random_uniform/mul: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/cond/dropout/Dropout/dropout/random_uniform/mul: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/cond/dropout/Dropout/dropout/random_uniform: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/cond/dropout/Dropout/dropout/random_uniform: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/cond/dropout/Dropout/dropout/add: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/cond/dropout/Dropout/dropout/add: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/cond/dropout/Dropout/dropout/Floor: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/cond/dropout/Dropout/dropout/Floor: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_1_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_1_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_1_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_1_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_1_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_1_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_1_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_1_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_1_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_1_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_1_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_1_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_1_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_1_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_1_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_1_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_1_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_1_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_1_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_1_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer1/cond/dropout/Dropout/dropout/mul_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ndnn/layer1/cond/dropout/Dropout/dropout/mul_1: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/cond/dropout/Dropout/dropout/mul_1: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/cond/dropout/Dropout/dropout/Shape/Switch: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/cond/dropout/Dropout/dropout/Shape/Switch: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_grad/Shape: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_grad/Shape: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\ndnn/layer0/cond/dropout/Dropout/dropout/mul: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/cond/dropout/Dropout/dropout/mul: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_1_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_1_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_1_grad/Shape: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_1_grad/Shape: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/cond/dropout/Dropout/dropout/Shape: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/cond/dropout/Dropout/dropout/Shape: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/cond/dropout/Dropout/dropout/random_uniform/RandomUniform: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/cond/dropout/Dropout/dropout/random_uniform/RandomUniform: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/cond/dropout/Dropout/dropout/random_uniform/mul: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/cond/dropout/Dropout/dropout/random_uniform/mul: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/cond/dropout/Dropout/dropout/random_uniform: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/cond/dropout/Dropout/dropout/random_uniform: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/cond/dropout/Dropout/dropout/add: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/cond/dropout/Dropout/dropout/add: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/cond/dropout/Dropout/dropout/Floor: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/cond/dropout/Dropout/dropout/Floor: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_1_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_1_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_1_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_1_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_1_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_1_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_1_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_1_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_1_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_1_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_1_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_1_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_1_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_1_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_1_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_1_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_1_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_1_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_1_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_1_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/dnn/layer0/cond/dropout/Dropout/dropout/mul_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ndnn/layer0/cond/dropout/Dropout/dropout/mul_1: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/cond/dropout/Dropout/dropout/mul_1: /job:localhost/replica:0/task:0/gpu:1\nglobal_step: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] global_step: /job:localhost/replica:0/task:0/cpu:0\nIsVariableInitialized: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] IsVariableInitialized: /job:localhost/replica:0/task:0/cpu:0\npack: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] pack: /job:localhost/replica:0/task:0/cpu:0\nLogicalNot: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] LogicalNot: /job:localhost/replica:0/task:0/gpu:0\nreport_uninitialized_variables/Reshape_1: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] report_uninitialized_variables/Reshape_1: /job:localhost/replica:0/task:0/cpu:0\nreport_uninitialized_variables/Where: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] report_uninitialized_variables/Where: /job:localhost/replica:0/task:0/cpu:0\nreport_uninitialized_variables/Squeeze: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] report_uninitialized_variables/Squeeze: /job:localhost/replica:0/task:0/gpu:0\nreport_uninitialized_variables/Gather: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] report_uninitialized_variables/Gather: /job:localhost/replica:0/task:0/cpu:0\nsave/Assign_2: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/Assign_2: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_shard: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_shard: /job:localhost/replica:0/task:0/gpu:0\nsave/restore_all/NoOp: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_all/NoOp: /job:localhost/replica:0/task:0/gpu:0\nsave/restore_all: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_all: /job:localhost/replica:0/task:0/gpu:0\nsave/save: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/save: /job:localhost/replica:0/task:0/cpu:0\nsave/control_dependency: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/control_dependency: /job:localhost/replica:0/task:0/cpu:0\nsave/ShardedFilespec: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/ShardedFilespec: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/train: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/train: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nglobal_step/read: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] global_step/read: /job:localhost/replica:0/task:0/cpu:0\nglobal_step/Assign: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] global_step/Assign: /job:localhost/replica:0/task:0/cpu:0\ninit/NoOp: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] init/NoOp: /job:localhost/replica:0/task:0/gpu:0\ninit: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] init: /job:localhost/replica:0/task:0/gpu:0\nreport_uninitialized_variables/Reshape_1/shape: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] report_uninitialized_variables/Reshape_1/shape: /job:localhost/replica:0/task:0/cpu:0\nreport_uninitialized_variables/concat/values_0: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] report_uninitialized_variables/concat/values_0: /job:localhost/replica:0/task:0/gpu:0\nreport_uninitialized_variables/concat/concat_dim: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] report_uninitialized_variables/concat/concat_dim: /job:localhost/replica:0/task:0/gpu:0\nreport_uninitialized_variables/Slice/size: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] report_uninitialized_variables/Slice/size: /job:localhost/replica:0/task:0/gpu:0\nreport_uninitialized_variables/Slice/begin: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] report_uninitialized_variables/Slice/begin: /job:localhost/replica:0/task:0/gpu:0\nsave/restore_slice_21/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_21/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_21/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_21/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_20/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_20/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_20/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_20/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_19/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_19/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_19/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_19/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_18/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_18/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_18/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_18/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_17/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_17/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_17/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_17/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_16/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_16/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_16/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_16/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_15/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_15/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_15/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_15/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_14/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_14/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_14/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_14/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_13/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_13/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_13/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_13/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_12/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_12/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_12/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_12/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_11/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_11/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_11/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_11/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_10/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_10/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_10/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_10/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_9/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_9/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_9/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_9/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_8/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_8/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_8/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_8/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_7/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_7/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_7/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_7/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_6/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_6/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_6/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_6/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_5/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_5/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_5/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_5/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_4/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_4/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_4/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_4/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_3/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_3/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_3/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_3/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_2/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_2/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_2/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_2/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_1/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_1/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice_1/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice_1/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice/shape_and_slice: /job:localhost/replica:0/task:0/cpu:0\nsave/restore_slice/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/restore_slice/tensor_name: /job:localhost/replica:0/task:0/cpu:0\nsave/save_2/shapes_and_slices: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/save_2/shapes_and_slices: /job:localhost/replica:0/task:0/cpu:0\nsave/save_2/tensor_names: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/save_2/tensor_names: /job:localhost/replica:0/task:0/cpu:0\nsave/ShardedFilename_2/shard: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/ShardedFilename_2/shard: /job:localhost/replica:0/task:0/gpu:2\nsave/save_1/shapes_and_slices: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/save_1/shapes_and_slices: /job:localhost/replica:0/task:0/cpu:0\nsave/save_1/tensor_names: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/save_1/tensor_names: /job:localhost/replica:0/task:0/cpu:0\nsave/ShardedFilename_1/shard: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/ShardedFilename_1/shard: /job:localhost/replica:0/task:0/gpu:1\nsave/save/shapes_and_slices: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/save/shapes_and_slices: /job:localhost/replica:0/task:0/cpu:0\nsave/save/tensor_names: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/save/tensor_names: /job:localhost/replica:0/task:0/cpu:0\nsave/ShardedFilename/shard: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] save/ShardedFilename/shard: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/Const_7: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/Const_7: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/Const_6: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/Const_6: /job:localhost/replica:0/task:0/gpu:2\nOptimizeLoss/Const_5: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/Const_5: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/Const_4: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/Const_4: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/Const_3: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/Const_3: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/Const_2: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/Const_2: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/Const_1: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/Const_1: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/Const: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/Const: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/HistogramSummary_23/tag: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_23/tag: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/global_norm_8/Const_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_8/Const_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_8/Const: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_8/Const: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/HistogramSummary_22/tag: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_22/tag: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/HistogramSummary_21/tag: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_21/tag: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/HistogramSummary_20/tag: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_20/tag: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/global_norm_7/Const_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_7/Const_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_7/Const: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_7/Const: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/HistogramSummary_19/tag: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_19/tag: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/HistogramSummary_18/tag: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_18/tag: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/HistogramSummary_17/tag: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_17/tag: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/global_norm_6/Const_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_6/Const_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_6/Const: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_6/Const: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/HistogramSummary_16/tag: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_16/tag: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/HistogramSummary_15/tag: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_15/tag: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/HistogramSummary_14/tag: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_14/tag: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/global_norm_5/Const_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_5/Const_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_5/Const: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_5/Const: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/HistogramSummary_13/tag: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_13/tag: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/HistogramSummary_12/tag: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_12/tag: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/HistogramSummary_11/tag: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_11/tag: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/global_norm_4/Const_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_4/Const_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_4/Const: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_4/Const: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/HistogramSummary_10/tag: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_10/tag: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/HistogramSummary_9/tag: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_9/tag: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/HistogramSummary_8/tag: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_8/tag: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/global_norm_3/Const_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_3/Const_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_3/Const: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_3/Const: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/HistogramSummary_7/tag: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_7/tag: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/HistogramSummary_6/tag: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_6/tag: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/HistogramSummary_5/tag: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_5/tag: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/global_norm_2/Const_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_2/Const_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_2/Const: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_2/Const: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/HistogramSummary_4/tag: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_4/tag: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/HistogramSummary_3/tag: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_3/tag: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/HistogramSummary_2/tag: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_2/tag: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/global_norm_1/Const_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_1/Const_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm_1/Const: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm_1/Const: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/HistogramSummary_1/tag: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary_1/tag: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/HistogramSummary/tag: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/HistogramSummary/tag: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/ScalarSummary_1/tags: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/ScalarSummary_1/tags: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/clip_by_global_norm/mul/x: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/clip_by_global_norm/mul/x: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/clip_by_global_norm/Const: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/clip_by_global_norm/Const: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/clip_by_global_norm/truediv/x: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/clip_by_global_norm/truediv/x: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm/Const_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm/Const_1: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/global_norm/Const: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/global_norm/Const: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/zeros_5/Const: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/zeros_5/Const: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/zeros_4/Const: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/zeros_4/Const: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/zeros_3/Const: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/zeros_3/Const: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/zeros_2/Const: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/zeros_2/Const: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/zeros_1/Const: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/zeros_1/Const: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/zeros/Const: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/zeros/Const: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/xentropy_grad/ExpandDims/dim: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/xentropy_grad/ExpandDims/dim: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/ones_grad/Const: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/ones_grad/Const: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_grad/Reshape/shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_grad/Reshape/shape: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_2_grad/Reshape/shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_2_grad/Reshape/shape: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_1_grad/Tile/multiples: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_1_grad/Tile/multiples: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_1_grad/Reshape/shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_1_grad/Reshape/shape: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/ones_like_grad/Const: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/ones_like_grad/Const: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_3_grad/Tile/multiples: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_3_grad/Tile/multiples: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_3_grad/Reshape/shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum_3_grad/Reshape/shape: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/gradients/Const: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/gradients/Const: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/learning_rate/Initializer/Const: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/learning_rate/Initializer/Const: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/ScalarSummary/tags: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/ScalarSummary/tags: /job:localhost/replica:0/task:0/cpu:0\nOptimizeLoss/avg/AssignMovingAvg/sub/x: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/avg/AssignMovingAvg/sub/x: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/avg/decay: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/avg/decay: /job:localhost/replica:0/task:0/gpu:0\nOptimizeLoss/zeros: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/zeros: /job:localhost/replica:0/task:0/gpu:0\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/ones_like/Const: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/ones_like/Const: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Equal_1/y: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Equal_1/y: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Greater/y: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Greater/y: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Const_3: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Const_3: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Const_2: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Const_2: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/ones/Const: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/ones/Const: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Reshape_1/shape: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Reshape_1/shape: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Equal/y: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Equal/y: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Reshape/shape: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Reshape/shape: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Slice/size: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Slice/size: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Slice/begin: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Slice/begin: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Const_1: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Const_1: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum/reduction_indices: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/softmax_classifier/softmax_cross_entropy_loss/Sum/reduction_indices: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/HistogramSummary_3/tag: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/HistogramSummary_3/tag: /job:localhost/replica:0/task:0/cpu:0\nlogistic_regression/HistogramSummary_2/tag: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/HistogramSummary_2/tag: /job:localhost/replica:0/task:0/cpu:0\nlogistic_regression/bias/Initializer/random_uniform/max: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/bias/Initializer/random_uniform/max: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/bias/Initializer/random_uniform/shape: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/bias/Initializer/random_uniform/shape: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/weights/Initializer/random_uniform/max: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/weights/Initializer/random_uniform/max: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/weights/Initializer/random_uniform/shape: /job:localhost/replica:0/task:0/gpu:2\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/weights/Initializer/random_uniform/shape: /job:localhost/replica:0/task:0/gpu:2\nlogistic_regression/HistogramSummary_1/tag: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/HistogramSummary_1/tag: /job:localhost/replica:0/task:0/cpu:0\nlogistic_regression/HistogramSummary/tag: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] logistic_regression/HistogramSummary/tag: /job:localhost/replica:0/task:0/cpu:0\ndnn/layer2/prob/Initializer/Const: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/prob/Initializer/Const: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/Squeeze/input: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/Squeeze/input: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/cond/dropout/Dropout/dropout/random_uniform/max: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/cond/dropout/Dropout/dropout/random_uniform/max: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/fully_connected/bias/Initializer/zeros: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/fully_connected/bias/Initializer/zeros: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/fully_connected/weights/Initializer/random_uniform/max: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/fully_connected/weights/Initializer/random_uniform/max: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer2/fully_connected/weights/Initializer/random_uniform/shape: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer2/fully_connected/weights/Initializer/random_uniform/shape: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/prob/Initializer/Const: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/prob/Initializer/Const: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/Squeeze/input: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/Squeeze/input: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/cond/dropout/Dropout/dropout/random_uniform/max: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/cond/dropout/Dropout/dropout/random_uniform/max: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/fully_connected/bias/Initializer/zeros: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/fully_connected/bias/Initializer/zeros: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/fully_connected/weights/Initializer/random_uniform/max: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/fully_connected/weights/Initializer/random_uniform/max: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer1/fully_connected/weights/Initializer/random_uniform/shape: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer1/fully_connected/weights/Initializer/random_uniform/shape: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/prob/Initializer/Const: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/prob/Initializer/Const: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/Squeeze/input: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/Squeeze/input: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/cond/dropout/Dropout/dropout/random_uniform/max: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/cond/dropout/Dropout/dropout/random_uniform/max: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/fully_connected/bias/Initializer/zeros: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/fully_connected/bias/Initializer/zeros: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/fully_connected/weights/Initializer/random_uniform/max: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/fully_connected/weights/Initializer/random_uniform/max: /job:localhost/replica:0/task:0/gpu:1\ndnn/layer0/fully_connected/weights/Initializer/random_uniform/shape: /job:localhost/replica:0/task:0/gpu:1\nI tensorflow/core/common_runtime/simple_placer.cc:818] dnn/layer0/fully_connected/weights/Initializer/random_uniform/shape: /job:localhost/replica:0/task:0/gpu:1\nOptimizeLoss/train/value: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] OptimizeLoss/train/value: /job:localhost/replica:0/task:0/cpu:0\nglobal_step/Initializer/zeros: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] global_step/Initializer/zeros: /job:localhost/replica:0/task:0/cpu:0\nWARNING:tensorflow:dnn (from tensorflow.contrib.learn.python.learn.ops.dnn_ops) is deprecated and will be removed after 2016-08-01.\nInstructions for updating:\nPlease use tf.contrib.layers.stack instead.\nWARNING:tensorflow:learn.ops.dnn is deprecated,     please use contrib.layers.dnn.\nWARNING:tensorflow:dropout (from tensorflow.contrib.learn.python.learn.ops.dropout_ops) is deprecated and will be removed after 2016-08-15.\nInstructions for updating:\nPlease use tf.contrib.layers.dropout instead.\nWARNING:tensorflow:dropout (from tensorflow.contrib.learn.python.learn.ops.dropout_ops) is deprecated and will be removed after 2016-08-15.\nInstructions for updating:\nPlease use tf.contrib.layers.dropout instead.\nWARNING:tensorflow:dropout (from tensorflow.contrib.learn.python.learn.ops.dropout_ops) is deprecated and will be removed after 2016-08-15.\nInstructions for updating:\nPlease use tf.contrib.layers.dropout instead.\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:09:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 1080, pci bus id: 0000:06:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:2) -> (device: 2, name: GeForce GTX 1080, pci bus id: 0000:05:00.0)\nE tensorflow/core/client/tensor_c_api.cc:485] Cannot assign a device to node 'save/ShardedFilename_2': Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and devices: \nIdentity: CPU \nShardedFilename: CPU \n     [[Node: save/ShardedFilename_2 = ShardedFilename[_device=\"/device:GPU:2\"](save/Const, save/ShardedFilename_2/shard, save/num_shards)]]\nTraceback (most recent call last):\n  File \"multiple_gpu.py\", line 40, in <module>\n    score = metrics.accuracy_score(y_test, classifier.predict(X_test))\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.py\", line 243, in predict\n    return self._predict(x, axis=axis, batch_size=batch_size)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.py\", line 217, in _predict\n    feed_fn=predict_data_feeder.get_feed_dict_fn())\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 686, in _infer_model\n    restore_checkpoint_path=checkpoint_path)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 680, in run_feeds\n    _restore_from_checkpoint(session, g, restore_checkpoint_path)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 106, in _restore_from_checkpoint\n    saver.restore(session, checkpoint_path)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1114, in restore\n    {self.saver_def.filename_tensor_name: save_path})\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 382, in run\n    run_metadata_ptr)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 655, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 723, in _do_run\n    target_list, options, run_metadata)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 743, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'save/ShardedFilename_2': Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and devices: \nIdentity: CPU \nShardedFilename: CPU \n     [[Node: save/ShardedFilename_2 = ShardedFilename[_device=\"/device:GPU:2\"](save/Const, save/ShardedFilename_2/shard, save/num_shards)]]\nCaused by op u'save/ShardedFilename_2', defined at:\n  File \"multiple_gpu.py\", line 40, in <module>\n    score = metrics.accuracy_score(y_test, classifier.predict(X_test))\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.py\", line 243, in predict\n    return self._predict(x, axis=axis, batch_size=batch_size)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.py\", line 217, in _predict\n    feed_fn=predict_data_feeder.get_feed_dict_fn())\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 686, in _infer_model\n    restore_checkpoint_path=checkpoint_path)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 680, in run_feeds\n    _restore_from_checkpoint(session, g, restore_checkpoint_path)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 104, in _restore_from_checkpoint\n    saver = saver or _make_saver(graph)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 96, in _make_saver\n    max_to_keep=keep_checkpoint_max)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 854, in __init__\n    restore_sequentially=restore_sequentially)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 512, in build\n    save_tensor = self._AddShardedSaveOps(filename_tensor, per_device)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 232, in _AddShardedSaveOps\n    filename_tensor, shard, num_shards_tensor)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 200, in sharded_filename\n    return gen_io_ops._sharded_filename(filename_tensor, shard, num_shards)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 460, in _sharded_filename\n    shard=shard, num_shards=num_shards, name=name)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2298, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1232, in __init__\n    self._traceback = _extract_stack()\n```\n", "sorry. its `log_device_placement=True`\n", "Thanks for the full logs, that's actually easier for me, to see the full context.  Though now I'm suspecting that the problem is largely localized by your first post.\n\nThe ShardedFileOp, defined in tensorflow/core/kernels/save_op.cc is a CPU only Op.  For some reason, the program is trying to place this Op on the GPU, and it fails at that point, presumably because there is no GPU version of the kernel.  This seems like a bug, however I notice several warnings about deprecated libraries in your log.  I'm going to reassign this report to the author of the skflow package, meanwhile you might try modifying the program to use the non-deprecated libraries.  Hopefully that will solve the problem.\n", "@proxvoculi\nOk, thank you very much:) \n", "Same error here!\n\n@poxvoculi Also tried changing the deprecated stuff by doing:\n\n```\nwith tf.device('/gpu:1'):\n        layers = tf.contrib.layers.stack(X, tf.contrib.layers.fully_connected, [32, 64, 128], scope='fc')\n    with tf.device('/gpu:2'):\n        return learn.models.logistic_regression(layers, y)\n```\n\nLeads to the same error though:\n`I tensorflow/core/common_runtime/gpu/gpu_device.cc:840] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:840] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GRID K520, pci bus id: 0000:00:04.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:840] Creating TensorFlow device (/gpu:2) -> (device: 2, name: GRID K520, pci bus id: 0000:00:05.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:840] Creating TensorFlow device (/gpu:3) -> (device: 3, name: GRID K520, pci bus id: 0000:00:06.0)\nE tensorflow/core/client/tensor_c_api.cc:485] Cannot assign a device to node 'save/ShardedFilename_2': Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and devices: \nIdentity: CPU \nShardedFilename: CPU \n     [[Node: save/ShardedFilename_2 = ShardedFilename[_device=\"/device:GPU:2\"](save/Const, save/ShardedFilename_2/shard, save/num_shards)]]\nTraceback (most recent call last):\n  File \"/home/ubuntu/retention/models/test.py\", line 40, in <module>\n    classifier.fit(X_train, y_train)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/base.py\", line 166, in fit\n    monitors=monitors)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 578, in _train_model\n    max_steps=max_steps)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 276, in _supervised_train\n    scaffold=scaffold) as super_sess:\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/supervised_session.py\", line 212, in __init__\n    self._sess = recoverable_session.RecoverableSession(self._create_session)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/recoverable_session.py\", line 46, in __init__\n    WrappedSession.__init__(self, sess_factory())\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/supervised_session.py\", line 232, in _create_session\n    init_fn=self._scaffold.init_fn)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py\", line 164, in prepare_session\n    max_wait_secs=max_wait_secs, config=config)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py\", line 203, in recover_session\n    sess.run([self._local_init_op])\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 382, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 655, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 723, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 743, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'save/ShardedFilename_2': Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and devices: \nIdentity: CPU \nShardedFilename: CPU \n     [[Node: save/ShardedFilename_2 = ShardedFilename[_device=\"/device:GPU:2\"](save/Const, save/ShardedFilename_2/shard, save/num_shards)]]\nCaused by op u'save/ShardedFilename_2', defined at:\n  File \"/home/ubuntu/retention/models/test.py\", line 40, in <module>\n    classifier.fit(X_train, y_train)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/base.py\", line 166, in fit\n    monitors=monitors)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 578, in _train_model\n    max_steps=max_steps)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 252, in _supervised_train\n    keep_checkpoint_max=keep_checkpoint_max)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/supervised_session.py\", line 152, in __init__\n    lambda: training_saver.Saver(sharded=True,\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/supervised_session.py\", line 164, in _get_or_default\n    op = default_constructor()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/supervised_session.py\", line 153, in <lambda>\n    max_to_keep=keep_checkpoint_max))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 861, in __init__\n    restore_sequentially=restore_sequentially)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 513, in build\n    save_tensor = self._AddShardedSaveOps(filename_tensor, per_device)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 233, in _AddShardedSaveOps\n    filename_tensor, shard, num_shards_tensor)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 201, in sharded_filename\n    return gen_io_ops._sharded_filename(filename_tensor, shard, num_shards)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 460, in _sharded_filename\n    shard=shard, num_shards=num_shards, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2310, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1232, in __init__\n    self._traceback = _extract_stack()`\n", "@vrv Can you take a look - seems like problem with auto-placement of other ops when some ops are pinned.\n", "This isn't really a bug -- some library or user code is trying to place \"sharded_filename\" on GPU, and sharded_filename can't be placed on GPU.\n\nThe solutions are to enable soft_placement in the ConfigProto (dangerous), or figure out why the user/library code is trying to assign a string-based operation to a GPU.\n", "Perhaps add that `soft_placement` as an option in [learn/estimators/run_config.py#L71](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/estimators/run_config.py#L71) and pass `config` into your custom `Estimator`. \n", "@vrv @terrytangyuan ,\n\nThanks for the helps, however it does not work..Same error appears\n\nI added \n\n```\nallow_soft_placement = True, \n```\n\nto Line 71 in `/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/run_config.py` \n\nand then added\n\n```\nfrom tensorflow.contrib.learn.python.learn.estimators import run_config \nconfig_  = run_config.RunConfig()\nclassifier = learn.TensorFlowEstimator(model_fn=my_model, n_classes=3, config=config_)\n```\n\nto line 39 in file `~/tensorflow/tensorflow/examples/skflow/multiple_gpu.py`\n", "What is the error? Please use `Estimator` going forward. `TensorFlowEstimator` may not work and we are removing it soon\n", "ok, i will try to replace with Estimator, may take a while, since I am quite new to tensorflow.\n\nAnd here is the message: \n\n```\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\nWARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpHNcq6t\nWARNING:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(4)]), is_sparse=False)\nWARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(3)]), is_sparse=False)\nWARNING:tensorflow:dnn (from tensorflow.contrib.learn.python.learn.ops.dnn_ops) is deprecated and will be removed after 2016-08-01.\nInstructions for updating:\nPlease use tf.contrib.layers.stack instead.\nWARNING:tensorflow:learn.ops.dnn is deprecated,     please use contrib.layers.dnn.\nWARNING:tensorflow:dropout (from tensorflow.contrib.learn.python.learn.ops.dropout_ops) is deprecated and will be removed after 2016-08-15.\nInstructions for updating:\nPlease use tf.contrib.layers.dropout instead.\nWARNING:tensorflow:dropout (from tensorflow.contrib.learn.python.learn.ops.dropout_ops) is deprecated and will be removed after 2016-08-15.\nInstructions for updating:\nPlease use tf.contrib.layers.dropout instead.\nWARNING:tensorflow:dropout (from tensorflow.contrib.learn.python.learn.ops.dropout_ops) is deprecated and will be removed after 2016-08-15.\nInstructions for updating:\nPlease use tf.contrib.layers.dropout instead.\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GeForce GTX 1080\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335\npciBusID 0000:09:00.0\nTotal memory: 7.92GiB\nFree memory: 7.38GiB\nW tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x3804080\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: \nname: GeForce GTX 1080\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335\npciBusID 0000:06:00.0\nTotal memory: 7.92GiB\nFree memory: 7.70GiB\nW tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x3e315d0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 2 with properties: \nname: GeForce GTX 1080\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335\npciBusID 0000:05:00.0\nTotal memory: 7.92GiB\nFree memory: 7.62GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 2 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y Y Y \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   Y Y Y \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 2:   Y Y Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:09:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 1080, pci bus id: 0000:06:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:2) -> (device: 2, name: GeForce GTX 1080, pci bus id: 0000:05:00.0)\nWARNING:tensorflow:dnn (from tensorflow.contrib.learn.python.learn.ops.dnn_ops) is deprecated and will be removed after 2016-08-01.\nInstructions for updating:\nPlease use tf.contrib.layers.stack instead.\nWARNING:tensorflow:learn.ops.dnn is deprecated,     please use contrib.layers.dnn.\nWARNING:tensorflow:dropout (from tensorflow.contrib.learn.python.learn.ops.dropout_ops) is deprecated and will be removed after 2016-08-15.\nInstructions for updating:\nPlease use tf.contrib.layers.dropout instead.\nWARNING:tensorflow:dropout (from tensorflow.contrib.learn.python.learn.ops.dropout_ops) is deprecated and will be removed after 2016-08-15.\nInstructions for updating:\nPlease use tf.contrib.layers.dropout instead.\nWARNING:tensorflow:dropout (from tensorflow.contrib.learn.python.learn.ops.dropout_ops) is deprecated and will be removed after 2016-08-15.\nInstructions for updating:\nPlease use tf.contrib.layers.dropout instead.\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:09:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 1080, pci bus id: 0000:06:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:2) -> (device: 2, name: GeForce GTX 1080, pci bus id: 0000:05:00.0)\nE tensorflow/core/client/tensor_c_api.cc:485] Cannot assign a device to node 'save/ShardedFilename_2': Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and devices: \nIdentity: CPU \nShardedFilename: CPU \n     [[Node: save/ShardedFilename_2 = ShardedFilename[_device=\"/device:GPU:2\"](save/Const, save/ShardedFilename_2/shard, save/num_shards)]]\nTraceback (most recent call last):\n  File \"multiple_gpu.py\", line 43, in <module>\n    score = metrics.accuracy_score(y_test, classifier.predict(X_test))\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.py\", line 243, in predict\n    return self._predict(x, axis=axis, batch_size=batch_size)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.py\", line 217, in _predict\n    feed_fn=predict_data_feeder.get_feed_dict_fn())\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 686, in _infer_model\n    restore_checkpoint_path=checkpoint_path)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 680, in run_feeds\n    _restore_from_checkpoint(session, g, restore_checkpoint_path)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 106, in _restore_from_checkpoint\n    saver.restore(session, checkpoint_path)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1114, in restore\n    {self.saver_def.filename_tensor_name: save_path})\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 382, in run\n    run_metadata_ptr)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 655, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 723, in _do_run\n    target_list, options, run_metadata)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 743, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'save/ShardedFilename_2': Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and devices: \nIdentity: CPU \nShardedFilename: CPU \n     [[Node: save/ShardedFilename_2 = ShardedFilename[_device=\"/device:GPU:2\"](save/Const, save/ShardedFilename_2/shard, save/num_shards)]]\nCaused by op u'save/ShardedFilename_2', defined at:\n  File \"multiple_gpu.py\", line 43, in <module>\n    score = metrics.accuracy_score(y_test, classifier.predict(X_test))\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.py\", line 243, in predict\n    return self._predict(x, axis=axis, batch_size=batch_size)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.py\", line 217, in _predict\n    feed_fn=predict_data_feeder.get_feed_dict_fn())\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 686, in _infer_model\n    restore_checkpoint_path=checkpoint_path)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 680, in run_feeds\n    _restore_from_checkpoint(session, g, restore_checkpoint_path)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 104, in _restore_from_checkpoint\n    saver = saver or _make_saver(graph)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 96, in _make_saver\n    max_to_keep=keep_checkpoint_max)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 854, in __init__\n    restore_sequentially=restore_sequentially)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 512, in build\n    save_tensor = self._AddShardedSaveOps(filename_tensor, per_device)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 232, in _AddShardedSaveOps\n    filename_tensor, shard, num_shards_tensor)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 200, in sharded_filename\n    return gen_io_ops._sharded_filename(filename_tensor, shard, num_shards)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 460, in _sharded_filename\n    shard=shard, num_shards=num_shards, name=name)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2298, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1232, in __init__\n    self._traceback = _extract_stack()\n```\n", "Simply change `TensorflowEstimator` to `Estimator` in the origin code, would result in following Type error\n\n```\nTraceback (most recent call last):\n  File \"multiple_gpu.py\", line 42, in <module>\n    classifier.fit(X_train, y_train)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 238, in fit\n    max_steps=max_steps)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 538, in _train_model\n    train_op, loss_op = self._get_train_ops(features, targets)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 774, in _get_train_ops\n    _, loss, train_op = self._call_model_fn(features, targets, ModeKeys.TRAIN)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 758, in _call_model_fn\n    return self._model_fn(features, targets)\n  File \"multiple_gpu.py\", line 35, in my_model\n    layers = learn.ops.dnn(X, [10, 20, 10], dropout=0.5)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/framework/python/framework/deprecation.py\", line 105, in new_func\n    return func(*args, **kwargs)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/ops/dnn_ops.py\", line 69, in dnn\n    lambda: tensor_in)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1330, in cond\n    p_2, p_1 = switch(pred, pred)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 261, in switch\n    return gen_control_flow_ops._switch(data, pred, name=name)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_control_flow_ops.py\", line 370, in _switch\n    result = _op_def_lib.apply_op(\"Switch\", data=data, pred=pred, name=name)\n  File \"/home/xlws/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 463, in apply_op\n    (prefix, dtypes.as_dtype(input_arg.type).name))\nTypeError: Input 'pred' of 'Switch' Op has type float32 that does not match expected type of bool.\n```\n\nsad..:(\n", "Closing due to inactivity. Please open a new github issue if the problem persists with recent versions."]}, {"number": 3595, "title": "Unable to replicate RNN results on a different dataset", "body": "### What is the problem?\n\n[This RNN tutorial script ](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/ptb_word_lm.py) works perfectly fine until the contents of the files are unchanged, but once changed a **KeyError** is encountered. (see the error log below)\n### Environment info\n\nOperating System:\n\nInstalled version of CUDA and cuDNN: \n\nlrwxrwxrwx 1 root root       12 May 24 00:01 libcuda.so -> libcuda.so.1\nlrwxrwxrwx 1 root root       17 May 24 00:01 libcuda.so.1 -> libcuda.so.352.41\n-rwxr-xr-x 1 root root 14280360 May 24 00:01 libcuda.so.352.41\nlrwxrwxrwx 1 root root       29 May 24 00:02 libcudnn.so -> /etc/alternatives/libcudnn_so\nlrwxrwxrwx 1 root root       17 Feb  9 07:47 libcudnn.so.4 -> libcudnn.so.4.0.7\n-rw-r--r-- 1 root root 61453024 Feb  9 07:47 libcudnn.so.4.0.7\nlrwxrwxrwx 1 root root       32 May 24 00:02 libcudnn_static.a -> /etc/alternatives/libcudnn_stlib\n-rw-r--r-- 1 root root 62025862 Feb  9 07:47 libcudnn_static_v4.a\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed: \n   **_Ubuntu/Linux 64-bit, GPU enabled, Python 2.7**_\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\n0.9.0\n### Steps to reproduce\n1. Download data from here: http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz \n2. Cloned the tensorflow git repository, and be in the root of the git tree.\n3. cd tensorflow/models/rnn/ptb\n4. python ptb_word_lm.py --data_path=/tmp/simple-examples/data/ --model small\n### What have you tried?\n1. Change the contents of the file ptb.train.txt OR ptb.valid.txt OR ptb.test.txt\n### Logs or other output that would be helpful\n\nTraceback (most recent call last):\n  File \"ptb_word_lm.py\", line 350, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"ptb_word_lm.py\", line 289, in main\n    raw_data = reader.ptb_raw_data(FLAGS.data_path)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/models/rnn/ptb/reader.py\", line 76, in ptb_raw_data\n    valid_data = _file_to_word_ids(valid_path, word_to_id)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/models/rnn/ptb/reader.py\", line 48, in _file_to_word_ids\n    return [word_to_id[word] for word in data]\nKeyError: '[The'\n\n**_NOTE**_: For this specific example, the contents of ptb.valid.txt were changed and the first line of this file is \"[The Parent's Assistant, by Maria Edgeworth]\"\n", "comments": ["Hi, \nI tried a bunch of things and tried to run it. Couldn't get it working. I don't think this script would be tailored specifically to the PTB data, so I am pretty sure I am missing something here. Any help/hint would be highly appreciated. Thanks!\n", "@michaelisard Probably you have seen something like this before #3567 .\n", "This is not clearly a correctness/performance issue with TensorFlow, rather it's a question about usage of a particular program, so it would be more appropriate to ask this question on StackOverflow.  Please ask it there, and tag it with the 'tensorflow' tag.\n\nI did take a quck look at 'ptb_valid.txt' in the *.tgz bundle referenced above.  It looks like the fragments are newline separated.  I didn't see any use of '[' or ']' to delimit text.   From your question, it sounds like you're using those chars, which may be incorrect.\n"]}, {"number": 3594, "title": "Moved eightbit graph trimming to before output_nodes definition", "body": "Currently fails when output_nodes have inputs that are removed by graph trimming. Example below:\n\n```\nimport tensorflow as tf\nfrom quantize_graph import GraphRewriter\nfrom tensorflow.python.framework.graph_util import \\\n    convert_variables_to_constants\n\ng = tf.Graph()\nwith g.as_default():\n    x = tf.placeholder(shape=(2,), dtype=tf.float32, name='input_node')\n    y = tf.get_variable(name='quantize_target', shape=(2,), dtype=tf.float32,\n                        initializer=tf.random_normal_initializer(0., 1.))\n    z = tf.add(x, y, name='output_node')\n    init = tf.initialize_all_variables()\n\nwith tf.Session(graph=g) as sess:\n    sess.run(init)\n    frozen_def = convert_variables_to_constants(\n        sess, g.as_graph_def(), ['output_node'])\n\nrewriter = GraphRewriter(frozen_def, 'eightbit')\noutput_def = rewriter.rewrite(['output_node'])\n```\n\nTraceback:\n\n```\nTraceback (most recent call last):\n  File \"quantize.py\", line 22, in <module>\n    output_def = rewriter.rewrite(['output_node'])\n  File \"<path>/quantize_graph.py\", line 333, in rewrite\n    self.eightbitize_nodes_recursively(output_node)\n  File \"<path>/quantize_graph.py\", line 455, in eightbitize_nodes_recursively\n    input_node = self.nodes_map[input_node_name]\nKeyError: u'quantize_target/read'\n\n```\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n\nOn 1 Aug 2016 10:36 AM, \"googlebot\" notifications@github.com wrote:\n\n> Thanks for your pull request. It looks like this may be your first\n> contribution to a Google open source project. Before we can look at your\n> pull request, you'll need to sign a Contributor License Agreement (CLA).\n> \n> \ud83d\udcdd _Please visit https://cla.developers.google.com/\n> https://cla.developers.google.com/ to sign._\n> \n> Once you've signed, please reply here (e.g. I signed it!) and we'll\n> \n> ## verify. Thanks.\n> - If you've already signed a CLA, it's possible we don't have your\n>   GitHub username or you're using a different email address. Check your\n>   existing CLA data https://cla.developers.google.com/clas and verify\n>   that your email is set on your git commits\n>   https://help.github.com/articles/setting-your-email-in-git/.\n> - If you signed the CLA as a corporation, please let us know the\n>   company's name.\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/3594#issuecomment-236467020,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AAoOq5WXZxDd5gs0f0EezJvwKlrVBA9Tks5qbT-VgaJpZM4JZKRU\n> .\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "Assigning @petewarden for reviewing. \n", "Just realized this will probably result in issues when output nodes themselves are trimmed. Will ponder further...\n", "@jackd should we wait for you to ponder the issue before we move forward with review / testing?\n", "@danmane Sorry, busy time at work. Changed the interface of GraphRewriter.remove_unneeded_nodes to allow for an optional whitelist, and the corresponding call in eightbitizing code to node remove any of the output nodes. As a result, identity outputs are not pruned from the graph. In certain circumstances this is slightly sub-optimal: for example, it would be possible to remove an identity mapping resulting in an output node by removing the input from the graph and relinking dependencies to the output... but I wasn't able to resolve control edge tests with this approach. In these rare cases, I find it difficult to imagine a single extra identity call should be too strenuous for a system.\n", "@petewarden could you please review this?\n", "@jackd Sorry for the slow process here :( Can you please fix merge conflicts, and then I will make sure that someone takes a look promptly.\n", "Pinging @jackd -- can you fix the merge conflicts?\n", "Closing due to inactivity. Please merge the conflicts and re-open if you want us to take another look.\n"]}, {"number": 3593, "title": "How to run custom encoder-decoder in Tensorflow using available APIs?", "body": "I need to run a encoder-decoder model in Tensorflow. I see that using the available APIs `basic_rnn_seq2seq(encoder_input_data, decoder_input_data, lstm_cell)` etc., an encoder-decoder system can be created. However, few pertaining issues are:\n1. How can we enter the embeddings such as word2vec in such model? I am\n   aware that we can do embedding lookup but as per the API\n   `encoder_input_data` is a list of 2D Tensor of size batch_size x\n   input_size. How can each word be represented using its respective word embedding in this setup? Even `embedding_rnn_seq2seq` internally extracts the embeddings. How to give pre-calculated word embeddings as input? \n2. How can we get the cost and perplexity through the API?\n3. In case of test instances, we may not know the corresponding decoder inputs. How to handle such case?\n", "comments": ["This kind of usage question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow). GitHub issues are for TensorFlow bugs and installation issues. Thanks!\n"]}, {"number": 3592, "title": "Regex tag and zoom in for histogram summary does not work properly", "body": "Since ResNet could create hundreds of layers and the initial activation value of layers are also very large, I found I need to zoom in multiple times, and also have hundreds of histogram summary in one tag group. So it would be critical to be able to zoom, and also break summary down according to regex.\n\nHowever, I found though for scalar summary, it works pretty well, for histogram summary, I can only zoom in once in 0.9.0, and not even once in 0.10.0. Also the regex group function seems to not work at all (see the photo below, it seems all summary comes in whatever the regex is --- I write a \"###\" in this case). \n\nAt first I though it is just there are too many graphs, so my computer stuck. But after I tried some small network, the phenomenon held. Could it be fixed? Thanks a lot.\n\n![image](https://cloud.githubusercontent.com/assets/2428233/17275589/b6d748b4-573f-11e6-8a96-f95decbefc7e.png)\n", "comments": ["Zoom doesn't work on those histograms. That's currently working as intended. In a future release, we will rename the histograms to \"distribution charts\" and add in true histogram charts which are much nicer. \n\nFor the performance issues: in the future, we hope to improve performance for large numbers of charts in a single group, but it's not on the immediate roadmap. We are actively working on ways to make it easier to set up the tag groups.\n\nYou're right that the regex filter doesn't work on the histogram tab. We'll dig into it and report back.\n", "Thanks for reaching back. Performance perhaps won't be an issue when regex\nis working since we could filter relevant out each time.\n\nAs for zooming, I remember it works in 0.5, at least. It is nice to have\nthat feature around, since sometime, the vibration in the network may cause\nactivation or parameters to reach a far larger value than the values when\nthe network stablizes. To be able to zoom in sometimes helps a lot,\notherwise, the stable values are indiscernable.\n\nOn 11 August 2016 at 01:26, Daniel W Mane notifications@github.com wrote:\n\n> Zoom doesn't work on those histograms. That's currently working as\n> intended. In a future release, we will rename the histograms to\n> \"distribution charts\" and add in true histogram charts which are much\n> nicer.\n> \n> For the performance issues: in the future, we hope to improve performance\n> for large numbers of charts in a single group, but it's not on the\n> immediate roadmap. We are actively working on ways to make it easier to set\n> up the tag groups.\n> \n> You're right that the regex filter doesn't work on the histogram tab.\n> We'll dig into it and report back.\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3592#issuecomment-238939630,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ACUNSZ0BIXc5niYyFkIxl2ar39q7_xtvks5qegnhgaJpZM4JY_b9\n> .\n", "Closing due to inactivity. Feel free to open a new github issue if the problem is still current."]}, {"number": 3591, "title": " How to use python code about  the mnist  to  build the android apk ", "body": "just as the title said .\nI just want to come true the mnist  on the android like the tensorflow android_demo\nnow I just know how to build the model with python\nand what I should do the next.\n", "comments": ["@zwb88008 Are you trying to find this https://github.com/miyosuda/TensorFlowAndroidMNIST ?\n\n`TensorFlowAndroidMNIST` is the app to run directly on you Android, just like `android_demo`. Python seems not to be recommended to integrated with Android/Java application and I hope this could help.\n", "@tobegit3hub thank you very much . it is all I want to find.\n", "You're so welcome. Feel free to close the issue and we're looking forward to any good product about TensorFlow \ud83d\ude03 \n", "Thanks @tobegit3hub :)"]}, {"number": 3590, "title": "Added missing name in release.md", "body": "Simply added my name (non-Googler) and removed my nickname. \n", "comments": ["I'm sorry about this. I thought I fixed that last time, but maybe it was only on the 0.9 branch or something.\n", "No worries. :-)\n"]}, {"number": 3589, "title": "bazel 0.3.1 compilation failure on master branch", "body": "**Edit: There is no problem with bazel 0.3.1 and TF 0.9, problem present with master branch and 0.10 RC**\n\nUbuntu 14 x64 MSI GS60 (860M - compute score 3.0)\n\n```\nprintf \"\\nn\\ny\\n\\n7.5\\n\\n\\n\\n3.0\\n\" | ./configure\nbazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\n```\n\n:\n\n```\n[several minutes of successful compiling]\n...\nERROR: /home/ggg/000/tensorflow/tensorflow/core/kernels/BUILD:1515:1: undeclared inclusion(s) in rule '//tensorflow/core/kernels:depth_space_ops_gpu':\nthis rule is missing dependency declarations for the following files included by 'tensorflow/core/kernels/depthtospace_op_gpu.cu.cc':\n  '/usr/local/cuda-7.5/include/cuda_runtime.h'\n  '/usr/local/cuda-7.5/include/host_config.h'\n  '/usr/local/cuda-7.5/include/builtin_types.h'\n  '/usr/local/cuda-7.5/include/device_types.h'\n  '/usr/local/cuda-7.5/include/host_defines.h'\n  '/usr/local/cuda-7.5/include/driver_types.h'\n  '/usr/local/cuda-7.5/include/surface_types.h'\n  '/usr/local/cuda-7.5/include/texture_types.h'\n  '/usr/local/cuda-7.5/include/vector_types.h'\n  '/usr/local/cuda-7.5/include/channel_descriptor.h'\n  '/usr/local/cuda-7.5/include/cuda_runtime_api.h'\n  '/usr/local/cuda-7.5/include/cuda_device_runtime_api.h'\n  '/usr/local/cuda-7.5/include/driver_functions.h'\n  '/usr/local/cuda-7.5/include/vector_functions.h'\n  '/usr/local/cuda-7.5/include/vector_functions.hpp'\n  '/usr/local/cuda-7.5/include/common_functions.h'\n  '/usr/local/cuda-7.5/include/math_functions.h'\n  '/usr/local/cuda-7.5/include/math_functions.hpp'\n  '/usr/local/cuda-7.5/include/math_functions_dbl_ptx3.h'\n  '/usr/local/cuda-7.5/include/math_functions_dbl_ptx3.hpp'\n  '/usr/local/cuda-7.5/include/cuda_surface_types.h'\n  '/usr/local/cuda-7.5/include/cuda_texture_types.h'\n  '/usr/local/cuda-7.5/include/device_functions.h'\n  '/usr/local/cuda-7.5/include/device_functions.hpp'\n  '/usr/local/cuda-7.5/include/device_atomic_functions.h'\n  '/usr/local/cuda-7.5/include/device_atomic_functions.hpp'\n  '/usr/local/cuda-7.5/include/device_double_functions.h'\n  '/usr/local/cuda-7.5/include/device_double_functions.hpp'\n  '/usr/local/cuda-7.5/include/sm_20_atomic_functions.h'\n  '/usr/local/cuda-7.5/include/sm_20_atomic_functions.hpp'\n  '/usr/local/cuda-7.5/include/sm_32_atomic_functions.h'\n  '/usr/local/cuda-7.5/include/sm_32_atomic_functions.hpp'\n  '/usr/local/cuda-7.5/include/sm_35_atomic_functions.h'\n  '/usr/local/cuda-7.5/include/sm_20_intrinsics.h'\n  '/usr/local/cuda-7.5/include/sm_20_intrinsics.hpp'\n  '/usr/local/cuda-7.5/include/sm_30_intrinsics.h'\n  '/usr/local/cuda-7.5/include/sm_30_intrinsics.hpp'\n  '/usr/local/cuda-7.5/include/sm_32_intrinsics.h'\n  '/usr/local/cuda-7.5/include/sm_32_intrinsics.hpp'\n  '/usr/local/cuda-7.5/include/sm_35_intrinsics.h'\n  '/usr/local/cuda-7.5/include/surface_functions.h'\n  '/usr/local/cuda-7.5/include/surface_functions.hpp'\n  '/usr/local/cuda-7.5/include/texture_fetch_functions.h'\n  '/usr/local/cuda-7.5/include/texture_fetch_functions.hpp'\n  '/usr/local/cuda-7.5/include/texture_indirect_functions.h'\n  '/usr/local/cuda-7.5/include/texture_indirect_functions.hpp'\n  '/usr/local/cuda-7.5/include/surface_indirect_functions.h'\n  '/usr/local/cuda-7.5/include/surface_indirect_functions.hpp'\n  '/usr/local/cuda-7.5/include/device_launch_parameters.h'\n  '/usr/local/cuda-7.5/include/cuda_fp16.h'\n  '/usr/local/cuda-7.5/include/math_constants.h'\n  '/usr/local/cuda-7.5/include/curand_kernel.h'\n  '/usr/local/cuda-7.5/include/curand.h'\n  '/usr/local/cuda-7.5/include/curand_discrete.h'\n  '/usr/local/cuda-7.5/include/curand_precalc.h'\n  '/usr/local/cuda-7.5/include/curand_mrg32k3a.h'\n  '/usr/local/cuda-7.5/include/curand_mtgp32_kernel.h'\n  '/usr/local/cuda-7.5/include/cuda.h'\n  '/usr/local/cuda-7.5/include/curand_mtgp32.h'\n  '/usr/local/cuda-7.5/include/curand_philox4x32_x.h'\n  '/usr/local/cuda-7.5/include/curand_globals.h'\n  '/usr/local/cuda-7.5/include/curand_uniform.h'\n  '/usr/local/cuda-7.5/include/curand_normal.h'\n  '/usr/local/cuda-7.5/include/curand_normal_static.h'\n  '/usr/local/cuda-7.5/include/curand_lognormal.h'\n  '/usr/local/cuda-7.5/include/curand_poisson.h'\n  '/usr/local/cuda-7.5/include/curand_discrete2.h'.\nnvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.\nnvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nUse --verbose_failures to see the command lines of failed build steps.\nINFO: Elapsed time: 464.576s, Critical Path: 281.74s\n```\n", "comments": ["I was able to solve this in a (somewhat hacky) way by following the instructions here:\n\nhttp://stackoverflow.com/a/38586576/6598481\n\nIn short, add the following within toolchain{} in the file tensorflow/third_party/gpus/crosstool/CROSSTOOL.\n\n`cxx_builtin_include_directory: \"/usr/local/cuda-7.5/include\"`\n\nThis is discussed in #1157.\n", "This didn't fix the problem. Through it appears it changed it somewhat.\n\n```\nERROR: /home/ggg/000/tensorflow/tensorflow/core/kernels/BUILD:1496:1: undeclared inclusion(s) in rule '//tensorflow/core/kernels:batchtospace_op_gpu':\nthis rule is missing dependency declarations for the following files included by 'tensorflow/core/kernels/batchtospace_op_gpu.cu.cc':\n  '/usr/local/cuda-7.5/include/cuda_runtime.h'\n  '/usr/local/cuda-7.5/include/host_config.h'\n  '/usr/local/cuda-7.5/include/builtin_types.h'\n  '/usr/local/cuda-7.5/include/device_types.h'\n  '/usr/local/cuda-7.5/include/host_defines.h'\n  '/usr/local/cuda-7.5/include/driver_types.h'\n  '/usr/local/cuda-7.5/include/surface_types.h'\n  '/usr/local/cuda-7.5/include/texture_types.h'\n  '/usr/local/cuda-7.5/include/vector_types.h'\n  '/usr/local/cuda-7.5/include/channel_descriptor.h'\n  '/usr/local/cuda-7.5/include/cuda_runtime_api.h'\n  '/usr/local/cuda-7.5/include/cuda_device_runtime_api.h'\n  '/usr/local/cuda-7.5/include/driver_functions.h'\n  '/usr/local/cuda-7.5/include/vector_functions.h'\n  '/usr/local/cuda-7.5/include/vector_functions.hpp'\n  '/usr/local/cuda-7.5/include/common_functions.h'\n  '/usr/local/cuda-7.5/include/math_functions.h'\n  '/usr/local/cuda-7.5/include/math_functions.hpp'\n  '/usr/local/cuda-7.5/include/math_functions_dbl_ptx3.h'\n  '/usr/local/cuda-7.5/include/math_functions_dbl_ptx3.hpp'\n  '/usr/local/cuda-7.5/include/cuda_surface_types.h'\n  '/usr/local/cuda-7.5/include/cuda_texture_types.h'\n  '/usr/local/cuda-7.5/include/device_functions.h'\n  '/usr/local/cuda-7.5/include/device_functions.hpp'\n  '/usr/local/cuda-7.5/include/device_atomic_functions.h'\n  '/usr/local/cuda-7.5/include/device_atomic_functions.hpp'\n  '/usr/local/cuda-7.5/include/device_double_functions.h'\n  '/usr/local/cuda-7.5/include/device_double_functions.hpp'\n  '/usr/local/cuda-7.5/include/sm_20_atomic_functions.h'\n  '/usr/local/cuda-7.5/include/sm_20_atomic_functions.hpp'\n  '/usr/local/cuda-7.5/include/sm_32_atomic_functions.h'\n  '/usr/local/cuda-7.5/include/sm_32_atomic_functions.hpp'\n  '/usr/local/cuda-7.5/include/sm_35_atomic_functions.h'\n  '/usr/local/cuda-7.5/include/sm_20_intrinsics.h'\n  '/usr/local/cuda-7.5/include/sm_20_intrinsics.hpp'\n  '/usr/local/cuda-7.5/include/sm_30_intrinsics.h'\n  '/usr/local/cuda-7.5/include/sm_30_intrinsics.hpp'\n  '/usr/local/cuda-7.5/include/sm_32_intrinsics.h'\n  '/usr/local/cuda-7.5/include/sm_32_intrinsics.hpp'\n  '/usr/local/cuda-7.5/include/sm_35_intrinsics.h'\n  '/usr/local/cuda-7.5/include/surface_functions.h'\n  '/usr/local/cuda-7.5/include/surface_functions.hpp'\n  '/usr/local/cuda-7.5/include/texture_fetch_functions.h'\n  '/usr/local/cuda-7.5/include/texture_fetch_functions.hpp'\n  '/usr/local/cuda-7.5/include/texture_indirect_functions.h'\n  '/usr/local/cuda-7.5/include/texture_indirect_functions.hpp'\n  '/usr/local/cuda-7.5/include/surface_indirect_functions.h'\n  '/usr/local/cuda-7.5/include/surface_indirect_functions.hpp'\n  '/usr/local/cuda-7.5/include/device_launch_parameters.h'\n  '/usr/local/cuda-7.5/include/cuda_fp16.h'\n  '/usr/local/cuda-7.5/include/math_constants.h'\n  '/usr/local/cuda-7.5/include/curand_kernel.h'\n  '/usr/local/cuda-7.5/include/curand.h'\n  '/usr/local/cuda-7.5/include/curand_discrete.h'\n  '/usr/local/cuda-7.5/include/curand_precalc.h'\n  '/usr/local/cuda-7.5/include/curand_mrg32k3a.h'\n  '/usr/local/cuda-7.5/include/curand_mtgp32_kernel.h'\n  '/usr/local/cuda-7.5/include/cuda.h'\n  '/usr/local/cuda-7.5/include/curand_mtgp32.h'\n  '/usr/local/cuda-7.5/include/curand_philox4x32_x.h'\n  '/usr/local/cuda-7.5/include/curand_globals.h'\n  '/usr/local/cuda-7.5/include/curand_uniform.h'\n  '/usr/local/cuda-7.5/include/curand_normal.h'\n  '/usr/local/cuda-7.5/include/curand_normal_static.h'\n  '/usr/local/cuda-7.5/include/curand_lognormal.h'\n  '/usr/local/cuda-7.5/include/curand_poisson.h'\n  '/usr/local/cuda-7.5/include/curand_discrete2.h'.\nnvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.\nnvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nUse --verbose_failures to see the command lines of failed build steps.\nINFO: Elapsed time: 181.759s, Critical Path: 175.10s\n```\n", "@martinwicke would you take a look?\n", "I can reproduce this issue\nafter I change bazel back to 0.3.0 and 0.2.3, the problem still there.\nenv:\nxubuntu 16.04.1\ngcc/g++ 4.9.3\nbazel 0.3.1 0.3.0 0.2.3\npython 2.7.12\ncuda 8.0rc\ncudnn 5.0.5\n\nERROR: /home/terrypang/workspace/tensorflow/tensorflow/core/kernels/BUILD:1496:1: undeclared inclusion(s) in rule '//tensorflow/core/kernels:batchtospace_op_gpu':\nthis rule is missing dependency declarations for the following files included by 'tensorflow/core/kernels/batchtospace_op_gpu.cu.cc':\n  '/usr/local/cuda-8.0/include/cuda_runtime.h'\n  '/usr/local/cuda-8.0/include/host_config.h'\n  '/usr/local/cuda-8.0/include/builtin_types.h'\n  '/usr/local/cuda-8.0/include/device_types.h'\n  '/usr/local/cuda-8.0/include/host_defines.h'\n  '/usr/local/cuda-8.0/include/driver_types.h'\n  '/usr/local/cuda-8.0/include/surface_types.h'\n  '/usr/local/cuda-8.0/include/texture_types.h'\n  '/usr/local/cuda-8.0/include/vector_types.h'\n  '/usr/local/cuda-8.0/include/library_types.h'\n  '/usr/local/cuda-8.0/include/channel_descriptor.h'\n  '/usr/local/cuda-8.0/include/cuda_runtime_api.h'\n  '/usr/local/cuda-8.0/include/cuda_device_runtime_api.h'\n  '/usr/local/cuda-8.0/include/driver_functions.h'\n  '/usr/local/cuda-8.0/include/vector_functions.h'\n  '/usr/local/cuda-8.0/include/vector_functions.hpp'\n  '/usr/local/cuda-8.0/include/common_functions.h'\n  '/usr/local/cuda-8.0/include/math_functions.h'\n  '/usr/local/cuda-8.0/include/math_functions.hpp'\n  '/usr/local/cuda-8.0/include/math_functions_dbl_ptx3.h'\n  '/usr/local/cuda-8.0/include/math_functions_dbl_ptx3.hpp'\n  '/usr/local/cuda-8.0/include/cuda_surface_types.h'\n  '/usr/local/cuda-8.0/include/cuda_texture_types.h'\n  '/usr/local/cuda-8.0/include/device_functions.h'\n  '/usr/local/cuda-8.0/include/device_functions.hpp'\n  '/usr/local/cuda-8.0/include/device_atomic_functions.h'\n  '/usr/local/cuda-8.0/include/device_atomic_functions.hpp'\n  '/usr/local/cuda-8.0/include/device_double_functions.h'\n  '/usr/local/cuda-8.0/include/device_double_functions.hpp'\n  '/usr/local/cuda-8.0/include/sm_20_atomic_functions.h'\n  '/usr/local/cuda-8.0/include/sm_20_atomic_functions.hpp'\n  '/usr/local/cuda-8.0/include/sm_32_atomic_functions.h'\n  '/usr/local/cuda-8.0/include/sm_32_atomic_functions.hpp'\n  '/usr/local/cuda-8.0/include/sm_35_atomic_functions.h'\n  '/usr/local/cuda-8.0/include/sm_60_atomic_functions.h'\n  '/usr/local/cuda-8.0/include/sm_60_atomic_functions.hpp'\n  '/usr/local/cuda-8.0/include/sm_20_intrinsics.h'\n  '/usr/local/cuda-8.0/include/sm_20_intrinsics.hpp'\n  '/usr/local/cuda-8.0/include/sm_30_intrinsics.h'\n  '/usr/local/cuda-8.0/include/sm_30_intrinsics.hpp'\n  '/usr/local/cuda-8.0/include/sm_32_intrinsics.h'\n  '/usr/local/cuda-8.0/include/sm_32_intrinsics.hpp'\n  '/usr/local/cuda-8.0/include/sm_35_intrinsics.h'\n  '/usr/local/cuda-8.0/include/surface_functions.h'\n  '/usr/local/cuda-8.0/include/texture_fetch_functions.h'\n  '/usr/local/cuda-8.0/include/texture_indirect_functions.h'\n  '/usr/local/cuda-8.0/include/surface_indirect_functions.h'\n  '/usr/local/cuda-8.0/include/device_launch_parameters.h'\n  '/usr/local/cuda-8.0/include/cuda_fp16.h'\n  '/usr/local/cuda-8.0/include/math_constants.h'\n  '/usr/local/cuda-8.0/include/curand_kernel.h'\n  '/usr/local/cuda-8.0/include/curand.h'\n  '/usr/local/cuda-8.0/include/curand_discrete.h'\n  '/usr/local/cuda-8.0/include/curand_precalc.h'\n  '/usr/local/cuda-8.0/include/curand_mrg32k3a.h'\n  '/usr/local/cuda-8.0/include/curand_mtgp32_kernel.h'\n  '/usr/local/cuda-8.0/include/cuda.h'\n  '/usr/local/cuda-8.0/include/curand_mtgp32.h'\n  '/usr/local/cuda-8.0/include/curand_philox4x32_x.h'\n  '/usr/local/cuda-8.0/include/curand_globals.h'\n  '/usr/local/cuda-8.0/include/curand_uniform.h'\n  '/usr/local/cuda-8.0/include/curand_normal.h'\n  '/usr/local/cuda-8.0/include/curand_normal_static.h'\n  '/usr/local/cuda-8.0/include/curand_lognormal.h'\n  '/usr/local/cuda-8.0/include/curand_poisson.h'\n  '/usr/local/cuda-8.0/include/curand_discrete2.h'.\nnvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.\nnvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.\nTarget //tensorflow/cc:tutorials_example_trainer failed to build\nUse --verbose_failures to see the command lines of failed build steps.\nINFO: Elapsed time: 311.674s, Critical Path: 256.05s\n", "Just now I grabbed the 0.9 github release. No issues [with bazel 0.3.1] whatsoever.\nI have tried the 0.10 RC github release yesterday and it had the same issue(s).\n", "@zheng-xq, @josh11b, It looks like depthtospace and batchtospace are missing some dependency on cuda? Is this something you recognize?\n", "TensorFlow should not include the paths like that. It should be like \"third_party/gpus/cuda/include/...\". \n\nSo it is possible that those headers are implicitly included by nvcc. But I cannot reproduce this problem with my local bazel 2.0. My guess is that the newer bazel checks those include dependencies differently. \n", "This is outside my expertise.\n", "@damienmg do you have an idea of what is happening here? \n", "Investigating. It might be related to symlink. I needs to install cuda on my workstation.\n", "I am stuck when needing to download cuDNN. Is there any good guide I can follow to install those dependency without signing a 1000 line license?\n", "(alternatively if there is a simple docker image I can use to repro).\n", "If we would help you with that we would probably violate the license agreement which you so carefully are trying to avoid signing. ;-) \n", "IANAL so I cannot sign it on the behalf of Google.\n", "(I am speaking of the thing you must accept to be allowed to download cuDNN). Maybe that's perfectly fine but only @martinwicke or someone else from TF at Google might know :) \n", "x64 cuDNN v5 for cuda 7.5: https://www.sendspace.com/file/v142i4\n", "Thanks I was able to repro.\n", "I am going offline for the day but I have fixed it with:\n\n```\n$ git diff third_party/gpus/crosstool/CROSSTOOL\ndiff --git a/third_party/gpus/crosstool/CROSSTOOL b/third_party/gpus/crosstool/CROSSTOOL\nindex 8db81a9..dfc568b 100644\n--- a/third_party/gpus/crosstool/CROSSTOOL\n+++ b/third_party/gpus/crosstool/CROSSTOOL\n@@ -58,7 +58,7 @@ toolchain {\n   # absolute locations and has no remote execution, yet. However, this will need\n   # to be fixed, maybe with auto-detection?\n   cxx_builtin_include_directory: \"/usr/lib/gcc/\"\n-  cxx_builtin_include_directory: \"/usr/local/include\"\n+  cxx_builtin_include_directory: \"/usr/local\"\n   cxx_builtin_include_directory: \"/usr/include\"\n   tool_path { name: \"gcov\" path: \"/usr/bin/gcov\" }\n```\n\nSo it means only it missing the include path. #3269 should fix that.\n", "Is there an ETA for when this will be merged into master?\n", "I am not entirely sure whether it is okay to change this for all users. We will look at this problem in more details and see whether this is the best way. Meanwhile, please use this patch to work around this issue. \n", "@alexmonroe87: before the end of the week I guess, there are still a couple of issue with tests.\n\n@zheng-xq: this is absolutely not correct to change this but absolutely not worth than hard-coding /usr/local/include :). The correct fix is #3269 \n", "What's the status/ETA of that fix? \n", "The status is David has still to fix the breakage and then the change is good to merge from my perspective.\n", "This is presumably not affecting everyone. Since a master patch is not forthcoming, what is it about our environments that causes it? Maybe we can fix that.\n", "Something I noticed that is happening after I applied damienmg's fix is that bazel dies a lot.\n`Error: unexpected EOF from Bazel server.`\nNo sure if it's related, restarting does appear to help and it finishes the build.\n", "I guess the EOF is because the Bazel server get killed. Generally happens when you have a OOM killer that decide that bazel is using too much memory.\n", "@damienmg Now your fix no longer works (can't be applied), something was done to the CROSSTOOL it seems. I'm somewhat confused as to why I'm even getting this error, surely if it was affecting more people something would have been done already, why so few people get this error?\n\n```\nERROR: /home/ggg/000/tensorflow/tensorflow/core/kernels/BUILD:1531:1: undeclared inclusion(s) in rule '//tensorflow/core/kernels:depth_space_ops_gpu':\nthis rule is missing dependency declarations for the following files included by 'tensorflow/core/kernels/spacetodepth_op_gpu.cu.cc':\n  '/usr/local/cuda-7.5/include/cuda_runtime.h'\n  '/usr/local/cuda-7.5/include/host_config.h'\n  '/usr/local/cuda-7.5/include/builtin_types.h'\n  '/usr/local/cuda-7.5/include/device_types.h'\n  '/usr/local/cuda-7.5/include/host_defines.h'\n  '/usr/local/cuda-7.5/include/driver_types.h'\n  '/usr/local/cuda-7.5/include/surface_types.h'\n  '/usr/local/cuda-7.5/include/texture_types.h'\n  '/usr/local/cuda-7.5/include/vector_types.h'\n  '/usr/local/cuda-7.5/include/channel_descriptor.h'\n  '/usr/local/cuda-7.5/include/cuda_runtime_api.h'\n  '/usr/local/cuda-7.5/include/cuda_device_runtime_api.h'\n  '/usr/local/cuda-7.5/include/driver_functions.h'\n  '/usr/local/cuda-7.5/include/vector_functions.h'\n  '/usr/local/cuda-7.5/include/vector_functions.hpp'\n  '/usr/local/cuda-7.5/include/common_functions.h'\n  '/usr/local/cuda-7.5/include/math_functions.h'\n  '/usr/local/cuda-7.5/include/math_functions.hpp'\n  '/usr/local/cuda-7.5/include/math_functions_dbl_ptx3.h'\n  '/usr/local/cuda-7.5/include/math_functions_dbl_ptx3.hpp'\n  '/usr/local/cuda-7.5/include/cuda_surface_types.h'\n  '/usr/local/cuda-7.5/include/cuda_texture_types.h'\n  '/usr/local/cuda-7.5/include/device_functions.h'\n  '/usr/local/cuda-7.5/include/device_functions.hpp'\n  '/usr/local/cuda-7.5/include/device_atomic_functions.h'\n  '/usr/local/cuda-7.5/include/device_atomic_functions.hpp'\n  '/usr/local/cuda-7.5/include/device_double_functions.h'\n  '/usr/local/cuda-7.5/include/device_double_functions.hpp'\n  '/usr/local/cuda-7.5/include/sm_20_atomic_functions.h'\n  '/usr/local/cuda-7.5/include/sm_20_atomic_functions.hpp'\n  '/usr/local/cuda-7.5/include/sm_32_atomic_functions.h'\n  '/usr/local/cuda-7.5/include/sm_32_atomic_functions.hpp'\n  '/usr/local/cuda-7.5/include/sm_35_atomic_functions.h'\n  '/usr/local/cuda-7.5/include/sm_20_intrinsics.h'\n  '/usr/local/cuda-7.5/include/sm_20_intrinsics.hpp'\n  '/usr/local/cuda-7.5/include/sm_30_intrinsics.h'\n  '/usr/local/cuda-7.5/include/sm_30_intrinsics.hpp'\n  '/usr/local/cuda-7.5/include/sm_32_intrinsics.h'\n  '/usr/local/cuda-7.5/include/sm_32_intrinsics.hpp'\n  '/usr/local/cuda-7.5/include/sm_35_intrinsics.h'\n  '/usr/local/cuda-7.5/include/surface_functions.h'\n  '/usr/local/cuda-7.5/include/surface_functions.hpp'\n  '/usr/local/cuda-7.5/include/texture_fetch_functions.h'\n  '/usr/local/cuda-7.5/include/texture_fetch_functions.hpp'\n  '/usr/local/cuda-7.5/include/texture_indirect_functions.h'\n  '/usr/local/cuda-7.5/include/texture_indirect_functions.hpp'\n  '/usr/local/cuda-7.5/include/surface_indirect_functions.h'\n  '/usr/local/cuda-7.5/include/surface_indirect_functions.hpp'\n  '/usr/local/cuda-7.5/include/device_launch_parameters.h'\n  '/usr/local/cuda-7.5/include/cuda_fp16.h'\n  '/usr/local/cuda-7.5/include/math_constants.h'\n  '/usr/local/cuda-7.5/include/curand_kernel.h'\n  '/usr/local/cuda-7.5/include/curand.h'\n  '/usr/local/cuda-7.5/include/curand_discrete.h'\n  '/usr/local/cuda-7.5/include/curand_precalc.h'\n  '/usr/local/cuda-7.5/include/curand_mrg32k3a.h'\n  '/usr/local/cuda-7.5/include/curand_mtgp32_kernel.h'\n  '/usr/local/cuda-7.5/include/cuda.h'\n  '/usr/local/cuda-7.5/include/curand_mtgp32.h'\n  '/usr/local/cuda-7.5/include/curand_philox4x32_x.h'\n  '/usr/local/cuda-7.5/include/curand_globals.h'\n  '/usr/local/cuda-7.5/include/curand_uniform.h'\n  '/usr/local/cuda-7.5/include/curand_normal.h'\n  '/usr/local/cuda-7.5/include/curand_normal_static.h'\n  '/usr/local/cuda-7.5/include/curand_lognormal.h'\n  '/usr/local/cuda-7.5/include/curand_poisson.h'\n  '/usr/local/cuda-7.5/include/curand_discrete2.h'.\nnvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.\nnvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nUse --verbose_failures to see the command lines of failed build steps.\nINFO: Elapsed time: 328.853s, Critical Path: 325.40s\n\n```\n", "@alexmonroe87 it should be fixed by @davidzchen cuda toolchain auto configuration. What does `echo | nvcc -E -xc++ - -v` returns?\n", "@alexmonroe87 When you run your configure script, are you explicitly setting the CUDA version? If not, you are most likely hitting #3985.\n", "@damienmg  \"nvcc fatal   : Unknown option 'xc++'\"\n\n@davidzchen Specifying 7.5 fixed the problem. Thank you.\n", "Seems that we just need to run the command without `-xc++`:\n\n```\n\u276f\u276f\u276f echo | /usr/local/cuda/bin/nvcc -E - -v\n#$ _SPACE_=\n#$ _CUDART_=cudart\n#$ _HERE_=/usr/local/cuda/bin\n#$ _THERE_=/usr/local/cuda/bin\n#$ _TARGET_SIZE_=\n#$ _TARGET_DIR_=\n#$ _TARGET_SIZE_=64\n#$ TOP=/usr/local/cuda/bin/..\n#$ NVVMIR_LIBRARY_DIR=/usr/local/cuda/bin/../nvvm/libdevice\n#$ LD_LIBRARY_PATH=/usr/local/cuda/bin/../lib:\n#$ PATH=/usr/local/cuda/bin/../open64/bin:/usr/local/cuda/bin/../nvvm/bin:/usr/local/cuda/bin:/usr/local/google/home/dzc/.local/bin:/usr/local/google/home/dzc/Projects/bazelbuild/bazel/output:/usr/local/google/home/dzc/.linuxbrew/bin:/usr/local/google/home/dzc/.bin:/usr/local/bin:/usr/local/google/home/dzc/.local/bin:/usr/local/google/home/dzc/Projects/bazelbuild/bazel/output:/usr/local/google/home/dzc/.linuxbrew/bin:/usr/local/google/home/dzc/.bin:/usr/local/bin:/usr/lib/google-golang/bin:/usr/local/buildtools/java/jdk/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/google/home/dzc/go/bin:/usr/local/google/home/dzc/go/bin\n#$ INCLUDES=\"-I/usr/local/cuda/bin/..//include\"\n#$ LIBRARIES=  \"-L/usr/local/cuda/bin/..//lib64/stubs\" \"-L/usr/local/cuda/bin/..//lib64\"\n#$ CUDAFE_FLAGS=\n#$ PTXAS_FLAGS=\nnvcc fatal   : Don't know what to do with '/tmp/tmpxft_00001887_00000000-0_stdin'\n```\n\nThough, I'm not quite sure what is causing the \"Don't know what to do with\" error yet.\n\n@alexmonroe87 No problem. I'll go ahead and close this. The fix for #3985 is out for review but depends on a change that will be going into the next Bazel release.\n"]}]