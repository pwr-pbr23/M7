[{"number": 30425, "title": "Failed to load the native TensorFlow runtime", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Manjaro\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None\r\n- TensorFlow installed from (source or binary): \r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source): 8\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nI got this error\r\n\r\n```Traceback (most recent call last):\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/usr/lib/python3.7/imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/usr/lib/python3.7/imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: /usr/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN6google8protobuf8internal26fixed_address_empty_stringB5cxx11E\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/__init__.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/usr/lib/python3.7/imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/usr/lib/python3.7/imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: /usr/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN6google8protobuf8internal26fixed_address_empty_stringB5cxx11E\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n```\r\n\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": []}, {"number": 30424, "title": "Fix typos", "body": "This PR fixes several typos in the warning and the error messages.", "comments": ["@taehoonlee Could you please address the reviewer comments and resolve conflicts? Thanks!", "Thank you for the comment, @mihaimaruseac. Updated."]}, {"number": 30423, "title": "2.0 beta's \"zero_output_for_mask\" produces unexpected zero-filling behaviors for GRU, LSTM.", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.2 LTS in GOOGLE COLAB\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.0.0-beta0-16-g1d91213fe7 2.0.0-beta1\r\n- Python version: Python 3.6.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA Version: 10.0\r\n- GPU model and memory: Tesla T4 (16G)\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nThe call() methods of tf.keras.layers.GRU and others (e.g. LSTM) does not produce output as expected for \"zero_output_for_mask\"  when the layer is created with \"return_sequences=True\".\r\nRegardless of the value \"zero_output_for_mask\", the result of call() fills zeros for masked timestamps.\r\n\r\n**Describe the expected behavior**\r\nIt should produce outputs as the masked timestamps should be filled zeros if zero_output_for_mask is True. If false,  the masked timestamps should be filled with previous outputs. \r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nfor zero_output_for_mask in [False, True]:\r\n  #tf.keras.Sequential Model\r\n  model = tf.keras.Sequential([\r\n      tf.keras.layers.Embedding(16, 5, mask_zero=True),\r\n      tf.keras.layers.GRU(5, return_sequences=True, zero_output_for_mask=zero_output_for_mask)\r\n  ]\r\n  )\r\n\r\n  model.compile(\r\n      optimizer='rmsprop',\r\n      loss='mse'\r\n      )\r\n\r\n  np_x = np.ones((2, 5), dtype=np.float32)\r\n\r\n  # masking timestamp 3,4 of sample index 1.\r\n  np_x[1, 3:] = 0\r\n  #print(np_x)\r\n\r\n  # model's call()\r\n  result_mask_call = model(np_x)\r\n\r\n  print(\"---- zero_output_for_mask is {} ------\".format(zero_output_for_mask))\r\n  print(result_mask_call[1,:].numpy())\r\n\r\n```\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nI suspect that tf2.0 alpha's GRU's call() is changed in tf2.0 beta version.\r\nPLEASE refer FINAL line of both snippets.\r\n\r\nbeta version snippet of GRU's call() in recurrent_v2.py \r\n```\r\n  def call(self, inputs, mask=None, training=None, initial_state=None):\r\n    # GRU does not support constants. Ignore it during process.\r\n    inputs, initial_state, _ = self._process_inputs(inputs, initial_state, None)\r\n\r\n    if isinstance(mask, list):\r\n      mask = mask[0]\r\n\r\n    input_shape = K.int_shape(inputs)\r\n    timesteps = input_shape[0] if self.time_major else input_shape[1]\r\n\r\n    if not self.could_use_cudnn:\r\n```\r\n\r\nalpha version snippet of GRU's call() in recurrent.py (UnifiedGRU)\r\n```\r\n  def call(self, inputs, mask=None, training=None, initial_state=None):\r\n    # GRU does not support constants. Ignore it during process.\r\n    inputs, initial_state, _ = self._process_inputs(inputs, initial_state, None)\r\n\r\n    if isinstance(mask, list):\r\n      mask = mask[0]\r\n\r\n    input_shape = K.int_shape(inputs)\r\n    timesteps = input_shape[0] if self.time_major else input_shape[1]\r\n\r\n    if mask is not None or not self.could_use_cudnn:\r\n```\r\n", "comments": ["@jangmino Please provide us the error log. And also provide us the complete code to replicate the issue on our environment. Thanks!", "> @jangmino Please provide us the error log. And also provide us the complete code to replicate the issue on our environment. Thanks!\r\n\r\nI downloaded my colab file as ipynb and packed as zip file.\r\nThere was no error but only UNEXPECTED output.\r\nYou can watch the output by running my colab.\r\n\r\n[Reproducing_Code_Unexpected_zero_filling_behaviors_for__zero_ouputput_for_mask__[TF_2_0_beta].zip](https://github.com/tensorflow/tensorflow/files/3376099/Reproducing_Code_Unexpected_zero_filling_behaviors_for__zero_ouputput_for_mask__.TF_2_0_beta.zip)\r\n", "I was able to reproduce the reported issue on Colab with tensorflow-gpu 2.0.0.beta1.Thanks!", "@jangmino Could you check whether the issue with latest TF. I ran your code with `!pip install tf-nightly-gpu-2.0-preview`. Here is the [gist](https://colab.sandbox.google.com/gist/jvishnuvardhan/f4e161a207b4a835f0a5227dd688b9e4/reproducing_code_unexpected_zero_filling_behaviors_for__zero_ouputput_for_mask__-tf_2_0_beta.ipynb). \r\n\r\nPlease close the issue if you think the issue was resolved. Thanks", "Automatically closing this out since I understand it to be resolved, but please let me know if I'm mistaken.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30423\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30423\">No</a>\n"]}, {"number": 30422, "title": "[DEPRECATED REMOVAL]keepprob removed and changed to rate", "body": "```\r\nW0705 03:48:59.803786 139794489620288 deprecation.py:506] From /media/siju//tensorflow/python/nn_test.runfiles/org_tensorflow/tensorflow/python/ops/nn_test.py:316: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\r\n```", "comments": []}, {"number": 30421, "title": "TF2.0beta1+cudnn: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): virtualenv and pip\r\n- TensorFlow version (use command below): tensorflow-gpu 2.0.0-beta1\r\n- Python version: 3.6.7\r\n- GCC/Compiler version (if compiling from source): 7.4.0\r\n- CUDA/cuDNN version: 7.6.0\r\n- GPU model and memory:  GTX1660Ti, 6 GB\r\n\r\n**Describe the current behavior**\r\nUnknownError                              Traceback (most recent call last)\r\n<ipython-input-1-df32bfd3ff54> in <module>\r\n      1 import tensorflow as tf\r\n----> 2 tf.keras.layers.Conv2D(10, 3)(tf.ones((1, 5, 5, 3)))\r\n\r\n~/venv_tf2.0/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    710           with base_layer_utils.autocast_context_manager(\r\n    711               input_list, self._mixed_precision_policy.should_cast_variables):\r\n--> 712             outputs = self.call(inputs, *args, **kwargs)\r\n    713           self._handle_activity_regularization(inputs, outputs)\r\n    714           self._set_mask_metadata(inputs, outputs, input_masks)\r\n\r\n~/venv_tf2.0/lib/python3.6/site-packages/tensorflow/python/keras/layers/convolutional.py in call(self, inputs)\r\n    194 \r\n    195   def call(self, inputs):\r\n--> 196     outputs = self._convolution_op(inputs, self.kernel)\r\n    197 \r\n    198     if self.use_bias:\r\n\r\n~/venv_tf2.0/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py in __call__(self, inp, filter)\r\n   1076 \r\n   1077   def __call__(self, inp, filter):  # pylint: disable=redefined-builtin\r\n-> 1078     return self.conv_op(inp, filter)\r\n   1079 \r\n   1080 \r\n\r\n~/venv_tf2.0/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py in __call__(self, inp, filter)\r\n    632 \r\n    633   def __call__(self, inp, filter):  # pylint: disable=redefined-builtin\r\n--> 634     return self.call(inp, filter)\r\n    635 \r\n    636 \r\n\r\n~/venv_tf2.0/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py in __call__(self, inp, filter)\r\n    231         padding=self.padding,\r\n    232         data_format=self.data_format,\r\n--> 233         name=self.name)\r\n    234 \r\n    235 \r\n\r\n~/venv_tf2.0/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py in conv2d(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name, filters)\r\n   1950                            data_format=data_format,\r\n   1951                            dilations=dilations,\r\n-> 1952                            name=name)\r\n   1953 \r\n   1954 \r\n\r\n~/venv_tf2.0/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py in conv2d(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\r\n   1029             input, filter, strides=strides, use_cudnn_on_gpu=use_cudnn_on_gpu,\r\n   1030             padding=padding, explicit_paddings=explicit_paddings,\r\n-> 1031             data_format=data_format, dilations=dilations, name=name, ctx=_ctx)\r\n   1032       except _core._SymbolicException:\r\n   1033         pass  # Add nodes to the TensorFlow graph.\r\n\r\n~/venv_tf2.0/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py in conv2d_eager_fallback(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name, ctx)\r\n   1128   explicit_paddings, \"data_format\", data_format, \"dilations\", dilations)\r\n   1129   _result = _execute.execute(b\"Conv2D\", 1, inputs=_inputs_flat, attrs=_attrs,\r\n-> 1130                              ctx=_ctx, name=name)\r\n   1131   _execute.record_gradient(\r\n   1132       \"Conv2D\", _inputs_flat, _attrs, _result, name)\r\n\r\n~/venv_tf2.0/lib/python3.6/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     65     else:\r\n     66       message = e.message\r\n---> 67     six.raise_from(core._status_to_exception(e.code, message), None)\r\n     68   except TypeError as e:\r\n     69     if any(ops._is_keras_symbolic_tensor(x) for x in inputs):\r\n\r\n/usr/lib/python3/dist-packages/six.py in raise_from(value, from_value)\r\n\r\nUnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]\r\n\r\n**Describe the expected behavior**\r\nOutput the inference results\r\n\r\n**Code to reproduce the issue**\r\nimport tensorflow as tf\r\ntf.keras.layers.Conv2D(10, 3)(tf.ones((1, 5, 5, 3)))\r\n\r\n\r\nHow should resolve it? Thanks", "comments": ["I also have this problem for several days. \r\nwin10, python3.6, TF2.0beta1, cuda10.0, cudnn7.6.\r\nWhat's really ridiculous is that it works well when I finished installing them. After about two days when I used layers.conv2D it didn't work and reported Failed to get convolution algorithm. I have tried to fix it for reinstall cuda and cudnn, and check environment variables. \r\nIt seems it has noting to do with cuda cudnn. Now my code works well without this issue by using this:\r\n`physical_devices = tf.config.experimental.list_physical_devices('GPU')\r\ntf.config.experimental.set_memory_growth(physical_devices[0], True)` \r\nLeading by issued#29632, thank srihari-humbarwadi\r\n\r\n", "Dear @kurobaneHITOMI \r\n\r\nNow my code works well without this issue by using this:\r\n> `physical_devices = tf.config.experimental.list_physical_devices('GPU') tf.config.experimental.set_memory_growth(physical_devices[0], True)`\r\n> Leading by issued#29632, thank srihari-humbarwadi\r\n\r\nIt did work, thanks so much", "> I also have this problem for several days.\r\n> win10, python3.6, TF2.0beta1, cuda10.0, cudnn7.6.\r\n> What's really ridiculous is that it works well when I finished installing them. After about two days when I used layers.conv2D it didn't work and reported Failed to get convolution algorithm. I have tried to fix it for reinstall cuda and cudnn, and check environment variables.\r\n> It seems it has noting to do with cuda cudnn. Now my code works well without this issue by using this:\r\n> `physical_devices = tf.config.experimental.list_physical_devices('GPU') tf.config.experimental.set_memory_growth(physical_devices[0], True)`\r\n> Leading by issued#29632, thank srihari-humbarwadi\r\n\r\nHi, \r\nThis solution didn't work for my. \r\n\r\nI'm running on TF 2 rc1. I've added these lines and I still get this error of Failed to get convolution algorithm...\r\n\r\nAre there any other solutions?\r\nRegards, Alon"]}, {"number": 30420, "title": "tensorflow java api, branch r1.14,the version in pom file is still 1.13", "body": "build jni from branch r1.14,the jar name is still 1.13.0-rc2\r\nwhich is correct version?", "comments": ["The versions will be updated as part of the release process, but missing a `android_buildinfo.json` artifact is currently blocking the release. I'm looking into that."]}, {"number": 30419, "title": "\u7c7b\u578b\u95ee\u9898", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue: https://www.tensorflow.org/tutorials/keras/basic_classification\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing): plt.xlabel(class_names[train_labels[i]])\u4e2dtrain_labels\u8fd4\u56de\u7684\u662fnumpy.float64 \uff0c\u4f46\u662fclass_names\u9700\u8981Integer\u3002\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n", "comments": ["@OkShen ,\r\nThank you for your contribution towards improvement of documentation. Can you please provide clear description of the issue so that proper action can be taken.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 30418, "title": "Memory Saving Gradients for TF2", "body": "**System information**\r\n- TensorFlow 2.0 beta\r\n\r\nThere are libraries for TF1 that are able to calculate more memory efficient gradients such as [gradient-checkpointing](https://github.com/cybertronai/gradient-checkpointing). They edit the graph with the [tf.contrib.graph_editor](https://www.tensorflow.org/api_docs/python/tf/contrib/graph_editor) to save memory. However, tf.contrib does not exist anymore which is why I cannot run large models such as GPT2 in TF2 (converted with `tf_upgrade_v2`) as it overflows my GPU memory in Google Colab. Is there a TF2 feature that can help me? \r\n", "comments": ["@mpafla Will it be possible to provide us the minimal code snippet which replicates your issue.Thanks!", "This issue is a feature request, so what's there to replicate?", "If you have a look [here](https://github.com/nshepperd/gpt-2/blob/finetuning/src/memory_saving_gradients.py), they use `import tensorflow.contrib.graph_editor as ge` which does not exist in TF2. How would I do this in TF2? Is there some feature that helps me with this?\r\n\r\nSorry, I cannot provide a code snippet. I need some general guidance (maybe I should've posted on stackoverflow - I wasn't sure).", "There's the [tf.recompute_grad](https://github.com/tensorflow/tensorflow/blob/2cb8b4ab8f038f5c6de2381ad215fdaa6fd2bc22/tensorflow/python/ops/custom_gradient.py#L351) decorator available in tf2 nightly which you can add to your code to do checkpointing.\r\n\r\nIt's probably possible to fork tf.contrib.graph_editor and make it work with tf.compat.v1.wrap_function to keep the functionality you need, though.\r\n\r\nOtherwise I'm happy to discuss proposals for a better tf2-friendly way of making this happen.", "Thanks for your answer, I think it could be done with this. I am far from an expert, but I like how it is done [here](https://github.com/cybertronai/gradient-checkpointing/blob/master/memory_saving_gradients.py#L42). Basically, you overwrite tf.gradients with their version of gradients, but are also to specify a 'checkpoint heuristic' such as 'memory' or 'speed' that computes gradients more memory or more speed efficient respectively.", "@alextp I'm not sure that recompute_grad allows for gradient checkpointing style memory reduction.\r\n\r\nThe code below runs 200 blocks of 200 \"layers\", each of which is just element-wise operations with a single vector. Gradient checkpointing should mean that during the forward pass, the activations of only 200 layers are stored, rather than all 40000 layers.\r\n\r\nIf this were accomplishing what gradient checkpointing does, the peak memory usage should be around 100000 * 200 * 2 * 4 bytes (<200 MB), but this causes an OOM error on my 8 GB GPU. Have I understood the suggestion correctly?\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nDIM = 100000\r\nB_SIZE = 200\r\n@tf.recompute_grad\r\ndef run_block(x, variables=None):\r\n    for _ in range(B_SIZE):\r\n        x = variables[0] * x\r\n    return x\r\n\r\nv = tf.Variable(np.zeros(DIM), dtype=tf.float32)\r\nx = tf.zeros(DIM, dtype=tf.float32)\r\nopt = tf.optimizers.SGD(lr=1e-5)\r\n\r\nwith tf.GradientTape() as g:\r\n    g.watch(x)\r\n    layer_out = x\r\n    for _ in range(B_SIZE):\r\n        layer_out = run_block(layer_out, variables=[v])\r\n    loss = tf.reduce_sum(layer_out)\r\n    print(g.gradient(loss, x))\r\n```", "@mpafla I've written a simple gradient checkpointing decorator [here](https://github.com/davisyoshida/tf2-gradient-checkpointing)", "I believe the tf-slim version works:\r\n\r\nhttps://github.com/google-research/tf-slim/blob/a62dc893de5e46e6f2e9ec24a74b2abce026307a/tf_slim/layers/rev_block_lib.py#L465\r\n\r\n", "It doesn't appear that there's a way to use that for something like a Keras layer right?", "It should work fine inside a Keras layer, something like:\r\n\r\n```python\r\nclass MyLayer(tf.keras.layers.Layer):\r\n\r\n  def call(self, inputs):\r\n    @rev_block_lib.recompute_grad\r\n    def call_impl(inputs):\r\n      # do stuff\r\n\r\n    return call_impl(inputs)\r\n```\r\n\r\nIf there's enough interest, my team has an internal version that supports recomputation with random number generation (e.g. Dropout) that we could consider open sourcing.", "Does it only work in graph mode perhaps? I tried it in eager mode and didn't get memory savings.", "Hi @ppham27, just chiming in to +1 definitely interested in an implementation of gradient checkpointing which works in graph mode. The tf-slim version doesn't run for TF2+ versions which no longer have contrib (without quite a bit of hackery, anyway).", "> Does it only work in graph mode perhaps? I tried it in eager mode and didn't get memory savings.\r\n\r\nI'm not sure if it works in pure eager mode, but I do recall it working with TF2 if you annotated your computation with `@tf.function` (possibly with `experimental_compile=True`). This was months ago since I last tried, and perhaps, the situation is different, now.\r\n\r\n> Hi @ppham27, just chiming in to +1 definitely interested in an implementation of gradient checkpointing which works in graph mode. The tf-slim version doesn't run for TF2+ versions which no longer have contrib (without quite a bit of hackery, anyway).\r\n\r\nOkay, I'll see what it takes to push something to https://github.com/tensorflow/addons. I'm not on the TF team at Google and only contribute in my spare cycles, so it may take me some time. My team's implementation is tested to work with both TF1 and TF2, but there still may be some cases, we've missed.\r\n\r\n", "Just updating that I spent some time extricating the necessary code out of tf-slim for my use case and it runs with `tf-nightly==2.2.0.dev20200303` in graph mode successfully for a model running on TPU.", "@mathemakitten Do you mind to share how you did this on TPU? I can only manage to make it work on GPU model training, by splitting the model into several blocks and apply recompute_grad on them. But in TPU, the model seems won't work if I split the model into several blocks for training.", "@RayXie29 I've uploaded a standalone version of the code I extracted out of the tf-slim implementation for usage on TPU and made it available [here](https://github.com/mathemakitten/gradient-checkpointing). I hope it helps!", "@mathemakitten Thank you so much for sharing this.", "If anybody still needs this, we released [recompute_grad](https://github.com/google-research/google-research/blob/master/etcmodel/layers/recompute_grad.py#L169) as part of our EMNLP paper [ETC: Encoding Long and Structured Inputs in Transformers\r\n](https://arxiv.org/abs/2004.08483)\r\n\r\nWe ran our experiments on TPUs in the paper, but I've tested on GPUs with and without XLA. It has the nice bonus that it supports dropout layers, too, if you use [RecomputingDropout](https://github.com/google-research/google-research/blob/81200ee32d8ce89e2359cd2bc4e3bd29ad713ba6/etcmodel/layers/recomputing_dropout.py#L61), which should be a drop-in replacement for `tf.keras.layers.Dropout`.", "@mpafla,\r\nWith respect to the [above comment](https://github.com/tensorflow/tensorflow/issues/30418#issuecomment-719124842), can you please let us know if we can close this issue? Thanks!", "@mpafla,\r\n\r\nAs I can see that you've reacted thumbs up to @rmothukuru 's above comment about closing the issue, I am closing it now. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30418\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30418\">No</a>\n"]}, {"number": 30417, "title": "Mixed-precision mode in keras: 'AutoCastVariable' object is not subscriptable", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 LTS\r\n- TensorFlow installed from (source or binary): official Tensorflow docker = tensorflow/tensorflow:1.14.0-gpu-py3\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version: 3.6.8\r\n\r\n**Describe the current behavior**\r\nThe following error occurs in a given code below when trying to enable mixed-precision mode with `keras.mixed_precision.experimental.set_policy('infer_float32_vars')`:\r\n```\r\n    auto_cast_variable_slice_repr.py:16 call\r\n        return keras.backend.dot(inputs, w[:16, :16])\r\n\r\n    TypeError: 'AutoCastVariable' object is not subscriptable\r\n```\r\n\r\nIt looks like _ResourceVariable_ (which is returned by self.add_weight with mixed-precision is OFF) supports slice operations, while _AutoCastVariable_ (returned by self.add_weight when mixed-precision is ON) doesn't.\r\n\r\nIt's possible to workaround this issue by converting this variable into tensor (as shown on line 15), but it's not clear if it's a straightforward way to perform slice op on Variable.\r\n\r\n**Describe the expected behavior**\r\nShould work without any error.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport numpy as np\r\n\r\nfrom tensorflow import keras\r\n\r\n# Comment this line out to make code complete successfully\r\nkeras.mixed_precision.experimental.set_policy('infer_float32_vars')\r\n\r\nclass MyLayer(keras.layers.Layer):\r\n    def build(self, input_shape):\r\n        self.w = self.add_weight(shape=(16, 16))\r\n\r\n    def call(self, inputs, **kwargs):\r\n        w = self.w\r\n        # Uncomment this workaround line below to make it work with mixed-precision ON\r\n        # w = keras.backend.cast(w, dtype=w.dtype)\r\n        return keras.backend.dot(inputs, w[:16, :16])\r\n\r\ninput = keras.layers.Input(shape=(16, ))\r\noutput = MyLayer()(input)\r\nmodel = keras.models.Model(input, output)\r\n\r\nmodel.predict(np.zeros(shape=(16, 16)))\r\n```", "comments": ["Reproduced the Error with TF Version 1.14", "Thank you for the bug report. This should be fixed by 604988b5d4e8cec6564db6502e6e40eefac8fc67.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30417\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30417\">No</a>\n"]}, {"number": 30416, "title": "Build doesn't find files that exist", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: git tag v2.0.0_beta1\r\n- Python version: 3.6.7\r\n- Installed using virtualenv? pip? conda?: \r\n- Bazel version (if compiling from source): bazel release 0.24.1\r\n- GCC/Compiler version (if compiling from source): \"C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC//bin/amd64/cl.exe\"\r\nMicrosoft (R) C/C++ Optimizing Compiler Version 19.00.24234.1 for x64\r\n- CUDA/cuDNN version: 10.1/7.6.1\r\n- GPU model and memory: GeForce GTX 1060 (6GB)\r\n\r\n\r\n\r\n**Describe the problem**\r\nBuild fails, each time with other .h file, that it can't find.\r\nAll files are available.\r\n\r\nRun 1:\r\nERROR: D:/data/users/andrey/projects/tensorflow_gpu_v2.0_3/tensorflow/core/kernels/data/BUILD:1012:1: C++ compilation of rule '//tensorflow/core/kernels/data:optional_ops_gpu' failed (Exit 2): python.exe failed: error executing command\r\n  cd C:/users/andrey/_bazel_andrey/ntapso4i/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1\r\n    SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\INCLUDE;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\winrt;\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\LIB\\amd64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\um\\x64;\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\amd64;C:\\windows\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\Tools;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x86;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;;C:\\windows\\system32\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=D:/Data/Users/andrey/AppData/Local/Programs/Python/Python36/python.exe\r\n    SET PYTHON_LIB_PATH=D:/Data/Users/andrey/AppData/Local/Programs/Python/Python36/lib/site-packages\r\n    SET TEMP=C:\\Users\\andrey\\AppData\\Local\\Temp\r\n    SET TF_CONFIGURE_IOS=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=6.1\r\n    SET TF_CUDA_PATHS=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1,C:/Program Files/cudnn-10.1-windows10-x64-v7.6.1.34\r\n    SET TF_CUDA_VERSION=10.1\r\n    SET TF_CUDNN_VERSION=7.6.1\r\n    SET TF_NEED_CUDA=1\r\n    SET TMP=C:\\Users\\andrey\\AppData\\Local\\Temp\r\n  D:/Data/Users/andrey/AppData/Local/Programs/Python/Python36/python.exe -B external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/genfiles /Ibazel-out/x64_windows-opt/bin /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/genfiles/external/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/x64_windows-opt/genfiles/external/local_config_sycl /Ibazel-out/x64_windows-opt/bin/external/local_config_sycl /Iexternal/nsync /Ibazel-out/x64_windows-opt/genfiles/external/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/gif_archive /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive /Ibazel-out/x64_windows-opt/bin/external/gif_archive /Iexternal/jpeg /Ibazel-out/x64_windows-opt/genfiles/external/jpeg /Ibazel-out/x64_windows-opt/bin/external/jpeg /Iexternal/protobuf_archive /Ibazel-out/x64_windows-opt/genfiles/external/protobuf_archive /Ibazel-out/x64_windows-opt/bin/external/protobuf_archive /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/genfiles/external/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-opt/genfiles/external/fft2d /Ibazel-out/x64_windows-opt/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-opt/genfiles/external/highwayhash /Ibazel-out/x64_windows-opt/bin/external/highwayhash /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-opt/genfiles/external/snappy /Ibazel-out/x64_windows-opt/bin/external/snappy /Iexternal/local_config_cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cudnn_header /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cublas_headers_virtual /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/genfiles/external/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/gif_archive/lib /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/lib /Ibazel-out/x64_windows-opt/bin/external/gif_archive/lib /Iexternal/gif_archive/windows /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/windows /Ibazel-out/x64_windows-opt/bin/external/gif_archive/windows /Iexternal/protobuf_archive/src /Ibazel-out/x64_windows-opt/genfiles/external/protobuf_archive/src /Ibazel-out/x64_windows-opt/bin/external/protobuf_archive/src /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive/src /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda /Iexternal/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/include /Iexternal/local_config_cuda/cuda/cublas/include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cublas/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cublas/include /D__CLANG_SUPPORT_DYN_ANNOTATION__ /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DEIGEN_HAS_TYPE_TRAITS=0 /DTF_USE_SNAPPY /showIncludes /MD /O2 /DNDEBUG -w -DWIN32_LEAN_AND_MEAN -DNOGDI /arch:AVX2 -nvcc_options=disable-warnings -DGOOGLE_CUDA=1 -DTENSORFLOW_MONOLITHIC_BUILD /DPLATFORM_WINDOWS /DEIGEN_HAS_C99_MATH /DTENSORFLOW_USE_EIGEN_THREADPOOL /DEIGEN_AVOID_STL_ARRAY /Iexternal/gemmlowp /wd4018 /wd4577 /DNOGDI /DTF_COMPILE_LIBRARY -x cuda -DGOOGLE_CUDA=1 -nvcc_options=relaxed-constexpr -nvcc_options=ftz=true /Fobazel-out/x64_windows-opt/bin/tensorflow/core/kernels/data/_objs/optional_ops_gpu/optional_ops.cu.o /c tensorflow/core/kernels/data/optional_ops.cu.cc\r\nExecution platform: @bazel_tools//platforms:host_platform\r\nc1xx: fatal error C1083: Cannot open source file: 'tensorflow/core/kernels/data/optional_ops.cu.cc': No such file or directory\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n\r\nRun 2:\r\nERROR: D:/data/users/andrey/projects/tensorflow_gpu_v2.0_3/tensorflow/contrib/framework/BUILD:111:1: C++ compilation of rule '//tensorflow/contrib/framework:python/ops/_variable_ops_gpu' failed (Exit 2): python.exe failed: error executing command\r\n  cd C:/users/andrey/_bazel_andrey/ntapso4i/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1\r\n    SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\INCLUDE;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\winrt;\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\LIB\\amd64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\um\\x64;\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\amd64;C:\\windows\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\Tools;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x86;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;;C:\\windows\\system32\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=D:/Data/Users/andrey/AppData/Local/Programs/Python/Python36/python.exe\r\n    SET PYTHON_LIB_PATH=D:/Data/Users/andrey/AppData/Local/Programs/Python/Python36/lib/site-packages\r\n    SET TEMP=C:\\Users\\andrey\\AppData\\Local\\Temp\r\n    SET TF_CONFIGURE_IOS=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=6.1\r\n    SET TF_CUDA_PATHS=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1,C:/Program Files/cudnn-10.1-windows10-x64-v7.6.1.34\r\n    SET TF_CUDA_VERSION=10.1\r\n    SET TF_CUDNN_VERSION=7.6.1\r\n    SET TF_NEED_CUDA=1\r\n    SET TMP=C:\\Users\\andrey\\AppData\\Local\\Temp\r\n  D:/Data/Users/andrey/AppData/Local/Programs/Python/Python36/python.exe -B external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/genfiles /Ibazel-out/x64_windows-opt/bin /Iexternal/protobuf_archive /Ibazel-out/x64_windows-opt/genfiles/external/protobuf_archive /Ibazel-out/x64_windows-opt/bin/external/protobuf_archive /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/x64_windows-opt/genfiles/external/local_config_sycl /Ibazel-out/x64_windows-opt/bin/external/local_config_sycl /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/genfiles/external/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/local_config_cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual /Iexternal/protobuf_archive/src /Ibazel-out/x64_windows-opt/genfiles/external/protobuf_archive/src /Ibazel-out/x64_windows-opt/bin/external/protobuf_archive/src /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda /Iexternal/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/include /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DEIGEN_HAS_TYPE_TRAITS=0 /D__CLANG_SUPPORT_DYN_ANNOTATION__ /showIncludes /MD /O2 /DNDEBUG -w -DWIN32_LEAN_AND_MEAN -DNOGDI /arch:AVX2 -nvcc_options=disable-warnings /DEIGEN_STRONG_INLINE=inline -x cuda -DGOOGLE_CUDA=1 -nvcc_options=relaxed-constexpr -nvcc_options=ftz=true /Fobazel-out/x64_windows-opt/bin/tensorflow/contrib/framework/_objs/python/ops/_variable_ops_gpu/zero_initializer_op_gpu.cu.o /c tensorflow/contrib/framework/kernels/zero_initializer_op_gpu.cu.cc\r\nExecution platform: @bazel_tools//platforms:host_platform\r\nc1xx: fatal error C1083: Cannot open source file: 'tensorflow/contrib/framework/kernels/zero_initializer_op_gpu.cu.cc': No such file or directory\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n\r\n\r\nRun 3:\r\nERROR: D:/data/users/andrey/projects/tensorflow_gpu_v2.0_3/tensorflow/contrib/rnn/BUILD:199:1: C++ compilation of rule '//tensorflow/contrib/rnn:python/ops/_gru_ops_gpu' failed (Exit 2): python.exe failed: error executing command\r\n  cd C:/users/andrey/_bazel_andrey/ntapso4i/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1\r\n    SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\INCLUDE;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\winrt;\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\LIB\\amd64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\um\\x64;\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\amd64;C:\\windows\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\Tools;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x86;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;;C:\\windows\\system32\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=D:/Data/Users/andrey/AppData/Local/Programs/Python/Python36/python.exe\r\n    SET PYTHON_LIB_PATH=D:/Data/Users/andrey/AppData/Local/Programs/Python/Python36/lib/site-packages\r\n    SET TEMP=C:\\Users\\andrey\\AppData\\Local\\Temp\r\n    SET TF_CONFIGURE_IOS=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=6.1\r\n    SET TF_CUDA_PATHS=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1,C:/Program Files/cudnn-10.1-windows10-x64-v7.6.1.34\r\n    SET TF_CUDA_VERSION=10.1\r\n    SET TF_CUDNN_VERSION=7.6.1\r\n    SET TF_NEED_CUDA=1\r\n    SET TMP=C:\\Users\\andrey\\AppData\\Local\\Temp\r\n  D:/Data/Users/andrey/AppData/Local/Programs/Python/Python36/python.exe -B external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/genfiles /Ibazel-out/x64_windows-opt/bin /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/x64_windows-opt/genfiles/external/local_config_sycl /Ibazel-out/x64_windows-opt/bin/external/local_config_sycl /Iexternal/protobuf_archive /Ibazel-out/x64_windows-opt/genfiles/external/protobuf_archive /Ibazel-out/x64_windows-opt/bin/external/protobuf_archive /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/genfiles/external/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/local_config_cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/protobuf_archive/src /Ibazel-out/x64_windows-opt/genfiles/external/protobuf_archive/src /Ibazel-out/x64_windows-opt/bin/external/protobuf_archive/src /Iexternal/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda /Iexternal/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/include /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DEIGEN_HAS_TYPE_TRAITS=0 /D__CLANG_SUPPORT_DYN_ANNOTATION__ /showIncludes /MD /O2 /DNDEBUG -w -DWIN32_LEAN_AND_MEAN -DNOGDI /arch:AVX2 -nvcc_options=disable-warnings /DEIGEN_STRONG_INLINE=inline -x cuda -DGOOGLE_CUDA=1 -nvcc_options=relaxed-constexpr -nvcc_options=ftz=true /Fobazel-out/x64_windows-opt/bin/tensorflow/contrib/rnn/_objs/python/ops/_gru_ops_gpu/gru_ops_gpu.cu.o /c tensorflow/contrib/rnn/kernels/gru_ops_gpu.cu.cc\r\nExecution platform: @bazel_tools//platforms:host_platform\r\nc1xx: fatal error C1083: Cannot open source file: 'tensorflow/contrib/rnn/kernels/gru_ops_gpu.cu.cc': No such file or directory\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n\r\n\r\nRun 4:\r\nERROR: D:/data/users/andrey/projects/tensorflow_gpu_v2.0_3/tensorflow/core/kernels/BUILD:321:1: C++ compilation of rule '//tensorflow/core/kernels:extract_volume_patches_op_gpu' failed (Exit 2): python.exe failed: error executing command\r\n  cd C:/users/andrey/_bazel_andrey/ntapso4i/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1\r\n    SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\INCLUDE;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\winrt;\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\LIB\\amd64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\um\\x64;\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\amd64;C:\\windows\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\Tools;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x86;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;;C:\\windows\\system32\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=D:/Data/Users/andrey/AppData/Local/Programs/Python/Python36/python.exe\r\n    SET PYTHON_LIB_PATH=D:/Data/Users/andrey/AppData/Local/Programs/Python/Python36/lib/site-packages\r\n    SET TEMP=C:\\Users\\andrey\\AppData\\Local\\Temp\r\n    SET TF_CONFIGURE_IOS=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=6.1\r\n    SET TF_CUDA_PATHS=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1,C:/Program Files/cudnn-10.1-windows10-x64-v7.6.1.34\r\n    SET TF_CUDA_VERSION=10.1\r\n    SET TF_CUDNN_VERSION=7.6.1\r\n    SET TF_NEED_CUDA=1\r\n    SET TMP=C:\\Users\\andrey\\AppData\\Local\\Temp\r\n  D:/Data/Users/andrey/AppData/Local/Programs/Python/Python36/python.exe -B external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/genfiles /Ibazel-out/x64_windows-opt/bin /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/genfiles/external/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/x64_windows-opt/genfiles/external/local_config_sycl /Ibazel-out/x64_windows-opt/bin/external/local_config_sycl /Iexternal/mkl_dnn /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn /Iexternal/nsync /Ibazel-out/x64_windows-opt/genfiles/external/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/gif_archive /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive /Ibazel-out/x64_windows-opt/bin/external/gif_archive /Iexternal/jpeg /Ibazel-out/x64_windows-opt/genfiles/external/jpeg /Ibazel-out/x64_windows-opt/bin/external/jpeg /Iexternal/protobuf_archive /Ibazel-out/x64_windows-opt/genfiles/external/protobuf_archive /Ibazel-out/x64_windows-opt/bin/external/protobuf_archive /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/genfiles/external/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-opt/genfiles/external/fft2d /Ibazel-out/x64_windows-opt/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-opt/genfiles/external/highwayhash /Ibazel-out/x64_windows-opt/bin/external/highwayhash /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-opt/genfiles/external/snappy /Ibazel-out/x64_windows-opt/bin/external/snappy /Iexternal/local_config_cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cublas_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cudnn_header /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/mkl_dnn/include /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/include /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/include /Iexternal/mkl_dnn/src /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src /Iexternal/mkl_dnn/src/common /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src/common /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/common /Iexternal/mkl_dnn/src/cpu /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src/cpu /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu /Iexternal/mkl_dnn/src/cpu/gemm /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src/cpu/gemm /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu/gemm /Iexternal/mkl_dnn/src/cpu/xbyak /Ibazel-out/x64_windows-opt/genfiles/external/mkl_dnn/src/cpu/xbyak /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu/xbyak /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/genfiles/external/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/gif_archive/lib /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/lib /Ibazel-out/x64_windows-opt/bin/external/gif_archive/lib /Iexternal/gif_archive/windows /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/windows /Ibazel-out/x64_windows-opt/bin/external/gif_archive/windows /Iexternal/protobuf_archive/src /Ibazel-out/x64_windows-opt/genfiles/external/protobuf_archive/src /Ibazel-out/x64_windows-opt/bin/external/protobuf_archive/src /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive/src /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda /Iexternal/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/include /Iexternal/local_config_cuda/cuda/cublas/include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cublas/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cublas/include /D__CLANG_SUPPORT_DYN_ANNOTATION__ /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DEIGEN_HAS_TYPE_TRAITS=0 /DTENSORFLOW_USE_CUSTOM_CONTRACTION_KERNEL /DTENSORFLOW_USE_MKLDNN_CONTRACTION_KERNEL /DTF_USE_SNAPPY /showIncludes /MD /O2 /DNDEBUG -w -DWIN32_LEAN_AND_MEAN -DNOGDI /arch:AVX2 -nvcc_options=disable-warnings -DGOOGLE_CUDA=1 -DTENSORFLOW_MONOLITHIC_BUILD /DPLATFORM_WINDOWS /DEIGEN_HAS_C99_MATH /DTENSORFLOW_USE_EIGEN_THREADPOOL /DEIGEN_AVOID_STL_ARRAY /Iexternal/gemmlowp /wd4018 /wd4577 /DNOGDI /DTF_COMPILE_LIBRARY -x cuda -DGOOGLE_CUDA=1 -nvcc_options=relaxed-constexpr -nvcc_options=ftz=true /Fobazel-out/x64_windows-opt/bin/tensorflow/core/kernels/_objs/extract_volume_patches_op_gpu/extract_volume_patches_op_gpu.cu.o /c tensorflow/core/kernels/extract_volume_patches_op_gpu.cu.cc\r\nExecution platform: @bazel_tools//platforms:host_platform\r\nc1xx: fatal error C1083: Cannot open source file: 'tensorflow/core/kernels/extract_volume_patches_op_gpu.cu.cc': No such file or directory\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nbazel build --config=opt --config=cuda --copt=-nvcc_options=disable-warnings //tensorflow/tools/pip_package:build_pip_package\r\n\r\n**Any other info / logs**\r\n.tf_configure.bazelrc\r\nbuild --action_env PYTHON_BIN_PATH=\"D:/Data/Users/andrey/AppData/Local/Programs/Python/Python36/python.exe\"\r\nbuild --action_env PYTHON_LIB_PATH=\"D:/Data/Users/andrey/AppData/Local/Programs/Python/Python36/lib/site-packages\"\r\nbuild --python_path=\"D:/Data/Users/andrey/AppData/Local/Programs/Python/Python36/python.exe\"\r\nbuild:xla --define with_xla_support=false\r\nbuild --action_env TF_CUDA_VERSION=\"10.1\"\r\nbuild --action_env TF_CUDNN_VERSION=\"7.6.1\"\r\nbuild --action_env TF_CUDA_PATHS=\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1,C:/Program Files/cudnn-10.1-windows10-x64-v7.6.1.34\"\r\nbuild --action_env CUDA_TOOLKIT_PATH=\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1\"\r\nbuild --action_env TF_CUDA_COMPUTE_CAPABILITIES=\"6.1\"\r\nbuild --config=cuda\r\nbuild:opt --copt=/arch:AVX2\r\nbuild:opt --define with_default_optimizations=true\r\nbuild --config monolithic\r\nbuild --copt=-w --host_copt=-w\r\nbuild --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI\r\nbuild --verbose_failures\r\nbuild --distinct_host_configuration=false\r\nbuild --define=override_eigen_strong_inline=true\r\nbuild:v2 --define=tf_api_version=2\r\ntest --flaky_test_attempts=3\r\ntest --test_size_filters=small,medium\r\ntest --test_tag_filters=-benchmark-test,-no_oss,-oss_serial\r\ntest --build_tag_filters=-benchmark-test,-no_oss\r\ntest --test_tag_filters=-no_windows,-gpu\r\ntest --build_tag_filters=-no_windows,-gpu\r\nbuild --action_env TF_CONFIGURE_IOS=\"0\"", "comments": ["@AndreyPlotkinOr Is this the duplicate [of #30415](https://github.com/tensorflow/tensorflow/issues/30415).\r\nIf yes, can we close this issue, will track resolution there. Thanks!", "@gadagashwini It's not the same issue.\r\n\r\nReally weird!\r\nI recreated an environment, that was created be bazel (all sets + working directory)\r\nI then edited the msvc_wrapper_for_nvcc.py to extract the exact command, that was run.\r\nmsvc_wrapper_for_nvcc.py runs nvcc.exe with LOTS of flags.\r\n\r\nI run nvcc.exe with full set of flags, and got the same error: No such file or directory\r\n\r\nAfter eliminating unnecessary flags (which apparently all flags), I still get the same error.\r\n\r\n`C:\\Users\\andrey\\_bazel_andrey\\y37cttbw\\execroot\\org_tensorflow>\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1/bin/nvcc.exe\" -c tensorflow\\contrib\\image\\kernels\\adjust_hsv_in_yiq_op_gpu.cu.cc\r\nadjust_hsv_in_yiq_op_gpu.cu.cc\r\nc1xx: fatal error C1083: Cannot open source file: 'tensorflow/contrib/image/kernels/adjust_hsv_in_yiq_op_gpu.cu.cc': No such file or directory`\r\n\r\nWhen running the same command with full path, everything worked ok:\r\n\r\n`C:\\Users\\andrey\\_bazel_andrey\\y37cttbw\\execroot\\org_tensorflow>\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1/bin/nvcc.exe\" -c C:\\tensorflow_gpu_v2.0_3\\tensorflow\\contrib\\image\\kernels\\adjust_hsv_in_yiq_op_gpu.cu.cc\r\nadjust_hsv_in_yiq_op_gpu.cu.cc`\r\n\r\nI thought it's because \"tensorflow\" folder is a junction:\r\n`C:\\Users\\andrey\\_bazel_andreyl\\y37cttbw\\execroot\\org_tensorflow>dir\r\n Directory of C:\\Users\\andrey\\_bazel_andre-pl\\y37cttbw\\execroot\\org_tensorflow\r\n04-Jul-19  16:29    <DIR>          bazel-out\r\n04-Jul-19  16:29    <DIR>          external\r\n04-Jul-19  16:29    <JUNCTION>     tensorflow [C:\\tensorflow_gpu_v2.0_3\\tensorflow]\r\n04-Jul-19  16:29    <JUNCTION>     third_party [C:\\tensorflow_gpu_v2.0_3\\third_party]`\r\n\r\nI then copied \"tensorflow\" directory content instead a junction, but it still returns same exception.\r\n\r\nSo relative path is the reason.", "I found the source of the problem.\r\nMy windows had a registry definition to open CMD with predefined folder:\r\n[HKEY_CURRENT_USER\\Software\\Microsoft\\Command Processor]\r\n\"AutoRun\"=\"..........\"\r\n\r\nAfter removing the definition, the compilation passed smoothly.\r\n\r\n.bzl files falsely expect that the default working directory will be the same as their own.\r\nIt was not the case this time.\r\n", "@AndreyPlotkinOr Looks like issue resolved. Let us know if this is still an issue. ", "Depends.\r\nI only found what caused the problem, and it's a really seldom case.\r\nIt's worth patching, if it's a quick fix.\r\n\r\nAnyway you decide, it's good to be documented (at least here in the issue).", "@hlopko to see if he has any ideas", "I'll delegate to experts here, @meteorcloudy and @laszlocsomor did you know about `[HKEY_CURRENT_USER\\Software\\Microsoft\\Command Processor]` `AutoRun`? What would you recommend?", "@hlopko I didn't know about `AutoRun` before, but now I do! ;)\r\n\r\n@AndreyPlotkinOr Nice debugging for this issue! Thanks! I wonder if it's because we run nvcc compiler with `shell = True`, which triggered the `AutoRun`.\r\nhttps://github.com/tensorflow/tensorflow/blob/eaafddf7e64391c79a0cf3b31f50c33275e38a40/third_party/gpus/crosstool/windows/msvc_wrapper_for_nvcc.py.tpl#L164\r\n\r\nCan you test if it works with `AutoRun` set after removing `shell = True`?", "@AndreyPlotkinOr : Awesome debugging!\r\n\r\n@hlopko : Wow, thanks for the heads-up. I didn't know about it. Apparently it's a `.bashrc`-like mechanism. If Bazel runs any `.bat` files or cmd.exe commands, those might be susceptible to this too.\r\n\r\n", "@meteorcloudy I tried the compilation without shell = True, but it still throws the same exception.", "@AndreyPlotkinOr Thanks for the test! So looks like the AutoRun was not triggered in Bazel. I reviewed your bug report again, IIRC, you tested nvcc.exe outside of Bazel and can still reproduce the bug. So I guess it's nvcc that somehow triggered the AutoRun? If that's the case, the only way to fix it is to disable `AutoRun`. What Bazel can do is to detect AutoRun is enabled and give users a warning.", "@AndreyPlotkinOr,\r\n\r\nWe are checking to see if you still need help on this issue. Can you try building the latest stable version of TF i.e `2.6.0` and let us know if the issue persists? You can use this [guide](https://www.tensorflow.org/install/source_windows) for your reference and take a look at this [link](https://www.tensorflow.org/install/source_windows#tested_build_configurations) for the tested build configs.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30416\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30416\">No</a>\n"]}, {"number": 30415, "title": "Failed to build Windows +TF2 + XLA + python", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: git tag v2.0.0_beta1\r\n- Python version: 3.6.7\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source): bazel release 0.24.1\r\n- GCC/Compiler version (if compiling from source): \"C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC//bin/amd64/cl.exe\"\r\nMicrosoft (R) C/C++ Optimizing Compiler Version 19.00.24234.1 for x64\r\n- CUDA/cuDNN version: 10.1/7.6.1\r\n- GPU model and memory: GeForce GTX 1060 (6GB)\r\n\r\n\r\n\r\n**Describe the problem**\r\nBuild fails with error:\r\nERROR: D:/data/users/andrey/projects/tensorflow_gpu_v2.0_2/tensorflow/compiler/xla/service/BUILD:2338:1: C++ compilation of rule '//tensorflow/compiler/xla/service:hlo_execution_profile' failed (Exit 2): python.exe failed: error executing command\r\n  cd C:/users/andrey/_bazel_andrey/xstmf7fr/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1\r\n    SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\INCLUDE;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\winrt;\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\LIB\\amd64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\um\\x64;\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\amd64;C:\\windows\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\Tools;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x86;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;;C:\\windows\\system32\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=D:/Data/Users/andrey/AppData/Local/Programs/Python/Python36/python.exe\r\n    SET PYTHON_LIB_PATH=D:/Data/Users/andrey/AppData/Local/Programs/Python/Python36/lib/site-packages\r\n    SET TEMP=C:\\Users\\andrey\\AppData\\Local\\Temp\r\n    SET TF_CONFIGURE_IOS=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=6.1\r\n    SET TF_CUDA_PATHS=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1,C:/Program Files/cudnn-10.1-windows10-x64-v7.6.1.34\r\n    SET TF_CUDA_VERSION=10.1\r\n    SET TF_CUDNN_VERSION=7.6.1\r\n    SET TF_NEED_CUDA=1\r\n    SET TMP=C:\\Users\\andrey\\AppData\\Local\\Temp\r\n  D:/Data/Users/andrey/AppData/Local/Programs/Python/Python36/python.exe -B external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/genfiles /Ibazel-out/x64_windows-opt/bin /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/genfiles/external/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/nsync /Ibazel-out/x64_windows-opt/genfiles/external/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/x64_windows-opt/genfiles/external/local_config_sycl /Ibazel-out/x64_windows-opt/bin/external/local_config_sycl /Iexternal/gif_archive /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive /Ibazel-out/x64_windows-opt/bin/external/gif_archive /Iexternal/jpeg /Ibazel-out/x64_windows-opt/genfiles/external/jpeg /Ibazel-out/x64_windows-opt/bin/external/jpeg /Iexternal/com_google_protobuf /Ibazel-out/x64_windows-opt/genfiles/external/com_google_protobuf /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/genfiles/external/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-opt/genfiles/external/fft2d /Ibazel-out/x64_windows-opt/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-opt/genfiles/external/highwayhash /Ibazel-out/x64_windows-opt/bin/external/highwayhash /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-opt/genfiles/external/snappy /Ibazel-out/x64_windows-opt/bin/external/snappy /Iexternal/local_config_cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda /Iexternal/local_config_tensorrt /Ibazel-out/x64_windows-opt/genfiles/external/local_config_tensorrt /Ibazel-out/x64_windows-opt/bin/external/local_config_tensorrt /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/genfiles/external/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/gif_archive/lib /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/lib /Ibazel-out/x64_windows-opt/bin/external/gif_archive/lib /Iexternal/gif_archive/windows /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/windows /Ibazel-out/x64_windows-opt/bin/external/gif_archive/windows /Iexternal/com_google_protobuf/src /Ibazel-out/x64_windows-opt/genfiles/external/com_google_protobuf/src /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf/src /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive/src /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda /Iexternal/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/include /D__CLANG_SUPPORT_DYN_ANNOTATION__ /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DEIGEN_HAS_TYPE_TRAITS=0 /DTF_USE_SNAPPY /showIncludes /MD /O2 /DNDEBUG -w -DWIN32_LEAN_AND_MEAN -DNOGDI /arch:AVX2 -nvcc_options=disable-warnings /Fobazel-out/x64_windows-opt/bin/tensorflow/compiler/xla/service/_objs/hlo_execution_profile/hlo_execution_profile.o /c tensorflow/compiler/xla/service/hlo_execution_profile.cc\r\nExecution platform: @bazel_tools//platforms:host_platform\r\n.\\tensorflow/compiler/xla/service/hlo_cost_analysis.h(42): error C2131: expression did not evaluate to a constant\r\n.\\tensorflow/compiler/xla/service/hlo_cost_analysis.h(42): note: failure was caused by unevaluable pointer value\r\n.\\tensorflow/compiler/xla/service/hlo_cost_analysis.h(43): error C2131: expression did not evaluate to a constant\r\n.\\tensorflow/compiler/xla/service/hlo_cost_analysis.h(43): note: failure was caused by unevaluable pointer value\r\n.\\tensorflow/compiler/xla/service/hlo_cost_analysis.h(44): error C2131: expression did not evaluate to a constant\r\n.\\tensorflow/compiler/xla/service/hlo_cost_analysis.h(44): note: failure was caused by unevaluable pointer value\r\n.\\tensorflow/compiler/xla/service/hlo_cost_analysis.h(45): error C2131: expression did not evaluate to a constant\r\n.\\tensorflow/compiler/xla/service/hlo_cost_analysis.h(45): note: failure was caused by unevaluable pointer value\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nbazel build --config=opt --config=cuda --copt=-nvcc_options=disable-warnings //tensorflow/tools/pip_package:build_pip_package\r\n\r\n\r\n**Any other info / logs**\r\n.tf_configure.bazelrc\r\nbuild --action_env PYTHON_BIN_PATH=\"D:/Data/Users/andrey/AppData/Local/Programs/Python/Python36/python.exe\"\r\nbuild --action_env PYTHON_LIB_PATH=\"D:/Data/Users/andrey/AppData/Local/Programs/Python/Python36/lib/site-packages\"\r\nbuild --python_path=\"D:/Data/Users/andrey/AppData/Local/Programs/Python/Python36/python.exe\"\r\nbuild:xla --define with_xla_support=true\r\nbuild --action_env TF_CUDA_VERSION=\"10.1\"\r\nbuild --action_env TF_CUDNN_VERSION=\"7.6.1\"\r\nbuild --action_env TF_CUDA_PATHS=\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1,C:/Program Files/cudnn-10.1-windows10-x64-v7.6.1.34\"\r\nbuild --action_env CUDA_TOOLKIT_PATH=\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1\"\r\nbuild --action_env TF_CUDA_COMPUTE_CAPABILITIES=\"6.1\"\r\nbuild --config=cuda\r\nbuild:opt --copt=/arch:AVX2\r\nbuild:opt --define with_default_optimizations=true\r\nbuild --config monolithic\r\nbuild --copt=-w --host_copt=-w\r\nbuild --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI\r\nbuild --verbose_failures\r\nbuild --distinct_host_configuration=false\r\nbuild --define=override_eigen_strong_inline=true\r\nbuild:v2 --define=tf_api_version=2\r\ntest --flaky_test_attempts=3\r\ntest --test_size_filters=small,medium\r\ntest --test_tag_filters=-benchmark-test,-no_oss,-oss_serial\r\ntest --build_tag_filters=-benchmark-test,-no_oss\r\ntest --test_tag_filters=-no_windows,-gpu\r\ntest --build_tag_filters=-no_windows,-gpu\r\nbuild --action_env TF_CONFIGURE_IOS=\"0\"", "comments": ["I run 2 time, and got other error:\r\nERROR: D:/data/users/andrey/projects/tensorflow_gpu_v2.0_2/tensorflow/compiler/xla/service/BUILD:2237:1: C++ compilation of rule '//tensorflow/compiler/xla/service:computation_placer' failed (Exit 2): python.exe failed: error executing command\r\n  cd C:/users/andrey/_bazel_andrey/xstmf7fr/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1\r\n    SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\INCLUDE;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\winrt;\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\LIB\\amd64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\um\\x64;\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\amd64;C:\\windows\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\Tools;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x86;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;;C:\\windows\\system32\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=D:/Data/Users/andrey/AppData/Local/Programs/Python/Python36/python.exe\r\n    SET PYTHON_LIB_PATH=D:/Data/Users/andrey/AppData/Local/Programs/Python/Python36/lib/site-packages\r\n    SET TEMP=C:\\Users\\andrey\\AppData\\Local\\Temp\r\n    SET TF_CONFIGURE_IOS=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=6.1\r\n    SET TF_CUDA_PATHS=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1,C:/Program Files/cudnn-10.1-windows10-x64-v7.6.1.34\r\n    SET TF_CUDA_VERSION=10.1\r\n    SET TF_CUDNN_VERSION=7.6.1\r\n    SET TF_NEED_CUDA=1\r\n    SET TMP=C:\\Users\\andrey\\AppData\\Local\\Temp\r\n  D:/Data/Users/andrey/AppData/Local/Programs/Python/Python36/python.exe -B external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/genfiles /Ibazel-out/x64_windows-opt/bin /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/genfiles/external/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/nsync /Ibazel-out/x64_windows-opt/genfiles/external/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/x64_windows-opt/genfiles/external/local_config_sycl /Ibazel-out/x64_windows-opt/bin/external/local_config_sycl /Iexternal/gif_archive /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive /Ibazel-out/x64_windows-opt/bin/external/gif_archive /Iexternal/jpeg /Ibazel-out/x64_windows-opt/genfiles/external/jpeg /Ibazel-out/x64_windows-opt/bin/external/jpeg /Iexternal/com_google_protobuf /Ibazel-out/x64_windows-opt/genfiles/external/com_google_protobuf /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/genfiles/external/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-opt/genfiles/external/fft2d /Ibazel-out/x64_windows-opt/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-opt/genfiles/external/highwayhash /Ibazel-out/x64_windows-opt/bin/external/highwayhash /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-opt/genfiles/external/snappy /Ibazel-out/x64_windows-opt/bin/external/snappy /Iexternal/local_config_cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda /Iexternal/local_config_tensorrt /Ibazel-out/x64_windows-opt/genfiles/external/local_config_tensorrt /Ibazel-out/x64_windows-opt/bin/external/local_config_tensorrt /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/genfiles/external/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/gif_archive/lib /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/lib /Ibazel-out/x64_windows-opt/bin/external/gif_archive/lib /Iexternal/gif_archive/windows /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/windows /Ibazel-out/x64_windows-opt/bin/external/gif_archive/windows /Iexternal/com_google_protobuf/src /Ibazel-out/x64_windows-opt/genfiles/external/com_google_protobuf/src /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf/src /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive/src /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda /Iexternal/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/include /D__CLANG_SUPPORT_DYN_ANNOTATION__ /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DEIGEN_HAS_TYPE_TRAITS=0 /DTF_USE_SNAPPY /showIncludes /MD /O2 /DNDEBUG -w -DWIN32_LEAN_AND_MEAN -DNOGDI /arch:AVX2 -nvcc_options=disable-warnings /Fobazel-out/x64_windows-opt/bin/tensorflow/compiler/xla/service/_objs/computation_placer/computation_placer.o /c tensorflow/compiler/xla/service/computation_placer.cc\r\nExecution platform: @bazel_tools//platforms:host_platform\r\ntensorflow/compiler/xla/service/computation_placer.cc(47): error C2064: term does not evaluate to a function taking 2 arguments\r\ntensorflow/compiler/xla/service/computation_placer.cc(47): note: class does not define an 'operator()' or a user defined conversion operator to a pointer-to-function or reference-to-function that takes appropriate number of arguments\r\ntensorflow/compiler/xla/service/computation_placer.cc(72): error C2064: term does not evaluate to a function taking 2 arguments\r\ntensorflow/compiler/xla/service/computation_placer.cc(72): note: class does not define an 'operator()' or a user defined conversion operator to a pointer-to-function or reference-to-function that takes appropriate number of arguments\r\ntensorflow/compiler/xla/service/computation_placer.cc(95): error C2064: term does not evaluate to a function taking 2 arguments\r\ntensorflow/compiler/xla/service/computation_placer.cc(95): note: class does not define an 'operator()' or a user defined conversion operator to a pointer-to-function or reference-to-function that takes appropriate number of arguments\r\ntensorflow/compiler/xla/service/computation_placer.cc(108): error C2661: 'xla::Array<T>::operator ()': no overloaded function takes 2 arguments\r\n        with\r\n        [\r\n            T=int\r\n        ]\r\ntensorflow/compiler/xla/service/computation_placer.cc(132): error C2064: term does not evaluate to a function taking 2 arguments\r\ntensorflow/compiler/xla/service/computation_placer.cc(132): note: class does not define an 'operator()' or a user defined conversion operator to a pointer-to-function or reference-to-function that takes appropriate number of arguments\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build", "Run 3:\r\nERROR: D:/data/users/andrey/projects/tensorflow_gpu_v2.0_2/tensorflow/compiler/xla/BUILD:437:1: C++ compilation of rule '//tensorflow/compiler/xla:literal_util' failed (Exit 2): python.exe failed: error executing command\r\n  cd C:/users/andrey/_bazel_andrey/xstmf7fr/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1\r\n    SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\INCLUDE;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\winrt;\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\LIB\\amd64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\um\\x64;\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\amd64;C:\\windows\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\Tools;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x86;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;;C:\\windows\\system32\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=D:/Data/Users/andrey/AppData/Local/Programs/Python/Python36/python.exe\r\n    SET PYTHON_LIB_PATH=D:/Data/Users/andrey/AppData/Local/Programs/Python/Python36/lib/site-packages\r\n    SET TEMP=C:\\Users\\andrey\\AppData\\Local\\Temp\r\n    SET TF_CONFIGURE_IOS=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=6.1\r\n    SET TF_CUDA_PATHS=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1,C:/Program Files/cudnn-10.1-windows10-x64-v7.6.1.34\r\n    SET TF_CUDA_VERSION=10.1\r\n    SET TF_CUDNN_VERSION=7.6.1\r\n    SET TF_NEED_CUDA=1\r\n    SET TMP=C:\\Users\\andrey\\AppData\\Local\\Temp\r\n  D:/Data/Users/andrey/AppData/Local/Programs/Python/Python36/python.exe -B external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/genfiles /Ibazel-out/x64_windows-opt/bin /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/genfiles/external/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/nsync /Ibazel-out/x64_windows-opt/genfiles/external/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/x64_windows-opt/genfiles/external/local_config_sycl /Ibazel-out/x64_windows-opt/bin/external/local_config_sycl /Iexternal/gif_archive /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive /Ibazel-out/x64_windows-opt/bin/external/gif_archive /Iexternal/jpeg /Ibazel-out/x64_windows-opt/genfiles/external/jpeg /Ibazel-out/x64_windows-opt/bin/external/jpeg /Iexternal/com_google_protobuf /Ibazel-out/x64_windows-opt/genfiles/external/com_google_protobuf /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/genfiles/external/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-opt/genfiles/external/fft2d /Ibazel-out/x64_windows-opt/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-opt/genfiles/external/highwayhash /Ibazel-out/x64_windows-opt/bin/external/highwayhash /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-opt/genfiles/external/snappy /Ibazel-out/x64_windows-opt/bin/external/snappy /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/genfiles/external/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/gif_archive/lib /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/lib /Ibazel-out/x64_windows-opt/bin/external/gif_archive/lib /Iexternal/gif_archive/windows /Ibazel-out/x64_windows-opt/genfiles/external/gif_archive/windows /Ibazel-out/x64_windows-opt/bin/external/gif_archive/windows /Iexternal/com_google_protobuf/src /Ibazel-out/x64_windows-opt/genfiles/external/com_google_protobuf/src /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf/src /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-opt/genfiles/external/farmhash_archive/src /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/genfiles/external/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/genfiles/external/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /D__CLANG_SUPPORT_DYN_ANNOTATION__ /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DEIGEN_HAS_TYPE_TRAITS=0 /DTF_USE_SNAPPY /showIncludes /MD /O2 /DNDEBUG -w -DWIN32_LEAN_AND_MEAN -DNOGDI /arch:AVX2 -nvcc_options=disable-warnings /Fobazel-out/x64_windows-opt/bin/tensorflow/compiler/xla/_objs/literal_util/literal_util.o /c tensorflow/compiler/xla/literal_util.cc\r\nExecution platform: @bazel_tools//platforms:host_platform\r\n.\\tensorflow/compiler/xla/array2d.h(108): error C2064: term does not evaluate to a function taking 2 arguments\r\n.\\tensorflow/compiler/xla/array2d.h(108): note: class does not define an 'operator()' or a user defined conversion operator to a pointer-to-function or reference-to-function that takes appropriate number of arguments\r\ntensorflow/compiler/xla/literal_util.cc(317): note: see reference to function template instantiation 'std::unique_ptr<xla::Array2D<float>,std::default_delete<_Ty>> xla::MakeLinspaceArray2D<float>(double,double,tensorflow::int64,tensorflow::int64)' being compiled\r\n        with\r\n        [\r\n            _Ty=xla::Array2D<float>\r\n        ]\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build", "I see that the error comes from tensorflow/compiler/xla/array2d.h(108)\r\nhttps://github.com/tensorflow/tensorflow/blame/master/tensorflow/compiler/xla/array2d.h#L108\r\n\r\n@hawkinsp @jlebar @tensorflower-gardener @bixia1 @sanjoy I see that you contributed to this file.\r\nMay I ask for your assistance?\r\nThanks in advance!", "Maybe I compile with wrong cl.exe?\r\nThis one tries to compile:\r\n\r\nC:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64/cl.exe\r\nFile version: 19.0.24234.1\r\nProduct name: Microsoft Visual Studio 2015\r\nProduct version: 14.00.24234.1", "XLA on windows is not yet supported as far as I know. There should be another issue already open for XLA on windows. Please retriage, routing to XLA team.", "Yes, we don't yet support XLA on Windows.  But I'd be happy to review patches that fix windows specific issues on a case by case basis.", "Closing this issue since we have an existing thread discussing the same topic.\r\nhttps://github.com/tensorflow/tensorflow/issues/15213\r\nFeel free to reopen if necessary. Thanks!"]}, {"number": 30414, "title": "[Lite] num_ranks option brings to user through cmd line parameter", "body": "num_ranks optional parameters provides to user to calculate accuracy ranks on out file.", "comments": []}, {"number": 30413, "title": "gradient back propagation in tf.contrib.image.transform", "body": "**System information** Ubuntu 16.04\r\nTensorFlow version 1.10.1\r\n\r\ntf.contrib.image.transform applies the given transform(s) to the image(s). But gradients are not backpropagated into transformation parameters https://www.tensorflow.org/api_docs/python/tf/contrib/image/transform. \r\nAffine transformations can be constructed using a series of translations, scales, rotations and shears. It could calculate the gradient and back propagation, at least in rotation,scale and translations. I noticed that tf.contrib.image.rotate and tf.contrib.image.translate do not emphasize that gradients cannot propagate backwards.\r\nI'd like to know how to back propagation into the transformation parameters especially in affine transform. Do I need to explicitly define the gradient using gradient_map_override?\uff08#17442\uff09\r\n\r\nAny suggestions would be helpful. Thanks\r\n\r\nThis may change the current api.", "comments": ["@xuyingxiao ,\r\nCan you please try using latest version of Tensorflow (1.14) and confirm if the issue still persists.\r\n\r\nIf the issue persists, In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "Yeah,there is a demo https://github.com/xuyingxiao/image_transform\r\nThe main loss function lines:\r\n    `h10 = tf.cos(pred_rotate_theta)*pred_scale_x\r\n    h11 = tf.sin(pred_rotate_theta)*pred_scale_x\r\n    h12 = pred_offset_x\r\n    h20 = -tf.sin(pred_rotate_theta)*pred_scale_x\r\n    h21 = tf.cos(pred_rotate_theta)*pred_scale_y\r\n    h22 = pred_offset_y\r\n    h30 = tf.constant([0.0])\r\n    h31 = tf.constant([0.0])\r\n    h32 = tf.constant([1.0])\r\n\r\n    matrix_3_3 = tf.linalg.inv(tf.reshape(tf.concat([h10,h11,h12,h20,h21,h22,h30,h31,h32],axis=-1),shape=(3,3)))\r\n    matrix_1_8 = tf.contrib.image.matrices_to_flat_transforms(matrix_3_3)\r\n\r\n    warp_image = tf.contrib.image.transform(input_disp_polygon_map,matrix_1_8,interpolation=\"BILINEAR\",name=None)\r\n    print(\"warp_image\",warp_image.shape)\r\n\twarp_loss = tf.reduce_mean(tf.abs(warp_image - input_gt_polygon_map))`\r\n\r\n**Commit line 504 runs with only warp_loss, THANKS!** \r\nAny suggestions would be helpful.", "@xuyingxiao \r\n\r\ndid someone solve this?", "> @xuyingxiao\r\n> \r\n> did someone solve this?\r\n\r\nNot yet.", "tf.contrib.image.translate has the same issue.", "This solved problem: https://github.com/kevinzakka/spatial-transformer-network\r\nEnjoy :)", "`contrib` module is deprecated with TF 2.X \r\nYou may still use subset if features by using `tf addons` module. Thanks!\r\nhttps://www.tensorflow.org/addons/api_docs/python/tfa/image"]}, {"number": 30412, "title": " I noticed that MonitoredSession is a very inefficient method.How to save the model according to the set conditions, not periodically.", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**win10\r\n- TensorFlow version (you are using):1.12\r\n- Are you willing to contribute it (Yes/No):no\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n I noticed that MonitoredSession is a very inefficient method.Saving the model periodically.\r\n**Will this change the current api? How?**\r\nSetting conditions to save the model, not periodically.\r\n**Who will benefit with this feature?**\r\neveryone\r\n**Any Other info.**\r\n", "comments": ["Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information."]}, {"number": 30411, "title": "NCHW or NHWC when convert .pb into .tflite", "body": "**System information**\r\n- OS Platform and Distribution :Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (or github SHA if from source):1.13.1\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\nCheck failed: status.ok() Unexpected value for attribute 'data_format'. Expected 'NHWC'\r\n\r\n**Any other info / logs**\r\n\r\nThe model I trained uses 'NCHW', such as my TF point - conv2d, which is in NCHW format. Now I want to convert frozen.pb to frozen. tflite. The above error occurred in the program. I want to know how I can successfully convert NCHW-formatted models to tflite when I only have frozen.pb. Thanks\r\n", "comments": ["Can you provide a minimally reproducible example? Either provide the frozen graph with the commands to convert the model, or provide a snippet of code that produces the same error.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30411\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30411\">No</a>\n"]}, {"number": 30410, "title": "Get prediction from tflite model Android", "body": "I worked on eye detection in real time project.\r\nI have generated a tflite model graph from trained frozen inference graph .pb and I want to use the tflite model in Android Studio.\r\nI have integrated OpenCV library and I have added TensorFlow tflite library in the application.\r\nThe front cam of my android device works fine.\r\n+ I have this code: \r\n```.java\r\n\r\npackage com.example.opencvtest;\r\n\r\nimport org.opencv.android.BaseLoaderCallback;\r\nimport org.opencv.android.CameraBridgeViewBase.CvCameraViewFrame;\r\nimport org.opencv.android.LoaderCallbackInterface;\r\nimport org.opencv.android.OpenCVLoader;\r\nimport org.opencv.core.Mat;\r\nimport org.opencv.android.CameraBridgeViewBase;\r\nimport org.opencv.android.CameraBridgeViewBase.CvCameraViewListener2;\r\n\r\nimport android.app.Activity;\r\nimport android.content.pm.ActivityInfo;\r\nimport android.content.res.AssetFileDescriptor;\r\nimport android.hardware.Camera;\r\nimport android.os.Bundle;\r\nimport android.util.Log;\r\nimport android.view.Menu;\r\nimport android.view.MenuItem;\r\nimport android.view.SurfaceView;\r\nimport android.view.WindowManager;\r\nimport android.widget.Toast;\r\n\r\nimport java.io.FileInputStream;\r\nimport java.io.IOException;\r\nimport java.lang.reflect.Method;\r\nimport java.nio.MappedByteBuffer;\r\nimport java.nio.channels.FileChannel;\r\nimport org.tensorflow.lite.Interpreter;\r\nimport org.tensorflow.lite.Tensor;\r\n\r\n\r\npublic class MainActivity extends Activity implements CvCameraViewListener2 {\r\n    private static final String TAG = \"OCVSample::Activity\";\r\n\r\n    private CameraBridgeViewBase mOpenCvCameraView;\r\n    private boolean              mIsJavaCamera = true;\r\n    private MenuItem             mItemSwitchCamera = null;\r\n    String modelFile=\"iristf.tflite\";\r\n    Interpreter tflite;\r\n    Tensor ts;\r\n\r\n\r\n    //Load model tflite\r\n    private MappedByteBuffer loadModelFile(Activity activity, String MODEL_FILE) throws IOException {\r\n        AssetFileDescriptor fileDescriptor = activity.getAssets().openFd(MODEL_FILE);\r\n        FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor());\r\n        FileChannel fileChannel = inputStream.getChannel();\r\n        long startOffset = fileDescriptor.getStartOffset();\r\n        long declaredLength = fileDescriptor.getDeclaredLength();\r\n        return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength);\r\n    }\r\n    private BaseLoaderCallback mLoaderCallback = new BaseLoaderCallback(this) {\r\n        @Override\r\n        public void onManagerConnected(int status) {\r\n            switch (status) {\r\n                case LoaderCallbackInterface.SUCCESS:\r\n                {\r\n                    Log.i(TAG, \"OpenCV loaded successfully\");\r\n                    mOpenCvCameraView.setCameraIndex(1);\r\n                    mOpenCvCameraView.enableView();\r\n                } break;\r\n                default:\r\n                {\r\n                    super.onManagerConnected(status);\r\n                } break;\r\n            }\r\n        }\r\n    };\r\n\r\n    public MainActivity() {\r\n        Log.i(TAG, \"Instantiated new \" + this.getClass());\r\n    }\r\n\r\n    /** Called when the activity is first created. */\r\n    @Override\r\n    public void onCreate(Bundle savedInstanceState) {\r\n        Log.i(TAG, \"called onCreate\");\r\n        super.onCreate(savedInstanceState);\r\n        setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_PORTRAIT);\r\n\r\n        getWindow().addFlags(WindowManager.LayoutParams.FLAG_KEEP_SCREEN_ON);\r\n\r\n        setContentView(R.layout.activity_main);\r\n        try {\r\n            tflite = new Interpreter(loadModelFile(this, modelFile));\r\n             ts=tflite.getInputTensor(0);\r\n\r\n        }\r\n        catch (IOException e) {\r\n            e.printStackTrace();\r\n        }\r\n\r\n        mOpenCvCameraView = (CameraBridgeViewBase) findViewById(R.id.tutorial1_activity_java_surface_view);\r\n\r\n        mOpenCvCameraView.setVisibility(SurfaceView.VISIBLE);\r\n\r\n        mOpenCvCameraView.setCvCameraViewListener(this);\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n    }\r\n\r\n    @Override\r\n    public void onPause()\r\n    {\r\n        super.onPause();\r\n        if (mOpenCvCameraView != null)\r\n            mOpenCvCameraView.disableView();\r\n    }\r\n\r\n    @Override\r\n    public void onResume()\r\n    {\r\n        super.onResume();\r\n        if (!OpenCVLoader.initDebug()) {\r\n            Log.d(TAG, \"Internal OpenCV library not found. Using OpenCV Manager for initialization\");\r\n            OpenCVLoader.initAsync(OpenCVLoader.OPENCV_VERSION_3_0_0, this, mLoaderCallback);\r\n        } else {\r\n            Log.d(TAG, \"OpenCV library found inside package. Using it!\");\r\n            mLoaderCallback.onManagerConnected(LoaderCallbackInterface.SUCCESS);\r\n        }\r\n    }\r\n\r\n    public void onDestroy() {\r\n        super.onDestroy();\r\n        if (mOpenCvCameraView != null)\r\n            mOpenCvCameraView.disableView();\r\n    }\r\n\r\n    public void onCameraViewStarted(int width, int height) {\r\n    }\r\n\r\n    public void onCameraViewStopped() {\r\n    }\r\n\r\n    public Mat onCameraFrame(CvCameraViewFrame inputFrame) {\r\n        return inputFrame.rgba();\r\n    }\r\n    protected void setDisplayOrientation(Camera camera, int angle){\r\n        Method downPolymorphic;\r\n        try\r\n        {\r\n            downPolymorphic = camera.getClass().getMethod(\"setDisplayOrientation\", new Class[] { int.class });\r\n            if (downPolymorphic != null)\r\n                downPolymorphic.invoke(camera, new Object[] { angle });\r\n        }\r\n        catch (Exception e1)\r\n        {\r\n            e1.printStackTrace();\r\n        }\r\n    }\r\n}\r\n\r\n\r\n```\r\n\r\nMy goals are : \r\n\r\n+ Decomposed the input streaming from cam into frames.\r\n+ Get predictions from frames using tflite model.\r\n\r\nI have followed many tutorials ( Medium StackOverflow, Github, Tensorflow Documentation...).\r\nBut I didn't get an answer to those questions below :\r\n\r\nI want to know how can I get predictions from video stream?\r\nHow can I get frames from input streaming?\r\nHow to use the tflite model to get predictions from the video stream ( or images )?\r\n\r\nThanks.", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged//tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n", "I ask this  question on stackoverflow and data science stack exchange but I didn't get any answer :\r\n[Link](https://datascience.stackexchange.com/questions/55089/extract-features-predictions-from-tflite-model-on-android-device)", "@abdou31 ,\r\nSorry to inform you that providing support at such level will be difficult as there are high priority Bugs, Performance Issues and Feature Requests to be looked upon.", "But this is related to developer's use , I mean my question have a relationship with how to use Tensorflow on mobile ( documentation ) \r\nBut I didn't found anything on documentation.\r\nThe only thing that I found, is ML kit with Tensorflow ( firebase ) but this is not recomended beacause it not always free and it requires INTERNET CONNECTION.", "@abdou31 Which model are you training? What is the input data to the model?\r\n\r\nFrom my understanding, there is no way to run the model on Videos (Not sure if there are models which work on videos). The models usually expect images or sequence of images. \r\n\r\nSo you have to extract the images from the video feed and input to your inference pipeline", "The model that I worked on is Resnet,\r\nThis is the project that I use for creating my own model and training my own dataset \r\n+ [link](https://github.com/yinguobing/cnn-facial-landmark)\r\nThe input data is a sequence of images ( or streaming input e.g webcam ).\r\nThe output sequence of image ( or streaming input e.g webcam that show the points on the eye region ) like this :\r\n![ssasse](https://user-images.githubusercontent.com/19480228/60874720-c0eaea80-a238-11e9-9b81-3de29a965879.PNG)\r\n\r\nI have successfully got a result from my webcam ( pc webcam ) using frozen inference model ( not good result because the training is started from scratch).\r\nBut the problem now is on the mobile device, I need to use the model ( tflite or frozen .pb ) with Android SDK.\r\nHow can I do that?\r\n", "Checkout how TFLite andorid sample apps. You basically get imae from camera and do the required preprocessing before passing the image to your model.", "I started to do this\r\nI have asked for help from others on many websites (StackOverflow, data StackExchange ) but I didn't get any results \r\nAs you can see, those are links related to my questions on websites I talked about:\r\n[link 1](https://datascience.stackexchange.com/questions/55089/extract-features-predictions-from-tflite-model-on-android-device)\r\n[link 2](https://stackoverflow.com/questions/56915664/extracting-features-predictions-from-tflite-model)\r\n\r\nOn those websites, I have attached the source code that I have got from some tutorials and TensorFlow samples to starting the project. \r\nThe principal problem here is that TensorFlow samples are talking about image classification and object detection but my project is talking about eye region landmarks ( draw landmark on the eye region ) using the regression, not a classification.\r\nDo you have any idea about how can I get predictions from the last layer of the tflite model?\r\n", "Another example you might want to look at in Image segmentation on Andorid, there are different projects on github which do this.", "Also image segmentation is not related to my project..\r\nCan you gives me links of project on github that can help me?", "Hi @abdou31 , the detection sample is not unlike what you want (see https://www.tensorflow.org/lite/models/object_detection/overview), and demonstrates how to feed frame inputs and parse semantic outputs (e.g., labels, boxes) for use in your app.", "I had explained what I want and I had told you that the project is not a classification [link](https://github.com/tensorflow/examples/pull/73) my CNN used regression to predict and localize the eye region and draw landmarks on contours of the eye.\r\nSo image classification doesn't meet what I want.\r\n", "@abdou31 while classification/detection are not identical to your use-case, the point is that they demonstrate how to map to and from model-specific inputs/outputs. I would recommend using some of the instructions @ https://www.tensorflow.org/lite/guide/faq#how_do_i_inspect_a_tflite_file, or a model visualizer like [Netron](https://github.com/lutzroeder/netron), to inspect the names/types of the inputs/outputs of your graph, and work back from there.", "Thanks, I have the name and the types of the outputs and inputs of my model ( frozen inference graph .pb ) that I used to generate tflite model.\r\nI have read and I have seen many tutorials and I know that my tflite model has an input tensor with those parameters (batch, width, height, channels) => (1,112,112,3): input_to_float:0\r\nchannels=>3 ( RGB) .\r\nand for the input is a frame ( image ):  logits/BiasAdd:0\r\nI had successfully got a good result and extract predictions from frozen inference graph using a python script.\r\nWhen I take the webcam as an input, I get an output with landmark drawn on the eye region.\r\nSo my object, for now, not a detection from webcam of the PC, but from my smartphone.\r\nFor that reason, I have converted the model to tflite model to use it in Android Studio following steps and instructions mentioned on the Tensorflow guide ( add the model in the assets folder...).\r\nBut I encountered some difficulties when I try to add an image as an input and try to get just the positions of landmarks ( x and y coordinates ).\r\nHoping you understand me.", "@abdou31 I got the same problem as you. In my case, I want to extract the image features before the fully connected layer by TFLite, and I will use the image feature to find some similar images. But the solutions what I found is all about Python and C++, I don't know how to get the feature by TFLite, did you solve it?", "I change to CoreML with iPhone. \r\nI did not find a solution for tensorflow lite", "@abdou31 So your project dose not support Android right now? Or you use other ML framework on Android? And could you tell me which API in CoreML can extract the features, thanks.", " I'm a Phd student and the project is to validate the end of the studies.\r\nSo the project requires a mobile app ( for iphone or for android ).\r\nFor that reason I have changed to Iphone ( CoreML), also I have found a implementation that does not needed a many changes."]}, {"number": 30409, "title": "[TF2.0] TensorArray and tf.function", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code: `yes`\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `OSX`\r\n- TensorFlow installed from (source or binary): `binary - 2.0.0-beta1`\r\n- TensorFlow version (use command below): `v2.0.0-beta0-16-g1d91213fe7 2.0.0-beta1`\r\n- Python version: `3.6`\r\n\r\n**Describe the current behaviour**\r\n\r\nThe code works in eager mode but does not work when applying the decorator `@tf.function`.\r\n2 errors happen sequentially:\r\n- The first one is about types, `Dataset.enumerate()` outputs an index of type `int64` which is different from a `TensorArray` inner type (`int32`). \r\n\r\n- The second one breaks because of uninitialized tensors.\r\n\r\n**Describe the expected behaviour**\r\nFor the first one, It should break in eager mode too.\r\nFor the second one, it should work as in eager mode\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\n\r\na = tf.random.uniform([10, 2])\r\nd = tf.data.Dataset.from_tensor_slices(a).batch(2)\r\n\r\n\r\ndef accumulate(d):\r\n    arr = tf.TensorArray(tf.float32, 1, dynamic_size=True)\r\n\r\n    for i, t in d.enumerate():\r\n        arr.write(i, t)\r\n\r\n    return arr.concat()\r\n\r\n\r\n@tf.function\r\ndef accumulate_f_error1(d):\r\n    arr = tf.TensorArray(tf.float32, 1, dynamic_size=True)\r\n\r\n    for i, t in d.enumerate():\r\n        arr.write(i, t)\r\n\r\n    return arr.concat()\r\n\r\n\r\n@tf.function\r\ndef accumulate_f_error2(d):\r\n    arr = tf.TensorArray(tf.float32, 1, dynamic_size=True)\r\n\r\n    for i, t in d.enumerate():\r\n        j = tf.cast(i, tf.int32)\r\n        arr.write(j, t)\r\n\r\n    return arr.concat()\r\n\r\n\r\n# Works well\r\ndata = accumulate(d)\r\nprint(data)\r\n\r\n# # Breaks because of  a wrong type\r\n# data = accumulate_f_error1(d)\r\n# print(data)\r\n\r\n# Breaks due to uninitialized tensors?\r\ndata = accumulate_f_error2(d)\r\nprint(data)\r\n```", "comments": ["I am able to reproduce the above mention issue on Colab with Tensorflow 2.0.0.beta1. ", "Replace `arr.write(j, t)` with `arr = arr.write(j, t)`\r\n\r\nThe issue is that tf.function executes as a graph. In eager mode the array will be updated (as a convenience), but you're really meant to use the return value to chain operations: https://www.tensorflow.org/api_docs/python/tf/TensorArray#returns_6", "Thanks a lot for your answer, this was not obvious to me.\r\n\r\nI've also noticed that this one also return an error when using `tf.function`:\r\n```python\r\ndef accumulate_arg(d, arr):\r\n    for i, t in d.enumerate():\r\n        arr = arr.write(tf.cast(i, tf.int32), t)\r\n\r\n    return arr.concat()\r\n\r\n\r\n@tf.function\r\ndef accumulate_graph_arg(d, arr):\r\n    for i, t in d.enumerate():\r\n        arr = arr.write(tf.cast(i, tf.int32), t)\r\n\r\n    return arr.concat()\r\n\r\n\r\n# Works well\r\narr = tf.TensorArray(tf.float32, 1, dynamic_size=True)\r\ndata = accumulate_arg(d, arr)\r\nprint(\"accumulate_arg\\n\", data)\r\n\r\n# breaks\r\narr = tf.TensorArray(tf.float32, 1, dynamic_size=True)\r\ndata = accumulate_graph_arg(d, arr)\r\nprint(\"accumulate_graph_arg\\n\", data)\r\n```\r\n\r\nBut now I'm not sure anymore if this is a bug or not. TF2 is really nice but can clearly be quite strange to figure out if something is not working because of a bug or not.", "In the latter example you're trying to write an int32 where TensorFlow expects a float32. Again, my guess is that eager does some auto casting for convenience; however that generally shouldn't be relied upon.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30409\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30409\">No</a>\n", "I'm sorry but I don't believe this has anything to do with autocasting in eager mode because it has nothing to do with eager mode.\r\nI should have put the whole example.\r\n```python\r\nimport tensorflow as tf\r\n\r\n\r\n# Data types is float32\r\na = tf.random.uniform([10, 2])\r\nd = tf.data.Dataset.from_tensor_slices(a).batch(2)\r\n\r\n\r\n@tf.function\r\ndef accumulate_graph(d):\r\n    arr = tf.TensorArray(tf.float32, 1, dynamic_size=True)\r\n\r\n    for i, t in d.enumerate():\r\n        arr = arr.write(tf.cast(i, tf.int32), t)\r\n\r\n    return arr.concat()\r\n\r\n\r\n@tf.function\r\ndef accumulate_graph_arg(d, arr):\r\n    for i, t in d.enumerate():\r\n        arr = arr.write(tf.cast(i, tf.int32), t)\r\n\r\n    return arr.concat()\r\n\r\n\r\n\r\n# Works well (not eager mode)\r\ndata = accumulate_graph(d)\r\nprint(\"accumulate_graph\\n\", data)\r\n\r\n\r\n# Does not work\r\n# The only thing that changes is that the tensorArray is coming from outside the function\r\n\r\n# Error: ValueError: Cannot convert a partially known TensorShape to a Tensor: <unknown>\r\n\r\narr = tf.TensorArray(tf.float32, 1, dynamic_size=True)\r\ndata = accumulate_graph_arg(d, arr)\r\nprint(\"accumulate_graph_arg\\n\", data)\r\n```", "Ah, I see. Thanks for clarifying. You can fix it by explicitly setting the element shape:\r\n```\r\narr = tf.TensorArray(tf.float32, 1, dynamic_size=True, infer_shape=False, element_shape=(2, 2))\r\ndata = accumulate_graph_arg(d, arr)\r\n``` \r\nHowever the fact that the default behavior doesn't cross a tf.function boundary well seems less than ideal. @alextp Is passing a TensorArray with infer_shape=True to a function a supported use case, or does the side effect (modifying the array when it sees data) preclude that. (In which case a more helpful error message at the tf.function boundary would probably help.)", "This appears to be weird for me because it is explicitly written in the doc that the batch dimension can be different between elements: `All of the values must have been written, their ranks must match, and their shapes must all match for all dimensions except the first.`\r\n\r\nIf I'm not mistaken, in the current use case, when the dataset iteration returns not enough elements in the last batch, it will break again.\r\n\r\nAlso, accumulating tensors is very useful sometimes, is there any better way to do that?\r\n", "TensorArray is just a python object as far as tf.function is concerned (i.e. it's not a composite tensor) so I don't understand how the element shape gets dropped.\r\n\r\n@mdanatg could this be related to autograph?", "Nevermind, it's completely unrelated to autograph.\r\n\r\nWhat seems to be happening here is that tf.function treats TensorArray as a python object, but TensorArray has different implementations in graph and eager modes (in graph mode we can use the tensorlist ops and do zero copies, but in eager mode the tensor list ops have to copy, as there are always outstanding references to its inputs; so for eager tensor array we use an implementation backed by a python list) but when we create a tensor array eagerly and pass it into a function we try to use the eager version which can be somewhat confusing.\r\n\r\nI don't know if this is the issue, but if it is then we can work around it by avoiding having tensorarrays cross the eager / function boundary, and have a long term fix by maybe making tensorarrays composite tensors and finding a way to cast from the eager representation to the graph representation when passing them to functions.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30409\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30409\">No</a>\n", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!", "I have opened a new issue, related to the end of the discussion here:\r\n[Issue 34683](https://github.com/tensorflow/tensorflow/issues/34683)"]}, {"number": 30408, "title": "Poor documentation of tf.saved_model.Builder", "body": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/saved_model/Builder\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe documentation is unclear on several points and especially hard to understand for people who are new to tensorflow.\r\n\r\n### Clear description\r\n\r\nWhat is the difference of using saved_model.Builder to other ways of exporting models and graphs? For someone just wanting to use a pre-trained tensorflow model it is very hard to get an overview over all the different types of formats etc. \r\n\r\nFor example what is the difference to tf.io.write_graph? As far as I could find out I need to use the saved_model stuff, because it is able to add tags, which tf.io is not able to do and which is needed for serving. The docs are very unclear on the whole topic of how to use pre trained models in a custom application. (for example in https://github.com/tensorflow/models/blob/master/research/slim/export_inference_graph.py tf.io.write_graph is used)\r\n\r\nThere is also no data types given for the parameters so as someone new to TF I am absolutely unable to guess what should go there. The only description is foo_signatures and foo_assets, but there is no example showing how these parameters are properly used.\r\n\r\nI managed to use saved_model.simple_save, but it is deprecated and from the documentation of the saved_model.Builder, I have no idea how I could replicate the same functionality as with simple_save.\r\n\r\n### Usage example\r\n\r\nThere is example code, but there is no complete example on how to create a frozen graph or on how to export (and import again) a pre-trained model.\r\n\r\n### Submit a pull request?\r\n\r\nI am an absolute beginner to TF so I cannot correct the docs in a meaningful way. sorry\r\n", "comments": ["@twatzl ,\r\nIf your goal is to replicate **tf.saved_model.simple_save**, you can use  **tf.compat.v1.saved_model.simple_save** instead. \r\n\r\nYou can find clear documentation about Saved Model in the [Save And Restore section of TF Website](https://www.tensorflow.org/guide/saved_model#save_and_restore_models).\r\n\r\nPlease let us know if that helps.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 30407, "title": "Error in post-training quantization with TFLiteConverter", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): nightly (1.15.0-dev20190704)\r\n- Python version: 3.5.2\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: GTX 2080Ti\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nRuntimeError when convert frozen graph to TFLite with `converter.optimizations = [tf.lite.Optimize.DEFAULT]` and `converter.representative_dataset = representative_data_gen`\r\n\r\n`RuntimeError: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.No calibrator found for context.Node number 0 (PAD) failed to invoke.`\r\n\r\nI double checked the shape of the input array which is [1, 512, 512, 3] and I can convert it to a float tflite model without any dynamic-sized tensor. I'm not sure where and what raised this error... \r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nMy data generator:\r\n```\r\n    def representative_data_gen():\r\n        for im_info in image_list:\r\n            path = im_info.split(' ')[0]\r\n            img = cv2.imread(path)\r\n            img = letterbox_transform(img)\r\n            img = normalize_image(img)\r\n            img = np.expand_dims(img, 0)\r\n            yield [img.astype('float32')]\r\n```\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@NEU-Gou ,\r\nCode snippet provided seems to be incomplete. In order to expedite the trouble-shooting process, please provide a minimal code snippet so that we can reproduce your error. Thanks! ", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 30406, "title": "how to use tensorflow::tensor in c++", "body": "\r\npython code:\r\n input_tensor = tf.placeholder(dtype=tf.float32, shape=[1, 256, 512, 3], name='input_tensor')\r\n phase_tensor = tf.constant(False, tf.bool)\r\n\r\nc++ code:\r\ntensorflow::Tensor input_tensor(tensorflow::DT_FLOAT, tensorflow::TensorShape({1, 256, 512, 3}));\r\n    tensorflow::Tensor phase(tensorflow::DT_BOOL, tensorflow::TensorShape());\r\n    phase.scalar<bool>()() = false;\r\n\r\nthis convertion is right?\r\nwho can help me?\r\n\r\n\r\n", "comments": ["This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [StackOverflow](http://stackoverflow.com/questions/tagged//tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!\r\n", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 30405, "title": "Resolving Empty Clusters in tf.contrib.factorization.KMeans ", "body": "**System information**\r\n- TensorFlow version : 1.14.0\r\n- Are you willing to contribute it : If my time and my skills permit\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nHi,\r\nI am working on implementing a state-of-the-art deep learning architecture. The architecture requires applying KMeans algorithm on every epoch. However, the current graph generated by the \"__init__\" function in **tf.contrib.factorization.KMeans** doesn't support resolving empty clusters. I.e. it doesn't prevent the formation of empty clusters. \r\n\r\nThe approach I want to implement is to assign a new cluster center for the empty cluster by perturbing a non-empty cluster center and assigning some points in the non_empty cluster to the empty one.\r\n\r\n**Will this change the current API? How?**\r\nYup, by adding a new parameter to the KMeans \"__init__\" function.\r\nThe added parameter corresponds to whether the returned graph should support the prevention of empty clusters formation or no. Something like  a Boolean **prevent_empty_clusters**.\r\n\r\n**Who will benefit with this feature?**\r\nThe feature will give the KMeans API users more options. Those who are interested in a KMeans algorithm that prevents empty clusters are the ones who will benefit. \r\n\r\n**Any Other info.**\r\nNo\r\n", "comments": ["Any new updates related to this Issue", "Contrib is no longer actively maintained, so closing this issue. Consider looking at the tf-addons package for a potential new home for your feature idea."]}, {"number": 30404, "title": "TypeError: Input 'y' of 'Sub' Op has type int64 that does not match type int32 of argument 'x'.", "body": "System Info:\r\nOS:  Mac OS 10.14.5\r\nPython Version: 2.7.13\r\nTensorflow Version: 1.10.0 (CPU)\r\nTensorflow Installation: conda + pip install\r\n\r\n---------------------------------------------------------\r\n\r\nIssue Description:\r\n\r\nI have a slice operation ( tf.slice ) in model graph.  the 'dtype'  of 'begin' and 'size' in tf.slice() is defined 'tf.int64', which looks like:\r\n```python\r\nbegin_tensor = tf.convert_to_tensor([0, 0, 0, 0], dtype=tf.int64)\r\nsize_tensor = tf.convert_to_tensor([-1, -1, 1, -1], dtype=tf.int64)\r\n# shape of A_t is [batch_size, max_sequence_len, hidden_dim, hidden_dim]\r\ntransition_A_t = tf.squeeze(tf.slice(A_t, begin=begin_tensor, size=size_tensor), axis=2)\r\n```\r\nWhen I start to train, it shows the error:\r\n**TypeError: Input 'y' of 'Sub' Op has type int64 that does not match type int32 of argument 'x'.**\r\n From the Traceback, I guess there's something wrong in the backpropagation and gradient computation.\r\n\r\nAnd everything goes on well when  I change the 'dtype'  of 'begin' and 'size' from 'tf.int64' to 'tf.int 32'  which likes:\r\n```python\r\nbegin_tensor = tf.convert_to_tensor([0, 0, 0, 0], dtype=tf.int32)\r\nsize_tensor = tf.convert_to_tensor([-1, -1, 1, -1], dtype=tf.int32)\r\n```\r\nI don't know why there will be a tensor with dtype=tf.int32 in gradient computation. I'm sure the dtype of variables I defined is either tf.float32 or tf.int64.\r\nI'm not sure if this is a bug. But it really confuses me for a long time. Please have look !\r\nThe whole Traceback is as follows:\r\n\r\n> Traceback (most recent call last):\r\n  File \"/Users/xxx/working/xxx_project/classifiers/train_seasonal_content_classifier.py\", line 230, in <module>\r\n    tf.app.run()\r\n  File \"/Users/xxx/anaconda3/envs/tensorflow_1_10_py2/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/Users/xxx/working/xxx_project/classifiers/train_seasonal_content_classifier.py\", line 224, in main\r\n    eval_result, _ = tf.estimator.train_and_evaluate(classifier, train_spec=train_spec, eval_spec=eval_spec)\r\n  File \"/Users/xxx/anaconda3/envs/tensorflow_1_10_py2/lib/python2.7/site-packages/tensorflow/python/estimator/training.py\", line 451, in train_and_evaluate\r\n    return executor.run()\r\n  File \"/Users/xxx/anaconda3/envs/tensorflow_1_10_py2/lib/python2.7/site-packages/tensorflow/python/estimator/training.py\", line 590, in run\r\n    return self.run_local()\r\n  File \"/Users/xxx/anaconda3/envs/tensorflow_1_10_py2/lib/python2.7/site-packages/tensorflow/python/estimator/training.py\", line 691, in run_local\r\n    saving_listeners=saving_listeners)\r\n  File \"/Users/xxx/anaconda3/envs/tensorflow_1_10_py2/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 376, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/Users/xxx/anaconda3/envs/tensorflow_1_10_py2/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1145, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"/Users/xxx/anaconda3/envs/tensorflow_1_10_py2/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1170, in _train_model_default\r\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\r\n  File \"/Users/xxx/anaconda3/envs/tensorflow_1_10_py2/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1133, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"/Users/xxx/working/xxx_project/classifiers/models/universal_transformer_multi_tags_classifier.py\", line 50, in model_fn\r\n    mode=mode)\r\n  File \"/Users/xxx/working/xxx_project/classifiers/losses/multi_tags_loss.py\", line 43, in process_multi_tag_loss_fn\r\n    grads = tf.gradients(total_loss, tvars)\r\n  File \"/Users/xxx/anaconda3/envs/tensorflow_1_10_py2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 596, in gradients\r\n    gate_gradients, aggregation_method, stop_gradients)\r\n  File \"/Users/xxx/anaconda3/envs/tensorflow_1_10_py2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 779, in _GradientsHelper\r\n    lambda: grad_fn(op, *out_grads))\r\n  File \"/Users/xxx/anaconda3/envs/tensorflow_1_10_py2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 398, in _MaybeCompile\r\n    return grad_fn()  # Exit early\r\n  File \"/Users/xxx/anaconda3/envs/tensorflow_1_10_py2/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 779, in <lambda>\r\n    lambda: grad_fn(op, *out_grads))\r\n  File \"/Users/xxx/anaconda3/envs/tensorflow_1_10_py2/lib/python2.7/site-packages/tensorflow/python/ops/array_grad.py\", line 250, in _SliceGrad\r\n    array_ops.shape(input_vec) - slice_size - begin_vec, shape)\r\n  File \"/Users/xxx/anaconda3/envs/tensorflow_1_10_py2/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 850, in binary_op_wrapper\r\n    return func(x, y, name=name)\r\n  File \"/Users/xxx/anaconda3/envs/tensorflow_1_10_py2/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 8188, in sub\r\n    \"Sub\", x=x, y=y, name=name)\r\n  File \"/Users/xxx/anaconda3/envs/tensorflow_1_10_py2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 546, in _apply_op_helper\r\n    inferred_from[input_arg.type_attr]))\r\nTypeError: Input 'y' of 'Sub' Op has type int64 that does not match type int32 of argument 'x'.\r\n", "comments": ["@dockiHan ,\r\nIs there any specific reason that you are using Older Version of TF (1.10). If possible for you, can you please upgrade the TF Version to 1.14 and confirm if the issue still persists.\r\n\r\nIf the issue persists, can you please provide the value of Input Tensor (A_t) so that we can reproduce the error at our end.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "I have the same problem in both 1.10 and 1.14. Problem occurs when I slice a tensor and use the slice in the loss function. Sorry no MWE. ", "> I have the same problem in both 1.10 and 1.14. Problem occurs when I slice a tensor and use the slice in the loss function. Sorry no MWE.\r\n\r\nMake sure to cast the indices you use for slicing to int32.", "@MoustafaMeshry can you please explain what you mean by casting the indices used for slicing to int32? Thanks!", "I meant to cast the \"begin\" and \"size\" arguments to int32 before passing them to tf.slice. However, looking at the [documentation](https://www.tensorflow.org/api_docs/python/tf/slice) of `tf.slice(input, begin, size)`, it seems that it now supports both int32 or int64 dtypes for the \"begin\" / \"size\" arguments."]}, {"number": 30403, "title": "All notebooks kernel changed to python3, to make it consistent with all others.", "body": "", "comments": ["Check out this pull request on ReviewNB: https://app.reviewnb.com/tensorflow/tensorflow/pull/30403 \n\n You'll be able to see visual diffs and write comments on notebook cells. Powered by <a href='https://www.reviewnb.com'>ReviewNB</a>."]}, {"number": 30402, "title": "[Intel MKL] Enabling MKL Conv2D BWD in eager mode", "body": "This PR depends on #30401. So please review and merge #30401 first.", "comments": ["@mahmoud-abuzaina Did you get a chance to look on reviewer comments? Please let us know on the update. Thanks! ", "@gbaned: I am sorry for the late response. After handling the related PR \"eagle mode Conv fwd\",\r\nI can deal with the \"bwd\" one. I may not answer all questions/comments since I am covering\r\nthe original developer. But I will try my best.", "@alextp Got it. Then I can handle MKL-related, incremental eager PRs alone and will request reviews from eager owners when there are major changes.", "@penpornk  Hi Penporn, please help to get this one merged into 2.0. Thanks!   -GZ", "@gzmkl I'm working on getting it merged into the master branch. :) After that, I'll see if we can cherrypick this into 2.0. Same for https://github.com/tensorflow/tensorflow/pull/31311."]}, {"number": 30401, "title": "[Intel MKL] Enabling MKL Conv2D FWD in eager mode", "body": "", "comments": ["@mahmoud-abuzaina Can you please resolve conflicts? Thanks!", "Mahoud is on long vacation and I am covering him for this PR.\r\n\r\nMerge conflicts have been addressed.  Thanks!    -GZ", "@gzmkl  Still, conflicts are appearing. Can you please resolve? Thanks!", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F30401) for more info**.\n\n<!-- need_author_cla -->", "@gbaned It seems that I resolved but not committed. Now conflicts should be gone. Thank you!", "@penpornk  Thanks for your review comments. I will address them today.   -- GZ", "I've manually verified that both users contributing to this PR have signed the CLA with their associated emails (not sure why the bot is complaining). Setting CLA to yes.", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F30401) for more info**.\n\n<!-- cla_yes -->", "@alextp: some benchmark result\r\n\r\nCombined with PR #30401 (conv fwd) and #30402 (conv bwd), for resnet50 training performance\r\nis improved from 0.7 images/second to 7 images/second. \r\n", "@[eager code owner]: please let me know if you need more changes or more info. Thanks.  GZ", "@penpornk @alextp @mahmoud-abuzaina  \r\nPlease approve this PR if you are fine. We have two more related PRs (eager mode conv bwd; \r\neager mode matmul) which need to be included in 2.0 release.\r\nThanks!", "@gzmkl Please resolve conflicts.", "Yes, I am addressing the conflict issue. Problem is resulted from a previous PR (MKL DNN 1.0) integration and I need some time due to API changes. Hopefully I will get it resolved today.", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F30401) for more info**.\n\n<!-- need_author_cla -->", "Conflicts within mkl_conv_ops.cc have been resolved.", "@gzmkl, @mahmoud-abuzaina  Could you please sign cla ? Thank you.", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F30401) for more info**.\n\n<!-- cla_yes -->", "@penpornk  Thank you for the approval. It took quite a while to address the merge conflicts.  ", "There are three test failures. `Windows Bazel` and `Windows Bazel GPU` are already-failing tests. \r\n\r\n`Linux GPU` has a [memory corruption in CAPI.Executor_MatMul_CPUAsync](https://source.cloud.google.com/results/invocations/f927c5de-725e-4d13-9e5b-f9a410205c1a/targets/%2F%2Ftensorflow%2Fc%2Feager:c_api_experimental_test_gpu/log) in //tensorflow/c/eager:c_api_experimental_test_gpu.\r\n\r\n@alextp @jaingaurav, do you know if this failure is related to the PR?\r\n\r\n@gzmkl I'll be unavailable for a few hours so please coordinate with others on this PR in the meanwhile.", "@penpornk  No, this PR only touches Conv2D forward and is not related to \"MatMul\" or \"gpu\"."]}, {"number": 30400, "title": "Removed the deprecated API from contrib module", "body": "", "comments": ["@amitsrivastava78 Could you please address the build failures? Thanks!", "@gbaned , i have solved the build errors.\r\n@alextp , Sorry for the trouble there were some indentation related issues which i have fixed, can you please re-approve the PR.\r\n\r\nRegards\r\nAmit", "@alextp  the rework is complete ,can you please approve the PR.\r\n\r\nRegards\r\nAmit", "@gbaned , can you pls help to get this PR merged.\r\n\r\nRegards\r\nAmit", "@alextp , there were some TC failures which i have fixed, can you please re-approve the PR.\r\n\r\nRegards\r\nAmit", "@amitsrivastava78 sorry for the delay , there were some test failures , can you please check the build failures and update your branch, thank you.", "Can one of the admins verify this patch?", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 30399, "title": "[Lite] Accuracy tool compilation issue fix", "body": "Compilation bug fix change.", "comments": []}, {"number": 30398, "title": "[LITE]File handle leak fix", "body": "", "comments": ["Can one of the admins verify this patch?"]}, {"number": 30397, "title": "ValueError: Cannot feed value of shape (60000,) for Tensor 'Placeholder_1:0', which has shape '(?, 10)'", "body": "```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n\r\nmnist = tf.keras.datasets.mnist\r\n\r\n(x_train, y_train), (x_test, y_test) = mnist.load_data(r'C:\\Users\\Ati\\Downloads\\mnist.npz')\r\n\r\n\r\nReshaping the array to 2-dims so that it can work with the Keras API\r\nx_train = x_train.reshape(x_train.shape[0], 784)\r\nx_test = x_test.reshape(x_test.shape[0], 784)\r\n#input_shape = (28, 28, 1)\r\n\r\n Making sure that the values are float so that we can get decimal points after division\r\nx_train = x_train.astype('float32')\r\nx_test = x_test.astype('float32')\r\n\r\nNormalizing the RGB codes by dividing it to the max RGB value.\r\nx_train /= 255\r\nx_test /= 255\r\n#y_train = tf.one_hot(y_train, 1)\r\n\r\n#b=len(y_train)\r\n#print('number of rows in y_train=',b) # it's 1*60000\r\n\r\nprint('y_train shape:', y_train.shape)\r\nprint('x_train shape:', x_train.shape)\r\nz=len(x_train)\r\nprint('number of rows in x_train=',z) # it's 1*60000\r\nclass NeuralNetwork:\r\n    def add_layer(inputs,in_size,out_size,activation_function=None):\r\n        Weights= tf.Variable(tf.random_normal([in_size,out_size]))\r\n        biases= tf.Variable(tf.zeros([out_size])+0.1)\r\n        Wx_plus_b = tf.matmul(inputs,Weights)+biases\r\n        if activation_function is None:\r\n            outputs = Wx_plus_b\r\n        else:\r\n            outputs = activation_function(Wx_plus_b)\r\n        return outputs\r\n\r\n#y_train = y_train.reshape((60000, 1))\r\nxs = tf.placeholder(tf.float32,[None, 784]) #same with x_train=60000*784\r\nys = tf.placeholder(tf.float32,[None,10 ])\r\n\r\nl1=NeuralNetwork.add_layer(xs ,784,10,activation_function=None)\r\n\r\nprediction= NeuralNetwork.add_layer(l1,10,1,activation_function=None)\r\n\r\nloss=tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),\r\n                  reduction_indices=[1]))\r\ntrain_step=tf.train.GradientDescentOptimizer(0.1).minimize(loss)\r\n\r\ninit=tf.global_variables_initializer()\r\n\r\nsess=tf.Session()\r\nsess.run(init)\r\n\r\nfor i in range(1000):\r\n    sess.run(train_step, feed_dict={xs:x_train, ys:y_train})\r\n    sess.run(train_step, feed_dict={xs:x_test, ys:y_test})\r\n    if i % 50==0: #print loss every 50 step\r\n        print(\"loss after training =\",sess.run(loss,feed_dict={xs:x_train,ys:y_train}))\r\n\r\n", "comments": ["@ati6868 Please provide your TensorFlow version? Thanks!\r\n \r\n", "Version 1.13.1\n\nOn Fri, Jul 5, 2019 at 10:16 AM gadagashwini <notifications@github.com>\nwrote:\n\n> @ati6868 <https://github.com/ati6868> Please provide your TensorFlow\n> version? Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/30397?email_source=notifications&email_token=AMQW3F664K3NI7GHGEOBDA3P53N4TA5CNFSM4H5TQJFKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODZISXEQ#issuecomment-508636050>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AMQW3F6QTHVY3YSSPY4UZXTP53N4TANCNFSM4H5TQJFA>\n> .\n>\n", "I was able to reproduce the reported issue on Colab with Tensorflow version 1.13.1.", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow-tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n", "hi.\r\nYou are facing this problem because your output dimension of placeholder(60000, 10) do not matches the actual output(60000, 1) dimension .\r\nRather you can try changing your actual output values to categorical by the following code, just after loading the data and make sure to import to_categorical from keras.utils.\r\n\r\ny_train = to_categorical(y_train)\r\ny_test = to_categorical(y_test)\r\n\r\nProblem solved"]}, {"number": 30396, "title": "Tensorflow 1.12 - ERROR: missing input file '@kissfft//:LICENSE'", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04.2 LTS\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.12\r\n- Python version: 3.6.8\r\n- Installed using virtualenv? pip? conda?: virtualenv\r\n- Bazel version (if compiling from source) :0.26.1\r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0\r\n- CUDA/cuDNN version: disabled\r\n- GPU model and memory: no GPU, 16GB of RAM\r\n\r\n**Describe the problem**\r\nFails to build.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\nexport PYTHON_BIN_PATH=\"$VIRTUAL_ENV\"'/bin/python'\r\nexport PYTHON_LIB_PATH=\"$VIRTUAL_ENV\"\r\nexport TF_DOWNLOAD_MKL='1'\r\nexport TF_NEED_MKL='1'\r\nexport CC_OPT_FLAGS='-march=native'\r\nexport TF_NEED_JEMALLOC='1'\r\nexport TF_NEED_GCP='0'\r\nexport TF_NEED_HDFS='0'\r\nexport TF_ENABLE_XLA='0'  # JIT\r\nexport TF_NEED_VERBS='0'\r\nexport TF_NEED_OPENCL='0'\r\nexport TF_NEED_OPENCL_SYCL='0'\r\nexport TF_NEED_COMPUTECPP='0'\r\nexport TF_NEED_CUDA='0'\r\nexport TF_NEED_MPI='0'\r\nexport TF_NEED_S3='0'\r\nexport TF_NEED_GDR='0'\r\nexport TF_SET_ANDROID_WORKSPACE='0'\r\nexport TF_NEED_KAFKA='0'\r\nexport TF_CUDA_CLANG='0'\r\nexport TF_DOWNLOAD_CLANG='0'\r\nexport TF_NEED_ROCM='0'\r\n./configure\r\nbazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\nbazel-bin/tensorflow/tools/pip_package/build_pip_package \"$HOME\"'/repos/tensorflow_pkg'\r\n```\r\n\r\n**Any other info / logs**\r\nLast bit of the build log:\r\n```\r\n[6,438 / 6,444] Compiling .../core/ops/summary_ops.cc [for host]; 2s local\r\n\r\n[6,450 / 6,454] 2 actions, 1 running\r\n    Compiling tensorflow/core/ops/summary_ops.cc [for host]; 2s local\r\n    [Prepa] ProtoCompile .../core/example/example_parser_configuration_pb2.py\r\n\r\n\r\n\r\nERROR: missing input file '@kissfft//:LICENSE'\r\n[6,452 / 6,456] Compiling .../core/ops/summary_ops.cc [for host]; 2s local\r\n\r\nERROR: /home/ubuntu/repos/tensorflow-for-py3/tensorflow/tools/pip_package/BUILD:263:1: //tensorflow/tools/pip_package:build_pip_package: missing input file '@kissfft//:LICENSE'\r\n[6,453 / 6,456] checking cached actions\r\n\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n[6,453 / 6,456] checking cached actions\r\n\r\nUse --verbose_failures to see the command lines of failed build steps.\r\n[6,453 / 6,456] checking cached actions\r\n\r\nERROR: /home/ubuntu/repos/tensorflow-for-py3/tensorflow/tools/pip_package/BUILD:263:1 1 input file(s) do not exist\r\n[6,453 / 6,456] checking cached actions\r\n\r\nINFO: Elapsed time: 1405.912s, Critical Path: 107.29s\r\n[6,453 / 6,456] checking cached actions\r\n\r\nINFO: 529 processes: 529 local.\r\n[6,453 / 6,456] checking cached actions\r\n\r\nFAILED: Build did NOT complete successfully\r\n\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nEDIT: Wait, this might be the solution https://github.com/tensorflow/tensorflow/issues/28129", "comments": ["Ran `bazel clean` and let it run again, ensuring I had `--nightly_flag` set, and it succeeded:\r\n```\r\n[14,489 / 14,493] 2 actions, 1 running\r\n    Compiling .../contrib/boosted_trees/kernels/split_handler_ops.cc; 6s local\r\n    [Prepa] Creating source manifest for //.../debug:grpc_tensorflow_server\r\n\r\n\r\n\r\n[14,491 / 14,493] .../boosted_trees:python/ops/_boosted_trees_ops.so; 6s local\r\n\r\n[14,491 / 14,493] .../boosted_trees:python/ops/_boosted_trees_ops.so; 7s local\r\n\r\n[14,491 / 14,493] .../boosted_trees:python/ops/_boosted_trees_ops.so; 8s local\r\n\r\n[14,491 / 14,493] .../boosted_trees:python/ops/_boosted_trees_ops.so; 9s local\r\n\r\n[14,491 / 14,493] .../ops/_boosted_trees_ops.so; 10s local\r\n\r\n[14,491 / 14,493] .../ops/_boosted_trees_ops.so; 11s local\r\n\r\n[14,491 / 14,493] .../ops/_boosted_trees_ops.so; 12s local\r\n\r\n[14,491 / 14,493] .../ops/_boosted_trees_ops.so; 13s local\r\n\r\n[14,491 / 14,493] .../ops/_boosted_trees_ops.so; 14s local\r\n\r\n[14,491 / 14,493] .../ops/_boosted_trees_ops.so; 15s local\r\n\r\n[14,491 / 14,493] .../ops/_boosted_trees_ops.so; 16s local\r\n\r\n[14,491 / 14,493] .../ops/_boosted_trees_ops.so; 17s local\r\n\r\n[14,491 / 14,493] .../ops/_boosted_trees_ops.so; 18s local\r\n\r\n[14,491 / 14,493] .../ops/_boosted_trees_ops.so; 19s local\r\n\r\n[14,492 / 14,493] [Prepa] .../boosted_trees:python/ops/_boosted_trees_ops.so\r\n\r\nTarget //tensorflow/tools/pip_package:build_pip_package up-to-date:\r\n[14,493 / 14,493] checking cached actions\r\n\r\n  bazel-bin/tensorflow/tools/pip_package/build_pip_package\r\n[14,493 / 14,493] checking cached actions\r\n\r\nINFO: Elapsed time: 29325.993s, Critical Path: 220.01s\r\n[14,493 / 14,493] checking cached actions\r\n\r\nINFO: 9047 processes: 9047 local.\r\n[14,493 / 14,493] checking cached actions\r\n\r\nINFO: Build completed successfully, 9764 total actions\r\n\r\nINFO: Build completed successfully, 9764 total actions\r\n\r\n[13.75.212.14] run: bazel-bin/tensorflow/tools/pip_package/build_pip_package /home/ubuntu/repos/tensorflow_pkg\r\nThu Jul 4 18:48:48 UTC 2019 : === Preparing sources in dir: /tmp/tmp.qlPBZKWFGC\r\n~/repos/tensorflow-for-py3 ~/repos/tensorflow-for-py3\r\n~/repos/tensorflow-for-py3\r\n/tmp/tmp.qlPBZKWFGC/tensorflow/include ~/repos/tensorflow-for-py3\r\n~/repos/tensorflow-for-py3\r\nThu Jul 4 18:49:03 UTC 2019 : === Building wheel\r\nwarning: no files found matching '*.pyd' under directory '*'\r\nwarning: no files found matching '*.pd' under directory '*'\r\nwarning: no files found matching '*.dylib' under directory '*'\r\nwarning: no files found matching '*.dll' under directory '*'\r\nwarning: no files found matching '*.lib' under directory '*'\r\nwarning: no files found matching '*.h' under directory 'tensorflow_core/include/tensorflow'\r\nwarning: no files found matching '*' under directory 'tensorflow_core/include/third_party'\r\nThu Jul 4 18:49:28 UTC 2019 : === Output wheel file is in: /home/ubuntu/repos/tensorflow_pkg\r\n```\r\n\r\n\ud83c\udf89"]}]