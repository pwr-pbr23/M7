[{"number": 10163, "title": "Custom Poets Models Run Slow on Android", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Not really.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Android/Windows\r\n- **TensorFlow installed from (source or binary)**: Binary (From android nightly\r\n- **TensorFlow version (use command below)**: 1.2\r\n\r\n### Describe the problem\r\nI've noticed that using a retrained inception model within the demo app, following the guidelines suggested, is awfully slow. Shouldn't the custom models generated in the style of Tensorflow for poets be pretty similar to the inception model that the demo comes with? I have noticed inference times to be around 5 times as slow on two devices. (Nexus 6P and Pixel C) compared to the original demo.\r\nEven when the graphs are quantized I am getting no apparent performance increase (apart from model size). If anything it's actually slower.\r\nIs this normal behaviour? I'm aware of the image size is different (224 vs 299) but is that enough to haemorrhage the performance?\r\n\r\n### Source code / logs\r\nAvg. ms for Conv2D is 1366ms \r\nInference time ~1700ms (Pixel C) ~3500 (Nexus 6P)\r\n\r\nModel building steps: Normal Model via Tensorflow for poets etc. --> strip nodes --> quantize --> replace in apk.\r\nSame performance regardless of quantization.\r\n\r\n@andrewharp this was what I referred to in the windows/android thread. Can move to s/o if preferred.", "comments": ["I just tested using the TF AAR (1.2.0-rc0) with a stripped inception V3, and got ~1300ms performance (1000ms with an optimized graph) on my Pixel. Also tried the latest armeabi-v7a libs (as the AAR will use arm64 on the Pixel) downloaded from nightly with similar results. Conv2D takes about 900ms.\r\n\r\nYour times do seem a bit slow, but as this doesn't seem like a TF issue StackOverflow is probably a better venue.", "Hmmm ok. I might open a s/o question at some point then. Cheers."]}, {"number": 10162, "title": "ResourceExhaustedError", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Custom adaptation of tensorflow doc example\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS 10.11.3 El Capitan\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.1.0-rc0-61-g1ec6ed5 1.1.0 / python 3.5.2\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: No CUDA-compliant GPU on Mac Book Pro\r\n- **Exact command to reproduce**:  see full code below\r\n\r\n### Describe the problem\r\n\r\nThe gist below fails reproducibly with the following error both from a jupyter notebook or the command line : \r\n```\r\nResourceExhaustedError (see above for traceback): ./models/m9-6/model.ckpt-826.data-00000-of-00001\r\n\t [[Node: save/RestoreV2_6 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_6/tensor_names, save/RestoreV2_6/shape_and_slices)]]\r\n```\r\nI added some explict `del` and explicit garbage collection but that doesn't seem to change anything. I'm not sure if this is an OOM per se or if it is a different kind of resource exhaustion. In any case I wasn't expecting fitting a fresh model `m` repeatedly in a loop to be an issue so I'm reporting this in case it happens to be a TF issue.\r\n\r\n### Source code / logs\r\n\r\nhttps://gist.github.com/lelayf/f81b078a197b30490d6d52ba3f02f0a4\r\n", "comments": ["This is really more of a [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) question so please follow up with further questions there. I think the issue is that you are adding operations to the graph within your loop, so it's getting bigger and bigger and eventually running out of resources. You should probably create a new session for each experiment in order to properly garbage-collect the state in between experiments."]}, {"number": 10161, "title": "DOC modify install_mac and install_linux", "body": "Originally in [install_mac](https://www.tensorflow.org/install/install_mac) it says \r\n\r\n> installing from sources, which is for experts and is documented in a separate guide.\r\n\r\nBut it didn't say what that separate guide is. I think that is wield, so I added a link to that.\r\nAlso, [install_linux](https://www.tensorflow.org/install/install_linux) didn't mention install from source option, so I added one to that too\r\n\r\n", "comments": ["Can one of the admins verify this patch?", "Jenkins test this please."]}, {"number": 10160, "title": "Fixing broken links in Linear Model Tutorial.", "body": "The Links in the Linear Model Tutorial are broken. This commit / pull request fixes the URLs. ", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "Signed the contributor license agreement. ", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->", "CLAs look good, thanks!\n\n<!-- ok -->", "Jenkins test this please."]}, {"number": 10159, "title": "Update README.md", "body": "there was an _ instead of a .\r\nI tried the code example out and the module doesn't have saved_model_builder but does have saved_model.builder", "comments": ["Can one of the admins verify this patch?", "Jenkins test this please.", "Jenkins test this please."]}, {"number": 10158, "title": "Fix Cuda configuration on Windows", "body": "When creating a genrule for a set of files, we should use copy instead of\r\nsymlink on Windows.\r\n\r\nThis addresses an error reported at stackoverflow:\r\nhttps://stackoverflow.com/questions/44038367/genrules-without-outputs-dont-make-sense-bazel-windows-10-build\r\n\r\nApplied the same approach to python_config.bzl to simplify the code.", "comments": ["Jenkins test this please."]}, {"number": 10157, "title": "bazel build failure of tensorflow with mkl and specific eigen3 flags", "body": "### System information\r\n\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nDon't have code yet\r\n\r\n- **OS Platform and Distribution\r\nLinux Ubuntu 16.04\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\ngit clone latest revision (TensorFlow 1.1)\r\n- **TensorFlow version (use command below)**:\r\n\r\n- **Bazel version (if compiling from source)**:\r\nBuild label: 0.4.5\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Thu Mar 16 12:19:38 2017 (1489666778)\r\nBuild timestamp: 1489666778\r\nBuild timestamp as int: 1489666778\r\n\r\n- **CUDA/cuDNN version**:\r\nNone\r\n- **GPU model and memory**:\r\nNone\r\n\r\n- **Exact command to reproduce**:\r\nI don't understand what the above sentence refers to?\r\n\r\n### Describe the problem\r\n\r\nBazel failed to build/compile tensor flow with mkl support\r\nI added these compiler flags during the configure phase and they caused the compilation error:\r\n\r\n -DEIGEN_USE_MKL_ALL -DMKL_ILP64 \r\n\r\n### Source code / logs\r\n\r\nConfigure phase:\r\n\r\n```\r\n\r\ndrormeirovich@drormeirovich-xps-13-9360:~/projects/tensorflow$ sudo ./configure \r\nPlease specify the location of python. [Default is /usr/bin/python]: \r\nFound possible Python library paths:\r\n  /usr/local/lib/python2.7/dist-packages\r\n  /usr/lib/python2.7/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]\r\n\r\nUsing python library path: /usr/local/lib/python2.7/dist-packages\r\nDo you wish to build TensorFlow with MKL support? [y/N] y\r\nMKL support will be enabled for TensorFlow\r\nDo you wish to download MKL LIB from the web? [Y/n] n\r\nPlease specify the location where MKL is installed. [Default is /opt/intel/mklml]: /opt/intel/mkl\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: -O3 -DNDEBUG -fPIC -DEIGEN_USE_MKL_ALL -DMKL_ILP64 -fopenmp -m64 -v -I/opt/intel/mkl/include\r\nDo you wish to use jemalloc as the malloc implementation? [Y/n] \r\njemalloc enabled\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] \r\nNo Google Cloud Platform support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with Hadoop File System support? [y/N] \r\nNo Hadoop File System support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] \r\nNo XLA support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with VERBS support? [y/N] \r\nNo VERBS support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with OpenCL support? [y/N] \r\nNo OpenCL support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with CUDA support? [y/N] \r\nNo CUDA support will be enabled for TensorFlow\r\nINFO: Starting clean (this may take a while). Consider using --async if the clean takes more than several minutes.\r\nConfiguration finished\r\n\r\n```\r\nBuild command...\r\n\r\n`sudo bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n`\r\nError output:\r\n\r\n```\r\nERROR: /home/drormeirovich/projects/tensorflow/tensorflow/core/kernels/BUILD:998:1: C++ compilation of rule '//tensorflow/core/kernels:gather_functor' failed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG ... (remaining 64 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\nUsing built-in specs.\r\nCOLLECT_GCC=/usr/bin/gcc\r\nTarget: x86_64-linux-gnu\r\nConfigured with: ../src/configure -v --with-pkgversion='Ubuntu 6.2.0-3ubuntu11~16.04' --with-bugurl=file:///usr/share/doc/gcc-6/README.Bugs --enable-languages=c,ada,c++,java,go,d,fortran,objc,obj-c++ --prefix=/usr --program-suffix=-6 --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --with-sysroot=/ --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-vtable-verify --enable-libmpx --enable-plugin --with-system-zlib --disable-browser-plugin --enable-java-awt=gtk --enable-gtk-cairo --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-6-amd64/jre --enable-java-home --with-jvm-root-dir=/usr/lib/jvm/java-1.5.0-gcj-6-amd64 --with-jvm-jar-dir=/usr/lib/jvm-exports/java-1.5.0-gcj-6-amd64 --with-arch-directory=amd64 --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --enable-objc-gc --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu\r\nThread model: posix\r\ngcc version 6.2.0 20160901 (Ubuntu 6.2.0-3ubuntu11~16.04) \r\nCOLLECT_GCC_OPTIONS='-U' '_FORTIFY_SOURCE' '-fstack-protector' '-Wall' '-B' '/usr/bin' '-B' '/usr/bin' '-Wunused-but-set-parameter' '-Wno-free-nonheap-object' '-fno-omit-frame-pointer' '-g0' '-O2' '-D' '_FORTIFY_SOURCE=1' '-D' 'NDEBUG' '-ffunction-sections' '-fdata-sections' '-O3' '-D' 'NDEBUG' '-D' 'EIGEN_USE_MKL_ALL' '-D' 'MKL_ILP64' '-v' '-I' '/opt/intel/mkl/include' '-std=c++11' '-O3' '-D' 'NDEBUG' '-D' 'EIGEN_USE_MKL_ALL' '-D' 'MKL_ILP64' '-fopenmp' '-m64' '-v' '-I' '/opt/intel/mkl/include' '-MD' '-MF' 'bazel-out/local-opt/bin/tensorflow/core/kernels/_objs/gather_functor/tensorflow/core/kernels/gather_functor.pic.d' '-frandom-seed=bazel-out/local-opt/bin/tensorflow/core/kernels/_objs/gather_functor/tensorflow/core/kernels/gather_functor.pic.o' '-fPIC' '-D' 'EIGEN_MPL2_ONLY' '-iquote' '.' '-iquote' 'bazel-out/local-opt/genfiles' '-iquote' 'external/bazel_tools' '-iquote' 'bazel-out/local-opt/genfiles/external/bazel_tools' '-iquote' 'external/eigen_archive' '-iquote' 'bazel-out/local-opt/genfiles/external/eigen_archive' '-iquote' 'external/local_config_sycl' '-iquote' 'bazel-out/local-opt/genfiles/external/local_config_sycl' '-isystem' 'external/bazel_tools/tools/cpp/gcc3' '-isystem' 'external/eigen_archive' '-isystem' 'bazel-out/local-opt/genfiles/external/eigen_archive' '-D' 'EIGEN_AVOID_STL_ARRAY' '-I' 'external/gemmlowp' '-Wno-sign-compare' '-fno-exceptions' '-msse3' '-pthread' '-fno-canonical-system-headers' '-Wno-builtin-macro-redefined' '-D' '__DATE__=\"redacted\"' '-D' '__TIMESTAMP__=\"redacted\"' '-D' '__TIME__=\"redacted\"' '-c' '-o' 'bazel-out/local-opt/bin/tensorflow/core/kernels/_objs/gather_functor/tensorflow/core/kernels/gather_functor.pic.o' '-mtune=generic' '-march=x86-64' '-pthread'\r\n /usr/lib/gcc/x86_64-linux-gnu/6/cc1plus -quiet -v -v -I /opt/intel/mkl/include -I /opt/intel/mkl/include -I external/gemmlowp -imultiarch x86_64-linux-gnu -MD bazel-out/local-opt/bin/tensorflow/core/kernels/_objs/gather_functor/tensorflow/core/kernels/gather_functor.pic.d -MF bazel-out/local-opt/bin/tensorflow/core/kernels/_objs/gather_functor/tensorflow/core/kernels/gather_functor.pic.d -MQ bazel-out/local-opt/bin/tensorflow/core/kernels/_objs/gather_functor/tensorflow/core/kernels/gather_functor.pic.o -D_GNU_SOURCE -D_REENTRANT -U _FORTIFY_SOURCE -D _FORTIFY_SOURCE=1 -D NDEBUG -D NDEBUG -D EIGEN_USE_MKL_ALL -D MKL_ILP64 -D NDEBUG -D EIGEN_USE_MKL_ALL -D MKL_ILP64 -D EIGEN_MPL2_ONLY -D EIGEN_AVOID_STL_ARRAY -D __DATE__=\"redacted\" -D __TIMESTAMP__=\"redacted\" -D __TIME__=\"redacted\" -iquote . -iquote bazel-out/local-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/local-opt/genfiles/external/bazel_tools -iquote external/eigen_archive -iquote bazel-out/local-opt/genfiles/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/local-opt/genfiles/external/local_config_sycl -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/eigen_archive -isystem bazel-out/local-opt/genfiles/external/eigen_archive tensorflow/core/kernels/gather_functor.cc -quiet -dumpbase gather_functor.cc -m64 -msse3 -mtune=generic -march=x86-64 -auxbase-strip bazel-out/local-opt/bin/tensorflow/core/kernels/_objs/gather_functor/tensorflow/core/kernels/gather_functor.pic.o -g0 -O2 -O3 -O3 -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -Wno-sign-compare -Wno-builtin-macro-redefined -std=c++11 -version -fstack-protector -fno-omit-frame-pointer -ffunction-sections -fdata-sections -fopenmp -frandom-seed=bazel-out/local-opt/bin/tensorflow/core/kernels/_objs/gather_functor/tensorflow/core/kernels/gather_functor.pic.o -fPIC -fno-exceptions -fno-canonical-system-headers -Wformat-security -o /tmp/ccloY0qb.s\r\nGNU C++11 (Ubuntu 6.2.0-3ubuntu11~16.04) version 6.2.0 20160901 (x86_64-linux-gnu)\r\n\tcompiled by GNU C version 6.2.0 20160901, GMP version 6.1.0, MPFR version 3.1.4, MPC version 1.0.3, isl version 0.15\r\nGGC heuristics: --param ggc-min-expand=100 --param ggc-min-heapsize=131072\r\nignoring nonexistent directory \"external/bazel_tools/tools/cpp/gcc3\"\r\nignoring nonexistent directory \"bazel-out/local-opt/genfiles/external/eigen_archive\"\r\nignoring duplicate directory \"/usr/include/x86_64-linux-gnu/c++/6\"\r\nignoring nonexistent directory \"/usr/local/include/x86_64-linux-gnu\"\r\nignoring nonexistent directory \"/usr/lib/gcc/x86_64-linux-gnu/6/../../../../x86_64-linux-gnu/include\"\r\nignoring duplicate directory \"/opt/intel/mkl/include\"\r\nignoring nonexistent directory \"bazel-out/local-opt/genfiles/external/bazel_tools\"\r\nignoring duplicate directory \"external/eigen_archive\"\r\n  as it is a non-system directory that duplicates a system directory\r\nignoring nonexistent directory \"bazel-out/local-opt/genfiles/external/eigen_archive\"\r\nignoring nonexistent directory \"bazel-out/local-opt/genfiles/external/local_config_sycl\"\r\n#include \"...\" search starts here:\r\n .\r\n bazel-out/local-opt/genfiles\r\n external/bazel_tools\r\n external/local_config_sycl\r\n#include <...> search starts here:\r\n /opt/intel/mkl/include\r\n external/gemmlowp\r\n external/eigen_archive\r\n /usr/include/c++/6\r\n /usr/include/x86_64-linux-gnu/c++/6\r\n /usr/include/c++/6/backward\r\n /usr/lib/gcc/x86_64-linux-gnu/6/include\r\n /usr/local/include\r\n /usr/lib/gcc/x86_64-linux-gnu/6/include-fixed\r\n /usr/include/x86_64-linux-gnu\r\n /usr/include\r\nEnd of search list.\r\nGNU C++11 (Ubuntu 6.2.0-3ubuntu11~16.04) version 6.2.0 20160901 (x86_64-linux-gnu)\r\n\tcompiled by GNU C version 6.2.0 20160901, GMP version 6.1.0, MPFR version 3.1.4, MPC version 1.0.3, isl version 0.15\r\nGGC heuristics: --param ggc-min-expand=100 --param ggc-min-heapsize=131072\r\nCompiler executable checksum: 23988a38771f71e4676d56931fe884f7\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:522:0,\r\n                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14,\r\n                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from ./tensorflow/core/kernels/gather_functor.h:19,\r\n                 from tensorflow/core/kernels/gather_functor.cc:52:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/products/GeneralMatrixMatrix_BLAS.h: In static member function 'static void Eigen::internal::general_matrix_matrix_product<Index, double, LhsStorageOrder, ConjugateLhs, double, RhsStorageOrder, ConjugateRhs, 0>::run(Index, Index, Index, const double*, Index, const double*, Index, double*, Index, double, Eigen::internal::level3_blocking<double, double>&, Eigen::internal::GemmParallelInfo<Index>*)':\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/products/GeneralMatrixMatrix_BLAS.h:106:1: error: cannot convert 'Eigen::BlasIndex* {aka long long int*}' to 'const int*' for argument '3' to 'int dgemm_(const char*, const char*, const int*, const int*, const int*, const double*, const double*, const int*, const double*, const int*, const double*, double*, const int*)'\r\n GEMM_SPECIALIZATION(double,   d,  double, d)\r\n ^\r\n\r\n```", "comments": ["See also https://github.com/PointCloudLibrary/pcl/issues/1266\r\n\r\nIs the `-DEIGEN_USE_MKL_ALL` flag necessary? That's probably turning code on that wouldn't otherwise be enabled.\r\n\r\nDid you modify the workspace.bzl file to upgrade Eigen?", "Hi,\r\nThe link you mentioned is about a compilation problem in Eigen, but it seems to be related to other type of conflict which I don't have. Moreover, it is written there that problem is solved with a newer version of Eigen while in my case I'm using the latest version (even newer than in that link)\r\n\r\nI removed the MKL flag and now the compilation finished, however I wish to work with MKL support and I don't know how to confirm that the Eigen's code generation and compilation of tensorflow integrated successfully with my current project (which already uses MKL and 64bit integers as indexes).\r\n\r\nI guess currently I don't have a better way to make sure it's OK besides using breakpoints inside Eigen source code and see if it calls the correct functions in MKL.\r\n\r\nRegarding the bazel workspace, I didn't modify any file. Do I need to?\r\n\r\n10x!", "@jart Could you take a look please? Thanks.", "@drormeir I fixed this problem editing the file  Eigen/src/Core/util/MKL_support.h\r\n\r\nI added the following code at line 116:\r\n\r\n```\r\n+#ifdef EIGEN_BLAS_INDEX\r\n+typedef EIGEN_BLAS_INDEX BlasIndex;\r\n+#elif defined(EIGEN_USE_MKL)\r\n typedef MKL_INT BlasIndex;\r\n #else\r\n typedef int BlasIndex;\r\n #endif\r\n```\r\n\r\nand in my CMakeLists I did:\r\n\r\n```\r\nif (USE_MKL)\r\n    find_package(MKL REQUIRED)\r\n    include_directories(${MKL_INCLUDE_DIRS})\r\n    set(EXTRA_LIBRARIES ${EXTRA_LIBRARIES} ${MKL_LIBRARIES})\r\n    add_definitions(-DENABLE_MKL)\r\n    add_definitions(-DMKL_LP64)\r\n    add_definitions(-DEIGEN_BLAS_INDEX=int)\r\nendif (USE_MKL)\r\n```\r\n\r\nThis problem is a conflict between MKL_INT and BLAS index type.  In my case, the BLAS is using int as index and MKL_INT is a long long. I did this workaround and everything is working fine.\r\n\r\nAlso, I did a pull request to eigen repository. I`m waiting to be accepted.\r\n\r\nhttps://bitbucket.org/eigen/eigen/pull-requests/320/add-macro-to-define-blas-index-type/diff#comment-39775997", "Thanks!", "It is not a bug in TensorFlow; it's a problem with Eigen.\r\n\r\nWhen used in the MKL mode, Eigen's code defines `BlasIndex` to be whatever `MKL_INT` is:\r\n\r\n```\r\ntypedef MKL_INT BlasIndex;\r\n```\r\n\r\nIt is utterly confusing because the definition of `MKL_INT` varies depending on the size of indices you want to use in your program. However, instead of using the MKL's BLAS interface, which takes the size of `MKL_INT` into account, Eigen defines its own interface (https://bitbucket.org/eigen/eigen/src/e7027de735d6450c8ede3ce2f65166714c6aef50/Eigen/src/misc/blas.h?at=default&fileviewer=file-view-default) using only 32-bit long ints. This is the reason for the compilation errors you see.\r\n\r\n@gogo40 Your patch is unnecessary if you use short indices (`-DMKL_LP64`) and makes a significant chunk of the Eigen's unit tests fail if you use long indices (`-DMKL_ILP64 -DEIGEN_BLAS_INDEX=int`). This is because the implementation of BLAS in `libmkl_intel_ilp64.so` expects 64-bit long indices.\r\n\r\n@drormeir if you use `-DMKL_LP64` instead of `-DMKL_ILP64`, TensorFlow will compile fine. I would not expect to see performance improvements though.", "Thank you!\n\nOn Jul 14, 2017 23:57, \"Lukasz Janyst\" <notifications@github.com> wrote:\n\n> It is not a bug in TensorFlow; it's a problem with Eigen.\n>\n> When used in the MKL mode, Eigen's code defines BlasIndex to be whatever\n> MKL_INT is:\n>\n> typedef MKL_INT BlasIndex;\n>\n> It is utterly confusing because the definition of MKL_INT varies\n> depending on the size of indices you want to use in your program. However,\n> instead of using the MKL's BLAS interface, which takes the size of MKL_INT\n> into account, Eigen defines its own interface (\n> https://bitbucket.org/eigen/eigen/src/e7027de735d6450c8ede3ce2f65166\n> 714c6aef50/Eigen/src/misc/blas.h?at=default&fileviewer=file-view-default)\n> using only 32-bit long ints. This is the reason for the compilation errors\n> you see.\n>\n> @gogo40 <https://github.com/gogo40> Your patch is unnecessary if you use\n> short indices (-DMKL_LP64) and makes a significant chunk of the Eigen's\n> unit tests fail if you use long indices (-DMKL_ILP64\n> -DEIGEN_BLAS_INDEX=int). This is because the implementation of BLAS in\n> libmkl_intel_ilp64.so expects 64-bit long indices.\n>\n> @drormeir <https://github.com/drormeir> if you use -DMKL_LP64 instead of\n> -DMKL_ILP64, TensorFlow will compile fine. I would not expect to see\n> performance improvements though.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/10157#issuecomment-315465528>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AYEDEa7uYfjj9T7CCpmXYlBFZat8h3jiks5sN9Y3gaJpZM4Nk8LC>\n> .\n>\n", "Thank you @ljanyst ", "Looks like this issue was resolved.\r\nI will close this issue.\r\n\r\nIt is also obsolete now, as you can just use `--config=mkl` to build with MKL support."]}, {"number": 10156, "title": "Added missing case for osx", "body": "Small patch for #10060 ", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it!", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->", "Email was missing in github, added it. Does it need to be the primary email?", "CLAs look good, thanks!\n\n<!-- ok -->", "Jenkins test this please.", "Jenkins test this please.", "Jenkins test this please."]}, {"number": 10155, "title": "Estimator should be able to partially load checkpoints", "body": "### Describe the problem\r\nWhen training neural networks and experimenting with different architectures or simply adapting a model to a new number of classes, it is crucial to be able to reuse an existing trained model as far as possible. For example, if I want to use the inception-v4 architecture and train it on 700 instead of 1000 classes, I need to be able to load all layers but the logit ones.\r\n\r\nUnfortunately, this is not possible (at least I wasn't able to find a way) with the Estimator API. Whenever the size of a variable in my model changes or I add or remove a variable, the Estimator cannot load an existing checkpoint any more. This is a major drawback making the Estimator basically unusable for developing a new architecture or adapting an existing one by iteratively adapting the model.\r\n\r\n### Requested features\r\n* It should be possible to tell the Estimator that it's ok if some variables aren't found in the checkpoint. Those should simply be initialized as if no checkpoint would be loaded.\r\n* It should be possible to specify scopes that should not be loaded from the checkpoint or to specify a flag that says something like \"just don't load variables that have a different shape / that you can't load\".\r\n* Be able to load an existing checkpoint from a different path than the Estimator's `model_dir` when there is no checkpoint in the `model_dir` yet. This is helpful to start training from a different checkpoint without manully having to copy those model's checkpoints into the new `model_dir`\r\n\r\n### Inspiration\r\nThis request has been inspired by the parameters you can specify to the [train_image_classifier.py](https://github.com/tensorflow/models/blob/master/slim/train_image_classifier.py) script from the tensorflow-models/slim directory. There you have the parameters `--checkpoint_exclude_scopes`, `--ignore_missing_vars` and `--checkpoint_path`.\r\n\r\nOf course, one could say it's possible to implement this manually. But I think these are basic functionalities for everyone doing a bit more deeplearning than only the tutorial. That's why I think this should be part of the otherwise easy to use Estimator API. ", "comments": ["Thanks for reaching out. This is very broad as far as feature requests go. I'll let @honkentuber respond, since he works on tf.learn.", "If you're using a custom estimator, and supplying your own model_fn, you can call `init_from_checkpoint`. The `checkpoint_dir` arg can be different from your `model_dir`, and `assignment_map` allows you to map only the subset of variables you want to load.\r\n\r\nHere's the API doc for 1.1, in 1.2 it will be available as tf.train.init_from_checkpoint.\r\ntensorflow.org/api_docs/python/tf/contrib/framework/init_from_checkpoint", "@honkentuber \r\nI'm trying to do as you suggested, but when I call init_from_checkpoint from my model_fn it somehow mess the init operation...\r\nI'm getting:\r\n`RuntimeError: Init operations did not make model ready for local_init.  Init op: group_deps, init fn: None, error: Variables not initialized: ...`\r\n\r\nthe trained model_dir is different then the old one, but both options didn't work for me.\r\nany suggestions?", "as suggested here: https://stackoverflow.com/questions/43336553/how-to-use-tf-train-monitoredtrainingsession-to-restore-only-certain-variables\r\n\r\nI edited prepare_session function (just commented out: `# if not is_loaded_from_checkpoint:`)\r\nand now it works. I assume it can have bad effect in other scenarios but right now it looks like a bug ", "@honkentuber: Thanks for your response and sorry for my delay!\r\n\r\nHow exactly would I use `init_from_checkpoint` in the `model_fn`? And how would I test if this is the first run of my model (which is when I want to load the checkpoint from elsewhere) and when I continue training in the same folder (then I'd like to use the normal checkpoint loading). Can you outline a small example?", "Hi, I just had the same issue, follow below a possible workflow.\r\n\r\n```\r\n.\r\n.\r\n def _model_fn(features, labels, mode, params, config):\r\n    graph = create_your_graph_here(features, labels)\r\n    tf.contrib.framework.init_from_checkpoint(\"./checkpoint_path\", {\"scope/\":\"my_scope/\"})\r\n    .....\r\n```\r\n\r\nCheers\r\n", "Hello,\r\ncould you clarify how `init_from_checkpoint`'s `assignment_map` should be defined?\r\n\r\nI'm trying to restore weights from an InceptionResnet_v2 checkpoint, but I want to exclude the `InceptionResnetV2/Logits` and `InceptionResnetV2/AuxLogits` scopes.\r\nI get the variables to restore via `tf.contrib.slim.get_variables_to_restore(exclude=['InceptionResnetV2/Logits', 'InceptionResnetV2/AuxLogits'])` and extract the scopes from the resulting list via `scopes = { os.path.dirname(v.name) for v in variables_to_restore }`. If I build the assignment_map as `{s+'/':s+'/' for s in scopes}`, the model init fails trying to restore `InceptionResnetV2/Logits/Logits/biases`. In `scopes` there is no `*/Logits/*`, so why is `init_from_checkpoint` loading those as well from the checkpoint?", "I've managed to use `init_from_checkpoint`, but until there I've made some mistakes.\r\nFirst created a hook object (instance of a class that inherits from `tf.train.SessionRunHook` ) to load pretrained weights after a session is created ( on `after_create_session` method). But for some reason the string \"Adam\" was appended at the end of each variable name and then the variables could not be found in the checkpoint file. Yes, \"Adam\" due to the optimizer being used. \r\n\r\nAs my second attempt, I tried to execute `init_from_checkpoint` right after my network architecture is defined on `model_fn` and it seems to work. The following is the snippet I'm currently using:\r\n\r\n```\r\ndef model_fn(features, labels, mode, params):\r\n    is_training = mode == ModeKeys.TRAIN\r\n    logits = cnn_architecture(features, is_training=is_training)  # Architecture is defined here\r\n    tf.train.init_from_checkpoint(FLAGS.checkpoint_path,{\"InceptionV4/\":\"InceptionV4/\"})\r\n    ...\r\n```\r\n\r\nWhen the training starts the following appears on my console:\r\n\r\n```\r\n...\r\nINFO:tensorflow:Initialize variable InceptionV4/Mixed_5c/Branch_2/Conv2d_0a_1x1/weights from checkpoint ../checkpoint_models/inception_v4.ckpt with InceptionV4/Mixed_5c/Branch_2/Conv2d_0a_1x1/weights\r\nINFO:tensorflow:Initialize variable InceptionV4/Mixed_7c/Branch_1/Conv2d_0c_3x1/BatchNorm/moving_mean from checkpoint ../checkpoint_models/inception_v4.ckpt with InceptionV4/Mixed_7c/Branch_1/Conv2d_0c_3x1/BatchNorm/moving_mean\r\n...\r\n```\r\nOBS: I'm using TF-1.4\r\nI hope it helps you", "Would be nice to have an official example in the docs, showing how to use the Estimators API when some weights should be initialized from an existing checkpoint in the very first step and all others should be initialized randomly. @honkentuber ", "@jonasrauber AMEN!\r\n\r\nUntil then, I finally managed to find a way to make it work, see my question and answer here: https://stackoverflow.com/q/47867748/3214872\r\n\r\nThe question's code, amended with the answer's fix, can be used as a working example for this use-case.", "Partially related to the fine tuning case in https://github.com/tensorflow/tensorflow/issues/14713. ", "Nagging Awaiting TensorFlower: It has been 14 days with no activityand the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "This issue should hopefully be searchable enough to be the definitive documentation. Please note StackOverflow has better searchability. We might also welcome a PR adding docs for this to the official site. Thanks everyone for reaching out.", "How this is related to the new warm start parameter in master?", "https://github.com/tensorflow/tensorflow/issues/14713#issuecomment-361866951", "Supposing that we want to accept this [Stackoverflow solution](https://stackoverflow.com/questions/46423956/load-checkpoint-and-finetuning-using-tf-estimator-estimator) can we document at least how to handle this with estimator created by `tf.keras.estimator.model_to_estimator` API?", "I'm using the following `SessionRunHook` to warm_start with an `exclude=[\"Logits\"]` filter\u2013\u2013useful for excluding the last FC layer of a pre-trained model. but shouldn't it be easier?\r\n\r\n```\r\nclass RestoreHook(tf.train.SessionRunHook):\r\n  \"\"\"restores model from a checkpoint_path with include/exclude variable filtering from\r\n  see:\r\n   - https://www.tensorflow.org/api_docs/python/tf/contrib/framework/assign_from_checkpoint_fn\r\n   - https://www.tensorflow.org/api_docs/python/tf/contrib/framework/get_variables_to_restore\r\n  \r\n  args:\r\n    checkpoint_path: full path to checkpoint\r\n    include: an optional list/tuple of scope strings for filtering which\r\n      variables from the VARIABLES collection to include. None would include all\r\n      the variables.\r\n    exclude: an optional list/tuple of scope strings for filtering which\r\n      variables from the VARIABLES collection to exclude. None it would not\r\n      exclude any.\r\n  \r\n  use in combination with tf.Estimator `training_hooks`\r\n\r\n  \r\n  usage:\r\n    def main():\r\n      checkpoint_path = \"/path/to/checkpoint/file.ckpt\"\r\n      restore_hook = RestoreHook(checkpoint_path, exclude=['Logits'])\r\n      estimator = tf.estimator.Estimator( model_fn=model_fn, \r\n                                          warm_start_from=None\r\n                                         )\r\n      estimator.train(, hooks=[restore_hook,])\r\n\r\n  \"\"\"\r\n  def __init__(self, checkpoint_path, include=None, exclude=None ):\r\n      self.checkpoint_path = checkpoint_path\r\n      self.include = include\r\n      self.exclude = exclude\r\n\r\n  def after_create_session(self, session, coord=None):\r\n      # delay until AFTER graph is created\r\n      var_list = tf.contrib.framework.get_variables_to_restore(include=self.include, exclude=self.exclude)\r\n      self.init_fn = tf.contrib.framework.assign_from_checkpoint_fn(\r\n              checkpoint_path,\r\n              var_list=var_list,\r\n              ignore_missing_vars=True\r\n              )      \r\n      if session.run(tf.train.get_or_create_global_step()) == 0:\r\n          # suppress WARN\r\n          log_level = tf.logging.get_verbosity()\r\n          tf.logging.set_verbosity(tf.logging.ERROR)\r\n          self.init_fn(session)\r\n          tf.logging.set_verbosity(log_level)\r\n          \r\n```", "@mixuala it is easier (from version 1.6, at least). Look at the warm start parameter @bhack mentioned, it does essentially what your hook does (allows you to filter what variables to restore based on a regexp on the var names)", "Seems warm_start parameter can only specify the variables to restore with single reg string or use  `var_name_to_vocab_info`. Is it possible to filter with a list, or we can choose to ignore the missing variables in old checkpoint.", "You can explicitly pass in a list of Variables or list of strings if you want to avoid regexp + TRAINABLE_VARIABLES ([docstring](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/warm_starting_util.py#L315)).", "Thanks, I check again and seems r1.9 add this feature", "I have a simple network. 2 conv 2d layers followed by dense layers. I need to initialise only conv layer weights. So in Estimator WarmStart I give the following.\r\ntf.estimator.WarmStartSettings(ckpt_to_initialize_from = checkpoint_dir,\r\n                                                       vars_to_warm_start = [conv1c/kernel,conv1c/bias,conv2c/kernel,conv2c/bias] ,\r\n                                                       var_name_to_vocab_info=None,\r\n                                                        var_name_to_prev_var_name = {\"conv1c/kernel\":\"conv1/kernel\",\"conv1c/bias\":\"conv1/bias\",\"conv2c/kernel\":\"conv2/kernel\",\"conv2c/bias\":\"conv2/bias\"})\r\nIf i give list of variables that i want to restart, then it adds all the global variables in that variable scope.\r\n![image](https://user-images.githubusercontent.com/20920622/48241386-b142aa00-e3fc-11e8-83d4-420edacec533.png)\r\n![image](https://user-images.githubusercontent.com/20920622/48241404-ca4b5b00-e3fc-11e8-9550-c904a8a232ed.png)\r\nWhy not get only TRAINABLE VARIABLES here?", "I apologize for the convoluted (no pun intended) API here -- there are users who want to warm-start variables from the GLOBAL_VARIABLES collection (such as batch norm or optimizer accumulator vars, which aren't added to TRAINABLE_VARIABLES), and we also needed to ensure backwards compatibility.  So tangibly, we have the following options for vars_to_warm_start:\r\n\r\n- regexp, which applies tf.get_collection to TRAINABLE_VARIABLES\r\n- list of tf.Variable, which is explicit\r\n- list of strings, each a regex scope to provide to tf.get_collection on GLOBAL_VARIABLES\r\n- `None`\r\n\r\nAn upcoming release's documentation should make this more clear.", "Thank you for the explanation. For transfer learning, we might initialize few layers and use different optimizer compared to the one pre-trained network was trained on. In that case getting global variables produces an error. It will be nice to include may be the scope from which the user can choose if he/ she wants to initialize global variables or only trainable variables. ", "I have a similar issue. I try to load a variable and train with Adam which had not been trainable in the previous model. For example I try to load: \"graph/logits/conv/biases\" but \"graph/logits/conv/biases/Adam\" is loaded too, which does not exist in my checkpoint and results in an error.\r\n\r\nI am wondering why there is no name check in this line  (Amirtha1189 mentioned above) in file \"tensorflow/python/training/warm_start_util.py\" :\r\n```\r\n        list_of_vars += ops.get_collection(ops.GraphKeys.GLOBAL_VARIABLES,\r\n                                           scope=v)\r\n```\r\nIf it would be:\r\n```\r\n        for i in ops.get_collection(ops.GraphKeys.GLOBAL_VARIABLES,\r\n                                           scope=v):\r\n            if v == i.name:\r\n                list_of_vars += i \r\n```\r\ninstead. \r\n\r\nThe utility variabels (Adam, ExponentialMovingAverage) would be excluded. And there would still be the option to get them by passing in the whole name.", "@jart should have some examples in `tensorflow/models`.", "Check out [this thread](https://github.com/tensorflow/tensorflow/issues/14713). This is possible with a custom hook.", "> I've managed to use `init_from_checkpoint`, but until there I've made some mistakes.\r\n> First created a hook object (instance of a class that inherits from `tf.train.SessionRunHook` ) to load pretrained weights after a session is created ( on `after_create_session` method). But for some reason the string \"Adam\" was appended at the end of each variable name and then the variables could not be found in the checkpoint file. Yes, \"Adam\" due to the optimizer being used.\r\n> \r\n> As my second attempt, I tried to execute `init_from_checkpoint` right after my network architecture is defined on `model_fn` and it seems to work. The following is the snippet I'm currently using:\r\n> \r\n> ```\r\n> def model_fn(features, labels, mode, params):\r\n>     is_training = mode == ModeKeys.TRAIN\r\n>     logits = cnn_architecture(features, is_training=is_training)  # Architecture is defined here\r\n>     tf.train.init_from_checkpoint(FLAGS.checkpoint_path,{\"InceptionV4/\":\"InceptionV4/\"})\r\n>     ...\r\n> ```\r\n> When the training starts the following appears on my console:\r\n> \r\n> ```\r\n> ...\r\n> INFO:tensorflow:Initialize variable InceptionV4/Mixed_5c/Branch_2/Conv2d_0a_1x1/weights from checkpoint ../checkpoint_models/inception_v4.ckpt with InceptionV4/Mixed_5c/Branch_2/Conv2d_0a_1x1/weights\r\n> INFO:tensorflow:Initialize variable InceptionV4/Mixed_7c/Branch_1/Conv2d_0c_3x1/BatchNorm/moving_mean from checkpoint ../checkpoint_models/inception_v4.ckpt with InceptionV4/Mixed_7c/Branch_1/Conv2d_0c_3x1/BatchNorm/moving_mean\r\n> ...\r\n> ```\r\n> OBS: I'm using TF-1.4\r\n> I hope it helps you\r\n\r\nI got this message, in tf.logging.DEBUG and not in tf.logging.INFO, for TF-1.12 hopefully it is helpful. ", "> > I've managed to use `init_from_checkpoint`, but until there I've made some mistakes.\r\n> > First created a hook object (instance of a class that inherits from `tf.train.SessionRunHook` ) to load pretrained weights after a session is created ( on `after_create_session` method). But for some reason the string \"Adam\" was appended at the end of each variable name and then the variables could not be found in the checkpoint file. Yes, \"Adam\" due to the optimizer being used.\r\n> > As my second attempt, I tried to execute `init_from_checkpoint` right after my network architecture is defined on `model_fn` and it seems to work. The following is the snippet I'm currently using:\r\n> > ```\r\n> > def model_fn(features, labels, mode, params):\r\n> >     is_training = mode == ModeKeys.TRAIN\r\n> >     logits = cnn_architecture(features, is_training=is_training)  # Architecture is defined here\r\n> >     tf.train.init_from_checkpoint(FLAGS.checkpoint_path,{\"InceptionV4/\":\"InceptionV4/\"})\r\n> >     ...\r\n> > ```\r\n> > When the training starts the following appears on my console:\r\n> > ```\r\n> > ...\r\n> > INFO:tensorflow:Initialize variable InceptionV4/Mixed_5c/Branch_2/Conv2d_0a_1x1/weights from checkpoint ../checkpoint_models/inception_v4.ckpt with InceptionV4/Mixed_5c/Branch_2/Conv2d_0a_1x1/weights\r\n> > INFO:tensorflow:Initialize variable InceptionV4/Mixed_7c/Branch_1/Conv2d_0c_3x1/BatchNorm/moving_mean from checkpoint ../checkpoint_models/inception_v4.ckpt with InceptionV4/Mixed_7c/Branch_1/Conv2d_0c_3x1/BatchNorm/moving_mean\r\n> > ...\r\n> > ```\r\n> > OBS: I'm using TF-1.4\r\n> > I hope it helps you\r\n> \r\n> I got this message, in tf.logging.DEBUG and not in tf.logging.INFO, for TF-1.12 hopefully it is helpful.\r\n\r\nThank you very much. Especially message log under tf.logging.DEBUG was very helpful. ", "When using **estimator** for training, argument `warm_start_from` in `tf.estimator.Estimator()` could be used to load pretrained model and it could be `tf.estimtor.WarmStartSettings()` which accepts regex to capture variables to warm-start.\r\n\r\nFor example, if we want to exclude dense layer for fine tuning: <br>\r\n```python\r\nwarm_start_settings = tf.estimator.WarmStartSettings(model_checkpoint_path, vars_to_warm_start='^(?!.*dense)')\r\n...\r\nest = tf.estimator.Estimator(model_fn=model_function, model_dir=model_dir, config=run_config, warm_start_from=warm_start_settings)\r\n...\r\n```", "@CasiaFan But how to handle situations that the vars in pretrained model change their scope in current model? It seems the param `var_name_to_prev_var_name`  doesn't accept regex format", "@honkentuber  I try to address this problem as you said.But I meet a new problem. I load partially variable from a pretrain_dir. and use the model_dir to save the new model. So I write the resotre code part in the model_fn. \r\n\r\nBut when is start training, every iteration could restore from the pretrained checkpoint and model_dir. I just want it resotre from the pretrain_dir in the beginning.\r\n\r\n`\r\ndef gan_model_fn(features, labels, mode, params):\r\n\r\n    model = transformer.Transformer(params, mode == tf.estimator.ModeKeys.TRAIN, mode=mode)\r\n\r\n    if mode == tf.estimator.ModeKeys.TRAIN:\r\n        \r\n        TENSORS_TO_LOG = {\r\n            \"bt_loss\" : bt_loss,\r\n        }\r\n\r\n        logging_hook = tf.train.LoggingTensorHook(\r\n            TENSORS_TO_LOG,\r\n            every_n_iter=100)\r\n        \r\n        print(\"Right Here !!!\")\r\n        train_op = gen_train_op(bt_loss, params)\r\n        \r\n        print(\"!!!!!!!!!!!!!restore init from pretrain checkpoint\")\r\n        checkpoint_file = tf.train.get_checkpoint_state(params.pretrain_dir).model_checkpoint_path\r\n        variables = tf.global_variables()\r\n        var_keep_dic = get_variables_in_checkpoint_file(checkpoint_file)\r\n        var_keep_dic.pop('global_step')\r\n    \r\n        assignment_map = {}\r\n        for v in variables:\r\n            if v.name.split(':')[0] in var_keep_dic:\r\n                print('Varibles restored: %s' % v.name)\r\n                assignment_map[v.name.split(\":\")[0]] = v\r\n        tf.logging.info(\"Restoring from {}\".format(checkpoint_file))\r\n        tf.train.init_from_checkpoint(checkpoint_file, assignment_map)\r\n    \r\n        return tf.estimator.EstimatorSpec(\r\n            mode=mode,\r\n            loss=bt_loss,\r\n            train_op=train_op,\r\n            training_hooks=[logging_hook])\r\n    else:\r\n        tf.logging.info(\"----------the mode is {} ---------\".format(mode))\r\n        return tf.estimator.EstimatorSpec(\r\n            mode=mode,\r\n            loss=bt_loss,\r\n            predictions={\"predictions\": gen_samples},\r\n            eval_metric_ops=metrics.get_eval_metrics_rl(gen_samples, labels, params)\r\n        )"]}, {"number": 10154, "title": "tensorflow-gpu windows10 ImportError: No module named '_pywrap_tensorflow_internal'", "body": "Hi, I have encountered the following issue when importing the gpu version of tensorflow in python3.5 on windows10:\r\n\r\nC:\\Users\\Gwendoline>activate tensorflow-gpu\r\n\r\n(tensorflow-gpu) C:\\Users\\Gwendoline>python\r\nPython 3.5.3 |Continuum Analytics, Inc.| (default, May 15 2017, 10:43:23) [MSC v.1900 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 919, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: Le module sp\u00e9cifi\u00e9 est introuvable.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 51, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 52, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 919, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: Le module sp\u00e9cifi\u00e9 est introuvable.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n\r\nI have downloaded the 8.0 version of CUDA and cuDNN v5.1, and have put the cuDNN files cudnn64_5.dll, cudnn.h, and cudnn.lib respectively in the CUDA repositories bin\\, include\\ and lib\\x64. The corresponding environment variable path is set as C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\bin. Can you help ? Many thanks", "comments": ["I have same problem \ud83d\ude22", "@mrry Could you take a look please? Thanks.", "I've created a script for diagnosing common TensorFlow on Windows installation issues. Please download the script from https://gist.github.com/mrry/ee5dbcfdd045fa48a27d56664411d41c and run `python tensorflow_self_check.py`. It will print suggestions for how to fix your installation. Let me know if you are still facing problems after running the script.", "Hi derek\r\nAt first thank you for your response\r\nI ran your script and it's results is :\r\n\r\nERROR: Failed to import the TensorFlow module.\r\n\r\n- Python version is 3.5.\r\n\r\n- TensorFlow is installed at: C:\\Program\r\nFiles\\Anaconda3\\lib\\site-packages\\tensorflow\r\n\r\n- Could not load 'cudnn64_5.dll'. The GPU version of TensorFlow\r\n  requires that this DLL be installed in a directory that is named in\r\n  your %PATH% environment variable. Note that installing cuDNN is a\r\n  separate step from installing CUDA, and it is often found in a\r\n  different directory from the CUDA DLLs. You may install the\r\n  necessary DLL by downloading cuDNN 5.1 from this URL:\r\n  https://developer.nvidia.com/cudnn\r\n\r\nBut as i told you, i downloaded cudnn 5.1\r\nIt contains 3 files\r\nCudnn64_5.dll\r\nCudnn.h\r\nCudnn.lib\r\n\r\nI copied :\r\ncudnn64_5.dll to cuda DLLs directory and then added it to windows\r\nenvironment variable PATH\r\nCudnn.h to cuda includes\r\nCudnn.lib to cuda libs/x64\r\nbut because of you said , i copied dll file in\r\n anaconda3/DLLs\r\nNow still i have past problem\r\nImage links of errors and directories files : \r\nhttps://ibb.co/bZHkFv\r\nhttps://ibb.co/fbOgoF\r\nhttps://ibb.co/hEUnTF\r\nhttps://ibb.co/kNuhvv\r\nhttps://ibb.co/ivDmNa\r\nhttps://ibb.co/dk2fha\r\nhttps://ibb.co/mCyLha\r\nhttps://ibb.co/cP2P8F\r\nThank you my friend\r\n", "Hi @mrry, many thanks for your response ! Sadly the script only advised me to post a help message on github :( It issued the following:\r\n\r\nERROR: Failed to import the TensorFlow module.\r\n\r\n- Python version is 3.5.\r\n\r\n- TensorFlow is installed at: C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\r\n\r\n- All required DLLs are present. Please open an issue on the\r\n  TensorFlow GitHub page: https://github.com/tensorflow/tensorflow/issues", "@mlghost It looks like you might be running a 32-bit version of Python and importing a 64-bit version of TensorFlow... for example, all of the official packages are 64-bit.\r\n\r\n@gwendoline-28 I'm sorry to hear that the script didn't fix your problem! Can you please paste in the full error that you see when you do `import tensorflow` in Python?", "Hi @mrry, here is the full error:\r\n\r\nMicrosoft Windows [version 10.0.14393]\r\n(c) 2016 Microsoft Corporation. Tous droits r\u00e9serv\u00e9s.\r\n\r\nC:\\Users\\Gwendoline>activate tensorflow-gpu\r\n\r\n(tensorflow-gpu) C:\\Users\\Gwendoline>python\r\nPython 3.5.3 |Continuum Analytics, Inc.| (default, May 15 2017, 10:43:23) [MSC v.1900 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 919, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: Le module sp\u00e9cifi\u00e9 est introuvable.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 51, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 52, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 919, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: Le module sp\u00e9cifi\u00e9 est introuvable.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nMany thanks ! ", "@gwendoline-28 There must be some other DLL causing the import to fail. Can you try opening the file `C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\_pywrap_tensorflow_internal.pyd` using the [Dependency Walker](http://www.dependencywalker.com/) tool and see if it reports any dependency errors?", "Hi @mrry, many thanks, it looks like there were indeed dependency errors. Dependency Walker has displayed the list of .dll files that were not found (a whole bunch of them):\r\n\r\nError: At least one required implicit or forwarded dependency was not found.\r\nError: At least one module has an unresolved import due to a missing export function in an implicitly dependent module.\r\nError: A circular dependency was detected.\r\nWarning: At least one delay-load dependency module was not found.\r\nWarning: At least one module has an unresolved import due to a missing export function in a delay-load dependent module.\r\n\r\nAm I supposed to reinstall tensorflow or another package to get them ?", "Hmm, that's surprising. Can you share the list of DLLs that were not found?\r\n\r\n(Also, just to make sure, can you run Dependency Walker from the Anaconda terminal in the environment where TensorFlow is installed? This might have a different `%PATH%` from the default system `%PATH%`, and so some of the errors might be false negatives....)", "Hi again, here is the list of .dll files that were not found:\r\nAPI-MS-WIN-CORE-APIQUERY-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-APPCOMPAT-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-APPINIT-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-ATOMS-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-COMM-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-CONSOLE-L2-1-0.DLL\r\nAPI-MS-WIN-CORE-CRT-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-CRT-L2-1-0.DLL\r\nAPI-MS-WIN-CORE-DATETIME-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-DATETIME-L1-1-2.DLL\r\nAPI-MS-WIN-CORE-DEBUG-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-DELAYLOAD-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-ENCLAVE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-ERRORHANDLING-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-ERRORHANDLING-L1-1-3.DLL\r\nAPI-MS-WIN-CORE-FIBERS-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-FIBERS-L2-1-1.DLL\r\nAPI-MS-WIN-CORE-FILE-L1-2-1.DLL\r\nAPI-MS-WIN-CORE-FILE-L1-2-2.DLL\r\nAPI-MS-WIN-CORE-FILE-L2-1-1.DLL\r\nAPI-MS-WIN-CORE-FILE-L2-1-2.DLL\r\nAPI-MS-WIN-CORE-HEAP-L1-2-0.DLL\r\nAPI-MS-WIN-CORE-HEAP-L2-1-0.DLL\r\nAPI-MS-WIN-CORE-HEAP-OBSOLETE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-INTERLOCKED-L1-2-0.DLL\r\nAPI-MS-WIN-CORE-IO-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-JOB-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-KERNEL32-LEGACY-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-KERNEL32-PRIVATE-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-LIBRARYLOADER-L1-2-0.DLL\r\nAPI-MS-WIN-CORE-LIBRARYLOADER-L1-2-2.DLL\r\nAPI-MS-WIN-CORE-LIBRARYLOADER-L2-1-0.DLL\r\nAPI-MS-WIN-CORE-LOCALIZATION-L1-2-1.DLL\r\nAPI-MS-WIN-CORE-LOCALIZATION-L2-1-0.DLL\r\nAPI-MS-WIN-CORE-LOCALIZATION-OBSOLETE-L1-3-0.DLL\r\nAPI-MS-WIN-CORE-LOCALIZATION-PRIVATE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-MEMORY-L1-1-2.DLL\r\nAPI-MS-WIN-CORE-MISC-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-NAMEDPIPE-L1-2-0.DLL\r\nAPI-MS-WIN-CORE-NAMEDPIPE-L1-2-2.DLL\r\nAPI-MS-WIN-CORE-NAMESPACE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-NORMALIZATION-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-PATH-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-PERFCOUNTERS-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-PRIVATEPROFILE-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-PROCESSENVIRONMENT-L1-2-0.DLL\r\nAPI-MS-WIN-CORE-PROCESSSNAPSHOT-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-PROCESSTHREADS-L1-1-2.DLL\r\nAPI-MS-WIN-CORE-PROCESSTHREADS-L1-1-3.DLL\r\nAPI-MS-WIN-CORE-PROCESSTOPOLOGY-L1-2-0.DLL\r\nAPI-MS-WIN-CORE-PSAPI-ANSI-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-PSAPI-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-QUIRKS-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-REALTIME-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-REGISTRY-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-REGISTRY-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-REGISTRYUSERSPECIFIC-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-RTLSUPPORT-L1-2-0.DLL\r\nAPI-MS-WIN-CORE-SHLWAPI-LEGACY-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-SHLWAPI-OBSOLETE-L1-2-0.DLL\r\nAPI-MS-WIN-CORE-SIDEBYSIDE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-STRING-L2-1-0.DLL\r\nAPI-MS-WIN-CORE-STRING-L2-1-1.DLL\r\nAPI-MS-WIN-CORE-STRING-OBSOLETE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-STRINGANSI-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-SYNCH-L1-2-1.DLL\r\nAPI-MS-WIN-CORE-SYSINFO-L1-2-1.DLL\r\nAPI-MS-WIN-CORE-SYSINFO-L1-2-3.DLL\r\nAPI-MS-WIN-CORE-THREADPOOL-L1-2-0.DLL\r\nAPI-MS-WIN-CORE-THREADPOOL-LEGACY-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-THREADPOOL-PRIVATE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-URL-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-VERSION-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-VERSION-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-VERSION-PRIVATE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-VERSIONANSI-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-VERSIONANSI-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-WINDOWSERRORREPORTING-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-WINRT-ERROR-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-WOW64-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-WOW64-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-XSTATE-L2-1-0.DLL\r\nAPI-MS-WIN-EVENTING-CLASSICPROVIDER-L1-1-0.DLL\r\nAPI-MS-WIN-EVENTING-CONSUMER-L1-1-0.DLL\r\nAPI-MS-WIN-EVENTING-OBSOLETE-L1-1-0.DLL\r\nAPI-MS-WIN-GDI-INTERNAL-UAP-L1-1-0.DLL\r\nAPI-MS-WIN-SECURITY-APPCONTAINER-L1-1-0.DLL\r\nAPI-MS-WIN-SECURITY-AUDIT-L1-1-1.DLL\r\nAPI-MS-WIN-SECURITY-BASE-L1-2-0.DLL\r\nAPI-MS-WIN-SECURITY-BASE-PRIVATE-L1-1-1.DLL\r\nAPI-MS-WIN-SERVICE-CORE-L1-1-1.DLL\r\nAPI-MS-WIN-SERVICE-CORE-L1-1-2.DLL\r\nAPI-MS-WIN-SERVICE-MANAGEMENT-L1-1-0.DLL\r\nAPI-MS-WIN-SERVICE-MANAGEMENT-L2-1-0.DLL\r\nAPI-MS-WIN-SERVICE-PRIVATE-L1-1-0\r\nAPI-MS-WIN-SERVICE-PRIVATE-L1-1-1.DLL\r\nAPI-MS-WIN-SERVICE-PRIVATE-L1-1-2.DLL\r\nAPI-MS-WIN-SERVICE-WINSVC-L1-2-0.DLL\r\nNVCUDA.DLL\r\nAPI-MS-ONECOREUAP-SETTINGSYNC-STATUS-L1-1-0.DLL\r\nAPI-MS-WIN-APPMODEL-IDENTITY-L1-2-0.DLL\r\nAPI-MS-WIN-APPMODEL-RUNTIME-INTERNAL-L1-1-0.DLL\r\nAPI-MS-WIN-APPMODEL-RUNTIME-INTERNAL-L1-1-3.DLL\r\nAPI-MS-WIN-APPMODEL-RUNTIME-L1-1-0.DLL\r\nAPI-MS-WIN-APPMODEL-RUNTIME-L1-1-1.DLL\r\nAPI-MS-WIN-APPMODEL-RUNTIME-L1-1-2.DLL\r\nAPI-MS-WIN-APPMODEL-STATE-L1-2-0.DLL\r\nAPI-MS-WIN-APPMODEL-UNLOCK-L1-1-0.DLL\r\nAPI-MS-WIN-BASE-UTIL-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-CALENDAR-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-COM-L1-1-0\r\nAPI-MS-WIN-CORE-COM-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-COM-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-COM-L2-1-1.DLL\r\nAPI-MS-WIN-CORE-COM-MIDLPROXYSTUB-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-COM-PRIVATE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-COM-PRIVATE-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-DELAYLOAD-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-FIRMWARE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-IO-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-JOB-L2-1-0.DLL\r\nAPI-MS-WIN-CORE-KERNEL32-LEGACY-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-KERNEL32-LEGACY-L1-1-5.DLL\r\nAPI-MS-WIN-CORE-KERNEL32-PRIVATE-L1-1-2.DLL\r\nAPI-MS-WIN-CORE-LARGEINTEGER-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-LOCALIZATION-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-LOCALIZATION-L1-2-2.DLL\r\nAPI-MS-WIN-CORE-LOCALIZATION-OBSOLETE-L1-2-0.DLL\r\nAPI-MS-WIN-CORE-LOCALREGISTRY-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-MARSHAL-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-MEMORY-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-MEMORY-L1-1-4.DLL\r\nAPI-MS-WIN-CORE-PRIVATEPROFILE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-PROCESSTOPOLOGY-OBSOLETE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-PSM-APPNOTIFY-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-PSM-KEY-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-REALTIME-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-REGISTRY-L2-2-0.DLL\r\nAPI-MS-WIN-CORE-REGISTRY-PRIVATE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-SHLWAPI-OBSOLETE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-SHUTDOWN-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-SYSINFO-L1-2-0.DLL\r\nAPI-MS-WIN-CORE-TEXTINPUT-CLIENT-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-TOOLHELP-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-WINRT-ERRORPRIVATE-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-WINRT-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-WINRT-PROPERTYSETPRIVATE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-WINRT-PROPERTYSETPRIVATE-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-WINRT-REGISTRATION-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-WINRT-ROBUFFER-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-WINRT-STRING-L1-1-0.DLL\r\nAPI-MS-WIN-COREUI-SECRUNTIME-L1-1-0.DLL\r\nAPI-MS-WIN-DEVICES-CONFIG-L1-1-1.DLL\r\nAPI-MS-WIN-DEVICES-QUERY-L1-1-1.DLL\r\nAPI-MS-WIN-DOWNLEVEL-KERNEL32-L2-1-0.DLL\r\nAPI-MS-WIN-DOWNLEVEL-SHLWAPI-L2-1-1.DLL\r\nAPI-MS-WIN-DWMAPI-L1-1-0.DLL\r\nAPI-MS-WIN-DX-D3DKMT-L1-1-0.DLL\r\nAPI-MS-WIN-DX-D3DKMT-L1-1-2.DLL\r\nAPI-MS-WIN-EVENTING-LEGACY-L1-1-0.DLL\r\nAPI-MS-WIN-EVENTLOG-LEGACY-L1-1-0.DLL\r\nAPI-MS-WIN-GDI-DPIINFO-L1-1-0.DLL\r\nAPI-MS-WIN-MM-JOYSTICK-L1-1-0.DLL\r\nAPI-MS-WIN-MM-MISC-L1-1-1.DLL\r\nAPI-MS-WIN-MM-MISC-L2-1-0.DLL\r\nAPI-MS-WIN-MM-MME-L1-1-0.DLL\r\nAPI-MS-WIN-MM-TIME-L1-1-0.DLL\r\nAPI-MS-WIN-NTUSER-RECTANGLE-L1-1-0.DLL\r\nAPI-MS-WIN-NTUSER-SYSPARAMS-L1-1-0.DLL\r\nAPI-MS-WIN-OLE32-IE-L1-1-0.DLL\r\nAPI-MS-WIN-POWER-BASE-L1-1-0.DLL\r\nAPI-MS-WIN-POWER-SETTING-L1-1-0.DLL\r\nAPI-MS-WIN-RO-TYPERESOLUTION-L1-1-0.DLL\r\nAPI-MS-WIN-RTCORE-NTUSER-CLIPBOARD-L1-1-0.DLL\r\nAPI-MS-WIN-RTCORE-NTUSER-PRIVATE-L1-1-0.DLL\r\nAPI-MS-WIN-RTCORE-NTUSER-PRIVATE-L1-1-1.DLL\r\nAPI-MS-WIN-RTCORE-NTUSER-SYNCH-L1-1-0.DLL\r\nAPI-MS-WIN-RTCORE-NTUSER-WINDOW-L1-1-0.DLL\r\nAPI-MS-WIN-RTCORE-NTUSER-WINEVENT-L1-1-0.DLL\r\nAPI-MS-WIN-SECURITY-ACCESSHLPR-L1-1-0.DLL\r\nAPI-MS-WIN-SECURITY-ACTIVEDIRECTORYCLIENT-L1-1-0.DLL\r\nAPI-MS-WIN-SECURITY-ACTIVEDIRECTORYCLIENT-L1-1-1.DLL\r\nAPI-MS-WIN-SECURITY-BASE-L1-1-0.DLL\r\nAPI-MS-WIN-SECURITY-CAPABILITY-L1-1-0.DLL\r\nAPI-MS-WIN-SECURITY-CREDENTIALS-L1-1-0.DLL\r\nAPI-MS-WIN-SECURITY-CREDENTIALS-L2-1-0.DLL\r\nAPI-MS-WIN-SECURITY-CRYPTOAPI-L1-1-0.DLL\r\nAPI-MS-WIN-SECURITY-GROUPPOLICY-L1-1-0.DLL\r\nAPI-MS-WIN-SECURITY-LSALOOKUP-L1-1-1.DLL\r\nAPI-MS-WIN-SECURITY-LSALOOKUP-L1-1-2.DLL\r\nAPI-MS-WIN-SECURITY-LSALOOKUP-L2-1-1.DLL\r\nAPI-MS-WIN-SECURITY-LSAPOLICY-L1-1-0.DLL\r\nAPI-MS-WIN-SECURITY-PROVIDER-L1-1-0.DLL\r\nAPI-MS-WIN-SECURITY-SDDL-L1-1-0.DLL\r\nAPI-MS-WIN-SECURITY-SDDLPARSECOND-L1-1-0.DLL\r\nAPI-MS-WIN-SECURITY-SYSTEMFUNCTIONS-L1-1-0.DLL\r\nAPI-MS-WIN-SERVICE-WINSVC-L1-1-0.DLL\r\nAPI-MS-WIN-SHCORE-COMHELPERS-L1-1-0.DLL\r\nAPI-MS-WIN-SHCORE-OBSOLETE-L1-1-0.DLL\r\nAPI-MS-WIN-SHCORE-REGISTRY-L1-1-1.DLL\r\nAPI-MS-WIN-SHCORE-SCALING-L1-1-1.DLL\r\nAPI-MS-WIN-SHCORE-STREAM-L1-1-0.DLL\r\nAPI-MS-WIN-SHCORE-STREAM-WINRT-L1-1-0.DLL\r\nAPI-MS-WIN-SHCORE-SYSINFO-L1-1-0.DLL\r\nAPI-MS-WIN-SHCORE-THREAD-L1-1-0.DLL\r\nAPI-MS-WIN-SHCORE-UNICODEANSI-L1-1-0.DLL\r\nAPI-MS-WIN-SHELL-SHELLCOM-L1-1-0.DLL\r\nAPI-MS-WIN-SHELL-SHELLFOLDERS-L1-1-0.DLL\r\nAPI-MS-WIN-SHLWAPI-IE-L1-1-0.DLL\r\nAPI-MS-WIN-SHLWAPI-WINRT-STORAGE-L1-1-1.DLL\r\nAPI-MS-WIN-STORAGE-EXPORTS-EXTERNAL-L1-1-0.DLL\r\nAPI-MS-WIN-STORAGE-EXPORTS-INTERNAL-L1-1-0.DLL\r\nDEVICELOCKHELPERS.DLL\r\nEMCLIENT.DLL\r\nEXT-MS-MF-PAL-L2-1-0.DLL\r\nEXT-MS-ONECORE-APPCHROMEAPI-L1-1-0.DLL\r\nEXT-MS-ONECORE-APPDEFAULTS-L1-1-0.DLL\r\nEXT-MS-ONECORE-APPMODEL-VEVENTDISPATCHER-L1-1-0.DLL\r\nEXT-MS-ONECORE-DCOMP-L1-1-0.DLL\r\nEXT-MS-ONECORE-HLINK-L1-1-0.DLL\r\nEXT-MS-ONECORE-ORIENTATION-L1-1-0.DLL\r\nEXT-MS-ONECORE-PHONEINFO-L1-1-0.DLL\r\nEXT-MS-ONECORE-SHELLCHROMEAPI-L1-1-1.DLL\r\nEXT-MS-ONECORE-SHELLCHROMEAPI-L1-1-2.DLL\r\nEXT-MS-WIN-ADVAPI32-MSI-L1-1-0.DLL\r\nEXT-MS-WIN-ADVAPI32-NPUSERNAME-L1-1-0.DLL\r\nEXT-MS-WIN-ADVAPI32-NTMARTA-L1-1-0.DLL\r\nEXT-MS-WIN-ADVAPI32-PSM-APP-L1-1-0.DLL\r\nEXT-MS-WIN-ADVAPI32-REGISTRY-L1-1-0.DLL\r\nEXT-MS-WIN-ADVAPI32-SAFER-L1-1-0.DLL\r\nEXT-MS-WIN-APPCOMPAT-APPHELP-L1-1-0.DLL\r\nEXT-MS-WIN-APPMODEL-DAXCORE-L1-1-0.DLL\r\nEXT-MS-WIN-APPMODEL-DEPLOYMENT-L1-1-1.DLL\r\nEXT-MS-WIN-APPMODEL-STATE-EXT-L1-2-0.DLL\r\nEXT-MS-WIN-APPMODEL-USERCONTEXT-L1-1-0.DLL\r\nEXT-MS-WIN-APPMODEL-VIEWSCALEFACTOR-L1-1-0.DLL\r\nEXT-MS-WIN-APPXDEPLOYMENTCLIENT-APPXDEPLOY-L1-1-0.DLL\r\nEXT-MS-WIN-APPXDEPLOYMENTCLIENT-APPXDEPLOYONECORE-L1-1-0.DLL\r\nEXT-MS-WIN-AUDIOCORE-PAL-L1-1-2.DLL\r\nEXT-MS-WIN-AUTHZ-CONTEXT-L1-1-0.DLL\r\nEXT-MS-WIN-AUTHZ-REMOTE-L1-1-0.DLL\r\nEXT-MS-WIN-COM-CLBCATQ-L1-1-0.DLL\r\nEXT-MS-WIN-COM-COML2-L1-1-1.DLL\r\nEXT-MS-WIN-COM-OLE32-L1-1-1.DLL\r\nEXT-MS-WIN-COM-OLE32-L1-1-4.DLL\r\nEXT-MS-WIN-COM-PSMREGISTER-L1-2-1.DLL\r\nEXT-MS-WIN-COM-SUSPENDRESILIENCY-L1-1-0.DLL\r\nEXT-MS-WIN-CORE-WINRT-REMOTE-L1-1-0.DLL\r\nEXT-MS-WIN-DEVMGMT-DM-L1-1-0.DLL\r\nEXT-MS-WIN-DEVMGMT-POLICY-L1-1-0.DLL\r\nEXT-MS-WIN-DIRECT2D-DESKTOP-L1-1-0.DLL\r\nEXT-MS-WIN-DOMAINJOIN-NETJOIN-L1-1-0.DLL\r\nEXT-MS-WIN-DWMAPIDXGI-EXT-L1-1-0.DLL\r\nEXT-MS-WIN-EDPUTIL-POLICY-L1-1-0.DLL\r\nEXT-MS-WIN-EVENTING-RUNDOWN-L1-1-0.DLL\r\nEXT-MS-WIN-FAMILYSAFETY-CHILDACCOUNT-L1-1-0.DLL\r\nEXT-MS-WIN-FECLIENT-ENCRYPTEDFILE-L1-1-0.DLL\r\nEXT-MS-WIN-FIREWALLAPI-WEBPROXY-L1-1-0.DLL\r\nEXT-MS-WIN-GDI-CLIPPING-L1-1-0.DLL\r\nEXT-MS-WIN-GDI-DC-CREATE-L1-1-1.DLL\r\nEXT-MS-WIN-GDI-DC-L1-2-0.DLL\r\nEXT-MS-WIN-GDI-DC-L1-2-1.DLL\r\nEXT-MS-WIN-GDI-DEVCAPS-L1-1-0.DLL\r\nEXT-MS-WIN-GDI-DRAW-L1-1-1.DLL\r\nEXT-MS-WIN-GDI-DRAW-L1-1-3.DLL\r\nEXT-MS-WIN-GDI-FONT-L1-1-1.DLL\r\nEXT-MS-WIN-GDI-FONT-L1-1-3.DLL\r\nEXT-MS-WIN-GDI-INTERNAL-DESKTOP-L1-1-0.DLL\r\nEXT-MS-WIN-GDI-METAFILE-L1-1-1.DLL\r\nEXT-MS-WIN-GDI-METAFILE-L1-1-2.DLL\r\nEXT-MS-WIN-GDI-PATH-L1-1-0.DLL\r\nEXT-MS-WIN-GDI-PRINT-L1-1-0.DLL\r\nEXT-MS-WIN-GDI-PRIVATE-L1-1-0.DLL\r\nEXT-MS-WIN-GDI-RENDER-L1-1-0.DLL\r\nEXT-MS-WIN-GDI-WCS-L1-1-0.DLL\r\nEXT-MS-WIN-GPAPI-GROUPPOLICY-L1-1-0.DLL\r\nEXT-MS-WIN-KERNEL32-APPCOMPAT-L1-1-0.DLL\r\nEXT-MS-WIN-KERNEL32-DATETIME-L1-1-0.DLL\r\nEXT-MS-WIN-KERNEL32-ERRORHANDLING-L1-1-0.DLL\r\nEXT-MS-WIN-KERNEL32-FILE-L1-1-0.DLL\r\nEXT-MS-WIN-KERNEL32-LOCALIZATION-L1-1-0.DLL\r\nEXT-MS-WIN-KERNEL32-PACKAGE-CURRENT-L1-1-0.DLL\r\nEXT-MS-WIN-KERNEL32-PACKAGE-L1-1-1.DLL\r\nEXT-MS-WIN-KERNEL32-QUIRKS-L1-1-0.DLL\r\nEXT-MS-WIN-KERNEL32-QUIRKS-L1-1-1.DLL\r\nEXT-MS-WIN-KERNEL32-REGISTRY-L1-1-0.DLL\r\nEXT-MS-WIN-KERNEL32-SIDEBYSIDE-L1-1-0.DLL\r\nEXT-MS-WIN-KERNEL32-WINDOWSERRORREPORTING-L1-1-0.DLL\r\nEXT-MS-WIN-KERNEL32-WINDOWSERRORREPORTING-L1-1-1.DLL\r\nEXT-MS-WIN-KERNELBASE-PROCESSTHREAD-L1-1-0.DLL\r\nEXT-MS-WIN-MININPUT-INPUTHOST-L1-1-0.DLL\r\nEXT-MS-WIN-MPR-MULTIPLEPROVIDERROUTER-L1-1-0.DLL\r\nEXT-MS-WIN-MRMCORER-ENVIRONMENT-L1-1-0.DLL\r\nEXT-MS-WIN-MRMCORER-RESMANAGER-L1-1-0.DLL\r\nEXT-MS-WIN-NTDSAPI-ACTIVEDIRECTORYCLIENT-L1-1-0.DLL\r\nEXT-MS-WIN-NTDSAPI-ACTIVEDIRECTORYCLIENT-L1-1-1.DLL\r\nEXT-MS-WIN-NTUSER-DC-ACCESS-EXT-L1-1-0.DLL\r\nEXT-MS-WIN-NTUSER-DIALOGBOX-L1-1-1.DLL\r\nEXT-MS-WIN-NTUSER-DRAW-L1-1-1.DLL\r\nEXT-MS-WIN-NTUSER-DRAW-L1-1-2.DLL\r\nEXT-MS-WIN-NTUSER-GUI-L1-3-0.DLL\r\nEXT-MS-WIN-NTUSER-KEYBOARD-L1-1-1.DLL\r\nEXT-MS-WIN-NTUSER-KEYBOARD-L1-3-0.DLL\r\nEXT-MS-WIN-NTUSER-MENU-L1-1-2.DLL\r\nEXT-MS-WIN-NTUSER-MESSAGE-L1-1-1.DLL\r\nEXT-MS-WIN-NTUSER-MESSAGE-L1-1-3.DLL\r\nEXT-MS-WIN-NTUSER-MISC-L1-3-0.DLL\r\nEXT-MS-WIN-NTUSER-MISC-L1-5-1.DLL\r\nEXT-MS-WIN-NTUSER-MOUSE-L1-1-0.DLL\r\nEXT-MS-WIN-NTUSER-PRIVATE-L1-2-0.DLL\r\nEXT-MS-WIN-NTUSER-PRIVATE-L1-3-1.DLL\r\nEXT-MS-WIN-NTUSER-RECTANGLE-EXT-L1-1-0.DLL\r\nEXT-MS-WIN-NTUSER-ROTATIONMANAGER-L1-1-0.DLL\r\nEXT-MS-WIN-NTUSER-SERVER-L1-1-0.DLL\r\nEXT-MS-WIN-NTUSER-STRING-L1-1-0.DLL\r\nEXT-MS-WIN-NTUSER-SYNCH-L1-1-0.DLL\r\nEXT-MS-WIN-NTUSER-UICONTEXT-EXT-L1-1-0.DLL\r\nEXT-MS-WIN-NTUSER-WINDOW-L1-1-1.DLL\r\nEXT-MS-WIN-NTUSER-WINDOW-L1-1-3.DLL\r\nEXT-MS-WIN-NTUSER-WINDOW-L1-1-4.DLL\r\nEXT-MS-WIN-NTUSER-WINDOWCLASS-L1-1-1.DLL\r\nEXT-MS-WIN-NTUSER-WINDOWSTATION-L1-1-1.DLL\r\nEXT-MS-WIN-OLE32-BINDCTX-L1-1-0.DLL\r\nEXT-MS-WIN-OLE32-IE-EXT-L1-1-0.DLL\r\nEXT-MS-WIN-OLE32-OLEAUTOMATION-L1-1-0.DLL\r\nEXT-MS-WIN-PROFILE-EXTENDER-L1-1-0.DLL\r\nEXT-MS-WIN-PROFILE-LOAD-L1-1-0.DLL\r\nEXT-MS-WIN-PROFILE-USERENV-L1-1-0.DLL\r\nEXT-MS-WIN-PROFILE-USERENV-L1-1-1.DLL\r\nEXT-MS-WIN-RAS-RASAPI32-L1-1-0.DLL\r\nEXT-MS-WIN-RDR-DAVHLPR-L1-1-0.DLL\r\nEXT-MS-WIN-RO-TYPERESOLUTION-L1-1-0.DLL\r\nEXT-MS-WIN-ROMETADATA-DISPENSER-L1-1-0.DLL\r\nEXT-MS-WIN-RPC-SSL-L1-1-0.DLL\r\nEXT-MS-WIN-RTCORE-GDI-DEVCAPS-L1-1-0.DLL\r\nEXT-MS-WIN-RTCORE-GDI-OBJECT-L1-1-0.DLL\r\nEXT-MS-WIN-RTCORE-GDI-RGN-L1-1-0.DLL\r\nEXT-MS-WIN-RTCORE-GDI-RGN-L1-1-1.DLL\r\nEXT-MS-WIN-RTCORE-MINUSER-INPUT-L1-1-2.DLL\r\nEXT-MS-WIN-RTCORE-MINUSER-PRIVATE-EXT-L1-1-0.DLL\r\nEXT-MS-WIN-RTCORE-NTUSER-CURSOR-L1-1-0.DLL\r\nEXT-MS-WIN-RTCORE-NTUSER-DC-ACCESS-L1-1-0.DLL\r\nEXT-MS-WIN-RTCORE-NTUSER-DPI-L1-2-0.DLL\r\nEXT-MS-WIN-RTCORE-NTUSER-IAM-L1-1-1.DLL\r\nEXT-MS-WIN-RTCORE-NTUSER-INTEGRATION-L1-1-0.DLL\r\nEXT-MS-WIN-RTCORE-NTUSER-SYNCH-EXT-L1-1-0.DLL\r\nEXT-MS-WIN-RTCORE-NTUSER-SYSCOLORS-L1-1-0.DLL\r\nEXT-MS-WIN-RTCORE-NTUSER-SYSPARAMS-L1-1-0.DLL\r\nEXT-MS-WIN-RTCORE-NTUSER-WINDOW-EXT-L1-1-0.DLL\r\nEXT-MS-WIN-SECUR32-TRANSLATENAME-L1-1-0.DLL\r\nEXT-MS-WIN-SECURITY-CAPAUTHZ-L1-1-0.DLL\r\nEXT-MS-WIN-SECURITY-CHAMBERS-L1-1-0.DLL\r\nEXT-MS-WIN-SECURITY-CREDUI-INTERNAL-L1-1-0.DLL\r\nEXT-MS-WIN-SECURITY-CREDUI-L1-1-0.DLL\r\nEXT-MS-WIN-SECURITY-CRYPTUI-L1-1-0.DLL\r\nEXT-MS-WIN-SECURITY-CRYPTUI-L1-1-1.DLL\r\nEXT-MS-WIN-SECURITY-EFS-L1-1-0.DLL\r\nEXT-MS-WIN-SECURITY-EFSWRT-L1-1-1.DLL\r\nEXT-MS-WIN-SESSION-USERMGR-L1-1-0.DLL\r\nEXT-MS-WIN-SESSION-USERTOKEN-L1-1-0.DLL\r\nEXT-MS-WIN-SESSION-WINSTA-L1-1-0.DLL\r\nEXT-MS-WIN-SESSION-WTSAPI32-L1-1-0.DLL\r\nEXT-MS-WIN-SETUPAPI-INF-L1-1-0.DLL\r\nEXT-MS-WIN-SETUPAPI-INF-L1-1-1.DLL\r\nEXT-MS-WIN-SHELL-DIRECTORY-L1-1-0.DLL\r\nEXT-MS-WIN-SHELL-EMBEDDEDMODE-L1-1-0.DLL\r\nEXT-MS-WIN-SHELL-PROPSYS-L1-1-0.DLL\r\nEXT-MS-WIN-SHELL-SHELL32-L1-2-0.DLL\r\nEXT-MS-WIN-SHELL-SHLWAPI-L1-1-0.DLL\r\nEXT-MS-WIN-SHELL32-SHELLCOM-L1-1-0.DLL\r\nEXT-MS-WIN-SMBSHARE-BROWSERCLIENT-L1-1-0.DLL\r\nEXT-MS-WIN-STORAGE-SENSE-L1-1-0.DLL\r\nEXT-MS-WIN-SXS-OLEAUTOMATION-L1-1-0.DLL\r\nEXT-MS-WIN-UI-VIEWMANAGEMENT-L1-1-0.DLL\r\nEXT-MS-WIN-USP10-L1-1-0.DLL\r\nEXT-MS-WIN-WER-UI-L1-1-0.DLL\r\nEXT-MS-WIN-WER-XBOX-L1-1-0.DLL\r\nEXT-MS-WIN-WINRT-STORAGE-L1-1-0.DLL\r\nEXT-MS-WIN-WLAN-ONEXUI-L1-1-0.DLL\r\nEXT-MS-WIN-WWAN-WWAPI-L1-1-0.DLL\r\nEXT-MS-WIN-WWAN-WWAPI-L1-1-1.DLL\r\nIESHIMS.DLL\r\n\r\nFrom the Anaconda terminal, I typed:\r\nactivate tensorflow-gpu\r\ncd C:\\Users\\Gwendoline\\Downloads\r\ndepends C:\\Users\\Gwendoline\\Anaconda3\\envs\\tensorflow-gpu\\Lib\\site-packages\\tensorflow\\python\\_pywrap_tensorflow_internal.pyd\r\nand got the exact same result.", "@mrry assigning you since you have been dealing with the issue, but please unassign yourself if you don't have time.", "Aha, it looks like `NVCUDA.DLL` is the main missing dependency. (I think all of the others are false negatives, owing to a change in the way Windows DLLs work in recent versions.)\r\n\r\nStrangely, it seems the `cudart64_80.dll` *can* be found, and I would expect them to be in the same location. Can you confirm where `cudart64_80.dll` is installed on your machine, and check whether `NVCUDA.DLL` is in the same location?", "Hi, I have found the file cudart64_80.dll in C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\bin, however NVCUDA.DLL is not in this folder.", "I just checked my local installation and `NVCUDA.DLL` is installed in `C:\\Windows\\System32\\`. Can you check if it is in that directory?\r\n\r\nAlso, can you ensure that `C:\\Windows\\System32` is present in your `%PATH%` environment variable? (It would be unusual for this not to be the case.)", "Hi, I have searched for the file nvcuda.dll in C:\\ and it is nowhere to be found. However C:\\Windows\\system32 is present in my path environment variable.", "OK, in that case I think there is a problem with your CUDA installation. Can you try reinstalling CUDA 8.0? (For those following along, I've added a check for `NVCUDA.DLL` to the self-check script.)", "Hi, I have re-installed CUDA 8 with a local installer but still haven't found the file NVCUDA.DLL in C:\\. Is there any other way I can download it ?", "The next step might be to try reinstalling the NVIDIA driver for your GPU. I haven't been able to find definitive instructions about getting `NVCUDA.DLL`, but this [FAQ](https://developer.nvidia.com/cuda-faq) seems relevant:\r\n\r\n> **Q: What do I need to distribute my CUDA application?**\r\n> Applications that use the driver API only need the CUDA driver library (\"nvcuda.dll\" under Windows), which is included as part of the standard NVIDIA driver install.\r\n\r\n\r\n", "I haven't installed the nvidia driver yet - it may be the source of the issue indeed (I was looking for tensorflow to work with cpu only first).", "I think that's almost certainly the source of the error. The `tensorflow-gpu` package requires that you have a CUDA-capable GPU installed (and CUDA and cuDNN on top of that). If you want to work with CPU only, try uninstalling `tensorflow-gpu` and installing the `tensorflow` package instead.", "Many thanks for your help !"]}, {"number": 10153, "title": "Android: No OpKernel was registered to support Op 'ExtractImagePatches'", "body": "Hi, I have read (#9763 =>) #9476 #5764 #8486 #6260 #5921 (#1269 This one is too old to be helpful).\r\n\r\nI was trying to use YOLOv2 on Android TensorFlow. I followed the exact same procedure stated in the README that successfully got the tiny-yolo-voc model running on my phones, the only different in the code is the filename. But I got the following error message and the app die.\r\n\r\n```\r\nFATAL EXCEPTION: inference\r\nProcess: org.tensorflow.demo, PID: 31154\r\njava.lang.IllegalArgumentException: No OpKernel was registered to support Op 'ExtractImagePatches' with these attrs.  Registered devices: [CPU], Registered kernels: <no registered kernels>\r\n                                                                     \r\n[[Node: ExtractImagePatches = ExtractImagePatches[T=DT_FLOAT, ksizes=[1, 2, 2, 1], padding=\"VALID\", rates=[1, 1, 1, 1], strides=[1, 2, 2, 1]](concat)]]\r\nat org.tensorflow.Session.run(Native Method)\r\nat org.tensorflow.Session.access$100(Session.java:48)\r\nat org.tensorflow.Session$Runner.runHelper(Session.java:295)\r\nat org.tensorflow.Session$Runner.run(Session.java:245)\r\nat org.tensorflow.contrib.android.TensorFlowInferenceInterface.run(TensorFlowInferenceInterface.java:142)\r\nat org.tensorflow.demo.TensorFlowYoloDetector.recognizeImage(TensorFlowYoloDetector.java:165)\r\nat org.tensorflow.demo.DetectorActivity$3.run(DetectorActivity.java:313)\r\nat android.os.Handler.handleCallback(Handler.java:755)\r\nat android.os.Handler.dispatchMessage(Handler.java:95)\r\nat android.os.Looper.loop(Looper.java:156)\r\nat android.os.HandlerThread.run(HandlerThread.java:61)\r\n```\r\n\r\nI also tried Yolo9000, it works (actually died because I didnot provide the matching label/name set, but it didnot yield the same error).\r\n\r\n1. I tried optimize_for_inference (https://petewarden.com/2016/09/27/tensorflow-for-mobile-poets/amp/), but the new pb file still have \"ExtractImagePatches\" op, so it didn't work for me.\r\n```\r\n$ grep \"ExtractImagePatches\" *\r\nBinary file graph-yolo-voc.pb matches\r\nBinary file opt.pb matches\r\n```\r\n\r\n2. I generated ops_to_register.h (shown below) and put it in tensorflow/tensorflow/core/framework dir (#8486), and it didn't work for me.\r\n```\r\n#ifndef OPS_TO_REGISTER\r\n#define OPS_TO_REGISTER\r\nconstexpr inline bool ShouldRegisterOp(const char op[]) {\r\n  return false\r\n     || (strcmp(op, \"BiasAdd\") == 0)\r\n     || (strcmp(op, \"ConcatV2\") == 0)\r\n     || (strcmp(op, \"Const\") == 0)\r\n     || (strcmp(op, \"Conv2D\") == 0)\r\n     || (strcmp(op, \"ExtractImagePatches\") == 0)\r\n     || (strcmp(op, \"Identity\") == 0)\r\n     || (strcmp(op, \"MaxPool\") == 0)\r\n     || (strcmp(op, \"Maximum\") == 0)\r\n     || (strcmp(op, \"Mul\") == 0)\r\n     || (strcmp(op, \"NoOp\") == 0)\r\n     || (strcmp(op, \"Pad\") == 0)\r\n     || (strcmp(op, \"Placeholder\") == 0)\r\n     || (strcmp(op, \"RealDiv\") == 0)\r\n     || (strcmp(op, \"Sub\") == 0)\r\n     || (strcmp(op, \"_Recv\") == 0)\r\n     || (strcmp(op, \"_Send\") == 0)\r\n  ;\r\n}\r\n#define SHOULD_REGISTER_OP(op) ShouldRegisterOp(op)\r\n\r\n\r\n    namespace {\r\n      constexpr const char* skip(const char* x) {\r\n        return (*x) ? (*x == ' ' ? skip(x + 1) : x) : x;\r\n      }\r\n\r\n      constexpr bool isequal(const char* x, const char* y) {\r\n        return (*skip(x) && *skip(y))\r\n                   ? (*skip(x) == *skip(y) && isequal(skip(x) + 1, skip(y) + 1))\r\n                   : (!*skip(x) && !*skip(y));\r\n      }\r\n\r\n      template<int N>\r\n      struct find_in {\r\n        static constexpr bool f(const char* x, const char* const y[N]) {\r\n          return isequal(x, y[0]) || find_in<N - 1>::f(x, y + 1);\r\n        }\r\n      };\r\n\r\n      template<>\r\n      struct find_in<0> {\r\n        static constexpr bool f(const char* x, const char* const y[]) {\r\n          return false;\r\n        }\r\n      };\r\n    }  // end namespace\r\n    constexpr const char* kNecessaryOpKernelClasses[] = {\r\n\"BiasOp<CPUDevice, float>\",\r\n\"ConcatV2Op<CPUDevice, float>\",\r\n\"ConstantOp\",\r\n\"Conv2DOp<CPUDevice, float>\",\r\n\"ExtractImagePatchesOp<CPUDevice, float>\",\r\n\"IdentityOp\",\r\n\"MaxPoolingOp<CPUDevice, float>\",\r\n\"BinaryOp<CPUDevice, functor::maximum<float>>\",\r\n\"BinaryOp<CPUDevice, functor::mul<float>>\",\r\n\"NoOp\",\r\n\"PadOp<CPUDevice, float>\",\r\n\"PlaceholderOp\",\r\n\"BinaryOp<CPUDevice, functor::div<float>>\",\r\n\"BinaryOp<CPUDevice, functor::sub<float>>\",\r\n\"RecvOp\",\r\n\"SendOp\",\r\n};\r\n#define SHOULD_REGISTER_OP_KERNEL(clz) (find_in<sizeof(kNecessaryOpKernelClasses) / sizeof(*kNecessaryOpKernelClasses)>::f(clz, kNecessaryOpKernelClasses))\r\n\r\n#define SHOULD_REGISTER_OP_GRADIENT false\r\n#endif\r\n\r\n```\r\n\r\n3. I added `tensorflow/core/kernels/extract_image_patches_op.cc` to `tf_op_files.txt`(#5764), and run bazel like this `$ bazel build -c opt //tensorflow/examples/android:tensorflow_demo --copt=\"-DSELECTIVE_REGISTRATION\" --define ANDROID_TYPES=__ANDROID_TYPES_FULL__` (#9476), still, didn't work for me.\r\n\r\nI am using ubuntu 16.04, \r\nTensorFlow installed from (I think I did not install because I just `pip list` and tensorflow was not on that list. I just follow https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android , and every thing works for tiny-yolo-voc),\r\n[bazel release 0.4.5],\r\nmy phone is running Android 7.0\r\n\r\nThanks,\r\nCHL", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there.", "@CHLLHC @StarRain-L Both of these ops should be included via tensorflow/core:android_op_registrations_and_gradients, which includes array_ops.cc (ExtractImagePatches) and math_ops.cc (Maximum). Can you provide more details about how you are building your app? Does it work if you use the [prebuilt binaries](https://ci.tensorflow.org/view/Nightly/job/nightly-android/)?\r\n\r\nAnd just to note, selective registration should also not be necessary.", "I just put \"extract_image_patches_op.cc\" in ./tensorflow/tensorflow/core/kernels/BUILD inside the \r\n`filegroup(\r\n    name = \"android_core_ops\",`", "@CHLLHC have you found a solution to this issue? I've made similar attempts to get ExtractImagePatches running on android to no avail.", "Hi MME,\r\n\r\nI did solve this issue and make it run on my phone.", "@CHLLHC could you please share how you got it to work?", "I try numerous methods, I have listed all I remember above. But my confession is that I didn't undo all operations from one method before trying another. Although I got it work after adding the line `\"extract_image_patches_op.cc\"` in the scope of `filegroup( name = \"android_core_ops\",` in the `BUILD` file under `./tensorflow/tensorflow/core/kernels/`,  I can't say for sure that `--copt=\"-DSELECTIVE_REGISTRATION\" --define ANDROID_TYPES=__ANDROID_TYPES_FULL__`, changing `ops_to_register.h`, nor putting `generated ops_to_register.h` in `tf_op_files.txt` is not necessary. \r\n\r\nThe only thing I am sure is the first method in my original post (optimize_for_inference) is not helping. And I only get my app running on a phone with 4GB of ram.", "using the prebuilt binaries results in the exact error mentioned above (`No OpKernel was registered to support Op 'ExtractImagePatches' with these attrs`) \r\n\r\nHowever, I was able to get this working with only the following steps:\r\n\r\n1. Modify `tensorflow/core/kernels/BUILD`, adding `extract_image_patches_op.cc` and `extract_image_patches_op.h` to the `android_core_ops` target\r\n\r\n2. Clean and build with the standard bazel command:\r\n```\r\nbazel clean && \\\r\n    bazel build -c opt //tensorflow/contrib/android:libtensorflow_inference.so \\\r\n    --crosstool_top=//external:android/crosstool \\\r\n    --host_crosstool_top=@bazel_tools//tools/cpp:toolchain \\\r\n    --cpu=armeabi-v7a\r\n```\r\nAlthough I'm rather new to bazel, I have the suspicion that I wasted many iterations by not running a `bazel clean` in between attempts.", "@matt-deboer Thank you for your nice instructions ! Do you mind sharing the .jar you get following your bazel command? I built mine with following your comment but I get this exception when I run my app:\r\n\r\n``` ruby\r\nCaused by: java.lang.RuntimeException: Native TF methods not found; check that the correct native libraries are present in the APK.\r\n    at org.tensorflow.contrib.android.TensorFlowInferenceInterface.prepareNativeRuntime(TensorFlowInferenceInterface.java:534)\r\n    at org.tensorflow.contrib.android.TensorFlowInferenceInterface.<init>(TensorFlowInferenceInterface.java:60)\r\n```  \r\n\r\nAlso do you do anything special with .jar and .so created? I simply add them in my 'libs' and 'libs/armeabi-v7a/' respectively, and add the .jar as a dependency in my build.gradle. Should I do something else ?", "@GauthierChan It looks like your custom .so is not being packaged into the apk.\r\n\r\nPutting them in the `libs` dir (in the structure you've mentioned) should work just fine, but you'll want to add the `.so` file(s) as a dependency also, similar to this:\r\n```\r\ncompile fileTree(dir: 'libs', include: ['*.jar', '**/*.so'])\r\n```", "I had trouble with these instructions for quite a while, I was still getting the 'Native TF methods not found' errors. After a while, I realized that the problem was my Android CPU was not arm-based, but rather x86_64. So, in my case, I used the awesome instructions from @matt-deboer, but replaced 'cpu=armeabi-v7a' with 'cpu=x86_64', and that resolved things for me."]}, {"number": 10152, "title": "Defragmentation support of BFCAllocator", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 208192074d7d19f6b51724bb06fd4c2a143649e7\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\n\r\nFrom the documentation of the [`BFCAllocator`](https://github.com/tensorflow/tensorflow/blob/208192074d7d19f6b51724bb06fd4c2a143649e7/tensorflow/core/common_runtime/bfc_allocator.h#L44), it aims to bring defragmentation support, which might be important for GPUs with relatively small memory so that potentially larger graphs can be supported.  The defragmentation part seems to be missing from the current implementation. Is there any plan on this, or any thoughts can be shared?\r\n", "comments": ["@zffchen78 Could you take a look please? Thanks.", "Friendly ping.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activityand the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It seems that I have misunderstood this allocator. This allocator actually supports \"defragmentation\" via coalescing.  This helps but might not be enough if there many allocations with non-power-of-2 size. However, this kind of optimization might not fit in this `BFCAllocator`. Closing."]}, {"number": 10151, "title": "Support dictionaries of tensors in tf.contrib.data.Dataset", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary (nightly build)\r\n- **TensorFlow version (use command below)**: v1.2.0-rc0-172-g9e25de3\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: `python3 test.py`\r\n\r\n### Describe the problem\r\nWith the new `tf.contrib.data.Dataset`, it is possible to work with tuples and lists of tensors, but not with dictionaries. Using dictionary structures is supported for things like `tf.batch`, and it would make migrating to Dataset easier if it also supported it.\r\n\r\n### Source code / logs\r\ntest.py\r\n```python\r\nimport tensorflow as tf\r\n\r\ndataset = tf.contrib.data.Dataset.range(3)\r\n\r\n# Using tuples works\r\ndataset_tup = dataset.map(lambda x: (x, x * 10))\r\n# Using lists works\r\ndataset_list = dataset.map(lambda x: [x, x * 10])\r\n# Using dicts doesn't work\r\n# dataset_dict = dataset.map(lambda x: {'a': x, 'b': x * 10})\r\n\r\n# Select dataset_tup, dataset_list or dataset_struct to output the values\r\ndataset_out = dataset_tup\r\n\r\niterator = dataset_tup.make_one_shot_iterator()\r\nnext_element = iterator.get_next()\r\n\r\nsess = tf.Session()\r\n\r\nfor _ in range(3):\r\n    print(sess.run(next_element))\r\n```\r\n\r\nWhen trying to use structs, I get this error\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\", line 460, in make_tensor_proto\r\n    str_values = [compat.as_bytes(x) for x in proto_values]\r\n  File \"/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\", line 460, in <listcomp>\r\n    str_values = [compat.as_bytes(x) for x in proto_values]\r\n  File \"/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/python/util/compat.py\", line 65, in as_bytes\r\n    (bytes_or_text,))\r\nTypeError: Expected binary or unicode string, got {'a': <tf.Tensor 'arg0:0' shape=() dtype=int64>, 'b': <tf.Tensor 'mul:0' shape=() dtype=int64>}\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ede/test/test3.py\", line 10, in <module>\r\n    dataset_dict = dataset.map(lambda x: {'a': x, 'b': x * 10})\r\n  File \"/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/data/python/ops/dataset_ops.py\", line 813, in map\r\n    return MapDataset(self, map_func, num_threads, output_buffer_size)\r\n  File \"/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/data/python/ops/dataset_ops.py\", line 1436, in __init__\r\n    self._map_func.add_to_graph(ops.get_default_graph())\r\n  File \"/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/function.py\", line 619, in add_to_graph\r\n    self._create_definition_if_needed()\r\n  File \"/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/data/python/framework/function.py\", line 167, in _create_definition_if_needed\r\n    outputs = self._func(*inputs)\r\n  File \"/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/data/python/ops/dataset_ops.py\", line 1427, in tf_map_func\r\n    flattened_ret = [ops.convert_to_tensor(t) for t in nest.flatten(ret)]\r\n  File \"/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/data/python/ops/dataset_ops.py\", line 1427, in <listcomp>\r\n    flattened_ret = [ops.convert_to_tensor(t) for t in nest.flatten(ret)]\r\n  File \"/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 676, in convert_to_tensor\r\n    as_ref=False)\r\n  File \"/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 741, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 113, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n  File \"/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 102, in constant\r\n    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\r\n  File \"/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\", line 464, in make_tensor_proto\r\n    \"supported type.\" % (type(values), values))\r\nTypeError: Failed to convert object of type <class 'dict'> to Tensor. Contents: {'a': <tf.Tensor 'arg0:0' shape=() dtype=int64>, 'b': <tf.Tensor 'mul:0' shape=() dtype=int64>}. Consider casting elements to a supported type.\r\n```", "comments": ["Passing off to contrib/data owner @mrry.", "This makes a lot of sense. I'm working on adding that feature now.", "Thanks for the fix! A well needed feature.\r\nI saw it was merged to master but couldn't find this commit in 1.2.0/1.2.1 releases. \r\n\r\nAny idea when will it be in one of the official releases? ", "@zachmoshe I think it missed last call for the 1.2 branch, but it's included in the 1.3 branch, so it should be in the next release candidate, which is currently being prepared."]}, {"number": 10150, "title": "tf.reshape modify the value of tensor", "body": "![kaywxxy2r62q pv063 _ve](https://cloud.githubusercontent.com/assets/12975526/26388007/7e87051a-4084-11e7-941e-f9d38e37e3c8.png)\r\n![nf8b f d1ae4_gi 9an](https://cloud.githubusercontent.com/assets/12975526/26388013/8154563a-4084-11e7-89b9-dfaf03761171.png)\r\nwhen i reshape the samples, the value of it is modified, why?", "comments": ["Because all the time TF draws a sample from your distribution. Try:\r\n```python\r\nwith tf.Session() as sess:\r\n  print sess.run([samples,ss])\r\n```\r\ninstead"]}, {"number": 10149, "title": "tf.contrib.distributions: undocumented behaviour in Multinomial and Categorical", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes?\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Sierra 10.12.3\r\n- **TensorFlow installed from (source or binary)**: binary, via pip\r\n- **TensorFlow version (use command below)**: 1.1.0 (v1.1.0-rc0-61-g1ec6ed5)\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:\r\n\r\n```python\r\nimport tensorflow as tf\r\ncategorical = tf.contrib.distributions.Categorical(probs = [0.25, 0.5, 0.25])\r\nmultinomial = tf.contrib.distributions.Multinomial(total_count = 1., probs = [0.25, 0.5, 0.25])\r\nmvn = tf.contrib.distributions.MultivariateNormalDiag(loc = [0., 0., 0.], scale_diag= [1., 1., 1.])\r\n\r\n# expected values (points 1 and 2)\r\n\r\n# The docs for Categorical say value should be float or double, but it expects an int\r\ncategorical.log_prob([0, 0, 1]) \r\n# <tf.Tensor 'Categorical_2/log_prob/Neg:0' shape=(3,) dtype=float32>\r\ncategorical.log_prob([0., 0., 1.])\r\n# TypeError: Value passed to parameter 'labels' has DataType float32 not in list of allowed values: int32, int64\r\n\r\n# The docs for Categorical say value should be float or double, which is how it behaves (though this is unlike categorical)\r\nmultinomial.log_prob([0, 0, 1]) \r\n# ValueError: Tensor conversion requested dtype int32 for Tensor with dtype float32: 'Tensor(\"Multinomial_2/log_prob/Log:0\", shape=(3,), dtype=float32)'\r\nmultinomial.log_prob([0., 0., 1.])\r\n# <tf.Tensor 'Multinomial_1/log_prob/sub:0' shape=() dtype=float32>\r\n\r\n# output shape (points 3 and 4)\r\n\r\n# The docs for both say that the output should be:\r\n# \"a Tensor of 'shape sample_shape(x) + self.batch_shape' with values of type self.dtype\"\r\n# though sample_shape doesn't seem to be relevant here, it's an argument to param_shapes() and sample()\r\n\r\n# for Categorical (with int value), the result is a vector, matching the shape of value\r\ncategorical.log_prob([0, 0, 1]) \r\n# <tf.Tensor 'Categorical_2/log_prob/Neg:0' shape=(3,) dtype=float32>\r\n\r\n# for Multinomial (with float value), the result is a scalar\r\nmultinomial.log_prob([0., 0., 1.])\r\n# <tf.Tensor 'Multinomial_1/log_prob/sub:0' shape=() dtype=float32>\r\n\r\n# for Multivariate Normal the result is a scalar\r\nmvn.log_prob([0.1, 0.2, 0.3])\r\n# <tf.Tensor 'MultivariateNormalDiag_2/log_prob/add:0' shape=() dtype=float32>\r\n```\r\n\r\n### Describe the problem\r\nThere are four related issues:\r\n\r\n1. The expected type of `value` for the `log_prob()` method in `tf.contrib.distributions.Categorical` is inconsistent with the documentation.\r\n\r\n2. The expected values for `tf.contrib.distributions.Categorical` and `tf.contrib.distributions.Multinomial` are inconsistent with one another, which is odd as the categorical distribution is a special case of the multinomial, with `total_count  = 1`\r\n\r\n3. The output dimensions for `tf.contrib.distributions.Categorical` and `tf.contrib.distributions.Multinomial` are inconsistent with the documentation\r\n\r\n4. The output dimensions for `tf.contrib.distributions.Categorical` are a vector, which doesn't really make sense for a multivariate distribution, and is inconsistent with `tf.contrib.distributions.Multinomial` and `tf.contrib.distributions.MultivariateNormal*`\r\n\r\nDetails are in the code snippet above\r\n", "comments": ["Passing documentation issue off to contrib/distributions czar @langmore.", "Punting this issue to @jvdillon. PTAL.", "Thanks for reporting this issue! I'll put together a fix right now and report back.", "Sorry for the delay! Small update: we implemented a fix and it's currently under review.", "Fix submitted. Should be in master in a few days."]}, {"number": 10148, "title": "TF tutorial getting started fix", "body": "Hi, \r\n\r\nI am not personally having an issue, but I wanted to make you aware of some things in the tutorial that might throw off a new user.  \r\n\r\nWhen the tutorial starts talking about the high level functions, they define the epochs here:\r\n\r\ninput_fn = tf.contrib.learn.io.numpy_input_fn({\"x\":x}, y, batch_size=4, num_epochs=1000)\r\n\r\nbut then they redefine here:\r\n\r\nestimator.fit(input_fn=input_fn, steps=1000)\r\n\r\nThis seems redundant, and per earlier issues:\r\nhttps://github.com/tensorflow/tensorflow/issues/10042\r\nhttps://github.com/tensorflow/tensorflow/issues/7677\r\n\r\nThere were people who said this made their system glitch.  If the system did accept both arguments, then I am not clear, nor have I found anywhere in the documentation, where it says which argument would take precedence if they are different numbers.\r\n\r\nOn another note, earlier in the tutorial, it where it calculates print(sess.run(linear_model, {x:[1,2,3,4]})), for some reason there is a floating decimal point way at the end of the output:\r\n\r\n[ 0.          0.30000001  0.60000002  0.90000004]\r\n\r\nThis doesn't add up, unless there is just some kind of extra operation that is not being shown.  I know it is likely a lot of work to handle all the issues that you get, but fixing these things might reduce your workload over time, as new users will be less confused up front, not to mention keep users from getting discourages and changing to other platforms before they begin.  Thank you for your help.\r\n\r\n", "comments": ["Hi again,\r\nI see the difference between step and epoch now.  Step is the number of batches you need to complete an epoch apparently.  E.g. steps=totalSamples/batchSize.  Still makes very little sense to me in the tutorial, given batchSize==totalSamples, although the problem isn't terrible if it goes unresolved.  I still have no explanation for the numbers being off in the latter example?  Thanks again!", "Hello Lee-L-Boyd, \r\n\r\nso i am twins14  and just a beginner, who is really intersting in learning tensorflow in my sparetime :))\r\nBut i really need some help :((\r\ni am looking for a machine learning example like the \"image classification\" to reconstruct it.\r\nSo my question to you is if you have such a code example ? \ud83d\udc4d \r\nWhen not, do you have maybe other little examples in Tensorflow for me to begin learning \ud83d\udcaf \r\nMy email adress is: almin-b@hotmail.de\r\n\r\nSo i would be very glad hearing from you :)\r\n\r\nWish you a nice evening!", "Hi twins14,\r\n\r\nI am new to TF myself.  What I have been doing is going over the mnist\r\ntutorial, which is basically just classifying numbers in photos:\r\n\r\nhttps://www.tensorflow.org/get_started/mnist/beginners\r\n\r\nwith the actual code you can run here:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/mnist.py\r\n\r\nI have moved on to the graph visualizations tutorial here:\r\n\r\nhttps://www.tensorflow.org/get_started/summaries_and_tensorboard\r\n\r\nand code for it here:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py\r\n\r\nI think understanding the visualization portion will be very important if\r\nyou want to actually test your code.  Goodluck!\r\n\r\n\r\n\r\n\r\nOn Wed, May 24, 2017 at 3:36 PM, twins14 <notifications@github.com> wrote:\r\n\r\n> Hello Lee-L-Boyd,\r\n>\r\n> so i am twins14 and just a beginner, who is really intersting in learning\r\n> tensorflow in my sparetime :))\r\n> But i really need some help :((\r\n> i am looking for a machine learning example like the \"image\r\n> classification\" to reconstruct it.\r\n> So my question to you is if you have such a code example ? \ud83d\udc4d\r\n> When not, do you have maybe other little examples in Tensorflow for me to\r\n> begin learning \ud83d\udcaf\r\n> My email adress is: almin-b@hotmail.de\r\n>\r\n> So i would be very glad hearing from you :)\r\n>\r\n> Wish you a nice evening!\r\n>\r\n> \u2014\r\n> You are receiving this because you authored the thread.\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/tensorflow/tensorflow/issues/10148#issuecomment-303843623>,\r\n> or mute the thread\r\n> <https://github.com/notifications/unsubscribe-auth/AB0YNqxTF0z8-s-CkPZFeuE-28oROAPZks5r9JSzgaJpZM4Nkaxf>\r\n> .\r\n>\r\n", "Thank you very much for your support \ud83d\udc4d\r\n\r\nMittwoch, 24 Mai 2017, 10:55nachm. +02:00 von Lee-L-Boyd notifications@github.com<mailto:notifications@github.com>:\r\n\r\nHi twins14,\r\n\r\nI am new to TF myself. What I have been doing is going over the mnist\r\ntutorial, which is basically just classifying numbers in photos:\r\n\r\nhttps://www.tensorflow.org/get_started/mnist/beginners\r\n\r\nwith the actual code you can run here:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/mnist.py\r\n\r\nI have moved on to the graph visualizations tutorial here:\r\n\r\nhttps://www.tensorflow.org/get_started/summaries_and_tensorboard\r\n\r\nand code for it here:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py\r\n\r\nI think understanding the visualization portion will be very important if\r\nyou want to actually test your code. Goodluck!\r\n\r\n\r\n*Lee L. Boyd*\r\nPresident - CSGSA at UTSA, 2017\r\nr <lee.l.boyd@gmail.com<mailto:lee.l.boyd@gmail.com>>cx653@my.utsa.edu\r\n(210)-404-3607\r\n\r\nOn Wed, May 24, 2017 at 3:36 PM, twins14 <notifications@github.com<mailto:notifications@github.com>> wrote:\r\n\r\n> Hello Lee-L-Boyd,\r\n>\r\n> so i am twins14 and just a beginner, who is really intersting in learning\r\n> tensorflow in my sparetime :))\r\n> But i really need some help :((\r\n> i am looking for a machine learning example like the \"image\r\n> classification\" to reconstruct it.\r\n> So my question to you is if you have such a code example ? \ud83d\udc4d\r\n> When not, do you have maybe other little examples in Tensorflow for me to\r\n> begin learning \ud83d\udcaf\r\n> My email adress is: almin-b@hotmail.de<mailto:almin-b@hotmail.de>\r\n>\r\n> So i would be very glad hearing from you :)\r\n>\r\n> Wish you a nice evening!\r\n>\r\n> \u2014\r\n> You are receiving this because you authored the thread.\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/tensorflow/tensorflow/issues/10148#issuecomment-303843623>,\r\n> or mute the thread\r\n> <https://github.com/notifications/unsubscribe-auth/AB0YNqxTF0z8-s-CkPZFeuE-28oROAPZks5r9JSzgaJpZM4Nkaxf>\r\n> .\r\n>\r\n\r\n\u2014\r\nYou are receiving this because you commented.\r\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/issues/10148#issuecomment-303848011>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AbmDlIqZMI9OovxjpeX5SEgf7VlDNGrUks5r9Jk2gaJpZM4Nkaxf>.\r\n", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly."]}, {"number": 10147, "title": "Strange Behavior During Grid Search", "body": "I implemented a customized grid search wrapper for a sequence-to-sequence model. The implementation is extremely simple:\r\n\r\n```\r\ndef single_round_model_eval(train_fun, decode_fun, eval_fun,\r\n                            train_set, dev_set, metrics):\r\n    # Train the model with a certain set of hyperparameters and evaluate on the\r\n    # development set.\r\n\r\n    # :param train_fun: Function to train the model.\r\n    # :param decode_fun: Function to decode from the trained model.\r\n    # :param eval_fun: Function to evaluate the decoding results.\r\n    # :param train_set: Training dataset.\r\n    # :param dev_set: Development dataset.\r\n    # :param metrics: Name of the evaluation metrics to be tuned.\r\n\r\n    # :return: The metrics being tuned.\r\n\r\n    tf.reset_default_graph()\r\n    train_fun(train_set, dev_set)\r\n\r\n    tf.reset_default_graph()\r\n    decode_sig = decode_fun(dev_set, verbose=False)\r\n\r\n    M = eval_fun(dev_set, decode_sig, verbose=False)\r\n\r\n    return M[metrics]\r\n```\r\n\r\nThe algorithm basically calls the above function every time it moves to a new point in the grid (a new set of hyperparameters).\r\n\r\nThe complete implementation can be found here:\r\nhttps://github.com/TellinaTool/awesome_nmt/blob/master/encoder_decoder/grid_search.py\r\n\r\nThe `single_round_model_eval` creates a training graph, trains the model; then creates a \"forward only\" decoding graph, and decode the predictions on the dev set; finally evaluates the newly decoded predictions (no graph operations is used in the evaluation step). \r\n\r\nYet I encountered a strange behavior that my subsequent runs always achieve much worse numbers compared to the first run. I didn't find problems in hyperparameter settings, and think this may be caused by that some variables carries residue values from the previous run. I tried to use `tf.reset_default_graph()` to force reset but that also doesn't help. I'm also wondering if it is caused by missing resets of the optimizer I used (tf.train.AdamOptimizer).\r\n\r\nCould anyone offer some help? Thanks!", "comments": []}, {"number": 10146, "title": "CUDA_ERROR_INVALID_DEVICE", "body": "Got the following error when trying to run tensorflow on GPU:\r\n\r\n> E tensorflow/core/common_runtime/direct_session.cc:137] Internal: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_INVALID_DEVICE\r\n> Traceback (most recent call last):\r\n>   File \"main.py\", line 200, in <module>\r\n>     model = PNN2(**pnn2_params)\r\n>   File \"/homes/jwpan/Github/DL_MultiField_Categorical_Data/python/models.py\", line 767, in __init__\r\n>     self.sess = tf.Session(config=config)\r\n>   File \"/projects/ml/mlas/tensorflow/1.0.8/gpu/python2.7/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1176, in __init__\r\n>     super(Session, self).__init__(target, graph, config=config)\r\n>   File \"/projects/ml/mlas/tensorflow/1.0.8/gpu/python2.7/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 552, in __init__\r\n>     self._session = tf_session.TF_NewDeprecatedSession(opts, status)\r\n>   File \"/projects/ml/mlas/tensorflow/1.0.8/gpu/python2.7/lib/python2.7/contextlib.py\", line 24, in __exit__\r\n>     self.gen.next()\r\n>   File \"/projects/ml/mlas/tensorflow/1.0.8/gpu/python2.7/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n>     pywrap_tensorflow.TF_GetCode(status))\r\n> tensorflow.python.framework.errors_impl.InternalError: Failed to create session.\r\n\r\nHave tried to set CUDA_VISIBLE_DEVICES but still does not work.\r\nHere is the output of nvidia-smi, just wonder why all GPUs are \"Off\"?\r\n\r\n> Tue May 23 21:28:08 2017\r\n> +------------------------------------------------------+\r\n> | NVIDIA-SMI 352.39     Driver Version: 352.39         |\r\n> |-------------------------------+----------------------+----------------------+\r\n> | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n> | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n> |===============================+======================+======================|\r\n> |   0  Tesla K80           On   | 0000:06:00.0     Off |                    0 |\r\n> | N/A   37C    P0    62W / 149W |  10983MiB / 11519MiB |      0%   E. Process |\r\n> +-------------------------------+----------------------+----------------------+\r\n> |   1  Tesla K80           On   | 0000:07:00.0     Off |                    0 |\r\n> | N/A   57C    P0    73W / 149W |  10983MiB / 11519MiB |      0%   E. Process |\r\n> +-------------------------------+----------------------+----------------------+\r\n> |   2  Tesla K80           On   | 0000:0A:00.0     Off |                    0 |\r\n> | N/A   38C    P0    60W / 149W |  10983MiB / 11519MiB |      0%   E. Process |\r\n> +-------------------------------+----------------------+----------------------+\r\n> |   3  Tesla K80           On   | 0000:0B:00.0     Off |                    0 |\r\n> | N/A   54C    P0    73W / 149W |  10983MiB / 11519MiB |      0%   E. Process |\r\n> +-------------------------------+----------------------+----------------------+\r\n> |   4  Tesla K80           On   | 0000:0E:00.0     Off |                    0 |\r\n> | N/A   37C    P0    61W / 149W |  10983MiB / 11519MiB |      0%   E. Process |\r\n> +-------------------------------+----------------------+----------------------+\r\n> |   5  Tesla K80           On   | 0000:0F:00.0     Off |                    0 |\r\n> | N/A   59C    P0    75W / 149W |  10983MiB / 11519MiB |      0%   E. Process |\r\n> +-------------------------------+----------------------+----------------------+\r\n> |   6  Tesla K80           On   | 0000:12:00.0     Off |                    0 |\r\n> | N/A   39C    P0    61W / 149W |  10983MiB / 11519MiB |      0%   E. Process |\r\n> +-------------------------------+----------------------+----------------------+\r\n> |   7  Tesla K80           On   | 0000:13:00.0     Off |                    0 |\r\n> | N/A   62C    P0    74W / 149W |  10983MiB / 11519MiB |      0%   E. Process |\r\n> +-------------------------------+----------------------+----------------------+\r\n> \r\n> +-----------------------------------------------------------------------------+\r\n> | Processes:                                                       GPU Memory |\r\n> |  GPU       PID  Type  Process name                               Usage      |\r\n> |=============================================================================|\r\n> |    0     24673    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |\r\n> |    1     16902    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |\r\n> |    2     27468    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |\r\n> |    3     11704    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |\r\n> |    4     13475    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |\r\n> |    5     16115    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |\r\n> |    6      2095    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |\r\n> |    7     23351    C   /homes/bjaros/sw/python2.7-bigml/bin/python  10959MiB |\r\n> +-----------------------------------------------------------------------------+", "comments": ["Searching through our issues points to some similar problems:\r\nhttps://github.com/NVIDIA/nvidia-docker/issues/262\r\n\r\nDid you try the recommendations there?"]}, {"number": 10145, "title": "local distributed tensorflow async btw graph multigpu example is extremely slow", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Not really, this primarily a copy and paste of the distributed tensorflow example\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.2 GPU\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 8.0\r\n- **GPU model and memory**: Titan X Pascal, 12G, 4 total\r\n- **Exact command to reproduce**:\r\n\r\n\r\n```bash\r\npython async_btwgraph_launcher.py\r\n```\r\nasync_btwgraph_launcher.py\r\n```python\r\nfrom async_btwgraph_dist_trainer import train\r\nimport os\r\nfrom multiprocessing import Process\r\nimport time\r\nfrom tensorflow.contrib.training import HParams\r\nimport tensorflow as tf\r\n# Set up configurations to sweep\r\noutput_dir ='tfprojects/output_dir_debug'\r\n\r\ncluster_spec ={\"ps\": [\"localhost:2227\"\r\n                      ],\r\n    \"worker\": [\r\n        \"localhost:2223\",\r\n        \"localhost:2224\",\r\n        \"localhost:2225\",\r\n        \"localhost:2226\"\r\n        ]\r\n    }\r\n\r\ncluster = tf.train.ClusterSpec(cluster_spec)\r\ndef worker(device):\r\n    params = HParams(cluster=cluster,\r\n                     job_name = device[0],\r\n                     task_index = device[1])\r\n\r\n    if device[0]=='worker':\r\n        # allow each worker to see only 1 of the 4 GPUS\r\n        os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(params.task_index)\r\n\r\n    else:\r\n        # hide all 4 GPUS from ps\r\n        os.environ[\"CUDA_VISIBLE_DEVICES\"]=''\r\n\r\n\r\n    train(output_dir, params)\r\n\r\nif __name__ == '__main__':\r\n    devices = [['ps',0],\r\n               ['worker',0],\r\n               ['worker',1],\r\n               ['worker',2],\r\n               ['worker',3]\r\n               ]\r\n\r\n    processes = []\r\n    for d in devices:\r\n\r\n        p = Process(target=worker, args=(d,))\r\n        p.start()\r\n        processes.append(p)\r\n\r\n    for p in processes:\r\n        p.join()\r\n```\r\nasync_btwgraph_dist_trainer.py\r\n```python\r\nimport os\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport time\r\n\r\ntf.logging.set_verbosity(tf.logging.INFO)  # enables training error print out during training\r\n\r\ndef model_fn(features,labels,mode,params):\r\n\r\n\r\n    outputs = layers.fully_connected(\r\n                    inputs = features,\r\n                    num_outputs = 4096)\r\n    outputs = layers.fully_connected(\r\n                    inputs = outputs,\r\n                    num_outputs = 4096)\r\n    outputs = layers.fully_connected(\r\n                    inputs = outputs,\r\n                    num_outputs = 256)\r\n\r\n    loss = tf.losses.mean_squared_error(outputs, labels)\r\n\r\n\r\n    train_op = tf.contrib.layers.optimize_loss(\r\n              loss, None, optimizer='Adam',\r\n                        learning_rate = .0001)\r\n\r\n\r\n    predictions = {\"predictions\":tf.identity(outputs,name = 'predictions')}\r\n    return predictions, loss, train_op\r\n\r\n\r\ndef dumb_input_fn():\r\n\r\n    x = tf.random_normal([128,256], dtype=tf.float32)\r\n    y = tf.random_normal([128,256], dtype=tf.float32)\r\n\r\n    return [x,y]\r\n\r\n#\r\ndef train(output_dir, params={}):\r\n    print('***JOBNAME**:',params.job_name)\r\n    cluster = params.cluster\r\n    job_name = params.job_name\r\n    task_index = params.task_index\r\n    gpu = task_index\r\n    # Create and start a server for the local task.\r\n    server = tf.train.Server(cluster,\r\n                           job_name=job_name,\r\n                           task_index=task_index)\r\n\r\n    if job_name == \"ps\":\r\n        server.join()\r\n    elif job_name == \"worker\":\r\n\r\n        # Assigns ops to the local worker by default.\r\n        with tf.device(tf.train.replica_device_setter(\r\n            worker_device=\"/job:worker/replica:0/task:%d\" % task_index,\r\n            cluster=cluster)):\r\n\r\n            # Build model...\r\n            x,y = dumb_input_fn()\r\n            _, _, train_op = model_fn(x,y,None,params)\r\n\r\n        global_step = tf.contrib.framework.get_or_create_global_step()\r\n        # The StopAtStepHook handles stopping after running given steps.\r\n        hooks=[tf.train.StopAtStepHook(last_step=100000)]\r\n\r\n        step = 0\r\n        start_time = time.time()\r\n\r\n        with tf.train.MonitoredTrainingSession(master=server.target,\r\n                                               is_chief=(task_index == 0),\r\n                                               checkpoint_dir=output_dir,\r\n                                               hooks=hooks) as mon_sess:\r\n            while not mon_sess.should_stop():\r\n\r\n                _ = mon_sess.run(train_op)\r\n\r\n                if step % 10 == 0:\r\n                    print(\"Step:\", step,10/(time.time()-start_time),'steps/sec')\r\n                    start_time = time.time()\r\n\r\n                step+=1\r\n\r\n```\r\n### Describe the problem\r\nI'm trying to use the distributed tensorflow [example](https://www.tensorflow.org/versions/r1.2/deploy/distributed) to do async between graph replication on a 4 Titan X machine, with 1 GPU per worker.  Without distributed TF and using a single GPU, the same code trains at ~150-200 steps/sec.  As shown at the end of the log below, this distributed trainer clocks at ~ 2 steps/sec.  The 4 GPUs are barely utilized,\r\n![image](https://cloud.githubusercontent.com/assets/15891975/26372649/9d8f25cc-3fcc-11e7-87f0-0be4b1a80fb6.png)\r\nwith plenty of  CPU headroom,\r\n![image](https://cloud.githubusercontent.com/assets/15891975/26372709/c4203ca8-3fcc-11e7-804f-5daa97bc5b70.png)\r\n\r\nAlso, if I simply remove the parameter server from this example, but keeping all 4 workers, they all grab GPU:0 maxing it out, and each worker process running at ~50steps/sec, and GPUs 1-3 are unused.\r\n![image](https://cloud.githubusercontent.com/assets/15891975/26373341/28da56e0-3fcf-11e7-87a7-db64dfac13e4.png)\r\nHowever, see that I'm setting os.environ[\"CUDA_VISIBLE_DEVICES\"] to enable only 1 unique GPU per worker.  \r\n\r\nIs this expected behavior?\r\nThanks,\r\nLuke \r\n\r\n### Source code / logs\r\n```bash\r\npython async_btwgraph_launcher.py\r\n***JOBNAME**: ps\r\n2017-05-23 15:06:16.761116: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-23 15:06:16.761187: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-23 15:06:16.761200: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-23 15:06:16.761212: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-23 15:06:16.761225: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n***JOBNAME**: worker\r\n2017-05-23 15:06:16.763172: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-23 15:06:16.763247: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-23 15:06:16.763259: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-23 15:06:16.763269: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-23 15:06:16.763280: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n***JOBNAME**: worker\r\n2017-05-23 15:06:16.765599: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-23 15:06:16.765671: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-23 15:06:16.765684: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-23 15:06:16.765693: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-23 15:06:16.765705: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n***JOBNAME**: worker\r\n2017-05-23 15:06:16.767881: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-23 15:06:16.767951: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-23 15:06:16.767983: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-23 15:06:16.768005: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-23 15:06:16.768024: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n***JOBNAME**: worker\r\n2017-05-23 15:06:16.771552: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-23 15:06:16.771617: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-23 15:06:16.771638: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-23 15:06:16.771649: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-23 15:06:16.771660: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-23 15:06:16.885876: E tensorflow/stream_executor/cuda/cuda_driver.cc:406] failed call to cuInit: CUDA_ERROR_NO_DEVICE\r\n2017-05-23 15:06:16.885946: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: mlearn2\r\n2017-05-23 15:06:16.885961: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: mlearn2\r\n2017-05-23 15:06:16.886027: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: 375.39.0\r\n2017-05-23 15:06:16.886800: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:369] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  375.39  Tue Jan 31 20:47:00 PST 2017\r\nGCC version:  gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.4)\r\n\"\"\"\r\n2017-05-23 15:06:16.886835: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 375.39.0\r\n2017-05-23 15:06:16.886848: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:300] kernel version seems to match DSO: 375.39.0\r\n2017-05-23 15:06:16.898031: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2227}\r\n2017-05-23 15:06:16.898063: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2223, 1 -> localhost:2224, 2 -> localhost:2225, 3 -> localhost:2226}\r\n2017-05-23 15:06:16.908193: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:2227\r\n2017-05-23 15:06:18.817380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] Found device 0 with properties:\r\nname: TITAN X (Pascal)\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.911\r\npciBusID 0000:02:00.0\r\nTotal memory: 11.90GiB\r\nFree memory: 11.60GiB\r\n2017-05-23 15:06:18.817433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:927] DMA: 0\r\n2017-05-23 15:06:18.817443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:937] 0:   Y\r\n2017-05-23 15:06:18.817581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:996] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:02:00.0)\r\n2017-05-23 15:06:18.859150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] Found device 0 with properties:\r\nname: TITAN X (Pascal)\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.911\r\npciBusID 0000:03:00.0\r\nTotal memory: 11.90GiB\r\nFree memory: 11.76GiB\r\n2017-05-23 15:06:18.859216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:927] DMA: 0\r\n2017-05-23 15:06:18.859227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:937] 0:   Y\r\n2017-05-23 15:06:18.859274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:996] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:03:00.0)\r\n2017-05-23 15:06:18.900436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] Found device 0 with properties:\r\nname: TITAN X (Pascal)\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.911\r\npciBusID 0000:81:00.0\r\nTotal memory: 11.90GiB\r\nFree memory: 11.76GiB\r\n2017-05-23 15:06:18.900506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:927] DMA: 0\r\n2017-05-23 15:06:18.900520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:937] 0:   Y\r\n2017-05-23 15:06:18.900562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:996] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:81:00.0)\r\n2017-05-23 15:06:18.922840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] Found device 0 with properties:\r\nname: TITAN X (Pascal)\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.911\r\npciBusID 0000:82:00.0\r\nTotal memory: 11.90GiB\r\nFree memory: 11.76GiB\r\n2017-05-23 15:06:18.922898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:927] DMA: 0\r\n2017-05-23 15:06:18.922913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:937] 0:   Y\r\n2017-05-23 15:06:18.922954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:996] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:82:00.0)\r\n2017-05-23 15:06:18.947847: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2227}\r\n2017-05-23 15:06:18.947913: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2223, 1 -> localhost:2224, 2 -> localhost:2225, 3 -> localhost:2226}\r\n2017-05-23 15:06:18.954688: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:2223\r\n2017-05-23 15:06:19.008071: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2227}\r\n2017-05-23 15:06:19.008132: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2223, 1 -> localhost:2224, 2 -> localhost:2225, 3 -> localhost:2226}\r\n2017-05-23 15:06:19.016316: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:2224\r\n2017-05-23 15:06:19.052548: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2227}\r\n2017-05-23 15:06:19.052589: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2223, 1 -> localhost:2224, 2 -> localhost:2225, 3 -> localhost:2226}\r\n2017-05-23 15:06:19.056154: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2227}\r\n2017-05-23 15:06:19.056176: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2223, 1 -> localhost:2224, 2 -> localhost:2225, 3 -> localhost:2226}\r\n2017-05-23 15:06:19.060973: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:2225\r\n2017-05-23 15:06:19.063039: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:2226\r\n2017-05-23 15:06:19.444002: I tensorflow/core/distributed_runtime/master_session.cc:999] Start master session 6bd586237b42120b with config:\r\n\r\n2017-05-23 15:06:19.458159: I tensorflow/core/distributed_runtime/master_session.cc:999] Start master session 924ffab74f941016 with config:\r\n\r\n2017-05-23 15:06:19.478740: I tensorflow/core/distributed_runtime/master_session.cc:999] Start master session c85138445cc12f91 with config:\r\n\r\n2017-05-23 15:06:19.481805: I tensorflow/core/distributed_runtime/master_session.cc:999] Start master session c77091e3456c2d32 with config:\r\n\r\nStep: 0 5.582075516520828 steps/sec\r\nStep: 10 2.1573368439379705 steps/sec\r\nStep: 20 2.2082990011777794 steps/sec\r\nStep: 30 2.1863694281593564 steps/sec\r\nStep: 40 2.254566631295363 steps/sec\r\nStep: 50 2.2088188362675036 steps/sec\r\nStep: 60 2.163473831162752 steps/sec\r\n2017-05-23 15:06:49.920556: I tensorflow/core/distributed_runtime/master_session.cc:999] Start master session 617cf268cb5a24e3 with config:\r\n\r\n2017-05-23 15:06:49.952686: I tensorflow/core/distributed_runtime/master_session.cc:999] Start master session 9b89c26b8c702b9f with config:\r\n\r\n2017-05-23 15:06:49.955667: I tensorflow/core/distributed_runtime/master_session.cc:999] Start master session b8d674f54212032f with config:\r\n\r\nStep: 0 0.30616911528363916 steps/sec\r\nStep: 0 0.30273764853875 steps/sec\r\nStep: 0 0.3023278973613949 steps/sec\r\nStep: 70 1.7908409267412564 steps/sec\r\nStep: 10 1.4149145268366454 steps/sec\r\nStep: 10 1.4475748080324984 steps/sec\r\nStep: 10 1.3904163169606496 steps/sec\r\nStep: 80 1.486386761414297 steps/sec\r\nStep: 20 1.4357212501056003 steps/sec\r\nStep: 20 1.4629177065889272 steps/sec\r\nStep: 20 1.4312276702523932 steps/sec\r\nStep: 90 1.4173087487398812 steps/sec\r\n```", "comments": ["Does the original example code work?", "well, the original example is incomplete, in the section\r\n``` # Build model...\r\n      loss = ...\r\n```\r\nbut, the only key difference I can tell is launching the processes with the multiprocessing module, instead of manually.  I wouldn't expect that to matter, but I'll double check.\r\n", "Ok, I've double checked, and as anticipated it makes no difference.  All 4 workers train at ~1.5steps/sec.  GPU/CPU utilization is the same as before (i.e. 0-5% per GPU at any give time).  This is 33x slower for me than just using a single GPU in the non-distributed setting.  \r\n\r\nSpecifically, I did away with async_btwgraph_launcher.py completely, and added the following to the end of async_btwgraph_dist_trainer.py:\r\n```python\r\nif __name__ == '__main__':\r\n    output_dir ='tfprojects/output_dir_debug'\r\n\r\n    cluster_spec ={\"ps\": [\"localhost:2227\",\r\n                                ],\r\n                \"worker\": [\r\n                    \"localhost:2223\",\r\n                    \"localhost:2224\",\r\n                    \"localhost:2225\",\r\n                    \"localhost:2226\"\r\n                    ]\r\n                }\r\n    cluster = tf.train.ClusterSpec(cluster_spec)\r\n    params = HParams(cluster=cluster,\r\n                     job_name = FLAGS.job_name,\r\n                     task_index = FLAGS.task_index)\r\n    if FLAGS.job_name=='worker':\r\n        # allow each worker to see only 1 of the 4 GPUS\r\n        os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(params.task_index)\r\n\r\n    else:\r\n        # hide all 4 GPUS from ps\r\n        os.environ[\"CUDA_VISIBLE_DEVICES\"]=''\r\n    train(output_dir, params)\r\n```\r\nAs in the online example, I then run these 5 commands, each one in a separate terminal session.\r\n```bash\r\npython async_btwgraph_dist_trainer.py --job_name=ps --task_index=0\r\n```\r\n\r\n```bash\r\npython async_btwgraph_dist_trainer.py --job_name=worker --task_index=0\r\n```\r\n\r\n```bash\r\npython async_btwgraph_dist_trainer.py --job_name=worker --task_index=1\r\n```\r\n\r\n```bash\r\npython async_btwgraph_dist_trainer.py --job_name=worker --task_index=2\r\n```\r\n\r\n```bash\r\npython async_btwgraph_dist_trainer.py --job_name=worker --task_index=3\r\n```", "Oh you're using multiprocessing. TensorFlow is not fork safe. However you can import tensorflow from the worker callback functions.", "@jart ,  thank you for the information.  However, I removed  multiprocessing completely in the example just above your most recent reply, but the issue still exists. \r\n\r\nCan you reopen this until it's resolved?\r\n\r\n", "Any updates/solutions? I am having a similar problem.", "As far as I know the bottleneck was inter-GPU bandwidth with very large models.  In the example I had hid the GPUs from the parameter server, and I later gained some speed increase by revealing them.   However, instead try a separate parameter server on each GPU that only sees that GPU , where each worker still sees only one GPU.  ", "@lw394 Do you have a working version of the script above that you were trying to run?", "@jppgks ,  I've used this testing for a 4 Titan X machine.  You can set --distributed=False to compare single GPU, non distributed performance.  With a smaller network, i.e. --hidden-units=128, I see some improvement with 4 GPUs vs 1.  With --hidden_units=2048,  4 gpus distributed is less than half the speed of just using one.  \r\n  \r\n```python\r\nfrom __future__ import division, absolute_import, print_function, unicode_literals\r\n\r\nimport os\r\nimport time\r\nfrom multiprocessing import Process\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib import layers\r\nfrom tensorflow import flags\r\n\r\ntf.logging.set_verbosity(tf.logging.INFO)\r\n\r\nflags.DEFINE_integer(\"hidden_units\", 256,\r\n                   \"number hidden units\")\r\nflags.DEFINE_integer(\"batch_size\", 128,\r\n                   \"batch size\")\r\nflags.DEFINE_bool(\"distributed\", True,\r\n                   \"set to False for not distributed\")\r\n\r\nflags.DEFINE_string(\"output_dir\",\"temp_dir\",'path to output_dir')\r\n\r\nFLAGS = tf.flags.FLAGS\r\n\r\nOUTPUT_DIM = 256\r\nINPUT_DIM = 256\r\n\r\ndef model_fn(features,labels):\r\n\r\n    outputs = tf.layers.dense(features,FLAGS.hidden_units)\r\n    outputs = tf.layers.dense(outputs,FLAGS.hidden_units)\r\n    outputs = tf.layers.dense(outputs,FLAGS.hidden_units)\r\n    outputs = tf.layers.dense(outputs,FLAGS.hidden_units)\r\n    outputs = tf.layers.dense(outputs,OUTPUT_DIM)\r\n\r\n    return outputs\r\n\r\n\r\n\r\ndef dumb_input_fn():\r\n\r\n    x = tf.random_normal([FLAGS.batch_size,INPUT_DIM], dtype=tf.float32)\r\n    y = tf.random_normal([FLAGS.batch_size,OUTPUT_DIM], dtype=tf.float32)\r\n\r\n    return [x,y]\r\n\r\n\r\ndef train(output_dir, dist_info={}):\r\n    \r\n    cluster = dist_info['cluster']\r\n    job_name = dist_info['job_name']\r\n    task_index = dist_info['task_index']\r\n\r\n    print('%s:%s'%(job_name,task_index))\r\n\r\n    # Create and start a server for the local task.\r\n    server = tf.train.Server(cluster,\r\n                           job_name=job_name,\r\n                           task_index=task_index)\r\n\r\n    if job_name == \"ps\":\r\n        server.join()\r\n    elif job_name == \"worker\":\r\n        with tf.device('/cpu:0'):\r\n            x,y = dumb_input_fn()\r\n        # Assigns ops to the local worker by default.\r\n        with tf.device(tf.train.replica_device_setter(\r\n            worker_device=\"/job:worker/task:%d\" % task_index,\r\n            cluster=cluster)):\r\n    \r\n            outputs = model_fn(x,y)\r\n            loss = tf.losses.mean_squared_error(outputs, y)\r\n     \r\n            train_op = tf.contrib.layers.optimize_loss(loss, None, optimizer='Adam',learning_rate = 1e-3)\r\n\r\n\r\n        global_step = tf.train.get_or_create_global_step()\r\n\t# session run hooks\r\n        hooks=[tf.train.StopAtStepHook(last_step=10000)]\r\n\r\n        config = tf.ConfigProto()\r\n        config.gpu_options.allow_growth = True\r\n        with tf.train.MonitoredTrainingSession(master=server.target,\r\n                                               is_chief=(task_index == 0),\r\n                                               checkpoint_dir=output_dir,\r\n                                               hooks=hooks,\r\n                                               config=config) as mon_sess:\r\n            step = 0\r\n            test_interval = 100\r\n            start_time = time.time()\r\n            while not mon_sess.should_stop():\r\n                \r\n                \r\n                _ = mon_sess.run(train_op)\r\n\r\n                if step > 0 and  step % test_interval == 0:\r\n                    print('Worker:',task_index,\"Step:\", step,test_interval/(time.time()-start_time),'steps/sec')\r\n                    start_time = time.time()\r\n\r\n                step+=1\r\n\r\ndef start_task(task_info):\r\n    job_name = task_info['job_name']\r\n    task_index = task_info['task_index']\r\n    if job_name=='worker':\r\n        # allow each worker to see only 1 of the 4 GPUS\r\n        os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(task_index)\r\n        \r\n    train(FLAGS.output_dir, task_info)\r\n\r\ndef main(argv=None):\r\n    if tf.gfile.Exists(FLAGS.output_dir):\r\n        tf.gfile.DeleteRecursively(FLAGS.output_dir)\r\n\r\n    if FLAGS.distributed:\r\n        tasks = [\r\n                ['ps',0],\r\n                ['worker',0],\r\n                ['worker',1],\r\n                ['worker',2],\r\n                ['worker',3]\r\n                ]\r\n        cluster_spec ={\"ps\": [\"localhost:2227\"],\r\n                        \"worker\": [\r\n                            \"localhost:2223\",\r\n                            \"localhost:2224\",\r\n                            \"localhost:2225\",\r\n                            \"localhost:2226\"\r\n                            ]\r\n                        }\r\n    else:\r\n        tasks = [['worker',0]]\r\n        cluster_spec ={\"worker\": [\"localhost:2223\"]}\r\n\r\n    cluster = tf.train.ClusterSpec(cluster_spec)\r\n    \r\n    processes = []\r\n    \r\n    for t in tasks:\r\n        task_info = {'cluster':cluster,\r\n                  'job_name':t[0],\r\n                  'task_index':t[1]}\r\n\r\n        p = Process(target=start_task, args=(task_info,))\r\n        p.start()\r\n        processes.append(p)\r\n    try:\r\n        for p in processes:\r\n            p.join()\r\n    except KeyboardInterrupt:\r\n        for p in processes:\r\n            p.terminate()\r\n\r\nif __name__ == '__main__':\r\n    tf.app.run()\r\n\r\n```"]}, {"number": 10144, "title": "Update RELEASE.md", "body": "Move savedmodel cli.", "comments": []}, {"number": 10143, "title": "RecordInput mini batches for dividing processing among multiple devices.", "body": "Adds one component of the [high performance models tensorflow benchmark](https://www.tensorflow.org/performance/performance_models) upstream so it is more readily available. This is based on the minibatch function in [preprocessing.py](https://github.com/tensorflow/benchmarks/blob/master/scripts/tf_cnn_benchmarks/preprocessing.py) in the example benchmark.\r\n\r\nI need to write a test, but wasn't sure if this is the right place to add this functionality to the API.", "comments": ["Can one of the admins verify this patch?", "Reassigning to @ekelsen, who added this code and is best placed to rule on API changes!", "@ekelsen tried incorporating some of those changes you suggested, guess there are also some conflicts to resolve", "@ekelsen where should a test go? There doesn't seem to be a `data_flow_ops_test.py`.\r\n\r\nI also realized that changing `batch_size` would break backwards compatibility, so I decided to just name the second parameter `batches`.", "found it https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/record_input_test.py", "sgtm", "@ekelsen ready for another review", "LGTM, thanks!", "Great! Do we need to @ mention a tensorflower for the final steps?", "Jenkins, test this please", "Jenkins, test this please.", "tests pass locally for me now, thanks for bearing with me as I figure out the workflow", "@ekelsen could you re-run the test?", "Jenkins, test this please.", "Jenkins, test this please.", "Broken Mac build rebuilt here: http://ci.tensorflow.org/job/tensorflow-pull-requests-mac/5319/console", "So you're saying the test passed? My local test was actually on OS X", "Yes, the test did pass.", "Awesome my first real code merged in TF :-) thanks!", "Oh wait I guess some code took the back door earlier via keras, but still good haha. ", "Thanks!\u200b\r\n", "I agree that stacking the full records probably doesn't make sense.\r\n\r\nCould maybe consider passing an optional function that turns records into something that can be stacked, and then stacking them?", "Seems like a technically sound strategy, but maybe there is an alternative that is more straightforward for users?\r\n\r\nI don't know the internals of `StagingArea` but perhaps feeding full records directly to that, pulling out the result, then returning might be enough so loading will be fast and users can do as they please with the returned results?\r\n\r\nPerhaps the easiest thing to do is I could add a comment recommending users just read the [high performance models guide](https://www.tensorflow.org/performance/performance_models) before using. :-)\r\n\r\n"]}, {"number": 10142, "title": "tf.nn.softmax overflow due to exp(x)", "body": "From reading the doc and code of ```tf.nn.softmax```, it looks like this function naively call a ```_softmax``` function which may have the overflow problem if the x in exp(x) is too big. (underflow can happen, too)\r\n\r\nThis is a typical problem of machine learning, and googling 'log sum exp' gives some information. TF even has a function ```reduce_logsumexp``` to calculate the value in a robust way. \r\n\r\nI think it makes sense that ```nn.softmax``` also use similar method of ```reduce_logsumexp```. I ran into a loss  = NaN today and suspect this is the cause. \r\n\r\nThanks,\r\n", "comments": ["I'm not so sure you can do the exact same thing. That method is taking into account that if you scale the computation based on the range of the existing values, you can exp and reduce (sum) in a space where there is more floating accuracy. You'd have to do that scaling and return the caling to the user. That would make for a complicated interface for users of tf.softmax.  As you say this is a known problem, which is why we have reduce_logsumexp (and softmax_cross_entropy_with_logit), but tf.nn.softmax may be useful in other situations. ", "note that softmax does subtract the maximum logit, so the max value it will exponentiate will be 0.  I don't think this is the cause of your NaN.  Without more information it's hard to say.", "This issue is automatically closed due to lack of activity. Please re-open if this is still an issue for you. Thanks!", "@ekelsen I read this statement also regarding other softmax functions such as tf.nn.sparse_softmax_cross_entropy_with_logits. However, I do have this issue. Using TFdebug I figured out that an nan value (inf) often results from the output of the softmax calculation done within sparse_softmax_... Shouldn't this be impossible using a max value subtraction?", "Another source of NaNs in sparse_softmax can be from passing in an int label that is >= than the number of dimensions in the logits. Hope that helps."]}, {"number": 10141, "title": "slim.batch_norm as normalizer_fn in tf.contrib.layers.fully_connected destroys network", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nMac OS X 10.12.4\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary, conda\r\n- **TensorFlow version (use command below)**:\r\n1.1.0\r\n- **Exact command to reproduce**:\r\n`net = layers.fully_connected(input_dim, dim, biases_initializer=tf.constant_initializer(0.1), activation_fn=None, normalizer_fn=tf.contrib.slim.batch_norm)`\r\n\r\n### Describe the problem\r\nAfter training a network without normalizer_fn set (or set to =False) and after trying to restore the network with incorrect setting of normalizer_fn, in my case with tf.contrib.slim.batch_norm, TensorFlow creates a new network structure with batch norms and completely annihilates the previously trained model and its structure, leaving the previously trained structure unavailable for restoring. There should be some way to restore previously trained models even after setting incorrect parameters. \r\n\r\n### Source code / logs\r\nFunction for creating a network given an initial \r\n```\r\nself.layers = [200, 100]\r\nself.embedding_size = 50\r\n    def dense_batchnorm_relu(self, dimensions, phase):\r\n        input_dim = self.query\r\n        for dim in dimensions:\r\n            print input_dim\r\n            net = layers.fully_connected(input_dim, dim, biases_initializer=tf.constant_initializer(0.1), activation_fn=None, normalizer_fn=tf.contrib.slim.batch_norm)\r\n            self.layers.append(net)\r\n            input_dim = net\r\n        net = layers.fully_connected(input_dim, self.embedding_size, biases_initializer=tf.constant_initializer(0.1), activation_fn=None)\r\n        self.layers.append(net)\r\n\r\nErrors:\r\n`\r\n\r\n2017-05-23 21:09:50.047879: W tensorflow/core/framework/op_kernel.cc:1152] Not found: Key fully_connected_1/biases not found in checkpoint\r\n2017-05-23 21:09:50.481725: W tensorflow/core/framework/op_kernel.cc:1152] Not found: Key fully_connected_1/weights not found in checkpoint\r\n\r\n....\r\nline 785, in restore\r\n    loader = tf.train.Saver()\r\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1056, in __init__\r\n    self.build()\r\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1086, in build\r\n    restore_sequentially=self._restore_sequentially)\r\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 691, in build\r\n    restore_sequentially, reshape)\r\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 407, in _AddRestoreOps\r\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\r\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 247, in restore_op\r\n    [spec.tensor.dtype])[0])\r\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 669, in restore_v2\r\n    dtypes=dtypes, name=name)\r\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\r\n    op_def=op_def)\r\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nNotFoundError (see above for traceback): Key fully_connected_1/biases not found in checkpoint\r\n\t [[Node: save/RestoreV2_6 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_6/tensor_names, save/RestoreV2_6/shape_and_slices)]]\r\n\r\n\r\n`\r\nEtc.", "comments": ["@sguada Would you mind taking a look at this?", "It is possible to restore the weights from a different model (what would happen when you add a normalization_fn) but it won't work well, since the activations would change and what it was learnt before would be useless.\r\n\r\nLook at this [notebook](https://github.com/tensorflow/models/blob/master/slim/slim_walkthrough.ipynb) on how you could assign the variables from a checkpoint, using \r\n\r\n`slim.assign_from_checkpoint_fn(model_path, var_list, ignore_missing_vars=True)`\r\n", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Closing due to inactivity. Please comment with new information and I will reopen.", "> It is possible to restore the weights from a different model (what would happen when you add a normalization_fn) but it won't work well, since the activations would change and what it was learnt before would be useless.\r\n> \r\n> Look at this [notebook](https://github.com/tensorflow/models/blob/master/slim/slim_walkthrough.ipynb) on how you could assign the variables from a checkpoint, using\r\n> \r\n> `slim.assign_from_checkpoint_fn(model_path, var_list, ignore_missing_vars=True)`\r\n\r\nHi, sguada @sguada    the link you provide is 404 now. Could you update it ?"]}, {"number": 10140, "title": "Cannot import tensorflow (python 3.5.2)", "body": "I downloaded the tensorflow pip, the cuda and the cudnn and installed all of them bu it still showing the same error.\r\n`import tensorflow\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 906, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<pyshell#0>\", line 1, in <module>\r\n    import tensorflow\r\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 51, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 52, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 906, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.`", "comments": ["I apologize but I am having a hard time understanding what the problem is, where the problem is, and what version it affects. Please resubmit and pay attention to the issue template (https://github.com/tensorflow/tensorflow/issues/new) . Please provide all the information it asks. Thank you."]}, {"number": 10139, "title": "Fixed deprecation warnings", "body": "Removed deprecation warnings for text classification example with CNN on words", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it", "CLAs look good, thanks!\n\n<!-- ok -->", "Jenkins test this please."]}, {"number": 10138, "title": "Fix spelling of Bahdanau in BahdanauAttention docstring", "body": "Looks like \"Bahdanau\" was mispelled in the docstring, this fixes it.", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Jenkins test this please.", "Failure not related to this typo fix."]}, {"number": 10137, "title": "ImportError after upgrading pandas to newest version", "body": "```python\r\nfrom tensorflow.contrib.learn.python.learn.learn_io import data_feeder\r\n```\r\n\r\nRaise error:\r\n```python\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-8-eae9a04c9717> in <module>()\r\n----> 1 from tensorflow.contrib.learn.python.learn.learn_io import data_feeder\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/__init__.py in <module>()\r\n     38 from tensorflow.contrib import labeled_tensor\r\n     39 from tensorflow.contrib import layers\r\n---> 40 from tensorflow.contrib import learn\r\n     41 from tensorflow.contrib import legacy_seq2seq\r\n     42 from tensorflow.contrib import linalg\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/__init__.py in <module>()\r\n     85 \r\n     86 # pylint: disable=wildcard-import\r\n---> 87 from tensorflow.contrib.learn.python.learn import *\r\n     88 # pylint: enable=wildcard-import\r\n     89 \r\n\r\n/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/__init__.py in <module>()\r\n     21 \r\n     22 # pylint: disable=wildcard-import\r\n---> 23 from tensorflow.contrib.learn.python.learn import *\r\n     24 # pylint: enable=wildcard-import\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/__init__.py in <module>()\r\n     23 from tensorflow.contrib.learn.python.learn import basic_session_run_hooks\r\n     24 from tensorflow.contrib.learn.python.learn import datasets\r\n---> 25 from tensorflow.contrib.learn.python.learn import estimators\r\n     26 from tensorflow.contrib.learn.python.learn import graph_actions\r\n     27 from tensorflow.contrib.learn.python.learn import learn_io as io\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/__init__.py in <module>()\r\n    295 from tensorflow.contrib.learn.python.learn.estimators._sklearn import NotFittedError\r\n    296 from tensorflow.contrib.learn.python.learn.estimators.constants import ProblemType\r\n--> 297 from tensorflow.contrib.learn.python.learn.estimators.dnn import DNNClassifier\r\n    298 from tensorflow.contrib.learn.python.learn.estimators.dnn import DNNEstimator\r\n    299 from tensorflow.contrib.learn.python.learn.estimators.dnn import DNNRegressor\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py in <module>()\r\n     27 from tensorflow.contrib.layers.python.layers import optimizers\r\n     28 from tensorflow.contrib.learn.python.learn import metric_spec\r\n---> 29 from tensorflow.contrib.learn.python.learn.estimators import dnn_linear_combined\r\n     30 from tensorflow.contrib.learn.python.learn.estimators import estimator\r\n     31 from tensorflow.contrib.learn.python.learn.estimators import head as head_lib\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py in <module>()\r\n     29 from tensorflow.contrib.layers.python.layers import optimizers\r\n     30 from tensorflow.contrib.learn.python.learn import metric_spec\r\n---> 31 from tensorflow.contrib.learn.python.learn.estimators import estimator\r\n     32 from tensorflow.contrib.learn.python.learn.estimators import head as head_lib\r\n     33 from tensorflow.contrib.learn.python.learn.estimators import model_fn\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py in <module>()\r\n     47 from tensorflow.contrib.learn.python.learn.estimators import tensor_signature\r\n     48 from tensorflow.contrib.learn.python.learn.estimators._sklearn import NotFittedError\r\n---> 49 from tensorflow.contrib.learn.python.learn.learn_io import data_feeder\r\n     50 from tensorflow.contrib.learn.python.learn.utils import export\r\n     51 from tensorflow.contrib.learn.python.learn.utils import saved_model_export_utils\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/learn_io/__init__.py in <module>()\r\n     19 from __future__ import print_function\r\n     20 \r\n---> 21 from tensorflow.contrib.learn.python.learn.learn_io.dask_io import extract_dask_data\r\n     22 from tensorflow.contrib.learn.python.learn.learn_io.dask_io import extract_dask_labels\r\n     23 from tensorflow.contrib.learn.python.learn.learn_io.dask_io import HAS_DASK\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/learn_io/dask_io.py in <module>()\r\n     24 try:\r\n     25   # pylint: disable=g-import-not-at-top\r\n---> 26   import dask.dataframe as dd\r\n     27   allowed_classes = (dd.Series, dd.DataFrame)\r\n     28   HAS_DASK = True\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/dask/dataframe/__init__.py in <module>()\r\n----> 1 from .core import (DataFrame, Series, Index, _Frame, map_partitions,\r\n      2                    repartition)\r\n      3 from .io import (from_array, from_bcolz, from_array, from_bcolz,\r\n      4                  from_pandas, from_dask_array, from_castra, read_hdf,\r\n      5                  from_imperative, from_delayed)\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/dask/dataframe/core.py in <module>()\r\n     35 return_scalar = '__return_scalar__'\r\n     36 \r\n---> 37 pd.computation.expressions.set_use_numexpr(False)\r\n     38 \r\n     39 \r\n\r\nAttributeError: module 'pandas' has no attribute 'computation'\r\n```", "comments": ["upgrade dask solved the problem."]}, {"number": 10136, "title": "Add SMAPE(symmetric mean absolute percentage error) loss function. ", "body": "Add SMAPE(symmetric mean absolute percentage error) loss function. The existing MAPE has the disadvantage that they put a heavier penalty on positive errors than on negative errors. SMAPE can mitigate this the uneven penalty.", "comments": ["Can one of the admins verify this patch?", "This also shouldn't be on the 1.1 branch, but I'll let Francois comment first.", "We won't merge:\r\n\r\n- Not common enough to become part of the core codebase\r\n- Would introduce an API discrepancy with the reference Keras API"]}, {"number": 10135, "title": "pip default installs TF1.1 still. On purpose?", "body": "On both my Windows 10 and Ubuntu 16.10 instances, trying to upgrade with pip still installs 1.1 even though 1.2.0rc0 is quite clearly available there. On ubuntu I managed to get it by forcing the version. Wondering if this is intentional?\r\n\r\nNote: Will check again that this is the case on Windows still as it was yesterday. ", "comments": ["yes, this behavior is normal. RC versions = release candidate and thus are not officially released yet to PyPI.", "Ok well that makes perfect sense. Considering I know what a release candidate is i'm annoyed my brain didn't make that connection. It's been a very very slow day in the office today.\r\n\r\nThanks @nelson-liu . Closing."]}, {"number": 10134, "title": "C++ Tensor's Slice assignment works unexpectedly when using GPU", "body": "### System information\r\n\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: \r\n  Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: \r\n  Linux 3.16.0-4-amd64 #1 SMP Debian 3.16.7-ckt20-1+deb8u2 (2016-01-02) x86_64 GNU/Linux\r\n- **TensorFlow installed from (source or binary)**:\r\n  binary\r\n- **TensorFlow version (use command below)**:\r\n  tensorflow-gpu (1.1.0rc2)\r\n- **Bazel version (if compiling from source)**:\r\n  None\r\n- **CUDA/cuDNN version**:\r\n  cuda 8.0\r\n- **GPU model and memory**:\r\n  GeForce GTX 1080 8110Mb\r\n- **Exact command to reproduce**:\r\n  See below.\r\n\r\n### Describe the problem\r\n\r\n`tensorflow::Tensor::Slice` returns another `tensorflow::Tensor` , which is the slice of the original `Tensor` in the first dimension,  but if you assign a slice to another when writing operation with `GPUDevice` , it seems to fail to work like expected,\r\n\r\nIn gist below I write a simple operation which set the output as the same value of input, by setting each slice of output in the first dimension to be the same of input. When registered only CPUKernel, this op works well, but when registered only GPUKernel, it gives some random values I had no idea with.\r\n\r\nI use `g++ -std=c++11 -shared -o CopyByBatchOp.so CopyByBatchOp.cc -I $TF_INC -fPIC -lcudart -L $CUDA_HOME/lib64 -D GOOGLE_CUDA=1 -Wfatal-e\r\nrrors -I $CUDA_HOME/include -D_GLIBCXX_USE_CXX11_ABI=0` to compile the operation, for both GPU version and CPU version.\r\n\r\nAfter compiling, I use `test_op = tf.load_op_library('CopyByBatchOp.so')` in Python to load it. A simple test script is included in gist below.\r\n\r\n\r\n\r\nFYI, I've been looking for a way to assign a slice of one tensor to another slice for a long time, Eigen tensors works well by `      output.slice(start, size).device(d) = input.slice(start, size);` with `d` as some `CPUDevice`, but somehow breakdown when I use a `GPUDevice`, could not figure out why since I don't know how to debug it. I guess maybe the two problems are relevant.\r\n\r\n### Source code / logs\r\n\r\n[gist](https://gist.github.com/Zardinality/616137e6edc309af57a3cbbb5032d848)", "comments": ["I think there is a bug in your code. \r\n\r\nhttps://gist.github.com/Zardinality/616137e6edc309af57a3cbbb5032d848\r\noutput_tensor->Slice(i, i+1) = input_tensor.Slice(i, i+1);\r\n\r\nBoth on CPU and GPU, this doesn't do anything, it just makes a temporary Tensor relinquish its ownership and points to another Tensor, and be released immediately afterwards. \r\n\r\nIf you switch to Eigen on GPU, you need to make sure the pointers are indeed GPU pointers. Otherwise, you get bad pointer acccess. \r\n", "Well, I remember back then I write a simple script that call slice on both sides of equal sign to convince myself this works, don't know how I got it worked out. As for the slice assignment problem, I've tackled it through assignment per element in a cuda kernel. Hope this helpful for other people who are possibly puzzled on same problem."]}]