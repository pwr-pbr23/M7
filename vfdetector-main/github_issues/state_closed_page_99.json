[{"number": 52155, "title": "Building failure of libtensorflowlite_gpu_delegate.so", "body": "\r\n\r\n**System information**\r\n- OS Platform and Distribution: Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.6.0\r\n- Bazel version (if compiling from source): 3.7.2\r\n- GCC/Compiler version (if compiling from source): 9.3.0\r\n\r\n\r\n**Describe the problem**\r\nBuilding libtensorflowlite_gpu_delegate.so fails complaining about `absl::Status`.\r\nHowever building libtensorflowlite_c.so works well (using `bazel build -c opt tensorflow/lite/c:libtensorflowlite_c.so`)\r\n\r\nUsing lastest or v2.5.0 also fails.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\ngit clone https://github.com/tensorflow/tensorflow -b v2.6.0   \r\ncd tensorflow  \r\nbazel build -c opt tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so\r\n```\r\n\r\n**Any other info / logs**\r\n\r\n```\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=201\r\nINFO: Reading rc options for 'build' from /home/michel/gin-tflite/tensorflow/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /home/michel/gin-tflite/tensorflow/.bazelrc:\r\n  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true\r\nINFO: Found applicable config definition build:short_logs in file /home/michel/gin-tflite/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /home/michel/gin-tflite/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:linux in file /home/michel/gin-tflite/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false\r\nINFO: Found applicable config definition build:dynamic_kernels in file /home/michel/gin-tflite/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS\r\nDEBUG: /home/michel/.cache/bazel/_bazel_michel/2729c94059558bc79129827a71924973/external/tf_runtime/third_party/cuda/dependencies.bzl:51:10: The following command will download NVIDIA proprietary software. By using the software you agree to comply with the terms of the license agreement that accompanies the software. If you do not agree to the terms of the license agreement, do not use the software.\r\nDEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = \"1556410077 -0400\"\r\nDEBUG: Repository io_bazel_rules_docker instantiated at:\r\n  /home/michel/gin-tflite/tensorflow/WORKSPACE:23:14: in <toplevel>\r\n  /home/michel/gin-tflite/tensorflow/tensorflow/workspace0.bzl:108:34: in workspace\r\n  /home/michel/.cache/bazel/_bazel_michel/2729c94059558bc79129827a71924973/external/bazel_toolchains/repositories/repositories.bzl:37:23: in repositories\r\nRepository rule git_repository defined at:\r\n  /home/michel/.cache/bazel/_bazel_michel/2729c94059558bc79129827a71924973/external/bazel_tools/tools/build_defs/repo/git.bzl:199:33: in <toplevel>\r\nINFO: Analyzed target //tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so (0 packages loaded, 0 targets configured).\r\nINFO: Found 1 target...\r\nERROR: /home/michel/gin-tflite/tensorflow/tensorflow/lite/delegates/gpu/gl/BUILD:48:11: C++ compilation of rule '//tensorflow/lite/delegates/gpu/gl:api2' failed (Exit 1): gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections ... (remaining 43 argument(s) skipped)\r\nIn file included from external/opencl_headers/CL/cl.h:32,\r\n                 from ./tensorflow/lite/delegates/gpu/api.h:42,\r\n                 from ./tensorflow/lite/delegates/gpu/gl/api2.h:23,\r\n                 from tensorflow/lite/delegates/gpu/gl/api2.cc:16:\r\nexternal/opencl_headers/CL/cl_version.h:34:104: note: #pragma message: cl_version.h: CL_TARGET_OPENCL_VERSION is not defined. Defaulting to 220 (OpenCL 2.2)\r\n   34 | #pragma message(\"cl_version.h: CL_TARGET_OPENCL_VERSION is not defined. Defaulting to 220 (OpenCL 2.2)\")\r\n      |                                                                                                        ^\r\nIn file included from /usr/include/EGL/eglplatform.h:128,\r\n                 from /usr/include/EGL/egl.h:39,\r\n                 from ./tensorflow/lite/delegates/gpu/gl/portable_gl31.h:21,\r\n                 from ./tensorflow/lite/delegates/gpu/api.h:50,\r\n                 from ./tensorflow/lite/delegates/gpu/gl/api2.h:23,\r\n                 from tensorflow/lite/delegates/gpu/gl/api2.cc:16:\r\n./tensorflow/lite/delegates/gpu/api.h:261:17: error: expected unqualified-id before 'int'\r\n  261 |   virtual absl::Status SetInputShape(int index,\r\n      |                 ^~~~~~\r\n./tensorflow/lite/delegates/gpu/api.h:271:17: error: expected unqualified-id before 'int'\r\n  271 |   virtual absl::Status SetInputObjectDef(int index, ObjectDef def) = 0;\r\n      |                 ^~~~~~\r\n./tensorflow/lite/delegates/gpu/api.h:272:17: error: expected unqualified-id before 'int'\r\n  272 |   virtual absl::Status SetOutputObjectDef(int index, ObjectDef def) = 0;\r\n      |                 ^~~~~~\r\n./tensorflow/lite/delegates/gpu/api.h:273:17: error: expected unqualified-id before 'int'\r\n  273 |   virtual absl::Status SetAllInputObjectDefsTo(ObjectDef def) {\r\n      |                 ^~~~~~\r\n```\r\n", "comments": ["@mpromonet Could you please have a look at the similar issue [link1,](https://github.com/tensorflow/tensorflow/issues/44926) [link2](https://stackoverflow.com/questions/63438024/using-tensorflow-lite-gpu-delegate-in-androids-native-environment-with-c-api) and let us know if it helps ?Thanks!", "Hi sushreebarsa,\r\n\r\nI read these before writing this issue, may you clarify what can helps.\r\nFrom https://github.com/tensorflow/tensorflow/issues/44926 I tried `bazel build -c opt  --copt -Os --copt -DTFLITE_GPU_BINARY_RELEASE --copt -s --strip always tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so`, the build error seems the same.\r\n\r\nBest Regards,\r\nMichel.", "@mpromonet What do you want? libtensorflowlite_gpu_delegate.so for your machine running Ubuntu 20.04 or or Android platform. \r\n\r\nFor the latter case, please run `./configure` and set Android NDK and SDK paths.\r\nFor the former one, I guess it's not supported and well-tested. Messages like\r\n```\r\n./tensorflow/lite/delegates/gpu/api.h:261:17: error: expected unqualified-id before 'int'\r\n  261 |   virtual absl::Status SetInputShape(int index,\r\n      |                 ^~~~~~\r\n./tensorflow/lite/delegates/gpu/api.h:271:17: error: expected unqualified-id before 'int'\r\n  271 |   virtual absl::Status SetInputObjectDef(int index, ObjectDef def) = 0;\r\n      |                 ^~~~~~\r\n```\r\nare because of something like `#define Status int` in `X11/Xlib.h`", "Hi freedomtan,\r\n\r\nThanks for your answer, I was trying to build tensorflow lite with gpu support for running it on Ubuntu20.04 not for Android.\r\nIt seems the `#define Status int` in `X11/Xlib.h` brings conflict, I tried to put some `#undef Status` build is continuing, but raise others problems with eigen.\r\n\r\nBest Regards,\r\nMichel.", "Depending on the platform, you may have to define `MESA_EGL_NO_X11_HEADERS` and/or `EGL_NO_X11` which don't include the X11 headers that @freedomtan mentioned above.  Depending on the version of the header file, it may be named slightly differently, so you need to dig into your EGL header files a little bit.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52155\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52155\">No</a>\n", "Hi,\r\n\r\nThanks, I confirm it is building on Ubuntu:20.04 using : \r\n```\r\nbazel build -c opt tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so --copt -DEGL_NO_X11=1\r\n```\r\n\r\nBest Regards,\r\nMichel.\r\n"]}, {"number": 52154, "title": "Tensorflow fails to build on Fedora ppc64le", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Fedora 34 ppcle64\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.4.3\r\n- Python version: 3.9.7\r\n- Installed using virtualenv? pip? conda?: source\r\n- Bazel version (if compiling from source): 3.1.0\r\n- GCC/Compiler version (if compiling from source): gcc 11.2.1\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nI installed all the dependencies that I knew about (eigen3, protobuf*, pip, bazel, etc.) and I get a lengthy build error\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n`bazel build --config=opt tensorflow:libtensorflow.so`\r\n\r\n**Any other info / logs**\r\nThe build error:\r\nhttps://paste.centos.org/view/11a395f2\r\n\r\n```\r\n  exec env - \\\r\n    PATH=/home/bkeys/Devel/Software/bazel/output/:/home/bkeys/.local/bin:/home/bkeys/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/bin/python3 \\\r\n    PYTHON_LIB_PATH=/usr/lib/python3.9/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n  /bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/ppc-opt/bin/tensorflow/compiler/xla/service/cpu/_objs/runtime_single_threaded_conv2d/runtime_single_threaded_conv2d.pic.d '-frandom-seed=bazel-out/ppc-opt/bin/tensorflow/compiler/xla/service/cpu/_objs/runtime_single_threaded_conv2d/runtime_single_threaded_conv2d.pic.o' -fPIC -D__CLANG_SUPPORT_DYN_ANNOTATION__ -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -iquote . -iquote bazel-out/ppc-opt/bin -iquote external/com_google_absl -iquote bazel-out/ppc-opt/bin/external/com_google_absl -iquote external/eigen_archive -iquote bazel-out/ppc-opt/bin/external/eigen_archive -isystem external/eigen_archive -isystem bazel-out/ppc-opt/bin/external/eigen_archive -w -DAUTOLOAD_DYNAMIC_KERNELS '-mcpu=native' '-std=c++14' -DEIGEN_AVOID_STL_ARRAY -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc -o bazel-out/ppc-opt/bin/tensorflow/compiler/xla/service/cpu/_objs/runtime_single_threaded_conv2d/runtime_single_threaded_conv2d.pic.o)\r\nExecution platform: @local_execution_config_platform//:platform\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:110,\r\n                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_conv2d_impl.h:18,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:18:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h: In instantiation of 'void Eigen::internal::TensorContractionKernel<ResScalar, LhsScalar, RhsScalar, StorageIndex, OutputMapper, LhsMapper, RhsMapper>::packRhs(RhsScalar**, const typename RhsMapper::SubMapper&, StorageIndex, StorageIndex) [with ResScalar = float; LhsScalar = float; RhsScalar = float; StorageIndex = long int; OutputMapper = Eigen::internal::blas_data_mapper<float, long int, 0, 0, 1>; LhsMapper = Eigen::internal::TensorContractionInputMapper<float, long int, 1, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>; RhsMapper = Eigen::internal::TensorContractionInputMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, true, 0, Eigen::MakePointer>; Eigen::internal::TensorContractionKernel<ResScalar, LhsScalar, RhsScalar, StorageIndex, OutputMapper, LhsMapper, RhsMapper>::RhsBlock = float*; typename RhsMapper::SubMapper = Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, true, 0, Eigen::MakePointer>]':\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:890:25:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalGemmPartial(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*, Eigen::TensorContractionEvaluatorBase<Derived>::Index, Eigen::TensorContractionEvaluatorBase<Derived>::Index, int) const [with bool lhs_inner_dim_contiguous = true; bool rhs_inner_dim_contiguous = true; bool rhs_inner_dim_reordered = true; int Alignment = 0; bool use_output_kernel = true; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float; Eigen::TensorContractionEvaluatorBase<Derived>::Index = long int]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:783:52:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalGemm(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*) const [with bool lhs_inner_dim_contiguous = true; bool rhs_inner_dim_contiguous = true; bool rhs_inner_dim_reordered = true; int Alignment = 0; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:720:66:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalProductSequential(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*) const [with bool lhs_inner_dim_contiguous = true; bool rhs_inner_dim_contiguous = true; bool rhs_inner_dim_reordered = true; int Alignment = 0; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:1015:5:   required from 'void Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::evalProduct(Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::Scalar*) const [with int Alignment = 0; Indices = const Eigen::array<Eigen::IndexPair<long long int>, 1>; LeftArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >; RightArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >; OutputKernelType = const Eigen::NoOpOutputKernel; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::Scalar = float]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:699:70:   [ skipping 2 instantiation contexts, use -ftemplate-backtrace-limit=0 to disable ]\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorMorphing.h:180:39:   required from 'bool Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::evalSubExprsIfNeeded(Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::EvaluatorPointerType) [with NewDimensions = const Eigen::DSizes<long long int, 4>; ArgType = const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::EvaluatorPointerType = float*]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorAssign.h:152:44:   required from 'bool Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::evalSubExprsIfNeeded(Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::EvaluatorPointerType) [with LeftArgType = Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer>; RightArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel> >; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::EvaluatorPointerType = float*]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h:131:61:   required from 'static void Eigen::internal::TensorExecutor<Expression, Eigen::DefaultDevice, true, Eigen::internal::Off>::run(const Expression&, const Eigen::DefaultDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel> > >]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDevice.h:35:62:   required from 'Eigen::TensorDevice<ExpressionType, DeviceType>& Eigen::TensorDevice<ExpressionType, DeviceType>::operator=(const OtherDerived&) [with OtherDerived = Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel> >; ExpressionType = Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer>; DeviceType = Eigen::DefaultDevice]'\r\n./tensorflow/compiler/xla/service/cpu/runtime_conv2d_impl.h:79:25:   required from 'void tensorflow::xla::EigenConvImpl(const EigenDevice&, ScalarType*, ScalarType*, ScalarType*, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index) [with EigenDevice = Eigen::DefaultDevice; ScalarType = float; Eigen::Index = long int]'\r\ntensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:57:33:   required from here\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:248:5: error: ambiguous template instantiation for 'struct Eigen::internal::gemm_pack_rhs<float, long int, Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, true, 0, Eigen::MakePointer>, 4, 0, false, false>'\r\n  248 |     RhsPacker()(*rhsBlock, data_mapper, depth, cols);\r\n      |     ^~~~~~~~~~~\r\nIn file included from external/eigen_archive/Eigen/Core:319,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.h:19,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:16:\r\nexternal/eigen_archive/Eigen/src/Core/products/GeneralBlockPanelKernel.h:2551:8: note: candidates are: 'template<class Scalar, class Index, class DataMapper, int nr, bool Conjugate, bool PanelMode> struct Eigen::internal::gemm_pack_rhs<Scalar, Index, DataMapper, nr, 0, Conjugate, PanelMode> [with Scalar = float; Index = long int; DataMapper = Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, true, 0, Eigen::MakePointer>; int nr = 4; bool Conjugate = false; bool PanelMode = false]'\r\n 2551 | struct gemm_pack_rhs<Scalar, Index, DataMapper, nr, ColMajor, Conjugate, PanelMode>\r\n      |        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nIn file included from external/eigen_archive/Eigen/Core:339,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.h:19,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:16:\r\nexternal/eigen_archive/Eigen/src/Core/arch/AltiVec/MatrixProduct.h:2691:8: note:                 'template<class Index, class DataMapper, int nr, bool Conjugate, bool PanelMode> struct Eigen::internal::gemm_pack_rhs<float, Index, DataMapper, nr, 0, Conjugate, PanelMode> [with Index = long int; DataMapper = Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, true, 0, Eigen::MakePointer>; int nr = 4; bool Conjugate = false; bool PanelMode = false]'\r\n 2691 | struct gemm_pack_rhs<float, Index, DataMapper, nr, ColMajor, Conjugate, PanelMode>\r\n      |        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nIn file included from ./tensorflow/core/kernels/eigen_spatial_convolutions.h:23,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_conv2d_impl.h:19,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:18:\r\n./tensorflow/core/kernels/eigen_spatial_convolutions-inl.h:1044:8: note:                 'template<class NewDimension, long int Rows, long int Cols, class ArgType, class Device, class Scalar, class Index, class nocontract_t, class contract_t, int packet_size, bool inner_dim_contiguous, bool inner_dim_reordered, int Alignment, int nr> struct Eigen::internal::gemm_pack_rhs<Scalar, Index, Eigen::internal::TensorContractionSubMapper<Scalar, Index, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimension, const Eigen::TensorImagePatchOp<Rows, Cols, ArgType> >, Device>, nocontract_t, contract_t, packet_size, inner_dim_contiguous, inner_dim_reordered, Alignment>, nr, 0, false, false> [with NewDimension = const Eigen::DSizes<long long int, 2>; long int Rows = -1; long int Cols = -1; ArgType = const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer>; Device = Eigen::DefaultDevice; Scalar = float; Index = long int; nocontract_t = Eigen::array<long int, 1>; contract_t = Eigen::array<long int, 1>; int packet_size = 4; bool inner_dim_contiguous = true; bool inner_dim_reordered = true; int Alignment = 0; int nr = 4]'\r\n 1044 | struct gemm_pack_rhs<\r\n      |        ^~~~~~~~~~~~~~\r\n 1045 |     Scalar, Index,\r\n      |     ~~~~~~~~~~~~~~\r\n 1046 |     TensorContractionSubMapper<\r\n      |     ~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n 1047 |         Scalar, Index, Rhs,\r\n      |         ~~~~~~~~~~~~~~~~~~~\r\n 1048 |         TensorEvaluator<\r\n      |         ~~~~~~~~~~~~~~~~\r\n 1049 |             const TensorReshapingOp<\r\n      |             ~~~~~~~~~~~~~~~~~~~~~~~~\r\n 1050 |                 NewDimension, const TensorImagePatchOp<Rows, Cols, ArgType> >,\r\n      |                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n 1051 |             Device>,\r\n      |             ~~~~~~~~\r\n 1052 |         nocontract_t, contract_t, packet_size, inner_dim_contiguous,\r\n      |         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n 1053 |         inner_dim_reordered, Alignment>,\r\n      |         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n 1054 |     nr, ColMajor, false, false> {\r\n      |     ~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:110,\r\n                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_conv2d_impl.h:18,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:18:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:248:5: error: invalid use of incomplete type 'Eigen::internal::TensorContractionKernel<float, float, float, long int, Eigen::internal::blas_data_mapper<float, long int, 0, 0, 1>, Eigen::internal::TensorContractionInputMapper<float, long int, 1, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, true, 0, Eigen::MakePointer> >::RhsPacker' {aka 'struct Eigen::internal::gemm_pack_rhs<float, long int, Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, true, 0, Eigen::MakePointer>, 4, 0, false, false>'}\r\n  248 |     RhsPacker()(*rhsBlock, data_mapper, depth, cols);\r\n      |     ^~~~~~~~~~~\r\nIn file included from external/eigen_archive/Eigen/Core:275,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.h:19,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:16:\r\nexternal/eigen_archive/Eigen/src/Core/util/BlasUtil.h:25:8: note: declaration of 'Eigen::internal::TensorContractionKernel<float, float, float, long int, Eigen::internal::blas_data_mapper<float, long int, 0, 0, 1>, Eigen::internal::TensorContractionInputMapper<float, long int, 1, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, true, 0, Eigen::MakePointer> >::RhsPacker' {aka 'struct Eigen::internal::gemm_pack_rhs<float, long int, Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, true, 0, Eigen::MakePointer>, 4, 0, false, false>'}\r\n   25 | struct gemm_pack_rhs;\r\n      |        ^~~~~~~~~~~~~\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:110,\r\n                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_conv2d_impl.h:18,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:18:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h: In instantiation of 'void Eigen::internal::TensorContractionKernel<ResScalar, LhsScalar, RhsScalar, StorageIndex, OutputMapper, LhsMapper, RhsMapper>::packRhs(RhsScalar**, const typename RhsMapper::SubMapper&, StorageIndex, StorageIndex) [with ResScalar = float; LhsScalar = float; RhsScalar = float; StorageIndex = long int; OutputMapper = Eigen::internal::blas_data_mapper<float, long int, 0, 0, 1>; LhsMapper = Eigen::internal::TensorContractionInputMapper<float, long int, 1, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>; RhsMapper = Eigen::internal::TensorContractionInputMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>; Eigen::internal::TensorContractionKernel<ResScalar, LhsScalar, RhsScalar, StorageIndex, OutputMapper, LhsMapper, RhsMapper>::RhsBlock = float*; typename RhsMapper::SubMapper = Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>]':\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:890:25:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalGemmPartial(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*, Eigen::TensorContractionEvaluatorBase<Derived>::Index, Eigen::TensorContractionEvaluatorBase<Derived>::Index, int) const [with bool lhs_inner_dim_contiguous = true; bool rhs_inner_dim_contiguous = true; bool rhs_inner_dim_reordered = false; int Alignment = 0; bool use_output_kernel = true; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float; Eigen::TensorContractionEvaluatorBase<Derived>::Index = long int]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:783:52:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalGemm(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*) const [with bool lhs_inner_dim_contiguous = true; bool rhs_inner_dim_contiguous = true; bool rhs_inner_dim_reordered = false; int Alignment = 0; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:720:66:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalProductSequential(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*) const [with bool lhs_inner_dim_contiguous = true; bool rhs_inner_dim_contiguous = true; bool rhs_inner_dim_reordered = false; int Alignment = 0; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:1015:5:   required from 'void Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::evalProduct(Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::Scalar*) const [with int Alignment = 0; Indices = const Eigen::array<Eigen::IndexPair<long long int>, 1>; LeftArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >; RightArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >; OutputKernelType = const Eigen::NoOpOutputKernel; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::Scalar = float]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:699:70:   [ skipping 2 instantiation contexts, use -ftemplate-backtrace-limit=0 to disable ]\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorMorphing.h:180:39:   required from 'bool Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::evalSubExprsIfNeeded(Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::EvaluatorPointerType) [with NewDimensions = const Eigen::DSizes<long long int, 4>; ArgType = const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::EvaluatorPointerType = float*]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorAssign.h:152:44:   required from 'bool Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::evalSubExprsIfNeeded(Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::EvaluatorPointerType) [with LeftArgType = Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer>; RightArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel> >; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::EvaluatorPointerType = float*]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h:131:61:   required from 'static void Eigen::internal::TensorExecutor<Expression, Eigen::DefaultDevice, true, Eigen::internal::Off>::run(const Expression&, const Eigen::DefaultDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel> > >]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDevice.h:35:62:   required from 'Eigen::TensorDevice<ExpressionType, DeviceType>& Eigen::TensorDevice<ExpressionType, DeviceType>::operator=(const OtherDerived&) [with OtherDerived = Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel> >; ExpressionType = Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer>; DeviceType = Eigen::DefaultDevice]'\r\n./tensorflow/compiler/xla/service/cpu/runtime_conv2d_impl.h:79:25:   required from 'void tensorflow::xla::EigenConvImpl(const EigenDevice&, ScalarType*, ScalarType*, ScalarType*, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index) [with EigenDevice = Eigen::DefaultDevice; ScalarType = float; Eigen::Index = long int]'\r\ntensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:57:33:   required from here\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:248:5: error: ambiguous template instantiation for 'struct Eigen::internal::gemm_pack_rhs<float, long int, Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>, 4, 0, false, false>'\r\n  248 |     RhsPacker()(*rhsBlock, data_mapper, depth, cols);\r\n      |     ^~~~~~~~~~~\r\nIn file included from external/eigen_archive/Eigen/Core:319,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.h:19,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:16:\r\nexternal/eigen_archive/Eigen/src/Core/products/GeneralBlockPanelKernel.h:2551:8: note: candidates are: 'template<class Scalar, class Index, class DataMapper, int nr, bool Conjugate, bool PanelMode> struct Eigen::internal::gemm_pack_rhs<Scalar, Index, DataMapper, nr, 0, Conjugate, PanelMode> [with Scalar = float; Index = long int; DataMapper = Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>; int nr = 4; bool Conjugate = false; bool PanelMode = false]'\r\n 2551 | struct gemm_pack_rhs<Scalar, Index, DataMapper, nr, ColMajor, Conjugate, PanelMode>\r\n      |        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nIn file included from external/eigen_archive/Eigen/Core:339,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.h:19,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:16:\r\nexternal/eigen_archive/Eigen/src/Core/arch/AltiVec/MatrixProduct.h:2691:8: note:                 'template<class Index, class DataMapper, int nr, bool Conjugate, bool PanelMode> struct Eigen::internal::gemm_pack_rhs<float, Index, DataMapper, nr, 0, Conjugate, PanelMode> [with Index = long int; DataMapper = Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>; int nr = 4; bool Conjugate = false; bool PanelMode = false]'\r\n 2691 | struct gemm_pack_rhs<float, Index, DataMapper, nr, ColMajor, Conjugate, PanelMode>\r\n      |        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nIn file included from ./tensorflow/core/kernels/eigen_spatial_convolutions.h:23,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_conv2d_impl.h:19,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:18:\r\n./tensorflow/core/kernels/eigen_spatial_convolutions-inl.h:1044:8: note:                 'template<class NewDimension, long int Rows, long int Cols, class ArgType, class Device, class Scalar, class Index, class nocontract_t, class contract_t, int packet_size, bool inner_dim_contiguous, bool inner_dim_reordered, int Alignment, int nr> struct Eigen::internal::gemm_pack_rhs<Scalar, Index, Eigen::internal::TensorContractionSubMapper<Scalar, Index, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimension, const Eigen::TensorImagePatchOp<Rows, Cols, ArgType> >, Device>, nocontract_t, contract_t, packet_size, inner_dim_contiguous, inner_dim_reordered, Alignment>, nr, 0, false, false> [with NewDimension = const Eigen::DSizes<long long int, 2>; long int Rows = -1; long int Cols = -1; ArgType = const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer>; Device = Eigen::DefaultDevice; Scalar = float; Index = long int; nocontract_t = Eigen::array<long int, 1>; contract_t = Eigen::array<long int, 1>; int packet_size = 4; bool inner_dim_contiguous = true; bool inner_dim_reordered = false; int Alignment = 0; int nr = 4]'\r\n 1044 | struct gemm_pack_rhs<\r\n      |        ^~~~~~~~~~~~~~\r\n 1045 |     Scalar, Index,\r\n      |     ~~~~~~~~~~~~~~\r\n 1046 |     TensorContractionSubMapper<\r\n      |     ~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n 1047 |         Scalar, Index, Rhs,\r\n      |         ~~~~~~~~~~~~~~~~~~~\r\n 1048 |         TensorEvaluator<\r\n      |         ~~~~~~~~~~~~~~~~\r\n 1049 |             const TensorReshapingOp<\r\n      |             ~~~~~~~~~~~~~~~~~~~~~~~~\r\n 1050 |                 NewDimension, const TensorImagePatchOp<Rows, Cols, ArgType> >,\r\n      |                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n 1051 |             Device>,\r\n      |             ~~~~~~~~\r\n 1052 |         nocontract_t, contract_t, packet_size, inner_dim_contiguous,\r\n      |         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n 1053 |         inner_dim_reordered, Alignment>,\r\n      |         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n 1054 |     nr, ColMajor, false, false> {\r\n      |     ~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:110,\r\n                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_conv2d_impl.h:18,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:18:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:248:5: error: invalid use of incomplete type 'Eigen::internal::TensorContractionKernel<float, float, float, long int, Eigen::internal::blas_data_mapper<float, long int, 0, 0, 1>, Eigen::internal::TensorContractionInputMapper<float, long int, 1, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer> >::RhsPacker' {aka 'struct Eigen::internal::gemm_pack_rhs<float, long int, Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>, 4, 0, false, false>'}\r\n  248 |     RhsPacker()(*rhsBlock, data_mapper, depth, cols);\r\n      |     ^~~~~~~~~~~\r\nIn file included from external/eigen_archive/Eigen/Core:275,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.h:19,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:16:\r\nexternal/eigen_archive/Eigen/src/Core/util/BlasUtil.h:25:8: note: declaration of 'Eigen::internal::TensorContractionKernel<float, float, float, long int, Eigen::internal::blas_data_mapper<float, long int, 0, 0, 1>, Eigen::internal::TensorContractionInputMapper<float, long int, 1, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer> >::RhsPacker' {aka 'struct Eigen::internal::gemm_pack_rhs<float, long int, Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>, 4, 0, false, false>'}\r\n   25 | struct gemm_pack_rhs;\r\n      |        ^~~~~~~~~~~~~\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:110,\r\n                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_conv2d_impl.h:18,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:18:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h: In instantiation of 'void Eigen::internal::TensorContractionKernel<ResScalar, LhsScalar, RhsScalar, StorageIndex, OutputMapper, LhsMapper, RhsMapper>::packRhs(RhsScalar**, const typename RhsMapper::SubMapper&, StorageIndex, StorageIndex) [with ResScalar = float; LhsScalar = float; RhsScalar = float; StorageIndex = long int; OutputMapper = Eigen::internal::blas_data_mapper<float, long int, 0, 0, 1>; LhsMapper = Eigen::internal::TensorContractionInputMapper<float, long int, 1, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>; RhsMapper = Eigen::internal::TensorContractionInputMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, true, 0, Eigen::MakePointer>; Eigen::internal::TensorContractionKernel<ResScalar, LhsScalar, RhsScalar, StorageIndex, OutputMapper, LhsMapper, RhsMapper>::RhsBlock = float*; typename RhsMapper::SubMapper = Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, true, 0, Eigen::MakePointer>]':\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:890:25:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalGemmPartial(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*, Eigen::TensorContractionEvaluatorBase<Derived>::Index, Eigen::TensorContractionEvaluatorBase<Derived>::Index, int) const [with bool lhs_inner_dim_contiguous = true; bool rhs_inner_dim_contiguous = false; bool rhs_inner_dim_reordered = true; int Alignment = 0; bool use_output_kernel = true; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float; Eigen::TensorContractionEvaluatorBase<Derived>::Index = long int]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:783:52:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalGemm(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*) const [with bool lhs_inner_dim_contiguous = true; bool rhs_inner_dim_contiguous = false; bool rhs_inner_dim_reordered = true; int Alignment = 0; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:720:66:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalProductSequential(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*) const [with bool lhs_inner_dim_contiguous = true; bool rhs_inner_dim_contiguous = false; bool rhs_inner_dim_reordered = true; int Alignment = 0; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:1015:5:   required from 'void Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::evalProduct(Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::Scalar*) const [with int Alignment = 0; Indices = const Eigen::array<Eigen::IndexPair<long long int>, 1>; LeftArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >; RightArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >; OutputKernelType = const Eigen::NoOpOutputKernel; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::Scalar = float]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:699:70:   [ skipping 2 instantiation contexts, use -ftemplate-backtrace-limit=0 to disable ]\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorMorphing.h:180:39:   required from 'bool Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::evalSubExprsIfNeeded(Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::EvaluatorPointerType) [with NewDimensions = const Eigen::DSizes<long long int, 4>; ArgType = const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::EvaluatorPointerType = float*]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorAssign.h:152:44:   required from 'bool Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::evalSubExprsIfNeeded(Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::EvaluatorPointerType) [with LeftArgType = Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer>; RightArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel> >; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::EvaluatorPointerType = float*]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h:131:61:   required from 'static void Eigen::internal::TensorExecutor<Expression, Eigen::DefaultDevice, true, Eigen::internal::Off>::run(const Expression&, const Eigen::DefaultDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel> > >]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDevice.h:35:62:   required from 'Eigen::TensorDevice<ExpressionType, DeviceType>& Eigen::TensorDevice<ExpressionType, DeviceType>::operator=(const OtherDerived&) [with OtherDerived = Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel> >; ExpressionType = Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer>; DeviceType = Eigen::DefaultDevice]'\r\n./tensorflow/compiler/xla/service/cpu/runtime_conv2d_impl.h:79:25:   required from 'void tensorflow::xla::EigenConvImpl(const EigenDevice&, ScalarType*, ScalarType*, ScalarType*, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index) [with EigenDevice = Eigen::DefaultDevice; ScalarType = float; Eigen::Index = long int]'\r\ntensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:57:33:   required from here\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:248:5: error: ambiguous template instantiation for 'struct Eigen::internal::gemm_pack_rhs<float, long int, Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, true, 0, Eigen::MakePointer>, 4, 0, false, false>'\r\n  248 |     RhsPacker()(*rhsBlock, data_mapper, depth, cols);\r\n      |     ^~~~~~~~~~~\r\nIn file included from external/eigen_archive/Eigen/Core:319,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.h:19,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:16:\r\nexternal/eigen_archive/Eigen/src/Core/products/GeneralBlockPanelKernel.h:2551:8: note: candidates are: 'template<class Scalar, class Index, class DataMapper, int nr, bool Conjugate, bool PanelMode> struct Eigen::internal::gemm_pack_rhs<Scalar, Index, DataMapper, nr, 0, Conjugate, PanelMode> [with Scalar = float; Index = long int; DataMapper = Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, true, 0, Eigen::MakePointer>; int nr = 4; bool Conjugate = false; bool PanelMode = false]'\r\n 2551 | struct gemm_pack_rhs<Scalar, Index, DataMapper, nr, ColMajor, Conjugate, PanelMode>\r\n      |        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nIn file included from external/eigen_archive/Eigen/Core:339,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.h:19,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:16:\r\nexternal/eigen_archive/Eigen/src/Core/arch/AltiVec/MatrixProduct.h:2691:8: note:                 'template<class Index, class DataMapper, int nr, bool Conjugate, bool PanelMode> struct Eigen::internal::gemm_pack_rhs<float, Index, DataMapper, nr, 0, Conjugate, PanelMode> [with Index = long int; DataMapper = Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, true, 0, Eigen::MakePointer>; int nr = 4; bool Conjugate = false; bool PanelMode = false]'\r\n 2691 | struct gemm_pack_rhs<float, Index, DataMapper, nr, ColMajor, Conjugate, PanelMode>\r\n      |        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nIn file included from ./tensorflow/core/kernels/eigen_spatial_convolutions.h:23,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_conv2d_impl.h:19,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:18:\r\n./tensorflow/core/kernels/eigen_spatial_convolutions-inl.h:1044:8: note:                 'template<class NewDimension, long int Rows, long int Cols, class ArgType, class Device, class Scalar, class Index, class nocontract_t, class contract_t, int packet_size, bool inner_dim_contiguous, bool inner_dim_reordered, int Alignment, int nr> struct Eigen::internal::gemm_pack_rhs<Scalar, Index, Eigen::internal::TensorContractionSubMapper<Scalar, Index, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimension, const Eigen::TensorImagePatchOp<Rows, Cols, ArgType> >, Device>, nocontract_t, contract_t, packet_size, inner_dim_contiguous, inner_dim_reordered, Alignment>, nr, 0, false, false> [with NewDimension = const Eigen::DSizes<long long int, 2>; long int Rows = -1; long int Cols = -1; ArgType = const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer>; Device = Eigen::DefaultDevice; Scalar = float; Index = long int; nocontract_t = Eigen::array<long int, 1>; contract_t = Eigen::array<long int, 1>; int packet_size = 4; bool inner_dim_contiguous = false; bool inner_dim_reordered = true; int Alignment = 0; int nr = 4]'\r\n 1044 | struct gemm_pack_rhs<\r\n      |        ^~~~~~~~~~~~~~\r\n 1045 |     Scalar, Index,\r\n      |     ~~~~~~~~~~~~~~\r\n 1046 |     TensorContractionSubMapper<\r\n      |     ~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n 1047 |         Scalar, Index, Rhs,\r\n      |         ~~~~~~~~~~~~~~~~~~~\r\n 1048 |         TensorEvaluator<\r\n      |         ~~~~~~~~~~~~~~~~\r\n 1049 |             const TensorReshapingOp<\r\n      |             ~~~~~~~~~~~~~~~~~~~~~~~~\r\n 1050 |                 NewDimension, const TensorImagePatchOp<Rows, Cols, ArgType> >,\r\n      |                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n 1051 |             Device>,\r\n      |             ~~~~~~~~\r\n 1052 |         nocontract_t, contract_t, packet_size, inner_dim_contiguous,\r\n      |         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n 1053 |         inner_dim_reordered, Alignment>,\r\n      |         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n 1054 |     nr, ColMajor, false, false> {\r\n      |     ~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:110,\r\n                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_conv2d_impl.h:18,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:18:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:248:5: error: invalid use of incomplete type 'Eigen::internal::TensorContractionKernel<float, float, float, long int, Eigen::internal::blas_data_mapper<float, long int, 0, 0, 1>, Eigen::internal::TensorContractionInputMapper<float, long int, 1, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, true, 0, Eigen::MakePointer> >::RhsPacker' {aka 'struct Eigen::internal::gemm_pack_rhs<float, long int, Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, true, 0, Eigen::MakePointer>, 4, 0, false, false>'}\r\n  248 |     RhsPacker()(*rhsBlock, data_mapper, depth, cols);\r\n      |     ^~~~~~~~~~~\r\nIn file included from external/eigen_archive/Eigen/Core:275,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.h:19,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:16:\r\nexternal/eigen_archive/Eigen/src/Core/util/BlasUtil.h:25:8: note: declaration of 'Eigen::internal::TensorContractionKernel<float, float, float, long int, Eigen::internal::blas_data_mapper<float, long int, 0, 0, 1>, Eigen::internal::TensorContractionInputMapper<float, long int, 1, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, true, 0, Eigen::MakePointer> >::RhsPacker' {aka 'struct Eigen::internal::gemm_pack_rhs<float, long int, Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, true, 0, Eigen::MakePointer>, 4, 0, false, false>'}\r\n   25 | struct gemm_pack_rhs;\r\n      |        ^~~~~~~~~~~~~\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:110,\r\n                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_conv2d_impl.h:18,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:18:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h: In instantiation of 'void Eigen::internal::TensorContractionKernel<ResScalar, LhsScalar, RhsScalar, StorageIndex, OutputMapper, LhsMapper, RhsMapper>::packRhs(RhsScalar**, const typename RhsMapper::SubMapper&, StorageIndex, StorageIndex) [with ResScalar = float; LhsScalar = float; RhsScalar = float; StorageIndex = long int; OutputMapper = Eigen::internal::blas_data_mapper<float, long int, 0, 0, 1>; LhsMapper = Eigen::internal::TensorContractionInputMapper<float, long int, 1, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>; RhsMapper = Eigen::internal::TensorContractionInputMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer>; Eigen::internal::TensorContractionKernel<ResScalar, LhsScalar, RhsScalar, StorageIndex, OutputMapper, LhsMapper, RhsMapper>::RhsBlock = float*; typename RhsMapper::SubMapper = Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer>]':\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:890:25:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalGemmPartial(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*, Eigen::TensorContractionEvaluatorBase<Derived>::Index, Eigen::TensorContractionEvaluatorBase<Derived>::Index, int) const [with bool lhs_inner_dim_contiguous = true; bool rhs_inner_dim_contiguous = false; bool rhs_inner_dim_reordered = false; int Alignment = 0; bool use_output_kernel = true; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float; Eigen::TensorContractionEvaluatorBase<Derived>::Index = long int]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:783:52:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalGemm(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*) const [with bool lhs_inner_dim_contiguous = true; bool rhs_inner_dim_contiguous = false; bool rhs_inner_dim_reordered = false; int Alignment = 0; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:720:66:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalProductSequential(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*) const [with bool lhs_inner_dim_contiguous = true; bool rhs_inner_dim_contiguous = false; bool rhs_inner_dim_reordered = false; int Alignment = 0; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:1015:5:   required from 'void Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::evalProduct(Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::Scalar*) const [with int Alignment = 0; Indices = const Eigen::array<Eigen::IndexPair<long long int>, 1>; LeftArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >; RightArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >; OutputKernelType = const Eigen::NoOpOutputKernel; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::Scalar = float]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:699:70:   [ skipping 2 instantiation contexts, use -ftemplate-backtrace-limit=0 to disable ]\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorMorphing.h:180:39:   required from 'bool Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::evalSubExprsIfNeeded(Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::EvaluatorPointerType) [with NewDimensions = const Eigen::DSizes<long long int, 4>; ArgType = const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::EvaluatorPointerType = float*]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorAssign.h:152:44:   required from 'bool Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::evalSubExprsIfNeeded(Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::EvaluatorPointerType) [with LeftArgType = Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer>; RightArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel> >; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::EvaluatorPointerType = float*]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h:131:61:   required from 'static void Eigen::internal::TensorExecutor<Expression, Eigen::DefaultDevice, true, Eigen::internal::Off>::run(const Expression&, const Eigen::DefaultDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel> > >]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDevice.h:35:62:   required from 'Eigen::TensorDevice<ExpressionType, DeviceType>& Eigen::TensorDevice<ExpressionType, DeviceType>::operator=(const OtherDerived&) [with OtherDerived = Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel> >; ExpressionType = Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer>; DeviceType = Eigen::DefaultDevice]'\r\n./tensorflow/compiler/xla/service/cpu/runtime_conv2d_impl.h:79:25:   required from 'void tensorflow::xla::EigenConvImpl(const EigenDevice&, ScalarType*, ScalarType*, ScalarType*, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index) [with EigenDevice = Eigen::DefaultDevice; ScalarType = float; Eigen::Index = long int]'\r\ntensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:57:33:   required from here\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:248:5: error: ambiguous template instantiation for 'struct Eigen::internal::gemm_pack_rhs<float, long int, Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer>, 4, 0, false, false>'\r\n  248 |     RhsPacker()(*rhsBlock, data_mapper, depth, cols);\r\n      |     ^~~~~~~~~~~\r\nIn file included from external/eigen_archive/Eigen/Core:319,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.h:19,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:16:\r\nexternal/eigen_archive/Eigen/src/Core/products/GeneralBlockPanelKernel.h:2551:8: note: candidates are: 'template<class Scalar, class Index, class DataMapper, int nr, bool Conjugate, bool PanelMode> struct Eigen::internal::gemm_pack_rhs<Scalar, Index, DataMapper, nr, 0, Conjugate, PanelMode> [with Scalar = float; Index = long int; DataMapper = Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer>; int nr = 4; bool Conjugate = false; bool PanelMode = false]'\r\n 2551 | struct gemm_pack_rhs<Scalar, Index, DataMapper, nr, ColMajor, Conjugate, PanelMode>\r\n      |        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nIn file included from external/eigen_archive/Eigen/Core:339,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.h:19,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:16:\r\nexternal/eigen_archive/Eigen/src/Core/arch/AltiVec/MatrixProduct.h:2691:8: note:                 'template<class Index, class DataMapper, int nr, bool Conjugate, bool PanelMode> struct Eigen::internal::gemm_pack_rhs<float, Index, DataMapper, nr, 0, Conjugate, PanelMode> [with Index = long int; DataMapper = Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer>; int nr = 4; bool Conjugate = false; bool PanelMode = false]'\r\n 2691 | struct gemm_pack_rhs<float, Index, DataMapper, nr, ColMajor, Conjugate, PanelMode>\r\n      |        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nIn file included from ./tensorflow/core/kernels/eigen_spatial_convolutions.h:23,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_conv2d_impl.h:19,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:18:\r\n./tensorflow/core/kernels/eigen_spatial_convolutions-inl.h:1044:8: note:                 'template<class NewDimension, long int Rows, long int Cols, class ArgType, class Device, class Scalar, class Index, class nocontract_t, class contract_t, int packet_size, bool inner_dim_contiguous, bool inner_dim_reordered, int Alignment, int nr> struct Eigen::internal::gemm_pack_rhs<Scalar, Index, Eigen::internal::TensorContractionSubMapper<Scalar, Index, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimension, const Eigen::TensorImagePatchOp<Rows, Cols, ArgType> >, Device>, nocontract_t, contract_t, packet_size, inner_dim_contiguous, inner_dim_reordered, Alignment>, nr, 0, false, false> [with NewDimension = const Eigen::DSizes<long long int, 2>; long int Rows = -1; long int Cols = -1; ArgType = const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer>; Device = Eigen::DefaultDevice; Scalar = float; Index = long int; nocontract_t = Eigen::array<long int, 1>; contract_t = Eigen::array<long int, 1>; int packet_size = 4; bool inner_dim_contiguous = false; bool inner_dim_reordered = false; int Alignment = 0; int nr = 4]'\r\n 1044 | struct gemm_pack_rhs<\r\n      |        ^~~~~~~~~~~~~~\r\n 1045 |     Scalar, Index,\r\n      |     ~~~~~~~~~~~~~~\r\n 1046 |     TensorContractionSubMapper<\r\n      |     ~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n 1047 |         Scalar, Index, Rhs,\r\n      |         ~~~~~~~~~~~~~~~~~~~\r\n 1048 |         TensorEvaluator<\r\n      |         ~~~~~~~~~~~~~~~~\r\n 1049 |             const TensorReshapingOp<\r\n      |             ~~~~~~~~~~~~~~~~~~~~~~~~\r\n 1050 |                 NewDimension, const TensorImagePatchOp<Rows, Cols, ArgType> >,\r\n      |                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n 1051 |             Device>,\r\n      |             ~~~~~~~~\r\n 1052 |         nocontract_t, contract_t, packet_size, inner_dim_contiguous,\r\n      |         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n 1053 |         inner_dim_reordered, Alignment>,\r\n      |         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n 1054 |     nr, ColMajor, false, false> {\r\n      |     ~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:110,\r\n                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_conv2d_impl.h:18,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:18:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:248:5: error: invalid use of incomplete type 'Eigen::internal::TensorContractionKernel<float, float, float, long int, Eigen::internal::blas_data_mapper<float, long int, 0, 0, 1>, Eigen::internal::TensorContractionInputMapper<float, long int, 1, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer> >::RhsPacker' {aka 'struct Eigen::internal::gemm_pack_rhs<float, long int, Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer>, 4, 0, false, false>'}\r\n  248 |     RhsPacker()(*rhsBlock, data_mapper, depth, cols);\r\n      |     ^~~~~~~~~~~\r\nIn file included from external/eigen_archive/Eigen/Core:275,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.h:19,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:16:\r\nexternal/eigen_archive/Eigen/src/Core/util/BlasUtil.h:25:8: note: declaration of 'Eigen::internal::TensorContractionKernel<float, float, float, long int, Eigen::internal::blas_data_mapper<float, long int, 0, 0, 1>, Eigen::internal::TensorContractionInputMapper<float, long int, 1, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer> >::RhsPacker' {aka 'struct Eigen::internal::gemm_pack_rhs<float, long int, Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer>, 4, 0, false, false>'}\r\n   25 | struct gemm_pack_rhs;\r\n      |        ^~~~~~~~~~~~~\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:110,\r\n                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_conv2d_impl.h:18,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:18:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h: In instantiation of 'void Eigen::internal::TensorContractionKernel<ResScalar, LhsScalar, RhsScalar, StorageIndex, OutputMapper, LhsMapper, RhsMapper>::packRhs(RhsScalar**, const typename RhsMapper::SubMapper&, StorageIndex, StorageIndex) [with ResScalar = float; LhsScalar = float; RhsScalar = float; StorageIndex = long int; OutputMapper = Eigen::internal::blas_data_mapper<float, long int, 0, 0, 1>; LhsMapper = Eigen::internal::TensorContractionInputMapper<float, long int, 1, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer>; RhsMapper = Eigen::internal::TensorContractionInputMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, true, 0, Eigen::MakePointer>; Eigen::internal::TensorContractionKernel<ResScalar, LhsScalar, RhsScalar, StorageIndex, OutputMapper, LhsMapper, RhsMapper>::RhsBlock = float*; typename RhsMapper::SubMapper = Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, true, 0, Eigen::MakePointer>]':\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:890:25:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalGemmPartial(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*, Eigen::TensorContractionEvaluatorBase<Derived>::Index, Eigen::TensorContractionEvaluatorBase<Derived>::Index, int) const [with bool lhs_inner_dim_contiguous = false; bool rhs_inner_dim_contiguous = true; bool rhs_inner_dim_reordered = true; int Alignment = 0; bool use_output_kernel = true; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float; Eigen::TensorContractionEvaluatorBase<Derived>::Index = long int]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:783:52:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalGemm(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*) const [with bool lhs_inner_dim_contiguous = false; bool rhs_inner_dim_contiguous = true; bool rhs_inner_dim_reordered = true; int Alignment = 0; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:720:66:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalProductSequential(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*) const [with bool lhs_inner_dim_contiguous = false; bool rhs_inner_dim_contiguous = true; bool rhs_inner_dim_reordered = true; int Alignment = 0; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:1015:5:   required from 'void Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::evalProduct(Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::Scalar*) const [with int Alignment = 0; Indices = const Eigen::array<Eigen::IndexPair<long long int>, 1>; LeftArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >; RightArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >; OutputKernelType = const Eigen::NoOpOutputKernel; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::Scalar = float]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:699:70:   [ skipping 2 instantiation contexts, use -ftemplate-backtrace-limit=0 to disable ]\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorMorphing.h:180:39:   required from 'bool Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::evalSubExprsIfNeeded(Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::EvaluatorPointerType) [with NewDimensions = const Eigen::DSizes<long long int, 4>; ArgType = const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::EvaluatorPointerType = float*]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorAssign.h:152:44:   required from 'bool Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::evalSubExprsIfNeeded(Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::EvaluatorPointerType) [with LeftArgType = Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer>; RightArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel> >; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::EvaluatorPointerType = float*]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h:131:61:   required from 'static void Eigen::internal::TensorExecutor<Expression, Eigen::DefaultDevice, true, Eigen::internal::Off>::run(const Expression&, const Eigen::DefaultDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel> > >]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDevice.h:35:62:   required from 'Eigen::TensorDevice<ExpressionType, DeviceType>& Eigen::TensorDevice<ExpressionType, DeviceType>::operator=(const OtherDerived&) [with OtherDerived = Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel> >; ExpressionType = Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer>; DeviceType = Eigen::DefaultDevice]'\r\n./tensorflow/compiler/xla/service/cpu/runtime_conv2d_impl.h:79:25:   required from 'void tensorflow::xla::EigenConvImpl(const EigenDevice&, ScalarType*, ScalarType*, ScalarType*, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index) [with EigenDevice = Eigen::DefaultDevice; ScalarType = float; Eigen::Index = long int]'\r\ntensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:57:33:   required from here\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:248:5: error: invalid use of incomplete type 'Eigen::internal::TensorContractionKernel<float, float, float, long int, Eigen::internal::blas_data_mapper<float, long int, 0, 0, 1>, Eigen::internal::TensorContractionInputMapper<float, long int, 1, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, true, 0, Eigen::MakePointer> >::RhsPacker' {aka 'struct Eigen::internal::gemm_pack_rhs<float, long int, Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, true, 0, Eigen::MakePointer>, 4, 0, false, false>'}\r\n  248 |     RhsPacker()(*rhsBlock, data_mapper, depth, cols);\r\n      |     ^~~~~~~~~~~\r\nIn file included from external/eigen_archive/Eigen/Core:275,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.h:19,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:16:\r\nexternal/eigen_archive/Eigen/src/Core/util/BlasUtil.h:25:8: note: declaration of 'Eigen::internal::TensorContractionKernel<float, float, float, long int, Eigen::internal::blas_data_mapper<float, long int, 0, 0, 1>, Eigen::internal::TensorContractionInputMapper<float, long int, 1, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, true, 0, Eigen::MakePointer> >::RhsPacker' {aka 'struct Eigen::internal::gemm_pack_rhs<float, long int, Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, true, 0, Eigen::MakePointer>, 4, 0, false, false>'}\r\n   25 | struct gemm_pack_rhs;\r\n      |        ^~~~~~~~~~~~~\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:110,\r\n                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_conv2d_impl.h:18,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:18:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h: In instantiation of 'void Eigen::internal::TensorContractionKernel<ResScalar, LhsScalar, RhsScalar, StorageIndex, OutputMapper, LhsMapper, RhsMapper>::packRhs(RhsScalar**, const typename RhsMapper::SubMapper&, StorageIndex, StorageIndex) [with ResScalar = float; LhsScalar = float; RhsScalar = float; StorageIndex = long int; OutputMapper = Eigen::internal::blas_data_mapper<float, long int, 0, 0, 1>; LhsMapper = Eigen::internal::TensorContractionInputMapper<float, long int, 1, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer>; RhsMapper = Eigen::internal::TensorContractionInputMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>; Eigen::internal::TensorContractionKernel<ResScalar, LhsScalar, RhsScalar, StorageIndex, OutputMapper, LhsMapper, RhsMapper>::RhsBlock = float*; typename RhsMapper::SubMapper = Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>]':\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:890:25:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalGemmPartial(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*, Eigen::TensorContractionEvaluatorBase<Derived>::Index, Eigen::TensorContractionEvaluatorBase<Derived>::Index, int) const [with bool lhs_inner_dim_contiguous = false; bool rhs_inner_dim_contiguous = true; bool rhs_inner_dim_reordered = false; int Alignment = 0; bool use_output_kernel = true; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float; Eigen::TensorContractionEvaluatorBase<Derived>::Index = long int]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:783:52:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalGemm(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*) const [with bool lhs_inner_dim_contiguous = false; bool rhs_inner_dim_contiguous = true; bool rhs_inner_dim_reordered = false; int Alignment = 0; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:720:66:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalProductSequential(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*) const [with bool lhs_inner_dim_contiguous = false; bool rhs_inner_dim_contiguous = true; bool rhs_inner_dim_reordered = false; int Alignment = 0; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:1015:5:   required from 'void Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::evalProduct(Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::Scalar*) const [with int Alignment = 0; Indices = const Eigen::array<Eigen::IndexPair<long long int>, 1>; LeftArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >; RightArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >; OutputKernelType = const Eigen::NoOpOutputKernel; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::Scalar = float]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:699:70:   [ skipping 2 instantiation contexts, use -ftemplate-backtrace-limit=0 to disable ]\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorMorphing.h:180:39:   required from 'bool Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::evalSubExprsIfNeeded(Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::EvaluatorPointerType) [with NewDimensions = const Eigen::DSizes<long long int, 4>; ArgType = const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::EvaluatorPointerType = float*]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorAssign.h:152:44:   required from 'bool Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::evalSubExprsIfNeeded(Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::EvaluatorPointerType) [with LeftArgType = Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer>; RightArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel> >; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::EvaluatorPointerType = float*]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h:131:61:   required from 'static void Eigen::internal::TensorExecutor<Expression, Eigen::DefaultDevice, true, Eigen::internal::Off>::run(const Expression&, const Eigen::DefaultDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel> > >]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDevice.h:35:62:   required from 'Eigen::TensorDevice<ExpressionType, DeviceType>& Eigen::TensorDevice<ExpressionType, DeviceType>::operator=(const OtherDerived&) [with OtherDerived = Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel> >; ExpressionType = Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer>; DeviceType = Eigen::DefaultDevice]'\r\n./tensorflow/compiler/xla/service/cpu/runtime_conv2d_impl.h:79:25:   required from 'void tensorflow::xla::EigenConvImpl(const EigenDevice&, ScalarType*, ScalarType*, ScalarType*, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index) [with EigenDevice = Eigen::DefaultDevice; ScalarType = float; Eigen::Index = long int]'\r\ntensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:57:33:   required from here\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:248:5: error: invalid use of incomplete type 'Eigen::internal::TensorContractionKernel<float, float, float, long int, Eigen::internal::blas_data_mapper<float, long int, 0, 0, 1>, Eigen::internal::TensorContractionInputMapper<float, long int, 1, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer> >::RhsPacker' {aka 'struct Eigen::internal::gemm_pack_rhs<float, long int, Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>, 4, 0, false, false>'}\r\n  248 |     RhsPacker()(*rhsBlock, data_mapper, depth, cols);\r\n      |     ^~~~~~~~~~~\r\nIn file included from external/eigen_archive/Eigen/Core:275,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.h:19,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:16:\r\nexternal/eigen_archive/Eigen/src/Core/util/BlasUtil.h:25:8: note: declaration of 'Eigen::internal::TensorContractionKernel<float, float, float, long int, Eigen::internal::blas_data_mapper<float, long int, 0, 0, 1>, Eigen::internal::TensorContractionInputMapper<float, long int, 1, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer> >::RhsPacker' {aka 'struct Eigen::internal::gemm_pack_rhs<float, long int, Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>, 4, 0, false, false>'}\r\n   25 | struct gemm_pack_rhs;\r\n      |        ^~~~~~~~~~~~~\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:110,\r\n                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_conv2d_impl.h:18,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:18:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h: In instantiation of 'void Eigen::internal::TensorContractionKernel<ResScalar, LhsScalar, RhsScalar, StorageIndex, OutputMapper, LhsMapper, RhsMapper>::packRhs(RhsScalar**, const typename RhsMapper::SubMapper&, StorageIndex, StorageIndex) [with ResScalar = float; LhsScalar = float; RhsScalar = float; StorageIndex = long int; OutputMapper = Eigen::internal::blas_data_mapper<float, long int, 0, 0, 1>; LhsMapper = Eigen::internal::TensorContractionInputMapper<float, long int, 1, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer>; RhsMapper = Eigen::internal::TensorContractionInputMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, true, 0, Eigen::MakePointer>; Eigen::internal::TensorContractionKernel<ResScalar, LhsScalar, RhsScalar, StorageIndex, OutputMapper, LhsMapper, RhsMapper>::RhsBlock = float*; typename RhsMapper::SubMapper = Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, true, 0, Eigen::MakePointer>]':\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:890:25:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalGemmPartial(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*, Eigen::TensorContractionEvaluatorBase<Derived>::Index, Eigen::TensorContractionEvaluatorBase<Derived>::Index, int) const [with bool lhs_inner_dim_contiguous = false; bool rhs_inner_dim_contiguous = false; bool rhs_inner_dim_reordered = true; int Alignment = 0; bool use_output_kernel = true; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float; Eigen::TensorContractionEvaluatorBase<Derived>::Index = long int]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:783:52:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalGemm(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*) const [with bool lhs_inner_dim_contiguous = false; bool rhs_inner_dim_contiguous = false; bool rhs_inner_dim_reordered = true; int Alignment = 0; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:720:66:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalProductSequential(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*) const [with bool lhs_inner_dim_contiguous = false; bool rhs_inner_dim_contiguous = false; bool rhs_inner_dim_reordered = true; int Alignment = 0; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:1015:5:   required from 'void Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::evalProduct(Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::Scalar*) const [with int Alignment = 0; Indices = const Eigen::array<Eigen::IndexPair<long long int>, 1>; LeftArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >; RightArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >; OutputKernelType = const Eigen::NoOpOutputKernel; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::Scalar = float]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:699:70:   [ skipping 2 instantiation contexts, use -ftemplate-backtrace-limit=0 to disable ]\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorMorphing.h:180:39:   required from 'bool Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::evalSubExprsIfNeeded(Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::EvaluatorPointerType) [with NewDimensions = const Eigen::DSizes<long long int, 4>; ArgType = const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::EvaluatorPointerType = float*]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorAssign.h:152:44:   required from 'bool Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::evalSubExprsIfNeeded(Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::EvaluatorPointerType) [with LeftArgType = Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer>; RightArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel> >; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::EvaluatorPointerType = float*]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h:131:61:   required from 'static void Eigen::internal::TensorExecutor<Expression, Eigen::DefaultDevice, true, Eigen::internal::Off>::run(const Expression&, const Eigen::DefaultDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel> > >]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDevice.h:35:62:   required from 'Eigen::TensorDevice<ExpressionType, DeviceType>& Eigen::TensorDevice<ExpressionType, DeviceType>::operator=(const OtherDerived&) [with OtherDerived = Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel> >; ExpressionType = Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer>; DeviceType = Eigen::DefaultDevice]'\r\n./tensorflow/compiler/xla/service/cpu/runtime_conv2d_impl.h:79:25:   required from 'void tensorflow::xla::EigenConvImpl(const EigenDevice&, ScalarType*, ScalarType*, ScalarType*, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index) [with EigenDevice = Eigen::DefaultDevice; ScalarType = float; Eigen::Index = long int]'\r\ntensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:57:33:   required from here\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:248:5: error: invalid use of incomplete type 'Eigen::internal::TensorContractionKernel<float, float, float, long int, Eigen::internal::blas_data_mapper<float, long int, 0, 0, 1>, Eigen::internal::TensorContractionInputMapper<float, long int, 1, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, true, 0, Eigen::MakePointer> >::RhsPacker' {aka 'struct Eigen::internal::gemm_pack_rhs<float, long int, Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, true, 0, Eigen::MakePointer>, 4, 0, false, false>'}\r\n  248 |     RhsPacker()(*rhsBlock, data_mapper, depth, cols);\r\n      |     ^~~~~~~~~~~\r\nIn file included from external/eigen_archive/Eigen/Core:275,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.h:19,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:16:\r\nexternal/eigen_archive/Eigen/src/Core/util/BlasUtil.h:25:8: note: declaration of 'Eigen::internal::TensorContractionKernel<float, float, float, long int, Eigen::internal::blas_data_mapper<float, long int, 0, 0, 1>, Eigen::internal::TensorContractionInputMapper<float, long int, 1, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, true, 0, Eigen::MakePointer> >::RhsPacker' {aka 'struct Eigen::internal::gemm_pack_rhs<float, long int, Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, true, 0, Eigen::MakePointer>, 4, 0, false, false>'}\r\n   25 | struct gemm_pack_rhs;\r\n      |        ^~~~~~~~~~~~~\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:110,\r\n                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_conv2d_impl.h:18,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:18:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h: In instantiation of 'void Eigen::internal::TensorContractionKernel<ResScalar, LhsScalar, RhsScalar, StorageIndex, OutputMapper, LhsMapper, RhsMapper>::packRhs(RhsScalar**, const typename RhsMapper::SubMapper&, StorageIndex, StorageIndex) [with ResScalar = float; LhsScalar = float; RhsScalar = float; StorageIndex = long int; OutputMapper = Eigen::internal::blas_data_mapper<float, long int, 0, 0, 1>; LhsMapper = Eigen::internal::TensorContractionInputMapper<float, long int, 1, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer>; RhsMapper = Eigen::internal::TensorContractionInputMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer>; Eigen::internal::TensorContractionKernel<ResScalar, LhsScalar, RhsScalar, StorageIndex, OutputMapper, LhsMapper, RhsMapper>::RhsBlock = float*; typename RhsMapper::SubMapper = Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer>]':\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:890:25:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalGemmPartial(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*, Eigen::TensorContractionEvaluatorBase<Derived>::Index, Eigen::TensorContractionEvaluatorBase<Derived>::Index, int) const [with bool lhs_inner_dim_contiguous = false; bool rhs_inner_dim_contiguous = false; bool rhs_inner_dim_reordered = false; int Alignment = 0; bool use_output_kernel = true; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float; Eigen::TensorContractionEvaluatorBase<Derived>::Index = long int]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:783:52:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalGemm(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*) const [with bool lhs_inner_dim_contiguous = false; bool rhs_inner_dim_contiguous = false; bool rhs_inner_dim_reordered = false; int Alignment = 0; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:720:66:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalProductSequential(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*) const [with bool lhs_inner_dim_contiguous = false; bool rhs_inner_dim_contiguous = false; bool rhs_inner_dim_reordered = false; int Alignment = 0; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:1015:5:   required from 'void Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::evalProduct(Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::Scalar*) const [with int Alignment = 0; Indices = const Eigen::array<Eigen::IndexPair<long long int>, 1>; LeftArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >; RightArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >; OutputKernelType = const Eigen::NoOpOutputKernel; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::Scalar = float]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:699:70:   [ skipping 2 instantiation contexts, use -ftemplate-backtrace-limit=0 to disable ]\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorMorphing.h:180:39:   required from 'bool Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::evalSubExprsIfNeeded(Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::EvaluatorPointerType) [with NewDimensions = const Eigen::DSizes<long long int, 4>; ArgType = const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel>; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::EvaluatorPointerType = float*]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorAssign.h:152:44:   required from 'bool Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::evalSubExprsIfNeeded(Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::EvaluatorPointerType) [with LeftArgType = Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer>; RightArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel> >; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::EvaluatorPointerType = float*]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h:131:61:   required from 'static void Eigen::internal::TensorExecutor<Expression, Eigen::DefaultDevice, true, Eigen::internal::Off>::run(const Expression&, const Eigen::DefaultDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel> > >]'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDevice.h:35:62:   required from 'Eigen::TensorDevice<ExpressionType, DeviceType>& Eigen::TensorDevice<ExpressionType, DeviceType>::operator=(const OtherDerived&) [with OtherDerived = Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, const Eigen::NoOpOutputKernel> >; ExpressionType = Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer>; DeviceType = Eigen::DefaultDevice]'\r\n./tensorflow/compiler/xla/service/cpu/runtime_conv2d_impl.h:79:25:   required from 'void tensorflow::xla::EigenConvImpl(const EigenDevice&, ScalarType*, ScalarType*, ScalarType*, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index) [with EigenDevice = Eigen::DefaultDevice; ScalarType = float; Eigen::Index = long int]'\r\ntensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:57:33:   required from here\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:248:5: error: invalid use of incomplete type 'Eigen::internal::TensorContractionKernel<float, float, float, long int, Eigen::internal::blas_data_mapper<float, long int, 0, 0, 1>, Eigen::internal::TensorContractionInputMapper<float, long int, 1, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer> >::RhsPacker' {aka 'struct Eigen::internal::gemm_pack_rhs<float, long int, Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer>, 4, 0, false, false>'}\r\n  248 |     RhsPacker()(*rhsBlock, data_mapper, depth, cols);\r\n      |     ^~~~~~~~~~~\r\nIn file included from external/eigen_archive/Eigen/Core:275,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.h:19,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:16:\r\nexternal/eigen_archive/Eigen/src/Core/util/BlasUtil.h:25:8: note: declaration of 'Eigen::internal::TensorContractionKernel<float, float, float, long int, Eigen::internal::blas_data_mapper<float, long int, 0, 0, 1>, Eigen::internal::TensorContractionInputMapper<float, long int, 1, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer> >::RhsPacker' {aka 'struct Eigen::internal::gemm_pack_rhs<float, long int, Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer>, 4, 0, false, false>'}\r\n   25 | struct gemm_pack_rhs;\r\n      |        ^~~~~~~~~~~~~\r\nTarget //tensorflow:libtensorflow.so failed to build\r\nINFO: Elapsed time: 1163.559s, Critical Path: 148.84s\r\nINFO: 4754 processes: 4754 local.\r\nFAILED: Build did NOT complete successfully\r\n```", "comments": ["@bkeys ,\r\nCan you please refer this issues with similar error.[1](https://github.com/tensorflow/tensorflow/issues/44626) and [2](https://github.com/tensorflow/tensorflow/issues/46781#issuecomment-771930946).It helps.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52154\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52154\">No</a>\n"]}, {"number": 52153, "title": "Linking of rule '@com_github_grpc_grpc//src/compiler:grpc_cpp_plugin' failed", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution: linux Centos7.7.1908\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.2.0\r\n- Python version: 3.8.10\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): 2.0.0\r\n- GCC/Compiler version (if compiling from source): 9.3.1\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\n\r\n**Describe the problem**\r\nhi,\r\n\r\nI am trying to build TensorFlow 2.2.0's cpp dependency library on centos7.7, but bazel will always prompt me \r\n```\r\nLinking of rule'@com_github_grpc_grpc//src/compiler:grpc_cpp_plugin' failed\r\n```\r\n\r\nI used the same method and everything went well when I built TensorFlow on Ubuntu system. I don\u2019t know if it\u2019s the problem of the system or my method.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n```\r\nsk103@super5:/home/sk103/tool/tensorflow/tensorflow-2.2.0>./configure \r\nYou have bazel 2.0.0 installed.\r\nPlease specify the location of python. [Default is /usr/bin/python]: \r\n\r\n\r\nFound possible Python library paths:\r\n  /usr/local/python3/lib/python3.8/site-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/local/python3/lib/python3.8/site-packages]\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: n\r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: n\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: n\r\nNo CUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to download a fresh release of clang? (Experimental) [y/N]: n\r\nClang will not be downloaded.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]: \r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n\t--config=mkl         \t# Build with MKL support.\r\n\t--config=monolithic  \t# Config for mostly static monolithic build.\r\n\t--config=ngraph      \t# Build with Intel nGraph support.\r\n\t--config=numa        \t# Build with NUMA support.\r\n\t--config=dynamic_kernels\t# (Experimental) Build kernels into separate shared objects.\r\n\t--config=v2          \t# Build TensorFlow 2.x instead of 1.x.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n\t--config=noaws       \t# Disable AWS S3 filesystem support.\r\n\t--config=nogcp       \t# Disable GCP support.\r\n\t--config=nohdfs      \t# Disable HDFS support.\r\n\t--config=nonccl      \t# Disable NVIDIA NCCL support.\r\nConfiguration finished\r\nsk103@super5:/home/sk103/tool/tensorflow/tensorflow-2.2.0>\r\n```\r\n\r\n```\r\nsk103@super5:/home/sk103/tool/tensorflow/tensorflow-2.2.0>bazel build //tensorflow:libtensorflow_cc.so\r\n...\r\n\r\nERROR: /home/sk103/.cache/bazel/_bazel_sk103/46f66c8afcc04e6816b6d553e9e7afff/external/com_github_grpc_grpc/src/compiler/BUILD:80:1: Linking of rule '@com_github_grpc_grpc//src/compiler:grpc_cpp_plugin' failed (Exit 1)\r\nbazel-out/host/bin/external/com_github_grpc_grpc/src/compiler/_objs/grpc_cpp_plugin/cpp_plugin.o:cpp_plugin.cc:function ProtoBufMethod::~ProtoBufMethod(): error: undefined reference to 'operator delete(void*, unsigned long)'\r\nbazel-out/host/bin/external/com_github_grpc_grpc/src/compiler/_objs/grpc_cpp_plugin/cpp_plugin.o:cpp_plugin.cc:function ProtoBufService::~ProtoBufService(): error: undefined reference to 'operator delete(void*, unsigned long)'\r\nbazel-out/host/bin/external/com_github_grpc_grpc/src/compiler/_objs/grpc_cpp_plugin/cpp_plugin.o:cpp_plugin.cc:function ProtoBufFile::~ProtoBufFile(): error: undefined reference to 'operator delete(void*, unsigned long)'\r\nbazel-out/host/bin/external/com_github_grpc_grpc/src/compiler/_objs/grpc_cpp_plugin/cpp_plugin.o:cpp_plugin.cc:function google::protobuf::io::StringOutputStream::~StringOutputStream(): error: undefined reference to 'operator delete(void*, unsigned long)'\r\nbazel-out/host/bin/external/com_github_grpc_grpc/src/compiler/_objs/grpc_cpp_plugin/cpp_plugin.o:cpp_plugin.cc:function grpc_cpp_generator::ClassName(google::protobuf::Descriptor const*, bool): error: undefined reference to 'std::__throw_out_of_range_fmt(char const*, ...)'\r\nbazel-out/host/bin/external/com_github_grpc_grpc/src/compiler/_objs/grpc_cpp_plugin/cpp_plugin.o:cpp_plugin.cc:function ProtoBufFile::package_parts() const: error: undefined reference to 'std::__throw_out_of_range_fmt(char const*, ...)'\r\nbazel-out/host/bin/external/com_github_grpc_grpc/src/compiler/_objs/grpc_cpp_plugin/cpp_plugin.o:cpp_plugin.cc:function CppGrpcGenerator::Generate(google::protobuf::FileDescriptor const*, std::string const&, google::protobuf::compiler::GeneratorContext*, std::string*) const: error: undefined reference to 'std::__throw_out_of_range_fmt(char const*, ...)'\r\nbazel-out/host/bin/external/com_github_grpc_grpc/src/compiler/_objs/grpc_cpp_plugin/cpp_plugin.o:cpp_plugin.cc:function CppGrpcGenerator::Generate(google::protobuf::FileDescriptor const*, std::string const&, google::protobuf::compiler::GeneratorContext*, std::string*) const: error: undefined reference to 'std::__throw_out_of_range_fmt(char const*, ...)'\r\nbazel-out/host/bin/external/com_google_protobuf/_objs/protobuf/dynamic_message.o:dynamic_message.cc:function google::protobuf::DynamicMessageFactory::GetPrototypeNoLock(google::protobuf::Descriptor const*) [clone .cold]: error: undefined reference to '__cxa_throw_bad_array_new_length'\r\nbazel-out/host/bin/external/com_google_protobuf/_objs/protobuf/struct.pb.o:struct.pb.cc:function google::protobuf::Struct::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const [clone .cold]: error: undefined reference to '__cxa_throw_bad_array_new_length'\r\nbazel-out/host/bin/external/com_google_protobuf/_objs/protobuf_lite/extension_set.o:extension_set.cc:function google::protobuf::internal::ExtensionSet::~ExtensionSet(): error: undefined reference to 'operator delete[](void*, unsigned long)'\r\nbazel-out/host/bin/external/com_google_protobuf/_objs/protobuf_lite/extension_set.o:extension_set.cc:function google::protobuf::internal::ExtensionSet::GrowCapacity(unsigned long): error: undefined reference to 'operator delete[](void*, unsigned long)'\r\ncollect2: error: ld returned 1 exit status\r\nTarget //tensorflow:libtensorflow_cc.so failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nERROR: /home/sk103/tool/tensorflow/tensorflow-2.2.0/tensorflow/core/BUILD:1763:1 Linking of rule '@com_github_grpc_grpc//src/compiler:grpc_cpp_plugin' failed (Exit 1)\r\nINFO: Elapsed time: 94.025s, Critical Path: 28.32s\r\nINFO: 347 processes: 347 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\n```", "comments": ["Hi @oooooome !\r\nCould you please fill the issue Template from [here ](https://github.com/tensorflow/tensorflow/issues/new/choose)as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code/colab gist to reproduce the issue faced].Thanks!", "@mohantym  Sorry, there were some problems when I started this issue, now I have updated this issue", "Hi @oooooome ! Could you try again with Tested configurations from[ here](https://www.tensorflow.org/install/source#tested_build_configurations) for TF 2.2 . ", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "thanks guys, I have solved this problem!\r\n\r\nAccording to the following error messages, I found that it was related to the C++ standard library, so I checked the causes of these errors. Many answers indicated that this error may be related to the libstdc++.so library. So I updated and compiled the gcc version to 7.5, and updated the libstdc++.so library, and finally compiled successfully.", "Ok @oooooome ,Thanks for updating on the same. Could you please close this issue then?", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52153\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52153\">No</a>\n"]}, {"number": 52152, "title": "TensorFlow unit test failure kernels:requantize_op_test on AARCH64", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): git HEAD\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source): 3.7.2\r\n- GCC/Compiler version (if compiling from source): 10.3.0\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nTest fails\r\n\r\n**Describe the expected behavior**\r\n\r\nTest passes\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): No\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nbazel test //tensorflow/core/kernels:requantize_op_test\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n[ RUN      ] RequantizeTest.HandCraftedRequantize\r\ntensorflow/core/framework/tensor_testutil.cc:128: Failure\r\nValue of: IsEqual(Tx[i], Ty[i], t)\r\nActual: false (128 not equal to 127)\r\nExpected: true\r\ni = 1\r\n[  FAILED  ] RequantizeTest.HandCraftedRequantize (37 ms)\r\n", "comments": ["@cfRod @nSircombe", "In the inline function RequantizeManyInNewRangeUsingEigen<qint32, quint8> in https://github.com/tensorflow/tensorflow/blob/89363b5e083a5c9faa12660cd05c1d79c6ea9f36/tensorflow/core/kernels/quantization_utils.h#L727 you can see the use of rounding_delta. This causes a 'round to nearest' operation when converting from int32 to uint8. In the test the intermediate value of 127.5 results in an output of 128 when the test is run on x86 and uses this code.\r\nHowever on AARCH64 the requantize is done by https://github.com/google/gemmlowp and you can see in the verification code that a simple cast is done https://github.com/google/gemmlowp/blob/f9959600daa42992baace8a49544a00a743ce1b6/meta/test_transform_correctness.cc#L85 which uses truncation, no rounding. This means that a different result is obtained. In this test the intermediate value of 127.5 is truncated to 127. This fails the comparison against the expected 128 and the test fails. ", "Fixed by https://github.com/tensorflow/tensorflow/pull/53630", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52152\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52152\">No</a>\n"]}, {"number": 52149, "title": "TPU not connecting in virtualenv in Cloud TPU-VM", "body": "TF failed to connect to TPU when TF installed in virtualenv.\r\ngetting the following error\r\n\r\n```\r\nTensorflow version 2.6.0\r\n2021-09-27 08:27:32.379081: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-09-27 08:27:32.420848: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\r\nTraceback (most recent call last):\r\n  File \"/home/raj/env/lib/python3.8/site-packages/tensorflow/python/tpu/tpu_strategy_util.py\", line 107, in initialize_tpu_system\r\n    output = _tpu_init_fn()\r\n  File \"/home/raj/env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3039, in __call__\r\n    return graph_function._call_flat(\r\n  File \"/home/raj/env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 1963, in _call_flat\r\n    return self._build_call_outputs(self._inference_function.call(\r\n  File \"/home/raj/env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 591, in call\r\n    outputs = execute.execute(\r\n  File \"/home/raj/env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_embedding_config=\"\", is_global_init=false, embedding_config=\"\", enable_whole_mesh_compilations=false]\r\nRegistered devices: [CPU]\r\nRegistered kernels:\r\n  <no registered kernels>\r\n\r\n         [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"tpu-test.py\", line 10, in <module>\r\n    tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\r\n  File \"/home/raj/env/lib/python3.8/site-packages/tensorflow/python/tpu/tpu_strategy_util.py\", line 110, in initialize_tpu_system\r\n    raise errors.NotFoundError(\r\ntensorflow.python.framework.errors_impl.NotFoundError: TPUs not found in the cluster. Failed in initialization: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_embedding_config=\"\", is_global_init=false, embedding_config=\"\", enable_whole_mesh_compilations=false]\r\nRegistered devices: [CPU]\r\nRegistered kernels:\r\n  <no registered kernels>\r\n\r\n         [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]\r\n```\r\ncode runs successfully with pre-installed TensorFlow. Fails when installed in a virtualenv\r\npre-installed TF version `tf-nightly==2.6.0`\r\n\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nTPU-VM create\r\n```bash\r\ngcloud alpha compute tpus tpu-vm create deberta --accelerator-type=v3-8 --version=v2-alpha --zone europe-west4-a\r\n```\r\n```bash\r\nvirtualenv env\r\nsource env/bin/activate\r\n```\r\n```python\r\nimport tensorflow as tf\r\nprint(\"Tensorflow version \" + tf.__version__)\r\n\r\n@tf.function\r\ndef add_fn(x,y):\r\n  z = x + y\r\n  return z\r\n\r\ncluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='local')\r\ntf.tpu.experimental.initialize_tpu_system(cluster_resolver)\r\nstrategy = tf.distribute.TPUStrategy(cluster_resolver)\r\n\r\nx = tf.constant(1.)\r\ny = tf.constant(1.)\r\nz = strategy.run(add_fn, args=(x,y))\r\nprint(z)\r\n```\r\n```\r\npython tpu-test.py\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Inside the VM for `TPUClusterResolver`, in the argument tpu It can be the TPU name or TPU worker `gRPC` address. If not set, it will try automatically resolve the TPU address on Cloud TPUs. \r\nBut, If set to \"`local`\", it will assume that the TPU is directly connected to the VM instead of over the network.", "@sachinprasadhs \r\nI am trying to execute the code in the TPU-VM. Where TPU is directly attached to the VM", "Currently TensorFlow on TPU VM requires a special build of TensorFlow that comes pre-installed on the VM. `tf-nightly` or `tensorflow` in PyPI unfortunately won't work with TPU VM.\r\n\r\nThere is a wheel that should be included within the TPU VM at `/usr/share/tpu/*.whl` which I think you can pip install in your virtualenv instead?", "Thanks. wheel inside `/usr/share/tpu/*.whl` is working. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52149\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52149\">No</a>\n", "@allenwang28 \r\n\r\n> There is a wheel that should be included within the TPU VM at `/usr/share/tpu/*.whl`\r\n\r\nThank you! Currently there is a `tf_nightly-2.7.0-cp38-cp38-linux_x86_64.whl`, which is Python 3.8. Would you please consider adding Python 3.9 and Python 3.10 versions as well?"]}, {"number": 52147, "title": "tensorFlow.compat.v1 no module named compat", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are\r\nnot verified bugs in TensorFlow, please go to\r\n[Discourse](https://discuss.tensorflow.org/).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n", "comments": ["using tensorflow 2.6 , python 3.9. running generate_tfrecord.py file in pycharm . Getting no module compat found error. Any idea how to resolve this issue", "@SHILPASHIVAMALLU ,\r\nCan you please refer this [link](https://github.com/tensorflow/tensorflow/issues/50121) with similar error.It helps.Also, In order to expedite the trouble-shooting process, could you please provide a complete code you are using.Thanks!\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 52144, "title": "returning NUMA node zero?", "body": "**System information**\r\n- Fedora 34\r\n- TensorFlow version: 2.6.0\r\n- Python version: 3.9.7\r\n- Installed Tensorflow using pip\r\n- CUDA/cuDNN version: 11.4\r\n- GPU model and memory: NVIDIA T600 / 4GB\r\n\r\n**Problem description:**\r\n```python\r\nimport tensorflow as tf\r\ntf.config.list_physical_devices('GPU')\r\n```\r\n\r\n> 2021-09-26 15:29:11.893611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2021-09-26 15:29:11.898701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2021-09-26 15:29:11.898993: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\r\n\r\nShould I solve it? or ignore it?", "comments": ["@water5 \r\nPlease refer to similar error issues and let us know: [link](https://github.com/tensorflow/tensorflow/issues/47245#issuecomment-786245812),[link1](https://stackoverflow.com/questions/44232898/memoryerror-in-tensorflow-and-successful-numa-node-read-from-sysfs-had-negativ),[link2](https://github.com/tensorflow/tensorflow/issues/51358#issuecomment-898411697)\r\n\r\n\r\nAlso, try setting a hard limit on the total GPU memory as shown in [this guide](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth) and let us know if it works.\r\n\r\nSimilar issue #36025 for reference. Thanks!\r\n\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52144\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52144\">No</a>\n"]}, {"number": 52143, "title": "Errors", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 16.04 and 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Samsung galaxy m12\r\n- TensorFlow installed from (source or binary): I used the venv code\r\n- TensorFlow version (use command below): none: read below\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: mediatek and 6gb\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n`(venv) om@localhost:~/twitchtubemain$ python3 -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n> import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\r\n>`\r\n\r\n\r\n**Describe the current behavior**\r\n(venv) om@localhost:~/twitchtubemain$ pip install --upgrade tensorflow\r\nCollecting tensorflow\r\n  Cache entry deserialization failed, entry ignored\r\n  Could not find a version that satisfies the requirement tensorflow (from versions: )\r\nNo matching distribution found for tensorflow\r\n(venv) om@localhost:~/twitchtubemain$\r\n**Describe the expected behavior**\r\nTensor flow getting installed using pip\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n(venv) om@localhost:~/twitchtubemain$ pip install --upgrade tensorflow\r\nCollecting tensorflow\r\n  Cache entry deserialization failed, entry ignored\r\n  Could not find a version that satisfies the requirement tensorflow (from versions: )\r\nNo matching distribution found for tensorflow\r\n(venv) om@localhost:~/twitchtubemain$\r\n", "comments": ["(venv) om@localhost:~/twitchtubemain$ python\r\nPython 3.6.9 (default, Jan 26 2021, 15:33:00)\r\n[GCC 8.4.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nModuleNotFoundError: No module named 'tensorflow'\r\n>>>", "Heyy, how is your day going", "@omxpro \r\nPlease refer to similar error issue: [link](https://stackoverflow.com/questions/46568913/tensorflow-import-error-no-module-named-tensorflow/48159412),[link1](https://stackoverflow.com/questions/42244198/importerror-no-module-named-tensorflow),[link2](https://www.pythonpool.com/no-module-named-tensorflow-error-solved/),[link3](https://github.com/tensorflow/tensorflow/issues/32147#issuecomment-534791929)\r\n\r\n\r\nAlso verify:\r\n\r\nYou are running 32-bit Python or 32-bit OS\r\nYou have not installed the [Microsoft Visual C++ Redistributable](https://support.microsoft.com/en-us/topic/the-latest-supported-visual-c-downloads-2647da03-1eea-4433-9aff-95f26a218cc0) package\r\nYour CPU does not support AVX instructions.\r\nPlease take a look at the [system requirements](https://www.tensorflow.org/install/pip#system-requirements) and check if you have the correct dependencies installed.\r\n\r\nThanks!", "I tried link and link1 none of those worker And I also tried `python3 -m pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.0-py3-none-any.whl` and it installed tensorflow but I got this error\r\n\r\nError importing tensorflow.  Unless you are using bazel,\r\nyou should not try to import tensorflow from its source directory;\r\nplease exit the tensorflow source tree, and relaunch your python interpreter\r\nfrom there.", "Link2 dosn't help either", "Idk how to check avx CPU  and I haven't installed vscode package I am running Tensorflow on terminal on mobile", "@omxpro \r\nCan you please confirm if you are using pip install or bazel and for pip have you followed [guide](https://www.tensorflow.org/install/pip), [you may refer to [link](https://www.youtube.com/watch?v=YBnLVZJs6ps),[link1](https://www.youtube.com/watch?v=s4Lcf9du9L8])", "Yes I have followed the guide", "I used pip install", "And my terminal is running aarch64 aka 64 bits", "Uninstalled tersorflow installing it again using official instructions\r\n", "t:/usr/local/lib/python3.6/dist-packages$ pip install --upgrade tensorflow\r\nERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\r\nERROR: No matching distribution found for tensorflow\r\nom@localhost:/usr/local/lib/python3.6/dist-packages$", "@omxpro \r\nplease verify all requirements, ex is your python 32 bits.\r\n#48733 #50399 #47151 [this is clearly a compatibility issue", "It's 64 bits I checked it", "I used a method from #47151 and thus is the error I got after that\r\n\r\nom@localhost:~/twitchtubemain$ pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.0-py3-none-any.whl\r\nCollecting tensorflow==0.12.0                           Using cached https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.0-py3-none-any.whl (38.4 MB)                                                     Requirement already satisfied: protobuf==3.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==0.12.0) (3.1.0)                                        Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==0.12.0) (1.16.0)                                           Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==0.12.0) (0.37.0)                                           Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==0.12.0) (1.19.5)                                         Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf==3.1.0->tensorflow==0.12.0) (58.1.0)                           Installing collected packages: tensorflow             Successfully installed tensorflow-0.12.0              om@localhost:~/twitchtubemain$                        om@localhost:~/twitchtubemain$ python main.py         Traceback (most recent call last):                      File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/__init__.py\", line 49, in <module>             from tensorflow.python import pywrap_tensorflow     File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>    _pywrap_tensorflow = swig_import_helper()           File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper                                                _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)                                   File \"/usr/lib/python3.6/imp.py\", line 243, in load_module                                                    return load_dynamic(name, filename, file)           File \"/usr/lib/python3.6/imp.py\", line 343, in load_dynamic                                                   return _load(spec)                                ImportError: /usr/local/lib/python3.6/dist-packages/tensorflow/python/_pywrap_tensorflow.so: invalid ELF header\r\nDuring handling of the above exception, another exception occurred:\r\nTraceback (most recent call last):                      File \"main.py\", line 1, in <module>                     from src.ClipHandler import ClipHandler             File \"/home/om/twitchtubemain/src/ClipHandler.py\", line 8, in <module>                                        import tensorflow as tf                             File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 24, in <module>                    from tensorflow.python import *                     File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/__init__.py\", line 60, in <module>             raise ImportError(msg)                            ImportError: Traceback (most recent call last):         File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/__init__.py\", line 49, in <module>             from tensorflow.python import pywrap_tensorflow     File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>    _pywrap_tensorflow = swig_import_helper()           File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper                                                _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)                                   File \"/usr/lib/python3.6/imp.py\", line 243, in load_module                                                    return load_dynamic(name, filename, file)           File \"/usr/lib/python3.6/imp.py\", line 343, in load_dynamic                                                   return _load(spec)                                ImportError: /usr/local/lib/python3.6/dist-packages/tensorflow/python/_pywrap_tensorflow.so: invalid ELF header\r\n\r\nError importing tensorflow.  Unless you are using bazel,                                                    you should not try to import tensorflow from its source directory;                            om@localhost:~/twitchtubemain\r\n\r\nIssue comment link: https://github.com/tensorflow/tensorflow/issues/47151#issuecomment-808707401", "[Error file.txt](https://github.com/tensorflow/tensorflow/files/7236810/Error.file.txt)\r\nError file to make you see the error better ", "Why are you installing mac wheel when you are on Linux?", "> Why are you installing mac wheel when you are on Linux?\r\n\r\nI tried Linux wheel too", "> aarch64\r\n\r\nThe official wheels only support x86_64.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "@omxpro \r\nAs per above comment can you please move this to closed staus.", "Okay", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52143\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52143\">No</a>\n"]}, {"number": 52142, "title": "Cannot convert concrete functions with no input arguments", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- TensorFlow installation (pip package or built from source): from pip package tf-nightly\r\n- TensorFlow library (version, if pip package or github SHA, if built from source): 2.7.0-dev20210922\r\n\r\n### 2. Code\r\n\r\nCurrent TFLite conversion code seems to assume that all signatures take at least 1 input parameter. If you try to export a signature with no input parameters, you get the following error:\r\n\r\n`tensorflow.lite.python.convert_phase.ConverterError: input array size mismatch: got 1, expected: 0`\r\n\r\nHere's an example code reproducing the issue. If an input argument is added to the `test` function (even if ignored), and accordingly to `get_concrete_function`, the error disappears.\r\n\r\n```python\r\nimport tensorflow as tf                                                        \r\n                                                                               \r\nclass TestModel(tf.keras.models.Model):\r\n  @tf.function\r\n  def test(self):\r\n    return 123\r\n\r\ntest_model = TestModel()\r\nsignatures = [test_model.test.get_concrete_function()]\r\n\r\nconverter = tf.lite.TFLiteConverter.from_concrete_functions(signatures, test_model)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\ntflite_model = converter.convert()\r\n```\r\n\r\n### 3. Other info\r\n\r\nIn another code also trying to export a function without arguments I got this other variation of the error.\r\n\r\n`ValueError: Failed to parse the model: NULL SignatureDef inputs for exported method testFailed to construct interpreter.`\r\n\r\nHowever, I couldn't provide a simple repro code for this exact one. Sharing just in case it gives some kind of additional clue.", "comments": ["Hi @leandro-gracia-gil ! I tried to replicate in TF 2.6 (Stable version ) .Changed Arguments as per this [thread](https://www.tensorflow.org/lite/convert#convert_concrete_functions_) to resolve the issue. Its replicating in TF-nightly  though.\r\n\r\nAttaching [GIST](https://colab.research.google.com/gist/mohantym/13a375c8fcb737231f5fb0093704676d/github_52142.ipynb#scrollTo=2DDy1tt-BTZI) for reference. Thank you! ", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52142\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52142\">No</a>\n", "Still happening in TF 2.7.0.", "Re-opening this issue as it is replicating in 2.7 and nightly. Attaching [Gist ](https://colab.research.google.com/gist/mohantym/13a375c8fcb737231f5fb0093704676d/github_52142.ipynb#scrollTo=Tn3vsoC6A0AE)for reference.", "Hi @sachinprasadhs! Could you please look at this issue!", "I also found that if multiple signatures are used (which is my actual use case), then conversion works but loading the model throws an exception complaining about NULL SignatureDef inputs.\r\n\r\n```python\r\nimport tensorflow as tf                                                        \r\n                                                                               \r\nclass TestModel(tf.keras.models.Model):                                        \r\n  @tf.function                                                                 \r\n  def test_1(self):                                                            \r\n    return 123                                                                 \r\n                                                                               \r\n  @tf.function                                                                 \r\n  def test_2(self):                                                            \r\n    return 456                                                                 \r\n                                                                               \r\ntest_model = TestModel()                                                       \r\nsignatures = [                                                                 \r\n  test_model.test_1.get_concrete_function(),                                   \r\n  test_model.test_2.get_concrete_function(),                                   \r\n]                                                                              \r\n                                                                               \r\nconverter = tf.lite.TFLiteConverter.from_concrete_functions(signatures, test_model)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]                           \r\n\r\n# This now works but...\r\ntflite_model = converter.convert()\r\n\r\n# This throws \"ValueError: NULL SignatureDef inputs for exported method test_1\"\r\ninterpreter = tf.lite.Interpreter(model_content=tflite_model)\r\n```\r\n\r\nI've also tried using a dummy default argument. If I use a Python argument it makes no difference. If I use a tensor argument defaulting to some constant tensor then the conversion fails.\r\n\r\nAdding a dummy tensor argument that is explicitly passed then ignored does work around the problem, but it's not an option for me because it introduces breaking signature changes with previous versions of model. Furthermore, this extra dummy argument won't be required again once this bug is fixed, creating yet another breaking signature change later if I use this workaround now.\r\n\r\nSo, any possible workarounds that avoid having to explicitly pass an argument when invoking these signatures in the interpreter would be much appreciated.", "Another update trying to work around this. If you set a dummy default value when using `get_concrete_function()` instead of setting it at function signature level, then conversion and loading both work, but the signature runner ignores the default argument and still forces you to provide a value for the dummy.\r\n\r\n```python\r\nimport tensorflow as tf                                                        \r\n                                                                               \r\nclass TestModel(tf.keras.models.Model):\r\n  @tf.function\r\n  def test_1(self, dummy):                                                     \r\n    return 123                                                                 \r\n                                                                               \r\n  @tf.function                                                                 \r\n  def test_2(self, dummy):\r\n    return 456                                                                 \r\n  \r\ntest_model = TestModel()\r\nsignatures = [\r\n  test_model.test_1.get_concrete_function(dummy=tf.constant(0)),               \r\n  test_model.test_2.get_concrete_function(dummy=tf.constant(0)),               \r\n] \r\n    \r\nconverter = tf.lite.TFLiteConverter.from_concrete_functions(signatures, test_model) \r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]                           \r\ntflite_model = converter.convert()\r\n    \r\ninterpreter = tf.lite.Interpreter(model_content=tflite_model)\r\n\r\n# This works, but requires explicitly setting the dummy, which I'm trying to avoid.\r\ninterpreter.get_signature_runner('test_1')(dummy=tf.constant(0))\r\n\r\n# Throws \"ValueError: Invalid number of inputs provided for running a SignatureDef, expected 1 vs provided 0\".\r\ninterpreter.get_signature_runner('test_1')()\r\n```\r\n\r\nIf there's a way to work around this issue without having to explicitly set a value for a dummy argument in the signature runner, please let me know.", "Another related update. It seems that not only functions with no inputs fail, but functions with no outputs too.\r\n\r\nFor example:\r\n```python\r\n  @tf.function\r\n  def test(self, dummy):                                                     \r\n    return []\r\n```\r\n\r\nUsing this function in the example above raises `ValueError: NULL SignatureDef outputs for exported method test` not when converting, but when loading the model in an interpreter. It happens in tf-nightly too.\r\n\r\nFunctions with no outputs are certainly rare. I found this while automatically creating functions that export information about another function's input arguments. When it got a function with no input arguments, the returned value collapsed to an empty list, which exposed the problem.\r\n\r\nSo, while there might not be a clear purpose for directly writing functions that return no values, they might be the result of some other automatic process. In those cases this problem is making loading the entire model to fail, when it should be possible to return an empty dict of results after invoking such functions.", "A signature is defined/identified by the inputs and outputs. Though the output can be an empty dictionary, the input cannot be empty: (see example below)\r\n\r\n*Note: For one signature, the name defaults to `serving_signature`*\r\n```\r\nimport tensorflow as tf                                                        \r\n                                                                               \r\nclass TestModel(tf.keras.models.Model):\r\n  @tf.function(input_signature=[tf.TensorSpec(shape=[None], dtype=tf.float32)])\r\n  def test_1(self, dummy):                                                     \r\n    return {}                                                             \r\n                                                                                                                                              \r\ntest_model = TestModel()\r\nsignatures = [test_model.test_1.get_concrete_function()]\r\n    \r\nconverter = tf.lite.TFLiteConverter.from_concrete_functions(signatures, test_model) \r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]                           \r\ntflite_model = converter.convert()\r\n    \r\ninterpreter = tf.lite.Interpreter(model_content=tflite_model)\r\nsignature_runner = interpreter.get_signature_runner('serving_default')\r\nsignature_runner(dummy=tf.constant(0, dtype=tf.float32))\r\n```\r\n\r\nOutput:\r\n```\r\n{}\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52142\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52142\">No</a>\n", "@MeghnaNatraj \r\nThat limitation is absurd in the case where you have multiple signatures and some of them act as properties returning information about the model. It forces you to pass a tensor even if it's completely ignored inside.\r\n\r\nWould it be possible to consider adding support for this?", "@leandro-gracia-gil Unfortunately, we will not be able to add support for this as it is not a critically blocking feature. You are free to add a PR and contribute to resolving this if you wish to. Thank you."]}, {"number": 52141, "title": "Is it even possible to build tensorflow on Windows? ", "body": "**System information**\r\n- Windows 10 Pro x64 - 19043.1237\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.4\r\n- Python version: 3.8\r\n- Installed using virtualenv? pip? conda?: no\r\n- Bazel version (if compiling from source): 3.7.1\r\n- GCC/Compiler version (if compiling from source): VC 14.29.30133\r\n- CUDA/cuDNN version: 11.0/8.0\r\n- GPU model and memory: Nvidia GTX 1080\r\n\r\n\r\nI checked the the build from source page and followed the instructions. I have the repository cloned, I checked out 2.4 and I configured it with default settings except for 'cuda support' which I enabled. \r\n\r\nI go to bazel, try to build it, and all hell breaks loose: \r\n\r\n`bazel build -c opt --config=cuda --define=no_tensorflow_py_deps=true --copt=-nvcc_options=disable-warnings //tensorflow:tensorflow.dll --verbose_failures.` \r\n\r\n> ERROR: Config value 'cuda' is not defined in any .rc file\r\n\r\nEven if I give up on cuda option, it still fails: \r\n\r\n`bazel build -c opt --define=no_tensorflow_py_deps=true --copt=-nvcc_options=disable-warnings //tensorflow:tensorflow.so --verbose_failures`\r\n\r\n> ERROR: no such target '//tensorflow:tensorflow.dll': target 'tensorflow.dll' not declared in package 'tensorflow'\r\n\r\nThen I tried a suggestion to use libtensorflow_cc.so: \r\n\r\n`bazel build -c opt --define=no_tensorflow_py_deps=true --copt=-nvcc_options=disable-warnings //tensorflow:libtensorflow_cc.so --verbose_failures`\r\n\r\n> ERROR: no such target '//tensorflow:libtensorflow_cc.so': target 'libtensorflow_cc.so' not declared in package 'tensorflow'\r\n\r\nIn other words, nothing is even remotely working. \r\n\r\nI don't understand anything about anything at this point. Is it not supposed to work? Was support for Windows removed? ", "comments": ["@ammarsalman94 Could you please try to Build from [Source ](https://www.tensorflow.org/install/source_windows#setup_for_windows) using TF latest stable version 2.6.0 and have a look at the similar issue [link](https://stackoverflow.com/questions/34785414/how-to-install-tensorflow-on-windows) , Please let us know if it helps? Thanks!", "@sushreebarsa \r\nI tried with version 2.6, same issues. I looked at the SO answer provided, in summary it says Bazel doesn't work on Windows and I have to build for Linux. If I wanted to run Tensorflow on Linux I wouldn't be trying to build it for Windows. So that defeats the whole purpose. Is that the conclusion? It simply doesn't build on Windows and the whole instruction pages are pretty much a waste of time?", "@ammarsalman94 \r\nAs per [guide](https://www.tensorflow.org/install/source_windows) it is possible to have bazel on windows, please verify the system [requirements](https://www.tensorflow.org/install/pip#system-requirements) and hardware requirements. [refer to [link](https://github.com/tensorflow/tensorflow/issues/52143#issuecomment-927651685])]", "@Saduf2019 Thank you for the response. I ended up reinstalling Windows itself and it seems there were a lot of issues in my previous Windows version and configuration. With a fresh install things went smother and now the issue is resolved. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52141\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52141\">No</a>\n", "@ammarsalman94 \r\nThank you for your response, glad the issue is resolved."]}, {"number": 52139, "title": "When does tensorflow 2.x support crf\uff1f", "body": "In view of the fact that the crf implemented by tensorflow addons or implemented by ourselves are integrated into the tensorflow 2.x framework is not friendly, so, when will tensorflow 2.x support crf?", "comments": ["Hi @colynhn! ,Could you please fill the template for[ feature request](https://github.com/tensorflow/tensorflow/issues/new/choose) from here as It will help us track and expedite the feature request properly.", "@mohantym Is asking me to resubmit an issue according to the template for feature request\uff1f", "Hi @colynhn ! It was request for specific instructions .Actually I looked into this issue earlier from [here ](https://www.tensorflow.org/addons/api_docs/python/tfa/layers/CRF) , As you said CRF is already part of add-ons , but could not find clear details . We will be able to help the community better if you provide specific instructions in form of template. ", "Hi @Saduf2019! Could you please look into this feature request ?", "thx, i first use the crf of tfaddons until tensorflow officially supports this layer."]}, {"number": 52138, "title": "(Apple Silicon aka M1) import tensorflow killed python in terminal", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 11.6 (Big Sur)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version: 2.4, 2.5, 2.6\r\n- Python version: 3.9.7\r\n- Installed using virtualenv? pip? conda?: conda (Miniforge 3 ARM64), pip \r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: M1\r\n\r\n**Describe the problem**\r\nHi, there. \r\nI have a problem with importing tensorflow related modules (tensorflow, keras, etc.). \r\nOthers e.g., pandas, numpy, pillow, etc. worked without issue.\r\nObviously, I installed tensorflow supporting arm64 NOT Intel x86x64, and other modules such as PyTorch installed as ARM worked well without Rosseta.\r\n\r\nAfter executing 'import tensorflow' in the terminal, it instantaneously kills python. (zsh: killed python)\r\nI tried to change the python version to 3.8 and tensorflow version to 2.4 or 2.5, but results were the same. \r\nReinstalling miniforge 3 ARM64 also did not work well.\r\nActually, importing tensorflow worked very well about just a week ago, but suddenly it didn't work :(\r\n\r\nHowever, one strange thing is when I open the terminal with Rosetta, there is no issue for importing tensorflow and it uses GPU, too when I execute some toy example codes (MNIST).\r\nThanks!\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n1. tensorflow install command\r\nconda install -c apple tensorflow-deps\r\nconda install tensorflow\r\npip instal ltensorflow-metal\r\n\r\n2. import tensorflow in terminal (M1 native)\r\n\r\nPython 3.9.7 | packaged by conda-forge | (default, Sep 23 2021, 07:30:24) \r\n[Clang 11.1.0 ] on darwin\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n'>>> import tensorflow as tf\r\nzsh: killed     python\r\n\r\n3. import tensorflow in terminal with Rosetta\r\n\r\nPython 3.9.7 | packaged by conda-forge | (default, Sep 23 2021, 07:30:24)\r\n[Clang 11.1.0 ] on darwin\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n\r\n'>>> import tensorflow as tf\r\nInit Plugin\r\nInit Graph Optimizer\r\nInit Kernel\r\n\r\n'>>> tf.test.is_gpu_available()\r\nWARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.config.list_physical_devices('GPU')` instead.\r\nMetal device set to: Apple M1\r\n\r\nsystemMemory: 16.00 GB\r\nmaxCacheSize: 5.33 GB\r\n\r\n2021-09-26 12:25:10.098855: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\r\n2021-09-26 12:25:10.099073: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\r\nTrue\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n**(tmp) jh@JHs-M1-MacBookAir ~ % conda install -c apple tensorflow-deps**\r\nCollecting package metadata (current_repodata.json): done\r\nSolving environment: failed with initial frozen solve. Retrying with flexible solve.\r\nSolving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\r\nCollecting package metadata (repodata.json): done\r\nSolving environment: done\r\n\r\nPackage Plan\r\n\r\n  environment location: /opt/homebrew/Caskroom/miniforge/base/envs/tmp\r\n\r\n  added / updated specs:\r\n    - tensorflow-deps\r\n\r\n\r\nThe following NEW packages will be INSTALLED:\r\n\r\n  absl-py            conda-forge/noarch::absl-py-0.10.0-pyhd8ed1ab_1\r\n  aiohttp            conda-forge/osx-arm64::aiohttp-3.7.4.post0-py39h5161555_0\r\n  astunparse         conda-forge/noarch::astunparse-1.6.3-pyhd8ed1ab_0\r\n  async-timeout      conda-forge/noarch::async-timeout-3.0.1-py_1000\r\n  attrs              conda-forge/noarch::attrs-21.2.0-pyhd8ed1ab_0\r\n  blinker            conda-forge/noarch::blinker-1.4-py_1\r\n  brotlipy           conda-forge/osx-arm64::brotlipy-0.7.0-py39h5161555_1001\r\n  c-ares             conda-forge/osx-arm64::c-ares-1.17.2-h3422bc3_0\r\n  ca-certificates    conda-forge/osx-arm64::ca-certificates-2021.5.30-h4653dfc_0\r\n  cached-property    conda-forge/noarch::cached-property-1.5.2-hd8ed1ab_1\r\n  cached_property    conda-forge/noarch::cached_property-1.5.2-pyha770c72_1\r\n  cachetools         conda-forge/noarch::cachetools-4.2.2-pyhd8ed1ab_0\r\n  certifi            conda-forge/osx-arm64::certifi-2021.5.30-py39h2804cbe_0\r\n  cffi               conda-forge/osx-arm64::cffi-1.14.6-py39h52b1de0_1\r\n  chardet            conda-forge/osx-arm64::chardet-4.0.0-py39h2804cbe_1\r\n  charset-normalizer conda-forge/noarch::charset-normalizer-2.0.0-pyhd8ed1ab_0\r\n  click              conda-forge/osx-arm64::click-8.0.1-py39h2804cbe_0\r\n  cryptography       conda-forge/osx-arm64::cryptography-3.4.7-py39h73257c9_0\r\n  dataclasses        conda-forge/noarch::dataclasses-0.8-pyhc8e2a94_3\r\n  flatbuffers        conda-forge/osx-arm64::flatbuffers-2.0.0-hbdafb3b_0\r\n  gast               conda-forge/noarch::gast-0.4.0-pyh9f0ad1d_0\r\n  google-auth        conda-forge/noarch::google-auth-1.35.0-pyh6c4a22f_0\r\n  google-auth-oauth~ conda-forge/noarch::google-auth-oauthlib-0.4.6-pyhd8ed1ab_0\r\n  google-pasta       conda-forge/noarch::google-pasta-0.2.0-pyh8c360ce_0\r\n  grpcio             conda-forge/osx-arm64::grpcio-1.38.1-py39h9e1b6db_0\r\n  h5py               conda-forge/osx-arm64::h5py-3.1.0-nompi_py39h99babb8_100\r\n  hdf5               conda-forge/osx-arm64::hdf5-1.10.6-nompi_h0fc092c_1114\r\n  idna               conda-forge/noarch::idna-3.1-pyhd3deb0d_0\r\n  importlib-metadata conda-forge/osx-arm64::importlib-metadata-4.8.1-py39h2804cbe_0\r\n  keras              conda-forge/noarch::keras-2.6.0-pyhd8ed1ab_0\r\n  keras-preprocessi~ conda-forge/noarch::keras-preprocessing-1.1.2-pyhd8ed1ab_0\r\n  krb5               conda-forge/osx-arm64::krb5-1.19.2-hd92b7a7_0\r\n  libblas            conda-forge/osx-arm64::libblas-3.9.0-11_osxarm64_openblas\r\n  libcblas           conda-forge/osx-arm64::libcblas-3.9.0-11_osxarm64_openblas\r\n  libclang           conda-forge/osx-arm64::libclang-11.1.0-default_h0fdd720_1\r\n  libcurl            conda-forge/osx-arm64::libcurl-7.79.1-h8fe1914_0\r\n  libcxx             conda-forge/osx-arm64::libcxx-12.0.1-h168391b_0\r\n  libedit            conda-forge/osx-arm64::libedit-3.1.20191231-hc8eb9b7_2\r\n  libev              conda-forge/osx-arm64::libev-4.33-h642e427_1\r\n  libffi             conda-forge/osx-arm64::libffi-3.4.2-hbdafb3b_4\r\n  libgfortran        conda-forge/osx-arm64::libgfortran-5.0.0.dev0-11_0_1_hf114ba7_23\r\n  libgfortran5       conda-forge/osx-arm64::libgfortran5-11.0.1.dev0-hf114ba7_23\r\n  liblapack          conda-forge/osx-arm64::liblapack-3.9.0-11_osxarm64_openblas\r\n  libllvm11          conda-forge/osx-arm64::libllvm11-11.1.0-h93073aa_2\r\n  libnghttp2         conda-forge/osx-arm64::libnghttp2-1.43.0-hf3018f0_0\r\n  libopenblas        conda-forge/osx-arm64::libopenblas-0.3.17-openmp_h5dd58f0_1\r\n  libprotobuf        conda-forge/osx-arm64::libprotobuf-3.18.0-hccf11d3_0\r\n  libssh2            conda-forge/osx-arm64::libssh2-1.10.0-hb80f160_1\r\n  llvm-openmp        conda-forge/osx-arm64::llvm-openmp-12.0.1-hf3c4609_1\r\n  markdown           conda-forge/noarch::markdown-3.3.4-pyhd8ed1ab_0\r\n  multidict          conda-forge/osx-arm64::multidict-5.1.0-py39h5161555_1\r\n  ncurses            conda-forge/osx-arm64::ncurses-6.2-h9aa5885_4\r\n  numpy              conda-forge/osx-arm64::numpy-1.19.5-py39h1f3b974_2\r\n  oauthlib           conda-forge/noarch::oauthlib-3.1.1-pyhd8ed1ab_0\r\n  openssl            conda-forge/osx-arm64::openssl-1.1.1l-h3422bc3_0\r\n  opt_einsum         conda-forge/noarch::opt_einsum-3.3.0-pyhd8ed1ab_1\r\n  pip                conda-forge/noarch::pip-21.2.4-pyhd8ed1ab_0\r\n  protobuf           conda-forge/osx-arm64::protobuf-3.18.0-py39hfb83b0d_0\r\n  pyasn1             conda-forge/noarch::pyasn1-0.4.8-py_0\r\n  pyasn1-modules     conda-forge/noarch::pyasn1-modules-0.2.7-py_0\r\n  pycparser          conda-forge/noarch::pycparser-2.20-pyh9f0ad1d_2\r\n  pyjwt              conda-forge/noarch::pyjwt-2.1.0-pyhd8ed1ab_0\r\n  pyopenssl          conda-forge/noarch::pyopenssl-20.0.1-pyhd8ed1ab_0\r\n  pysocks            conda-forge/osx-arm64::pysocks-1.7.1-py39h2804cbe_3\r\n  python             conda-forge/osx-arm64::python-3.9.7-h54d631c_2_cpython\r\n  python_abi         conda-forge/osx-arm64::python_abi-3.9-2_cp39\r\n  pyu2f              conda-forge/noarch::pyu2f-0.1.5-pyhd8ed1ab_0\r\n  readline           conda-forge/osx-arm64::readline-8.1-hedafd6a_0\r\n  requests           conda-forge/noarch::requests-2.26.0-pyhd8ed1ab_0\r\n  requests-oauthlib  conda-forge/noarch::requests-oauthlib-1.3.0-pyh9f0ad1d_0\r\n  rsa                conda-forge/noarch::rsa-4.7.2-pyh44b312d_0\r\n  scipy              conda-forge/osx-arm64::scipy-1.7.0-py39h5060c3b_0\r\n  setuptools         conda-forge/osx-arm64::setuptools-58.0.4-py39h2804cbe_2\r\n  six                conda-forge/noarch::six-1.15.0-pyh9f0ad1d_0\r\n  sqlite             conda-forge/osx-arm64::sqlite-3.36.0-h72a2b83_2\r\n  tensorboard        conda-forge/noarch::tensorboard-2.6.0-pyhd8ed1ab_1\r\n  tensorboard-data-~ conda-forge/osx-arm64::tensorboard-data-server-0.6.0-py39hfb8cd70_0\r\n  tensorboard-plugi~ conda-forge/noarch::tensorboard-plugin-wit-1.8.0-pyh44b312d_0\r\n  tensorflow-deps    apple/osx-arm64::tensorflow-deps-2.6.0-0\r\n  termcolor          conda-forge/noarch::termcolor-1.1.0-py_2\r\n  tk                 conda-forge/osx-arm64::tk-8.6.11-he1e0b03_1\r\n  typing-extensions  conda-forge/noarch::typing-extensions-3.7.4.3-0\r\n  typing_extensions  conda-forge/noarch::typing_extensions-3.7.4.3-py_0\r\n  tzdata             conda-forge/noarch::tzdata-2021a-he74cb21_1\r\n  urllib3            conda-forge/noarch::urllib3-1.26.7-pyhd8ed1ab_0\r\n  werkzeug           conda-forge/noarch::werkzeug-2.0.1-pyhd8ed1ab_0\r\n  wheel              conda-forge/noarch::wheel-0.35.1-pyh9f0ad1d_0\r\n  wrapt              conda-forge/osx-arm64::wrapt-1.12.1-py39h5161555_3\r\n  xz                 conda-forge/osx-arm64::xz-5.2.5-h642e427_1\r\n  yarl               conda-forge/osx-arm64::yarl-1.6.3-py39h5161555_2\r\n  zipp               conda-forge/noarch::zipp-3.5.0-pyhd8ed1ab_0\r\n  zlib               conda-forge/osx-arm64::zlib-1.2.11-h31e879b_1009\r\n\r\n\r\nProceed ([y]/n)? y\r\n\r\nPreparing transaction: done\r\nVerifying transaction: done\r\nExecuting transaction: done\r\n\r\n**(tmp) jh@JHs-M1-MacBookAir ~ % conda install tensorflow**\r\nCollecting package metadata (current_repodata.json): done\r\nSolving environment: failed with initial frozen solve. Retrying with flexible solve.\r\nSolving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\r\nCollecting package metadata (repodata.json): done\r\nSolving environment: done\r\n\r\nPackage Plan\r\n\r\n  environment location: /opt/homebrew/Caskroom/miniforge/base/envs/tmp\r\n\r\n  added / updated specs:\r\n    - tensorflow\r\n\r\n\r\nThe following NEW packages will be INSTALLED:\r\n\r\n  abseil-cpp         conda-forge/osx-arm64::abseil-cpp-20210324.2-hbdafb3b_0\r\n  astor              conda-forge/noarch::astor-0.8.1-pyh9f0ad1d_0\r\n  giflib             conda-forge/osx-arm64::giflib-5.2.1-h27ca646_2\r\n  grpc-cpp           conda-forge/osx-arm64::grpc-cpp-1.37.1-h538f867_3\r\n  icu                conda-forge/osx-arm64::icu-68.1-h17758a7_0\r\n  jpeg               conda-forge/osx-arm64::jpeg-9d-h27ca646_0\r\n  libpng             conda-forge/osx-arm64::libpng-1.6.37-hf7e6567_2\r\n  python-flatbuffers conda-forge/noarch::python-flatbuffers-1.12-pyhd8ed1ab_1\r\n  re2                conda-forge/osx-arm64::re2-2021.08.01-hbdafb3b_0\r\n  snappy             conda-forge/osx-arm64::snappy-1.1.8-hc88da5d_3\r\n  tensorflow         conda-forge/osx-arm64::tensorflow-2.6.0-py39hdf13c20_0\r\n  tensorflow-base    conda-forge/osx-arm64::tensorflow-base-2.6.0-py39h34a2d98_0\r\n  tensorflow-estima~ conda-forge/osx-arm64::tensorflow-estimator-2.6.0-py39h4ec10df_0\r\n\r\nThe following packages will be DOWNGRADED:\r\n\r\n  grpcio                              1.38.1-py39h9e1b6db_0 --> 1.37.1-py39h9e1b6db_0\r\n  libprotobuf                             3.18.0-hccf11d3_0 --> 3.15.8-hccf11d3_1\r\n  protobuf                            3.18.0-py39hfb83b0d_0 --> 3.15.8-py39hfb83b0d_0\r\n\r\n\r\nProceed ([y]/n)? y\r\n\r\nPreparing transaction: done\r\nVerifying transaction: done\r\nExecuting transaction: done\r\n\r\n**(tmp) jh@JHs-M1-MacBookAir ~ % pip install tensorflow-metal**\r\nCollecting tensorflow-metal\r\n  Using cached tensorflow_metal-0.1.2-cp39-cp39-macosx_11_0_arm64.whl (1.2 MB)\r\nRequirement already satisfied: wheel~=0.35 in /opt/homebrew/Caskroom/miniforge/base/envs/tmp/lib/python3.9/site-packages (from tensorflow-metal) (0.35.1)\r\nRequirement already satisfied: six~=1.15.0 in /opt/homebrew/Caskroom/miniforge/base/envs/tmp/lib/python3.9/site-packages (from tensorflow-metal) (1.15.0)\r\nInstalling collected packages: tensorflow-metal\r\nSuccessfully installed tensorflow-metal-0.1.2\r\n", "comments": ["I resolved myself this issue by following guide from this link: https://github.com/ctrahey/m1-tensorflow-config, but I still wonder why tensorflow installed via above procedure killed python.", "Did you update bigsur 11.6 recently? I did and I bumped into the same issue, I solved  the problem by upgrading to monterey 12(beta). I think bigsur 11.6 was a problem", "@SeungVictor Thanks for the reply. Yes, I updated may Mac OS to Big Sur 11.6 and Xcode to 13.0, recently. I did not test my tensorflow codes right after the update, so that maybe I would not checked the issue right away. I'll try to check whether the issue still occurs on the Monterey OS.", "Update 2: My tensorflow codes worked well after conda packages update using conda update conda and conda using conda update --all. Maybe the issue was a temporal crash related conda packages.\r\n\r\n**Python 3.9.7 | packaged by conda-forge | (default, Sep 23 2021, 07:30:24) to Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:24:02)** \r\n\r\nPython 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:24:02) \r\n[Clang 11.1.0 ] on darwin\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n'>>>import tensorflow as tf\r\nInit Plugin\r\nInit Graph Optimizer\r\nInit Kernel\r\n'>>>tf.__version__\r\n'2.6.0'\r\n'>>>tf.config.list_physical_devices()\r\n[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52138\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52138\">No</a>\n"]}, {"number": 52136, "title": "\ud83d\udd27 Loosen version constraints on `typing-extensions`", "body": "These changes loosen the version constraints on `typing-extensions` to allow TensorFlow to be installed alongside packages that require `typing-extensions >= 3.10`, such as newer versions of Black and PyLint.\r\n\r\nPreviously TensorFlow required a `typing-extensions` version in the `3.7.x` series. However, the newer `3.10.x` series is fully backwards-compatible with the `3.7.x` series (and there are no `3.8.x` or `3.9.x` series). Therefore, these changes allow `typing-extensions` to be installed using either the `3.7.x` or `3.10.x` series.\r\n\r\nIn order to ensure that any future backwards-incompatible changes in the `typing-extensions` package don't cause issues, TensorFlow's dependency on `typing-extensions` does not allow versions from the `3.11.x` series or beyond (`< 3.11`).\r\n\r\nFixes #51743.\r\n\r\nI wasn't able to run the unit tests locally due to #47989, but I'm hoping that since this is such a minor change all tests will pass successfully \ud83d\ude05", "comments": ["This seems to be fixed already on master by 41e6614. The `install_requires` is now `typing_extensions >= 3.6.6`.", "Hooray! Closing this PR since it is no longer necessary \ud83d\udc4d"]}, {"number": 52135, "title": "Restart kernel (Ipython Konsole in Spyder 5.1.5) with os._exit(0) does not work when using tensorflow.distribute.MirroredStrategy", "body": "Hi together,\r\n\r\nI have installed\r\n\r\n****System information**\r\n- OS Platform and Distribution: Windows Server 2016\r\n- TensorFlow installed from: binary? (conda install)\r\n- TensorFlow version: 2.6.0\r\n- Python version: 3.9.7\r\n- Installed using: pip & conda\r\n- Bazel version: ?\r\n- GCC/Compiler version:  4.7.0 20111220\r\n- CUDA/cuDNN version: 8.1.0.77 & 11.2.2\r\n- GPU model and memory:  2xTesla M60, 2x8gb**\r\n\r\n\r\n**When I use the code:\r\n\r\n```\r\nimport tensorflow\r\nimport os\r\n\r\nos._exit(0)\r\n```\r\n\r\nin Spyder 5.1.5 the kernel (IPython-Konsole) gets restarted without problems.\r\n\r\nWhen I use the code:\r\n\r\n```\r\nimport tensorflow\r\nimport os\r\n\r\nstrategy = tensorflow.distribute.MirroredStrategy(cross_device_ops=tensorflow.distribute.HierarchicalCopyAllReduce())\r\n\r\nos._exit(0)\r\n```\r\n\r\nin Spyder 5.1.5 the kernel (IPython-Konsole) could not be restarted properly.\r\n\r\nThe error message which is displayed is:\r\n\r\n```\r\n**Beim Starten des Kernels ist ein Fehler aufgetreten** (GERMAN)\r\n\r\n2021...15:44:01.699142: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance\u2011critical operations: AVX AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021...15:44:02.898151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6938 MB memory: \u2011> device: 0, name: Tesla M60, pci bus id: 0000:04:00.0, compute capability: 5.2\r\n2021...15:44:02.903256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6939 MB memory: \u2011> device: 1, name: Tesla M60, pci bus id: 0000:05:00.0, compute capability: 5.2\r\n```\r\n**\r\n\r\nI want to quit and restart a kernel session when a condition in the training arises to start the current script from new. (GPU memory etc. gets released with a restart)\r\n\r\nWhy is this behaviour and how can I get around this, thanks?\r\n", "comments": ["Hi @sanatmpa1! Could you please look at this issue ? .  ", "@RomanFoell,\r\n\r\nI tried replicating it with Spyder 4.2.1, but I am not getting the error mentioned. By any chance can you try with spyder `4.2.1` and let us know if you're facing the same?", "Hi sanatmpa1,\r\n\r\nI did not try it on my Remote Server, so the setting in my first post, but I tried it on my Laptop:\r\n\r\n****System information**\r\n- OS Platform and Distribution: Windows 10\r\n- TensorFlow installed from: binary? (conda install)\r\n- TensorFlow version: 2.6.0\r\n- Python version: 3.9.7\r\n- Installed using: pip & conda\r\n- Bazel version: ?\r\n- GCC/Compiler version:  10.2.0\r\n- CUDA/cuDNN version: 8.2.1 & 11.0.221\r\n- GPU model and memory:  no GPU**\r\n\r\nError for the same code with Spyder 5.1.5 ( no problems with the code until os._exit(0) ):\r\n\r\n`An error ocurred while starting the kernel\r\n202117:34:51.150757: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found\r\n202117:34:51.150866: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\r\n202117:34:51.158362: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: RT\u2011Z0M6A\r\n202117:34:51.158967: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: RT\u2011Z0M6A\r\n202117:34:51.159515: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance\u2011critical operations: AVX AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.`\r\n\r\nWhen I use Spyder 4.2.1, the kernel gets frozen with no error message, but no restart of the kernel.\r\n\r\nDo you need any further information. Package list or something like that?\r\n\r\nThanks, Roman\r\n\r\n\r\n\r\n", "When I tried in colab, the log shows the kernel restart is working fine, from which I infer this should not be a bug from TF end. Attached the screen shot for the same.\r\n\r\n![image](https://user-images.githubusercontent.com/87846724/136567253-209a9e04-62a3-492a-8fdc-ba0e83304ca1.png)\r\n", "@RomanFoell,\r\n\r\nCan you take a look at this [SO thread](https://stackoverflow.com/questions/47267716/spyder-an-error-ocurred-while-starting-the-kernel) and also this [link](https://docs.spyder-ide.org/current/troubleshooting/common-illnesses.html) from Spyder which discusses more about the different reasons behind the error `An error ocurred while starting the kernel`.", "Nothing from your advices worked so far. I started an issue topic in the Spyder section:\r\n\r\nhttps://github.com/spyder-ide/spyder/issues/16561\r\n\r\n", "@RomanFoell,\r\n\r\nAs per this [comment](https://github.com/spyder-ide/spyder/issues/16561#issuecomment-947891068), It has been addded to milestone of spyder for 5.2.1 release. Can you close this issue for now and you can create a new one in future if you want to report any issues from TF end. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52135\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52135\">No</a>\n"]}, {"number": 52134, "title": "Function call stack: train_function ", "body": "\r\n![2](https://user-images.githubusercontent.com/26819449/134773664-3244a63e-aab1-4259-8c1a-27a0fb2b91df.JPG)\r\n\r\nWhy I am getting this error? any solution? \r\n\r\n", "comments": ["It seems that one of your images is corrupted. Check your data.", "@bguetarni  how to know which one is corrupted ??", "Not easy. Try to make a script that read each one of your images (without display) and check if the image is correctly opened. Seems that your images are JPEG, find a library to open JPEG images and try that.", "@bguetarni  thank you. actually, I tried running again. Doing a factory reset in google colab and clearing the output. It worked perfectly then."]}, {"number": 52133, "title": "ValueError: unknown url type: '/content/Mango'", "body": "![1](https://user-images.githubusercontent.com/26819449/134773285-e34a8aaf-2cbe-43be-9507-94cf0d47283d.JPG)\r\n I want to run my Mango dataset. Can you please tell me what I am doing wrong here.?\r\nThank You.", "comments": []}, {"number": 52132, "title": "TF 2.6 OOM Error not happening in TF 2.3", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 2.6.0\r\n- Python version: 3.9.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.2.2/8.2.1\r\n- GPU model and memory: NVIDIA GEForce GTX 1060\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nCode crashes at the end of an epoch when training \r\n[tf-2-6.log](https://github.com/tensorflow/tensorflow/files/7229788/tf-2-6.log)\r\nwith a larger size. In TF2.3, warning was generated but code used to run. Also, I have tried using as below\r\n'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \r\nWhen I set this env variable and run, the code simple exits after sometime and as far as i can see, the fit function is not called. \r\n**Describe the expected behavior**\r\nCode is expected to run without crash. In TF 2.3, there is no problem. In tf 2.6, there is a crash.\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\nCode is same as the keras example below\r\nhttps://keras.io/examples/vision/image_classification_from_scratch/\r\nProblem occurs at batch size 32. For this batch size, though i get the initial warning about memory,the code does not crash.\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Hi,\r\n\r\nit seems we have a similar error: https://github.com/tensorflow/tensorflow/issues/52123\r\n\r\nBest, Roman", "Hi @skrishnanv ,Could you try again with \r\n\r\n> batch size =16 \r\n\r\nReference:\r\nhttps://github.com/tensorflow/models/issues/8487\r\n\r\nYou can also stop the  memory growth using commands in below link\r\nhttps://forums.developer.nvidia.com/t/tensorflow-python-framework-errors-impl-resourceexhaustederror/155746", "Hi,\nI have tried with batch size 16 and 24. There is no problem.\nI have also stopped the memory growth. It does not help for 2.6.\nFor 2.3 everything works fine(no crash).\nThanks\n\n\n\nOn Tue, 28 Sep, 2021, 9:47 am mohantym, ***@***.***> wrote:\n\n> Hi @skrishnanv <https://github.com/skrishnanv> ,Could you try again with\n>\n> batch size =16\n>\n> Reference:\n> tensorflow/models#8487 <https://github.com/tensorflow/models/issues/8487>\n>\n> You can also stop the memory growth using commands in below link\n>\n> https://forums.developer.nvidia.com/t/tensorflow-python-framework-errors-impl-resourceexhaustederror/155746\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/52132#issuecomment-928767188>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ALAFBNPHW5T6VTAGWMHTFJTUEE6XDANCNFSM5EXTY7UQ>\n> .\n> Triage notifications on the go with GitHub Mobile for iOS\n> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>\n> or Android\n> <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.\n>\n>\n", "I get a GPU OOM also when I use model.predict(x_input,batch_size = batch_size) with batch_size =1.\r\n\r\nThe training is gone through with batch-size 40.\r\n\r\nx_input was also the training-input with size [5704,122,242,1]. First index is training-amount.\r\n\r\nEven more strange is the fact, that when I  try the same code for different times, it sometimes works, sometimes crashes (model.predict with batch-size 1).\r\n\r\nDifferent size of x_input regarding the amount of samples, so shrinking 5704 to 1000 or something, always works.\r\n\r\nI load the saved model with:\r\n\r\n```\r\nstrategy = tensorflow.distribute.MirroredStrategy(cross_device_ops=tensorflow.distribute.HierarchicalCopyAllReduce())\r\n    \r\n## Open a strategy scope\r\nwith strategy.scope():\r\n\r\n    model = tensorflow.keras.Model(..., ...)\r\n\r\n    ## load model\r\n    model.load_weights(save_load_path_model + load_model_name + '.h5')\r\n        \r\n    ## compile model\r\n    loss = tensorflow.keras.losses.MeanSquaredError(name='MeanSquaredError')\r\n        model.compile(loss=loss, metrics=[tensorflow.keras.metrics.BinaryCrossentropy()])\r\n```\r\n\r\n\r\n(see also, as already mentioned: https://github.com/tensorflow/tensorflow/issues/52123)", "Hi @Saduf2019! Could you please look at this issue! providing GIST in TF [2.5](https://colab.research.google.com/gist/mohantym/2e27202a8a28595da1cc2c4e3b732c4b/image_classification_from_scratch.ipynb#scrollTo=82v3sePkvlva) ,[2.6](https://colab.research.google.com/gist/mohantym/37aecab0cc4b784f56b470b9c0ec65ff/image_classification_from_scratch.ipynb#scrollTo=Dw0o6l9Evlvb) and [2.7 ](https://colab.research.google.com/gist/mohantym/2c5f96c5438653643456e2fec5c15a46/image_classification_from_scratch.ipynb#scrollTo=64m-_h9pvlvb)for reference . Training took a bit longer time and does not seem to replicate in Colab Environment.", "@skrishnanv Quick question. How did you ran with `TF2.3`? For me, it has thrown the following error. Thanks\r\n\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-9-00f9736fd5b5> in <module>()\r\n      1 data_augmentation = keras.Sequential(\r\n      2     [\r\n----> 3         layers.RandomFlip(\"horizontal\"),\r\n      4         layers.RandomRotation(0.1),\r\n      5     ]\r\n\r\nAttributeError: module 'tensorflow.keras.layers' has no attribute 'RandomFlip'", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52132\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52132\">No</a>\n"]}, {"number": 52131, "title": "build failed with bazel 4.2.1 ( windows 10 )", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.7.0rc0\r\n- Python version: 3.9.7\r\n- Installed using virtualenv? pip? conda?: N/A\r\n- Bazel version (if compiling from source): 4.2.1\r\n- GCC/Compiler version (if compiling from source): Visual Studio 2019\r\n- CUDA/cuDNN version: 11.4 / 8.2.6\r\n- GPU model and memory: RTX3090 GDDR6X 24GB\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nbuild error (permission)\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\nbazel build --copt=-nvcc_options=disable-warnings --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\nINFO: Repository llvm-project instantiated at:\r\n  D:/repo/tensorflow/WORKSPACE:15:14: in <toplevel>\r\n  D:/repo/tensorflow/tensorflow/workspace2.bzl:1090:21: in workspace\r\n  D:/repo/tensorflow/tensorflow/workspace2.bzl:654:15: in _tf_repositories\r\n  D:/repo/tensorflow/third_party/llvm/setup.bzl:10:19: in llvm_setup\r\nRepository rule llvm_configure defined at:\r\n  C:/users/alanp/_bazel_alanp/ibqopsat/external/llvm-raw/utils/bazel/configure.bzl:83:33: in <toplevel>\r\nERROR: An error occurred during the fetch of repository 'llvm-project':\r\n   Traceback (most recent call last):\r\n        File \"C:/users/alanp/_bazel_alanp/ibqopsat/external/llvm-raw/utils/bazel/configure.bzl\", line 73, column 25, in _llvm_configure_impl\r\n                _overlay_directories(repository_ctx)\r\n        File \"C:/users/alanp/_bazel_alanp/ibqopsat/external/llvm-raw/utils/bazel/configure.bzl\", line 62, column 13, in _overlay_directories\r\n                fail((\"Failed to execute overlay script: '{cmd}'\\n\" +\r\nError in fail: Failed to execute overlay script: 'D:/anaconda3/python.exe C:/users/alanp/_bazel_alanp/ibqopsat/external/llvm-raw/utils/bazel/overlay_directories.py --src C:/users/alanp/_bazel_alanp/ibqopsat/external/llvm-raw --overlay C:/users/alanp/_bazel_alanp/ibqopsat/external/llvm-raw/utils/bazel/llvm-project-overlay --target .'\r\nExited with code 1\r\nstdout:\r\n\r\nstderr:\r\nTraceback (most recent call last):\r\n  File \"C:\\users\\alanp\\_bazel_alanp\\ibqopsat\\external\\llvm-raw\\utils\\bazel\\overlay_directories.py\", line 92, in <module>\r\n    main(parse_arguments())\r\n  File \"C:\\users\\alanp\\_bazel_alanp\\ibqopsat\\external\\llvm-raw\\utils\\bazel\\overlay_directories.py\", line 80, in main\r\n    _symlink_abs(os.path.join(args.overlay, relpath),\r\n  File \"C:\\users\\alanp\\_bazel_alanp\\ibqopsat\\external\\llvm-raw\\utils\\bazel\\overlay_directories.py\", line 64, in _symlink_abs\r\n    os.symlink(os.path.abspath(from_path), os.path.abspath(to_path))\r\nOSError: [WinError 1314] A required privilege is not held by the client: 'C:\\\\users\\\\alanp\\\\_bazel_alanp\\\\ibqopsat\\\\external\\\\llvm-raw\\\\utils\\\\bazel\\\\llvm-project-overlay\\\\.bazelignore' -> 'C:\\\\users\\\\alanp\\\\_bazel_alanp\\\\ibqopsat\\\\external\\\\llvm-project\\\\.bazelignore'\r\n\r\nERROR: Error fetching repository: Traceback (most recent call last):\r\n        File \"C:/users/alanp/_bazel_alanp/ibqopsat/external/llvm-raw/utils/bazel/configure.bzl\", line 73, column 25, in _llvm_configure_impl\r\n                _overlay_directories(repository_ctx)\r\n        File \"C:/users/alanp/_bazel_alanp/ibqopsat/external/llvm-raw/utils/bazel/configure.bzl\", line 62, column 13, in _overlay_directories\r\n                fail((\"Failed to execute overlay script: '{cmd}'\\n\" +\r\nError in fail: Failed to execute overlay script: 'D:/anaconda3/python.exe C:/users/alanp/_bazel_alanp/ibqopsat/external/llvm-raw/utils/bazel/overlay_directories.py --src C:/users/alanp/_bazel_alanp/ibqopsat/external/llvm-raw --overlay C:/users/alanp/_bazel_alanp/ibqopsat/external/llvm-raw/utils/bazel/llvm-project-overlay --target .'\r\nExited with code 1\r\nstdout:\r\n\r\nstderr:\r\nTraceback (most recent call last):\r\n  File \"C:\\users\\alanp\\_bazel_alanp\\ibqopsat\\external\\llvm-raw\\utils\\bazel\\overlay_directories.py\", line 92, in <module>\r\n    main(parse_arguments())\r\n  File \"C:\\users\\alanp\\_bazel_alanp\\ibqopsat\\external\\llvm-raw\\utils\\bazel\\overlay_directories.py\", line 80, in main\r\n    _symlink_abs(os.path.join(args.overlay, relpath),\r\n  File \"C:\\users\\alanp\\_bazel_alanp\\ibqopsat\\external\\llvm-raw\\utils\\bazel\\overlay_directories.py\", line 64, in _symlink_abs\r\n    os.symlink(os.path.abspath(from_path), os.path.abspath(to_path))\r\nOSError: [WinError 1314] A required privilege is not held by the client: 'C:\\\\users\\\\alanp\\\\_bazel_alanp\\\\ibqopsat\\\\external\\\\llvm-raw\\\\utils\\\\bazel\\\\llvm-project-overlay\\\\.bazelignore' -> 'C:\\\\users\\\\alanp\\\\_bazel_alanp\\\\ibqopsat\\\\external\\\\llvm-project\\\\.bazelignore'\r\n\r\nERROR: D:/repo/tensorflow/tensorflow/tools/pip_package/BUILD:278:10: //tensorflow/tools/pip_package:build_pip_package depends on //tensorflow/compiler/mlir/tensorflow:gen_mlir_passthrough_op_py in repository @ which failed to fetch. no such package '@llvm-project//mlir': Failed to execute overlay script: 'D:/anaconda3/python.exe C:/users/alanp/_bazel_alanp/ibqopsat/external/llvm-raw/utils/bazel/overlay_directories.py --src C:/users/alanp/_bazel_alanp/ibqopsat/external/llvm-raw --overlay C:/users/alanp/_bazel_alanp/ibqopsat/external/llvm-raw/utils/bazel/llvm-project-overlay --target .'\r\nExited with code 1\r\nstdout:\r\n\r\nstderr:\r\nTraceback (most recent call last):\r\n  File \"C:\\users\\alanp\\_bazel_alanp\\ibqopsat\\external\\llvm-raw\\utils\\bazel\\overlay_directories.py\", line 92, in <module>\r\n    main(parse_arguments())\r\n  File \"C:\\users\\alanp\\_bazel_alanp\\ibqopsat\\external\\llvm-raw\\utils\\bazel\\overlay_directories.py\", line 80, in main\r\n    _symlink_abs(os.path.join(args.overlay, relpath),\r\n  File \"C:\\users\\alanp\\_bazel_alanp\\ibqopsat\\external\\llvm-raw\\utils\\bazel\\overlay_directories.py\", line 64, in _symlink_abs\r\n    os.symlink(os.path.abspath(from_path), os.path.abspath(to_path))\r\nOSError: [WinError 1314] A required privilege is not held by the client: 'C:\\\\users\\\\alanp\\\\_bazel_alanp\\\\ibqopsat\\\\external\\\\llvm-raw\\\\utils\\\\bazel\\\\llvm-project-overlay\\\\.bazelignore' -> 'C:\\\\users\\\\alanp\\\\_bazel_alanp\\\\ibqopsat\\\\external\\\\llvm-project\\\\.bazelignore'\r\n\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Analysis failed\r\nINFO: Elapsed time: 110.401s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (53 packages loaded, 14 targets configured)\r\n    currently loading: tensorflow/lite/python ... (2 packages)\r\n    Fetching @flatbuffers; fetching\r\n    Fetching ...uffers; Extracting C:/users/alanp/_bazel_alanp/ibqopsat/external/flatbuffers/temp10953078659403648945/\\\r\nv1.12.0.tar.gz\r\n```", "comments": ["same with bazel 3.7.2\r\n\r\n2.6.0 had no problems like this", "@alanpurple We see that you are using` tf-nightly` version(2.7.0rc0) which is not stable release. Could you please try to  Build from [Source](https://www.tensorflow.org/install/source) using Latest Stable version of TF 2.6.0 and let us know if the issue still persists? Thank you!", "@sushreebarsa I've already told......   see the above comment", "@alanpurple Could you please let us know if we can close the issue?Thanks!", "ERROR: An error occurred during the fetch of repository 'llvm-project'\r\n\r\nI have the same problem with master branch(2.6)!!!!!!!!!!!!\r\n\r\nwin10      bazel 3.7.2   vs2019\r\n\r\nI followed everything in offical website but I still have this problem......\r\n\r\nsorry for my english\r\n\r\n~~~\r\nRepository rule llvm_configure defined at:\r\n  C:/users/admin/_bazel_admin/xv6zejqw/external/llvm-raw/utils/bazel/configure.bzl:83:33: in <toplevel>\r\nERROR: An error occurred during the fetch of repository 'llvm-project':\r\n   Traceback (most recent call last):\r\n        File \"C:/users/admin/_bazel_admin/xv6zejqw/external/llvm-raw/utils/bazel/configure.bzl\", line 73, column 25, in _llvm_configure_impl\r\n                _overlay_directories(repository_ctx)\r\n        File \"C:/users/admin/_bazel_admin/xv6zejqw/external/llvm-raw/utils/bazel/configure.bzl\", line 62, column 13, in _overlay_directories\r\n                fail((\"Failed to execute overlay script: '{cmd}'\\n\" +\r\nError in fail: Failed to execute overlay script: 'C:/Users/admin/AppData/Local/Programs/Python/Python38/python.exe C:/users/admin/_bazel_admin/xv6zejqw/external/llvm-raw/utils/bazel/overlay_directories.py --src C:/users/admin/_bazel_admin/xv6zejqw/external/llvm-raw --overlay C:/users/admin/_bazel_admin/xv6zejqw/external/llvm-raw/utils/bazel/llvm-project-overlay --target .'\r\nExited with code 1\r\nstdout:\r\n~~~", "~~~\r\nWARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/f6def0e40525562b44741e9c489a26f74183f250.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nLoading: 0 packages loaded\r\n    Fetching @llvm-raw; fetching 43s\r\n    Fetching ...vm-raw; Extracting C:/users/admin/_bazel_admin/xv6zejqw/external/llvm-raw/temp17527059103751939930/90b\\\r\nabc86c3feda7f9395b36ccfe72ca61bbc39e2.tar.gz 18s\r\n~~~\r\n\r\nCould it be the link of \"llvm\" down?", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "so, no solution?", "@alanpurple,\r\n\r\nAs it looks like a permission error, Can you confirm if you have tried running the command prompt as admin? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "the overlay script in llvm bazel configure is not compatible with current windows environment\r\n\r\nthis will block building capability of tensorflow by bazel in windows if not using other methods ", "this may not be the problem of tensorflow\r\n\r\nprobably of bazel or llvm project", "@alanpurple,\r\n\r\nThanks for the update. So in this case, Can you try opening an issue in either [bazel](https://github.com/bazelbuild/bazel/issues) or file a bug in [LLVM](https://llvm.org/docs/HowToSubmitABug.html) to get it resolved at earliest?", "@sanatmpa1 \r\nI did post it\r\n\r\nhttps://github.com/bazelbuild/bazel/issues/14176", "Thanks for the confirmation @alanpurple, You can close this issue and create a new one in future if you need to report anything from tensorflow end.", "@sanatmpa1 \r\n\r\nexecuting powershell with admin privilege solved this\r\nof course \"nogcp\" & \"nonccl\" options still not work in windows\r\n\r\nIt seems that bazel&llvm now needs admin privilege execution", "@alanpurple,\r\n\r\nGlad that your problem is solved with admin privilege, infact I have also advised to run with admin privilege in this [comment](https://github.com/tensorflow/tensorflow/issues/52131#issuecomment-940185962) as it looked like a permission error.\r\n\r\nCan you confirm if we are good to close this issue? Thanks!", "closing, but isn't this still a problem? ( since admin privilege wasn't needed before )\r\n\r\nI mean, bazel's problem", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52131\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52131\">No</a>\n", "Admin privilege needed:\r\n\r\nTensorFlow:\r\n> closing, but isn't this still a problem? ( since admin privilege wasn't needed before )\r\n> \r\n> I mean, bazel's problem\r\n\r\nBazel:\r\n> If the tool requires admin privilege to run, then it's not a Bazel bug, I don't think there is anything we can do from the Bazel side.\r\n\r\nSolution: Switch to CMake"]}, {"number": 52130, "title": "Tensorflow build debug failed", "body": "\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux xxx-ROG 5.12.19-1-MANJARO #1 SMP PREEMPT Tue Jul 20 20:57:37 UTC 2021 x86_64 GNU/Linux):\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version: master,lastest commit:225be1b5fb5 Update TFRT dependency to use revision\r\n- Python version:3.9.7\r\n- Installed using virtualenv? pip? conda?:None,just use system python and pip\r\n- Bazel version (if compiling from source): bazel 3.7.2\r\n- GCC/Compiler version (if compiling from source):/usr/bin/gcc-10\r\n- CUDA/cuDNN version:release 11.4, V11.4.100/cudnn8.2\r\n- GPU model and memory:RTX3090 32G GDDR6,memory 64G 3200Mhz\r\n\r\n\r\n\r\n**Describe the problem**\r\n- command:\r\n  -  bazel build --config=mkl --copt=-mavx2 --copt=-O3 --copt=-DINTEL_MKL_QUANTIZED -s -c dbg --verbose_failures //tensorflow/tools/pip_package:build_pip_package\r\n  -  bazel build -c dbg --config=cuda  //tensorflow/tools/pip_package:build_pip_package\r\n  - bazel build -c opt --copt=\"-g\" --cxxopt=\"-g\" //tensorflow/tools/pip_package:build_pip_package\r\n**I had used all method,same error like this:**\r\n\r\n/home/xxx/tensorflow/tensorflow/python/BUILD:3170:24: Linking of rule '//tensorflow/python:_pywrap_tensorflow_internal.so' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc @bazel-out/k8-dbg/bin/tensorflow/python/_pywrap_tensorflow_internal.so-2.params\r\nbazel-out/k8-dbg/bin/external/llvm-project/mlir/libGPUToNVVMTransforms.a(LowerGpuOpsToNVVMOps.pic.o):(.debug_loc+0x6087e): relocation truncated to fit: R_X86_64_32 against `.debug_info'\r\nbazel-out/k8-dbg/bin/external/llvm-project/mlir/libGPUToNVVMTransforms.a(LowerGpuOpsToNVVMOps.pic.o):(.debug_loc+0x60c9c): relocation truncated to fit: R_X86_64_32 against `.debug_info'\r\nbazel-out/k8-dbg/bin/external/llvm-project/mlir/libGPUToNVVMTransforms.a(LowerGpuOpsToNVVMOps.pic.o):(.debug_loc+0x60df0): relocation truncated to fit: R_X86_64_32 against `.debug_info'\r\nbazel-out/k8-dbg/bin/external/llvm-project/mlir/libGPUToNVVMTransforms.a(LowerGpuOpsToNVVMOps.pic.o):(.debug_loc+0x60e1a): relocation truncated to fit: R_X86_64_32 against `.debug_info'\r\nbazel-out/k8-dbg/bin/external/llvm-project/mlir/libGPUToNVVMTransforms.a(LowerGpuOpsToNVVMOps.pic.o):(.debug_loc+0x60ef7): relocation truncated to fit: R_X86_64_32 against `.debug_info'\r\nbazel-out/k8-dbg/bin/external/llvm-project/mlir/libGPUToNVVMTransforms.a(LowerGpuOpsToNVVMOps.pic.o):(.debug_loc+0x60f0f): relocation truncated to fit: R_X86_64_32 against `.debug_info'\r\nbazel-out/k8-dbg/bin/external/llvm-project/mlir/libGPUToNVVMTransforms.a(LowerGpuOpsToNVVMOps.pic.o):(.debug_loc+0x60f27): relocation truncated to fit: R_X86_64_32 against `.debug_info'\r\nbazel-out/k8-dbg/bin/external/llvm-project/mlir/libGPUToNVVMTransforms.a(LowerGpuOpsToNVVMOps.pic.o):(.debug_loc+0x60f3f): relocation truncated to fit: R_X86_64_32 against `.debug_info'\r\nbazel-out/k8-dbg/bin/external/llvm-project/mlir/libGPUToNVVMTransforms.a(LowerGpuOpsToNVVMOps.pic.o):(.debug_loc+0x60f57): relocation truncated to fit: R_X86_64_32 against `.debug_info'\r\nbazel-out/k8-dbg/bin/external/llvm-project/mlir/libGPUToNVVMTransforms.a(LowerGpuOpsToNVVMOps.pic.o):(.debug_loc+0x60fbf): relocation truncated to fit: R_X86_64_32 against `.debug_info'\r\nbazel-out/k8-dbg/bin/external/llvm-project/mlir/libGPUToNVVMTransforms.a(LowerGpuOpsToNVVMOps.pic.o):(.debug_loc+0x60fd7): additional relocation overflows omitted from the output\r\ncollect2: error: ld returned 1 exit status\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\n\r\n", "comments": ["@bleedingfight,\r\n\r\nCan you take a look at this [comment](https://github.com/tensorflow/tensorflow/issues/15172#issuecomment-358682439) from a similar issue and try if it helps? Also try installing GCC 7.3.1 as per the [tested build configuration](https://www.tensorflow.org/install/source#tested_build_configurations). Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52130\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52130\">No</a>\n", "> @bleedingfight,\r\n> \r\n> Can you take a look at this [comment](https://github.com/tensorflow/tensorflow/issues/15172#issuecomment-358682439) from a similar issue and try if it helps? Also try installing GCC 7.3.1 as per the [tested build configuration](https://www.tensorflow.org/install/source#tested_build_configurations). Thanks!\r\n\r\nsolved it!"]}, {"number": 52129, "title": "Tensorflow site language switching", "body": "![tf-site](https://user-images.githubusercontent.com/5677691/134763303-c4bb3386-de5f-41e6-9ac7-6c5ef0f58e9e.png)\r\nSwitching from Russian to English doesn't work.\r\nEnglish -> Russian is ok\r\nRussian -> French is ok\r\nRussian -> Deutsch is ok\r\nI've tried this: https://www.tensorflow.org/ and this\r\nhttps://www.tensorflow.org/?hl=en\r\nAlso I've deleted all other languages except English from my Google Account.", "comments": ["Tested in Google Chrome and Mozilla Firefox browser.", "Hi @zzz7net! I checked the translation in Russian then switched to English from Drop down .Link is working fine for me. Could you  check again after disconnecting from any VPN service if you are using.", "VPN is off and the same result. Even if I connect through VPN a language of the interface should not depend on my location. Because I switch the language manually. I can switch from Russian to any language except English. And this is a bug or web-designer flaw.", "Hi @zzz7net ! I tried to replicate the above situation in my local system (connected with VPN) , It lagged a bit after I switched from Russian to English and then it worked when I refreshed the Site once. Can you check after refreshing the page once?", "@mohantym I appreciate your efforts, but I'm already used to this feature. It shouldn't work that way, but let's say it is a Google feature, not a bug. Hopefully in the future someone will rewrite tensorflow site and everything will work as it should.", "@zzz7net ,We will definitely track this issue . Feel free to close this issue if it helped!", "As far as I know it will be closed automatically after some amount of time. But anyway thanks. This was a nice conversation.", "Closing the issue as language translation is reflecting after refresh( website lags a bit when connected to VPN )."]}, {"number": 52128, "title": "Differences between tf.saved_model.save and model.save", "body": "## URL(s) with the issue:\r\n\r\n- https://www.tensorflow.org/api_docs/python/tf/saved_model/save\r\n- https://www.tensorflow.org/api_docs/python/tf/keras/Model#save\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nI was recently trying to save a subclassed model with `model.save()` (I had always thought `tf.saved_model.save` and `model.save` pretty much work the same way) which led me to receive:\r\n\r\n> ValueError: Model <__main__. ... object at ...> cannot be saved because the input shapes have not been set. Usually, input shapes are automatically determined from calling .fit() or .predict(). To manually set the shapes, call model._set_inputs(inputs).\r\n\r\nwhereas I had already set shapes, I was later able to easily save the model with `tf.saved_model.save` after seeing #31057 .\r\n\r\nI believe adding to the docs how these two work differently would be a really useful addition.\r\n\r\n### Submit a pull request?\r\n\r\n> Are you planning to also submit a pull request to fix the issue?\r\n\r\nI would love to create a PR after first discussing this issue.", "comments": ["@Rishit-dagli \r\n\r\nif you using latest tensor-flow u should use saving custom model, but if we r using 2.0 or below we use save weight and load weight, the issue reported is not a bug or performance issue please open this in tf discussion forum as there is a larger community to support their, and move this to closed status.\r\n\r\n", "Hi @Saduf2019 ,\r\nThanks for the update, that makes sense. But with this issue, I also wanted to request if the _docs_ could explicitly cover the differences between these two.", "@Rishit-dagli \r\nPlease feel free to submit a PR, or share the link where the information is to be updated.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 52127, "title": "Fix tfl.shape and tfl.pseudo_const lowering for dynamic shapes", "body": "Dynamic shapes cannot be converted to a constant during the lowering process.\r\nAlso, changed the rewriter to occur top down. This works better for shapes\r\ninference. Pseudo_const also requires a rewriter as they can be generated\r\nduring canonicalization.", "comments": []}, {"number": 52126, "title": "Update version numbers for TensorFlow 2.7.0-rc0", "body": "Before merging this PR, please double check that it has correctly updated\n`core/public/version.h`, `tools/pip_package/setup.py`, and\n`tensorflow/tensorflow.bzl`. Also review the execution notes below:\n\n```\nMajor: 2 -> 2\nMinor: 7 -> 7\nPatch: 0 -> 0\n\nWARNING: Below are potentially instances of lingering old version string \n\"2.7.0\" in source directory \"tensorflow/\" that are not updated by this script. \nPlease check them manually!\ntensorflow/lite/g3doc/guide/signatures.ipynb:206:2.7.0\ntensorflow/lite/g3doc/performance/quantization_debugger.ipynb:146:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:139:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:142:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:143:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:158:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:159:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:165:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:166:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:173:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:174:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:175:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:176:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:177:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:178:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:179:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:180:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:181:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:182:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:183:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:184:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:185:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:186:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:187:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:188:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:189:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:190:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:191:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:192:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:194:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:194:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:194:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:194:2.7.0\ntensorflow/lite/tools/versioning/runtime_version.cc:97:2.7.0\ntensorflow/lite/tools/versioning/runtime_version.cc:281:2.7.0\ntensorflow/lite/tools/versioning/runtime_version.cc:312:2.7.0\ntensorflow/lite/tools/versioning/runtime_version.cc:365:2.7.0\ntensorflow/tools/pip_package/setup.py:53:2.7.0\ntensorflow/tools/pip_package/setup.py:119:2.7.0\ntensorflow/tools/pip_package/setup.py:121:2.7.0\ntensorflow/tools/pip_package/setup.py:123:2.7.0\nBinary file tensorflow/cc/saved_model/testdata/SimpleV1Model/saved_model.pb \nmatches\ntensorflow/tensorflow.bzl:58:2.7.0\n\nWARNING: Below are potentially instances of lingering old version string \n\"2.7.0\" in source directory \"tensorflow/\" that are not updated by this script. \nPlease check them manually!\ntensorflow/lite/g3doc/guide/signatures.ipynb:206:2.7.0\ntensorflow/lite/g3doc/performance/quantization_debugger.ipynb:146:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:139:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:142:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:143:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:158:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:159:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:165:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:166:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:173:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:174:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:175:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:176:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:177:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:178:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:179:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:180:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:181:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:182:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:183:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:184:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:185:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:186:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:187:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:188:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:189:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:190:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:191:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:192:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:194:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:194:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:194:2.7.0\ntensorflow/lite/g3doc/examples/on_device_training/overview.ipynb:194:2.7.0\ntensorflow/lite/tools/versioning/runtime_version.cc:97:2.7.0\ntensorflow/lite/tools/versioning/runtime_version.cc:281:2.7.0\ntensorflow/lite/tools/versioning/runtime_version.cc:312:2.7.0\ntensorflow/lite/tools/versioning/runtime_version.cc:365:2.7.0\ntensorflow/tools/pip_package/setup.py:53:2.7.0\ntensorflow/tools/pip_package/setup.py:119:2.7.0\ntensorflow/tools/pip_package/setup.py:121:2.7.0\ntensorflow/tools/pip_package/setup.py:123:2.7.0\nBinary file tensorflow/cc/saved_model/testdata/SimpleV1Model/saved_model.pb \nmatches\ntensorflow/tensorflow.bzl:58:2.7.0\n```", "comments": []}, {"number": 52124, "title": "Mysterious bunch of meta_optimizer.cc:801 errors", "body": "- OS Platform and Distribution: Linux Ubuntu 18.04\r\n- TensorFlow compiled from source master, via Docker\r\n- TensorFlow version 2.7.0\r\n- Python version: 3.9.7\r\n- Bazel version: 3.7.2\r\n- CUDA/cuDNN version: 11.4/8.2\r\n- GPU model and memory: NVIDIA 1080 Ti\r\n\r\nI'm getting the following error messages which I don't understand if I have to pay attention to or disregard:\r\n\r\n```\r\n2021-09-24 18:59:43.243685: E tensorflow/core/framework/resource_handle.cc:39] A ref-counted ResourceHandle cannot be serialized losslesslyDeserializing the result is a failure: ShuffleDatasetV3/SeedGenerator_2\r\n2021-09-24 18:59:53.258130: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:380] Filling up shuffle buffer (this may take a while): 2799 of 10000\r\n2021-09-24 19:00:03.260611: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:380] Filling up shuffle buffer (this may take a while): 5660 of 10000\r\n2021-09-24 19:00:13.259760: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:380] Filling up shuffle buffer (this may take a while): 8506 of 10000\r\n2021-09-24 19:00:18.494994: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:405] Shuffle buffer filled.\r\n2021-09-24 19:00:20.879185: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:801] function_optimizer failed: INVALID_ARGUMENT: Node 'model_lstm_partitionedcall_24_RetVal': Connecting to invalid output 27 of source node model/lstm/PartitionedCall which has 27 outputs.\r\n2021-09-24 19:00:20.901732: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:801] layout failed: OUT_OF_RANGE: src_output = 27, but num_outputs is only 27\r\n2021-09-24 19:00:20.929210: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:801] function_optimizer failed: INVALID_ARGUMENT: Node 'model_lstm_partitionedcall_24_RetVal': Connecting to invalid output 27 of source node model/lstm/PartitionedCall which has 27 outputs.\r\n2021-09-24 19:00:20.970470: W tensorflow/core/common_runtime/process_function_library_runtime.cc:859] Ignoring multi-device function optimization failure: INVALID_ARGUMENT: Input 0 of node model_lstm_partitionedcall_2_RetVal was passed bool from model/lstm/PartitionedCall:5 incompatible with expected int32.\r\n2021-09-24 19:00:21.214614: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:801] function_optimizer failed: INVALID_ARGUMENT: Input 5 of node gradients/decoder/lstm_1/PartitionedCall_grad/PartitionedCall was passed int32 from gradients_decoder_lstm_1_partitionedcall_grad_decoder_lstm_1_partitionedcall:0 incompatible with expected bool.\r\n2021-09-24 19:00:21.275349: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:801] function_optimizer failed: INVALID_ARGUMENT: Input 5 of node gradients/decoder/lstm_1/PartitionedCall_grad/PartitionedCall was passed int32 from gradients_decoder_lstm_1_partitionedcall_grad_decoder_lstm_1_partitionedcall:0 incompatible with expected bool.\r\n2021-09-24 19:00:21.331375: W tensorflow/core/common_runtime/process_function_library_runtime.cc:859] Ignoring multi-device function optimization failure: INVALID_ARGUMENT: Input 5 of node gradients/decoder/lstm_1/PartitionedCall_grad/PartitionedCall was passed int32 from gradients_decoder_lstm_1_partitionedcall_grad_decoder_lstm_1_partitionedcall:0 incompatible with expected bool.\r\n```\r\n\r\nThis happens while running custom training loop:\r\n\r\n```\r\nnum_epochs = 20\r\noptimizer = Adam(learning_rate=0.001)\r\ntrain_loss_result = []\r\nval_loss_result = []\r\n\r\n\r\n@tf.function\r\ndef ger_preproc(ger):\r\n    inputs = ger[:, :-1]\r\n    outputs = ger[:, 1:]\r\n    return inputs, outputs\r\n\r\n\r\n@tf.function\r\ndef masked_loss(true_german, predicted_german):\r\n    loss = SparseCategoricalCrossentropy(from_logits=True, reduction='none')(true_german, predicted_german)\r\n    mask = tf.cast(true_german != 0, tf.float32)\r\n    loss *= mask\r\n    return tf.reduce_mean(loss)\r\n\r\n\r\n@tf.function\r\ndef forward_pass(eng_inputs, ger_inputs):\r\n    g_in, g_out = ger_preproc(ger_inputs)\r\n    hidden_state, cell_state = encoder(eng_inputs)\r\n    predicted_german, _, _ = decoder(g_in, hidden_state, cell_state)\r\n    current_loss = masked_loss(g_out, predicted_german)\r\n    return current_loss\r\n\r\n\r\nfor epoch in range(num_epochs):\r\n    train_ds, val_ds = make_dss()\r\n    train_loss = Mean()\r\n    val_loss = Mean()\r\n\r\n    # train\r\n    for eng_inputs, ger_inputs in train_ds:\r\n        with tf.GradientTape() as t:\r\n            current_loss = forward_pass(eng_inputs, ger_inputs)\r\n        trainable_vars = encoder.trainable_variables + decoder.trainable_variables\r\n        grads = t.gradient(current_loss, trainable_vars)\r\n        optimizer.apply_gradients(zip(grads, trainable_vars))\r\n        train_loss(current_loss)\r\n\r\n    # validate\r\n    for eng_inputs, ger_inputs in val_ds:\r\n        current_loss = forward_pass(eng_inputs, ger_inputs)\r\n        val_loss(current_loss)\r\n```\r\n\r\nThe funny thing [here](https://www.tensorflow.org/text/tutorials/nmt_with_attention#test_the_training_step) they have similar 801 errors:\r\n\r\n```\r\n2021-08-31 11:08:27.919851: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:801] function_optimizer failed: Invalid argument: Input 6 of node gradient_tape/while/while_grad/body/_531/gradient_tape/while/gradients/while/decoder_1/gru_3/PartitionedCall_grad/PartitionedCall was passed variant from gradient_tape/while/while_grad/body/_531/gradient_tape/while/gradients/while/decoder_1/gru_3/PartitionedCall_grad/TensorListPopBack_2:1 incompatible with expected float.\r\n2021-08-31 11:08:28.004195: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:801] shape_optimizer failed: Out of range: src_output = 25, but num_outputs is only 25\r\n2021-08-31 11:08:28.044145: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:801] layout failed: Out of range: src_output = 25, but num_outputs is only 25\r\n2021-08-31 11:08:28.169643: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:801] function_optimizer failed: Invalid argument: Input 6 of node gradient_tape/while/while_grad/body/_531/gradient_tape/while/gradients/while/decoder_1/gru_3/PartitionedCall_grad/PartitionedCall was passed variant from gradient_tape/while/while_grad/body/_531/gradient_tape/while/gradients/while/decoder_1/gru_3/PartitionedCall_grad/TensorListPopBack_2:1 incompatible with expected float.\r\n2021-08-31 11:08:28.227653: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:801] shape_optimizer failed: Out of range: src_output = 25, but num_outputs is only 25\r\n2021-08-31 11:08:28.301920: W tensorflow/core/common_runtime/process_function_library_runtime.cc:841] Ignoring multi-device function optimization failure: Invalid argument: Input 1 of node while/body/_1/while/TensorListPushBack_56 was passed float from while/body/_1/while/decoder_1/gru_3/PartitionedCall:6 incompatible with expected variant.\r\n{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.0628138>}\r\n```\r\nwhich they explain will disappear after couple of training loops.\r\n\r\nInterestingly enough, when I run the same code on Google Colab I don't have any errors\r\n\r\n**Question:**\r\n\r\n1. What these errors mean and should I pay attention to them?\r\n2. Does not having these errors on Colab mean there is a problem with locally compiled TF?", "comments": ["Hi @sbushmanov ! Could you please provide a Colab gist for the same code as It will help expedite the issue.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 52123, "title": "GPU Out of Memory for different training-data sizes but same training/model configurations (tested on two installations of python)", "body": "Hi together,\r\n\r\nI have installed\r\n\r\n****System information**\r\n- OS Platform and Distribution: Windows Server 2016\r\n- TensorFlow installed from: binary? (conda install)\r\n- TensorFlow version: 2.6.0\r\n- Python version: 3.9.7\r\n- Installed using: pip & conda\r\n- Bazel version: ?\r\n- GCC/Compiler version:  4.7.0 20111220\r\n- CUDA/cuDNN version: 8.1.0.77 & 11.2.2\r\n- GPU model and memory:  2xTesla M60, 2x8gb**\r\n\r\n**I train a model with tensorflow.keras on two GPUs, Tesla M60.\r\n\r\nThe model gets trained successfully when I limit the amount of training-data below a certain value (around 700). When i go above that value I get an out of memory error for the GPU (overall possible training-data size is 2196).** \r\n\r\n**I use the same setting for the model- and training configuration, but feed different size of training-data:\r\n\r\n```\r\nlearning_rate = 0.001\r\nepochs = 200\r\nbatch_size = 80\r\nbuffer = 1000;\r\n\r\nx_train = io.loadmat(...)\r\nx_train = x_train[0:700,:,:] # optional\r\ny_train = io.loadmat(...)\r\ny_train = x_train[0:700,:,:] # optional\r\nx_test = io.loadmat(...)\r\ny_test = io.loadmat(...)\r\n\r\nstrategy = tensorflow.distribute.MirroredStrategy(cross_device_ops=tensorflow.distribute.HierarchicalCopyAllReduce())\r\n\r\nwith strategy.scope():\r\n    \r\n     autoencoder = tensorflow.keras.Model(...)\r\n    \r\n     loss = tensorflow.keras.losses.MeanSquaredError(name='MeanSquaredError')\r\n\r\n     autoencoder.compile(optimizer=tensorflow.keras.optimizers.Adam(learning_rate=learning_rate), loss=loss])\r\n\r\ntrain_data = tensorflow.data.Dataset.from_tensor_slices((x_train, y_train))\r\nval_data = tensorflow.data.Dataset.from_tensor_slices((x_test, y_test))\r\n\r\ntrain_data = train_data.shuffle(buffer).batch(batch_size)\r\nval_data = val_data.shuffle(buffer).batch(batch_size)\r\n\r\noptions = tensorflow.data.Options()\r\noptions.experimental_distribute.auto_shard_policy = tensorflow.data.experimental.AutoShardPolicy.DATA\r\n\r\ntrain_data = train_data.with_options(options)\r\nval_data = val_data.with_options(options)\r\n\r\nautoencoder.fit(train_data,\r\n          validation_data=val_data,\r\n          epochs=epochs,\r\n          callbacks=[livelossplot.PlotLossesKeras(outputs=[livelossplot.outputs.MatplotlibPlot(figpath=save_string_plot)]),tensorflow.keras.callbacks.TensorBoard(log_dir=\"model\\\\\" + string_name_model, histogram_freq = True, write_grads=True)],\r\n          verbose=0)\r\n```\r\n\r\nWhen I do not use tensorflow.data it works for a size until 1100 and then crashes (with the warning: AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset):\r\n\r\n```\r\nautoencoder.fit(x_train, y_train,\r\n          validation_data=(x_test, y_test),\r\n          epochs=epochs,\r\n          batch_size= batch_size,\r\n          shuffle = 1,\r\n          callbacks=[livelossplot.PlotLossesKeras(outputs=[livelossplot.outputs.MatplotlibPlot(figpath=save_string_plot)]),tensorflow.keras.callbacks.TensorBoard(log_dir=\"model\\\\\" + string_name_model, histogram_freq = True, write_grads=True)],\r\n          verbose=0)\r\n```\r\n\r\nOutput of the console:\r\n\r\n```\r\n2021-09-24 16:37:15.026869: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\nINFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\r\nNumber of GPU devices: 2\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nModel: \"model\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\n...\r\n=================================================================\r\nTotal params: 5,449,621\r\nTrainable params: 5,449,621\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nWARNING: tensorflow:\"write_grads\" will be ignored in TensorFlow 2.0 for the \"TensorBoard\" Callback.\r\n\r\n2021-09-24 16:37:15.026869: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-09-24 16:37:16.869314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7999 MB memory:  -> device: 0, name: Tesla M60, pci bus id: 0000:04:00.0, compute capability: 5.2\r\n2021-09-24 16:37:16.886082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 7999 MB memory:  -> device: 1, name: Tesla M60, pci bus id: 0000:05:00.0, compute capability: 5.2\r\n2021-09-24 16:37:16.940255: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 7.81G (8387559424 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2021-09-24 16:37:17.130269: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 7.81G (8387559424 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2021-09-24 16:37:34.157788: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\r\n2021-09-24 16:37:34.158409: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\r\n2021-09-24 16:37:34.158977: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1614] Profiler found 2 GPUs\r\n2021-09-24 16:37:34.651065: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\r\n2021-09-24 16:37:34.656233: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\r\nINFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = hierarchical_copy, num_packs = 1\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = hierarchical_copy, num_packs = 1\r\n\r\n2021-09-24 16:37:15.026869: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-09-24 16:37:16.869314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7999 MB memory:  -> device: 0, name: Tesla M60, pci bus id: 0000:04:00.0, compute capability: 5.2\r\n2021-09-24 16:37:16.886082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 7999 MB memory:  -> device: 1, name: Tesla M60, pci bus id: 0000:05:00.0, compute capability: 5.2\r\n2021-09-24 16:37:16.940255: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 7.81G (8387559424 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2021-09-24 16:37:17.130269: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 7.81G (8387559424 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2021-09-24 16:37:34.157788: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\r\n2021-09-24 16:37:34.158409: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\r\n2021-09-24 16:37:34.158977: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1614] Profiler found 2 GPUs\r\n2021-09-24 16:37:34.651065: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\r\n2021-09-24 16:37:34.656233: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\r\n2021-09-24 16:37:35.497874: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\r\n2021-09-24 16:37:43.261958: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8100\r\n2021-09-24 16:37:44.298596: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8100\r\n2021-09-24 16:37:56.952727: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.44GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2021-09-24 16:38:00.057046: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 799.90M (838756352 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2021-09-24 16:38:00.067119: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 799.90M (838756352 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n\r\n2021-09-24 16:37:15.026869: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-09-24 16:37:16.869314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7999 MB memory:  -> device: 0, name: Tesla M60, pci bus id: 0000:04:00.0, compute capability: 5.2\r\n2021-09-24 16:37:16.886082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 7999 MB memory:  -> device: 1, name: Tesla M60, pci bus id: 0000:05:00.0, compute capability: 5.2\r\n2021-09-24 16:37:16.940255: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 7.81G (8387559424 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2021-09-24 16:37:17.130269: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 7.81G (8387559424 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2021-09-24 16:37:34.157788: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\r\n2021-09-24 16:37:34.158409: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\r\n2021-09-24 16:37:34.158977: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1614] Profiler found 2 GPUs\r\n2021-09-24 16:37:34.651065: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\r\n2021-09-24 16:37:34.656233: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\r\n2021-09-24 16:37:35.497874: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\r\n2021-09-24 16:37:43.261958: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8100\r\n2021-09-24 16:37:44.298596: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8100\r\n2021-09-24 16:37:56.952727: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.44GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2021-09-24 16:38:00.057046: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 799.90M (838756352 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2021-09-24 16:38:00.067119: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 799.90M (838756352 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2021-09-24 16:38:05.247935: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_1_bfc) ran out of memory trying to allocate 2.60GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2021-09-24 16:38:05.633715: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 799.90M (838756352 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2021-09-24 16:38:05.635113: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_1_bfc) ran out of memory trying to allocate 592.64MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2021-09-24 16:38:05.637273: W tensorflow/core/kernels/gpu_utils.cc:49] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\r\n2021-09-24 16:38:05.676313: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_1_bfc) ran out of memory trying to allocate 2.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2021-09-24 16:38:09.847595: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_1_bfc) ran out of memory trying to allocate 2.56GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2021-09-24 16:38:10.081564: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 799.90M (838756352 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2021-09-24 16:38:10.094857: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 799.90M (838756352 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2021-09-24 16:38:10.096256: W tensorflow/core/common_runtime/bfc_allocator.cc:457] Allocator (GPU_0_bfc) ran out of memory trying to allocate 576.64MiB (rounded to 604651520)requested by op model/up_sampling2d_2/resize/ResizeNearestNeighbor\r\nIf the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \r\nCurrent allocation summary follows.\r\nCurrent allocation summary follows.\r\n2021-09-24 16:38:10.100036: I tensorflow/core/common_runtime/bfc_allocator.cc:1004] BFCAllocator dump for GPU_0_bfc\r\n2021-09-24 16:38:10.101103: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (256): \tTotal Chunks: 53, Chunks in use: 51. 13.3KiB allocated for chunks. 12.8KiB in use in bin. 464B client-requested in use in bin.\r\n2021-09-24 16:38:10.103078: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (512): \tTotal Chunks: 6, Chunks in use: 6. 3.0KiB allocated for chunks. 3.0KiB in use in bin. 3.0KiB client-requested in use in bin.\r\n2021-09-24 16:38:10.104925: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (1024): \tTotal Chunks: 7, Chunks in use: 7. 7.5KiB allocated for chunks. 7.5KiB in use in bin. 7.0KiB client-requested in use in bin.\r\n2021-09-24 16:38:10.106369: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (2048): \tTotal Chunks: 6, Chunks in use: 6. 12.0KiB allocated for chunks. 12.0KiB in use in bin. 12.0KiB client-requested in use in bin.\r\n2021-09-24 16:38:10.107841: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2021-09-24 16:38:10.109201: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (8192): \tTotal Chunks: 3, Chunks in use: 3. 24.0KiB allocated for chunks. 24.0KiB in use in bin. 24.0KiB client-requested in use in bin.\r\n2021-09-24 16:38:10.110729: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2021-09-24 16:38:10.112922: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (32768): \tTotal Chunks: 2, Chunks in use: 2. 80.0KiB allocated for chunks. 80.0KiB in use in bin. 80.0KiB client-requested in use in bin.\r\n2021-09-24 16:38:10.114261: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (65536): \tTotal Chunks: 3, Chunks in use: 3. 295.0KiB allocated for chunks. 295.0KiB in use in bin. 265.0KiB client-requested in use in bin.\r\n2021-09-24 16:38:10.115402: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (131072): \tTotal Chunks: 1, Chunks in use: 1. 221.3KiB allocated for chunks. 221.3KiB in use in bin. 112.5KiB client-requested in use in bin.\r\n2021-09-24 16:38:10.116460: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2021-09-24 16:38:10.117438: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (524288): \tTotal Chunks: 3, Chunks in use: 3. 2.17MiB allocated for chunks. 2.17MiB in use in bin. 1.88MiB client-requested in use in bin.\r\n2021-09-24 16:38:10.118483: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (1048576): \tTotal Chunks: 3, Chunks in use: 1. 4.57MiB allocated for chunks. 1.51MiB in use in bin. 1.51MiB client-requested in use in bin.\r\n2021-09-24 16:38:10.119711: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (2097152): \tTotal Chunks: 6, Chunks in use: 6. 12.01MiB allocated for chunks. 12.01MiB in use in bin. 12.00MiB client-requested in use in bin.\r\n2021-09-24 16:38:10.120816: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (4194304): \tTotal Chunks: 2, Chunks in use: 2. 9.01MiB allocated for chunks. 9.01MiB in use in bin. 9.01MiB client-requested in use in bin.\r\n2021-09-24 16:38:10.121871: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (8388608): \tTotal Chunks: 8, Chunks in use: 8. 74.46MiB allocated for chunks. 74.46MiB in use in bin. 66.02MiB client-requested in use in bin.\r\n2021-09-24 16:38:10.122955: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2021-09-24 16:38:10.124753: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (33554432): \tTotal Chunks: 5, Chunks in use: 3. 191.93MiB allocated for chunks. 116.25MiB in use in bin. 116.25MiB client-requested in use in bin.\r\n2021-09-24 16:38:10.126652: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (67108864): \tTotal Chunks: 5, Chunks in use: 4. 417.20MiB allocated for chunks. 300.95MiB in use in bin. 267.62MiB client-requested in use in bin.\r\n2021-09-24 16:38:10.127752: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (134217728): \tTotal Chunks: 11, Chunks in use: 10. 1.69GiB allocated for chunks. 1.46GiB in use in bin. 1.46GiB client-requested in use in bin.\r\n2021-09-24 16:38:10.128826: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (268435456): \tTotal Chunks: 10, Chunks in use: 9. 4.64GiB allocated for chunks. 4.38GiB in use in bin. 4.38GiB client-requested in use in bin.\r\n2021-09-24 16:38:10.129892: I tensorflow/core/common_runtime/bfc_allocator.cc:1027] Bin for 576.64MiB was 256.00MiB, Chunk State: \r\n2021-09-24 16:38:10.130516: I tensorflow/core/common_runtime/bfc_allocator.cc:1033]   Size: 268.79MiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 144.16MiB | Requested Size: 144.16MiB | in_use: 1 | bin_num: -1\r\n2021-09-24 16:38:10.131899: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Next region of size 7548803072\r\n2021-09-24 16:38:10.134235: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308600000 of size 256 next 1\r\n2021-09-24 16:38:10.135090: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308600100 of size 1280 next 2\r\n2021-09-24 16:38:10.136035: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308600600 of size 256 next 3\r\n2021-09-24 16:38:10.136988: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308600700 of size 256 next 4\r\n2021-09-24 16:38:10.137955: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308600800 of size 256 next 5\r\n2021-09-24 16:38:10.138876: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308600900 of size 512 next 6\r\n2021-09-24 16:38:10.139927: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308600b00 of size 256 next 9\r\n2021-09-24 16:38:10.140919: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308600c00 of size 256 next 10\r\n2021-09-24 16:38:10.141902: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308600d00 of size 1024 next 11\r\n2021-09-24 16:38:10.142889: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308601100 of size 256 next 14\r\n2021-09-24 16:38:10.143898: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308601200 of size 256 next 15\r\n2021-09-24 16:38:10.144874: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308601300 of size 2048 next 16\r\n2021-09-24 16:38:10.145839: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308601b00 of size 256 next 19\r\n2021-09-24 16:38:10.146883: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308601c00 of size 256 next 20\r\n2021-09-24 16:38:10.147809: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308601d00 of size 256 next 21\r\n2021-09-24 16:38:10.148730: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308601e00 of size 256 next 24\r\n2021-09-24 16:38:10.149641: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308601f00 of size 256 next 25\r\n2021-09-24 16:38:10.150520: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308602000 of size 2048 next 26\r\n2021-09-24 16:38:10.151408: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308602800 of size 1024 next 29\r\n2021-09-24 16:38:10.152308: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308602c00 of size 512 next 33\r\n2021-09-24 16:38:10.153202: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308602e00 of size 256 next 34\r\n2021-09-24 16:38:10.154137: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308602f00 of size 256 next 35\r\n2021-09-24 16:38:10.155069: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308603000 of size 256 next 36\r\n2021-09-24 16:38:10.155968: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308603100 of size 256 next 39\r\n2021-09-24 16:38:10.156904: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308603200 of size 256 next 40\r\n2021-09-24 16:38:10.157817: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308603300 of size 256 next 41\r\n2021-09-24 16:38:10.158709: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308603400 of size 256 next 42\r\n2021-09-24 16:38:10.159620: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308603500 of size 256 next 43\r\n2021-09-24 16:38:10.160283: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308603600 of size 256 next 44\r\n2021-09-24 16:38:10.160887: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308603700 of size 256 next 49\r\n2021-09-24 16:38:10.161529: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308603800 of size 256 next 50\r\n2021-09-24 16:38:10.162132: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308603900 of size 256 next 51\r\n2021-09-24 16:38:10.162729: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308603a00 of size 256 next 52\r\n2021-09-24 16:38:10.163341: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308603b00 of size 256 next 53\r\n2021-09-24 16:38:10.163931: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308603c00 of size 256 next 54\r\n2021-09-24 16:38:10.164527: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308603d00 of size 256 next 55\r\n2021-09-24 16:38:10.165123: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308603e00 of size 256 next 56\r\n2021-09-24 16:38:10.165723: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308603f00 of size 256 next 57\r\n2021-09-24 16:38:10.166320: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308604000 of size 256 next 58\r\n2021-09-24 16:38:10.166919: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308604100 of size 256 next 59\r\n2021-09-24 16:38:10.167585: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308604200 of size 512 next 61\r\n2021-09-24 16:38:10.168191: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308604400 of size 1280 next 7\r\n2021-09-24 16:38:10.168783: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308604900 of size 8192 next 8\r\n2021-09-24 16:38:10.169474: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308606900 of size 8192 next 60\r\n2021-09-24 16:38:10.170079: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308608900 of size 2048 next 62\r\n2021-09-24 16:38:10.170778: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308609100 of size 71680 next 23\r\n2021-09-24 16:38:10.171890: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 430861a900 of size 40960 next 22\r\n2021-09-24 16:38:10.173425: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308624900 of size 256 next 63\r\n2021-09-24 16:38:10.174511: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308624a00 of size 2048 next 64\r\n2021-09-24 16:38:10.175245: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308625200 of size 1024 next 66\r\n2021-09-24 16:38:10.175960: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308625600 of size 512 next 67\r\n2021-09-24 16:38:10.176683: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308625800 of size 226560 next 38\r\n2021-09-24 16:38:10.177507: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 430865cd00 of size 115200 next 37\r\n2021-09-24 16:38:10.178267: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308678f00 of size 965120 next 28\r\n2021-09-24 16:38:10.179019: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308764900 of size 655360 next 27\r\n2021-09-24 16:38:10.179931: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308804900 of size 2105344 next 13\r\n2021-09-24 16:38:10.180725: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308a06900 of size 2097152 next 12\r\n2021-09-24 16:38:10.181481: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308c06900 of size 2097152 next 32\r\n2021-09-24 16:38:10.182494: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4308e06900 of size 2097152 next 31\r\n2021-09-24 16:38:10.183930: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4309006900 of size 12582912 next 18\r\n2021-09-24 16:38:10.186139: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4309c06900 of size 8388608 next 17\r\n2021-09-24 16:38:10.187408: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 430a406900 of size 8388608 next 30\r\n2021-09-24 16:38:10.188021: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 430ac06900 of size 165334528 next 45\r\n2021-09-24 16:38:10.188640: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 43149b3700 of size 165334528 next 46\r\n2021-09-24 16:38:10.189259: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 431e760500 of size 828325376 next 47\r\n2021-09-24 16:38:10.189878: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 434fd54300 of size 828325376 next 48\r\n2021-09-24 16:38:10.190495: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4381348100 of size 8388608 next 65\r\n2021-09-24 16:38:10.191114: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4381b48100 of size 256 next 68\r\n2021-09-24 16:38:10.191702: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4381b48200 of size 8192 next 69\r\n2021-09-24 16:38:10.192302: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4381b4a200 of size 512 next 70\r\n2021-09-24 16:38:10.192923: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4381b4a400 of size 2097152 next 71\r\n2021-09-24 16:38:10.193532: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4381d4a400 of size 1024 next 72\r\n2021-09-24 16:38:10.194126: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4381d4a800 of size 8388608 next 73\r\n2021-09-24 16:38:10.194731: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 438254a800 of size 2048 next 74\r\n2021-09-24 16:38:10.195326: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 438254b000 of size 40960 next 75\r\n2021-09-24 16:38:10.195924: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4382555000 of size 256 next 76\r\n2021-09-24 16:38:10.196512: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4382555100 of size 655360 next 77\r\n2021-09-24 16:38:10.197162: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 43825f5100 of size 2048 next 78\r\n2021-09-24 16:38:10.197935: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 43825f5900 of size 8388608 next 79\r\n2021-09-24 16:38:10.198566: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4382df5900 of size 1024 next 80\r\n2021-09-24 16:38:10.199171: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4382df5d00 of size 2097152 next 81\r\n2021-09-24 16:38:10.199774: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4382ff5d00 of size 512 next 82\r\n2021-09-24 16:38:10.200370: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4382ff5f00 of size 115200 next 83\r\n2021-09-24 16:38:10.200972: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4383012100 of size 256 next 84\r\n2021-09-24 16:38:10.201567: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4383012200 of size 256 next 85\r\n2021-09-24 16:38:10.202154: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4383012300 of size 256 next 86\r\n2021-09-24 16:38:10.202746: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4383012400 of size 256 next 87\r\n2021-09-24 16:38:10.203336: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4383012500 of size 256 next 88\r\n2021-09-24 16:38:10.203925: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4383012600 of size 256 next 89\r\n2021-09-24 16:38:10.204516: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4383012700 of size 256 next 90\r\n2021-09-24 16:38:10.205110: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4383012800 of size 256 next 91\r\n2021-09-24 16:38:10.205700: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4383012900 of size 256 next 92\r\n2021-09-24 16:38:10.206305: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4383012a00 of size 256 next 93\r\n2021-09-24 16:38:10.206890: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4383012b00 of size 256 next 94\r\n2021-09-24 16:38:10.207480: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4383012c00 of size 256 next 95\r\n2021-09-24 16:38:10.208083: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] Free  at 4383012d00 of size 256 next 96\r\n2021-09-24 16:38:10.208672: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4383012e00 of size 256 next 97\r\n2021-09-24 16:38:10.209263: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] Free  at 4383012f00 of size 256 next 98\r\n2021-09-24 16:38:10.209855: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4383013000 of size 256 next 99\r\n2021-09-24 16:38:10.210453: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] Free  at 4383013100 of size 1587200 next 121\r\n2021-09-24 16:38:10.211148: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4383196900 of size 1587200 next 122\r\n2021-09-24 16:38:10.212069: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] Free  at 438331a100 of size 1616384 next 107\r\n2021-09-24 16:38:10.213013: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 43834a4b00 of size 256 next 103\r\n2021-09-24 16:38:10.213903: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 43834a4c00 of size 14105088 next 104\r\n2021-09-24 16:38:10.214862: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4384218600 of size 4723968 next 102\r\n2021-09-24 16:38:10.215837: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4384699b00 of size 4723968 next 105\r\n2021-09-24 16:38:10.216802: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4384b1b000 of size 604651520 next 100\r\n2021-09-24 16:38:10.217784: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 43a8bbf000 of size 9447680 next 108\r\n2021-09-24 16:38:10.218759: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 43a94c1900 of size 604651520 next 101\r\n2021-09-24 16:38:10.219791: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 43cd565900 of size 151162880 next 110\r\n2021-09-24 16:38:10.220784: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 43d658e900 of size 604651520 next 106\r\n2021-09-24 16:38:10.221783: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 43fa632900 of size 302325760 next 109\r\n2021-09-24 16:38:10.222803: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 440c684900 of size 302325760 next 111\r\n2021-09-24 16:38:10.223807: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 441e6d6900 of size 75581440 next 114\r\n2021-09-24 16:38:10.224553: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4422eeb100 of size 302325760 next 112\r\n2021-09-24 16:38:10.225302: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4434f3d100 of size 77455360 next 113\r\n2021-09-24 16:38:10.225931: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 443991b100 of size 154910720 next 115\r\n2021-09-24 16:38:10.226570: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4442cd7100 of size 154910720 next 116\r\n2021-09-24 16:38:10.227203: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] Free  at 444c093100 of size 38727680 next 117\r\n2021-09-24 16:38:10.227826: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 444e582100 of size 154910720 next 118\r\n2021-09-24 16:38:10.228460: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 445793e100 of size 40632320 next 119\r\n2021-09-24 16:38:10.229099: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 4459ffe100 of size 40632320 next 120\r\n2021-09-24 16:38:10.229716: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] Free  at 445c6be100 of size 40632320 next 123\r\n2021-09-24 16:38:10.230343: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 445ed7e100 of size 40632320 next 124\r\n2021-09-24 16:38:10.230960: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 446143e100 of size 81264640 next 127\r\n2021-09-24 16:38:10.231581: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] Free  at 44661be100 of size 121896960 next 125\r\n2021-09-24 16:38:10.232205: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 446d5fe100 of size 162529280 next 126\r\n2021-09-24 16:38:10.232828: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 44770fe100 of size 81264640 next 128\r\n2021-09-24 16:38:10.233609: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 447be7e100 of size 151162880 next 130\r\n2021-09-24 16:38:10.234502: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] Free  at 4484ea7100 of size 255160320 next 129\r\n2021-09-24 16:38:10.235133: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 44941fe100 of size 325058560 next 131\r\n2021-09-24 16:38:10.235754: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 44a77fe100 of size 151162880 next 132\r\n2021-09-24 16:38:10.236381: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 44b0827100 of size 151162880 next 133\r\n2021-09-24 16:38:10.237279: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] Free  at 44b9850100 of size 281843456 next 18446744073709551615\r\n2021-09-24 16:38:10.238327: I tensorflow/core/common_runtime/bfc_allocator.cc:1065]      Summary of in-use Chunks by size: \r\n2021-09-24 16:38:10.239150: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 51 Chunks of size 256 totalling 12.8KiB\r\n2021-09-24 16:38:10.239952: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 6 Chunks of size 512 totalling 3.0KiB\r\n2021-09-24 16:38:10.240768: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 5 Chunks of size 1024 totalling 5.0KiB\r\n2021-09-24 16:38:10.241629: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 2 Chunks of size 1280 totalling 2.5KiB\r\n2021-09-24 16:38:10.242496: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 6 Chunks of size 2048 totalling 12.0KiB\r\n2021-09-24 16:38:10.243374: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 3 Chunks of size 8192 totalling 24.0KiB\r\n2021-09-24 16:38:10.244263: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 2 Chunks of size 40960 totalling 80.0KiB\r\n2021-09-24 16:38:10.245130: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 71680 totalling 70.0KiB\r\n2021-09-24 16:38:10.246015: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 2 Chunks of size 115200 totalling 225.0KiB\r\n2021-09-24 16:38:10.247038: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 226560 totalling 221.3KiB\r\n2021-09-24 16:38:10.248025: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 2 Chunks of size 655360 totalling 1.25MiB\r\n2021-09-24 16:38:10.248993: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 965120 totalling 942.5KiB\r\n2021-09-24 16:38:10.249967: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 1587200 totalling 1.51MiB\r\n2021-09-24 16:38:10.250796: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 5 Chunks of size 2097152 totalling 10.00MiB\r\n2021-09-24 16:38:10.251468: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 2105344 totalling 2.01MiB\r\n2021-09-24 16:38:10.252107: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 2 Chunks of size 4723968 totalling 9.01MiB\r\n2021-09-24 16:38:10.252738: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 5 Chunks of size 8388608 totalling 40.00MiB\r\n2021-09-24 16:38:10.253379: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 9447680 totalling 9.01MiB\r\n2021-09-24 16:38:10.254007: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 12582912 totalling 12.00MiB\r\n2021-09-24 16:38:10.254649: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 14105088 totalling 13.45MiB\r\n2021-09-24 16:38:10.255296: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 3 Chunks of size 40632320 totalling 116.25MiB\r\n2021-09-24 16:38:10.255945: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 75581440 totalling 72.08MiB\r\n2021-09-24 16:38:10.256603: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 77455360 totalling 73.87MiB\r\n2021-09-24 16:38:10.257252: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 2 Chunks of size 81264640 totalling 155.00MiB\r\n2021-09-24 16:38:10.257897: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 4 Chunks of size 151162880 totalling 576.64MiB\r\n2021-09-24 16:38:10.258555: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 3 Chunks of size 154910720 totalling 443.20MiB\r\n2021-09-24 16:38:10.259204: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 162529280 totalling 155.00MiB\r\n2021-09-24 16:38:10.259850: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 2 Chunks of size 165334528 totalling 315.35MiB\r\n2021-09-24 16:38:10.260496: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 3 Chunks of size 302325760 totalling 864.96MiB\r\n2021-09-24 16:38:10.261148: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 325058560 totalling 310.00MiB\r\n2021-09-24 16:38:10.261806: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 3 Chunks of size 604651520 totalling 1.69GiB\r\n2021-09-24 16:38:10.262449: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 2 Chunks of size 828325376 totalling 1.54GiB\r\n2021-09-24 16:38:10.263077: I tensorflow/core/common_runtime/bfc_allocator.cc:1072] Sum Total of in-use chunks: 6.34GiB\r\n2021-09-24 16:38:10.263676: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] total_region_allocated_bytes_: 7548803072 memory_limit_: 8387559424 available bytes: 838756352 curr_region_allocation_bytes_: 16775118848\r\n2021-09-24 16:38:10.264780: I tensorflow/core/common_runtime/bfc_allocator.cc:1080] Stats: \r\nLimit:                      8387559424\r\nInUse:                      6807338240\r\nMaxInUse:                   7269322496\r\nNumAllocs:                         237\r\nMaxAllocSize:               2722111488\r\nReserved:                            0\r\nPeakReserved:                        0\r\nLargestFreeBlock:                    0\r\n\r\n2021-09-24 16:38:10.266805: W tensorflow/core/common_runtime/bfc_allocator.cc:468] ******************************************************************************_******__**********___\r\n2021-09-24 16:38:10.267767: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at image_resizer_state.h:150 : Resource exhausted: OOM when allocating tensor with shape[40,122,242,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\nTraceback (most recent call last):\r\n  File \"U:\\Roman Foell\\EAC\\PT Autostart\\autoencoder3.py\", line 368, in <module>\r\n    autoencoder.fit(train_data,\r\n  File \"C:\\Users\\FLO9FE\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1184, in fit\r\n    tmp_logs = self.train_function(iterator)\r\n  File \"C:\\Users\\FLO9FE\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 885, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"C:\\Users\\FLO9FE\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 950, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"C:\\Users\\FLO9FE\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3039, in __call__\r\n    return graph_function._call_flat(\r\n  File \"C:\\Users\\FLO9FE\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1963, in _call_flat\r\n    return self._build_call_outputs(self._inference_function.call(\r\n  File \"C:\\Users\\FLO9FE\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\", line 591, in call\r\n    outputs = execute.execute(\r\n  File \"C:\\Users\\FLO9FE\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 59, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\nResourceExhaustedError: 3 root error(s) found.\r\n  (0) Resource exhausted:  OOM when allocating tensor with shape[40,122,242,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[node model/up_sampling2d_2/resize/ResizeNearestNeighbor (defined at \\Anaconda3\\envs\\keras\\lib\\threading.py:973) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\r\n\t [[div_no_nan/ReadVariableOp/_82]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\r\n  (1) Resource exhausted:  OOM when allocating tensor with shape[40,122,242,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[node model/up_sampling2d_2/resize/ResizeNearestNeighbor (defined at \\Anaconda3\\envs\\keras\\lib\\threading.py:973) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\r\n  (2) Resource exhausted:  OOM when allocating tensor with shape[40,122,242,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[node model/up_sampling2d_2/resize/ResizeNearestNeighbor (defined at \\Anaconda3\\envs\\keras\\lib\\threading.py:973) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\r\n\t [[update_0/AssignAddVariableOp/_115]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_train_function_3609]\r\nFunction call stack:\r\ntrain_function -> train_function -> train_function\r\n```\r\n\r\nThis confuses me, as I think the GPU memory usage is mainly dependent on the batch size, not the amount of training-data and for smaller training-sizes it works with the same batch size.\r\n\r\nCan anyone tell me, what is wrong in my thinking?\r\n\r\nI tested the exact same code for another configuration of python installation:\r\n\r\n****System information**\r\n- OS Platform and Distribution: Windows Server 2016\r\n- TensorFlow installed from: binary? (conda install)\r\n- TensorFlow version: 2.1.0\r\n- Python version: 3.6.12\r\n- Installed using: pip & conda\r\n- Bazel version: ?\r\n- GCC/Compiler version:  4.7.0 20111220\r\n- CUDA/cuDNN version: 7.6.5 & 10.1.243\r\n- GPU model and memory:  2xTesla M60, 2x8gb**\r\n\r\nAnd now the amount of training-data does not affect the GPU memory, so no out of memory any more (each case with tensorflow.data and without).\r\n\r\n\r\nOutput of the console:\r\n```\r\n2021-09-24 16:20:59.870861: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2021-09-24 16:22:10.628594: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2021-09-24 16:22:10.799285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:04:00.0 name: Tesla M60 computeCapability: 5.2\r\ncoreClock: 1.1775GHz coreCount: 16 deviceMemorySize: 7.44GiB deviceMemoryBandwidth: 149.31GiB/s\r\n2021-09-24 16:22:10.804613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: \r\npciBusID: 0000:05:00.0 name: Tesla M60 computeCapability: 5.2\r\ncoreClock: 1.1775GHz coreCount: 16 deviceMemorySize: 7.44GiB deviceMemoryBandwidth: 149.31GiB/s\r\n2021-09-24 16:22:10.806588: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2021-09-24 16:22:10.816111: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2021-09-24 16:22:10.822623: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2021-09-24 16:22:10.826388: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2021-09-24 16:22:10.837615: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2021-09-24 16:22:10.844618: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2021-09-24 16:22:10.866320: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2021-09-24 16:22:10.872124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1\r\n2021-09-24 16:22:10.874800: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\r\n2021-09-24 16:22:11.008743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:04:00.0 name: Tesla M60 computeCapability: 5.2\r\ncoreClock: 1.1775GHz coreCount: 16 deviceMemorySize: 7.44GiB deviceMemoryBandwidth: 149.31GiB/s\r\n2021-09-24 16:22:11.010790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: \r\npciBusID: 0000:05:00.0 name: Tesla M60 computeCapability: 5.2\r\ncoreClock: 1.1775GHz coreCount: 16 deviceMemorySize: 7.44GiB deviceMemoryBandwidth: 149.31GiB/s\r\n2021-09-24 16:22:11.012167: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2021-09-24 16:22:11.012877: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2021-09-24 16:22:11.013581: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2021-09-24 16:22:11.014257: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2021-09-24 16:22:11.014944: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2021-09-24 16:22:11.015645: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2021-09-24 16:22:11.016341: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2021-09-24 16:22:11.019457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1\r\nINFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\r\nNumber of GPU devices: 2\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nModel: \"model\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\n...\r\n=================================================================\r\nTotal params: 5,449,621\r\nTrainable params: 5,449,621\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nWARNING: tensorflow: \"write_grads\" will be ignored in TensorFlow 2.0 for the \"TensorBoard\" Callback.\r\nUsing TensorFlow backend.\r\nINFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = hierarchical_copy, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = hierarchical_copy, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n\r\n2021-09-24 16:20:59.870861: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2021-09-24 16:22:10.628594: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2021-09-24 16:22:10.799285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:04:00.0 name: Tesla M60 computeCapability: 5.2\r\ncoreClock: 1.1775GHz coreCount: 16 deviceMemorySize: 7.44GiB deviceMemoryBandwidth: 149.31GiB/s\r\n2021-09-24 16:22:10.804613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: \r\npciBusID: 0000:05:00.0 name: Tesla M60 computeCapability: 5.2\r\ncoreClock: 1.1775GHz coreCount: 16 deviceMemorySize: 7.44GiB deviceMemoryBandwidth: 149.31GiB/s\r\n2021-09-24 16:22:10.806588: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2021-09-24 16:22:10.816111: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2021-09-24 16:22:10.822623: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2021-09-24 16:22:10.826388: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2021-09-24 16:22:10.837615: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2021-09-24 16:22:10.844618: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2021-09-24 16:22:10.866320: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2021-09-24 16:22:10.872124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1\r\n2021-09-24 16:22:10.874800: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\r\n2021-09-24 16:22:11.008743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:04:00.0 name: Tesla M60 computeCapability: 5.2\r\ncoreClock: 1.1775GHz coreCount: 16 deviceMemorySize: 7.44GiB deviceMemoryBandwidth: 149.31GiB/s\r\n2021-09-24 16:22:11.010790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: \r\npciBusID: 0000:05:00.0 name: Tesla M60 computeCapability: 5.2\r\ncoreClock: 1.1775GHz coreCount: 16 deviceMemorySize: 7.44GiB deviceMemoryBandwidth: 149.31GiB/s\r\n2021-09-24 16:22:11.012167: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2021-09-24 16:22:11.012877: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2021-09-24 16:22:11.013581: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2021-09-24 16:22:11.014257: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2021-09-24 16:22:11.014944: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2021-09-24 16:22:11.015645: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2021-09-24 16:22:11.016341: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2021-09-24 16:22:11.019457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1\r\n2021-09-24 16:22:12.903330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-09-24 16:22:12.904505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 1 \r\n2021-09-24 16:22:12.905254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N Y \r\n2021-09-24 16:22:12.906147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 1:   Y N \r\n2021-09-24 16:22:12.910666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7999 MB memory) -> physical GPU (device: 0, name: Tesla M60, pci bus id: 0000:04:00.0, compute capability: 5.2)\r\n2021-09-24 16:22:12.921192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7999 MB memory) -> physical GPU (device: 1, name: Tesla M60, pci bus id: 0000:05:00.0, compute capability: 5.2)\r\n2021-09-24 16:22:13.020179: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 7.81G (8387559424 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2021-09-24 16:22:13.390727: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 7.81G (8387559424 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2021-09-24 16:22:47.092329: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2021-09-24 16:22:48.266275: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2021-09-24 16:22:49.534717: W tensorflow/stream_executor/gpu/redzone_allocator.cc:312] Internal: Invoking GPU asm compilation is supported on Cuda non-Windows platforms only\r\nRelying on driver to perform ptx compilation. This message will be only logged once.\r\n2021-09-24 16:22:56.271936: W tensorflow/core/common_runtime/bfc_allocator.cc:243] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.60GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2021-09-24 16:22:56.526591: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 799.90M (838756352 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2021-09-24 16:22:56.528823: W tensorflow/core/common_runtime/bfc_allocator.cc:243] Allocator (GPU_0_bfc) ran out of memory trying to allocate 592.64MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2021-09-24 16:22:56.532185: W tensorflow/core/kernels/gpu_utils.cc:48] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\r\n\r\n2021-09-24 16:20:59.870861: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2021-09-24 16:22:10.628594: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2021-09-24 16:22:10.799285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:04:00.0 name: Tesla M60 computeCapability: 5.2\r\ncoreClock: 1.1775GHz coreCount: 16 deviceMemorySize: 7.44GiB deviceMemoryBandwidth: 149.31GiB/s\r\n2021-09-24 16:22:10.804613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: \r\npciBusID: 0000:05:00.0 name: Tesla M60 computeCapability: 5.2\r\ncoreClock: 1.1775GHz coreCount: 16 deviceMemorySize: 7.44GiB deviceMemoryBandwidth: 149.31GiB/s\r\n2021-09-24 16:22:10.806588: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2021-09-24 16:22:10.816111: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2021-09-24 16:22:10.822623: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2021-09-24 16:22:10.826388: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2021-09-24 16:22:10.837615: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2021-09-24 16:22:10.844618: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2021-09-24 16:22:10.866320: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2021-09-24 16:22:10.872124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1\r\n2021-09-24 16:22:10.874800: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\r\n2021-09-24 16:22:11.008743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:04:00.0 name: Tesla M60 computeCapability: 5.2\r\ncoreClock: 1.1775GHz coreCount: 16 deviceMemorySize: 7.44GiB deviceMemoryBandwidth: 149.31GiB/s\r\n2021-09-24 16:22:11.010790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: \r\npciBusID: 0000:05:00.0 name: Tesla M60 computeCapability: 5.2\r\ncoreClock: 1.1775GHz coreCount: 16 deviceMemorySize: 7.44GiB deviceMemoryBandwidth: 149.31GiB/s\r\n2021-09-24 16:22:11.012167: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2021-09-24 16:22:11.012877: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2021-09-24 16:22:11.013581: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2021-09-24 16:22:11.014257: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2021-09-24 16:22:11.014944: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2021-09-24 16:22:11.015645: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2021-09-24 16:22:11.016341: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2021-09-24 16:22:11.019457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1\r\n2021-09-24 16:22:12.903330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-09-24 16:22:12.904505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 1 \r\n2021-09-24 16:22:12.905254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N Y \r\n2021-09-24 16:22:12.906147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 1:   Y N \r\n2021-09-24 16:22:12.910666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7999 MB memory) -> physical GPU (device: 0, name: Tesla M60, pci bus id: 0000:04:00.0, compute capability: 5.2)\r\n2021-09-24 16:22:12.921192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7999 MB memory) -> physical GPU (device: 1, name: Tesla M60, pci bus id: 0000:05:00.0, compute capability: 5.2)\r\n2021-09-24 16:22:13.020179: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 7.81G (8387559424 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2021-09-24 16:22:13.390727: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 7.81G (8387559424 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2021-09-24 16:22:47.092329: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2021-09-24 16:22:48.266275: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2021-09-24 16:22:49.534717: W tensorflow/stream_executor/gpu/redzone_allocator.cc:312] Internal: Invoking GPU asm compilation is supported on Cuda non-Windows platforms only\r\nRelying on driver to perform ptx compilation. This message will be only logged once.\r\n2021-09-24 16:22:56.271936: W tensorflow/core/common_runtime/bfc_allocator.cc:243] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.60GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2021-09-24 16:22:56.526591: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 799.90M (838756352 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2021-09-24 16:22:56.528823: W tensorflow/core/common_runtime/bfc_allocator.cc:243] Allocator (GPU_0_bfc) ran out of memory trying to allocate 592.64MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2021-09-24 16:22:56.532185: W tensorflow/core/kernels/gpu_utils.cc:48] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\r\n2021-09-24 16:22:59.342139: W tensorflow/core/common_runtime/bfc_allocator.cc:243] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2021-09-24 16:23:02.347060: W tensorflow/core/common_runtime/bfc_allocator.cc:243] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.56GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2021-09-24 16:23:06.302744: W tensorflow/core/common_runtime/bfc_allocator.cc:243] Allocator (GPU_1_bfc) ran out of memory trying to allocate 2.60GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2021-09-24 16:23:06.604781: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 799.90M (838756352 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2021-09-24 16:23:06.606373: W tensorflow/core/common_runtime/bfc_allocator.cc:243] Allocator (GPU_1_bfc) ran out of memory trying to allocate 592.64MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n\r\n2021-09-24 16:20:59.870861: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2021-09-24 16:22:10.628594: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2021-09-24 16:22:10.799285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:04:00.0 name: Tesla M60 computeCapability: 5.2\r\ncoreClock: 1.1775GHz coreCount: 16 deviceMemorySize: 7.44GiB deviceMemoryBandwidth: 149.31GiB/s\r\n2021-09-24 16:22:10.804613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: \r\npciBusID: 0000:05:00.0 name: Tesla M60 computeCapability: 5.2\r\ncoreClock: 1.1775GHz coreCount: 16 deviceMemorySize: 7.44GiB deviceMemoryBandwidth: 149.31GiB/s\r\n2021-09-24 16:22:10.806588: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2021-09-24 16:22:10.816111: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2021-09-24 16:22:10.822623: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2021-09-24 16:22:10.826388: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2021-09-24 16:22:10.837615: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2021-09-24 16:22:10.844618: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2021-09-24 16:22:10.866320: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2021-09-24 16:22:10.872124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1\r\n2021-09-24 16:22:10.874800: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\r\n2021-09-24 16:22:11.008743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:04:00.0 name: Tesla M60 computeCapability: 5.2\r\ncoreClock: 1.1775GHz coreCount: 16 deviceMemorySize: 7.44GiB deviceMemoryBandwidth: 149.31GiB/s\r\n2021-09-24 16:22:11.010790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: \r\npciBusID: 0000:05:00.0 name: Tesla M60 computeCapability: 5.2\r\ncoreClock: 1.1775GHz coreCount: 16 deviceMemorySize: 7.44GiB deviceMemoryBandwidth: 149.31GiB/s\r\n2021-09-24 16:22:11.012167: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2021-09-24 16:22:11.012877: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2021-09-24 16:22:11.013581: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2021-09-24 16:22:11.014257: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2021-09-24 16:22:11.014944: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2021-09-24 16:22:11.015645: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2021-09-24 16:22:11.016341: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2021-09-24 16:22:11.019457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1\r\n2021-09-24 16:22:12.903330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-09-24 16:22:12.904505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 1 \r\n2021-09-24 16:22:12.905254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N Y \r\n2021-09-24 16:22:12.906147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 1:   Y N \r\n2021-09-24 16:22:12.910666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7999 MB memory) -> physical GPU (device: 0, name: Tesla M60, pci bus id: 0000:04:00.0, compute capability: 5.2)\r\n2021-09-24 16:22:12.921192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7999 MB memory) -> physical GPU (device: 1, name: Tesla M60, pci bus id: 0000:05:00.0, compute capability: 5.2)\r\n2021-09-24 16:22:13.020179: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 7.81G (8387559424 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2021-09-24 16:22:13.390727: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 7.81G (8387559424 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2021-09-24 16:22:47.092329: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2021-09-24 16:22:48.266275: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2021-09-24 16:22:49.534717: W tensorflow/stream_executor/gpu/redzone_allocator.cc:312] Internal: Invoking GPU asm compilation is supported on Cuda non-Windows platforms only\r\nRelying on driver to perform ptx compilation. This message will be only logged once.\r\n2021-09-24 16:22:56.271936: W tensorflow/core/common_runtime/bfc_allocator.cc:243] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.60GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2021-09-24 16:22:56.526591: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 799.90M (838756352 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\nlocator (GPU_0_bfc) ran out of memory trying to allocate 592.64MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2021-09-24 16:22:56.532185: W tensorflow/core/kernels/gpu_utils.cc:48] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\r\n2021-09-24 16:22:59.342139: W tensorflow/core/common_runtime/bfc_allocator.cc:243] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2021-09-24 16:23:02.347060: W tensorflow/core/common_runtime/bfc_allocator.cc:243] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.56GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2021-09-24 16:23:06.302744: W tensorflow/core/common_runtime/bfc_allocator.cc:243] Allocator (GPU_1_bfc) ran out of memory trying to allocate 2.60GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2021-09-24 16:23:06.604781: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 799.90M (838756352 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2021-09-24 16:23:06.606373: W tensorflow/core/common_runtime/bfc_allocator.cc:243] Allocator (GPU_1_bfc) ran out of memory trying to allocate 592.64MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2021-09-24 16:23:09.801961: W tensorflow/core/common_runtime/bfc_allocator.cc:243] Allocator (GPU_1_bfc) ran out of memory trying to allocate 2.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n```\r\n\r\nI wanted to use the latest version because of some additional features. So can anyone tell me still, what might went wrong?\r\n**\r\n", "comments": ["Hi,\r\n\r\nsimilar errors: https://github.com/tensorflow/tensorflow/issues/52132\r\n\r\nBest, Roman", "@RomanFoell \r\nIs this still an issue.", "Hm, yes, I mean https://github.com/tensorflow/tensorflow/issues/52132 is not solved as well, isnt it?\r\n\r\nYou can close this issue, if you link it to the one above. This would be ok.\r\n\r\nI think they both are that similar, that if either one of them is solved, the other will be as well.", "Moving this to closed status as per above comment", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52123\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52123\">No</a>\n"]}, {"number": 52122, "title": "TFLite dynamic size does not work for GRUs", "body": "TensorFlow and TensorFlowLite allow to use dynamic sizes for some given dimensions, basicaly setting them to None.\r\nThis works perfectly with a convolutional layer, however does not seem to work in TensorFlowLite for GRU (most probably all RNNs) layers. The following code and output gives an example of the error:\r\n\r\n```\r\nRuntimeError: tensorflow/lite/kernels/concatenation.cc:80 t->dims->data[d] != t0->dims->data[d] (2 != 1)Node number 24 (CONCATENATION) failed to prepare.\r\nNode number 10 (WHILE) failed to invoke.\r\n```\r\n\r\n```\r\n###\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras.layers import Input, GRU, Conv1D\r\n\r\n###\r\ndef get_tf_net(input_shp, outsize_size=10, layer_name='RNN'):\r\n\r\n    if layer_name=='RNN':\r\n        layer = GRU(outsize_size, return_sequences=True, use_bias=True)\r\n    elif layer_name=='Conv':\r\n        layer = Conv1D(outsize_size, kernel_size=1, padding='same')\r\n        \r\n    inputs = Input(shape=input_shp)\r\n    outputs = layer(inputs)\r\n    model = Model(inputs, outputs)\r\n    \r\n    return model\r\ndef convert2TFLite(path2Model, path2Save):\r\n\r\n    if path2Model.split('.')[-1]=='h5':\r\n        model = tf.keras.models.load_model(path2Model)\r\n        model = tf.lite.TFLiteConverter.from_keras_model(model)\r\n    elif path2Model.split('.')[-1]=='pb':\r\n        model = tf.lite.TFLiteConverter.from_saved_model(path2Model)\r\n\r\n    model = model.convert()\r\n\r\n    with open(path2Save, 'wb') as f:\r\n        f.write(model)\r\n\r\n    return\r\n\r\nprint(f\"TensorFlow Version = {tf.__version__}\")\r\n\r\ndef main(layer_name):\r\n    \r\n    ###\r\n    tensor_shape = (1, 3, 5)\r\n    outsize_size = 7\r\n    path_to_save = \"model\"\r\n\r\n    ###\r\n    input_shp = list(tensor_shape)\r\n    input_shp[0] = None\r\n    input_shp[1] = None\r\n    input_shp = input_shp[1:]\r\n\r\n    model = get_tf_net(input_shp=input_shp, outsize_size=outsize_size, layer_name=layer_name)\r\n    model.compile()\r\n\r\n    model.summary()\r\n\r\n    model.save('{}.h5'.format(path_to_save))\r\n\r\n    path2Model = '{}.h5'.format(path_to_save)\r\n    path2Save = '{}-from-h5.tflite'.format(path_to_save)\r\n    convert2TFLite(path2Model, path2Save)\r\n\r\n    model = tf.lite.Interpreter(model_path=path2Save)\r\n\r\n    input_details = model.get_input_details()\r\n    output_details = model.get_output_details()\r\n\r\n    model.allocate_tensors()\r\n\r\n    ###\r\n    tests = []\r\n\r\n    x = np.random.randn(*tensor_shape).astype(np.float32)\r\n    out_shape = list(x.shape)\r\n    out_shape[-1] = outsize_size\r\n    y = np.random.randn(*out_shape).astype(np.float32)\r\n    tests += [(x,y)]\r\n\r\n    tmp_tensor_shape = list(tensor_shape)\r\n    tmp_tensor_shape[1] = 2*tmp_tensor_shape[1]\r\n    x = np.random.randn(*tmp_tensor_shape).astype(np.float32)\r\n    out_shape = list(x.shape)\r\n    out_shape[-1] = outsize_size\r\n    y = np.random.randn(*out_shape).astype(np.float32)\r\n    tests += [(x,y)]\r\n\r\n    tmp_tensor_shape = list(tensor_shape)\r\n    tmp_tensor_shape[0] = 2*tmp_tensor_shape[0]\r\n    x = np.random.randn(*tmp_tensor_shape).astype(np.float32)\r\n    out_shape = list(x.shape)\r\n    out_shape[-1] = outsize_size\r\n    y = np.random.randn(*out_shape).astype(np.float32)\r\n    tests += [(x,y)]\r\n\r\n    for x,y in tests:\r\n        print(\"Testing with:\",x.shape, y.shape)\r\n        model.resize_tensor_input(input_details[0]['index'], x.shape)\r\n        model.resize_tensor_input(output_details[0]['index'], y.shape)\r\n\r\n        input_details = model.get_input_details()\r\n        output_details = model.get_output_details()\r\n\r\n        model.allocate_tensors()\r\n\r\n        model.set_tensor(input_details[0]['index'], x)\r\n        model.invoke()\r\n        y = model.get_tensor(output_details[0]['index'])\r\n        \r\n    return\r\n\r\nmain(layer_name='Conv')\r\nmain(layer_name='RNN')\r\n```\r\n\r\n```\r\nTensorFlow Version = 2.6.0\r\nModel: \"model\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ninput_1 (InputLayer)         [(None, None, 5)]         0         \r\n_________________________________________________________________\r\nconv1d (Conv1D)              (None, None, 7)           42        \r\n=================================================================\r\nTotal params: 42\r\nTrainable params: 42\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nINFO:tensorflow:Assets written to: /tmp/tmpv4iu1kbp/assets\r\nTesting with: (1, 3, 5) (1, 3, 7)\r\nTesting with: (1, 6, 5) (1, 6, 7)\r\nTesting with: (2, 3, 5) (2, 3, 7)\r\nModel: \"model_1\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ninput_2 (InputLayer)         [(None, None, 5)]         0         \r\n_________________________________________________________________\r\ngru (GRU)                    (None, None, 7)           294       \r\n=================================================================\r\nTotal params: 294\r\nTrainable params: 294\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nWARNING:absl:Found untraced functions such as gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\r\nINFO:tensorflow:Assets written to: /tmp/tmpmafb70jj/assets\r\nINFO:tensorflow:Assets written to: /tmp/tmpmafb70jj/assets\r\nTesting with: (1, 3, 5) (1, 3, 7)\r\nTesting with: (1, 6, 5) (1, 6, 7)\r\nTesting with: (2, 3, 5) (2, 3, 7)\r\n\r\nRuntimeErrorTraceback (most recent call last)\r\n<ipython-input-1-1cc2a142f111> in <module>\r\n    108 \r\n    109 main(layer_name='Conv')\r\n--> 110 main(layer_name='RNN')\r\n\r\n<ipython-input-1-1cc2a142f111> in main(layer_name)\r\n    102 \r\n    103         model.set_tensor(input_details[0]['index'], x)\r\n--> 104         model.invoke()\r\n    105         y = model.get_tensor(output_details[0]['index'])\r\n    106 \r\n\r\n~/.local/lib/python3.7/site-packages/tensorflow/lite/python/interpreter.py in invoke(self)\r\n    873     \"\"\"\r\n    874     self._ensure_safe()\r\n--> 875     self._interpreter.Invoke()\r\n    876 \r\n    877   def reset_all_variables(self):\r\n\r\nRuntimeError: tensorflow/lite/kernels/concatenation.cc:80 t->dims->data[d] != t0->dims->data[d] (2 != 1)Node number 24 (CONCATENATION) failed to prepare.\r\nNode number 10 (WHILE) failed to invoke.\r\n```", "comments": ["@jvishnuvardhan ,\r\nI was able to reproduce the issue in tf v2.5, v2.6 and nightly.Please find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/c145d603e628bb72ab7db0e4f61e45f8/52122.ipynb).", "@helion-du-mas-des-bourboux-thales I updated `supported_ops` and I don't notice any error. [Here](https://colab.research.google.com/gist/jvishnuvardhan/3c4aa7fdcd5d808f19c362467bc4a48f/untitled1065.ipynb) is a gist for reference. Thanks!\r\n\r\n`        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]`\r\n\r\nPlease verify once and let us know what you think. Thanks!\r\n", "@jvishnuvardhan, thank you for the help.\r\nIndeed it works on nightly, but not on 2.6.0.", "This will be available on next stable version (`TF2.7`) which will be release in near future. Till that time, please use `tf-nightly`.\r\n\r\nI am closing this issue as this was resolved in recent `tf-nightly`. Please feel free to reopen if I am mistaken. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52122\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52122\">No</a>\n"]}, {"number": 52120, "title": "Update release notes for TensorFlow 2.7.0", "body": "This PR is intentionally incomplete. One of the Release Owners for 2.7.0\nneeds to fill in the internal release notes for this version before the PR gets\nsubmitted. Click on the :pencil2: icon in the header for `RELEASE.md` under\n\"Files Changed\" above.", "comments": ["What do you mean?"]}, {"number": 52119, "title": "Update ops.py", "body": "Fixed c++ session API 404 error.", "comments": []}, {"number": 52118, "title": "Different inference result when use models exported by the same ckpt.", "body": "I save tf model multi times using the same ckpt as following:\r\n\r\n```\r\nbuilder = tf.saved_model.builder.SavedModelBuilder(export_path)\r\nbuilder.add_meta_graph_and_variables(\r\n                    sess,\r\n                    tags=[tf.saved_model.tag_constants.SERVING],\r\n                    signature_def_map=signature_def_map,\r\n                    main_op=tf.tables_initializer(),\r\n                    saver=saver,\r\n                )\r\nbuilder.save()\r\n```\r\n\r\nBut when i load model with saved pb and variables(generated by multi times export as above) and infer with the same input. The results are slightly different. Is it normal?\r\n\r\nThanks very much!", "comments": [" \nAh Ha, nice.\n    On Thursday, September 23, 2021, 08:07:47 PM PDT, zhaochaochao ***@***.***> wrote:  \n \n \n\n\nI save tf model multi times using the same ckpt as following:\nbuilder = tf.saved_model.builder.SavedModelBuilder(export_path)\nbuilder.add_meta_graph_and_variables(\n                    sess,\n                    tags=[tf.saved_model.tag_constants.SERVING],\n                    signature_def_map=signature_def_map,\n                    main_op=tf.tables_initializer(),\n                    saver=saver,\n                )\nbuilder.save()\n\nBut when i load model with saved pb and variables(generated by multi times export as above) and infer with the same input. The results are slightly different. Is it normal?\n\nThanks very much!\n\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or unsubscribe.\nTriage notifications on the go with GitHub Mobile for iOS or Android.\n  ", "@zhaocc1106 Could you please refer to the Issue  [link1](https://stackoverflow.com/questions/45705070/how-to-load-and-use-a-saved-model-on-tensorflow), Official documentation  [link2](https://www.tensorflow.org/api_docs/python/tf/compat/v1/saved_model/Builder),[link3](https://www.tensorflow.org/guide/saved_model) , Please let us know if it helps?Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 52117, "title": "the link 404", "body": "examples/lite/examples/pose_estimation/raspberry_pi/setup.sh\r\nline9-10\r\n# Install Python dependencies\r\npython3 -m pip install -r requirements.txt\r\n\r\nthe link in the file requirements.txt --extra-index-url https://google-coral.github.io/py-repo/\r\nargparse cannot found", "comments": ["@liufan19960306 ,\r\nWe see that the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose) has not been filled, could you please do so as it helps us analyse the issue.Also please provide the reference link which you are referring.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "I have verified all the python related [links](https://www.tensorflow.org/install/source), there is no broken link, you may also refer to [link](https://stackoverflow.com/questions/65654215/python-requirements-txt-file-in-package)", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}]