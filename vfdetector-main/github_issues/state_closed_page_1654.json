[{"number": 3287, "title": "tf.cond and tf.case execute all branches", "body": "When I run:\n\n``` python\nimport tensorflow as tf\n\n\nX1 = tf.Variable(1.)\nX2 = tf.Variable(1.)\n\ncond_value = tf.Variable(True)\n\nassign_1 = tf.assign(X1, 2.)\nassign_2 = tf.assign(X2, 2.)\n\nwith tf.control_dependencies([assign_1]):\n    result_1 = tf.identity(X1)\nwith tf.control_dependencies([assign_2]):\n    result_2 = tf.identity(X2)\n\ncond_result = tf.cond(cond_value, lambda: result_1, lambda: result_2)\n\nwith tf.Session() as sesh:\n    sesh.run(tf.initialize_all_variables())\n    sesh.run(cond_result)\n    print(sesh.run(X1), sesh.run(X2))\n```\n\nmy expected output is: 2.0 1.0 but my actual output is 2.0 2.0. I need control flow in my graph that actually controls which nodes get executed, not just selects from a list of tensors. Am I missing some sort of operation here?\n", "comments": ["Assigning to Yuan -- this is expected behavior, but we still need more documentation on this.\n\nI believe if you define your control dependencies as a function, and the lambda calls the function, it will work.\n\ne.g.,\n\n```\ndef fn1():\n  with tf.control_dependencies....\n\ncond_result = tf.cond(cond_value, lambda: fn1(), lambda: fn2())\n```\n\nor something like that.  Essentially the ops have to be defined in the function passed to the lambda for them to not be executed.\n", "ah, I see. This may require a large amount of refactoring on my part\n", "the assigns need to be in the method as well:\n\n``` python\nimport tensorflow as tf\n\n\nX1 = tf.Variable(1.)\nX2 = tf.Variable(1.)\n\ncond_value = tf.Variable(True)\n\n\ndef result_1():\n    assign_1 = tf.assign(X1, 2.)\n    with tf.control_dependencies([assign_1]):\n        return tf.identity(X1)\ndef result_2():\n    assign_2 = tf.assign(X2, 2.)\n    with tf.control_dependencies([assign_2]):\n        return tf.identity(X2)\n\ncond_result = tf.cond(cond_value, result_1, result_2)\n\nwith tf.Session() as sesh:\n    sesh.run(tf.initialize_all_variables())\n    sesh.run(cond_result)\n    print(sesh.run(X1), sesh.run(X2))\n```\n", "Lifting this requirement would allow me to have more modular code when designing resnet structures:\n\n``` python\n...\n        with tf.variable_scope('resnet1'):\n            for i in range(5):\n                with tf.variable_scope(str(i)):\n                    X = self.conv(elu(X1), 3, 3, 16, name='conv1')                # 128 -> 128\n                    X = self.conv(elu(X), 3, 3, 16, name='conv2')                 # 128 -> 128\n                    X1 = self.feedback(X, X1, dropout=0.7)\n...\n```\n\nIn this case, feedback will add the two tensors with a 70% chance or simply pass X1 with a 30% chance.\n", "For your simple example, I believe that you could simply do:\n\n```\n      X1 = tf.Variable(1.)\n      X2 = tf.Variable(1.)\n      cond_value = tf.Variable(True)\n      cond_result = tf.cond(cond_value, lambda: tf.assign(X1, 2.), lambda: tf.assign(X2, 2.))\n\n      sess.run(tf.initialize_all_variables())\n      sess.run(cond_result)\n      print(sess.run(X1), sess.run(X2))\n```\n", "sure, I get that, I threw it together to test the unexpected behavior I was seeing running rnns, wasn't supposed to be a polished example. Now I'm getting some weird behavior when converting my trainable variables to constants. It might be a separate issue but the stack looks like:\n\n```\nTraceback (most recent call last):\n  File \"/usr/local/bin/finalize_graph\", line 9, in <module>\n    load_entry_point('KnitNN==0.5.3', 'console_scripts', 'finalize_graph')()\n  File \"/usr/local/lib/python3.5/site-packages/KnitNN-0.5.3-py3.5.egg/nn/tools/finalize_graph.py\", line 59, in finalize_graph\n    variable_names_whitelist=variables)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/graph_util.py\", line 224, in convert_variables_to_constants\n    returned_variables = sess.run(variable_names)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 382, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 598, in _run\n    processed_fetches = self._process_fetches(fetches)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 553, in _process_fetches\n    'Tensor. (%s)' % (subfetch, fetch, str(e)))\nValueError: Fetch argument 'base_model/cond/resnet1/Assign/Switch:1:0' of 'base_model/cond/resnet1/Assign/Switch:1:0' cannot be interpreted as a Tensor. (The name 'base_model/cond/resnet1/Assign/Switch:1:0' looks a like a Tensor name, but is not a valid one. Tensor names must be of the form \"<op_name>:<output_index>\".)\n```\n", "@vrv @yuanbyu  is there other way to avoid evaluating all branches other than put the operator creation inside the lambda?\r\nThere are many cases like:\r\n\r\n```python\r\n# Complex code creating two subgraphs\r\ntf.case(predicate, true_fn=lambda: subgraph_a, false_fn=lambda: subgraph_b)\r\n```\r\n\r\nIt would be hard to refactor the creation of `subgraph_a` and `subgraph_b` into the lambda for `true_fn` and `false_fn`. Maybe add an additional argument that avoids evaluating all branches?\r\nThis feels like a limitation of the expressiveness of TF Python API, rather than an intended feature.\r\n"]}, {"number": 3286, "title": "Branch 127253427", "body": "", "comments": []}, {"number": 3285, "title": "How to install with GLIBC_2.12?", "body": "I install it directly with conda\n\nAnd get \"version `GLIBC_2.17' not found,required by _pywrap_tensorflow.so\"\n\nI use LD_PRELOAD to load GLIBC_2.17\n\nAnd get \"__vdso_time: invalid mode for dlopen(): Invalid argument\"\n\nI try to install from the source, but bazel require GLIBC_2.14\n\nWhat should I do?\n\n---\n\n```\nuname -a\nLinux mu01 2.6.32-358.el6.x86_64 #1 SMP Tue Jan 29 11:47:41 EST 2013 x86_64 x86_64 x86_64 GNU/Linux\n```\n\nand the version of glibc is 2.12\n", "comments": ["A possible solution would be to build bazel from source as well.\nYou can then use your custom bazel to build tensorflow.\nThis requires a bit more work, but would be more robust.\n", "Hi,\n\nthis is my solution to run it on a CentOS6 machine.\n\n```\n# create dirs\nmkdir -p tools/libc6_2.19\ncd ~/tools/\n\n#http://stackoverflow.com/questions/33655731/error-while-importing-tensorflow-in-python2-7-in-ubuntu-12-04-glibc-2-17-not-f/34897674#34897674\nwget http://launchpadlibrarian.net/198723917/libc6_2.19-0ubuntu6.6_amd64.deb\nwget http://launchpadlibrarian.net/198723918/libc6-dev_2.19-0ubuntu6.6_amd64.deb\nwget ftp://rpmfind.net/linux/sourceforge/m/ma/magicspecs/apt/3.0/x86_64/RPMS.lib/libstdc++-4.8.2-7mgc30.x86_64.rpm\nrpm2cpio libstdc++-4.8.2-7mgc30.x86_64.rpm| cpio -idmv\n```\n\nand run it with:\n\n```\nLD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:$HOME/tools/libc6_2.19/lib/x86_64-linux-gnu/:$HOME/tools/libc6_2.19/usr/lib64/\" $HOME/tools/libc6_2.19/lib/x86_64-linux-gnu/ld-2.19.so `which python` main.py\n```\n", "I tried it, but what I get is :\n\n```\nLD_LIBRARY_PATH=\"$HOME/jupyter_workspace/tf/lib/x86_64-linux-gnu/:$HOME/jupyter_workspace/tf/usr/lib64/\" $HOME/jupyter_workspace/tf/lib/x86_64-linux-gnu/ld-2.17.so `which python`\nPython 2.7.12 |Continuum Analytics, Inc.| (default, Jul  2 2016, 17:42:40)\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\nAnaconda is brought to you by Continuum Analytics.\nPlease check out: http://continuum.io/thanks and https://anaconda.org\n>>> import tensorflow\nsh: error while loading shared libraries: __vdso_time: invalid mode for dlopen(): Invalid argument\nsh: error while loading shared libraries: __vdso_time: invalid mode for dlopen(): Invalid argument\nsh: error while loading shared libraries: __vdso_time: invalid mode for dlopen(): Invalid argument\nsh: error while loading shared libraries: __vdso_time: invalid mode for dlopen(): Invalid argument\n>>>\n```\n\nT_T\n\nit seems that this glibc and the old vdso are incompatible?\n", "Are you using a Redhat linux? It is not officially supported so please move this to stackoverflow where you might get more help. Thanks.\n"]}, {"number": 3284, "title": "add norm1d and 2d support", "body": "#2826\n- add norm1d support\n- I'll write norm2d, and add test\n", "comments": ["Can one of the admins verify this patch?\n", "I'm not sure how much of this CL overlaps (if any) with the existing ops, assigning to those who are more familiar\n", "@vrv I see #2826 , so I think it's not implemented before\n", "This is a premature optimization. See tf.contrib.distributions.\n\nThis op doesn't support broadcasting and has no registered gradients.  It's not clear that it's any faster the equivalent tensorflow code.\n", "@benoitsteiner @ebrevdo thank you for the code review, learned  a lot. can I continue working on this pr, adding broadcasting and gradients?\n", "Can one of the admins verify this patch?\n", "I think some numbers about why tf.contrib.distributions is not fast enough would be needed before accepting this (in general we only try to add custom ops when we can't get the equivalent from compositions of primitive ops at a reasonable speed).\n"]}, {"number": 3283, "title": "Fix bug in gcs_smoke", "body": "", "comments": []}, {"number": 3282, "title": "Add Install step in Installation for Linux.", "body": "- Add Install step in in Installation for Linux for better following installation.\n- Fix layout in RNN tutorials.\n", "comments": ["Can one of the admins verify this patch?\n", "Merged configure the installation as suggested. But I didn't have an experience on configure GPU because lacked of environment.  So it maybe have some incorrect parts.\n", "I think this is fine. Reading the whole thing I noticed it's still pretty garbled, but this is a good start. We should probably rewrite this to factor the GPU story out completely -- it's currently repeated between MacOS and Linux.\n\nAnyway, LGTM.\n", "Jenkins, test this please.\n"]}, {"number": 3281, "title": "Enable reverse op for complex values", "body": "I've enabled complex values for the reverse op based on #3271.\nThis is part of the more general #2577.\n\nI've also extended the tests to cover all enabled dtypes.\nOne thing that I've noticed is that we're compiling GPU code for `bool` and `int32`, but we're not enabling GPU kernels for these dtypes.\nI've added commented out versions of the kernel registrations for these dtypes to point out that they're currently not enabled.\n", "comments": ["Can one of the admins verify this patch?\n", "@girving can I assign this one to you?  If not, feel free to re-assign.\n", "Looks good except for the comment about the comment.\n", "Okay, I've added a `TODO` to the commented out op registrations.\nI could have a look at enabling those in a second PR.\n", "Jenkins, test this please.\n", "Jenkins, test this please.\n", "@vrv Do you know why the tests wouldn't be triggering here?\n", "i dunno, Jenkins is not exactly reliable ;).\n\n@tensorflow-jenkins test this please\n", "Failures seem unrelated.  Merging.  Thank you for the stream of contributions!\n"]}, {"number": 3280, "title": "Default env python maybe different from python selected in config step", "body": "Python that is default in the environment maybe different from the one selected in the  configure step. [File](https://github.com/tensorflow/tensorflow/blob/master/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc)\ncalls `#!/usr/bin/env python`, it should instead be the one defined in the configuration step.\n", "comments": ["Thanks for reporting. \n@vrv Could you take a look at this please?\n", "I'm really not sure what we can do here, short of rewriting all python files during configure (which would be insane) -- I would suggest using an environment where the python you use in your configure step matches the environment.  If someone else has any suggestions, please let us know.\n"]}, {"number": 3279, "title": "Multiple fixes in KMeans clustering estimator", "body": "- Fixed inconsistent usage of `batch_size` and `steps` in kmeans estimator\n- Removed unused `continue_training` and `verbose`\n- Reused the same `RunConfig` in tests\n", "comments": ["(i'm waiting for green tests :)\n", "@vrv Thanks. Done!  :-) \n", "(not sure who the best reviewer is for this, so assigning to two people)\n", "Perhaps @martinwicke can take a look. This is similar to #3244. \n", "the self.batch_size line puzzled me -- is it ever executed? I feel like it shouldn't have worked in tests.\n", "@martinwicke Yeah the author was using `num_points` for `bacth_size` like this in the test class:\n\n```\n   @property\n    def batch_size(self):   \n      return self.num_points\n```\n", "@martinwicke so `self.batch_size` is a property defined in `KMeansTest` so it can be reused.\n", "Thanks!\n"]}, {"number": 3278, "title": "Implement 3D data for LSTM RNN -- request", "body": "I'm new to this, and I'm not sure where is the appropriate place to make a dev requests. If I am in the wrong place, can someone please redirect me?\n\nI am not an experienced Tensorflow dev or I would try to build this myself, but I think it is a really interesting idea and I would love for another dev to build it. \n\nThe idea is for an LSTM RNN to accept 3D data -- such as video frames. I'm interested in papers such as [this](http://cvgl.stanford.edu/papers/CVPR16_Social_LSTM.pdf), where LSTM RNN's are used for object tracking. Also [this](http://mediatum.ub.tum.de/doc/1138498/100891.pdf) paper.\n\nIs there a way to do this already in Tensorflow?\n\nI know I can flatten data, but that kind of defeats the point. I want a 3D network. In other words, please look at the attached picture for what I am envisioning. \n\n![file_000](https://cloud.githubusercontent.com/assets/3602993/16751849/9e9e25fa-47aa-11e6-89b3-ed4fe4b6b174.jpeg)\n\nEach frame is a full layer (in a horizontal direction). The second layer has inputs from both the second frame and the outputs from the first frame.\n", "comments": ["@ebrevdo Could you take a look at this please?\n", "Perhaps you want each frame convolved with some trainable kernel. See the cell types in tf.contrib.rnn and tf.contrib.grid_rnn.  perhaps something there already does what you want.\n", "@ebrevdo Grid LSTM RNNs support n-dimensional inputs in theory, but since the Tensorflow implementation uses the `RNNCell` object, the network requires a list of inputs, as opposed to a 3D volume. \n", "I posted [this](http://stackoverflow.com/questions/38855807/tensorflow-grid3lstmcell-visualization) to SO, it may be way I'm looking for. In which case we can close this issue.\n", "Closed per @KendallWeihe as this does sound like more of a design discussion, rather than a bug.\n"]}, {"number": 3277, "title": "Broadcast 0-rank tensors when computing gradients for tf.nn.relu", "body": "### Environment info\n\nOperating System: OSX (macOS....?), CPU only, version 0.9.0\n\nPerhaps this is desired behavior, but I would have much appreciated a more descriptive warning at least, which would have saved much debugging.  \n\nI haven't found a small reproducible case for this: but in the code I originally found this bug, no error is raised as the other variables are trained, leaving me scratching my head as to why the linear rectified variable was not being trained. \n\nThe same issue also occurs for tf.nn.softplus, and perhaps other methods as well. \n### Steps to reproduce\n\n```\nimport tensorflow as tf\nsess = tf.Session()\n\nx = tf.Variable(100.)\ny = tf.nn.relu(x)\nloss = y ** 2\noptimizer = tf.train.AdamOptimizer(learning_rate=0.1)\ntrain_op = optimizer.minimize(loss)\nsess.run(tf.initialize_all_variables())\n\nsess.run(train_op)\n\n---------------------------------------------------------------------------\nInvalidArgumentError                      Traceback (most recent call last)\n/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n    729     try:\n--> 730       return fn(*args)\n    731     except errors.OpError as e:\n\n/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)\n    711                                  feed_dict, fetch_list, target_list,\n--> 712                                  status, run_metadata)\n    713 \n\n/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/contextlib.py in __exit__(self, type, value, traceback)\n     65             try:\n---> 66                 next(self.gen)\n     67             except StopIteration:\n\n/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/framework/errors.py in raise_exception_on_not_ok_status()\n    449           compat.as_text(pywrap_tensorflow.TF_Message(status)),\n--> 450           pywrap_tensorflow.TF_GetCode(status))\n    451   finally:\n\nInvalidArgumentError: We only handle up to Tensor::dims() up to 8, not 0\n     [[Node: gradients_29/Relu_5_grad/ReluGrad = ReluGrad[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients_29/pow_9_grad/tuple/control_dependency, Relu_5)]]\n\nDuring handling of the above exception, another exception occurred:\n\nInvalidArgumentError                      Traceback (most recent call last)\n<ipython-input-51-ea082b2869a4> in <module>()\n----> 1 sess.run(train_op)\n\n/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\n    380     try:\n    381       result = self._run(None, fetches, feed_dict, options_ptr,\n--> 382                          run_metadata_ptr)\n    383       if run_metadata:\n    384         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n\n/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\n    653     movers = self._update_with_movers(feed_dict_string, feed_map)\n    654     results = self._do_run(handle, target_list, unique_fetches,\n--> 655                            feed_dict_string, options, run_metadata)\n    656 \n    657     # User may have fetched the same tensor multiple times, but we\n\n/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\n    721     if handle is None:\n    722       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n--> 723                            target_list, options, run_metadata)\n    724     else:\n    725       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n\n/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n    741         except KeyError:\n    742           pass\n--> 743       raise type(e)(node_def, op, message)\n    744 \n    745   def _extend_graph(self):\n\nInvalidArgumentError: We only handle up to Tensor::dims() up to 8, not 0\n     [[Node: gradients_29/Relu_5_grad/ReluGrad = ReluGrad[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients_29/pow_9_grad/tuple/control_dependency, Relu_5)]]\nCaused by op 'gradients_29/Relu_5_grad/ReluGrad', defined at:\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/runpy.py\", line 170, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-49-21a2f038fac9>\", line 5, in <module>\n    train_op = optimizer.minimize(loss)\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/training/optimizer.py\", line 193, in minimize\n    grad_loss=grad_loss)\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/training/optimizer.py\", line 250, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/ops/gradients.py\", line 482, in gradients\n    in_grads = _AsList(grad_fn(op, *out_grads))\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/ops/nn_grad.py\", line 233, in _ReluGrad\n    return gen_nn_ops._relu_grad(grad, op.outputs[0])\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1374, in _relu_grad\n    features=features, name=name)\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 2297, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 1231, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op 'Relu_5', defined at:\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/runpy.py\", line 170, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 17 identical lines from previous traceback]\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-49-21a2f038fac9>\", line 2, in <module>\n    y = tf.nn.relu(x)\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1312, in relu\n    result = _op_def_lib.apply_op(\"Relu\", features=features, name=name)\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 2297, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 1231, in __init__\n    self._traceback = _extract_stack()\n```\n### What have you tried?\n\nThe problem is resolved by expanding the dimensions of `x`:\n\n```\nimport tensorflow as tf\nsess = tf.Session()\n\nx = tf.Variable(100.)\ny = tf.nn.relu(tf.expand_dims(x, 0))\nloss = y ** 2\noptimizer = tf.train.AdamOptimizer(learning_rate=0.1)\ntrain_op = optimizer.minimize(loss)\nsess.run(tf.initialize_all_variables())\n\nsess.run(train_op)\n# runs fine\n```\n\nI wonder if it would be possible to do this automatically? \n", "comments": ["So I checked this out, does seem to be a bug. The good news is it looks like it might be really easy to fix. \n\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/numeric_op.h#L90\nJust add NDIM_CASE(0); on line 90 and the template magic should take care of the rest.\n\nI'll work on getting this submitted.\n", "Looks like the fix got pushed. Could you check whether this solves the issue with your more complicated example?\n\nThank you for the awesome bug report!\n", "Yup! All is well. Thanks for quickly dispatching this one!\n"]}, {"number": 3276, "title": "Trouble building from source: import tensorflow fails (from any directory)", "body": "### Environment info\n\nOperating System: Ubuntu 14.04\n\nInstalled version of CUDA and cuDNN: 7.5/5\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n-rw-r--r-- 1 root root 189170 Oct  8  2015 /usr/local/cuda/lib/libcudadevrt.a\nlrwxrwxrwx 1 root root     16 Oct  8  2015 /usr/local/cuda/lib/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root     19 Oct  8  2015 /usr/local/cuda/lib/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x 1 root root 311596 Oct  8  2015 /usr/local/cuda/lib/libcudart.so.7.5.18\n-rw-r--r-- 1 root root 558020 Oct  8  2015 /usr/local/cuda/lib/libcudart_static.a\n1. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n   Traceback (most recent call last):\n   File \"<string>\", line 1, in <module>\n   ImportError: No module named tensorflow\n   If installed from sources, provide the commit hash: (most recent: b62f19cdc7672ff31b90b4f2b7aad870849be3e0)\n### Steps to reproduce\n1.  Created an empty conda environment only seeded w/ python 2.7.5 + anaconda\n2. Installed numpy scipy\n3. Correctly configured w/ ./configure\n4. Ran the exact bazel build command provided on the site from root of tensorflow cloned directory\n5. import tensorflow fails (from any directory) AND conda list or pip list do not show tensorflow after installation.  (Yes, I checked to make sure that the ./configure had the right address matching the output of which python)\n### What have you tried?\n1. Creating new conda env, to see if it would help. Don't have access to virtualenv on my machine nor do I have sudo access.\n", "comments": ["This is a question better suited for StackOverflow. Please ask it there and tag it with the `tensorflow` tag.\n"]}, {"number": 3275, "title": "Update Eigen to version that includes scan op fix", "body": "This updates Eigen to a newer version that includes a fix needed to merge #2711.\n", "comments": ["Can one of the admins verify this patch?\n", "https://github.com/tensorflow/tensorflow/blob/dfb71ea206eb9f61e5d97c9727caa1a6449e39cb/tensorflow/contrib/cmake/external/eigen.cmake#L10 can you update that too?\n", "Yeah, sorry for forgetting about the cmake build. I've updated it too, now.\n", "@tensorflow-jenkins test this please\n", "@tensorflow-jenkins test this please (once more, I don't expect the result to change.  cmake is always broken anyway :/).  Will merge if everything else passes.\n", "Cool, the cmake test build is a good idea.\nThe error\n\n```\nexecvp: /usr/local/bin/protoc: Permission denied\n```\n\nseems a bit bizarre. Maybe the filesystem is mounted with `noexec`, or SELinux is interfering?\n", "The protobuf installation is unpacked from a zip file here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/install/install_proto3.sh#L29\nMaybe the executable permissions aren't preserved when unpacking. (Although it seems to have the right permissions when I unzip that file on my laptop)\n\n**Edit:** It might be the fact that the file has `550` permissions once unzipped, and is owned by root, while we're trying to execute it as the user that we mapped into the container.\n", "Bah, I am just going to merge this anyway, benoit has another update that should hopefully fix this anyway.\n", "Thanks! That means #2711 should work now after a rebase.\n"]}, {"number": 3274, "title": "Branch 127122527", "body": "", "comments": []}, {"number": 3273, "title": "Cannot build from source", "body": "Cannot build from source\n### Environment info\n\nOperating System: Arch Linux\n\nInstalled version of CUDA and cuDNN: \n7.5\n\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n-rwxr-xr-x 1 root root 311596 May  1 07:04 /opt/cuda/lib/libcudart.so.7.5.18\n-rw-r--r-- 1 root root 558020 May  1 07:04 /opt/cuda/lib/libcudart_static.a\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n   0.9.0rc0\n\nIf installed from sources, provide the commit hash:\necdb06c03db58daef5a8271bdef9f85c3bf28d08\n### Steps to reproduce\n1. bazel build -c opt --config=cuda --verbose_failures //tensorflow/tools/pip_package:build_pip_package\n### What have you tried?\n1. bazel build -c opt --genrule_strategy=standalone --spawn_strategy=standalone --config=cuda --verbose_failures //tensorflow/tools/pip_package:build_pip_package\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n\n```\nERROR: /home/bernardo/.cache/bazel/_bazel_bernardo/6e092ee851f20b3b3e86c2bd0d1d1759/external/protobuf/BUILD:331:1: C++ compilation of rule '@protobuf//:protoc' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command \n  (cd /home/bernardo/.cache/bazel/_bazel_bernardo/6e092ee851f20b3b3e86c2bd0d1d1759/tensorflow && \\\n  exec env - \\\n    PATH=/opt/cuda/bin/:/usr/local/sbin:/usr/local/bin:/usr/bin:/snap/bin:/opt/cuda/bin:/usr/lib/jvm/default/bin:/usr/bin/site_perl:/usr/bin/vendor_perl:/usr/bin/core_perl \\\n  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -g0 '-std=c++11' -iquote external/protobuf -iquote bazel-out/host/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/host/genfiles/external/bazel_tools -isystem external/protobuf/src -isystem bazel-out/host/genfiles/external/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fno-canonical-system-headers '-frandom-seed=bazel-out/host/bin/external/protobuf/_objs/protoc/external/protobuf/src/google/protobuf/compiler/main.o' -MD -MF bazel-out/host/bin/external/protobuf/_objs/protoc/external/protobuf/src/google/protobuf/compiler/main.d -c external/protobuf/src/google/protobuf/compiler/main.cc -o bazel-out/host/bin/external/protobuf/_objs/protoc/external/protobuf/src/google/protobuf/compiler/main.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\ngcc: error trying to exec 'cc1plus': execvp: No such file or directory\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nINFO: Elapsed time: 1.540s, Critical Path: 0.24s\n```\n", "comments": ["The supported Operating systems by TensorFlow are: Ubuntu Linux 14 LTE to 16. Mac OS X El Capitan. CentOS 7 and above\n\nFor other OS, please direct the question to Stackoverflow and people might be able to help there.\n"]}, {"number": 3272, "title": "Revert \"Revert \"Misc improvements to Dockerfile.devel-gpu\"\"", "body": "Reverts tensorflow/tensorflow#3157 which reverted #3143, but which now has proper CLA.\n", "comments": ["Yeah, it's unnecessary, you're right. Oh well. Doesn't hurt either.\n"]}, {"number": 3271, "title": "Reverse for complex numbers", "body": "tf.reverse does not seem to be implemented for complex numbers\n\n```\nw_real = tf.Variable(tf.truncated_normal([10], stddev=0.1, dtype=tf.float32))\nw_imag = tf.Variable(tf.truncated_normal([10], stddev=0.1, dtype=tf.float32))\nw = tf.complex(w_real, w_imag)\nw_rev = tf.reverse(w, [True])\n```\n\nI came across this needing to construct a matrix that is conjugate symmetric, but this was also referenced on StackOverflow : [http://stackoverflow.com/questions/38145235/why-cant-i-reverse-a-sequence-of-complex-numbers-in-tensorflow](http://stackoverflow.com/questions/38145235/why-cant-i-reverse-a-sequence-of-complex-numbers-in-tensorflow)\n", "comments": ["Related to https://github.com/tensorflow/tensorflow/issues/2577 which tracks general support for complex numbers in tensor transformation functions.\n", "I've enabled `reverse` for complex numbers on the GPU in #3281, so this can be closed if everyone agrees.\n"]}, {"number": 3270, "title": "Loading Multiple models into the same session of tensorflow", "body": "I have trained two models. en-fr and fr-en models. The fr-en model has different vocab size compared to the en-fr model. The first model is being loaded properly. It crashes while loading the second one. I have trained both the models separately. Please check the log file attached to see the error logs. kindly tell me the right way to go ahead.\n\nI want to create a webservice for en-rf and fr-en translation. I ahve to load the models in a session for this, which is causing the problem. below is the piece of code. I am using the translate.py provided by tensorflow and the methods available in it.\n\n```\n`global en_fr_sess\n\n if en_fr_sess==None:\n en_fr_sess = tf.Session()\n\n global en_fr_model\n global en_fr_en_vocab_path\n global en_fr_fr_vocab_path\n\n en_fr_model = create_model(en_fr_sess, True)\n en_fr_model.batch_size = 1  \n fr_en_model = fr_en_create_model(en_fr_sess, True)\n fr_en_model.batch_size = 1`\n```\n\nI am able to run both the models separately and generate the translations. However, when I try to load both the models in the same session or even a different session one after the other, I get the following error\n\n```\n`ValueError: Variable embedding_attention_seq2seq/RNN/EmbeddingWrapper/embedding already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:`\n`File \"/usr/local/lib/python2.7/dist-packages/tensorflow/models/rnn/translate/seq2seq_model.py\", line 113, in seq2seq_f\nfeed_previous=do_decode)`\n`File \"/usr/local/lib/python2.7/dist-packages/tensorflow/models/rnn/translate/seq2seq_model.py\", line 136, in <lambda>\nself.target_weights, buckets, lambda x, y: seq2seq_f(x, y, True),`\n`File \"/usr/local/lib/python2.7/dist-packages/tensorflow/models/rnn/translate/seq2seq_model.py\", line 137, in __init__\nsoftmax_loss_function=softmax_loss_function)`\n```\n\nPlease find the detailed log file attached too. Kindly give me the inputs on how to proceed further. \n[out.txt](https://github.com/tensorflow/tensorflow/files/357036/out.txt)\n", "comments": ["@lukaszkaiser any inputs?\n", "As said in the other thread -- you want separate variables for each model. So you need to use \"with tf.variable_scope(...)\" before creating each model. And since you didn't do this before training, you'll have to re-name the variables you restore from the checkpoint. This can be done by passing a dict to the Saver object, rather than just a list of variables (as is done now). Let me know if you have more specific questions, I'll be happy to help, but here is the overview.\n\n(0) Currently both your models are trying to share parameters, that's where the error comes from (they cannot share because vocab sizes are different, but it's just a consequence of a different problem: you don't want to share the variables, you want 2 separate sets of them).\n\n(1) You cannot create 2 separate sets just with 2 sessions, you need to put them in variable_scopes. Just before calling create_model, open a scope, for example:\n  with tf.variable_scope('en_fr'):\n    en_fr_model = create_model(...)\n  with tf.variable_scope('fr_en'):\n    fr_en_model = create_model(...)\n\n(2) Now you have 2 sets of variables, but their names don't correspond to the names you've saved in checkpoints during training, because your names are now prefixed with 'en_fr/' and 'fr_en/' and those in checkpoint are not. So you need to add some logic to the Saver object in the model to tell it to prefix the variables from the checkpoint in the right way. This can be done by passing a dict to the Saver, see [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/saver.py#L791)\n", "Thanks for your quick response @lukaszkaiser \nmy doubts may be very trivial but I will go ahead and ask.\nI have trained two models. you rightly pointed out that I have not used tf.varaible_scope during the training stage. When you say I need to rename variables that I restore from the checkpoint, \n\n```\n`ckpt = tf.train.get_checkpoint_state(FLAGS.train_dir)\n if ckpt and tf.gfile.Exists(ckpt.model_checkpoint_path):\n    print(\"Reading model parameters from %s\" % ckpt.model_checkpoint_path)\n    model.saver.restore(session, ckpt.model_checkpoint_path)\n else:\n    print(\"Created model with fresh parameters.\")\n    session.run(tf.initialize_all_variables())\nreturn model`\n```\n\nThis is the place where the restoring is done, from the trained model cptk file. What are all the variables that I need to rename? \n\nAlso by using the tf.variable_scope(), will the variables be prefixed with the string given, en_fr or fr_en automatically. ?\n\nis retraining both the models with tf.variable_scope a better option?\n", "I trained two new models with fewer steps. While training the new models, I used with tf.variable_scope(\"en_fr\") for en-fr translator and with tf.variable_scope(\"fr_en\") for fr-en translator. \n\nFor training : \n\n```\nwith tf.variable_scope('fr_en'):\n   model = create_model(sess, False)\n\nwith tf.variable_scope('en_fr'):\n  model = create_model(sess, False)\n```\n\nduring decoding : en-fr\n\n```\n`def en_fr_decode(sentence):\n\n   global en_fr_sess\n\n   if en_fr_sess==None:\n     en_fr_sess = tf.Session()\n\n   global en_fr_model\n   global en_fr_en_vocab_path\n   global en_fr_fr_vocab_path\n\n\n  if en_fr_model==None:\n   with tf.variable_scope('en_fr'):\n      #import pdb; pdb.set_trace()\n      en_fr_model = create_model(en_fr_sess, True)\n      en_fr_model.batch_size = 1` \n```\n\ndecoding fr-en : \n\n```\n`def fr_en_decode(sentence):\n\n  global fr_en_sess\n\n  if fr_en_sess==None:\n    fr_en_sess = tf.Session()\n\n  global fr_en_model\n  global fr_en_en_vocab_path\n  global fr_en_fr_vocab_path\n\n  if fr_en_model==None:\n    with tf.variable_scope('fr_en'):\n      fr_en_model = fr_en_create_model(fr_en_sess, True)\n      fr_en_model.batch_size = 1`\n```\n\nand the create model functions are as below:\n\n```\n`def create_model(session, forward_only):\n\n  model = seq2seq_model.Seq2SeqModel(\n  FLAGS.en_vocab_size, FLAGS.fr_vocab_size, _buckets,\n  FLAGS.size, FLAGS.num_layers, FLAGS.max_gradient_norm, FLAGS.batch_size,\n  FLAGS.learning_rate, FLAGS.learning_rate_decay_factor,\n  forward_only=forward_only)\n  ckpt = tf.train.get_checkpoint_state(FLAGS.train_dir)\n  if ckpt and tf.gfile.Exists(ckpt.model_checkpoint_path):\n    print(\"Reading model parameters from %s\" % ckpt.model_checkpoint_path)\n    model.saver.restore(session, ckpt.model_checkpoint_path)\n  else:\n    print(\"Created model with fresh parameters.\")\n    session.run(tf.initialize_all_variables())\nreturn model\n\ndef fr_en_create_model(session, forward_only):\n\n  model = seq2seq_model.Seq2SeqModel(\n     380, 380, _buckets,\n     FLAGS.size, FLAGS.num_layers, FLAGS.max_gradient_norm, FLAGS.batch_size,\n     FLAGS.learning_rate, FLAGS.learning_rate_decay_factor,\n     forward_only=forward_only)\n ckpt = tf.train.get_checkpoint_state(\"./password_data/train2/\")\n if ckpt and tf.gfile.Exists(ckpt.model_checkpoint_path):\n    print(\"Reading model parameters from %s\" % ckpt.model_checkpoint_path)\n    model.saver.restore(session, ckpt.model_checkpoint_path)\n else:\n    print(\"Created model with fresh parameters.\")\n    session.run(tf.initialize_all_variables())\nreturn model`\n```\n\nPlease see the error logs in the file attached. You can see in the logs that the english to french translation is done, after which I am trying to load the french to english model using fr_en_create_model() method. This will give me error as \n\n```\n`NotFoundError: Tensor name \"en_fr/Variable\" not found in checkpoint files ./password_data/train2/translate.ckpt-400\n [[Node: fr_en/save/restore_slice = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_fr_en/save/Const_0, fr_en/save/restore_slice/tensor_name, fr_en/save/restore_slice/shape_and_slice)]]\n [[Node: fr_en/save/restore_slice_46/_58 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_31_fr_en/save/restore_slice_46\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]`\n```\n\n[nohup_1.txt](https://github.com/tensorflow/tensorflow/files/358786/nohup_1.txt)\n", "I think what you did is good and you're almost there. The one problem you see is due to [this line](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/translate/seq2seq_model.py#L166). The Saver() object takes a list of variables, and it's tf.all_variables(), so it's trying to restore them all. While your checkpoint only has a subset of them (not the en_fr ones), so you get an error.\n\nI think you can, for example, just create 2 savers and filter the variables to only include the relevant ones, e.g, `self.saver_en-fr = Saver([v for v in tf.all_variables() if 'en_fr' in v.name])`. And then call restore twice, on both savers. Hope that works, let me know!\n", "With your inputs, I made the modifications in seq2seq_model.py. Below are the lines of code I have added \n\n```\nall_vars = tf.all_variables()\nmodel_one_vars = [k for k in all_vars if k.name.startswith(\"en_fr\")]\nmodel_two_vars = [k for k in all_vars if k.name.startswith(\"fr_en\")]\n\nif not model_two_vars:\n   self.saver_en_fr = tf.train.Saver(model_one_vars)\nelse:\n   self.saver_fr_en = tf.train.Saver(model_two_vars)\n```\n\nin place of \n    `self.saver = tf.train.Saver(tf.all_variables())`\n\nThings are working fine now. I have successfully loaded two models. Thanks a lot for your inputs :-)\n", "Thanks to @lukaszkaiser and @suraj1990 , I've run into the same issue and the suggestion works for me.\n", "Does the variable scope method work when working with Keras? Even while using different variable scopes, the models seem to be sharing weights.", "When using objects, the idea is that same-object=shared-weights and different-objects=non-shared-weights. But it should be very simple to not share, just create the object twice. Or am I missing something?", "@lukaszkaiser that's what I did, but it doesn't seem to work. I have two models (in 2 different objects), A and B in the same session. Training only A gives 90% of so accuracy, while training B after A and then evaluating A gives less than random accuracy. This issue disappears when I run them in different threads, so it's probably something to do with two models in the same session (probably sharing weoghts of some layers).", "This sounds like a bug. Could you create a small test file where this problem appears and attach here, so we can reproduce and try to correct it? Thanks!", "Same problem here. The restoration is working on both models but the results are bad. Take a look:\r\n\r\n```\r\nwith tf.variable_scope('localization'):\r\n            binarylogits, _, softmax_weights, convoluted = inception.inference(images, num_classes, \r\n                                                                            restore_loc=True, restore_rec=False)  \r\n        \r\nnum_classes = 102\r\nwith tf.variable_scope('recognition'):\r\n            _, logits, _, _ = inception.inference(bbox_image, num_classes, \r\n                                                             restore_loc=False, restore_rec=True)  \r\n\r\nvariables_to_restore = tf.get_collection(\r\n            slim.variables.VARIABLES_TO_RESTORE)\r\nloc_varlist = {v.name[13:][:-2]: v \r\n                        for v in variables_to_restore if v.name[:12]=='localization'}\r\nrec_varlist = {v.name[12:][:-2]: v \r\n                        for v in variables_to_restore if v.name[:11]=='recognition'}\r\n        \r\nloc_saver = tf.train.Saver(var_list=loc_varlist)\r\nrec_saver = tf.train.Saver(var_list=rec_varlist)\r\n        \r\nloc_saver.restore(sess, FLAGS.localization_model_checkpoint_path)\r\nprint('%s: Pre-trained model restored from %s' %\r\n                    (datetime.now(), FLAGS.localization_model_checkpoint_path))\r\n\r\nrec_saver.restore(sess, FLAGS.recognition_model_checkpoint_path)\r\nprint('%s: Pre-trained model restored from %s' %\r\n                    (datetime.now(), FLAGS.recognition_model_checkpoint_path))\r\n```\r\n\r\nThe recognition model doesn't give the results I am receiving when I run it without the localization model.", "I updated the above code take a look. Finally the second model (recognition) cannot produce the right predictions, but in a script without the first model it works fine.", "@chrisrn Have you fixed this problem?", "@Yuliang-Zou  Yes finally it works. Probably there was a tensorflow bug in the past.", "@chrisrn So you just updated the version of tensorflow, and it works now?", "@suraj1990 @lukaszkaiser @anguyen8 @iamgroot42 @chrisrn \r\n\r\nI am facing the same issue.\r\n\r\nI have trained two models separately . The output of 1st model is used as output of 2nd model . \r\nWhen i run the two models individually , i save the output of 1st model in a numpy array and then later feed that to 2nd model , results are as expected , but when i combine them in a single graph , the output of 2nd model is horrendously bad. I have made sure that there is no name conflict. \r\n\r\nAny advice on how anyone overcame this ?\r\n\r\nThanks\r\n", "@iamgroot42 how did you run it on two threads?\r\n", "@chrisrn how did it work?", "@Raj-08  I think it's clear from the code I provide. All you need to do is separating the variables of the models.", "@chrisrn  which tensorflow version are you using?\r\n", "@Raj-08 I don't remember which version I was using on January 2017. But it was an older one, so you can load multiple models using the newest versions for sure!", "@chrisrn Thanks man , but i have tried to restore it as you mentioned , but no luck . \r\n", "i am using tensorflow version 1.4", "@iamgroot42 had mentioned that the two models might be sharing same variables , i have checked all the variables in tf.global_variables () , there is no conflict i could find.", "@Raj-08 The above technique with the scopes is referring to models that have variables with the same names, so you are using the scopes to avoid that. If your models do not have same variable names then it's easier to load them. Pay attention on where you place the savers and also the variables that you feed to them!", "`  with tf.Graph().as_default():\r\n\r\n    C = tf.constant([0],shape=[30,30,1])\r\n\r\n    D = tf.constant([0],shape=[40,40,1])\r\n    input_image = tf.placeholder(tf.uint8, [1, None, None, 3], name=_INPUT_NAME)\r\n    image_size = tf.shape(input_image)[1:3]\r\n    image = tf.squeeze(input_image, axis=0)\r\n    image = tf.expand_dims(image, 0)\r\n    model_options = common.ModelOptions(\r\n        outputs_to_num_classes={common.OUTPUT_TYPE: FLAGS.num_classes},\r\n        crop_size=[481,481],\r\n        atrous_rates=FLAGS.atrous_rates,\r\n        output_stride=FLAGS.output_stride)\r\n    with tf.variable_scope('segmentation'):\r\n        if tuple(FLAGS.inference_scales) == (1.0,):\r\n          tf.logging.info('Exported model performs single-scale inference.')\r\n          predictions = model_deeplab.predict_labels(\r\n              image,\r\n              model_options=model_options,\r\n              image_pyramid=FLAGS.image_pyramid)\r\n        else:\r\n          tf.logging.info('Exported model performs multi-scale inference.')\r\n          predictions = model_deeplab.predict_labels_multi_scale(\r\n              image,\r\n              model_options=model_options,\r\n              eval_scales=FLAGS.inference_scales,\r\n              add_flipped_images=FLAGS.add_flipped_images)\r\n   \r\n    \r\n        predictions = predictions['semantic']\r\n\r\n        logits_deeplab = tf.scalar_mul(255,predictions)\r\n        logits_deeplab = tf.squeeze(logits_deeplab)\r\n        logits_deeplab = tf.expand_dims(logits_deeplab, axis=0)\r\n        logits_deeplab = tf.expand_dims(logits_deeplab, axis=3)\r\n        eroded = tf.nn.erosion2d(tf.cast(logits_deeplab,dtype=tf.int32),C,[1,1,1,1],[1,1,1,1],'SAME')\r\n\r\n        dilated = tf.nn.dilation2d(tf.cast(logits_deeplab,dtype=tf.int32),D,[1,1,1,1],[1,1,1,1],'SAME')\r\n\r\n\r\n\r\n        dilated =  tf.where(tf.equal(dilated,255),tf.fill([1,481,481,1],127),dilated)\r\n\r\n        trimap =  tf.where(tf.equal(eroded,255),tf.fill([1,481,481,1],255),dilated)\r\n        trimap_inp = tf.concat([tf.cast(image,dtype=tf.float32),tf.cast(trimap,dtype=tf.float32)],axis=3,name='new')\r\n        model_options = common.ModelOptions(\r\n        outputs_to_num_classes={common.OUTPUT_TYPE: 64},\r\n        crop_size=[481,481],\r\n        atrous_rates=[12,24,36],\r\n        output_stride=FLAGS.output_stride)\r\n    mod_vars = tf.model_variables()\r\n    print('l1',len(mod_vars))\r\n    with tf.variable_scope('matting'):\r\n        logits= model.multi_scale_logits(\r\n              trimap_inp,\r\n              model_options=model_options,\r\n              image_pyramid = [1.0])\r\n        \r\n        mod_vars = tf.model_variables()\r\n        print('l2',len(mod_vars))\r\n        all_trainables = tf.trainable_variables()\r\n        logits=logits['semantic']\r\n        logits_p=logits['merged_logits_matting'] \r\n        upsample_logits=True\r\n        logits_p=upsample_layer(logits_p,64,'up_matting',upscale_factor=4)\r\n        print('LP',logits_p)\r\n        logits_p = create_new_conv_layer(logits_p,64,1,'pred')\r\n        deeplab_op_255 = tf.scalar_mul(255.0,logits_p)\r\n        concat_inp = tf.concat([tf.cast(image,dtype=tf.float32),deeplab_op_255],axis=3)\r\n        conv1 = create_new_conv_layer(concat_inp,4,64,'conv1')\r\n        conv2 = create_new_conv_layer(conv1,64,64,'conv2')\r\n        conv3 = create_new_conv_layer(conv2,64,64,'conv3')\r\n        logits_al = create_new_conv_layer(conv3,64,1,'pred1')\r\n        logits_al = tf.nn.sigmoid(logits_al)\r\n    variables_to_restore = tf.get_collection(\r\n            tf.GraphKeys.MODEL_VARIABLES)\r\n    print(len(variables_to_restore))\r\n\r\n    loc_varlist = {v.name[13:][:-2]: v \r\n                        for v in variables_to_restore if v.name[:12]=='segmentation'}\r\n    rec_varlist = {v.name[8:][:-2]: v \r\n                        for v in variables_to_restore if v.name[:7]=='matting'}\r\n    print('L1',len(loc_varlist))\r\n    print('L2',len(rec_varlist))\r\n    f = open('/home/ubuntu/all_data_seg/train_mat_25_08.txt')\r\n    message = f.read()\r\n    lines = message.split('\\n')\r\n\r\n    saver_restore_1 = tf.train.Saver(loc_varlist)   \r\n    saver_restore_2 = tf.train.Saver(rec_varlist)`", "Here is my code , tried eveything , doesnt seem to work ! ", "@chrisrn Yeah my model has same name conflict as well , using your method there is no more name conflict . ", "@lukaszkaiser  @Raj-08 @chrisrn\r\n\r\nWhile loading multiple trained files i am facing the issue of \"raise ValueError(\"None values not supported.\")\".\r\n\r\n\r\nMy error:\r\nTraceback (most recent call last):\r\n  File \"C:/Users/Garima Thakur/Desktop/neuro_jazh/neuro_v3_jpzh/src/server.py\", line 47, in <module>\r\n    nn_zh = NeuroNER(**arguments_zh)\r\n  File \"C:\\Users\\Garima Thakur\\Desktop\\neuro_jazh\\neuro_v3_jpzh\\src\\neuroner.py\", line 316, in __init__\r\n    model = EntityLSTM(dataset, parameters)\r\n  File \"C:\\Users\\Garima Thakur\\Desktop\\neuro_jazh\\neuro_v3_jpzh\\src\\entity_lstm.py\", line 242, in __init__\r\n    self.define_training_procedure(parameters)\r\n  File \"C:\\Users\\Garima Thakur\\Desktop\\neuro_jazh\\neuro_v3_jpzh\\src\\entity_lstm.py\", line 262, in define_training_procedure\r\n    for grad, var in grads_and_vars]\r\n  File \"C:\\Users\\Garima Thakur\\Desktop\\neuro_jazh\\neuro_v3_jpzh\\src\\entity_lstm.py\", line 262, in <listcomp>\r\n    for grad, var in grads_and_vars]\r\n  File \"C:\\Users\\Garima Thakur\\anaconda3\\envs\\neuro_1\\lib\\site-packages\\tensorflow_core\\python\\util\\dispatch.py\", line 180, in wrapper\r\n    return target(*args, **kwargs)\r\n  File \"C:\\Users\\Garima Thakur\\anaconda3\\envs\\neuro_1\\lib\\site-packages\\tensorflow_core\\python\\ops\\clip_ops.py\", line 79, in clip_by_value\r\n    t.values if isinstance(t, ops.IndexedSlices) else t, name=\"t\")\r\n  File \"C:\\Users\\Garima Thakur\\anaconda3\\envs\\neuro_1\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1184, in convert_to_tensor\r\n    return convert_to_tensor_v2(value, dtype, preferred_dtype, name)\r\n  File \"C:\\Users\\Garima Thakur\\anaconda3\\envs\\neuro_1\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1242, in convert_to_tensor_v2\r\n    as_ref=False)\r\n  File \"C:\\Users\\Garima Thakur\\anaconda3\\envs\\neuro_1\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1297, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"C:\\Users\\Garima Thakur\\anaconda3\\envs\\neuro_1\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\", line 286, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n  File \"C:\\Users\\Garima Thakur\\anaconda3\\envs\\neuro_1\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\", line 227, in constant\r\n    allow_broadcast=True)\r\n  File \"C:\\Users\\Garima Thakur\\anaconda3\\envs\\neuro_1\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\", line 265, in _constant_impl\r\n    allow_broadcast=allow_broadcast))\r\n  File \"C:\\Users\\Garima Thakur\\anaconda3\\envs\\neuro_1\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_util.py\", line 437, in make_tensor_proto\r\n    raise ValueError(\"None values not supported.\")\r\nValueError: None values not supported.\r\nException ignored in: <bound method NeuroNER.__del__ of <neuroner.NeuroNER object at 0x00000172BB384D30>>\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Garima Thakur\\Desktop\\neuro_jazh\\neuro_v3_jpzh\\src\\neuroner.py\", line 566, in __del__\r\n    self.sess.close()\r\nAttributeError: 'NeuroNER' object has no attribute 'sess'\r\n\r\n\r\nEven though i have automated the model for different language (as i have to train for 3 -4 languages) and have done whatever was recommended, but i am till facing this issue. It would be great if someone could just help me here. \r\nThank you in advance :)\r\n\r\n\r\n\r\nMycode:\r\n\r\nimport tensorflow as tf\r\nimport re\r\nimport time\r\nimport utils_tf\r\nimport utils_nlp\r\nimport os\r\nimport pickle\r\n\r\n\r\ndef bidirectional_LSTM(input, language, hidden_state_dimension, initializer, sequence_length=None,\r\n                       output_sequence=True):\r\n    with tf.variable_scope(f\"bidirectional_LSTM_{language}\"):\r\n        if sequence_length == None:\r\n            batch_size = 1\r\n            sequence_length = tf.shape(input)[1]\r\n            sequence_length = tf.expand_dims(sequence_length, axis=0, name='sequence_length')\r\n        else:\r\n            batch_size = tf.shape(sequence_length)[0]\r\n\r\n        lstm_cell = {}\r\n        initial_state = {}\r\n        for direction in [\"forward\", \"backward\"]:\r\n            with tf.variable_scope(f\"{direction}_{language}\"):\r\n                # LSTM cell\r\n                lstm_cell[direction] = tf.contrib.rnn.CoupledInputForgetGateLSTMCell(hidden_state_dimension,\r\n                                                                                     forget_bias=1.0,\r\n                                                                                     initializer=initializer,\r\n                                                                                     state_is_tuple=True)\r\n                # initial state: http://stackoverflow.com/questions/38441589/tensorflow-rnn-initial-state\r\n                initial_cell_state = tf.get_variable(f\"initial_cell_state_{language}\",\r\n                                                     shape=[1, hidden_state_dimension], dtype=tf.float32,\r\n                                                     initializer=initializer)\r\n                initial_output_state = tf.get_variable(f\"initial_output_state_{language}\",\r\n                                                       shape=[1, hidden_state_dimension], dtype=tf.float32,\r\n                                                       initializer=initializer)\r\n                c_states = tf.tile(initial_cell_state, tf.stack([batch_size, 1]))\r\n                h_states = tf.tile(initial_output_state, tf.stack([batch_size, 1]))\r\n                initial_state[direction] = tf.contrib.rnn.LSTMStateTuple(c_states, h_states)\r\n\r\n        # sequence_length must be provided for tf.nn.bidirectional_dynamic_rnn due to internal bug\r\n        outputs, final_states = tf.nn.bidirectional_dynamic_rnn(lstm_cell[\"forward\"],\r\n                                                                lstm_cell[\"backward\"],\r\n                                                                input,\r\n                                                                dtype=tf.float32,\r\n                                                                sequence_length=sequence_length,\r\n                                                                initial_state_fw=initial_state[\"forward\"],\r\n                                                                initial_state_bw=initial_state[\"backward\"])\r\n        if output_sequence == True:\r\n            outputs_forward, outputs_backward = outputs\r\n            output = tf.concat([outputs_forward, outputs_backward], axis=2, name='output_sequence')\r\n        else:\r\n\r\n            final_states_forward, final_states_backward = final_states\r\n            output = tf.concat([final_states_forward[1], final_states_backward[1]], axis=1, name='output')\r\n\r\n    return output\r\n\r\n\r\nclass EntityLSTM(object):\r\n    \"\"\"\r\n    An LSTM architecture for named entity recognition.\r\n    Uses a character embedding layer followed by an LSTM to generate vector representation from characters for each token.\r\n    Then the character vector is concatenated with token embedding vector, which is input to another LSTM  followed by a CRF layer.\r\n    \"\"\"\r\n\r\n    def __init__(self, dataset, parameters):\r\n        self.language = parameters[\"spacylanguage\"].split(\"_\")[0]\r\n        self.verbose = False\r\n        # Placeholders for input, output and dropout\r\n        self.input_token_indices = tf.placeholder(tf.int32, [None], name=\"input_token_indices\")\r\n        self.input_label_indices_vector = tf.placeholder(tf.float32, [None, dataset.number_of_classes],\r\n                                                         name=\"input_label_indices_vector\")\r\n        self.input_label_indices_flat = tf.placeholder(tf.int32, [None], name=\"input_label_indices_flat\")\r\n        self.input_token_character_indices = tf.placeholder(tf.int32, [None, None], name=\"input_token_indices\")\r\n        self.input_token_lengths = tf.placeholder(tf.int32, [None], name=\"input_token_lengths\")\r\n        self.dropout_keep_prob = tf.placeholder(tf.float32, name=\"dropout_keep_prob\")\r\n\r\n        # Internal parameters\r\n        initializer = tf.contrib.layers.xavier_initializer()\r\n        # with tf.variable_scope(f'{self.language}'):\r\n        print(f\"{self.language}\")\r\n        if parameters['use_character_lstm']:\r\n            # Character-level LSTM\r\n            # Idea: reshape so that we have a tensor [number_of_token, max_token_length, token_embeddings_size], which we pass to the LSTM\r\n            # Character embedding layer\r\n            print(f\"character_embedding_{self.language}\")\r\n            with tf.variable_scope(f\"character_embedding_{self.language}\"):\r\n                self.character_embedding_weights = tf.get_variable(\r\n                    f\"character_embedding_weights_{self.language}\",\r\n                    shape=[dataset.alphabet_size, parameters['character_embedding_dimension']],\r\n                    initializer=initializer)\r\n                embedded_characters = tf.nn.embedding_lookup(self.character_embedding_weights,\r\n                                                             self.input_token_character_indices,\r\n                                                             name='embedded_characters')\r\n                if self.verbose: print(\"embedded_characters: {0}\".format(embedded_characters))\r\n                utils_tf.variable_summaries(self.character_embedding_weights)\r\n\r\n            # Character LSTM layer\r\n            with tf.variable_scope(f'character_lstm_{self.language}') as vs:\r\n                print(type(self.language))\r\n                character_lstm_output = bidirectional_LSTM(embedded_characters, self.language,\r\n                                                           parameters['character_lstm_hidden_state_dimension'],\r\n                                                           initializer=initializer,\r\n                                                           sequence_length=self.input_token_lengths,\r\n                                                           output_sequence=False,\r\n                                                           )\r\n                self.character_lstm_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=f\"{vs.name}_{self.language}\")\r\n\r\n        # Token embedding layer\r\n        with tf.variable_scope(f\"token_embedding_{self.language}\"):\r\n            self.token_embedding_weights = tf.get_variable(\r\n                f\"token_embedding_weights_{self.language}\",\r\n                shape=[dataset.vocabulary_size, parameters['token_embedding_dimension']],\r\n                initializer=initializer,\r\n                trainable=not parameters['freeze_token_embeddings']\r\n            )\r\n            embedded_tokens = tf.nn.embedding_lookup(self.token_embedding_weights, self.input_token_indices)\r\n            utils_tf.variable_summaries(self.token_embedding_weights)\r\n\r\n        # Concatenate character LSTM outputs and token embeddings\r\n        if parameters['use_character_lstm']:\r\n            with tf.variable_scope(f\"concatenate_token_and_character_vectors_{self.language}\"):\r\n                if self.verbose: print('embedded_tokens: {0}'.format(embedded_tokens))\r\n                token_lstm_input = tf.concat([character_lstm_output, embedded_tokens], axis=1, name='token_lstm_input')\r\n                if self.verbose: print(\"token_lstm_input: {0}\".format(token_lstm_input))\r\n        else:\r\n            token_lstm_input = embedded_tokens\r\n\r\n        # Add dropout\r\n        with tf.variable_scope(f\"dropout_{self.language}\"):\r\n            token_lstm_input_drop = tf.nn.dropout(token_lstm_input, self.dropout_keep_prob,\r\n                                                  name='token_lstm_input_drop')\r\n            if self.verbose: print(\"token_lstm_input_drop: {0}\".format(token_lstm_input_drop))\r\n            # https://www.tensorflow.org/api_guides/python/contrib.rnn\r\n            # Prepare data shape to match `rnn` function requirements\r\n            # Current data input shape: (batch_size, n_steps, n_input)\r\n            # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\r\n            token_lstm_input_drop_expanded = tf.expand_dims(token_lstm_input_drop, axis=0,\r\n                                                            name='token_lstm_input_drop_expanded')\r\n            if self.verbose: print(\"token_lstm_input_drop_expanded: {0}\".format(token_lstm_input_drop_expanded))\r\n\r\n        # Token LSTM layer\r\n        with tf.variable_scope(f'token_lstm_{self.language}') as vs:\r\n            token_lstm_output = bidirectional_LSTM(token_lstm_input_drop_expanded, self.language,\r\n                                                   parameters['token_lstm_hidden_state_dimension'], initializer,\r\n                                                   output_sequence=True)\r\n            token_lstm_output_squeezed = tf.squeeze(token_lstm_output, axis=0)\r\n            self.token_lstm_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=f\"{vs.name}_{self.language}\")\r\n\r\n        # Needed only if Bidirectional LSTM is used for token level\r\n        with tf.variable_scope(f\"feedforward_after_lstm_{self.language}\") as vs:\r\n            W = tf.get_variable(\r\n                f\"W_{self.language}\",\r\n                shape=[2 * parameters['token_lstm_hidden_state_dimension'],\r\n                       parameters['token_lstm_hidden_state_dimension']],\r\n                initializer=initializer)\r\n            b = tf.Variable(tf.constant(0.0, shape=[parameters['token_lstm_hidden_state_dimension']]),\r\n                            name=f\"bias_{self.language}\")\r\n            outputs = tf.nn.xw_plus_b(token_lstm_output_squeezed, W, b, name=\"output_before_tanh\")\r\n            outputs = tf.nn.tanh(outputs, name=\"output_after_tanh\")\r\n            utils_tf.variable_summaries(W)\r\n            utils_tf.variable_summaries(b)\r\n            self.token_lstm_variables += tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=f\"{vs.name}_{self.language}\")\r\n\r\n        with tf.variable_scope(f\"feedforward_before_crf_{self.language}\") as vs:\r\n            W = tf.get_variable(\r\n                f\"W_{self.language}\",\r\n                shape=[parameters['token_lstm_hidden_state_dimension'], dataset.number_of_classes],\r\n                initializer=initializer)\r\n            b = tf.Variable(tf.constant(0.0, shape=[dataset.number_of_classes]), name=f\"bias_{self.language}\")\r\n            scores = tf.nn.xw_plus_b(outputs, W, b, name=\"scores\")\r\n            self.unary_scores = scores\r\n            self.predictions = tf.argmax(self.unary_scores, 1, name=\"predictions\")\r\n            utils_tf.variable_summaries(W)\r\n            utils_tf.variable_summaries(b)\r\n            self.feedforward_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=f\"{vs.name}_{self.language}\")\r\n\r\n        # CRF layer\r\n        if parameters['use_crf']:\r\n            with tf.variable_scope(f\"crf_{self.language}\") as vs:\r\n                # Add start and end tokens\r\n                small_score = -1000.0\r\n                large_score = 0.0\r\n                sequence_length = tf.shape(self.unary_scores)[0]\r\n                unary_scores_with_start_and_end = tf.concat(\r\n                    [self.unary_scores, tf.tile(tf.constant(small_score, shape=[1, 2]), [sequence_length, 1])], 1)\r\n                start_unary_scores = [[small_score] * dataset.number_of_classes + [large_score, small_score]]\r\n                end_unary_scores = [[small_score] * dataset.number_of_classes + [small_score, large_score]]\r\n                self.unary_scores = tf.concat([start_unary_scores, unary_scores_with_start_and_end, end_unary_scores],\r\n                                              0)\r\n                start_index = dataset.number_of_classes\r\n                end_index = dataset.number_of_classes + 1\r\n                input_label_indices_flat_with_start_and_end = tf.concat(\r\n                    [tf.constant(start_index, shape=[1]), self.input_label_indices_flat,\r\n                     tf.constant(end_index, shape=[1])], 0)\r\n\r\n                # Apply CRF layer\r\n                sequence_length = tf.shape(self.unary_scores)[0]\r\n                sequence_lengths = tf.expand_dims(sequence_length, axis=0, name='sequence_lengths')\r\n                unary_scores_expanded = tf.expand_dims(self.unary_scores, axis=0, name='unary_scores_expanded')\r\n                input_label_indices_flat_batch = tf.expand_dims(input_label_indices_flat_with_start_and_end, axis=0,\r\n                                                                name='input_label_indices_flat_batch')\r\n                if self.verbose: print('unary_scores_expanded: {0}'.format(unary_scores_expanded))\r\n                if self.verbose: print('input_label_indices_flat_batch: {0}'.format(input_label_indices_flat_batch))\r\n                if self.verbose: print(\"sequence_lengths: {0}\".format(sequence_lengths))\r\n                # https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/crf\r\n                # Compute the log-likelihood of the gold sequences and keep the transition params for inference at test time.\r\n                self.transition_parameters = tf.get_variable(\r\n                    f\"transitions_{self.language}\",\r\n                    shape=[dataset.number_of_classes + 2, dataset.number_of_classes + 2],\r\n                    initializer=initializer)\r\n                utils_tf.variable_summaries(self.transition_parameters)\r\n                log_likelihood, _ = tf.contrib.crf.crf_log_likelihood(\r\n                    unary_scores_expanded, input_label_indices_flat_batch, sequence_lengths,\r\n                    transition_params=self.transition_parameters)\r\n                self.loss = tf.reduce_mean(-log_likelihood, name='cross_entropy_mean_loss')\r\n                self.accuracy = tf.constant(1)\r\n\r\n                self.crf_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=f\"{vs.name}_{self.language}\")\r\n\r\n        # Do not use CRF layer\r\n        else:\r\n            with tf.variable_scope(f\"crf_{self.language}\") as vs:\r\n            # with tf.variable_scope(f\"crf\") as vs:\r\n                self.transition_parameters = tf.get_variable(\r\n                    f\"transitions\",\r\n                    shape=[dataset.number_of_classes + 2, dataset.number_of_classes + 2],\r\n                    initializer=initializer)\r\n                utils_tf.variable_summaries(self.transition_parameters)\r\n                self.crf_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=f\"{vs.name}_{self.language}\")\r\n\r\n            # Calculate mean cross-entropy loss\r\n            with tf.variable_scope(f\"loss_{self.language}\"):\r\n            # with tf.variable_scope(f\"loss\"):\r\n                losses = tf.nn.softmax_cross_entropy_with_logits(logits=self.unary_scores,\r\n                                                                 labels=self.input_label_indices_vector, name=f'softmax_{self.language}')\r\n                self.loss = tf.reduce_mean(losses, name=f'cross_entropy_mean_loss_{self.language}')\r\n            with tf.variable_scope(f\"accuracy_{self.language}\"):\r\n                correct_predictions = tf.equal(self.predictions, tf.argmax(self.input_label_indices_vector, 1))\r\n                self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, 'float'), name=f'accuracy_{self.language}')\r\n\r\n        self.define_training_procedure(parameters)\r\n        self.summary_op = tf.summary.merge_all()\r\n        self.saver = tf.train.Saver(max_to_keep=parameters['maximum_number_of_epochs'])  # defaults to saving all variables\r\n\r\n    def define_training_procedure(self, parameters):\r\n        # Define training procedure\r\n        self.global_step = tf.Variable(0, name=f\"global_step_{self.language}\", trainable=False)\r\n        if parameters['optimizer'] == 'adam':\r\n            self.optimizer = tf.train.AdamOptimizer(parameters['learning_rate'])\r\n        elif parameters['optimizer'] == 'sgd':\r\n            self.optimizer = tf.train.GradientDescentOptimizer(parameters['learning_rate'])\r\n        elif parameters['optimizer'] == 'adadelta':\r\n            self.optimizer = tf.train.AdadeltaOptimizer(parameters['learning_rate'])\r\n        else:\r\n            raise ValueError('The lr_method parameter must be either adadelta, adam or sgd.')\r\n\r\n        grads_and_vars = self.optimizer.compute_gradients(self.loss)\r\n        if parameters['gradient_clipping_value']:\r\n            grads_and_vars = [(tf.clip_by_value(grad, -parameters['gradient_clipping_value'],\r\n                                                parameters['gradient_clipping_value']), var)\r\n                              for grad, var in grads_and_vars]\r\n\r\n        # By defining a global_step variable and passing it to the optimizer we allow TensorFlow handle the counting of training steps for us.\r\n        # The global step will be automatically incremented by one every time you execute train_op.\r\n        self.train_op = self.optimizer.apply_gradients(grads_and_vars, global_step=self.global_step)\r\n\r\n\r\n    def load_pretrained_token_embeddings(self, sess, dataset, parameters, token_to_vector=None):\r\n        if parameters['token_pretrained_embedding_filepath'] == '':\r\n            return\r\n        # Load embeddings\r\n        start_time = time.time()\r\n        print('Load token embeddings... ', end='', flush=True)\r\n        if token_to_vector == None:\r\n            token_to_vector = utils_nlp.load_pretrained_token_embeddings(parameters)\r\n\r\n        initial_weights = sess.run(self.token_embedding_weights.read_value())\r\n        number_of_loaded_word_vectors = 0\r\n        number_of_token_original_case_found = 0\r\n        number_of_token_lowercase_found = 0\r\n        number_of_token_digits_replaced_with_zeros_found = 0\r\n        number_of_token_lowercase_and_digits_replaced_with_zeros_found = 0\r\n        for token in dataset.token_to_index.keys():\r\n            if token in token_to_vector.keys():\r\n                initial_weights[dataset.token_to_index[token]] = token_to_vector[token]\r\n                number_of_token_original_case_found += 1\r\n            elif parameters['check_for_lowercase'] and token.lower() in token_to_vector.keys():\r\n                initial_weights[dataset.token_to_index[token]] = token_to_vector[token.lower()]\r\n                number_of_token_lowercase_found += 1\r\n            elif parameters['check_for_digits_replaced_with_zeros'] and re.sub('\\d', '0',\r\n                                                                               token) in token_to_vector.keys():\r\n                initial_weights[dataset.token_to_index[token]] = token_to_vector[re.sub('\\d', '0', token)]\r\n                number_of_token_digits_replaced_with_zeros_found += 1\r\n            elif parameters['check_for_lowercase'] and parameters['check_for_digits_replaced_with_zeros'] and re.sub(\r\n                    '\\d', '0', token.lower()) in token_to_vector.keys():\r\n                initial_weights[dataset.token_to_index[token]] = token_to_vector[re.sub('\\d', '0', token.lower())]\r\n                number_of_token_lowercase_and_digits_replaced_with_zeros_found += 1\r\n            else:\r\n                continue\r\n            number_of_loaded_word_vectors += 1\r\n        elapsed_time = time.time() - start_time\r\n        print('done ({0:.2f} seconds)'.format(elapsed_time))\r\n        print(\"number_of_token_original_case_found: {0}\".format(number_of_token_original_case_found))\r\n        print(\"number_of_token_lowercase_found: {0}\".format(number_of_token_lowercase_found))\r\n        print(\"number_of_token_digits_replaced_with_zeros_found: {0}\".format(\r\n            number_of_token_digits_replaced_with_zeros_found))\r\n        print(\"number_of_token_lowercase_and_digits_replaced_with_zeros_found: {0}\".format(\r\n            number_of_token_lowercase_and_digits_replaced_with_zeros_found))\r\n        print('number_of_loaded_word_vectors: {0}'.format(number_of_loaded_word_vectors))\r\n        print(\"dataset.vocabulary_size: {0}\".format(dataset.vocabulary_size))\r\n        sess.run(self.token_embedding_weights.assign(initial_weights))\r\n\r\n    def load_embeddings_from_pretrained_model(self, sess, dataset, pretraining_dataset, pretrained_embedding_weights,\r\n                                              embedding_type='token'):\r\n        if embedding_type == 'token':\r\n            embedding_weights = self.token_embedding_weights\r\n            index_to_string = dataset.index_to_token\r\n            pretraining_string_to_index = pretraining_dataset.token_to_index\r\n        elif embedding_type == 'character':\r\n            embedding_weights = self.character_embedding_weights\r\n            index_to_string = dataset.index_to_character\r\n            pretraining_string_to_index = pretraining_dataset.character_to_index\r\n        # Load embeddings\r\n        start_time = time.time()\r\n        print('Load {0} embeddings from pretrained model... '.format(embedding_type), end='', flush=True)\r\n        initial_weights = sess.run(embedding_weights.read_value())\r\n\r\n        if embedding_type == 'token':\r\n            initial_weights[dataset.UNK_TOKEN_INDEX] = pretrained_embedding_weights[pretraining_dataset.UNK_TOKEN_INDEX]\r\n        elif embedding_type == 'character':\r\n            initial_weights[dataset.PADDING_CHARACTER_INDEX] = pretrained_embedding_weights[\r\n                pretraining_dataset.PADDING_CHARACTER_INDEX]\r\n\r\n        number_of_loaded_vectors = 1\r\n        for index, string in index_to_string.items():\r\n            if index == dataset.UNK_TOKEN_INDEX:\r\n                continue\r\n            if string in pretraining_string_to_index.keys():\r\n                initial_weights[index] = pretrained_embedding_weights[pretraining_string_to_index[string]]\r\n                number_of_loaded_vectors += 1\r\n        elapsed_time = time.time() - start_time\r\n        print('done ({0:.2f} seconds)'.format(elapsed_time))\r\n        print(\"number_of_loaded_vectors: {0}\".format(number_of_loaded_vectors))\r\n        if embedding_type == 'token':\r\n            print(\"dataset.vocabulary_size: {0}\".format(dataset.vocabulary_size))\r\n        elif embedding_type == 'character':\r\n            print(\"dataset.alphabet_size: {0}\".format(dataset.alphabet_size))\r\n        sess.run(embedding_weights.assign(initial_weights))\r\n\r\n    def restore_from_pretrained_model(self, parameters, dataset, sess, token_to_vector=None):\r\n        pretraining_dataset = pickle.load(\r\n            open(os.path.join(parameters['pretrained_model_folder'], 'dataset.pickle'), 'rb'))\r\n        pretrained_model_checkpoint_filepath = os.path.join(parameters['pretrained_model_folder'], 'model.ckpt')\r\n\r\n        # Assert that the label sets are the same\r\n        # Test set should have the same label set as the pretrained dataset\r\n        assert pretraining_dataset.index_to_label == dataset.index_to_label\r\n\r\n        # If the token and character mappings are exactly the same\r\n        if pretraining_dataset.index_to_token == dataset.index_to_token and pretraining_dataset.index_to_character == dataset.index_to_character:\r\n\r\n            # Restore the pretrained model\r\n            self.saver.restore(sess, pretrained_model_checkpoint_filepath)  # Works only when the dimensions of tensor variables are matched.\r\n\r\n        # If the token and character mappings are different between the pretrained model and the current model\r\n        else:\r\n\r\n            # Resize the token and character embedding weights to match them with the pretrained model (required in order to restore the pretrained model)\r\n            utils_tf.resize_tensor_variable(sess, self.character_embedding_weights, [pretraining_dataset.alphabet_size,\r\n                                                                                     parameters[\r\n                                                                                         'character_embedding_dimension']])\r\n            utils_tf.resize_tensor_variable(sess, self.token_embedding_weights, [pretraining_dataset.vocabulary_size,\r\n                                                                                 parameters[\r\n                                                                                     'token_embedding_dimension']])\r\n\r\n            # Restore the pretrained model\r\n            self.saver.restore(sess,\r\n                               pretrained_model_checkpoint_filepath)  # Works only when the dimensions of tensor variables are matched.\r\n\r\n            # Get pretrained embeddings\r\n            character_embedding_weights, token_embedding_weights = sess.run(\r\n                [self.character_embedding_weights, self.token_embedding_weights])\r\n\r\n            # Restore the sizes of token and character embedding weights\r\n            utils_tf.resize_tensor_variable(sess, self.character_embedding_weights,\r\n                                            [dataset.alphabet_size, parameters['character_embedding_dimension']])\r\n            utils_tf.resize_tensor_variable(sess, self.token_embedding_weights,\r\n                                            [dataset.vocabulary_size, parameters['token_embedding_dimension']])\r\n\r\n            # Re-initialize the token and character embedding weights\r\n            sess.run(tf.variables_initializer([self.character_embedding_weights, self.token_embedding_weights]))\r\n\r\n            # Load embedding weights from pretrained token embeddings first\r\n            self.load_pretrained_token_embeddings(sess, dataset, parameters, token_to_vector=token_to_vector)\r\n\r\n            # Load embedding weights from pretrained model\r\n            self.load_embeddings_from_pretrained_model(sess, dataset, pretraining_dataset, token_embedding_weights,\r\n                                                       embedding_type='token')\r\n            self.load_embeddings_from_pretrained_model(sess, dataset, pretraining_dataset, character_embedding_weights,\r\n                                                       embedding_type='character')\r\n\r\n            del pretraining_dataset\r\n            del character_embedding_weights\r\n            del token_embedding_weights\r\n\r\n        # Get transition parameters\r\n        transition_params_trained = sess.run(self.transition_parameters)\r\n\r\n        if not parameters['reload_character_embeddings']:\r\n            sess.run(tf.variables_initializer([self.character_embedding_weights]))\r\n        if not parameters['reload_character_lstm']:\r\n            sess.run(tf.variables_initializer(self.character_lstm_variables))\r\n        if not parameters['reload_token_embeddings']:\r\n            sess.run(tf.variables_initializer([self.token_embedding_weights]))\r\n        if not parameters['reload_token_lstm']:\r\n            sess.run(tf.variables_initializer(self.token_lstm_variables))\r\n        if not parameters['reload_feedforward']:\r\n            sess.run(tf.variables_initializer(self.feedforward_variables))\r\n        if not parameters['reload_crf']:\r\n            sess.run(tf.variables_initializer(self.crf_variables))\r\n\r\n        return transition_params_trained\r\n\r\n\r\n[entity_lstm.zip]\r\n(https://github.com/tensorflow/tensorflow/files/6606424/entity_lstm.zip)\r\n\r\n\r\n\r\n\r\n\r\n"]}, {"number": 3269, "title": "Add cuda_configure repository rule to autodetect cuda.", "body": "Fixes #2873 \n", "comments": ["Building using the system's default version of cuda libraries (running `bazel test --config=cuda //tensorflow/...` without `CUDA_VERSION=7.5) causes all the Python targets to raise the following import error:\n\n```\n\u276f\u276f\u276f bazel test --config=cuda //tensorflow/python:summary_writer_test --test_output=errors\nWARNING: /usr/local/google/home/dzc/Projects/tensorflow/tensorflow/util/python/BUILD:11:16: in includes attribute of cc_library rule //util/python:python_headers: 'python_include' resolves to 'util/python/python_include' not in 'third_party'. This will be an error in the future\nINFO: Analysed target //tensorflow/python:summary_writer_test (0 packages loaded).\nINFO: Found 1 test target...\nFAIL: //tensorflow/python:summary_writer_test (see /usr/local/google/home/dzc/.cache/bazel/_bazel_dzc/97010c3bd7554ebe07410261582c4d5e/execroot/tensorflow/bazel-out/local_linux-fastbuild/testlogs/tensorflow/python/summary_writer_test/test.log)\nINFO: From Testing //tensorflow/python:summary_writer_test:\n==================== Test output for //tensorflow/python:summary_writer_test:\nTraceback (most recent call last):\n  File \"/usr/local/google/home/dzc/.cache/bazel/_bazel_dzc/97010c3bd7554ebe07410261582c4d5e/execroot/tensorflow/bazel-out/local_linux-fastbuild/bin/tensorflow/python/summary_writer_test.runfiles/org_tensorflow/tensorflow/python/training/summary_writer_test.py\", line 26, in <module>\n    import tensorflow as tf\n  File \"/usr/local/google/home/dzc/.cache/bazel/_bazel_dzc/97010c3bd7554ebe07410261582c4d5e/execroot/tensorflow/bazel-out/local_linux-fastbuild/bin/tensorflow/python/summary_writer_test.runfiles/org_tensorflow/tensorflow/__init__.py\", line 23, in <module>\n    from tensorflow.python import *\n  File \"/usr/local/google/home/dzc/.cache/bazel/_bazel_dzc/97010c3bd7554ebe07410261582c4d5e/execroot/tensorflow/bazel-out/local_linux-fastbuild/bin/tensorflow/python/summary_writer_test.runfiles/org_tensorflow/tensorflow/python/__init__.py\", line 48, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File \"/usr/local/google/home/dzc/.cache/bazel/_bazel_dzc/97010c3bd7554ebe07410261582c4d5e/execroot/tensorflow/bazel-out/local_linux-fastbuild/bin/tensorflow/python/summary_writer_test.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>\n    _pywrap_tensorflow = swig_import_helper()\n  File \"/usr/local/google/home/dzc/.cache/bazel/_bazel_dzc/97010c3bd7554ebe07410261582c4d5e/execroot/tensorflow/bazel-out/local_linux-fastbuild/bin/tensorflow/python/summary_writer_test.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\nImportError: libcudart.so.7.5: cannot open shared object file: No such file or directory\n================================================================================\nTarget //tensorflow/python:summary_writer_test up-to-date:\n  bazel-bin/tensorflow/python/summary_writer_test\nINFO: Elapsed time: 0.447s, Critical Path: 0.10s\nINFO: Build completed, 1 test FAILED, 2 total actions\n//tensorflow/python:summary_writer_test                                  FAILED in 0.1s\n  /usr/local/google/home/dzc/.cache/bazel/_bazel_dzc/97010c3bd7554ebe07410261582c4d5e/execroot/tensorflow/bazel-out/local_linux-fastbuild/testlogs/tensorflow/python/summary_writer_test/test.log\n\nExecuted 1 out of 1 test: 1 fails locally.\n```\n\nAs expected, the `local_config_cuda/cuda/lib64` directory only contains the symlinks to the `.so`'s without the version suffix (`libcudart.so` rather than `libcudart.so.7.5`). However, it appears that the SWIG wrapper still ends up looking for the versioned libraries. I'm not familiar with how SWIG or `imp` works, but the string `\"7\\.5\"` does not appear any of the files under the files generated by `cuda_configure()` under `bazel-tensorflow/external/local_config_cuda`. Is the cuda version getting hard-coded somewhere else, causing the SWIG wrapper to look for the versioned library instead of the unversioned one?\n", "Ok this mostly looks good, I added some comments.\n\n@davidzchen: the tests are all broken, do you know why?\n", "@damienmg The tests are failing due to the following error:\n\n```\nERROR: com.google.devtools.build.lib.packages.BuildFileContainsErrorsException: error loading package '': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\n    File \"/workspace/third_party/gpus/cuda_configure.bzl\", line 219\n        _cuda_toolkit_path(repository_ctx)\n    File \"/workspace/third_party/gpus/cuda_configure.bzl\", line 72, in _cuda_toolkit_path\n        fail(\"Cannot find cuda toolkit path.\")\nCannot find cuda toolkit path.\n```\n\nI still need to figure out why the CI machine cannot find cuda.\n", "@jendap might knows more about the CI setup itself.\n", "So the PR LGTM, just needs to fix the test and figure out the problem with fetching.\n", "Here is the current breakdown of test failures. The good news is that the vast majority of tests are passing. Curiously, there are some additional test failures when the we are configuring using `CUDA_VERSION=7.5` than when the autoconf is configured to use the system default cuda version (i.e. the non-versioned files), and some of these appear to be `missing dependency declarations` errors. I am still investigating these.\n\n## Without `CUDA_VERSION=7.5` set\n\nBazel invocation:\n\n``` sh\nbazel fetch //...\nbazel test --config=cuda //tensorflow/...\n```\n\n6 / 624 tests failing:\n\n```\n//tensorflow/contrib/distributions:beta_test\n//tensorflow/contrib/distributions:dirichlet_test\n//tensorflow/contrib/distributions:gamma_test\n//tensorflow/contrib/distributions:inverse_gamma_test\n//tensorflow/contrib/distributions:mvn_test\n//tensorflow/examples/skflow:examples_test\n```\n\n## With `CUDA_VERSION=7.5` set\n\nBazel invocation:\n\n``` sh\nCUDA_VERSION=7.5 bazel fetch //...\nbazel test --config=cuda //tensorflow/...\n```\n\n13 / 624 tests failing:\n\n```\n//tensorflow/core:debug_debug_gateway_test (TIMEOUT)\n//tensorflow/contrib/distributions:beta_test\n//tensorflow/contrib/distributions:dirichlet_test\n//tensorflow/contrib/distributions:gamma_test\n//tensorflow/contrib/distributions:inverse_gamma_test\n//tensorflow/contrib/distributions:mvn_test\n//tensorflow/core:common_runtime_gpu_gpu_bfc_allocator_test\n//tensorflow/core:common_runtime_gpu_gpu_debug_allocator_test\n//tensorflow/core:common_runtime_gpu_gpu_event_mgr_test\n//tensorflow/core:common_runtime_gpu_gpu_tracer_test\n//tensorflow/core:common_runtime_gpu_pool_allocator_test\n//tensorflow/examples/skflow:examples_test\n//tensorflow/g3doc/how_tos/adding_an_op:cuda_op_test\n```\n", "Is this stalled? Maybe try to get some help from people from the TensorFlow team\n", "Try building with --config=cuda -c opt  ?\n", "Apologies for the wait. I have been busy with some work for my team these past few days. I'm working on this right now.\n", "I added a couple of other comment. This change LGTM if it passes the test suite.\n", "Making good progress. All of the CI build are passing except for the Linux GPU PIP build.\n\n@jendap - The Linux GPU PIP build is failing due to the following:\n\n```\nERROR: com.google.devtools.build.lib.packages.BuildFileContainsErrorsException: error loading package '': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\n    File \"/workspace/third_party/gpus/cuda_configure.bzl\", line 381\n        _create_cuda_repository(repository_ctx)\n    File \"/workspace/third_party/gpus/cuda_configure.bzl\", line 337, in _create_cuda_repository\n        repository_ctx.symlink(cudnn_header_dir + \"/cudnn.h\", \"cu...\")\njava.io.IOException: Could not create symlink from /usr/include/cudnn.h to /opt/jenkins/workspace/tensorflow-pull-requests-gpu_pip/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/external/local_config_cuda/cuda/include/cudnn.h: /opt/jenkins/workspace/tensorflow-pull-requests-gpu_pip/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/external/local_config_cuda/cuda/include/cudnn.h (Permission denied).\nConfiguration finished\n```\n\nIt seems that there is a permission error when `cuda_configure` attempts to create the symlinks for the CUDA toolkit files. Do we need to make some changes to the CI scripts to get this to work?\n", "Curious, the directory is owned by the jenkins user. however, there is already a cuda.h file in that folder, so I am guessing that is the reason for header symlink failing to be created.\n", "To me, it looks like the error is thrown during the configure script.\nIs it possible one of your changes is causing an unintended side effect?\n", "If there's already a cuda.h, could it be a caching/previous build issue? The GPU build changed, so I'll run this again.\n\nJenkins, test this please.\n", "It failed the same way, interesting.\nDavid, could you check your changes to the configure script?\n", "As @terrytangyuan has pointed out, this seems to be a pervasive issue, not related to any particular PR. I suspect we have to change the blocking presubmits in the branch setup. Let me see.\n", "Jenkins, test this please\n", "That is interesting. Before the `configure` script runs the `bazel fetch` command (where the error is happening), it runs `bazel clean --expunge`, which should have deleted all of the files Bazel generated for the workspace. Is it possible that not all of the files were deleted?\n", "Looking at the Linux-GPU failure now, it does look different. Can you take a look? \n", "I see the `no such package '@local_config_cuda//crosstool': BUILD file not found on package path.` error at the end of the log, but in the middle, we still have the permissions error:\n\n```\nERROR: com.google.devtools.build.lib.packages.BuildFileContainsErrorsException: error loading package '': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\n    File \"/workspace/third_party/gpus/cuda_configure.bzl\", line 381\n        _create_cuda_repository(repository_ctx)\n    File \"/workspace/third_party/gpus/cuda_configure.bzl\", line 337, in _create_cuda_repository\n        repository_ctx.symlink(cudnn_header_dir + \"/cudnn.h\", \"cu...\")\njava.io.IOException: Could not create symlink from /usr/include/cudnn.h to /opt/jenkins/workspace/tensorflow-pull-requests-gpu/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/external/local_config_cuda/cuda/include/cudnn.h: /opt/jenkins/workspace/tensorflow-pull-requests-gpu/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/external/local_config_cuda/cuda/include/cudnn.h (Permission denied).\n```\n\nMy understanding is that because `cc_configure` was not able to complete due to the permission issue when trying to symlink `cudnn.h` the workspace it created is incomplete, and the \"BUILD file not found on package\" error occurs because the BUILD file is generated [at a later step](https://github.com/davidzchen/tensorflow/blob/cuda-configure/third_party/gpus/cuda_configure.bzl#L342). @damienmg, is my understanding of this correct? If so, shouldn't the first error cause the loading phase to abort?\n", "I wiped the workspace and tried again, but same problem. \n", "That is odd. I'll investigate further tomorrow once I am back from vacation.\n", "Jenkins, test this please\n", "The header symlinking issue is fixed, but it looks like the Linux GPU build is unable to find the cuDNN libraries:\n\n```\nERROR: com.google.devtools.build.lib.packages.BuildFileContainsErrorsException: error loading package '': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\n    File \"/workspace/third_party/gpus/cuda_configure.bzl\", line 406\n        _create_cuda_repository(repository_ctx)\n    File \"/workspace/third_party/gpus/cuda_configure.bzl\", line 343, in _create_cuda_repository\n        _find_cudnn_lib_path(repository_ctx, cudnn_install_base..., ...)\n    File \"/workspace/third_party/gpus/cuda_configure.bzl\", line 252, in _find_cudnn_lib_path\n        fail(\"Cannot find %s or %s under %s\" ...))\nCannot find lib64/libcudnn.so.5 or libcudnn.so.5 under /usr/local/cuda.\n```\n\nI have dumped the list of files under both `/usr/local/cuda` and `/usr/local/cuda/lib64` (see [log](http://ci.tensorflow.org/job/tensorflow-pull-requests-gpu/1520/console)), and curiously, `libcudnn.so.5` is under neither directory (though all other cuda libraries appear to be present).\n\n@jendap, @martinwicke - where are the cuDNN libraries installed on the system for the GPU CI Docker containers?\n\nAlso, for my understanding, it seems that [`CUDA_DNN_LIB_ALT_PATH`](https://github.com/tensorflow/tensorflow/blob/master/third_party/gpus/cuda/cuda_config.sh#L128) in the existing CUDA detection implementation seems to suggest that `libcudnn.so` may be installed on some systems directly under `/usr/local/cuda` rather than under `/usr/local/cuda/lib` or `/usr/local/cuda/lib64`. Is my understanding of this correct?\n", "I just logged into our docker container used for a gpu pip test, and here is what I see.\nlibcudnn.so location: /usr/lib/x86_64-linux-gnu/libcudnn.so\n$ echo $LD_LIBRARY_PATH\n/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64\n\n$ ls -l /usr/local/cuda/lib64\nlrwxrwxrwx 1 root root 24 Aug 15  2015 /usr/local/cuda/lib64 -> targets/x86_64-linux/lib\n\n$ ls -l /usr/local/cuda/lib  \nls: cannot access /usr/local/cuda/lib: No such file or directory\n", "@gunan - To confirm: on the docker container for the GPU tests, `libcudnn.so` is installed under `/usr/lib/x86_64-linux-gnu` and not `/usr/local/cuda/lib64`? Is this expected?\n\nThis seems odd to me since [`Dockerfile.gpu`](https://github.com/tensorflow/tensorflow/blob/73ced9d797056c7e67a06ed2098dd809d85ec44a/tensorflow/tools/ci_build/Dockerfile.gpu#L25) seems to specify that `libcudnn.so` is also installed under `/usr/local/cuda/lib64`:\n\n``` dockerfile\nENV CUDNN_INSTALL_PATH /usr/local/cuda\n```\n", "Correct. At least this is what I am seeing. I do not know if this is expected or not, but my bet is it is unexpected.\nI also downloaded the clean image from nvidia's dockerhub, and it is the same as what I saw on our jenkins workers.\n\nDoes this issue look related?\nhttps://github.com/NVIDIA/nvidia-docker/issues/37\n", "It's possible. We did just upgraded to cudnn 5 (tensorflow/tensorflow#3773), but it is curious that the existing GPU CI build does not seem to be failing with this issue.\n\nI have opened NVIDIA/nvidia-docker#172 to confirm whether the location of `libcudnn.so` is expected in the image.\n", "On my workstation I tried with nvidia/cuda 7.5-cudnn4-devel image and it is in the same location, not under /usr/lib/cuda\nSo the issue is not specific to cudnn5 image\n", "I see. Also, @flx42 just [confirmed](https://github.com/NVIDIA/nvidia-docker/issues/172#issuecomment-240015793) on NVIDIA/nvidia-docker#172 that `/usr/lib/x86_64-linux-gnu` is, in fact, the correct install location for `libcudnn.so`.\n\nIn that case, is the `ENV CUDNN_INSTALL_PATH` line in `Dockerfile.gpu` is incorrect then?\n\nIt is still unclear to me why the CI GPU builds for the existing code is not failing due to this ~~since the existing code [searches for `libcudnn.so` under a `$CUDNN_INSTALL_BASEDIR/lib64` directory](https://github.com/tensorflow/tensorflow/blob/master/third_party/gpus/cuda/cuda_config.sh#L127)~~.\n\n**Edit:** It seems that the case where `libcudnn.so` is installed under `/usr/lib/x86_64-linux-gnu` is the reason why we have `CUDA_DNN_LIB_ALT_PATH`, though it is still unclear how the test was able to find `libcudnn.so` since `CUDNN_INSTALL_PATH` was set to `/usr/local/cuda`.\n", "Jenkins, test this please\n", "Any progress here?\nr0.10 full release is blocked on this PR.\n", "I was able to get the Linux GPU build to work and made sure that both of the possible install paths for `libcudnn.so` are supported. I also started looking into changes needed internally to merge this into the internal repo (@gunan, I have added you to that thread). I am also oncall this week and have been a bit busy with that as well.\n\nAll of the Linux GPU tests are passing except for these:\n\n```\n//tensorflow/core:common_runtime_gpu_gpu_tracer_test\n//tensorflow/g3doc/how_tos/adding_an_op:cuda_op_test\n//tensorflow/python:device_lib_test\n```\n\nThese tests seem to all be failing due to the following:\n\n```\nActual: Invalid argument: Cannot assign a device to node 'n/_2': Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/gpu:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n     [[Node: n/_2 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](n/_0, n/_1)]]\nExpected: ::tensorflow::Status::OK()\n```\n\nThese error message seem to be related:\n\n```\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:61] cannot enable peer access from device ordinal 0 to device ordinal 1\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:61] cannot enable peer access from device ordinal 0 to device ordinal 2\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:61] cannot enable peer access from device ordinal 0 to device ordinal 3\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:61] cannot enable peer access from device ordinal 1 to device ordinal 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:61] cannot enable peer access from device ordinal 1 to device ordinal 2\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:61] cannot enable peer access from device ordinal 1 to device ordinal 3\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:61] cannot enable peer access from device ordinal 2 to device ordinal 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:61] cannot enable peer access from device ordinal 2 to device ordinal 1\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:61] cannot enable peer access from device ordinal 2 to device ordinal 3\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:61] cannot enable peer access from device ordinal 3 to device ordinal 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:61] cannot enable peer access from device ordinal 3 to device ordinal 1\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:61] cannot enable peer access from device ordinal 3 to device ordinal 2\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:138] DMA: 0 1 2 3 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:148] 0:   Y N N N \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:148] 1:   N Y N N \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:148] 2:   N N Y N \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:148] 3:   N N N Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:842] Ignoring gpu device (device: 0, name: GRID K2, pci bus id: 0000:00:04.0) with Cuda compute capability 3.0. The minimum required Cuda capability is 3.5.\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:842] Ignoring gpu device (device: 1, name: GRID K2, pci bus id: 0000:00:05.0) with Cuda compute capability 3.0. The minimum required Cuda capability is 3.5.\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:842] Ignoring gpu device (device: 2, name: GRID K2, pci bus id: 0000:00:06.0) with Cuda compute capability 3.0. The minimum required Cuda capability is 3.5.\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:842] Ignoring gpu device (device: 3, name: GRID K2, pci bus id: 0000:00:07.0) with Cuda compute capability 3.0. The minimum required Cuda capability is 3.5.\ntensorflow/core/debug/debug_gateway_test.cc:140: Failure\nValue of: (s)\n  Actual: Invalid argument: Cannot assign a device to node 'n/_2': Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/gpu:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n     [[Node: n/_2 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](n/_0, n/_1)]]\nExpected: ::tensorflow::Status::OK()\nWhich is: OK\n```\n\nIs the message about the CUDA compute capability being on the CI machine 3.0 correct?\n", "Yes, Cuda compute capability is correct.\nWe have k2 cards on jenkins' test machines.\n\nYour error looks like those tests were not able to access the GPUs\n", "Understood. In that case, we need to set the minimum compute capability to 3.0 for the tests. I have made a change to set an env variable for that in Dockerfile.gpu and re-running the tests now.\n", "I have fixed Dockerfile.gpu to use the compute capability, and Linux GPU tests are now passing. The status of the MacOS CPU Tests is still \"Waiting for status to be reported.\" Are those tests stalled?\n\nThis PR itself is ready. There is a bit of work I need to do internally to allow this PR to be correctly imported into the internal repo before we can merge this.\n", "Hi, just coming back from holidays. David: do you still need my help on\nthis PR?\n\nOn Mon, Aug 22, 2016 at 10:03 AM David Z. Chen notifications@github.com\nwrote:\n\n> I have fixed Dockerfile.gpu to use the compute capability, and Linux GPU\n> tests are now passing. The status of the MacOS CPU Tests is still \"Waiting\n> for status to be reported.\" Are those tests stalled?\n> \n> This PR itself is ready. There is a bit of work I need to do internally to\n> allow this PR to be correctly imported into the internal repo before we can\n> merge this.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/3269#issuecomment-241339893,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ADjHf80c6oBMYhUKT13L5oxXLKCmulT6ks5qiVfEgaJpZM4JJPRy\n> .\n", "Woohoo!  Mac test machines are currently disabled, but hopefully the changes here should apply there as well.\n", "Congrats Rasmus, you'll have to work with David this week to pull this change in internally :)\n", "Uh oh, that have I done!?!\n", "Now, what is the best way to pull this PR into r0.10?\n", "git cherry-pick :)\n", "Thank you everyone for taking the time to help me understand the intricacies of the TensorFlow CUDA build setup and taking the time to review this change! :)\n", "This change is big enough in terms of the impact on installation that we\nmay want to wait another full 7 days until we exit RC (assuming everything\nelse is clear). I'd like to see the effect on issues first and have this\nfield tested by the community on more systems than we can muster here.\nOn Mon, Aug 22, 2016 at 16:48 David Z. Chen notifications@github.com\nwrote:\n\n> Thank you everyone for taking the time to help me understand the\n> intricacies of the TensorFlow CUDA build setup and taking the time to\n> review this change! :)\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/3269#issuecomment-241585340,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AAjO_Yi2Vnkd9FgelyXZCrvBIMXNRoubks5qijVVgaJpZM4JJPRy\n> .\n", "Martin, do you think we should re-release the docker images and pip wheel files for the RC?\n", "To make RC1? This change won't affect the binaries at all, so I don't think\nthat's necessary.\nOn Mon, Aug 22, 2016 at 22:35 gunan notifications@github.com wrote:\n\n> Martin, do you think we should re-release the docker images and pip wheel\n> files for the RC?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/3269#issuecomment-241631192,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AAjO_bkEVQYInXgtutCnkXCfJA_tlQTHks5qioaFgaJpZM4JJPRy\n> .\n", "@davidzchen With this PR, it looks like setting variable `TF_CUDA_COMPUTE_CAPABILITIES` before the configure doesn't work anymore, am I missing something? Now you have to set `CUDA_COMPUTE_CAPABILITIES` instead.\n", "@flx42 Setting `TF_CUDA_COMPUTE_CAPABILITIES` before running `configure` should still work since that part of the `configure` script (showing the Cuda compute capabilities prompt only if `TF_CUDA_COMPUTE_CAPABILITIES` is not set) is still there: https://github.com/tensorflow/tensorflow/blob/master/configure#L239\n\nRunning `TF_CUDA_COMPUTE_CAPABILITIES=3.0,5.2 ./configure`, then running a bazel build command, then looking at the compute capabilities generated in `bazel-tensorflow/external/local_config_cuda/cuda/cuda_config.h` confirms that the correct compute capabilities were set.\n\nWhat is the issue that you are observing?\n", "> Running TF_CUDA_COMPUTE_CAPABILITIES=3.0,5.2 ./configure, then running a bazel build command, then looking at the compute capabilities generated in bazel-tensorflow/external/local_config_cuda/cuda/cuda_config.h confirms that the correct compute capabilities were set.\n\nEdit: sorry, my bad, 3.5,5.2 is the default.\n\nOn my side, I tried with a modified version of the current Dockerfile.devel-gpu:\n\n```\ndiff --git a/tensorflow/tools/docker/Dockerfile.devel-gpu b/tensorflow/tools/docker/Dockerfile.devel-gpu\nindex 4877f8c..3b542b0 100644\n--- a/tensorflow/tools/docker/Dockerfile.devel-gpu\n+++ b/tensorflow/tools/docker/Dockerfile.devel-gpu\n@@ -1,4 +1,4 @@\n-FROM nvidia/cuda:7.5-cudnn5-devel\n+FROM nvidia/cuda:8.0-cudnn5-devel\n\n MAINTAINER Craig Citro <craigcitro@google.com>\n\n@@ -89,6 +89,7 @@ WORKDIR /tensorflow\n ENV CUDA_TOOLKIT_PATH /usr/local/cuda\n ENV CUDNN_INSTALL_PATH /usr/local/cuda\n ENV TF_NEED_CUDA 1\n+ENV TF_CUDA_COMPUTE_CAPABILITIES \"6.0\"\n\n RUN ./configure && \\\n     bazel build -c opt --config=cuda tensorflow/tools/pip_package:build_pip_package && \\\n```\n\nAnd I saw 3.5, 5.2 in cuda_config.h\n", "@davidzchen Looks like after the `configure` I do have 6.0 in `cuda_config.h`, but during the `bazel build` step, it becomes `3.5,5.2` instead.\n", "@flx42 That is odd. I'll take a look. #4002 is the tracking bug opened for that issue.\n"]}, {"number": 3268, "title": "Timeline's reported memory usage not properly displayed in Chrome", "body": "I am attempting to debug out-of-memory issues using the recently introduced support for timeline:\n\n```\nrun_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\nrun_metadata = tf.RunMetadata()\nsess.run(..., options=run_options, run_metadata=run_metadata)\ntrain_writer.add_run_metadata(run_metadata, 'step' + repr(i))\ntl = timeline.Timeline(run_metadata.step_stats)\ntrace_file = tf.gfile.Open(name='timeline', mode='w')\ntrace_file.write(tl.generate_chrome_trace_format(show_memory=True))\n```\n\nThe file is generated, but when opened via `chrome://tracing/` the memory usage events are not displayed at all, only the names. Moreover, opening such memory section results in the CPU-usage events disappearing as well:\n\n<img width=\"665\" alt=\"screen shot 2016-07-11 at 7 23 59 pm\" src=\"https://cloud.githubusercontent.com/assets/6617696/16727681/2fcce290-479d-11e6-8ce4-8563e16f3212.png\">\n\n<img width=\"699\" alt=\"screen shot 2016-07-11 at 7 24 09 pm\" src=\"https://cloud.githubusercontent.com/assets/6617696/16727688/35cf0cf4-479d-11e6-9fc2-1bdc8706e227.png\">\n\nPossibly too many datapoints results in failure to display them?\n", "comments": ["@prb12 Could you take a look at this please?\n", "Update: zooming out a lot in the browser make the dots appear, but that's more of a workaround than a real solution.\n\nBy the way, are the colours related in any way to the size of memory allocations?\n", "> Update: zooming out a lot in the browser make the dots appear, but that's more of a workaround than a real solution.\n\n@stepelu I'm not sure exactly what is going on in this case to produce the UI issues you are seeing - from your description of things changing with zoom levels, it could very easily be an issue with the chrome viewer (which is nothing to do with TensorFlow).  To reproduce it would be helpful if you could provide a copy of the `StepStats` protobuf (preferably) or at least the JSON of the chrome trace.\n\n> By the way, are the colors related in any way to the size of memory allocations?\n\nThe colors of everything in the GUI are chosen by the chrome trace viewer based on the 'name' of the event (usually the Op name).  They are not under the control of TensorFlow unfortunately  :-(\n\n**Note:** There are a number of reasons that the show_memory option is disabled by default:\n- The most important is that there isn't really enough information in the `StepStats` to correctly determine the order of allocation/frees (which is non-deterministic in reality) and so the histogram is at best an approximation of the truth.  The `Timeline` code is effectively replaying a trace of allocs and frees where the timestamps are taken with a very coarse clock, and simulating the memory usage.  Fixing this would require adding much more expensive instrumentation which would hurt the common case performance.\n- The second problem is that the ops which are executed and recorded in the `StepStats` are not necessarily those in the original `GraphDef` due to substantial graph rewriting (e.g. adding Send/Recv nodes when partitioning the graph across devices) and various optimization passes (constant folding, CSE, etc).  It is impossible for the `Timeline` code to correctly determine the dataflow dependencies of these ops - and it currently has a very fragile heuristic based on parsing the string 'description' field of the op to guess its inputs.  It would be possible to do a much better job if somebody implemented a way to retrieve the post-optimization graphs in the `RunMetadata`.  \n- Another, often more important issue, is that a lot of memory consumption is by **stateful** ops such as Queues and Variables which aren't included in this analysis.  e.g. I have seen multiple cases where poorly configured Queues have been consuming many gigabytes of memory.  \n\nSo - in summary, I wouldn't recommend relying too heavily on the Timeline memory analysis at the moment.  \n", "Closing for now, but if you would like to supply a timeline for debugging, please reopen.\n", "@prb12 Hi! I'm wondering if the timeline memory analysis is currently able to capture more accurate memory statistics in the latest TF version?"]}, {"number": 3267, "title": "TensorBoard: gracefully handle deleted event files", "body": "Hi!\n\nAt the moment, TensorBoard at firstignores the deletion of folders and event files inside the log directory, and displays them as though they were there. Then at some later time (i can't tell what triggers it), it starts throwing exceptions, like\n\n```\n  File \"bla/lib/python3.5/site-packages/tensorflow/python/platform/gfile.py\", line 379, in ListDirectory\n    files = os.listdir(directory)\nFileNotFoundError: [Errno 2] No such file or directory: 'bla/dataset-test/logs/watch/dbg/test'\n```\n\nHowever, sometimes a cleanup is required, and unused runs have to be deleted. This is not possible under the current version.\n\nThe workaround of restarting TensorBoard every time that a run is deleted is **very** unsatisfying, because loading a log directory with several (long) runs takes forever\u2122.\n\nWould it be possible to implement the handling of deleted session files and directories in TensorBoard?\n", "comments": ["This is fixed at head, will be fixed in the next release.\n", "@danmane Is this head already pushed? I just tried with 8c10acb2039af47f3a2940281b3e056e9789a82d , and after I delete event files, I still get errors:\n\n`ERROR:tensorflow:Unable to reload accumulator 'dbg_tcmalloc': [Errno 2] No such file or directory: '/fast/cavitylearn/dataset-test/logs/dbg_tcmalloc'\nERROR:tensorflow:Unable to reload accumulator 'dbg_tcmalloc/test': [Errno 2] No such file or directory: '/fast/cavitylearn/dataset-test/logs/dbg_tcmalloc/test'`\n\nAnd the run still stays present in TensorBoard.\n\nTo put short, the behaviour is just like before. Is this intended? \n\nWhat I meant is that instead of showing errors when event files disappear, TensorBoard should drop (or mark as invalid) the runs that have disappeared.\n", "@danmane any update on this?\n", "Since the code has changed substantially since this issue was opened, it might be obsolete. Feel free to open a new github issue if the problem still persists in recent versions.", "```\r\nWARNING:tensorflow:Deleting accumulator 'run1/test'\r\nWARNING:tensorflow:Deleting accumulator 'run1'\r\nWARNING:tensorflow:Deleting accumulator 'run2/test'\r\nWARNING:tensorflow:Deleting accumulator 'run2'\r\n```\r\nWonderful! This is indeed fixed. Thanks for the great work!"]}, {"number": 3266, "title": "ERROR: Cannot find './util/python/python_lib", "body": "### Environment info\n\nOperating System:\nOSX El Capitan 10.11.5\n\nInstalled version of CUDA and cuDNN: \nN/A\n\nIf installed from sources, provide the commit hash:\na4b7bb9\n### Steps to reproduce\n1. `git clone --recursive https://github.com/tensorflow/models.git`\n2. `cd models/syntaxnet/tensorflow`\n3. `./configure`\n4. `cd ..`\n5. `bazel build syntaxnet/...`\n### What have you tried?\n1. Confirmed that bazel version is 0.2.2\n2. Confirmed that configure has been run\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n`INFO: Found 74 targets...\nERROR: /private/var/tmp/_bazel_pberkman/64f225994fec6ff696f44dfe0caf6bfc/external/org_tensorflow/util/python/BUILD:14:1: Executing genrule @org_tensorflow//util/python:python_check failed: bash failed: error executing command /bin/bash -c ... (remaining 1 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\nERROR: Cannot find 'external/org_tensorflow/util/python/python_lib'.  Did you run configure?`\n\nSeems that this issue is consistent with error https://github.com/tensorflow/tensorflow/issues/2703\n", "comments": ["Duplicate to https://github.com/tensorflow/models/issues/266\n"]}, {"number": 3265, "title": "Change is_training of tf.contrib.layers.batch_norm to conditional function", "body": "`tf.contrib.layers.batch_norm` is using `is_training` as a python boolean variable so I may have to define two different ops which share its variables by using `reuse=True` to the second op.\n\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L209\n\nHowever, I think it is better to use `tf.placeholder` or other tensor variables as `is_training` and use `tf.cond` to dynamically change training and testing phase without defining two different ops. Or is there any better usage of using `tf.contrib.layers.batch_norm` that I couldn't think of? Also, is `tf.contrib.layers.fully_connected` ready to use `batch_norm` as a `normalizer_fn` (because I guess this is still in contrib for several months)?\n", "comments": ["I am currently using it like that with my own wrapper around it and think that it is supposed to work like that as `tf.contrib.layers.dropout` does: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L433-L435\n", "@ilblackdragon Could you take a look at this please?\n", "I already have done it internally, it will push soon.\n", "Fixed in https://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed\n", "do we need to update tensorflow? I tried but it seems it made no difference.\n", "Yeah you need 0.10 https://github.com/tensorflow/tensorflow/tree/r0.10\n"]}, {"number": 3264, "title": "Extend #3020 to decode animated GIF", "body": "#3020 has been squashed into a single commit, with proper authorship acknowledgment. I'll squash my commits after code review.\n\nThis PR extends #3020 by loading all frames. The underlying library  `giflib` is too low level to handle the GIF optimizations properly, so an error will be raised if the source GIF is optimized.\n\nFor the test, a synthetic file is used to test the actual decoded content.\n\nPlease review @buaaliyi @martinwicke\n", "comments": ["Can one of the admins verify this patch?\n", "We found a Contributor License Agreement for you (the sender of this pull request) and all commit authors, but as best as we can tell these commits were authored by someone else.  If that's the case,  please add them to this pull request and have them confirm that they're okay with these commits being contributed to Google.  If we're mistaken and you did author these commits, just reply here to confirm.\n\n<!-- need_author_consent -->\n", "@tensorflow-jenkins test this please. (Preliminary testing prior to detailed review).\n", "There are test failures. Please take a look: http://ci.tensorflow.org/job/tensorflow-pull-requests-cpu/1261/consoleFull\n", "Hi @caisq ,\n\nI checked the logs, and the errors are that the testdata can't be found. Is it a mistake in the testing framework? because the tests have passed on my local machine before I submitted here, and the same tests have passed in the other buckets. \n\n```\nNotFoundError: tensorflow/core/lib/gif/testdata/optimized.gif\nNotFoundError: tensorflow/core/lib/gif/testdata/scan.gif\n```\n\nThanks!\n", "I'll merge #3020 so CLAbot will be happy. The test failure is a test on installation failure. Test data for those tests needs to be copied manually (by the testing framework). Add the relevant lines here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/builds/test_installation.sh#L243\n", "@martinwicke Added the lines to copy test data over\n", "Jenkins, test this please\n", "@tensorflow-jenkins test this please\n", "Assuming this passes, could you squash this PR into two commits: one containing @buaaliyi's changes and one containing yours? Then I can merge without squashing and we'll preserve authorship and have a nice tree. \n", "There is a conflict with HEAD, so I have to merge and resolve. I don't know how to get rid of the merge commit message.\n", "Yeah, so three commits, that's fine.\n", "@googlebot  I confirm it.\n", "Jenkins, test this please\n\nCLAbot is broken I guess.\n", "Hooray! Thank you!\n", "Great !\n", "Great! Thanks!\n"]}, {"number": 3263, "title": "Segmentation fault, import tensorflow, tensorflow 0.9, mac osx", "body": "I have followed the installation steps for GPU enabled tensorflow 0.9 on OSX, (https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html#installation-for-mac-os-x), within a conda environment.  The installation seems to go smoothly, but I get a seg fault error when importing tensorflow.  I have tried the fixes from related threads without success. \n\nSee below for the segmentation fault error.\n### Environment info\n\nOperating System: Mac OSX 10.10.5\n\nInstalled version of CUDA and cuDNN:  CUDA 7.5 and cuDNN 5.1\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n$ ls -l /usr/local/cuda/lib/libcud*\n-rwxr-xr-x  1 root     wheel      8280 Apr 13 02:02 /usr/local/cuda/lib/libcuda.dylib\nlrwxr-xr-x  1 root     wheel        45 Apr 13 02:03 /usr/local/cuda/lib/libcudadevrt.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudadevrt.a\nlrwxr-xr-x  1 root     wheel        50 Apr 13 02:03 /usr/local/cuda/lib/libcudart.7.5.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.7.5.dylib\nlrwxr-xr-x  1 root     wheel        46 Apr 13 02:03 /usr/local/cuda/lib/libcudart.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.dylib\nlrwxr-xr-x  1 root     wheel        49 Apr 13 02:03 /usr/local/cuda/lib/libcudart_static.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart_static.a\n-rwxr-xr-x@ 1 lw17567  staff  58975112 Jun 10 04:30 /usr/local/cuda/lib/libcudnn.5.dylib\nlrwxr-xr-x@ 1 lw17567  staff        16 Jun 10 04:31 /usr/local/cuda/lib/libcudnn.dylib -> libcudnn.5.dylib\n-rw-r--r--@ 1 lw17567  staff  56392320 Jun 10 04:30 /usr/local/cuda/lib/libcudnn_static.a\n\nInstalled tensorflow 0.9 within anaconda 2 env,\n\npip version: pip 8.1.2\nPython 2.7.12\n\nThe output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\n$ python -c \"import tensorflow; print(tensorflow.**version**)\"\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.7.5.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.5.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.7.5.dylib locally\nSegmentation fault: 11\n### Steps to reproduce\n\n1.) Create a conda environment\n2.) Followed https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html#installation-for-mac-os-x\n3.) Launch python and import  tensorflow \n### What have you tried?\n1. importing numpy before importing tensorflow\n2. ensuring that I'm outside the tensorflow source directory (well outside)\n3. adding /Developer/NVIDIA/CUDA-7.5/lib to the DYLD_LIBRARY_PATH, per #2773 \n   4.) uninstalling and reinstalling everything and trying again.\n### Logs or other output that would be helpful\n\nOutput from bt, after using gdb to run test script with only line, 'import tensorflow'\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.7.5.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.5.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.7.5.dylib locally\n\nProgram received signal SIGSEGV, Segmentation fault.\n0x00007fff8d2b8f92 in strlen () from /usr/lib/system/libsystem_c.dylib\n\n(gdb) bt\n#0 0x00007fff8d2b8f92 in strlen () from /usr/lib/system/libsystem_c.dylib\n#1 0x0000000104a0b4f0 in perftools::gputools::internal::DsoLoader::GetDsoHandle(tensorflow::StringPiece, void, perftools::gputools::internal::DsoLoader::LoadKind) ()\n\nfrom /Users/lw17567/anaconda2/envs/tensorflow2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#2 0x0000000104a0c06c in perftools::gputools::internal::DsoLoader::GetLibcudaDsoHandle(void) ()\n\nfrom /Users/lw17567/anaconda2/envs/tensorflow2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#3 0x0000000104a0d0d2 in std::__1::__function::__func, tensorflow::Status (void)>::operator()(void&&) ()\n\nfrom /Users/lw17567/anaconda2/envs/tensorflow2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#4 0x0000000104a0c86f in perftools::gputools::internal::CachedDsoLoader::FetchHandleResult(std::__1::function) ()\n\nfrom /Users/lw17567/anaconda2/envs/tensorflow2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#5 0x0000000104a0cdcf in perftools::gputools::internal::CachedDsoLoader::GetLibcudaDsoHandle() ()\n\nfrom /Users/lw17567/anaconda2/envs/tensorflow2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n---Type to continue, or q to quit---\n#6 0x0000000104a8ebe5 in perftools::gputools::initialize_cuda_gpu_executor()\n\n()\nfrom /Users/lw17567/anaconda2/envs/tensorflow2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n#7 0x00007fff5fc12d4b in ?? ()\n#8 0x000000155fbfc830 in ?? ()\n#9 0x0000000000000001 in ?? ()\n#10 0x00000001034c02e8 in ?? ()\n#11 0x00000001034c0740 in ?? ()\n#12 0x00000001034c0420 in ?? ()\n#13 0x00007fff5fc38660 in ?? ()\n#14 0x00000000000001b8 in ?? ()\n#15 0x00000001004613d0 in ?? ()\n#16 0x00007fff5fbfc8a0 in ?? ()\n#17 0x0000000000000713 in ?? ()\n#18 0x00007fff5fc38598 in ?? ()\n#19 0x00007fff5fc41a38 in ?? ()\n#20 0x00007fff5fbfc830 in ?? ()\n#21 0x00007fff5fc12ed8 in ?? ()\n#22 0x00000001004613d0 in ?? ()\n#23 0x0000b481cbaa22ee in ?? ()\n#24 0x00007fff5fbfc890 in ?? ()\n#25 0x00007fff5fc0f8d1 in ?? ()\n\n---Type to continue, or q to quit---\n#26 0x0000000000000000 in ?? ()\n\nIf necessary, please see the full gdb output, and deviceQuery (CUDA sample) output in my related comments in #2773 .  \n", "comments": ["@martinwicke Could you take a look at this please?\n", "Having the same problem, It appears that it fails when loading libcuda.dylib. Unfortunately, since  https://github.com/tensorflow/tensorflow/pull/2878 it's now looking for libcuda.1.dylib instead.\n\nCreating a symlink or changing the name of libcuda.dylib to libcuda.1.dylib in /usr/local/cuda/lib seems to do the job.\n", "@Menerve , THANK YOU!  It worked, I would have never found that.\n", "@Menerve three hours of building and pip installing and uninstalling later, I finally find your helpful comment. THANK YOU.\n", "@ASRagab @lw394 Glad to help! But I'm not sure why this issue is closed. Something needs to be done here.\n", "@Menerve we've been told that this is a bug in the naming / packaging for OS X cuda installs -- I think we're waiting for the real fix by them, which is to name the library with a .1, and maybe add the symlink.\n", "reopened per @Menerve's suggestion, I'll let google close it.\n", ":) I wish I could mark this as \"still an issue, but not a TensorFlow-specific issue\" :(\n", "You could add the symlink step to you OSX step by step guide?\n", "@jrimestad Might be too late for your question, but for anyone who doesn't know how to add the symlink:\r\n```bash\r\nsudo ln -sf /usr/local/cuda/lib/libcuda.dylib /usr/local/cuda/lib/libcuda.1.dylib\r\n```\r\nrun this in terminal will do the trick. ", "thank you so much!", "Thank you @Menerve !! Your comment saved me!", "Many thanks @Menerve and @zhubofei \r\n**Summary:**\r\nAfter installing tensorflow-gpu and trying to import it in python I also got the Segmentation faults. First had to add the /Developer/NVIDIA/CUDA-8.0/lib as well as /Developer/NVIDIA/cudnn-8.0/lib to DYLD_LIBRARY_PATH in the bash_profile, and then needed to rename libcuda, with \"sudo ln -sf /usr/local/cuda/lib/libcuda.dylib /usr/local/cuda/lib/libcuda.1.dylib\"\r\n\r\nAs a newbie in library dependency issues I would like to ask you all: how do naming issues like with the libcuda.1 happen?", "still got problem after done the DYLD_LIBRARY_PATH  and sudo.  still segmentation fault:11.  any further advice.", "In my case i was getting seg fault 11 when importing tensorflow to my virtual env python.\r\nThen I suspected I was doing some rookie mistake in my .bash_profile.\r\nI found [this link](http://mxnet.io/get_started/osx_setup.html)\r\nThe tell you to add this to your bash:\r\n`export CUDA_HOME=\"/usr/local/cuda\"`\r\n`export DYLD_LIBRARY_PATH=\"$CUDA_HOME/lib:$DYLD_LIBRARY_PATH\"`\r\n `export PATH=\"$CUDA_HOME/bin:$PATH\"`\r\nI suspect it is crucial to define a CUDA_HOME variable on your bash.\r\nNow my tensorflow is up and running on python.", "I needed TensorFlow with GPU support version 0.12.0 specifically (`pip install tensorflow-gpu==0.12.0` and ran into similar issues on two different macs: a macbook running 10.11 and an iMac running 10.12.\r\n\r\nOn 10.11 I could see tensorflow complaining about missing .dylibs, but it didn't crash I manually symlinked libraries from `/usr/local/cuda/lib` to `/usr/local/lib` until it was happy:\r\n```python\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.dylib locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.dylib locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.dylib locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.1.dylib locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.dylib locally\r\n```\r\n\r\nOn 10.12 I just got `segfault 11` after running `import tensorflow` in an interpreter.\r\nI got around it in a similar fashion, but perhaps a bit messier: symlinking ALL the libraries :))\r\n`for l in /usr/local/cuda/lib;do sudo ln -s $l /usr/local/lib/$(basename $l);done`\r\n\r\nOn both configurations I've used the latest CUDA Driver (8.0.61) and SDK (8.0) with CuDNN 5.1 in this case (which is what the tensorflow-gpu 0.12.0 was compiled against)."]}, {"number": 3262, "title": "IOS Makefile Problem", "body": "I followed the steps given in https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile but ran into problems when running the command  make -f tensorflow/contrib/makefile/Makefile  TARGET=IOS  IOS_ARCH=ARM64. \n### Environment info\n\nOperating System:\nMacBook Pro (Retina, 13-inch, Mid 2014), 10.11.5 El Capitan\nXcode 7.3.1 \n\n[make_file_errors.txt](https://github.com/tensorflow/tensorflow/files/356308/make_file_errors.txt)\n### Steps to reproduce\n1.  make -f tensorflow/contrib/makefile/Makefile  TARGET=IOS  IOS_ARCH=ARM64 (in the root tensorflow directory)\n### What have you tried?\n1. Recloning and following steps in https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile  again  \n2. Trying to resolve using Stackoverflow  \n### Logs or other output that would be helpful\n\nAttaced below \nThank You!\n", "comments": ["The error message:\n[make_file_errors.txt](https://github.com/tensorflow/tensorflow/files/356312/make_file_errors.txt)\n", "@petewarden Could you take a look at this please?\n", "Can you try this again using the new tensorflow/contrib/makefile/build_all_ios.sh script? I believe this should now fix this issue.\n", "Closing the issue, as there seems to be a resolution now.\r\nPlease reopen if you still run into it."]}, {"number": 3261, "title": "Environment variables PATH and LD_LIBRARY_PATH not being passed to Protobuf compiler", "body": "With protobuf neither the PATH nor LD_LIBRARY_PATH are being passed and building tensorflow fails with:\n\n```\n(cd /home/gbkedar/.cache/bazel/_bazel_gbkedar/2cce0d25c048758b29b453d7b4e29b85/execroot/tensorflow && \\\n  exec env - \\\n  bazel-out/host/bin/external/protobuf/protoc '--cpp_out=bazel-out/local_linux-opt/genfiles/' -I. -Iexternal/protobuf/src -Ibazel-out/local_linux-opt/genfiles/external/protobuf/src tensorflow/core/example/example.proto tensorflow/core/example/example_parser_configuration.proto tensorflow/core/example/feature.proto tensorflow/core/framework/allocation_description.proto tensorflow/core/framework/attr_value.proto tensorflow/core/framework/cost_graph.proto tensorflow/core/framework/device_attributes.proto tensorflow/core/framework/function.proto tensorflow/core/framework/graph.proto tensorflow/core/framework/kernel_def.proto tensorflow/core/framework/log_memory.proto tensorflow/core/framework/op_def.proto tensorflow/core/framework/step_stats.proto tensorflow/core/framework/summary.proto tensorflow/core/framework/tensor.proto tensorflow/core/framework/tensor_description.proto tensorflow/core/framework/tensor_shape.proto tensorflow/core/framework/tensor_slice.proto tensorflow/core/framework/types.proto tensorflow/core/framework/variable.proto tensorflow/core/framework/versions.proto tensorflow/core/lib/core/error_codes.proto tensorflow/core/protobuf/config.proto tensorflow/core/protobuf/meta_graph.proto tensorflow/core/protobuf/named_tensor.proto tensorflow/core/protobuf/queue_runner.proto tensorflow/core/protobuf/saver.proto tensorflow/core/protobuf/tensorflow_server.proto tensorflow/core/util/event.proto tensorflow/core/util/memmapped_file_system.proto tensorflow/core/util/saved_tensor_slice.proto tensorflow/core/util/test_log.proto)\nERROR: /project/roysam/compiledLibs/tensorflow/tensorflow/core/BUILD:91:1: null failed: protoc failed: error executing command\n  (cd /home/gbkedar/.cache/bazel/_bazel_gbkedar/2cce0d25c048758b29b453d7b4e29b85/execroot/tensorflow && \\\n  exec env - \\\n  bazel-out/host/bin/external/protobuf/protoc '--cpp_out=bazel-out/host/genfiles/' -I. -Iexternal/protobuf/src -Ibazel-out/host/genfiles/external/protobuf/src tensorflow/core/example/example.proto tensorflow/core/example/example_parser_configuration.proto tensorflow/core/example/feature.proto tensorflow/core/framework/allocation_description.proto tensorflow/core/framework/attr_value.proto tensorflow/core/framework/cost_graph.proto tensorflow/core/framework/device_attributes.proto tensorflow/core/framework/function.proto tensorflow/core/framework/graph.proto tensorflow/core/framework/kernel_def.proto tensorflow/core/framework/log_memory.proto tensorflow/core/framework/op_def.proto tensorflow/core/framework/step_stats.proto tensorflow/core/framework/summary.proto tensorflow/core/framework/tensor.proto tensorflow/core/framework/tensor_description.proto tensorflow/core/framework/tensor_shape.proto tensorflow/core/framework/tensor_slice.proto tensorflow/core/framework/types.proto tensorflow/core/framework/variable.proto tensorflow/core/framework/versions.proto tensorflow/core/lib/core/error_codes.proto tensorflow/core/protobuf/config.proto tensorflow/core/protobuf/meta_graph.proto tensorflow/core/protobuf/named_tensor.proto tensorflow/core/protobuf/queue_runner.proto tensorflow/core/protobuf/saver.proto tensorflow/core/protobuf/tensorflow_server.proto tensorflow/core/util/event.proto tensorflow/core/util/memmapped_file_system.proto tensorflow/core/util/saved_tensor_slice.proto tensorflow/core/util/test_log.proto): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\nbazel-out/host/bin/external/protobuf/protoc: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by bazel-out/host/bin/external/protobuf/protoc)\nbazel-out/host/bin/external/protobuf/protoc: /usr/lib64/libstdc++.so.6: version `CXXABI_1.3.8' not found (required by bazel-out/host/bin/external/protobuf/protoc)\nbazel-out/host/bin/external/protobuf/protoc: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.18' not found (required by bazel-out/host/bin/external/protobuf/protoc)\nTarget //tensorflow/cc:tutorials_example_trainer failed to build\n```\n\nFurther, checking the dependencies of protoc shows that they are set correctly when it is compiled\n\n```\nldd bazel-out/host/bin/external/protobuf/protoc\n        linux-vdso.so.1 =>  (0x00007ffffadff000)\n        libpthread.so.0 => /lib64/libpthread.so.0 (0x00002b5195f33000)\n        libstdc++.so.6 => /share/apps/gcc-4.9.2/lib64/libstdc++.so.6 (0x00002b5196150000)\n        libgcc_s.so.1 => /share/apps/gcc-4.9.2/lib64/libgcc_s.so.1 (0x00002b5196463000)\n        libc.so.6 => /lib64/libc.so.6 (0x00002b5196679000)\n        /lib64/ld-linux-x86-64.so.2 (0x0000003e37c00000)\n        libm.so.6 => /lib64/libm.so.6 (0x00002b5196a0d000)\n```\n\nI have checked out and built the master of bazel. Previous to https://github.com/bazelbuild/bazel/commit/c9bc051f32b0d153110863e983749420200d000c other parts were being passed the PATH and not LD_LIBRARY_PATH. For example:\n\n```\n//third_party/gpus/cuda:cuda_check [action 'Executing genrule //third_party/gpus/cuda:cuda_check']\n(cd /home/gbkedar/.cache/bazel/_bazel_gbkedar/2cce0d25c048758b29b453d7b4e29b85/execroot/tensorflow && \\\n  exec env - \\\n    PATH= ...... \\\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; OUTPUTDIR=`readlink -f bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda/../../..`; cd `dirname third_party/gpus/cuda/cuda_config.sh`; OUTPUTDIR=$OUTPUTDIR ./cuda_config.sh --check;')\n```\n\nThe commit adds LD_LIBRARY_PATH:\n\n```\n//third_party/gpus/cuda:cuda_check [action 'Executing genrule //third_party/gpus/cuda:cuda_check']\n(cd /home/gbkedar/.cache/bazel/_bazel_gbkedar/2cce0d25c048758b29b453d7b4e29b85/execroot/tensorflow && \\\n  exec env - \\\n    LD_LIBRARY_PATH= ...... \\\n    PATH= ...... \\\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; OUTPUTDIR=`readlink -f bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda/../../..`; cd `dirname third_party/gpus/cuda/cuda_config.sh`; OUTPUTDIR=$OUTPUTDIR ./cuda_config.sh --check;')\n```\n\nwhich solves some issues when gcc or python are not in the default path but not this one.\n", "comments": ["It looks like the macro tf_proto_library which is causing the error  is defined [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/default/build_config.bzl).\n\nEdit:\nThe compiler is called from bazel-tensorflow/external/protobuf/protobuf.bzl \nThere is a ctx.action call where we need to add env=ctx.configuration.default_shell_env to add the paths. I haven't worked out where the file is created/downloaded.\n", "@martinwicke Could you take a look at this please?\n", "Sorry, the close was a mistake\n", "@damienmg is this something we can fix on our side or is that a problem in bazel?\n", "I have sovled this problem by add `linker_flag: \"-Wl,-rpath,you-local-gcc-lib-path\"` to the `toolchain`section with `host_system_name: \"local\"` in the `third_party/gpus/crosstool/CROSSTOOL` file .\n\nThis problem is caused by `exec env -` ,which clear LD_LIBRARY_PATH, resulted protoc can't find you gcc lib\n", "@martinwicke @philwo recently added the LD_LIBRARY_PATH to the list of environment passed when using the default shell env (which the action might not, this is an option in genrule / skylark action). This should be fixed with Bazel at HEAD.\n\nAlso we have a more general principle approach to that, see http://www.bazel.io/docs/designs/2016/06/21/environment.html\n\nSo this is a problem in Bazel, and we fixed it but there might be some fix to do when invoking protoc\n", "Thanks @damienmg. I'll close this issue, and we should revisit it when the fix in bazel hits a release. \n", "Still not working for me.  I use bazel-0.4.0 and tensorflow-0.11.0.\n\nI compiled bazel from the source, with CROSSTOOL modified so as to hard-code the library path\n\n  linker_flag: \"-Wl,-rpath,/home/sr1/greg.m/lib/gcc-4.9.4_built/lib64\"\n\nand this setup does have an effect on bazel itself, even when I clear env variables\n\nenv - ldd ~/bin/bazel\n        linux-vdso.so.1 =>  (0x00007ffe8999e000)\n        librt.so.1 => /lib64/librt.so.1 (0x000000347ee00000)\n        libdl.so.2 => /lib64/libdl.so.2 (0x000000347e600000)\n        libpthread.so.0 => /lib64/libpthread.so.0 (0x000000347e200000)\n        **libstdc++.so.6** => /home/sr1/greg.m/lib/gcc-4.9.4_built/lib64/libstdc++.so.6 (0x00002ae1100c1000)\n        libm.so.6 => /lib64/libm.so.6 (0x000000347ea00000)\n        libgcc_s.so.1 => /home/sr1/greg.m/lib/gcc-4.9.4_built/lib64/libgcc_s.so.1 (0x00002ae1103d3000)\n        libc.so.6 => /lib64/libc.so.6 (0x000000347de00000)\n        /lib64/ld-linux-x86-64.so.2 (0x000000347d600000)\n\nHowever, when I try to build tensorflow with that bazel binary, protoc complains about missing libraries\n\nbazel build -c opt --config=cuda --verbose_failures //tensorflow/tools/pip_package:build_pip_package\n...\nERROR: /home/sr1/greg.m/lib/tensorflow-0.11.0/tensorflow/python/BUILD:1611:1: null failed: protoc failed: error executing command \n  (cd /scratch/greg.m/.cache/bazel/_bazel_greg.m/a9520ec1e3d4c7a317ca28043c7f63b1/execroot/tensorflow-0.11.0 && \\\n  exec env - \\\n  bazel-out/host/bin/external/protobuf/protoc '--python_out=bazel-out/local_linux-py3-opt/genfiles/' -I. -Iexternal/protobuf/python -Ibazel-out/local_linux-py3-opt/genfiles/external/protobuf/python tensorflow/python/training/checkpoint_state.proto): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\n\nAnd I verified that the protoc indeed is missing the path to libstdc++.so.6 that we expect to see because of the linker_flag added to CROSSTOOL \n\nenv - ldd bazel-out/host/bin/external/protobuf/protoc\nbazel-out/host/bin/external/protobuf/protoc: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by bazel-out/host/bin/external/protobuf/protoc)\nbazel-out/host/bin/external/protobuf/protoc: /usr/lib64/libstdc++.so.6: version`CXXABI_1.3.8' not found (required by bazel-out/host/bin/external/protobuf/protoc)\nbazel-out/host/bin/external/protobuf/protoc: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.18' not found (required by bazel-out/host/bin/external/protobuf/protoc)\n        linux-vdso.so.1 =>  (0x00007fffa0aa2000)\n        libpthread.so.0 => /lib64/libpthread.so.0 (0x00002ab8e7ec3000)\n        **libstdc++.so.6** => /usr/lib64/libstdc++.so.6 (0x00002ab8e80e0000)\n        libgcc_s.so.1 => /lib64/libgcc_s.so.1 (0x00002ab8e83e7000)\n        libc.so.6 => /lib64/libc.so.6 (0x00002ab8e85fd000)\n        /lib64/ld-linux-x86-64.so.2 (0x000000347d600000)\n        libm.so.6 => /lib64/libm.so.6 (0x00002ab8e8991000)\n\nWithout clearing env variables, protoc has the library\n\nldd bazel-out/host/bin/external/protobuf/protoc\n        linux-vdso.so.1 =>  (0x00007ffebe1f2000)\n        libpthread.so.0 => /lib64/libpthread.so.0 (0x00002b11fde14000)\n        **libstdc++.so.6** => /home/sr1/greg.m/lib/gcc-4.9.4_built/lib64/libstdc++.so.6 (0x00002b11fe032000)\n        libgcc_s.so.1 => /home/sr1/greg.m/lib/gcc-4.9.4_built/lib64/libgcc_s.so.1 (0x00002b11fe344000)\n        libc.so.6 => /lib64/libc.so.6 (0x00002b11fe55a000)\n        /lib64/ld-linux-x86-64.so.2 (0x000000347d600000)\n        libm.so.6 => /lib64/libm.so.6 (0x00002b11fe8ef000)\n", "I was able to overcome the `'GLIBCXX_3.4.20' not found` issue in a manner similar to what @xsj0jsx [suggested](https://github.com/tensorflow/tensorflow/issues/3261#issuecomment-234147379). You would probably need [these two lines](https://github.com/bazelbuild/bazel/issues/649#issuecomment-166710509), not one. However, you would probably have to [fix two more things](https://github.com/tensorflow/tensorflow/issues/110#issuecomment-265431453).", "> It looks like the macro tf_proto_library which is causing the error is defined here.\r\n\r\n> Edit:\r\n> The compiler is called from bazel-tensorflow/external/protobuf/protobuf.bzl\r\n> There is a ctx.action call where we need to add env=ctx.configuration.default_shell_env to add the > paths. I haven't worked out where the file is created/downloaded.\r\n\r\n@gbkedar 's comment is correct on this issue. Please read the PR I referenced above. In the meanwhile, there is an easy fix to this problem. Please read my protocol on building TensorFlow with a customized tool chain.\r\n\r\nhttp://biophysics.med.jhmi.edu/~yliu120/tensorflow.html\r\n\r\n(Search for configuration section) You can manually add the patch (same as my PR) after running ./configure"]}, {"number": 3260, "title": "Deep Dream Tutorial with UnsupportedOperation: fileno", "body": "When running Deep Dream Tutorial on Jupyter Notebook, for the section of Naive feature visualization, it shows following\n\n`UnsupportedOperation: fileno`\n\nbacktracked up from \n\n`PIL.Image.fromarray(a).save(f, fmt)`\n\nupto  `PIL/ImageFile.pyc in _save(im, fp, tile)`\n\n```\n    475     try:\n--> 476         fh = fp.fileno()\n    477         fp.flush()\n    478     except AttributeError:\n```\n\nThe TensorFlow is installed under Anaconda and created an environment with internal installation of PIL package. \n\n```\nsource activate tensorflow\nconda install PIL\n```\n", "comments": ["Please provide operating system, GPU version if used, tensorflow version, etc... \n", "Ubuntu 16.04 LTS\nCPU only\nTensorFlow 0.9\n", "That's weird, is the jupyter notebook running on something that doesn't allow for file i/o? \n", "Running Jupyter with a Python3 kernel resolved this for me. Noting that fileno() for [Python3](https://docs.python.org/3/library/io.html#io.IOBase.fileno) raises a different exception than [Python2](https://docs.python.org/2/library/io.html#io.IOBase.fileno), there may be something fishy in the stream.\n", "Ok. I have no idea what this is, I'm glad there's a workaround. I'll close this issue, this doesn't feel like something we can fix in TensorFlow.\n"]}, {"number": 3258, "title": "fix mispellings and add minor corrections", "body": "The main change of the PR is the change of interface from a single Reader(, isText) to a more (IMHO) go idiomatic `ReadFromBuffer` and `ReadFromString`\n", "comments": ["Can one of the admins verify this patch?\n", "Awesome \ud83d\udc4d\n", "(ping when ready to review)\n", "@vrv I think this PR is ready to be reviewed.\n\nI tried to add some other things like the go bazel rules to build the package uzing bazel but I will wait for this PR to be merged and the branch to be rebased. \n", "@tensorflow-jenkins test this please\n\nI have no idea if we even have tests for this or what happens, but trying it anyway.\n", "@vrv there are few tests, but I don't think they are linked to the CI system.\n", "This didn't work, I guess.\n", "@martinwicke can you guys rebase origin/go on top of origin/master ? a bunch of PR are trying to catch up the go branch to the master one. \n", "I rebased the go branch on top of current master.\n", "\ud83c\udf89  Thanks ! \ud83c\udf89 \n", "We found a Contributor License Agreement for you (the sender of this pull request) and all commit authors, but as best as we can tell these commits were authored by someone else.  If that's the case,  please add them to this pull request and have them confirm that they're okay with these commits being contributed to Google.  If we're mistaken and you did author these commits, just reply here to confirm.\n\n<!-- need_author_consent -->\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "PR rebased too.  \n", "@vrv you've looked at this in the past. should we merge it?\n", "I dunno, there are no tests triggered for this branch, so merging might break the branch.  @Mistobaan can fix it I guess if there are problems :)\n", "\ud83d\udc4d \n"]}, {"number": 3257, "title": "Fix word2vec excepction when words contain chinese.", "body": "When word2vec deal with Chinese language, it will break out below exception.\n\n```\nTraceback (most recent call last):\n  File \"word2vec_tf.py\", line 58, in <module>\n    main()\n  File \"word2vec_tf.py\", line 47, in main\n    model = Word2Vec(options, session)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/models/embedding/word2vec.py\", line 166, in __init__\n    self.save_vocab()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/models/embedding/word2vec.py\", line 382, in save_vocab\n    opts.vocab_counts[i]))\nUnicodeEncodeError: 'ascii' codec can't encode character u'\\u90fd' in position 0: ordinal not in range(128)\n```\n\nI fix this exception by adding `encode('utf-8')` , and then it successful run word2vec model.\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "@tensorflow-jenkins test this please\n"]}]