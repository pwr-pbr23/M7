[{"number": 8999, "title": "Fix KeyError in quantize_graph round, quantize opt", "body": "The round/quantize paths check for a boolean value in a dictionary before it is set, leading to a KeyError. This change allows the input graph to be quantized using the 'round' and 'quantize' options. The quantized graph can't actually be used (for the 'round' option, at least) due to a lack of a `RoundToSteps` Op, but I figured I'd submit this anyway.\r\n\r\nPinging @petewarden for thoughts on whether this is worth incorporating now.", "comments": ["Can one of the admins verify this patch?", "Can we have a test for this perhaps?", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "@drpngx - agreed on figuring out a way to properly test these. Originally this was just to fix some regressions, but it's better to follow through and try to get the entire tool up-to-spec. I made a few tweaks to the existing `quantize_graph_test.py` file to help get that ball rolling. Notes on the current changes:\r\n\r\n* Changed `self.already_visited.get(...)` to `if current_node.name in self.already_visited` to [keep existing pattern consistent](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/quantization/quantize_graph.py#L510-L511)\r\n* As [@petewarden notes](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/quantization/quantize_graph_test.py#L165-L173)- we can't actually use the `'rounded'` mode right now as there is no `RoundToSteps` Op. We can still run the `GraphRewriter` to check that the recursion no longer fails.\r\n* I created a test for the `'quantize'` mode (and set it to use the `QuantizeV2` Op), but I'm getting some failures for several of the tests. I've attached the failure log below.\r\n\r\n[Test failure log](https://github.com/tensorflow/tensorflow/files/914756/test.txt)\r\n\r\nI'll try to spend more time on this over the next week or two.\r\n\r\n(Additionally, I had a rebase hiccup, which caused the CLA issue; should be fixed now).", "@samjabrahams that sounds like a good approach to me. Looking forward to updates!", "@samjabrahams any updates?  Thanks!", "Hi @vrv- I'm going to spend some time on this today- hopefully have the PR updated relatively shortly!", "Making a bit of progress figuring out what's going wrong (at least for this leg of it). It looks like somewhere between `quantize_graph_test.py` and `quantize_graph.py`, a `GraphDef` containing two nodes with the same name is getting passed along to `import_graph_def()`. This causes an error when `import_graph_def()` attempts to find the inputs for each operation, as the inputs being assigned to the \"Dequantize\" op are those from another operation (in this case, the other operation doesn't have any inputs).\r\n\r\n[Relevant section of `import_graph_def()`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/importer.py#L305-L313)\r\n\r\nI'll keep poking to see where the hiccup is. In the meantime, would it be a good idea to add a check in `import_graph_def()` to make sure there aren't duplicate operation names in the `GraphDef`?", "CLAs look good, thanks!\n\n<!-- ok -->", "I figured out that some nodes were getting added twice: [once here](https://github.com/tensorflow/tensorflow/blob/d57c31661e8f76d6c3d91f3969d4d4219c9ea97c/tensorflow/tools/quantization/quantize_graph.py#L503-L505), and again [here](https://github.com/tensorflow/tensorflow/blob/d57c31661e8f76d6c3d91f3969d4d4219c9ea97c/tensorflow/tools/quantization/quantize_graph.py#L497-L500). If a node is an input to `Conv2D`, `BiasAdd`, or `MatMul`, both the original and a quantized version of that input is added to the graph, both of which have the same name (leading to the error mentioned above).\r\n\r\nFor now, I've removed the loop that adds quantized inputs, and the \"Dequantize Operation expects three inputs\" errors have gone away. However, I'm not sure if this is the correct fix: is the `quantize_graph` tool supposed to quantize the inputs to `Conv2D`, `BiasAdd`, and `MatMul`? If so, we'll need to rework the algorithm to not double-add operations.\r\n\r\nAdditionally, we're getting some numeric failures from converting to/from quantized land. My guess is that these are due to forcing the quantized range to include the number 0, but I figured I would include this just in case something looks screwy.\r\n\r\n```\r\n2.0000 4.0000 6.0000 8.0000 10.0000 12.0000 8.0000 10.0000 12.0000 14.0000 16.0000 18.0000 \r\n3.7647 5.5843 7.3412 9.0980 10.9176 12.6745 9.0980 10.9176 12.6745 14.4314 16.2510 18.0078 \r\nTensors have 5 different values (41.6666666667%), with mean difference -0.896732529004 and mean absolute difference 0.896732529004\r\n\r\n2.0078 4.0157 6.0235 7.9686 9.9765 7.0275 8.9725 10.9804 12.9882 14.9961 \r\n3.7020 5.4588 7.2157 8.9098 10.6667 8.0314 9.7882 11.5451 13.2392 14.9961 \r\nTensors have 4 different values (40.0%), with mean difference -0.85960791111 and mean absolute difference 0.85960791111\r\n\r\n2.0000 4.0000 6.0000 8.0000 10.0000 7.0000 9.0000 11.0000 13.0000 15.0000 \r\n3.7216 5.4549 7.1882 8.9216 10.6549 8.0549 9.7882 11.5216 13.2549 14.9882 \r\nTensors have 4 different values (40.0%), with mean difference -0.854902219772 and mean absolute difference 0.857255125046\r\n\r\n105.0000 150.0000 183.0000 95.0000 235.0000 312.0000 357.0000 178.0000 187.0000 234.0000 261.0000 121.0000 \r\n171.5843 204.4628 229.1216 164.3922 267.1373 323.6471 356.5255 225.0118 232.2039 266.1098 285.6314 182.8863 \r\nTensors have 11 different values (91.6666666667%), with mean difference -40.8928273519 and mean absolute difference 40.9719085693\r\n\r\n1.0000 4.0000 9.0000 16.0000 25.0000 36.0000 49.0000 64.0000 81.0000 100.0000 121.0000 144.0000 \r\n2.2431 5.0471 10.0941 16.8235 25.7961 37.0118 49.9098 64.4902 81.3137 100.3804 121.1294 144.1216 \r\nTensors have 4 different values (33.3333333333%), with mean difference -0.696733077367 and mean absolute difference 0.696733077367\r\n\r\n74.0000 80.0000 86.0000 92.0000 173.0000 188.0000 203.0000 218.0000 \r\n123.1059 127.0588 131.0118 134.9647 188.0471 198.2118 207.8118 217.9765 \r\nTensors have 7 different values (87.5%), with mean difference -26.7735290527 and mean absolute difference 26.7794113159\r\n\r\n348.0000 252.0000 274.0000 175.0000 \r\n348.0353 300.5451 311.4000 261.8745 \r\nTensors have 3 different values (75.0%), with mean difference -43.2137298584 and mean absolute difference 43.2137298584\r\n```\r\n\r\n", "@tensorflow-jenkins test this please", "Noting the failures I get on my machine when running [`bazel test tensorflow/tools/quantization:quantize_graph_test`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/quantization/quantize_graph_test.py):\r\n\r\n* test_bias_add\r\n* test_bias_add_w_fake_quant_w_min_max_vars\r\n* test_bias_add_w_fallback_min_max_vars\r\n* test_conv\r\n* test_identity\r\n* test_mat_mul_small\r\n* test_odd_padding_problem\r\n\r\nThese are the ones that complain about numeric inaccuracy. I don't think `tensorflow/tools` is included in the CI tests, so the errors may not pop up here.", "It looks like it is running in our CI: https://ci.tensorflow.org/job/tensorflow-pull-requests-cpu-python3/4296/consoleFull\r\n\r\nI can see the same types of accuracy errors, so good to confirm.  I'll leave it up to @petewarden to figure out what next steps are!", "Sorry for commenting so late (the original mention came in while I was on vacation, and I must have missed it when I was catching up). I've been trying to move over to the newer version of the quantize_nodes rewriting rule in the Graph Transform Tool, since this python script became hard to maintain. As a sanity check, are you able to use this alternative approach?\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms/#eight-bit-calculations", "@petewarden - apologies, I haven't forgotten about this. Last week was busy- I'll try out the new script and let you know the results this week.", "Can one of the admins verify this patch?", "@samjabrahams any updates?", "The Graph Transform Tool works well! Tested the features relevant to this PR, and it works smoothly. Is the plan to deprecate `tools/quantization` (at least the current code in there) in favor of GTT?", "@petewarden can you answer @samjabrahams's questions regarding future plans? \r\n@samjabrahams does this mean we can close this PR or do you intend to rework it?\r\n", "@rmlarsen if the tool is going to be deprecated in favor of the GTT, I'm fine closing this out. Otherwise, I'm still not sure whether this fix is the right one ([questions/concerns here](https://github.com/tensorflow/tensorflow/pull/8999#issuecomment-298783900)).", "I believe that is the case. Sorry for the large amounts of semi-deprecated code all around... \r\nI will close this issue then.\r\n\r\n@petewarden will you remove the dead code? "]}, {"number": 8998, "title": "Merge rc1 back into master.", "body": "See title.", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->"]}, {"number": 8997, "title": "separate license and code annotation", "body": "separate license and code annotation", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please\r\n", "Actually, the general approach is not to have this separation. Closing PR."]}, {"number": 8996, "title": "clean separation", "body": "better differentiate license and annotation.", "comments": ["Can one of the admins verify this patch?", "Thanks for the change but in general, we don't have any separation between code and copyright. Closing PR."]}, {"number": 8995, "title": "delete fist null line", "body": "delete fist null line", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please"]}, {"number": 8994, "title": "Reload Button in Tensorboard 1.1rc1 Resets Chart Scales", "body": "In tensorboard 1.1rc1, hitting the \"reload button\",  ![image](https://cloud.githubusercontent.com/assets/51059/24721828/7f66e63a-1a0f-11e7-9942-15d4609e0e46.png), causes the scaling on the charts to reset. That was not the case in 1.0.1.\r\n\r\nFor example if I zoom in here:\r\n![image](https://cloud.githubusercontent.com/assets/51059/24721857/9772cd7a-1a0f-11e7-8e4a-3f6535df7edb.png)\r\nto:\r\n![image](https://cloud.githubusercontent.com/assets/51059/24721867/9cedb1a2-1a0f-11e7-9a0d-24d57648d242.png)\r\nthis zoom is lost.", "comments": ["@dandelionmane @jart : Any ideas?", "The same scale reset happens when checking and unchecking runs.", "Acknowledged", "Any chance this will fixed before final 1.1 release?", "@dandelionmane It looks like TF 1.1 is shipping. Did this get fixed?", "This appears to still happen in TF 1.1.", "Any update on this? This isn't a performance bug \u2013 it's a usability issue.", "@dandelionmane any chance this is fixed in 1.2.0?", "This is still happening in 1.2.0-rc0. Is this changed behavior intentional?", "Looks like Chi migrated this to our new repository at https://github.com/tensorflow/tensorboard/issues/36, so I'm closing it. Please feel free to continue discussion there."]}, {"number": 8993, "title": "\"Split on underscores\" is Missing in Tensorboard 1.1rc1", "body": "Old Tensorboard:\r\n![image](https://cloud.githubusercontent.com/assets/51059/24721612/dff607b6-1a0e-11e7-9023-314a8e50661c.png)\r\n\r\nNew Tensorboard:\r\n![image](https://cloud.githubusercontent.com/assets/51059/24721635/ed11cf0c-1a0e-11e7-969a-ad945d587eac.png)\r\n\r\nNote that \"Split on underscores\" appears missing. I see no issues, etc related to the removal of this feature.", "comments": ["@dandelionmane @jart: Any comments on this?", "I removed it because I wanted to clean up the UI, and because there's nothing special about using underscores rather than slashes. The fix is it replace underscores with slashes in your summary names.", "What do you mean by slashes? Are they automatically split?", "So it looks like using `/`only works if the keys on the left does not already exist. \r\nFor example this works (both on 1.1rc1):\r\n![image](https://cloud.githubusercontent.com/assets/51059/24816749/f09f96e6-1ba7-11e7-9c1c-e36dd81bb0d0.png)\r\n\r\nbut this does not:\r\n![image](https://cloud.githubusercontent.com/assets/51059/24816764/01af4b98-1ba8-11e7-8dad-eca20d0ffb5d.png)\r\n"]}, {"number": 8991, "title": "use /* better than //", "body": "use /* better than //", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "pr of the month"]}, {"number": 8990, "title": "wipe out null string", "body": "wipe out null string. markdown will not influence ", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please"]}, {"number": 8989, "title": "Adding License headers to the cmake files.", "body": "See title.", "comments": []}, {"number": 8988, "title": "Branch 152232810", "body": "", "comments": ["@tensorflow-jenkins test this please\r\n", "@rohan100jain Thanks for dealing with all the merging after my formatting changes yesterday!"]}, {"number": 8987, "title": "Adding a hint to the XLA op metadata, set when the op is updating a variable", "body": "The hint can be used for ensuring that the buffer allocated to a variable remains at the same place.  For a static graph compiler, this prevents an extra copy at the end of the execution.\r\n\r\n", "comments": ["Can one of the admins verify this patch?", "ok - i've run all the XLA unit tests and there is something wrong - will look into that immediately"]}, {"number": 8986, "title": "Inception v1, v2 - ValueError: Can not squeeze dim[1], expected a dimension of 1, got 2 for 'InceptionV2/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes: [1,2,2,1000].", "body": "Hello,\r\n\r\nI'm trying to run a few different inception models with their checkpoints from the pretrained models table [here](https://github.com/tensorflow/models/tree/master/slim). I've managed to get v3, v4, and resnet v2 working. v1 and v2 however I'm getting the issue above. I'm using the latest tensorflow and pulled the latest off the repo. Below is the code I use to load the model.\r\n\r\n```\r\ncheckpoint_file = os.getcwd() + '\\inception_v2.ckpt'\r\n#Load the model\r\nsess = tf.Session()\r\narg_scope = inception_v2_arg_scope()\r\n\r\nwith slim.arg_scope(arg_scope):\r\n      logits, end_points = inception_v2(scaled_input_tensor, is_training=False)\r\nsaver = tf.train.Saver()\r\nsaver.restore(sess, checkpoint_file)\r\n```", "comments": ["@Exuro889 : Please include all information asked for in the new issue template. Without that, it is hard to be able to help. For example, what do you mean by the \"latest version of TensorFlow\"? (Built from source? Or the latest release version?) What was the full code snippet you used (what is `inception_v2_arg_scope()` for example)?\r\n\r\nAnyway, I think I was able to reduce this to the following with TensorFlow 1.0.1:\r\n\r\n```sh\r\ngit clone https://github.com/tensorflow/models.git\r\ncd ./models/slim\r\n```\r\n\r\nThen in Python\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom nets import inception_v2\r\n\r\nscaled_input_tensor = tf.placeholder(tf.float32, shape=[1, 299, 299, 3])\r\nlogits, end_points = inception_v2.inception_v2(scaled_input_tensor, is_training=False)\r\n```\r\n\r\nyields the error:\r\n\r\n```\r\nValueError: Can not squeeze dim[1], expected a dimension of 1, got 2 for 'InceptionV2/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes: [1,2,2,1000].\r\n```\r\n\r\n@sguada @nathansilberman : Mind taking a look?", "for Inception V1 the default shape is [224,224] ", "for Inception V1 and V2 the default shape [None, 224, 224, 3] ", "@Exuro889 : Seems like your `scaled_input_tensor` was of the wrong size."]}, {"number": 8985, "title": "ValueError while restoring pre-trained SyntaxNet language parser", "body": "- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*: yes, but closely following [this](https://www.tensorflow.org/api_docs/python/tf/train/import_meta_graph) example.\r\n- *TensorFlow installed from (source or binary)?*: binary.  `tf.__version__` == `1.0.0`\r\n- *TensorFlow version*: 1.0.0 (installed with `pip install tensorflow-gpu`\r\n- *CUDA/cuDNN version*: cuda 8/ cudnn 5.1.10\r\n- *GPU Model and Memory*: GeForce GTX 1080 (8 GB), nvidia driver 367.57\r\n- *Exact command to reproduce*:\r\n\r\n### Describe the problem clearly\r\nI'm attempting to play with the ParseySaurus pre-trained ConLL17 models from [here](https://github.com/tensorflow/models/blob/master/syntaxnet/g3doc/conll2017/README.md).   Attempting to reconstitute them from a `*.meta` file results in an error.\r\n### Source Code / Logs\r\nprep: \r\n```\r\nwget https://drive.google.com/file/d/0BxpbZGYVZsEeSFdrUnBNMUp1YzQ/view?usp=sharing\r\ntar xzf conll17.tar.gz\r\n```\r\n\r\nipython transcript follows\r\n```python\r\nimport tensorflow as tf\r\n%cd conll17/English\r\nwith tf.Session() as sess:\r\n    saver = tf.train.import_meta_graph('segmenter/checkpoint.meta')\r\n    saver.restore(sess,'segmenter/checkpoint.data-00000-of-00001')\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)                  \r\n---------------------------------------------------------------------------                                                   \r\nValueError                                Traceback (most recent call last)           \r\n<ipython-input-15-325bf8959c4e> in <module>()                 \r\n      1 with tf.Session() as sess:                            \r\n----> 2     saver = tf.train.import_meta_graph('segmenter/checkpoint.meta')                                                   \r\n      3     saver.restore(sess,'segmenter/checkpoint.data-00000-of-00001')                                                    \r\n      4       \r\n\r\n/home/gvoysey/.local/share/virtualenvs/DeepSpeech/local/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs)    \r\n   1575                                       clear_devices=clear_devices,                    \r\n   1576                                       import_scope=import_scope,                      \r\n-> 1577                                       **kwargs)       \r\n   1578   if meta_graph_def.HasField(\"saver_def\"):            \r\n   1579     return Saver(saver_def=meta_graph_def.saver_def, name=import_scope)                                               \r\n\r\n/home/gvoysey/.local/share/virtualenvs/DeepSpeech/local/lib/python2.7/site-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name)                                                      \r\n    496     importer.import_graph_def(                        \r\n    497         input_graph_def, name=(import_scope or \"\"), input_map=input_map,                                                              \r\n--> 498         producer_op_list=producer_op_list)            \r\n    499       \r\n    500     # Restores all the other collections.             \r\n\r\n/home/gvoysey/.local/share/virtualenvs/DeepSpeech/local/lib/python2.7/site-packages/tensorflow/python/framework/importer.pyc in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list)                    \r\n    257       # Set any default attr values that aren't present.                                                              \r\n    258       if node.op not in op_dict:                      \r\n--> 259         raise ValueError('No op named %s in defined operations.' % node.op)                                           \r\n    260       op_def = op_dict[node.op]                       \r\n    261       for attr_def in op_def.attr:                    \r\n\r\nValueError: No op named GetSession in defined operations.        \r\n```\r\n", "comments": ["The syntaxnext models use a custom op ([`GetSession`](https://github.com/tensorflow/models/blob/master/syntaxnet/dragnn/core/ops/dragnn_ops.cc)) that is defined in the syntaxnet codebase and is not part of the core TensorFlow distribution.\r\n\r\nThus, in order to use it, you need to follow the [instructions](https://github.com/tensorflow/models/tree/master/syntaxnet) for using that particular implementation syntaxnet. This README linked to will also point to stackoverflow and other channels of getting support to use the model. Hope that helps.\r\n\r\nClosing this out since it doesn't appear to be a bug with TensorFlow."]}, {"number": 8984, "title": "[CMake Docs] links typo fix", "body": "", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please"]}, {"number": 8983, "title": "Tensorboard not showing embeddings", "body": "I am trying to create embeddings visualization from a pretrained network called FaceNet although nothing shows up when I open it in Tensorboard. Here is my source code\r\n```\r\nimport tensorflow as tf\r\nimport os\r\nfrom tensorflow.contrib.tensorboard.plugins import projector\r\n\r\nMODEL_DIR = \"20170216-091149\"\r\nmeta_file, ckpt_file = facenet.get_model_filenames(MODEL_DIR)\r\nwith tf.Graph().as_default():\r\n    with tf.Session().as_default() as sess: \r\n        # Importing the graph\r\n        model_dir_exp = os.path.expanduser(MODEL_DIR)\r\n        print(model_dir_exp)\r\n        saver = tf.train.import_meta_graph(os.path.join(model_dir_exp, meta_file))\r\n        \r\n        # Restoring and retrieving needed layers\r\n        saver.restore(tf.get_default_session(), os.path.join(model_dir_exp, ckpt_file))\r\n        images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\r\n        embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\r\n        phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\") \r\n        \r\n        # Create variables needed for Tensorboard\r\n        embedding = tf.Variable(tf.zeros([33, 128]), name = \"embedding\") \r\n        assignment = embedding.assign(embeddings)\r\n        \r\n        # Create writer class\r\n        writer = tf.summary.FileWriter(os.path.join(MODEL_DIR, \"model\"))\r\n        writer.add_graph(sess.graph)\r\n        \r\n        # Setup the embeddings\r\n        config = projector.ProjectorConfig()\r\n        embedding_config = config.embeddings.add()\r\n        embedding_config.tensor_name = embedding.name\r\n        embedding_config.metadata_path = os.path.join(os.getcwd(), MODEL_DIR, 'labels.tsv')\r\n        embedding_config.sprite.image_path = os.path.join(os.getcwd(), MODEL_DIR,'sprite.png')\r\n        embedding_config.sprite.single_image_dim.extend([160, 160])\r\n        projector.visualize_embeddings(writer, config)\r\n        \r\n        # Create the embeddings\r\n        sess.run(assignment, feed_dict = {images_placeholder : face_images, phase_train_placeholder : False})\r\n```\r\n\r\nI have read the FAQs and this is what I got when I ran `tensorboard --logdir 20170216-091149/ --debug`\r\n\r\n```\r\nINFO:tensorflow:TensorBoard is in debug mode.\r\nINFO:tensorflow:Starting TensorBoard in directory /Users/kevinlu/Documents/Facial-Recognition/facial_recognition\r\nINFO:tensorflow:TensorBoard path_to_run is: {'/Users/kevinlu/Documents/Facial-Recognition/facial_recognition/20170216-091149': None}\r\nINFO:tensorflow:Event Multiplexer initializing.\r\nINFO:tensorflow:Event Multiplexer done initializing\r\nINFO:tensorflow:TensorBoard reload process beginning\r\nINFO:tensorflow:Starting AddRunsFromDirectory: /Users/kevinlu/Documents/Facial-Recognition/facial_recognition/20170216-091149\r\nINFO:tensorflow:Adding events from directory /Users/kevinlu/Documents/Facial-Recognition/facial_recognition/20170216-091149/model\r\nINFO:tensorflow:Constructing EventAccumulator for /Users/kevinlu/Documents/Facial-Recognition/facial_recognition/20170216-091149/model\r\nINFO:tensorflow:Done with AddRunsFromDirectory: /Users/kevinlu/Documents/Facial-Recognition/facial_recognition/20170216-091149\r\nINFO:tensorflow:TensorBoard reload process: Reload the whole Multiplexer\r\nINFO:tensorflow:Beginning EventMultiplexer.Reload()\r\nDEBUG:tensorflow:Opening a record reader pointing at /Users/kevinlu/Documents/Facial-Recognition/facial_recognition/20170216-091149/model/\r\n```\r\n\r\nThe TensorBoard path_to_run seems correct as that is where I am storing my checkpoint files, the metadata file and sprite image.\r\n\r\nThen I ran`find 20170216-091149/ | grep tfevents` and I got \r\n\r\n```20170216-091149/model/events.out.tfevents.1491408129.Kevins-MacBook-Pro.local``` \r\n\r\n\r\nNote the `model` folder contains the `tfevents` file and the `projector_config.pbtxt` file\r\nSo my data also exists. The last thing I did as per the troubleshooting was: \r\n`tensorboard --inspect --logdir=20170216-091149/` and I got this as the output\r\n\r\n\r\n```\r\n======================================================================\r\nProcessing event files... (this can take a few minutes)\r\n======================================================================\r\n\r\nFound event files in:\r\n20170216-091149/model\r\n\r\nThese tags are in 20170216-091149/model:\r\naudio -\r\nhistograms -\r\nimages -\r\nscalars -\r\n======================================================================\r\n\r\nEvent statistics for 20170216-091149/model:\r\naudio -\r\ngraph\r\n   first_step           0\r\n   last_step            0\r\n   max_step             0\r\n   min_step             0\r\n   num_steps            1\r\n   outoforder_steps     []\r\nhistograms -\r\nimages -\r\nscalars -\r\nsessionlog:checkpoint -\r\nsessionlog:start -\r\nsessionlog:stop -\r\n======================================================================\r\n```\r\n\r\nThe code I used is exactly the same as the Hands On Tensorboard video code, and when I ran the debug commands as recommended by the FAQ the output of the MNIST tutorial is the same as above.", "comments": ["Please do try to provide all the details asked for in the new issue template and code that can reproduce the problem. I tried to edit the code snippet above so that the problem could be reproduced, but there seem to be a bunch of dependencies on other files which I don't know where to get from. Without a reproducible example, it is a bit hard to be helpful.\r\n\r\nThat said, I think this is because tensorboard doesn't know where the checkpoint is. You can probably fix that by specifying [`model_checkpoint_path`](https://github.com/tensorflow/tensorflow/blob/efe5376f3dec8fcc2bf3299a4ff4df6ad3591c88/tensorflow/tensorboard/plugins/projector/projector_config.proto#L41) in the `ProjectorConfig` using something like:\r\n\r\n```python\r\nconfig = projector.ProjectorConfig()\r\nconfig.model_checkpoint_path = os.path.join(model_dir_exp, ckpt_file)\r\n```\r\n\r\nSince this seems to be more of a usage issue and not a bug or feature request, I'll close this issue out and suggest that such questions (or follow ups) be posted on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) instead since there is a larger community that reads and answers questions there and we try to keep the github issues focused on bugs and feature requests.\r\n\r\nHope that helps!"]}, {"number": 8982, "title": "log_device_placement not working in some cases", "body": "Hey guys, thank you for working on TensorFlow so hard!\r\n\r\nI think I found a small bug, but it might be so that I just don't understand ConfigProto correctly.\r\nSo:\r\n\r\n```\r\nconfig = tf.ConfigProto(log_device_placement=True)\r\nserver = tf.train.Server.create_local_server()\r\nwith tf.Session(server.target, config=config):\r\n```\r\n\r\noutputs the device placement correctly, but\r\n\r\n```\r\nconfig = tf.ConfigProto(log_device_placement=True)\r\nserver = tf.train.Server.create_local_server(config=config)\r\nwith tf.Session(server.target):\r\n```\r\n\r\ndoesn't (at all).\r\n\r\nWhile this is not groundbreaking, just wanted to let you know.\r\n\r\nCheers, Kris", "comments": ["That indeed seems to be at least a discrepancy between the documentation of `tf.train.Server` and the behavior.\r\n\r\n@suharshs : Mind taking a look? It seems that `tf.Session(target)` in Python ends up sending a `CreateSession` RPC with `CreateSessionRequest.config` based on the options provided the `tf.Session` constructor. This means that the default provided to `tf.train.Server` was ignored. Which might be okay? But perhaps something needs to be cleaned up (either we don't have a \"default\" for the server, or we use it?)\r\n\r\nFYI @mrry ", "The docs for tf.train.Server say:\r\n```\r\nconfig: (Options.) A `tf.ConfigProto` that specifies default\r\n        configuration options for all sessions that run on this server.\r\n```\r\nThis doesn't seem to match the code in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc\r\nIt looks like the ServerDef (which has the session_opts) passed in isn't even passed to the MasterSession, unless I am missing something.\r\nWe need to somehow merge the session_opts in ServerDef with the ones passed to MasterSession before creating it. I'll look into this.\r\nThanks @krisjobs !"]}, {"number": 8981, "title": "fix summary writer thread leak", "body": "#4820 \r\nI assume there is only one daemon thread consumes event_queue.", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please."]}, {"number": 8980, "title": "Update adding_an_op.md", "body": "The issue (#1569) is related to gcc 5 and also above.", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please."]}, {"number": 8979, "title": "Compilation Error when building tensorflow with opencl, with computecpp(SYCL)", "body": "### Environment info\r\nOperating System: Ubuntu 16.10 64bit\r\nHardware: i7-2600k + R9 290X\r\ncomputecpp 0.1.3\r\ntensorflow branch r1.1\r\npython 3.5\r\n\r\ngit rev-parse HEAD\r\n```\r\n36a47f2bdcbbdf302da6f292ceee366ebd9640d2\r\n\r\n```\r\nBazel Version\r\n```\r\nBuild label: 0.4.5\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Thu Mar 16 12:19:38 2017 (1489666778)\r\nBuild timestamp: 1489666778\r\nBuild timestamp as int: 1489666778\r\n\r\n```\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\nCompilation with\r\n```\r\nbazel build -c opt --config=sycl //tensorflow/tools/pip_package:build_pip_package\r\n```\r\nresults in this Error\r\n\r\n```\r\nERROR: /home/flo/Workspace/tensorflow/tensorflow/contrib/tensor_forest/BUILD:97:1: C++ compilation of rule '//tensorflow/contrib/tensor_forest:python/ops/_tensor_forest_ops.so' failed: computecpp failed: error executing command external/local_config_sycl/crosstool/computecpp -Wall -msse3 -g0 -O2 -DNDEBUG '-std=c++11' -MD -MF ... (remaining 56 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\nIn file included from tensorflow/contrib/tensor_forest/kernels/count_extremely_random_stats_op.cc:20:\r\nIn file included from /usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/unordered_map:41:\r\n/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:471:67: error: pack expansion contains parameter packs '_Elements' and '_UElements' that have different lengths (1 vs. 3)\r\n      return __and_<is_constructible<_Elements, const _UElements&>...>::value;\r\n                                     ~~~~~~~~~        ~~~~~~~~~~  ^\r\n/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:664:21: note: in instantiation of function template specialization 'std::_TC<true, std::tuple<int, int, int> &&>::_ConstructibleTuple<int, int, int>' requested here```\r\n                    _ConstructibleTuple<_UElements...>()\r\n                    ^\r\n/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:670:19: note: while substituting prior template arguments into non-type template parameter [with _UElements = <int, int, int>, _Dummy = void]\r\n        constexpr tuple(const tuple<_UElements...>& __in)\r\n                  ^~~~~\r\n/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:1400:36: note: while substituting deduced template arguments into function template 'tuple' [with _UElements = <int, int, int>, _Dummy = (no value), $2 = (no value)]\r\n    { return tuple<_Elements&&...>(std::forward<_Elements>(__args)...); }\r\n                                   ^\r\n/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/hashtable_policy.h:621:16: note: in instantiation of function template specialization 'std::forward_as_tuple<std::tuple<int, int, int> >' requested here\r\n                                      std::forward_as_tuple(std::move(__k)),\r\n                                           ^\r\n/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/unordered_map.h:908:16: note: in instantiation of member function 'std::__detail::_Map_base<std::tuple<int, int, int>, std::pair<const std::tuple<int, int, int>, float>, std::allocator<std::pair<const std::tuple<int, int, int>, float> >, std::__detail::_Select1st, std::equal_to<std::tuple<int, int, int> >, tensorflow::CountExtremelyRandomStats::TupleIntHash, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[]' requested here\r\n      { return _M_h[std::move(__k)]; }\r\n               ^\r\ntensorflow/contrib/tensor_forest/kernels/count_extremely_random_stats_op.cc:421:22: note: in instantiation of member function 'std::unordered_map<std::tuple<int, int, int>, float, tensorflow::CountExtremelyRandomStats::TupleIntHash, std::equal_to<std::tuple<int, int, int> >, std::allocator<std::pair<const std::tuple<int, int, int>, float> > >::operator[]' requested here\r\n          split_delta[make_tuple(accumulator, split, column)] += w;\r\n                     ^\r\nIn file included from tensorflow/contrib/tensor_forest/kernels/count_extremely_random_stats_op.cc:20:\r\nIn file included from /usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/unordered_map:41:\r\n/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:477:65: error: pack expansion contains parameter packs '_UElements' and '_Elements' that have different lengths (3 vs. 1)\r\n      return __and_<is_convertible<const _UElements&, _Elements>...>::value;\r\n                                         ~~~~~~~~~~   ~~~~~~~~~ ^\r\n/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:666:21: note: in instantiation of function template specialization 'std::_TC<true, std::tuple<int, int, int> &&>::_ImplicitlyConvertibleTuple<int, int, int>' requested here\r\n                    _ImplicitlyConvertibleTuple<_UElements...>()\r\n                    ^\r\n/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:670:19: note: while substituting prior template arguments into non-type template parameter [with _UElements = <int, int, int>, _Dummy = void]\r\n        constexpr tuple(const tuple<_UElements...>& __in)\r\n                  ^~~~~\r\n/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:1400:36: note: while substituting deduced template arguments into function template 'tuple' [with _UElements = <int, int, int>, _Dummy = (no value), $2 = (no value)]\r\n    { return tuple<_Elements&&...>(std::forward<_Elements>(__args)...); }\r\n                                   ^\r\n/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/hashtable_policy.h:621:16: note: in instantiation of function template specialization 'std::forward_as_tuple<std::tuple<int, int, int> >' requested here\r\n                                      std::forward_as_tuple(std::move(__k)),\r\n                                           ^\r\n/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/unordered_map.h:908:16: note: in instantiation of member function 'std::__detail::_Map_base<std::tuple<int, int, int>, std::pair<const std::tuple<int, int, int>, float>, std::allocator<std::pair<const std::tuple<int, int, int>, float> >, std::__detail::_Select1st, std::equal_to<std::tuple<int, int, int> >, tensorflow::CountExtremelyRandomStats::TupleIntHash, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[]' requested here\r\n      { return _M_h[std::move(__k)]; }\r\n               ^\r\ntensorflow/contrib/tensor_forest/kernels/count_extremely_random_stats_op.cc:421:22: note: in instantiation of member function 'std::unordered_map<std::tuple<int, int, int>, float, tensorflow::CountExtremelyRandomStats::TupleIntHash, std::equal_to<std::tuple<int, int, int> >, std::allocator<std::pair<const std::tuple<int, int, int>, float> > >::operator[]' requested here\r\n          split_delta[make_tuple(accumulator, split, column)] += w;\r\n                     ^\r\nIn file included from tensorflow/contrib/tensor_forest/kernels/count_extremely_random_stats_op.cc:20:\r\nIn file included from /usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/unordered_map:41:\r\n/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:483:62: error: pack expansion contains parameter packs '_Elements' and '_UElements' that have different lengths (1 vs. 3)\r\n      return __and_<is_constructible<_Elements, _UElements&&>...>::value;\r\n                                     ~~~~~~~~~  ~~~~~~~~~~   ^\r\n/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:688:21: note: in instantiation of function template specialization 'std::_TC<true, std::tuple<int, int, int> &&>::_MoveConstructibleTuple<int, int, int>' requested here\r\n                    _MoveConstructibleTuple<_UElements...>()\r\n                    ^\r\n/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:694:19: note: while substituting prior template arguments into non-type template parameter [with _UElements = <int, int, int>, _Dummy = void]\r\n        constexpr tuple(tuple<_UElements...>&& __in)\r\n                  ^~~~~\r\n/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:1400:36: note: while substituting deduced template arguments into function template 'tuple' [with _UElements = <int, int, int>, _Dummy = (no value), $2 = (no value)]\r\n    { return tuple<_Elements&&...>(std::forward<_Elements>(__args)...); }\r\n                                   ^\r\n/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/hashtable_policy.h:621:16: note: in instantiation of function template specialization 'std::forward_as_tuple<std::tuple<int, int, int> >' requested here\r\n                                      std::forward_as_tuple(std::move(__k)),\r\n                                           ^\r\n/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/unordered_map.h:908:16: note: in instantiation of member function 'std::__detail::_Map_base<std::tuple<int, int, int>, std::pair<const std::tuple<int, int, int>, float>, std::allocator<std::pair<const std::tuple<int, int, int>, float> >, std::__detail::_Select1st, std::equal_to<std::tuple<int, int, int> >, tensorflow::CountExtremelyRandomStats::TupleIntHash, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[]' requested here\r\n      { return _M_h[std::move(__k)]; }\r\n               ^\r\ntensorflow/contrib/tensor_forest/kernels/count_extremely_random_stats_op.cc:421:22: note: in instantiation of member function 'std::unordered_map<std::tuple<int, int, int>, float, tensorflow::CountExtremelyRandomStats::TupleIntHash, std::equal_to<std::tuple<int, int, int> >, std::allocator<std::pair<const std::tuple<int, int, int>, float> > >::operator[]' requested here\r\n          split_delta[make_tuple(accumulator, split, column)] += w;\r\n                     ^\r\nIn file included from tensorflow/contrib/tensor_forest/kernels/count_extremely_random_stats_op.cc:20:\r\nIn file included from /usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/unordered_map:41:\r\n/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:489:60: error: pack expansion contains parameter packs '_UElements' and '_Elements' that have different lengths (3 vs. 1)\r\n      return __and_<is_convertible<_UElements&&, _Elements>...>::value;\r\n                                   ~~~~~~~~~~    ~~~~~~~~~ ^\r\n/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:690:21: note: in instantiation of function template specialization 'std::_TC<true, std::tuple<int, int, int> &&>::_ImplicitlyMoveConvertibleTuple<int, int, int>' requested here\r\n                    _ImplicitlyMoveConvertibleTuple<_UElements...>()\r\n                    ^\r\n/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:694:19: note: while substituting prior template arguments into non-type template parameter [with _UElements = <int, int, int>, _Dummy = void]\r\n        constexpr tuple(tuple<_UElements...>&& __in)\r\n                  ^~~~~\r\n/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:1400:36: note: while substituting deduced template arguments into function template 'tuple' [with _UElements = <int, int, int>, _Dummy = (no value), $2 = (no value)]\r\n    { return tuple<_Elements&&...>(std::forward<_Elements>(__args)...); }\r\n                                   ^\r\n/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/hashtable_policy.h:621:16: note: in instantiation of function template specialization 'std::forward_as_tuple<std::tuple<int, int, int> >' requested here\r\n                                      std::forward_as_tuple(std::move(__k)),\r\n                                           ^\r\n/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/unordered_map.h:908:16: note: in instantiation of member function 'std::__detail::_Map_base<std::tuple<int, int, int>, std::pair<const std::tuple<int, int, int>, float>, std::allocator<std::pair<const std::tuple<int, int, int>, float> >, std::__detail::_Select1st, std::equal_to<std::tuple<int, int, int> >, tensorflow::CountExtremelyRandomStats::TupleIntHash, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[]' requested here\r\n      { return _M_h[std::move(__k)]; }\r\n               ^\r\ntensorflow/contrib/tensor_forest/kernels/count_extremely_random_stats_op.cc:421:22: note: in instantiation of member function 'std::unordered_map<std::tuple<int, int, int>, float, tensorflow::CountExtremelyRandomStats::TupleIntHash, std::equal_to<std::tuple<int, int, int> >, std::allocator<std::pair<const std::tuple<int, int, int>, float> > >::operator[]' requested here\r\n          split_delta[make_tuple(accumulator, split, column)] += w;\r\n                     ^\r\n4 errors generated.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 853.100s, Critical Path: 837.41s\r\n```\r\n\r\n### What other attempted solutions have you tried?\r\nTried different compilers(clang,gcc) and a older version of computecpp\r\n\r\nIs this a issue with Tensorflow or ComputeCPP, Can someone reproduce that behaviour ?\r\nRegards Flo", "comments": ["This seems to be an issue compiling STL classes like `unordered_map`, based on the first few lines:\r\n\r\n```\r\nIn file included from /usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/unordered_map:41:\r\n/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:471:67: error: pack expansion contains parameter packs '_Elements' and '_UElements' that have different lengths (1 vs. 3)\r\n      return __and_<is_constructible<_Elements, const _UElements&>...>::value;\r\n```\r\n\r\nClosing this out since it doesn't appear to be a TensorFlow bug, perhaps some compiler/architecture settings on your machine? Feel free to reopen if you think I'm mistaken about this being a TensorFlow issue.", "@FloThinksPi Can you try my fork? https://github.com/lukeiwanski/tensorflow-opencl? \r\nAs well, I see you are using GCC6 I would suggest trying with GCC4.8 for now ."]}, {"number": 8978, "title": "Synchronous Training using SyncReplicasOptimizer", "body": "I'm trying to implement a synchronous distributed Recurrent Neural Network using TensorFlow on multiple servers. Here's the link to my code: https://github.com/tushar00jain/spark-ml/blob/master/rnn-sync.ipynb. I've also provided the relevant part below.\r\n\r\nI want the computations within the same batch to happen in parallel but I think it's still computing separate RNNs on each worker server and updating the parameters on the parameter server separately. I know this because I am printing the _current_state variable after I run the graph for each batch. Also, the _total_loss for the same global step is different on each worker server.\r\n\r\nI'm following the instructions provided at the following links: https://www.tensorflow.org/deploy/distributed#replicated_training https://www.tensorflow.org/api_docs/python/tf/train/SyncReplicasOptimizer\r\n\r\nIs this a bug or is there something wrong with my code?\r\n\r\n        sess = sv.prepare_or_wait_for_session(server.target)\r\n        queue_runners = tf.get_collection(tf.GraphKeys.QUEUE_RUNNERS)\r\n        sv.start_queue_runners(sess, queue_runners)\r\n\r\n        tf.logging.info('Started %d queues for processing input data.',\r\n                        len(queue_runners))\r\n\r\n        if is_chief:\r\n                sv.start_queue_runners(sess, chief_queue_runners)\r\n                sess.run(init_tokens_op)\r\n\r\n        print(\"{0} session ready\".format(datetime.now().isoformat()))\r\n        #####################################################################\r\n\r\n        ########################### training loop ###########################\r\n        _current_state = np.zeros((batch_size, state_size))\r\n        for batch_idx in range(args.steps):\r\n            if sv.should_stop() or tf_feed.should_stop():\r\n                break\r\n\r\n            batchX, batchY = feed_dict(tf_feed.next_batch(batch_size))\r\n\r\n            print('==========================================================')\r\n            print(_current_state)\r\n\r\n            if args.mode == \"train\":\r\n                _total_loss, _train_step, _current_state, _predictions_series, _global_step = sess.run(\r\n                [total_loss, train_step, current_state, predictions_series, global_step],\r\n                feed_dict={\r\n                    batchX_placeholder:batchX,\r\n                    batchY_placeholder:batchY,\r\n                    init_state:_current_state\r\n                })\r\n\r\n                print(_global_step, batch_idx)\r\n                print(_current_state)\r\n                print('==========================================================')\r\n\r\n                if _global_step % 5 == 0:\r\n                    print(\"Step\", _global_step, \"Loss\", _total_loss)  ", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "hmm thanks for the reply. I just thought it could be a bug because I was following the instructions as stated on the website but can't get to synchronise the training.\r\n\r\n", "This is most likely something wrong with the code. Only the chief is supposed to update the variables including global step once the vars collected enough gradients. It is also expected that each worker will do this separately to keep the speed of async runs as much as possible...", "Thanks! I'm not sure how to keep the hidden state consistent across all machines since it's not a trainable parameter but I'll ask on StackOverflow."]}, {"number": 8977, "title": "When running ./configure, no Opencl Support Option", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\r\n\r\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\r\nout of scope for GitHub Issues and point people to StackOverflow.\r\n\r\nFor bugs or installation issues, please provide the following information.\r\nThe more information you provide, the more easily we will be able to offer\r\nhelp and advice.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\n### Environment info\r\nOperating System:\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n2. The output of `bazel version`\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\n\r\n### What other attempted solutions have you tried?\r\n\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n", "comments": ["I have changed $TF_NEED_OPENCL\r\nMy fault"]}, {"number": 8976, "title": "Illegal instruction when importing tensorflow", "body": "After compiling tensorflow from source I get an \"illegal instruction\" error. \r\nI traced it back to this error with gdb:\r\n\r\n> Thread 1 \"python\" received signal SIGILL, Illegal instruction.\r\n> 0x00007fffdc684d16 in google::protobuf::SimpleDescriptorDatabase::DescriptorIndex<std::pair<void const*, int> >::AddFile(google::protobuf::FileDescriptorProto const&, std::pair<void const*, int>) ()\r\n>   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n\r\nI can successfully install and import the latest nightly build (and I have been able to compile and import tensorflow from source in the past on the same machine). I tried uninstalling all the dependencies and let pip install them again when I install the tensorflow wheel to no avail. I also tried to install the protobuf 3.1 wheel as suggested in the documentation, as well as the latest 3.2 wheel.\r\nAny suggestion is welcome.\r\n\r\nHere the details of my system:\r\n\r\nOperating System: Linux Ubuntu 16.04\r\nCUDA and CuDNN version\r\n> ls -l /usr/local/cuda/lib64/libcud*\r\n> -rw-r--r-- 1 root root   556000 Jan 27 00:48 /usr/local/cuda/lib64/libcudadevrt.a\r\n> lrwxrwxrwx 1 root root       16 Jan 27 00:51 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\r\n> lrwxrwxrwx 1 root root       19 Jan 27 00:51 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.61\r\n> -rw-r--r-- 1 root root   415432 Jan 27 00:48 /usr/local/cuda/lib64/libcudart.so.8.0.61\r\n> -rw-r--r-- 1 root root   775162 Jan 27 00:48 /usr/local/cuda/lib64/libcudart_static.a\r\n> lrwxrwxrwx 1 root root       13 Sep 24  2016 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\r\n> lrwxrwxrwx 1 root root       17 Sep 24  2016 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5\r\n> -rwxr-xr-x 1 root root 79337624 Sep 24  2016 /usr/local/cuda/lib64/libcudnn.so.5.1.5\r\n> -rw-r--r-- 1 root root 69756172 Sep 24  2016 /usr/local/cuda/lib64/libcudnn_static.a\r\n\r\nTensorflow commit: a9b7946540a27cc53bbdc9db1564196979fe30ae\r\nBazel version\r\n> Build label: 0.4.5\r\n> Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\n> Build time: Thu Mar 16 12:19:38 2017 (1489666778)\r\n> Build timestamp: 1489666778\r\n> Build timestamp as int: 1489666778", "comments": ["If you are still able to install and use the nightly installs, then it would suggest some funky interaction with your system setup and the build. Perhaps you can isolate to a clean environment in a docker container (you could even use the same docker images that are used for the nightly builds (using [`tensorflow/tools/ci_build/builds/pip.sh gpu --test_tag_filters=local,-benchmark-test --distinct_host_configuration=false --config=cuda -c opt`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/builds/pip.sh)\r\n", "It indeed seems to be a problem with my environment. Thank you for your answer, I will investigate further.", "@fvisin Did you ever determine the cause of this? I'm experiencing the same problem.", "In the end it was my fault: I had a set of extra flags that I mistakenly thought were right for my architecture. I was able to compile with the default settings, so I figured out the error was in my optimization flags.", "Ended up figuring it out last night, after installing the pre-built cuda package worked. It was the same problem for me; I had the flag for SSE enabled on a machine that didn't support it.", "after Upgrading to TensorFlow 1.6, I have this issue too. Programs which worked before stopped with\r\n\"fish: 'python3 <scriptname.py>' terminated by signal SIGILL (Illegale Instruktion)\"\r\ntest.py has just a single line, in which it imports tensorflow library.\r\n", "@leonard7e  Is it an older machine?  Perhaps the newer Tensorflow is compiled with more of the (newish) cpu SSE/parallelization flags.", "Hi hware.\r\n\r\nMy computer supports up to sse4_2. \r\n\r\n$> cat /proc/cpuinfo\r\ngives ...\r\n...\r\nmodel name\t: Intel(R) Celeron(R) CPU G3900TE @ 2.30GHz\r\n...\r\nflags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave rdrand lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti retpoline intel_pt rsb_ctxsw tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust erms invpcid rdseed smap clflushopt xsaveopt xsavec xgetbv1 xsaves dtherm arat pln pts hwp hwp_notify hwp_act_window hwp_epp\r\n\r\n\r\n(( --- Edit 24.3.2018 -- ))\r\nI compiled tensorflow 1.6.0 manually. It seems to work now."]}, {"number": 8975, "title": "Tensorflow build fails with bazel 0.3.2", "body": "**i am getting include file issue, have installed latest zlib1g-dev, but no luck** any help will be appreciated \r\n\r\n**Bazel binaries built from source V0.3.2,**\r\n**TF command:  bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package**\r\n\r\nERROR is ERROR: tensorflow/core/BUILD:853:1: undeclared inclusion(s) in rule '//tensorflow/core:lib_internal':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/core/lib/png/png_io.cc':\r\n~/.cache/bazel/_bazel_madhu/a9aabe45cf3d94341ef4fb777deb58c5/external/zlib_archive/zlib.h'\r\n~/.cache/bazel/_bazel_madhu/a9aabe45cf3d94341ef4fb777deb58c5/external/zlib_archive/zconf.h'.\"\r\n\r\n**output from echo | gcc -E -xc++ - -v ** \r\n\r\n\r\n\r\nUsing built-in specs.\r\nCOLLECT_GCC=gcc\r\nTarget: x86_64-linux-gnu\r\nConfigured with: ../src/configure -v --with-pkgversion='Ubuntu 5.4.0-6ubuntu1~16.04.4' --with-bugurl=file:///usr/share/doc/gcc-5/README.Bugs --enable-languages=c,ada,c++,java,go,d,fortran,objc,obj-c++ --prefix=/usr --program-suffix=-5 --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --with-sysroot=/ --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-vtable-verify --enable-libmpx --enable-plugin --with-system-zlib --disable-browser-plugin --enable-java-awt=gtk --enable-gtk-cairo --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-5-amd64/jre --enable-java-home --with-jvm-root-dir=/usr/lib/jvm/java-1.5.0-gcj-5-amd64 --with-jvm-jar-dir=/usr/lib/jvm-exports/java-1.5.0-gcj-5-amd64 --with-arch-directory=amd64 --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --enable-objc-gc --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu\r\nThread model: posix\r\ngcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.4)\r\nCOLLECT_GCC_OPTIONS='-E' '-v' '-mtune=generic' '-march=x86-64'\r\n /usr/lib/gcc/x86_64-linux-gnu/5/cc1plus -E -quiet -v -imultiarch x86_64-linux-gnu -D_GNU_SOURCE - -mtune=generic -march=x86-64 -fstack-protector-strong -Wformat -Wformat-security\r\nignoring duplicate directory \"/usr/include/x86_64-linux-gnu/c++/5\"\r\nignoring nonexistent directory \"/usr/local/include/x86_64-linux-gnu\"\r\nignoring nonexistent directory \"/usr/lib/gcc/x86_64-linux-gnu/5/../../../../x86_64-linux-gnu/include\"\r\n#include \"...\" search starts here:\r\n#include <...> search starts here:\r\n /usr/include/c++/5\r\n /usr/include/x86_64-linux-gnu/c++/5\r\n /usr/include/c++/5/backward\r\n /usr/lib/gcc/x86_64-linux-gnu/5/include\r\n /usr/local/include\r\n /usr/lib/gcc/x86_64-linux-gnu/5/include-fixed\r\n /usr/include/x86_64-linux-gnu\r\n /usr/include\r\nEnd of search list.\r\n# 1 \"<stdin>\"\r\n# 1 \"<built-in>\"\r\n# 1 \"<command-line>\"\r\n# 1 \"/usr/include/stdc-predef.h\" 1 3 4\r\n# 1 \"<command-line>\" 2\r\n# 1 \"<stdin>\"\r\nCOMPILER_PATH=/usr/lib/gcc/x86_64-linux-gnu/5/:/usr/lib/gcc/x86_64-linux-gnu/5/:/usr/lib/gcc/x86_64-linux-gnu/:/usr/lib/gcc/x86_64-linux-gnu/5/:/usr/lib/gcc/x86_64-linux-gnu/\r\nLIBRARY_PATH=/usr/lib/gcc/x86_64-linux-gnu/5/:/usr/lib/gcc/x86_64-linux-gnu/5/../../../x86_64-linux-gnu/:/usr/lib/gcc/x86_64-linux-gnu/5/../../../../lib/:/lib/x86_64-linux-gnu/:/lib/../lib/:/usr/lib/x86_64-linux-gnu/:/usr/lib/../lib/:/usr/lib/gcc/x86_64-linux-gnu/5/../../../:/lib/:/usr/lib/\r\nCOLLECT_GCC_OPTIONS='-E' '-v' '-mtune=generic' '-march=x86-64'\r\n", "comments": ["If you're following the instructions on [building TensorFlow from sources](https://www.tensorflow.org/install/install_sources), it should tell you that doing so\r\n[requires 0.4.5](https://github.com/tensorflow/tensorflow/blob/83be34c47c7ed81c62bd61a908fde017e301b578/tensorflow/workspace.bzl#L107)\r\n\r\nBazel versions less than that are not supported.", "@asimshankar I am following the above link, alsoI am using modified version of Tensorflow sources and to my surprise the workspace.bzl does not have any check on the bazel version...                      \r\nunder def tf_workspace()", "@madhutummi : Seems like you're using a version of the source code that is different from HEAD. To build from sources, ideally build from the latest release branch and use bazel 0.4.5.\r\n\r\nHope that helps.", "This issue is fixed and can be closed.\r\nThis was resolved by removing all the entries of bazel version using \r\nrm $HOME/.cache/bazel -fr\r\nsudo rm /usr/local/bin/bazel /etc/bazelrc /usr/local/lib/bazel -fr  ~/.cache/bazel\r\n\r\nand updating the PATH to point to the correct gcc version and zlib files.\r\n"]}, {"number": 8974, "title": "contrib/slim: Fix broken links in README.md", "body": "Fixes #8969", "comments": []}, {"number": 8973, "title": " C++ compilation of rule '//tensorflow/core:lib_hash_crc32c_accelerate_internal' failed: ", "body": "I am installing tensorflow with GPU and meeting some problems:\r\n\r\nWARNING: /home/EI/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': Use SavedModel Builder instead.\r\nWARNING:  #/home/EI/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': Use SavedModel instead.\r\nINFO: Found 1 target...\r\nERROR: /home/EI/tensorflow/tensorflow/core/BUILD:1280:1: C++ compilation of rule '//tensorflow/core:lib_hash_crc32c_accelerate_internal' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter ... (remaining 41 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\ngcc: error trying to exec 'cc1plus': execvp: No such file or directory\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 1994.312s, Critical Path: 8.68s\r\n\r\nOperating System: Ubuntu 16.04LTS\r\ngcc  4.9.3\r\nbazel :0.4.5\r\npython:3.6.0\r\nCUDA:8.0.61_375.62\r\ncuDNN:5.1.1\r\n", "comments": ["As suggested in the logs, try using the `--verbose_failures` flag for bazel to get the exact command being executed that fails. Then you should be able to execute that command and get more information as to the cause of the failure.\r\n", "@asimshankar  well ,I did use --verbose_failures, but I still can't found what's wrong with it .\r\nen...can the problem be related with anaconda ? the java version \"1.8.0_121\"seems like no problem.\r\n\r\nbazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures\r\nWARNING: /home/EI/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': Use SavedModel Builder instead.\r\nWARNING: /home/EI/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': Use SavedModel instead.\r\nINFO: Found 1 target...\r\nERROR: /home/EI/tensorflow/tensorflow/core/BUILD:1280:1: C++ compilation of rule '//tensorflow/core:lib_hash_crc32c_accelerate_internal' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command \r\n  (cd /home/EI/.cache/bazel/_bazel_EI/2e0782785985dd9cb1b5d0cb62ad2606/execroot/tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH='/usr/local/cuda-8.0/lib64:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:$JAVA_HOME/bin:/snap/bin:/usr/local/cuda/bin:/usr/local/cuda/lib64' \\\r\n    PATH='/usr/local/cuda-8.0/bin:/home/EI/anaconda3/bin:/home/EI/anaconda2/bin:/home/EI/bin:/home/EI/.local/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:$JAVA_HOME/bin:/snap/bin:/usr/local/cuda/bin:JAVA_HOME/bin:/usr/lib/Java/jdk1.8.0_121/jre/bin:/home/EI/anaconda3/bin:/home/EI/anaconda2/bin:/usr/local/cuda/bin:/home/EI/bin:JAVA_HOME/bin:/usr/lib/Java/jdk1.8.0_121/jre/bin' \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -g0 '-std=c++11' -MD -MF bazel-out/host/bin/tensorflow/core/_objs/lib_hash_crc32c_accelerate_internal/tensorflow/core/lib/hash/crc32c_accelerate.d '-frandom-seed=bazel-out/host/bin/tensorflow/core/_objs/lib_hash_crc32c_accelerate_internal/tensorflow/core/lib/hash/crc32c_accelerate.o' -iquote . -iquote bazel-out/host/genfiles -iquote external/bazel_tools -iquote bazel-out/host/genfiles/external/bazel_tools -isystem external/bazel_tools/tools/cpp/gcc3 -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare -fno-exceptions '-DGOOGLE_CUDA=1' -msse3 -pthread -msse4.2 -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fno-canonical-system-headers -c tensorflow/core/lib/hash/crc32c_accelerate.cc -o bazel-out/host/bin/tensorflow/core/_objs/lib_hash_crc32c_accelerate_internal/tensorflow/core/lib/hash/crc32c_accelerate.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\ngcc: error trying to exec 'cc1plus': execvp: No such file or directory\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 2.081s, Critical Path: 1.32s\r\n", "@ElviseZhou - with `--verbose_failures` you have the exact command that failed (in this case, some invocation of `gcc`). Perhaps you can execute that and see what the error is. From the log above, it seems that the command is something like:\r\n\r\n```\r\ncd /home/EI/.cache/bazel/bazel_EI/2e0782785985dd9cb1b5d0cb62ad2606/execroot/tensorflow && exec env - LD_LIBRARY_PATH='/usr/local/cuda-8.0/lib64:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:$JAVA_HOME/bin:/snap/bin:/usr/local/cuda/bin:/usr/local/cuda/lib64' PATH='/usr/local/cuda-8.0/bin:/home/EI/anaconda3/bin:/home/EI/anaconda2/bin:/home/EI/bin:/home/EI/.local/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:$JAVA_HOME/bin:/snap/bin:/usr/local/cuda/bin:JAVA_HOME/bin:/usr/lib/Java/jdk1.8.0_121/jre/bin:/home/EI/anaconda3/bin:/home/EI/anaconda2/bin:/usr/local/cuda/bin:/home/EI/bin:JAVA_HOME/bin:/usr/lib/Java/jdk1.8.0_121/jre/bin' external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -g0 '-std=c++11' -MD -MF bazel-out/host/bin/tensorflow/core/objs/lib_hash_crc32c_accelerate_internal/tensorflow/core/lib/hash/crc32c_accelerate.d '-frandom-seed=bazel-out/host/bin/tensorflow/core/objs/lib_hash_crc32c_accelerate_internal/tensorflow/core/lib/hash/crc32c_accelerate.o' -iquote . -iquote bazel-out/host/genfiles -iquote external/bazel_tools -iquote bazel-out/host/genfiles/external/bazel_tools -isystem external/bazel_tools/tools/cpp/gcc3 -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare -fno-exceptions '-DGOOGLE_CUDA=1' -msse3 -pthread -msse4.2 -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE=\"redacted\"' '-D__TIMESTAMP_=\"redacted\"' '-D__TIME__=\"redacted\"' -fno-canonical-system-headers -c tensorflow/core/lib/hash/crc32c_accelerate.cc -o bazel-out/host/bin/tensorflow/core/_objs/lib_hash_crc32c_accelerate_internal/tensorflow/core/lib/hash/crc32c_accelerate.o\r\n```", "@asimshankar  thanks ,the probblem solved ,but  en... it seems like another problem appears .it's \r\nweird...https://github.com/tensorflow/tensorflow/issues/9015", "How was the problem solved? Did you figure out what the error was?\r\n\r\nClosing this out since it seems you've filed a duplicate."]}, {"number": 8972, "title": "conv2d_transpose output shape more undefined than input shape", "body": "I have posted [this on StackOverflow](http://stackoverflow.com/questions/43113984/output-shape-of-tf-nn-conv2d-transpose-is-entirely-undefined-even-though-only-ba) already but haven't gotten an answer yet, plus it feels like a bug very similar to https://github.com/tensorflow/tensorflow/issues/5807 which is why I'm posting it here as well.\r\n\r\nBasically the problem is that the output shape of `tf.nn.conv2d_transpose` is entirely undefined, even if e.g. only one dimension in the input is unknown. So in the following code snippet, the shape of `out` is `[3, 10, 5, 5]` as expected if using the static shape to get the size of the first dimension. However if you use the dynamic shape (commented line in the snippet below), then the shape of `out` is `[?, ?, ?, ?]` instead of `[?, 10, 5, 5]`.\r\n\r\nThis is a problem for me because I am using `out` in a batch-normalization layer with `tf.contrib.layers.python.layers.batch_norm` for which certain dimensions must be defined.\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\ninput_ = tf.Variable(tf.random_normal([3, 10, 5, 1]))\r\nw = tf.get_variable('w', initializer=tf.truncated_normal([3, 3, 5, 1], mean=0.0, stddev=0.01, dtype=tf.float32))\r\n\r\n# output_shape = [tf.shape(input_)[0], 10, 5, 5]\r\noutput_shape = [input_.get_shape()[0].value, 10, 5, 5]\r\nout = tf.nn.conv2d_transpose(input_,\r\n                             filter=w,\r\n                             output_shape=tf.pack(output_shape),\r\n                             strides=[1, 1, 1, 1],\r\n                             padding='SAME')\r\n```\r\n\r\nI am using TF v0.12 on Ubuntu 14.04, Python 3.5.2, installed in Anaconda environment through pip.", "comments": ["For your needs, a workaround would be to explicitly set the shape using `out.set_shape([None, 10, 5, 5])` so code downstream knows (from `out.shape` or `out.get_shape()`) what you wanted them to know.\r\n\r\nI'll dig in a bit more about a more principled fix. Let me know if the workaround is sufficient for you for now.\r\n\r\n", "@asimshankar Thanks for your reply - that workaround is sufficient for me at the moment. FWIW, an answer on SO pointed out that apparently also `tf.reshape(out_shape)` would be a possible workaround, as the reshape restores the static shape, see https://github.com/tensorflow/tensorflow/issues/833#issuecomment-278016198.", "Glad to hear you have a workaround for now.\r\n\r\nA more appropriate fix would be to have the shape inference function for [`Conv2DBackpropInput`](https://github.com/tensorflow/tensorflow/blob/de7a060aa76cb3ab6cec16f9402d9152e341b0af/tensorflow/core/ops/nn_ops.cc#L566) work out the shape from gradients/attrs. For this, contributions are welcome.\r\n\r\nAlternatively, if and when we move graph construction in Python to run on top of the C API, the ShapeRefiner might be able to provide the partial shape of the input and make this shape inference function more accurate (FYI @skye)", "Automatically closing due to lack of recent activity. Since this issue is old at this point, please reopen the issue if it still occurs when tried with the latest version of Tensorflow. Thank you.", "I am still having this issue with the current version of TensorFlow. For the code below, the print statement returns: \r\n\r\n(?, 7, 7, 32)\r\n(?, ?, ?, ?)\r\n\r\n```\r\nh1 = tf.nn.relu(conv_transpose(z_matrix, [tf.shape(self.images)[0], 14, 14, 16], name=\"g_h1\"))\r\nh2 = conv_transpose(h1, [tf.shape(self.images)[0], 28, 28, 1], name=\"g_h2\")\r\n```\r\n```\r\n\r\ndef conv_transpose(x, outputShape, name):\r\n    with tf.variable_scope(name):\r\n        print x.get_shape()\r\n        w = tf.get_variable(\"w\",[5,5, outputShape[-1], x.get_shape()[-1]], initializer=tf.truncated_normal_initializer(stddev=0.02))\r\n        b = tf.get_variable(\"b\",[outputShape[-1]], initializer=tf.constant_initializer(0.0))\r\n        deconv_shape = tf.stack(outputShape)\r\n        convt = tf.nn.conv2d_transpose(x, w, output_shape=deconv_shape, strides=[1,2,2,1])\r\n        return convt`\r\n```", "I think `tensor_util.constant_value_as_shape` could be used to address the issue? Created a PR #13193 for that."]}, {"number": 8971, "title": "html5lib dependency issue", "body": "Install Tensorflow from source, met `html5lib` dependency issue:\r\n\r\n```\r\nProcessing dependencies for tensorflow==1.1.0rc0\r\nerror: html5lib 1.0b8 is installed but html5lib!=0.9999,!=0.99999,<0.99999999,>=0.999 is required by {'bleach'}\r\n```\r\n\r\n## 1. Env:\r\n### 1.1 OS:\r\nLinux Mint 18.1 Cinnamon 64-bit\r\n### 1.2 CUDA & CUDNN:\r\nGPU: Nvidia Titan X Pascal\r\n```\r\n$ls -l /usr/local/cuda/lib64/libcud*\r\n-rw-r--r-- 1 root root   556000 Apr  5 00:46 /usr/local/cuda/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root root       16 Apr  5 00:46 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root root       19 Apr  5 00:46 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.61\r\n-rwxr-xr-x 1 root root   415432 Apr  5 00:46 /usr/local/cuda/lib64/libcudart.so.8.0.61\r\n-rw-r--r-- 1 root root   775162 Apr  5 00:46 /usr/local/cuda/lib64/libcudart_static.a\r\nlrwxrwxrwx 1 root root       13 Apr  5 00:47 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\r\nlrwxrwxrwx 1 root root       17 Apr  5 00:47 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5\r\n-rwxr-xr-x 1 root root 79337624 Apr  5 00:47 /usr/local/cuda/lib64/libcudnn.so.5.1.5\r\n-rw-r--r-- 1 root root 69756172 Apr  5 00:47 /usr/local/cuda/lib64/libcudnn_static.a\r\n```\r\n### 1.3 Tensorflow git version\r\n```\r\n$ git rev-parse HEAD\r\na9b7946540a27cc53bbdc9db1564196979fe30ae\r\n```\r\n\r\n### 1.4 Bazel version\r\n```\r\n$ bazel version\r\nBuild label: 0.4.5\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Thu Mar 16 12:19:38 2017 (1489666778)\r\nBuild timestamp: 1489666778\r\nBuild timestamp as int: 1489666778\r\n```\r\n\r\n### 1.5 Installed html4lib\r\n```\r\n$sudo -H pip3 list\r\n...\r\nhtml5lib (0.9999999)\r\n...\r\n```\r\n\r\n## 2. Reproduction\r\nAfter clone the git, executing a script with the following commands to install [developer mode] :\r\n\r\n```\r\nbazel clean\r\n./configure\r\nbazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 --config=cuda -k //tensorflow/tools/pip_package:build_pip_package\r\n#bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\nsudo rm -r _python_build\r\nmkdir _python_build\r\ncd _python_build\r\nln -s ../bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/org_tensorflow/* .\r\nln -s ../tensorflow/tools/pip_package/* .\r\nsudo -H python3 setup.py develop\r\n```\r\n", "comments": ["I ran into a similar problem when I tried to use tensorboard.\r\nFirst I got the error:\r\n\r\n    from html5lib.filters.base import Filter\r\n    ImportError: No module named 'html5lib.filters.base'\r\n\r\n\r\nI fixed it by unistalling html5lib via pip and installing version 0.9999.\r\nLinuxMint, Anaconda in a python 3.5 env.", "Problem solved by changing the html5lib version to 0.9999999\r\n\r\nStep 1: edit `tensorflow/tools/pip_package/setup.py`, update\r\n```\r\n'html5lib == 1.0b8',\r\n```\r\nto \r\n```\r\n'html5lib == 0.9999999',\r\n```\r\n\r\nStep 2: edit `tensorflow/workspace.bzl`, update\r\n```\r\n  native.new_http_archive(\r\n      name = \"org_html5lib\",\r\n      urls = [\r\n          \"http://bazel-mirror.storage.googleapis.com/github.com/html5lib/html5lib-python/archive/1.0b8.tar.gz\",\r\n          \"https://github.com/html5lib/html5lib-python/archive/1.0b8.tar.gz\",\r\n      ],\r\n      sha256 = \"adb36c879264e8880b92589c4c4fe0814cd9d157b73328b14d728f48a6bab0a4\",\r\n      strip_prefix = \"html5lib-python-1.0b8\",\r\n      build_file = str(Label(\"//third_party:html5lib.BUILD\")),\r\n  )\r\n```\r\nto\r\n```\r\n  native.new_http_archive(\r\n      name = \"org_html5lib\",\r\n      urls = [\r\n          \"http://bazel-mirror.storage.googleapis.com/github.com/html5lib/html5lib-python/archive/0.9999999.tar.gz\",\r\n          \"https://github.com/html5lib/html5lib-python/archive/0.9999999.tar.gz\",\r\n      ],\r\n      sha256 = \"184257f98539159a433e2a2197309657ae1283b4c44dbd9c87b2f02ff36adce8\",\r\n      strip_prefix = \"html5lib-python-0.9999999.tar.gz\",\r\n      build_file = str(Label(\"//third_party:html5lib.BUILD\")),\r\n  )\r\n```\r\n\r\nAttention,  the `googleapis` url for 0.9999999.tar.gz is not alive, but the `github` one will work, so it worked", "Do yo need to build from head? Could you build from the release branch (or better still use the release binaries) instead?\r\n\r\nAppreciate the report, but the release branches will be more stable.\r\n\r\n(FYI: @dandelionmane @jart )", "Wow it looks like html5lib tags each release with two IDs. One <1.0 and one >1.0. https://pypi.python.org/pypi/html5lib So 0.9999999 actually is the same version we're using now, which is 1.0b8. What a nightmare. Sending a PR now.\r\n\r\nCC: @dandelionmane "]}, {"number": 8970, "title": "Added \"hop_bytes\" option to FixedLengthRecordReader", "body": "A \"hop_bytes\" option added to FixedLengthRecordReader.\r\n\r\nWith this option, one can easily read fixed-length record from file with a sliding window. This is useful for reading audio waveform or features with contexts.\r\n\r\nExample:\r\n\r\nfile:\r\n`\"1234567\"`\r\n\r\nreader:\r\n`record_bytes=3, hop_bytes=2`\r\n\r\nresult:\r\n`\"123\", \"345\", \"567\"`", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Can you please add tests for this change?", "@t13m please ping this PR when you've got a chance to add some unit tests.  Thanks!", "@concretevitamin @rohan100jain Sure I'm working on unit tests. Should the unit test be added to `tensorflow/python/test_kernels/reader_ops_test.py`? Should I modify the origin `FixedLengthRecordReaderTest` or write a new test just for this new option?\r\n\r\nThank you very much.", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->", "CLAs look good, thanks!\n\n<!-- ok -->", "@concretevitamin Hi, I modified the original unittest of `FixedLengthRecordReader` to make it test the new argument. The unittest is passed. I'm not sure if it is enough, if not, please let me know. Thank you for reviewing.", "@t13m feel free update the code and push, or ask if you have any questiosn.", "Hi, sorry for reply so late. I added the comment requested, thanks for reviewing!", "Jenkins, test this please.", "cc @martinwicke @josh11b \r\nThis PR involves an API change (in io_ops.py / FixedLengthRecordReader). I can fix the golden during the upcoming pull. Let me know if you think we should proceed in other ways.", "@caisq Hi, sorry but I didn't get it. Could you please explain what does \"fix the golden\" and \"upcoming pull\" mean?", "@t13m These changes are being pulled to Google's internal SCM as per our routine sync, where it is subject to compatibility checks not present on GitHub."]}, {"number": 8969, "title": "Broken link in README.md", "body": "In https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/README.md\r\n\r\n > ...In addition to the types of scope mechanisms in TensorFlow (name_scope, variable_scope, TF-Slim adds a...\r\n\r\nLink of variable_scope ( https://www.tensorflow.org/api_docs/python/state_layers#variable_scope ) is broken.\r\n\r\n", "comments": []}]