[{"number": 13532, "title": "tf.contrib.data.Dataset generated by slicing and dicing very large images", "body": "Hi\r\n(writing here as requested by @mrry for further tf.contrib.data feature requests)\r\n\r\nI would like to create a Dataset by cutting up and preprocessing very large images. I did this:\r\n\r\n```\r\ndataset = tf.contrib.data.Dataset.from_tensor_slices(tf.constant(img_filelist))\r\ndataset = dataset.flat_map(load_cut_up_and_process)\r\n```\r\n\r\nThis goes out of memory because my function load_cut_up_and_process creates too many pieces from one image, all in memory. If I try to make a function that returns fewer pieces for an image and then want to call it repeatedly on the same image to get more, how can I achieve that with Dataset, without replicating the huge image in memory? The only thing I can think of is:\r\n\r\n```\r\ndataset = tf.contrib.data.Dataset.from_tensor_slices(tf.constant(img_filelist))\r\ndataset = dataset.flat_map(load_and_replicate_each_image) # Dataset is [im1, im1, im1, im2, im2, im2, im3, im3, im3, ...]\r\ndataset = dataset.flat_map(cut_up_and_process_gently)\r\n```\r\n\r\nNow the second step goes out of memory because the implementation of load_and_replicate_each_image necessarily involves a tensor like [im, im, im] and multiple copies of the image will not fit. I also thought of this:\r\n\r\n```\r\ndataset = tf.contrib.data.Dataset.from_tensor_slices(tf.constant(img_filelist))\r\ndataset = dataset.flat_map(replicate_each_filename) # Dataset is [imfname1, imfname1, imfname1, imfname2, imfname2, imfname2, imfname3, imfname3, imfname3, ...]\r\ndataset = dataset.flat_map(load_cut_up_and_process_gently)\r\n```\r\n\r\nWhich works, does not go out of memory, but now I am loading the same huge image multiple times in a row which is slow.\r\n\r\nAny ideas ?", "comments": ["I don't think this is a bug or feature request... please post on Stack Overflow instead, providing more details of what's in the functions.", "Ok, the general question is: how do you generate a dataset from a list of very large images by cutting them up in pieces in a case when 1) you cannot load multiple very large images in memory at once and 2) the collection of pieces resulting from one image will not fit in memory either.\r\n\r\nIf the answer is \"you cannot\", then this is a feature request :-)", "@martin-gorner Not quite sure what you want to achieve but are you looking for a \"partial read\" of a file, so that only a chunk of the data records (off, len) is read into the memory?\r\n\r\nIn that case, I think it will very much depends on the underlying file format of the `img_filelist` and the implementation of the `load_cut_up_and_process_gently`.\r\n\r\nIt should always be possible with your own implementation. I do think you may get more help from StackOverflow.", "Sorry @martin-gorner but I'm going to close this out.  We have limited resources in fielding github issues, so we really need to be strict wrt our \"bugs+features in github, questions on StackOverflow\" policy.\r\n\r\nHere's the standard boilerplate:\r\n\r\nThis question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 13531, "title": "Simplify random selection of context words for word2vec example", "body": "Use random.sample to simplify random selection of context words", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please."]}, {"number": 13530, "title": "Pandas_input_fn slow, starving CPU/GPU", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: It is a customized version of the Deep & Wide example code. Fairly close to original code.\r\n- **OS Platform and Distribution: Windows Server 2012 R2\r\n- **TensorFlow installed from: nightly build WHL through pip (this was tried after numerous other versions, including install through pip)\r\n- **TensorFlow version (use command below)**: b'unknown' 1.4.0-dev20170926\r\n- **Python version**: 3.5 and 3.6\r\n- **Bazel version (if compiling from source)**: Not compiling\r\n- **CUDA/cuDNN version**: CUDA 8, CUDnn 6.1\r\n- **GPU model and memory**: Tesla M60 GPU 8GB\r\n- **Exact command to reproduce**:  See attached Script.\r\n-For the record, the server vm has 8 xeon physical cores and 240 gb ram allocated. The CPU only machine is a new skylake i7 with 32gb ram.\r\n\r\n### Describe the problem\r\nTo start, I submitted to stack overflow (https://stackoverflow.com/questions/46457476/tensorflow-pandas-input-fn-slow-starving-cpu-gpu) and have not been able to garner assistance after multiple edits to make sure it was framed correctly. I truly believe this is a bug since I am sticking so close to the example code, but if I have made a mistake I am deeply sorry to all of you.\r\n\r\nI am working on a wide and deep model following the framework in the Tensorflow Wide and Deep tutorial (https://www.tensorflow.org/tutorials/wide_and_deep). Model works fine when built the old way (load entire dataset from pandas, convert to tensors, feed in input_fn) which is ok for running on a CPU. \r\n\r\nHowever, to make it work on the GPU the dataset is too large to fit into GPU memory, so batching is necessary. I tried using the pandas_input_fn to batch data to the video card and noticed I get spikes of activity followed by long lulls while the next batch is prepared. The odd thing is, this happens even if I run it on a machine with CPU only. The lulls are almost the exact same length, so it isn't simply the video card crushing through a simple model faster than the proc can deliver it. It seems like it is always waiting to begin loading the next batch until the last one is done training. \r\n\r\n(If this function simply cannot be used in this way, can we get an example of Deep and Wide using the dataset API? or a manual build of deep and wide using layers and queues? At the moment, the example code for the dataset api using make_one_shot_iterator for canned estimators doesn't run.)\r\n\r\nI increased the complexity of the model to make sure it wasn't too easy to compute and still have the same issue. I have tried increasing the number of threads allocated to pandas_input_fn, I have tried increasing the queue size to far larger than seems reasonable (10x dataset size) which helps a bit, but not much. I am not sure if the slowdown is when it is queueing or de-queueing, but I have been unable to solve the issue after two weeks of troubleshooting. The data I am working with is 117 columns, 400k rows.\r\n\r\nI have created a generic script that generates fake values to simulate the problem. However, there are far fewer fake columns than real ones, so the gap between steps is not nearly as long, but still noticeable. Code attached.\r\n\r\n\r\n--\r\n\r\n### Source code / logs\r\nattached\r\n[pandas_input_example.txt](https://github.com/tensorflow/tensorflow/files/1363335/pandas_input_example.txt)\r\n", "comments": ["@mrry, could you make some suggestions?", "I too have been dealing with extremely low (<10%) GPU usage when using `pandas_input_fn` with a `DNNRegressor` and Titan Xp", "I have not addressed usage itself yet because I assumed it was due to the balance of loading data. I couldn't dial in that balance with the GPU taking such long pauses. That said, my GPU usage was also extremely low, even when I seemed to be filling memory up (growth set to true, etc.) I never got above 12%. Still, I am much more worried about the batching speed issue. This bug, if it is indeed a bug, means we are still stuck loading tabular data via tfrecord/protobuf if we want decent performance. Its a problem because its more than 90% of our ML use cases (image data is fun, but a huge portion of ML is just strait up data). That said, I'm not complaining overall, Tensorflow is an amazing achievement and it gets better every day. Thanks to all the devs volunteering on this project.", "@mellvinbaker Looking at your example code, I noticed that the `batch_size` is 200000 (i.e. the full size of the `DataFrame`). Is that what you'd typically use in your application?\r\n\r\nGiven that the `pandas_input_fn()` is based on a `FeedingQueueRunner`, it would have to feed 200000 elements to build such a batch. At ~20us per feed, I'm not surprised that it stalls for a noticeable amount of time.\r\n", "@mrry The dataframe is 400,000 rows, not 200,000 and those 200,000 rows make for about ~.75gb of data (that is with my own dataset, with this generated dataset its closer to .3gb). I am not sure how that is any different than a .3GB array of image values. I would not think that batching .3gb of numbers to a GPU would be outside the scope of pandas_input_fn, but maybe I misunderstand its purpose (or its use, both are very possible). When would you ever need to batch a dataset of say 50mb to a tesla M60? The whole thing would fit in memory, thus avoiding the need for batching at all.\r\n\r\nThe typical use would be to pull about 2,000,000 rows from SQL, batch them into the most efficient size for the GPU (without compromising training), and run the model. At the moment, I can run the entire 2,000,000 through an estimator if I use CPU only because I have ~128gb of ram on the server. That runs in half the time of batching that same 2,000,000 rows to the GPU, regardless of batch size. \r\n\r\nI have tried batch sizes ranging from 20k to 200k and all have the same problem. When one batch is done, the GPU sits idle waiting for more. The smaller the batch though, the lower the GPU utilization, thus causing slowdowns on the other end.\r\n\r\nedit: This sounded more argumentative than I meant it too. Rest assured I am trying to be complete and concise, not snarky.", "FYI, I have rebuilt my input functions to see if TFRecord would work better. While it does do a better job of keeping the processor fed without lag (still a little between steps, but I haven't even optimized, still doing 1 file 1 thread etc.) it isn't a solution for this type of data. It makes sense for pictures, which change very little. But if you are working with a dataset that needs feature engineering it can be a bit iterative. \r\nWith 400k rows taking ~8 hours to serialize to TFRecord, we entirely lose any advantage gained by using GPU.\r\n\r\nThanks again guys for looking into issues like this and for all the hard work. ", "Checking in to say that i encountered the same problem. \r\n\r\n2kk objects with 300 features, feeded to wideanddeep estimator through TFRecordDataset, cpu is overloaded at 800%(8 cores) while titan gpu is at 10% utilisation. Tried on various batch sizes from 64 to 20k.\r\n\r\nIs there something i am doing wrong or is there any updates about this issue?", "Reassigning this to @rohan100jain, who has been working on a GPU prefetching optimization for `tf.data` that should fix the utilization problem.", "had the same issue, really want to know how to improve the performance.", "Just wanted to ping here and mention that I'm indeed working on a GPU prefetching optimization that should help parallelize loading of batches much more and hence improve performance. The work is nearly done - I'm just testing and making sure it functions correctly before publishing some instructions as to how to use it. Please stay tuned for a week or so as I solidify this more. Thanks!", "@rohan100jain any update for this performance issue? From the thread above, I assume there is already a solution, wonder when will it be published? Thanks.", "It is not only pandas, direct reading from csv (TextLineDataset), DNNRegressor still underutilising GPU. ", "Please try out tf.data.experimental.copy_to_device(\"/gpu:0\").prefetch(1) to get prefetching onto the GPU.", "Sorry, I just saw the response. Where would I put this, is it a runconfig parameter, part of pandas_input_fn, a decorator at the top of the script? Or does this only apply to text_line_dataset?", "> Sorry, I just saw the response. Where would I put this, is it a runconfig parameter, part of pandas_input_fn, a decorator at the top of the script? Or does this only apply to text_line_dataset?\r\n\r\n@rohan100jain  Could you please answer this ?", "I have the same problem, the utilization of gpu is too low\uff0creally want to know how to improve the performance.", "Having same issue with CSV input function using TextLineDataset (w/ decodeCsv call). Read speeds are extremely low. I am seeing 2MB/s max even on SSD drive", "The prefetching currently works only for tf.data, so you'll have to replace your pandas_input_fn with a dataset. I believe you can use SQLDAtaset (https://www.tensorflow.org/versions/r1.12/api_docs/python/tf/data/experimental/SqlDataset?hl=en) to construct one of these.\r\n\r\nOnce you have a dataset (lets call it sql_ds) with the information, you can do the following\r\n\r\ndef input_fn():\r\n  sql_ds = <create_sql_dataset>\r\n  ds = sql_ds.apply(tf.data.experimental.copy_to_device(\"/gpu:0\")).prefetch(1)\r\n  return ds\r\n\r\nEstimators allow returning datatsets in their input fn and things should flow from there.\r\n\r\nFor the CSV input fn and other cases, just use different input dataset (CSVDataset for example: https://www.tensorflow.org/api_docs/python/tf/data/experimental/CsvDataset?hl=en)", "Same problem with pandas_input_fn. Less than 10% GPU utilization on my brand new RTX 2080 TI... I spent all that money and I can process just as fast on a multi-core AMD CPU??? I don't get it. How are the \"big boys\" using these cards to get speedup?\r\n", "> It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?\r\n\r\nWell, I've been focusing on learning 2.0 so I haven't focused on this - but still not getting over 15% GPU utilization (with very short bursts to 25%) no matter what I do.  Is there any example I can download to demonstrate full GPU utilization? That would be really helpful.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=13530\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=13530\">No</a>\n", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 13529, "title": "skip some single example when reading tfrecords", "body": "I have created several tfrecords files that containing images, labels, or other information. \r\nWhen reading tfrecords, can I skip some samples according to the information after `tf.parse_single_example`. For example, I want to select those samples with certain labels or those sample with the image size larger than the threshold. \r\n\r\nI don't know how to do it in the current version. I hope you will support this feature in the future.", "comments": ["(This is probably more suited as a Stack Overflow question...) If you write your input pipeline using `tf.contrib.data`, you can use the [`Dataset.filter()`](https://www.tensorflow.org/api_docs/python/tf/contrib/data/Dataset#filter) method to skip records based on a user-defined predicate.", "I have tried using `tf.contrib.data`, if I skip some samples, then the `Dataset.filter()` returns None, which will raise the error.\r\n\r\nHere is what I did:\r\n\r\n    ```\r\n    def filter_fn(self, image, label):\r\n    \u00a6   if label == 1:\r\n    \u00a6   \u00a6   return image, label\r\n    \u00a6   else:\r\n    \u00a6   \u00a6   pass\r\n\r\n    def input(self, data_type='train') :\r\n    \u00a6   if data_type == 'train':\r\n    \u00a6   \u00a6   filenames = self.train_file\r\n    \u00a6   elif data_type == 'val':\r\n    \u00a6   \u00a6   filenames = self.val_file\r\n    \u00a6   else:\r\n    \u00a6   \u00a6   raise NotImplementationError()\r\n\r\n    \u00a6   dataset = tf.contrib.data.TFRecordDataset(filenames)\r\n    \u00a6   dataset = dataset.map(self.parse_fn, num_threads=self.num_threads)\r\n    \u00a6   # dataset = dataset.shuffle(buffer_size=10000)\r\n    \u00a6   dataset = dataset.filter(self.filter_fn)\r\n    \u00a6   dataset = dataset.batch(self.batch_size)\r\n    \u00a6   dataset = dataset.repeat()\r\n    \u00a6   dataset = dataset.make_one_shot_iterator()\r\n    \u00a6   return dataset.get_next()\r\n```\r\n\r\nThen it raises the error:\r\n\r\n  File \"new_data.py\", line 160, in input\r\n    dataset = dataset.filter(self.filter_fn)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/data/python/ops/dataset_ops.py\", line 1072, in filter\r\n    return FilterDataset(self, predicate)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/data/python/ops/dataset_ops.py\", line 1916, in __init__\r\n    self._predicate.add_to_graph(ops.get_default_graph())\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/function.py\", line 449, in add_to_graph\r\n    self._create_definition_if_needed()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/data/python/framework/function.py\", line 168, in _create_definition_if_needed\r\n    outputs = self._func(*inputs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/data/python/ops/dataset_ops.py\", line 1908, in tf_predicate\r\n    ret = ops.convert_to_tensor(ret, dtype=dtypes.bool)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 611, in convert_to_tensor\r\n    as_ref=False)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 676, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 121, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 102, in constant\r\n    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_util.py\", line 364, in make_tensor_proto\r\n    raise ValueError(\"None values not supported.\")\r\nValueError: None values not supported.\r\n\r\n", "`filter_fn` should return a `tf.bool` tensor, evaluating to true if you want to keep the record, and false if you want to skip it.", "Thank you very much!"]}, {"number": 13528, "title": "Add an actionable error message for build_info ImportError", "body": "This `import` statement is now the first point where we attempt to import a generated file, and hence could see a failure if the user tries to `import tensorflow` from the root of the git repository source tree. When this `import` fails, raise a more actionable error message.\r\n\r\nFixes #13526.", "comments": ["Test failure in `DropStaleGradientOptimizerTest` looks unrelated: https://ci.tensorflow.org/job/tensorflow-pull-requests-cpu-python3/6874/consoleFull\r\n\r\nShould I kick off another round of tests, or is this good to merge?"]}, {"number": 13527, "title": "R1.3", "body": "(I meant to merge to my own branch not to r1.3, please ignore)\r\nfirst success attempt to use OpenCV in Tensorflow C++", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "Closing since this is an accidental merge. r1.3 is closed for commits."]}, {"number": 13526, "title": "Importing TF in Python yields 'cannot import name 'build_info'", "body": "### System information\r\nFedora 26 x64 (4.13.4-200.fc26.x86_64)\r\nTensorflow installed from source:\r\n```\r\ntf.VERSION = 1.3.0\r\ntf.GIT_VERSION = b'v1.3.0-rc1-3011-gd86448938'\r\ntf.COMPILER_VERSION = b'v1.3.0-rc1-3011-gd86448938'\r\n```\r\nPython version 3.6.2 (Anaconda)\r\nBazel installed from their Fedora/COPR repositories, version 0.6.0- (@non-git)\r\nNo CUDA (or compatible GPU)\r\nIntel MKL 2018.0.128\r\nc++ (GCC) 7.2.1 20170915 (Red Hat 7.2.1-2)\r\n`bazel build -c opt --config=mkl //tensorflow/tools/pip_package:build_pip_package`\r\nNotice the `mkl` flag in the bazel build\r\n\r\n### Describe the problem\r\nConfiguration and bazel build finished without error. When attempting to import tensorflow in Python, I get this:\r\n\r\n```\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/torstein/progs/tensorflow/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"/home/torstein/progs/tensorflow/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/home/torstein/progs/tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 25, in <module>\r\n    from tensorflow.python.platform import self_check\r\n  File \"/home/torstein/progs/tensorflow/tensorflow/python/platform/self_check.py\", line 24, in <module>\r\n    from tensorflow.python.platform import build_info\r\nImportError: cannot import name 'build_info'\r\n```", "comments": ["Does this only affect `--config=mkl` builds?", "Actually, is `/home/torstein/progs/tensorflow` the directory in which you built TensorFlow?", "Yes, that is correct\n\n2017-10-06 17:50 GMT+02:00 Derek Murray <notifications@github.com>:\n\n> Actually, is /home/torstein/progs/tensorflow the directory in which you\n> built TensorFlow?\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/13526#issuecomment-334792606>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AGd9xEM_oDuRzi8cXHvsR866ewHp1C_fks5spkwvgaJpZM4PwnOJ>\n> .\n>\n", "OK, I think it should work if you `cd` out of that directory. `build_info.py` is a generated file and from the stack trace it looks like Python is trying to `import tensorflow` from the source tree, which doesn't contain any generated files.\r\n\r\nThis has tripped us up before, and `build_info` recently became the first generated file that we attempt to import. I've sent PR #13528 to add a better error message.", "You were right. Starting Python from another directory does not result in the error.\r\n\r\nThank you", "Thanks for confirming (and for raising the issue in the first place... now we have a much better error message in place)!", "Hi,\r\n can anyone tell me how can fix this error  i am runnig manage.py file but i am getting this error\r\n\r\n\r\nC:\\Users\\Dhanesh\\Desktop\\Check it Please\\ChatterBot-master\\examples\\django_app>python manage.py\r\nTraceback (most recent call last):\r\n  File \"manage.py\", line 10, in <module>\r\n    execute_from_command_line(sys.argv)\r\n  File \"C:\\Users\\Dhanesh\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 350, in execute_from_command_line\r\n    utility.execute()\r\n  File \"C:\\Users\\Dhanesh\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 324, in execute\r\n    django.setup()\r\n  File \"C:\\Users\\Dhanesh\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\django\\__init__.py\", line 18, in setup\r\n    apps.populate(settings.INSTALLED_APPS)\r\n  File \"C:\\Users\\Dhanesh\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\django\\apps\\registry.py\", line 85, in populate\r\n    app_config = AppConfig.create(entry)\r\n  File \"C:\\Users\\Dhanesh\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\django\\apps\\config.py\", line 116, in create\r\n    mod = import_module(mod_path)\r\n  File \"C:\\Users\\Dhanesh\\AppData\\Local\\Programs\\Python\\Python35\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 944, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 664, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 634, in _load_backward_compatible\r\n  File \"C:\\Users\\Dhanesh\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\chatterbot-0.7.6-py3.5.egg\\chatterbot\\__init__.py\", line 4, in <module>\r\n  File \"C:\\Users\\Dhanesh\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\chatterbot-0.7.6-py3.5.egg\\chatterbot\\chatterbot.py\", line 4, in <module>\r\n  File \"C:\\Users\\Dhanesh\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\chatterbot-0.7.6-py3.5.egg\\chatterbot\\input\\__init__.py\", line 2, in <module>\r\n  File \"C:\\Users\\Dhanesh\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\chatterbot-0.7.6-py3.5.egg\\chatterbot\\input\\microsoft.py\", line 4, in <module>\r\nImportError: cannot import name 'Statement'"]}, {"number": 13525, "title": "Fix for AVX2 support in Visual Studio", "body": "This is a fix for issue #10199. Visual Studio 2015 (possibly other versions) lacks definitions for  _mm256_extract_epi8, -16, -32, or -64 in the immintrin.h header, nor in the associated runtime, so it must be implemented manually.\r\n\r\nFor wider portability these functions are renamed based on their required extraction indices. These intrinsics should be just as fast as the externally linked versions provided by GCC.", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Also note that AVX and AVX2 are not enabled by default in CMakeLists.txt, even when native arch optimization is enabled. I will place another pull request to fix this in the future, along with a number of other CMake fixes.", "Jenkins, test this please.", "Jenkins, test this please.", "Looks like the CI server is having some unrelated failures? Is that common?", "Unfortunately more common than we would like.\r\nRetrying tests.\r\nJenkins, test this please.", "The change looks good to me, but I'll defer to @benoitsteiner since it's in Eigen code. (I'm not sure how or whether we pull in Eigen code from other repositories, and whether it would be better to make the change upstream first.)", "@scottmudge, thanks for your job about avx2, great!\r\nI pulled the latest tensorflow project which included your commits about avx2 and compiled successfully by command:\r\ncmake .. -A x64 -DCMAKE_BUILD_TYPE=Release -DSWIG_EXECUTABLE=C:\\D\\tools\\swigwin-3.0.12\\swig.exe -DPYTHON_EXECUTABLE=C:\\D\\tools\\Anaconda3\\python.exe -DPYTHON_LIBRARIES=C:\\D\\tools\\Anaconda3\\python35.lib -Dtensorflow_ENABLE_GPU=ON -DCUDNN_HOME=\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\" -Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX\r\n\r\nbut it still hints when running,\r\nYour CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n\r\nWhat else should I do to enable AVX2 for tensorflow on WINDOWS? Thanks so much.\r\n\r\nFrank", "Hey Frank,\r\n\r\nYes the CMakeLists.txt file in TensorFlow needs some modifications; it does not properly set the AVX/AVX2 flags. \r\n\r\nFind this line in the CMakeLists.txt file in ./tensorflow/contrib/cmake/:\r\n\r\n```\r\nif (tensorflow_OPTIMIZE_FOR_NATIVE_ARCH)\r\n  include(CheckCXXCompilerFlag)\r\n  CHECK_CXX_COMPILER_FLAG(\"-march=native\" COMPILER_OPT_ARCH_NATIVE_SUPPORTED)\r\n  if (COMPILER_OPT_ARCH_NATIVE_SUPPORTED)\r\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -march=native\")\r\n  endif()\r\nendif()\r\n```\r\n\r\nAnd change it to:\r\n\r\n```\r\nif (tensorflow_OPTIMIZE_FOR_NATIVE_ARCH)\r\n  include(CheckCXXCompilerFlag)\r\n  CHECK_CXX_COMPILER_FLAG(\"-march=native\" COMPILER_OPT_ARCH_NATIVE_SUPPORTED)\r\n  if (WIN32)\r\n\t  if (COMPILER_OPT_ARCH_NATIVE_SUPPORTED)\r\n\t\tset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /arch:AVX /arch:AVX2\")\r\n\t  endif()\r\n  else()\r\n\tif (COMPILER_OPT_ARCH_NATIVE_SUPPORTED)\r\n\t\tset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -march=native\")\r\n\tendif()\r\n  endif()\r\nendif()\r\n```\r\n\r\nSort of a hacky way to force enable it, but it'll do the job for now. I need to do another pull request with a better fix. \r\n\r\nIf you get error C1001 when compiling with GPU support, take a look at this thread:\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/9470\r\n\r\nI'm not sure if it does it on the master branch, but I had the problem as of v1.3.1", "@scottmudge \r\n\r\nI tried your hacky way, but it still indicated the issue of \u201cwas not compiled to use: AVX2\u201d. I noticed the information in configuration stage on my platform,\r\n-- Performing Test COMPILER_OPT_ARCH_NATIVE_SUPPORTED \r\n-- Performing Test COMPILER_OPT_ARCH_NATIVE_SUPPORTED - Failed \r\n-- Performing Test COMPILER_OPT_WIN_CPU_SIMD_SUPPORTED \r\n-- Performing Test COMPILER_OPT_WIN_CPU_SIMD_SUPPORTED - Success\r\n\r\nI got the code from tensorflow:master with the latest commit as follow,\r\ncommit 10c871ed92a1d9b36c5e2e3a674d5812c67e82a1 \r\nMerge: 87ac9901b 188297f80 \r\nAuthor: Shanqing Cai <cais@google.com> \r\nDate: Mon Oct 9 09:34:12 2017 -0400\r\n\r\nFinally I modified one line in CMakeLists.txt with adding \"/arch:AVX2\", and it seems to work. Haha, it is another hacky way.\r\n\r\n_if (tensorflow_WIN_CPU_SIMD_OPTIONS)\r\n  if (WIN32)\r\n    CHECK_CXX_COMPILER_FLAG(\"${tensorflow_WIN_CPU_SIMD_OPTIONS}\" COMPILER_OPT_WIN_CPU_SIMD_SUPPORTED)\r\n    if(COMPILER_OPT_WIN_CPU_SIMD_SUPPORTED)\r\n      set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} ${tensorflow_WIN_CPU_SIMD_OPTIONS} **/arch:AVX2**\")\r\n    else()\r\n      message(FATAL_ERROR \"${tensorflow_WIN_CPU_SIMD_OPTIONS} not supported\")\r\n    endif()\r\n  endif()\r\nendif()_\r\n\r\nThanks so much for your help.", "@yang0773\r\nCan you please share python wheels for Windows with AVX2 support? \r\nI've been trying to build tensorflow for couple of days, but still get stupid fatal error C1002...", "@iNomaD Here is one I compiled, v1.3.1 w/ AVX2, GPU (up to CUDA 6.1), x64 for Windows:\r\n\r\nhttps://github.com/scottmudge/tensorflow/releases/download/v1.3.1_mod/tensorflow_gpu-1.3.1-cp36-cp36m-win_amd64.whl", "Actually tf on windows can be built like this:\r\n```\r\ncmake .. -A x64 -DCMAKE_BUILD_TYPE=Release ^\r\n-DSWIG_EXECUTABLE=C:\\local\\swigwin-3.0.10\\swig.exe ^\r\n-DPYTHON_EXECUTABLE=C:\\local\\Anaconda3-4.1.1-Windows-x86_64\\python.exe ^\r\n-DPYTHON_LIBRARIES=C:\\local\\Anaconda3-4.1.1-Windows-x86_64\\libs\\python35.lib ^\r\n-Dtensorflow_ENABLE_GPU=ON ^\r\n-DCUDNN_HOME=\"C:\\local\\cudnn-8.0-v5.1\\cuda\" ^\r\n-Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX2\r\n```\r\nThe last option can be: =/arch:AVX2, then log \"Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\" is disappeared.\r\n", "can you build it using AVX2 and AVX at the same time? ", "https://docs.microsoft.com/en-us/cpp/preprocessor/predefined-macros\r\n\r\nIn Visual C++, when you set `/arch:AVX2` both AVX and AVX2 are used."]}, {"number": 13524, "title": "Why is gen_ctc_op not visible in the github repository?", "body": "I want to take a look at the core of the ctc_loss implementation, and looking at ctc_ops.py shows it's imported from the gen_ctc_ops module but that module is impossible to find in the github repository. Where can I find it?\r\nThanks", "comments": ["btw, this question was answered on stackoverflow", "Could you share the link of the question please?", "https://stackoverflow.com/questions/41147734/looking-for-source-code-of-from-gen-nn-ops-in-tensorflow/"]}, {"number": 13523, "title": "Float variable in loop not incremented properly", "body": "Hi,\r\n\r\nI am running the following code in tensorflow:\r\n\r\nimport tensorflow as tf\r\n\r\ncount = tf.get_variable(\"count\", shape=(), dtype=tf.float32, trainable=False)\r\ntf.assign(count, 0)\r\ni = tf.get_variable(\"i\", shape=(), dtype=tf.int32, trainable=False)\r\ntf.assign(i, 0)\r\n\r\ncond = lambda i, count: tf.less(i, 5)\r\nbody = lambda i, count: (tf.add(i,1), tf.add(count, 1))\r\ni, count = tf.while_loop(cond, body, [i, count], shape_invariants=[tf.TensorShape(None), tf.TensorShape(None)])\r\n\r\ninit = tf.global_variables_initializer()\r\n\r\nwith tf.Session() as session:\r\n    session.run(init)\r\n    print(\"i\", session.run(i), \"count\", session.run(count))\r\n\r\nThe expected result is that both, count and i have value 5. However, for count I get always different strange results like 6.18427 5.47266 5.81323\r\n\r\nHowever, when I change the datatype of count to tf.int32, it works as expected.\r\n\r\nUbuntu 16.04 64 Bit\r\nTF Version: v1.2.0-5-g435cdfc 1.2.1\r\nPython 3.5.2\r\n", "comments": ["I think I see the source of confusion: those `tf.assign()` calls don't actually perform the assignment, but rather create an operation that you have to run in order to perform the assignment. See [this Stack Overflow answer](https://stackoverflow.com/a/34220750/3574081).\r\n\r\n(The \"different strange results\" are due to the fact that the default initializer for [`tf.get_variable()`](https://www.tensorflow.org/api_docs/python/tf/get_variable) uses random values.)"]}, {"number": 13522, "title": "Cannot register 2 metrics with the same name error.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nSwift API for TensorFlow\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nmacOS 10.12.6 (16G29), Darwin MacBookPro.local 16.7.0 Darwin Kernel Version 16.7.0\r\n- **TensorFlow installed from (source or binary)**:\r\nsource\r\n- **TensorFlow version (use command below)**:\r\nmaster branch [d864489]\r\n- **Python version**: \r\nPython 2.7.13\r\n- **Bazel version (if compiling from source)**:\r\nbazel release 0.5.4\r\n- **CUDA/cuDNN version**:\r\nno\r\n- **GPU model and memory**:\r\nno\r\n- **Exact command to reproduce**:\r\n\r\nDear TensorFlow contributors, \r\n I am working on swift height-level API for TensorFlow. To provide that, I am [using system module](https://github.com/apple/swift-package-manager/blob/master/Documentation/Usage.md#require-system-libraries) to provide access to C and C++ API. C API is clear in swift code, for C++ library I am writing my own wrappers. After update master branch I can't pass tests in my framework. Launch tests leads to error: \r\n> Cannot register 2 metrics with the same name: /tensorflow/cc/saved_model/load_attempt_count\r\n\r\nMy guess is:\r\nAfter commit [a674130] ''Expose C API symbols on OS X\", all C API available on C++ library. \r\n[more info](https://github.com/tensorflow/tensorflow/pull/12741)\r\nYou can see all C interfaces are available at C++ library:\r\n`\r\n$ nm bazel-bin/tensorflow/libtensorflow_cc.so | grep 'TF_New'\r\n000000000000f5f0 T _TF_NewBuffer\r\n000000000000f610 T _TF_NewBufferFromString\r\n000000000000f6b0 T _TF_NewDeprecatedSession\r\n00000000000176f0 T _TF_NewGraph\r\n0000000000017aa0 T _TF_NewImportGraphDefOptions\r\n0000000000013190 T _TF_NewOperation\r\n000000000001a170 T _TF_NewSession\r\n000000000000f500 T _TF_NewSessionOptions\r\n000000000000ea90 T _TF_NewStatus\r\n000000000000ee80 T _TF_NewTensor\r\n0000000000018a70 T _TF_NewWhile\r\n000000000001cbb0 t __ZZ22TF_NewBufferFromStringEN3$_08__invokeEPvm\r\n`\r\n\r\nSo, my question/request is: \r\n1) Is it well-considered and final decision to provide C API in C++ library?\r\n2) Will it be default and public configuration to provide C API in C++ library?\r\n3) Is there any way to configure and build tensorflow library without changing \r\n`tools/tf_env_collect.sh` file?\r\nThank you for your work. ", "comments": ["I'm sorry, but from your description I'm not quite certain what the problem is. On the surface it seems the same initializers are being linked into your binary multiple times and precisely why that is happening isn't clear to me as I'm not sure about the details of the process being used to link. Unfortunately, the TensorFlow maintainers do not have enough background in Swift to be helpful there. Perhaps you could look at how other Swift bindings such as https://github.com/PerfectlySoft/Perfect-TensorFlow work?\r\n", "Hello,  \r\n >>On the surface it seems the same initializers are being linked into your binary multiple times...\r\n\r\nAs you can see, any binary has only one  linking: \r\n```\r\n\r\n$ otool -L ./.build/x86_64-apple-macosx10.10/debug/OpProducer\r\n./.build/x86_64-apple-macosx10.10/debug/OpProducer:\r\n\t/System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation (compatibility version 150.0.0, current version 1443.13.0)\r\n\t/usr/local/opt/protobuf/lib/libprotobuf.14.dylib (compatibility version 15.0.0, current version 15.0.0)\r\n\t/server/repository/tensorflow/bazel-out/darwin_x86_64-opt/bin/tensorflow/libtensorflow_cc.so (compatibility version 0.0.0, current version 0.0.0)\r\n\t/server/repository/tensorflow/bazel-out/darwin_x86_64-opt/bin/tensorflow/libtensorflow.so (compatibility version 0.0.0, current version 0.0.0)\r\n\t/usr/lib/libobjc.A.dylib (compatibility version 1.0.0, current version 228.0.0)\r\n\t/usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1252.0.0)\r\n\t/System/Library/Frameworks/Foundation.framework/Versions/C/Foundation (compatibility version 300.0.0, current version 1443.14.0)\r\n\t@rpath/libswiftCore.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftCoreFoundation.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftCoreGraphics.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftDarwin.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftDispatch.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftFoundation.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftIOKit.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftObjectiveC.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftSwiftOnoneSupport.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n```\r\nThe same with tests: \r\n\r\n```\r\n$ otool -L ./.build/x86_64-apple-macosx10.10/debug/TensorFlowPackageTests.xctest/Contents/MacOS/TensorFlowPackageTests\r\n./.build/x86_64-apple-macosx10.10/debug/TensorFlowPackageTests.xctest/Contents/MacOS/TensorFlowPackageTests:\r\n\t/System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation (compatibility version 150.0.0, current version 1443.13.0)\r\n\t/usr/local/opt/protobuf/lib/libprotobuf.14.dylib (compatibility version 15.0.0, current version 15.0.0)\r\n\t/server/repository/tensorflow/bazel-out/darwin_x86_64-opt/bin/tensorflow/libtensorflow_cc.so (compatibility version 0.0.0, current version 0.0.0)\r\n\t/server/repository/tensorflow/bazel-out/darwin_x86_64-opt/bin/tensorflow/libtensorflow.so (compatibility version 0.0.0, current version 0.0.0)\r\n\t/usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 400.9.0)\r\n\t/usr/lib/libobjc.A.dylib (compatibility version 1.0.0, current version 228.0.0)\r\n\t/usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1252.0.0)\r\n\t/System/Library/Frameworks/Foundation.framework/Versions/C/Foundation (compatibility version 300.0.0, current version 1443.14.0)\r\n\t@rpath/XCTest.framework/Versions/A/XCTest (compatibility version 1.0.0, current version 13201.0.0)\r\n\t@rpath/libswiftAppKit.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftCore.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftCoreData.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftCoreFoundation.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftCoreGraphics.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftCoreImage.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftDarwin.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftDispatch.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftFoundation.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftIOKit.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftMetal.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftObjectiveC.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftQuartzCore.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftSwiftOnoneSupport.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftXCTest.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftXPC.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n```\r\nAre there any way to trace library code ?", "I rebuild build without C++ API and C++ library\r\n\r\n```\r\notool -L ./.build/x86_64-apple-macosx10.10/debug/OpProducer\r\n./.build/x86_64-apple-macosx10.10/debug/OpProducer:\r\n\t/System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation (compatibility version 150.0.0, current version 1443.13.0)\r\n\t/usr/local/opt/protobuf/lib/libprotobuf.14.dylib (compatibility version 15.0.0, current version 15.0.0)\r\n\t/server/repository/tensorflow/bazel-out/darwin_x86_64-opt/bin/tensorflow/libtensorflow.so (compatibility version 0.0.0, current version 0.0.0)\r\n\t/usr/lib/libobjc.A.dylib (compatibility version 1.0.0, current version 228.0.0)\r\n\t/usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1252.0.0)\r\n\t/System/Library/Frameworks/Foundation.framework/Versions/C/Foundation (compatibility version 300.0.0, current version 1443.14.0)\r\n\t@rpath/libswiftCore.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftCoreFoundation.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftCoreGraphics.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftDarwin.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftDispatch.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftFoundation.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftIOKit.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftObjectiveC.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n\t@rpath/libswiftSwiftOnoneSupport.dylib (compatibility version 1.0.0, current version 900.0.65)\r\n```\r\n\r\nAnd that is works fine. It means, that I can't use C and C++ libraries in the same code at the same time.\r\nBut in **r1.3** it is **works**. That means, somebody (I think @fritzo at [a651023](https://github.com/tensorflow/tensorflow/commit/a6510237f06f03babfbcce1bcfa77f07f0d03c50)) added C code to C++ library. And after that you can't use both libraries in your code.\r\nI tried build only with C++ library, but unfortunately It doesn't work. There is no enough implementation C code in C++ library.  \r\n\r\n\r\n", "Rebuild with latest changes in master only with C++ library. \r\nYes, it is works fine on mac os. Linking passed, tests passed.\r\nOn Linux (Linux kraken 4.4.0-96-generic #119-Ubuntu SMP Tue Sep 12 14:59:54 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux):\r\n+ Build and run C API related code.\r\n- Can't link C++ code in binary and tests, error:\r\n```\r\n$ swift build --product OpProducer -Xcxx -std=c++11\r\nCompile CCAPI EventsWriter.cc\r\nCompile Swift Module 'OpProducer' (3 sources)\r\nLinking ./.build/x86_64-unknown-linux/debug/OpProducer\r\n/server/repository/TensorFlow/Sources/CCAPI/EventsWriter.cc:32: error: undefined reference to 'tensorflow::Event::Event()'\r\n/server/repository/TensorFlow/Sources/CCAPI/EventsWriter.cc:36: error: undefined reference to 'tensorflow::EventsWriter::WriteEvent(tensorflow::Event const&)'\r\n/server/repository/TensorFlow/Sources/CCAPI/EventsWriter.cc:38: error: undefined reference to 'tensorflow::Event::~Event()'\r\n/server/repository/TensorFlow/Sources/CCAPI/EventsWriter.cc:38: error: undefined reference to 'tensorflow::Event::~Event()'\r\n/server/repository/TensorFlow/Sources/CCAPI/EventsWriter.cc:41: error: undefined reference to 'tensorflow::EventsWriter::EventsWriter(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'\r\n/server/repository/tensorflow/bazel-genfiles/tensorflow/core/util/event.pb.h:1105: error: undefined reference to 'tensorflow::Event::clear_what()'\r\n/server/repository/tensorflow/tensorflow/core/util/events_writer.h:46: error: undefined reference to 'tensorflow::EventsWriter::Close()'\r\n//usr/lib/gcc/x86_64-linux-gnu/5.4.0/../../../../include/c++/5.4.0/bits/unique_ptr.h:76: error: undefined reference to 'tensorflow::io::RecordWriter::~RecordWriter()'\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\n<unknown>:0: error: link command failed with exit code 1 (use -v to see invocation)\r\nerror: terminated(1): /usr/bin/swift-build-tool -f /server/repository/TensorFlow/.build/debug.yaml OpProducer\r\n```\r\nTested as static and dynamic (own) libraries. \r\nThe same with tests. [Log attached](https://www.octadero.com/wp-content/uploads/2017/10/build.log_.zip).\r\n\r\n\r\nFor example EventWriter wrapper is really simple: \r\n```\r\n#include \"include/EventsWriter.h\"\r\n#include \"tensorflow/core/framework/graph.pb.h\"\r\n#include \"tensorflow/core/util/events_writer.h\"\r\n\r\nusing namespace std;\r\nusing namespace tensorflow;\r\n\r\nvoid write(const void* serializedGraph, size_t serializedGraphSize, EventsWriter* writer, double wall_time, int64 step) {\r\n\t\r\n\tEvent event;\r\n\tevent.set_wall_time(wall_time);\r\n\tevent.set_step(step);\r\n\tevent.set_graph_def(serializedGraph, serializedGraphSize);\r\n\twriter->WriteEvent(event);\r\n\t\r\n}\r\n\r\nvoid createEventWriter(const void* serializedGraph, size_t serializedGraphSize, char * filePath, double wall_time, long long step) {\r\n\tEventsWriter eventsWriter(filePath);\r\n\twrite(serializedGraph, serializedGraphSize, &eventsWriter, wall_time, step);\r\n}\r\n```\r\n\r\n", "I tred to build that [example project](https://www.octadero.com/wp-content/uploads/2017/10/TFBuildTest.zip) with **r1.3** c++ library:\r\n\r\n```\r\nexport LD_LIBRARY_PATH=/server/repository/tensorflow_1.3/tensorflow/bazel-bin/tensorflow:/server/repository/tensorflow_1.3/protobuf/src/.libs/\r\nswift build -Xcxx -std=c++11 -Xlinker -L/server/repository/tensorflow_1.3/protobuf/src/.libs/ -Xlinker -lprotobuf -Xcxx -I/server/repository/tensorflow_1.3/tensorflow/tensorflow/contrib/makefile/downloads/nsync/public/ -Xcxx -I/server/repository/tensorflow_1.3/tensorflow/tensorflow/contrib/makefile/downloads/protobuf/src/ -Xcxx -I/server/repository/tensorflow_1.3/tensorflow/ -Xcxx -I/server/repository/tensorflow_1.3/tensorflow/bazel-genfiles -Xlinker -L/server/repository/tensorflow_1.3/tensorflow/bazel-bin/tensorflow -Xlinker -ltensorflow_cc \r\n``` \r\nIt is ok.\r\n[build log](https://www.octadero.com/wp-content/uploads/2017/10/simple_build_1.3.txt)\r\n\r\nAnd tried with **master** brunch:\r\n```\r\nexport LD_LIBRARY_PATH=/server/repository/tensorflow/bazel-bin/tensorflow:/usr/local/lib/\r\nswift build -Xcxx -std=c++11 -Xlinker -L/usr/local/lib -Xlinker -lprotobuf -Xcxx -I/server/repository/tensorflow/tensorflow/contrib/makefile/downloads/nsync/public/ -Xcxx -I/server/repository/tensorflow/tensorflow/contrib/makefile/downloads/protobuf/src/ -Xcxx -I/server/repository/tensorflow/ -Xcxx -I/server/repository/tensorflow/bazel-genfiles -Xlinker -L/server/repository/tensorflow/bazel-bin/tensorflow -Xlinker -ltensorflow_cc \r\n```\r\n\r\nError: \r\n```\r\n**/usr/bin/swiftc --driver-mode=swift -L /usr/lib/swift/pm/4 -lPackageDescription -swift-version 4 -I /usr/lib/swift/pm/4 -sdk / /server/repository/TFBuildTest/Package.swift -fileno 6\r\n/usr/bin/swift-build-tool -f /server/repository/TFBuildTest/.build/debug.yaml main -v\r\n/usr/bin/clang -target 'x86_64-unknown-linux' --sysroot / -fPIC -g '-O0' '-std=c++11' -I/server/repository/tensorflow/tensorflow/contrib/makefile/downloads/nsync/public/ -I/server/repository/tensorflow/tensorflow/contrib/makefile/downloads/protobuf/src/ -I/server/repository/tensorflow/ -I/server/repository/tensorflow/bazel-genfiles -fmodules -fmodule-name=CCAPI -I /server/repository/TFBuildTest/Sources/CCAPI/include '-fmodules-cache-path=/server/repository/TFBuildTest/.build/x86_64-unknown-linux/debug/ModuleCache' -MD -MT dependencies -MF '/server/repository/TFBuildTest/.build/x86_64-unknown-linux/debug/CCAPI.build/EventsWriter.cc.d' -c /server/repository/TFBuildTest/Sources/CCAPI/EventsWriter.cc -o '/server/repository/TFBuildTest/.build/x86_64-unknown-linux/debug/CCAPI.build/EventsWriter.cc.o'\r\narcr/server/repository/TFBuildTest/.build/x86_64-unknown-linux/debug/libCCAPI.a/server/repository/TFBuildTest/.build/x86_64-unknown-linux/debug/CCAPI.build/EventsWriter.cc.o\r\n/usr/bin/swiftc -module-name TFBuildTest -incremental -emit-dependencies -emit-module -emit-module-path /server/repository/TFBuildTest/.build/x86_64-unknown-linux/debug/TFBuildTest.swiftmodule -output-file-map /server/repository/TFBuildTest/.build/x86_64-unknown-linux/debug/TFBuildTest.build/output-file-map.json -num-threads 8 -c /server/repository/TFBuildTest/Sources/TFBuildTest/main.swift -I /server/repository/TFBuildTest/.build/x86_64-unknown-linux/debug -swift-version 4 -target x86_64-unknown-linux -sdk / -Onone -g -enable-testing -j8 -DSWIFT_PACKAGE -Xcc -fmodule-map-file=/server/repository/TFBuildTest/.build/x86_64-unknown-linux/debug/CCAPI.build/module.modulemap -I /server/repository/TFBuildTest/Sources/CCAPI/include -module-cache-path /server/repository/TFBuildTest/.build/x86_64-unknown-linux/debug/ModuleCache\r\n/usr/bin/swiftc -target 'x86_64-unknown-linux' -sdk / -Xlinker -L/usr/local/lib -Xlinker -lprotobuf -Xlinker -L/server/repository/tensorflow/bazel-bin/tensorflow -Xlinker -ltensorflow_cc -lstdc++ -g -L '/server/repository/TFBuildTest/.build/x86_64-unknown-linux/debug' -o '/server/repository/TFBuildTest/.build/x86_64-unknown-linux/debug/TFBuildTest' -module-name TFBuildTest -emit-executable -Xlinker '-rpath=$ORIGIN' '/server/repository/TFBuildTest/.build/x86_64-unknown-linux/debug/CCAPI.build/EventsWriter.cc.o' '/server/repository/TFBuildTest/.build/x86_64-unknown-linux/debug/TFBuildTest.build/main.swift.o'\r\n/server/repository/TFBuildTest/Sources/CCAPI/EventsWriter.cc:26: error: undefined reference to 'tensorflow::Event::Event()'\r\n/server/repository/TFBuildTest/Sources/CCAPI/EventsWriter.cc:30: error: undefined reference to 'tensorflow::EventsWriter::WriteEvent(tensorflow::Event const&)'\r\n/server/repository/TFBuildTest/Sources/CCAPI/EventsWriter.cc:32: error: undefined reference to 'tensorflow::Event::~Event()'\r\n/server/repository/TFBuildTest/Sources/CCAPI/EventsWriter.cc:32: error: undefined reference to 'tensorflow::Event::~Event()'\r\n/server/repository/TFBuildTest/Sources/CCAPI/EventsWriter.cc:35: error: undefined reference to 'tensorflow::EventsWriter::EventsWriter(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'\r\n/server/repository/tensorflow/bazel-genfiles/tensorflow/core/util/event.pb.h:1105: error: undefined reference to 'tensorflow::Event::clear_what()'\r\n/server/repository/tensorflow/tensorflow/core/util/events_writer.h:46: error: undefined reference to 'tensorflow::EventsWriter::Close()'\r\n//usr/lib/gcc/x86_64-linux-gnu/5.4.0/../../../../include/c++/5.4.0/bits/unique_ptr.h:76: error: undefined reference to 'tensorflow::io::RecordWriter::~RecordWriter()'\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\n<unknown>:0: error: link command failed with exit code 1 (use -v to see invocation)\r\nerror: terminated(1): /usr/bin/swift-build-tool -f /server/repository/TFBuildTest/.build/debug.yaml main -v** \r\n```\r\n\r\n[build log](https://www.octadero.com/wp-content/uploads/2017/10/simple_build_master.txt)\r\n", "@VladimirRoaming I'm also somewhat confused by your description of the problem.  Let me attempt to re-phrase the questions I think you're asking:\r\n\r\n1) Are `libtensorflow.so` and `libtensorflow_cc.so` intended to be used together, or separately?  I.e. is the user allowed to link both into the same binary?\r\n\r\n2) Should we expect that C API symbols are exported via `libtensorflow_cc.so`?  Or should they only be exported via `libtensorflow.so`?\r\n\r\n3) It seems that the behavior has changed between r1.3 and master on MacOS, possibly due to a651023.\r\n\r\n@asimshankar Perhaps you can comment on these questions.", "@VladimirRoaming : Can you reduce the problem to linking of a C++ binary? From what you've shared, it's hard for us to comment since there are many layers (including swift code which we're not familiar with) to wade through. \r\n\r\nThat said, I think [the change to split the TensorFlow shared libraries](https://github.com/tensorflow/tensorflow/commit/5c7f9e316d8c7735308a217310350d416d7498cc) into `libtensorflow_framework.so` + language API (e.g., `libtensorflow.so` for C, `libtensorflow_cc.so` for C++, `pywrap_tensorflow.so` for Python) is the one that is probably causing you trouble. As a result of this change, most of the framework symbols are in `libtensorflow_framework.so` now. And from the error messages above, it seems that the linker was having trouble finding `tensorflow::Event::Event()`, which will be in that library.\r\n\r\nThe fix should be simple enough, include `-ltensorflow_framework.so` in your command-line.\r\n(This change [is mentioned in the updated documentation](https://github.com/tensorflow/tensorflow/commit/5c7f9e316d8c7735308a217310350d416d7498cc#diff-4bef2b6f872037e4e6daaf3b93c6f253), however the documentation on tensorflow.org is tied to the latest stable release, not the master branch at github).\r\n\r\n\r\nAs an example, I did the following on Linux which seems to work out well:\r\n\r\n```sh\r\n# Build the C++ library from source\r\nbazel build -c opt //tensorflow:libtensorflow_cc.so\r\n\r\n# Create the test program\r\ncat >/tmp/test.cc <<EOF\r\n#include \"tensorflow/core/framework/graph.pb.h\"\r\n#include \"tensorflow/core/util/events_writer.h\"\r\n\r\nint main() {\r\n  tensorflow::EventsWriter writer(\"/tmp/events\");\r\n  writer.WriteEvent(tensorflow::Event());\r\n  writer.Close();\r\n}\r\nEOF\r\n\r\n# Build the test program\r\nEXTERNAL_DIR=\"$(bazel info output_base)/external\"\r\ng++ /tmp/test.cc \\\r\n -std=c++11 \\\r\n -I. -Ibazel-genfiles \\\r\n -I ${EXTERNAL_DIR}/protobuf_archive/src \\\r\n -I ${EXTERNAL_DIR}/nsync/public \\\r\n -Lbazel-bin/tensorflow -ltensorflow_cc -ltensorflow_framework\r\n\r\n# Run the test program\r\nLD_LIBRARY_PATH=bazel-bin/tensorflow ./a.out\r\n```\r\nAs for the questions Todd mentioned above:\r\n\r\n1. `libtensorflow_cc.so` is a strict superset of `libtensorflow.so` so you shouldn't have to link against both in the same binary. Though, this may change in the future.\r\n\r\n2. For now, yes, `libtensorflow_cc.so` exports all the symbols defined in the C API. Though, this may change in the future.\r\n\r\n3. If the analysis above is correct, this issue is not specific to macOS or Linux - in both you'll have to include `libtensorflow_framework.so` when linking/running, or build with `--config=monolithic`.\r\n\r\n", "Sorry for my flow of consciousness,\r\nI faced several issues in the new version and tried to resolve them.\r\nYes, you're absolutely right with those 3 points.\r\nThere is one more issue with linking phase at linux, I will describe it in a special ticket.", "@VladimirRoaming : It seems our posts might have collided. Does adding `-ltensorflow_framework` solve your issue? If not, please provide a short reproduction of the problem (similar to the commands and example program I shared above).", "Had to rebuild tensorflow from the scratch.\r\nYes, `-ltensorflow_framework` helped. Thanks a lot.", "Closing this issue out since it seems it has been addressed.", "I'm sorry to reopen this issue but I'm facing the same issue even with the solution proposed here. I'm using autotools to generate an executable file which is using opencv and tensorflow. To do this, i've set this libraries flags : AM_LDFLAGS = -lopencv_core -lopencv_imgproc -lopencv_highgui -lopencv_videoio -ltensorflow_cc -ltensorflow_framework -lprotobuf -lprotoc . My make command is working well but I'm trying to run my executable, I always have this error : \r\n\r\n`2020-06-09 14:02:25.158088: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/cc/saved_model/load_attempt_count\r\n2020-06-09 14:02:25.158383: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/cc/saved_model/load_latency\r\n2020-06-09 14:02:25.158467: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/cc/saved_model/load_latency_by_stage\r\n2020-06-09 14:02:25.159111: F tensorflow/core/framework/variant_op_registry.cc:53] Check failed: existing == nullptr (0x55a3931838 vs. nullptr)Unary VariantDecodeFn for type_name: tensorflow::data::WrappedDatasetVariant already registered\r\nAborted (core dumped)`\r\n\r\nAny suggestion would be much appreciated ! ", "> I'm sorry to reopen this issue but I'm facing the same issue even with the solution proposed here. I'm using autotools to generate an executable file which is using opencv and tensorflow. To do this, i've set this libraries flags : AM_LDFLAGS = -lopencv_core -lopencv_imgproc -lopencv_highgui -lopencv_videoio -ltensorflow_cc -ltensorflow_framework -lprotobuf -lprotoc . My make command is working well but I'm trying to run my executable, I always have this error :\r\n> \r\n> `2020-06-09 14:02:25.158088: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/cc/saved_model/load_attempt_count 2020-06-09 14:02:25.158383: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/cc/saved_model/load_latency 2020-06-09 14:02:25.158467: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/cc/saved_model/load_latency_by_stage 2020-06-09 14:02:25.159111: F tensorflow/core/framework/variant_op_registry.cc:53] Check failed: existing == nullptr (0x55a3931838 vs. nullptr)Unary VariantDecodeFn for type_name: tensorflow::data::WrappedDatasetVariant already registered Aborted (core dumped)`\r\n> \r\n> Any suggestion would be much appreciated !\r\n\r\nHave you solved it sir??I am also facing the same issue"]}, {"number": 13521, "title": "complex gradient update in optimization", "body": "Is there a plan to allow complex optimization in Tensorflow in the future?\r\n\r\nWhen you try to do it with version 1.3, you can calculate and evaluate gradients, but you cannot apply them with opt.apply_gradients(grds_and_vars). The error message you get is: \r\n\r\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'ApplyAdadelta' with these attrs.  Registered devices: [CPU,GPU], Registered kernels:\r\n  device='GPU'; T in [DT_DOUBLE]\r\n  device='GPU'; T in [DT_FLOAT]\r\n  device='GPU'; T in [DT_HALF]\r\n  device='CPU'; T in [DT_DOUBLE]\r\n  device='CPU'; T in [DT_FLOAT]\r\n  device='CPU'; T in [DT_HALF]\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo\r\n\r\n- **OS Platform and Distribution \r\nDistributor ID: Debian\r\nDescription:    Debian GNU/Linux 8.9 (jessie)\r\nRelease:        8.9\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\nusing pip install in a virtual conda environment\r\n\r\n- **TensorFlow version (use command below)**:\r\n1.3\r\n\r\n- **Python version**: \r\nPython 3.5.2 |Anaconda 4.3.0 (64-bit)| (default, Jul  2 2016, 17:53:06) \r\n\r\n- **Bazel version (if compiling from source)**:\r\nnot applicable\r\n\r\n- **CUDA/cuDNN version**:\r\n8.0/6.0\r\n\r\n- **GPU model and memory**:\r\nTesla K40c, 11439MiB\r\n\r\n- **Exact command to reproduce**:\r\nnot necessary, since feature request/question\r\n\r\n### Describe the problem\r\nproblem description above\r\n\r\n### Source code / logs\r\nnot applicable\r\n", "comments": ["@suharshs @kbsriram can you comment on future development plans, please?", "@suharshs will be able to speak authoritatively on this.\r\n\r\nFwiw, as a participant in the \"contributions welcome\" set the team has been very receptive to PRs improving gradient support, complex or otherwise. (Based on this error though, it might also reflect a general request to grow the set of ops with kernels that accept complex inputs.)", "cc: @asimshankar  @ebrevdo \r\n\r\nI don't believe anyone is actively working on this. To me this seems like a \"contributions welcome\" to add complex kernels for the desired ops.\r\n", "Seems like it should be easy enough for external contributors to add.  +1 for contributions welcome.", "Added PR #15402.", "Hi, I was trying to work with complex64 recently and still have the issue mentioned above. All the optimizers has the restriction to work on non-complex numbers only. \r\nHas the PR been merged? I was a bit confused from the closed message. \r\nThanks! ", "Are there any plans of adding complex values for optimization?", "This has been fixed in bf9c196f37b9cbb3109b2891aaf9da85bf5f712a. I should be included in the 2.1 release."]}, {"number": 13520, "title": "issue installing Tensorflow on NVIDIA Jetson TX2", "body": "Hello\r\n\r\nI am following this tutorial from Jetsonhacks to install Tensorflow on my NVIDIA Jetson TX2 board: http://www.jetsonhacks.com/2017/04/02/tensorflow-on-nvidia-jetson-tx2-development-kit/ \r\n\r\nThe situation: \r\n\r\nI ran a couple of provided scripts and seems like I ran into a bug, based on the error message I got. \r\n\r\n    - I haven't set up any swap memory\r\n    - normally CUDNN and CUDA should be properly installed, I installed them remotely via Jetpack\r\n    - df -h returns:\r\n\r\n\r\n    $ df -h\r\n    Filesystem      Size  Used Avail Use% Mounted on\r\n    /dev/mmcblk0p1   28G   19G  7.6G  71% /\r\n    none            7.0G     0  7.0G   0% /dev\r\n    tmpfs           7.7G  264K  7.7G   1% /dev/shm\r\n    tmpfs           7.7G   14M  7.7G   1% /run\r\n    tmpfs           5.0M  4.0K  5.0M   1% /run/lock\r\n    tmpfs           7.7G     0  7.7G   0% /sys/fs/cgroup\r\n    tmpfs           786M   72K  786M   1% /run/user/1001\r\n\r\n\r\n\r\nThe issue:\r\n\r\nWhen running the script provided by jetsonhacks: $ ./buildTensorFlow.sh\r\nI get this error message:\r\n\r\n    ERROR: /home/nvidia/tensorflow/tensorflow/core/kernels/BUILD:2183:1: C++ compilation of rule '//tensorflow/core/kernels:svd_op'     failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command \r\n      (cd /home/nvidia/.cache/bazel/_bazel_nvidia/d2751a49dacf4cb14a513ec663770624/execroot/org_tensorflow && \\\r\n      exec env - \\\r\n        CUDA_TOOLKIT_PATH=/usr/local/cuda \\\r\n        CUDNN_INSTALL_PATH=/usr/lib/aarch64-linux-gnu \\\r\n        GCC_HOST_COMPILER_PATH=/usr/bin/gcc \\\r\n        LD_LIBRARY_PATH=/home/nvidia/torch/install/lib:/home/nvidia/torch/install/lib: \\\r\n        PATH=/home/nvidia/torch/install/bin:/home/nvidia/torch/install/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \\\r\n        PWD=/proc/self/cwd \\\r\n        PYTHON_BIN_PATH=/usr/bin/python \\\r\n        PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \\\r\n        TF_CUDA_CLANG=0 \\\r\n        TF_CUDA_COMPUTE_CAPABILITIES=6.2 \\\r\n        TF_CUDA_VERSION=8.0 \\\r\n        TF_CUDNN_VERSION=5.1.10 \\\r\n        TF_NEED_CUDA=1 \\\r\n        TF_NEED_OPENCL=0 \\\r\n\r\n      external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE         '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-    frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -MD -MF bazel-out/local_linux-opt/bin    /tensorflow/core/kernels/_objs/svd_op/tensorflow/core/kernels/svd_op_complex64.pic.d '-frandom-seed=bazel-out/local_linux-    opt/bin/tensorflow/core/kernels/_objs/svd_op/tensorflow/core/kernels/svd_op_complex64.pic.o' -fPIC -DEIGEN_MPL2_ONLY -DSNAPPY -iquote . -iquote bazel-out/local_linux-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/local_linux-    opt/genfiles/external/bazel_tools -iquote external/protobuf -iquote bazel-out/local_linux-opt/genfiles/external/protobuf -iquote external/eigen_archive -iquote bazel-out/local_linux-opt/genfiles/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/local_linux-opt/genfiles/external/local_config_sycl -iquote external/gif_archive -iquote bazel-out/local_linux-opt/genfiles/external/gif_archive -iquote external/jpeg -iquote bazel-out/local_linux-opt/genfiles/external/jpeg -iquote external/com_googlesource_code_re2 -iquote bazel-out/local_linux-opt/genfiles/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/local_linux-opt/genfiles/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/local_linux-opt/genfiles/external/fft2d -iquote external/highwayhash -iquote bazel-out/local_linux-opt/genfiles/external/highwayhash -iquote external/png_archive -iquote bazel-out/local_linux-opt/genfiles/external/png_archive -iquote external/zlib_archive -iquote bazel-out/local_linux-opt/genfiles/external/zlib_archive -iquote external/snappy -iquote bazel-out/local_linux-opt/genfiles/external/snappy -iquote external/local_config_cuda -iquote bazel-out/local_linux-opt/genfiles/external/local_config_cuda -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/protobuf/src -isystem bazel-out/local_linux-opt/genfiles/external/protobuf/src -isystem external/eigen_archive -isystem bazel-out/local_linux-opt/genfiles/external/eigen_archive -isystem external/gif_archive/lib -isystem bazel-out/local_linux-opt/genfiles/external/gif_archive/lib -isystem external/farmhash_archive/src -isystem bazel-out/local_linux-opt/genfiles/external/farmhash_archive/src -isystem external/png_archive -isystem bazel-out/local_linux-opt/genfiles/external/png_archive -isystem external/zlib_archive -isystem bazel-out/local_linux-opt/genfiles/external/zlib_archive -isystem external/local_config_cuda/cuda -isystem bazel-out/local_linux-opt/genfiles/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/cuda/include -isystem bazel-out/local_linux-opt/genfiles/external/local_config_cuda/cuda/cuda/include -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare -fno-exceptions '-DGOOGLE_CUDA=1' -pthread '-DGOOGLE_CUDA=1' -no-canonical-prefixes -Wno-builtin-macro-redefined         '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fno-canonical-system-headers -c     tensorflow/core/kernels/svd_op_complex64.cc -o bazel-out/local_linux-opt/bin/tensorflow/core/kernels/_objs/svd_op/tensorflow/core/kernels/svd_op_complex64.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 4.\r\n    gcc: internal compiler error: Killed (program cc1plus)\r\n    Please submit a full bug report,\r\n    with preprocessed source if appropriate.\r\n    See <file:///usr/share/doc/gcc-5/README.Bugs> for instructions.\r\n    Target //tensorflow/tools/pip_package:build_pip_package failed to build\r\n    INFO: Elapsed time: 5924.737s, Critical Path: 813.48s[/code]\r\n    \r\n\r\nafter this error message I can't run this script: \r\n\r\n    $ ./packageTensorFlow.sh\r\n    ./packageTensorFlow.sh: line 3: cd: /home/nvidia/tensorflow: No such file or directory\r\n    ./packageTensorFlow.sh: line 4: bazel-bin/tensorflow/tools/pip_package/build_pip_package: No such file or directory\r\n    mv: cannot stat '/tmp/tensorflow_pkg/tensorflow-*.whl': No such file or directory\r\n\r\n\r\nWhat can I do to solve this issue so I can install Tensorflow as shown in this tutorial?\r\n\r\n", "comments": ["@andrewharp may have some ideas. That said, TensorFlow on platforms other than those covered by https://www.tensorflow.org/install/ are not supported by the TensorFlow maintainers (we unfortunately do not have the bandwidth to do so). You may want to contact the authors of the blog you pointed to.", "TensorFLow can be successfully installed on Jetson TX2."]}, {"number": 13519, "title": "Documentation mentions FeatureValueToId, but it's not found anywhere on the site.", "body": "The latest documentation on tensorflow.org expains that for embedding_lookup* functions ids are obtained typically from FeatureValueTold. The last term is not found anywhere else on the site. Probably some remnant from ancient functions.\r\n\r\nIt should probably be replaced with index_table_from* or something similar.\r\n", "comments": ["@smsorin could you add a link to the bad documentation, please? I'm not seeing \"FeatureValueTold\" on tensorflow.org, but it could be that I'm not searching well enough.", "https://www.tensorflow.org/versions/master/api_docs/python/tf/nn/embedding_lookup_sparse\r\n\r\nsp_ids: N x M SparseTensor of int64 ids (typically from FeatureValueToId), where N is typically batch size and M is arbitrary.\r\n\r\nI was seeing it on tf.nn.embedding_lookup as well but that seems to be fixed now.", "I think we got bit by the similarity of the glyphs for capital-i, and lowercase-L. \"FeatureValueToId\" gets a few more hits, while \"FeatureValueTold\" isn't on the site. \r\n\r\nHowever, even FeatureValueToId doesn't have much visible code or documentation. @zheng-xq, are the docs out of date (so we should remove the old reference and replace it with something more recent)?  ", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "@ysuematsu might have some ideas.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "opened internal bug.\r\n", "Nagging Assignee @alexgorban: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @alexgorban: It has been 16 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @alexgorban: It has been 47 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @alexgorban: It has been 62 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @alexgorban: It has been 77 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This should have been fixed around the end of April."]}, {"number": 13518, "title": "WIP: BUG: fix inconsistent scope for `tensorflow.python.layers.base.Layer`", "body": "It is proposed to fix #13429, however, I'm not sure whether it's the best solution. I'll finish the PR when I get back from holiday (next week).\r\n\r\n### How to test\r\n\r\n+ [ ] add test case.\r\n+ [ ] pass all tests.", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "@facaiy Can you rebase to master to resolve the conflict?", "Adding Eugene and Francois as they've been looking at Layers code more recently (I think I skipped some changes).", "Hi, @frankchn , it seems that master introduces a big change in `variable_scope.py`. I'll test nightly version. If bug still exists, I'll rebase master.\r\n\r\n@lukaszkaiser The bug is reported on `tf.layer` at first, however, I find that it seems from a little mistake in `variable_scope`.", "Could you make a smaller PR that only changes `variable_scope` first? I'd much rather do it in a 2-step way, as these changes can break things in a subtle way and it can be hard to figure out what broke what.", "The case is more subtle than I expected, so let's close the PR now and go to #13429 for discuss. I'll reopen the PR until the best solution is found."]}, {"number": 13517, "title": "Fix crash when `tf.pad` is used with int64 paddings.", "body": "This fix tries to fix the issue raised in #13506 where int64 data types for bounds in `tf.image.pad_to_bounding_box` crashes.\r\n\r\nThe reason of the crash is caused by the fact that int64 was directly converted into int32 without passing through kernel registeration.\r\n\r\nThis fix fixes the issue by adding `typename Tpadding` to the template and adds appropriate kernels.\r\n\r\nThis fix fixes #13506.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "Happy to review this but I'm on vacation until 10/9.\n\nOn Fri, Oct 6, 2017, 11:30 AM Frank Chen <notifications@github.com> wrote:\n\n> Jenkins, test this please.\n>\n> \u2014\n> You are receiving this because you were assigned.\n>\n>\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/13517#issuecomment-334818569>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AABnn8kJUKGmqRSt_f1QA3tefh5YoHvyks5spmO-gaJpZM4PwBFe>\n> .\n>\n", "Jenkins, test this please.", "Thanks @rryan for the review. The PR has been updated with alignment of `\\` fixed. Additional unit tests have also been added in `pad_op_test.py` for `int64`. Without the PR the new test case will trigger the crash.\r\n\r\nPlease take a look and let me know if there are any issues.", "LGTM, thanks!", "Jenkins, test this please.", "Jenkins, test this please.\r\n"]}, {"number": 13516, "title": "When using placeholder in MonitoredTrainingSession, summary called at first and not feed placeholder error", "body": "### System information\r\n\r\n== cat /etc/issue ===============================================\r\nVERSION=\"16.04.3 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== check pips ===================================================\r\nnumpy (1.13.3)\r\nprotobuf (3.4.0)\r\ntensorflow-gpu (1.3.0)\r\ntensorflow-tensorboard (0.1.5)\r\n\r\n== check for virtualenv =========================================\r\nTrue\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.3.0\r\ntf.GIT_VERSION = v1.3.0-rc2-20-g0787eee\r\ntf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH :/usr/local/cuda-8.0/lib64\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nFri Oct  6 11:16:46 2017       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 375.66                 Driver Version: 375.66                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX TIT...  Off  | 0000:01:00.0     Off |                  N/A |\r\n|  0%   54C    P0    52W / 250W |      0MiB / 12205MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-8.0/lib64/libcudart_static.a\r\n/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\r\n\r\n\r\n### Describe the problem\r\nI am using MonitoredTrainingSession. With both `tf.summary.scalar('test', d)` in graph and `checkpoint_dir='/temp',` as param, the error occurs. I assume it tries to summary all at the first and run `tf.summary.scalar('test', d)`. But I just want to run `a` and `b` to get the value, not activate any things relate to placeholder `h`. For people who will ask why you can't just feed a int, code of real I want to do is at last.\r\nI think this is a bug, or I do it in a wrong way?\r\n\r\n### Source code / logs\r\n```\r\nimport tensorflow as tf\r\n    \r\nwith tf.Graph().as_default():\r\n    global_step = tf.contrib.framework.get_or_create_global_step()\r\n\r\n    a = tf.constant(1, dtype=tf.int64)\r\n    b = tf.constant(2, dtype=tf.int64)\r\n    c = tf.add(a, b)\r\n\r\n    h = tf.placeholder(tf.int64)\r\n    d = tf.multiply(c, h)\r\n    tf.summary.scalar('test', d)\r\n\r\n    with tf.train.MonitoredTrainingSession(\r\n            checkpoint_dir='/temp',\r\n    ) as sess:\r\n        a_val, b_val = sess.run([a, b])\r\n```\r\n```\r\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype int64\r\n\t [[Node: Placeholder = Placeholder[dtype=DT_INT64, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\r\n\t [[Node: Const/_35 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_16_Const\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\n```\r\n\r\n\r\n**Code I real want to do**\r\n```\r\nimport tensorflow as tf\r\n\r\nwith tf.Graph().as_default():\r\n    global_step = tf.contrib.framework.get_or_create_global_step()\r\n    dataset_train = tf.contrib.data.Dataset.range(10)\r\n    dataset_val = tf.contrib.data.Dataset.range(90, 100)\r\n\r\n    iter_train_handle = dataset_train.make_one_shot_iterator().string_handle()\r\n    iter_val_handle = dataset_val.make_one_shot_iterator().string_handle()\r\n\r\n    handle = tf.placeholder(tf.string, shape=[])\r\n    iterator = tf.contrib.data.Iterator.from_string_handle(\r\n        handle, dataset_train.output_types, dataset_train.output_shapes)\r\n    next_batch = iterator.get_next()\r\n    tf.summary.scalar('test', next_batch)\r\n\r\n    with tf.train.MonitoredTrainingSession(\r\n            checkpoint_dir='/temp',\r\n    ) as sess:\r\n        handle_train, handle_val = sess.run([iter_train_handle, iter_val_handle])\r\n        for step in range(10):\r\n            print('train', sess.run(next_batch, feed_dict={handle: handle_train}))\r\n            if step % 3 == 0:\r\n                print('val', sess.run(next_batch, feed_dict={handle: handle_val}))\r\n```", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!\r\n\r\nThat said, `MonitoredTrainingSession` runs the summary operations and since your summary operation is connected to the placeholder, it is complaining about the missing feed.\r\n\r\nIf you do not want the features of the `MonitoredTrainingSession`, might I suggest using [`MonitoredSession`](https://www.tensorflow.org/api_docs/python/tf/train/MonitoredSession) or `Session` directly.\r\n\r\nClosing this out since it is not a bug or feature request (`MonitoredTrainingSession` intentionally tries to run summary operations at periodic intervals).", "@asimshankar I got it. Thank you for the comment. And sorry for taking your time to read.", "I had the same problem.\r\nI came with workaround:\r\nuse `sess._tf_sess()` instead of `sess` when you need to skip MonitoredSession internal behavior", "Hi, guys:\r\n@fumihwh\r\nThere is a demo for using placeholder in mot_session with SessionRunHook.\r\n[placeholder_mot_session](https://github.com/jke-zq/tensorflow120/blob/master/dataset_switch.py)", "@jke-zq  I use `MonitoredTrainingSession` with `SyncReplicasOptimizer`, I create the hook by `SyncReplicasOptimizer.make_session_run_hook` to initialize variables.\r\nIn `sync_replicas_optimizer.after_create_session`, I come cross the same problem about the placeholder of model.\r\nwhen `SyncReplicasOptimizer` initializing variables, it raises the feed_dict bug. Do you have any idea about this situation.", "I came across the same problem when using MonitoredTrainingSession instead of Superisor, error are following:\r\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [1,1]\r\n         [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[1,1], _device=\"/job:worker/replica:0/task:0/device:CPU:0\"]()]]"]}, {"number": 13515, "title": "Modified README for docker", "body": "Please accept my PR! I'm trying to get a hacktoberfest tshirt and I'm new to opensource, just trying to get my feet wet with how PRs work on github.\r\n\r\nI was skimming alot of information about docker and tensorflow online and when I came to the section of the readme I changed I had to stop and read carefully for a second to think about what was happening there, when I should have just skipped over it and kept going. Just added a comment that made it even more explicit that this code snipped is outdated and not recommended.\r\n\r\n", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Jenkins, test this please."]}, {"number": 13514, "title": "Fix small typo in docs of learn runner.", "body": "", "comments": []}, {"number": 13513, "title": "Branch 171234659", "body": "@frankchn Doing a push so we can cut the 1.4 branch. Hope you don't mind!", "comments": ["@frankchn FYI", "@yifeif @av8ramit No worries, go ahead!"]}, {"number": 13512, "title": "Branch 171231427 for 1.4 rc0", "body": "", "comments": ["Jenkins, test this please."]}, {"number": 13511, "title": "TensorForest: feature request - multi output label support", "body": "Looking at the code for TensorForest, it appears that it only allows: multiclass (including binary) classification or regression (scalar and vector). However, **there does not seem to be an obvious way to do a multi output classification setup** (in which there are multiple binary tasks that should all be predicted by a single model). Could this feature be implemented, or would you be able to guide in the easiest hack to convert to a multi output setup? Apologies if this should actually go to Stack Overflow, please let me know. Thank you!!", "comments": ["It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "I no longer work on TensorForest, so you will need to assign this to someone else.  @nataliaponomareva perhaps?", "For multi-label classification with forest, the easiest way would be probably\r\n- change your data to have a number of binary classification tasks (one for each label)\r\n- train a forest for each of your classification tasks\r\n- find appropriate thresholds for each of the task\r\n- assign the labels that pass these thresholds\r\n\r\nAlternatively, if you don't want to increase your dataset size that much (especially if you have a large number of potential labels), you can try boosted trees: (tensorflow/contrib/boosted_trees): \r\n- provide a multi-label loss that suits your problem the best (use multiclass strategy like a diagonal or full hessian, if the number of labels is not extreme)\r\n- use the scores from the ensemble plus some decision on top of them to decide whether the label applies or not. \r\n", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "I did respond, and I don't see any follow up questions", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "@nataliaponomareva @shivaniag  Are there any examples that use a multi-label loss for Boosted Trees? As far as I can see, [BoostedTreesRegressor ](https://www.tensorflow.org/api_docs/python/tf/estimator/BoostedTreesRegressor) is currently only implemented for _label_dimension=1_. In the [constructor](https://www.tensorflow.org/api_docs/python/tf/estimator/BoostedTreesRegressor#__init__), _label_dimension=_HOLD_FOR_MULTI_DIM_SUPPORT_ is a placeholder. I believe multi-dimensional labels are not supported yet. Please correct me if I'm wrong. \r\n\r\n#20575 ", "For the contrib (not core version), multi dimensional is supported. Take a look at \r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/boosted_trees/examples/mnist.py - it is a 10-dimensional multiclass problem. If you have any multidimensional problem (but not a multiclass, for which a wrapper already exists), you would need to \r\n- create a custom head with a loss\r\n- pass it into the GradientBoostedTreeEstimator\r\n\r\nSomething like this\r\n```\r\nloss_fn =  ... per example loss you want, that supports multi dimensional output. \r\nlearner_config.multi_class_strategy = (\r\n      learner_pb2.LearnerConfig.DIAGONAL_HESSIAN)\r\nmetrics_fn =  ... ur metrics fn\r\n# Use custom loss head\r\nhead = custom_loss_head.CustomLossHead(\r\n      loss_fn=loss_fn,\r\n      link_fn=tf.identity, # or what ever you need\r\n      logit_dimension=logit_dim, # your dimension of output\r\n      metrics_fn=metrics_fn)\r\nestimator = GradientBoostedDecisionTreeEstimator(\r\n      learner_config=learner_config,\r\n      head=head,\r\n....)\r\n```\r\n\r\n"]}, {"number": 13510, "title": "Make GCS and HDFS default build options.", "body": "", "comments": ["Jenkins, test this please."]}, {"number": 13509, "title": "Branch 171199546", "body": "", "comments": ["Jenkins, test this please.", "Jenkins, test this please.", "@akshayka what about also allowing graph_callable on functions that have no arguments?", "@yaroslavvb Great question; that's actually already supported. Just pass an empty list to graph_callable.\r\n\r\n```\r\n@graph_callable([])\r\ndef my_function():\r\n   ...\r\n```"]}, {"number": 13508, "title": "Iterator.get_next() returning a tensor of shape ()", "body": "### System information\r\n- **Have I written custom code**: Yes\r\n- **OS Platform and Distribution**: Windows 10 (also tested on Ubuntu 16.04)\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: b'unknown' 1.3.0\r\n- **Python version**: 3.5.3\r\n- **CUDA/cuDNN version**: 8.0/6.0\r\n\r\n### Describe the problem\r\nHello,\r\nI am currently trying to use the Dataset API with TFRecords. Using a (tested) dataset I made and refactoring working code, I wanted to switch from queues to Datasets. With the following code:\r\n \r\n```Python\r\ndef parse_function(serialized_example):\r\n\r\n    # Context features\r\n    context_features = {\r\n         \"label\": tf.FixedLenFeature([], dtype=tf.int64),\r\n    }\r\n\r\n    # Sequence features\r\n    sequence_features = {\r\n         \"positions\": tf.FixedLenSequenceFeature([], dtype=tf.string),\r\n    }\r\n\r\n    # Parsing the TFRecord\r\n    context_parsed, sequence_parsed = tf.parse_single_sequence_example(\r\n        serialized=serialized_example,\r\n        context_features=context_features,\r\n        sequence_features=sequence_features)\r\n\r\n    label = tf.cast(context_parsed['label'], tf.int32)\r\n    sequence = tf.decode_raw(sequence_parsed['positions'], tf.float32)\r\n\r\n    return tf.reshape(sequence, [height, width, channels]), label\r\n\r\ndef main(_):\r\n    dataset = tensorflow.contrib.data.TFRecordDataset(\"path\")\r\n    dataset.map(parse_function)\r\n    dataset.batch(64)\r\n\r\n    iterator = dataset.make_one_shot_iterator()\r\n    sequences, labels = iterator.get_next()\r\n    ...\r\n\r\n```\r\nthe last line will raise a TypeError(\"'Tensor' object is not iterable.\"). iterator.get_next() returns in this case a tensor with shape (), but I believe it should return a tuple of batched sequences and labels, as defined in my parse_function. I tried with every iterator, in or out of a session, but no change.\r\n\r\nIs it a bug or am I doing something wrong? Examples from https://www.tensorflow.org/programmers_guide/datasets#decoding_image_data_and_resizing_it\r\nreally suggest this is the way to go.\r\n\r\nThanks,\r\nQuentin", "comments": ["I think there\u2019s a bug in your code. The following lines:\r\n\r\n```python\r\ndef main(_):\r\n    dataset = tensorflow.contrib.data.TFRecordDataset(\"path\")\r\n    dataset.map(parse_function)\r\n    dataset.batch(64)\r\n```\r\n\r\n...should be changed to:\r\n\r\n```python\r\ndef main(_):\r\n    dataset = tensorflow.contrib.data.TFRecordDataset(\"path\")\r\n    dataset = dataset.map(parse_function)\r\n    dataset = dataset.batch(64)\r\n```\r\n\r\nThe high-level point is that calling methods on a `Dataset` does not modify an existing object; instead it returns a new `Dataset`, so you must assign the returned value to a Python variable (or chain it with other methods that are eventually assigned to a Python variable).", "Wow, sorry to have bothered you with that... Got stuck on it for 3 hours, thanks for your help.", "No worries! I'm just glad it wasn't seriously broken :)."]}, {"number": 13507, "title": "AttributeError in distributed training", "body": "Im am running tensorflow gpu '0.12.1' installed in a virtualenv on Debian 9.1 with cuda 8 and cudnn 5.1.\r\n\r\nI tried to run the tutorial from https://www.tensorflow.org/versions/r1.2/deploy/distributed\r\n\r\nI started 2 servers and 2 workers like in the tutorial. The servers started as expected.\r\n\r\nI run this command to start a worker:\r\n```bash\r\npython cluster_trainer.py \\\r\n  --ps_hosts=131.188.30.144:2222,131.188.30.142:2222 \\\r\n  --worker_hosts=131.188.30.134:2222,131.188.30.135:2222 \\\r\n  --job_name=worker --task_index=1\r\n```\r\nThe works exited with the error message:\r\n```\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: GeForce GTX 1050 Ti\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.392\r\npciBusID 0000:02:00.0\r\nTotal memory: 3.94GiB\r\nFree memory: 3.87GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:02:00.0)\r\nI tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:197] Initialize GrpcChannelCache for job ps -> {0 -> 131.188.30.144:2222, 1 -> 131.188.30.142:2222}\r\nI tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:197] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2222, 1 -> 131.188.30.135:2222}\r\nI tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:211] Started server with target: grpc://localhost:2222\r\n['131.188.30.144:2222', '131.188.30.142:2222'] ['131.188.30.134:2222', '131.188.30.135:2222'] worker 0\r\nTraceback (most recent call last):\r\n  File \"cluster_trainer.py\", line 85, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/cip/2016/ko01jaxu/lib/tensorflow/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 43, in run\r\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\r\n  File \"cluster_trainer.py\", line 36, in main\r\n    loss, global_step=global_step)\r\n  File \"/home/cip/2016/ko01jaxu/lib/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 269, in minimize\r\n    grad_loss=grad_loss)\r\n  File \"/home/cip/2016/ko01jaxu/lib/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 320, in compute_gradients\r\n    self._assert_valid_dtypes([loss])\r\n  File \"/home/cip/2016/ko01jaxu/lib/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 460, in _assert_valid_dtypes\r\n    dtype = t.dtype.base_dtype\r\nAttributeError: 'ellipsis' object has no attribute 'dtype'\r\n```\r\n", "comments": ["I think this is a better question for stackoverflow (you are not meant to copy paste the \"...\" from the code on that page, those are for you to fill in)"]}, {"number": 13506, "title": "tf.image.pad_to_bounding_box crashes when passed bounds with dtype int64", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:from pip in virtualenv\r\n- **TensorFlow version (use command below)**:v1.3.0-rc2-20-g0787eee 1.3.0\r\n- **Python version**: '3.5.2 (default, Nov 17 2016, 17:05:23) \\n[GCC 5.4.0 20160609]'\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n## Description\r\n\r\nPassing arguments of type int64 to `tf.image.pad_to_bounding_box` triggers a crash of the python interpreter. This is a bug because the type required by `tf.image.pad_to_bounding_box` not documented anywhere and just causes a crash with a cryptic error message.\r\n\r\n## Sources/Logs\r\n\r\nThe following snippet crashes the whole python interpreter with a core dump.\r\n\r\n    import tensorflow as tf\r\n    i = tf.constant([0, 0, 3, 3], dtype=tf.int64)\r\n    img = tf.ones([1,1,1], dtype=tf.float32)\r\n    sess = tf.Session()\r\n    sess.run(tf.image.pad_to_bounding_box(img, i[0], i[1], i[2], i[3]))\r\n\r\nAnd leaves the following \r\n\r\n    2017-10-05 13:51:24.789715: F tensorflow/core/framework/tensor.cc:493] Check failed: dtype() == expected_dtype (9 vs. 3)\r\n", "comments": ["this is bad, it shouldn't crash Python even if type is wrong", "The crash is caused by the fact that int64 was never registered in the kernel of `tf.image.pad_to_bounding_box`. Instead, the `int64` of the `Tpadding` is directly used as `int32` without appropriate processing.\r\n\r\nA PR #13517 has been created to address the crash.", "Thanks for debugging and the PR @yongtang !\r\n\r\nMarking as \"Contributions Welcome\", though it seems the contribution has already been sent :)"]}, {"number": 13505, "title": "Fix for #13498", "body": "@skye I'm kind of indecisive it turns out. :P This is just your fix along with an equivalent fix for `RemoveEdge`. I don't know if you want to merge it given that you might make changes to your fix, but I'm putting here just in case. The `RemoveEdge` fix is pretty much equivalent and since the method is not used in the graph constructor, I didn't change its call sites to use `false` for the update node def argument. I'm not sure if that collides with anything else, but I guess the tests can tell us something (I didn't run them on my laptop because they take forever and I can't use it in the meantime).", "comments": ["Can one of the admins verify this patch?", "Let's hold off on this until my patch is actually submitted :)", "Sounds good! By the way, I just pushed a small update for `RemoveEdge`, because the previous version caused some problems.", "@tensorflow-jenkins test this please", "@skye I think I resolved this earlier today. Are there any changes I omitted?\n\nOn Oct 18, 2017, 2:29 PM -0400, Skye Wanderman-Milne <notifications@github.com>, wrote:\n> @eaplatanios you need to rebase. The AddControlEdge API changed during code review: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/graph/graph.h#L446\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub, or mute the thread.\n", "Sorry I deleted that previous comment, I was somehow looking at the wrong thing.", "No worries. It was actually super well timed. I like pushed the changes a few minutes before you sent me that. :)\n\nOn Oct 18, 2017, 2:44 PM -0400, Skye Wanderman-Milne <notifications@github.com>, wrote:\n> Sorry I deleted that previous comment, I was somehow looking at the wrong thing.\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub, or mute the thread.\n", "@skye I added a simple test for the new method. I'm not sure what your convention is for unit tests. Please let me know if you want me to test for some specific condition other than the simple case I added. :)", "@skye I made all of the suggested changes. :)", "@skye I made the changes you suggested except the one about the boolean function which I think is correct, but could you please check and let me know if I'm confused about something? :)", "Sounds good! Have fun wherever you\u2019re going! :)\n\nOn Oct 18, 2017, 8:57 PM -0400, Skye Wanderman-Milne <notifications@github.com>, wrote:\n> @skye commented on this pull request.\n> In tensorflow/core/graph/graph_test.cc:\n> > +  ASSERT_TRUE(ControlEdgeExistsInGraphOrNodeDef(a, b));\n> +\n> +  graph_.RemoveControlEdge(edge_1);\n> +  ASSERT_TRUE(!ControlEdgeExistsInGraphOrNodeDef(c, a));\n> +  ASSERT_TRUE(ControlEdgeExistsInGraphOrNodeDef(a, b));\n> +\n> +  graph_.RemoveControlEdge(edge_2);\n> +  ASSERT_TRUE(!ControlEdgeExistsInGraphOrNodeDef(c, a));\n> +  ASSERT_TRUE(!ControlEdgeExistsInGraphOrNodeDef(a, b));\n> +\n> +  // Test removing a duplicate control edge.\n> +  // Note that unless allow_duplicates is true, the duplicate edge\n> +  // will not be added. That's why we expect edge_4 to be a null\n> +  // pointer. We are not testing with allow_duplicates set to true,\n> +  // as that is a highly unlikely use case that does not make much\n> +  // sense.\n> I need to run soon, and will be gone until next week, so this is fine, or do it in a separate PR and I'll review when I get back.\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub, or mute the thread.\n", "Jenkins, test this please.", "Jenkins, test this please."]}, {"number": 13504, "title": "Use --config=monolithic for the Android CI build", "body": "Avoids building some code for op generation. @av8ramit could you test it?", "comments": ["http://ci.tensorflow.org/view/Experimental/job/experimental-android-2/3/console"]}, {"number": 13503, "title": "Unstack int64 tensors on GPU", "body": "Registered unstack GPU kernel op for int64 tensors.\r\nExtended tests to check unstack op on different types of tensors for CPU and GPU.", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "It's been 3 weeks now.", "@tensorflow-jenkins test this please\r\n"]}]