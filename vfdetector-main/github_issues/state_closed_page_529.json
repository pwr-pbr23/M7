[{"number": 37858, "title": "tf.function retracing even with input_signature", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04.3 LTS\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: No\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 2.1\r\n- **Python version**: 3.7\r\n- **Bazel version (if compiling from source)**: None\r\n- **GCC/Compiler version (if compiling from source)**: None\r\n- **CUDA/cuDNN version**: 9.2\r\n- **GPU model and memory**: GTX 1080 Ti\r\n- **Exact command to reproduce**: Run the attached script\r\n\r\n### Describe the problem\r\nI made & saved a Keras model \r\nBut it brought tf.function retracing even with input_signature when it was loaded\r\n\r\n### Source code / logs\r\n\r\n* log\r\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7ff01c64e950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\r\n\r\n* Source code\r\nI removed the code one by one to narrow down the root-cause, still having the retracing issue\r\nI think that this should work.\r\nTo reproduce the issue, we need to do 2 steps as follows\r\n\r\n1) Save a model\r\n```\r\nimport os\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n@tf.function(input_signature=[\r\n    tf.TensorSpec([None, 15, 15], tf.uint16, name='curr'),\r\n    tf.TensorSpec([None, 2, 15, 15], tf.uint16, name='refs'),\r\n    tf.TensorSpec([None, 15, 15], tf.uint8, name='grades_image'),\r\n    tf.TensorSpec([None, 15, 15], tf.uint8, name='alarms_image'),\r\n])\r\ndef all_attributes(curr, refs, grades_image, alarms_image):\r\n    return tf.ones(tf.shape(curr)[0], tf.float32)\r\n\r\ndef create_layer(tf_func, name=None, trainable=False):\r\n    Return keras layer instance for given tensorflow function\"\"\"\r\n    if name is None:\r\n        name = getattr(tf_func, '__name__', 'unnamed') + '_layer'\r\n    class NewLayer(tf.keras.layers.Layer):\r\n        def call(self, inputs):\r\n            return tf_func(*inputs)\r\n    NewLayer.__name__ = name  \r\n    layer_instance = NewLayer()\r\n    layer_instance.trainable = trainable\r\n    return layer_instance\r\n\r\nclass TestModel:\r\n    Class for Selfi model for production\"\"\"\r\n    def build(self, name='unnamed_model'):\r\n        curr = tf.keras.Input(shape=(15, 15), dtype=tf.uint16, name='curr')\r\n        refs = tf.keras.Input(shape=(2, 15, 15), dtype=tf.uint16, name='refs')\r\n        grades_image = tf.keras.Input(shape=(15, 15), dtype=tf.uint8, name='grades_image')\r\n        alarms_image = tf.keras.Input(shape=(15, 15), dtype=tf.uint8, name='alarms_image')\r\n        inputs = [curr, refs, grades_image, alarms_image]\r\n        all_atts_stacked = create_layer(all_attributes)(inputs)\r\n        outputs = [all_atts_stacked]        \r\n        m = tf.keras.Model(inputs=inputs, outputs=outputs, name=name)\r\n        self._keras_model = m\r\n        return self\r\n    def save(self, out_path):\r\n        model = self._keras_model\r\n        model.save(out_path)\r\n        return self\r\n\r\nif __name__ == \"__main__\":\r\n    m = TestModel().build(name='Attribute_Model')\r\n    save_root_dir = './Models'\r\n    save_path = os.path.join(save_root_dir, m.name)\r\n    m.save(save_path) \r\n```\r\n\r\n2) Load & try the saved model. Here the retracing issue happens\r\n```\r\nimport numpy as np\r\nfrom numpy import ndarray\r\nfrom typing import Tuple, List\r\nimport tensorflow as tf\r\nimport time\r\n\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\nif gpus:\r\n  try:\r\n    for gpu in gpus:\r\n      tf.config.experimental.set_memory_growth(gpu, True)\r\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\r\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\r\n  except RuntimeError as e:\r\n    print(e)\r\n\r\nmodel_path = \"./Models\"\r\n\r\ndef copy_to_aligned_data(input_arr: ndarray, align: int) -> ndarray:\r\n    pixels = input_arr.size\r\n    alignment = align\r\n    dtype = input_arr.dtype\r\n    nbytes = pixels * dtype.itemsize\r\n    buf = np.empty(nbytes + alignment, dtype=np.uint8)\r\n    start_index = -buf.ctypes.data % alignment\r\n    out_array = buf[start_index:start_index + nbytes].view(dtype).reshape(input_arr.shape)\r\n    out_array[:] = input_arr[:]\r\n    return out_array\r\n\r\ndef create_inputs_for_supervised_model(img_shape, refs_shape) -> List:\r\n    curr = np.random.randint(max_value_14bit, size=img_shape, dtype=np.uint16)\r\n    refs = np.random.randint(max_value_14bit, size=refs_shape, dtype=np.uint16)\r\n    grades_image = np.random.randint(max_value_8bit, size=img_shape, dtype=np.uint8)\r\n    alarms_image = np.random.randint(2, size=img_shape, dtype=np.uint8)\r\n    curr_align = copy_to_aligned_data(curr, 64)\r\n    refs_align = copy_to_aligned_data(refs, 64)\r\n    grades_image_align = copy_to_aligned_data(grades_image, 64)\r\n    alarms_image_align = copy_to_aligned_data(alarms_image, 64)\r\n    curr_tf = tf.convert_to_tensor(curr_align, curr_align.dtype)\r\n    refs_tf = tf.convert_to_tensor(refs_align, refs_align.dtype)\r\n    grades_tf = tf.convert_to_tensor(grades_image_align, grades_image_align.dtype)\r\n    alarms_tf = tf.convert_to_tensor(alarms_image_align, alarms_image_align.dtype)\r\n    return [curr_tf, refs_tf, grades_tf, alarms_tf]\r\n\r\nmodel_orig = tf.keras.models.load_model(model_path, compile=False)\r\n\r\nmax_value_14bit = np.iinfo(np.uint16).max // 4\r\nmax_value_8bit = np.iinfo(np.uint8).max\r\n\r\ndefects_count = 20\r\nimg_shapee = (defects_count, 15, 15)\r\nrefs_shapee = (defects_count, 2, 15, 15)\r\ninputs = create_inputs_for_supervised_model(img_shapee, refs_shapee)\r\noutput = model_orig(inputs)\r\n\r\nloop = 10\r\nfor i in range(loop):\r\n    defects_count = 10000 + i*100\r\n    img_shapee = (defects_count, 15, 15)\r\n    refs_shapee = (defects_count, 2, 15, 15)\r\n    inputs = create_inputs_for_supervised_model(img_shapee, refs_shapee)\r\n    start = time.time()\r\n    output = model_orig(inputs)\r\n    output.numpy()\r\n    duration_ms = (time.time() - start)*1000  # / loop\r\n```\r\n\r\n\r\n", "comments": ["@MarisJon,\r\nI tried to reproduce the issue, but I'm facing an error stating `ModuleNotFoundError: No module named 'amatdeep'`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/2ecc32da7cbb4e4c245a879a6bdbb317/37858.ipynb#scrollTo=5v3is8k8CSgH).\r\n\r\nLooks like the given code is incomplete. In order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here. \r\n\r\nAlso, please add ``` (3 backticks) before and after your code to preserve the formatting. Thanks!", "Hello. Thank you for the reply. I am sorry for this inconvenience. Added more details in the original report. Please refer to it. Thank you", "Was able to reproduce the issue with [TF v2.1](https://colab.research.google.com/gist/amahendrakar/b7254a6f0f6c597612fa57f350b55f45/37858.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/8dfc5eb16936865e723b72b4e0adaae5/37858-tf-nightly.ipynb). Please find the attached gist. Thanks!", "Hi, an easy workaround is applying @tf.function outside of the model.\r\n\r\n```python\r\n@tf.function(input_signature=[\r\n    tf.TensorSpec([None, 15, 15], tf.uint16, name='curr'),\r\n    tf.TensorSpec([None, 2, 15, 15], tf.uint16, name='refs'),\r\n    tf.TensorSpec([None, 15, 15], tf.uint8, name='grades_image'),\r\n    tf.TensorSpec([None, 15, 15], tf.uint8, name='alarms_image'),\r\n])\r\ndef model_orig_run(*inputs):\r\n  return model_orig(inputs)\r\n\r\n#...\r\n\r\noutput = model_orig_run(*inputs)\r\n```\r\n", "> Hi, an easy workaround is applying @tf.function outside of the model.\r\n> \r\n> ```python\r\n> @tf.function(input_signature=[\r\n>     tf.TensorSpec([None, 15, 15], tf.uint16, name='curr'),\r\n>     tf.TensorSpec([None, 2, 15, 15], tf.uint16, name='refs'),\r\n>     tf.TensorSpec([None, 15, 15], tf.uint8, name='grades_image'),\r\n>     tf.TensorSpec([None, 15, 15], tf.uint8, name='alarms_image'),\r\n> ])\r\n> def model_orig_run(*inputs):\r\n>   return model_orig(inputs)\r\n> \r\n> #...\r\n> \r\n> output = model_orig_run(*inputs)\r\n> ```\r\n\r\n@kkimdev \r\nI agree. input_signature must be added when a model is loaded? Is this what is supposed to be done to remove retracing?", "@k-w-w ", "Was able to run your code without any Warnings for retracing in Tensorflow GPU 2.5, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/5c4875489c923dde215eb17366c441cf/37858.ipynb). Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37858\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37858\">No</a>\n"]}, {"number": 37857, "title": "tflite_with_xnnpack.cc: undefined reference to `TfLiteXNNPackDelegateOptionsDefault'", "body": "**System information**\r\n\r\n```\r\nLinux ubuntu 5.3.0-1019-raspi2 #21-Ubuntu SMP Mon Feb 17 14:05:03 UTC 2020 aarch64 aarch64 aarch64 GNU/Linux\r\n```\r\n\r\n- TensorFlow installed from source \r\n- TensorFlow version: commit e9db6486b37a5aa4ed25aa3e661d64cc9e0fdd2\r\n- GCC/Compiler version (if compiling from source):\r\n\r\n```\r\nubuntu@ubuntu:~$ aarch64-linux-gnu-g++ --version\r\naarch64-linux-gnu-g++ (Ubuntu 9.2.1-9ubuntu2) 9.2.1 20191008\r\n```\r\n- GPU model and memory: Raspberry Pi 4 4GB\r\n\r\n**Describe the problem**\r\n\r\nProblem building TFLite library with make in arm64\r\ntflite_with_xnnpack.cc: undefined reference to `TfLiteXNNPackDelegateOptionsDefault'\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n```\r\nubuntu@ubuntu:~/tensorflow$` git checkout e9db6486b37a5aa4ed25aa3e661d64cc9e0fdd2e\r\n...\r\nubuntu@ubuntu:~/tensorflow$ ./tensorflow/lite/tools/make/download_dependencies.sh\r\n...\r\nubuntu@ubuntu:~/tensorflow$ ./tensorflow/lite/tools/make/build_aarch64_lib.sh \r\n...\r\naarch64-linux-gnu-g++ -O3 -DNDEBUG -fPIC --std=c++11  -DTFLITE_WITH_RUY -DTFLITE_WITHOUT_XNNPACK -march=armv8-a -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/home/ubuntu/tensorflow/tensorflow/lite/tools/make/../../../../../ -I/home/ubuntu/tensorflow/tensorflow/lite/tools/make/../../../../../../ -I/home/ubuntu/tensorflow/tensorflow/lite/tools/make/downloads/ -I/home/ubuntu/tensorflow/tensorflow/lite/tools/make/downloads/eigen -I/home/ubuntu/tensorflow/tensorflow/lite/tools/make/downloads/absl -I/home/ubuntu/tensorflow/tensorflow/lite/tools/make/downloads/gemmlowp -I/home/ubuntu/tensorflow/tensorflow/lite/tools/make/downloads/neon_2_sse -I/home/ubuntu/tensorflow/tensorflow/lite/tools/make/downloads/farmhash/src -I/home/ubuntu/tensorflow/tensorflow/lite/tools/make/downloads/flatbuffers/include -I/home/ubuntu/tensorflow/tensorflow/lite/tools/make/downloads/fp16/include -I -I/usr/local/include \\\r\n-o /home/ubuntu/tensorflow/tensorflow/lite/tools/make/gen/linux_aarch64/bin/benchmark_model /home/ubuntu/tensorflow/tensorflow/lite/tools/make/gen/linux_aarch64/obj/tensorflow/lite/tools/benchmark/benchmark_main.o \\\r\n -Wl,--whole-archive /home/ubuntu/tensorflow/tensorflow/lite/tools/make/gen/linux_aarch64/lib/benchmark-lib.a -Wl,--no-whole-archive -Wl,--no-export-dynamic -Wl,--exclude-libs,ALL -Wl,--gc-sections -Wl,--as-needed -lrt -lstdc++ -lpthread -lm -ldl\r\n/usr/bin/ld: /home/ubuntu/tensorflow/tensorflow/lite/tools/make/gen/linux_aarch64/lib/benchmark-lib.a(tflite_with_xnnpack.o): in function `tflite::AcquireXNNPACKDelegate(int)':\r\ntflite_with_xnnpack.cc:(.text+0x2c): undefined reference to `TfLiteXNNPackDelegateOptionsDefault'\r\n/usr/bin/ld: tflite_with_xnnpack.cc:(.text+0x40): undefined reference to `TfLiteXNNPackDelegateCreate'\r\n/usr/bin/ld: tflite_with_xnnpack.cc:(.text+0x48): undefined reference to `TfLiteXNNPackDelegateDelete'\r\n/usr/bin/ld: tflite_with_xnnpack.cc:(.text+0x58): undefined reference to `TfLiteXNNPackDelegateDelete'\r\ncollect2: error: ld returned 1 exit status\r\nmake: *** [tensorflow/lite/tools/make/Makefile:321: /home/ubuntu/tensorflow/tensorflow/lite/tools/make/gen/linux_aarch64/bin/benchmark_model] Error 1\r\nmake: *** Waiting for unfinished jobs....\r\n```\r\n\r\n**Any other info / logs**\r\n\r\n**Workarround**: revert commit 7247fefebbbae4ba02a4aa01d18c503719eb72c8 fix the problem\r\n\r\n\r\n", "comments": ["No longer occurs in commit @9d2bdd0b244c759ca54c6f10f58c069ec2200452", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37857\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37857\">No</a>\n"]}, {"number": 37856, "title": "tf.SparseTensor to tf.sparse.SparseTensor", "body": "Afaik, tf.SparseTensor is currently just an alias for tf.sparse.SparseTensor. But since the later might get removed in the future, suggest replacing usage with the more consistent alias.", "comments": ["Please resolve conflicts", "> Please resolve conflicts\r\n\r\nConflicts have been resolved.", "Can you fix the sanity build please? It's a pylint error", "@mihaimaruseac sorry, there are files with pylint warnings that I am not sure how to fix. Should I close this PR and reopen another PR to make sure only revised files without pylint errors occur? Please forgive me that I'm still new to the whole process.", "The pylint errors are\r\n\r\n```\r\ntensorflow/examples/saved_model/integration_tests/export_simple_text_embedding.py:90: [C0301(line-too-long), ] Line too long (86/80)\r\ntensorflow/python/util/nest.py:313: [C0301(line-too-long), ] Line too long (85/80)\r\ntensorflow/python/util/nest.py:367: [C0301(line-too-long), ] Line too long (87/80)\r\ntensorflow/python/util/nest.py:540: [C0301(line-too-long), ] Line too long (87/80)\r\ntensorflow/python/util/nest.py:577: [C0301(line-too-long), ] Line too long (81/80)\r\ntensorflow/python/util/nest.py:765: [C0301(line-too-long), ] Line too long (85/80)\r\ntensorflow/python/util/nest.py:914: [C0301(line-too-long), ] Line too long (85/80)\r\ntensorflow/python/util/nest.py:1018: [C0301(line-too-long), ] Line too long (85/80)\r\ntensorflow/python/util/nest.py:1236: [C0301(line-too-long), ] Line too long (85/80)\r\ntensorflow/python/util/nest.py:1316: [C0301(line-too-long), ] Line too long (85/80)\r\ntensorflow/python/util/nest.py:1341: [C0301(line-too-long), ] Line too long (85/80)\r\ntensorflow/python/util/nest.py:1365: [C0301(line-too-long), ] Line too long (85/80)\r\ntensorflow/python/ops/ragged/ragged_tensor.py:1640: [C0301(line-too-long), ] Line too long (85/80)\r\ntensorflow/python/ops/sets_impl.py:159: [C0301(line-too-long), ] Line too long (85/80)\r\ntensorflow/python/ops/sets_impl.py:170: [C0301(line-too-long), ] Line too long (87/80)\r\ntensorflow/python/ops/sets_impl.py:227: [C0301(line-too-long), ] Line too long (87/80)\r\ntensorflow/python/ops/sets_impl.py:241: [C0301(line-too-long), ] Line too long (87/80)\r\ntensorflow/python/ops/sets_impl.py:305: [C0301(line-too-long), ] Line too long (87/80)\r\ntensorflow/python/ops/sets_impl.py:319: [C0301(line-too-long), ] Line too long (87/80)\r\ntensorflow/python/ops/map_fn.py:196: [C0301(line-too-long), ] Line too long (84/80)\r\ntensorflow/python/ops/array_ops.py:3072: [C0301(line-too-long), ] Line too long (82/80)\r\ntensorflow/python/framework/sparse_tensor.py:483: [C0301(line-too-long), ] Line too long (85/80)\r\ntensorflow/python/data/util/sparse.py:68: [C0301(line-too-long), ] Line too long (87/80)\r\ntensorflow/python/data/util/sparse.py:109: [C0301(line-too-long), ] Line too long (86/80)\r\ntensorflow/python/data/experimental/ops/batching.py:124: [C0301(line-too-long), ] Line too long (87/80)\r\ntensorflow/python/feature_column/feature_column.py:1972: [C0301(line-too-long), ] Line too long (81/80)\r\ntensorflow/python/data/ops/dataset_ops.py:2918: [C0301(line-too-long), ] Line too long (86/80)\r\ntensorflow/python/feature_column/feature_column_v2.py:2518: [C0301(line-too-long), ] Line too long (81/80)\r\n```\r\n\r\nAll of these are files modified in this PR.", "@mihaimaruseac Thanks for your help. The pylint errors you mentioned are all fixed. Somehow I have more pylint warnings in my vscode, there must be some settings incorrect in my environment.", "We also have a few warnings whitelisted, so ignore those"]}, {"number": 37855, "title": "Add behavioral note to VariableV2 and VarhandleOp", "body": "Fixes #37830 .\r\n@mihaimaruseac , Please review.", "comments": ["We should not add Python doctests/examples to the base api_defs. Those files are shared across multiple languages.", "@mihaimaruseac , removed doctest, please review.", "See 8582a583d45fdf6a895c0677c7f68b4bf3596ee9 for an example of how to add python-specific text to an OP. Let's try to do that", "@ashutosh1919 Can you please check reviewer comments and keep us posted. Thanks!", "@gbaned , created new PR for the python_api of this #37925. And @mihaimaruseac is aware about it.This PR contains changes to base_api.", "Let's close this one in favor of #37925 ", "@mihaimaruseac, note that this PR contains the changes in base_api where as #37925 contains changes in python_api. So, do you want me to include these changes in #37925? If yes, then please reply, if no, then please reopen this PR", "Yes, please, let's include everything in one single PR", "@gbaned, It has been 10 days since @mihaimaruseac approved this PR. It is not merged yet. Please, can you check internal status and update me if something is wrong?", "I don't understand what this is trying to say, but VarHandleIOp doesn't get automatically read in any meaningful way."]}, {"number": 37854, "title": "Tenserflow error", "body": "Using TensorFlow backend.\r\nUsing TensorFlow backend.\r\nException in thread django-main-thread:\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\munis\\Python36\\lib\\threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"C:\\Users\\munis\\Python36\\lib\\threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"C:\\Users\\munis\\Python36\\lib\\site-packages\\django\\utils\\autoreload.py\", line 54, in wrapper\r\n    fn(*args, **kwargs)\r\n  File \"C:\\Users\\munis\\Python36\\lib\\site-packages\\django\\core\\management\\commands\\runserver.py\", line 117, in inner_run\r\n    self.check(display_num_errors=True)\r\n  File \"C:\\Users\\munis\\Python36\\lib\\site-packages\\django\\core\\management\\base.py\", line 390, in check\r\n    include_deployment_checks=include_deployment_checks,\r\n  File \"C:\\Users\\munis\\Python36\\lib\\site-packages\\django\\core\\management\\base.py\", line 377, in _run_checks\r\n    return checks.run_checks(**kwargs)\r\n  File \"C:\\Users\\munis\\Python36\\lib\\site-packages\\django\\core\\checks\\registry.py\", line 72, in run_checks\r\n    new_errors = check(app_configs=app_configs)\r\n  File \"C:\\Users\\munis\\Python36\\lib\\site-packages\\django\\core\\checks\\urls.py\", line 40, in check_url_namespaces_unique\r\n    all_namespaces = _load_all_namespaces(resolver)\r\n  File \"C:\\Users\\munis\\Python36\\lib\\site-packages\\django\\core\\checks\\urls.py\", line 57, in _load_all_namespaces\r\n    url_patterns = getattr(resolver, 'url_patterns', [])\r\n  File \"C:\\Users\\munis\\Python36\\lib\\site-packages\\django\\utils\\functional.py\", line 80, in __get__\r\n    res = instance.__dict__[self.name] = self.func(instance)\r\n  File \"C:\\Users\\munis\\Python36\\lib\\site-packages\\django\\urls\\resolvers.py\", line 579, in url_patterns\r\n    patterns = getattr(self.urlconf_module, \"urlpatterns\", self.urlconf_module)\r\n  File \"C:\\Users\\munis\\Python36\\lib\\site-packages\\django\\utils\\functional.py\", line 80, in __get__\r\n    res = instance.__dict__[self.name] = self.func(instance)\r\n  File \"C:\\Users\\munis\\Python36\\lib\\site-packages\\django\\urls\\resolvers.py\", line 572, in urlconf_module\r\n    return import_module(self.urlconf_name)\r\n  File \"C:\\Users\\munis\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"C:\\Users\\munis\\Python36\\miniproject\\miniproject\\urls.py\", line 3, in <module>\r\n    from bankloan import views\r\n  File \"C:\\Users\\munis\\Python36\\miniproject\\bankloan\\views.py\", line 5, in <module>\r\n    from keras import backend as K\r\n  File \"C:\\Users\\munis\\Python36\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"C:\\Users\\munis\\Python36\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"C:\\Users\\munis\\Python36\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"C:\\Users\\munis\\Python36\\lib\\site-packages\\keras\\backend\\__init__.py\", line 89, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"C:\\Users\\munis\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\munis\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 99, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\Users\\munis\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"C:\\Users\\munis\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\Users\\munis\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 10, in <module>\r\n    from tensorflow.python.eager import context as _context\r\n  File \"C:\\Users\\munis\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\eager\\context.py\", line 29, in <module>\r\n    from tensorflow.core.protobuf import config_pb2\r\n  File \"C:\\Users\\munis\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\munis\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\munis\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named 'tensorflow_core.core'", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the code snippet to reproduce the issue. If you are unclear what to include see the issue template displayed in the [Github new issue template.](https://github.com/tensorflow/tensorflow/issues/new/choose)\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!", "Closing as duplicate.\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156\r\n\r\n#36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204", "Sorry, different issue. Please fill in issue template", "@munishvira \r\n\r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in the [Github new issue template.](https://github.com/tensorflow/tensorflow/issues/new/choose)\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37854\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37854\">No</a>\n"]}, {"number": 37853, "title": "Added example and description about numpy_function() in Dataset.map()", "body": "Fixes #36979 .\r\n@mihaimaruseac , Please review.", "comments": ["@mihaimaruseac ,\r\nIn the issue mentioned, non-compatibility of `numpy()` function with `MapDataset` is discussed.\r\nI have also mentioned another past issue about same topic. But, there was a bit confusion between `py_function` and `numpy_function`. That will be clear with addition of this example.\r\nI think this fixes the issue. If you think still something is missing, please mention it here so that I will also include that in this PR.", "@mihaimaruseac and @jsimsa , Added description. Please review.", "@mihaimaruseac, thank you so much for the commit. "]}, {"number": 37852, "title": "NFC - minor spelling tweaks in documents", "body": "Fix minor spelling issues in `.md` and `.td` files", "comments": []}, {"number": 37851, "title": "[Autograph] Fix Autograph '\\' error", "body": "This is a PR from JIZHI, the AI platform in Tencent.\r\n\r\nThis PR solves the backslash continuation error mentioned in [#35765](https://github.com/tensorflow/tensorflow/issues/35765)\r\n\r\nTo illustrate this fix, let's take this function as an example:\r\n```python\r\n# some indentation...\r\n  def f():\r\n    a = \\\r\n    1\r\n    return a\r\n\r\n```\r\nThe problem is that the `new_code` after process will be\r\n```python\r\ndef f():\r\n  a =1\r\n  return a\r\n```\r\nThe number of lines does not match. This PR fixes it by align the \"a = \\\" and \"1\" with \"a =1\".", "comments": ["sorry i didn't notice that the backslash error was solved in master. maybe we can commit this quick fix to r2.1?", "Branches are locked after release, I'm afraid. But the 2.2 release should arrive soon.\r\n\r\nI noticed the PR adds code to handle the Windows `\\r\\n` line terminators. Should we amend `_unfold_continuations` at line 48, or did the version at head work properly in your tests?", "I've tried the r2.2 on a Windows machine and it works. Close the pr because the bug was already fixed."]}, {"number": 37850, "title": "Lower case c++1z config", "body": "The `.bazelrc` actually checks for `c++1z` and not `C++1z` (mind the capital `C`) so this should be accounted for in the docs.", "comments": ["In the future, please try to merge multiple single typo fixes in a single PR to reduce hours CI/letters changed metric"]}, {"number": 37849, "title": "Fix typos in .bazelrc", "body": "`arch_native_linux` is actually called `native_arch_linux` down below in the `.bazelrc` where it's actually being consumed.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37849) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37849) for more info**.\n\n<!-- ok -->", "Please merge with #37850 since both touch the same file", "I merged it and will close the other one."]}, {"number": 37848, "title": "Cannot import Tensorflow on Ubuntu VPS", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): conda install -c conda-forge tensorflow=1.10.0\r\n- TensorFlow version: 1.10.0\r\n- Python version: 3.5.4\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nWhen I try to import tensorflow on my vps, I get an undefined symbol error. I have tried reinstalling it, but that did not help. I am not sure what else to try or do. Does it maybe have something to do with a wheel?\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```$ python app.py\r\nTraceback (most recent call last):\r\n  File \"app.py\", line 7, in <module>\r\n    from tensorflow import * # pylint: disable=unused-import\r\n  File \"/home/me/anaconda3/envs/audiogen/lib/python3.5/site-packages/tensorflow/__init__.py\", line 22, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"/home/me/anaconda3/envs/audiogen/lib/python3.5/site-packages/tensorflow/python/__init__.py\", line 52, in <module>\r\n    from tensorflow.core.framework.graph_pb2 import *\r\n  File \"/home/me/anaconda3/envs/audiogen/lib/python3.5/site-packages/tensorflow/core/framework/graph_pb2.py\", line 6, in <module>\r\n    from google.protobuf import descriptor as _descriptor\r\n  File \"/home/me/anaconda3/envs/audiogen/lib/python3.5/site-packages/google/protobuf/descriptor.py\", line 47, in <module>\r\n    from google.protobuf.pyext import _message\r\nImportError: /home/iman/anaconda3/envs/audiogen/lib/python3.5/site-packages/google/protobuf/pyext/_message.cpython-35m-x86_64-linux-gnu.so: undefined symbol: _ZNK6google8protobuf10TextFormat17FieldValuePrinter9PrintBoolEb```", "comments": ["Please try to use 1.15, 2.1 or 2.2. 1.10 is too old and we don't support it anymore.", "> Please try to use 1.15, 2.1 or 2.2. 1.10 is too old and we don't support it anymore.\r\n\r\n@imandhillon,\r\nCould you please check @mihaimaruseac's comment and let know if you're still facing the same issue? Thanks!", "@imandhillon,\r\nAny updates regarding this issue? Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37848\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37848\">No</a>\n"]}, {"number": 37847, "title": "TypeError: save() got an unexpected keyword argument 'save_format'", "body": "\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): I followed a tutorial of Adrian Rosebrock ( Pyimagesearch )\r\n- OS Platform and Distribution : Windows 10 x64\r\n- TensorFlow installed from (\r\nbinary): - TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.6\r\n- CUDA/cuDNN version: - GPU model and memory:9/7\r\n\r\n**Standalone code to reproduce the issue** \r\nI'm trying to train a dataset of COVID-19 virus to detect the normal person and the no normal person ( he have not the virus) .\r\nwhen I execute the script `train_covid19.py` that I have got from ( https://www.pyimagesearch.com/2020/03/16/detecting-covid-19-in-x-ray-images-with-keras-tensorflow-and-deep-learning/?fbclid=IwAR2P7bkAaIf9F_I1dk2xyLRpQB2mfAtc3ov3fpsls8B-wNEeCVPT3cizCWY), I got an error after I have completed the 25 epochs of training.\r\n>[INFO] saving COVID-19 detector model...\r\nTraceback (most recent call last):\r\n  File \"train_covid19.py\", line 164, in <module>\r\n    model.save(args[\"model\"], save_format=\"h5\")\r\nTypeError: save() got an unexpected keyword argument 'save_format'\r\n\r\nI'm sure that the problem is a bug in the version of the tensorflow or some changes ( because Adrain is used Tensorflow 2.0 and the version that I used is 1.13.1)\r\nSo I need to know how can I change this line to make the complete code works?\r\nThanks :)\r\n\r\n", "comments": ["@abdou31, In the given link, Tensorflow version used is 2.0, Try to execute the `train_covid19.py` with Tf2.0.\r\nThanks", "I know that the problem with the version, but I solved the problem by changing some lines using the version 1.13.1. ", "@abdou31, Can you provide the modified code snippet to find the root cause. Thanks", "@abdou31, Any update", "Hello @gadagashwini , I have just made an update in the last line of the code:\r\n\r\n```python\r\n#model.save(args[\"model\"], save_format=\"h5\") the new version Tensorflow 2.0\r\nmodel.save(args[\"model\"]) # the version that I've used Tensorflow 1.13.1\r\n```", "@abdou31, Could you provide the complete modified code. Thanks", "@abdou31,\r\nplease update on the above comment", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37847\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37847\">No</a>\n", "save the 'model_name{}'.format(model_format) for example:\r\nmodel_format='.h5'\r\nmodel.save('model_name{}'.format(model_format))"]}, {"number": 37846, "title": "How to solve this problem?(download_dependencies.sh)(c++ tensorflow)", "body": "downloading https://github.com/google/googletest/archive/release-1.8.0.tar.gz\r\ndownloading https://mirror.bazel.build/github.com/google/nsync/archive/0559ce013feac8db639ee1bf776aca0325d28777.tar.gz\r\n\r\ngzip: stdin: unexpected end of file\r\ntar: Child returned status 1\r\ntar: Error is not recoverable: exiting now\r\n", "comments": ["@heartraeh \r\nIt looks like you haven't used a template to create this issue. Please resubmit your issue using a template from [here](https://github.com/tensorflow/tensorflow/issues/new/choose). We ask users to use the template because it reduces overall time to resolve a new issue by avoiding extra communication to get to the root of the issue. \r\n\r\nAs per the error please refer to #31799 #35747 and [link1](https://www.linuxquestions.org/questions/linux-newbie-8/gzip-stdin-unexpected-end-of-file-when-untaring-598924/) [link2](https://stackoverflow.com/questions/39643013/gzip-stdin-not-in-gzip-format-tar-child-returned-status-1-tar-error-is-not-r), we will need the tensor flow version and steps performed before you encountered the error to help you resolve the issue\r\n", "@heartraeh\r\nplease update on the above comment", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37846\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37846\">No</a>\n"]}, {"number": 37845, "title": "Calling tf.keras.model.save twice fails", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Debian 9\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or\r\nbinary): binary\r\n- TensorFlow version (use command below): `v2.1.0-rc2-17-ge5bf8de 2.1.0`\r\n- Python version: 3.5.3\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from\r\nsource): n/a\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n**Describe the current behavior**\r\n\r\nAs demonstrated in this [gist](https://gist.github.com/zmjjmz/ade6ecb5eaf011788b1da62db4413cad), calling `tf.keras.Model.save` twice on a Model object fails on the second call.\r\n\r\n**Describe the expected behavior**\r\n\r\nIt uh, would work.\r\n\r\n**Standalone code to reproduce the issue** \r\n\r\nThis [gist](https://gist.github.com/zmjjmz/ade6ecb5eaf011788b1da62db4413cad)\r\n\r\nRelated to (I'm fairly certain) [this issue](https://github.com/tensorflow/tensorflow/issues/33085).", "comments": ["@zmjjmz \r\n\r\nCan you try with latest TF version(`!pip install tensorflow==2.2.0rc1`). I am not seeing nay issue with TF 2.2.0rc1. Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/ed616015607be729cae5eaf2eb306478/untitled745.ipynb). Thanks!", "My test works on TF 2.2.0rc1, thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37845\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37845\">No</a>\n", "Are there workarounds in TF2.1?  I'm trying to train on AI-Platform which doesn't offer 2.2", "> Are there workarounds in TF2.1? I'm trying to train on AI-Platform which doesn't offer 2.2\r\n\r\nThis came up for me using a `ModelCheckpoint` callback.  I just realized setting `save_weights_only=True` fixes the problem. Not perfect but at least it works!"]}, {"number": 37844, "title": "Cannot convert model containing categorical_column_with_vocabulary_list op", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):CentOS\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (or github SHA if from source): 2.2.0rc0\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport os\r\n\r\nmodel_dir = \"models/feature_column_example\"\r\ncategory = tf.constant([\"A\", \"B\", \"A\", \"C\", \"C\", \"A\"])\r\nlabel = tf.constant([1, 0, 1, 0, 0, 0])\r\n\r\nds = tf.data.Dataset.from_tensor_slices(({\"category\": category}, label))\r\nds = ds.batch(2)\r\n\r\nfc_category = tf.feature_column.indicator_column(\r\n    tf.feature_column.categorical_column_with_vocabulary_list(\r\n        \"category\", vocabulary_list=[\"A\", \"B\", \"C\"]\r\n    )\r\n)\r\nfeature_layer = tf.keras.layers.DenseFeatures([fc_category])\r\n\r\nmodel = tf.keras.Sequential(\r\n    [\r\n        feature_layer,\r\n        tf.keras.layers.Dense(10, activation=\"relu\"),\r\n        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\r\n    ]\r\n)\r\nmodel.compile(\r\n    optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\r\n)\r\n\r\nmodel.fit(ds, epochs=2)\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.allow_custom_ops = True\r\n# converter.experimental_new_converter = True\r\n# converter.experimental_new_quantizer = True\r\n\r\n# Convert the model.\r\ntflite_model = converter.convert()\r\nopen(os.path.join(model_dir, \"output.tflite\"), \"wb\").write(tflite_model)\r\n\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\nCannot convert a Tensor of dtype resource to a NumPy array.\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n```\r\nsaved_model_cli show --dir models/feature_column_example/ --tag_set serve --signature_def serving_default\r\n\r\nThe given SavedModel SignatureDef contains the following input(s):\r\n  inputs['category'] tensor_info:\r\n      dtype: DT_STRING\r\n      shape: (-1, 1)\r\n      name: serving_default_category:0\r\nThe given SavedModel SignatureDef contains the following output(s):\r\n  outputs['output_1'] tensor_info:\r\n      dtype: DT_FLOAT\r\n      shape: (-1, 1)\r\n      name: StatefulPartitionedCall_7:0\r\nMethod name is: tensorflow/serving/predict\r\n\r\n```\r\n\r\n**Failure details**\r\nCannot convert a Tensor of dtype `resource` to a NumPy array.\r\n\r\nAccording to my analysis, this might be caused by some HashTable Ops, which create table handles. And my additional question is: whether tfliteconverter could convert model contains ops of initialize hashtableV2 and LookupTableImportV2? Thank you.\r\n\r\n\r\n**Any other info / logs**: Full logs\r\n```\r\nTraceback (most recent call last):\r\n  File \"feature_column_example.py\", line 62, in <module>\r\n    export_keras_hashtable_model()\r\n  File \"feature_column_example.py\", line 58, in export_keras_hashtable_model\r\n    tflite_model = converter.convert()\r\n  File \"/root/tf2.2/lib/python3.6/site-packages/tensorflow/lite/python/lite.py\", line 464, in convert\r\n    self._funcs[0], lower_control_flow=False))\r\n  File \"/root/tf2.2/lib/python3.6/site-packages/tensorflow/python/framework/convert_to_constants.py\", line 706, in convert_variables_to_constants_v2_as_graph\r\n    func, lower_control_flow, aggressive_inlining)\r\n  File \"/root/tf2.2/lib/python3.6/site-packages/tensorflow/python/framework/convert_to_constants.py\", line 457, in _convert_variables_to_constants_v2_impl\r\n    tensor_data = _get_tensor_data(func)\r\n  File \"/root/tf2.2/lib/python3.6/site-packages/tensorflow/python/framework/convert_to_constants.py\", line 217, in _get_tensor_data\r\n    data = val_tensor.numpy()\r\n  File \"/root/tf2.2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 961, in numpy\r\n    maybe_arr = self._numpy()  # pylint: disable=protected-access\r\n  File \"/root/tf2.2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 929, in _numpy\r\n    six.raise_from(core._status_to_exception(e.code, e.message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot convert a Tensor of dtype resource to a NumPy array.\r\n\r\n```\r\n", "comments": ["Was able to reproduce the issue with [TF v2.2.0-rc1](https://colab.research.google.com/gist/amahendrakar/d48d1559efb550feec8ff5e4e6f93bbd/37844.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/8cce7083e1f2a856454c76e30ffe2901/37844-tf-nightly.ipynb). Please find the attached gist. Thanks!", "Thanks for the prompt response to this issue.\r\n\r\nI also read the official document about [operator compatibility](https://www.tensorflow.org/lite/guide/ops_compatibility), saying that, ops such as EMBEDDING_LOOKUP, HASHTABLE_LOOKUP, `are present, but not ready for custom models`. Is it doable to write my own tflite kernels for these lookup ops? Or the tflite converter does not support the correlated operators? Thanks~!\r\n\r\n", "EMBEDDING_LOOKUP is already supported via TensorFlow Lite builtin ops. And the experimental hashtable op kernels are existing under the following directory:  https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/experimental/kernels.\r\nIn order to enable them in Python, here is the example code.\r\n\r\n```\r\nwith tf.Session() as sess:\r\n    int64_values = tf.constant([1, 2, 3], dtype=tf.int64)\r\n    string_values = tf.constant(['bar', 'foo', 'baz'], dtype=tf.string)\r\n    int64_to_string_initializer = tf.lookup.KeyValueTensorInitializer(\r\n        int64_values, string_values)\r\n    string_to_int64_initializer = tf.lookup.KeyValueTensorInitializer(\r\n        string_values, int64_values)\r\n    int64_to_string_table = tf.lookup.StaticHashTable(\r\n        int64_to_string_initializer, '7')\r\n    string_to_int64_table = tf.lookup.StaticHashTable(\r\n        string_to_int64_initializer, 4)\r\n\r\n    with tf.control_dependencies([tf.initializers.tables_initializer()]):\r\n      input_int64_tensor = tf.placeholder(tf.int64, shape=[1])\r\n      input_string_tensor = tf.placeholder(tf.string, shape=[1])\r\n      out_string_tensor = int64_to_string_table.lookup(input_int64_tensor)\r\n      out_int64_tensor = string_to_int64_table.lookup(input_string_tensor)\r\n\r\n    graph_def = tf.get_default_graph().as_graph_def()\r\n    tf.io.write_graph(graph_def, '/tmp/', 'hashtable.pbtxt')\r\n\r\n  converter = tf.lite.TFLiteConverter(graph_def,\r\n                                      [input_int64_tensor, input_string_tensor],\r\n                                      [out_string_tensor, out_int64_tensor])\r\n\r\n  supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\r\n  converter.target_spec.supported_ops = supported_ops\r\n  converter.allow_custom_ops = True\r\n  tflite_model = converter.convert()\r\n\r\n  # Initialize interpreter with HashTableV2 custom ops.\r\n  model_interpreter = interpreter_wrapper.InterpreterWithCustomOps(\r\n      model_content=tflite_model, custom_op_registerers=['AddHashtableOps'])\r\n\r\n  input_details = model_interpreter.get_input_details()\r\n  output_details = model_interpreter.get_output_details()\r\n  print('Input details: ', input_details)\r\n  print('Output details: ', output_details)\r\n\r\n  model_interpreter.allocate_tensors()\r\n  model_interpreter.reset_all_variables()\r\n  model_interpreter.set_tensor(input_details[0]['index'],\r\n                               np.array([2], dtype=np.int64))\r\n  model_interpreter.set_tensor(input_details[1]['index'],\r\n                               np.array(['foo'], dtype=np.string_))\r\n  model_interpreter.invoke()\r\n\r\n  for out in output_details:\r\n    result = model_interpreter.get_tensor(out['index'])  # Expect no errors.\r\n    print('Result tensor: ', out['name'], result.shape, result)\r\n```\r\n\r\nThe AddHashtableOps Python module exists in here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/kernels/BUILD#L177\r\n\r\nIf you want to make your own custom ops, please check out https://www.tensorflow.org/lite/guide/ops_custom.\r\n\r\nFor the below error at the conversion, currently, we are trying to fix it soon hopefully. I will leave a comment when it is fixed in the nightly build.\r\n\r\n```\r\nCannot convert a Tensor of dtype resource to a NumPy array.\r\n```\r\n\r\n", "@abattery Hi Jae Sung, thanks a lot for your feedback. Actually I saw your commits of hashtable ops in tensorflow project. Thus I was looking forward for your reply when I created this issue: ) \r\n\r\nAfter running the above example, I still have a couple of questions.\r\n1) Does the code only work for tfv2? I've tried it on both tfv2.2 and tfv1.15. The tflite file converted by tfv1.15 does not contain LookupTableImportV2 op. Whether this conversion can be success in tf1.15, in anyway? \r\n<img width=\"490\" alt=\"tflite_converted_by_tf1_15\" title=\"tflite_converted_by_tf1_15\" src=\"https://user-images.githubusercontent.com/62575734/77973157-4c654980-72a8-11ea-9c0f-5b7e45ac8f03.png\">\r\n\r\n\r\n2) What is the function of `with tf.control_dependencies([tf.initializers.tables_initializer()])` to a graph that is converted to tflite? If I don't use this context statement, but instead, use separated tf.initializers.tables_initializer(), it also cannot be converted to a correct graph.\r\n<img width=\"496\" alt=\"tf22_no_dep\" title=\"tf22_no_dep\" src=\"https://user-images.githubusercontent.com/62575734/77973166-55eeb180-72a8-11ea-8fe8-906d493e0820.png\">\r\n\r\nThank you again!", "Hi,\r\n\r\nI have tested with both TF 1.15.0 version and TF 2.2.0rc2 version with the above sample. As you said, the model generated from TF 1.15.0 version does not contains LookupTableImportV2 node. In your case, is it okay to use TF 2.x version? Thank you for reporting a bug.\r\n\r\nThe tf.control_dependencies method creates an explicit dependency between things in a graph. For example, it is required because the LookupTableImportV2 op node should be located before the LookupTableFindV2 op node appears.\r\n\r\nBest regards,\r\nJaesung", "> Hi,\r\n> \r\n> I have tested with both TF 1.15.0 version and TF 2.2.0rc2 version with the above sample. As you said, the model generated from TF 1.15.0 version does not contains LookupTableImportV2 node. In your case, is it okay to use TF 2.x version? Thank you for reporting a bug.\r\n> \r\n> The tf.control_dependencies method creates an explicit dependency between things in a graph. For example, it is required because the LookupTableImportV2 op node should be located before the LookupTableFindV2 op node appears.\r\n> \r\n> Best regards,\r\n> Jaesung\r\nHi, I've tried to complie the tf 2.x source code, and pip install it\uff0cbut when I run the example above, I met  no symbol AddHashtableOps.\r\nThanks for your help. @abattery ", "Removed AddHashtableOps support in Python temporarily. However, you can still add this to an interpreter in C++.", "> Removed AddHashtableOps support in Python temporarily. However, you can still add this to an interpreter in C++.\r\nWould you please show me a demo? Thank you very much!", "### How to Include Hashtable ops in your TFLite.\r\nCurrently, hashtable ops are under the experimental stage. You need to add hashtable ops manually by including the following dependency:\r\n\r\n `      \"//tensorflow/lite/experimental/kernels:hashtable_op_kernels\"`\r\n\r\nAnd then, your op resolver should add them like the following statements:\r\n\r\n```\r\n  // Add hashtable op handlers.\r\n  resolver->AddCustom(\"HashTableV2\",    \r\n                      tflite::ops::custom::Register_HASHTABLE());\r\n  resolver->AddCustom(\"LookupTableFindV2\",\r\n                      tflite::ops::custom::Register_HASHTABLE_FIND());\r\n  resolver->AddCustom(\"LookupTableImportV2\",\r\n                      tflite::ops::custom::Register_HASHTABLE_IMPORT());\r\n  resolver->AddCustom(\"LookupTableSizeV2\",\r\n                      tflite::ops::custom::Register_HASHTABLE_SIZE());\r\n```", "@abattery Hi Jaesung, thanks a lot for your reply. Since the TF1.15.0 of export+convert cannot success, I'm wondering if model exported from TF version under 2.x could be converted correctly?\r\n\r\n> I have tested with both TF 1.15.0 version and TF 2.2.0rc2 version with the above sample. As you said, the model generated from TF 1.15.0 version does not contains LookupTableImportV2 node. In your case, is it okay to use TF 2.x version? Thank you for reporting a bug.\r\n\r\nSay the currently lookup example you posted previously: I've tried to firstly export with model using SavedModelBuilder with `TF v1.15.0` and converted the saved model using `TF2.2.0`, but still not success. The tflite file shows a missing of LookupImportV2 Op. I'm wondering if there's any methods could make this work: TF v1.15.0 export model and TF2.2 convert? \r\n", "Model should need to store a explicit dependency between LookupImportV2 op and other Lookup ops. However, it seems that TF v1.15.0 could not store that information.\r\n\r\nIf the information is already lost, the TF 2.2 converter can not revive the missing information.", "@abattery May I ask for some details about the dependency? Is it the Python API part or C++ kernels? I'm wondering if I could get this done through refactor some tensorflow code.", "Could you try setting with \"drop_control_dependency=False\" in the TFLiteConverterV1?\r\n\r\n\r\n", "@abattery is this still the case?\r\n\r\n> Removed AddHashtableOps support in Python temporarily. However, you can still add this to an interpreter in C++.\r\n\r\nIf it's been added back, do you have any example code on how to use it from python?  As mentioned in this [stack overflow post](https://stackoverflow.com/questions/65876823/converting-model-to-tflite-with-select-tf-ops-cannot-convert-ops-hashtablev2-o), I was able to add `converter.allow_custom_ops = True` to get past `tf.HashTableV2` missing custom implemenation errors during conversion to tflite, however I'm not clear on how to perform inference with the tflite model.", "Please take a look at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/hashtable/README.md in order to use the provided hash table op kernels as a custom op library.", "Was able to replicate the issue with TF v2.5,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/31af45e243f5e3d2da1150f51da001c5/untitled300.ipynb) ..Thanks!", "This above converter error can be gone when the saved model converter is choosen.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37844\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37844\">No</a>\n"]}, {"number": 37843, "title": "Remove redundant cusolverDnIRSInfosGetNiters", "body": "It seems to be defined twice.\r\n\r\nTEST:build tensorflow with cuda 10.2", "comments": ["Fixes https://github.com/tensorflow/tensorflow/issues/37812", "Thanks @powderluv and @sanjoy. I saw that recently the file has been regenerated. Will take a look at what happen there. cc: @chsigg ", "I'm not sure how we ended up with a duplicate function, but this pull request does the right thing.", "> I'm not sure how we ended up with a duplicate function, but this pull request does the right thing.\r\n\r\nYes, but it manually modifies an auto-generated file which is why I was pushing back at first.", "> Yes, but it manually modifies an auto-generated file which is why I was pushing back at first.\r\n\r\nNVIDIA's header contains a duplicate redeclaration of this function and our wrapper generator produced a wrapper for each. We're unlikely to have to generate these again, and the wrappers do need fair amount of manual attention in any case. \r\n\r\nThis change should be merged.\r\n", "> > Yes, but it manually modifies an auto-generated file which is why I was pushing back at first.\r\n> \r\n> NVIDIA's header contains a duplicate redeclaration of this function and our wrapper generator produced a wrapper for each. We're unlikely to have to generate these again, and the wrappers do need fair amount of manual attention in any case.\r\n> \r\n> This change should be merged.\r\n\r\nOk, thanks!"]}, {"number": 37842, "title": "2.2.0-rc2 cherry-pick request: Place keras API tree at the root of pip package", "body": "Place keras API tree at the root of pip package to get autocomplete working for deeper imports (for e.g. from tensorflow.keras.losses import KLD).\r\n\r\nThis is to fix issue reported here:\r\nhttps://github.com/tensorflow/tensorflow/issues/32982#event-2825106557\r\n\r\nPiperOrigin-RevId: 301880779\r\nChange-Id: I332e0570750dfdd61712688a4f327f7993019520", "comments": []}, {"number": 37841, "title": "iOS example projects don't build with Swift file and bridging header", "body": "Problem description\r\nThe iOS example apps don't build if you add a single Swift file and bridging header to the project. The error is \"error: 'vector' file not found\" in tensorflow/examples/ios/camera/ios_image_load.h:18:10.\r\n\r\nSteps to reproduce\r\n1. Download the TensorFlow repo and follow instructions to set up any/all of the iOS example projects.\r\n2. Run an example app on your phone or simulator to verify that it works.\r\n3. Add a single empty Swift file, File.swift, to the project and include a bridging header.\r\n4. #import \"ios_image_load.h\" in the bridging header.\r\n5. Build and observe build error 'vector' file not found.\r\n\r\n**System information**\r\n- MacOS Mojave\r\n- Xcode 11.3.1\r\n- TensorFlow installed from latest on GitHub\r\n\r\nThis is similar to https://github.com/tensorflow/tensorflow/issues/22051 but that issue was closed with a solution that does not apply to the iOS example apps.", "comments": ["@tonytallman, \r\nPlease Provide the exact sequence of commands / steps that you executed before running into the problem. Thanks", "@gadagashwini \r\nThe tensorflow repository has example iOS apps at tensorflow/examples/ios. If you add a Swift file to any of the example apps then the example app won't build. This demonstrates a general problem with mixing tensorflow c++ and Swift. Using one of tensorflow's example apps just makes it easier to demonstrate the problem.\r\n\r\n1. Download or clone tensorflow repository.\r\n2. Follow the instructions at https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/ios/README.md to build and run one of the three example apps.\r\n3. Add a single empty Swift file, File.swift, to the example app project and include a bridging header.\r\n4. Add the line #import \"ios_image_load.h\" in the bridging header to expose tensorflow to Swift.\r\n5. Build and observe build error 'vector' file not found.\r\n", "@jvishnuvardhan \r\nI'm pretty sure that the answer is to create an Objective-C wrapper around ios_image_load.h and put that wrapper into the bridging header. If you give me a couple of days I can provide a more detailed answer and maybe even submit a pull-request with a Swift sample using tensorflow c++ code.", "I have confirmed that the solution is to create an Objective-C++ wrapper class with a header file that contains no c++, and code file that imports ios_image_load.h. Put the wrapper class' header file in the bridging header file. Now you can call the wrapper class from Swift.\r\n\r\nWrapperClass.h:\r\n----------------\r\n```\r\n@interface WrapperClass : NSObject\r\n- (void)loadImage;\r\n@end\r\n```\r\n\r\nWrapperClass.mm:\r\n------------------\r\n```\r\n#import \"WrapperClass.h\"\r\n#import \"ios_image_load.h\" \r\n@implementation WrapperClass\r\n- (void)loadImage {\r\n    std::vector<tensorflow::uint8> image_data = LoadImageFromFile(\r\n      [image_path UTF8String], &image_width, &image_height, &image_channels);\r\n}\r\n@end\r\n```\r\n\r\ntf_simple_example-Bridging-Header.h:\r\n--------------------------------------\r\n```\r\n#import \"ImageLoader.h\"\r\n```\r\n\r\nImageLoaderSwift.swift:\r\n------------------------\r\n```\r\nclass ImageLoaderSwift {\r\n    init() {\r\n        ImageLoader().loadImage()\r\n    }\r\n}\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37841\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37841\">No</a>\n"]}, {"number": 37840, "title": "validation_split-Parameter in model.fit() leads to severe crashes due to enormous stacktrace", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): Installed from Pypi (Python Packaging Index), Version 2.1.0\r\n- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0\r\n- Python version: 3.7.6\r\n- Bazel version (if compiling from source): -\r\n- GCC/Compiler version (if compiling from source): -\r\n- CUDA/cuDNN version: nvcc -V: release 10.1, V10.1.105 \r\n- GPU model and memory: GTX 1060, 6 GB \r\n\r\n**Describe the current behavior**\r\n\r\nI created the following model and I am using it in a jupyter notebook to learn some data:\r\n\r\n```\r\nmodel = Sequential()\r\nmodel.add(LSTM(100, input_shape=input_shape, return_sequences=True))\r\nmodel.add(LSTM(100, return_sequences=True))\r\nmodel.add(LSTM(100))\r\nmodel.add(Dense(number_of_classes, activation='softmax'))\r\n\r\nmodel.compile(optimizer=Adam(lr=0.001),\r\n              loss='categorical_crossentropy', \r\n              metrics=['acc'])\r\n\r\nhistory = model.fit(x=[MODEL_DATA['DATA_TRAIN_PADDED_NORMALIZED']],\r\n                    y=[MODEL_DATA['DATA_LABELS_OHC']],\r\n                    validation_split=0.2,\r\n                    epochs=500,\r\n                    verbose=1)\r\n```\r\n\r\nWhen I imported all layers from the `keras`-package, the code works successfully on the CPU. Yet I would like to use the GPU-accelerated LSTMs (formerly known as CuDNNLSTM, but they are merged in TF 2.1 into LSTM).\r\n\r\nTo train my model, I am using a jupyter notebook. Sadly, once I changed my imports from the old `keras`-packages to `tensorflow.keras` and thus to the GPU-accelerated LSTMs, I suffered from sudden major crashes. And by \"major\" I mean a crashing jupyter-server that crashes my Firefox as well. When using pycharm with the jupyter notebook plugin, pycharm crashes too.\r\n\r\nSo I wondered why I had those massive problems across different processes on my machines that occured when I executed tensorflow and my notebook.\r\n\r\nAs it turns out, I could trace the problem to the following line [0]. It appears that as part of raising the ValueError, `x` is returned in its constructor in the `str.format()`-call. Here, `x` is my complete training data set. This resulted in a dump of 262 MB of text into stderr as part of the stacktrace that then lead to the consequences (crashing jupyter server, crashing browser via websocket-connection to localhost). I found that out by piping the stream to a file, as the exception's message has a len() of 275168064 characters!\r\n\r\nNext, I wondered if the bug is still present in the newest version of tensorflow. I could see in git that the corresponding lines of code do not exist anymore when installing `tf-nightly` (version: v1.12.1-27849-g9278bbfc24 2.2.0-dev20200323 ) as the whole file, `training_v2.py`, does not exist anymore. Subsequently, I re-ran my code with the current tf-nightly from PyPI. First, I got this error [1], as I did not provide a numpy array.\r\n\r\nAfter changing my model.fit() to the following:\r\n```\r\nhistory = model.fit(x=np.array([MODEL_DATA['DATA_TRAIN_PADDED_NORMALIZED']]),\r\n                    y=np.array([MODEL_DATA['DATA_LABELS_OHC']]),\r\n                    validation_split=0.2,\r\n                    epochs=500,\r\n                    verbose=1)\r\n```\r\n\r\n... I ran into the following error [2]:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Joo\\AppData\\Local\\Programs\\Python\\Python37\\lib\\contextlib.py\", line 130, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"C:\\[...]\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2805, in variable_creator_scope\r\n    yield\r\n  File \"C:\\[...]\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 854, in fit\r\n    epoch_logs = copy.copy(logs)\r\nUnboundLocalError: local variable 'logs' referenced before assignment\r\n```\r\nIt appears, that `logs` does not exist here [2].\r\n\r\nNot using `validation_split` as part of model.fit() solved all my problems for tf 2.1.0, but I had to find it out the hard way. \ud83d\ude41  Moreover, I could not resolve the problem for tf-nightly at all, even when omitting the parameter as other exceptions popped up.\r\n\r\nThanks in advance for checking the code and improving tensorflow.\r\n\r\n[0] https://github.com/tensorflow/tensorflow/blob/f270180a6caa8693f2b2888ac7e6b8e69c4feaa8/tensorflow/python/keras/engine/training_v2.py#L539\r\n\r\n[1] https://github.com/tensorflow/tensorflow/blob/e7bbb424808eb7ebbeb959b993496adafd024609/tensorflow/python/keras/engine/data_adapter.py#L1386\r\n\r\n[2] https://github.com/tensorflow/tensorflow/blob/c45d13f92b921dae044a5639f8b1bc560fe9b71c/tensorflow/python/keras/engine/training.py#L857\r\n\r\n**Describe the expected behavior**\r\n\r\nI would expect an exception that does not return over 260 MB of text as part of the stack trace. The important part of the stack trace (in the beginning of the message) is also not shown (i. e., that validation_split cannot be used), as the 260 MB of `x` overfill the non-infinite buffer of my IDE in a split second, thus omitting the whole stack trace with my training data.", "comments": ["@jliebers \r\nplease provide us with complete simple stand alone code for us to replicate the issue faced by you in our local, [gist of code shared is](https://colab.sandbox.google.com/gist/Saduf2019/f99a24679f147526f8466432751ad3f4/untitled106.ipynb)", "Hi @Saduf2019 ,\r\n\r\nthank you for your quick response. \ud83d\ude42 \ud83d\ude80 \r\n\r\nPlease check out this gist: https://gist.github.com/jliebers/b9a285ac97607916a10cb091b860fa48\r\n\r\nFor the **tf-nightly** problem, please check the output from above. As described it justs ends in a local variable not being assigned without any large problems.\r\n\r\nFor the **tensorflow==2.1.0** problem, that resulted in major crashes of jupyter and my browser, please check this gist: https://gist.github.com/jliebers/42a3d787aea2595219e48e2abea6c7cf\r\n(Please note the empty output of the last cell. Apparently colab does not execute it at all, but it causes major crashes on my offline-setup with jupyter and firefox)\r\n\r\nBy moving my code into this example that can be reproduced I found some obvious flaws which on the other hand still should not cause such massive problems. I think the biggest problem is that I did not use numpy but sticked to the standard iterable data structures of python. \r\n\r\nTo be fair, in my real project I stick to numpy, but since my real notebook became huge I apparently altered some types by mistake in the middle of it, resulting in standard python data structures. (i.e., `DATA_NORMALIZED` being a list of lists of tuples and `LABELS_OHC` being a list of lists).\r\n\r\n![grafik](https://user-images.githubusercontent.com/24356915/77411807-47daf580-6dbd-11ea-9087-aa7b657e2e0c.png)\r\n\r\n![grafik](https://user-images.githubusercontent.com/24356915/77411760-34c82580-6dbd-11ea-9421-d7225af645c2.png)\r\n\r\nThank you in advance for your consideration.", "I guess this is training issue rather than a LSTM issue, the training logic has been updated recently. Adding @omalleyt12.", "Hi @qlzh727 ,\r\n\r\nthank you and thank you all for your consideration. \ud83d\ude42 \ud83d\udc4d \r\n\r\nI just would quickly like to clarify, that the main reason for me to open this issue is, that the raised Exception in tf-2.1.0 contains a string which includes the whole training `x` (262 MB of text data), thus leading to crashes and such. The tf-nightly issue is of course also a problem but from my perspective way less severe.\r\n\r\nThank you and thank you all for the good work!", "Thanks  for the report. Will submit the fix very soon.", "Should be fixed now. Btw, your code is not providing a correct input data to the model. The np.array([list]) will make the a numpy array with shape [1, ?, ?], and instead, you should do np.array(list).", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37840\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37840\">No</a>\n"]}, {"number": 37839, "title": "ModelCheckpoint callback can't save entire subclassed models", "body": "The keras callback `ModelCheckpoint` won't save a subclassed model in SavedModel format. It only ever saves the checkpoints.\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nclass TestModel(tf.keras.Model):\r\n\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.dense1 = tf.keras.layers.Dense(64, activation='relu')\r\n        self.dense2 = tf.keras.layers.Dense(64, activation='relu')\r\n        self.dense3 = tf.keras.layers.Dense(10)\r\n\r\n    def call(self, inputs):\r\n        x = self.dense1(inputs)\r\n        x = self.dense2(x)\r\n        return self.dense3(x)\r\n\r\n\r\nmodel = TestModel()\r\nmodel.compile(optimizer=tf.keras.optimizers.Adam(0.01),\r\n              loss='mse',      \r\n              metrics=['mae'])  \r\n\r\ndata = np.random.random((1000, 32))\r\nlabels = np.random.random((1000, 10))\r\n\r\nmodel.fit(\r\n    data, labels, epochs=10, batch_size=32,\r\n    callbacks=[tf.keras.callbacks.ModelCheckpoint('model_{epoch:02d}.ckpt',\r\n                                                  save_weights_only=False)])\r\n```\r\n\r\nIt seems as if the callback forces weights_only saving [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/callbacks.py#L1148). While this makes sense if the model is in `.h5` format, it doesn't make sense for `SavedModel` format.", "comments": ["@lminer \r\n\r\nCan you please share simple standalone code to reproduce the issue.It helps us in localizing the issue faster. Please, let us know TF version as well. Thanks!", "If I read well the source code, if you custom model inherits from `Model` and is a graph network (_i.e._ not running eagerly) it should be working...", "@pandrey-fr @ravikyram I'll try to get a standalone example together. The problem must be that the model is being run eagerly. How to you force it to be a graph network? Also, why is it a problem if it's run eagerly? I made my own version of the callback where I deleted the check for whether it is running eagerly and it saves without a problem.", "@ravikyram @pandrey-fr it's updated.", "Okay, actually it turns out that `_is_graph_network` is _not_ about `Eager` execution, but about the distinction between the functional and subclass APIs.\r\n\r\nIn functional API, you would define your example network as:\r\n```python\r\ndense1 = tf.keras.layers.Dense(64, activation='relu')\r\ndense2 = tf.keras.layers.Dense(64, activation='relu')\r\ndense3 = tf.keras.layers.Dense(10)\r\ninputs = tf.keras.Input((32,), dtype='float32')\r\noutput = dense3(dense2(dense1(inputs)))\r\nmodel = tf.keras.Model(inputs, output)\r\n```\r\nWhich would have the computation graph built at instantiation, notably through the clear definition of inputs' (and thus, all nodes') specification.\r\n\r\nIn the subclass API however, the instantiation procedure differs ([this method](https://github.com/tensorflow/tensorflow/blob/dc05a7a6b94e65f92924c82841a5332c86cbc3c9/tensorflow/python/keras/engine/network.py#L366) is called), which results in a Model with somehow reduced capabilities. To be fair, the point of this is to allow defining `Model` constructor subclasses which implement alternative behaviours, _e.g._ different train step procedures, yet remain general enough to be used in functional API.\r\n\r\nNow in your example, I would advise writing your model architecture as a `tf.keras.layers.Layer` subclass, and then using the functional API to instantiate a `Model` out of it:\r\n```python\r\nclass TestModel(tf.keras.layers.Layer):\r\n\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.dense1 = tf.keras.layers.Dense(64, activation='relu')\r\n        self.dense2 = tf.keras.layers.Dense(64, activation='relu')\r\n        self.dense3 = tf.keras.layers.Dense(10)\r\n\r\n    def call(self, inputs):\r\n        x = self.dense1(inputs)\r\n        x = self.dense2(x)\r\n        return self.dense3(x)\r\n\r\ninputs = tf.keras.Input((32,), dtype='float32')\r\nnetwork = TestModel()\r\nmodel = tf.keras.Model(inputs, network(inputs))\r\n```", "Is it necessary to use that approach anymore? In tensorflow 2.2.0-rc1 I can save a subclassed model in the SavedModel format and restore it without a problem. Maybe this check is now obsolete.\r\n\r\nEdit: @pandrey-fr is the problem that it wouldn't be possible to serialize the model into the SavedModel format if I overrode `train_step` as then it really would involve serializing code?", "> In tensorflow 2.2.0-rc1 I can save a subclassed model in the SavedModel format and restore it without a problem.\r\n\r\nI have to admit I don't quite get why it works in 2.2 and not in previous versions, but great! If I understand well, some specifications are inferred / set within the `fit` call, which explains why I was initially able to replicate the issue by attempting to use `model.save` _before_ `model.fit`.\r\n\r\n> is the problem that it wouldn't be possible to serialize the model into the SavedModel format if I overrode train_step as then it really would involve serializing code?\r\n\r\nNormally this should not be an issue. The checkpoints should allow you to resume training with an instance of the same custom model class; I don't think that checkpoints do not contain the `train_step` code, but to be honest I do not know much about the checkpointing system.", "Should we perhaps alter that check to only apply for h5 format?", "@lminer Isn't this the intended behavior of checkpointing as it only saves weights of the model not the model itself?", "@gowthamkpr the callback has the option of either saving weights or saving the entire model. Given that it has this option, and that it has the ability to delivery this functionality provided you are saving in SavedModel format, why not enable it?", "I am running in this same issue as well, have a sub-classed keras model that I can save fine manually using the SaveModel format. However when using the ModelCheckpoint this is not possible, as model._is_graph_network is False for a sub-classed model (which results in save_weights_only flag to be set to True ([here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/callbacks.py#L1161)). ", "@gowthamkpr Any update on this? I understand why this was the intended behavior back when subclassed models couldn't be saved. But now that this functionality has been added in tensorflow 2.2.0, it makes sense to update the callback so that there is feature parity between subclassed models and functional api models.", "@lminer  @claudio525 Thanks for the update.", "Is there an update here?", "Yes, let's have an update on this ASAP, please.\r\n\r\nThanks.", "I still see this issue in TF 2.3.0. When I reload model, it doesn't have custom train_step method. Is there any fix yet?\r\n\r\nI would like to continue training model after reloading it.", "Upvote here. I would love to see this fixed.", "I m facing the same issue as well subclass model is the only option for the keras CRF layer and as result of this issue we can't save the best model post early stopping.", "Duplicate of #37620", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37839\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37839\">No</a>\n", "any progress ? "]}, {"number": 42795, "title": "[ko] Remove references to tf-nightly-2.0-preview package", "body": "The `tf-nightly-2.0-preview` package does not exist anymore. Please upgrade all notebooks to use `%tensorflow_version 2.x` like:\r\n\r\n```\r\ntry:\r\n  # %tensorflow_version only exists in Colab.\r\n  %tensorflow_version 2.x\r\nexcept Exception:\r\n  pass\r\n```\r\n\r\nAffects:\r\n\r\n* [/site/ko/tutorials/keras/text_classification.ipynb](https://github.com/tensorflow/docs-l10n/blob/master/site/ko/tutorials/keras/text_classification.ipynb)\r\n* [/site/ko/tutorials/keras/overfit_and_underfit.ipynb](https://github.com/tensorflow/docs-l10n/blob/master/site/ko/tutorials/keras/overfit_and_underfit.ipynb)\r\n* [/site/ko/tutorials/structured_data/feature_columns.ipynb](https://github.com/tensorflow/docs-l10n/blob/master/site/ko/tutorials/structured_data/feature_columns.ipynb)\r\n", "comments": ["REVIEWERS cc: @rickiepark @cre8tor @choiuijin1125 @JKIsaacLee @NoelBird @wckim @eat-toast @jaketae", "I\u2019ll work on the fix today and open a PR!", "Thanks @jaketae :)"]}, {"number": 42794, "title": "[zh-cn] Remove references to tf-nightly-2.0-preview package", "body": "The `tf-nightly-2.0-preview` package does not exist anymore. Please upgrade all notebooks to use `%tensorflow_version 2.x` like:\r\n\r\n```\r\ntry:\r\n  # %tensorflow_version only exists in Colab.\r\n  %tensorflow_version 2.x\r\nexcept Exception:\r\n  pass\r\n```\r\n\r\nAffects:\r\n\r\n* [/site/zh-cn/lite/convert/python_api.md](https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/lite/convert/python_api.md)\r\n* [/site/zh-cn/tutorials/estimator/boosted_trees.ipynb](https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/tutorials/estimator/boosted_trees.ipynb)\r\n", "comments": ["REVIEWERS cc: @kuri-leo @JayYip @yantaozhao @loveunk @wind2esg @tigerneil @MofiiTech @gaoljhy @Mr-Linus @flopsySong @echosun1996", "These files should be synced using out GitLocalize project: https://gitlocalize.com/tensorflow/docs-l10n\r\n\r\n* https://gitlocalize.com/repo/4592/zh-cn/site/en-snapshot/lite/convert/python_api.md\r\n* `boosted_tree.ipynb` looks fixed.\r\n\r\nBut this issue is old and I'm working on a better status/notification system. Closing"]}, {"number": 42793, "title": "[ja] Remove references to tf-nightly-2.0-preview package", "body": "The `tf-nightly-2.0-preview` package does not exist anymore. Please upgrade all notebooks to use `%tensorflow_version 2.x` like:\r\n\r\n```\r\ntry:\r\n  # %tensorflow_version only exists in Colab.\r\n  %tensorflow_version 2.x\r\nexcept Exception:\r\n  pass\r\n```\r\n\r\nAffects:\r\n\r\n* [/site/ja/lite/convert/python_api.md](https://github.com/tensorflow/docs-l10n/blob/master/site/ja/lite/convert/python_api.md)\r\n* [/site/ja/guide/function.ipynb](https://github.com/tensorflow/docs-l10n/blob/master/site/ja/guide/function.ipynb)\r\n* [/site/ja/tutorials/load_data/csv.ipynb](https://github.com/tensorflow/docs-l10n/blob/master/site/ja/tutorials/load_data/csv.ipynb)\r\n", "comments": ["REVIEWERS cc: @ohtaman @sfujiwara @masa-ita @AseiSugiyama @yukinagae @nuka137 @chie8842 @kiszk", "Thank you for your notification, we'll update & fix them.", "I think https://github.com/tensorflow/docs-l10n/pull/152 fixed this issue. However, we have to update these outdated documents.\r\n\r\n- [/site/ja/lite/convert/python_api.md](https://github.com/tensorflow/docs-l10n/blob/master/site/ja/lite/convert/python_api.md)\r\n- [ja/tutorials/load_data/csv.ipynb](https://github.com/tensorflow/docs-l10n/blob/master/site/ja/tutorials/load_data/csv.ipynb) (it's broken as mentioned  https://github.com/tensorflow/docs-l10n/issues/138)\r\n\r\nI'm going to update them and make two PRs for each document.", "Thanks @AseiSugiyama for taking a look.\r\n\r\nNow that Colab defaults to TF 2.2, we can remove the `%tensorflow_version 2.x` block from notebooks.\r\n\r\nMark just merged https://github.com/tensorflow/docs-l10n/pull/152 which should remove them, but we may need to keep an eye on any outstanding pull requests", "Right, I would like to contribute to the TF community to be an \"eye\" \ud83d\udc40 \r\n\r\nBy the way, I found it is hard to update translated documents to follow the original document since we lack the sync tool like `nb_code_sync.py` after separating docs repo and docs-l10n repo. Do you have any ideas about this?", "@AseiSugiyama Hello. `nb_code_sync.py` should still work, you can pass it the `--src` argument.\r\nBut, point taken, I'll look into streamlining that tool now that the repos are separate", "@lamberta How about the result of your taking a look? I think it is not obvious the way to maintain the `en` directory and other languages' directory that we can use `nb_code_sync.py` with git only because `docs` and `docs-l10n` are separated.", "Hi @AseiSugiyama , thanks for taking a look.\r\nI made the command-line errors a little easier to read in https://github.com/tensorflow/docs-l10n/pull/175, but the script seems to work-as-intended:\r\n\r\n```\r\n# Install deps:\r\n$ pip3 install --user absl-py\r\n\r\n# Assume you've downloaded both tensorflow/docs and tensorflow/docs-l10n repos\r\n$ cd docs-l10n\r\n\r\n$ ./tools/nb_code_sync.py --src=../docs/site/en/guide/function.ipynb \\\r\n    ./site/ja/guide/function.ipynb\r\n\r\nError: Notebooks must have same amount of code cells to sync between.\r\nPlease manually compare the source and destination notebooks.\r\n```\r\n\r\nUnfortunately. these Japanese notebooks are quite out-of-date and missing a number of code cells that are in the en/ source-of-truth. This script assumes that the number of code cells matches between the two notebooks to properly sync.\r\nQuickly looking at the [Japanese version](https://github.com/tensorflow/docs-l10n/blob/master/site/ja/guide/function.ipynb), I can see that it's missing the \"Debugging\" section in the [English version](https://github.com/tensorflow/docs/blob/master/site/en/guide/function.ipynb) (and maybe more).\r\n\r\nFor something like this, you'll have to manually look through and make sure it's structurally similar to the en/ version. `nb_code_sync.py` is really just meant to keep any code changes up-to-date and avoid too much drift.", "@lamberta Thank you for your kindly reporting! It sounds nice that we will be able to use the `nb_code_sync.py` after updating these three notebooks (maybe). I made a PR for csv.ipynb https://github.com/tensorflow/docs-l10n/pull/176 and try to update all these notebooks.\r\n", "I updated related documents by https://github.com/tensorflow/docs-l10n/pull/176 https://github.com/tensorflow/docs-l10n/pull/190 https://github.com/tensorflow/docs-l10n/pull/220 and they've been marged \ud83c\udf89\r\n\r\nI guess we can safely close this issue. Thank you for your work, @lamberta!", "Awesome. Thank you @AseiSugiyama this is great\r\n"]}, {"number": 37838, "title": "Can't restore weights to fine-tune SSD model", "body": "I am trying to fine-tune the model `ssd_mobilenet_coco_v1` but, when I execute the training script I do not obtain **restoring checkpoints**. Instead, I obtain **saving checkpoints** (as described below), so I think I am not using the pre-trained model correctly.\r\n**My question is: am I loading the pre-trained weights or the weights are being randomly initialized?**\r\nI provide the obtained output, the expected output, and my `pipeline.config` file.\r\nThanks in advance.\r\n\r\n**System information** \r\n- OS Platform and Distribution: Ubuntu 18.04 \r\n- TensorFlow installed from binary - 1.15\r\n- Python version: 3 \r\n- CUDA/cuDNN version: 10.0/7.6.5\r\n- GPU model and memory: 12GB and Tesla P100-PCIE-16GB\r\n\r\n**Describe the current behavior**\r\n```\r\nWARNING:tensorflow:\r\nThe TensorFlow contrib module will not be included in TensorFlow 2.0.\r\nFor more information, please see:\r\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\r\n  * https://github.com/tensorflow/addons\r\n  * https://github.com/tensorflow/io (for I/O related ops)\r\nIf you depend on functionality not listed there, please file an issue.\r\n\r\nWARNING:tensorflow:From /content/models/research/object_detection/model_main.py:109: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\r\n\r\nWARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\r\n\r\nW0323 17:45:14.716734 140406623115136 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\r\n\r\nWARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:628: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\r\n\r\nW0323 17:45:14.720826 140406623115136 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:628: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\r\n\r\nWARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\r\nW0323 17:45:14.720992 140406623115136 model_lib.py:629] Forced number of epochs for all eval validations to be 1.\r\nWARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\r\n\r\nW0323 17:45:14.721235 140406623115136 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\r\n\r\nINFO:tensorflow:Maybe overwriting train_steps: 50000\r\nI0323 17:45:14.721395 140406623115136 config_util.py:488] Maybe overwriting train_steps: 50000\r\nINFO:tensorflow:Maybe overwriting use_bfloat16: False\r\nI0323 17:45:14.721562 140406623115136 config_util.py:488] Maybe overwriting use_bfloat16: False\r\nINFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\r\nI0323 17:45:14.721702 140406623115136 config_util.py:488] Maybe overwriting sample_1_of_n_eval_examples: 1\r\nINFO:tensorflow:Maybe overwriting eval_num_epochs: 1\r\nI0323 17:45:14.721852 140406623115136 config_util.py:488] Maybe overwriting eval_num_epochs: 1\r\nINFO:tensorflow:Maybe overwriting load_pretrained: True\r\nI0323 17:45:14.722014 140406623115136 config_util.py:488] Maybe overwriting load_pretrained: True\r\nINFO:tensorflow:Ignoring config override key: load_pretrained\r\nI0323 17:45:14.722141 140406623115136 config_util.py:498] Ignoring config override key: load_pretrained\r\nWARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\r\nW0323 17:45:14.722986 140406623115136 model_lib.py:645] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\r\nINFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\r\nI0323 17:45:14.723167 140406623115136 model_lib.py:680] create_estimator_and_inputs: use_tpu False, export_to_tpu False\r\nINFO:tensorflow:Using config: {'_model_dir': '/content/data_trunks/train_dir', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\r\ngraph_options {\r\n  rewrite_options {\r\n    meta_optimizer_iterations: ONE\r\n  }\r\n}\r\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb28ee6dd30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\r\nI0323 17:45:14.723658 140406623115136 estimator.py:212] Using config: {'_model_dir': '/content/data_trunks/train_dir', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\r\ngraph_options {\r\n  rewrite_options {\r\n    meta_optimizer_iterations: ONE\r\n  }\r\n}\r\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb28ee6dd30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\r\nWARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fb28ee132f0>) includes params argument, but params are not passed to Estimator.\r\nW0323 17:45:14.723914 140406623115136 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fb28ee132f0>) includes params argument, but params are not passed to Estimator.\r\nINFO:tensorflow:Not using Distribute Coordinator.\r\nI0323 17:45:14.724645 140406623115136 estimator_training.py:186] Not using Distribute Coordinator.\r\nINFO:tensorflow:Running training and evaluation locally (non-distributed).\r\nI0323 17:45:14.724889 140406623115136 training.py:612] Running training and evaluation locally (non-distributed).\r\nINFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\r\nI0323 17:45:14.725183 140406623115136 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\r\nWARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\r\nW0323 17:45:14.731667 140406623115136 deprecation.py:323] From /tensorflow-1.15.0/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\r\nWARNING:tensorflow:From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\r\n\r\nW0323 17:45:14.744504 140406623115136 module_wrapper.py:139] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\r\n\r\nWARNING:tensorflow:From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\r\n\r\nW0323 17:45:14.744798 140406623115136 module_wrapper.py:139] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\r\n\r\nWARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\r\n\r\nW0323 17:45:14.759091 140406623115136 module_wrapper.py:139] From /content/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\r\n\r\nWARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\r\nW0323 17:45:14.759980 140406623115136 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.\r\nWARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.experimental.parallel_interleave(...)`.\r\nW0323 17:45:14.767862 140406623115136 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.experimental.parallel_interleave(...)`.\r\nWARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\r\nW0323 17:45:14.768066 140406623115136 deprecation.py:323] From /tensorflow-1.15.0/python3.6/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\r\nWARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.map()\r\nW0323 17:45:14.794663 140406623115136 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.map()\r\nWARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.\r\n\r\nW0323 17:45:16.303668 140406623115136 module_wrapper.py:139] From /tensorflow-1.15.0/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.\r\n\r\nWARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\r\n\r\nW0323 17:45:24.681373 140406623115136 module_wrapper.py:139] From /tensorflow-1.15.0/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\r\n\r\nWARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.where in 2.0, which has the same broadcast rule as np.where\r\nW0323 17:45:24.773309 140406623115136 deprecation.py:323] From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.where in 2.0, which has the same broadcast rule as np.where\r\nWARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\r\n\r\nW0323 17:45:27.258008 140406623115136 module_wrapper.py:139] From /tensorflow-1.15.0/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\r\n\r\nWARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\n`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\r\nW0323 17:45:31.055150 140406623115136 api.py:332] From /tensorflow-1.15.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\n`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\r\nWARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\r\n\r\nW0323 17:45:35.093766 140406623115136 module_wrapper.py:139] From /tensorflow-1.15.0/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\r\n\r\nWARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\r\n\r\nW0323 17:45:35.095073 140406623115136 module_wrapper.py:139] From /tensorflow-1.15.0/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\r\n\r\nWARNING:tensorflow:From /content/models/research/object_detection/inputs.py:166: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.cast` instead.\r\nW0323 17:45:35.583931 140406623115136 deprecation.py:323] From /content/models/research/object_detection/inputs.py:166: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.cast` instead.\r\nWARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\r\n\r\nW0323 17:45:37.435810 140406623115136 module_wrapper.py:139] From /tensorflow-1.15.0/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\r\n\r\nWARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.batch(..., drop_remainder=True)`.\r\nW0323 17:45:38.169332 140406623115136 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.batch(..., drop_remainder=True)`.\r\nINFO:tensorflow:Calling model_fn.\r\nI0323 17:45:38.185292 140406623115136 estimator.py:1148] Calling model_fn.\r\nWARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\r\n\r\nW0323 17:45:38.194174 140406623115136 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\r\n\r\nWARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use `layer.__call__` method instead.\r\nW0323 17:45:38.196500 140406623115136 deprecation.py:323] From /tensorflow-1.15.0/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use `layer.__call__` method instead.\r\nWARNING:tensorflow:From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\r\n\r\nW0323 17:45:40.323006 140406623115136 module_wrapper.py:139] From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\r\n\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI0323 17:45:40.337304 140406623115136 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI0323 17:45:40.377328 140406623115136 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI0323 17:45:40.414876 140406623115136 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI0323 17:45:40.454860 140406623115136 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI0323 17:45:40.493021 140406623115136 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI0323 17:45:40.533962 140406623115136 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\r\nWARNING:tensorflow:From /content/models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\r\n\r\nW0323 17:45:40.580100 140406623115136 module_wrapper.py:139] From /content/models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\r\n\r\nWARNING:tensorflow:From /content/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\r\n\r\nW0323 17:45:40.581026 140406623115136 module_wrapper.py:139] From /content/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\r\n\r\nWARNING:tensorflow:From /content/models/research/object_detection/utils/variables_helper.py:142: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\r\n\r\nW0323 17:45:40.583110 140406623115136 module_wrapper.py:139] From /content/models/research/object_detection/utils/variables_helper.py:142: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\r\n\r\nWARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:353: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\r\n\r\nW0323 17:45:40.585104 140406623115136 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:353: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\r\n\r\nWARNING:tensorflow:From /content/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\r\n\r\nW0323 17:45:41.311894 140406623115136 module_wrapper.py:139] From /content/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\r\n\r\nWARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1163: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\r\n\r\nW0323 17:45:44.619992 140406623115136 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1163: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\r\n\r\nWARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\r\n\r\nW0323 17:45:44.627572 140406623115136 module_wrapper.py:139] From /content/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\r\n\r\nWARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\r\n\r\nW0323 17:45:44.629132 140406623115136 module_wrapper.py:139] From /content/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\r\n\r\nWARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1275: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\r\n\r\nW0323 17:45:44.672892 140406623115136 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1275: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\r\n\r\nWARNING:tensorflow:From /content/models/research/object_detection/builders/graph_rewriter_builder.py:36: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\r\n\r\nW0323 17:45:44.675707 140406623115136 module_wrapper.py:139] From /content/models/research/object_detection/builders/graph_rewriter_builder.py:36: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\r\n\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/add_fold\r\nI0323 17:45:50.407618 140406623115136 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/add_fold\r\nI0323 17:45:50.408249 140406623115136 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/add_fold\r\nI0323 17:45:50.408696 140406623115136 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/add_fold\r\nI0323 17:45:50.409127 140406623115136 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/add_fold\r\nI0323 17:45:50.409549 140406623115136 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/add_fold\r\nI0323 17:45:50.410022 140406623115136 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/add_fold\r\nI0323 17:45:50.410556 140406623115136 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/add_fold\r\nI0323 17:45:50.411051 140406623115136 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/add_fold\r\nI0323 17:45:50.411566 140406623115136 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/add_fold\r\nI0323 17:45:50.412048 140406623115136 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/add_fold\r\nI0323 17:45:50.412456 140406623115136 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/add_fold\r\nI0323 17:45:50.412898 140406623115136 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/add_fold\r\nI0323 17:45:50.413309 140406623115136 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/add_fold\r\nI0323 17:45:50.413769 140406623115136 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/add_fold\r\nI0323 17:45:50.414207 140406623115136 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/add_fold\r\nI0323 17:45:50.414690 140406623115136 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/add_fold\r\nI0323 17:45:50.415128 140406623115136 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/add_fold\r\nI0323 17:45:50.415588 140406623115136 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/add_fold\r\nI0323 17:45:50.415981 140406623115136 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/add_fold\r\nI0323 17:45:50.416409 140406623115136 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/add_fold\r\nI0323 17:45:50.416898 140406623115136 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/add_fold\r\nI0323 17:45:50.417309 140406623115136 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/add_fold\r\nI0323 17:45:50.417730 140406623115136 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/add_fold\r\nI0323 17:45:50.418143 140406623115136 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/add_fold\r\nI0323 17:45:50.418587 140406623115136 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/add_fold\r\nI0323 17:45:50.419028 140406623115136 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/add_fold\r\nI0323 17:45:50.419415 140406623115136 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/add_fold\r\nWARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:380: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\r\n\r\nW0323 17:45:50.432834 140406623115136 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:380: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\r\n\r\nWARNING:tensorflow:From /content/models/research/object_detection/builders/optimizer_builder.py:58: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\r\n\r\nW0323 17:45:50.448522 140406623115136 module_wrapper.py:139] From /content/models/research/object_detection/builders/optimizer_builder.py:58: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\r\n\r\nWARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:398: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\r\n\r\nW0323 17:45:50.448780 140406623115136 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:398: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\r\n\r\nWARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:515: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\r\n\r\nW0323 17:45:57.322220 140406623115136 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:515: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\r\n\r\nWARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:519: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\r\n\r\nW0323 17:45:57.992308 140406623115136 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:519: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\r\n\r\nWARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:520: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\r\n\r\nW0323 17:45:57.992649 140406623115136 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:520: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\r\n\r\nINFO:tensorflow:Done calling model_fn.\r\nI0323 17:45:57.993029 140406623115136 estimator.py:1150] Done calling model_fn.\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nI0323 17:45:57.994582 140406623115136 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\r\nINFO:tensorflow:Graph was finalized.\r\nI0323 17:46:01.981108 140406623115136 monitored_session.py:240] Graph was finalized.\r\n2020-03-23 17:46:01.986871: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\r\n2020-03-23 17:46:01.987126: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x172ef100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-03-23 17:46:01.987164: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-03-23 17:46:01.989628: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-03-23 17:46:02.107870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-03-23 17:46:02.108885: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x172eef40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-03-23 17:46:02.108919: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\r\n2020-03-23 17:46:02.109195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-03-23 17:46:02.110107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\r\npciBusID: 0000:00:04.0\r\n2020-03-23 17:46:02.110456: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-03-23 17:46:02.112221: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-03-23 17:46:02.115141: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-03-23 17:46:02.115636: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-03-23 17:46:02.117511: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-03-23 17:46:02.118515: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-03-23 17:46:02.122292: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-03-23 17:46:02.122478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-03-23 17:46:02.123576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-03-23 17:46:02.124399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n2020-03-23 17:46:02.124482: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-03-23 17:46:02.126257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-03-23 17:46:02.126306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \r\n2020-03-23 17:46:02.126323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \r\n2020-03-23 17:46:02.126518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-03-23 17:46:02.127473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-03-23 17:46:02.128351: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\r\n2020-03-23 17:46:02.128408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\r\nINFO:tensorflow:Running local_init_op.\r\nI0323 17:46:05.840927 140406623115136 session_manager.py:500] Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nI0323 17:46:06.250185 140406623115136 session_manager.py:502] Done running local_init_op.\r\nINFO:tensorflow:\r\nSaving checkpoints for 0 into /content/data_trunks/train_dir/model.ckpt\r\n```\r\n\r\n**Describe the expected behavior**\r\nI was expecting to see something like\r\n```\r\n(...)\r\nI0323 17:46:17.423462 140406623115136 basic_session_run_hooks.py:606] Restoring checkpoints for 0 into /content/data_trunks/train_dir/model.ckpt.\r\n```\r\n\r\n**Standalone code to reproduce the issue** \r\n```\r\npython model_main.py \\\r\n    --pipeline_config_path=models/ssd_mobilenet_v1_coco/pipeline.config \\\r\n    --model_dir=train_dir \\\r\n    --alsologtostderr \\\r\n    --num_train_steps=50000 \\\r\n    --num_eval_steps=500\r\n```\r\n\r\n**Other info / logs**\r\n\r\nMy `pipeline.config` file:\r\n```\r\nmodel {\r\n  ssd {\r\n    num_classes: 1\r\n    image_resizer {\r\n      fixed_shape_resizer {\r\n        height: 300\r\n        width: 300\r\n      }\r\n    }\r\n    feature_extractor {\r\n      type: \"ssd_mobilenet_v1\"\r\n      depth_multiplier: 1.0\r\n      min_depth: 16\r\n      conv_hyperparams {\r\n        regularizer {\r\n          l2_regularizer {\r\n            weight: 3.99999989895e-05\r\n          }\r\n        }\r\n        initializer {\r\n          random_normal_initializer {\r\n            mean: 0.0\r\n            stddev: 0.00999999977648\r\n          }\r\n        }\r\n        activation: RELU_6\r\n        batch_norm {\r\n          decay: 0.97000002861\r\n          center: true\r\n          scale: true\r\n          epsilon: 0.0010000000475\r\n        }\r\n      }\r\n      override_base_feature_extractor_hyperparams: true\r\n    }\r\n    box_coder {\r\n      faster_rcnn_box_coder {\r\n        y_scale: 10.0\r\n        x_scale: 10.0\r\n        height_scale: 5.0\r\n        width_scale: 5.0\r\n      }\r\n    }\r\n    matcher {\r\n      argmax_matcher {\r\n        matched_threshold: 0.5\r\n        unmatched_threshold: 0.5\r\n        ignore_thresholds: false\r\n        negatives_lower_than_unmatched: true\r\n        force_match_for_each_row: true\r\n        use_matmul_gather: true\r\n      }\r\n    }\r\n    similarity_calculator {\r\n      iou_similarity {\r\n      }\r\n    }\r\n    box_predictor {\r\n      convolutional_box_predictor {\r\n        conv_hyperparams {\r\n          regularizer {\r\n            l2_regularizer {\r\n              weight: 3.99999989895e-05\r\n            }\r\n          }\r\n          initializer {\r\n            random_normal_initializer {\r\n              mean: 0.0\r\n              stddev: 0.00999999977648\r\n            }\r\n          }\r\n          activation: RELU_6\r\n          batch_norm {\r\n            decay: 0.97000002861\r\n            center: true\r\n            scale: true\r\n            epsilon: 0.0010000000475\r\n          }\r\n        }\r\n        min_depth: 0\r\n        max_depth: 0\r\n        num_layers_before_predictor: 0\r\n        use_dropout: false\r\n        dropout_keep_probability: 0.800000011921\r\n        kernel_size: 1\r\n        box_code_size: 4\r\n        apply_sigmoid_to_scores: false\r\n        class_prediction_bias_init: -4.59999990463\r\n      }\r\n    }\r\n    anchor_generator {\r\n      ssd_anchor_generator {\r\n        num_layers: 6\r\n        min_scale: 0.20000000298\r\n        max_scale: 0.949999988079\r\n        aspect_ratios: 1.0\r\n        aspect_ratios: 2.0\r\n        aspect_ratios: 0.5\r\n        aspect_ratios: 3.0\r\n        aspect_ratios: 0.333299994469\r\n      }\r\n    }\r\n    post_processing {\r\n      batch_non_max_suppression {\r\n        score_threshold: 0.300000011921\r\n        iou_threshold: 0.600000023842\r\n        max_detections_per_class: 100\r\n        max_total_detections: 100\r\n      }\r\n      score_converter: SIGMOID\r\n    }\r\n    normalize_loss_by_num_matches: true\r\n    loss {\r\n      localization_loss {\r\n        weighted_smooth_l1 {\r\n        }\r\n      }\r\n      classification_loss {\r\n        weighted_sigmoid_focal {\r\n          gamma: 2.0\r\n          alpha: 0.75\r\n        }\r\n      }\r\n      classification_weight: 1.0\r\n      localization_weight: 1.0\r\n    }\r\n    encode_background_as_zeros: true\r\n    normalize_loc_loss_by_codesize: true\r\n    inplace_batchnorm_update: true\r\n    freeze_batchnorm: false\r\n  }\r\n}\r\ntrain_config {\r\n  batch_size: 18\r\n  data_augmentation_options {\r\n    random_horizontal_flip {\r\n    }\r\n  }\r\n  data_augmentation_options {\r\n    ssd_random_crop {\r\n    }\r\n  }\r\n  sync_replicas: true\r\n  optimizer {\r\n    momentum_optimizer {\r\n      learning_rate {\r\n        cosine_decay_learning_rate {\r\n          learning_rate_base: 0.20000000298\r\n          total_steps: 50000\r\n          warmup_learning_rate: 0.0599999986589\r\n          warmup_steps: 2000\r\n        }\r\n      }\r\n      momentum_optimizer_value: 0.899999976158\r\n    }\r\n    use_moving_average: false\r\n  }\r\n  fine_tune_checkpoint: \"/content/data_trunks/ssd_mobilenet_v1_coco/model.ckpt\"\r\n  fine_tune_checkpoint_type: \"detection\"\r\n  num_steps: 50000\r\n  startup_delay_steps: 0.0\r\n  replicas_to_aggregate: 8\r\n  max_number_of_boxes: 100\r\n  unpad_groundtruth_tensors: false\r\n}\r\ntrain_input_reader {\r\n  label_map_path: \"/content/data_trunks/label_map.pbtxt\"\r\n  tf_record_input_reader {\r\n    input_path: \"/content/data_trunks/train_8869_v4.record\"\r\n  }\r\n}\r\neval_config {\r\n  num_examples: 640\r\n  metrics_set: \"coco_detection_metrics\"\r\n  use_moving_averages: false\r\n}\r\neval_input_reader {\r\n  label_map_path: \"/content/data_trunks/label_map.pbtxt\"\r\n  shuffle: false\r\n  num_readers: 1\r\n  tf_record_input_reader {\r\n    input_path: \"/content/data_trunks/eval_640_v4.record\"\r\n  }\r\n}\r\ngraph_rewriter {\r\n  quantization {\r\n    delay: 48000\r\n    weight_bits: 8\r\n    activation_bits: 8\r\n  }\r\n}\r\n```", "comments": ["@aaguiar96,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here. Thanks!", "> @aaguiar96,\r\n> In order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here. Thanks!\r\n\r\n@amahendrakar done :)", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\nThanks!\r\n"]}, {"number": 37837, "title": "Make @tf.function-wrapped functions pickleable", "body": "It can sometimes be useful to be able to pickle functions wrapped with `@tf.function`. For example, https://github.com/horovod/horovod/issues/1743 is a use case from Horovod.\r\n\r\nThis PR tries to make these objects pickleable, and adds a test. For general usage `cloudpickle` or `dill` are probably better than Python's built-in `pickle`, but the basic module suffices for a test.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37837) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37837) for more info**.\n\n<!-- ok -->", "@itamarst Can you please address Ubuntu Sanity errors? Thanks!", "Yes, I will take a look, tomorrow probably.", "@gbaned any idea why CI jobs never finished?", "CI jobs only start after approval", "Can you rebase on master please?", "@itamarst Can you please check @mihaimaruseac's comments and keep us posted. Thanks!", "1. Sounds like @mihaimaruseac is OK with my response to review comments.\r\n2. I rebased.", "Hello @itamarst\r\n\r\nThis PR breaks on Windows\r\n\r\n```\r\nTraceback (most recent call last):\r\n\r\n  File \"C:\\Python36\\lib\\site-packages\\absl\\testing\\parameterized.py\", line 258, in bound_param_test\r\n\r\n    test_method(self, *testcase_params)\r\n\r\n  File \"\\\\?\\T:\\tmp\\Bazel.runfiles_1agxy3ir\\runfiles\\org_tensorflow\\py_test_dir\\tensorflow\\python\\eager\\def_function_test.py\", line 766, in test_pickle\r\n\r\n    from tensorflow.python.eager.def_function_test import undecorated_function\r\n\r\nModuleNotFoundError: No module named 'tensorflow.python.eager.def_function_test'\r\n```\r\n\r\nI was wondering if we really need the import inside the test, since the function should already be in scope ", "Hm. I was thinking the import was needed for pickling stuff from `__main__`, because that's often a problem, but in this case the pickle isn't shared with anyone so actually it's fine. So yes, the import is unneeded if you think that'll fix it.", "Let's do another PR with the import removed.\r\n\r\nPlease assign me on the PR and I'll take care of it and have it land asap."]}, {"number": 37836, "title": "Use correct variable _device attribute in Keras optimizer_v2.", "body": "Fixes a large performance regression for MirroredStrategy.\n\nPiperOrigin-RevId: 302069884\nChange-Id: I32ff43f146c6f60d462d2713908c3cf258ace3de", "comments": []}, {"number": 37835, "title": "Allow different prefixes for TF_SYSTEM_LIBS libraries", "body": "**System information**\r\n- TensorFlow version (you are using): 2.1.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nUsing TF_SYSTEM_LIBS to compile TensorFlow requires to have the libraries installed into a common prefix. It is however not uncommon to have different prefixes for different software (think: /opt/foo-1.x.y, /opt/bar-w.e.r...)\r\n\r\nHowever TF currently only supports a single prefix via `PREFIX, INCLUDEDIR and LIBDIR`.\r\n\r\nSo what would be great is having one environment variable per dependency, e.g. `TF_PROTOBUF_PREFIX` to set this to the folder containing the `include`, `bin` etc folders.\r\n\r\nAlternatively: As all the stuff (headers, binaries) must already be able to be found: Why not use the environment variables PATH, CPATH, (LD_)LIBRARY_PATH? Or a similar (maybe new) variable supporting multiple paths?\r\n\r\n**Will this change the current api? How?**\r\n\r\nNo\r\n\r\n**Who will benefit with this feature?**\r\n\r\nPackage maintainers", "comments": ["This is a feature request for introducing/supporting a different install prefix for each dependency or alternatively using a list of paths to allow installing dependencies into different prefixes. I don't see how your bug report using the existing variables relates to a feature request and can be \"the same error\".    \r\nSo yes, wrong issue. Updating the initial description to make it clearer", "Ping! @perfinion @angerson ", "*Ping*\r\n\r\nThis currently seems to apply to protobuf and jsoncpp", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37835\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37835\">No</a>\n"]}, {"number": 37834, "title": "keras conv layer weight cannot be updated during distribution training mode", "body": "OS: Ubuntu 18.04\r\nTensorflow: 2.1.0\r\nPython: 3.7\r\nGPUs: 4 gpus\r\n\r\ntrying to train a gan network on multiple GPUs. The network has a spectral normalization layer to update convolution layer weights. The sample code and error are provided as follows:\r\n\r\n```python\r\nimport tensorflow as tf\r\nstrategy = tf.distribute.MirroredStrategy()\r\n\r\nwith strategy.scope():\r\n    conv = tf.keras.layers.Conv2D(5, 3, 1)\r\n    x = tf.random.normal((1,5, 5, 3))\r\n    conv(x)\r\n\r\n@tf.function\r\ndef update_w(w, nw):\r\n    w.assign(nw)\r\n\r\nx2 = tf.random.normal((3,3, 3, 5))\r\nstrategy.experimental_run_v2(update_w, args=(conv.kernel, x2))\r\n```\r\n![image](https://user-images.githubusercontent.com/731496/77329724-5a234800-6d59-11ea-9ee4-a3b976178147.png)\r\n", "comments": ["i have replicated the error faced on nightly, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/f9a25e7d853d7e41aebf3bfe473aaac0/37834.ipynb)", "@w19787 As the error message suggests we currently disallow aggregating a MirroredVariable in replica context since we aggregate the values before assigning (this is to ensure that the MirroredVariables remain in sync).\r\n\r\nWould it be possible to work around this by updating the variable in cross replica context like the error message suggests?", "i am unable to work around this issue in cross replica context with merge fn and extended.update. it can work on one gpu but still failed on multiple gpu.\r\n\r\nwhen we create keras layer, i.e Conv2d, there is no argument to specify the aggregation parameter of weights, i think it should be the reason for this issue. I want to confirm whether the above understanding is correct, if so, why we design so? thanks.", "A workaround for this is making a new variable creator and using `tf.variable_creator_scope`:\r\n```\r\ndef variable_creator(next_creator, **kwargs):\r\n    kwargs['aggregation'] = tf.VariableAggregation.ONLY_FIRST_REPLICA\r\n    return next_creator(**kwargs)\r\nwith tf.variable_creator_scope(variable_creator):\r\n    conv.build(input_shape)\r\n```\r\nCalling `build` inside your creator's scope will make the variables inside get the `aggregation` parameter. I chose `tf.VariableAggregation.ONLY_FIRST_REPLICA` but you may chose the `tf.VariableAggregation` that fits your use case better", "@w19787 Sorry for the late response. Recent changes have made it possible to call assign on mirrored variables in replica context(when there is no aggregation). Hopefully that should fix issues like this. However if you want to update your variable in cross replica context you can use something like:\r\n\r\n```\r\nstrategy = tf.distribute.MirroredStrategy()\r\nprint(\"Devices used \", strategy.extended.worker_devices)\r\nwith strategy.scope():\r\n    conv = tf.keras.layers.Conv2D(5, 3, 1)\r\n    x = tf.random.normal((1,5, 5, 3))\r\n    conv(x)\r\n\r\n@tf.function\r\ndef update_w(w, nw):\r\n    def merge_fn(strategy, w, nw):\r\n      strategy.extended.update(w, lambda v,w:v.assign(w), args=(nw,))\r\n    replica_ctx = tf.distribute.get_replica_context()\r\n    replica_ctx.merge_call(merge_fn, args=(w, nw))\r\n\r\nx2 = tf.random.normal((3,3, 3, 5))\r\nprint(\"before update \", conv.kernel[0])\r\nstrategy.experimental_run_v2(update_w, args=(conv.kernel, x2))\r\nprint(\"after update \", conv.kernel[0])\r\n```", "> @w19787 Sorry for the late response. Recent changes have made it possible to call assign on mirrored variables in replica context(when there is no aggregation). Hopefully that should fix issues like this. However if you want to update your variable in cross replica context you can use something like:\r\n> \r\n> ```\r\n> strategy = tf.distribute.MirroredStrategy()\r\n> print(\"Devices used \", strategy.extended.worker_devices)\r\n> with strategy.scope():\r\n>     conv = tf.keras.layers.Conv2D(5, 3, 1)\r\n>     x = tf.random.normal((1,5, 5, 3))\r\n>     conv(x)\r\n> \r\n> @tf.function\r\n> def update_w(w, nw):\r\n>     def merge_fn(strategy, w, nw):\r\n>       strategy.extended.update(w, lambda v,w:v.assign(w), args=(nw,))\r\n>     replica_ctx = tf.distribute.get_replica_context()\r\n>     replica_ctx.merge_call(merge_fn, args=(w, nw))\r\n> \r\n> x2 = tf.random.normal((3,3, 3, 5))\r\n> print(\"before update \", conv.kernel[0])\r\n> strategy.experimental_run_v2(update_w, args=(conv.kernel, x2))\r\n> print(\"after update \", conv.kernel[0])\r\n> ```\r\n\r\nthanks a lot!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37834\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37834\">No</a>\n"]}, {"number": 37833, "title": "session->Run", "body": "```\r\n/home/sy/tf_test/mnist/tf.cpp: In function \u2018int main(int, char**)\u2019:\r\n/home/sy/tf_test/mnist/tf.cpp:219:142: error: no matching function for call to \u2018tensorflow::Session::Run(<brace-enclosed initializer list>, <brace-enclosed initializer list>, <brace-enclosed initializer list>, std::vector<tensorflow::Tensor>*)\u2019\r\n n = session->Run({{inputt, inputm}}, {\"code2str_conversion/chars_conversion/cond/Merge:0\",\"init_all_tables\"}, {}, &outputs);\r\n                                                                                                                           ^\r\nIn file included from /home/sy/tf_test/mnist/tf.cpp:25:0:\r\n/home/sy/tensorflow/tensorflow/core/public/session.h:121:18: note: candidate: virtual tensorflow::Status tensorflow::Session::Run(const std::vector<std::pair<std::__cxx11::basic_string<char>, tensorflow::Tensor> >&, const std::vector<std::__cxx11::basic_string<char> >&, const std::vector<std::__cxx11::basic_string<char> >&, std::vector<tensorflow::Tensor>*)\r\n   virtual Status Run(const std::vector<std::pair<string, Tensor> >& inputs,\r\n                  ^~~\r\n/home/sy/tensorflow/tensorflow/core/public/session.h:121:18: note:   no known conversion for argument 1 from \u2018<brace-enclosed initializer list>\u2019 to \u2018const std::vector<std::pair<std::__cxx11::basic_string<char>, tensorflow::Tensor> >&\u2019\r\n/home/sy/tensorflow/tensorflow/core/public/session.h:150:18: note: candidate: virtual tensorflow::Status tensorflow::Session::Run(const tensorflow::RunOptions&, const std::vector<std::pair<std::__cxx11::basic_string<char>, tensorflow::Tensor> >&, const std::vector<std::__cxx11::basic_string<char> >&, const std::vector<std::__cxx11::basic_string<char> >&, std::vector<tensorflow::Tensor>*, tensorflow::RunMetadata*)\r\n   virtual Status Run(const RunOptions& run_options,\r\n                  ^~~\r\n/home/sy/tensorflow/tensorflow/core/public/session.h:150:18: note:   candidate expects 6 arguments, 4 provided\r\nCMakeFiles/tf_test.dir/build.make:62: recipe for target 'CMakeFiles/tf_test.dir/tf.cpp.o' failed\r\nmake[2]: *** [CMakeFiles/tf_test.dir/tf.cpp.o] Error 1\r\nCMakeFiles/Makefile2:67: recipe for target 'CMakeFiles/tf_test.dir/all' failed\r\nmake[1]: *** [CMakeFiles/tf_test.dir/all] Error 2\r\nMakefile:83: recipe for target 'all' failed\r\nmake: *** [all] Error 2\r\n```\r\n\r\n\r\nwhen I run a model of EAST,the program run successfully\u3002\r\nBut,when I run the second model, the program fails.(python ok )\r\nCan the C ++ API initialize the model?\r\n\r\n\uff08ubuntu18.04,tensorflow c++ 1.13\uff09", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the code snippet to reproduce the issue. If you are unclear what to include see the issue template displayed in the [Github new issue template.](https://github.com/tensorflow/tensorflow/issues/new/choose)\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!", "What statement should I use to initialize in C ++.\r\npython code:\r\n`sess_id.run(graph_id.get_operation_by_name(\"MyGraphID/init_all_tables\")) `\r\n\r\n\r\nother infermation:\r\n```\r\ndef initialize_all_tables(name=\"init_all_tables\"):\r\n  \"\"\"Returns an Op that initializes all tables of the default graph.\r\n\r\n  Args:\r\n    name: Optional name for the initialization op.\r\n\r\n  Returns:\r\n    An Op that initializes all tables.  Note that if there are\r\n    not tables the returned Op is a NoOp.\r\n  \"\"\"\r\n  return tables_initializer(name)\r\n\r\n\r\n@tf_export(v1=[\"initializers.tables_initializer\", \"tables_initializer\"])\r\ndef tables_initializer(name=\"init_all_tables\"):\r\n  \"\"\"Returns an Op that initializes all tables of the default graph.\r\n\r\n  Args:\r\n    name: Optional name for the initialization op.\r\n\r\n  Returns:\r\n    An Op that initializes all tables.  Note that if there are\r\n    not tables the returned Op is a NoOp.\r\n  \"\"\"\r\n  initializers = ops.get_collection(ops.GraphKeys.TABLE_INITIALIZERS)\r\n  if initializers:\r\n    return control_flow_ops.group(*initializers, name=name)\r\n  return control_flow_ops.no_op(name=name)\r\n\r\n```", "Please fill in issue template and don't just paste error message with no formatting.\r\n\r\nTF 1.13 is no longer supported. Can you try 1.15 or 2.1 or master instead?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 37832, "title": "Modified TensorScatterAdd to correctly specify examples for shape of tensor", "body": "Fixes #37669. \r\n@mihaimaruseac and @karllessard , Please review this one.", "comments": []}]