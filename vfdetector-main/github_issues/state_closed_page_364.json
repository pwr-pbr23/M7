[{"number": 43138, "title": "tensorflow 1.14 gpu  is not  in 2060S 2080TI", "body": " import tensorflow as tf\r\n/home/sl/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\n/home/sl/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\n/home/sl/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\n/home/sl/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\n/home/sl/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\n/home/sl/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\n/home/sl/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\n/home/sl/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\n/home/sl/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\n/home/sl/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\n/home/sl/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\n/home/sl/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\n>>> tf.test.is_gpu_available()\r\n2020-09-11 17:33:59.857951: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-09-11 17:33:59.873846: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\r\n2020-09-11 17:33:59.961881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-09-11 17:33:59.962263: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fc4d8a9e40 executing computations on platform CUDA. Devices:\r\n2020-09-11 17:33:59.962281: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce RTX 2060 SUPER, Compute Capability 7.5\r\n2020-09-11 17:33:59.983750: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600000000 Hz\r\n2020-09-11 17:33:59.984247: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fc4d9d5990 executing computations on platform Host. Devices:\r\n2020-09-11 17:33:59.984263: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\r\n2020-09-11 17:33:59.984404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-09-11 17:33:59.984701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \r\nname: GeForce RTX 2060 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.665\r\npciBusID: 0000:01:00.0\r\n2020-09-11 17:33:59.984785: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory\r\n2020-09-11 17:33:59.984839: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory\r\n2020-09-11 17:33:59.984887: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory\r\n2020-09-11 17:33:59.984935: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory\r\n2020-09-11 17:33:59.984983: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory\r\n2020-09-11 17:33:59.985029: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory\r\n2020-09-11 17:33:59.987699: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n2020-09-11 17:33:59.987719: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1663] Cannot dlopen some GPU libraries. Skipping registering GPU devices...\r\n2020-09-11 17:33:59.987739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-09-11 17:33:59.987748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \r\n2020-09-11 17:33:59.987754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \r\nFalse\r\n>>> from tensorflow.python.client import device_lib\r\n>>> print(device_lib.list_local_devices())\r\n2020-09-11 17:35:02.273857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-09-11 17:35:02.274176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \r\nname: GeForce RTX 2060 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.665\r\npciBusID: 0000:01:00.0\r\n2020-09-11 17:35:02.274268: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory\r\n2020-09-11 17:35:02.274317: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory\r\n2020-09-11 17:35:02.274363: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory\r\n2020-09-11 17:35:02.274407: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory\r\n2020-09-11 17:35:02.274450: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory\r\n2020-09-11 17:35:02.274494: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory\r\n2020-09-11 17:35:02.274511: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n2020-09-11 17:35:02.274518: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1663] Cannot dlopen some GPU libraries. Skipping registering GPU devices...\r\n2020-09-11 17:35:02.274530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-09-11 17:35:02.274536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \r\n2020-09-11 17:35:02.274542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \r\n[name: \"/device:CPU:0\"\r\ndevice_type: \"CPU\"\r\nmemory_limit: 268435456\r\nlocality {\r\n}\r\n", "comments": ["@zyxcambridge,\r\nIn order to expedite the trouble-shooting process, could you please fill in the below template.\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nThanks!", "Also, TensorFlow 1.x is not actively supported. \r\n\r\nCould you please update TensorFlow to v2.3 along with all the dependencies as mentioned [here](https://www.tensorflow.org/install/source#gpu), and let us know if you are still facing the same issue. Thanks! ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 43137, "title": "[mlir][lhlo] Replace lhlo-copy-removal pass with mlir-copy-removal pass", "body": "This PR removes lhlo-copy-removal pass entirely and replace its usages with ```mlir::createCopyRemovalPass()```.", "comments": ["This fails to build. An example is\r\n\r\n```\r\nExecution platform: @org_tensorflow//third_party/toolchains:rbe_ubuntu16.04-manylinux2010\r\ntensorflow/compiler/mlir/hlo/include/mlir-hlo/Dialect/mhlo/IR/lhlo_ops.td:37:9: error: Could not find include file 'mlir/Interfaces/CopyOpInterface.td'\r\ninclude \"mlir/Interfaces/CopyOpInterface.td\"\r\n        ^\r\ntensorflow/compiler/mlir/hlo/include/mlir-hlo/Dialect/mhlo/IR/lhlo_ops.td:37:9: error: Unexpected input at top level\r\ninclude \"mlir/Interfaces/CopyOpInterface.td\"\r\n        ^\r\nERROR: /tmpfs/src/github/tensorflow/tensorflow/compiler/mlir/hlo/BUILD:164:1: Couldn't build file tensorflow/compiler/mlir/hlo/include/mlir-hlo/Dialect/mhlo/IR/lhlo_ops_structs.h.inc: Generating code from table: include/mlir-hlo/Dialect/mhlo/IR/lhlo_ops.td //tensorflow/compiler/mlir/hlo:lhlo_ops_inc_gen___gen_struct_attr_decls_1316491227_genrule failed (Exit 1): bash failed: error executing command \r\n  (cd /tmpfs/bazel_output/_bazel_kbuilder/f2d52ca1f092ccbe254cc98c3dc90790/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/bin:/usr/bin:/usr/local/bin \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/k8-opt/bin/external/llvm-project/mlir/mlir-tblgen -gen-struct-attr-decls tensorflow/compiler/mlir/hlo/include/mlir-hlo/Dialect/mhlo/IR/lhlo_ops.td -Ibazel-out/k8-opt-exec-DEE97DD4/bin -I external/llvm-project/mlir/include -I external/org_tensorflow -I bazel-out/k8-opt-exec-DEE97DD4/bin/external/llvm-project/mlir/include -I bazel-out/k8-opt-exec-DEE97DD4/bin/external/org_tensorflow -Itensorflow/compiler/mlir/hlo/include -Iexternal/org_tensorflow/tensorflow/compiler/mlir/hlo/include -Ibazel-out/k8-opt-exec-DEE97DD4/bin/tensorflow/compiler/mlir/hlo/include -I $(dirname tensorflow/compiler/mlir/hlo/include/mlir-hlo/Dialect/mhlo/IR/lhlo_ops.td) -o bazel-out/k8-opt-exec-DEE97DD4/bin/tensorflow/compiler/mlir/hlo/include/mlir-hlo/Dialect/mhlo/IR/lhlo_ops_structs.h.inc')\r\n```\r\n\r\nLikely the BUILD rule for the lhlo target needs to reference that tablegen include.", "Thanks!"]}, {"number": 43136, "title": "Remove stray backticks in `tf.keras.initializers.Initializer` docstring.", "body": "Remove stray backticks in `Initializer` docstring.", "comments": []}, {"number": 43135, "title": "Mac c++ tensorflow_cpu segmentation fault", "body": "I build tensorflow 1.12 c++ on Mac without gpu. I can load .meta and .ckpt of model. When I run session->run() \uff0cprogram raise segmentation error. I can get some node output results in middle but I could not get   the last outputs results.  Thank you very much for your help.\r\nMy environment is:\r\n   \r\n MacOS 10.15.4, tensorflow 1.12, cuda(None), bazel 0.15.2, clang version 11.0.3\r\n\r\n`\r\n    MetaGraphDef graphdef; //Graph Definition for current model\r\n\r\n    string checkpointPath = \"../static/model_ldh\";\r\n    Status status_load = ReadBinaryProto(Env::Default(), \"../static/model_ldh.meta\", &graphdef);\r\n    if (!status_load.ok()) {\r\n        std::cout << \"ERROR: Loading model failed...\"<< std::endl;\r\n        std::cout << status_load.ToString() << \"\\n\";\r\n        return -1;\r\n    }\r\n    //create session\r\n    SessionOptions options;\r\n    auto session = NewSession(options);\r\n    if (session == nullptr) {\r\n        std::cout << \"ERROR: Creating graph in session failed...\" << std::endl;\r\n        return -1;\r\n    }\r\n    //add graph into session\r\n    Status status = session->Create(graphdef.graph_def());\r\n    if (!status.ok()) {\r\n        throw runtime_error(\"Error creating graph: \" + status.ToString());\r\n    }\r\n    // load weights\r\n    Tensor checkpointPathTensor(DT_STRING, TensorShape());\r\n    checkpointPathTensor.scalar<std::string>()() = checkpointPath;\r\n    status = session->Run(\r\n            {{ graphdef.saver_def().filename_tensor_name(), checkpointPathTensor },},\r\n            {},\r\n            {graphdef.saver_def().restore_op_name()},\r\n            nullptr);\r\n    if (!status.ok()) {\r\n        throw runtime_error(\"Error loading checkpoint from \" + checkpointPath + \": \" + status.ToString());\r\n    }\r\n\r\n    string image_path = \"../static/test.jpg\";\r\n    int input_height = 112;\r\n    int input_width = 96;\r\n    int input_mean = 127;\r\n    int input_std = 128;\r\n    std::vector<Tensor> resized_tensors;\r\n    Status read_tensor_status =\r\n            ReadTensorFromImageFile(image_path, input_height, input_width, input_mean,\r\n                                    input_std, &resized_tensors); // load image . shape is [1, 112, 96, 3]\r\n    if (!read_tensor_status.ok()) {\r\n        LOG(ERROR) << read_tensor_status;\r\n        cout<<\"resing error\"<<endl;\r\n        return -1;\r\n    }\r\n\r\n    const Tensor& resized_tensor = resized_tensors[0];\r\n    std::cout << resized_tensor.DebugString()<<endl;\r\n\r\n    vector<tensorflow::Tensor> outputs;\r\n    tensorflow::string output_node1 = \"outputs_A:0\" , output_node2 = \"outputs_B:0\";\r\n    tensorflow::Tensor phase_train(DT_BOOL, {1});\r\n    tensorflow::Tensor switch_all(DT_BOOL, {1});\r\n    tensorflow::Tensor keep_prob(DT_FLOAT,{1});\r\n    auto phase_train_data = phase_train.tensor<bool, 1>(); phase_train_data(0) = false;\r\n    auto switch_all_data = switch_all.tensor<bool, 1>(); switch_all_data(0) = false;\r\n    auto keep_prob_data = keep_prob.tensor<float, 1>(); keep_prob_data(0) = 1.0;\r\n    vector<pair<string, tensorflow::Tensor>> need_inputs = {{\"inputs:0\", resized_tensor},\r\n         {\"switch:0\", switch_all}, {\"keep_prob:0\", keep_prob}, {\"phase_train:0\", phase_train}};\r\n\r\n    outputs.clear();\r\n    tensorflow::string  debug = \"FaceResNet/NetA_3/conv4/layer_0/Conv/p_re_lu/Relu:0\";\r\n    Status status_run = session->Run(need_inputs, {debug}, {}, &outputs); // **I can get this results**\r\n    status_run = session->Run(need_inputs, {output_node1}, {}, &outputs); // **this line will occur to segmentation fault**\r\n    `\r\nthe error statcks are as following :\r\n`Eigen::internal::gemm_pack_rhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 16, true, false, 0, Eigen::MakePointer>, 4, 0, false, false>::operator()(float*, Eigen::internal::TensorContractionSubMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 16, true, false, 0, Eigen::MakePointer> const&, long, long, long, long) const 0x0000000105f7e75c\r\nEigen::TensorEvaluator<Eigen::TensorContractionOp<Eigen::array<Eigen::IndexPair<long>, 1ul> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>::Context<Eigen::internal::gemm_pack_lhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 16, true, false, 0, Eigen::MakePointer>, 48, 16, 0, false, false>, Eigen::internal::gemm_pack_rhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 16, true, false, 0, Eigen::MakePointer>, 4, 0, false, false>, Eigen::internal::gebp_kernel<float, float, long, Eigen::internal::blas_data_mapper<float, long, 0, 0>, 48, 4, false, false>, Eigen::internal::TensorContractionInputMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 16, true, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 16, true, false, 0, Eigen::MakePointer>, Eigen::internal::blas_data_mapper<float, long, 0, 0> >::pack_rhs(long, long) 0x0000000105f80aa8\r\nEigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) 0x000000010def1e7e\r\nstd::__1::__function::__func<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'(), std::__1::allocator<tensorflow::thread::EigenEnvironment::CreateThread(std::__1::function<void ()>)::'lambda'()>, void ()>::operator()() 0x000000010def17df\r\nvoid* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void ()> > >(void*) 0x000000010df15200\r\n_pthread_start 0x00007fff6f560109\r\nthread_start 0x00007fff6f55bb8b`\r\n\r\nThis model is work in python environment with tf 1.12. I am so puzzled.\r\n\r\n`\r\n\r\ndef load_ckpt():\r\n\r\n    sess = tf.Session()\r\n    saver = tf.train.import_meta_graph(\"./log/model_ldh.meta\", clear_devices = True)\r\n    saver.restore(sess, \"./log/model_ldh\")\r\n    phase_train_ = sess.graph.get_tensor_by_name('phase_train:0')\r\n    keep_prob_ = sess.graph.get_tensor_by_name('keep_prob:0')\r\n    inputs_ = sess.graph.get_tensor_by_name('inputs:0')\r\n    switch_ = sess.graph.get_tensor_by_name('switch:0')\r\n    outputs_B_ = sess.graph.get_tensor_by_name('outputs_B:0')\r\n    outputs_A_ = sess.graph.get_tensor_by_name('outputs_A:0')\r\n    images = np.random.randint(0, 255, size = (1, 112, 96, 3))\r\n    switch = np.array([False])\r\n    #debug = sess.graph.get_tensor_by_name(\"FaceResNet/NetA_3/conv4/layer_0/Conv/p_re_lu/Relu:0\")\r\n\r\n    feed_dict = {\r\n        inputs_: images,\r\n        switch_: switch, \r\n        phase_train_: np.array(False),\r\n        keep_prob_: np.array(1.0)\r\n    }\r\n\r\n    ret = sess.run(outputs_A_, feed_dict) # This program could work\r\n    print(ret.shape)\r\n`", "comments": ["need help", "@woshildh \r\nIs there any particular reason for using 1.13 version as its quite old and we have support for 1.5 and 2.x versions, would you want to upgrade the latest version and let us know if you are still facing any issue.\r\nWith respect to the error reported: #9638 [[link](https://www.tensorflow.org/install/source])]", "@Saduf2019 Thanks, I will try a new version. ", "@Saduf2019 , Thanks, I solved this problem after I compile tf 1.13", "Thanks for the update, glad the issue is resolved."]}, {"number": 43134, "title": "Implementation of a missing hook in XlaDeviceContext", "body": "This supplies a default implementation of XlaDeviceContext::ThenExecute(). Without it, a host callback may fail to execute in some scenarios (because there's no one to execute it), causing a deadlock if anyone is waiting for that callback.", "comments": ["@ekuznetsov139  Can you please check @sanjoy's comments and keep us posted ? Thanks!", "I don't mean to block this, but how did you even manage to use XLA devices? They are disabled now, and there shouldn't really be a reason for using them?..", "Or is it deadlocking in `compiler/tests` and somehow only using ROCm?", "I am upstreaming a change that's been in the ROCm repo for a while. It was a fix for a deadlock in one of the unit tests. If it is irrelevant now, we can close this and I'll delete the corresponding code in the ROCm fork instead.", "> If it is irrelevant now\r\n\r\nCould you check whether it is relevant and whether the test is deadlocking now?", "I can confirm that the function is still being called during execution of some //tensorflow/compiler/... tests. It'll take some time to determine which (if any) tests deadlock as a result.", "Confirmed. The following tests time out on ROCm without this patch:\r\n//tensorflow/compiler/tests:eager_test_gpu\r\n//tensorflow/compiler/tests:while_test_gpu"]}, {"number": 43133, "title": "tensorflow.python.framework.errors_impl.UnknownError: ", "body": "I tried  to test the face filter model which i had in my system. when i run the test script i am getting the following error. In cpu it is running without any issue but in gpu its causing the issue.\r\n\r\ntensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[{{node conv2d_1/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_1/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, conv2d_1/Conv2D/ReadVariableOp)]]\r\n", "comments": ["@Shobana1230 \r\n\r\nRequest you to fill [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nThis error might arise due to incompatibility between the cuda  and cuDNN version.\r\n\r\nPlease, see build tested configurations for [Linux/mac OS](https://www.tensorflow.org/install/source#tested_build_configurations), [windows\r\n](https://www.tensorflow.org/install/source_windows#tested_build_configurations).\r\nRefer similar issues #24828, [SO link](https://stackoverflow.com/questions/53698035/failed-to-get-convolution-algorithm-this-is-probably-because-cudnn-failed-to-in) and see if it helps you. Thanks!", " OS Platform and Distribution (e.g., Linux Ubuntu 16.04):18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below):1.12.0\r\n- Python version:3.6.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):gcc 7.5\r\n- CUDA/cuDNN version:cuda 9.0\r\n- GPU model and memory: GTX 1660", "@Shobana1230 \r\n\r\nTF 1.x is not actively supported. Can you please upgrade to TF 2.3 and see if the issue still persists. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43133\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43133\">No</a>\n"]}, {"number": 43132, "title": "Tensorflow 2.3: No gradients provided for any variable", "body": "**System information**\r\n- Used Functional API\r\n- OS: Ubuntu 20.04 and Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from source\r\n- TensorFlow version: 2.3\r\n- Python version:3.6.7\r\n\r\n\r\nHi I have built a model using functional API but when I start to train the model it says \"**No gradients provided for any variable:**\"\r\n A minimalistic [gist](https://gist.github.com/partha117/1c20da6252ef43f429c30fafe17cc93f)  is attached to recreate the error\r\n", "comments": ["@partha117,\r\nI was able to reproduce the issue with [TF v2.3](https://colab.research.google.com/gist/amahendrakar/0b38b676fda3c7fa42d86f89ea4eec87/43132.ipynb). \r\n\r\nHowever with [TF-nightly](https://colab.research.google.com/gist/amahendrakar/fafb742ce2a2fb43467c6d3defb93144/43132-tf-nightly.ipynb#scrollTo=GVJ3l3ZtwSmg), I am facing a different error stating `ValueError: Input 1 is incompatible with layer Full_Model: expected shape=(None, 183), found shape=(None, 15)`. Please find the attached gist.\r\n\r\nCould you please check if you are still facing the same issue with the latest TF-nightly? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "The problem is solved. It was caused by the shape of the dataset output. Previously the shape was (in1,in2,in3) after changing it to ((in1,in2,in3),None) the problem solved.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43132\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43132\">No</a>\n"]}, {"number": 43131, "title": "Just Qustion: In Android JAVA, keras model is ok?", "body": "Hi, I'm developing android app\r\n\r\nand my NN in python is keras(Tf.keras) with LSTM, conv2d, resnet, attention (very deep)\r\n\r\nI want to use this NN in JAVA.android\r\n\r\n1) can I use TF-lite for my keras of python?? \r\n\r\nI heard TF.lite only support some TF model so I'm worried\r\n\r\n2) and can I convert keras to tensorflow? and just use tensorflow in JAVA?\r\n\r\n3) and can I convert keras to tensorflow? and just use tensorflow lite or tensorflow.mobile in JAVA?\r\n\r\nThx.\r\n", "comments": ["@SungmanHong As I understand you are talking about converting the Keras model to a TF Lite Model and then using that in your Android app. Tp convert your model to a `.tflite` format I would recommend you to use the [TensorFlow Lite converter](https://www.tensorflow.org/lite/convert#convert_a_keras_model_). To then use this model in your Android app you could very easily make use of [ML Model Binding plugin](https://developer.android.com/studio/preview/features#tensor-flow-lite-models) with Android Studio (4.1 or above) which makes it easy for you to directly import `.tflite model` files and also generate easy-to-use classes.", "@Rishit-dagli  Thanks a lot, In fact, so far, I've been trying to port the neural network on the Android app through Pythorch Mobile.\r\nbut now, latest pytorch and pytorch mobile are not compatible each other...;; https://github.com/pytorch/vision/issues/1943\r\nThe App is just CRUSHED WHEN THE MODEL IS LOADED and others have experienced similar things.\r\nI downgraded pytorch and seems its good and is compatible to pytorch.android module yet.\r\nI hope TF and TFmobile is more stable and compatible than pytorch_mobile and pytorch android module.", "> @Rishit-dagli Thanks a lot, In fact, so far, I've been trying to port the neural network on the Android app through Pythorch Mobile.\r\n> but now, latest pytorch and pytorch mobile are not compatible each other...;; [pytorch/vision#1943](https://github.com/pytorch/vision/issues/1943)\r\n> The App is just CRUSHED WHEN THE MODEL IS LOADED and others have experienced similar things.\r\n> I downgraded pytorch and seems its good and is compatible to pytorch.android module yet.\r\n> I hope TF and TFmobile is more stable and compatible than pytorch_mobile and pytorch android module.\r\n\r\nI personally have not worked with PyTorch Mobile so I wouldn't be able to compare them, but I have noticed that the TF Lite Android Support Library is pretty stable"]}, {"number": 43130, "title": "A dynamic link library (DLL) initialization routine failed. ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Window 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): libtensorflow_jni-cpu-windows-x86_64-1.14.0\r\n- TensorFlow version: 1.14\r\n\r\n\r\n**Describe the problem**\r\nSo I was trying to run `` using a guide for [windows 10](https://www.tensorflow.org/install/lang_java#windows) and I followed the guide exactly as it said to.\r\nline 108 in `org/tensorflow/NativeLibrary.java`: System.load(extractResource(jniResource, jniLibName, tempDirectory));, the exception occurred:\r\n\r\nException in thread \"main\" java.lang.UnsatisfiedLinkError: I:\\Code\\Android\\test\\SpeechRecognition_tf_lite\\lib\\tensorflow_jni.dll: A dynamic link library (DLL) initialization routine failed. \r\n\tat java.lang.ClassLoader$NativeLibrary.load(Native Method)\r\n\tat java.lang.ClassLoader.loadLibrary0(Unknown Source)\r\n\tat java.lang.ClassLoader.loadLibrary(Unknown Source)\r\n\tat java.lang.Runtime.load0(Unknown Source)\r\n\tat java.lang.System.load(Unknown Source)\r\n\tat org.tensorflow.NativeLibrary.load(NativeLibrary.java:108)\r\n\tat org.tensorflow.TensorFlow.init(TensorFlow.java:67)\r\n\tat org.tensorflow.TensorFlow.<clinit>(TensorFlow.java:82)\r\n\tat org.tensorflow.Graph.<clinit>(Graph.java:479)\r\n\tat TFInterface.TensorFlowInferenceInterface.<init>(TensorFlowInferenceInterface.java:61)\r\n\tat ASR.Chain.<init>(Chain.java:60)\r\n\tat ASR.ASR.main(ASR.java:6)\r\n", "comments": ["@FriedaSmith \r\n\r\nWhat is make/model of your cpu?\r\nI suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)\r\nMake sure to download the [latest microsoft visual c++ redistributable from here](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads).\r\n.Also, please follow the instructions from to install from [Tensorflow website](https://www.tensorflow.org/install/source_windows).\r\n\r\nPlease, check Your CPU/Python is on 32 bits?Please, refer #36167 and see if it helps you.\r\nPlease, refer similar issue #36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204\r\nThanks!", "@ravikyram Hello. Must source code be used to build tensorflow? Can only `libtensorflow_jni-cpu-windows-x86_64-1.14.0/tensorflow_jni.dll` and `libtensorflow-1.14.0.jar` be used tensorflow?\r\nIn eclipse, I just use `System.load (extractresource (jniresource, jnilibname, tempdirectory))` function loads `tensorflow_ jni.dll`. I also installed latest microsoft visual c++ redistributable. \r\nCPU: intel core i7 880 64bit\r\n", "@FriedaSmith \r\n\r\nPlease, provide the exact sequence of commands / steps that you executed before running into the problem. Thanks!", "1. Go to: https://www.tensorflow.org/install/lang_java and download libtensorflow.jar and Java Native Interface (JNI) file, save it to project root;\r\n2. Copy Example code from https://www.tensorflow.org/install/lang_java and save `HelloTensorFlow .java`\r\n\r\nimport org.tensorflow.Graph;\r\nimport org.tensorflow.Session;\r\nimport org.tensorflow.Tensor;\r\nimport org.tensorflow.TensorFlow;\r\n\r\npublic class HelloTensorFlow {\r\n\tpublic static void main(String[] args) throws Exception {\r\n\t\ttry (Graph g = new Graph()) {\r\n\t\t\tfinal String value = \"Hello from \" + TensorFlow.version();\r\n\t\t\ttry (Tensor t = Tensor.create(value.getBytes(\"UTF-8\"))) {\r\n\t\t\t\tg.opBuilder(\"Const\", \"MyConst\").setAttr(\"dtype\", t.dataType()).setAttr(\"value\", t).build();\r\n\t\t\t}\r\n\r\n\t\t\ttry (Session s = new Session(g); Tensor output = s.runner().fetch(\"MyConst\").run().get(0)) {\r\n\t\t\t\tSystem.out.println(new String(output.bytesValue(), \"UTF-8\"));\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}\r\n\r\n3. Put `HelloTensorFlow.java`, `libtensorflow.jar`, and `tensorflow_jni.dll` in the same directory.\r\n4. Run the command: `javac -cp libtensorflow-1.3.0.jar HelloTensorFlow.java` and `java -cp libtensorflow-1.3.0.jar;. -Djava.library.path=jni HelloTensorFlow`.\r\nI:\\Code\\Android\\test\\test>`javac -cp libtensorflow-1.3.0.jar HelloTensorFlow.java`\r\nPicked up JAVA_TOOL_OPTIONS: -Dfile.encoding=UTF-8\r\n\r\nI:\\Code\\Android\\test\\test>`java -cp libtensorflow-1.3.0.jar;. -Djava.library.path=jni HelloTensorFlow`\r\nPicked up JAVA_TOOL_OPTIONS: -Dfile.encoding=UTF-8\r\nException in thread \"main\" java.lang.UnsatisfiedLinkError: Cannot find TensorFlow native library for OS: windows, architecture: x86_64. See https://github.com/tensorflow/tensorflow/tree/master/tensorflow/java/README.md for possible solutions (such as building the library from source). Additional information on attempts to find the native library can be obtained by adding org.tensorflow.NativeLibrary.DEBUG=1 to the system properties of the JVM.\r\n        at org.tensorflow.NativeLibrary.load(NativeLibrary.java:66)\r\n        at org.tensorflow.TensorFlow.init(TensorFlow.java:36)\r\n        at org.tensorflow.TensorFlow.<clinit>(TensorFlow.java:40)\r\n        at org.tensorflow.Graph.<clinit>(Graph.java:194)\r\n        at HelloTensorFlow.main(HelloTensorFlow.java:8)", "@FriedaSmith Please take a look at this [issue](https://github.com/tensorflow/tensorflow/issues/14456) and let me know it it helps.!\r\n", "@gowthamkpr Thank you. This is a CPU problem. So I changed my computer and it worked.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43130\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43130\">No</a>\n"]}, {"number": 43129, "title": "Integer quantization error", "body": "Traceback (most recent call last):\r\n  File \"D:/hua_work/tf_lite/lite_test.py\", line 32, in <module>\r\n    interpreter.allocate_tensors()\r\n  File \"E:\\Anaconda3\\envs\\tensorflow23\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py\", line 243, in allocate_tensors\r\n    return self._interpreter.AllocateTensors()\r\nRuntimeError: tensorflow/lite/kernels/pad.cc:118 op_context.input->type != op_context.constant_values->type (INT8 != FLOAT32)Node number 3 (PADV2) failed to prepare.\r\n\r\nThere is pad layer in the model, error after full quantization\r\n", "comments": ["@huafeihuayu,\r\nIn order to reproduce the issue reported here, could you please provide the TensorFlow version, the complete code and the dataset you are using. Thanks!", "@amahendrakar \r\nQuantization code\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport cv2\r\n\r\ndef representative_dataset_gen():\r\n    img=cv2.imread('C:/sfz/00/all/10cn000000000.jpg')\r\n    img=np.array(img,dtype='float32')\r\n    image_paths_tensor = tf.convert_to_tensor(img,dtype=tf.float32)\r\n    dataset = tf.data.Dataset.from_tensor_slices(image_paths_tensor)\r\n    for input_value in dataset.batch(1).take(100):\r\n        print(input_value)\r\n        yield [input_value]\r\nsaved_model_dir='D:/sfz/tf_sfz'\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.representative_dataset = representative_dataset_gen\r\n# Ensure that if any ops can't be quantized, the converter throws an error\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.allow_custom_ops=True\r\n# Set the input and output tensors to uint8 (APIs added in r2.3)\r\nconverter.inference_input_type = tf.uint8\r\nconverter.inference_output_type = tf.uint8\r\ntflite_model_quant = converter.convert()\r\nopen(\"D:/sfz/tf_sfz/model26.tflite\",\"wb\").write(tflite_model_quant)\r\n\r\ntensorflow-gpu2.3.0       C:/sfz/00/all/10cn000000000.jpg it is 32*416*33 ", "@huafeihuayu,\r\nCould you please share the saved_model files as well (i.e. contents of the folder `D:/sfz/tf_sfz`), so that we can reproduce the issue on our end. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Has this problem been solved or is there any workaround? \r\nI am facing the same issue when converting a Resnet18 (onnx --> tf --> tflite) to tflite with full int8 quantization with TensorFlow \r\n2.3", "@mschreil,\r\nCould you please submit a new issue from [this link](https://github.com/tensorflow/tensorflow/issues/new/choose) and fill in the template, so that we can track the issue there. Thanks!\r\n"]}, {"number": 43128, "title": "Models for TensorFlow Lite which are quantized according to the post-training quantization does not run on NPU of some devices.", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Y es\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):macOS 10.13.6, Android 10.1.0\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: MatePad Pro\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.15.3\r\n- Python version:3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nI am trying int8 quantization of my model on TensorFlow Lite.\r\nConversion itself worked using tensorflow 1.15.3 but the converted model ran extremely slowly on Kirin 990. logcat indicates that it runs on CPU, not NPU.\r\n(Conversion using tensorflow 2.3.0 did not work.)\r\n\r\nmobilenet_v1_1.0_224_quant.tflite in tensorflow/examples runs fast on Kirin 990. logcat indicates that it runs on NPU.\r\n\r\nSo I checked the differences between them.\r\n\r\n1. My model is int8(tf.lite.OpsSet.TFLITE_BUILTINS_INT8) quantization but mobilenet_v1_1.0_224_quant.tflite seems uint8 quantization.\r\n\r\n2. The \"filter\" property of Conv2D has a \"quantization\" attribute in mobilenet_v1_1.0_224_quant.tflite, but The \"filter\" property of Conv2D has no \"quantization\" attribute in my converted model.\r\n\r\nHow can I convert my model like mobilenet_v1_1.0_224_quant.tflite?\r\nPlease disclose the conversion script for mobilenet_v1_1.0_224_quant.tflite.\r\n\r\nI asked [the question](https://stackoverflow.com/questions/63700590/how-can-i-convert-my-model-like-mobilenet-v1-1-0-224-quant-tflite-in-tensorflow) on stackoverflow, but have not gotten relevant answers, so I ask the question here again.\r\n\r\nThanks.\r\n\r\n[Edit]\r\nIn my current understanding, some NNAPI drivers have not supported per-channel quantized model yet. But the post-training quantization in TensorFlow supports only er-channel quantization.\r\nI will appreciate if you provide solutions to resolve this situation.\r\n\r\n**Describe the expected behavior**\r\n\r\nI will get a fast, quantized model.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@y-ich \r\nPlease share simple stand alone code or if possible share a colab gist with error reported, if possible can you try in later versions of tf [2.x] and see if it helps resolve your issue.", "@Saduf2019 san, thank you for your response!\r\n\r\nDo you need my conversion script or converted model?", "@Saduf2019 san, I prepared the model.\r\n\r\nhttps://github.com/y-ich/reproduction_43128\r\n\r\nBTW, if you provide the conversion script for mobilenet_v1_1.0_224_quant.tflite, I can investigate this issue.\r\nYou do not need to spend your time for this issue.\r\n\r\nAbout  tf [2.x], I could not convert the model by tf 2.3.0.", "I have met a similar issue. The int8 tflite model is slower comparing with Fp32.\r\nI only use the default convert options.\r\n```\r\ndef representative_dataset_gen():\r\n  for input_value in dataset:\r\n    yield [input_value[0]]\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.representative_dataset = representative_dataset_gen\r\n```\r\nI don't think the overhead comes from quant and dequant op. But the Conv2D int8 vs fp32 is the hotspot.\r\n", "@y-ich \r\nPlease update a s per above comment.", "@Saduf2019 san,\r\n\r\nMaybe \"update a s per above comment\" is kind of typo? I am sorry that I cannot understand it.\r\n\r\nCurrently what I want to know is how to quantize weights as uint8 instead of int8.\r\nPlease let me know it.", "I have the same issue, i need to quantize a ssd_mobilenet_v1_fpn to use it on Android for object detection. \r\nFrom what I understood there are 3 types of quantizations,  as explained here: [https://www.tensorflow.org/lite/performance/post_training_quantization](url)\r\n\r\nI managed to perform dynamic range quantization, so now my model has uint8 filter weights. but it's still slow and too heavy!\r\nIn order to reduce futher latency i should perform full integer quantization to have both weights and inputs in uint8 format.\r\n\r\nSo i guess your model is dynamic range quantized and the example model is fully integer quantized.\r\n\r\nI tried this guide to fully quanized my model: https://neuralet.com/article/quantization-of-tensorflow-object-detection-api-models/\r\n\r\ni wrote this code:\r\n```python\r\n\r\nimport tensorflow as tf\r\nimport cv2\r\nimport numpy as np\r\nfrom imutils import paths\r\n\t\t\r\ndef dataset_gen():\r\n\timages_path =  # path to represantative dataset\r\n\tif images_path is None:\r\n\t\traise Exception(\r\n\t\t\t\"Image directory is None, full integer quantization requires images directory!\"\r\n\t\t)\r\n\timagePaths = list(paths.list_images(images_path))\r\n\tfor p in imagePaths:\r\n\t\timage = cv2.imread(p)\r\n\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\r\n\t\timage = cv2.resize(image, (640, 480))\r\n\t\timage = image.astype(\"float\")\r\n\t\timage = np.expand_dims(image, axis=1)\r\n\t\timage = image.reshape(1, 640, 480, 3)\r\n\t\tyield [image.astype(\"float32\")]\r\n\r\nfrozen_graph_file = # path to frozen graph (.pb file)\r\ninput_arrays = [\"normalized_input_image_tensor\"]\r\noutput_arrays = ['TFLite_Detection_PostProcess',\r\n\t\t  'TFLite_Detection_PostProcess:1',\r\n\t\t  'TFLite_Detection_PostProcess:2',\r\n\t\t  'TFLite_Detection_PostProcess:3']\r\ninput_shapes = {\"normalized_input_image_tensor\" : [1, 640, 480, 3]}\r\nconverter = tf.lite.TFLiteConverter.from_frozen_graph(frozen_graph_file,\r\n\t\t\t\t\t\tinput_arrays=input_arrays,\r\n\t\t\t\t\t\toutput_arrays=output_arrays,\r\n\t\t\t\t\t\tinput_shapes=input_shapes)\r\n\t\t\t\t\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\t\t\t\t \r\nconverter.allow_custom_ops = True\r\nconverter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\r\nconverter.representative_dataset = tf.lite.RepresentativeDataset(dataset_gen())\r\ntflite_quant_model = converter.convert()\r\n\r\nwith open(\"detect.tflite\", \"wb\") as tflite_file:\r\n\ttflite_file.write(tflite_quant_model)\r\n\r\n```\r\n\r\nbut it runs without producing any output models.\r\n", "@vito-filo san,\r\n\r\nCould tell me how to get uint8 filter weights?\r\nIn my experience, TensorFlow v1.15.3 generates only int8 weights, not uint8.", "uint8 or int8 may not matter.\r\n\"per channel quantization\" or not may matter.\r\nHuawei's NNAPI driver seems not support per-channel quantized weight yet.\r\nI guess that some old version of TensorFlow quantizes as uint8 and per-tensor, but the last TensorFlow 1 and the latest TensorFlow 2 quantize as in8 and per-channel.\r\n\r\nI want to know how to quantize models as per-tensor (and uint8).", "Now that I'm paying attention in my model i have int8 weights, not uint8.\r\nHowever i think this is not the main problem, as @Leslie-Fang said the overhead is on the float32 parameters you may have in the layers.\r\n\r\nI think you can get the best optimization with full integer quantization. unfortunately I am not yet able do it on my model. I wonder if @Leslie-Fang did it.\r\n\r\nCheck if you have some float32 parameters in your conv layers (as input, output or bias).\r\nI am not well versed in these things, but I think we have the same problem and a possible solution to improve speed on mobile devices is to convert all float32 parameters to int8 (or uint8).\r\n\r\n", "@vito-filo san,\r\n\r\nThank you for your advice!\r\nI tried \"Integer only\" in [Post-training quantization](https://www.tensorflow.org/lite/performance/post_training_quantization), but the result was same.\r\n\r\n\"adb logcat\" say,\r\n    09-15 20:38:55.971   886   886 E AndroidNN: AnnOpConvParser::isSupport1_1(278)::\"Conv input type per channel not support\"\r\n\r\nI think that tensorflow had changed conv quantization from per-tensor to per-channel in some version.\r\nI want to know what version is the last version using per-tensor.", "I found the same issue and it has no answers.\r\nhttps://github.com/tensorflow/tensorflow/issues/39944", "I found the statement \u201cUInt8 models trained with the legacy quantization-aware training path are also supported\u201d in the document [\u201c TensorFlow Lite Hexagon delegate\u201d](https://www.tensorflow.org/lite/performance/hexagon_delegate).\r\nIt is a part of the answer which I want to know.\r\n\r\nNow my question is, how can I disable per-channel(per-axis) quantization for post-training quantization.", "I summarized my understanding and close this issue.\r\n\r\n1. Android 10 introduced NNAPI 1.2, which supports per-channel quantization. And TensorFlow Lite moved from per-tensor quantization-aware training to per-channel post-training quantization as main line.\r\n2. Huawei did not implement NNAPI 1.2 for NPU on Android 10, so per-channel quantized model falls back to CPU.\r\n3. TensorFlow Lite seems on the way to support \u201cdisable_per_channel\u201d with low priority.\r\n\r\nI hope that EMUI 11 supports NNAPI 1.2 or implementation of \u201cdisable_per_channel\u201d on TensorFlow Lite will finish soon.", "@y-ich I encountered the same problem. On Huawei phones(OS: Android 10), the NNAPI delegate failed to open.\r\nSo, do you have a solution now?\r\nBelow is a screenshot of my error log.\r\n![](https://user-images.githubusercontent.com/24367027/117395743-22f70280-af2b-11eb-8fb3-777a9a985f00.png)\r\n", "Meet same problem\uff0cdo you get a solution now ?\r\nWhether tensorflow  < 1.15 work?"]}, {"number": 43127, "title": "Revert \"Add symmetric int16 support to tflu softmax reference kernel\"", "body": "Reverts tensorflow/tensorflow#38873\r\n\r\nThis is the first workaround for #43126 ", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 43126, "title": "Int16 softmax is using std::vector", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian\r\n- TensorFlow installed from (source or binary): Source\r\n- Tensorflow version (commit SHA if source): 35d9474383c9befd99f457031ada977d681742c4\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): STM32F4\r\n\r\n**Describe the problem**\r\nThis command:\r\n```\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=stm32f4 kernel_softmax_test\r\n```\r\n\r\nFails with the following error message:\r\n```\r\n/home/advaitjain/tensorflow/github/tensorflow/tensorflow/lite/micro/tools/make/downloads/gcc_embedded/bin/../lib/gcc/arm-none-eabi/7.3.1/thumb/v7e-m/libgcc.a(unwind-arm.o): In function `get_eit_entry':\r\nunwind-arm.c:(.text+0x138): undefined reference to `__exidx_end'\r\nunwind-arm.c:(.text+0x13c): undefined reference to `__exidx_start'\r\ncollect2: error: ld returned 1 exit status\r\n```\r\n\r\nThe underlying issue is that the reference implementation of int16 softmax uses std::vector which is incompatible with Micro.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/35d9474383c9befd99f457031ada977d681742c4/tensorflow/lite/kernels/internal/reference/softmax.h#L168\r\n\r\nThe near-term fix will be to revert PR #38873. Longer-term we would have to fix up the reference implementation to be friendly for embedded platforms.\r\n\r\nThis issue was not caught by continuous integration when the PR was merged because we do not build for TARGET=stm32f4 with only the reference kernels. We only do so with TAGS=cmsis-nn.\r\n\r\nTwo ways to safeguard against this in the future would be:\r\n 1. build STM32F4 without any additional TAGS\r\n 1. fix up bluepill and add more tests to that target -- this is likely preferable.\r\n", "comments": ["Tagging @freddan80 and @sicong-li-arm \r\n\r\nI'm not thrilled with the revert because of the effort involved in getting this landed from everyone involved. I hope there aren't too many side effects. Let's figure out a proper fix if this is high priority for you guys.", "@advaitjain Is this issue resolved with #43180 ?", "> @advaitjain Is this issue resolved with #43180 ?\r\n\r\nYes, we should be able to revert #43127 once #43180 is merged.", "@advaitjain @freddan80 Just came back to office. Sorry for the oversight! The fix looks good to me. Ping me if there's anything I need to do.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43126\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43126\">No</a>\n", "Created #43320 to \"revert the revert\"."]}, {"number": 43125, "title": "tf.data.experimental.service throws error when using with TPUs", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes, I put an example to reproduce the issue below\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n`\r\n$ uname -a\r\nLinux james-tpu 4.19.0-10-cloud-amd64 #1 SMP Debian 4.19.132-1 (2020-07-24) x86_64 GNU/Linux\r\n`\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nN/A\r\n- TensorFlow installed from (source or binary):\r\nbinary\r\n- TensorFlow version (use command below):\r\nv2.3.0-rc2-23-gb36436b087 2.3.0\r\n- Python version:\r\n3.7.3\r\n- Bazel version (if compiling from source):\r\nN/A\r\n- GCC/Compiler version (if compiling from source):\r\nN/A\r\n- CUDA/cuDNN version:\r\nN/A\r\n- GPU model and memory:\r\nN/A\r\n\r\n**Describe the current behavior**\r\nErrors out with `2020-09-10 22:59:13.294374: E tensorflow/core/common_runtime/eager/context.cc:678] Failed to register function remotely due to Failed to register dataset: failed to connect to all addresses` see full log below\r\n\r\n**Describe the expected behavior**\r\nI wouldn't expect an error for this code.\r\n**Standalone code to reproduce the issue**\r\n<details>\r\n<summary>Code</summary>\r\n\r\n```\r\nimport logging\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nlogging.getLogger('tensorflow').setLevel(logging.DEBUG)\r\n\r\n\r\ndef get_dataset(dispatcher, batch_size):\r\n  fake_data = np.zeros((128, 256, 256), dtype=np.float32)\r\n  ds = tf.data.Dataset.from_tensor_slices(fake_data)\r\n  ds = ds.repeat()\r\n  ds = ds.batch(batch_size)\r\n  ds = ds.apply(tf.data.experimental.service.distribute('parallel_epochs', dispatcher.target, job_name='data_job'))\r\n  return ds\r\n\r\ndef run(strategy, batch_size):\r\n  data_dispatcher = tf.data.experimental.service.DispatchServer(port=0)\r\n  dispatcher_address = data_dispatcher.target.split(\"://\")[1]\r\n  worker = tf.data.experimental.service.WorkerServer(\r\n    port=0, dispatcher_address=dispatcher_address)\r\n\r\n  per_replica_batch_size = batch_size // strategy.num_replicas_in_sync\r\n  dataset = strategy.experimental_distribute_datasets_from_function(\r\n    lambda _: get_dataset(\r\n      data_dispatcher,\r\n      per_replica_batch_size,\r\n    )\r\n  )\r\n  ds_iterator = iter(dataset)\r\n\r\n  @tf.function(input_signature=[tf.TensorSpec([256, 256], dtype=tf.float32)])\r\n  def step_fn(inputs):\r\n    return\r\n\r\n  @tf.function\r\n  def train_step(iterator):\r\n    strategy.run(step_fn, args=(next(iterator),))\r\n\r\n  for _ in range(10):\r\n    train_step(ds_iterator)\r\n\r\n\r\ndef setup_strategy(tpu=False):\r\n  resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='james-tpu')\r\n  tf.config.experimental_connect_to_cluster(resolver)\r\n  tf.tpu.experimental.initialize_tpu_system(resolver)\r\n  return tf.distribute.TPUStrategy(resolver)\r\n\r\n\r\nif __name__ == '__main__':\r\n  strategy = setup_strategy()\r\n  batch_size = 64\r\n  run(strategy, batch_size)\r\n```\r\n</details>\r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n<details>\r\n<summary>Logs</summary>\r\n\r\n```\r\n2020-09-10 22:59:07.877313: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-09-10 22:59:07.882757: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2299995000 Hz\r\n2020-09-10 22:59:07.883041: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3aa2460 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-09-10 22:59:07.883156: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-09-10 22:59:07.889580: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.184.89.74:8470}\r\n2020-09-10 22:59:07.889626: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:31299}\r\n2020-09-10 22:59:07.904477: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.184.89.74:8470}\r\n2020-09-10 22:59:07.904533: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:31299}\r\n2020-09-10 22:59:07.905018: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:405] Started server with target: grpc://localhost:31299\r\nINFO:tensorflow:Initializing the TPU system: james-tpu\r\nINFO:tensorflow:Initializing the TPU system: james-tpu\r\nINFO:tensorflow:Clearing out eager caches\r\nINFO:tensorflow:Clearing out eager caches\r\nINFO:tensorflow:Finished initializing TPU system.\r\nINFO:tensorflow:Finished initializing TPU system.\r\nINFO:tensorflow:Found TPU system:\r\nINFO:tensorflow:Found TPU system:\r\nINFO:tensorflow:*** Num TPU Cores: 8\r\nINFO:tensorflow:*** Num TPU Cores: 8\r\nINFO:tensorflow:*** Num TPU Workers: 1\r\nINFO:tensorflow:*** Num TPU Workers: 1\r\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\r\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\r\n2020-09-10 22:59:13.294374: E tensorflow/core/common_runtime/eager/context.cc:678] Failed to register function remotely due to Failed to register dataset: failed to connect to all addresses\r\nThis shouldn't happen, please file a bug to tensorflow team.\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/jamesbartlett/train/pixieml/pixieml/models/transformer/minimal_example.py\", line 54, in <module>\r\n    run(strategy, batch_size)\r\n  File \"/home/jamesbartlett/train/pixieml/pixieml/models/transformer/minimal_example.py\", line 30, in run\r\n    ds_iterator = iter(dataset)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/input_lib.py\", line 1199, in __iter__\r\n    enable_legacy_iterators)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/input_lib.py\", line 1752, in _create_iterators_per_worker\r\n    worker_devices)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/input_lib.py\", line 1609, in __init__\r\n    devices)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/input_lib.py\", line 1448, in __init__\r\n    self._make_iterator()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/input_lib.py\", line 1619, in _make_iterator\r\n    self._dataset, self._devices, source_device=host_device)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py\", line 547, in __init__\r\n    dataset.element_spec)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py\", line 54, in __init__\r\n    init_func_concrete = _init_func.get_concrete_function()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 2939, in get_concrete_function\r\n2020-09-10 22:59:13.297630: W tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.cc:76] Unable to destroy remote tensor handles. If you are running a tf.function, it usually indicates some op in the graph gets an error: Failed to register dataset: failed to connect to all addresses\r\n    *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 2906, in _get_concrete_function_garbage_collected\r\n    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3213, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3075, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 991, in func_graph_from_py_func\r\n    expand_composites=True)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\", line 635, in map_structure\r\n    structure[0], [func(*x) for x in entries],\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\", line 635, in <listcomp>\r\n    structure[0], [func(*x) for x in entries],\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 942, in convert\r\n    x = ops.convert_to_tensor_or_composite(x)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1622, in convert_to_tensor_or_composite\r\n    value=value, dtype=dtype, name=name, as_ref=False)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1661, in internal_convert_to_tensor_or_composite\r\n    accepted_result_types=(Tensor, composite_tensor.CompositeTensor))\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1467, in convert_to_tensor\r\n    return graph.capture(value, name=name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 624, in capture\r\n    return self.capture_eager_tensor(tensor, name)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 721, in capture_eager_tensor\r\n    graph_const = constant_op.constant(tensor.numpy(), dtype=tensor.dtype,\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1063, in numpy\r\n    maybe_arr = self._numpy()  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1031, in _numpy\r\n    six.raise_from(core._status_to_exception(e.code, e.message), None)  # pylint: disable=protected-access\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.UnavailableError: Failed to register dataset: failed to connect to all addresses\r\nError in atexit._run_exitfuncs:\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/tpu_strategy.py\", line 540, in async_wait\r\n    context.async_wait()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\", line 2319, in async_wait\r\n    context().sync_executors()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\", line 658, in sync_executors\r\n    pywrap_tfe.TFE_ContextSyncExecutors(self._context_handle)\r\ntensorflow.python.framework.errors_impl.UnavailableError: Failed to register dataset: failed to connect to all addresses\r\n2020-09-10 22:59:13.375822: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 30, Output num: 0\r\nAdditional GRPC error information from remote target /job:worker/replica:0/task:0:\r\n:{\"created\":\"@1599778753.375752373\",\"description\":\"Error received from peer ipv4:10.184.89.74:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 30, Output num: 0\",\"grpc_status\":3}\r\n```\r\n</details>", "comments": ["Was able to reproduce the issue with TF v2.3. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/a9bf81fba516d0dfee51bcfca6507d6f/43125.ipynb). Thanks!", "Hi @JamesMBartlett, to help isolate if this is an issue with tf.data or with tpu, can you confirm that your code runs without TPUs using the default strategy `tf.distribute.get_strategy` ?", "Yeah the error goes away with the default strategy, although there's a bug with my minimal example where I specified the wrong input shape, so you get the following error: \r\n```\r\nValueError: Python inputs incompatible with input_signature:\r\n      inputs: (\r\n        Tensor(\"IteratorGetNext:0\", shape=(None, 256, 256), dtype=float32))\r\n      input_signature: (\r\n        TensorSpec(shape=(256, 256), dtype=tf.float32, name=None))\r\n```", "Can you provide a fix so that the code runs without error when using the default strategy?", "This code errors if you run with variable `tpu = True` on line 59, and doesn't error if `tpu = False`:\r\n```\r\nimport logging\r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nlogging.getLogger('tensorflow').setLevel(logging.DEBUG)\r\n\r\n\r\ndef get_dataset(dispatcher, batch_size):\r\n  fake_data = np.zeros((128, 256, 256), dtype=np.float32)\r\n  ds = tf.data.Dataset.from_tensor_slices(fake_data)\r\n  ds = ds.repeat()\r\n  ds = ds.batch(batch_size)\r\n  ds = ds.apply(tf.data.experimental.service.distribute('parallel_epochs', dispatcher.target, job_name='data_job'))\r\n  return ds\r\n\r\ndef run(strategy, batch_size):\r\n  data_dispatcher = tf.data.experimental.service.DispatchServer(port=0)\r\n  dispatcher_address = data_dispatcher.target.split(\"://\")[1]\r\n  worker = tf.data.experimental.service.WorkerServer(\r\n    port=0, dispatcher_address=dispatcher_address)\r\n\r\n  per_replica_batch_size = batch_size // strategy.num_replicas_in_sync\r\n  dataset = strategy.experimental_distribute_datasets_from_function(\r\n    lambda _: get_dataset(\r\n      data_dispatcher,\r\n      per_replica_batch_size,\r\n    )\r\n  )\r\n  ds_iterator = iter(dataset)\r\n\r\n  @tf.function(input_signature=[tf.TensorSpec([None, 256, 256], dtype=tf.float32)])\r\n  def step_fn(inputs):\r\n    pass\r\n\r\n  @tf.function\r\n  def train_step(iterator):\r\n    strategy.run(step_fn, args=(next(iterator),))\r\n\r\n  for _ in range(10):\r\n    train_step(ds_iterator)\r\n\r\n  print('Finished, stopping data workers...')\r\n  del ds_iterator\r\n  del dataset\r\n  data_dispatcher._stop()\r\n  worker._stop()\r\n  print('Stopped')\r\n\r\n\r\ndef setup_tpu_strategy():\r\n  resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='james-tpu')\r\n  tf.config.experimental_connect_to_cluster(resolver)\r\n  tf.tpu.experimental.initialize_tpu_system(resolver)\r\n  return tf.distribute.TPUStrategy(resolver)\r\n\r\n\r\nif __name__ == '__main__':\r\n  tpu = False\r\n  if tpu:\r\n    strategy = setup_tpu_strategy()\r\n  else:\r\n    strategy = tf.distribute.get_strategy()\r\n  batch_size = 64\r\n  run(strategy, batch_size)\r\n```", "@aaudiber do you have any thoughts here? The error is \"Failed to register function remotely due to Failed to register dataset\".", "@rxsang is that the full error? The real cause should be included as \"Failed to register dataset: \\<cause\\>\" (error message created [here](https://github.com/tensorflow/tensorflow/blob/8e789c38727f955fd9735e41c0155a536f0d30b6/tensorflow/core/data/service/data_service.cc#L123)/[here](https://github.com/tensorflow/tensorflow/blob/8e789c38727f955fd9735e41c0155a536f0d30b6/tensorflow/core/data/service/grpc_util.cc#L34-L35))", "I think the full error is `2020-09-10 22:59:13.294374: E tensorflow/core/common_runtime/eager/context.cc:678] Failed to register function remotely due to Failed to register dataset: failed to connect to all addresses\r\nThis shouldn't happen, please file a bug to tensorflow team.`\r\nHowever it is not that informative.", "@JamesMBartlett I think the problem is in the target passed in\r\n\r\n```\r\nds = ds.apply(tf.data.experimental.service.distribute('parallel_epochs', dispatcher.target, job_name='data_job'))\r\n```\r\n\r\n`dispatcher.target` will return something like `\"grpc://localhost:39263\"`. This works when the client runs on the local machine (non-TPU case), but when the TPU tries to register the dataset with \"localhost:39263\", it hits \"Failed to register dataset: failed to connect to all addresses\". Can you try setting a specific port and using an IP address accessible from the TPU?\r\n\r\nSomething like\r\n\r\n```\r\ndata_dispatcher = tf.data.experimental.service.DispatchServer(port=5050)\r\n...\r\nds = ds.apply(tf.data.experimental.service.distribute('parallel_epochs', \"grpc://<ip_address>:5050, job_name='data_job'))\r\n```", "I can confirm that if I use `grpc://<ip_address>:5050` then my minimal example works.", "Thanks for confirming James! I will submit a change to include the dispatcher address in the error message, to help diagnose this type of issue in the future.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43125\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43125\">No</a>\n", "> I can confirm that if I use `grpc://<ip_address>:5050` then my minimal example works.\r\n\r\nHow did you determine the IP for the TPU VM? Does it work in Colab TPU?\r\nDoes it work without dataset = strategy.experimental_distribute_datasets_from_function or with strategy.experimental_distribute_dataset?"]}, {"number": 43123, "title": "Make the internal and external builds more similar.", "body": "This should help prevent back and forth [like this](https://github.com/tensorflow/tensorflow/pull/39946#issuecomment-690726860)", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 43122, "title": "model_main_tf2.py \"module tensorflow.compat.v2 has no attribute app\"", "body": "\r\n### System informatio\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**: model_main_tf2.py \r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04.5\r\n-   **TensorFlow installed from (source or binary)**: 2.3.0\r\n-   **TensorFlow version (use command below)**: v2.3.0-rc2-23-gb36436b087 2.3.0\r\n-   **Python version**: Python 3.6.9\r\n-   **GPU model and memory**: V100\r\n-   **Exact command to reproduce**: python3 ../../models/research/object_detection/model_main_tf2.py --pipeline_config_path=model/pipe.config --model_dir=training --logtostderr\r\n\r\n### Describe the problem\r\nI'm just trying to run a basic training job through the provided script in the object_detection samples. I used to run the model_main.py with TF 1.x.\r\n\r\n### Source code / logs\r\n```\r\n2020-09-10 20:33:44.263700: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\nTraceback (most recent call last):\r\n  File \"../../models/research/object_detection/model_main_tf2.py\", line 112, in <module>\r\n    tf.app.run()\r\nAttributeError: module 'tensorflow.compat.v2' has no attribute 'app'\r\n```", "comments": ["You need to update your model for TF2. Has you see It Is changed:\r\nhttps://github.com/tensorflow/models/blob/master/research/object_detection/model_main_tf2.py#L113", "@turowicz \r\n\r\nIn this tensorflow 2 guide,https://www.tensorflow.org/guide/effective_tf2, it says tf.app is removed.So in TF 1.x your code is running fine.\r\nTo resolve this error, modify the code so that it uses 2.x API \r\nYou can refer similar issues #37128,#34431.Thanks!", "Thanks, it works when I check out `master` branch of this repository.", "[[Solved] module \u2018tensorflow.compat.v2.__internal__\u2019 has no attribute \u2018tf2\u2019\r\n](https://exerror.com/module-tensorflow-compat-v2-internal-has-no-attribute-tf2/)"]}, {"number": 43120, "title": "After several iterations the error:  \"input and filter must have the same depth\" is arose", "body": "I am trying to fit my model by using a generator working on my dataset (audio files). I use a gold cluster (SLURM) to run my program including generator for creating my input features and corresponding targets (by using yeilding method, and safe threading), and fit_generator for training my model.\r\nUnfortunetly, after 388 iterations including batches with 128 size, the error:\r\n\r\n tensorflow.python.framework.errors_impl.InvalidArgumentError:  input and filter must have the same depth: 6 vs 18\r\n\t [[node model_4/conv2d_80/BiasAdd (defined at /Project1/Training/Prog/preANDtrain_generator_model2.py:187) ]] [Op:__inference_train_function_9095]\r\n\r\nFunction call stack:\r\ntrain_function\r\n\r\n2020-09-10 17:09:40.560724: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.\r\n\t [[{{node PyFunc}}]] \r\n\r\nwas shown and my program was failed. \r\nThe depth (#channels) of the input features is 6 and the first layer is a covolutional layer with 18 channels (filters). I became confused why the error was shown after 388 iterations, and why the depth of input features and the first layer must be same.\r\nI will be so grateful if someone can help me to solve the problem\r\n[New Text Document.txt](https://github.com/tensorflow/tensorflow/files/5204020/New.Text.Document.txt)\r\n.\r\n\r\n", "comments": ["Have you seen https://stackoverflow.com/questions/59380430/how-to-use-model-fit-which-supports-generators-after-fit-generator-deprecation? \r\nPlease also fill the template issue and share a very, very minimal but runnable example or colab to reproduce this.", "Thank you so much bhack for your answer.\r\n\r\nI have just tried **fit** instead of **fit_generator** in my program, and the same error was shown at the same iteration (388).\r\nIt is really confusing that the error arises after several iterations.\r\n\r\nI created a template for this issue and attached a very very minimal program and dataset: [relatedtoissue_43120](https://github.com/PEYMAN333/relatedtoissue_43120) https://github.com/PEYMAN333/relatedtoissue_43120\r\n\r\nThank you again for your help.\r\n", "I performed line to line double checks, and found out that one line has unwanted TAB, in one of the functions of the generator. This could lead to a reduced dimension feature in audio files with small size. I edited and run again the program. Fortunately, the training phase passed the 388 iteration. However, I am still surprised for the strange shown error which may seem irrelevant! The \"ValueError: Error when checking input: expected input_ to have * dimensions, but got array with shape (, ,)**\" may be more relevant for this dimension mismatching.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43120\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43120\">No</a>\n"]}, {"number": 43119, "title": "Segfault on absurdly large shuffle buffer for `make_csv_dataset`", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch linux kernel 5.8.7 (primary), Ubuntu 18.04 (container)\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): (git) v2.3.0-rc2-23-gb36436b087 (tf version) 2.3.0\r\n- Python version: 3.8.5\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: N/A -- run on a CPU\r\n\r\n**Describe the current behavior**\r\nUnder certain (admittedly abnormal) shuffle buffer sizes, attempting to use the returned dataset fails with a segfault.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nWith a CSV with ~300 pieces of data per entry, the following snippet causes a segfault:\r\n\r\n```py\r\n# Given:\r\n#   ABSURDLY_LARGE_NUMBER = <around 2\u00d710^17>\r\n#   YOUR_CSV_PATH = <somewhere you put your csv file>\r\n#   LABEL_COLUMN = <label column from the csv>\r\n#   INPUT_COLUMNS = <list of columns from the csv, len() around 300>\r\n\r\nimport tensorflow as tf\r\n\r\n# Helper function to get a dataset\r\ndef get_dataset(file_path, **kwargs):\r\n    return tf.data.experimental.make_csv_dataset(\r\n        file_path,\r\n        batch_size=1,\r\n        num_epochs=1,\r\n        label_name=LABEL_COLUMN,\r\n        select_columns=[LABEL_COLUMN] + INPUT_COLUMNS, # Around 300 entries\r\n        header=True,\r\n        shuffle=True,\r\n        shuffle_buffer_size=ABSURDLY_LARGE_NUMBER, # <- SOURCE OF ERROR\r\n        **kwargs)\r\n\r\n# Used later, with some model constructed with the keras `Sequential` API\r\n\r\nmodel.evaluate(get_dataset(YOUR_CSV_PATH))\r\n```\r\n\r\n[Full standalone example](https://gist.github.com/sharnoff/5dc5000fca80a2ab0f78b2786b75c2eb)\r\n\r\nThere might be (justified) responses like:\r\n\r\n> Well sure - a segfault should be expected if you're going to be doing silly things like this!\r\n\r\nAnd that's perhaps fair, but bugs are often only dumb in hindsight, and this was a result of rapid modification of a script over time - pieces get left in that you might not expect.\r\n\r\n## Possible cause\r\n\r\n**[disclaimer]** This is purely speculation; I'm basing this on the bits of information I found after\r\n\r\nBecause the maximum value of a 64-bit unsigned integer is around 2\u00d710^19, and the requested buffer size was around 2\u00d710^17, the size of an individual piece of data (at around 300 inputs) would have been enough to trigger overflow in the allocation size where it might not have been caught initially.\r\n\r\nThe segfault may have also been a result of the size of the requested allocation for the shuffle buffer.\r\n\r\nWhen running inside GDB, an *internal* error was generated, reading:\r\n```\r\n../../gdb/utils.c:684: internal-error: virtual memory exhausted: can't allocate 5506620787261440008 bytes.\r\nA problem internal to GDB has been detected, further debugging may prove unreliable\r\n```\r\n\r\nWhile an internal bug in GDB is a completely separate topic, the indication of the requested allocation size may be helpful here.\r\n\r\n## Possible source\r\n\r\n(with the extensive help of a friend) I managed to track a possible source for a bad allocation down to [these](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/data/shuffle_dataset_op.cc#L146) two [lines](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/data/shuffle_dataset_op.cc#L351), where an invalid allocation might be attempted. I believe these could be sources of the segfault (though there may be more)", "comments": ["@sharnoff \r\n\r\nLooks like code is incomplete.Please, share colab link or simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "Thanks for the response - I've added [the link](https://gist.github.com/sharnoff/5dc5000fca80a2ab0f78b2786b75c2eb) to the issue", "@sharnoff \r\n\r\nI tried reproducing the in colab with TF version 2.3.0 and i see session is getting crashed. Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/0518f4ae9de1da6640bcafda5a17a7cb/untitled336.ipynb). Thanks!", "This is \"working as intended\". tf.data does not guard against user choosing absurdly large values that run the underlying machine out of memory.\r\n\r\nThis is no different than say in C++ trying to create a vector that is absurdly large.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43119\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43119\">No</a>\n", "@jsimsa While I appreciate that this behavior might be expected in C++ (more at the end), Python *does* have protection against this. For example, below is the output I get in the Python interpreter with a similar type of error:\r\n```\r\n>>> x = [None] * (1000**4)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nMemoryError\r\n```\r\nI understand that, in practice, this type of error only occurs through the user being dumb. But I don't belive that segfaults should be expected behavior for python code -- they make code *particularly* difficult to debug. Crucially, the majority of Tensorflow users are not fluent in C++ or other systems languages.\r\n\r\nFinally, on the topic of this being expected behavior, it's worth noting that the C++ standard library *also* has protection against bad allocations -- a feature that is intentionally absent in abseil's implementation of `make_unique`. See [https://en.cppreference.com/w/cpp/memory/unique_ptr/make_unique](https://en.cppreference.com/w/cpp/memory/unique_ptr/make_unique):\r\n\r\n> Exceptions\r\n> May throw `std::bad_alloc` or any exception thrown by the constructor of T. If an exception is thrown, this function has no effect."]}, {"number": 43118, "title": "Add bazel to the test_x86 script.", "body": "This should enable external contributors to more easily test with bazel and prevent [back and forth](https://github.com/tensorflow/tensorflow/pull/42452#pullrequestreview-486197542) to try and resolve internal errors.\r\n\r\nNote that bazel is not invoked from test_all.sh.  This is because the bazel build is already part of the presubmits and the goal here is to enable developers to catch errors sooner locally.\r\n\r\nAlso, the fact that the micro test_all.sh script runs within a docker container means that initiating a bazel build on the CI system would mean downloading bazel to the docker image.", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 43117, "title": "Update .bazelrc", "body": "wd", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F43117) for more info**.\n\n<!-- need_sender_cla -->", "Wrongly opened it."]}, {"number": 43116, "title": "I want to add a \"RecvTensor\" Op on \"timeline\" Tracing  for RDMA  , But  The code does not worked, can help me ? ", "body": "The \"rdma\" extension is now on this[ link ](https://github.com/tensorflow/networking/blob/e1c7ae09923293f9cce5eba0a159e75993b793be/tensorflow_networking/verbs/rdma_rendezvous_mgr.cc#L74)\r\n\r\nI want to add \"RecvTensor\" Op on \"Chrome://tracing\" which is for rdma.\r\n\r\nrdma.cc\r\n`class RdmaTensorRequest {\r\n...\r\n RdmaChannel* rdma_channel() {\r\n    return channel_;\r\n  }\r\n....\r\n}`\r\n\r\n\r\n\r\nrdma_rendezvous_mgr.cc \r\n\r\n```void RdmaRemoteRendezvous::RecvFromRemoteAsync(  ...\r\n\r\n RdmaTensorRequest* request =\r\n      rc->InsertTensorRequest(key, step_id_, dst_dev, recv_args, done);\r\n  request->set_recv_req_start_micros(Env::Default()->NowMicros());  \r\n\r\nauto* worker_cache = request->rdma_channel()->adapter_->\r\n            worker_env_->session_mgr->LegacySession()->worker_cache.get();\r\n  auto* timeline_logger = dynamic_cast<WorkerCachePartial*>(worker_cache)->GetLoagger();\r\n  bool logging_active = timeline_logger->LoggingActive() || VLOG_IS_ON(2);\r\n  if (logging_active) {\r\n    if (timeline_logger->LoggingActive()) {\r\n      // timeline_logger->RecordDataTransfer(\r\n      //         step_id, send_start_usec, end_usec, key, request->src_device(),\r\n      //         request->dst_device(), num_bytes, \"\", \"RecvBuf\");\r\n      std::vector<string> key_parts = str_util::Split(key, ';');\r\n      if (key_parts.size() != 5) {\r\n        LOG(WARNING) << \"Bad key: \" << key;\r\n      } else {\r\n\r\n        int64 end_usec = Env::Default()->NowMicros();\r\n        int64 send_start_usec = end_usec - 10;\r\n        timeline_logger->RecordRecvTensor(step_id_, send_start_usec, end_usec,\r\n                                  key_parts[3],  // tensor name\r\n                                  key_parts[0],  // src_device\r\n                                  key_parts[2],  // dst_device\r\n                                  2);\r\n      }\r\n    }\r\n  }\r\n`\r\n\r\n\r\nBut this code  does not work, can help me?", "comments": ["@wu-yy Please post this issue [here](https://github.com/tensorflow/networking/issues) as this issue is primarily related to tensorflow/networking not tensorflow itself. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 43115, "title": "tf.signal.ifft returns results with different dtypes for subsequent calls with the same parameter", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 10.4\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v1.12.1-40510-ga32c74ae8f 2.4.0-dev20200829\r\n- Python version: Python 3.8.3\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\n\r\nWhen calling `tf.signal.ifft` with an operand with a `complex128` dtype several times, the first call returns a `complex128` array as expected, but all subsequent calls return a `complex64` array.\r\n\r\n**Describe the expected behavior**\r\n\r\n`tf.signal.ifft` should always return an array with the same type as its input per the documentation; more importantly, it should be consistent across calls.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\noperand = np.ones((2, 2), dtype=np.complex128)\r\nprint(tf.signal.ifft(operand).dtype)\r\nprint(tf.signal.ifft(operand).dtype)\r\n```\r\n", "comments": ["For me It works with tf-nightly and:\r\n```\r\nprint(tf.signal.ifft([operand]).dtype)\r\nprint(tf.signal.ifft([operand]).dtype)\r\n```", "for me it is:\r\n**2020-09-11 11:01:58.434235**: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n**2020-09-11 11:01:58.458559**: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f80984b9190 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n**2020-09-11 11:01:58.458578**: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\ntf.complex64\r\n\r\n\r\n\r\nyou need rebuild TensorFlow with the appropriate compiler flags. Because this TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA", "@TuringEmmy try with https://pypi.org/project/tf-nightly-cpu/", "@TuringEmmy \r\nPlease update as per above comment.\r\nIs there any particular reason for using older version of tf [1.13] when there are later versions available, would you want to upgrade  to latest version and let us know if you still face issues.", "@Saduf2019\r\nI assume you mean me, as @TuringEmmy is not the original author of the issue.\r\nI am using the TF nightly build `2.4.0-dev20200829`; isn't that (one of) the most recent TF2 builds? Nevertheless, I upgraded to `v1.12.1-41432-g3e446295d8 2.4.0-dev20200912`, the latest version I was able to get through pip, and the issue is still here.\r\n\r\n> For me It works with tf-nightly and:\r\n> \r\n> ```\r\n> print(tf.signal.ifft([operand]).dtype)\r\n> print(tf.signal.ifft([operand]).dtype)\r\n> ```\r\n\r\n@bhack This indeed works, but the behavior is still different across calls without the brackets. Any insight why?", "Closing this issue since its resolved. Feel free to reopen if necessary. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43115\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43115\">No</a>\n"]}, {"number": 43114, "title": "Problem saving and loading Keras Model that was built with StellarGraph library", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nI am using StellarGraph package which uses Keras for building graph neural networks. \r\n \r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Catalina\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NIL\r\n\r\n- TensorFlow installed from (source or binary): binary \r\n- TensorFlow version (use command below): pip install tensorflow 2.3.0\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: \r\n- GPU model and memory: \r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nI have used the following code to save and load the Keras model:\r\n\r\n```\r\njson_file = open(os.path.join(\"./outputs/model_new/\", 'model.json'), 'r')\r\nmodel_json = json_file.read()\r\njson_file.close()\r\nmodel = model_from_json(model_json, custom_objects=sg.custom_keras_layers)\r\n# load weights into new model\r\nmodel.load_weights(os.path.join(\"./outputs/model_new/\", \"model.h5\"))   \r\nmodel.compile(\r\n            optimizer=optimizers.Adam(lr=0.002),\r\n            loss=keras.losses.binary_crossentropy,\r\n            metrics=METRICS,\r\n        )\r\n```\r\n\r\nHowever, it returns the following error:\r\n\r\n```\r\nValueError: Dimension 1 in both shapes must be equal, but are 2 and 1. Shapes are [?,2] and [?,1]. for '{{node mean_hin_aggregator_3/concat_5}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](mean_hin_aggregator_3/Reshape_35, mean_hin_aggregator_3/truediv_5, mean_hin_aggregator_3/concat_5/axis)' with input shapes: [?,2,18], [?,1,18], [] and with computed input tensors: input[2] = <2>.\r\n```\r\n\r\nPlease note that I am using StellarGraph to build the graph model. There are some custom layers involved such as Mean_hin_aggregator. I suspect this is the cause of the problem. A similar problem was mentioned in StellarGraph issues before: https://github.com/stellargraph/stellargraph/issues/201\r\n\r\n**Describe the expected behavior**\r\n\r\nIt should return the trained model.\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@kwanchet \r\n\r\nCan you please share colab link or simple standalone code with supporting files ( `model.json`) to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "A brilliant feature of HinSage is that it can do inductive representation learning. Not being able to save and load the model makes this much less useful. \r\n\r\nIs this being looked at so we can use this awesome algorithm in all its glory?", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43114\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43114\">No</a>\n", "@ravikyram I am encountering similar issues. Here is the colab [link](https://colab.research.google.com/github/stellargraph/stellargraph/blob/master/demos/link-prediction/hinsage-link-prediction.ipynb#scrollTo=AUcv_Osglmxf) . \r\n\r\nAfter training the model, i used `model.save('model/movie_rec.h5')` to save the model. However, I am having issues loading the model using ` models.load_model(\"model/movie_rec.h5\")`. \r\n\r\nCould you please advise what's the proper way of saving and loading graph models? Thank you!", "@enjieli @benste  seems like saving the weight and neural network architecture via `model.save` might be a problem.  Not too sure why it happens. \r\n\r\nBut a workaround might be to use `save_weights` to save the weights/checkpoints and `load_weights` to load the weights/checkpoints. \r\nThat being said, to make sure you can do proper inference, you may need to re-use model training steps in your google colab to re-setup the neural network architecture and use 'load_weights'.  ", "@kwanchet thank you so much for your input! "]}, {"number": 43113, "title": "Bump google-cloud-cpp to 1.17.1", "body": "@mihaimaruseac \r\nThank you for my wonderful journey with Google Summer of Code at TensorFlow \ud83c\udf89 \r\n\r\nIn this PR, I bump the `google-cloud-cpp` to `1.17.1` so we can remove `com_github_nlohmann_json_single_header`. \r\n`nlohmann_json` is just a wrapper around `nlohmann_json_lib`.\r\n\r\nI will send some PRs to clean up the code in all 3 filesystems. \r\nI could do the `window` plugin too if you are too busy.\r\nAbout the blogpost, I think we could delay it until all 3 filesystems are moved into `SIG IO`. What do you think ?", "comments": ["Thank you for the contributions.\r\n\r\nFor the blog post, I'll send another notification for review, sorry it gets delayed so long."]}, {"number": 43112, "title": "Basic Queries regarding MobileBERT predictions using TFLite Model Maker", "body": "Hello,\r\n\r\nI trained the pre-trained MobileBERT using TFLite Model Maker for a binary text-classification task. The training and evaluation went fine.\r\n\r\nI have two doubts:\r\n\r\n1) How can the trained model be used to predict the label for a **sample sentence** which is passed as an argument to the model? When we tried the many possible methods to predict the label for a sample sentence, we got errors regarding \"tensors required\". Rather, how can we pass a **list of strings** to the model and **get the labels**? What is the appropriate method?\r\n\r\n2) Also, what are the correct methods to **re-load the saved model** into a new Colab session to perform predictions? \r\n\r\nI would be grateful for any guidance received. Thanks.\r\n", "comments": ["> When we tried the many possible methods to predict the label for a sample sentence, we got errors regarding \"tensors required\". Rather, how can we pass a **list of strings** to the model and **get the labels**? What is the appropriate method?\r\n\r\n@katreparitosh,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and the dataset you are using.\r\n\r\nAlternatively, you can also share the Colab notebook you are running. Thanks!", "@amahendrakar Hello, I will re-frame my query because now I have a better understanding of what I need. \r\n\r\nI basically want to load the saved model into a script and run inference on sample sentences. Therefore, I followed the code provided in the [documentation](https://www.tensorflow.org/lite/guide/inference#load_and_run_a_model_in_python). \r\n\r\nThe line - \"input_data = np.array(np.random.random_sample(input_shape), dtype=np.int32)\" fetches a random sample and later gives prediction in the form of probability. \r\n\r\nMy query is **how can I write a sample sentence** and **pass** it for prediction. Example:  \"What a sunny day\", etc. I was unable to find references where TFLite MobileBERT is used for Text Classification.\r\n\r\nHence, kindly share the correct procedure to do so where I can just change the sentence in the code cell and run sample tests? ", "> My query is **how can I write a sample sentence** and **pass** it for prediction. Example: \"What a sunny day\", etc. I was unable to find references where TFLite MobileBERT is used for Text Classification.\r\n\r\n@katreparitosh,\r\nPlease use the same pre-processing steps you have used during the training, on the sentence you want to pass and then pass it as the input to the model. Please take a look at [this](https://www.tensorflow.org/tutorials/keras/text_classification#prepare_the_dataset_for_training) text classification tutorial which might be useful in this case.\r\n\r\nAlso, this question is better asked on [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow) since it is not a TensorFlow bug or feature request. There is also a larger community that reads questions there. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 43111, "title": "tf .function gives different output than standard function", "body": "No custom code. TF 2.3\r\n\r\nI am trying to make a \"backtest\" differentiable so i decide to use tf.function's auto differentiation capability.\r\n\r\nDespite taking a very long time to compile the function, finally it gets converted into TF ops. However the \"loss\" i get when running a TF version of the function and the python version are completely different.\r\n\r\n```\r\n@tf.function\r\ndef get_loss(h_actions, nh_actions, prices):\r\n    entry_point = 0.0\r\n    exit_point = 0.0\r\n    holding = False\r\n    profit = 0.0\r\n    index = 0\r\n    fee = 0.001\r\n    keep_perc = 1 - fee\r\n    final_index = len(prices) - 1\r\n\r\n    while index < final_index:\r\n        curr_price = prices[index]\r\n\r\n        if holding:\r\n            act_value = h_actions[index]\r\n        else:\r\n            act_value = nh_actions[index]\r\n\r\n        if act_value > 0.5:\r\n            if holding is False:  # BUY\r\n                holding = True\r\n                entry_point = curr_price\r\n\r\n            else:  # SELL\r\n                holding = False\r\n                exit_point = curr_price\r\n                profit += (pow(keep_perc, 2) * exit_point / entry_point) - 1\r\n\r\n        index += 1\r\n    return profit\r\n```\r\n\r\nThe inputs for this function are precomputed predictions and price history is supplied.\r\n\r\nI don't believe the values for these specifically are very important. I was able to produce the same behavior with a dummy set\r\n\r\n```\r\nsamples = np.random.normal(size=(1000, 10))\r\nprices = [random.uniform(1, 1000) for _ in range(1000)]\r\nsamples[:, -1] = 1\r\nholding_preds = model.predict(samples)\r\nsamples[:, -1] = -1\r\nnot_holding_preds = model.predict(samples)\r\n```\r\n\r\nThe only thing i see is that a warning in thrown saying that there's a large unroll loop. Other than that why would i get getting a different output?\r\n", "comments": ["Can you share a dummy, minimal, but runnable model definition to run the dummy set?", "@bhack https://colab.research.google.com/drive/1uy8kr4efsRWB759M9avlpCOsWD3rQMpC#scrollTo=vDXjYZ43tbPI&line=95&uniqifier=1", "Please remove authentication from the colab example.", "My bad. Hopefully this is better https://colab.research.google.com/drive/1uy8kr4efsRWB759M9avlpCOsWD3rQMpC?usp=sharing", "I don't see the warning in the colab. Can you add something to show the wrong behavior?", "The losses don't match up. I added a line to show that they produce different values despite they are same function, one is just converted to TF\r\n\r\nhttps://colab.research.google.com/drive/1uy8kr4efsRWB759M9avlpCOsWD3rQMpC?usp=sharing", "@ben-arnao Your autograph tracing on the control flow over `holding` will not work as you expect: \r\nSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/control_flow.md#all-python-code-paths-are-executed-during-tracing\r\n\r\nSee also autograph tracing limits:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md", "> @ben-arnao Your autograph tracing on the control flow over `holding` will not work as you expect:\r\n> See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/control_flow.md#all-python-code-paths-are-executed-during-tracing\r\n> \r\n> See also autograph tracing limits:\r\n> https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md\r\n\r\nThank you for this. I will look into these and see if there is a way to modify the code.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43111\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43111\">No</a>\n"]}, {"number": 43110, "title": "Add missing initialization of filter_offset in fully connected CMSIS-NN kernel", "body": "Fixes a bug where the filter_offset parameter is uninitialized in the CMSIS-NN kernel. Further explained in #42918 .\r\n\r\nFixes: #42918", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 43109, "title": "Add test to ensure that MicroInterpreter.tensors_size() works.", "body": "This was broken and not caught when switching to TfLiteEvalTensors. This\r\ntest ensures that the API properly reports the size. MicroInterpreter is\r\nthe source of truth for TfLiteContext values - I'm setting this field\r\nhere (it used to be set in MicroAllocator).\r\n\r\nFixes https://github.com/tensorflow/tensorflow/issues/42964", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 43108, "title": "Several visual studio  editions and error of  LLVM requires at least MSVC 2017.", "body": "I want to build tf-2.2.0 with bazel in win10.After some preparations\uff0c I follow cmds like below:\r\n**First:**\r\npython ./configure.py\r\n\r\n.... **everything ok**\r\n\r\n**Then:**\r\nbazel build --config=opt //tensorflow:tensorflow_cc.dll\r\n\r\nI get **some errors:** \r\n D:/softwares/tensorflow-2.2.0/tensorflow/core/framework/BUILD:582:1: C++ compilation of rule '//tensorflow/core/framework:bfloat16' failed (Exit 2)\r\n\r\n\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:                C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\corecrt_wstring.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:              C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\stdexcept\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:               C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\exception\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:                C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\type_traits\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:                 C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\xstddef\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:                  C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cstddef\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:                  C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\initializer_list\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:                C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\malloc.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:                C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\vcruntime_exception.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:                 C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\eh.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:                  C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\corecrt_terminate.h\r\n\r\nexternal/llvm-project/llvm/include\\llvm/Support/Compiler.h(88): fatal error C1189: #error:  LLVM requires at least MSVC 2017.\r\n\r\n**I know** it means that I need at least vs 2017 but I already have vs2019 (vs2019 is set up at D:\\Softwares\\vs2019).\r\n\r\nIt seems that bazel will serach vs in default path, e.g. C:\\Program Files (x86)\\Microsoft Visual Studio 14.0 instead of my costume path. \r\nSo I want to know where to **change** the default visual stuio path that bazel uses with my costume path?\r\n\r\nos : win10\r\nvs: vs2013/vs2015/vs2019\r\nNeed help please.", "comments": ["@github2016-yuan \r\n\r\nCan you please refer this [link](https://docs.bazel.build/versions/master/install-windows.html#bazel-does-not-find-visual-studio-or-visual-c) and see if it helps you. Thanks!", "@ravikyram \r\nThanks for your solution and I do as what you suggest.\r\n**BAZEL_VC:** C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\r\n**BAZEL_VS:** C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\r\n\r\nThen I  bazel build --config=opt //tensorflow:tensorflow_cc.dll again.\r\n\r\nbut I **still** get the same error:\r\nERROR: F:/tf4/as7vs55w/external/llvm-project/llvm/BUILD:399:1: C++ compilation of rule '@llvm-project//llvm:llvm-tblgen' failed (Exit 2)\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:                 C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\vadefs.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:                C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\corecrt.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:                 C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\vcruntime.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:               C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\use_ansi.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:              C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\stddef.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:             C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\cstdlib\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:              C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\stdlib.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:               C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\corecrt_malloc.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:               C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\corecrt_search.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:               C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE\\corecrt_wstdlib.h\r\n\r\nexternal/llvm-project/llvm/include\\llvm/Support/Compiler.h(88): fatal error C1189: #error:  LLVM requires **at least MSVC 2017**.\r\nTarget //tensorflow:tensorflow_cc.dll failed to build\r\nINFO: Elapsed time: 84.207s, Critical Path: 47.55s\r\nINFO: 20 processes: 20 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\nSo how to do please?\r\n\r\n\r\n", "We're not able to provide support for Bazel configuration issues that are not bugs in TF. Please check out [Bazel's Support Page](https://bazel.build/support.html).", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43108\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43108\">No</a>\n", "Finally I solve it and build c++ tf2.2.0-gpu library. Here are my some try:\r\n(1)set  system environment-variable and reboot pc\r\n(2)set up BuildTools for vs2019\r\n(3)delete everything that created by former building\r\n(4)build again \r\n\r\nIn face, I do not know what step solves the issue exactly but luckily it works at last.\r\nNow I get dll,lib and header file."]}, {"number": 43107, "title": "No gradient defined for operation RaggedTensorFromVariant / or no gradients at all", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 2.3.0\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: 10.2\r\n- GPU model and memory: RTX 2070 SUPER, 8Gb\r\n\r\n\r\n**Describe the current behavior**\r\nUsing RaggedTensor I want to minimize KL loss for different segments of a weights matrix (assuming their coefficients drawn from multivariate normal distribution in each segment). RaggedTensors is used inside tf.map_fn. First, I met [issue](https://github.com/tensorflow/tensorflow/issues/42189) \r\nLookupError: gradient registry has no entry for: RaggedTensorFromVariant\r\nI was fixed it with [provided code](https://github.com/tensorflow/tensorflow/issues/42189#issuecomment-673529072)\r\nHowever, optimization is not working. Weights are not updated during training. For simplicity, I want to minimize only trace in covariance matrix, but nothing happens. I think that provided code doesn't allow gradients to pass through.\r\n \r\n**Describe the expected behavior**\r\nI expect trace will be minimized to zero\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nclass DenseCov(tf.keras.layers.Dense):\r\n    def __init__(self, units, segments, **kwargs):\r\n        \r\n        self.segment_ids = tf.keras.backend.constant(segments, dtype=tf.int64, name='segment_ids')\r\n        self.W_ragged = None\r\n        self.embed_dim = None\r\n        super().__init__(units=units, use_bias=False, kernel_initializer=tf.keras.initializers.Ones(), **kwargs)\r\n    \r\n    def call(self, inputs):\r\n        logits = super().call(inputs)\r\n\r\n        # Want to minimize Kullback\u2013Leibler divergence between two multivariate normal distributions\r\n        # But for simplicity minimize only trace\r\n\r\n        W_ragged = tf.RaggedTensor.from_value_rowids(tf.transpose(self.kernel), self.segment_ids, name='init_ragged')\r\n        means = tf.reduce_mean(W_ragged, axis=1, name='means')\r\n        W_centred = W_ragged - tf.expand_dims(means, 1)\r\n        cov_matrix = tf.map_fn(lambda x: tf.matmul(x, x, True) / (tf.cast(tf.shape(x)[0], tf.float32) - 1), W_centred, name='calc_covar')\r\n        cov_matrix = cov_matrix.to_tensor(name='convert_dense')\r\n        \r\n        traces =  tf.map_fn(lambda x: tf.linalg.trace(x), cov_matrix, name='calc_trace')\r\n        # traces = 0.\r\n\r\n        # logdets = tf.map_fn(lambda x: -tf.linalg.logdet(x), cov_matrix, name='calc_logdet')  # disabled for simplicity\r\n        logdets = 0.\r\n\r\n        # loss = traces + logdets + tf.reduce_sum(centroid_means**2, axis=1)  # disabled for simplicity\r\n        loss = traces\r\n\r\n        loss = tf.reduce_mean(loss, name='total_loss')        \r\n        self.add_loss(loss)\r\n        return logits\r\n    \r\n    def build(self, input_shape):\r\n        super().build(input_shape)\r\n\r\n        # Distorted matrix a bit\r\n        W = self.kernel\r\n        W.assign_add(np.random.randn(N_dim, N_class).astype(np.float32))\r\n        \r\n    def get_config(self):\r\n        config = {\r\n            'segments': self.segment_ids.numpy(),\r\n        }\r\n        base_config = super().get_config()\r\n        base_config.update(config)\r\n        return base_config\r\n\r\nN_class, N_domains, N_dim, N_samples = 50000, 1, 10, 100\r\nsegments = np.random.randint(0, N_domains, N_class)\r\nsegments = np.sort(segments)\r\n\r\ndata = np.random.randn(N_samples, N_dim).astype(np.float32)\r\ny_true = np.random.randn(N_samples).astype(np.float32)\r\n\r\ntf.keras.backend.clear_session()\r\nmodel = tf.keras.models.Sequential()\r\nmodel.add(tf.keras.Input(shape=(N_dim,)))\r\nmodel.add(DenseCov(N_class, segments))\r\nmodel.add(tf.keras.layers.Dense(1))\r\n\r\ndef dummy_loss(y_true, y_pred):\r\n    return 0*tf.reduce_sum(y_pred)\r\n\r\nmodel.compile(optimizer=tf.keras.optimizers.Adam(0.1), loss=dummy_loss)\r\n\r\nfrom tensorflow.raw_ops import RaggedTensorToVariant\r\n\r\n@tf.RegisterGradient(\"RaggedTensorFromVariant\")\r\ndef _RaggedTensorFromVariantGrad(*args):\r\n    if len(args) == 2:\r\n        op, grad = args\r\n        res = [RaggedTensorToVariant(rt_nested_splits=[], rt_dense_values=grad,\r\n                                      batched_input=False)]\r\n    else:\r\n        op, empty, grad = args\r\n        res = [RaggedTensorToVariant(rt_nested_splits=[op.outputs[0]], rt_dense_values=grad,\r\n                                    batched_input=True)]\r\n    return res\r\n\r\ninitial_trace = np.trace(np.cov((model.layers[-2].weights[0].numpy())))\r\n\r\nloss = []\r\nfor i in range(10):\r\n    res = model.train_on_batch(data[:10], y_true[:10])\r\n    print(f\"Iter {i}, loss: {res}, delta: {initial_trace-res} \")\r\n```\r\nReturns\r\n```\r\n/home/data/venv/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\r\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\r\n\r\nIter 0, loss: 9.99978256225586, delta: 1.1581866488086234e-07 \r\nIter 1, loss: 9.99978256225586, delta: 1.1581866488086234e-07 \r\nIter 2, loss: 9.99978256225586, delta: 1.1581866488086234e-07 \r\nIter 3, loss: 9.99978256225586, delta: 1.1581866488086234e-07 \r\nIter 4, loss: 9.99978256225586, delta: 1.1581866488086234e-07 \r\nIter 5, loss: 9.99978256225586, delta: 1.1581866488086234e-07 \r\nIter 6, loss: 9.99978256225586, delta: 1.1581866488086234e-07 \r\nIter 7, loss: 9.99978256225586, delta: 1.1581866488086234e-07 \r\nIter 8, loss: 9.99978256225586, delta: 1.1581866488086234e-07 \r\nIter 9, loss: 9.99978256225586, delta: 1.1581866488086234e-07 \r\n\r\n```", "comments": ["Was able to reproduce the issue with TF v2.3 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/133fb56d1e1c9cc631a8d21d08fa3dec/43107-tf-nightly.ipynb). Thanks!", "@cataclysmus I think that you can experiment to remove `loss=dummy_loss` from compile as it is not mandatory as you can see in:\r\nhttps://www.tensorflow.org/guide/keras/custom_layers_and_models\r\n\r\n> It's also possible not to pass any loss in `compile`,\r\nsince the model already has a loss to minimize, via the `add_loss`\r\ncall during the forward pass!\r\n \r\n\r\nThen you will see:\r\n```\r\nValueError: No gradients provided for any variable: ['dense_cov/kernel:0', 'dense/kernel:0', 'dense/bias:0'].\r\n```\r\nI think that you could try to solve this cause there is any \"flow\" connection between your `loss` and your `logits`.", "> @cataclysmus I think that you can experiment to remove `loss=dummy_loss` from compile as it is not mandatory as you can see in:\r\n> https://www.tensorflow.org/guide/keras/custom_layers_and_models\r\n> \r\n> > It's also possible not to pass any loss in `compile`,\r\n> > since the model already has a loss to minimize, via the `add_loss`\r\n> > call during the forward pass!\r\n> \r\n> Then you will see:\r\n> \r\n> ```\r\n> ValueError: No gradients provided for any variable: ['dense_cov/kernel:0', 'dense/kernel:0', 'dense/bias:0'].\r\n> ```\r\n> \r\n> I think that you could try to solve this cause there is any \"flow\" connection between your `loss` and your `logits`.\r\n\r\nYou should not remove `loss=dummy_loss` because of `ValueError: No gradients provided for any variable` . Imagine this construction to be used as a regularizer of some big matrix in a classification problem. So for the real task `dummy_loss ` will be replaced with crossentropy. Here, I wanted to demonstrate that gradients are zeros, if `map_fn` is used together with `RaggedTensor`. I have already checked this fact with `tf.GradientTape` and printing gradient values.  Just replace \r\n`loss = traces`\r\nwith\r\n`loss = tf.reduce_sum(means**2, axis=1)`\r\nand you will see, that matrix becomes to change and gradients are not zeros.\r\n        ", " >  So for the real task dummy_loss will be replaced with crossentropy.\r\n\r\nYes of course, but don't think it is your dummy case right?  Also cause `loss = tf.reduce_sum(means**2, axis=1)` and others works fine.\r\n\r\nHave you tried `tf.map_fn` with something different from `RaggedTensor`?\r\n\r\n", "Same code, no `RaggedTensor`. It works\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nclass DenseCov(tf.keras.layers.Dense):\r\n    def __init__(self, units, segments, **kwargs):\r\n        \r\n        self.segment_ids = tf.keras.backend.constant(segments, dtype=tf.int64, name='segment_ids')\r\n        self.W_ragged = None\r\n        self.embed_dim = None\r\n        super().__init__(units=units, use_bias=False, kernel_initializer=tf.keras.initializers.Ones(), **kwargs)\r\n    \r\n    def call(self, inputs):\r\n        logits = super().call(inputs)\r\n\r\n        # Want to minimize Kullback\u2013Leibler divergence between two multivariate normal distributions\r\n        # But for simplicity minimize only trace\r\n\r\n#         W_ragged = tf.RaggedTensor.from_value_rowids(tf.transpose(self.kernel), self.segment_ids, name='init_ragged')\r\n        W_ragged = tf.transpose(self.kernel)\r\n        W_ragged = tf.expand_dims(W_ragged, 0)\r\n\r\n        means = tf.reduce_mean(W_ragged, axis=1, name='means')\r\n        W_centred = W_ragged - tf.expand_dims(means, 1)\r\n        cov_matrix = tf.map_fn(lambda x: tf.matmul(x, x, True) / (tf.cast(tf.shape(x)[0], tf.float32) - 1),\r\n                               W_centred, name='calc_covar')\r\n#         cov_matrix = cov_matrix.to_tensor(name='convert_dense')\r\n        \r\n        traces =  tf.map_fn(lambda x: tf.linalg.trace(x), cov_matrix, name='calc_trace')\r\n        # traces = 0.\r\n\r\n        # logdets = tf.map_fn(lambda x: -tf.linalg.logdet(x), cov_matrix, name='calc_logdet')  # disabled for simplicity\r\n        logdets = 0.\r\n\r\n        # loss = traces + logdets + tf.reduce_sum(centroid_means**2, axis=1)  # disabled for simplicity\r\n        loss = traces\r\n\r\n        loss = tf.reduce_mean(loss, name='total_loss')        \r\n        self.add_loss(loss)\r\n        return logits\r\n    \r\n    def build(self, input_shape):\r\n        super().build(input_shape)\r\n\r\n        # Distorted matrix a bit\r\n        W = self.kernel\r\n        W.assign_add(np.random.randn(N_dim, N_class).astype(np.float32))\r\n        \r\n    def get_config(self):\r\n        config = {\r\n            'segments': self.segment_ids.numpy(),\r\n        }\r\n        base_config = super().get_config()\r\n        base_config.update(config)\r\n        return base_config\r\n\r\nN_class, N_domains, N_dim, N_samples = 500, 1, 10, 100\r\nsegments = np.random.randint(0, N_domains, N_class)\r\nsegments = np.sort(segments)\r\n\r\ndata = np.random.randn(N_samples, N_dim).astype(np.float32)\r\ny_true = np.random.randn(N_samples).astype(np.float32)\r\n\r\ntf.keras.backend.clear_session()\r\nmodel = tf.keras.models.Sequential()\r\nmodel.add(tf.keras.Input(shape=(N_dim,)))\r\nmodel.add(DenseCov(N_class, segments))\r\nmodel.add(tf.keras.layers.Dense(1))\r\n\r\ndef dummy_loss(y_true, y_pred):\r\n    return 0*tf.reduce_sum(y_pred)\r\n\r\nmodel.compile(optimizer=tf.keras.optimizers.Adam(0.1), loss=dummy_loss)\r\n\r\n\r\ninitial_trace = np.trace(np.cov((model.layers[-2].weights[0].numpy())))\r\n\r\nloss = []\r\nfor i in range(10):\r\n    res = model.train_on_batch(data[:10], y_true[:10])\r\n    print(f\"Iter {i}, loss: {res}, delta: {initial_trace-res} \")\r\n```\r\nOutput:\r\n```\r\nIter 0, loss: 10.365920066833496, delta: 6.145684974256937e-07 \r\nIter 1, loss: 8.83370590209961, delta: 1.5322147793023841 \r\nIter 2, loss: 7.489259243011475, delta: 2.876661438390519 \r\nIter 3, loss: 6.322910308837891, delta: 4.043010372564103 \r\nIter 4, loss: 5.31702995300293, delta: 5.048890728399064 \r\nIter 5, loss: 4.454628944396973, delta: 5.911291737005021 \r\nIter 6, loss: 3.721179485321045, delta: 6.644741196080949 \r\nIter 7, loss: 3.102418899536133, delta: 7.263501781865861 \r\nIter 8, loss: 2.583615779876709, delta: 7.7823049015252845 \r\nIter 9, loss: 2.150526285171509, delta: 8.215394396230485\r\n```", "/cc @edloper Can you take a look at this?", "Thank you for helping me. I simplified code for the debugging\r\n\r\n```\r\nfrom tensorflow.raw_ops import RaggedTensorToVariant\r\n@tf.RegisterGradient(\"RaggedTensorFromVariant\")\r\ndef _RaggedTensorFromVariantGrad(*args):\r\n\r\n    op, empty, grad = args\r\n    res = RaggedTensorToVariant(rt_nested_splits=[op.outputs[0]], rt_dense_values=grad,\r\n                                batched_input=True)\r\n    return res\r\n\r\nx = tf.constant([[1., 2.], \r\n               [3., 4.],\r\n               [-1., 2.], \r\n               [3., -4.]\r\n            ], dtype=tf.float32)\r\n\r\nwith tf.GradientTape(persistent=True) as g:\r\n    g.watch(x)\r\n    W_ragged = tf.RaggedTensor.from_value_rowids(x, [0, 0 , 1, 1], name='init_ragged')\r\n    y = tf.reduce_mean(W_ragged, axis=1)\r\ndy_dx = g.gradient(y, W_ragged.values)\r\nprint(\"Gradient means\")\r\nprint(dy_dx)\r\n\r\n\r\nwith tf.GradientTape(persistent=True) as g:\r\n    g.watch(x)\r\n    W_ragged = tf.RaggedTensor.from_value_rowids(x, [0, 0 , 1, 1], name='init_ragged')\r\n    y = tf.map_fn(lambda x: tf.matmul(x, x, True) / (tf.cast(tf.shape(x)[0], tf.float32) - 1),\r\n                               W_ragged, name='calc_covar')\r\n\r\ndy_dx = g.gradient(y.values, W_ragged.values)\r\nprint(\"\\nGradient Covar\")\r\nprint(dy_dx)\r\n```\r\nOutputs:\r\n```\r\nGradient means\r\ntf.Tensor(\r\n[[0.5 0.5]\r\n [0.5 0.5]\r\n [0.5 0.5]\r\n [0.5 0.5]], shape=(4, 2), dtype=float32)\r\n\r\nGradient Covar\r\nNone\r\n```", "I have similar issue. Any workaround for this? I used `tf.map_fn` for RaggedTensor during calculating loss, and error `gradient registry has no entry for: RaggedTensorFromVariant` occured in backprop using GradientTape.", "We are working on a fix for this; hopefully it should go out in the nightly builds sometime next week.", "I've just hit this same wall. I am using `tf.map_fn` for RaggedTensor in my custom layers and custom loss (inherited from `keras.layers.Layer` and `keras.losses.Loss` respectively) and get the error:\r\n`LookupError: gradient registry has no entry for: RaggedTensorFromVariant` (while using `with tf.GradientTape`)\r\nor\r\n` LookupError: No gradient defined for operation 'CrossEntropy_RT/map/while/RaggedFromVariant_1/RaggedTensorFromVariant' (op type: RaggedTensorFromVariant)` (while using `model.fit()`).\r\n\r\nI look forward to the fix.", "Fixed in be6b1fdb0699d4000b70ad32cc23d1503e5c7511.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43107\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43107\">No</a>\n"]}]