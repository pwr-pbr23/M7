[{"number": 40343, "title": "timeseries_dataset_from_array wrong target output value", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 19.10 \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.3.0-dev20200609 - nightly-gpu\r\n- Python version:Python 3.7.5\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: 10.0/7\r\n- GPU model and memory: GeForce RTX 2060 8GB\r\n\r\n**Describe the current behavior**\r\nThe output target (or y) start first with record of data (or sliding window), not with sequence_length+1 item \r\n**Describe the expected behavior**\r\nTarget (or y) should start from sequence_length+1\r\n**Standalone code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.preprocessing import timeseries_dataset_from_array\r\nimport numpy as np\r\ntf.__version__\r\n\r\nseries = np.arange(1, 100)\r\nprint(series)\r\ntest_ds = timeseries_dataset_from_array(\r\n        series, series, sequence_length=90, batch_size=1, shuffle=False, seed=7, sequence_stride=1, sampling_rate=1\r\n    )\r\ninputs, targets = tf.data.experimental.get_single_element(test_ds.take(1))\r\nprint(inputs.numpy())\r\nprint(targets.numpy())\r\n\r\n\"\"\"\r\noutput:\r\ninputs [[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\r\n  25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\r\n  49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\r\n  73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90]]\r\n**targets [1]**\r\n\"\"\"\r\nI was expecting target to start from 91. \r\nIs the expected behaviour to start from 1 or it should continue from end of \"sliding window\"?\r\n\r\nI changed the targets series as np.roll(series, -90) and remove last record of dataset and output looks ok. \r\n\r\nseries = np.arange(1, 100)\r\n#print(series)\r\nprint(np.roll(series, -90))\r\ntest_ds = timeseries_dataset_from_array(\r\n        series, np.roll(series, -90), sequence_length=90, batch_size=1, shuffle=False, seed=7, sequence_stride=1, sampling_rate=1\r\n    )\r\ninputs, targets = tf.data.experimental.get_single_element(test_ds.take(1))\r\nprint(\"inputs\", inputs.numpy())\r\nprint(\"targets\", targets.numpy())\r\n\r\n\"\"\"\r\ninputs [[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\r\n  25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\r\n  49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\r\n  73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90]]\r\n**targets [91]**\r\n\"\"\"\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Was able to reproduce the issue with TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/e68478b18059375d40442e6d2ac70207/40343.ipynb). Thanks!", "The second usage with `np.roll` is correct. This is also added in the documentation of [timeseries_dataset_from_array](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/timeseries_dataset_from_array).\r\nSee example 2 in the doc. Thanks!", "ok, will use roll/shift when I need it."]}, {"number": 40342, "title": "Cannot resume training using model.save and load_model()", "body": "**System Information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes\r\n\r\n- OS Platform and Distribution:\r\nCentOS Linux 7.6.1810\r\n\r\n- TensorFlow installed from : \r\nbinary (pip)\r\n\r\n- TensorFlow version :\r\n2.2.0-rc3\r\n\r\n- Python version:\r\n3.6.4\r\n\r\n- CUDA/cuDNN version:\r\nCUDA 10.1 / cuDNN 7.6.0\r\n\r\n- GPU model and memory:\r\n2 x TitanX - 12GB\r\n\r\n**Describe the current behavior**\r\nI am using Tensorflow 2.2.0 on multi-gpu system. Having the need to train large networks for several days, I save the model weights with optimizer state using ```model.save()```. When I reload the model using ```tf.keras.models.load_model()```, the loss spikes sharply on TensorBoard and the accuracy also shows a sudden drop. Though the loss recovers within the epoch, it does not comply with the intended behavior of saving training state using ```model.save()```.\r\n\r\n**Describe the expected behavior**\r\nThe API should be able to save and resume training from the very same point after loading a model from '.h5' file.\r\n\r\n**Standalone code to reproduce the issue**\r\nThis code is a minimal reproducible example. It was tested on multi-gpu systems with 8 gpus. The re-run of the script is achieved by deleting the current model and distribute strategy and re-initializing them to simulate stop and restart of training process.\r\n```\r\nimport os\r\nimport glob\r\nimport numpy as np\r\nimport tensorflow as tf\r\ntf.__version__\r\n\r\ngpus = tf.config.experimental.list_logical_devices('GPU')\r\nprint(gpus)\r\n\r\nRESULT_DIR = os.path.join(os.getcwd(), 'Test', 'Results')\r\nCHECKPOINT_FREQUENCY = 16\r\nLOG_EVERY = 1\r\n\r\nBATCH_SIZE_PER_GPU = 16\r\nNUM_GPUS = len(gpus)\r\nGLOBAL_BATCH_SIZE = BATCH_SIZE_PER_GPU * NUM_GPUS\r\n\r\ndef get_model():\r\n    \r\n    model = tf.keras.Sequential([\r\n        tf.keras.layers.Conv2D(filters=32, strides=1, kernel_size=(4,4), input_shape=(28,28,1)),\r\n        tf.keras.layers.Activation('relu'),\r\n        tf.keras.layers.BatchNormalization(),\r\n        tf.keras.layers.Flatten(),\r\n        tf.keras.layers.Dense(10)\r\n    ])\r\n    \r\n    return model\r\n\r\nclass SparseCategoricalLoss(tf.keras.losses.Loss):\r\n    \r\n    def __init__(self, num_classes, name='SparseCategoricalLoss', from_logits=False, loss_weight=1.0, *args, **kwargs):\r\n        \r\n        super().__init__(*args, **kwargs)\r\n        self.num_classes = num_classes\r\n        self.name = name\r\n        self.from_logits=from_logits\r\n        self.loss_weight = loss_weight\r\n        \r\n    def loss_fn(self, y_true, y_pred):\r\n        label = y_true[:,0:self.num_classes]\r\n        logit = y_pred[:,0:self.num_classes]\r\n        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=self.from_logits,\r\n                                                             name=self.name,\r\n                                                             reduction=tf.keras.losses.Reduction.NONE)(label, logit)\r\n        loss *= self.loss_weight\r\n        return loss\r\n    \r\n    \r\n    def call(self, y_true, y_pred):\r\n        total_loss = self.loss_fn(y_true, y_pred)\r\n        return total_loss\r\n\r\n    def get_config(self):\r\n         \r\n        config = super().get_config().copy()\r\n        config.update({\r\n            'num_classes' : self.num_classes,\r\n            'name' : self.name,\r\n            'loss_weight' : self.loss_weight\r\n        })\r\n        return config\r\n\r\nloss = SparseCategoricalLoss(num_classes=10,\r\n                             from_logits=True,\r\n                             name='categorical_loss')\r\n\r\nstrategy = tf.distribute.MirroredStrategy()\r\n\r\nwith strategy.scope():\r\n    \r\n    model = get_model()\r\n    \r\n    optimizer = tf.keras.optimizers.RMSprop(\r\n                                            learning_rate=0.001,\r\n                                            epsilon=1.0,\r\n                                            momentum=0.9,\r\n                                            rho=0.9\r\n                                           )\r\n    \r\n    model.compile(optimizer=optimizer, loss=loss, metrics=['acc'])\r\n\r\n(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.mnist.load_data()\r\nX_train = np.expand_dims(X_train, 3)\r\nX_test = np.expand_dims(X_test, 3)\r\n\r\nclass LoggingCallback(tf.keras.callbacks.Callback):\r\n\r\n    def __init__(self, result_dir, log_every, initial_step=0, checkpoint_frequency=None, **kwargs):\r\n        \r\n        super().__init__(**kwargs)\r\n        \r\n        # Create result directory\r\n        self.result_dir = result_dir\r\n        if not os.path.exists(result_dir):\r\n            os.makedirs(result_dir)\r\n        \r\n        # create checkpoint directory\r\n        checkpoint_dir = os.path.join(self.result_dir, 'checkpoint')\r\n        if not os.path.exists(checkpoint_dir):\r\n            os.makedirs(checkpoint_dir)\r\n        \r\n        # create tensorboard directory\r\n        tensorboard_dir = os.path.join(self.result_dir, 'tensorboard')\r\n        if not os.path.join(tensorboard_dir):\r\n            os.makedirs(tensorboard_dir)\r\n        \r\n        self.log_every = log_every\r\n        self.checkpoint_frequency = checkpoint_frequency\r\n        self.train_writer = tf.summary.create_file_writer( os.path.join(tensorboard_dir, 'train') )\r\n        self.step = initial_step\r\n        \r\n        \r\n    # Write metrics to TensorBoard    \r\n    def write_metrics_tensorboard(self, logs):\r\n        with self.train_writer.as_default():\r\n            for name, value in logs.items():\r\n                if name in ['batch', 'size']:\r\n                    continue\r\n                tf.summary.scalar(name, value, step=self.step)\r\n                \r\n                \r\n    def on_batch_end(self, batch, logs=None):\r\n        \r\n        self.step += 1\r\n        \r\n        # Write metrics to tensorboard\r\n        if self.step % self.log_every == 0:\r\n            self.write_metrics_tensorboard(logs)\r\n            \r\n        # Save model checkpoint (weights + optimizer state)\r\n        if self.checkpoint_frequency and self.step % self.checkpoint_frequency == 0:\r\n            name = 'model_step_%d.h5' % self.step\r\n            path = os.path.join(self.result_dir, 'checkpoint', name)\r\n            self.model.save( path )\r\n\r\ncallbacks = LoggingCallback(result_dir=RESULT_DIR, log_every=LOG_EVERY, checkpoint_frequency=CHECKPOINT_FREQUENCY)\r\n\r\nmodel.fit(\r\n          x = X_train, \r\n          y = Y_train, \r\n          batch_size=GLOBAL_BATCH_SIZE,\r\n          epochs=7,\r\n          validation_data = (X_test, Y_test),\r\n          callbacks=callbacks,\r\n          verbose=1 \r\n         )\r\n\r\ndel model\r\ndel strategy\r\n\r\nprevious_checkpoints = glob.glob(os.path.join(RESULT_DIR, 'checkpoint', '*'))\r\nprevious_checkpoints.sort(key=lambda x : int(os.path.basename(x).split('_')[2].replace('.h5', '')) )\r\nlatest_checkpoint = previous_checkpoints[-1]\r\nprint('Found Latest Checkpoint : %s' % latest_checkpoint)\r\n    \r\ninitial_step = int(os.path.basename(latest_checkpoint).split('_')[2].replace('.h5', ''))\r\nprint('Resuming training from step %d' % initial_step)\r\n    \r\nnew_callback = LoggingCallback(result_dir=RESULT_DIR, log_every=LOG_EVERY, initial_step=initial_step, checkpoint_frequency=CHECKPOINT_FREQUENCY)\r\n\r\nstrategy = tf.distribute.MirroredStrategy()\r\nwith strategy.scope():\r\n    model = tf.keras.models.load_model( latest_checkpoint, custom_objects={'SparseCategoricalLoss':SparseCategoricalLoss} )\r\n\r\nmodel.fit(\r\n          x = X_train, \r\n          y = Y_train, \r\n          batch_size=GLOBAL_BATCH_SIZE,\r\n          epochs=10,\r\n          validation_data = (X_test, Y_test),\r\n          callbacks=new_callback,\r\n          verbose=1 \r\n         )\r\n\r\n```\r\n\r\nHere is a link to colab showing the output : https://colab.research.google.com/gist/suraj-maniyar/1a305d7249baee4393147cb479ea2933/restart_training.ipynb\r\n\r\n\r\n\r\n**Other info / logs** \r\n\r\nThe TensorBoard entry looks like this : \r\n![tensorboard](https://user-images.githubusercontent.com/16310456/84227046-66de4f00-aab1-11ea-86eb-9bcb6de2aa8d.PNG)\r\n\r\n\r\nThis was a toy example using mnist. After about 26k steps, when the training was restarted, the loss spiked up indicating that the last saved checkpoint did not save the training configuration correctly.\r\nI am training an InceptionResNet network for several days and the spike in the loss is very concerning when I restart the training (shown below).\r\n![tensorboard_inception](https://user-images.githubusercontent.com/16310456/84227678-04864e00-aab3-11ea-940d-85748d4823ec.PNG)\r\n\r\n", "comments": ["If you are using `model.save` in TF 2.x the format defaults to \"tf\" and not \"h5\". Is there a reason you are saving to a .h5 file?\r\n\r\nadding @rchao to take a look at this issue. \r\n\r\ntf.keras [provides](https://www.tensorflow.org/tutorials/distribute/keras#define_the_callbacks) the ModelCheckpoint callback and TensorBoard callback which you can also use when training on multiple GPUs.", "@anj-s \r\nI missed that part. I ran the code again, this time saving it correctly in \".h5\" format and the problem still persists. Please find the gist here : https://colab.research.google.com/gist/suraj-maniyar/0bba4b18118c9db2fcc110989250098c/restart_training_h5.ipynb\r\n\r\nThe ModelCheckpoint callback assumes the initial step to be 0 which will not always be the case if I stop and restart training. Same argument applies to TensorBoard callback. I need the flexibility to update tensorboard and save checkpoint at any random step while maintaining the current training progress. ", "Curious if you see the same spike in loss if you just use a standard loss function. Wondering if this related to the custom objects load somehow.", "@suraj-maniyar Can you try using the \"tf\" format instead? see [tutorial](https://www.tensorflow.org/tutorials/distribute/save_and_load#overview) for saving/loading when using tf.distribute strategy.\r\nThe error might still persist but it will be good to save/load in the supported format so that we can narrow down root cause.", "> Curious if you see the same spike in loss if you just use a standard loss function. Wondering if this related to the custom objects load somehow.\r\n\r\n@nikitamaia \r\nThe spike does not occur when I use standard loss function with mnist data probably because mnist is an easy dataset to learn. \r\n(See gist [here](https://colab.research.google.com/gist/suraj-maniyar/9aea2729c8df407d45a4438916517e06/copy-of-restart_training_h5_standard_loss.ipynb)) \r\n\r\nBut when I used the standard loss on InceptionResNet, the spike was significant (see below):\r\n![loss_spike_large_network](https://user-images.githubusercontent.com/16310456/84319793-97b89580-ab3e-11ea-9bb3-436198f63548.PNG)\r\n", "> @suraj-maniyar Can you try using the \"tf\" format instead? see [tutorial](https://www.tensorflow.org/tutorials/distribute/save_and_load#overview) for saving/loading when using tf.distribute strategy.\r\n> The error might still persist but it will be good to save/load in the supported format so that we can narrow down root cause.\r\n\r\n@anj-s The [documentation](https://www.tensorflow.org/tutorials/distribute/save_and_load#the_keras_apis) says that model.save has to be called outside of strategy.scope().\r\nSince I am calling it via a callback, it will get called within the scope (correct me if I am wrong here). So is there a way to save model from a callback when using tf.distribute.strategy? Is that the reason I am getting the spike in loss?", "@anj-s \r\nI tried saving the model using \"tf\" format and  the problem still persists.\r\nSee gist [here](https://colab.research.google.com/gist/suraj-maniyar/048b5697090e7ffc1bf09ca14fb8da01/copy-of-restart_training_tf_save.ipynb). \r\nAny work-around for this issue?", "@suraj-maniyar question for you - if you do `model.fit()`, then save, and load immediately, does the loaded model retain the weight that was just saved? ", "@rchao Yes the weights are same when I load the model right after ```model.fit()``` and ```model.save()```.\r\nBut the training after loading the weights still shows the spike in loss and gets worse from there on. ([gist](https://colab.research.google.com/gist/suraj-maniyar/a7c4b8009bc71f951204eb40018706ab/copy-of-restart_training_tf_save_v2.ipynb))   ", "So to be clear, if you save and load, the weights are the same, but if you continue training, the loaded model would have incorrect loss and accuracy from the original model you saved from?", "Yes. Precisely.", "@rchao Any updates?", "@nikitamaia @anj-s @rchao \r\nAre there any updates on this issue?", "Sorry for the late response - but based on the information here I wasn't able to tell where went wrong. Will reply here if we have any updates.", "Could it be the batch normalization losing history of the momentum?\r\nTry without the batchnorm layer and see if you still see the spikes.", "@w4nderlust \r\nI still see the problem even after removing batch normalization ([gist](https://colab.research.google.com/gist/suraj-maniyar/e3bd058be7efafc1c3a34456d3b85ebd/copy-of-restart_training_tf_save_v2.ipynb)).", "> @w4nderlust\r\n> I still see the problem even after removing batch normalization ([gist](https://colab.research.google.com/gist/suraj-maniyar/e3bd058be7efafc1c3a34456d3b85ebd/copy-of-restart_training_tf_save_v2.ipynb)).\r\n\r\nIf batch norm is not the problem, it could be that this problem is related to this issue I opened yesterday: https://github.com/tensorflow/tensorflow/issues/41053\r\nIn that case, my problem is that after resuming a stateful optimizer in a custom training loop (by means of pickling and unpickling) the learning curves differ.\r\nIn my case, if I use a stateless optimizer, like SGD, I see no problem, the problems only appear when using a stateful optimizer like Adam.\r\nMaybe, just to confirm if that is the problem, you could test your code using SGD instead of RMSProp. If you don't see the problem, then it's likely that the issue is with the resume logic of the optimizer.", "@w4nderlust \r\nI still see the issue with SGD optimizer ([gist](https://colab.research.google.com/gist/suraj-maniyar/71092e331e37d66fd92ecfcf027bc77c/copy-of-test1.ipynb)). \r\nI had tried something similar to what you mentioned in your issue i.e. save and load optimizer state separately as pickle object, but I was still seeing the spike in loss.\r\nI wonder if ```tf.distribute.Strategy``` has a different logic to save and reload model and causing the optimizer to reset.", "@suraj-maniyar apologies for the delay here. In your experience, does this issue show up even when not using any distribution strategy? I tried one of your [gists](https://colab.research.google.com/gist/suraj-maniyar/048b5697090e7ffc1bf09ca14fb8da01/copy-of-restart_training_tf_save.ipynb) and changed it from using MirroredStrategy to the [default strategy](https://www.tensorflow.org/guide/distributed_training#default_strategy) - using default strategy is equivalent to not using any distribution strategy. And I see the same effect on loss. \r\n\r\nIf this is the case, then perhaps this is a more general issue and not specific to dist strat, and Keras team maybe in best position to help debug. My best guess would be something weird is going on with saving/loading the custom loss object. @pavithrasv maybe able to help look, as I don't have much experience with saving/loading these custom objects in keras. \r\n\r\n\r\n", "Yes this issue is persistent even without any distribution strategy. Here's my [gist](https://colab.research.google.com/gist/suraj-maniyar/4539773fdaa9a3a8ab6be0de5a745e1b/resume_train_no_dist_strat.ipynb) if you need to look @guptapriya @pavithrasv ", "Thanks for confirming @suraj-maniyar. We will ask the folks who are expert in Keras to take a look. ", "Same issue here as well. Tried TF2.0 and 2.2 - same thing. Quite basic scenario:\r\n1. Train model for x epoch\r\n2. Save model as json and weights separately\r\n3. Restart process to resume training:\r\n    - load model from json\r\n    - load weights\r\n    - model.fit()\r\nExpected the 'loss' to be close the last best saved value (monitor = 'loss'). Instead, model starts training like weights were not loaded at all. Strategy does not affect the result.\r\n\r\nNote. When all of the above steps are run sequentially in a process(without restart - step #3) model will continue training as expected.", "I had the same problem than suraj-maniyar on a custom training with custom loss. I'm using a stateful optimizer as well but without any distribution strategy. I found a satisfying solution here : https://stackoverflow.com/questions/49503748/save-and-load-model-optimizer-state. \r\n\r\nThe problem was to resume the optimizer state, which was possible without compiling the model, this solution works with Adam could be adapted to other optimizer I guess.\r\n\r\nHope this helps.", "@Lapiquettejack \r\nI have tried that and it didn't work for me.", "Hi @suraj-maniyar, based on your last [gist](https://colab.sandbox.google.com/gist/suraj-maniyar/4539773fdaa9a3a8ab6be0de5a745e1b/resume_train_no_dist_strat.ipynb) link, I've tried to add `model.compile(optimizer=optimizer, loss=loss, metrics=['acc'])` right after the model is loaded via `tf.keras.models.load_model`. The training accuracy of the loaded model is improved a lot compared to that in your gist. \r\n\r\nUnfortunately, the Tensorboard was not launched successfully on my end. Could you try the same to see how the Tensorboard metrics looks like?", "Echo with a similar issue https://github.com/keras-team/keras/issues/14231", "Same issue here:\r\n1. trained model in TF==2.2.0. Saved in SavedModel format, and JSON and .h5. \r\n2. from new session, load model and continue/resume training. Out of the box, the accuracy starts from 0 and loss is high. ", "> Could it be the batch normalization losing history of the momentum?\r\n> Try without the batchnorm layer and see if you still see the spikes.\r\n\r\nSame issue! I found it is batchnorm momentum causing the problem, as you suggested. Checkpoints were not saving my optimiser (Adam) attributes, so I exported these separately. However, I am not sure how to access the batchnorm layer attributes. Any suggestions would be extremely helpful ;)", "Still happens in 2.6.0. I read elsewhere this happens with distributed strategies. Optimizer weights are not saved in the savedmodel, and so are not loaded when restarting from the savedmodel. Nowhere is the tf docs does it warn about this. I don't mind if it's the case, but at least update the docs and give a workaround, this has been an issue for 2+ years.\r\n\r\nMy workaround steps are:\r\n\r\n1. save two checkpoints during training, one h5 model checkpoint, one weights only checkpoint\r\n2. when resuming, load the model from the h5, then model.load_weights() from the weights only checkpoint\r\n3. model.save(\"path\", include_optimizer=False) after training to create a savedmodel for inference\r\n\r\nYou can print the model.optimizer.weights after this. If you try to load a savedmodel saved during distributed training you cannot print model.optimizer.weights because they don't exist. And if you try to load a weights checkpoint into a loaded savedmodel, it will say the optimizer weights are unused.", "Hi There,\n\n This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! \n\n Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40342\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40342\">No</a>\n"]}, {"number": 40341, "title": "How could I know my data is distributed in the right way?", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n\r\nI am pretraining BERT in 1 machine with 4 GPU.\r\n\r\nThe input function code:\r\n```\r\n   def input_fn(params):\r\n        batch_size = FLAGS.train_batch_size\r\n\r\n        name_to_features = {\r\n            \"input_ids\":\r\n                tf.FixedLenFeature([max_seq_length], tf.int64),\r\n            \"input_mask\":\r\n                tf.FixedLenFeature([max_seq_length], tf.int64),\r\n            \"segment_ids\":\r\n                tf.FixedLenFeature([max_seq_length], tf.int64),\r\n            \"masked_lm_positions\":\r\n                tf.FixedLenFeature([max_predictions_per_seq], tf.int64),\r\n            \"masked_lm_ids\":\r\n                tf.FixedLenFeature([max_predictions_per_seq], tf.int64),\r\n            \"masked_lm_weights\":\r\n                tf.FixedLenFeature([max_predictions_per_seq], tf.float32),\r\n            \"next_sentence_labels\":\r\n                tf.FixedLenFeature([1], tf.int64),\r\n        }\r\n\r\n        if is_training:\r\n            d = tf.data.Dataset.from_tensor_slices(tf.constant(input_files))\r\n            d = d.repeat()\r\n            d = d.shuffle(buffer_size=len(input_files))\r\n\r\n            cycle_length = min(num_cpu_threads, len(input_files))\r\n\r\n            d = d.apply(\r\n                tf.contrib.data.parallel_interleave(\r\n                    tf.data.TFRecordDataset,\r\n                    sloppy=is_training,\r\n                    cycle_length=cycle_length))\r\n            d = d.shuffle(buffer_size=100)\r\n        else:\r\n            d = tf.data.TFRecordDataset(input_files)\r\n            d = d.repeat()\r\n\r\n        d = d.apply(\r\n            tf.contrib.data.map_and_batch(\r\n                lambda record: _decode_record(record, name_to_features),\r\n                batch_size=batch_size,\r\n                num_parallel_batches=num_cpu_threads,\r\n                drop_remainder=True))\r\n        d = d.prefetch(10)\r\n        return d\r\n```\r\nThe mirrow strategy code:\r\n```\r\n    distribution = tf.contrib.distribute.MirroredStrategy(\r\n        devices=[\"device:GPU:%d\" % i for i in range(FLAGS.n_gpus)],\r\n        cross_tower_ops=tf.distribute.HierarchicalCopyAllReduce())\r\n\r\n    run_config = RunConfig(\r\n        train_distribute=distribution,\r\n        log_step_count_steps=log_every_n_steps,\r\n        model_dir=FLAGS.output_dir,\r\n        save_checkpoints_steps=FLAGS.save_checkpoints_steps)\r\n\r\n    model_fn = model_fn_builder(\r\n        bert_config=bert_config,\r\n        init_checkpoint=FLAGS.init_checkpoint,\r\n        learning_rate=FLAGS.learning_rate,\r\n        num_train_steps=FLAGS.num_train_steps,\r\n        num_warmup_steps=FLAGS.num_warmup_steps,\r\n        use_tpu=FLAGS.use_tpu,\r\n        use_one_hot_embeddings=FLAGS.use_tpu)\r\n\r\n    estimator = Estimator(\r\n        model_fn=model_fn,\r\n        params={},\r\n        config=run_config)\r\n\r\n```\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux \r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.15\r\n- Python version: 3.6\r\n- GPU model and memory: 22G\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nI am pretraining BERT in 1 machine with 4 GPU. \r\n\r\nThe problem is that I have 4 GPU. Each GPU could run 8 batchsize at most. \r\n\r\nI set `train_batch_size = 8` not 32. Is OK but I don't know each GPU get different data in one training step.\r\n\r\nIf I set `train_batch_size = 32`, it will out of memory (OOM).\r\n\r\nIs my code right now? Will the data be distributed to 4 GPU and each GPU get different data?\r\n\r\n**Describe the expected behavior**\r\n\r\nI read the some doc that said `train_batch_size` could be 32.\r\n\r\nThank you very much.\r\n", "comments": ["Hi @guotong1988 clarifying what your question is. Your model is training successfully with train_batch_size=8, but you are wondering if it is in fact distributing training across all 4 of your GPUs. Is that what you are asking?\r\n\r\nAdditionally, which doc are you referring to with a batch size of 32? \r\nIf you are getting an OOM error at that size, it sounds like a batch size of 8 is the largest you can fit on your GPU (maybe you could try 16?). As explained [here in the docs](https://www.tensorflow.org/guide/distributed_training#using_tfdistributestrategy_with_estimator_limited_support) with Estimators the dataset returned by your input_fn should provide the per replica batch size. The global batch size for a step can be obtained by PER_REPLICA_BATCH_SIZE * strategy.num_replicas_in_sync. So if you have 4 replicas, it would be 8 * 4 = 32.\r\n\r\n\r\n", "Yes, I am wondering if it is in fact distributing training across all 4 of my GPUs. ", "Can you share the training output? Or share an example with data that I can reproduce?", "Thank you!\r\nRaw data: https://github.com/guotong1988/BERT-multi-gpu/blob/master/sample_text.txt\r\nProcessed Data: https://github.com/guotong1988/BERT-multi-gpu/tree/master/tmp_data\r\n(You'd better process the raw data yourself)\r\n\r\nSimilar Code: https://github.com/guotong1988/BERT-multi-gpu/blob/master/run_pretraining_gpu_v2.py", "Can you also share what the training logs looks like on your end?", "![image](https://user-images.githubusercontent.com/4702353/84335181-e01b9600-abc6-11ea-82da-ccad5a62a96d.png)\r\n\r\nNote that the loss is 4x than 1 GPU setting. \r\n1 GPU setting start about 10.5 loss. 4 GPU setting start about 42 loss.\r\nIt is also a wondering whether it is right.", "Can you also add the INFO that prints before the first training step?", "[log.txt](https://github.com/tensorflow/tensorflow/files/4762187/log.txt)\r\nNote that this line is printed 4 times:\r\n```\r\nINFO:tensorflow:**** Trainable Variables ****\r\n```", "Hi @guotong1988, based on your code and the logs you shared it looks reasonable to me. You can see TF identifying 4 GPUs (devices 0,1,2,3) and the INFO \"Initializing RunConfig with distribution strategies.\"\r\n\r\nI would however suggest you look through the warnings in the logs, as several of the functions you are using are deprecated. Also note that Estimator support for MirroredStrategy is limited\r\n\r\nI'm closing this issue now since it is not a bug, and Stack Overflow is probably a better place to post these support questions. Thanks!", "https://stackoverflow.com/questions/62124961/tensorflow1-15-multi-gpu-1-machine-how-to-set-batch-size", "https://stackoverflow.com/questions/62316736/tensorflow1-15-the-inner-logic-of-estimators-input-fn-or-the-inner-logic-of-m"]}, {"number": 40340, "title": "Problem while adding a custom metric", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):  tf-nightly-gpu 2.3.0.dev20200609\r\n- Python version: 3.7.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.1/7\r\n- GPU model and memory: \r\n\r\n**Describe the current behavior**\r\nError when adding a custom metric.\r\n\r\n**Describe the expected behavior**\r\nShould accept a custom metric.\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nfrom tensorflow.keras import layers, Model\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import backend as K\r\nimport numpy as np\r\n\r\n\r\ndef custom_mse(y_true, y_pred):\r\n    # calculating squared difference between target and predicted values\r\n    loss = K.square(y_pred - y_true)  # (batch_size, 2)\r\n\r\n    # summing both loss values along batch dimension\r\n    loss = K.sum(loss, axis=1)  # (batch_size,)\r\n    loss = K.mean(loss, axis=-1)\r\n    return loss\r\n\r\nnp.random.seed(1)\r\nx_train = np.random.random((10,2))\r\ny1_train = np.random.random((10,1))\r\ny2_train = np.random.random((10,3))\r\n\r\ninput1 = keras.Input(shape=(2))\r\n\r\n# Build the network graph\r\na1 = layers.Dense(5)(input1)\r\na2 = layers.Dense(3)(a1)\r\na3 = layers.Dense(1)(a2)\r\n\r\n# Building Keras model\r\nmyModel = Model([input1], [a3, a2])\r\n\r\n# Creating custom loss\r\nmyCustomLoss = custom_mse(a1[:,0], a3)\r\n\r\n# Adding custom loss to the model\r\nmyModel.add_loss(myCustomLoss)\r\n\r\n# Compiling model with differente weights for the losses from the output\r\nmyModel.compile(optimizer='Adam',\r\n                loss=['mse','mse'],\r\n                loss_weights=[10.0, 5.0]\r\n                )\r\n\r\n# Creating a metric based on the myCustomLoss\r\nmyModel.add_metric(myCustomLoss, name='myMetric')\r\n\r\n# Fit the model\r\nmyModel.fit(x=[x_train],\r\n            y=[y1_train, y2_train],\r\n                epochs=5,\r\n                batch_size=5,\r\n                shuffle=True,\r\n                )\r\n```\r\nhttps://colab.research.google.com/drive/1RyuvG5l70MNG9wxEDw4biiyA_dG3sJBe?usp=sharing\r\n\r\n\r\n**Other info / logs** \r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-3-71ee0bb4652c> in <module>()\r\n     42 \r\n     43 # Creating a metric based on the myCustomLoss\r\n---> 44 myModel.add_metric(myCustomLoss, name='myMetric')\r\n     45 \r\n     46 # Fit the model\r\n\r\n3 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in add_metric(self, value, name, **kwargs)\r\n   1686       # Insert layers into the Keras Graph Network.\r\n   1687       aggregation = None if from_metric_obj else 'mean'\r\n-> 1688       self._graph_network_add_metric(value, aggregation, name)\r\n   1689 \r\n   1690   @deprecation.deprecated_args(None, '`inputs` is now automatically inferred',\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py in _graph_network_add_metric(self, value, aggregation, name)\r\n    794     new_nodes.extend(add_metric_layer.inbound_nodes)\r\n    795     new_layers.append(add_metric_layer)\r\n--> 796     self._insert_layers(new_layers, new_nodes)\r\n    797 \r\n    798   @property\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py in _insert_layers(self, layers, relevant_nodes)\r\n    728 \r\n    729     # Insert layers and update other layer attrs.\r\n--> 730     layer_set = set(self._layers)\r\n    731     deferred_layers = []\r\n    732     for layer in layers:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/data_structures.py in __hash__(self)\r\n    607     # List wrappers need to compare like regular lists, and so like regular\r\n    608     # lists they don't belong in hash tables.\r\n--> 609     raise TypeError(\"unhashable type: 'ListWrapper'\")\r\n    610 \r\n    611   def insert(self, index, obj):\r\n\r\nTypeError: unhashable type: 'ListWrapper'\r\n```\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40340\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40340\">No</a>\n"]}, {"number": 40339, "title": "Error in the tpu.ipynb notebook", "body": "I'm trying to implement the code in this notebook https://github.com/tensorflow/docs/blob/master/site/en/guide/tpu.ipynb\r\n\r\nThe lines for updating the training loss and accuracy are incorrect:\r\n```python\r\ntraining_loss.update_state(loss * strategy.num_replicas_in_sync)\r\ntraining_accuracy.update_state(labels, logits)\r\n```\r\nI don't understand the intent behind updating the loss with the product of the number of replicas and the batch loss but it gives the wrong result. Changing the line to\r\n```python\r\ntraining_loss.update_state(labels, logits)\r\n```\r\nappears to solve the bug.\r\n\r\nI also changed the definition of `training_loss` from a `metrics.Mean` to a `metrics.SparseCategoricalCrossentropy`. ", "comments": ["@rxsang can you confirm if this code is correct, and either fix or add a couple of comments explaining?\r\n\r\nThanks.", "Hi bjourne@,\r\n\r\nThanks for the feedbacks. Pasting all the code related to loss calculating in the current guide.\r\n\r\n```\r\nwith tf.GradientTape() as tape:\r\n    loss = tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\r\n    loss = tf.nn.compute_average_loss(loss, global_batch_size=batch_size)\r\ngrads = tape.gradient(loss, model.trainable_variables)\r\noptimizer.apply_gradients(list(zip(grads, model.trainable_variables)))\r\ntraining_loss.update_state(loss * strategy.num_replicas_in_sync)\r\n```\r\n\r\nThe reason is when working with DistributionStrategy, you first\r\n1. compute the loss\r\n2. calculate the gradients per replica\r\n3. aggregate the gradients across all the replicas\r\n\r\nThe reason is in 3#, the aggregation is the sum of all replicas. So if your loss is a mean loss, the gradients will be `num_replicas_in_sync` larger than expected. That's why we scale the loss by `num_replicas_in_sync` in 2#. However for the reported loss, we don't want to see the scaled loss, thus we multiply `num_replicas_in_sync` back.\r\n\r\nThe way you suggest will also work, but it will compute `SparseCategoricalCrossentropy` twice. Given calculating this metric should be cheap, I can change it to this one if this is clearer.\r\n\r\nDoes that make sense to you?", "Thanks for your response. Two things I don't understand. Why isn't the training accuracy calculated in the same way? Shouldn't it also suffer from the same kind of scaling issues? And when I write it the way you suggest, I get losses in the range 400 to 600. So I think there must be a bug there? Does it matter that my model does not use logits? ", "@bjourne Can you please share a simple standalone code to reproduce your issue? Thanks!\r\n\r\nIf this was already resolved, then please close the issue. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40338, "title": "Support fused batchnorm with any ndims and axis", "body": "- Modifies the BatchNormalizationBase layer to support fused=True with any number of dimensions and any (single) axis by adding reshape operations around the calls to nn.fused_batch_norm (which itself only supports NCHW and NHWC tensors).\r\n- Fixes tests to account for the broader support and adds a new test for a 3D convnet.\r\n- Use of fused=True is particularly important for mixed-precision training.\r\n\r\ncc @reedwm @nluehr ", "comments": ["@benbarsdell Can you please check @reedwm's comments and keep us posted. Thanks!", "I managed to root-cause the `layer_correctness_test` failure. There appears to be a bug [here](https://github.com/tensorflow/tensorflow/blob/9c7ddffd970e8e72585c66c4a2c7cf8bb42ed608/tensorflow/core/kernels/redux_functor.h#L60) (also [here](https://github.com/tensorflow/tensorflow/blob/9c7ddffd970e8e72585c66c4a2c7cf8bb42ed608/tensorflow/core/kernels/redux_functor.h#L229)) where the input is interpreted as `OutputT` instead of `InputT`.\r\nI'm not sure how to add a tensor typecast there, but just removing that piece of code does fix the problem.\r\n\r\nLet me know how you want to deal with it.", "> I managed to root-cause the `layer_correctness_test` failure. There appears to be a bug [here](https://github.com/tensorflow/tensorflow/blob/9c7ddffd970e8e72585c66c4a2c7cf8bb42ed608/tensorflow/core/kernels/redux_functor.h#L60) (also [here](https://github.com/tensorflow/tensorflow/blob/9c7ddffd970e8e72585c66c4a2c7cf8bb42ed608/tensorflow/core/kernels/redux_functor.h#L229)) where the input is interpreted as `OutputT` instead of `InputT`.\r\n> I'm not sure how to add a tensor typecast there, but just removing that piece of code does fix the problem.\r\n> \r\n> Let me know how you want to deal with it.\r\n\r\nCan you create a new PR to fix it? [This line](https://github.com/tensorflow/tensorflow/blob/9c7ddffd970e8e72585c66c4a2c7cf8bb42ed608/tensorflow/core/kernels/redux_functor.h#L195) has an example of how to cast. If this is trickier than I'm imagining and you don't want to deal with this, I can also get someone internally to fix it.", "> > I managed to root-cause the `layer_correctness_test` failure. There appears to be a bug [here](https://github.com/tensorflow/tensorflow/blob/9c7ddffd970e8e72585c66c4a2c7cf8bb42ed608/tensorflow/core/kernels/redux_functor.h#L60) (also [here](https://github.com/tensorflow/tensorflow/blob/9c7ddffd970e8e72585c66c4a2c7cf8bb42ed608/tensorflow/core/kernels/redux_functor.h#L229)) where the input is interpreted as `OutputT` instead of `InputT`.\r\n> > I'm not sure how to add a tensor typecast there, but just removing that piece of code does fix the problem.\r\n> > Let me know how you want to deal with it.\r\n> \r\n> Can you create a new PR to fix it? [This line](https://github.com/tensorflow/tensorflow/blob/9c7ddffd970e8e72585c66c4a2c7cf8bb42ed608/tensorflow/core/kernels/redux_functor.h#L195) has an example of how to cast. If this is trickier than I'm imagining and you don't want to deal with this, I can also get someone internally to fix it.\r\n\r\nThanks, I tried that but unfortunately only Eigen tensors have a `cast` method; the TF Tensor type does not. At this stage it's probably easier for someone internal to fix it, unless there's some other very easy fix that I haven't identified.", "@benbarsdell Can you please check @reedwm's comments and keep us posted. Thanks!", "Regarding Bessel's correction at inference time but not training time, it seems that the original batchnorm paper indicated doing it this way; there is some discussion here (evidently it is the same way in PyTorch):\r\nhttps://github.com/pytorch/pytorch/issues/1410\r\nhttps://stats.stackexchange.com/questions/311074/batch-normalization-variance-calculation\r\n\r\nIt sounds like you are going to take care of the remaining items internally @reedwm. If I've misinterpreted that or you need me to do anything else just let me know.", "Yes I will take care of using Bessel's correction for the nonfused implementation internally. Then we can merge this PR.", "@reedwm Any update on this PR? Please. Thanks!", "@reedwm Any update on this PR? Please. Thanks!", "@benbarsdell  Can you please resolve conflicts? Thanks!", "@benbarsdell Can you please resolve conflicts? Thanks!", "It turns out that the reshapes added by this PR prevent the grappler layout optimizer from optimizing out all the NCHW<->NHWC transposes.\r\n\r\nFor this reason I think we will have to abandon this PR and use https://github.com/tensorflow/tensorflow/pull/42970 instead."]}, {"number": 40337, "title": "Op not registered 'LSTMBlockCell' in binary running on..", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.13.1\r\n- Python version: 3.6.7\r\n- Installed using virtualenv? pip? conda?: virtualenv\r\n- Bazel version (if compiling from source): 0.20.0\r\n- GCC/Compiler version (if compiling from source): MSVC 2019\r\n- CUDA/cuDNN version: none\r\n- GPU model and memory: none\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nI exported a .pb model from python. I managed to import this model into Tensorflow C++, but receive the following error message when I add the graph to my session:\r\n\r\n\"Not found: Op type not registered 'LSTMBlockCell' in binary running on MYDESKTOP. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\r\nPress any key to continue . . .\"\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n#include \"stdafx.h\"\r\n#include <stdio.h>\r\n\r\n#include \"tensorflow/core/public/session.h\"\r\n#include \"tensorflow/core/platform/env.h\"\r\n\r\nusing namespace tensorflow;\r\n\r\nint main(int argc, char* argv[]) {\r\n  // Initialize a tensorflow session\r\n  Session* session;\r\n  Status status = NewSession(SessionOptions(), &session);\r\n  if (!status.ok()) {\r\n    std::cout << status.ToString() << \"\\n\";\r\n    return 1;\r\n  }\r\n\r\n  GraphDef graph_def;\r\n  status = ReadBinaryProto(Env::Default(), \"C:\\\\Users\\\\workaccount\\\\Documents\\\\werk\\\\hexachord\\\\pycharm\\\\magenta\\\\frozen_test.pb\", &graph_def);\r\n  if (status.ok()) {\r\n    std::cout << status.ToString() << \"\\n\";\r\n  }\r\n\r\n  // Add the graph to the session\r\n  status = session->Create(graph_def);\r\n  if (!status.ok()) {\r\n    std::cout << status.ToString() << \"\\n\";\r\n\tsystem(\"pause\");\r\n  }\r\n}\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n\r\nthank you kindly for your response", "comments": ["@JesseBerdowski Is this issue resolved?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing this issue as it has been inactive for more than 2 weeks. Please add additional comments for us to open this issue again. Thanks!"]}, {"number": 40336, "title": "Eager Function Inputs cannot be Keras Symbolic Tensors error when using Intermediate layers in custom loss function", "body": "I am using Colab with TF 2.2.\r\n\r\n**Current behavior**\r\n```\r\nInputs to eager execution function cannot be Keras symbolic tensors,\r\n but found [<tf.Tensor 'dense_3_1/Identity:0' shape=(100, 2) dtype=float32>\r\n, <tf.Tensor 'dense_2_1/Identity:0' shape=(100, 2) dtype=float32>]\r\n```\r\n**Expected behavior**\r\nModel trains successfully\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n1. Just copy the code from [here](https://github.com/keras-team/keras/blob/keras-2/examples/variational_autoencoder.py) to a colab cell,\r\n2. Change keras to tensorflow.keras (using just keras works).\r\n3. Code works with tf.config.experimental_run_functions_eagerly, but the problem is that it is very slow and sometimes causes OOM.\r\n", "comments": ["@Ehsan1997,\r\nPlease take a look at [this solution](https://github.com/tensorflow/tensorflow/issues/39702#issuecomment-631750377) from a similar issue and let us know if it works. Thanks!", "@amahendrakar  Below is the updated code, but the problem remains the same.\r\n\r\n```\r\n'''This script demonstrates how to build a variational autoencoder with Keras.\r\nReference: \"Auto-Encoding Variational Bayes\" https://arxiv.org/abs/1312.6114\r\n'''\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nfrom scipy.stats import norm\r\n\r\nfrom tensorflow.keras.layers import Input, Dense, Lambda\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras import backend as K\r\nfrom tensorflow.keras import metrics\r\nfrom tensorflow.keras.datasets import mnist\r\nfrom tensorflow.keras.losses import Loss\r\n\r\nbatch_size = 100\r\noriginal_dim = 784\r\nlatent_dim = 2\r\nintermediate_dim = 256\r\nepochs = 50\r\nepsilon_std = 1.0\r\n\r\nx = Input(batch_shape=(batch_size, original_dim))\r\nh = Dense(intermediate_dim, activation='relu')(x)\r\nz_mean = Dense(latent_dim)(h)\r\nz_log_var = Dense(latent_dim)(h)\r\n\r\n\r\ndef sampling(args):\r\n    z_mean, z_log_var = args\r\n    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.,\r\n                              stddev=epsilon_std)\r\n    return z_mean + K.exp(z_log_var / 2) * epsilon\r\n\r\n# note that \"output_shape\" isn't necessary with the TensorFlow backend\r\nz = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\r\n\r\n# we instantiate these layers separately so as to reuse them later\r\ndecoder_h = Dense(intermediate_dim, activation='relu')\r\ndecoder_mean = Dense(original_dim, activation='sigmoid')\r\nh_decoded = decoder_h(z)\r\nx_decoded_mean = decoder_mean(h_decoded)\r\n\r\nclass VAE_Loss(Loss):\r\n  def call(self, x, x_decoded_mean):\r\n    xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\r\n    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\r\n    return xent_loss + kl_loss\r\n\r\nvae = Model(x, x_decoded_mean)\r\nvae.compile(optimizer='rmsprop', loss=VAE_Loss())\r\n\r\n# train the VAE on MNIST digits\r\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n\r\nx_train = x_train.astype('float32') / 255.\r\nx_test = x_test.astype('float32') / 255.\r\nx_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\r\nx_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\r\n\r\nvae.fit(x_train, x_train,\r\n        shuffle=True,\r\n        epochs=epochs,\r\n        batch_size=batch_size,\r\n        validation_data=(x_test, x_test))\r\n\r\n# build a model to project inputs on the latent space\r\nencoder = Model(x, z_mean)\r\n\r\n# display a 2D plot of the digit classes in the latent space\r\nx_test_encoded = encoder.predict(x_test, batch_size=batch_size)\r\nplt.figure(figsize=(6, 6))\r\nplt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\r\nplt.colorbar()\r\nplt.show()\r\n\r\n# build a digit generator that can sample from the learned distribution\r\ndecoder_input = Input(shape=(latent_dim,))\r\n_h_decoded = decoder_h(decoder_input)\r\n_x_decoded_mean = decoder_mean(_h_decoded)\r\ngenerator = Model(decoder_input, _x_decoded_mean)\r\n\r\n# display a 2D manifold of the digits\r\nn = 15  # figure with 15x15 digits\r\ndigit_size = 28\r\nfigure = np.zeros((digit_size * n, digit_size * n))\r\n# linearly spaced coordinates on the unit square were transformed through the inverse CDF (ppf) of the Gaussian\r\n# to produce values of the latent variables z, since the prior of the latent space is Gaussian\r\ngrid_x = norm.ppf(np.linspace(0.05, 0.95, n))\r\ngrid_y = norm.ppf(np.linspace(0.05, 0.95, n))\r\n\r\nfor i, yi in enumerate(grid_x):\r\n    for j, xi in enumerate(grid_y):\r\n        z_sample = np.array([[xi, yi]])\r\n        x_decoded = generator.predict(z_sample)\r\n        digit = x_decoded[0].reshape(digit_size, digit_size)\r\n        figure[i * digit_size: (i + 1) * digit_size,\r\n               j * digit_size: (j + 1) * digit_size] = digit\r\n\r\nplt.figure(figsize=(10, 10))\r\nplt.imshow(figure, cmap='Greys_r')\r\nplt.show()\r\n```", "Was able to reproduce the issue with [TF v2.2](https://colab.research.google.com/gist/amahendrakar/364f4b37d81a98b445bcae9061526193/40336.ipynb#scrollTo=Fe55PvC_VMGx) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/6762524676176dca9d3204a1e4f87ee1/40336-tf-nightly.ipynb). Please find the attached gist. Thanks!", "@Ehsan1997 Can you please check this [tutorial](https://keras.io/examples/variational_autoencoder/) which is similar to your problem. Please let us know if you notice any issues. Thanks!", "@jvishnuvardhan Thanks for your reply, but the tutorial you pointed to uses the same input as the output, which is not what I want.\r\nI want some X (different from Y) to predict the Y.\r\nSecondly what I don't understand is that why is this code running correctly for old keras but not for the latest tf2?", "@Ehsan1997 In your code, you are using same `x_train` for X and Y. Check the `model.fit` function below.\r\n`vae.fit(x_train, x_train, shuffle=True,epochs=epochs, batch_size=batch_size, validation_data=(x_test, x_test))\r\n`\r\nRegarding why `tf.keas` was not working when `keras` was working with the same code, in `tf.keras` model.fit runs in graph model by default. However, some ops in the custom loss function expects eager Tensors while Graph Tensors are provided. You can use `run_eagerly=True` to run without any issue (may take little more time). \r\n\r\n`vae.compile(optimizer='rmsprop', loss=VAE_Loss(),run_eagerly=True)`\r\n\r\nPlease check the following [guide](https://www.tensorflow.org/guide/keras/train_and_evaluate) on defining custom_loss class. Thanks!", "@jvishnuvardhan Thanks for the reply.\r\n\r\nSorry for the confusion, but this code is the simplified version of what I am doing, I want a different image at output as to the one I am inputting.\r\n\r\nRun eagerly option really affects the performance, I have already mentioned about this in the opening post of this issue. I tried using the sub-class method for defining the loss, the problem still persists. \r\n\r\nIs there any way to make only a portion of the code run eagerly, so that other code runs fast?", "Is this still an issue?\r\nCould you please update TensorFlow to the latest stable version v.2.6 and let us know if you are facing the same error. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40336\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40336\">No</a>\n"]}, {"number": 40335, "title": "Remove cudnn RNN algo APIs from cudnn 8 inc file", "body": "Remove references to some cudnn APIs that were deprecated in cudnn 7 and will be removed in the final cudnn 8 release.\r\n\r\nattn: @reedwm ", "comments": []}, {"number": 40334, "title": "fix doc bug in extract patches", "body": "changed `ksizes` -> `sizes` in `tf.image.extract_patches` and updated the docs to reflect the current API.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40334) for more info**.\n\n<!-- need_sender_cla -->", "@andrewnc Thank you for your contribution. Can you please sign CLA? Thanks!", "It looks like this was already changed in nightly. I'm also not sure how to link my Google account to my GitHub", "You need to make your google email as the primary email on GitHub. Then you need to amend the commits to change user email to the Google one.\r\n\r\nAlternatively, you can sign CLA on your personal email too. That's what I did.", "Ah! Ok, I signed the CLA on my personal email. That makes sense. Thank you. ", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40334) for more info**.\n\n<!-- ok -->", "Oh. This is on r2.2 branch. We need it on master and then we can cherry-pick and wait for a patch release (triggered for security reasons only)", "Is there a straightforward way to get it on master, aside from branching from master and making the changes again?", "The following should work, I think (if you're starting from your fork's `extract_patches_doc` branch)\r\n\r\n```\r\ngit checkout master\r\ngit pull --rebase\r\ngit checkout -\r\ngit rebase -\r\ngit push -u\r\n```\r\n\r\nAnd then clicking the Edit button on top and changing the branch to `master` instead of `r2.2`", "Closing since change is already in master https://github.com/tensorflow/tensorflow/blob/4f6e48e9fd6fd8d536a96d78a6e6006e4ac0074c/tensorflow/python/ops/array_ops.py#L5389-L5393"]}, {"number": 40333, "title": "Extract patches doc update", "body": "Fix outdate documentation and documentation bug in `extract_patches` in `tf.image`", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40333) for more info**.\n\n<!-- need_sender_cla -->"]}, {"number": 40332, "title": "gradient descent and performance issues with Tf 2.1 ", "body": "I am using the latest builds of tensorflow and tensorflow probability respectively with the following code\r\n\r\n```\r\nx = x.astype(np.float64)#tf.dtypes.cast(x, tf.int32) #\r\n#x = tf.cast(x, tf.float32)\r\n#x = tensor_util.convert_nonref_to_tensor(x, dtype=x.dtype)\r\n\r\nclass RBFKernelFn(tf.keras.layers.Layer):\r\n  def __init__(self, **kwargs):\r\n    super(RBFKernelFn, self).__init__(**kwargs)\r\n    dtype = kwargs.get('dtype', None)\r\n    self.amplitude = tfp.util.TransformedVariable(\r\n      1., tfb.Softplus(), dtype=dtype, name='amplitude')\r\n    self.length_scale = tfp.util.TransformedVariable(\r\n      1., tfb.Softplus(), dtype=dtype, name='length_scale')\r\n    \r\n    \r\n  def call(self, x):\r\n    # Never called -- this is just a layer so it can hold variables\r\n    # in a way Keras understands.\r\n    #print(dtype)\r\n    return x\r\n\r\n  @property\r\n  def kernel(self):\r\n\r\n    \r\n    return tfk.ExponentiatedQuadratic(\r\n      amplitude=self.amplitude,\r\n      length_scale=self.length_scale)\r\n    observation_noise_variance = tfp.util.TransformedVariable(\r\n      1., tfb.Softplus(), dtype=dtype, name='observation_noise_variance')\r\n\r\ndtype = np.float64\r\namplitude = tfp.util.TransformedVariable(\r\n      1., tfb.Softplus(), dtype=dtype, name='amplitude')\r\nlength_scale = tfp.util.TransformedVariable(\r\n      1., tfb.Softplus(), dtype=dtype, name='length_scale')\r\nkernel = tfk.ExponentiatedQuadratic(\r\n      amplitude=amplitude,\r\n      length_scale=length_scale)\r\nobservation_noise_variance = tfp.util.TransformedVariable(\r\n      1., tfb.Softplus(), dtype=dtype, name='observation_noise_variance')\r\n```\r\n\r\nand this is the code for the neural network itself\r\n'\r\n```\r\nx_tst = x[189::]\r\nx_range = 237\r\nnum_distributions_over_Functions = 1\r\ntf.keras.backend.set_floatx('float64')\r\n#kernel = Brownian #tfp.positive_semidefinite_kernels.ExponentiatedQuadratic#MaternOneHalf()\r\n\r\nmodel = tf.keras.Sequential([\r\n    tf.keras.Input(shape=(1,14), dtype=np.float64),\r\n    tf.keras.layers.LSTM(25,kernel_initializer='ones',activation='tanh', dtype = x.dtype, use_bias=True),\r\n    #tf.keras.layers.InputLayer(input_shape=(10),dtype=x.dtype),#put a 1 before the 9 later\r\n    tf.keras.layers.Dense(50,kernel_initializer='ones', use_bias=False),\r\n    tf.keras.layers.BatchNormalization(),\r\n    tf.keras.layers.Dense(75,kernel_initializer='ones', use_bias=False),\r\n    tf.keras.layers.BatchNormalization(),\r\n    tf.keras.layers.Dense(100,kernel_initializer='ones', use_bias=False),\r\n    tf.keras.layers.BatchNormalization(),\r\n    tf.keras.layers.Dense(125,kernel_initializer='ones', use_bias=False),\r\n    tf.keras.layers.BatchNormalization(),\r\n    tf.keras.layers.Dense(150,kernel_initializer='ones',use_bias=False),\r\n    tf.keras.layers.BatchNormalization(),\r\n    tf.keras.layers.Dense(175,kernel_initializer='ones',use_bias=False),\r\n    tf.keras.layers.BatchNormalization(),\r\n    tf.keras.layers.Dense(200,kernel_initializer='ones',use_bias=False),\r\n    tf.keras.layers.BatchNormalization(),\r\n    tf.keras.layers.Dense(225,kernel_initializer='ones',use_bias=False),\r\n    tf.keras.layers.BatchNormalization(),\r\n    tf.keras.layers.Dense(250,kernel_initializer='ones',use_bias=False),\r\n    tf.keras.layers.BatchNormalization(),\r\n    tf.keras.layers.Dense(225,kernel_initializer='ones',use_bias=False),\r\n    tf.keras.layers.BatchNormalization(),\r\n    tf.keras.layers.Dense(200,kernel_initializer='ones',use_bias=False),\r\n    #goal is to eventually replace the first dense layer with an LSTM layer\r\n    #tf.keras.layers.LSTM\r\n    #tf.keras.layers.TimeDistributed(Dense(vocabulary)))\r\n    tf.keras.layers.BatchNormalization(),\r\n    tf.keras.layers.Dense(150,kernel_initializer='ones',use_bias=False),\r\n    tf.keras.layers.BatchNormalization(),\r\n    tf.keras.layers.Dense(125,kernel_initializer='ones', use_bias=False),\r\n    tf.keras.layers.BatchNormalization(),\r\n    tf.keras.layers.Dense(100,kernel_initializer='ones',use_bias=False),\r\n    tf.keras.layers.BatchNormalization(),\r\n    tf.keras.layers.Dense(75,kernel_initializer='ones', use_bias=False),\r\n    tf.keras.layers.BatchNormalization(),\r\n    tf.keras.layers.Dense(50,kernel_initializer='ones',use_bias=False),\r\n    tf.keras.layers.BatchNormalization(),\r\n    tf.keras.layers.Dense(25, kernel_initializer='ones',use_bias=False,),\r\n    tfp.layers.VariationalGaussianProcess(\r\n    num_inducing_points=num_inducing_points, kernel_provider=RBFKernelFn(dtype=x.dtype) , event_shape=(1,),\r\n    inducing_index_points_initializer=tf.compat.v1.constant_initializer(\r\n            np.linspace(0,x_range, num=1125,\r\n                        dtype=x.dtype)[..., np.newaxis]), unconstrained_observation_noise_variance_initializer=(tf.compat.v1.constant_initializer(np.log(np.expm1(1.)).astype(x.dtype))),variational_inducing_observations_scale_initializer=(tf.compat.v1.constant_initializer(np.log(np.expm1(1.)).astype(np.float64))), mean_fn=None,\r\n    jitter=1e-06, convert_to_tensor_fn=tfp.distributions.Distribution.sample)\r\n\r\n\r\n])\r\n```\r\n\r\nI am getting the following warnings which seem to be impacting my performance further. Before the upgrade I could get near 0 loss with 270 epochs. Now it has stopped improving altogether after a few hundred epochs and gets permanently stuck at 34.\r\n\r\n", "comments": ["@lordfiftyfive \r\nI ran the above code but face a different error, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/da44bbf73dd5df5eff55dec0b48d3b21/untitled.ipynb).\r\nPlease share code with all dependencies or share a colab gist for us to analyse the issue faced.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40332\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40332\">No</a>\n"]}, {"number": 40331, "title": "ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type list).", "body": "Im getting this valueError in colab gpu env with keras tensorflow ver 2.\r\nValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type list). on running the following code :\r\n # ---- CTC ----\r\n    # y_input layers (transcription data) for CTC loss\r\n\r\nlabels = Input(name='the_labels', shape=[None], dtype=dtype)       # transcription data (batch_size * y_seq_size)\r\ninput_length = Input(name='input_length', shape=X_train_length.shape, dtype=dtype)  # unpadded len of all x_sequences in batch\r\nlabel_length = Input(name='label_length', shape=label_length.shape, dtype=dtype)  # unpadded len of all y_sequences in batch\r\n\r\n\r\n# Lambda layer with ctc_loss function due to Keras not supporting CTC layers\r\nloss_out = Lambda(function=ctc_lambda_func, name='ctc', output_shape=(1,))([y_pred, np.float32, Y_train, np.float32, X_train_length, np.float32, label_length, np.float32])\r\nnetwork_model = Model(inputs=[input_data, labels, input_length, label_length], outputs=y_pred)\r\n\r\nPFA the screenshot for reference.\r\n![code](https://user-images.githubusercontent.com/17008416/84185974-6e035e00-aaad-11ea-9959-c22d7e7b4624.png)\r\n\r\n\r\n\r\n\r\n", "comments": ["@neenaloysius \r\n\r\nRequest you to share colab link or simple standalone code with supporting files to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40331\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40331\">No</a>\n"]}, {"number": 40330, "title": "[TF 2.3.0] [Intel MKL]  CPU Feature Guard MKL brand needs to change to oneDNN", "body": "CPU Feature Guard MKL brand needs to change to oneDNN", "comments": []}, {"number": 40329, "title": "[ROCm] Implementing reduction for complex64 and complex128", "body": "This PR implements reduction for complex64 and complex128 on ROCm by casting the tensors to hipFloatComplex and hipDoubleComplex respectively.", "comments": ["@ekuznetsov139 Can you please resolve conflicts? Thanks!", "Rasmus, would you have time to review this PR? I think you might be able to provide better feedback than me. Thank you!", "@ekuznetsov139 Can you please check @rmlarsen's comments and resolve conflicts?. Thanks!", "@ekuznetsov139 gentle ping", "@ekuznetsov139  Any update on this PR? Please. Thanks!", "@gbaned waiting for response from @rmlarsen.", "@rmlarsen, Any update on this PR? Please. Thanks!", "@rmlarsen, Any update on this PR? Please. Thanks!"]}, {"number": 40328, "title": "Subclassed model with ConvLSTM2D layer can't be saved as a SavedModel in TF2.2 ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): custom code, extended an example from TF guides \r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04/Mac OS 10.15\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.1 and 2.2\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.1 \r\n- GPU model and memory: 1080Ti 11Gb\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nAs a header states the model build with Subclassing API with ConvLSTM2D layer inside can't be saved as a SavedModel. Given that keras (.h5) model format doesn't support saving subclassed models I am left with no option to save the model architecture to file.\r\n\r\nThe issues appears in TF2.2 while there seems to be no bug in earlier version 2.1 \r\n\r\n**Describe the expected behavior**\r\n\r\nThe code is to work without issues in both TF2.2 and TF2.1\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nhttps://colab.research.google.com/drive/1zfhnbz_dHfPloT9mzk0ei5F4aFaZGgnt?usp=sharing\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras.layers import ConvLSTM2D, Bidirectional, LSTM\r\n\r\nclass CustomModel(keras.Model):\r\n  def __init__(self, hidden_units):\r\n    super(CustomModel, self).__init__()\r\n    self.lstm = Bidirectional(ConvLSTM2D(filters=16, kernel_size=(1, 1), return_sequences=True, return_state=True))\r\n    self.dense_layers = [keras.layers.Dense(u) for u in hidden_units]\r\n\r\n  def call(self, inputs, training=None, mask=None):\r\n    x = inputs\r\n    x, _, _, _, _ = self.lstm(x)\r\n    for layer in self.dense_layers:\r\n      x = layer(x)\r\n    return x\r\n\r\nmodel = CustomModel([16, 16, 10])\r\n# Build the model by calling it\r\ninput_arr = tf.random.uniform((1, 10, 10, 10, 5))\r\noutputs=model.predict(input_arr)\r\nmodel.save('my_model')\r\n\r\n# Delete the custom-defined model class to ensure that the loader does not have\r\n# access to it.\r\ndel CustomModel\r\n\r\nloaded = keras.models.load_model('my_model')\r\n```\r\n\r\nSimilar issue discussed on stackoverflow\r\nhttps://stackoverflow.com/questions/61362953/keras-convlstm2d-valueerror-when-saving-model", "comments": ["Was able to reproduce the issue with [TF v2.2](https://colab.research.google.com/gist/amahendrakar/2da837292cbfa01854fa77f2d2791d15/40328.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/6dbb8421ea8815a3c1a41110969c7d6a/40328-tf-nightly.ipynb#scrollTo=S8MN8xgvnjdw). Works without any issues with [TF v2.1](https://colab.research.google.com/gist/amahendrakar/cb19b976d100df61f01d41e17d2180d0/40328-2-1.ipynb). Please find the attached gist. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40328\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40328\">No</a>\n", "Saving works in TF 2.3.0-rc0, thanks!"]}, {"number": 40327, "title": "[ROCm] Enabling optimized FusedBatchNormInferenceMetaKernel for half", "body": "This PR enables optimized FusedBatchNormInferenceMetaKernel for half on ROCm.", "comments": ["Changes have been merged into master by commit e25d3e0. So closing the PR."]}, {"number": 40326, "title": "TF2. How to set tf.OptimizerOptions.L0", "body": "**System information**\r\n- Have I written custom code NO:\r\n- OS Platform and Distribution Linux (Ubuntu 20.04):\r\n- TensorFlow installed from source:\r\n- TensorFlow version (use command below):\r\n- Python version: 3.8.2\r\n- Bazel version 3.0.0:\r\n- GCC/Compiler version gcc (Ubuntu 8.4.0-3ubuntu2) 8.4.0):\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\nv1.12.1-32834-g3e842e5ffc 2.2.0\r\n\r\n**Describe the current behavior**\r\n\r\nReference: https://github.com/yaroslavvb/stuff/blob/master/matmul_benchmark.py\r\n\r\nScript from TF1.14\r\nin my TF1 workload,  I was calling this to avoid optimizing away redundant nodes and it worked.\r\n```\r\nconfig = tf.ConfigProto(graph_options=tf.GraphOptions(optimizer_options=tf.OptimizerOptions(opt_level=tf.OptimizerOptions.L0)))\r\nsess = tf.Session(config=config)\r\n```\r\n\r\n**Describe the expected behavior**\r\nWith TF2, I replaced above code with the following and it seems to be not working.  \r\n\r\n`tf.compat.v1.OptimizerOptions(opt_level=-1)`\r\n\r\n", "comments": ["Did you use `compat.v1` modules for other functions as well?\r\n```python\r\nconfig = tf.compat.v1.ConfigProto(graph_options=tf.compat.v1.GraphOptions(optimizer_options=tf.compat.v1.OptimizerOptions(opt_level=tf.compat.v1.OptimizerOptions.L0)))\r\nsess = tf.compat.v1.Session(config=config)\r\n```", "yes.` tf.compat.v1.OptimizerOptions(opt_level=-1)` worked.\r\n\r\nThanks\r\n"]}, {"number": 40325, "title": "[TF Lite] GPU delegates for windows", "body": "Hi, I'm trying to run tf lite on windows with gpu support, so I can run inference on a windows desktop app as fast as possible without relying on CUDA (users may not have a nvidia graphics card or cuda installed)\r\n\r\nIs there a way to compile/use the gpu delegates on windows?\r\n\r\nThis is related to #28830\r\n\r\n**System information**\r\n- OS Platform and Distribution: Windows 10 x64\r\n- TensorFlow installed from: source\r\n- TensorFlow version: v2.2.0\r\n- Python version: 3.6\r\n- Installed using conda\r\n- Bazel version: 2.0.0\r\n- GCC/Compiler version: Visual Studio 2019\r\n\r\n**Describe the problem**\r\n\r\nI cannot TF Lite with GPU support on windows. I compiled the tf lite c api, but it does not provide gpu delegates. I've tried to compile some sort of dll from //tensorflow/lite/delegates/gpu, but no luck.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n`bazel build //tensorflow/lite/c:tensorflowlite_c.dll -c opt`\r\n\r\nTrying to compile the delegates:\r\n`bazel build -c opt --copt -Os --copt -DTFLITE_GPU_BINARY_RELEASE --copt --linkopt -s --strip always //tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so`\r\n`bazel build //tensorflow/lite/delegates/gpu:api -c opt`\r\n\r\n**Any other info / logs**\r\n```\r\nbazel build -c opt --copt -Os --copt -DTFLITE_GPU_BINARY_RELEASE\r\n --copt --linkopt -s --strip always //tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so\r\n...\r\nERROR: Z:/projects/tensorflow/tensorflow/lite/delegates/gpu/cl/BUILD:207:1: C++ compilation of rule '//tensorflow/lite/delegates/gpu/cl:egl_sync' failed (Exit 2)\r\ncl : Command line warning D9002 : ignoring unknown option '--linkopt'\r\n.\\tensorflow/lite/delegates/gpu/cl/egl_sync.h(19): fatal error C1083: Cannot open include file: 'EGL/egl.h': No such file or directory\r\nTarget //tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so failed to build\r\nINFO: Elapsed time: 4.166s, Critical Path: 3.91s\r\nINFO: 31 processes: 31 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\n```\r\nbazel build //tensorflow/lite/delegates/gpu:api -c opt\r\n...\r\nERROR: Z:/projects/tensorflow/tensorflow/lite/delegates/gpu/BUILD:196:1: C++ compilation of rule '//tensorflow/lite/delegates/gpu:api' failed (Exit 2)\r\ncl_version.h: CL_TARGET_OPENCL_VERSION is not defined. Defaulting to 220 (OpenCL 2.2)\r\n.\\tensorflow/lite/delegates/gpu/gl/portable_gl31.h(21): fatal error C1083: Cannot open include file: 'EGL/egl.h': No such file or directory\r\nTarget //tensorflow/lite/delegates/gpu:api failed to build\r\nINFO: Elapsed time: 0.552s, Critical Path: 0.33s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40325\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40325\">No</a>\n", "Sorry, misread your question.  Reopening.", "Our team delivers TFLite GPU, and we primarily only support mobile use cases and don't have immediate plans to support desktop use cases.  We have OpenGL & OpenCL, and on top of that Vulkan is about to be released, and I had colleagues who successfully ran these on the desktop with minor modifications (OpenGL requires Mesa, but the others should be supported once you install the driver).\r\n\r\nNow, re: your original question, Windows: None of us have ever tried to run our backend on Windows.  In fact, we don't even have a Windows desktop in vicinity, not to mention any GPUs.  You would be on your own for employing the TFLite GPU delegate on Windows.  Based on the error messages, you are running into OpenCL compilation issues.  Have you installed OpenCL?", "Thanks @impjdi , I guess then that the way to go would be to modify the build file to generate a opengl dll based on the android build. Anyway for now I've moved to Onnx+DirectML, which seems the only way nowadays for doing inference in desktop GPU without CUDA.\r\n\r\nAbout OpenCL, indeed I don't have it installed, but as I'm on Windows, I'm trying the OpenGL version. For some reason, in the second try it seems that the build uses OpenCL by default.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40325\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40325\">No</a>\n", "If anyone ever gets TF Lite on Windows with GPU support please share your knowledge here!"]}, {"number": 40324, "title": "[ROCm] Fix for ROCm CSB breakage - 200609", "body": "The test `//tensorflow/python/eager:function_test_gpu` started failing today (200609), with the following error\r\n\r\n```\r\n======================================================================\r\nFAIL: testSwapImplementationInEager (__main__.FunctionTest)\r\ntestSwapImplementationInEager (__main__.FunctionTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/eager/function_test_gpu.runfiles/org_tensorflow/tensorflow/python/eager/function_test.py\", line 2824, in testSwapImplementationInEager\r\n    self.assertEqual(run_on_cpu(constant_op.constant(1)).numpy(), 3)\r\nAssertionError: 5 != 3\r\n\r\n----------------------------------------------------------------------\r\nRan 69 tests in 24.622s\r\n\r\nFAILED (failures=1, skipped=1)\r\n```\r\n\r\nThis failure seems to have been introduced by the commit b0b763203e98ea616f44678e194470791db7188d\r\n\r\nThe failing subtest is `testSwapImplementationInEager`, which I think relies on the `disable_meta_optimizer` being set to `False` (which is the default value). There is another subtest `testSharedRendezvous` within this unit-test that explicitly sets the same flag to `True`. If the `testSharedRendezvous` subtest runs before the `testSwapImplementationInEager` subtest, then the flag `disable_meta_optimizer` gets set to `True` and leads to the failure shown above (in the `testSwapImplementationInEager` subtest)\r\n\r\nThe \"fix\" is explicitly set the `disable_meta_optimizer` flag to `False` in the `testSwapImplementationInEager` subtest\r\n\r\n\r\n------------------------------------------------------\r\n\r\ncc @cheshire @chsigg @nvining-work \r\n", "comments": []}, {"number": 40323, "title": "Training using GradientTape not working ", "body": "Tensorflow 2.2.0 \r\nMac OS Catalina\r\nBuilt and Tested in Spyder 4\r\n\r\n![Figure_1](https://user-images.githubusercontent.com/28906480/84167840-9f106e00-aa6e-11ea-94c0-ed9c1cd211fc.png)\r\nRegression fits for each approach, the Keras fit is identical to the actual solution.\r\n\r\n\r\nI have been trying to build a Neural Network based regressor that can model a nonlinear function. I am recreating the issue with a dummy case here. \r\n\r\nInitially I have established a function **u=f(x,t)=sin(x/2)+e^(-t)** and built up a dataset by doing a parameter scan along x and t.\r\n\r\n    N = 5000\r\n    x = np.linspace(-np.pi, np.pi, N)\r\n    t = np.linspace(0, 2, N)\r\n\r\n    lb = np.asarray([x.min(), t.min()])\r\n    ub = np.asarray([x.max(), t.max()])\r\n\r\n    def func_u(x, t): # Function that we are interested in modelling.\r\n        return np.sin(x/2) + np.exp(-t)\r\n\r\n    u_actual = func_u(x, t) \r\n \r\n    X = np.vstack((x, t)).T\r\n\r\nAfter having built a labelled dataset that maps the function from input to output, tried fitting using a keras approach. \r\n\r\n```\r\ndef tf_model(): # Creating a two layer Neural Network. \r\n    act_func = 'relu'\r\n    model_tf = keras.Sequential()\r\n    model_tf.add(keras.layers.Input(shape=(2,)))\r\n    model_tf.add(keras.layers.Dense(100, activation=act_func))\r\n    model_tf.add(keras.layers.Dense(100, activation=act_func))\r\n    model_tf.add(keras.layers.Dense(1, activation='linear'))\r\n    \r\n    return model_tf\r\n\r\n\r\nmodel = tf_model()\r\nmodel.compile(optimizer='adam', loss='mse')\r\n\r\nmodel.fit(X, u_actual, # Fitting using the Keras API\r\n          batch_size=500,\r\n          epochs=1000,\r\n          verbose=1)\r\n\r\nu_model_fit = model(X).numpy()\r\n```\r\nWhich does an amazing job of fitting to the data. \r\n\r\nHowever, when I try and do that with a custom training implementation using GradientTape, it all goes awfully wrong: \r\n\r\n```\r\ndef shuffle_and_batch(X, Y, num_batches=50): # Shuffle and group the input data inot various datasizes. \r\n    indices = tf.range(start=0, limit=tf.shape(X)[0], dtype=tf.int32) \r\n    shuffled_indices = tf.random.shuffle(indices)\r\n    \r\n    X = tf.gather(X, shuffled_indices)\r\n    Y = tf.gather(Y, shuffled_indices)\r\n\r\n    X = tf.split(X, num_batches)\r\n    Y = tf.split(Y, num_batches)\r\n    return X, Y\r\n\r\n\r\nX_tf = tf.Variable(X, tf.float64) #Creating Tensors to treat as the inputs. \r\nY_tf = tf.Variable(u_actual, tf.float64)\r\n\r\nX_tf, Y_tf = shuffle_and_batch(X_tf, Y_tf)\r\n\r\n\r\ndef loss(model, X, Y): # mean squared reconstruction error \r\n    return tf.reduce_mean(tf.square(model(X, training=True) - Y))\r\n                          \r\ndef loss_and_gradients(model, X, Y):\r\n    with tf.GradientTape() as tape:\r\n        loss_tf = loss(model, X, Y)\r\n    grads_tf = tape.gradient(loss_tf, model.trainable_variables)  #Calculating the gradient of each of the loss with respect to the weights and biases. \r\n    return loss_tf, grads_tf\r\n    \r\n\r\noptimizer = tf.keras.optimizers.Adam()\r\nnIter =1000\r\nmodel = tf_model()\r\n\r\nfor it in range(nIter):\r\n    for batch_num in range(50):\r\n        loss_tf, grads_tf = loss_and_gradients(model, X_tf[batch_num], Y_tf[batch_num]) #Obtaining the loss and the gradients\r\n        optimizer.apply_gradients(zip(grads_tf, model.trainable_variables)) #Applying the gradients for each step \r\n\r\n    tf.print('Iter : {}, loss : {}'.format(it, loss_tf))\r\n    \r\nu_tf = model(X).numpy()\r\n```\r\nI tried to do that with Pytorch and pretty much arrive at the same solution as that of using Gradient Tape \r\n\r\n```\r\nmodel_torch = torch.nn.Sequential(\r\n    torch.nn.Linear(2, 100),\r\n    torch.nn.ReLU(),\r\n    torch.nn.Linear(100, 100),\r\n    torch.nn.ReLU(),\r\n    torch.nn.Linear(100, 1)\r\n    )\r\n\r\nX_torch = torch.tensor(X, dtype=torch.float64).float()\r\nY_torch = torch.tensor(u_actual, dtype=torch.float64).float()\r\n\r\n# X_torch, Y_torch = shuffle_and_batch_torch(X_torch, Y_torch)\r\nX_torch, Y_torch = torch.autograd.Variable(X_torch, requires_grad=True), torch.autograd.Variable(Y_torch, requires_grad=True) #Ensuring that tracing occurs. \r\n\r\ntraindata = torch.utils.data.TensorDataset(X_torch, Y_torch) #Loading, Shuffling and Batching the training data. \r\ndataloader = torch.utils.data.DataLoader(traindata, batch_size=50, shuffle=True)\r\n\r\ndef lossfunc_torch(model, X, Y): # Calculating the mean squared error, \r\n    y = model_torch(X)    \r\n    loss = (y-Y).pow(2).mean()\r\n    \r\n    return loss\r\n\r\noptimizer = torch.optim.Adam(model_torch.parameters(), 0.001)    \r\nnIter = 1000\r\n\r\n\r\nfor it in range(nIter):\r\n    for i, (x_torch, y_torch) in enumerate (dataloader):\r\n        optimizer.zero_grad()\r\n        \r\n        loss_torch = lossfunc_torch(model_torch, x_torch, y_torch)\r\n    \r\n        loss_torch.backward()\r\n        optimizer.step()\r\n        \r\n        \r\n    print(\"Iter : {}, Loss : {}\".format(it, loss_torch.item()))\r\n\r\n\r\nu_torch = model_torch(X_torch).detach().numpy()\r\n\r\n```\r\n", "comments": ["@gitvicky,\r\nOn running the code I am facing an error stating `InvalidArgumentError: cannot compute Sub as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:Sub]`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/3dfed527cc567b38f74a679f41ace4de/40323.ipynb#scrollTo=QXAF3MQB25G0). \r\n\r\nCould you please provide the complete code or attach the Python file you are running, so that we can reproduce the issue reported here. Thanks!", "\r\n@amahendrakar  \r\nYou can find the file in this repo : \r\n[https://github.com/gitvicky/Regression-Test.git](url)", "The issue seems to be have been the mismatch in the tensor shapes of the model output (500, 1) and the target output (500, ) which led to the reduce_mean being done across a tensor of shape (500, 500). \r\n\r\nThe issue is fixed with \r\nY = np.expand_dims(u_actual, axis=-1)\r\n"]}, {"number": 40322, "title": "\"The name 'num_detections:0' refers to a Tensor which does not exist. The operation, 'num_detections', does not exist in the graph.\"", "body": "\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on a mobile device: No\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.6\r\n- CUDA/cuDNN version:9/7.5\r\n- GPU model and memory: Nvidia Geforce 840m\r\n\r\n\r\n\r\n**Describe the current behaviour**\r\nI have successfully trained and used a face mask detection model based on Keras Yolo project, the model predicts with good accuracy, I have converted the Keras model (.h5 ) to .pb model ( frozen model ) to export the model on the web with Flask.\r\n\r\nI'm trying to test the model ( load the pb model ) and predict face mask and face no mask with an image.\r\n This code that I've used:\r\n```python\r\n\r\nimport os\r\nimport numpy as np\r\nimport cv2\r\nimport matplotlib.pyplot as plt\r\nimport tensorflow as tf\r\n# Provide path to an image for testing\r\nimg = cv2.imread(\"D:\\\\keras_to_tensorflow\\\\test_images\\\\dss.jpg\")\r\nimg_height, img_width, _ = img.shape\r\nimg_cv2 = img[:, :, [2, 1, 0]]\r\n# Load the Model\r\nmodel_path = \"D:\\\\keras_to_tensorflow\\\\\"\r\npb_file = os.path.join(model_path, 'face_detect.pb')\r\n# Read the graph.\r\nwith tf.gfile.FastGFile(pb_file, 'rb') as f:\r\n    graph_def = tf.GraphDef()\r\n    graph_def.ParseFromString(f.read())\r\ngpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1)\r\nwith tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\r\n    sess.graph.as_default()\r\n    tf.import_graph_def(graph_def, name='face_detect.pbtxt')\r\n\r\n#Include this part with the tensorflow session\r\n#Run the session using the tensors and feed the image to the session\r\n#img_in = cv2.resize(img_cv2, (224, 224))\r\n    img_in = img_cv2[:, :, [2, 1, 0]]  # BGR2RGB\r\n    outputs = sess.run([sess.graph.get_tensor_by_name('num_detections:0'),\r\n             sess.graph.get_tensor_by_name('detection_scores:0'),\r\n             sess.graph.get_tensor_by_name('detection_boxes:0'),\r\n             sess.graph.get_tensor_by_name('detection_classes:0')],\r\n             feed_dict={\r\n                       'input_1:0': img.reshape(1,\r\n                        img.shape[0],\r\n                        img.shape[1],3)})\r\n\r\n\r\n# Visualize the results\r\n    font = cv2.FONT_HERSHEY_SIMPLEX\r\n    for i in range(num_detections):\r\n        classId = int(outputs[3][0][i])\r\n        print(classId)\r\n        score = float(outputs[1][0][i])\r\n        bbox = [float(v) for v in outputs[2][0][i]]\r\n        if True:\r\n            x = bbox[1] * img_width\r\n            y = bbox[0] * img_height\r\n            right = bbox[3] * img_width\r\n            bottom = bbox[2] * img_height\r\n            cv2.rectangle(img_cv2,\r\n                          (int(x), int(y)),\r\n                          (int(right), int(bottom)),\r\n                          (225, 255, 0),\r\n                          thickness=2)\r\n            cv2.putText(img_cv2,str(class_list[classId-1]),(int(x),int(y)), font, 1, (200,0,0), 3, cv2.LINE_AA)\r\n            print('SCORE:',score, ', Class:',class_list[classId-1], ', BBox:',int(x),int(y),int(right),int(bottom))\r\n\r\n```\r\n\r\nI got this error :\r\n\r\n>KeyError: \"The name 'num_detections:0' refers to a Tensor which does not exist. The operation, 'num_detections', does not exist in the graph.\"\r\n\r\n\r\n+ Link of the project That I've used: https://github.com/experiencor/keras-yolo3\r\nThe problem that I did not have a tensor with this name, \r\n\r\nHow can I make this code work perfectly? \r\n\r\n\r\n\r\n", "comments": ["@abdou31 \r\nCan you please let us know if there is any particular reason to eb using this old version of tf, where later versions are available.\r\nI face [this error](https://colab.research.google.com/gist/Saduf2019/353e5156acfbfc72f8f99c0b2f7de769/untitled226.ipynb) when i run your code\r\n", "I used this version because I find it simple, the error you encounter comes from the version simply, so you must downgrade the version of Tensorflow.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "I'm waiting for a solution to my problem.", "@abdou31 \r\nPlease share your code in a colab gist with the error faced so we could analyse it. or else please upgrade the tf version and see if you still face the issue as this is a very old version that does not have support [please use 1.15 or 2.x versions]\r\n\r\nPlease refer to [this link](https://github.com/tensorflow/tensorflow/issues/40439#issuecomment-644274878).", "@abdou31\r\nPlease update as per above comment.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "You should know that this model is a Keras Yolo model.\nI don\u2019t have really this tensor in my model.\nThose tensors are only presented when if I use Tensorflow object detection API . In this case, I should know what tensors can output the number of detected objects , the number of classes , accuracy...", "@abdou31 I think. this is more related to the repo from where you are getting the `keras-yolo3`. I noticed, you already posted it in that repo. There are some issues similar to your issue but in TF2.x. Please feel free to check them. I would also suggest to use TF2.x version. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40322\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40322\">No</a>\n"]}, {"number": 40321, "title": "Neural Structured Learning", "body": "\r\nIs neural structured learning is same as using graph neural network?", "comments": ["@maxkaustav \r\n\r\nCan you go through the [link](https://www.tensorflow.org/neural_structured_learning) and see if it helps you.\r\nThis question is better asked on StackOverflow since it is not a bug or feature request. There is also a larger community that reads questions there and provide better and faster support for such issues. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40320, "title": "[ROCm] 3D pooling", "body": "This PR enables 3D pooling for ROCm.", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40320) for more info**.\n\n<!-- need_author_consent -->", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40320) for more info**.\n\n<!-- ok -->"]}, {"number": 40319, "title": "Options for tflite_convert", "body": "Hello guys,\r\n\r\nI'd like to find out all options available for `tflite_convert` and since I use `--help` I got\r\n\r\n```\r\n(tf-cpu):~$ tflite_convert --help\r\nusage: tflite_convert [-h] --output_file OUTPUT_FILE\r\n                      [--saved_model_dir SAVED_MODEL_DIR | --keras_model_file KERAS_MODEL_FILE]\r\n                      [--enable_v1_converter]\r\n                      [--experimental_new_converter [EXPERIMENTAL_NEW_CONVERTER]]\r\n\r\nCommand line tool to run TensorFlow Lite Converter.\r\n\r\noptional arguments:\r\n  -h, --help            show this help message and exit\r\n  --output_file OUTPUT_FILE\r\n                        Full filepath of the output file.\r\n  --saved_model_dir SAVED_MODEL_DIR\r\n                        Full path of the directory containing the SavedModel.\r\n  --keras_model_file KERAS_MODEL_FILE\r\n                        Full filepath of HDF5 file containing tf.Keras model.\r\n  --enable_v1_converter\r\n                        Enables the TensorFlow V1 converter in 2.0\r\n  --experimental_new_converter [EXPERIMENTAL_NEW_CONVERTER]\r\n                        Experimental flag, subject to change. Enables MLIR-\r\n                        based conversion instead of TOCO conversion.\r\n\r\n``` \r\n\r\nI see there are more options available such as ` --inference_type` `--std_dev_values` I'd like to know those and their respective parameters.\r\n ", "comments": ["@peter197321,\r\nPlease check [this](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/r1/convert/cmdline_reference.md) command line reference page for the converter and let us know if it helps. Thanks!", "You declare the `--enable_v1_converter` flag I can't see it that reference page ...\r\n\r\nQuantization method has been changed around `tflite_convert` and I wonder if this flag is set you can expect behaviour of `tflite_convert v1.x`\r\n\r\nTo me means that output quantized model has used per-tensor quantization for v1.x instead of per-axis (per-channel)  of v2.x \r\n", "@peter197321,\r\nAs per [this documentation](https://www.tensorflow.org/lite/convert/cmdline#usage), setting `--enable_v1_converter` as `True`, enables the 1.X command line flags instead of the 2.X flags.", "per [quantization_config.h](https://github.com/tensorflow/tensorflow/blob/8ab1c251ed27950b850cbc106bbe9a798b16b79a/tensorflow/compiler/mlir/lite/quantization/quantization_config.h#L53) there are other possible flags which I am looking for to set e.g. \r\n\r\n```\r\n  // When set to true, quantization will be done per-tensor. Currently, this\r\n  // option is only valid when the quantization parameters need to be created by\r\n  // scanning the constant content (post-training quantization or QAT without\r\n  // weight FakeQuant).\r\n  bool disable_per_channel = false;\r\n```\r\nis it possible to use those within `tflite_convert` call? If so please can you have some code snippet how to use? \r\n", "You can find the details of all options and the parameters of the methods in the source code of tflite_convert [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/python/tflite_convert.py).\r\nYou can also refer the high level details from the documentation [here](https://www.tensorflow.org/lite/convert). Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40319\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40319\">No</a>\n"]}, {"number": 40318, "title": "[TF Lite C API]  Zero outputs", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: SnapDragon 645, Android 10\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): v2.2.0\r\n- Python version: 2.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA 10.2\r\n- GPU model and memory: NA\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nI'm inferencing the same model in C++ API (using libtensorflowlite.so) and C API (using libtensorflowlite_c.so) on Android NDK r18b. While the C++ code works well and passed test cases, the C version output all zeros.\r\n\r\n**Describe the expected behavior**\r\n\r\nOutput from C and C++ version should be exactly the same.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\nvoid forward(const float* real, const float* imag, float* pout) {\r\n    TfLiteInterpreterAllocateTensors(interpreter);\r\n    TfLiteTensor* tflite_real = TfLiteInterpreterGetInputTensor(interpreter, 0);\r\n    TfLiteTensor* tflite_imag = TfLiteInterpreterGetInputTensor(interpreter, 1);\r\n    TfLiteTensorCopyFromBuffer(tflite_real, real, N1 * sizeof(float));\r\n    TfLiteTensorCopyFromBuffer(tflite_imag, imag, N2 * sizeof(float));\r\n\r\n    TfLiteInterpreterInvoke(interpreter);\r\n    const TfLiteTensor* out = TfLiteInterpreterGetOutputTensor(interpreter, 0);\r\n    TfLiteTensorCopyToBuffer(out, pout, N_OUT * sizeof(float));\r\n}\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Just to confirm, you built the libtensorflowlite.so and libtensorflowlite_c.so from source using NDK r18b? Is the client code that uses these libs also built using NDK r18b?\r\n\r\nYou might also try inspecting the TfLiteTensor* values directly (see also the TfLiteTensor definition in `lite/c/common.h`) to see if there's an issues with the memcpy behavior.", "Hi @jdduke: Yes, I built both `libtensorflowlite.so` and `libtensorflowlite_c.so` from `tf v2.2.0` using NDK r18b. Client code is using NDK r18b as well.\r\n\r\nWe were able to inference all other models and got exactly the same outputs as C++ API. Only with this specific model that it keeps returning zero, even though input is not zeros.\r\n\r\nIf it helps for debugging, here is the link to the model:\r\nhttps://drive.google.com/file/d/1ZoRjTupSMHydsbGy4cWDLIuZD7LnybsA/view?usp=sharing", "Can you confirm what sizes you're using for N1, N2 and N_OUT? And whether you did an explicit resize? It would be helpful to have some reference input values as well, if possible. Also, can you confirm that the entire output was zero? Thanks again.", "I created a local test feeding random/fixed float values to the inputs, and I get identical (non-zeroed) outputs using the C and C++ APIs for that model. I wouldn't think that this is 2.2-specific, but you might try also building from head to see if that resolves the issue?", "Thanks @jdduke let me retry the code.", "@jdduke Problem resolved, it's exactly due to memcpy and I set the wrong number of elements.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40318\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40318\">No</a>\n"]}, {"number": 40317, "title": "Make http://metadata.google.internal configurable", "body": "The TPU client library has a hardcoded dependency on `http://metadata.google.internal`. We happen to need to redirect this URL to a different VM. Since the URL is hardcoded, we're forced to use a fragile code patch against our version of Tensorflow, which isn't ideal, or rely on `/etc/hosts` to forward `metadata.google.internal`, which causes unexpected global side effects to the user's VM. (For example, GCE uses `metadata.google.internal` to distribute SSH keys to GCE VMs, which breaks when we reroute `metadata.google.internal` using `/etc/hosts`.)\r\n\r\noauth2client solves this by making `http://metadata.google.internal` configurable via the `GCE_METADATA_IP` environment variable. The final url becomes `'http://' + os.getenv('GCE_METADATA_IP', '169.254.169.254')`:\r\n\r\nhttps://github.com/googleapis/oauth2client/blob/50d20532a748f18e53f7d24ccbe6647132c979a9/oauth2client/client.py#L111\r\n\r\nFollowing oauth2client's lead, this PR makes `http://metadata.google.internal` configurable for Tensorflow users via `GCE_METADATA_IP`:\r\n\r\n```py\r\n_GCE_METADATA_URL_ENV_VARIABLE = 'GCE_METADATA_IP'\r\n\r\n# ...\r\n\r\ndef _gce_metadata_endpoint():\r\n  return 'http://' + os.environ.get(\r\n    _GCE_METADATA_URL_ENV_VARIABLE,\r\n    'metadata.google.internal')\r\n```\r\n\r\n`GCE_METADATA_IP` might seem like an awkward name. After all, `metadata.google.internal` is a URL, not an IP address. But it's probably best to match oauth2client's naming convention. That way users won't need to worry about setting two slightly-different variable names to configure both oauth2client and Tensorflow.", "comments": ["Hello! Any word on this?", "Can you fix sanity test please?\r\n\r\n```\r\nFAIL: Found 2 non-allowlisted pylint errors:\r\ntensorflow/python/tpu/client/client.py:73: [C0330(bad-continuation), ] Wrong hanging indentation (add 2 spaces).\r\n\r\ntensorflow/python/tpu/client/client.py:74: [C0330(bad-continuation), ] Wrong hanging indentation (add 2 spaces).\r\n```", "@shawwn Can you please check @mihaimaruseac's comments and keep us posted ? Thanks!", "@shawwn, Any update on this PR? Please. Thanks!", "Sorry for the delay! I've pushed a new commit. Is the pylint error fixed now?", "Achievement unlocked: JAX cited and implemented this PR: https://twitter.com/theshawwn/status/1455464111446315009\r\n\r\n\ud83c\udf89 \r\n"]}, {"number": 40316, "title": "Cannot register 2 metrics with the same name Error", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): JetPack 4.3 (Ubuntu 18.04) \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version (use command below):1.15.2\r\n- Python version:3.6.9\r\n- Bazel version (if compiling from source):0.26.1\r\n- GCC/Compiler version (if compiling from source):7.5.0\r\n- CUDA/cuDNN version:10.0/7.6.3\r\n- GPU model and memory:Jetson AGX Xavier (GPU Volta)\r\n\r\n\r\n**Describe the current behavior**\r\nI'm trying to create an executable of my code (C++) which is using opencv and tensorflow. For this, I have to use autotools which is a tool used to create Makefiles. I'm successfully making my executable but I'm trying to use it I always have this error : \r\n\r\n`2020-06-09 14:02:25.158088: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/cc/saved_model/load_attempt_count\r\n2020-06-09 14:02:25.158383: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/cc/saved_model/load_latency\r\n2020-06-09 14:02:25.158467: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/cc/saved_model/load_latency_by_stage\r\n2020-06-09 14:02:25.159111: F tensorflow/core/framework/variant_op_registry.cc:53] Check failed: existing == nullptr (0x55a3931838 vs. nullptr)Unary VariantDecodeFn for type_name: tensorflow::data::WrappedDatasetVariant already registered\r\nAborted (core dumped)\r\n`\r\n\r\nI do not really understand why,because I have included the required tensorflow flags in my configuration as you can see below : \r\n\r\nAM_LDFLAGS = -lopencv_core -lopencv_imgproc -lopencv_highgui -lopencv_videoio -ltensorflow_cc -ltensorflow_framework -lprotobuf -lprotoc\r\n\r\nAny help would be much appreciated, thanks !\r\n\r\n", "comments": ["@Kmarconi \r\n\r\nRequest you to share related code to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "Hi, thanks for your quick reply. I'm working on some object detection and my code is exactly the same as the one here : https://github.com/lysukhin/tensorflow-object-detection-cpp (I'm trying to compile the main.cpp file and to use the utils.h as a shared librarie). ", "Hi, just to save you some time for other issues, I wanted to let know that I've solved my issue this morning. It was coming from my tensorflow-cpp installation, I was using the wrong flags ( probably the monolitic one which is bad for the Jetson Xavier). For my new installation, I've used the nonccl flag and the noaws flag. Everything is working perfectly now.  ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40316\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40316\">No</a>\n", "> Hi, just to save you some time for other issues, I wanted to let know that I've solved my issue this morning. It was coming from my tensorflow-cpp installation, I was using the wrong flags ( probably the monolitic one which is bad for the Jetson Xavier). For my new installation, I've used the nonccl flag and the noaws flag. Everything is working perfectly now.\r\n\r\nHello, could you provide the detail of your configuration? I faced the same issue on Jetson "]}, {"number": 40315, "title": "Custom keras model  train success,but save error", "body": "SRGNNModel train sucess,but when I use tf.saved_model.save to save it, it crashed.\r\nIs it cased by tf.compat.v1.nn.dynamic_rnn ? How can I change it\uff1f\r\n\r\n-TensorFlow2.2\r\n\r\n**Complete Code**\r\n\r\n```\r\n# coding=utf-8\r\n\"\"\"\r\n @date  :2020-06-05 17:31\r\n\"\"\"\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\nimport tensorflow as tf\r\nimport argparse\r\nimport csv\r\nimport numpy as np\r\nimport time\r\nfrom functools import partial\r\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D\r\nfrom tensorflow.keras import Model\r\nimport numpy as np\r\nimport csv\r\nimport math\r\n\r\n\r\nclass SRGNNModel(Model):\r\n    def __init__(self, n_node, l2, step, lr, decay, lr_dc, batch_size=100, hidden_size=100, out_size=100):\r\n        super(SRGNNModel, self).__init__()\r\n        self.batch_size_num = batch_size\r\n        self.hidden_size = hidden_size\r\n        self.out_size = out_size\r\n        self.n_node = n_node\r\n        self.L2 = l2\r\n        self.step = step\r\n        self.stdv = 1.0 / math.sqrt(self.hidden_size)\r\n        self.nasr_w1 = tf.Varnasr_w1 = tf.Variable(\r\n            tf.random.uniform((self.out_size, self.out_size), -self.stdv, self.stdv), name='nasr_w1', dtype=tf.float32)\r\n        self.nasr_w2 = tf.Variable(tf.random.uniform((self.out_size, self.out_size), -self.stdv, self.stdv),\r\n                                   name='nasr_w2', dtype=tf.float32)\r\n        self.nasr_v = tf.Variable(tf.random.uniform((1, self.out_size), -self.stdv, self.stdv), name='nasrv',\r\n                                  dtype=tf.float32)\r\n        self.nasr_b = tf.Variable(tf.zeros((self.out_size,)), name='nasr_b', dtype=tf.float32)\r\n\r\n        self.embedding = tf.Variable(tf.random.uniform((self.n_node, self.hidden_size), -self.stdv, self.stdv),\r\n                                     name='embedding', dtype=tf.float32)\r\n        self.W_in = tf.Variable(tf.random.uniform((self.out_size, self.out_size), -self.stdv, self.stdv), name='W_in',\r\n                                dtype=tf.float32)\r\n        self.b_in = tf.Variable(tf.random.uniform((self.out_size,), -self.stdv, self.stdv), name='b_in',\r\n                                dtype=tf.float32)\r\n        self.W_out = tf.Variable(tf.random.uniform((self.out_size, self.out_size), -self.stdv, self.stdv), name='W_out',\r\n                                 dtype=tf.float32)\r\n        self.b_out = tf.Variable(tf.random.uniform((self.out_size,), -self.stdv, self.stdv), name='b_out',\r\n                                 dtype=tf.float32)\r\n        self.B = tf.Variable(tf.random.uniform((2 * self.out_size, self.out_size), -self.stdv, self.stdv), name='B',\r\n                             dtype=tf.float32)\r\n        self.learning_rate = tf.optimizers.schedules.ExponentialDecay(lr, decay, decay_rate=lr_dc, staircase=True)\r\n        self.opt = tf.optimizers.Adam(self.learning_rate)\r\n\r\n    def call(self, x):\r\n        (adj_in, adj_out, alias, item, mask) = x\r\n        self.batch_size = tf.shape(item)[0]\r\n        fin_state = tf.nn.embedding_lookup(self.embedding, item)\r\n        cell = tf.keras.layers.GRUCell(self.out_size)\r\n\r\n        adj_in = tf.cast(adj_in, tf.float32)\r\n        adj_out = tf.cast(adj_out, tf.float32)\r\n        mask = tf.cast(mask, tf.float32)\r\n        for i in range(self.step):\r\n            fin_state = tf.reshape(fin_state, [self.batch_size, -1, self.out_size])\r\n            fin_state_in = tf.reshape(tf.matmul(tf.reshape(fin_state, [-1, self.out_size]), self.W_in) + self.b_in,\r\n                                      [self.batch_size, -1, self.out_size])\r\n            fin_state_out = tf.reshape(tf.matmul(tf.reshape(fin_state, [-1, self.out_size]), self.W_out) + self.b_out,\r\n                                       [self.batch_size, -1, self.out_size])\r\n\r\n            av = tf.concat([tf.matmul(adj_in, fin_state_in), tf.matmul(adj_out, fin_state_out)], axis=-1)\r\n            init_state = tf.reshape(fin_state, [-1, self.out_size])\r\n            state_output, fin_state = tf.compat.v1.nn.dynamic_rnn(cell=cell,\r\n                                                                  inputs=tf.expand_dims(\r\n                                                                      tf.reshape(av, [-1, 2 * self.out_size]), axis=1),\r\n                                                                  initial_state=init_state\r\n                                                                  )\r\n        re_embedding = tf.reshape(fin_state, [self.batch_size, -1, self.out_size])\r\n        rm = tf.reduce_sum(mask, 1)\r\n        last_id = tf.gather_nd(alias, tf.stack([tf.range(self.batch_size), tf.cast(rm, tf.int32) - 1], axis=1))\r\n\r\n        last_h = tf.gather_nd(re_embedding, tf.stack([tf.range(self.batch_size), last_id], axis=1))\r\n\r\n        seq_h = tf.stack([tf.nn.embedding_lookup(re_embedding[i], alias[i]) for i in range(self.batch_size_num)],\r\n                         axis=0)\r\n        last = tf.matmul(last_h, self.nasr_w1)\r\n        seq = tf.matmul(tf.reshape(seq_h, [-1, self.out_size]), self.nasr_w2)\r\n        last = tf.reshape(last, [self.batch_size, 1, -1])\r\n        m = tf.nn.sigmoid(last + tf.reshape(seq, [self.batch_size, -1, self.out_size]) + self.nasr_b)\r\n        coef = tf.matmul(tf.reshape(m, [-1, self.out_size]), self.nasr_v, transpose_b=True) * tf.reshape(mask, [-1, 1])\r\n        b = self.embedding[1:]\r\n        ma = tf.concat([tf.reduce_sum(tf.reshape(coef, [self.batch_size, -1, 1]) * seq_h, 1),\r\n                        tf.reshape(last, [-1, self.out_size])], -1)\r\n        y1 = tf.matmul(ma, self.B)\r\n        logits = tf.matmul(y1, b, transpose_b=True)\r\n        return logits\r\n\r\n\r\ndef data_generator(data):\r\n    for example in data:\r\n        yield example\r\n\r\n\r\ndef process_data(row):\r\n    features = row[:-1]\r\n    labels = row[-1]\r\n    items, alias_inputs = tf.unique(features)  # value,index\r\n\r\n    vector_length = tf.shape(features)[0]\r\n    n_nodes = tf.shape(items)[0]\r\n    indices = tf.gather(alias_inputs, tf.stack([tf.range(vector_length - 1), tf.range(vector_length - 1) + 1],\r\n                                               axis=0))  # Stack and stagger values\r\n    unique_indices, _ = tf.unique(indices[0] * (vector_length + 1) + indices[1])  # unique(a*x + b)\r\n    unique_indices = tf.sort(unique_indices)  # Sort ascending\r\n    unique_indices = tf.stack(\r\n        [tf.math.floordiv(unique_indices, (vector_length + 1)), tf.math.floormod(unique_indices, (vector_length + 1))],\r\n        axis=1)  # Ungroup and stack\r\n    unique_indices = tf.cast(unique_indices, tf.int64)\r\n\r\n    values = tf.ones(tf.shape(unique_indices, out_type=tf.int64)[0], dtype=tf.int64)\r\n    dense_shape = tf.cast([n_nodes, n_nodes], tf.int64)\r\n\r\n    adj = tf.SparseTensor(indices=unique_indices, values=values, dense_shape=dense_shape)\r\n    adj = tf.sparse.to_dense(adj)\r\n\r\n    u_sum_in_tf = tf.math.reduce_sum(adj, 0)\r\n    u_sum_in_tf = tf.clip_by_value(u_sum_in_tf, 1, tf.reduce_max(u_sum_in_tf))\r\n    A_in = tf.math.divide(adj, u_sum_in_tf)\r\n\r\n    u_sum_out_tf = tf.math.reduce_sum(adj, 1)\r\n    u_sum_out_tf = tf.clip_by_value(u_sum_out_tf, 1, tf.reduce_max(u_sum_out_tf))\r\n    A_out = tf.math.divide(tf.transpose(adj), u_sum_out_tf)\r\n\r\n    mask = tf.fill(tf.shape(features), 1)\r\n\r\n    return A_in, A_out, alias_inputs, items, mask, labels\r\n\r\n\r\ndef input_fn(data, batch_size, max_seq, max_n_node):\r\n    dataset = tf.data.Dataset.from_generator(partial(data_generator, data), output_types=(tf.int32))\r\n    dataset = dataset.map(process_data, num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\n    dataset = dataset.padded_batch(batch_size=batch_size, padded_shapes=(\r\n        [max_n_node, max_n_node],\r\n        [max_n_node, max_n_node],\r\n        [max_seq],\r\n        [max_n_node],\r\n        [max_seq],\r\n        []))\r\n\r\n    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n    return dataset\r\n\r\n\r\ndef loss_fn(logits, labels):\r\n    softmax = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels - 1, logits=logits)\r\n    loss = tf.reduce_mean(softmax)\r\n    return loss\r\n\r\n\r\nif __name__ == '__main__':\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument('--model_path', default='saved_model_test', help='model path')\r\n    parser.add_argument('--method', type=str, default='ggnn', help='ggnn/gat/gcn')\r\n    parser.add_argument('--validation', action='store_true', help='validation')\r\n    parser.add_argument('--epoch', type=int, default=2, help='number of epochs to train for')\r\n    parser.add_argument('--batch_size', type=int, default=10, help='input batch size')\r\n    parser.add_argument('--hidden_size', type=int, default=100, help='hidden state size')\r\n    parser.add_argument('--l2', type=float, default=1e-5, help='l2 penalty')\r\n    parser.add_argument('--lr', type=float, default=0.001, help='learning rate')\r\n    parser.add_argument('--step', type=int, default=1, help='gnn propogation steps')\r\n    parser.add_argument('--nonhybrid', action='store_true', help='global preference')\r\n    parser.add_argument('--lr_dc', type=float, default=0.1, help='learning rate decay rate')\r\n    parser.add_argument('--lr_dc_step', type=int, default=3,\r\n                        help='the number of steps after which the learning rate decay')\r\n    opt = parser.parse_args()\r\n    n_node = 0\r\n    max_seq = 0\r\n    max_n_node = 0\r\n    origin_train_data = np.random.randint(1,50,size=[1000,10]).tolist()\r\n    n_node = max(n_node, np.amax([np.amax(z) for z in origin_train_data]) + 1)\r\n    max_seq = max(max_seq, len(max(origin_train_data, key=len)))\r\n    max_n_node = max(max_n_node, len(max([np.unique(i) for i in origin_train_data], key=len)))\r\n    train_dataset_size = len(origin_train_data)\r\n    print(n_node, max_seq, max_n_node)\r\n\r\n    origin_test_data = np.random.randint(1,50,size=[500,10]).tolist()\r\n    n_node = max(n_node, np.amax([np.amax(z) for z in origin_test_data]) + 1)\r\n    max_seq = max(max_seq, len(max(origin_test_data, key=len)))\r\n    max_n_node = max(max_n_node, len(max([np.unique(i) for i in origin_test_data], key=len)))\r\n    test_dataset_size = len(origin_test_data)\r\n\r\n    print(\"n_node:\", n_node)\r\n    print(\"max_seq:\", max_seq)\r\n    print(\"max_n_node:\", max_n_node)\r\n    print(\"train_dataset_size:\", train_dataset_size)\r\n    print(\"test_dataset_size:\", test_dataset_size)\r\n\r\n    train_loss = tf.keras.metrics.Mean(name='train_loss')\r\n\r\n    train_accuracy = tf.keras.metrics.SparseTopKCategoricalAccuracy(k=20)\r\n\r\n    test_loss = tf.keras.metrics.Mean(name='test_loss')\r\n    test_accuracy = tf.keras.metrics.SparseTopKCategoricalAccuracy(k=20)\r\n\r\n    optimizer = tf.keras.optimizers.Adam()\r\n    train_data = input_fn(origin_train_data, opt.batch_size, max_seq, max_n_node)\r\n    test_data = input_fn(origin_test_data, opt.batch_size, max_seq, max_n_node)\r\n\r\n    model = SRGNNModel(n_node=n_node,\r\n                       l2=opt.l2,\r\n                       step=opt.step,\r\n                       lr=opt.lr,\r\n                       decay=opt.lr_dc_step * train_dataset_size / opt.batch_size,\r\n                       lr_dc=opt.lr_dc,\r\n                       batch_size=opt.batch_size,\r\n                       hidden_size=opt.hidden_size,\r\n                       out_size=opt.hidden_size)\r\n\r\n\r\n    def train_step(inputs, labels):\r\n        with tf.GradientTape() as tape:\r\n            predictions = model(inputs)\r\n            loss = loss_fn(predictions, labels)\r\n        gradients = tape.gradient(loss, model.trainable_variables)\r\n        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n        train_loss(loss)\r\n        train_accuracy(labels - 1, predictions)\r\n\r\n\r\n    def test_step(inputs, labels):\r\n        predictions = model(inputs)\r\n        loss = loss_fn(predictions, labels)\r\n        test_loss(loss)\r\n        test_accuracy(labels - 1, predictions)\r\n\r\n\r\n    num = 0\r\n    for epoch in range(opt.epoch):\r\n        train_loss.reset_states()\r\n        train_accuracy.reset_states()\r\n        test_loss.reset_states()\r\n        test_accuracy.reset_states()\r\n        step_template = 'Epoch {},Global step {}, Loss: {}, Recall@20: {}'\r\n\r\n        for A_in, A_out, alias_inputs, items, mask, labels in train_data:\r\n            train_step((A_in, A_out, alias_inputs, items, mask), labels)\r\n            num = num + 1\r\n\r\n            if num % 10 == 0:\r\n                print(time.strftime('%Y-%m-%d %H:%M:%S ', time.localtime(time.time())) +\r\n                      step_template.format(epoch + 1, num * opt.batch_size, train_loss.result(),\r\n                                           train_accuracy.result() * 100))\r\n\r\n        for A_in, A_out, alias_inputs, items, mask, labels in test_data:\r\n            test_step((A_in, A_out, alias_inputs, items, mask), labels)\r\n        template = 'Epoch {}, Loss: {}, Recall@20: {}, Test Loss: {}, Test Recall@20: {}'\r\n        print(time.strftime('%Y-%m-%d %H:%M:%S ', time.localtime(time.time())) +\r\n              template.format(epoch + 1, train_loss.result(), train_accuracy.result() * 100, test_loss.result(),\r\n                              test_accuracy.result() * 100))\r\n    tf.saved_model.save(model, opt.model_path)\r\n```\r\n\r\n**Error Messgae**\r\n```\r\nTraceback (most recent call last):\r\n  File \"ttt.py\", line 257, in <module>\r\n    tf.saved_model.save(model, opt.model_path)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py\", line 951, in save\r\n    obj, export_dir, signatures, options, meta_graph_def)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py\", line 1008, in _build_meta_graph\r\n    checkpoint_graph_view)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_serialization.py\", line 75, in find_function_to_export\r\n    functions = saveable_view.list_functions(saveable_view.root)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py\", line 143, in list_functions\r\n    self._serialization_cache)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 1656, in _list_functions_for_serialization\r\n    Model, self)._list_functions_for_serialization(serialization_cache)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 2750, in _list_functions_for_serialization\r\n    .list_functions_for_serialization(serialization_cache))\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/base_serialization.py\", line 87, in list_functions_for_serialization\r\n    fns = self.functions_to_serialize(serialization_cache)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py\", line 77, in functions_to_serialize\r\n    serialization_cache).functions_to_serialize)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py\", line 92, in _get_serialized_attributes\r\n    serialization_cache)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/model_serialization.py\", line 47, in _get_serialized_attributes_internal\r\n    default_signature = save_impl.default_save_signature(self.obj)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py\", line 203, in default_save_signature\r\n    fn.get_concrete_function()\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 959, in get_concrete_function\r\n    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 872, in _get_concrete_function_garbage_collected\r\n    *args, **kwargs)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2496, in _get_concrete_function_garbage_collected\r\n    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2777, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2667, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 981, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 441, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saving_utils.py\", line 132, in _wrapped_model\r\n    outputs = model(inputs, training=False)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 927, in __call__\r\n    outputs = call_fn(cast_inputs, *args, **kwargs)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 309, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"ttt.py\", line 73, in call\r\n    initial_state=init_state\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py\", line 707, in dynamic_rnn\r\n    dtype=dtype)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py\", line 916, in _dynamic_rnn_loop\r\n    swap_memory=swap_memory)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2688, in while_loop\r\n    back_prop=back_prop)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/while_v2.py\", line 196, in while_loop\r\n    add_control_dependencies=add_control_dependencies)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 981, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/while_v2.py\", line 174, in wrapped_body\r\n    outputs = body(*_pack_sequence_as(orig_loop_vars, args))\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py\", line 884, in _time_step\r\n    (output, new_state) = call_cell()\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py\", line 870, in <lambda>\r\n    call_cell = lambda: cell(input_t, state)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 897, in __call__\r\n    self._maybe_build(inputs)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 2416, in _maybe_build\r\n    self.build(input_shapes)  # pylint:disable=not-callable\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\", line 316, in wrapper\r\n    output_shape = fn(instance, input_shape)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py\", line 1752, in build\r\n    caching_device=default_caching_device)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 577, in add_weight\r\n    caching_device=caching_device)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\", line 743, in _add_variable_with_custom_getter\r\n    **kwargs_for_getter)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\", line 141, in make_variable\r\n    shape=variable_shape if variable_shape else None)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 259, in __call__\r\n    return cls._variable_v1_call(*args, **kwargs)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 220, in _variable_v1_call\r\n    shape=shape)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 66, in getter\r\n    return captured_getter(captured_previous, **kwargs)\r\n  File \"/media/vdb1/application/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 511, in invalid_creator_scope\r\n    \"tf.function-decorated function tried to create \"\r\nValueError: tf.function-decorated function tried to create variables on non-first call.\r\n```", "comments": ["@jifei,\r\nOn running the code I'm facing an error stating `NameError: name 'Model' is not defined`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/b494cba70200dfac4ccac5dfaef0c017/40315.ipynb). \r\n\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here. Thanks!", "Also, please add ``` (i.e. three back ticks) before and after your code to preserve the indentation and formatting. Thanks!", "> Also, please add ``` (i.e. three back ticks) before and after your code to preserve the indentation and formatting. Thanks!\r\n\r\nThanks\uff0cI update the code.", "@jifei,\r\nPlease take a look at [this solution](https://github.com/tensorflow/tensorflow/issues/27120#issuecomment-540071844) from a similar issue and let us know if it helps. Thanks!", "I met the same problem (train process ok, not the save).  Do you know how to solve it?", "@guohuiGH,\r\nPlease submit a new issue from [this link](https://github.com/tensorflow/tensorflow/issues/new/choose) and fill in the template, so that we can track the issue there. Thanks!"]}, {"number": 40314, "title": "cant import tensorflow.contrib.tensorrt", "body": "is there any way to import contrib.tensorrt in tensorflow 2.2.0?\r\n", "comments": ["@glennford49 \r\nPlease refer to this [comment](https://github.com/tensorflow/tensorflow/issues/31350#issuecomment-566151053), and let us know if we can move this issue to resolved status.", "I've already fix this... tensorrt has been moved to core in version 2.x", "@glennford49 \r\nPlease confirm if we may move this issue resolved status."]}]