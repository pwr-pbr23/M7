[{"number": 55485, "title": "Are the instructions for building TFLite examples outdated?", "body": "I am trying to build an image classifier for android, and I am following the instructions provided [here](https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/android). Following the instructions to run the given example, I am getting this error:\r\n\r\n```\r\nQuerying the mapped value of map(java.io.File property(org.gradle.api.file.Directory, fixed(class org.gradle.api.internal.file.DefaultFilePropertyFactory$FixedDirectory, /Users/user1/samples/android_example/models/build/generated/ap_generated_sources/debug/out)) org.gradle.api.internal.file.DefaultFilePropertyFactory$ToFileTransformer@2325887e) before task ':models:compileDebugJavaWithJavac' has completed is not supported\r\n\r\n```\r\n\r\n**System Info**\r\n\r\n* System: mac\r\n* Android Studio version: 3.2\r\n* Android SDK version: 23\r\n", "comments": ["@AakashKumarNain ! Thanks for reporting the bug . Raised PR [#380](https://github.com/tensorflow/examples/pull/380) to address this issue. Please try again in Android Studio's latest version and let us know. Attaching [relevant document ](https://github.com/tensorflow/examples/pull/380)for reference. Thanks!", "Thanks @mohantym Let me try to build it with the updated instructions in your PR", "Hi @mohantym I tried with Android Studio 4.1 and the given examples still fails on build step. Here is the stacktrace:\r\n\r\n```\r\nFAILURE: Build failed with an exception.\r\n\r\n* What went wrong:\r\nExecution failed for task ':models:compileDebugJavaWithJavac'.\r\n> Failed to calculate the value of task ':models:compileDebugJavaWithJavac' property 'options.generatedSourceOutputDirectory'.\r\n   > Querying the mapped value of map(java.io.File property(org.gradle.api.file.Directory, fixed(class org.gradle.api.internal.file.DefaultFilePropertyFactory$FixedDirectory, /Users/user1/projects/android_example/models/build/generated/ap_generated_sources/debug/out)) org.gradle.api.internal.file.DefaultFilePropertyFactory$ToFileTransformer@7221f28c) before task ':models:compileDebugJavaWithJavac' has completed is not supported\r\n\r\n* Try:\r\n> Run with --info or --debug option to get more log output.\r\n> Run with --scan to get full insights.\r\n\r\n* Exception is:\r\norg.gradle.api.tasks.TaskExecutionException: Execution failed for task ':models:compileDebugJavaWithJavac'.\r\n        at org.gradle.api.internal.tasks.properties.DefaultTaskProperties.resolve(DefaultTaskProperties.java:76)\r\n        at org.gradle.execution.plan.LocalTaskNode.resolveMutations(LocalTaskNode.java:231)\r\n        at org.gradle.execution.plan.DefaultExecutionPlan.getResolvedMutationInfo(DefaultExecutionPlan.java:737)\r\n        at org.gradle.execution.plan.DefaultExecutionPlan.selectNext(DefaultExecutionPlan.java:649)\r\n        at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.lambda$executeNextNode$2(DefaultPlanExecutor.java:197)\r\n        at org.gradle.internal.resources.DefaultResourceLockCoordinationService.withStateLock(DefaultResourceLockCoordinationService.java:45)\r\n        at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.executeNextNode(DefaultPlanExecutor.java:186)\r\n        at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.run(DefaultPlanExecutor.java:140)\r\n        at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64)\r\n        at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48)\r\nCaused by: org.gradle.api.internal.provider.AbstractProperty$PropertyQueryException: Failed to calculate the value of task ':models:compileDebugJavaWithJavac' property 'options.generatedSourceOutputDirectory'.\r\n        at org.gradle.api.internal.provider.AbstractProperty.finalizeNow(AbstractProperty.java:239)\r\n        at org.gradle.api.internal.provider.AbstractProperty.beforeRead(AbstractProperty.java:230)\r\n        at org.gradle.api.internal.provider.AbstractProperty.calculateOwnValueNoProducer(AbstractProperty.java:120)\r\n        at org.gradle.api.internal.file.DefaultFilePropertyFactory$AbstractFileVar.access$100(DefaultFilePropertyFactory.java:180)\r\n        at org.gradle.api.internal.file.DefaultFilePropertyFactory$AbstractFileVar$2.calculateOwnValue(DefaultFilePropertyFactory.java:263)\r\n        at org.gradle.api.internal.provider.AbstractMinimalProvider.getOrNull(AbstractMinimalProvider.java:93)\r\n        at org.gradle.api.internal.tasks.properties.FileParameterUtils.resolveOutputFilePropertySpecs(FileParameterUtils.java:122)\r\n        at org.gradle.api.internal.tasks.properties.OutputUnpacker.visitOutputFileProperty(OutputUnpacker.java:67)\r\n        at org.gradle.api.internal.tasks.properties.CompositePropertyVisitor.visitOutputFileProperty(CompositePropertyVisitor.java:69)\r\n        at org.gradle.api.internal.tasks.properties.annotations.AbstractOutputPropertyAnnotationHandler.visitPropertyValue(AbstractOutputPropertyAnnotationHandler.java:50)\r\n        at org.gradle.api.internal.tasks.properties.bean.AbstractNestedRuntimeBeanNode.visitProperties(AbstractNestedRuntimeBeanNode.java:56)\r\n        at org.gradle.api.internal.tasks.properties.bean.NestedRuntimeBeanNode.visitNode(NestedRuntimeBeanNode.java:41)\r\n        at org.gradle.api.internal.tasks.properties.DefaultPropertyWalker.visitProperties(DefaultPropertyWalker.java:41)\r\n        at org.gradle.api.internal.tasks.TaskPropertyUtils.visitProperties(TaskPropertyUtils.java:42)\r\n        at org.gradle.api.internal.tasks.properties.DefaultTaskProperties.resolve(DefaultTaskProperties.java:67)\r\n        at org.gradle.execution.plan.LocalTaskNode.resolveMutations(LocalTaskNode.java:231)\r\n        at org.gradle.execution.plan.DefaultExecutionPlan.getResolvedMutationInfo(DefaultExecutionPlan.java:737)\r\n        at org.gradle.execution.plan.DefaultExecutionPlan.selectNext(DefaultExecutionPlan.java:649)\r\n        at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.lambda$executeNextNode$2(DefaultPlanExecutor.java:197)\r\n        at org.gradle.internal.resources.DefaultResourceLockCoordinationService.withStateLock(DefaultResourceLockCoordinationService.java:45)\r\n        at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.executeNextNode(DefaultPlanExecutor.java:186)\r\n        at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.run(DefaultPlanExecutor.java:140)\r\n        at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64)\r\n        at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48)\r\nCaused by: org.gradle.api.InvalidUserCodeException: Querying the mapped value of map(java.io.File property(org.gradle.api.file.Directory, fixed(class org.gradle.api.internal.file.DefaultFilePropertyFactory$FixedDirectory, /Users/user1/projects/android_example/models/build/generated/ap_generated_sources/debug/out)) org.gradle.api.internal.file.DefaultFilePropertyFactory$ToFileTransformer@7221f28c) before task ':models:compileDebugJavaWithJavac' has completed is not supported\r\n        at org.gradle.api.internal.provider.TransformBackedProvider.lambda$beforeRead$0(TransformBackedProvider.java:84)\r\n        at org.gradle.api.internal.provider.ValueSupplier$TaskProducer.visitContentProducerTasks(ValueSupplier.java:136)\r\n        at org.gradle.api.internal.provider.TransformBackedProvider.beforeRead(TransformBackedProvider.java:81)\r\n        at org.gradle.api.internal.provider.TransformBackedProvider.calculateOwnValue(TransformBackedProvider.java:63)\r\n        at org.gradle.api.internal.provider.AbstractMinimalProvider.calculateValue(AbstractMinimalProvider.java:103)\r\n        at org.gradle.api.internal.provider.MappingProvider.calculateOwnValue(MappingProvider.java:55)\r\n        at org.gradle.api.internal.provider.AbstractMinimalProvider.calculateValue(AbstractMinimalProvider.java:103)\r\n        at org.gradle.api.internal.provider.AbstractMinimalProvider.withFinalValue(AbstractMinimalProvider.java:159)\r\n        at org.gradle.api.internal.provider.DefaultProperty.finalValue(DefaultProperty.java:133)\r\n        at org.gradle.api.internal.provider.DefaultProperty.finalValue(DefaultProperty.java:26)\r\n        at org.gradle.api.internal.provider.AbstractProperty.finalizeNow(AbstractProperty.java:236)\r\n        ... 23 more\r\n\r\n\r\n* Get more help at https://help.gradle.org\r\n\r\nDeprecated Gradle features were used in this build, making it incompatible with Gradle 8.0.\r\n\r\nYou can use '--warning-mode all' to show the individual deprecation warnings and determine if they come from your own scripts or plugins.\r\n\r\nSee https://docs.gradle.org/7.4/userguide/command_line_interface.html#sec:command_line_warnings\r\n\r\nBUILD FAILED in 18s\r\n\r\n```", "Hi @sachinprasadhs ! Could you please look at this issue?", "Any updates on this?", "@khanhlvg, could you please take a look? Thanks!", "Upgrading to Android Gradle Plugin v4.2 and Android Studio 4.2 will solve this problem.\r\n\r\n* PR to upgrade Android Gradle Plugin: https://github.com/tensorflow/examples/pull/370\r\n* I'll create a commit to update README files to suggest using Android Studio 4.2 and above."]}, {"number": 55483, "title": "How to convert XLA HLO debug code to executable ?", "body": "Background : We use TF1.15 to training model, and I'm so sorry we can not upgrade TF to 2.8, because we add some new function for custom tensorflow.\r\nQuestion: I have a big model, and I want to increase training speed by using xla, but I meet a CUDA_ERROR_ILLEGAL_ADDRESS when I use xla, so I want to know how to solve this question. \r\nnow I have some infomations:\r\n1. I got error xla_cluster name.\r\n2. I got all inputs of error xla_cluster.\r\n3. I got all XLA HLO codes by ```export XLA_FLAGS=\"--xla_dump_to=./xla\"```\r\nFor eaier debug, For easier debugging, I want a method that converts the IR code into an executable.\r\nDebugging xla is very, very difficult, please help.\r\n\r\nother infos:\r\ncluster_728 have 30 ops. \r\nThe problem will not be repeated when I narrow down the cluster.\r\nThe problem will not recur when I shrink the batch_size again.\r\ndebug-file about cluster_728: [module_0023.tar.gz](https://github.com/tensorflow/tensorflow/files/8410698/module_0023.tar.gz)\r\n\r\n![image](https://user-images.githubusercontent.com/33950866/161570318-b613eca7-6a1e-49da-b223-3b744258f5e6.png)", "comments": ["[module_0023.tar.gz](https://github.com/tensorflow/tensorflow/files/8410698/module_0023.tar.gz)\r\n", "I follow https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/xla/tools/run_hlo_module_main.cc to replay_computation, \r\nTools have some bugs when I run **after_optimize**:\r\n```\r\nrun run_hlo_module --     --input_format=hlo                   --platform=CUDA     /data2/zhaozheng09/user/xla/workdir_mxl/waimai_model_train_platform/DIN_CAN_fixr_bn_pairwise/train/ok_xla/1649167006999201.module_0023.after_optimizations.txt\r\n```\r\nI got errors\r\n```\r\n2022-04-05 22:13:24.962594: F tensorflow/compiler/xla/tools/run_hlo_module.cc:65] Non-OK-status: result_status.status() status: Internal: Unexpected bitcast operation seen during layout assignment: %bitcast.10 = f32[135000,128]{1,0} bitcast(f32[9000,15,128] %fusion.4), metadata={op_type=\"Reshape\" op_name=\"mt_model_fn_0/mt_feature_process_1/input/mt_feature_process_52/attention_layer_view_att/view_attf_1_att/Tensordot/Reshape\"}.Failed to execute on CUDA\r\n```\r\n\r\nWhen I run **before_optimize**, \r\n```\r\nbazel run run_hlo_module --     --input_format=hlo                   --platform=CUDA     /data2/zhaozheng09/user/xla/workdir_mxl/waimai_model_train_platform/DIN_CAN_fixr_bn_pairwise/train/xla/1649167006999201.module_0023.before_optimizations.txt\r\n```\r\nI seem get a successful result \r\n```\r\nMismatches in shape (f32[90000,8], f32[360000,8], f32[360000,8], f32[180000,8], f32[540000,8], f32[90000,8], f32[270000,8], f32[360000,8], f32[180000,8], f32[90000,8], f32[90000,8], f32[180000,8], f32[90000,8], f32[81000,8], f32[864000,8], f32[9000,8], f32[180000,8], f32[90000,8], f32[180000,8], f32[90000,8], f32[180000,8], f32[180000,8], f32[180000,8], f32[180000,8], f32[180000,8], f32[180000,8], f32[180000,8], f32[180000,8], f32[180000,8], f32[684000,8], f32[45000,8], f32[9000,40,8], f32[9000,70,8], f32[9000,20,8], f32[9000,1,8], f32[9000,3,8], f32[9000,8], f32[9000,15,8], f32[9000,1,15], pred[9000,1,15], f32[9000,15,64], f32[135000,64], f32[9000,15,128], f32[135000,128], f32[135000,16]) (118854000 elements):\r\nArray at shape index {36},\r\nMismatch count 16567 (23.0097%) in shape f32[9000,8] (72000 elements), abs bound 0.1, rel bound 0.1\r\nnan mismatches 16567\r\nTop relative error mismatches:\r\n  actual -1.93359781e+20, expected            -nan, index {2,2}, rel error      inf, abs error      inf\r\n  actual            -inf, expected            -nan, index {2,1}, rel error      inf, abs error      inf\r\n  actual             inf, expected            -nan, index {0,6}, rel error      inf, abs error      inf\r\n  actual             inf, expected            -nan, index {0,5}, rel error      inf, abs error      inf\r\n  actual  8.84062801e+28, expected            -nan, index {0,1}, rel error      inf, abs error      inf\r\nAbsolute magnitude breakdown of actual values:\r\n  0      <= x < 0.0001 :       0 (  0.0000%)\r\n  0.0001 <= x < 0.001  :       0 (  0.0000%)\r\n  0.001  <= x < 0.01   :       0 (  0.0000%)\r\n  0.01   <= x < 0.1    :       0 (  0.0000%)\r\n  0.1    <= x < 1      :       0 (  0.0000%)\r\n  1      <= x < inf    :   72000 (100.0000%), mismatches 16567\r\nElements exceeding abs error bound 0.1: 16623 (23.0875%)\r\nRelative error breakdown of elements exceeding abs error bound:\r\n  <  0.0001 :      56 (0.3369%)\r\n  >= 0.0001 :   16567 (99.6631%)\r\n  >= 0.001  :   16567 (99.6631%)\r\n  >= 0.01   :   16567 (99.6631%)\r\n  >= 0.1    :   16567 (99.6631%)\r\n  >= 1      :   16567 (99.6631%)\r\nElements exceeding rel error bound 0.1: 16567 (23.0097%)\r\nAbsolute error breakdown of elements exceeding rel error bound:\r\n  <  0.0001 :       0 (0.0000%)\r\n  >= 0.0001 :   16567 (100.0000%)\r\n  >= 0.001  :   16567 (100.0000%)\r\n  >= 0.01   :   16567 (100.0000%)\r\n  >= 0.1    :   16567 (100.0000%)\r\n  >= 1      :   16567 (100.0000%)\r\n: Array at shape index {38},\r\nMismatch count 66607 (49.3385%) in shape f32[9000,1,15] (135000 elements), abs bound 0.1, rel bound 0.1\r\nnan mismatches 66607\r\nTop relative error mismatches:\r\n  actual -1.34479601e+37, expected            -nan, index {1,0,2}, rel error      inf, abs error      inf\r\n  actual -1.34479601e+37, expected            -nan, index {1,0,1}, rel error      inf, abs error      inf\r\n  actual -1.34479601e+37, expected            -nan, index {0,0,14}, rel error      inf, abs error      inf\r\n  actual -1.34479601e+37, expected            -nan, index {0,0,11}, rel error      inf, abs error      inf\r\n  actual -1.34479601e+37, expected            -nan, index {0,0,7}, rel error      inf, abs error      inf\r\nAbsolute magnitude breakdown of actual values:\r\n  0      <= x < 0.0001 :   30370 ( 22.4963%)\r\n  0.0001 <= x < 0.001  :     916 (  0.6785%)\r\n  0.001  <= x < 0.01   :     925 (  0.6852%)\r\n  0.01   <= x < 0.1    :     897 (  0.6644%)\r\n  0.1    <= x < 1      :     904 (  0.6696%)\r\n  1      <= x < inf    :  100988 ( 74.8059%), mismatches 66607\r\nElements exceeding abs error bound 0.1: 66607 (49.3385%)\r\nRelative error breakdown of elements exceeding abs error bound:\r\n  <  0.0001 :       0 (0.0000%)\r\n  >= 0.0001 :   66607 (100.0000%)\r\n  >= 0.001  :   66607 (100.0000%)\r\n  >= 0.01   :   66607 (100.0000%)\r\n  >= 0.1    :   66607 (100.0000%)\r\n  >= 1      :   66607 (100.0000%)\r\nElements exceeding rel error bound 0.1: 66607 (49.3385%)\r\nAbsolute error breakdown of elements exceeding rel error bound:\r\n  <  0.0001 :       0 (0.0000%)\r\n  >= 0.0001 :   66607 (100.0000%)\r\n  >= 0.001  :   66607 (100.0000%)\r\n  >= 0.01   :   66607 (100.0000%)\r\n  >= 0.1    :   66607 (100.0000%)\r\n  >= 1      :   66607 (100.0000%)\r\n: Array at shape index {40},\r\nMismatch count 8639604 (99.9954%) in shape f32[9000,15,64] (8640000 elements), abs bound 0.1, rel bound 0.1\r\nnan mismatches 8639585\r\nTop relative error mismatches:\r\n  actual               0, expected            -nan, index {0,0,4}, rel error      inf, abs error      inf\r\n  actual               0, expected            -nan, index {0,0,3}, rel error      inf, abs error      inf\r\n  actual               0, expected            -nan, index {0,0,2}, rel error      inf, abs error      inf\r\n  actual               0, expected            -nan, index {0,0,1}, rel error      inf, abs error      inf\r\n  actual               0, expected            -nan, index {0,0,0}, rel error      inf, abs error      inf\r\nAbsolute magnitude breakdown of actual values:\r\n  0      <= x < 0.0001 : 8639801 ( 99.9977%), mismatches 8639590\r\n  0.0001 <= x < 0.001  :       0 (  0.0000%)\r\n  0.001  <= x < 0.01   :       0 (  0.0000%)\r\n  0.01   <= x < 0.1    :       0 (  0.0000%)\r\n  0.1    <= x < 1      :       0 (  0.0000%)\r\n  1      <= x < inf    :     199 (  0.0023%), mismatches 14\r\nElements exceeding abs error bound 0.1: 8639604 (99.9954%)\r\nRelative error breakdown of elements exceeding abs error bound:\r\n  <  0.0001 :       0 (0.0000%)\r\n  >= 0.0001 : 8639604 (100.0000%)\r\n  >= 0.001  : 8639604 (100.0000%)\r\n  >= 0.01   : 8639604 (100.0000%)\r\n  >= 0.1    : 8639604 (100.0000%)\r\n  >= 1      : 8639604 (100.0000%)\r\nElements exceeding rel error bound 0.1: 8639604 (99.9954%)\r\nAbsolute error breakdown of elements exceeding rel error bound:\r\n  <  0.0001 :       0 (0.0000%)\r\n  >= 0.0001 : 8639604 (100.0000%)\r\n  >= 0.001  : 8639604 (100.0000%)\r\n  >= 0.01   : 8639604 (100.0000%)\r\n  >= 0.1    : 8639604 (100.0000%)\r\n  >= 1      : 8639604 (100.0000%)\r\n: Array at shape index {41},\r\nMismatch count 8639604 (99.9954%) in shape f32[135000,64] (8640000 elements), abs bound 0.1, rel bound 0.1\r\nnan mismatches 8639585\r\nTop relative error mismatches:\r\n  actual               0, expected            -nan, index {0,4}, rel error      inf, abs error      inf\r\n  actual               0, expected            -nan, index {0,3}, rel error      inf, abs error      inf\r\n  actual               0, expected            -nan, index {0,2}, rel error      inf, abs error      inf\r\n  actual               0, expected            -nan, index {0,1}, rel error      inf, abs error      inf\r\n  actual               0, expected            -nan, index {0,0}, rel error      inf, abs error      inf\r\nAbsolute magnitude breakdown of actual values:\r\n  0      <= x < 0.0001 : 8639801 ( 99.9977%), mismatches 8639590\r\n  0.0001 <= x < 0.001  :       0 (  0.0000%)\r\n  0.001  <= x < 0.01   :       0 (  0.0000%)\r\n  0.01   <= x < 0.1    :       0 (  0.0000%)\r\n  0.1    <= x < 1      :       0 (  0.0000%)\r\n  1      <= x < inf    :     199 (  0.0023%), mismatches 14\r\nElements exceeding abs error bound 0.1: 8639604 (99.9954%)\r\nRelative error breakdown of elements exceeding abs error bound:\r\n  <  0.0001 :       0 (0.0000%)\r\n  >= 0.0001 : 8639604 (100.0000%)\r\n  >= 0.001  : 8639604 (100.0000%)\r\n  >= 0.01   : 8639604 (100.0000%)\r\n  >= 0.1    : 8639604 (100.0000%)\r\n  >= 1      : 8639604 (100.0000%)\r\nElements exceeding rel error bound 0.1: 8639604 (99.9954%)\r\nAbsolute error breakdown of elements exceeding rel error bound:\r\n  <  0.0001 :       0 (0.0000%)\r\n  >= 0.0001 : 8639604 (100.0000%)\r\n  >= 0.001  : 8639604 (100.0000%)\r\n  >= 0.01   : 8639604 (100.0000%)\r\n  >= 0.1    : 8639604 (100.0000%)\r\n  >= 1      : 8639604 (100.0000%)\r\n: Array at shape index {42},\r\nMismatch count 743659 (4.3036%) in shape f32[9000,15,128] (17280000 elements), abs bound 0.1, rel bound 0.1\r\nTop relative error mismatches:\r\n  actual               0, expected             inf, index {0,0,62}, rel error      inf, abs error      inf\r\n  actual               0, expected             inf, index {0,0,57}, rel error      inf, abs error      inf\r\n  actual             inf, expected               0, index {0,0,50}, rel error      inf, abs error      inf\r\n  actual               0, expected             inf, index {0,0,23}, rel error      inf, abs error      inf\r\n  actual               0, expected             inf, index {0,0,8}, rel error      inf, abs error      inf\r\nAbsolute magnitude breakdown of actual values:\r\n  0      <= x < 0.0001 : 8633808 ( 49.9642%), mismatches 372005\r\n  0.0001 <= x < 0.001  :      24 (  0.0001%)\r\n  0.001  <= x < 0.01   :      26 (  0.0002%)\r\n  0.01   <= x < 0.1    :      35 (  0.0002%)\r\n  0.1    <= x < 1      :      73 (  0.0004%)\r\n  1      <= x < inf    : 8646034 ( 50.0349%), mismatches 371654\r\nElements exceeding abs error bound 0.1: 1727295 (9.9959%)\r\nRelative error breakdown of elements exceeding abs error bound:\r\n  <  0.0001 :  264452 (15.3102%)\r\n  >= 0.0001 : 1462843 (84.6898%)\r\n  >= 0.001  :  754875 (43.7027%)\r\n  >= 0.01   :  744657 (43.1112%)\r\n  >= 0.1    :  743659 (43.0534%)\r\n  >= 1      :  743560 (43.0477%)\r\nElements exceeding rel error bound 0.1: 743659 (4.3036%)\r\nAbsolute error breakdown of elements exceeding rel error bound:\r\n  <  0.0001 :       0 (0.0000%)\r\n  >= 0.0001 :  743659 (100.0000%)\r\n  >= 0.001  :  743659 (100.0000%)\r\n  >= 0.01   :  743659 (100.0000%)\r\n  >= 0.1    :  743659 (100.0000%)\r\n  >= 1      :  743659 (100.0000%)\r\n: Array at shape index {43},\r\nMismatch count 743659 (4.3036%) in shape f32[135000,128] (17280000 elements), abs bound 0.1, rel bound 0.1\r\nTop relative error mismatches:\r\n  actual               0, expected             inf, index {0,62}, rel error      inf, abs error      inf\r\n  actual               0, expected             inf, index {0,57}, rel error      inf, abs error      inf\r\n  actual             inf, expected               0, index {0,50}, rel error      inf, abs error      inf\r\n  actual               0, expected             inf, index {0,23}, rel error      inf, abs error      inf\r\n  actual               0, expected             inf, index {0,8}, rel error      inf, abs error      inf\r\nAbsolute magnitude breakdown of actual values:\r\n  0      <= x < 0.0001 : 8633808 ( 49.9642%), mismatches 372005\r\n  0.0001 <= x < 0.001  :      24 (  0.0001%)\r\n  0.001  <= x < 0.01   :      26 (  0.0002%)\r\n  0.01   <= x < 0.1    :      35 (  0.0002%)\r\n  0.1    <= x < 1      :      73 (  0.0004%)\r\n  1      <= x < inf    : 8646034 ( 50.0349%), mismatches 371654\r\nElements exceeding abs error bound 0.1: 1727295 (9.9959%)\r\nRelative error breakdown of elements exceeding abs error bound:\r\n  <  0.0001 :  264452 (15.3102%)\r\n  >= 0.0001 : 1462843 (84.6898%)\r\n  >= 0.001  :  754875 (43.7027%)\r\n  >= 0.01   :  744657 (43.1112%)\r\n  >= 0.1    :  743659 (43.0534%)\r\n  >= 1      :  743560 (43.0477%)\r\nElements exceeding rel error bound 0.1: 743659 (4.3036%)\r\nAbsolute error breakdown of elements exceeding rel error bound:\r\n  <  0.0001 :       0 (0.0000%)\r\n  >= 0.0001 :  743659 (100.0000%)\r\n  >= 0.001  :  743659 (100.0000%)\r\n  >= 0.01   :  743659 (100.0000%)\r\n  >= 0.1    :  743659 (100.0000%)\r\n  >= 1      :  743659 (100.0000%)\r\n\r\n\r\nExpected literal:\r\n[TRUNCATED, Literal with more than 1000 values]\r\n\r\nActual literal:\r\n[TRUNCATED, Literal with more than 1000 values]\r\n1/1 runs miscompared.\r\n``` ", "@zhaozheng09 We see that you are using TF v1.15 which is not actively supported ,so could you please post this issue in TF [forum](https://discuss.tensorflow.org/) where there is a larger community to get you the right help?Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 55482, "title": "Which version of CUDA does tensorflow2.8.0 correspond to? I can't find it on the website.", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Hello @OBLPlife ,\r\nEvery TensorFlow release is compatible with a certain version.I request you, please take a look at the tested build [configurations](https://www.tensorflow.org/install/source#gpu).In this case, can you please try installing TensorFlow v2.8 with CUDA 11.2 and cuDNN 8.1 and check if you are facing the same error. Thanks!\r\n", "> Hello @OBLPlife ,\n> Every TensorFlow release is compatible with a certain version.I request you, please take a look at the tested build [configurations](https://www.tensorflow.org/install/source#gpu).In this case, can you please try installing TensorFlow v2.8 with CUDA 11.2 and cuDNN 8.1 and check if you are facing the same error. Thanks!\n> \n\nOK\uff0cthanks for help", "@OBLPlife ,\r\nCould you please confirm if the issue is resolved. if yes,can you please feel free to move this issue to closed status.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55482\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55482\">No</a>\n"]}, {"number": 55481, "title": "Typo fix in LSTM docstring.", "body": "Replaced a dot with a space.", "comments": ["Hi @peskaf Thank you for the contribution. It looks like your PR relates to the Keras component. Please submit it to the github.com/keras-team/keras repository instead. \r\n\r\n It's better to submit multiple typo fixes in a single PR as the CPU/GPU hours wasted to CI test the typo are too many in comparison with the seconds it takes to submit a single typo fix. Hence we will not be encouraging one liner grammatical changes as this is expensive process. Please try to get multiple typos in one PR.  Thank you.\r\n\r\n@fchollet, @qlzh727"]}, {"number": 55479, "title": "Build TF 2.3 with GPU minus AVX", "body": "How to custom build TF 2.3 in centos 8 with GPU and without avx as my hardware not support AVX.", "comments": ["@nafeesmahbub,\r\n\r\n Could you please try [TensorFlow Dockerfile for centos 8](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dockerfiles/dockerfiles/onednn/centos-8.Dockerfile). Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55479\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55479\">No</a>\n"]}, {"number": 55478, "title": "How can we use gradients accumulation in tf.keras by defining the custom training step?", "body": "I found that when I used a very large model like robert-large,the implementation of gradients accumulation like this\r\nhttps://gist.github.com/innat/ba6740293e7b7b227829790686f2119c\r\nmay be very expensive for the gpu memory because  I need to store an additional copy of the parameters of the entire roberta model \r\nin here\r\n\"        self.gradient_accumulation = [tf.Variable(tf.zeros_like(v, dtype=tf.float32), \r\n                                                  trainable=False) for v in self.trainable_variables] \"\r\n\r\nThe below is my implementation , just  an imitation of the gradient accumulation of pytorch\uff0cbut this implementation is not valid because I found that the loss just did not decrese . I think it is a problem of the design of tf.gradienttape,when one batch size is over ,the tape did not record the gradients in last batch size . How can I resolve this problem?\r\n\r\n\r\n \r\n```\r\nclass Model2(tf.keras.Model): #cumsum the loss not the gradients\r\n    def __init__(self, n_gradients, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n        self.n_gradients = float(n_gradients)\r\n        self.n_acum_step = 0\r\n        #self.gradient_accumulation = [tf.Variable(tf.zeros_like(v, dtype=tf.float32), trainable=False) for v in self.trainable_variables]\r\n        self.total_loss= 0.00\r\n        #self.g=[]\r\n\r\n    def train_step(self, data):\r\n        self.n_acum_step+=1\r\n\r\n        x, y = data\r\n        # Gradient Tape\r\n        with tf.GradientTape() as tape:\r\n            y_pred = self(x, training=True)\r\n            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\r\n            self.total_loss += loss ##just cumsum the loss here\r\n        if self.n_acum_step >= self.n_gradients:\r\n          gradients = tape.gradient(self.total_loss/self.n_gradients, self.trainable_variables) # remember to average the loss\r\n          self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\r\n          self.total_loss=0.00 # reset the total loss\r\n          self.n_acum_step=0 ##reset the accumulation step\r\n\r\n          # update metrics\r\n        self.compiled_metrics.update_state(y, y_pred)\r\n        return {m.name: m.result() for m in self.metrics}\r\n\r\nmodel = Model2(n_gradients=16,inputs...,outputs...)\r\nmodel.fit....\r\n```\r\n", "comments": ["@wangbingnan136 \r\nIn order to expedite the trouble-shooting process here,could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose),and refer to this [thread](https://stackoverflow.com/questions/66472201/gradient-accumulation-with-custom-model-fit-in-tf-keras) .Please let us know if it helps?Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55478\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55478\">No</a>\n"]}, {"number": 55477, "title": "error: no matching function for call to 'partition_block_load_flags'", "body": "- OS Platform and Distribution: Gentoo\r\n- TensorFlow installed from source\r\n- TensorFlow version: 2.10.0\r\n- Python version: 3.10.4\r\n- Installed using: emerge\r\n- Bazel version: 5.1.1\r\n- GCC/Compiler version: 10.2.0\r\n- LLVM/Clang version: 14.0.1\r\n- CUDA/cuDNN version: 11.6.2\r\n- GPU model and memory: AMD Vega Frontier 16Gb\r\n- ROCM version: 5.1.1\r\n\r\nDoes not build from sources with errors:\r\n`bazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:760:5: error: no matching function for call to 'partition_block_load_flags'\r\n`\r\n\r\n`IUSE=\"rocm -cuda\" emerge sci-libs/tensorflow`\r\n\r\n[build.log](https://gist.github.com/raw/65bfdca10a815078fffe5e2aa00bc657)\r\n", "comments": ["@perestoronin, Thanks for reporting this issue. \r\nCould you provide the full error log or complete Traceback to investigate the root cause the error. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "@[gadagashwini](https://github.com/gadagashwini)\r\n\r\n```\r\nERROR: /var/tmp/portage/sci-libs/tensorflow-rocm-20220415/work/tensorflow-upstream-7b79fa425ada6494e9d451c2a82cef9999321499/tensorflow/core/kernels/image/BUILD:261:18: Compiling tensorflow/core/kernels/image/generate_box_proposals_op.cu.cc failed: (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_rocm/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer ... (remaining 167 arguments skipped)\r\nclang-14: warning: argument unused during compilation: '-fcuda-flush-denormals-to-zero' [-Wunused-command-line-argument]\r\nIn file included from tensorflow/core/kernels/image/generate_box_proposals_op.cu.cc:26:\r\nIn file included from ./tensorflow/core/kernels/gpu_prim.h:82:\r\nIn file included from bazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/hipcub/hipcub.hpp:36:\r\nIn file included from bazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/hipcub/backend/rocprim/hipcub.hpp:82:\r\nIn file included from bazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/hipcub/backend/rocprim/device/device_run_length_encode.hpp:35:\r\nIn file included from bazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/device_run_length_encode.hpp:37:\r\nIn file included from bazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/device_select.hpp:34:\r\nIn file included from bazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/device_partition.hpp:33:\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:760:5: error: no matching function for call to 'partition_block_load_flags'\r\n    partition_block_load_flags<\r\n    ^~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/device_partition.hpp:68:5: note: in instantiation of function template specialization 'rocprim::detail::partition_kernel_impl<rocprim::detail::select_method::flag, true, rocprim::detail::default_select_config<0, HIP_vector_type<float, 4>>, HIP_vector_type<float, 4> *, char *, HIP_vector_type<float, 4> *, int *, rocprim::empty_type, rocprim::detail::lookback_scan_state<unsigned int, true, true>, rocprim::empty_type>' requested here\r\n    partition_kernel_impl<SelectMethod, OnlySelected, Config>(\r\n    ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/device_partition.hpp:234:29: note: in instantiation of function template specialization 'rocprim::detail::partition_kernel<rocprim::detail::select_method::flag, true, rocprim::detail::default_select_config<0, HIP_vector_type<float, 4>>, HIP_vector_type<float, 4> *, char *, HIP_vector_type<float, 4> *, int *, rocprim::empty_type, rocprim::detail::lookback_scan_state<unsigned int, true, true>, rocprim::empty_type>' requested here\r\n            HIP_KERNEL_NAME(partition_kernel<\r\n                            ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/device_select.hpp:163:20: note: in instantiation of function template specialization 'rocprim::detail::partition_impl<rocprim::detail::select_method::flag, true, rocprim::default_config, unsigned int, HIP_vector_type<float, 4> *, char *, HIP_vector_type<float, 4> *, rocprim::empty_type, int *, rocprim::empty_type>' requested here\r\n    return detail::partition_impl<detail::select_method::flag, true, Config, offset_type>(\r\n                   ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/hipcub/backend/rocprim/device/device_select.hpp:61:27: note: in instantiation of function template specialization 'rocprim::select<rocprim::default_config, HIP_vector_type<float, 4> *, char *, HIP_vector_type<float, 4> *, int *>' requested here\r\n        return ::rocprim::select(\r\n                          ^\r\ntensorflow/core/kernels/image/generate_box_proposals_op.cu.cc:362:41: note: in instantiation of function template specialization 'hipcub::DeviceSelect::Flagged<HIP_vector_type<float, 4> *, char *, HIP_vector_type<float, 4> *, int *>' requested here\r\n        context, gpuprim::DeviceSelect::Flagged(\r\n                                        ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:169:6: note: candidate template ignored: requirement '(rocprim::detail::select_method)0 == select_method::predicate' was not satisfied [with SelectMethod = rocprim::detail::select_method::flag, BlockSize = 256, BlockLoadFlagsType = rocprim::block_load<bool, 256, 3, rocprim::block_load_method::block_load_transpose, 1, 1>, BlockDiscontinuityType = rocprim::block_discontinuity<HIP_vector_type<float, 4>, 256, 1, 1>]\r\nauto partition_block_load_flags(InputIterator /* block_predecessor */,\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:243:6: note: candidate template ignored: requirement '(rocprim::detail::select_method)0 == select_method::unique' was not satisfied [with SelectMethod = rocprim::detail::select_method::flag, BlockSize = 256, BlockLoadFlagsType = rocprim::block_load<bool, 256, 3, rocprim::block_load_method::block_load_transpose, 1, 1>, BlockDiscontinuityType = rocprim::block_discontinuity<HIP_vector_type<float, 4>, 256, 1, 1>]\r\nauto partition_block_load_flags(InputIterator block_predecessor,\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:119:6: note: candidate template ignored: could not match 'bool[ItemsPerThread]' against 'is_selected_type' (aka 'conditional<sizeof...(UnaryPredicates) == 1, bool[3], bool[1][3]>')\r\nauto partition_block_load_flags(InputIterator /* block_predecessor */,\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:344:6: note: candidate function template not viable: requires 12 arguments, but 11 were provided\r\nvoid partition_block_load_flags(InputIterator /*block_predecessor*/,\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:778:5: error: no matching function for call to 'convert_selected_to_indices'\r\n    convert_selected_to_indices(output_indices, is_selected);\r\n    ^~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:600:6: note: candidate template ignored: could not match 'bool[items_per_thread]' against 'is_selected_type' (aka 'conditional<sizeof...(UnaryPredicates) == 1, bool[3], bool[1][3]>')\r\nvoid convert_selected_to_indices(offset_type (&output_indices)[items_per_thread],\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:614:6: note: candidate template ignored: could not match 'uint2' (aka 'HIP_vector_type<unsigned int, 2>') against 'offset_type' (aka 'unsigned int')\r\nvoid convert_selected_to_indices(uint2 (&output_indices)[items_per_thread],\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:826:5: error: no matching function for call to 'partition_scatter'\r\n    partition_scatter<OnlySelected, block_size>(\r\n    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:457:6: note: candidate template ignored: could not match 'bool[ItemsPerThread]' against 'is_selected_type' (aka 'conditional<sizeof...(UnaryPredicates) == 1, bool[3], bool[1][3]>')\r\nauto partition_scatter(ValueType (&values)[ItemsPerThread],\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:524:6: note: candidate template ignored: could not match 'bool[2][ItemsPerThread]' against 'is_selected_type' (aka 'conditional<sizeof...(UnaryPredicates) == 1, bool[3], bool[1][3]>')\r\nvoid partition_scatter(ValueType (&values)[ItemsPerThread],\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:396:6: note: candidate template ignored: requirement '!true' was not satisfied [with OnlySelected = true, BlockSize = 256]\r\nauto partition_scatter(ValueType (&values)[ItemsPerThread],\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:760:5: error: no matching function for call to 'partition_block_load_flags'\r\n    partition_block_load_flags<\r\n    ^~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/device_partition.hpp:68:5: note: in instantiation of function template specialization 'rocprim::detail::partition_kernel_impl<rocprim::detail::select_method::flag, true, rocprim::detail::default_select_config<0, HIP_vector_type<float, 4>>, HIP_vector_type<float, 4> *, char *, HIP_vector_type<float, 4> *, int *, rocprim::empty_type, rocprim::detail::lookback_scan_state<unsigned int, false, true>, rocprim::empty_type>' requested here\r\n    partition_kernel_impl<SelectMethod, OnlySelected, Config>(\r\n    ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/device_partition.hpp:244:29: note: in instantiation of function template specialization 'rocprim::detail::partition_kernel<rocprim::detail::select_method::flag, true, rocprim::detail::default_select_config<0, HIP_vector_type<float, 4>>, HIP_vector_type<float, 4> *, char *, HIP_vector_type<float, 4> *, int *, rocprim::empty_type, rocprim::detail::lookback_scan_state<unsigned int, false, true>, rocprim::empty_type>' requested here\r\n            HIP_KERNEL_NAME(partition_kernel<\r\n                            ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/device_select.hpp:163:20: note: in instantiation of function template specialization 'rocprim::detail::partition_impl<rocprim::detail::select_method::flag, true, rocprim::default_config, unsigned int, HIP_vector_type<float, 4> *, char *, HIP_vector_type<float, 4> *, rocprim::empty_type, int *, rocprim::empty_type>' requested here\r\n    return detail::partition_impl<detail::select_method::flag, true, Config, offset_type>(\r\n                   ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/hipcub/backend/rocprim/device/device_select.hpp:61:27: note: in instantiation of function template specialization 'rocprim::select<rocprim::default_config, HIP_vector_type<float, 4> *, char *, HIP_vector_type<float, 4> *, int *>' requested here\r\n        return ::rocprim::select(\r\n                          ^\r\ntensorflow/core/kernels/image/generate_box_proposals_op.cu.cc:362:41: note: in instantiation of function template specialization 'hipcub::DeviceSelect::Flagged<HIP_vector_type<float, 4> *, char *, HIP_vector_type<float, 4> *, int *>' requested here\r\n        context, gpuprim::DeviceSelect::Flagged(\r\n                                        ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:169:6: note: candidate template ignored: requirement '(rocprim::detail::select_method)0 == select_method::predicate' was not satisfied [with SelectMethod = rocprim::detail::select_method::flag, BlockSize = 256, BlockLoadFlagsType = rocprim::block_load<bool, 256, 3, rocprim::block_load_method::block_load_transpose, 1, 1>, BlockDiscontinuityType = rocprim::block_discontinuity<HIP_vector_type<float, 4>, 256, 1, 1>]\r\nauto partition_block_load_flags(InputIterator /* block_predecessor */,\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:243:6: note: candidate template ignored: requirement '(rocprim::detail::select_method)0 == select_method::unique' was not satisfied [with SelectMethod = rocprim::detail::select_method::flag, BlockSize = 256, BlockLoadFlagsType = rocprim::block_load<bool, 256, 3, rocprim::block_load_method::block_load_transpose, 1, 1>, BlockDiscontinuityType = rocprim::block_discontinuity<HIP_vector_type<float, 4>, 256, 1, 1>]\r\nauto partition_block_load_flags(InputIterator block_predecessor,\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:119:6: note: candidate template ignored: could not match 'bool[ItemsPerThread]' against 'is_selected_type' (aka 'conditional<sizeof...(UnaryPredicates) == 1, bool[3], bool[1][3]>')\r\nauto partition_block_load_flags(InputIterator /* block_predecessor */,\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:344:6: note: candidate function template not viable: requires 12 arguments, but 11 were provided\r\nvoid partition_block_load_flags(InputIterator /*block_predecessor*/,\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:778:5: error: no matching function for call to 'convert_selected_to_indices'\r\n    convert_selected_to_indices(output_indices, is_selected);\r\n    ^~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:600:6: note: candidate template ignored: could not match 'bool[items_per_thread]' against 'is_selected_type' (aka 'conditional<sizeof...(UnaryPredicates) == 1, bool[3], bool[1][3]>')\r\nvoid convert_selected_to_indices(offset_type (&output_indices)[items_per_thread],\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:614:6: note: candidate template ignored: could not match 'uint2' (aka 'HIP_vector_type<unsigned int, 2>') against 'offset_type' (aka 'unsigned int')\r\nvoid convert_selected_to_indices(uint2 (&output_indices)[items_per_thread],\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:826:5: error: no matching function for call to 'partition_scatter'\r\n    partition_scatter<OnlySelected, block_size>(\r\n    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:457:6: note: candidate template ignored: could not match 'bool[ItemsPerThread]' against 'is_selected_type' (aka 'conditional<sizeof...(UnaryPredicates) == 1, bool[3], bool[1][3]>')\r\nauto partition_scatter(ValueType (&values)[ItemsPerThread],\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:524:6: note: candidate template ignored: could not match 'bool[2][ItemsPerThread]' against 'is_selected_type' (aka 'conditional<sizeof...(UnaryPredicates) == 1, bool[3], bool[1][3]>')\r\nvoid partition_scatter(ValueType (&values)[ItemsPerThread],\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:396:6: note: candidate template ignored: requirement '!true' was not satisfied [with OnlySelected = true, BlockSize = 256]\r\nauto partition_scatter(ValueType (&values)[ItemsPerThread],\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:760:5: error: no matching function for call to 'partition_block_load_flags'\r\n    partition_block_load_flags<\r\n    ^~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/device_partition.hpp:68:5: note: in instantiation of function template specialization 'rocprim::detail::partition_kernel_impl<rocprim::detail::select_method::flag, true, rocprim::detail::default_select_config<0, HIP_vector_type<float, 4>>, const HIP_vector_type<float, 4> *, char *, HIP_vector_type<float, 4> *, int *, rocprim::empty_type, rocprim::detail::lookback_scan_state<unsigned int, true, true>, rocprim::empty_type>' requested here\r\n    partition_kernel_impl<SelectMethod, OnlySelected, Config>(\r\n    ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/device_partition.hpp:234:29: note: in instantiation of function template specialization 'rocprim::detail::partition_kernel<rocprim::detail::select_method::flag, true, rocprim::detail::default_select_config<0, HIP_vector_type<float, 4>>, const HIP_vector_type<float, 4> *, char *, HIP_vector_type<float, 4> *, int *, rocprim::empty_type, rocprim::detail::lookback_scan_state<unsigned int, true, true>, rocprim::empty_type>' requested here\r\n            HIP_KERNEL_NAME(partition_kernel<\r\n                            ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/device_select.hpp:163:20: note: in instantiation of function template specialization 'rocprim::detail::partition_impl<rocprim::detail::select_method::flag, true, rocprim::default_config, unsigned int, const HIP_vector_type<float, 4> *, char *, HIP_vector_type<float, 4> *, rocprim::empty_type, int *, rocprim::empty_type>' requested here\r\n    return detail::partition_impl<detail::select_method::flag, true, Config, offset_type>(\r\n                   ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/hipcub/backend/rocprim/device/device_select.hpp:61:27: note: in instantiation of function template specialization 'rocprim::select<rocprim::default_config, const HIP_vector_type<float, 4> *, char *, HIP_vector_type<float, 4> *, int *>' requested here\r\n        return ::rocprim::select(\r\n                          ^\r\ntensorflow/core/kernels/image/generate_box_proposals_op.cu.cc:495:43: note: in instantiation of function template specialization 'hipcub::DeviceSelect::Flagged<const HIP_vector_type<float, 4> *, char *, HIP_vector_type<float, 4> *, int *>' requested here\r\n          context, gpuprim::DeviceSelect::Flagged(\r\n                                          ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:169:6: note: candidate template ignored: requirement '(rocprim::detail::select_method)0 == select_method::predicate' was not satisfied [with SelectMethod = rocprim::detail::select_method::flag, BlockSize = 256, BlockLoadFlagsType = rocprim::block_load<bool, 256, 3, rocprim::block_load_method::block_load_transpose, 1, 1>, BlockDiscontinuityType = rocprim::block_discontinuity<HIP_vector_type<float, 4>, 256, 1, 1>]\r\nauto partition_block_load_flags(InputIterator /* block_predecessor */,\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:243:6: note: candidate template ignored: requirement '(rocprim::detail::select_method)0 == select_method::unique' was not satisfied [with SelectMethod = rocprim::detail::select_method::flag, BlockSize = 256, BlockLoadFlagsType = rocprim::block_load<bool, 256, 3, rocprim::block_load_method::block_load_transpose, 1, 1>, BlockDiscontinuityType = rocprim::block_discontinuity<HIP_vector_type<float, 4>, 256, 1, 1>]\r\nauto partition_block_load_flags(InputIterator block_predecessor,\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:119:6: note: candidate template ignored: could not match 'bool[ItemsPerThread]' against 'is_selected_type' (aka 'conditional<sizeof...(UnaryPredicates) == 1, bool[3], bool[1][3]>')\r\nauto partition_block_load_flags(InputIterator /* block_predecessor */,\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:344:6: note: candidate function template not viable: requires 12 arguments, but 11 were provided\r\nvoid partition_block_load_flags(InputIterator /*block_predecessor*/,\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:778:5: error: no matching function for call to 'convert_selected_to_indices'\r\n    convert_selected_to_indices(output_indices, is_selected);\r\n    ^~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:600:6: note: candidate template ignored: could not match 'bool[items_per_thread]' against 'is_selected_type' (aka 'conditional<sizeof...(UnaryPredicates) == 1, bool[3], bool[1][3]>')\r\nvoid convert_selected_to_indices(offset_type (&output_indices)[items_per_thread],\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:614:6: note: candidate template ignored: could not match 'uint2' (aka 'HIP_vector_type<unsigned int, 2>') against 'offset_type' (aka 'unsigned int')\r\nvoid convert_selected_to_indices(uint2 (&output_indices)[items_per_thread],\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:826:5: error: no matching function for call to 'partition_scatter'\r\n    partition_scatter<OnlySelected, block_size>(\r\n    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:457:6: note: candidate template ignored: could not match 'bool[ItemsPerThread]' against 'is_selected_type' (aka 'conditional<sizeof...(UnaryPredicates) == 1, bool[3], bool[1][3]>')\r\nauto partition_scatter(ValueType (&values)[ItemsPerThread],\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:524:6: note: candidate template ignored: could not match 'bool[2][ItemsPerThread]' against 'is_selected_type' (aka 'conditional<sizeof...(UnaryPredicates) == 1, bool[3], bool[1][3]>')\r\nvoid partition_scatter(ValueType (&values)[ItemsPerThread],\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:396:6: note: candidate template ignored: requirement '!true' was not satisfied [with OnlySelected = true, BlockSize = 256]\r\nauto partition_scatter(ValueType (&values)[ItemsPerThread],\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:760:5: error: no matching function for call to 'partition_block_load_flags'\r\n    partition_block_load_flags<\r\n    ^~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/device_partition.hpp:68:5: note: in instantiation of function template specialization 'rocprim::detail::partition_kernel_impl<rocprim::detail::select_method::flag, true, rocprim::detail::default_select_config<0, HIP_vector_type<float, 4>>, const HIP_vector_type<float, 4> *, char *, HIP_vector_type<float, 4> *, int *, rocprim::empty_type, rocprim::detail::lookback_scan_state<unsigned int, false, true>, rocprim::empty_type>' requested here\r\n    partition_kernel_impl<SelectMethod, OnlySelected, Config>(\r\n    ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/device_partition.hpp:244:29: note: in instantiation of function template specialization 'rocprim::detail::partition_kernel<rocprim::detail::select_method::flag, true, rocprim::detail::default_select_config<0, HIP_vector_type<float, 4>>, const HIP_vector_type<float, 4> *, char *, HIP_vector_type<float, 4> *, int *, rocprim::empty_type, rocprim::detail::lookback_scan_state<unsigned int, false, true>, rocprim::empty_type>' requested here\r\n            HIP_KERNEL_NAME(partition_kernel<\r\n                            ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/device_select.hpp:163:20: note: in instantiation of function template specialization 'rocprim::detail::partition_impl<rocprim::detail::select_method::flag, true, rocprim::default_config, unsigned int, const HIP_vector_type<float, 4> *, char *, HIP_vector_type<float, 4> *, rocprim::empty_type, int *, rocprim::empty_type>' requested here\r\n    return detail::partition_impl<detail::select_method::flag, true, Config, offset_type>(\r\n                   ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/hipcub/backend/rocprim/device/device_select.hpp:61:27: note: in instantiation of function template specialization 'rocprim::select<rocprim::default_config, const HIP_vector_type<float, 4> *, char *, HIP_vector_type<float, 4> *, int *>' requested here\r\n        return ::rocprim::select(\r\n                          ^\r\ntensorflow/core/kernels/image/generate_box_proposals_op.cu.cc:495:43: note: in instantiation of function template specialization 'hipcub::DeviceSelect::Flagged<const HIP_vector_type<float, 4> *, char *, HIP_vector_type<float, 4> *, int *>' requested here\r\n          context, gpuprim::DeviceSelect::Flagged(\r\n                                          ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:169:6: note: candidate template ignored: requirement '(rocprim::detail::select_method)0 == select_method::predicate' was not satisfied [with SelectMethod = rocprim::detail::select_method::flag, BlockSize = 256, BlockLoadFlagsType = rocprim::block_load<bool, 256, 3, rocprim::block_load_method::block_load_transpose, 1, 1>, BlockDiscontinuityType = rocprim::block_discontinuity<HIP_vector_type<float, 4>, 256, 1, 1>]\r\nauto partition_block_load_flags(InputIterator /* block_predecessor */,\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:243:6: note: candidate template ignored: requirement '(rocprim::detail::select_method)0 == select_method::unique' was not satisfied [with SelectMethod = rocprim::detail::select_method::flag, BlockSize = 256, BlockLoadFlagsType = rocprim::block_load<bool, 256, 3, rocprim::block_load_method::block_load_transpose, 1, 1>, BlockDiscontinuityType = rocprim::block_discontinuity<HIP_vector_type<float, 4>, 256, 1, 1>]\r\nauto partition_block_load_flags(InputIterator block_predecessor,\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:119:6: note: candidate template ignored: could not match 'bool[ItemsPerThread]' against 'is_selected_type' (aka 'conditional<sizeof...(UnaryPredicates) == 1, bool[3], bool[1][3]>')\r\nauto partition_block_load_flags(InputIterator /* block_predecessor */,\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:344:6: note: candidate function template not viable: requires 12 arguments, but 11 were provided\r\nvoid partition_block_load_flags(InputIterator /*block_predecessor*/,\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:778:5: error: no matching function for call to 'convert_selected_to_indices'\r\n    convert_selected_to_indices(output_indices, is_selected);\r\n    ^~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:600:6: note: candidate template ignored: could not match 'bool[items_per_thread]' against 'is_selected_type' (aka 'conditional<sizeof...(UnaryPredicates) == 1, bool[3], bool[1][3]>')\r\nvoid convert_selected_to_indices(offset_type (&output_indices)[items_per_thread],\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:614:6: note: candidate template ignored: could not match 'uint2' (aka 'HIP_vector_type<unsigned int, 2>') against 'offset_type' (aka 'unsigned int')\r\nvoid convert_selected_to_indices(uint2 (&output_indices)[items_per_thread],\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:826:5: error: no matching function for call to 'partition_scatter'\r\n    partition_scatter<OnlySelected, block_size>(\r\n    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:457:6: note: candidate template ignored: could not match 'bool[ItemsPerThread]' against 'is_selected_type' (aka 'conditional<sizeof...(UnaryPredicates) == 1, bool[3], bool[1][3]>')\r\nauto partition_scatter(ValueType (&values)[ItemsPerThread],\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:524:6: note: candidate template ignored: could not match 'bool[2][ItemsPerThread]' against 'is_selected_type' (aka 'conditional<sizeof...(UnaryPredicates) == 1, bool[3], bool[1][3]>')\r\nvoid partition_scatter(ValueType (&values)[ItemsPerThread],\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:396:6: note: candidate template ignored: requirement '!true' was not satisfied [with OnlySelected = true, BlockSize = 256]\r\nauto partition_scatter(ValueType (&values)[ItemsPerThread],\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:760:5: error: no matching function for call to 'partition_block_load_flags'\r\n    partition_block_load_flags<\r\n    ^~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/device_partition.hpp:68:5: note: in instantiation of function template specialization 'rocprim::detail::partition_kernel_impl<rocprim::detail::select_method::flag, true, rocprim::detail::default_select_config<0, float>, const float *, char *, float *, int *, rocprim::empty_type, rocprim::detail::lookback_scan_state<unsigned int, true, true>, rocprim::empty_type>' requested here\r\n    partition_kernel_impl<SelectMethod, OnlySelected, Config>(\r\n    ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/device_partition.hpp:234:29: note: in instantiation of function template specialization 'rocprim::detail::partition_kernel<rocprim::detail::select_method::flag, true, rocprim::detail::default_select_config<0, float>, const float *, char *, float *, int *, rocprim::empty_type, rocprim::detail::lookback_scan_state<unsigned int, true, true>, rocprim::empty_type>' requested here\r\n            HIP_KERNEL_NAME(partition_kernel<\r\n                            ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/device_select.hpp:163:20: note: in instantiation of function template specialization 'rocprim::detail::partition_impl<rocprim::detail::select_method::flag, true, rocprim::default_config, unsigned int, const float *, char *, float *, rocprim::empty_type, int *, rocprim::empty_type>' requested here\r\n    return detail::partition_impl<detail::select_method::flag, true, Config, offset_type>(\r\n                   ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/hipcub/backend/rocprim/device/device_select.hpp:61:27: note: in instantiation of function template specialization 'rocprim::select<rocprim::default_config, const float *, char *, float *, int *>' requested here\r\n        return ::rocprim::select(\r\n                          ^\r\ntensorflow/core/kernels/image/generate_box_proposals_op.cu.cc:503:34: note: in instantiation of function template specialization 'hipcub::DeviceSelect::Flagged<const float *, char *, float *, int *>' requested here\r\n          gpuprim::DeviceSelect::Flagged(\r\n                                 ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:169:6: note: candidate template ignored: requirement '(rocprim::detail::select_method)0 == select_method::predicate' was not satisfied [with SelectMethod = rocprim::detail::select_method::flag, BlockSize = 256, BlockLoadFlagsType = rocprim::block_load<bool, 256, 13, rocprim::block_load_method::block_load_transpose, 1, 1>, BlockDiscontinuityType = rocprim::block_discontinuity<float, 256, 1, 1>]\r\nauto partition_block_load_flags(InputIterator /* block_predecessor */,\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:243:6: note: candidate template ignored: requirement '(rocprim::detail::select_method)0 == select_method::unique' was not satisfied [with SelectMethod = rocprim::detail::select_method::flag, BlockSize = 256, BlockLoadFlagsType = rocprim::block_load<bool, 256, 13, rocprim::block_load_method::block_load_transpose, 1, 1>, BlockDiscontinuityType = rocprim::block_discontinuity<float, 256, 1, 1>]\r\nauto partition_block_load_flags(InputIterator block_predecessor,\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:119:6: note: candidate template ignored: could not match 'bool[ItemsPerThread]' against 'is_selected_type' (aka 'conditional<sizeof...(UnaryPredicates) == 1, bool[13], bool[1][13]>')\r\nauto partition_block_load_flags(InputIterator /* block_predecessor */,\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:344:6: note: candidate function template not viable: requires 12 arguments, but 11 were provided\r\nvoid partition_block_load_flags(InputIterator /*block_predecessor*/,\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:778:5: error: no matching function for call to 'convert_selected_to_indices'\r\n    convert_selected_to_indices(output_indices, is_selected);\r\n    ^~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:600:6: note: candidate template ignored: could not match 'bool[items_per_thread]' against 'is_selected_type' (aka 'conditional<sizeof...(UnaryPredicates) == 1, bool[13], bool[1][13]>')\r\nvoid convert_selected_to_indices(offset_type (&output_indices)[items_per_thread],\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:614:6: note: candidate template ignored: could not match 'uint2' (aka 'HIP_vector_type<unsigned int, 2>') against 'offset_type' (aka 'unsigned int')\r\nvoid convert_selected_to_indices(uint2 (&output_indices)[items_per_thread],\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:826:5: error: no matching function for call to 'partition_scatter'\r\n    partition_scatter<OnlySelected, block_size>(\r\n    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:457:6: note: candidate template ignored: could not match 'bool[ItemsPerThread]' against 'is_selected_type' (aka 'conditional<sizeof...(UnaryPredicates) == 1, bool[13], bool[1][13]>')\r\nauto partition_scatter(ValueType (&values)[ItemsPerThread],\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:524:6: note: candidate template ignored: could not match 'bool[2][ItemsPerThread]' against 'is_selected_type' (aka 'conditional<sizeof...(UnaryPredicates) == 1, bool[13], bool[1][13]>')\r\nvoid partition_scatter(ValueType (&values)[ItemsPerThread],\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:396:6: note: candidate template ignored: requirement '!true' was not satisfied [with OnlySelected = true, BlockSize = 256]\r\nauto partition_scatter(ValueType (&values)[ItemsPerThread],\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:760:5: error: no matching function for call to 'partition_block_load_flags'\r\n    partition_block_load_flags<\r\n    ^~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/device_partition.hpp:68:5: note: in instantiation of function template specialization 'rocprim::detail::partition_kernel_impl<rocprim::detail::select_method::flag, true, rocprim::detail::default_select_config<0, float>, const float *, char *, float *, int *, rocprim::empty_type, rocprim::detail::lookback_scan_state<unsigned int, false, true>, rocprim::empty_type>' requested here\r\n    partition_kernel_impl<SelectMethod, OnlySelected, Config>(\r\n    ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/device_partition.hpp:244:29: note: in instantiation of function template specialization 'rocprim::detail::partition_kernel<rocprim::detail::select_method::flag, true, rocprim::detail::default_select_config<0, float>, const float *, char *, float *, int *, rocprim::empty_type, rocprim::detail::lookback_scan_state<unsigned int, false, true>, rocprim::empty_type>' requested here\r\n            HIP_KERNEL_NAME(partition_kernel<\r\n                            ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/device_select.hpp:163:20: note: in instantiation of function template specialization 'rocprim::detail::partition_impl<rocprim::detail::select_method::flag, true, rocprim::default_config, unsigned int, const float *, char *, float *, rocprim::empty_type, int *, rocprim::empty_type>' requested here\r\n    return detail::partition_impl<detail::select_method::flag, true, Config, offset_type>(\r\n                   ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/hipcub/backend/rocprim/device/device_select.hpp:61:27: note: in instantiation of function template specialization 'rocprim::select<rocprim::default_config, const float *, char *, float *, int *>' requested here\r\n        return ::rocprim::select(\r\n                          ^\r\ntensorflow/core/kernels/image/generate_box_proposals_op.cu.cc:503:34: note: in instantiation of function template specialization 'hipcub::DeviceSelect::Flagged<const float *, char *, float *, int *>' requested here\r\n          gpuprim::DeviceSelect::Flagged(\r\n                                 ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:169:6: note: candidate template ignored: requirement '(rocprim::detail::select_method)0 == select_method::predicate' was not satisfied [with SelectMethod = rocprim::detail::select_method::flag, BlockSize = 256, BlockLoadFlagsType = rocprim::block_load<bool, 256, 13, rocprim::block_load_method::block_load_transpose, 1, 1>, BlockDiscontinuityType = rocprim::block_discontinuity<float, 256, 1, 1>]\r\nauto partition_block_load_flags(InputIterator /* block_predecessor */,\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:243:6: note: candidate template ignored: requirement '(rocprim::detail::select_method)0 == select_method::unique' was not satisfied [with SelectMethod = rocprim::detail::select_method::flag, BlockSize = 256, BlockLoadFlagsType = rocprim::block_load<bool, 256, 13, rocprim::block_load_method::block_load_transpose, 1, 1>, BlockDiscontinuityType = rocprim::block_discontinuity<float, 256, 1, 1>]\r\nauto partition_block_load_flags(InputIterator block_predecessor,\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:119:6: note: candidate template ignored: could not match 'bool[ItemsPerThread]' against 'is_selected_type' (aka 'conditional<sizeof...(UnaryPredicates) == 1, bool[13], bool[1][13]>')\r\nauto partition_block_load_flags(InputIterator /* block_predecessor */,\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:344:6: note: candidate function template not viable: requires 12 arguments, but 11 were provided\r\nvoid partition_block_load_flags(InputIterator /*block_predecessor*/,\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:778:5: error: no matching function for call to 'convert_selected_to_indices'\r\n    convert_selected_to_indices(output_indices, is_selected);\r\n    ^~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:600:6: note: candidate template ignored: could not match 'bool[items_per_thread]' against 'is_selected_type' (aka 'conditional<sizeof...(UnaryPredicates) == 1, bool[13], bool[1][13]>')\r\nvoid convert_selected_to_indices(offset_type (&output_indices)[items_per_thread],\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:614:6: note: candidate template ignored: could not match 'uint2' (aka 'HIP_vector_type<unsigned int, 2>') against 'offset_type' (aka 'unsigned int')\r\nvoid convert_selected_to_indices(uint2 (&output_indices)[items_per_thread],\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:826:5: error: no matching function for call to 'partition_scatter'\r\n    partition_scatter<OnlySelected, block_size>(\r\n    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:457:6: note: candidate template ignored: could not match 'bool[ItemsPerThread]' against 'is_selected_type' (aka 'conditional<sizeof...(UnaryPredicates) == 1, bool[13], bool[1][13]>')\r\nauto partition_scatter(ValueType (&values)[ItemsPerThread],\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:524:6: note: candidate template ignored: could not match 'bool[2][ItemsPerThread]' against 'is_selected_type' (aka 'conditional<sizeof...(UnaryPredicates) == 1, bool[13], bool[1][13]>')\r\nvoid partition_scatter(ValueType (&values)[ItemsPerThread],\r\n     ^\r\nbazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:396:6: note: candidate template ignored: requirement '!true' was not satisfied [with OnlySelected = true, BlockSize = 256]\r\nauto partition_scatter(ValueType (&values)[ItemsPerThread],\r\n     ^\r\n18 errors generated when compiling for gfx900.\r\nINFO: Elapsed time: 540.462s, Critical Path: 126.61s\r\nINFO: 5460 processes: 791 internal, 4669 local.\r\nFAILED: Build did NOT complete successfully\r\n```", "This issue resolved after apply all three patches:\r\n1. https://github.com/ROCmSoftwarePlatform/rocRAND/pull/257\r\n2. https://github.com/ROCmSoftwarePlatform/hipRAND/pull/11\r\n3. [tf-hip_hcc.patch](https://gist.github.com/raw/e579227015a82e51ac384b93bc300fb5)\r\n```\r\n--- a/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_rocm.tpl\r\n+++ b/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_rocm.tpl\r\n@@ -257,7 +257,7 @@ def main():\r\n                                if not flag.startswith(('--rocm_log'))]\r\n \r\n     # XXX: SE codes need to be built with gcc, but need this macro defined\r\n-    cpu_compiler_flags.append(\"-D__HIP_PLATFORM_HCC__\")\r\n+    cpu_compiler_flags.append(\"-D__HIP_PLATFORM_AMD__\")\r\n     if VERBOSE: print(' '.join([CPU_COMPILER] + cpu_compiler_flags))\r\n     return subprocess.call([CPU_COMPILER] + cpu_compiler_flags)\r\n \r\n--- a/third_party/gpus/rocm_configure.bzl\r\n+++ b/third_party/gpus/rocm_configure.bzl\r\n@@ -724,7 +724,7 @@ def _create_local_rocm_repository(repository_ctx):\r\n \r\n     rocm_defines[\"%{unfiltered_compile_flags}\"] = to_list_of_strings([\r\n         \"-DTENSORFLOW_USE_ROCM=1\",\r\n-        \"-D__HIP_PLATFORM_HCC__\",\r\n+        \"-D__HIP_PLATFORM_AMD__\",\r\n         \"-DEIGEN_USE_HIP\",\r\n     ])\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55477\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55477\">No</a>\n"]}, {"number": 55475, "title": "tf.map_fn on RaggedTensors crash during gradient computation on a GPU", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **yes**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Colab**\r\n- TensorFlow installed from (source or binary): **binary**\r\n- TensorFlow version (use command below): **2.8**\r\n- Python version: **3.7**\r\n\r\n**Describe the current behavior**\r\n\r\nWhen some loss (`tf.losses.SparseCategoricalCrossentropy`, `tf.losses.CategoricalCrossentropy`, `tf.losses.BinaryCrossentropy`, or `tf.losses.MeanSquaredError`) is used on Ragged tensors, which is computed via a `tf.map_fn` on a `RaggedTensor`, that the gradient computation on a GPU crashes with\r\n```\r\nNode: 'Adam/gradients/zeros_like_2'\r\n2 root error(s) found.\r\n  (0) INTERNAL:  No unary variant unary_op function found for op ZEROS_LIKE Variant type_name: RaggedTensorVariant for device type: GPU\r\n\t [[{{node Adam/gradients/zeros_like_2}}]]\r\n\t [[binary_crossentropy/map/while/loop_body_control/_124/_67]]\r\n  (1) INTERNAL:  No unary variant unary_op function found for op ZEROS_LIKE Variant type_name: RaggedTensorVariant for device type: GPU\r\n\t [[{{node Adam/gradients/zeros_like_2}}]]\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_train_function_16690]\r\n```\r\n\r\nThe computation does not crash on a CPU and it does not crash when `tf.function`s are executed eagerly.\r\n\r\nAlso, if the `tf.map_fn` is circumvented by using the following argument to compile\r\n```python\r\n  loss=lambda yt, yp: tf.losses.BinaryCrossentropy()(yt. values, yp.values)\r\n```\r\nit works on GPU without a crash.\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\nThe code does not crash on a GPU.\r\n\r\n- Do you want to contribute a PR? (yes/no): **no**\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nA simple Colab reproducing the error is here: https://colab.research.google.com/drive/1OELAhvpQHhaz3sOYabf4SdBqKlQCjNjs?usp=sharing\r\n\r\n**Other info / logs**\r\n\r\nThe `map_fn` used is here: https://github.com/keras-team/keras/blob/2db5acf3e3c5904b014cb409d3c514bef44f9640/keras/losses.py#L1408 ", "comments": ["Note that I also opened an issue in the Keras repository https://github.com/keras-team/keras/issues/16354 , where we discuss whether we should avoid the `tf.map_fn` on the RaggedTensors, because it can probably be avoided -- the metrics with ragged tensors take a different approach, and instead of a ragged map, they use `flat_values`, see https://github.com/keras-team/keras/blob/2db5acf3e3c5904b014cb409d3c514bef44f9640/keras/utils/metrics_utils.py#L800 .", "@chunduriv I was able to reproduce the issue on colab using TF v2.8.0 ,tf-nightly on both [gpu](https://colab.research.google.com/gist/sushreebarsa/014fdaf99d8e375ce618c3c5aee9d150/untitled612.ipynb#scrollTo=cDbvjfYIh2Nu) and [cpu](https://colab.research.google.com/gist/sushreebarsa/22c50fcc02dd280c38bdfffc5c3f2235/55475-cpu.ipynb) , please find the attached gists for reference.Thanks!", "Oh, I was just pointed to me (by djoshea) that this is a duplicate of 46635, so closing.", "Closing as a duplicate of #46635 .", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55475\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55475\">No</a>\n"]}, {"number": 55473, "title": "when installing tf-nightly, pip's dependency resolver, tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0, but you have 2.10.0", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04.4\r\n- pip version: 22.0.4\r\n- TensorFlow installed from (source or binary): pip install tensorflow\r\n- TensorFlow version: 2.8.0\r\n- Python version: 3.9.11\r\n- Installed using virtualenv? pip? conda?: pip\r\n\r\n**Describe the problem**\r\nI follow the [tensorflow installation instruction](https://www.tensorflow.org/install),.\r\nWhen I process this: `pip install tf-nightly`, it says:\r\n\"\r\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\ntensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, but you have tf-estimator-nightly 2.10.0.dev2022040208 which is incompatible.\r\n\"\r\n\r\nDo I need to solve this and how to solve this?", "comments": ["@Raynchowkw ,\r\nI haven't found any issue/warning while using  **`pip install tf-nightly`**.Please find the gist [here](https://colab.research.google.com/gist/tilakrayal/3692e4eada6fe58a625a9d6ef07834fa/untitled288.ipynb).\r\nI request you, please try to restart/reboot the session after executing the nightly command.It disappears the warning.Also as tf-nightly is the unstable version, please try to test the code in stable version2.8.Thanks!", "@Raynchowkw - Also looks like you are installing tf-nightly in an environment that already has tensorflow version 2.8.  Please create a new environment for tf-nightly and keep tensorflow v2.8 and tf-nightly in different environments.", "Thanks.\r\nI just realize they are different version of tensorflow. I just keep the tensorflow 2.8 and it runs with no problems now.\r\nThanks a lot.", "@Raynchowkw ,\r\nGlad the suggestion worked to resolve the issue,Can you please feel free to move this to closed status.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55473\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55473\">No</a>\n", "Sure.\n\nOn Tue, Apr 5, 2022 at 7:48 PM tilakrayal ***@***.***> wrote:\n\n> @Raynchowkw\n> <https://urldefense.com/v3/__https://github.com/Raynchowkw__;!!IKRxdwAv5BmarQ!MweuSLg99bgSvbzAHh8IG5U48ld-PAUplXIjlnU9R-S5oeFGzOkmf9S0NaozEQA$>\n> ,\n> Glad the suggestion worked to resolve the issue,Can you please feel free\n> to move this to closed status.Thanks!\n>\n> \u2014\n> Reply to this email directly, view it on GitHub\n> <https://urldefense.com/v3/__https://github.com/tensorflow/tensorflow/issues/55473*issuecomment-1089704914__;Iw!!IKRxdwAv5BmarQ!MweuSLg99bgSvbzAHh8IG5U48ld-PAUplXIjlnU9R-S5oeFGzOkmf9S0puJUf3c$>,\n> or unsubscribe\n> <https://urldefense.com/v3/__https://github.com/notifications/unsubscribe-auth/ANTC4GKMFKPDUMWV3SQP65DVDT3PNANCNFSM5SMSSZLQ__;!!IKRxdwAv5BmarQ!MweuSLg99bgSvbzAHh8IG5U48ld-PAUplXIjlnU9R-S5oeFGzOkmf9S0_z8Je4s$>\n> .\n> You are receiving this because you were mentioned.Message ID:\n> ***@***.***>\n>\n"]}, {"number": 55472, "title": "tf.image.extract_patches default value for areas outside the input ", "body": "Running tf.image.extract_patches by the \"Same\" padding leads to zeros for areas outside the input. There is no way to change the default value and it is best to have this as another parameter for this function. This background label should be always zero; otherwise, this function mess up the labels.", "comments": ["@mehran66 \r\nCan you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new?assignees=&labels=type%3Afeature&template=30-feature-request.md) and also can you  please specify the use cases for this feature? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 55470, "title": "Rename pylintrc file back to \"pylintrc\".", "body": "It is currently named \"Pylint revert W + TODO for outdated chwcks\".\r\nLooks like it has been mistakenly renamed in 801aa9fcc2d7aeb0524a4bff72b16dbf370b53e8.", "comments": ["Duplicate of #55464 ."]}, {"number": 55469, "title": "[ROCm] Fix for BEF executable test failure for //tensorflow/compiler/xla/tes\u2026", "body": "\u2026ts:matrix_ops_simple_test_gpu.\r\n\r\n/cc @chsigg @hanbinyoon ", "comments": ["@rsanthanam-amd  Can you please address Ubuntu Sanity errors? Thank you!", "> @rsanthanam-amd Can you please address Ubuntu Sanity errors? Thank you!\r\n\r\nDone.", "Seems auto-merge is not happening but the changes are merged into master now, so we can close this. Thank you for the PR."]}, {"number": 55468, "title": "UnimplementedError  DNN library is not found when running a Conv1D layer", "body": "Windows 10\r\ncudnn 8.1.1.33, CUDA 11.2.2_461.33\r\nNvidia driver 11.2.109\r\ntensorflow 2.8.0\r\nPython 3.9.12\r\nAnaconda environment\r\nNvidia GeForece GPU RTX 3060,  16GB RAM, 512GB SSD\r\n\r\n**UnimplementedError  Node: 'sequential/conv1d/Conv1D'\r\nDNN library is not found.**\r\n\r\n```\r\n# Parameters\r\nembedding_dim = 16\r\nfilters = 128\r\nkernel_size = 5\r\ndense_dim = 6\r\n\r\n# Model Definition with Conv1D\r\nmodel_conv = tf.keras.Sequential([\r\n    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\r\n    tf.keras.layers.Conv1D(filters, kernel_size, activation='relu'),\r\n    tf.keras.layers.GlobalMaxPooling1D(),\r\n    tf.keras.layers.Dense(dense_dim, activation='relu'),\r\n    tf.keras.layers.Dense(1, activation='sigmoid')\r\n])\r\n\r\n# Set the training parameters\r\nmodel_conv.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\r\n\r\n# Print the model summary\r\nmodel_conv.summary()\r\n```\r\n\r\nModel: \"sequential\"\r\n```\r\n_________________________________________________________________\r\n Layer (type)                Output Shape              Param #   \r\n=================================================================\r\n embedding (Embedding)       (None, 120, 16)           160000    \r\n                                                                 \r\n conv1d (Conv1D)             (None, 116, 128)          10368     \r\n                                                                 \r\n global_max_pooling1d (Globa  (None, 128)              0         \r\n lMaxPooling1D)                                                  \r\n                                                                 \r\n dense (Dense)               (None, 6)                 774       \r\n                                                                 \r\n dense_1 (Dense)             (None, 1)                 7         \r\n                                                                 \r\n=================================================================\r\n```\r\n```\r\nTotal params: 171,149\r\nTrainable params: 171,149\r\nNon-trainable params: 0\r\n\r\nNUM_EPOCHS = 10\r\n\r\n# Train the model\r\nhistory_conv = model_conv.fit(training_padded, training_labels, epochs=NUM_EPOCHS, validation_data=(testing_padded, testing_labels))\r\n\r\n```\r\n\r\n\r\nEpoch 1/10\r\n---------------------------------------------------------------------------\r\nUnimplementedError                        Traceback (most recent call last)\r\nInput In [6], in <cell line: 4>()\r\n      1 NUM_EPOCHS = 10\r\n      3 # Train the model\r\n----> 4 history_conv = model_conv.fit(training_padded, training_labels, epochs=NUM_EPOCHS, validation_data=(testing_padded, testing_labels))\r\n\r\nFile ~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67, in filter_traceback.<locals>.error_handler(*args, **kwargs)\r\n     65 except Exception as e:  # pylint: disable=broad-except\r\n     66   filtered_tb = _process_traceback_frames(e.__traceback__)\r\n---> 67   raise e.with_traceback(filtered_tb) from None\r\n     68 finally:\r\n     69   del filtered_tb\r\n\r\nFile ~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     52 try:\r\n     53   ctx.ensure_initialized()\r\n---> 54   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n     55                                       inputs, attrs, num_outputs)\r\n     56 except core._NotOkStatusException as e:\r\n     57   if name is not None:\r\n\r\nUnimplementedError: Graph execution error:\r\n\r\nDetected at node 'sequential/conv1d/Conv1D' defined at (most recent call last):\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\runpy.py\", line 197, in _run_module_as_main\r\n      return _run_code(code, main_globals, None,\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\runpy.py\", line 87, in _run_code\r\n      exec(code, run_globals)\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\r\n      app.launch_new_instance()\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\r\n      app.start()\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\r\n      self.io_loop.start()\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\r\n      self.asyncio_loop.run_forever()\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\asyncio\\base_events.py\", line 601, in run_forever\r\n      self._run_once()\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\r\n      handle._run()\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\asyncio\\events.py\", line 80, in _run\r\n      self._context.run(self._callback, *self._args)\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 473, in dispatch_queue\r\n      await self.process_one()\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 462, in process_one\r\n      await dispatch(*args)\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 369, in dispatch_shell\r\n      await result\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 664, in execute_request\r\n      reply_content = await reply_content\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 355, in do_execute\r\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\r\n      return super().run_cell(*args, **kwargs)\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2863, in run_cell\r\n      result = self._run_cell(\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in _run_cell\r\n      return runner(coro)\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\r\n      coro.send(None)\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in run_cell_async\r\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3309, in run_ast_nodes\r\n      if await self.run_code(code, result, async_=asy):\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3369, in run_code\r\n      exec(code_obj, self.user_global_ns, self.user_ns)\r\n    File \"C:\\Users\\me\\AppData\\Local\\Temp\\ipykernel_9748\\331718196.py\", line 4, in <cell line: 4>\r\n      history_conv = model_conv.fit(training_padded, training_labels, epochs=NUM_EPOCHS, validation_data=(testing_padded, testing_labels))\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\r\n      return fn(*args, **kwargs)\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\r\n      tmp_logs = self.train_function(iterator)\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\r\n      return step_function(self, iterator)\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\r\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\r\n      outputs = model.train_step(data)\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\r\n      y_pred = self(x, training=True)\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\r\n      return fn(*args, **kwargs)\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\r\n      outputs = call_fn(inputs, *args, **kwargs)\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\r\n      return fn(*args, **kwargs)\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\sequential.py\", line 374, in call\r\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\r\n      return self._run_internal_graph(\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\r\n      outputs = node.layer(*args, **kwargs)\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\r\n      return fn(*args, **kwargs)\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\r\n      outputs = call_fn(inputs, *args, **kwargs)\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\r\n      return fn(*args, **kwargs)\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 248, in call\r\n      outputs = self.convolution_op(inputs, self.kernel)\r\n    File \"C:\\Users\\me\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 233, in convolution_op\r\n      return tf.nn.convolution(\r\nNode: 'sequential/conv1d/Conv1D'\r\nDNN library is not found.\r\n\t [[{{node sequential/conv1d/Conv1D}}]] [Op:__inference_train_function_842]\r\n", "comments": ["@bluetail14 ,\r\nEvery TensorFlow release is compatible with a certain version, for more information I request to take a look at the tested build [configurations](https://www.tensorflow.org/install/source_windows#gpu).\r\nAlso we see that you are trying to install using anaconda.I request you to try installing the tensorflow using [pip](https://www.tensorflow.org/install/pip)/[docker](https://www.tensorflow.org/install/docker) from this doc link.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55468\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55468\">No</a>\n"]}, {"number": 55467, "title": "[ROCm] Switch ROCm TF builds to use ROCm 5.1.0", "body": "/cc @cheshire @chsigg ", "comments": []}, {"number": 55465, "title": "r2.9 cherry-pick: 2d9de8e62c3 \"Insert new blurb for new release notes.\"", "body": "Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/2d9de8e62c30e606e817d1dec9ee1f546dcf19ba", "comments": ["Good, looks like the workflow works. This was just a test."]}, {"number": 55464, "title": "[hotfix] rename pylintrc", "body": "https://github.com/tensorflow/tensorflow/pull/55453\r\nThe test fails because the name of pylintrc has changed to an incorrect name.\r\n\r\n`pylintrc` is correct name.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/500065b9806bd7eff874841142ae0fb4f3e57d9c/.github/workflows/pylint-presubmit.yml#L48", "comments": ["Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nFor more information, open the [CLA check for this pull request](https://github.com/tensorflow/tensorflow/pull/55464/checks?check_run_id=5788517753).", "my pr is failed because this problem. https://github.com/tensorflow/tensorflow/pull/54455\r\n@gbaned "]}, {"number": 55463, "title": "I am using AD9361z7035 breakout board. using ubuntu version linaro 12.06 I want to install tensorflow lite on it. ", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1.  It must be a bug, a feature request, or a significant problem with the\r\n    documentation (for small docs fixes please send a PR instead).\r\n2.  The form below must be filled out.\r\n3.  It shouldn't be a TensorBoard issue. Those go\r\n    [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**:\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**:\r\n-   **TensorFlow installed from (source or binary)**:\r\n-   **TensorFlow version (use command below)**:\r\n-   **Python version**:\r\n-   **Bazel version (if compiling from source)**:\r\n-   **GCC/Compiler version (if compiling from source)**:\r\n-   **CUDA/cuDNN version**:\r\n-   **GPU model and memory**:\r\n-   **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["I am using ADRV9361Z7035 breakout board. Ubuntu version linaro 12.06 I want  to install tensorflow lite on it. \r\n\r\nI have **python3 version 3.4.0 and pip3 version 1.5.4**\r\n\r\nroot@analog:~# pip3 install tensorflow\r\nDownloading/unpacking tensorflow\r\nCannot fetch index base URL https://pypi.python.org/simple/\r\nCould not find any downloads that satisfy the requirement tensorflow\r\nCleaning up...\r\nNo distributions at all found for tensorflow\r\nStoring debug log for failure in /root/.pip/pip.log\r\n\r\n\r\nNeed guidance.", "Hi @waseem-arshad94 ! \r\nHere is the process of using lite models in microcontrollers .  \r\n \r\n1. convert your model to tflite and evaluate it in colab or local system.\r\n2. Convert lite model from step 1 to .h file using xxd converter  . \r\n3. include the header file from step 2  in your program and start inferencing.\r\n\r\nAttaching relevant thread for reference.[ 1](https://www.digikey.in/en/maker/projects/tinyml-getting-started-with-tensorflow-lite-for-microcontrollers/c0cdd850f5004b098d263400aa294023), [2](https://www.digikey.in/en/maker/projects/tinyml-getting-started-with-tensorflow-lite-for-microcontrollers/c0cdd850f5004b098d263400aa294023). Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55463\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55463\">No</a>\n"]}, {"number": 55462, "title": "Fixing syntax", "body": "Fixing syntax of the documentation from colon to full stop for much better readability. This is just the start for me to contribute to tensorflow, expect much more PRs in the future.", "comments": ["Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nFor more information, open the [CLA check for this pull request](https://github.com/tensorflow/tensorflow/pull/55462/checks?check_run_id=5786191328).", "Thank you for the contribution.\r\n\r\nThe colon is actually correct here, as it is followed by the status badges mentioned in the phrase.\r\n\r\nAlso, when sending grammar/typo fixes, can you do multiple changes in a PR, please? TensorFlow's CI takes hours and it's not right to waste so many hours for just a letter change.\r\n\r\nLooking forward for more contributions."]}, {"number": 55460, "title": "Fix tf.scatter_nd documentation", "body": "I experienced quite a lot of confusion while trying to understand this documentation. The part that confused me the most was \"`indices` is an integer of shape `shape`\", which is definitely not true. I ended up scrubbing through and fixing or improving the documentation in several other ways.", "comments": ["I just also removed the nondeterminism warning from the documentation. Since TF 2.7.0, this op is deterministic on both CPU and GPU (though not when using XLA), due to [this commit](https://github.com/tensorflow/tensorflow/commit/03ba364effe173d0b185977f0c14a48863d1f277) from @reedwm."]}, {"number": 55459, "title": "Create cherry-pick helper GA workflow", "body": "This creates a new helper workflow that can create a cherry-pick PR for\r\nOwners on the repository. Here's an example: https://github.com/angerson/tensorflow/pull/10", "comments": []}, {"number": 55458, "title": "Update version numbers for TensorFlow 2.9.0-rc0", "body": "Before merging this PR, please double check that it has correctly updated\n`core/public/version.h`, `tools/pip_package/setup.py`, and\n`tensorflow/tensorflow.bzl`. Also review the execution notes below:\n\n```\nMajor: 2 -> 2\nMinor: 9 -> 9\nPatch: 0 -> 0\n\nWARNING: Below are potentially instances of lingering old version string \n\"2.9.0\" in source directory \"tensorflow/\" that are not updated by this script. \nPlease check them manually!\ntensorflow/tools/pip_package/setup.py:48:2.9.0\ntensorflow/tools/pip_package/setup.py:84:2.9.0\ntensorflow/tools/pip_package/setup.py:108:2.9.0\ntensorflow/tools/pip_package/setup.py:110:2.9.0\ntensorflow/tools/pip_package/setup.py:112:2.9.0\ntensorflow/tools/ci_build/release/requirements_common.txt:27:2.9.0\ntensorflow/tools/ci_build/release/requirements_common.txt:28:2.9.0\ntensorflow/tools/ci_build/release/requirements_common.txt:29:2.9.0\ntensorflow/tensorflow.bzl:59:2.9.0\ntensorflow/workspace2.bzl:840:2.9.0\ntensorflow/workspace2.bzl:842:2.9.0\ntensorflow/lite/tools/versioning/runtime_version.cc:71:2.9.0\ntensorflow/lite/tools/versioning/runtime_version.cc:100:2.9.0\ntensorflow/lite/tools/versioning/runtime_version.cc:238:2.9.0\ntensorflow/lite/tools/versioning/runtime_version.cc:241:2.9.0\ntensorflow/lite/tools/versioning/runtime_version.cc:376:2.9.0\ntensorflow/lite/tools/versioning/runtime_version.cc:377:2.9.0\ntensorflow/lite/tools/versioning/runtime_version.cc:378:2.9.0\n\nWARNING: Below are potentially instances of lingering old version string \n\"2.9.0\" in source directory \"tensorflow/\" that are not updated by this script. \nPlease check them manually!\ntensorflow/tools/pip_package/setup.py:48:2.9.0\ntensorflow/tools/pip_package/setup.py:84:2.9.0\ntensorflow/tools/pip_package/setup.py:108:2.9.0\ntensorflow/tools/pip_package/setup.py:110:2.9.0\ntensorflow/tools/pip_package/setup.py:112:2.9.0\ntensorflow/tools/ci_build/release/requirements_common.txt:27:2.9.0\ntensorflow/tools/ci_build/release/requirements_common.txt:28:2.9.0\ntensorflow/tools/ci_build/release/requirements_common.txt:29:2.9.0\ntensorflow/tensorflow.bzl:59:2.9.0\ntensorflow/workspace2.bzl:840:2.9.0\ntensorflow/workspace2.bzl:842:2.9.0\ntensorflow/lite/tools/versioning/runtime_version.cc:71:2.9.0\ntensorflow/lite/tools/versioning/runtime_version.cc:100:2.9.0\ntensorflow/lite/tools/versioning/runtime_version.cc:238:2.9.0\ntensorflow/lite/tools/versioning/runtime_version.cc:241:2.9.0\ntensorflow/lite/tools/versioning/runtime_version.cc:376:2.9.0\ntensorflow/lite/tools/versioning/runtime_version.cc:377:2.9.0\ntensorflow/lite/tools/versioning/runtime_version.cc:378:2.9.0\n```", "comments": []}, {"number": 55457, "title": "Update release notes for TensorFlow 2.9.0", "body": "This PR is intentionally incomplete. One of the Release Owners for 2.9.0\nneeds to fill in the internal release notes for this version before the PR gets\nsubmitted. Click on the :pencil2: icon in the header for `RELEASE.md` under\n\"Files Changed\" above.", "comments": []}, {"number": 55456, "title": "Add release notes for manylinux2014 and libcxx ABI change", "body": "PiperOrigin-RevId: 438633589", "comments": []}, {"number": 55454, "title": "Keras cant load model with tf.where when dtype is float64", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.8 (also encountered on 2.4)\r\n- Python version: 3.7.5\r\n- Bazel version (if compiling from source): -\r\n- GCC/Compiler version (if compiling from source): -\r\n- CUDA/cuDNN version: -\r\n- GPU model and memory: -\r\n\r\n**Describe the current behavior**\r\nLoading a model that utilizes `tf.where` to replace a variable with some constant fails when all involved tensors are `float64` tensors.\r\n\r\nPossibly connected to [this issue](https://github.com/tensorflow/tensorflow/issues/47161).\r\n\r\n**Describe the expected behavior**\r\nThe model loads successfuly.\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\ndtype = 'float64'\r\n\r\nsome_input = keras.Input(shape=(1), dtype=dtype)\r\nsome_value = keras.layers.Dense(4, activation=\"relu\", dtype=dtype)(some_input)\r\nsome_value = keras.layers.Dense(2, dtype=dtype)(some_value)\r\n\r\nother_value = tf.constant([0.1], dtype=dtype)\r\n\r\nmask = tf.equal([0, 1], 1)\r\nreplaced_value = tf.where(mask, x=other_value, y=some_value)\r\n\r\nmodel = tf.keras.Model(inputs=[some_input], outputs=[replaced_value])\r\nmodel.save('my_test_model')\r\n\r\nloaded_model = tf.keras.models.load_model('my_test_model')\r\n```\r\n\r\nHowever, the model can be loaded properly when the arguments in the call to `tf.where` are switched, like this `tf.where(mask, x=some_value, y=other_value)`\r\n\r\nSetting `tf.keras.backend.set_floatx('float64')` does not prevent the error from occuring.\r\n\r\nSee this [Colab notebook](https://colab.research.google.com/drive/1mii4nbvHUJHaqbG60bEm88-ttdB7AltJ).\r\n\r\n**Other info / logs**\r\n```\r\n---------------------------------------------------------------------------\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n\r\n[<ipython-input-11-a4651214ca80>](https://localhost:8080/#) in <module>()\r\n----> 1 loaded_model = tf.keras.models.load_model('my_test_model')\r\n\r\n[/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py](https://localhost:8080/#) in error_handler(*args, **kwargs)\r\n     65     except Exception as e:  # pylint: disable=broad-except\r\n     66       filtered_tb = _process_traceback_frames(e.__traceback__)\r\n---> 67       raise e.with_traceback(filtered_tb) from None\r\n     68     finally:\r\n     69       del filtered_tb\r\n\r\n[/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py](https://localhost:8080/#) in _apply_op_helper(op_type_name, name, **keywords)\r\n    545 \r\n    546             raise TypeError(\r\n--> 547                 f\"{prefix} type \"\r\n    548                 f\"{dtypes.as_dtype(attrs[input_arg.type_attr]).name} of \"\r\n    549                 f\"argument '{inferred_from[input_arg.type_attr]}'.\")\r\n\r\nTypeError: Exception encountered when calling layer \"tf.where_3\" (type TFOpLambda).\r\n\r\nInput 'e' of 'SelectV2' Op has type float64 that does not match type float32 of argument 't'.\r\n\r\nCall arguments received:\r\n  \u2022 condition=['tf.Tensor(shape=(), dtype=bool)', 'tf.Tensor(shape=(), dtype=bool)']\r\n  \u2022 x=['0.1']\r\n  \u2022 y=tf.Tensor(shape=(None, 2), dtype=float64)\r\n  \u2022 name=None\r\n```\r\n", "comments": ["@VihGrimm ,\r\n`tf.keras.backend.set_floatx` supports only for Keras and it doesn't have any effect on Tensorflow. Also I request you to take a look at this [issue](https://github.com/tensorflow/tensorflow/issues/26033) where a similar feature has been proposed and it is still open and [comment](https://github.com/tensorflow/tensorflow/issues/35141#issuecomment-902165565) from the google developer. \r\n\r\nPlease try to use tf.constant which resulting tensor values are cast to the requested dtype.\r\n**`tf.constant([values], dtype=tf.float64)`**.Thanks!", "@tilakrayal \r\n\r\n> Please try to use tf.constant which resulting tensor values are cast to the requested dtype. **`tf.constant([values], dtype=tf.float64)`**.Thanks!\r\n\r\n`tf.constant([values], dtype='float64')` and `tf.constant([values], dtype=tf.float64)` seem to yield to the same result.\r\nIn particular the described behaviour does not change when setting dtype to `tf.float64` as opposed to `'float64'`.\r\n\r\n>  Also I request you to take a look at this [issue](https://github.com/tensorflow/tensorflow/issues/26033) where a similar feature has been proposed and it is still open and [comment](https://github.com/tensorflow/tensorflow/issues/35141#issuecomment-902165565) from the google developer.\r\n\r\nThank you for pointing out that issue and especially the comment.\r\nThe ongoing feature request to set tensorflow dtypes globally would probably solve the problem.\r\nThe dtype parameter for `tf.where` would definitely solve it.\r\n\r\n\r\n", "@VihGrimm ,\r\nCould you please confirm if the issue is resolved. if yes, please feel free to move this issue to closed status.Thanks!", "@tilakrayal \r\nFor me, the problem is solved with the workaround.\r\nHowever, it feels unsatisfactory to call the whole thing resolved, since the error still exists when loading models that use `tf.where`. And I would describe it as unexpected behavior.\r\nSince a fix is not foreseeable for now: maybe it would be good to point out this behavior in the docs so that others don`t face the same problem?", "@VihGrimm ,\r\nThanks for the suggestion.Glad the above [workaround](https://github.com/tensorflow/tensorflow/issues/55454#issuecomment-1085427895) helped to resolve the issue. Also I request to follow the similar feature which has been proposed to have the updates on the similar issue.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55454\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55454\">No</a>\n"]}, {"number": 55453, "title": "Pylint: Revert W + TODO", "body": "https://github.com/tensorflow/tensorflow/issues/55442", "comments": ["Oh, this accidentally renames the file :(", "How it was changed?", "![63dzVBiycCn8mzC](https://user-images.githubusercontent.com/323199/161339535-e076eec8-6ec4-4303-b8b9-755893e2020e.png)\r\n", "I've just edited this file on github directly. Who have renamed the file? copybara?", "Ok yes sorry.. it was just a bad copy paste in the Github form.", "It's all good, just an accidental rename. Fixed now.\r\n\r\nOur review process should have caught it."]}, {"number": 55451, "title": "CustomGraphOptimizer doesn't work", "body": "I implemented a `CustomGraphOptimizer`, and registered it through `CustomGraphOptimizerRegistrar`, but that optimizer seems not to work? Am I doing anything wrong?\r\n\r\nHere is my cc codes about `CustomGraphOptimizer`:\r\n```c++\r\n#include \"tensorflow/core/grappler/clusters/cluster.h\"\r\n#include \"tensorflow/core/grappler/grappler_item.h\"\r\n#include \"tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.h\"\r\n#include \"tensorflow/core/grappler/utils/functions.h\"\r\n\r\nnamespace tensorflow {\r\nnamespace grappler {\r\n\r\n#define DebugINFO(msg)                           \\\r\n    do {                                         \\\r\n        std::cout << \"[CUSTOM_OPTIMIZER]\" << \":\" \\\r\n                  << __FILE__ << \":\" << __LINE__ \\\r\n                  << \": \" << #msg << std::endl;  \\\r\n    } while (0)\r\n\r\nclass MyCustomGraphOptimizer : public CustomGraphOptimizer {\r\npublic:\r\n    MyCustomGraphOptimizer(const string& name) \r\n    : name_(name) {\r\n        DebugINFO(MyCustomGraphOptimizer_Ctor);\r\n    }\r\n\r\n    Status Init(const tensorflow::RewriterConfig_CustomGraphOptimizer* config) override {\r\n        DebugINFO(Init);\r\n        return Status::OK();\r\n    } \r\n\r\n    string name() const override { \r\n        DebugINFO(name); \r\n        return name_; \r\n    }\r\n\r\n    bool UsesFunctionLibrary() const override { \r\n        DebugINFO(UsesFunctionLibrary);\r\n        return false; \r\n    }\r\n\r\n    Status Optimize(Cluster* cluster, const GrapplerItem& item, GraphDef* optimized_graph) override {\r\n        DebugINFO(Optimize);\r\n        return Status::OK();\r\n    }\r\nprivate:\r\n    const string name_;\r\n};\r\n\r\nclass MyCustomGraphOptimizerRegistrar : public CustomGraphOptimizerRegistrar {\r\npublic:\r\n    MyCustomGraphOptimizerRegistrar(\r\n        const CustomGraphOptimizerRegistry::Creator& creator,\r\n        const string& name) \r\n    : CustomGraphOptimizerRegistrar(creator, name) {\r\n        DebugINFO(CustomGraphOptimizerRegistrar_Ctor); \r\n\r\n        std::vector<string> optimizers = CustomGraphOptimizerRegistry::GetRegisteredOptimizers();\r\n        for (auto const& opt : optimizers) {\r\n            std::cout << \"RegisteredOptimizer: \" << opt << std::endl;\r\n        }\r\n    }\r\n};\r\n\r\nstatic MyCustomGraphOptimizerRegistrar MyCustomGraphOptimizer_Registrar(\r\n    /*creator=*/\r\n    [](){\r\n        DebugINFO(MyCustomGraphOptimizer_Registrar);\r\n        return new MyCustomGraphOptimizer(\"MyCustomGraphOptimizer\");\r\n    }, /*name=*/\"CustomGraphOptimizer\");\r\n\r\n} // namespace grappler\r\n} // namespace tensorflow\r\n```\r\n\r\nAnd here is my python testing codes:\r\n```python\r\nfrom tensorflow.core.protobuf import config_pb2\r\nfrom tensorflow.python.framework import ops\r\nfrom tensorflow.python.grappler import tf_optimizer\r\nfrom tensorflow.python.framework import meta_graph\r\nfrom tensorflow.core.protobuf import rewriter_config_pb2\r\nfrom tensorflow.core.framework import graph_pb2\r\nfrom build import TFCustomGraphOptimizer as custom_graph_op\r\n\r\ndef _get_custom_rewriter_config():\r\n    rewriter_config = rewriter_config_pb2.RewriterConfig()\r\n    \r\n    rewriter_config.meta_optimizer_iterations = (\r\n      rewriter_config_pb2.RewriterConfig.ONE)\r\n    rewriter_config.min_graph_nodes = -1 # do not skip optimization\r\n\r\n    rewriter_config.optimizers.extend([\"constfold\", \"CustomGraphOptimizer\"])\r\n    rewriter_config.custom_optimizers.add().name = \"layout\"\r\n\r\n    opt = rewriter_config.custom_optimizers.add()\r\n    opt.name = \"MyCustomGraphOptimizer\"\r\n\r\n    return rewriter_config\r\n\r\ndef OptimizeGraph(graph, verbose=False):\r\n    # convert to metaGraph\r\n    meta_graph_def = meta_graph.create_meta_graph_def(graph=graph)\r\n\r\n    # create custom ConfigProto for Grappler\r\n    grappler_session_config = config_pb2.ConfigProto()\r\n    custom_rewriter_config = _get_custom_rewriter_config()\r\n    grappler_session_config.graph_options.rewrite_options.CopyFrom(custom_rewriter_config)\r\n\r\n    # Run Grappler\r\n    grappler = tf_optimizer.OptimizeGraph\r\n    converted_graph_def = grappler(config_proto=grappler_session_config,\r\n                                   metagraph=meta_graph_def,\r\n                                   verbose=verbose,\r\n                                   cluster=None,\r\n                                   strip_default_attributes=False)\r\n\r\n    return converted_graph_def\r\n\r\nif __name__ == \"__main__\":\r\n    import tensorflow as tf\r\n    from tensorflow.python.ops import random_ops\r\n\r\n    with ops.Graph().as_default() as g:\r\n        a = random_ops.random_uniform(shape=())\r\n        b = random_ops.random_uniform(shape=())\r\n\r\n        c = a + b\r\n\r\n        train_op = ops.get_collection_ref(ops.GraphKeys.TRAIN_OP)\r\n        train_op.append(c)\r\n\r\n        optimized_graph = OptimizeGraph(graph=g, verbose=True)\r\n        # print(optimized_graph)\r\n```", "comments": ["And the following is the running log for previous python codes:\r\n```shell\r\n[CUSTOM_OPTIMIZER]:/workspace/tensorflow/test_tf/custom_optimizer/custom_optimizer.cc:52: CustomGraphOptimizerRegistrar_Ctor\r\nRegisteredOptimizer: CustomGraphOptimizer\r\n2022-03-31 11:15:45.987946: E tensorflow/core/lib/monitoring/collection_registry.cc:81] Cannot register 2 metrics with the same name:\r\n2022-03-31 11:15:45.987991: E tensorflow/core/lib/monitoring/collection_registry.cc:81] Cannot register 2 metrics with the same name:\r\n2022-03-31 11:15:45.988010: E tensorflow/core/lib/monitoring/collection_registry.cc:81] Cannot register 2 metrics with the same name:\r\n2022-03-31 11:15:45.988036: E tensorflow/core/lib/monitoring/collection_registry.cc:81] Cannot register 2 metrics with the same name:\r\n2022-03-31 11:15:45.988051: E tensorflow/core/lib/monitoring/collection_registry.cc:81] Cannot register 2 metrics with the same name:\r\n2022-03-31 11:15:45.988067: E tensorflow/core/lib/monitoring/collection_registry.cc:81] Cannot register 2 metrics with the same name:\r\n2022-03-31 11:15:45.988077: E tensorflow/core/lib/monitoring/collection_registry.cc:81] Cannot register 2 metrics with the same name:\r\n2022-03-31 11:15:45.988083: E tensorflow/core/lib/monitoring/collection_registry.cc:81] Cannot register 2 metrics with the same name:\r\n2022-03-31 11:15:45.988137: E tensorflow/core/lib/monitoring/collection_registry.cc:81] Cannot register 2 metrics with the same name:\r\nWelcom\r\n2022-03-31 11:15:46.045381: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1052] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-03-31 11:15:46.045942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1052] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-03-31 11:15:46.046435: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 2\r\n2022-03-31 11:15:46.046516: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\r\n2022-03-31 11:15:46.183614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1052] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-03-31 11:15:46.184164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1052] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-03-31 11:15:46.210158: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1052] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-03-31 11:15:46.210738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1052] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-03-31 11:15:46.211258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1052] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-03-31 11:15:46.211751: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1052] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-03-31 11:15:46.696440: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1052] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-03-31 11:15:46.697035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1052] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-03-31 11:15:46.697554: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1052] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-03-31 11:15:46.698053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1052] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-03-31 11:15:46.698549: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1052] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-03-31 11:15:46.699058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9430 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:07:00.0, compute capability: 7.5\r\n2022-03-31 11:15:46.699337: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1052] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-03-31 11:15:46.699818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 9648 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:08:00.0, compute capability: 7.5\r\n2022-03-31 11:15:46.702396: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1176] Optimization results for grappler item: graph_to_optimize\r\n  constant_folding: Graph size after: 5 nodes (0), 4 edges (0), time = 0.261ms.\r\n  layout: Graph size after: 5 nodes (0), 4 edges (0), time = 0.142ms.\r\n```", "Never mind, I solved it."]}, {"number": 55450, "title": "Python Import error for tensorflow, tflearn and nltk libraries!", "body": "```\r\nTraceback (most recent call last):\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/__init__.py\", line 61, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: dlopen(/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/_pywrap_tensorflow.so, 0x000A): tried: '/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/_pywrap_tensorflow.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e'))\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/virajsabhaya/Library/CloudStorage/OneDrive-UniversityofTexasatArlington/Documents/MyPersonalProject/Interview_Chat_Bot/main.py\", line 2, in <module>\r\n    import tensorflow as tf\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/__init__.py\", line 72, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/__init__.py\", line 61, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: dlopen(/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/_pywrap_tensorflow.so, 0x000A): tried: '/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/_pywrap_tensorflow.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e'))\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n```\r\n---\r\n\r\n- I have even changed the path and tried setting up the envn paths to anaconda and python3 but it still shows this error. \r\n- If I comment the imports of the libraries mentioned I don't get any errors.", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n   * For TF-GPU - See point 1\n   * For TF-CPU - See point 2\n-----------------------------------------------------------------------------------------------\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\nMake sure you are using compatible TF and CUDA versions. Please refer following TF version and CUDA version compatibility table.\n| TF  | CUDA |\n| :-------------: | :-------------: |\n| 2.5.0  | 11.2 |\n| 2.4.0  | 11.0 |\n| 2.1.0 - 2.3.0  | 10.1 |\n| 1.13.1 - 2.0  | 10.0  |\n| 1.5.0 - 1.12.0 | 9.0 |\n\n  * If you have above configuration and using _**Windows**_ platform -\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n    * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n  * If you have above configuration and using _**Ubuntu/Linux**_ platform -\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n    * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n  * If error still persists then, apparently your CPU model does not support AVX instruction sets.\n    * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\nTherefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n   * Try Google Colab to use TensorFlow.\n      * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true). You get pre-installed latest stable TF version. Also you can use ```pip install```  to install any other preferred TF version.\n      * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n      * All you need is a good internet connection and you are all set.\n   * Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*\n", "@virajsabhaya23 ,\r\n\r\nIn order to expedite the trouble-shooting process, could you please provide the following information\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nTensorFlow installed from (source or binary):\r\nTensorFlow version:\r\nPython version:\r\nInstalled using virtualenv? pip? conda?:\r\nBazel version (if compiling from source):\r\nGCC/Compiler version (if compiling from source):\r\nCUDA/cuDNN version:\r\nGPU model and memory:\r\n \r\nand the exact sequence of commands / steps that you executed before running into the problem.Thanks!\r\n", "Also i request you to follow the steps mentioned [here](https://www.tensorflow.org/install) for installing the tensorflow with the compatible tested build [configurations](https://www.tensorflow.org/install/source#linux).Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55450\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55450\">No</a>\n"]}, {"number": 55449, "title": "Notebooks deleted when following beginner tutorial", "body": "Hi!\r\n\r\nThis issue is related to a notebook which is a part of the beginner tutorial focusing on text classification. \r\n\r\nLinks:\r\nhttps://www.tensorflow.org/tutorials/keras/text_classification\r\nhttps://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb\r\n\r\nI'm a beginner so I might be doing something wrong or something that is discouraged, but I figured that a warning may be appropriate if this is the case since this notebook is part of the beginner learning material.\r\n\r\n## Description of issue (reproduction steps):\r\nIn short, the issue is that when executing a few steps in a specific order, .ipynb files with a specific prefix in the working directory are deleted.\r\n\r\nRepro steps:\r\n1. Run cell 1 (imports)\r\n1. Run cell 2 (check version)\r\n1. Run cell 3 (get IMDB dataset)\r\n1. Restart kernel **before cell 3 is done**\r\n1. Run cell 1 again\r\n\r\nNow all .ipynb files in the working directory with a prefix of \"x_\" where x is a digit are deleted.\r\n\r\n## Environment\r\nI'm running the notebook in a local jupyter-lab (version 3.3.2) on a windows 10 (version 19042.1586) machine. \r\n\r\nIf there is anything else anyone would like to know I'm happy to answer!\r\n\r\nThanks!", "comments": ["@KristalAlfred ,\r\nI have followed the mentioned steps and executed the code in latest tf v2.8.I haven't faced any issues/errors during the execution.Please find the gist [here](https://colab.research.google.com/gist/tilakrayal/07fa03d9763d37653938fc4cf50e204a/text_classification.ipynb).\r\n \r\nAlso this issue in more related to jupyter-lab, i request you to refer this [link](https://stackoverflow.com/questions/68994024/jupyterlab-notebook-cells-going-missing) and check with the respective repo.Thanks!", "@tilakrayal,\r\nAlright! The SO-question you linked wasn't quite what I was describing, but you're right. This is probably more of a jupyter-lab issue. I'll raise the issue over there instead. Thanks for checking!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55449\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55449\">No</a>\n"]}, {"number": 55447, "title": "How about exporting `Tensor::FromProto` to Python API?", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.8\r\n- Are you willing to contribute it (Yes/No):\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nIf we have to convert TensorProto message in Python env, we can't directly convert it.\r\nWe have to \r\n\r\n1. construct a new tensor with protobuf message field\r\n2. serialize message to string and parse it using `tf.io.parse_tensor`\r\n3. or some other way\r\n\r\n**Will this change the current api? How?**\r\n\r\nYes. Maybe we can add the `tf.from_tensor_proto` like `tf.make_tensor_proto`.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nThe people who frequently handle protobuf messages.\r\nFor example, I handle TensorProto messages directly when I predict some examples with TensorFlow Serving using gRPC.\r\n\r\n**Any Other info.**\r\n\r\n[`Tensor::FromProto` docs link](https://www.tensorflow.org/api_docs/cc/class/tensorflow/tensor#fromproto)", "comments": ["What about [tf.make_ndarray](https://www.tensorflow.org/api_docs/python/tf/make_ndarray)?", "@rainwoodman Oh, I didn't know about that function. Thank you!", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)"]}, {"number": 55445, "title": "RuntimeError: Encountered unresolved custom op: PyFunc.Node number 559 (PyFunc) failed to prepare.", "body": "System information\r\n\r\nWindows\r\nTF 2.5.0\r\n\r\nCommand used to run the converter or code if you\u2019re using the Python API\r\nConverter:\r\n\r\n**keras_model = model.keras_model\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\r\nconverter.allow_custom_ops = True\r\nconverter.experimental_new_converter = True\r\nconverter.target_spec.supported_ops = [\r\n    tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\r\n    tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\r\n]\r\ntflite_model = converter.convert()**\r\n\r\nInference:\r\n\r\n **# Load the TFLite model and allocate tensors.\r\ninterpreter = tf.lite.Interpreter(model_path=tflite_model_path)\r\n\r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\n\r\ninterpreter.resize_tensor_input(input_details[0]['index'], layer_image.shape)\r\ninterpreter.allocate_tensors()\r\n\r\ninput_data_1 = np.array(layer_image, dtype=np.float32)\r\ninterpreter.set_tensor(input_details[0]['index'], input_data_1)\r\n\r\ninterpreter.invoke()**\r\n\r\nThe output from the Inference:\r\n**RuntimeError: Encountered unresolved custom op: PyFunc.Node number 559 (PyFunc) failed to prepare.**\r\n\r\nIm pretty new to tensorflow. Im facing an issue in tflite model inference.I have used a **tf.numpy_function** in my keras layer for inference part, the inference is perfectly working in keras. But when converted to tflite, the pinvoke is giving me the above error\r\n\r\n\r\n\r\n\r\n", "comments": ["Hi @MiracleMiranda07 !  If it is a keras model , you can skip the below line in 2.8 version. \r\n`keras_model = model.keras_model` \r\n\r\nCould you please share the model file snippet too?   Thanks!\r\n\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55445\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55445\">No</a>\n"]}]