[{"number": 55317, "title": "Default EQUALITY_OPERATORS in Autograph", "body": "fix https://github.com/tensorflow/tensorflow/issues/55278\r\n\r\n/cc @mdanatg  Let me know where do you want to move the test so that I write it like an integration test as where is now it will go to fail for missing variable conversion (`ag__.ld`).", "comments": ["I've extended an high level integration test. \r\nLet me know if we want to remove or we could modify the lowlevel one to pass.", "@mdanatg Copybara isn't happy", "Probably a tool failure, I'll trigger it again. But let's replace the line continuation from the string, just in case.", "Let me know why we make `import/copybara` cry", "Copybara still cries.", "A couple of internal tests are failing. Not clear why, the errors don't look related.", "Copybara again", "@mdanatg I suppose this was merged with b462db3b7482ff8e52b13ca686f2bca4508a6910. \r\nBut I have totally lost my attribution on git:\r\n\r\n`git show -s --format=\"%ae\" b462db3` \r\n\r\n`gardener@tensorflow.org`\r\n\r\n", "P.s. Ok I found it on `git show -s --format=\"%ce %ae\" e2cc982`. I suppose we could close this.", "Yes, it's strange that GH didn't automatically marked it as merged. Probably due to the internal revisions."]}, {"number": 55316, "title": "Fix eigen's headers to use 'std' instead of Eigen::internals", "body": "A recent commit on Eigen replaced many type metaprogramming with corresponding std types.\r\nhttps://gitlab.com/libeigen/eigen/-/commit/421cbf08660fdf9458ea64ca6ceb197e75c6e698\r\n\r\nThis patch prepares the code to build properly when the Eigen commit id is updated.", "comments": ["Hi @cantonios, Do you know when the Eigen commit Id will be updated again? This current PR is necessary to build TF properly with the Eigen master branch.", "@maxiwell thanks, this will save me some work in the future.  Appreciate the help.\r\n\r\n>A recent commit on Eigen replaced many type metaprogramming with corresponding std types.\r\n\r\nI put those `Eigen::internals` back in upstream precisely because of this break (and several other 3p library breaks).\r\n\r\n> Do you know when the Eigen commit Id will be updated again?\r\n\r\nThe Eigen commit id will be updated soon-ish.  Currently trying to work around a MSVC+NVCC compiler bug that causes our TF windows builds to break.  Silly MSVC (and NVCC).\r\n\r\n\r\n\r\n", "Thanks, @cantonios. I saw that copybara has failed. Is it necessary to do something else here to merge this PR?", "> Thanks, @cantonios. I saw that copybara has failed. Is it necessary to do something else here to merge this PR?\r\n\r\nNo, sorry, just took a while to get the necessary approvals.  Should continue with other checks now."]}, {"number": 55315, "title": "tfds.load Movie Lens  Failed to establish a new connection", "body": "I am executing the code on colab using the CPU configuration. Then, I execute this sequence of `pip install`:\r\n\r\n```\r\n!pip install tfds-nightly\r\n!pip install -q tensorflow-recommenders\r\n!pip install -q --upgrade tensorflow-datasets==4.3\r\n!pip install -q scann\r\n```\r\n\r\n**The Code That Caused the error:**\r\n\r\n```Python\r\ntfds.load(\"movielens/100k-ratings\", split=\"train\", shuffle_files = False)\r\n```\r\n\r\nThis is the error message:\r\n\r\n```Python\r\nOSError                                   Traceback (most recent call last)\r\n/usr/local/lib/python3.7/dist-packages/urllib3/connection.py in _new_conn(self)\r\n    158             conn = connection.create_connection(\r\n--> 159                 (self._dns_host, self.port), self.timeout, **extra_kw)\r\n    160 \r\n\r\n38 frames\r\nOSError: [Errno 113] No route to host\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nNewConnectionError                        Traceback (most recent call last)\r\nNewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f834bc01790>: Failed to establish a new connection: [Errno 113] No route to host\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nMaxRetryError                             Traceback (most recent call last)\r\nMaxRetryError: HTTPConnectionPool(host='files.grouplens.org', port=80): Max retries exceeded with url: /datasets/movielens/ml-100k.zip (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f834bc01790>: Failed to establish a new connection: [Errno 113] No route to host'))\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nConnectionError                           Traceback (most recent call last)\r\n/usr/local/lib/python3.7/dist-packages/requests/adapters.py in send(self, request, stream, timeout, verify, cert, proxies)\r\n    514                 raise SSLError(e, request=request)\r\n    515 \r\n--> 516             raise ConnectionError(e, request=request)\r\n    517 \r\n    518         except ClosedPoolError as e:\r\n\r\nConnectionError: HTTPConnectionPool(host='files.grouplens.org', port=80): Max retries exceeded with url: /datasets/movielens/ml-100k.zip (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f834bc01790>: Failed to establish a new connection: [Errno 113] No route to host'))\r\n```", "comments": ["Okay, I reported it directly to the tensorflow dataset github repository.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55315\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55315\">No</a>\n"]}, {"number": 55313, "title": "Redundant `create_padding_mask(inp)` masks", "body": "Hello,\r\n\r\n  in your tutorial about Transormer I think there are redundant `create_padding_mask(inp)` masks. The same mask is created for Encoder and Decoder too. Please look here:\r\n\r\n```python\r\n    # Encoder padding mask\r\n    enc_padding_mask = create_padding_mask(inp)\r\n\r\n    # Used in the 2nd attention block in the decoder.\r\n    # This padding mask is used to mask the encoder outputs.\r\n    dec_padding_mask = create_padding_mask(inp)\r\n```\r\n\r\nIt's the same padding mask created from `inp`. It's memory inefficient.\r\n \r\nLink: https://www.tensorflow.org/text/tutorials/transformer#create_the_transformer\r\n\r\nThanks.\r\nHave a nice day.\r\n\r\n", "comments": ["Hi @markub3327 ! Could you please post this [text](https://github.com/tensorflow/text/issues) repository?", "Yes, I can create issue in tensorflow/text.\r\n\r\nThanks.", "https://github.com/tensorflow/text/issues/863", "Hi @gadagashwini ! Could you please look at this issue?", "@markub3327,\r\n`dec_padding_mask` is expected. This padding mask is used to mask the encoder outputs. \r\ndec_padding_mask is for input and target language \r\n`dec_padding_mask = self.create_masks(inp, tar)`", "@gadagashwini \r\nNow the snippet look like here:\r\n\r\n```python\r\ndef create_masks(self, inp, tar):\r\n    # Encoder padding mask\r\n    enc_padding_mask = create_padding_mask(inp)\r\n\r\n    # Used in the 2nd attention block in the decoder.\r\n    # This padding mask is used to mask the encoder outputs.\r\n    dec_padding_mask = create_padding_mask(inp)\r\n\r\n    # Used in the 1st attention block in the decoder.\r\n    # It is used to pad and mask future tokens in the input received by\r\n    # the decoder.\r\n    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\r\n    dec_target_padding_mask = create_padding_mask(tar)\r\n    look_ahead_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\r\n\r\n    return enc_padding_mask, look_ahead_mask, dec_padding_mask\r\n```\r\n\r\nThe same thing with lower memory consumption and better way is:\r\n\r\n```python\r\ndef call(self, inputs, training):\r\n    # Keras models prefer if you pass all your inputs in the first argument\r\n    inp, tar = inputs\r\n\r\n    padding_mask, look_ahead_mask = self.create_masks(inp, tar)\r\n\r\n    enc_output = self.encoder(inp, training, padding_mask)  # (batch_size, inp_seq_len, d_model)\r\n\r\n    # dec_output.shape == (batch_size, tar_seq_len, d_model)\r\n    dec_output, attention_weights = self.decoder(\r\n        tar, enc_output, training, look_ahead_mask, padding_mask)\r\n\r\n    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\r\n\r\n    return final_output, attention_weights\r\n\r\ndef create_masks(self, inp, tar):\r\n    # Encoder padding mask (Used in the 2nd attention block in the decoder too.)\r\n    padding_mask = create_padding_mask(inp)\r\n\r\n    # Used in the 1st attention block in the decoder.\r\n    # It is used to pad and mask future tokens in the input received by\r\n    # the decoder.\r\n    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\r\n    dec_target_padding_mask = create_padding_mask(tar)\r\n    look_ahead_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\r\n\r\n    return padding_mask, look_ahead_mask\r\n```", "@markub3327,\r\nWould you like to contribute to this issue? \r\nOr any suggestion or workaround to fix this issue.Thanks! ", "@gadagashwini\r\n\r\nYes I can create PR.", "@gadagashwini\r\n\r\nI create PR at https://github.com/tensorflow/text/pull/869, is it OK?\r\n\r\nThanks.", "@markub3327, Thanks for the PR. "]}, {"number": 55312, "title": "DeeplabV3 custom dataset, inference problem black images", "body": "Good morning,\r\n\r\nI want to train a custom dataset using deeplabV3.\r\n\r\nI'm following this tutorial (https://sanjayparajuli27.medium.com/how-to-train-deeplab-on-custom-dataset-a40c41c4c6a3) for this dataset (https://www.kaggle.com/datasets/dansbecker/cityscapes-image-pairs) that I found on Kaggle, based on cityscapes.\r\n\r\nThere are images of 256x256 pixel in RGB colors, divided in 2975 imgs for training and 500 for validation, and I created the respective mask using this script\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom PIL import Image\r\nfrom tqdm import tqdm\r\nimport numpy as np\r\n\r\nimport os, shutil\r\n\r\n# palette (color map) describes the (R, G, B): Label pair\r\npalette = {(0,   0,   0) : 0 ,\r\n           (128,  0, 0) : 1,\r\n           (0, 128, 0): 2,\r\n           (128, 128, 0): 3,\r\n           (0, 0, 128): 4,\r\n           (0, 128, 128): 5,\r\n           (128, 128, 128): 6,\r\n           (64, 0, 0): 7,\r\n           (192, 0, 0): 8,\r\n           (64, 128, 0): 9,\r\n           (192, 128, 0): 10,\r\n           (64, 0, 128): 11,\r\n           (192, 0, 128): 12,\r\n           (64, 128, 128): 13,\r\n           (0, 64, 0): 14,\r\n           (128, 64, 0): 15,\r\n           (0, 192, 0): 16,\r\n           (128, 192, 0): 17,\r\n           (0, 64, 128): 18,\r\n           (128, 0, 128): 19\r\n         }\r\n\r\ndef convert_from_color_segmentation(arr_3d):\r\n    arr_2d = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.uint8)\r\n\r\n    for c, i in palette.items():\r\n        m = np.all(arr_3d == np.array(c).reshape(1, 1, 3), axis=2)\r\n        arr_2d[m] = i\r\n    return arr_2d\r\n\r\n\r\nlabel_dir = \"C:/Users/paolo.david/Desktop/Datasets/final/Validation/Mask_real/\" #don't forget the '/' at the end\r\nnew_label_dir = \"C:/Users/paolo.david/Desktop/Datasets/final/Validation/Mask_RAW2/\"\r\n\r\nif not os.path.isdir(new_label_dir):\r\n    print(\"creating folder: \",new_label_dir)\r\n    os.mkdir(new_label_dir)\r\nelse:\r\n    print(\"Folder alread exists. Delete the folder and re-run the code!!!\")\r\n\r\n\r\nlabel_files = os.listdir(label_dir)\r\n\r\nfor l_f in tqdm(label_files):\r\n    #arr = np.array(Image.open(l_f))\r\n    arr = np.array(Image.open(label_dir + l_f))\r\n    arr = arr[:,:,0:3]\r\n    arr_2d = convert_from_color_segmentation(arr)\r\n    #Image.fromarray(arr_2d).save(label_dir)\r\n    Image.fromarray(arr_2d).save(new_label_dir + l_f)\r\n```\r\n\r\nEach image in the dataset contain its same mask, so before to launch the new notebook I divided the image and the mask to have a situation like in the tutorial.\r\n\r\nYou can find my code here: https://drive.google.com/drive/folders/105JMDmujY6lknH3D74WM8R8S7jTb51qX?usp=sharing and this is the notebook https://drive.google.com/file/d/1xmUtLB-XPj4mZdqbx9SAQOXKSwxtxCLX/view?usp=sharing\r\n\r\nI have a problem with the inference. Every time I launch the notebook with few epochs (less then 10) I receive good results, but trying to increase the number of epoch I have all black images.\r\n\r\nThese are the parameters that I used for the train:\r\n\r\n```\r\n--model_variant=\"xception_65\" \\\r\n--atrous_rates=6 \\\r\n--atrous_rates=12 \\\r\n--atrous_rates=18 \\\r\n--output_stride=16 \\\r\n--decoder_output_stride=4 \\\r\n--train_crop_size=\"256,256\" \\\r\n--train_batch_size=4 \\\r\n--training_number_of_steps=30 \\\r\n--initialize_last_layer=False \\\r\n--last_layers_contain_logits_only=True \\\r\n--fine_tune_batch_norm=False \\\r\n```\r\n\r\nI edited the data_generator.py file putting\r\n\r\n```\r\n_CUSTOM_INFORMATION = DatasetDescriptor(\r\n    splits_to_sizes={\r\n        'train': 270,  # num of samples in train.txt\r\n        'val': 30,  # num of samples in val.txt\r\n    },\r\n    num_classes=21, # classes+bg+ignore_label\r\n    ignore_label=255,\r\n)\r\n\r\n_DATASETS_INFORMATION = {\r\n    'cityscapes': _CITYSCAPES_INFORMATION,\r\n    'pascal_voc_seg': _PASCAL_VOC_SEG_INFORMATION,\r\n    'ade20k': _ADE20K_INFORMATION,\r\n    'custom': _CUSTOM_INFORMATION  # custom dataset\r\n}\r\n```\r\n\r\nI'm using a pretrained model downloaded from here: http://download.tensorflow.org/models/deeplabv3_cityscapes_train_2018_02_06.tar.gz\r\n\r\nI keep the batch size at 4, and I don't know if it is correct or not. Can you tell me where could be the possible error?", "comments": ["@paolodavid \r\nIn order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose),\r\nThanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55312\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55312\">No</a>\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55312\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55312\">No</a>\n"]}, {"number": 55311, "title": "can it possible improve the tf serving performance", "body": "Now I train a recommend nn model offline ,and then predict it by tf serving on cpu online machine. There are 8 cores i just applied, and found it cost slow when predict it. More than 0.4% it costs 100ms when predict. The batch size request is 50. There are 167 one hot features and 3 full-connected layers.And the usage of cpu is also slow, it is only 20% usage.\r\nHow can i analyze the bottleneck of serving ,and can it possible to reduce the time cost ratio by adjust some parameters?\r\n\r\ni have tried many ways followed this links https://www.tensorflow.org/tfx/serving/performance ,but it hardly worked.\r\nTf serving can't support many sparse features so well?", "comments": ["@liumilan ,\r\nThis issue is more suitable for TensorFlow tfx repo. Please post it on Tensorflow/tfx repo from [here](https://github.com/tensorflow/tfx/issues). Thanks!", "ok,link as below \r\nhttps://github.com/tensorflow/tfx/issues/4759", "give tf time adjusting to language input for the module response duration and input a specific time with notifications to alert tf who is working on malware prevention issues.", "@liumilan ,\r\nCan you please close this issue, since it is already being tracked there? Thanks!\r\n"]}, {"number": 55310, "title": "Avoid loss of precision from using reciprocal", "body": "Taking the reciprocal of the calculated value results in a loss of precision. This causes the unit test prepare-tf.mlir.test to fail on AARCH64. So instead of taking the reciprocal of the calculated nudged_scale to get the inv_nudged_scale, calculate this value from the input values.", "comments": ["@cfRod @nSircombe ", "Adding @penpornk ", "@penpornk Updated as requested.", "@penpornk What happened here? Why the rollback?", "@elfringham It broke some internal tests which use fixed golden values. I'll do a more thorough test before bringing this PR back. You don't need to do anything."]}, {"number": 55309, "title": "Node: 'model/conv1d/Conv1D' DNN library is not found.", "body": "**System information**\r\n- OS: Linux Ubuntu 20.04:\r\n- TensorFlow installed from pip\r\n- TensorFlow version: v2.8.0-rc1-32-g3f878cff5b6 2.8.0\r\n- Python version: Python 3.8.10\r\n- CUDA/cuDNN version: NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6   \r\n- GPU model : [GeForce GTX 1650] \r\n\r\nHello, everyone.\r\nI'm trying to run a  convolutional neural network on tensorflow but I'm receiving the current error:\r\n\r\n> 2022-03-21 10:40:20.665473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2022-03-21 10:40:20.687599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2022-03-21 10:40:20.687804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2022-03-21 10:40:22.544819: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\n> To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n> 2022-03-21 10:40:22.545204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2022-03-21 10:40:22.545428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2022-03-21 10:40:22.545579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2022-03-21 10:40:22.815601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2022-03-21 10:40:22.815824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2022-03-21 10:40:22.815975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2022-03-21 10:40:22.816100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2607 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\r\n> Epoch 1/999999\r\n> 2022-03-21 10:40:23.481069: E tensorflow/stream_executor/cuda/cuda_dnn.cc:361] Loaded runtime CuDNN library: 8.0.4 but source was compiled with: 8.1.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\r\n> 2022-03-21 10:40:23.481615: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:1120 : UNIMPLEMENTED: DNN library is not found.\r\n> Traceback (most recent call last):\r\n>   File \"CNN_regression.py\", line 367, in <module>\r\n>     results = pd.concat([results,main(mode)], ignore_index=True)\r\n>   File \"CNN_regression.py\", line 124, in main\r\n>     history = model.fit(X_train, Y_train,\r\n>   File \"/home/italocaliari/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\r\n>     raise e.with_traceback(filtered_tb) from None\r\n>   File \"/home/italocaliari/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\", line 54, in quick_execute\r\n>     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n> tensorflow.python.framework.errors_impl.UnimplementedError: Graph execution error:\r\n> \r\n> Detected at node 'model/conv1d/Conv1D' defined at (most recent call last):\r\n>     File \"CNN_regression.py\", line 367, in <module>\r\n>       results = pd.concat([results,main(mode)], ignore_index=True)\r\n>     File \"CNN_regression.py\", line 124, in main\r\n>       history = model.fit(X_train, Y_train,\r\n>     File \"/home/italocaliari/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\r\n>       return fn(*args, **kwargs)\r\n>     File \"/home/italocaliari/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1384, in fit\r\n>       tmp_logs = self.train_function(iterator)\r\n>     File \"/home/italocaliari/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function\r\n>       return step_function(self, iterator)\r\n>     File \"/home/italocaliari/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function\r\n>       outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n>     File \"/home/italocaliari/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step\r\n>       outputs = model.train_step(data)\r\n>     File \"/home/italocaliari/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 859, in train_step\r\n>       y_pred = self(x, training=True)\r\n>     File \"/home/italocaliari/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\r\n>       return fn(*args, **kwargs)\r\n>     File \"/home/italocaliari/.local/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\r\n>       outputs = call_fn(inputs, *args, **kwargs)\r\n>     File \"/home/italocaliari/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\r\n>       return fn(*args, **kwargs)\r\n>     File \"/home/italocaliari/.local/lib/python3.8/site-packages/keras/engine/functional.py\", line 451, in call\r\n>       return self._run_internal_graph(\r\n>     File \"/home/italocaliari/.local/lib/python3.8/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\r\n>       outputs = node.layer(*args, **kwargs)\r\n>     File \"/home/italocaliari/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\r\n>       return fn(*args, **kwargs)\r\n>     File \"/home/italocaliari/.local/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\r\n>       outputs = call_fn(inputs, *args, **kwargs)\r\n>     File \"/home/italocaliari/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\r\n>       return fn(*args, **kwargs)\r\n>     File \"/home/italocaliari/.local/lib/python3.8/site-packages/keras/layers/convolutional.py\", line 248, in call\r\n>       outputs = self.convolution_op(inputs, self.kernel)\r\n>     File \"/home/italocaliari/.local/lib/python3.8/site-packages/keras/layers/convolutional.py\", line 233, in convolution_op\r\n>       return tf.nn.convolution(\r\n> Node: 'model/conv1d/Conv1D'\r\n> DNN library is not found.\r\n> \t [[{{node model/conv1d/Conv1D}}]] [Op:__inference_train_function_660]\r\n\r\n\r\n\r\nI'm running the exact same code with another computer with a Nvidia MX110 and is working just fine. I think this might be a configuration/installation issue related to:\r\n\r\n>  \"Loaded runtime CuDNN library: 8.0.4 but source was compiled with: 8.1.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\" \r\n\r\nI could not find any solution to this problem.\r\n\r\nThank you all in advance.\r\n\r\n", "comments": ["Hi @caliari-italo ! Could you switch to Cuda 11.2 and CuDNN 8.1 and let us know the results ? Attaching [tested configuration](https://www.tensorflow.org/install/source#gpu) for reference. Thanks!", "Unfortunately it didn't worked. The error is still the same even changing Cuda and CuDNN.", "Ok. Please use 2.8.0 stable version with Cuda 11.2 and CudNN 8.1 . Are you loading Pytorch and Tensorflow simultaneously as this[ thread ](https://forums.developer.nvidia.com/t/loaded-runtime-cudnn-incompatible-with-version-used-to-compile-source/180462/5)suggests? Could you provide a simple stand alone code to reproduce this issue too?", "I ended up using the TensorFlow Docker image and it worked just fine.\r\n\r\nhttps://www.tensorflow.org/install/docker", "@caliari-italo ! Shall we move this issue to closed status then?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55309\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55309\">No</a>\n"]}, {"number": 55308, "title": "I am getting the same errors with version 2.8.0 and python 3.9.", "body": "I am getting the same errors with version 2.8.0 and python 3.9.\r\nI need to use class_weight cause of my data is heavily imbalanced. \r\nIf I run without the class_weight, no errors.\r\nIs there solutions or workarounds for this issue?\r\nThanks\r\n\r\n\r\nWhen using a list for class_weight, I got:\r\n```\r\n  File \"/opt/local/stow/Python-3.7.1/lib/python3.7/site-packages/keras/engine/data_adapter.py\", line 1416, in _make_class_weight_map_fn\r\n    class_ids = list(sorted(class_weight.keys()))\r\nAttributeError: 'list' object has no attribute 'keys'\r\n```\r\nWhen using a dictionary for class_weight, I got:\r\n```\r\n  File \"/opt/local/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\", line 55, in quick_execute\r\n    inputs, attrs, num_outputs)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:\r\n\r\nindices[24] = 18 is not in [0, 10)\r\n         [[{{node GatherV2}}]]\r\n         [[IteratorGetNext]] [Op:__inference_train_function_43205]\r\n```\r\nThese errors occur even when I give all classes a weight 1.\r\n\r\nHowever, when I do not use class_weight in model.fit(), the training for my model just works fine.\r\n\r\nSo it looks like I just cannot use class_weight in training. But my classes are highly imbalanced; not using class weights would train a useless model.\r\n\r\nI would really appreciate any solution or workaround for this issue.\r\n\r\nThank you very much!\r\n\r\n_Originally posted by @lauraht in https://github.com/tensorflow/tensorflow/issues/40070#issuecomment-1066037695_", "comments": ["Hello!\r\nI saw this issue was closed; is there a solution or workaround for this issue?\r\nIf so, could you please also share the solution or workaround here? I would greatly appreciate it!\r\nThank you so much!", "Sorry, I posted by mistake as new issue, thats why I closed it.\r\nIt is related to issues/40070 and added there as comment.\r\n"]}, {"number": 55307, "title": "[TPU] TPUClusterResolver Can't Resolve TPU Metadata When Using Regional GKE Cluster", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): tensorflow/tensorflow:2.7.1, tensorflow/tensorflow:2.8.0\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.7.1, 2.8.0\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: cloud-tpus.google.com/preemptible-v2: \"8\"\r\n\r\n**Describe the current behavior**\r\nWe have a GKE regional cluster with TPU support. When I tried to create a ResNet-RS using the official TPU guide, I encountered the issue with TPUClusterResolver.\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/client/client.py\", line 259, in _fetch_cloud_tpu_metadata\r\n    r = service.projects().locations().nodes().get(name=self._full_name())\r\n  File \"/usr/local/lib/python3.8/dist-packages/googleapiclient/discovery.py\", line 1044, in method\r\n    raise TypeError(\r\nTypeError: Parameter \"name\" value \"projects/[PROJECT-CODE]/locations/us-central1-b/nodes/us-central1-b/[TPU-RESOURCE]\" does not match the pattern \"^projects/[^/]+/locations/[^/]+/nodes/[^/]+$\"\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/root/models/official/vision/beta/train.py\", line 70, in <module>\r\n    app.run(main)\r\n  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 312, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 258, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/root/models/official/vision/beta/train.py\", line 50, in main\r\n    distribution_strategy = distribute_utils.get_distribution_strategy(\r\n  File \"/root/models/official/common/distribute_utils.py\", line 151, in get_distribution_strategy\r\n    cluster_resolver = tpu_initialize(tpu_address)\r\n  File \"/root/models/official/common/distribute_utils.py\", line 88, in tpu_initialize\r\n    tf.config.experimental_connect_to_cluster(cluster_resolver)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/remote.py\", line 141, in connect_to_cluster\r\n    if cluster_spec_or_resolver.master() in _LOCAL_MASTERS:\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/cluster_resolver/tpu/tpu_cluster_resolver.py\", line 256, in master\r\n    cluster_spec = self.cluster_spec()\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/cluster_resolver/tpu/tpu_cluster_resolver.py\", line 330, in cluster_spec\r\n    network_endpoints = self._cloud_tpu_client.network_endpoints()\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/client/client.py\", line 346, in network_endpoints\r\n    response = self._fetch_cloud_tpu_metadata()\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/client/client.py\", line 262, in _fetch_cloud_tpu_metadata\r\n    raise ValueError(\"Could not lookup TPU metadata from name '%s'. Please \"\r\nValueError: Could not lookup TPU metadata from name 'us-central1-b/[TPU-RESOURCE]'. Please doublecheck the tpu argument in the TPUClusterResolver constructor. Exception: Parameter \"name\" value \"projects/[PROJECT-CODE]/locations/us-central1-b/nodes/us-central1-b/[TPU-RESOURCE]\" does not match the pattern \"^projects/[^/]+/locations/[^/]+/nodes/[^/]+$\"\r\n```\r\n\r\n**Describe the expected behavior**\r\nThe ResNet-RS job should run in TPU core without any issues.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): No\r\n- Briefly describe your candidate solution(if contributing): N/A\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\nhttps://cloud.google.com/tpu/docs/tutorials/resnet-rs-2.x\r\nRun this guide in a regional GKE cluster with TPU support.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n```\r\napiVersion: v1\r\nkind: Pod\r\nmetadata:\r\n    endpoints.cloud-tpus.google.com/gke: grpc://10.0.0.106:8470\r\n    name.cloud-tpus.google.com/gke: us-central1-b/[TPU-RESOURCE]\r\n  name: gke\r\nspec:\r\n  containers:\r\n  - command:\r\n    - bash\r\n    - -c\r\n    - export PYTHONPATH=$PYTHONPATH:/root/models && cd /root && apt-get update &&\r\n      apt-get install -y git && git clone https://github.com/tensorflow/models.git\r\n      && pip3 install tf-models-nightly tensorflow-text-nightly && pip3 install -r\r\n      models/official/requirements.txt && python3 /root/models/official/vision/beta/train.py\r\n      --experiment=resnet_rs_imagenet --mode=train_and_eval --model_dir=$MODEL_DIR\r\n      --tpu=$TPU_NAME --config_file=/root/models/official/vision/beta/configs/experiments/image_classification/imagenet_resnetrs50_i160.yaml\r\n      --params_override=\"task.train_data.input_path=$IMAGENET_DIR/train*, task.validation_data.input_path=$IMAGENET_DIR/valid*,\r\n      trainer.train_steps=100\" && sleep 900\r\n    env:\r\n    - name: IMAGENET_DIR\r\n      value: gs://cloud-tpu-test-datasets/fake_imagenet\r\n    - name: STORAGE_BUCKET\r\n      value: gs://xxxxx\r\n    - name: MODEL_DIR\r\n      value: gs://xxxxx/resnet-rs-2x_v6\r\n    - name: GOOGLE_APPLICATION_CREDENTIALS\r\n      value: /var/secrets/google/key.json\r\n    - name: KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS\r\n      valueFrom:\r\n        fieldRef:\r\n          apiVersion: v1\r\n          fieldPath: metadata.annotations['endpoints.cloud-tpus.google.com/gke-dgtest-tpu-resnetrs6']\r\n    - name: TPU_NAME\r\n      valueFrom:\r\n        fieldRef:\r\n          apiVersion: v1\r\n          fieldPath: metadata.annotations['name.cloud-tpus.google.com/gke-dgtest-tpu-resnetrs6']\r\n    image: tensorflow/tensorflow:2.8.0\r\n```\r\n", "comments": ["Okay, I just realized that I can use the endpoint IP directly, instead of name. Just change the `--tpu=$TPU_NAME` to `--tpu=$KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS`. It works on my side now within GKE regional cluster.\r\n\r\nI will just leave this ticket as it is, if it is needed to troubleshoot the TPUClusterResolver. Thank you!", "@ZeroExistence ,\r\nCan you please take a look at this issue [link](https://github.com/tensorflow/tensorflow/issues/30869) with the similar error.It helps.", "Also please move this issue to closed status as it has been resolved.Thanks!", "Thank you @tilakrayal for checking! Moving this issue to close.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55307\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55307\">No</a>\n"]}, {"number": 55306, "title": "Ppc build fix", "body": null, "comments": ["Thankfully the check for ROCm build has passed now. Now, the PR is ready for review/merge.\r\n", "I don't see an option to re-trigger the checks. Could someone please do it for me?", "Hello @gbaned and @sherhut , \r\nRequest you to please review this PR.", "@npanpaliya Can you please resolve conflicts? Thanks!", "@gbaned - Yes, I've updated my branch to resolve the conflicts. ", "@gbaned My branch is up-to-date as well as has passed all the checks. I wish if my PR can be reviewed and merged before another LLVM update to master.", "@gbaned - Any comments on this PR?\r\n", "@akuegel - Yes, LLVM fix can go directly into llvm-project too. But adding ppc64le support in LLVM will need more work and verification. \r\nFor TF to compile, only this change is needed in llvm and hence I added a patch in TF itself (TF follows this approach anyway).\r\nI'm working on llvm-project too but it will take time. Hence raised this PR to TF to fix the builds.", "> @akuegel - Yes, LLVM fix can go directly into llvm-project too. But adding ppc64le support in LLVM will need more work and verification. For TF to compile, only this change is needed in llvm and hence I added a patch in TF itself (TF follows this approach anyway). I'm working on llvm-project too but it will take time. Hence raised this PR to TF to fix the builds.\r\n\r\nOk, good to know that you are planning to change this in LLVM, too :)\r\nThis patching mechanism is meant to be used only short term (as far as I know), e.g. if the LLVM revision we want to use has some issues with GCC which will be fixed with a later LLVM revision, or if the Bazel build was broken at that revision. We have a bug filed to remove this macos patch file that we currently have there."]}, {"number": 55305, "title": "`tf.strings.unsorted_segment_join` crashes unexpectedly when `num_segments` is negative", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):2.8.0\r\n- Python version: 3.7.12\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\nGiven the following code snippet:\r\n```\r\nimport tensorflow as tf\r\n\r\ntry:\r\n  tf.strings.unsorted_segment_join(inputs=['123'],segment_ids=[0],num_segments=-1)\r\nexcept Exception:\r\n  print('an exception should be thrown, but unsorted_segment_join crashes')\r\n\r\nprint('Not reached')\r\n```\r\nthe call to `tf.strings.unsorted_segment_join`  causes a crash.\r\n\r\n**Describe the expected behavior**\r\n\r\nSince `num_segments` is negative, an exception should be thrown (perhaps an `InvalidArgumentError` or `ValueError`. The code should not crash.\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nThe code snippet above should reproduce the issue. \r\n\r\nThe following colab notebook (running the notebook should crash the session) demonstrates the issue: https://colab.research.google.com/drive/1zoYVGQXY9MlYgbtW4N3lC51yC8wQh5J2?usp=sharing\r\n\r\n", "comments": ["Hi @chunduriv ! Could you please look at this issue? It is replicating[ 2.7](https://colab.sandbox.google.com/gist/mohantym/250cc06f9006f7f406e88a64a3d97988/unexpected-crash-on-unsorted_segment_join-due-to-invalid-value-of-num_segments.ipynb#scrollTo=fwNys377gUGZ), [2.8 ](https://colab.sandbox.google.com/gist/mohantym/d226528fd7dca6e208a7c9b3ebbc18c4/unexpected-crash-on-unsorted_segment_join-due-to-invalid-value-of-num_segments.ipynb#scrollTo=fwNys377gUGZ)and [nightly](https://colab.sandbox.google.com/gist/mohantym/3a38571d2f553145bb038109198167f5/unexpected-crash-on-unsorted_segment_join-due-to-invalid-value-of-num_segments.ipynb#scrollTo=_f0oULUsaDZd).", "Reproduced\r\n\r\n```\r\nIn [6]: tf.strings.unsorted_segment_join(inputs=['123'],segment_ids=[0],num_segments=-1)\r\nF0322 11:23:25.727334 1107260 tensor_shape.cc:396] Check failed: size >= 0 (-1 vs. 0) \r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55305\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55305\">No</a>\n"]}, {"number": 55302, "title": "Update BUILD", "body": null, "comments": ["Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nFor more information, open the [CLA check for this pull request](https://github.com/tensorflow/tensorflow/pull/55302/checks?check_run_id=5616655665).", "@Jackzhang001001 Can you please sign CLA. Thanks!"]}, {"number": 55301, "title": "Applearning", "body": null, "comments": []}, {"number": 55300, "title": "Installation Issue - OSError: [Errno 2] No such file or directory: ...\\\\BufferizableOpInterface.cpp.inc", "body": "**System information**\r\n- OS Platform and Distribution: Windows 11 Professional \r\n- TensorFlow installed from: binary (`pip install tensorflow`)\r\n- TensorFlow version: 2.8.0\r\n- Python version: 3.10.3\r\n- Installed using virtualenv: `pip`\r\n- CUDA/cuDNN version: 11.6\r\n- GPU model and memory: NVIDIA RTX A2000 / RAM 32 GB\r\n\r\nTrying to install tensorflow on my PC (system described above) and found an issue as follows at the end of `pip install tensorflow`:\r\n\r\n```\r\nInstalling collected packages: tensorflow\r\nERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\%PathToRepo%\\\\tfenv\\\\Lib\\\\site-packages\\\\tensorflow\\\\include\\\\external\\\\llvm-project\\\\mlir\\\\_virtual_includes\\\\BufferizableOpInterfaceIncGen\\\\mlir\\\\Dialect\\\\Linalg\\\\ComprehensiveBufferize\\\\BufferizableOpInterface.cpp.inc'\r\n```\r\n\r\n`tfenv` is the name of the virtual environment I've created using the command `python -m venv --system-site-packages tfenv`.\r\nI've installed the pre-requisite (Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017 and 2019) from this [link](https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads). I'm guessing the error is somehow related to the MS Visual C++ or the virtual environment, but I'm not sure how.\r\n\r\nCould you help me please? Thank you in advance.", "comments": ["Similar to #46934", "Hi @ahmad-alkadri ! Can you check this [thread](https://stackoverflow.com/a/66754914/11530462) as workaround and let us know the results?  Thank you!", "> Hi @ahmad-alkadri ! Can you check this [thread](https://stackoverflow.com/a/66754914/11530462) as workaround and let us know the results? Thank you!\r\n\r\nAlright the installation succeeded! You're right the problem is the character limit on the path. Deactivating this limit on Windows is the solution. Thanks again!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55300\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55300\">No</a>\n"]}, {"number": 55299, "title": "Using Numpy BitGenerator with TF-1.15 (?)", "body": "Hi\r\nI am running minigo code from [here](https://github.com/mlcommons/training_results_v1.1/tree/main/NVIDIA/benchmarks/minigo/implementations/tensorflow/minigo). Although TF-1.15 and Numpy 1.17.3 are installed, I get the following error\r\n\r\n```\r\n  File \"freeze_graph.py\", line 19, in <module>\r\n    import dual_net\r\n  File \"/opt/reinforcement/minigo/dual_net.py\", line 32, in <module>\r\n    import tensorflow as tf\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow_core/__init__.py\", line 36, in <module>\r\n    from tensorflow._api.v1 import compat\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow_core/_api/v1/compat/__init__.py\", line 23, in <module>\r\n    from tensorflow._api.v1.compat import v1\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow_core/_api/v1/compat/v1/__init__.py\", line 673, in <module>\r\n    from tensorflow_estimator.python.estimator.api._v1 import estimator\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator._api.v1 import estimator\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/_api/v1/estimator/__init__.py\", line 12, in <module>\r\n    from tensorflow_estimator._api.v1.estimator import inputs\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/_api/v1/estimator/inputs/__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator.python.estimator.inputs.numpy_io import numpy_input_fn\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/inputs/numpy_io.py\", line 26, in <module>\r\n    from tensorflow_estimator.python.estimator.inputs.queues import feeding_functions\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py\", line 40, in <module>\r\n    import pandas as pd\r\n  File \"/usr/local/lib/python3.8/dist-packages/pandas/__init__.py\", line 22, in <module>\r\n    from pandas.compat import is_numpy_dev as _is_numpy_dev\r\n  File \"/usr/local/lib/python3.8/dist-packages/pandas/compat/__init__.py\", line 14, in <module>\r\n    from pandas._typing import F\r\n  File \"/usr/local/lib/python3.8/dist-packages/pandas/_typing.py\", line 120, in <module>\r\n    np.random.BitGenerator,\r\nAttributeError: module 'numpy.random' has no attribute 'BitGenerator'\r\n```\r\nAny idea about that? Am I missing something?", "comments": ["@mahmoodn,\r\n\r\nWe see that you are using old version of tensorflow (1.x) which is not actively supported. We recommend that you upgrade to 2.8.0 and let us know if the issue still persists in newer versions .Thanks!\r\n\r\nCan you take a look at this [link1](https://github.com/Nuitka/Nuitka/issues/659#issuecomment-632275406), [link2](https://github.com/aleju/imgaug/issues/537#issuecomment-1064647150) which discusses about the similar issue? It may help you. Thanks!", "OK. Based on the solution proposed in link2, `np.random.bit_generator.BitGenerator` fixed the error. Thanks.", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)"]}, {"number": 55298, "title": "org.tensorflow:tensorflow-lite-support:0.3.1 has missing files", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nWhen trying to deploy a TFLite model in Android Studio, I received the error ClassNotFound: about org.tensorflow.lite.support.common.SupportPreconditions.\r\n**Describe the expected behavior**\r\nNo error.\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\nmodelPath = \"local_path_of_model\"\r\nAudioClassifier model = AudioClassifier.createFromFile(requireContext(), modelPath);\r\nTensorAudio tensor = model.createInputTensorAudio();\r\nAudioRecord record = model.createAudioRecord();\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\nWhen I downgraded to org.tensorflow:tensorflow-lite-support:0.3.0, I didn't receive the error anymore.\r\n", "comments": ["@IoanaKitsune ,\r\nCan you please refer this link which helps to upgrade [TFLite Support 0.3.1](https://github.com/tensorflow/tflite-support/releases/tag/v0.3.1). Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "I face the same error and i figure out the problem.\r\nActually the problem is `SupportPreconditions.java` is in `/org/tensorflow/lite/support/common/internal/SupportPreconditions.java` not in `/org/tensorflow/lite/support/common/SupportPreconditions.java`\r\nWith lastest version of `tensorflow-lite-support:0.3.1`\r\nAnd this cause a problem with `implementation 'org.tensorflow:tensorflow-lite-task-audio:0.3.0'`\r\nAnd here's the full stacktrace:\r\n```Java\r\njava.lang. NoClassDefFoundError: Failed resolution\r\nof:Lorg/tensorflow/lite/support/common/SupportPreconditions;\r\nat\r\norg.tensorflow.lite.task.audio.classifier.AudioClassifier.createAudioRecord (AudioClassifier.java:473)\r\nat com.test.noplv.MainActivity.onCreate (MainActivity.java:45)\r\nat android.app.Activity.performCreate(Activity.java:7335)\r\nat\r\nandroid.app.Activity.performCreate (Activity.java:7326)\r\nat\r\nandroid.app.Instrumentation.callActivityOnCreate(Inst rumentation.java:1275) at\r\nandroid.app.ActivityThread.performLaunchActivity (ActivityThread.java:3119)\r\n\r\nat\r\nandroid.app.ActivityThread.handleLaunchActivity (ActivityThread.java:3282)\r\nat\r\nandroid.app.servertransaction.LaunchActivityItem.exec ute (LaunchActivityItem.java:78)\r\nat\r\nandroid.app.servertransaction.TransactionExecutor.exe cuteCallbacks (TransactionExecutor.java:108) at\r\nandroid.app.servertransaction.Transaction Executor.exe cute(TransactionExecutor.java:68)\r\nat\r\nandroid.app.Activity Thread$H.handleMessage (ActivityTh read.java:1970)\r\nat\r\nandroid.os.Handler.dispatchMessage(Handler.java:106)\r\nat android.os.Looper.loop (Looper.java:214) \r\nat\r\nandroid.app.ActivityThread.main(ActivityThread.java: 7156) at java.lang.reflect.Method.invoke (Native Method)\r\nat\r\ncom.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:494)\r\n```\r\nI hope you understand me\r\nThanks in advance.", "Oh, I see, thank you so much. I temporarily downgraded and it worked, but I\nthink your solution helps a lot!\n\nOn Fri, Apr 1, 2022, 03:03 Agono0 ***@***.***> wrote:\n\n> I face the same error and i figure out the problem.\n> Actually the problem is SupportPreconditions.java is in\n> /org/tensorflow/lite/support/common/internal/SupportPreconditions.java\n> not in /org/tensorflow/lite/support/common/SupportPreconditions.java\n> With lastest version of tensorflow-lite-support:0.3.1\n> And this cause a problem with implementation\n> 'org.tensorflow:tensorflow-lite-task-audio:0.3.0'\n> And here's the full stacktrace:\n>\n> java.lang. NoClassDefFoundError: Failed resolutionof:Lorg/tensorflow/lite/support/common/SupportPreconditions;atorg.tensorflow.lite.task.audio.classifier.AudioClassifier.createAudioRecord (AudioClassifier.java:473)at com.test.noplv.MainActivity.onCreate (MainActivity.java:45)at android.app.Activity.performCreate(Activity.java:7335)atandroid.app.Activity.performCreate (Activity.java:7326)atandroid.app.Instrumentation.callActivityOnCreate(Inst rumentation.java:1275) atandroid.app.ActivityThread.performLaunchActivity (ActivityThread.java:3119)\n> atandroid.app.ActivityThread.handleLaunchActivity (ActivityThread.java:3282)atandroid.app.servertransaction.LaunchActivityItem.exec ute (LaunchActivityItem.java:78)atandroid.app.servertransaction.TransactionExecutor.exe cuteCallbacks (TransactionExecutor.java:108) atandroid.app.servertransaction.Transaction Executor.exe cute(TransactionExecutor.java:68)atandroid.app.Activity Thread$H.handleMessage (ActivityTh read.java:1970)atandroid.os.Handler.dispatchMessage(Handler.java:106)at android.os.Looper.loop (Looper.java:214) atandroid.app.ActivityThread.main(ActivityThread.java: 7156) at java.lang.reflect.Method.invoke (Native Method)atcom.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:494)\n>\n> I hope you understand me\n> Thanks in advance.\n>\n> \u2014\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/55298#issuecomment-1085248167>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ALDLVBGJ2FEENM42VRNKNPDVCY4MDANCNFSM5REA5BJQ>\n> .\n> You are receiving this because you were mentioned.Message ID:\n> ***@***.***>\n>\n", "@IoanaKitsune ,\r\nCould you please confirm if the issue is resolved. if yes, please feel free to move this issue to closed status ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55298\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55298\">No</a>\n", "Properly not solved for me, any help.\r\nI describe the issue . But I didn't solve it", "I must modify the library files or what?\r\nThen if yes.\r\nhow l can move `SupportPreconditions.java` then?"]}, {"number": 55297, "title": "how to change tensorflow version if build from source?", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04 lts\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: master\r\n- Python version: 3.10.2\r\n- Bazel version (if compiling from source): 5.0.0\r\n- GCC/Compiler version (if compiling from source): 9.3.0\r\n- CUDA/cuDNN version: 11.2/8.1\r\n- GPU model and memory: RTX 3090\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nI am trying to build tensorflow from source. Everything works good and I successfully build it based on master branch. \r\n\r\nAfter I get the `.whl` package, I installed it and checked the version number. I get the following output:\r\n\r\n```\r\nPython 3.9.5 (default, Jun 18 2021, 13:37:06)\r\n[GCC 9.3.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> tf.__version__\r\n'2.9.0'\r\n>>>\r\n```\r\n\r\nI get the version number as `'2.9.0'`. it makes sense as I build based on master branch and the current release is `2.8.0`. However, I wish to customize the version number, for example, as `2.9.0--xxx` so that I know what features I added into this build. I thought there should be a setup file or something I can change but I cannot find it. Any ideas? Thx!\r\n\r\n", "comments": ["Hi @WingsOfPanda ! Once you cloned Tensorflow repo and entered into tensoflow folder through cd command , you can use `git checkout branch_name ` # r2.2, r2.3,r2.8 etc to select a release branch. Attaching relevant[ thread](https://www.tensorflow.org/install/source#download_the_tensorflow_source_code) for reference. Thanks!", "@WingsOfPanda please refer to how the master bump the version number from 2.8.0 to 2.9.0\r\n2719182f888c16b44dba504c2f2d2240ddc9396d", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55297\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55297\">No</a>\n"]}, {"number": 55295, "title": "Plugin implementation of AssignVarOp", "body": "I am struggling a lot to understand how plugins (pluggable device) should implement `AssignVarOp`.\r\n\r\nI created a [post](https://discuss.tensorflow.org/t/how-does-assignvarop-work/8335/3) on the discussion forum but it seems like no one is able to answer pluggable device questions.\r\n\r\nI am trying to run a `Conv2D` on a separate device (only dummy for now) using the pluggable device interface.\r\nI implemented the `Conv2D` kernel, and when running tensorflow asked for an implementation of `AssignVarOp`.\r\nSo I started implementing `AssignVarOp`, it has two input tensors (variable and value), variable is a tensor of type `TF_RESOURCE`.\r\nI imagine I should modify the data of the resource tensor, but what does it contain?\r\nAfter further research, it looks like `VarHandleOp` is the kernel responsible for the creation of the variable (and it's resource). \r\nSo I wrote a kernel for `VarHandleOp`. Checking the parameters at runtime, they are all uninitialized at the first call (`shared_name` is a default value, `shape` unitialized, etc).\r\nSo I am left with two choices:\r\n- Either I would update the variable attributes later (doesn't seem possible as the C api doesn't provide any function for modifying an input tensor dimensions)\r\n- Either I should store all dimensions, etc in the resource tensor data in the form of a `ResourceHandle`. Is this `Resourcehandle` type arbitrarily defined by the user?\r\n\r\nI have been following this basic [tutorial](https://github.com/jzhoulon/community/blob/plugin_tutorial/rfcs/20200624-pluggable-device-for-tensorflow/tutorial.md) for writing tensorflow plugins, but the logic for variable handling is missing and it seems like a necessary step for plugins.\r\n\r\n**I will be really thankful if the tensorflow team (or anyone) could help me understand the mechanism of variable handling for plugins.**\r\n\r\n**Thank you.**", "comments": ["@slai-nick,\r\n[This post](https://blog.tensorflow.org/2021/06/pluggabledevice-device-plugins-for-TensorFlow.html), introduces the [PluggableDevice](https://github.com/tensorflow/community/blob/master/rfcs/20200624-pluggable-device-for-tensorflow.md) architecture which offers a plugin mechanism for registering devices with TensorFlow without the need to make changes in TensorFlow code. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55295\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55295\">No</a>\n"]}, {"number": 55292, "title": "`tf.experimental.numpy.array` should have the same behavior as `numpy.array`, but currently crashes", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): N/A\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.8.0\r\n- Python version: 3.7.12\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nCurrently, the following code snippet below leads to a crash due to the incorrect value of `ndmin`.\r\n```\r\na = tf.constant(value=1)\r\nb = tf.constant(value=1000)\r\ntf.experimental.numpy.array(val=a,ndmin=b)\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nIt should not crash.\r\nIt should have the  same behavior as numpy.array given the same inputs (in which ndmin is validated):\r\n`ValueError: ndmin bigger than allowable number of dimensions NPY_MAXDIMS (=32)`\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nThe following colab demonstrates the issue:\r\nhttps://colab.research.google.com/drive/1Voz0WB5TCt3s5pQ2etIU3HFBZqN-YVFc?usp=sharing\r\n\r\n", "comments": ["@kanghj ,\r\nI have tried in colab with v 2.8 version and noticed that session is being crashed. Please, find the gist [here](https://colab.research.google.com/gist/tilakrayal/39587d8c4222dbbb35d876cb316973be/untitled255.ipynb). Also please find the errorlog of the crashed colab which stated as below.\r\n`Check failed: ndims_byte() < MaxDimensions() (unsigned char value 254 vs. 254)Too many dimensions in tensor`", "Thanks for checking. \r\n\r\nYes, indeed it crashes, which I am reporting as a bug. The expected, correct behavior is that`tf.experimental.numpy.array` should throw an exception (perhaps a `ValueError`, same as numpy.array), and not crash. Crashing is an unexpected, wrong behavior. ", "@chunduriv ,\r\nI have tried in colab with tf v2.8, v2.7, nightly and noticed that session is being crashed. Please, find the gist [here](https://colab.research.google.com/gist/tilakrayal/a0505cddfd9e7663e5c56e945b74b912/55292.ipynb). Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55292\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55292\">No</a>\n"]}, {"number": 55289, "title": "The code says that it failed to save and then never ran properly again. basically i upload a picture and then it shows the right prediction but the second picture it run into error but if i start with second photo as my first inout then it show the correct prediction ", "body": "from google.colab import files\r\nuploaded = files.upload()\r\n\r\nnew_image = plt.imread('20220316_134951.jpg')\r\nimg = plt.imshow(new_image)\r\n\r\nfrom skimage.transform import resize\r\nresized_image = resize(new_image, (IMG_SIZE,IMG_SIZE,3))\r\nimg = plt.imshow(resized_image)\r\n\r\n\r\n\r\npredictions = model.predict(np.array([resized_image]))\r\n\r\npredictions\r\n\r\nlist_index = [0,1,2,3,4]\r\nx = predictions\r\n\r\nfor i in range(5):\r\n  for j in range(5):\r\n    if x[0][list_index[i]] > x[0][list_index[j]]:\r\n      temp = list_index[i]\r\n      list_index[i] = list_index[j]\r\n      list_index[j] = temp\r\n\r\nfor i in range(3):\r\n  print(CATEGORIES[list_index[i]], ':', predictions[0][list_index[i]] *100, '%')\r\n\r\nprint(CATEGORIES[list_index[0]])\r\n", "comments": ["@youssefelnaggar ,\r\n In order to expedite the trouble-shooting process, could you please provide  code dependencies and the TensorFlow version you are using.Also could you please create a virtual environment and test your code again. It helps. Thanks!\r\n\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 55288, "title": "Update the RBE images to the latest container versions", "body": "Automated PR created once per week to get the latest Docker images.\nSee https://github.com/tensorflow/tensorflow/blob/master/.github/workflows/update-rbe.yml", "comments": []}, {"number": 55287, "title": "Update the RBE images to the latest container versions", "body": "Automated PR created once per week to get the latest Docker images.\nSee https://github.com/tensorflow/tensorflow/blob/master/.github/workflows/update-rbe.yml", "comments": ["Hmm, that's not right. I'll have to look at this again next week."]}, {"number": 55286, "title": "[oneDNN] Fix gru_v2_test_gpu and layer_correctness_test_gpu tests", "body": "Add device check to make sure the fusions available for oneDNN only happen for CPU.", "comments": ["> Thank you for the PR! Would you mind posting the error messages?\r\n\r\nThe error message:\r\nNo registered '_FusedMatMul' OpKernel for 'GPU' devices compatible with node node model_1/gru/while/gru_cell/add_1 . Registered: device='CPU'; T in [DT_BFLOAT16] device='CPU'; T in [DT_FLOAT] [[model_1/gru/while/body/_1/model_1/gru/while/gru_cell/add_1]] [Op:__inference_train_function_7022]", "When fixing the specific error we also found other places where oneDNN specific fusions were happening for GPU so added device check for those cases as well."]}, {"number": 55285, "title": "Crashed if using different types of grad in adadelta optimizer", "body": "\r\n\r\n\r\nI'm trying to use adadelta optimizer in my training process but it crashed. It came to that I used different types of value in grad parameters.\r\n\r\n**System information**\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.8.0\r\n- Python version: 3.7.11\r\n\r\n**Describe the current behavior**\r\n\r\nCrashed with error info.\r\n\r\n**Describe the expected behavior**\r\n\r\nError info could show the wrong type and would not crash.\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nfrom tensorflow.python.eager import context\r\nfrom tensorflow.python.framework import constant_op\r\nfrom tensorflow.python.framework import dtypes\r\nfrom tensorflow.python.ops import variables\r\nfrom tensorflow.python.training import adadelta\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    num_updates = 4\r\n    for grad in [0.2, 0.1, 0.01]:\r\n      for lr in [1.0, 0.5, 0.1]:\r\n          var0_init = [1.0, 2.0]\r\n          var1_init = [3.0, 4.0]\r\n          var0 = variables.Variable(var0_init, dtype=dtypes.float32)\r\n          var1 = variables.Variable(var1_init, dtype=dtypes.float32)\r\n          grads = constant_op.constant([grad, grad], dtype=dtypes.float16) # will pass if use dtypes.float32\r\n          accum = 0.0\r\n          accum_update = 0.0\r\n          rho = 0.95\r\n          epsilon = 1e-08\r\n\r\n          adadelta_opt = adadelta.AdadeltaOptimizer(learning_rate=lr, rho=rho, epsilon=epsilon)\r\n          if (not context.executing_eagerly()):\r\n              adadelta_update = adadelta_opt.apply_gradients(zip([grads, grads], [var0, var1]))\r\n\r\n              slot = ([None] * 2)\r\n              slot_update = ([None] * 2)\r\n\r\n          for step in range(num_updates):\r\n              adadelta_opt.apply_gradients(zip([grads, grads], [var0, var1]))\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\n\r\n```\r\n2022-03-19 05:46:32.562381: F tensorflow/core/framework/tensor.cc:718] Check failed: dtype() == expected_dtype (1 vs. 19) half expected, got float\r\n\r\nAborted (core dumped)\r\n```\r\n", "comments": ["Hi @gadagashwini ! Could you please look at this issue ? It is replicating in [2.7](https://colab.sandbox.google.com/gist/mohantym/6a2ebad30a7db9f181cf2d47c09a2430/github_55285.ipynb#scrollTo=58QL9gwiaX6H),[2.8 ](https://colab.sandbox.google.com/gist/mohantym/df41dba14c4a368adb3d34fe8fef6244/github_55285.ipynb#scrollTo=58QL9gwiaX6H)and [nightly](https://colab.sandbox.google.com/gist/mohantym/40a1f41730db516a90fa94515ab5268d/github_55285.ipynb#scrollTo=58QL9gwiaX6H) .", "Could you please try with the experimental Adadelta from Keras here https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/experimental/Adadelta and let us know if you find the similar behavior. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55285\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55285\">No</a>\n"]}, {"number": 55284, "title": "self._interpreter.AllocateTensors() returns with error : +1: Node number 189 (ADD) failed to prepare.", "body": "After converting model to tflite successfully getting error at interpreter.AllocateTensors() \r\n### 1. System information\r\ntensorflow 2.6\r\nonnx 1.9\r\npython 3.6\r\n\r\n#### code to invoke the TFLite Converter Python API and the errors.\r\nconverter = tf.lite.TFLiteConverter.from_saved_model('/model.pb')\r\n converter.target_spec.supported_ops = [\r\n        tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.\r\n        tf.lite.OpsSet.SELECT_TF_OPS  # enable TensorFlow ops.\r\n    ]\r\n    \r\n  tflite_model = converter.convert()\r\n  tflite_model_path = 'test_net_.tflite'\r\n    # Save the model\r\n  with open(tflite_model_path, 'wb') as f:\r\n        f.write(tflite_model)\r\ninterpreter = tf.lite.Interpreter(model_path=\"test_net_.tflite\")\r\ninterpreter.allocate_tensors()\r\n\r\nerror logs:\r\nINFO: Created TensorFlow Lite delegate for select TF ops.\r\n2022-03-18 12:56:44.148260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-03-18 12:56:44.149833: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\nINFO: TfLiteFlexDelegate delegate: 11 nodes delegated out of 1402 nodes with 3 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 1 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 0 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 0 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 1 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 1 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 0 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 0 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 1 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 2 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 14 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 2 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 14 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 2 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 14 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 1 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 14 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 1 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 8 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 2 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 14 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 2 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 14 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 2 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 14 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 2 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 14 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 2 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 14 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 2 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 14 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 1 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 1 nodes delegated out of 14 nodes with 1 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 1 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 8 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 2 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 14 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 2 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 14 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 2 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 14 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 2 nodes with 0 partitions.\r\n\r\nINFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 14 nodes with 0 partitions.\r\n\r\nTraceback (most recent call last):\r\n  \r\n  File \"/home/usr/.local/lib/python3.6/site-packages/tensorflow/lite/python/interpreter.py\", line 423, in allocate_tensors\r\n    return self._interpreter.AllocateTensors()\r\nRuntimeError: Given shapes, [1, 63, 95, 256] and [1, 64, 96, 256], are not broadcastable.Node number 189 (ADD) failed to prepare.\r\n\r\n", "comments": ["@MadhuriPatil1694,\r\n\r\nIn order to expedite the trouble-shooting process, please provide a complete code snippet  and `model.pb` to reproduce the issue reported here. Thanks!\r\n", "> @MadhuriPatil1694,\r\n> \r\n> In order to expedite the trouble-shooting process, please provide a complete code snippet and `model.pb` to reproduce the issue reported here. Thanks!\r\n\r\ntensorflow model and the converted tflite model is at path https://drive.google.com/drive/folders/1BAGSERjLu5Qgrp47rXGJF8ByfLv9K33v?usp=sharing", "tensorflow model was obtained from pytorch model using onnx to tensorflow conversion\r\nusing script \r\nmodel = onnx.load(\r\n    \"/training/final_model/model.onnx\")\r\n    tf_rep = tf_backend.prepare(model, device='cpu', logging_level='INFO',)", "I was able to replicate the issue using TF2.8. Please find the gist [here](https://colab.sandbox.google.com/gist/mohantym/c9888d6e3d0a1a45e8390d72d6236464/github_55284.ipynb) for reference.", "@MadhuriPatil1694 could you check if the inputs provided has the right shape? Refer to https://github.com/tensorflow/tensorflow/issues/49216", "@MeghnaNatraj  Yes while exporting the model I provided the correct input shape"]}, {"number": 55283, "title": "The tensorflow training freezes for no reason", "body": "I run a deep learning training code written in tensorflow and it seems stuck at the following code:\r\n```python\r\nhistory = model.fit(X_train_all, Y_train_all,\r\n                        epochs=nb_epoch,\r\n                        batch_size=batch_size,\r\n                        validation_data=(X_test, Y_test),\r\n                        # callbacks=[early_stopping, model_checkpoint],\r\n                        # callbacks=[model_checkpoint, lr_callback],\r\n                        callbacks=[model_checkpoint],\r\n                        verbose=0)\r\n```\r\nI tried to look closely and found it actually stuck at \r\n```python\r\n# coding=utf-8\r\ndef outer_factory():\r\n\r\n    def inner_factory(ag__):\r\n\r\n        def tf__rmse(y_true, y_pred):\r\n            with ag__.FunctionScope('rmse', 'fscope', ag__.STD) as fscope:\r\n                do_return = False\r\n                retval_ = ag__.UndefinedReturnValue()\r\n                try:\r\n                    do_return = True\r\n                    retval_ = (ag__.converted_call(ag__.ld(mean_squared_error), (ag__.ld(y_true), ag__.ld(y_pred)), None, fscope) ** 0.5)\r\n                except:\r\n                    do_return = False\r\n                    raise\r\n                return fscope.ret(retval_, do_return)\r\n        return tf__rmse\r\n    return inner_factory\r\n```\r\nThe outputs:\r\n```bash\r\ntraining model...\r\n/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\r\n  \"Even though the tf.config.experimental_run_functions_eagerly \"\r\n2022-03-18 07:54:21.572669: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\r\n2022-03-18 07:54:21.589590: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2300020000 Hz\r\n2022-03-18 07:54:21.624242: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\r\n2022-03-18 07:54:23.469658: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\r\n2022-03-18 07:54:23.863409: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\r\n/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\r\n  \"Even though the tf.config.experimental_run_functions_eagerly \"\r\n```\r\n<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): `pip3 install tensorflow ==2.4.1`\r\n- TensorFlow version (use command below): tensorflow                    2.4.1\r\n- Python version: Python 3.6.9\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA Version: 11.6 \r\n- GPU model and memory: Tesla V100-SXM2...\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["I also run other tensorflow codes, they all work well. I guess if it is the problem of the model achitecture? ", "@pengzhangzhi ,\r\nCan you please update to latest tensorflow version v2.8  from this [link](https://www.tensorflow.org/install/source#gpu) and test your code.It helps.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55283\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55283\">No</a>\n"]}, {"number": 55281, "title": "Simplify the DoPoolForward/Backward", "body": "This PR simplifies the code base for the pooling ops by following the style set by the `DoConvolve()`. This can also help reducing the duplicate code for our ongoing PR that supports big tensors.\r\n\r\ncc. @nluehr ", "comments": ["Gentle ping: Any updates? @jurahul ", "The \"Linux GPU\" failed but it seems it was due to the invocation tool failure. Can you take a look? Thx, @jurahul ", "\"feedback/copybara\" failed but I don't have access to the log. Can you take a look? @jurahul  Thx.", "Yes, I am looking into this. There are build failures from this change in internal code, which we need to fix on our side before this can be merged."]}, {"number": 55280, "title": "Implemented RaggedTensor.from_sparse for multi-dimensional SparseTensor", "body": "Implemented a more general version of `RaggedTensor.from_sparse`, now allowing conversion from multi-dimensional `SparseTensor`s to `RaggedTensors`.\r\n\r\nTo compare the performance with the original implementation specifically for the case of 2D sparse matrices, I simulated a random (1000, 1000) sparse tensor, with 50% sparsity. Under eager mode, the run time for the original implementation is 17.1  ms +/- 589 us, and the new implementation is 15.4 ms +/- 420 us. The performance wasn't worse.", "comments": ["Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nFor more information, open the [CLA check for this pull request](https://github.com/tensorflow/tensorflow/pull/55280/checks?check_run_id=5595025849).", "Found a problem. Close for now."]}, {"number": 55279, "title": "Build from Source Instructions for Tensorflow C++ on Linux", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/cc\r\nhttps://blog.devgenius.io/standalone-c-build-tensorflow-opencv-6dc9d8a1412d\r\n\r\n## Description of issue (what needs changing):\r\nPlease could you provide clear instructions for building Tensorflow C++ 2.x (2.4 and above) on Linux and potentially how to use the built library in a project with all its dependencies such as Eigen, protobuf and abseil? \r\n\r\n### Clear description\r\nThe documentation says that Tensorflow provides a stable C++ API but no build and usage (compiling and linking with CMake) appear to exist in documentation. I have spent a lot of time  dredging  for relevant information in articles and stackoverflow and realised that most of it is outdated becasue bazel-genfiles  folder doesnt exist and has been replaced quite possibly with bin folder, and there is no contrib file as well anymore which allowed easy building of dependencies. \r\n\r\nIt would be of great help if the Tensorflow Developers could demonstrate through a simple example for VS Code (it has become a standard) in Ubuntu, how to compile and link the library using CMake and ideally a descriptive example where a developer gets the idea of the capability of C++ API? It would be very useful if you could please make it clear what is possible with C++ API and what is not. For instance if C++ API also allows building the graph or just accepts the .pb file or how much of this example can be done in C++ API for instance as a cross reference: https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras ? \r\n\r\nIs it possible to do everything in C++ and not use Python at all ? \r\n\r\nWhy should someone use this method? How is it useful?\r\nTensorflow documentation should be the one stop shop for all official information about tensorflow especially associated with building, compiling and linking the library where the API is available, There is information on C API but not C++. Tensorflow is written in C++ (I believe) so it is not unfair to request the developers to help guide the users, how to use the C++ API well. Not sure why this hasn't already been done. If this information exists somewhere, I would very much appreciate if you could please make it more obvious. Python is popular but C++ is also useful in production performant environments. You all are doing a great job developing and building this library and I can only be grateful for that. I am very much hoping that you would help me and many other developers. Thanks very much. \r\n\r\n\r\n", "comments": ["@amehrish,\r\n\r\nBuild Tensorflow C++ from source using\r\n\r\n`bazel build -c dbg --config=opt //tensorflow:tensorflow_cc.dll`", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55279\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55279\">No</a>\n"]}]