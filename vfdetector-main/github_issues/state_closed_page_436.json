[{"number": 40782, "title": "[CherryPick 2.3] Exclude ML InlineAdvisor source files in LLVM BUILD", "body": "PiperOrigin-RevId: 318137323\nChange-Id: I31d01d9942935a0e2d612d0521d746221117f6dd", "comments": ["this is not needed for the r2.3 branch, closing this PR."]}, {"number": 40781, "title": "TFLite quantized hard_swish operator precision issue", "body": "Hi TFlite team,\r\n\r\nGit hash: b8a267a9fe95dea518cb04c726031e96874d26a0, dated at Jun 9 2020\r\n\r\nDescription:\r\n\r\nWhen I run quantized mobilenet v3, I found an infrequent precision issue in quantized hard_swish operator. Let me directly walk through the example to start. \r\n\r\nNote I already stripped off every other operators in mobilenet v3 models and tensor resized to [1] to make it clear and easier to run. The text below is the tflite .mlir. \r\n```\r\nmodule attributes {tfl.description = \"TOCO Converted.\", tfl.schema_version = 3 : i32} {\r\n  func @main(%arg0: tensor<1x!quant.uniform<u8:f32, 0.13308307528495789:105>>) -> tensor<1x!quant.uniform<u8:f32, 0.075572937726974487:5>> attributes {tf.entry_function = {inputs = \"input\", outputs = \"MobilenetV3/expanded_conv_6/expand/hard_swish/mul_1\"}} {\r\n    %0 = \"tfl.hard_swish\"(%arg0) : (tensor<1x!quant.uniform<u8:f32, 0.13308307528495789:105>>) -> tensor<1x240x!quant.uniform<u8:f32, 0.075572937726974487:5>>\r\n    return %0 : tensor<1x!quant.uniform<u8:f32, 0.075572937726974487:5>>\r\n  }\r\n}\r\n```\r\nA mismatch happens here when input element is 128, and here's how I calculate the expected number:\r\n\r\nreal_input_value = (quantized_input_value - input_zp) * input_scale = (128 - 105) * 0.13308307528495789 = 3.0609113\r\nreal_output_value = x * relu6(x+3) / 6 = x (if x > 3) = 3.0609113\r\nquantized_output_value = round_to_nearest(real_output_value / output_scale) + output_zp = 3.0609113 / 0.075572937726974487 + 5 = round(40.502742) + 5 = 41 + 5 = 46\r\n\r\n\r\nwhile tflite gives me answer of 45 in this case, which I don't think is correct. And that's because when rescaling output back to quantized space, the number is too close to 40.5, and tflite reference implementation might lose precision somewhere so it gets < 40.5 in this case, and leads to output=45 eventually. Btw, all other quantized input numbers are running fine.\r\n\r\nWhen I looked at the reference implementation under tflite/kernel/reference/reference_ops.h, it seems like it's using fixed point s0.15 to represent the relu-ish value, even when it's 1.0, which leads to a error factor of 32767 / 32768 for each fixed16_t multiplier. If I have to guess, that could be a source of error. Another possibility could be float vs double. I noticed in HardSwishPrepare it stores input and output scales as float type instead of double.\r\n\r\nThanks in advance!", "comments": ["Thanks for the report! Just a bit of context here from a historical/past maintainer of this code:\r\n\r\nPlease note that there is no expectation of bit-exactness across implementations of tflite ops; some off-by-one differences are always going to exist due to necessary compromises with efficient implementation considerations on each target hardware.\r\n\r\nFrom your debugging, this looks like a case where a value close to a half-integer gets pushed into the wrong direction by an intermediate rounding; the only way to be bit-exact in a cast like this would be to avoid intermediate roundings at all, which in the case of this function, would mean avoiding using NEON fixed-point multiplications, in NEON optimized code. So even if we modified this reference code to be bit-exact, we still probably wouldn't fix the NEON optimized code. This example illustrates why we don't even aim for our reference code to be bit-exact-normative.\r\n\r\nGoing beyond ARM CPU, if we consider other hardware backends where this will want to run in IEEE float16 for optimal performance (e.g. GPUs), that gives more examples why bit-exactness can't be the goal.\r\n\r\nThat's to say that an off-by-one difference isn't necessarily in itself a bug here. But of course, it's always interesting to improve this code if you can think of a better compromise of accuracy and usefulness of this reference code as a porting starting point for optimized implementations.", "Yes thanks for the feedback. After a second thought I generally agree with you and I think there's no point to pursue bit-exact or mathematically true result.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40781\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40781\">No</a>\n"]}, {"number": 40780, "title": "Fixed typos in image_ops_impl.py", "body": "Fixed typos in `non_max_suppression_padded` and `non_max_suppression_padded_v2`", "comments": []}, {"number": 40779, "title": "Update api_def_Maximum.pbtxt", "body": "Added 2 spaces at the end of each line to cause markdown to insert line breaks.\r\n\r\nFixes #39981", "comments": []}, {"number": 40778, "title": "Slightly improve performance of TensorShape methods in the common case", "body": "`TensorShape` is used a lot within the codebase and can end up on the hot path during eager execution. This PR simplifies some method calls to slightly improve performance for the case of fully defined shapes.\r\n\r\nMost changes are related to the switch to a [\"Easier to ask for forgiveness than permission\" (EAFP)](https://docs.python.org/3/glossary.html) pattern for accessing `TensorShape._dims` which is quite common in Python, but I would be happy to revert that if you prefer to still explicitely check for existance before access.\r\nThis PR improves performance of `.merge_elements()` by 50% and `.num_elements()` by 25%. `.rank`, `as_list` and `__add__` are 5-10% faster on my machine which probably doesn't really matter in practice.", "comments": ["@tomhennigan Can you please review this PR ? Thanks!", "Thanks for the PR!  Few things:\r\n- Actually, let's not use EAFP here. 1. `except:` path is expensive so it should be for true exceptions or unlikely executed branch. https://docs.python.org/2/faq/design.html#how-fast-are-exceptions. 2. Using `try:` block for a specific case can be error-prone as it could accidentally catch other things as well, and `TypeError` is pretty generic.\r\n- (optional) We can add micro benchmarks here tensorflow/python/eager/benchmarks_test.py .  But it looks like the optimizations are pretty obvious (using list comprehensions, etc, ...) so please feel free to skip.", "@kkimdev Thanks for taking a look at the PR. I don't fully agree with the performance argument you raise (e.g. [Python core uses this pattern quite often in key places as well](https://github.com/python/cpython/blob/ca8d46dd422e5aa10f444796d93faec5a8cbc1e0/Lib/_collections_abc.py#L675-L688)), but you raise a very valid point about  `TypeError` being too generic.\r\n\r\nI removed the use of EAFP in 8d93940cbee2d32ddafac4ba2d277f90cb60a09b"]}, {"number": 40777, "title": "[-Wsign-compare] warning fixes batch 4", "body": "warning_ids : [\r\n79, 80, 104, 105,\r\n106, 107, 112, 113,\r\n115, 116, 117, 134\r\n]\r\n\r\n@mihaimaruseac ", "comments": ["@joker-eph "]}, {"number": 40776, "title": "use string instead of const char* gcs", "body": "@mihaimaruseac \r\nThis PR use `std::string` instead of `char*` for `ParseGCSPath` and `tf_writable_file`", "comments": ["Turns out `std::move` of temporaries is not a good choice. Fixed internally, no need to do anything\r\n\r\n```\r\n.../tensorflow/c/experimental/filesystem/plugins/gcs/gcs_filesystem.cc:57:7: error: moving a temporary object prevents copy elision [-Werror,-Wpessimizing-move]\r\n      std::move(fname.substr(scheme_end + 1, bucket_end - scheme_end - 1));\r\n      ^\r\n.../tensorflow/c/experimental/filesystem/plugins/gcs/gcs_filesystem.cc:57:7: note: remove std::move call here\r\n      std::move(fname.substr(scheme_end + 1, bucket_end - scheme_end - 1));\r\n      ^~~~~~~~~~                                                         ~\r\n.../tensorflow/c/experimental/filesystem/plugins/gcs/gcs_filesystem.cc:59:13: error: moving a temporary object prevents copy elision [-Werror,-Wpessimizing-move]\r\n  *object = std::move(fname.substr(bucket_end + 1));\r\n            ^\r\n.../tensorflow/c/experimental/filesystem/plugins/gcs/gcs_filesystem.cc:59:13: note: remove std::move call here\r\n  *object = std::move(fname.substr(bucket_end + 1));\r\n            ^~~~~~~~~~                            ~\r\n2 errors generated.\r\n```"]}, {"number": 40775, "title": "Update api_def_Maximum.pbtxt", "body": "\r\n### Updated Code regarding following issue.\r\n### _tf.math.maximum example is written incorrectly._\r\n#39981 \r\n", "comments": []}, {"number": 40774, "title": "Fix _EagerTensorCache.flush", "body": "`_EagerTensorCache._data` is initialized with an `OrderedDict`:\r\nhttps://github.com/tensorflow/tensorflow/blob/7113c0b029ad067bf9b5e633082434bb4a4aba62/tensorflow/python/eager/context.py#L84\r\n\r\nHowever, `_EagerTensorCache.flush` resets the cache by assigning a `dict` instead of an `OrderedDict`. This can lead to different behaviour on older versions of Python where dictionary ordering wasn't preserved. This PR switches to using `.clear()` to flush the cache which won't change the data structure.", "comments": []}, {"number": 40773, "title": "added test for pywrap FastPathExecute using MatMul and tensors of dif\u2026", "body": "tensors of different shapes (version 2 to fix CLA)\r\n\r\n@saxenasaurabh ", "comments": ["@amturati Can you please check @alextp's comments and keep us posted. Thanks!\r\n"]}, {"number": 40772, "title": "d", "body": "d", "comments": ["@Lucysmith8 \r\nPlease refer to these links with similar error, and let us know if it helps:\r\n#33730 [link](https://github.com/pyinstaller/pyinstaller/issues/4200) [link1](https://webspark.hk/blog/python/pyinstaller-expected-str-error-fix/) ", "@Lucysmith8 \r\nThere is duplicate for this issue, please close current issue as its already traced.\r\nduplicates:\r\n#40485  #40458", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40772\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40772\">No</a>\n"]}, {"number": 40771, "title": "Tensorflow 2 - oneDNN 1.x build fails searching for i_malloc.h, mkl_cblas.h on non-x86 machines.", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nNAME=\"CentOS Linux\"\r\nVERSION=\"8 (Core)\"\r\n\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: master & 2.2.0\r\n- Python version: 3.6.8\r\n- Installed using virtualenv? pip? conda?: virtualenv\r\n- Bazel version (if compiling from source): 3.1.0\r\n- GCC/Compiler version (if compiling from source): GCC 8.3.1\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\n**Describe the problem**\r\nI am building Tensorflow with oneDNN 1.4.0 on an Aarch64 machine, which causes issues when searching for MKL-ML header files (e.g. i_malloc.h). \r\n\r\nExample log 1:\r\n\r\n``` \r\n/home/../tensorflow-nb/packages/tensorflow/tensorflow/core/common_runtime/BUILD:1018:1: C++ compilation of rule '//tensorflow/core/common_runtime:mkl_cpu_allocator' failed (Exit 1)\r\nIn file included from tensorflow/core/common_runtime/mkl_cpu_allocator.cc:18:\r\n./tensorflow/core/common_runtime/mkl_cpu_allocator.h:33:10: fatal error: i_malloc.h: No such file or directory\r\n #include \"i_malloc.h\"\r\n ^~~~~~~~~~~~\r\ncompilation terminated.\r\n```\r\nExample log 2:\r\n```\r\nERROR: /home/.../tensorflow-nb/packages/tensorflow/tensorflow/core/kernels/BUILD:4109:1: C++ compilation of rule '//tensorflow/core/kernels:mkl_batch_matmul_op' failed (Exit 1)\r\ntensorflow/core/kernels/mkl_batch_matmul_op.cc:31:10: fatal error: mkl_cblas.h: No such file or directory\r\n #include \"mkl_cblas.h\"\r\n          ^~~~~~~~~~~~~\r\ncompilation terminated.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nERROR: /home/.../tensorflow-nb/packages/tensorflow/tensorflow/lite/toco/python/BUILD:84:1 C++ compilation of rule '//tensorflow/core/kernels:mkl_batch_matmul_op' failed (Exit 1) \r\n```\r\n\r\nIn previous Tensorflow versions  (1.x), for example, when building with the older mkldnn library 0.21.x, these header files were removed with mkldnn ifdefs (INTEL_MKL_DNN_ONLY):\r\nhttps://github.com/tensorflow/tensorflow/blob/590d6eef7e91a6a7392c8ffffb7b58f2e0c8bc6b/tensorflow/core/common_runtime/mkl_cpu_allocator.h#L32\r\n\r\n while these ifdefs are not activated when building with the new oneDNN 1.x (with for e.g -DENABLE_MKLDNN_V1)\r\n\r\nThere are several sources that have this issue (this is from a successful x86 build):\r\n```\r\n./tensorflow/core/kernels/_objs/mkl_transpose_op/mkl_transpose_op.pic.d:3: external/mkl_linux/include/mkl_trans.h \\\r\n./tensorflow/core/kernels/_objs/mkl_transpose_op/mkl_transpose_op.pic.d:5: external/mkl_linux/include/mkl_types.h \\\r\n./tensorflow/core/kernels/_objs/mkl_batch_matmul_op/mkl_batch_matmul_op.pic.d:51: external/mkl_linux/include/mkl_cblas.h \\\r\n./tensorflow/core/kernels/_objs/mkl_batch_matmul_op/mkl_batch_matmul_op.pic.d:52: external/mkl_linux/include/mkl_types.h \\\r\n./tensorflow/core/common_runtime/_objs/mkl_cpu_allocator/mkl_cpu_allocator.pic.d:623: external/mkl_linux/include/i_malloc.h\r\n./tensorflow/core/common_runtime/_objs/threadpool_device/threadpool_device.pic.d:718: tensorflow/core/lib/core/bits.h external/mkl_linux/include/i_malloc.h \\ \r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\nbazel build --config=v2 --config=mkl  \\\r\n    --copt=\"-mtune=native\" --copt=\"-march=armv8-a\" --copt=\"-O3\" --copt=\"-fopenmp\" \\\r\n    --cxxopt=\"-mtune=native\" --cxxopt=\"-march=armv8-a\" --cxxopt=\"-O3\" --cxxopt=\"-fopenmp\" \\\r\n    --linkopt=\"-lm\" --linkopt=\"-fopenmp\" \\\r\n    --config=noaws  --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" \\\r\n    //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Adding @nSircombe  for support of oneDNN on ARM. ", "Thanks for the heads-up @agramesh1, as it happens I'm actually working with @cfRod!\r\n\r\nAt the moment, oneDNN v1.4+ builds on AArch64 'out of the box' and we've been able to build TensorFlow with oneDNN v0.20.x. But, as @cfRod details, we have some problems with building TensorFlow with oneDNN v1.x. - these don't appear to be an issue with oneDNN. \r\nIt looks as if there are two issues which balance each other out in the case of an x86 build:\r\n1. the ifdefs for a v1.x build appear to re-include headers omitted from v0.x builds.\r\n2. TensorFlow downloads an MKL-ML tarball (https://github.com/intel/mkl-dnn/releases/download/v0.21/mklml_lnx_2019.0.5.20190502.tgz) which includes those headers (as well as an MKL-ML binary). This doesn't appears to be unnecessary, and possibly unintentional?\r\nThis download does not happen for an AArch64 build, hence the missing header files. ", "@nSircombe yes, for MKL DNN 0.2.x version we had defines that will allow you to compile with only opensource components.\r\nWith the move to oneDNN 1.4x in TF2.2 that broke and we haven't fixed it as yet.  You should be able to remove all references of mkl in the allocator code to get it compile. We are working on cleaning up the code and remove the blob dependencies when compiled with oneDNN 1.4. ", "Submitted PR: https://github.com/tensorflow/tensorflow/pull/41232\r\n", "> Submitted PR: #41232\r\n\r\n@cfRod Thanks, I will review the code. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40771\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40771\">No</a>\n"]}, {"number": 40770, "title": "change_exit_code_when_bazel_none", "body": "https://github.com/tensorflow/tensorflow/issues/40719", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40770) for more info**.\n\n<!-- need_sender_cla -->", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40770) for more info**.\n\n<!-- ok -->"]}, {"number": 40769, "title": "[INTEL MKL] Update build name with new branding", "body": "", "comments": []}, {"number": 40768, "title": "Got OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function when writing custom layer.", "body": "I wrote the following custom layer\r\n```python\r\n'''\r\nDivide every 656 input vector into a group, get an output vector for each group\r\nInput: 1) Output of sentence encoder (None, 152 * 656, 100)\r\n       2) The concatenated user vector width dimension (100)\r\nOutput: Dimension (152, 100)\r\n'''\r\nclass SentenceToDocument(Layer):\r\n\r\n    def __init__(self, sentence_number, units=SENTENCE_MEM_DIM, **kwargs):\r\n        super(SentenceToDocument, self).__init__(**kwargs)\r\n        self.sentence_number = sentence_number\r\n        self.units = units\r\n\r\n    def build(self, input_shape):\r\n        self.vw = self.add_weight(\r\n            shape=(self.units, 1),\r\n            initializer=\"random_normal\",\r\n            trainable=True\r\n        )\r\n        self.wh = self.add_weight(\r\n            shape=(self.units, 100),\r\n            initializer=\"random_normal\",\r\n            trainable=True\r\n        )\r\n        self.wu = self.add_weight(\r\n            shape=(self.units, 100),\r\n            initializer=\"random_normal\",\r\n            trainable=True\r\n        )\r\n        self.bw = self.add_weight(\r\n            shape=(self.units, 1),\r\n            initializer=\"random_normal\",\r\n            trainable=True\r\n        )\r\n\r\n    def call(self, inputs):\r\n        res = tf.TensorArray(tf.float32, size=0, dynamic_size=True)\r\n        for idx, v in inputs[0]:\r\n            sentence_output = v\r\n            user_vec = inputs[1][idx]\r\n            section_size = inputs[0].shape[1] // self.sentence_number\r\n            sentences = [sentence_output[i*section_size:(i+1)*section_size] for i in range(self.sentence_number)]\r\n            res_per_sen = tf.TensorArray(tf.float32, size=0, dynamic_size=True)\r\n            for sentence in sentences:\r\n                e = []\r\n                u = user_vec\r\n                for word in sentence:\r\n                    word = tf.reshape(word, (-1, 1))\r\n                    u = tf.reshape(u, (-1, 1))\r\n                    wh = tf.matmul(self.wh, word)\r\n                    wu = tf.matmul(self.wu, u)\r\n                    tan = tf.tanh(wh + wu + self.bw)\r\n                    e.append(tf.matmul(tf.transpose(self.vw), tan))\r\n                sum_e = sum([tf.exp(i) for i in e])\r\n                alpha = [tf.exp(i) / sum_e for i in e]\r\n                s = tf.TensorArray(tf.float32, size=0, dynamic_size=True)\r\n                for i in sentence.shape[0]:\r\n                    s.write(s.size(), alpha[i] * sentence[i])\r\n                res_per_sen.write(res_per_sen.size(), s.stack())\r\n            res.write(res.size(), res_per_sen)\r\n        return res.stack()\r\n```\r\n\r\nI was using this layer in the middle of my model, it accepts two inputs, as described in the comment. For each data within the batch, it is supposed to first divide the data into several groups, then do some operations together with u with is another input, and the number of u is the same to the number of he groups. I thought it will output tensor with dimension (None, 152, 100), but I got the error below. I'm using tf-nightly and python 3.7.7 and Anaconda.\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\*****\\Anaconda3\\envs\\night\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1107, in _functional_construction_call\r\n    outputs = call_fn(cast_inputs, *args, **kwargs)\r\n  File \"C:\\Users\\*****\\Anaconda3\\envs\\night\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 258, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\ntensorflow.python.framework.errors_impl.OperatorNotAllowedInGraphError: in user code:\r\n\r\n    main.py:132 call  *\r\n        for idx, v in inputs[0]:\r\n    C:\\Users\\*****\\Anaconda3\\envs\\night\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:503 __iter__\r\n        self._disallow_iteration()\r\n    C:\\Users\\*****\\Anaconda3\\envs\\night\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:499 _disallow_iteration\r\n        self._disallow_in_graph_mode(\"iterating over `tf.Tensor`\")\r\n    C:\\Users\\*****\\Anaconda3\\envs\\night\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:479 _disallow_in_graph_mode\r\n        \" this function with @tf.function.\".format(task))\r\n\r\n    OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 286, in <module>\r\n    user_sentence_output = SentenceToDocument(max_sentence)([c1, con_user_vec])\r\n  File \"C:\\Users\\*****\\Anaconda3\\envs\\night\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 926, in __call__\r\n    input_list)\r\n  File \"C:\\Users\\*****\\Anaconda3\\envs\\night\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1114, in _functional_construction_call\r\n    '\\n\"\"\"')\r\nTypeError: You are attempting to use Python control flow in a layer that was not declared to be dynamic. Pass `dynamic=True` to the class constructor.\r\nEncountered error:\r\n\"\"\"\r\nin user code:\r\n\r\n    main.py:132 call  *\r\n        for idx, v in inputs[0]:\r\n    C:\\Users\\*****\\Anaconda3\\envs\\night\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:503 __iter__\r\n        self._disallow_iteration()\r\n    C:\\Users\\*****\\Anaconda3\\envs\\night\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:499 _disallow_iteration\r\n        self._disallow_in_graph_mode(\"iterating over `tf.Tensor`\")\r\n    C:\\Users\\*****\\Anaconda3\\envs\\night\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:479 _disallow_in_graph_mode\r\n        \" this function with @tf.function.\".format(task))\r\n\r\n    OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.\r\n\r\n\"\"\"\r\n```", "comments": ["@Brunnhild,\r\nOn running the code I am facing an error stating `NameError: name 'Layer' is not defined`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/0aed57fe70b05aa31971d41467c283b7/40768.ipynb).\r\n\r\nIn order to reproduce the error, could you please share the complete code and the supporting files you are using. Thanks!", "I found that error was due to the iteration on input tensor, I tried to iterate the input tensor by index, that caused the error. I changed the code to below\r\n```python\r\nfrom data import get_train_input, get_vocabulary\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras.layers import *\r\nfrom tensorflow.keras.utils import to_categorical\r\nfrom tensorflow import keras\r\nfrom collections import Counter\r\nimport numpy as np\r\nimport os\r\nimport pickle\r\nimport tensorflow as tf\r\n\r\n\r\nclass SentenceToDocument(Layer):\r\n\r\n    def __init__(self, sentence_number, units=SENTENCE_MEM_DIM, **kwargs):\r\n        super(SentenceToDocument, self).__init__(**kwargs)\r\n        self.sentence_number = sentence_number\r\n        self.units = units\r\n\r\n    def build(self, input_shape):\r\n        self.vw = self.add_weight(\r\n            shape=(self.units, 1),\r\n            initializer=\"random_normal\",\r\n            trainable=True\r\n        )\r\n        self.wh = self.add_weight(\r\n            shape=(self.units, 2 * MIDDLE_OUTPUT),\r\n            initializer=\"random_normal\",\r\n            trainable=True\r\n        )\r\n        self.wu = self.add_weight(\r\n            shape=(self.units, 2 * USER_VEC_DIM),\r\n            initializer=\"random_normal\",\r\n            trainable=True\r\n        )\r\n        self.bw = self.add_weight(\r\n            shape=(self.units, 1),\r\n            initializer=\"random_normal\",\r\n            trainable=True\r\n        )\r\n\r\n    def call(self, inputs):\r\n        res = tf.TensorArray(tf.float32, size=0, dynamic_size=True)\r\n        for con_input in inputs:\r\n            sentence_output = con_input[:-1] \r\n            section_size = sentence_output.shape[0] // self.sentence_number\r\n            user_vec = con_input[-1] # shape: (USER_VEC_DIM,)\r\n            wpu = tf.matmul(self.wu, tf.reshape(user_vec, (-1, 1)))\r\n            wub = tf.transpose(wpu + self.bw) # shape: (1, self.units)\r\n            wub = tf.tile(wub, (section_size, 1)) # shape: (section_size, units)\r\n            section_s = tf.TensorArray(tf.float32, size=self.sentence_number, dynamic_size=True)\r\n            for i in range(self.sentence_number):\r\n                h = sentence_output[i*section_size:(i+1)*section_size] # shape: (section_size, 2 * MIDDLE_OUTPUT)\r\n                wph = tf.matmul(h, tf.transpose(self.wh)) # shape: (section_size, units)\r\n                tanh = tf.tanh(wph + wub)\r\n                e = tf.matmul(tanh, self.vw) # shape: (section_size, 1)\r\n                alpha = tf.exp(e) / tf.reduce_sum(tf.exp(e)) # shape: (section_size, 1)\r\n                s = tf.tile(alpha, (1, h.shape[1])) * h # shape: (section_size, 2 * MIDDLE_OUTPUT)\r\n                s = tf.reduce_sum(s, axis=0) #shape: (2 * MIDDLE_OUTPUT,)\r\n                section_s = section_s.write(i, s)\r\n            section_s = section_s.stack() # shape: (self.sentence_number, 2 * MIDDLE_OUTPUT)\r\n            res = res.write(res.size(), section_s)\r\n        return res.stack()\r\n\r\n    def compute_output_shape(self, input_shape):\r\n        return (None, self.sentence_number, 2 * MIDDLE_OUTPUT)\r\n```\r\nAnd it works. Thanks for concerning. "]}, {"number": 40767, "title": "How to use both CPU and GPU for training in distributed training", "body": "Hi, I'd like to know how to use both CPU and GPU for training, this is how my solution looks like, but it only uses the GPU.\r\n\r\nstrategy = tf.distribute.MirroredStrategy(devices=['CPU', 'DML'])\r\n\r\nIf I do,\r\n\r\nwith tf.device('CPU'):\r\n    model.fit(....)\r\n\r\nThis uses the CPU, how can I use both to speed up things a little.", "comments": ["Hi @limapedro, if you only have 1 GPU you're probably best off not using distributed training and just running your code with your GPU. You won't be able to run MirroredStrategy with 1 GPU and 1 CPU. Think of it this way, in MirroredStrategy your model is replicated on each device. Each device receives a portion of the input data batch and computes the gradient. The gradients are then aggregated across all of your devices, and this new reduced gradient is what is used by each device to update the parameters of your model. Then this process happens again, taking another step in your training loop. If you were to use MirroredStrategy with 1 GPU and 1 CPU in sync, then your GPU would just be waiting around each step after the backwards pass for the CPU to finish so that the gradient could be updated. And your CPU would be a bottleneck.\r\n\r\nHope that explanation helps. But it doesn't really sound like you have a need for distributed training in this case if you only have one GPU. TensorFlow code, and tf.keras models will transparently run on a single GPU with no code changes required.", "@nikitamaia Thanks for replying, I was looking for to this because my GPU isn't much faster than my CPU on tensorflow, so using both would improve training times a bit, my device is DML one, from tensorflow-directml.", "I'm not familiar with DML, so I can't speak to that. Though it is surprising that training with GPU isn't much faster than training on CPU. However, as I mentioned earlier trying to use MirroredStrategy with 1 CPU and 1 GPU (even if it were possible) will not improve your training time.", "@nikitamaia Yeah, I'm using Vega 11, AMD integrated graphics, It is about 2x times faster running on Vega 11 versus my Ryzen CPU, I expect DML to become more popular in the following months. both for training and inference.", "I also wanted to distribute the training. My laptop integrated GPU, Intel Iris XE - Tiger Lake GT2, is as fast as the CPU, Intel Core i7-1165G7.\r\nIt would be good to train the model on both devices."]}, {"number": 40766, "title": "Cannot run .py file", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1.  It must be a bug, a feature request, or a significant problem with the\r\n    documentation (for small docs fixes please send a PR instead).\r\n2.  The form below must be filled out.\r\n3.  It shouldn't be a TensorBoard issue. Those go\r\n    [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**:\r\n-   **OS Platform and Distribution (e.g., Windows 10)**:\r\n-  **TensorFlow installed from (source)**:\r\n-   **TensorFlow version (3.6)**:\r\n-   **Bazel version (if compiling from source)**:\r\n-   **GCC/Compiler version (if compiling from source)**:\r\n-   **CUDA/cuDNN version 9**:\r\n-   **GPU model and memory nvidia gtx 1050 ti 4gb**:\r\n-   **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nC:\\Users\\marea\\Desktop\\Things\\Practica\\COD\\ImageProcessing>python \"ImageProcessing.py\"\r\nTraceback (most recent call last):\r\n  File \"ImageProcessing.py\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\marea\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 27, in <module>\r\n    from tensorflow._api.v2 import audio\r\n  File \"C:\\Users\\marea\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\_api\\v2\\audio\\__init__.py\", line 8, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\Users\\marea\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 52, in <module>\r\n    from tensorflow.core.framework.graph_pb2 import *\r\n  File \"C:\\Users\\marea\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\core\\framework\\graph_pb2.py\", line 6, in <module>\r\n    from google.protobuf import descriptor as _descriptor\r\n  File \"C:\\Users\\marea\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\google\\protobuf\\descriptor.py\", line 48, in <module>\r\n    from google.protobuf.pyext import _message\r\nImportError: DLL load failed: The specified procedure could not be found.", "comments": ["@BubbleBoy99 \r\n\r\nRequest you to fill issue template.\r\n\r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version\r\n\r\nRequest you to share colab link or simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40765, "title": "added tests for MatMul using FastPathExecute and different size tensors", "body": "@saxenasaurabh ", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40765) for more info**.\n\n<!-- need_author_cla -->", "@saxenasaurabh Thank you for your contribution. Can you please sign CLA? Thanks!", "@googlebot I fixed it."]}, {"number": 40764, "title": "how to convert frozen graph (.pb and .pbtxt) model into quantized edge.tflite model ", "body": "I have created one object detection model (.pb and .pbtxt) using 'faster_rcnn_inception_v2_coco_2018_01_28' model I found from TensorFlow zoo. It works fine on windows but I want to use this model on google coral edge TPU. How can I convert my frozen model into edgetpu.tflite quantized model? \r\n", "comments": ["@MevadaRavikumar,\r\nPlease take a look at [this](https://coral.ai/docs/edgetpu/compiler/#download) Edge TPU Compiler guide to convert your tflite model  to Edge TPU compatible format. \r\n\r\nAlso, this question is better asked on [StackOverflow](https://stackoverflow.com/questions/ask) since it is not a TensorFlow bug or feature request. There is a larger community that reads questions there. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n"]}, {"number": 40763, "title": "Avoid memory 'leak' in Go with multiple inputs", "body": "Fixes #40758. Go map iteration order is random. If we send randomly ordered lists of inputs to the C core it will create a key in the session executors_ cache for each of the random orderings. With more than a handful of inputs this can get big very quickly.", "comments": []}, {"number": 40762, "title": "tfcompile  --target_triple=\"armv7em-none-eabi\" calling wrong libraries", "body": "I found a bug inside tfcompile especially if your compiling for ARM embedded devices the  --target_triple=\"armv7em-none-eabi\" is calling incorrect functions when compiling. This should be compatible with arm-none-eabi-gcc libraries and one example is libgcc.a in the none-eabi version it does not have a function called __multi3 however in every other version such as gnu and linux its availble. So when tfcompile generates the files the compiler can not find the function __multi3.\r\n\r\nIs there a possible work around to this?\r\n\r\n**System information**\r\n- OS Platform and Distribution ( Linux Ubuntu 18):\r\n- TensorFlow installed from (source):\r\n- TensorFlow version (1.5 > ):\r\n- Python version: 3.6\r\n- Bazel version (0.10 > ):\r\n- GCC/Compiler version (if compiling from source):\r\n", "comments": ["@DroneMesh \r\nPlease update the tensor flow version and details on platform, in case you encountered the issue while running code share a simple indented stand alone code such that we can replicate the issue faced or colab gist with code and error for us to analyse.", "@Saduf2019 I am unable to update due to the nature of the project. The tfcompile is thinking I have long long int in my graphs when i don't. The project is very large and i will not be able to create a collab i wish a could. \r\n\r\nis there a way to specify and limit the int types?", "Solved it its a bug with LLVM"]}, {"number": 40761, "title": "trying again: Big performance gains for Go NewTensor and Value", "body": "This is re-establishing PR https://github.com/tensorflow/tensorflow/pull/39117 after some fat-fingering. Should be exactly the same as that PR\r\n\r\nAfter some helpful comments in #36578 (comment) I'm trying again with this performance improvement.\r\n\r\nPlease please please if it gets rolled back again because of \"internal test\" failures, please get some kind of debug information. Stack traces or something. Any kind of clue.\r\n\r\n```\r\nname                                  old time/op    new time/op    delta\r\nTensor/New/[150528]int32-16             1.78ms \u00b1 4%    0.13ms \u00b110%   -92.63%  (p=0.000 n=8+7)\r\nTensor/New/[100][100][100]int32-16      13.1ms \u00b1 1%     0.9ms \u00b153%   -92.81%  (p=0.000 n=8+8)\r\nTensor/New/[]float32-16                 3.72ms \u00b1 1%    0.97ms \u00b130%   -74.04%  (p=0.000 n=8+8)\r\nTensor/New/[][]float32-16               4.83ms \u00b1 2%    1.32ms \u00b1 8%   -72.69%  (p=0.000 n=8+8)\r\nTensor/New/[][][]float32-16             4.81ms \u00b1 1%    1.32ms \u00b1 4%   -72.51%  (p=0.001 n=8+6)\r\nTensor/New/[]string-16                   466ms \u00b1 1%      34ms \u00b1 4%   -92.60%  (p=0.001 n=7+7)\r\nTensor/New/[][]string-16                 460ms \u00b1 1%      35ms \u00b1 1%   -92.45%  (p=0.000 n=8+8)\r\nTensor/New/[][][]string-16               462ms \u00b1 2%      36ms \u00b1 5%   -92.14%  (p=0.000 n=8+8)\r\nTensor/Value/[150528]int32-16            647\u00b5s \u00b1 3%      82\u00b5s \u00b1 1%   -87.28%  (p=0.000 n=8+8)\r\nTensor/Value/[100][100][100]int32-16    6.43ms \u00b1 1%    0.99ms \u00b1 3%   -84.63%  (p=0.000 n=8+8)\r\nTensor/Value/[]float32-16               5.57ms \u00b1 3%    1.04ms \u00b1 7%   -81.26%  (p=0.000 n=8+8)\r\nTensor/Value/[][]float32-16             6.84ms \u00b1 1%    1.51ms \u00b1 1%   -77.96%  (p=0.000 n=8+8)\r\nTensor/Value/[][][]float32-16           6.87ms \u00b1 1%    1.52ms \u00b1 3%   -77.80%  (p=0.001 n=7+7)\r\nTensor/Value/[]string-16                 268ms \u00b1 3%      20ms \u00b1 2%   -92.45%  (p=0.000 n=8+8)\r\nTensor/Value/[][]string-16               269ms \u00b1 2%      20ms \u00b1 1%   -92.46%  (p=0.000 n=8+7)\r\nTensor/Value/[][][]string-16             271ms \u00b1 2%      20ms \u00b1 1%   -92.55%  (p=0.000 n=8+8)\r\n\r\nname                                  old alloc/op   new alloc/op   delta\r\nTensor/New/[150528]int32-16              606kB \u00b1 0%       0kB \u00b1 0%   -99.99%  (p=0.000 n=8+8)\r\nTensor/New/[100][100][100]int32-16      4.16MB \u00b1 0%    0.00MB \u00b1 0%  -100.00%  (p=0.000 n=7+8)\r\nTensor/New/[]float32-16                 4.01MB \u00b1 0%    0.00MB \u00b1 0%  -100.00%  (p=0.002 n=7+8)\r\nTensor/New/[][]float32-16               4.48MB \u00b1 0%    0.00MB \u00b1 0%  -100.00%  (p=0.000 n=8+8)\r\nTensor/New/[][][]float32-16             4.48MB \u00b1 0%    0.00MB \u00b1 0%  -100.00%  (p=0.002 n=7+8)\r\nTensor/New/[]string-16                  48.0MB \u00b1 0%     0.0MB \u00b1 0%  -100.00%  (p=0.000 n=7+8)\r\nTensor/New/[][]string-16                48.3MB \u00b1 0%     0.0MB \u00b1 0%  -100.00%  (p=0.000 n=7+8)\r\nTensor/New/[][][]string-16              48.3MB \u00b1 0%     0.0MB \u00b1 0%  -100.00%  (p=0.000 n=7+8)\r\nTensor/Value/[150528]int32-16           1.21MB \u00b1 0%    0.61MB \u00b1 0%   -50.00%  (p=0.000 n=8+8)\r\nTensor/Value/[100][100][100]int32-16    9.23MB \u00b1 0%    4.25MB \u00b1 0%   -53.93%  (p=0.000 n=8+8)\r\nTensor/Value/[]float32-16               8.01MB \u00b1 0%    4.01MB \u00b1 0%   -50.00%  (p=0.000 n=8+7)\r\nTensor/Value/[][]float32-16             9.21MB \u00b1 0%    4.25MB \u00b1 0%   -53.82%  (p=0.000 n=8+8)\r\nTensor/Value/[][][]float32-16           9.23MB \u00b1 0%    4.25MB \u00b1 0%   -53.93%  (p=0.000 n=8+8)\r\nTensor/Value/[]string-16                56.0MB \u00b1 0%    23.0MB \u00b1 0%   -58.91%  (p=0.000 n=8+7)\r\nTensor/Value/[][]string-16              58.5MB \u00b1 0%    23.3MB \u00b1 0%   -60.23%  (p=0.000 n=8+8)\r\nTensor/Value/[][][]string-16            58.5MB \u00b1 0%    23.3MB \u00b1 0%   -60.25%  (p=0.001 n=7+7)\r\n\r\nname                                  old allocs/op  new allocs/op  delta\r\nTensor/New/[150528]int32-16               4.00 \u00b1 0%      2.00 \u00b1 0%   -50.00%  (p=0.000 n=8+8)\r\nTensor/New/[100][100][100]int32-16       10.0k \u00b1 0%      0.0k \u00b1 0%   -99.96%  (p=0.000 n=8+8)\r\nTensor/New/[]float32-16                   4.00 \u00b1 0%      2.00 \u00b1 0%   -50.00%  (p=0.000 n=8+8)\r\nTensor/New/[][]float32-16                20.0k \u00b1 0%      0.0k \u00b1 0%   -99.99%  (p=0.000 n=8+8)\r\nTensor/New/[][][]float32-16              20.0k \u00b1 0%      0.0k \u00b1 0%   -99.98%  (p=0.000 n=8+8)\r\nTensor/New/[]string-16                   4.00M \u00b1 0%     0.00M \u00b1 0%  -100.00%  (p=0.000 n=8+8)\r\nTensor/New/[][]string-16                 4.01M \u00b1 0%     0.00M \u00b1 0%  -100.00%  (p=0.000 n=8+8)\r\nTensor/New/[][][]string-16               4.01M \u00b1 0%     0.00M \u00b1 0%  -100.00%  (p=0.000 n=8+8)\r\nTensor/Value/[150528]int32-16             7.00 \u00b1 0%      2.00 \u00b1 0%   -71.43%  (p=0.000 n=8+8)\r\nTensor/Value/[100][100][100]int32-16     40.2k \u00b1 0%      0.0k \u00b1 0%   -99.99%  (p=0.000 n=8+8)\r\nTensor/Value/[]float32-16                 7.00 \u00b1 0%      2.00 \u00b1 0%   -71.43%  (p=0.000 n=8+8)\r\nTensor/Value/[][]float32-16              40.0k \u00b1 0%      0.0k \u00b1 0%   -99.99%  (p=0.000 n=8+8)\r\nTensor/Value/[][][]float32-16            40.2k \u00b1 0%      0.0k \u00b1 0%   -99.99%  (p=0.000 n=8+8)\r\nTensor/Value/[]string-16                 5.00M \u00b1 0%     0.00M \u00b1 0%  -100.00%  (p=0.000 n=8+8)\r\nTensor/Value/[][]string-16               5.02M \u00b1 0%     0.00M \u00b1 0%  -100.00%  (p=0.000 n=8+8)\r\nTensor/Value/[][][]string-16             5.02M \u00b1 0%     0.00M \u00b1 0%  -100.00%  (p=0.000 n=8+8)```", "comments": ["@philpearl Can you please resolve conflicts? Thanks!", "Oh, it looks like the original version of this PR was merged somehow!? This PR is not necessary and adds no further changes - closing."]}, {"number": 40760, "title": "CUDA_ERROR_OUT_OF_MEMORY when converting model to tflite with the new experimental converter", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Scientific Linux 7.6, Nitrogen\r\n- TensorFlow installed from (source or binary): anaconda\r\n- TensorFlow version (or github SHA if from source): 2.2.0\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\n# Convert the model.\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_model = converter.convert()```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nConverterError                            Traceback (most recent call last)\r\n<ipython-input-17-1cbca637a6c6> in <module>\r\n      2 converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n      3 # converter.experimental_new_converter = False\r\n----> 4 tflite_model = converter.convert()\r\n      5 \r\n      6 # # Save the TF Lite model.\r\n\r\n~/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/lite/python/lite.py in convert(self)\r\n    516         input_tensors=input_tensors,\r\n    517         output_tensors=output_tensors,\r\n--> 518         **converter_kwargs)\r\n    519 \r\n    520     if self._is_calibration_quantize():\r\n\r\n~/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/lite/python/convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)\r\n    494       input_data.SerializeToString(),\r\n    495       debug_info_str=debug_info_str,\r\n--> 496       enable_mlir_converter=enable_mlir_converter)\r\n    497   return data\r\n    498 \r\n\r\n~/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n    225       stdout = _try_convert_to_unicode(stdout)\r\n    226       stderr = _try_convert_to_unicode(stderr)\r\n--> 227       raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\n    228   finally:\r\n    229     # Must manually cleanup files.\r\n\r\nConverterError: See console for info.\r\n2020-06-24 13:49:09.713424: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:144] Ignored output_format.\r\n2020-06-24 13:49:09.713504: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:147] Ignored drop_control_dependency.\r\n2020-06-24 13:49:09.727632: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n2020-06-24 13:49:09.733205: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3000000000 Hz\r\n2020-06-24 13:49:09.734188: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558fe1a42f80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-06-24 13:49:09.734222: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-06-24 13:49:09.735171: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-06-24 13:49:09.741175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-06-24 13:49:09.742017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce GTX 1060 6GB computeCapability: 6.1\r\ncoreClock: 1.7085GHz coreCount: 10 deviceMemorySize: 5.94GiB deviceMemoryBandwidth: 178.99GiB/s\r\n2020-06-24 13:49:09.742210: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-06-24 13:49:09.744013: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-06-24 13:49:09.745773: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-06-24 13:49:09.746089: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-06-24 13:49:09.748160: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-06-24 13:49:09.749163: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-06-24 13:49:09.753168: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-06-24 13:49:09.753338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-06-24 13:49:09.753698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-06-24 13:49:09.754068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-06-24 13:49:09.754113: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-06-24 13:49:09.801823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-06-24 13:49:09.801860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \r\n2020-06-24 13:49:09.801898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \r\n2020-06-24 13:49:09.802119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-06-24 13:49:09.802588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-06-24 13:49:09.802907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-06-24 13:49:09.803250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2020-06-24 13:49:09.805103: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558fe25c8fa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-06-24 13:49:09.805141: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1060 6GB, Compute Capability 6.1\r\n2020-06-24 13:49:09.807773: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 11.81M (12386304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-06-24 13:49:09.808353: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 10.63M (11147776 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-06-24 13:49:09.808846: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 9.57M (10033152 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-06-24 13:49:09.809396: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 8.61M (9029888 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-06-24 13:49:09.809879: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 7.75M (8126976 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-06-24 13:49:09.810419: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 6.98M (7314432 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-06-24 13:49:09.810917: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 6.28M (6583040 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-06-24 13:49:09.813411: F ./tensorflow/core/kernels/conv_2d_gpu.h:659] Non-OK-status: GpuLaunchKernel( SwapDimension1And2InTensor3UsingTiles<T, NumThreads, TileLongSide, TileShortSide>, total_tiles_count, NumThreads, 0, d.stream(), input, input_dims, output) status: Internal: out of memory\r\nFatal Python error: Aborted\r\n\r\nCurrent thread 0x00007fe187194740 (most recent call first):\r\n  File \"/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 56 in execute\r\n  File \"/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/lib/python3.7/site-packages/absl/app.py\", line 250 in _run_main\r\n  File \"/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/lib/python3.7/site-packages/absl/app.py\", line 299 in run\r\n  File \"/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/python/platform/app.py\", line 40 in run\r\n  File \"/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 93 in main\r\n  File \"/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/bin/toco_from_protos\", line 11 in <module>```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\n# Put link here or attach to the issue.\r\n```\r\n\r\n**Failure details**\r\nThe conversion is not successful and returns CUDA_ERROR_OUT_OF_MEMORY. However, if I set the experimental_new_converter flag to False, it works.\r\n\r\n**RNN conversion support**\r\nIf converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["I suspect that your session is running out of memory before conversion. This is plausible since gpu memory is not released till you kill the session.\r\nFor sanity check can you please try other method for tf lite conversion.\r\n```python\r\n# Converting a SavedModel to a TensorFlow Lite model.\r\nconverter = lite.TFLiteConverter.from_saved_model(saved_model_dir)\r\n```\r\nCreate a new notebook (instance) and convert your model from saved_model_dir to TF Lite.", "I tried it and it gives this error instead, though i see it still has something to do with internal memory:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nConverterError                            Traceback (most recent call last)\r\n<ipython-input-2-5e5eca5ce13e> in <module>\r\n      1 # Converting a SavedModel to a TensorFlow Lite model.\r\n      2 converter = tf.lite.TFLiteConverter.from_saved_model(\"./model_try\")\r\n----> 3 tflite_model = converter.convert()\r\n\r\n~/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/lite/python/lite.py in convert(self)\r\n    516         input_tensors=input_tensors,\r\n    517         output_tensors=output_tensors,\r\n--> 518         **converter_kwargs)\r\n    519 \r\n    520     if self._is_calibration_quantize():\r\n\r\n~/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/lite/python/convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)\r\n    494       input_data.SerializeToString(),\r\n    495       debug_info_str=debug_info_str,\r\n--> 496       enable_mlir_converter=enable_mlir_converter)\r\n    497   return data\r\n    498 \r\n\r\n~/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n    225       stdout = _try_convert_to_unicode(stdout)\r\n    226       stderr = _try_convert_to_unicode(stderr)\r\n--> 227       raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\n    228   finally:\r\n    229     # Must manually cleanup files.\r\n\r\nConverterError: See console for info.\r\n2020-06-24 20:51:33.900488: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:144] Ignored output_format.\r\n2020-06-24 20:51:33.900532: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:147] Ignored drop_control_dependency.\r\n2020-06-24 20:51:33.920571: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n2020-06-24 20:51:33.925758: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3000000000 Hz\r\n2020-06-24 20:51:33.926418: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5626744c8d10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-06-24 20:51:33.926452: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-06-24 20:51:33.927649: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-06-24 20:51:33.930945: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-06-24 20:51:33.931368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce GTX 1060 6GB computeCapability: 6.1\r\ncoreClock: 1.7085GHz coreCount: 10 deviceMemorySize: 5.94GiB deviceMemoryBandwidth: 178.99GiB/s\r\n2020-06-24 20:51:33.931574: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-06-24 20:51:33.933261: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-06-24 20:51:33.935057: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-06-24 20:51:33.935373: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-06-24 20:51:33.937151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-06-24 20:51:33.938008: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-06-24 20:51:33.942043: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-06-24 20:51:33.942194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-06-24 20:51:33.942522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-06-24 20:51:33.942754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-06-24 20:51:33.942805: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-06-24 20:51:33.991123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-06-24 20:51:33.991168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \r\n2020-06-24 20:51:33.991199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \r\n2020-06-24 20:51:33.991370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-06-24 20:51:33.991689: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-06-24 20:51:33.992023: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-06-24 20:51:33.992277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 193 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2020-06-24 20:51:34.000583: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56267504edc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-06-24 20:51:34.000613: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1060 6GB, Compute Capability 6.1\r\n2020-06-24 20:51:34.002881: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 193.81M (203227136 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2020-06-24 20:51:34.085757: F ./tensorflow/core/kernels/conv_2d_gpu.h:659] Non-OK-status: GpuLaunchKernel( SwapDimension1And2InTensor3UsingTiles<T, NumThreads, TileLongSide, TileShortSide>, total_tiles_count, NumThreads, 0, d.stream(), input, input_dims, output) status: Internal: out of memory\r\nFatal Python error: Aborted\r\n\r\nCurrent thread 0x00007f4a10303740 (most recent call first):\r\n  File \"/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 56 in execute\r\n  File \"/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/lib/python3.7/site-packages/absl/app.py\", line 250 in _run_main\r\n  File \"/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/lib/python3.7/site-packages/absl/app.py\", line 299 in run\r\n  File \"/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/python/platform/app.py\", line 40 in run\r\n  File \"/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 93 in main\r\n  File \"/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/bin/toco_from_protos\", line 11 in <module>\r\n```", "Can you please try [limiting gpu memory growth](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth)?\r\nKill the current session, exit the python interpreter.\r\nThen put following lines on top of your code.\r\n```python\r\nimport tensorflow as tf\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\ntf.config.experimental.set_memory_growth(gpus[0], True)\r\n# your rest of the code\r\n```\r\n", "Yep that did the trick. Thank you very much!", "You are welcome. Thanks for confirmation. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40760\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40760\">No</a>\n"]}, {"number": 40759, "title": "compress_find_cuda_config.py: fix  file names in&out", "body": "", "comments": ["Hi Liu, thank you for your PR. This is a difference between the Google-internal code and open source that we need to handle on our side. I will need to take care of this from our side.", "This should be fixed now. Thanks a lot for your PR!"]}, {"number": 40758, "title": "Apparent memory leak when using multiple input tensors with Go", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04, 20.04, Mac OS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Nop\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.0.1, 2.2. Bug also present in the master branch.\r\n- Python version: Not using python.\r\n- Bazel version (if compiling from source): 0.26.1\r\n- GCC/Compiler version (if compiling from source): 7.5.0\r\n- CUDA/cuDNN version: not using\r\n- GPU model and memory: not using\r\n\r\n**Describe the current behaviour**\r\nWhen serving a model using Go and CPUs where the model has multiple input tensors, memory usage goes up until we run out and restart. The leak is in 'C' memory, not the Go heap.\r\n\r\n**Describe the expected behaviour**\r\nMemory usage does not increase\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nThere's an apparent C memory leak serving models with Go & CPUs if you use multiple input tensors and use Session.Run. It isn't in fact a \"leak\" - the executors_ hashmap in tensorflow::DirectSession just grows very large. This is caused by an unfortunate interaction between Go's random map iteration and the keys generated for this hashmap in DirectSession::GetOrCreateExecutor.\r\n\r\nThe Go session.Run interface takes a map[tf.Output]*tf.Tensor to describe the input tensors. From this the Go TF code extracts a list of input tensor operations. Since in Go map iteration order is random, the order of this list is random and likely changes every time. The session converts this to a list of input names, which remains in random order. When we reach DirectSession:GetOrCreateExecutor the key for the executor cache is partially built from this randomly ordered list of names. \r\n\r\nGetOrCreateExecutor actually builds two keys: one in the supplied order and then one in sorted order. Both are kept in the executors_ hashmap. The unsorted version is present as a performance improvement.\r\n\r\nThe number of possible unique keys generated from n randomly ordered names is n! In my case I have 23 inputs, so 23 names and 23! possibilities. 23! is  approximately 2.58 * 10^22. We rapidly run out of memory storing these unsorted keys.\r\n\r\nI think the fix will be to order the inputs in the Go code (in newCRunArgs). I'm planning to submit a PR with a fix along these lines.\r\n\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40758\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40758\">No</a>\n"]}, {"number": 40757, "title": "Memory leak in macOS Catalina 10.15", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  macOS Catalina 10.15.5\r\n- TensorFlow installed from (source or binary): from conda install\r\n- TensorFlow version (use command below):  1.15\r\n- Python version: 3.7.6\r\n\r\n**Describe the current behavior**\r\n\r\nWhen I run a tensorflow code on my Macbook, the memory usage keeps rising. Then I tried the following::\r\n-I simplified the code to the following form and still can reproduce the problem.\r\n-I found that this problem occurs only when running train_op. So I attempt to change the \"sigmoid_cross_entropy_with_logits\" to \"softmax_cross_entropy_with_logits\", the memory leak disappeared. I don\u2019t know why.\r\n-I ran this code in the Windows 10 and docker. And the memory leak also disappeared.\r\n\r\nThe activity monitor shows that the memory usage, and it continues to grow (most of them are swap).\r\n![123](https://user-images.githubusercontent.com/12993399/85534520-fc4a1900-b643-11ea-8968-5d5242e83cc2.png)\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tqdm import tqdm\r\n\r\ndata_x = np.array([[72, 20], [16, 20]], dtype=np.int32)\r\ndata_y = np.array([[0], [1]])\r\n\r\nx = tf.placeholder(tf.float32, [2, 2], name='x')\r\ny = tf.placeholder(tf.float32, [2, 1], name='y')\r\n\r\noutputs = tf.layers.dense(x, 1, use_bias=True)\r\n\r\n# loss = tf.reduce_mean(tf.pow(y - outputs, 2))\r\nloss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=outputs))    #softmax_cross_entropy_with_logits\r\ntrain_op = tf.train.AdamOptimizer(0.001).minimize(loss)\r\ninit = tf.global_variables_initializer()\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(init)\r\n    for i in tqdm(range(10000000)):\r\n        sess.run([loss, train_op], feed_dict={x: data_x, y: data_y})\r\n```\r\n\r\n", "comments": ["I am experiencing the same behaviour with my models after updating macOS to 10.15.5. I am using tensorflow 2.2.0 with Keras.  The memory usage gets so high with larger networks, which have worked without problem before, that it gets killed by the kernel.", "@SawyerGao92 Does this happen with TF 2.2 version as well?\r\n@Gariane Can you please provide a minimal code repro ?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40756, "title": "ReduceMax/ReduceMin, int8 quantization.", "body": "Added int8 quantization for ReduceMax/ReduceMin.\r\n\r\nThis PR addressed this issue: https://github.com/tensorflow/tensorflow/issues/39601\r\n", "comments": ["Hi @talumbau Yes, this change has been used to quantize the real model, but, unfortunately, I can't share it due to IP. I run op_tests for reduce op and they were green.\r\nIs there any other places where I can add some tests for quantization ?\r\nI see tests in quantize_model_test.cc, but it looks they are for the different purpose. ", "Consulted with another team member and the op_test addition is sufficient. Thanks!", "Looks like this PR fails a number of tests. For example:\r\n\r\n`bazel  test --compilation_mode=opt //third_party/tensorflow/lite/testing:zip_test_reduce_max`\r\n\r\nas well as the `zip_test_reduce_min` in the same directory. The equivalent tests over the in `lite/experimental/mlir/testing` also fail, e.g. `tensorflow/lite/experimental/mlir/testing:zip_test_reduce_max`. If you can dig in to why these fail and resolve, we can move forward with merging.\r\n\r\n", "@talumbau Thanks! I will take a look", "This should be no longer needed. A fix has been sent. Please reopen if there is still a need"]}, {"number": 40755, "title": "Mapping a function on dataset is very slow compared to one-by-one application in a loop", "body": "**System information**\r\n- I have written custom code\r\n- OS - Linux Ubuntu 20.04 LTS\r\n- TensorFlow installed by pip (inside venv)\r\n- TensorFlow version = 2.2.0\r\n- Python version = 3.8.2\r\n- CUDA Version = 10.2 \r\n- GPU model = NVIDIA GeForce GTX 1080, memory = 11175MiB\r\n\r\n**Describe the current behavior**\r\n\r\nI have a tf.data.Dataset object build of _tensor slices_ . I'm applying some computation on this dataset, call it ``compute``,  using the ``map`` functionality of tf.data.Dataset. Unrolling the result of this mapping, i.e. iterating over the elements of the mapped dataset, takes considerably longer than a simple looping over the tensors and applying the ``compute`` one-by-one on each tensor. Here is a code to reproduce the issue. \r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nThe code below is stored in a file called ``test.py``.\r\n```python\r\nimport tensorflow as tf\r\n\r\nclass Test:\r\n    def __init__(self):\r\n        gpus = tf.config.experimental.list_physical_devices('GPU')\r\n        if gpus:\r\n            tf.config.experimental.set_memory_growth(gpus[0], True)\r\n\r\n    @tf.function\r\n    def compute(self, tensor):\r\n        # some dummy computation with a tensor\r\n        print('python.print ===> tracing compute ... ')\r\n\r\n        res = 100*tensor\r\n        res = tf.signal.rfft(res)  # perform some computationally heavy task\r\n\r\n        return res\r\n\r\n    def test_on_ds(self, N):\r\n        # apply self.compute on a dataset made of N random tensors of length 10000\r\n\r\n        tensors = tf.random.uniform(shape=[N, 10000], dtype=tf.float32)\r\n        ds      = tf.data.Dataset.from_tensor_slices(tensors)\r\n\r\n        t1 = tf.timestamp()\r\n        count  = tf.constant(0, dtype=tf.int32)\r\n\r\n        ds1 = ds.map(self.compute)\r\n        for tensor in ds1:\r\n            count += 1\r\n\r\n        t2 = tf.timestamp()\r\n        tf.print('time elapsed=', t2 - t1 )\r\n\r\n        return t2 - t1\r\n\r\n    def test_on_tensors(self, N):\r\n        # apply self.compute on a N random tensors of length 10000\r\n\r\n        tensors = tf.random.uniform(shape=[N, 10000], dtype=tf.float32)\r\n\r\n        t1 = tf.timestamp()\r\n        count  = tf.constant(0, dtype=tf.int32)\r\n\r\n        for i in tf.range(N):\r\n            x = self.compute( tensors[i] )\r\n            count += 1\r\n\r\n        t2 = tf.timestamp()\r\n        tf.print('time elapsed=', t2 - t1 )\r\n\r\n        return t2 - t1\r\n```\r\n\r\n**Logs** \r\n\r\nLet us now run the above code.\r\n\r\n```python\r\n\r\nimport tensorflow as tf\r\nimport test\r\n\r\nT = test.Test()\r\n\r\na = []\r\nfor _ in range(10):\r\n    a.append( T.test_on_ds(100) )\r\n\r\n# the result of tf.print\r\n\r\n# time elapsed= 1.0664479732513428\r\n# time elapsed= 1.063709020614624\r\n# time elapsed= 1.0634510517120361\r\n# time elapsed= 1.0631310939788818\r\n# time elapsed= 1.0632259845733643\r\n# time elapsed= 1.0634918212890625\r\n# time elapsed= 1.0678679943084717\r\n# time elapsed= 1.0707681179046631\r\n# time elapsed= 1.0651659965515137\r\n# time elapsed= 1.0619449615478516\r\n\r\n# average runtime ~ 1.06 sec\r\n\r\nb = [] \r\nfor _ in range(10):\r\n    b.append(T.test_on_tensors(100))\r\n\r\n# the result of tf.print\r\n\r\n# time elapsed= 0.04901123046875\r\n# time elapsed= 0.04906916618347168\r\n# time elapsed= 0.049163103103637695\r\n# time elapsed= 0.049206018447875977\r\n# time elapsed= 0.05437779426574707\r\n# time elapsed= 0.053722143173217773\r\n# time elapsed= 0.053966999053955078\r\n# time elapsed= 0.053440093994140625\r\n# time elapsed= 0.053852081298828125\r\n# time elapsed= 0.054525852203369141\r\n\r\n# average runtime ~ 0.05 sec\r\n\r\n```\r\n\r\n", "comments": ["@hayk314 \r\n\r\nI have tried in colab with TF version 2.2 and i am seeing below error message.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/726c3027f5c0e448bea0c5eb1182fba4/untitled65.ipynb)..Please, help me with the reproducible code so it helps me in localizing the issue faster.Thanks!", "@ravikyram\r\n\r\nthanks for getting back. I've slightly adjusted the the colab version you sent and executed successfully. It should be reproducible now.\r\n\r\nUpdate: apparently , I'm having some trouble saving the colab version,\r\nso please change the part \r\n```python\r\nimport tensorflow as tf\r\nimport test\r\n\r\nT = test.Test()\r\n\r\na = []\r\nfor _ in range(10):\r\n    a.append( T.test_on_ds(100) )\r\n```\r\n\r\nto \r\n```python\r\nT = Test()\r\n\r\na = []\r\nfor _ in range(10):\r\n    a.append( T.test_on_ds(100) )\r\n```", "I have tried in colab with TF versions 2.2, nightly versions and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/2c97ca2eb667c5c816519e00f2352b88/untitled66.ipynb).Thanks!", "Thanks @hayk314 that you posted this issue,I have tested the same on Colab but on the CPU rather than GPU,The result I got is like this:\r\n\r\n```python\r\na = []\r\nfor _ in range(10):\r\n    a.append( T.test_on_ds(100) )\r\n\r\n#python.print ===> tracing compute ... \r\n#time elapsed= 2.00871205329895\r\n#time elapsed= 1.8355748653411865\r\n#time elapsed= 1.836921215057373\r\n#time elapsed= 1.8343219757080078\r\n#time elapsed= 1.8295071125030518\r\n#time elapsed= 1.8368699550628662\r\n#time elapsed= 1.8276548385620117\r\n#time elapsed= 1.8265008926391602\r\n#time elapsed= 1.8188469409942627\r\n#time elapsed= 1.8279800415039062\r\n\r\nb = [] \r\nfor _ in range(10):\r\n    b.append(T.test_on_tensors(100))\r\n\r\n#python.print ===> tracing compute ... \r\n#time elapsed= 1.8935267925262451\r\n#time elapsed= 1.8384511470794678\r\n#time elapsed= 1.8555481433868408\r\n#time elapsed= 1.8480641841888428\r\n#time elapsed= 1.8555669784545898\r\n#time elapsed= 1.8445429801940918\r\n#time elapsed= 1.8436379432678223\r\n#time elapsed= 1.8572680950164795\r\n#time elapsed= 1.8487811088562012\r\n#time elapsed= 1.8445978164672852\r\n\r\n```  \r\nDoes it mean it it make no difference which method we used for applying function,performance will be same for any of them if done on CPU?\r\nBut for the GPU the performance difference b/w both was same as yours.\r\n", "@ShubhamShaswat \r\nI actually did not test this on CPU, so thanks for pointing this out.\r\nApparently, on CPU there seems to be no difference between mapping the function on a dataset and then materializing the map vs applying the function on tensors one-by-one. \r\n\r\nThe question for GPU, however, remains, since that might become the bottleneck in a larger pipelines (e.g. when the tensors on which the dataset was created are allocated on GPU).", "@ShubhamShaswat Good job noticing :-)\r\n\r\nI think this makes it clear -- the non-tf.data.Dataset.map code runs FFT on GPU, while tf.data.Dataset.map always uses CPU only -- see for example #13610, specific answer https://github.com/tensorflow/tensorflow/issues/13610#issuecomment-335566694 or stack overflow answer https://stackoverflow.com/a/46966248/3574081.\r\n\r\nUsing `tf.debugging.set_log_device_placement(True)` confirms that the tf.data.Dataset.map runs the FFT on a CPU even if GPU is available.", "@foxik thanks for your comments and the references, very helpful indeed. \r\n\r\nJust for verification, I changed the FFT calls to some straightforward matrix manipulations, and got similar results (just to make sure this has nothing to do with the tf.signal). So, indeed the map runs on CPU, while direct calls utilize the GPU (in both cases, the initial tensors were placed on GPU though).\r\n \r\nWhat I don't quite understand, is why would the map do its computation on CPU ? \r\n(apparently, there seems to be not much news since [#13610](https://github.com/tensorflow/tensorflow/issues/13610) , or not ?) I tried to google on that, but without much luck.  Any further links or insights on why the map uses CPU when GPU is available, will be much appreciated. \r\n", "@hayk314 Indeed, there is not much official comments on the subject. I suppose the idea is that the `tf.data` is meant as data preprocessing, which should happen in parallel with the training -- so if you want to load JPG images from disk, decode them and perform some data augmentation, you can use `tf.data` for it and it will perform this work on CPU, while the GPU is performing training _at the same time_.\r\n\r\nIf `tf.data` used a GPU, it may collide with the training process itself.\r\n\r\nHowever, I just tried explicitly placing the `compose` on a GPU and it respects that -- so using\r\n```python\r\n    @tf.function\r\n    def compute(self, tensor):\r\n        with tf.device(\"/gpu:0\"):\r\n            res = 100*tensor\r\n            res = tf.signal.rfft(res)  # perform some computationally heavy task\r\n        return res\r\n```\r\nmakes the `tf.data.Dataset.map` very similar to a direct call."]}, {"number": 40754, "title": "model.fit taking 30 minutes to set-up but only 3ms to run an epoch", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information**\r\n-Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n-OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux ubuntu 20.04 LTS\r\n-Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n-TensorFlow installed from (source or binary): via pip3\r\n-TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0\r\n-Python version: 3.8.2\r\n-Bazel version (if compiling from source): N/A\r\n-GCC/Compiler version (if compiling from source): N/A\r\n-CUDA/cuDNN version: 10.1\r\n-GPU model and memory: GeForce RTX 2070 8gb\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nWhen running model.fit it takes around 30 minutes each epoch before the progress bar shows up. the actual step then takes around 3ms to complete. is there any way to speed this up? and what is happening during these 30 minutes? I'm using Jupyter Notebook to run the code.\r\n\r\n**Describe the expected behavior**\r\n\r\nNot letting model.fit take 30 minutes per epoch.\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport matplotlib.pyplot as plt\r\n import numpy as np\r\n import pandas as pd\r\n from sklearn.model_selection import train_test_split\r\n\r\n import tensorflow as tf\r\n\r\n from tensorflow.keras import layers\r\n\r\n from tensorflow.keras import Model\r\n from tensorflow.keras.models import *\r\n from tensorflow.keras.layers import *\r\n from tensorflow.keras.callbacks import *\r\n from tensorflow.keras.optimizers import *\r\n from tensorflow.keras.utils import to_categorical, plot_model\r\n dataset_controller = pd.read_csv(\"data_template_braincap.csv\")\r\n randomint = round((len(dataset_controller.index) * 0.8))\r\n randomint2 = round(len(dataset_controller.index) - randomint)\r\n train=dataset_controller.head(randomint)\r\n test=dataset_controller.tail(randomint2)\r\n X_train = train.drop(['actual time', 'timestamp bci', 'timestamp controller', 'left stick x:', 'left stick y:', 'right stick x:', 'right stick y:', 'a:', 'b:', 'x:', 'y:', 'right trigger:'], axis = 1)\r\n y_train = train['a:']\r\n X_test = test.drop(['actual time', 'timestamp bci', 'timestamp controller', 'left stick x:', 'left stick y:', 'right stick x:', 'right stick y:', 'a:', 'b:', 'x:', 'y:', 'right trigger:'], axis = 1)\r\n y_test = test['a:']\r\n\r\n\r\n y_train = y_train.head(len(y_train)-256)\r\n\r\n y_train = y_train.values.reshape((1, len(y_train), 1))\r\n X_train = X_train.shift(periods=-256, fill_value=0)\r\n X_train = X_train.head(len(X_train)-256)\r\n X_train = X_train.values.reshape((1, len(X_train), 19))\r\n model = tf.keras.Sequential()\r\n model.add((layers.SimpleRNN(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False)))\r\n model.add(Dropout(0.3))\r\n model.add(Dense(1024))\r\n model.add(Dense(1024))\r\n model.add(Dense(1024))\r\n model.add(Dense(1))\r\n model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\r\n model.summary()\r\n model.fit(X_train, y_train, epochs=500, batch_size=2048)\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nthe dataset has 31 columns and 339972 rows. the first 5 rows look like this:\r\n```\r\n0,44295.68,15337.95,-187500.02,-187500.02,-56777.86,-41605.74,-73884.49,-78516.45,-187500.02,6256.72,-187500.02,-64932.48,-53366.2,-59987.21,-187500.02,-24877.74,0.0,0.0,0.0,14:08:15.156,1591358895156,1591358895164,0,12,0,0,0,0,0,0,0\r\n1,43882.2,14582.72,-187500.02,-187500.02,-57811.38,-43702.24,-74505.63,-79345.52,-187500.02,-17205.57,-187500.02,-62077.83,-52917.82,-57371.2,-187500.02,-32231.13,0.02,0.972,0.168,14:08:15.214,1591358895214,1591358895172,0,12,0,0,0,0,0,0,0\r\n2,44356.3,15663.66,-187500.02,-187500.02,-55410.51,-41974.36,-72097.02,-76903.34,-187500.02,-2991.58,-187500.02,-63242.92,-52042.46,-58320.08,-187500.02,-29449.72,0.0,0.0,0.0,14:08:15.214,1591358895214,1591358895180,0,12,0,0,0,0,0,0,0\r\n3,43967.04,14665.94,-187500.02,-187500.02,-58229.8,-42705.06,-75319.74,-80001.02,-187500.02,-3170.95,-187500.02,-64025.45,-53815.11,-59228.72,-187500.02,-26920.17,0.0,0.0,0.0,14:08:15.214,1591358895214,1591358895188,0,12,0,0,0,0,0,0,0\r\n4,44212.8,15311.93,-187500.02,-187500.02,-55950.53,-43095.84,-72422.33,-77356.32,-187500.02,-15505.09,-187500.02,-61992.98,-51984.52,-57185.35,-187500.02,-33186.15,0.0,0.0,0.0,14:08:15.214,1591358895214,1591358895196,0,9,0,0,0,0,0,0,0 \r\n```\r\nKeras output during model.fit:\r\n```\r\nEpoch 1/500\r\n1/1 [==============================] - 0s 3ms/step - loss: 0.3895\r\nEpoch 2/500\r\n1/1 [==============================] - 0s 4ms/step - loss: 232.1620\r\nEpoch 3/500\r\n1/1 [==============================] - 0s 4ms/step - loss: 20.5877\r\nEpoch 4/500\r\n1/1 [==============================] - 0s 3ms/step - loss: 51.7856\r\n```\r\n\r\n", "comments": ["@MarinoBrundu,\r\nCould you please share the `data_template_braincap.csv` file used in the code, so that we can reproduce the issue on our end. Thanks!", "I can't attach the file because the file type is not supported, but I uploaded it to google drive and you can download it from there.\r\n\r\nhttps://drive.google.com/file/d/1Kah4XS94L_loKs0XExq6ecpkGIG_ti1t/view?usp=sharing", "@MarinoBrundu Your data is one big sequence so each epoch only have one big step. That is why epoch time is very short relative to the waiting time, and make batch_size senseless. \r\nI am not sure what you want, but it seems like you may want to break the sequence into small sequences in some way. ", "@yixingfu that fixed the problem, thank you."]}, {"number": 40753, "title": "[TF2.2] Saving checkpoint failed when there is `dataset.shuffle` in dataset flow. ", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.2\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:  v2.2.0-rc4-8-g2b96f3662b 2.2.0\r\n\r\n\r\n**Describe the current behavior**\r\nI follow the **[guide](https://www.tensorflow.org/guide/data)** to do checkpoint.\r\nWhen there is `dataset.shuffle`, Saving checkpoint failed with the following information.\r\n```\r\ntensorflow.python.framework.errors_impl.FailedPreconditionError: ShuffleDatasetOp(4)::ReshufflingDataset depends on random seed generator resource. [Op:SerializeIterator]\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\n\r\nclass Net(tf.keras.Model):\r\n  \"\"\"A simple linear model.\"\"\"\r\n\r\n  def __init__(self):\r\n    super(Net, self).__init__()\r\n    self.l1 = tf.keras.layers.Dense(5)\r\n\r\n  def call(self, x):\r\n    return self.l1(x)\r\n  \r\ndef toy_dataset():\r\n  inputs = tf.range(10.)[:, None]\r\n  labels = inputs * 5. + tf.range(5.)[None, :]\r\n\r\n  dataset = tf.data.Dataset.from_tensor_slices(\r\n    dict(x=inputs, y=labels)).repeat()\r\n  dataset = dataset.shuffle(4).batch(2)\r\n  return dataset\r\n\r\nnet = Net()\r\n\r\ndef train_step(net, example, optimizer):\r\n  \"\"\"Trains `net` on `example` using `optimizer`.\"\"\"\r\n  with tf.GradientTape() as tape:\r\n    output = net(example['x'])\r\n    loss = tf.reduce_mean(tf.abs(output - example['y']))\r\n  variables = net.trainable_variables\r\n  gradients = tape.gradient(loss, variables)\r\n  optimizer.apply_gradients(zip(gradients, variables))\r\n  return loss\r\n  \r\n\r\nopt = tf.keras.optimizers.Adam(0.1)\r\ndataset = toy_dataset()\r\niterator = iter(dataset)\r\nckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=net, iterator=iterator)\r\nmanager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=3)\r\n\r\ndef train_and_checkpoint(net, manager):\r\n  ckpt.restore(manager.latest_checkpoint)\r\n  if manager.latest_checkpoint:\r\n    print(\"Restored from {}\".format(manager.latest_checkpoint))\r\n  else:\r\n    print(\"Initializing from scratch.\")\r\n\r\n  for _ in range(50):\r\n    example = next(iterator)\r\n    loss = train_step(net, example, opt)\r\n    ckpt.step.assign_add(1)\r\n    if int(ckpt.step) % 10 == 0:\r\n      save_path = manager.save()\r\n      print(\"Saved checkpoint for step {}: {}\".format(int(ckpt.step), save_path))\r\n      print(\"loss {:1.2f}\".format(loss.numpy()))\r\n      \r\ntrain_and_checkpoint(net, manager)\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.", "comments": ["I am able to replicate the issue faced, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/3b9b630a9b576d949430aa0f42fbba6c/untitled241.ipynb).", "@nolanliou I can reproduce the issue with `TF2.2`. However, it looks like this was resolved in recent `tf-nightly`. Please check the [gist](https://colab.research.google.com/gist/jvishnuvardhan/ce7d78b86510cb3680f64895eb25c92e/untitled241.ipynb) with `tf-nightly`.\r\n\r\nIf you want to use a stable version, then you need to wait for `TF2.3` which will be released in near future. \r\n\r\nPlease verify once and close the issue if this was resolved for you. Thanks!", "@jvishnuvardhan Thanks for your reply. It works with `tf-nightly`.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40753\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40753\">No</a>\n"]}]