[{"number": 11757, "title": "Fix tf.reduce_logsumexp to accept `-inf`", "body": "Fix #11692 ", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "Known flakiness in the mac failure.  Looks good for review @aselle !", "@tensorflow-jenkins test this please", "The test failure is unrelated. Merging."]}, {"number": 11756, "title": "Infinity mask breaks gradient", "body": "I'm trying to do softmax over selected indices, using infinity mask to silent out the unwanted ones. However, the gradient of those unwanted entires become nan as opposed to 0.\r\n\r\nThe reason I didn't use boolean mask is that the mask indices are different in my batch, which can't end up with a nice matrix form. If there's workaround here I'll be more than happy to adopt.\r\n\r\nThe code I tested the infinity mask is\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\na = tf.placeholder(tf.float32, [5])\r\ninf_mask = tf.placeholder(tf.float32, [5])\r\n\r\nb = tf.multiply(a, inf_mask)\r\nsf = tf.nn.softmax(b)\r\n\r\nloss = (sf[2] - 0)\r\ngrad = tf.gradients(loss, a)\r\n\r\nsess = tf.Session()\r\n\r\na_np = np.ones([5])\r\nnp_mask = np.ones([5]) * 4\r\nnp_mask[1] = -np.inf\r\n\r\nprint sess.run([sf, grad], feed_dict={\r\n    a: a_np,\r\n    inf_mask: np_mask\r\n})\r\n\r\nsess.close()\r\n```\r\n\r\nThe output is `[array([ 0.25,  0.  ,  0.25,  0.25,  0.25], dtype=float32), [array([-0.25,   nan,  0.75, -0.25, -0.25], dtype=float32)]]`\r\n\r\nThe mask is working but the gradient has a nan, which should have been 0 I think.", "comments": ["Could you ask on StackOverflow to see if anybody has a more elegant solution?", "Yes, there's a solution on StackOverflow that uses `np.finfo(np.float32).min` instead of `-np.inf` https://stackoverflow.com/questions/45310221/tensorflow-infinity-mask-breaks-gradient/.\r\n\r\nAlso, it seems a mask (a 0-1 mask instead of negative infinity mask) applied _after_ exponential also works. \r\n\r\nI'm not sure how robust these methods are though. Hope someone can clarify. Thanks!\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\na = tf.placeholder(tf.float32, [5])\r\ninf_mask = tf.placeholder(tf.float32, [5])\r\nzero_one_mask = tf.placeholder(tf.float32, [5])\r\nexp_a = tf.exp(a)\r\n\r\nb = tf.multiply(exp_a, zero_one_mask)\r\nsf = b / tf.reduce_sum(b)\r\n\r\n# b = tf.multiply(a, inf_mask)\r\n# sf = tf.nn.softmax(b)\r\n\r\nloss = (sf[2] - 0)\r\ngrad = tf.gradients(loss, a)\r\n\r\nsess = tf.Session()\r\n\r\na_np = np.ones([5])\r\nnp_mask = np.ones([5])\r\nnp_mask[1] = 0\r\n\r\nprint sess.run([sf, grad], feed_dict={\r\n    a: a_np,\r\n    zero_one_mask: np_mask\r\n})\r\n\r\nsess.close()\r\n```\r\n\r\nThe output is `[array([ 0.25,  0.  ,  0.25,  0.25,  0.25], dtype=float32), [array([-0.0625    , -0.        ,  0.18750001, -0.0625    , -0.0625    ], dtype=float32)]]`.", "softmax is written to avoid numerical inaccuracy for ill-conditioned finite values numbers. It does this by subtracting off the max abs value and doing the computation around that. That means that injecting infinities to its arguments will give you nans as you are seeing. This numerically robust computation is key for many models. I think if you can get away with the 0 to 1 solution that is pretty decent. You could look at some of the sparse cross entropy softmax with logits functions for maximum robustness and the ability to have a sparse subset of values. \r\n\r\n", "Do you have some examples for \"sparse cross entropy softmax with logits functions\"? Thanks!", "Once you start feeding in infinities, then I expect there'll be NaN's in gradients. Fundamental reason is that gradients are obtained using simple algebraic transformations which only make sense for finite numbers. The robust way of handling things would be to use boolean masks.\r\n\r\nIt looks like \"really large number\" works in this case, although in general things can overflow and give unexpected nan. For instance, the example below produces `nan` gradient.\r\n\r\n```\r\nx = tf.placeholder(tf.float32)\r\ny = tf.exp(x)\r\nz = tf.exp(-y)\r\ngrad = tf.gradients(z,[x])[0]\r\nprint sess.run(grad, feed_dict={x: 1e10})    # => nan\r\n```\r\n", "So between masking with a very big negative number and doing softmax by hand (calculating sum of exponentials and stuff), which one is more robust/numerically stable?\r\n\r\nOr is there a better way to do this now?", "@hongzimao @sy2737 I think you guys were on the right track originally, just didn't debug things quite correctly. You wanted `a-inf_mask`, not multiply. The second solution posted above is still dangerous. stable softmax should be `e^(a-max(a))`.\r\n\r\nThe key is that `exp(-inf)==0`, `max(a, -inf)==a` and `a-inf==-inf`. Unfortunately, `0*inf==nan`, so making the mask correctly is tricky.\r\n\r\nTwo most numerically stable options would be either -inf mask or just using a sparse softmax (which might be better depending on what you are doing). \r\n\r\nBelow is an example of using -inf mask. It has some specifics because of broadcasting but you should be able to make it into whatever you need. Note that if your intention is to use this for loss calculations, you should be doing something else. Should only be using softmax itself for things like attention.\r\n- Use `tf.sequence_mask` to create a mask from sequence lengths\r\n- Create an infinity mask (this is the ugly part)\r\n-- `tf.where` to get the indices\r\n-- `tf.tile` to make as many infs as required (broadcasting doesn't seem to work)\r\n-- `tf.scatter_nd` to make the mask using the indices and the infs\r\n- Then just `tf.nn.softmax(logits - infmask, axis=1)`\r\n\r\n```python\r\ndef masked_softmax(logits, mask):\r\n    \"\"\"\r\n    Masked softmax over dim 1, mask broadcasts over dim 2\r\n    :param logits: (N, L, T)\r\n    :param mask: (N, L)\r\n    :return: probabilities (N, L, T)\r\n    \"\"\"\r\n    v = tf.shape(logits)[2]\r\n    indices = tf.cast(tf.where(tf.logical_not(mask)), tf.int32)\r\n    inf = tf.constant(np.array([[np.inf]], dtype=np.float32), dtype=tf.float32)\r\n    infs = tf.tile(inf, [tf.shape(indices)[0], v])\r\n    infmask = tf.scatter_nd(\r\n        indices=indices,\r\n        updates=infs,\r\n        shape=tf.shape(logits))\r\n    _p = tf.nn.softmax(logits - infmask, axis=1)\r\n    return _p\r\n```\r\n\r\n", "Unfortunately, as @yaroslavvb mentioned the `masked_softmax` implementation by @bstriner broke for me when computing gradients, producing `NaN`s in computing the loss. \r\n\r\nA simple workaround that got it working for me was replacing `np.inf` with `tf.float32.max`. This, of course, incurs some penalty as the padded values will not be _completely_ negligible, but I think it is the most numerically stable approach. \r\n\r\nI'm also asking if there are any other downsides to this approach as I'm only just starting out with Tensorflow and Machine Learning in general, so I'd appreciate knowing if this approach is actually breaking anything. ", "My solution to this problem:\r\n\r\n```python\r\ndef maskedSoftmax(logits, mask):\r\n    \"\"\"\r\n    Masked softmax over dim 1\r\n    :param logits: (N, L)\r\n    :param mask: (N, L)\r\n    :return: probabilities (N, L)\r\n    \"\"\"\r\n    indices = tf.where(mask)\r\n    values = tf.gather_nd(logits, indices)\r\n    denseShape = tf.cast(tf.shape(logits), tf.int64)\r\n    sparseResult = tf.sparse_softmax(tf.SparseTensor(indices, values, denseShape))\r\n    result = tf.scatter_nd(sparseResult.indices, sparseResult.values, sparseResult.dense_shape)\r\n    result.set_shape(logits.shape)\r\n    return result\r\n```\r\n\r\n(Edit: My first proposal had problems with `None` in shape of logits)", "@LordBlackhawk's solution works very well for getting the probabilities. However I was not able to adapt this solution to get cross entropy, as apparently sparse_softmax_cross_entropy_with_logits cannot take sparse vectors as inputs.\r\n\r\nIs the only solution for calculating softmax cross entropy with masks to apply a -tf.float32.max mask before hand?", "@NickRyder You can adapt the sparse_logsoftmax below. Inputs are dense logits and sparse indices. It gives you the normalized logits in a dense matrix. You can then use the sparse_crossentropy_loss below to get the logits at the labels.\r\n\r\n```python\r\ndef sparse_logsoftmax(logits, idx):\r\n    dense_shape = tf.cast(tf.shape(logits), tf.int64)\r\n    logits_values = tf.gather_nd(params=logits, indices=idx)\r\n    sparse_logits = tf.SparseTensor(indices=idx, values=logits_values, dense_shape=dense_shape)\r\n    lmax = tf.sparse_reduce_max(sp_input=sparse_logits, axis=-1, keep_dims=True)\r\n    lmax = tf.stop_gradient(lmax)\r\n    normed_logits = logits - lmax\r\n    normed_exp_values = tf.exp(tf.gather_nd(params=normed_logits, indices=idx))\r\n    sparse_normed_exp = tf.SparseTensor(indices=idx, values=normed_exp_values, dense_shape=dense_shape)\r\n    normed_sum = tf.log(tf.sparse_reduce_sum(sp_input=sparse_normed_exp, axis=-1, keep_dims=True)) + lmax\r\n    lsm = logits - normed_sum\r\n    return lsm\r\n\r\n\r\ndef sparse_crossentropy_loss(logits, labels):\r\n    n = tf.shape(labels)[0]\r\n    idx = tf.stack((tf.range(n), labels), axis=-1)\r\n    nll = - tf.reduce_mean(tf.gather_nd(params=logits, indices=idx))\r\n    return nll\r\n```", "> @hongzimao @sy2737 I think you guys were on the right track originally, just didn't debug things quite correctly. You wanted `a-inf_mask`, not multiply. The second solution posted above is still dangerous. stable softmax should be `e^(a-max(a))`.\r\n> \r\n> The key is that `exp(-inf)==0`, `max(a, -inf)==a` and `a-inf==-inf`. Unfortunately, `0*inf==nan`, so making the mask correctly is tricky.\r\n> \r\n> Two most numerically stable options would be either -inf mask or just using a sparse softmax (which might be better depending on what you are doing).\r\n> \r\n> Below is an example of using -inf mask. It has some specifics because of broadcasting but you should be able to make it into whatever you need. Note that if your intention is to use this for loss calculations, you should be doing something else. Should only be using softmax itself for things like attention.\r\n> \r\n> * Use `tf.sequence_mask` to create a mask from sequence lengths\r\n> * Create an infinity mask (this is the ugly part)\r\n>   -- `tf.where` to get the indices\r\n>   -- `tf.tile` to make as many infs as required (broadcasting doesn't seem to work)\r\n>   -- `tf.scatter_nd` to make the mask using the indices and the infs\r\n> * Then just `tf.nn.softmax(logits - infmask, axis=1)`\r\n> \r\n> ```python\r\n> def masked_softmax(logits, mask):\r\n>     \"\"\"\r\n>     Masked softmax over dim 1, mask broadcasts over dim 2\r\n>     :param logits: (N, L, T)\r\n>     :param mask: (N, L)\r\n>     :return: probabilities (N, L, T)\r\n>     \"\"\"\r\n>     v = tf.shape(logits)[2]\r\n>     indices = tf.cast(tf.where(tf.logical_not(mask)), tf.int32)\r\n>     inf = tf.constant(np.array([[np.inf]], dtype=np.float32), dtype=tf.float32)\r\n>     infs = tf.tile(inf, [tf.shape(indices)[0], v])\r\n>     infmask = tf.scatter_nd(\r\n>         indices=indices,\r\n>         updates=infs,\r\n>         shape=tf.shape(logits))\r\n>     _p = tf.nn.softmax(logits - infmask, axis=1)\r\n>     return _p\r\n> ```\r\n\r\nI've adapted the `-np.inf` solution together with `sparse_softmax_cross_entropy_with_logits` and it worked flawlessly.\r\n\r\nThe only problem is that I expected it to be faster since we are only applying softmax to a subset of labels, but it takes the same time as the standard softmax over all the labels (10000+).\r\n\r\nWhat is going on here? Are all the gradients being calculated even for the infinity mask?\r\n\r\nIs there a more effecient solution that skips or ignores masked values, like `tf.sparse.softmax` suggested by @bstriner ?", "I've just tried @LordBlackhawk solution that uses `tf.sparse.softmax`.  It's 2x slower than @bstriner's `np.inf` together with `sparse_softmax_cross_entropy_with_logits`.\r\n\r\nBoth solutions are very elegant and using them provided sharper convergence and lower loss since the labels are restricted. But none of them is faster than the standard `tf.nn.softmax`. \r\n\r\nThis is baffling to me since I\u2019m using thousands of labels but each record only has a really small percentage of non-masked labels that need to be updated. I expected the cost to be similar to having a single softmax with the same number of logits as the length of the largest subset of labels, in this case hundreds.", "@hongzimao ,\r\nWe see that you are using older version of tensorflow (1.x) which is not actively supported. We recommend that you upgrade to latest stable version of tensorflow 2.6.0 and let us know if the issue still persists in newer versions .Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/11756\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/11756\">No</a>\n"]}, {"number": 11755, "title": "how to assign a tensor to a sub part of another tensor", "body": "Hi, dear all,\r\n\r\nI am new to tensorflow. Previously I use theano. Now I want to assign a tensor to a sub part of another tensor. e.g.:\r\n\r\na = \r\n[[0,0,0,0],\r\n[0,0,0,0],\r\n[0,0,0,0],\r\n[0,0,0,0]]\r\nb = \r\n[[1],\r\n[3],\r\n[4].\r\n[5]]\r\nI would assign to a[0,:], like this\r\na = \r\n[[1,0,0,0],\r\n[3,0,0,0],\r\n[4,0,0,0],\r\n[5,0,0,0]]\r\nin theano we use set_subtensor, what should I do with tensorflow? Thank you very much!", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 11754, "title": "Minor updates in MD files", "body": "-Made explicit HTTPS calls\r\n-Minor edits", "comments": ["Can one of the admins verify this patch?"]}, {"number": 11753, "title": "tf.train.SyncReplicasOptimizer no synchronization among workers", "body": "\r\n### System information\r\n- Have I written custom code : Yes\r\n- OS Platform and Distribution : Linux\r\n- TensorFlow installed from (source or binary)**: Binary\r\n- TensorFlow version (use command below)**: 1.2.1\r\n- Python version**: 3.5.2\r\n\r\n### Problem Description\r\nI'm trying to train an rnn model with distributed synchronized training and between graph replication. I'm using tf.train.replica_device_setter. Asynchronous Training works perfectly fine. As written in the [documentation](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/python/training/sync_replicas_optimizer.py) I'm wrapping my optimizer and creating the hook:\r\n\r\n```\r\ndef training(loss,learning_rate,global_step,num_workers,is_chief):\r\n    optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate)\r\n    optimizer = tf.train.SyncReplicasOptimizer(optimizer, replicas_to_aggregate=num_workers,\r\n                                       total_num_replicas=num_workers)\r\n    gvs = optimizer.compute_gradients(loss)\r\n    capped_gvs = [(tf.clip_by_value(grad, -CLIPPING_THRESHOLD, CLIPPING_THRESHOLD), var) for       grad, var in gvs]\r\n    train_op = optimizer.apply_gradients(capped_gvs,global_step=global_step)\r\n    print('Is Chief?: ' + str(is_chief))\r\n    hook=optimizer.make_session_run_hook(is_chief)\r\n    return train_op,hook\r\n```\r\nFor creating and running the Session I'm using exactly as told in the documentation:\r\n```\r\nsess = tf.train.MonitoredTrainingSession(master=server.target, is_chief=(task_index == 0),hooks=[hook])\r\nsess.run([train_op],feed_dict=...)\r\n```\r\n\r\nHowever as already noticed in #9596 and several other issues[[1](https://stackoverflow.com/questions/41293576/distributed-tensorflow-good-example-for-synchronous-training-on-cpus),[2](https://github.com/tensorflow/tensorflow/issues/8978)] the training does not seem to synchronize among workers. So is there a bug in SyncReplicasOptimizer? I'm seeing several hints for this hypothesis: \r\n\r\n1. One worker is constantly ahead by several steps in my logs.\r\n2. When stopping one worker the other just continues with the training as if nothing happened. In a synchronized setting training should stop or crash.\r\n3. The training steps take approximately the same time as asynchronous training. Synchronous Training should be slower because of the synchronization.\r\n\r\nQuestions:\r\n1. Is there any test with which one can confirm, that sync_replicas_optimizer.py really does synchronize?\r\n2. Is the API-Documentation regarding sync_replicas_optimizer.py up to date?\r\n2. Is this somehow related to tf.train.replica_device_setter as mentioned by @jmchen-g in #9596?\r\n3. Are there any workarounds for this?\r\n", "comments": ["@ali01 Do you have time to look into this?", "I haven't looked at synchronizing with tf.train.MonitoredTrainingSession yet. However, I have some experience related to using tf.train.Supervisor instead. I was having the same problem as yours:\r\n    * that one of the replicas (chief) was far ahead than others, while other seemed to be waiting for some time\r\n\r\nI noticed the default value (30 second) for parameter 'recovery_wait_secs' that tf.train.Supervisor takes. Basically, every replica checks every 30 second to see if the model is ready. So, the chief starts immediately and the rest simply wait for 30 sec. After I set this value to 1, the replicas started training almost at the same time (except the first few steps). So, I suggest you to look at which input parameter of tf.train.MonitoredTrainingSession this time is set. This might be a direction to look at.\r\n\r\n(This following discussion also refers to the use of tf.train.Supervisor so please check for yourself if it holds): Another point I have observed is that it seems like SyncReplicaOptimizer does not really care if the 'replicas_to_aggregate' gradients come from the different workers or not. Even if other workers are waiting or not initialized, the chief starts training immediately. And if you print the global_steps you will see same global_steps for 'replicas_to_aggregate' times. This means that the chief pushes enough gradients for tf.train.SyncReplicaOptimizer to average and apply the gradients. So, start the chief worker process only after starting all other workers.\r\n", "@utkrist Thank you for your informative answer. I checked the global step and indeed it behaves like you explained for tf.train.Supervisor, except for a short initial phase. In my case the model error with asynchronous training got bad after 15 to 20 Workers. When using synchronous training I can scale beyond 40 workers after increasing my learning rate by sqrt(workers), because of increased batch size. So the synchronization seems to work as expected. Issue can be closed.", "@smodlich I am curious how do you set the learning rate, is it simply lr = 1/(sqrt(workers)) or what?\r\nI also need to scale to many machines soon. ", "Glad to see that it works as expected :)\r\n\r\nApparently different models have different settings. Just note that the newer sync replica optimizer is using the average instead of sum so if you have N replicas, you might want to try sqrt(N) * lr instead of making it smaller.", "@utkrist I'm using a base learning rate of 0.001 which works fine for a single worker. I multiply this learning rate for distributed training by sqrt(N) where N is number of workers (Just as @jmchen-g wrote). I also tried: base lr*N (mentioned in [this paper](https://research.fb.com/wp-content/uploads/2017/06/imagenet1kin1h5.pdf?)) but that was to high.", "@smodlich Recently i used MonitoredTrainingSession and SyncReplicasOptimizer for distributed training, i was having the same problem as  yours.\r\nNow i found the solution:\r\n```\r\nhook=optimizer.make_session_run_hook(is_chief)\r\n```\r\nmodified to \r\n```\r\nhook=optimizer.make_session_run_hook(is_chief, num_tokens=0)\r\n```", "> @smodlich Recently i used MonitoredTrainingSession and SyncReplicasOptimizer for distributed training, i was having the same problem as yours.\r\n> Now i found the solution:\r\n> \r\n> ```\r\n> hook=optimizer.make_session_run_hook(is_chief)\r\n> ```\r\n> modified to\r\n> \r\n> ```\r\n> hook=optimizer.make_session_run_hook(is_chief, num_tokens=0)\r\n> ```\r\n\r\nIt seems solve my problem. Thanks a lot!", "> \r\n> \r\n> @smodlich Recently i used MonitoredTrainingSession and SyncReplicasOptimizer for distributed training, i was having the same problem as yours.\r\n> Now i found the solution:\r\n> \r\n> ```\r\n> hook=optimizer.make_session_run_hook(is_chief)\r\n> ```\r\n> \r\n> modified to\r\n> \r\n> ```\r\n> hook=optimizer.make_session_run_hook(is_chief, num_tokens=0)\r\n> ```\r\n\r\nI finally got my workers to synchronize by making this change.  Thanks."]}, {"number": 11752, "title": "R0.10", "body": "I need it for test", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "This has conflicts, and I don't think we're supporting r0.10 anymore -- consider making these changes to your own fork instead!  Thanks!"]}, {"number": 11751, "title": "add aarch64", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->"]}, {"number": 11750, "title": "summary.FileWriter should support with statement", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttp://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**:  v1.2.0-5-g435cdfc 1.2.1\r\n- **Python version**: 3.6.2\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 8.0\r\n- **GPU model and memory**: GTX1050 4GB\r\n- **Exact command to reproduce**:\r\n\r\n\r\n\r\n### Describe the problem\r\n\r\nPython users would expect a file writer to support the `with` statement, but it doesn't:\r\n\r\n\r\n\r\n### Source code / logs\r\n\r\n```py\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\n\r\nwith tf.Graph().as_default():\r\n    with tf.Session() as sess:\r\n        my_var = tf.Variable(tf.truncated_normal([3, 4]), name=\"myvar\", dtype=tf.float32)\r\n        my_var_plus = my_var.assign_add(np.ones([3, 4], dtype=np.float32) * 10.0)\r\n        a = tf.placeholder(tf.float32, shape=[None], name=\"input_a\")\r\n        b = tf.reduce_sum(a, name=\"sum_b\")\r\n        c = tf.reduce_max(a, name=\"max_c\")\r\n        d = tf.add(b, c)\r\n        with tf.summary.FileWriter(\"./tf_summary\", sess.graph):\r\n            res = sess.run(d, feed_dict={a: np.array([5, 6, 7, 8], dtype=np.float32)})\r\n            print(res)\r\n            init = tf.variables_initializer([my_var])\r\n            sess.run(init)\r\n            for _ in range(10):\r\n                res = sess.run(my_var_plus)\r\n            print(res)\r\n```\r\n\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/kaiyin/miniconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-19-39981f92616d>\", line 13, in <module>\r\n    with tf.summary.FileWriter(\"./tf_summary\", sess.graph):\r\nAttributeError: __enter__\r\n```", "comments": ["This seems like a reasonable request. What do you think @dandelionmane?", "Added PR #11799."]}, {"number": 11749, "title": "SGDR Learning Rate Decay Algorithm", "body": "Implementation of \r\n\"SGDR: Stochastic Gradient Descent with Warm Restarts\" by Ilya Loshchilov & Frank Hutter.\r\nhttps://arxiv.org/pdf/1608.03983.pdf\r\nDeveloped together with the author @loshchil\r\nAdds cosine annealing for learning rate decay #11113.\r\n\r\n![mmul](https://user-images.githubusercontent.com/21221121/28573907-88b545d0-714c-11e7-85cb-831f2398795a.png)\r\n\r\n\r\n", "comments": ["Can one of the admins verify this patch?", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_author_cla -->", "Recheck CLA", "CLAs look good, thanks!\n\n<!-- ok -->", "@vrv could you take another look, please?", "Yes, sorry, looking now.  GitHub doesn't notify me when people push changes. :(", "@tensorflow-jenkins test this please", "This new function needs to be referenced in the documentation here:\r\nhttps://www.tensorflow.org/api_guides/python/train#Decaying_the_learning_rate\r\n\r\nOnly tf.train.cosine_decay is referenced there. cosine_decay just decreases the learning rate town to its minimum. It does not restart.\r\n\r\nBy the way the documentation of cosine_decay should be corrected too. It mentions the SGDR article \"with warm restarts\" but it never states that it is NOT the cosine decay with restarts mentioned in the article.", "@martin-gorner To my best understanding, the original function mentioned here was removed in https://github.com/tensorflow/tensorflow/pull/14500/commits/65a11ef710083c106fb5479145b3b8e133f79b1d after @PatrykChrabaszcz introduced (please see https://github.com/tensorflow/tensorflow/pull/14500 ) cosine_decay function and cosine_decay_restarts which implements cosine annealing with restarts.\r\n\r\nThe paper is referenced correctly because this is where cosine decay was proposed. Cosine decay  does not automatically assume restarts, it defines how learning rate decays / the shape of its decrease. SGDR represents SGD with restarts employing cosine annealing for each of its cycles by default (SGDR will remain SGDR if you replace cosine annealing for each cycle with an alternative decay scheme such as  piecewise_constant).  \r\n\r\n@PatrykChrabaszcz could you please double-check my assessment and (if you agree with it) add cosine_decay_restarts to https://www.tensorflow.org/api_guides/python/train#Decaying_the_learning_rate\r\nonce you have some spare time? ", "Yes, **sgdr_decay** from the contrib package is not available anymore. \r\nInstead, one can use **cosine_decay_restarts** function, which is implemented here:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/learning_rate_decay.py#L600\r\n\r\nThe documentation is available here:\r\nhttps://www.tensorflow.org/api_docs/python/tf/train/cosine_decay_restarts\r\n\r\nI do not know why the link was not added to the api_guides section\r\n\r\n@martin-gorner Do you want us to fix this? If it is the case then can you point me to the files which are used to generate api_guides part of the documentation?\r\n", "I do not know which files are used. @martinwicke should know.\r\nWhere are the files that generate this list in the documentation:\r\nhttps://www.tensorflow.org/api_guides/python/train#Decaying_the_learning_rate\r\nThe function cosine_decay_restarts should be added to the list.", "Ah. @MarkDaoust knows for sure, I believe the file is here:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/api_guides/python/train.md\r\n", "> I believe the file is here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/api_guides/python/train.md\r\n\r\nYes. This is the correct file."]}, {"number": 11748, "title": "Ensure that the multi-instruction fuse can take shared inputs", "body": "Note that the fuse action only works when the shared input / constant\r\nappears after all of its consumers in the list of instructions.\r\n\r\nthere isn't (currently) a test to verify that this behaviour will continue to function in the future", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "I do not think that the failure in the windows test is down to my change.\r\n", "Thanks @DavidNorman, I'll wait for the review from an XLA person to move forward, but this seems like a nice test case from an outside observer :)", "@tensorflow-jenkins test this please", "Thanks for the PR and for the review!", "thanks @vrv and @eliben ", "This failure is due to a disk space failure on the OS/X build machine I think.  ", "Actually - that's why the other change has failed.  this one has failed due to a test called:\r\n\r\n//tensorflow/contrib/signal:spectral_ops_test \r\n\r\nI don't think that adding an XLA test can affect this test though.  I'm confused about why it failed for OS/X and not Linux.  Perhaps it is a flakey test?   I will double check the logs though.", "It's a flaky test on mac only for an unrelated op, (not sure why the numerics are bad there, the author of the test knows about it)."]}, {"number": 11747, "title": "typo in the beginning comment", "body": "There is typo \"r\" before the beginning comment.", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "@tigercosmos: thanks for the PR. However, this is not a typo. The doc string contains special characters, which make it necessary to use the r prefix."]}, {"number": 11746, "title": "ctc", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttp://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": []}, {"number": 11745, "title": "Using AOT compilation on network with bidirectionnal layer fails because of missing Exit on Switch node", "body": "I have been reproducing that for a while, ranging from 1.0.1 builds to current master. Running `tfcompile` fails like this:\r\n\r\n```\r\ntensorflow/bazel-bin/tensorflow/compiler/aot/tfcompile --graph=test.pb  --config=native_client/tfcompile.config.pbtxt\r\n2017-07-13 13:29:55.989141: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 4 visible devices\r\nINVALID ARGUMENTS: Missing Exit successor to bidirectional_rnn/fw/fw/while/Switch\r\n```\r\n\r\nI have been able to find that this was 100% repro when we have the bidirectionnal layer in the network:\r\n```\r\ntf.nn.bidirectional_dynamic_rnn(...)\r\n```\r\n\r\nAs long as there are no more bidirectionnal layers, then it is fine. I searched and I have not been able to find any documentation (but maybe I missed it?) that would state properly the status of the `Exit` node wrt `Switch` node. Further investigation would show that some of the `Switch` nodes in the network would be followed by one `Exit` but that this one was being followed by `Identity`.\r\n\r\nI assumed that the checks performed by `tfcompile` were too tight, and took a chance:\r\n```\r\ndiff --git a/tensorflow/compiler/tf2xla/functionalize_control_flow.cc b/tensorflow/compiler/tf2xla/functionalize_control_flow.cc\r\nindex faa88ecfe..fda3cbd00 100644\r\n--- a/tensorflow/compiler/tf2xla/functionalize_control_flow.cc\r\n+++ b/tensorflow/compiler/tf2xla/functionalize_control_flow.cc\r\n@@ -383,8 +383,8 @@ Status FunctionalizeLoop(Graph* graph, Frame* frame,\r\n         }\r\n       }\r\n       if (arg.exit == nullptr) {\r\n-        return errors::InvalidArgument(\"Missing Exit successor to \",\r\n-                                       arg.switch_node->name());\r\n+        // return errors::InvalidArgument(\"Missing Exit successor to \",\r\n+        //                                arg.switch_node->name());\r\n       }\r\n     }\r\n   }\r\n@@ -454,7 +454,7 @@ Status FunctionalizeLoop(Graph* graph, Frame* frame,\r\n       graph->AddEdge(in_edge->src(), in_edge->src_output(), while_node, i);\r\n     }\r\n \r\n-    if (!arg.is_loop_invariant) {\r\n+    if (arg.exit != nullptr && !arg.is_loop_invariant) {\r\n       std::vector<const Edge*> edges(arg.exit->out_edges().begin(),\r\n                                      arg.exit->out_edges().end());\r\n       for (const Edge* edge : edges) {\r\n```\r\n\r\nThis indeed worked and I have been able to build (even cross-build for ARM/RPi3) a RNN-based network (using `BasicRNN` cells or `BasicLSTM` cells).\r\n\r\nSo I guess that the questions is really: am I just lucky that it works because one `Switch` MUST really have an `Exit` node (and thus, is there something wrong in the current model), or is it just being picky ?", "comments": ["Looks like I should have had a more close look at issue #11275", "@lissyx did you manage to solve this?", "Short answer, yes. Long answer I has to work on some TaskCluster bits to have more tooling, and there are still issues related to upstream but I managed to get it working even with ARM cross compilation targeting RPi3."]}, {"number": 11744, "title": "can't understand tf.contrib.training.bucket_by_sequence_length", "body": "```\r\nseqLen = 10\r\ninputs = []\r\ninputs.append(tf.convert_to_tensor(np.array([2,3,3,3,3,3,5,4,3])))\r\ninputs.append(tf.convert_to_tensor(np.array([2, 3, 4])))\r\ninputs.append(tf.convert_to_tensor(np.array([3,4,3])))\r\ninputs.append(tf.convert_to_tensor(np.array([3,4,2])))\r\ninputs.append(tf.convert_to_tensor(np.array([3,4,5])))\r\ninputs.append(tf.convert_to_tensor(np.array([3,4,4])))\r\ninputs.append(tf.convert_to_tensor(np.array([3,4,1])))\r\n\r\nsequences, output = tf.contrib.training.bucket_by_sequence_length(input_length=seqLen, tensors= inputs, batch_size=[4,2], \r\n                                                                  bucket_boundaries =[4], allow_smaller_final_batch=True,\r\n                                              dynamic_pad=True, capacity=32)\r\n\r\ninit_op = tf.global_variables_initializer()\r\n\r\nsess = tf.Session()\r\n\r\nsess.run(init_op)\r\n\r\ncoord = tf.train.Coordinator()\r\nthreads = tf.train.start_queue_runners(sess=sess, coord=coord)\r\n\r\ntry:\r\n    while not coord.should_stop():\r\n        s, o= sess.run([sequences, output])\r\n        print s\r\n        print '****'\r\n        print o\r\n        print '----'\r\n        coord.request_stop()\r\n\r\nexcept tf.errors.OutOfRangeError:\r\n    print('Done training -- epoch limit reached')\r\nfinally:\r\n    coord.request_stop()\r\n\r\ncoord.join(threads)\r\nsess.close()\r\n```\r\nIt seems that the documentation of those bucketing function is quite not clear\r\nI can't figure out why the result the this code is \r\n```\r\n[10 10]\r\n****\r\n[array([[2, 3, 3, 3, 3, 3, 5, 4, 3],\r\n       [2, 3, 3, 3, 3, 3, 5, 4, 3]]), array([[2, 3, 4],\r\n       [2, 3, 4]]), array([[3, 4, 3],\r\n       [3, 4, 3]]), array([[3, 4, 2],\r\n       [3, 4, 2]]), array([[3, 4, 5],\r\n       [3, 4, 5]]), array([[3, 4, 4],\r\n       [3, 4, 4]]), array([[3, 4, 1],\r\n       [3, 4, 1]])]\r\n----\r\n```\r\n\r\nwhat I intended was :  batch size 4 for those input length are smaller than 4,  batch size 2 for those input length is bigger or the same as 4(because the bucket_boundaries = [4])\r\n\r\nThere was a similar post before #5609 but I still think that there lacks a  proper example for it.\r\n\r\nwhich point do i misunderstand about?", "comments": ["Hi, I've also been struggling for 2 days now trying to batch multiple sentences with different lengths with this function. I simply cannot get it to work. If anyone has any guidance I would greatly appreciate it.\r\nThanks ", "This may be of help:\r\nhttps://github.com/wcarvalho/jupyter_notebooks/blob/ebe762436e2eea1dff34bbd034898b64e4465fe4/tf.bucket_by_sequence_length/bucketing%20practice.ipynb", "From the README, \"We use GitHub issues for tracking requests and bugs. So please see TensorFlow Discuss for general questions and discussion, and please direct specific questions to Stack Overflow.\" Please close, and if you need further help, ask on TensorFlow Discuss and/or Stack Overflow. ", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "Actually, i was requesting for new documentation for those bucketing function usage and examples\n\n_Sent from my Samsung SM-G950N using [FastHub](https://play.google.com/store/apps/details?id=com.fastaccess.github)_"]}, {"number": 11743, "title": "ImportError: cannot import name contrib", "body": "How to downgrade tensorflow to 1.0.0  ?", "comments": []}, {"number": 11742, "title": "Docker :: Restoring from a model outside the container returns FailedPreconditionError", "body": "### System information\r\n- **OS Platform and Distribution**: Docker Tensorflow CPU Image\r\n- **TensorFlow version (use command below)**: 1.2.1\r\n- **Python version**: Python 2.7.12\r\n\r\n### Source code / logs\r\n```python\r\nsaver = tf.train.Saver()\r\nwith tf.Session(config=config) as sess:\r\n    saver.restore(sess, checkpoint_file)\r\n```\r\n\r\n### The Issue\r\nI'm binding a host `models` directory to `/data/models` inside the container.\r\nWhen trying to restore, I got a `Failed precondition`\r\nEverything's okay when I'm not using Docker\r\nEverything's okay when I'm building a Docker Image with the models already copied into it (but not flexible)\r\n\r\n```\r\nINFO:tensorflow:Restoring parameters from /data/models/OSVOS_parent.ckpt-50000\r\n2017-07-25 08:53:42.434679: W tensorflow/core/framework/op_kernel.cc:1158] Failed precondition: /data/models/OSVOS_parent.ckpt-50000.index\r\n///\r\ntensorflow.python.framework.errors_impl.FailedPreconditionError: /data/models/OSVOS_parent.ckpt-50000.index\r\n\t [[Node: save/RestoreV2_20 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/RestoreV2_20/tensor_names, save/RestoreV2_20/shape_and_slices)]]\r\n\r\nFailedPreconditionError (see above for traceback): /data/models/OSVOS_parent.ckpt-50000.index\r\n\t [[Node: save/RestoreV2_20 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/RestoreV2_20/tensor_names, save/RestoreV2_20/shape_and_slices)]]\r\n```", "comments": ["@ilchemla what are the versions of your tensorflow inside and outside the docker container?", "@caisq Same `tensorflow (1.2.1)`", "How are you mounting? with -v on the docker run? Are they read-only? If you copy the checkpoint into the docker cotnainer rather than -v mounted directory does it work (slightly different than just pre-loading it into the image)?\r\n", "Yes I'm using `-v` argument\r\n\r\n`docker run -ti -v /Users/work/data/models/:/data/models/ -v /Users/work/tensorflow-example:/opt/tensorflow-example tensorflow/tensorflow python -u /opt/tensorflow-example/train.py --model /data/models/OSVOS_parent.ckpt-50000`\r\n\r\nThe issue doesn't reproduce 100% but for most call it happen.\r\n\r\n**EDIT:** Found that the issue happen only when I was mounting a directory located on an external hardisk. Closing the issue.\r\n\r\nThanks for the support!"]}, {"number": 11741, "title": "Fix web link to tool_developers guide", "body": "Fix web link in README.md by changing it from:\r\n[https://www.tensorflow.org/versions/master/how_tos/tool_developers/index.html](https://www.tensorflow.org/versions/master/how_tos/tool_developers/index.html)\r\nto:\r\n[https://www.tensorflow.org/versions/master/extend/tool_developers/index.html](https://www.tensorflow.org/versions/master/extend/tool_developers/index.html)", "comments": ["Can one of the admins verify this patch?"]}, {"number": 11740, "title": "several Session , Models in one file ", "body": "so I am using CNN for fave detection and also I have CNN for age classification . but it seems two network doesn't work together.\r\n\r\nmy code is :\r\n\r\n```\r\ndef main():\r\n\r\n    minsize = 20\r\n    threshold = [0.6, 0.7, 0.7]\r\n    factor = 0.709\r\n\r\n\r\n    print('Creating networks and loading parameters')\r\n   \r\n\r\n\r\n    sess= tf.Session()\r\n    with tf.variable_scope(\"MTCNN\"):\r\n\r\n            pnet, rnet, onet = FD2.create_mtcnn(sess, None,\"MTCNN\")\r\n    writer = tf.summary.FileWriter(\"./graphs\", sess.graph)\r\n      \r\n    img = cv2.imread('./test1.jpg')\r\n    img_matlab = img.copy()\r\n\r\n    # BGR -> RGB\r\n    tmp = img_matlab[:, :, 2].copy()\r\n    img_matlab[:, :, 2] = img_matlab[:, :, 0]\r\n    img_matlab[:, :, 0] = tmp\r\n\r\n    boundingboxes, points = FD2.detect_face(img_matlab, minsize, pnet, rnet, onet, threshold, factor)\r\n    points=np.reshape(points.T, (-1,10))\r\n\r\n    boxes=boundingboxes    \r\n    x1 = boxes[:, 0]\r\n    y1 = boxes[:, 1]\r\n    x2 = boxes[:, 2]\r\n    y2 = boxes[:, 3]\r\n\r\n\r\n    with sess.as_default():\r\n    \r\n    \r\n        label_list_age = AGE_LIST\r\n        nlabels_age = len(label_list_age)\r\n\r\n        model_fn_age = select_model(FLAGS.model_type_age)\r\n        images = tf.placeholder(tf.float32, [None, RESIZE_FINAL, RESIZE_FINAL, 3])\r\n        soft = tf.placeholder(tf.float32, [None, RESIZE_FINAL, RESIZE_FINAL, 3])\r\n\r\n        logits_age = model_fn_age(nlabels_age, images, 1, False)\r\n        init = tf.global_variables_initializer()\r\n        requested_step = FLAGS.requested_step if FLAGS.requested_step else None\r\n        checkpoint_path_age = '%s' % (FLAGS.model_dir_age)\r\n        model_checkpoint_path_age, global_step_age = get_checkpoint(checkpoint_path_age, requested_step, FLAGS.checkpoint_age)\r\n       \r\n        saver = tf.train.Saver()\r\n        saver.restore(sess, model_checkpoint_path_age)\r\n        softmax_output_age = tf.nn.softmax(logits_age)\r\n        coder= ImageCoder()\r\n\r\n    #with tf.Session as sess:\r\n\r\n       \r\n        \r\n        for i in range(x1.shape[0]):\r\n\r\n       \r\n            upper_cut = [min(img.shape[0], int(y2[i]) ), min(img.shape[1], int(x2[i]))]\r\n            lower_cut = [max(int(y1[i]), 0), max(int(x1[i]) , 0)]\r\n            age_image = img[lower_cut[0]:upper_cut[0], lower_cut[1]:upper_cut[1]]\r\n            best_choice_age= classify_age(sess, label_list_age, softmax_output_age, coder, boxes,age_image )\r\n            age.append(best_choice_age)\r\n   \r\n        img = markLandmark(img,points)\r\n        img = drawBoxes(img, boundingboxes)\r\n\r\n        cv2.imshow('window',img)\r\n        cv2.waitKey(0)\r\n\r\n        sess.close()\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n\r\n```\r\n\r\n\r\n\r\n\r\nand the  error is : \r\n```\r\n  File \"/home/sepid/tf/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/home/sepid/tf/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nNotFoundError (see above for traceback): Key MTCNN/rnet/conv5-2/weights not found in checkpoint\r\n\t [[Node: save/RestoreV2_45 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_45/tensor_names, save/RestoreV2_45/shape_and_slices)]]\r\n\t [[Node: save/RestoreV2_18/_169 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_28_save/RestoreV2_18\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\r\n```\r\n", "comments": ["From the error message, it seems that you're trying to restore a checkpoint that doesn't contain weights for one of your models.\r\n\r\nThe error stacktrace provided seems to be truncated (instead of the full error seen) and the code provided isn't sufficient to reproduce the problem (e.g., I have no clue what the `FD2` module is or how the checkpoints were created).\r\n\r\nI'd suggest trying to distill the code above into a small reproducible example.\r\n\r\nIn general, if you combine two networks into one graph, then you'd want to checkpoint the combined graph. Alternatively, you could use separate graphs and sessions for each network.", "got it , thank you will try to make separate graphs ."]}, {"number": 11739, "title": "Add less_equal and logical_or to android_core_ops", "body": "Added below two ops to android_core_ops, as similar to #11631\r\ntensorflow/core/kernels/cwise_op_logical_or.cc\r\ntensorflow/core/kernels/cwise_op_less_equal.cc\r\n\r\nI think these are very basic ops and should add to the list by default.", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please"]}, {"number": 11738, "title": "Using VSCode to import tensorflow failed", "body": "I've installed tensorflow on Windows 10 successfully.But I can only run tensorflow under terminal command .What I want to do is to write python script on VSCode. It turns out some configuration may be done for VSCode.So Is there anyone who can solve this?Thanks a lot.", "comments": []}, {"number": 11737, "title": "syntaxnet: parser_eval --graph_builder=greedy ,Assign requires shapes of both tensors to match. lhs shape= [32,69] rhs shape= [400,69]", "body": "Error: \r\n![image](https://user-images.githubusercontent.com/21216639/28559200-238f40a6-7148-11e7-90c6-0f426bfe8426.png)\r\n\r\nI use GPU to train;\r\nwhen greedy training, I can train model and parser eval with --graph_builder=structured successful, but parser_eval with --graph_builder=greedy failed;\r\nhere is my configuration: \r\n\"bazel-bin/syntaxnet/parser_trainer\" \\\r\n  --arg_prefix=brain_parser \\\r\n  --batch_size=400 \\\r\n  --compute_lexicon \\\r\n  --decay_steps=4400 \\\r\n  --graph_builder=greedy \\\r\n  --hidden_layer_sizes=1024,1024 \\\r\n  --learning_rate=0.08 \\\r\n  --momentum=0.9 \\\r\n  --seed=4 \\\r\n  --output_path=$TMP_DIR \\\r\n  --task_context=$TMP_DIR/context \\\r\n  --training_corpus=training-corpus \\\r\n  --tuning_corpus=tuning-corpus \\\r\n  --params=$PARAMS \\\r\n  --num_epochs=25 \\\r\n  --report_every=1000 \\\r\n  --checkpoint_every=10000 \\\r\n  --logtostderr\r\n\r\n\"bazel-bin/syntaxnet/parser_eval\" \\\r\n  --task_context=$TMP_DIR/brain_parser/greedy/$PARAMS/context \\\r\n  --hidden_layer_sizes=1024,1024 \\\r\n  --input=dev-corpus \\\r\n  --output=stdout \\\r\n  --arg_prefix=brain_parser \\\r\n  --graph_builder=greedy \\\r\n  --model_path=$TMP_DIR/brain_parser/greedy/$PARAMS/model \\\r\n  --logtostderr \\\r\n  > $TMP_DIR/greedy-out\r\n\r\n\"bazel-bin/syntaxnet/parser_eval\" \\\r\n  --task_context=$TMP_DIR/context \\\r\n  --hidden_layer_sizes=1024,1024 \\\r\n  --beam_size=1 \\\r\n  --input=dev-corpus \\\r\n  --output=stdout \\\r\n  --arg_prefix=brain_parser \\\r\n  --graph_builder=structured \\\r\n  --model_path=$TMP_DIR/brain_parser/greedy/$PARAMS/model \\\r\n  --logtostderr \\\r\n  > $TMP_DIR/struct-beam1-out\r\n\r\n\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 11736, "title": "tf1.2.1 can't build on Ubuntu 16.04 pyenv", "body": "I can't build tf1.2.1 from source. on ubuntu 16.04 and pyenv.\r\ntf1.0, tf1.1 are ok to be build normally.\r\n\r\n### System information\r\n- Ubuntu 16.04\r\n- tf from git checkout r1.2\r\n- python 3.5.2\r\n- bazel 0.5.2 (from deb)\r\n- CUDA 8.0, cudnn5\r\n- GTX 1080ti x2\r\n\r\n### python environment\r\n\r\n```\r\npyenv install 3.5.2\r\npyenv virtualenv 3.5.2 tf1.2\r\npyenv local tf1.2\r\n```\r\nrequired packages on https://www.tensorflow.org/install/install_sources are all installed.\r\n\r\n### my config\r\n\r\n`cat cat .tf_configure.bazelrc`\r\n\r\n```\r\nbuild --action_env PYTHON_BIN_PATH=\"/home/yusuke/.pyenv/shims/python\"                                                                                                                                        \r\nbuild --action_env PYTHON_LIB_PATH=\"/home/yusuke/.pyenv/versions/tf1.2/lib/python3.5/site-packages\"\r\nbuild --define PYTHON_BIN_PATH=\"/home/yusuke/.pyenv/shims/python\"\r\nbuild --define PYTHON_LIB_PATH=\"/home/yusuke/.pyenv/versions/tf1.2/lib/python3.5/site-packages\"\r\nbuild --force_python=py3\r\nbuild --host_force_python=py3\r\nbuild --python3_path=\"/home/yusuke/.pyenv/shims/python\"\r\ntest --force_python=py3\r\ntest --host_force_python=py3\r\ntest --define PYTHON_BIN_PATH=\"/home/yusuke/.pyenv/shims/python\"\r\ntest --define PYTHON_LIB_PATH=\"/home/yusuke/.pyenv/versions/tf1.2/lib/python3.5/site-packages\"\r\nrun --define PYTHON_BIN_PATH=\"/home/yusuke/.pyenv/shims/python\"\r\nrun --define PYTHON_LIB_PATH=\"/home/yusuke/.pyenv/versions/tf1.2/lib/python3.5/site-packages\"\r\nbuild --define with_jemalloc=true\r\nbuild --define with_xla_support=true\r\nbuild:opt --cxxopt=-march=native --copt=-march=native\r\nbuild --action_env TF_NEED_CUDA=\"1\"\r\nbuild --action_env TF_NEED_OPENCL=\"0\"\r\nbuild --action_env TF_CUDA_CLANG=\"0\"\r\nbuild --action_env CUDA_TOOLKIT_PATH=\"/usr/local/cuda\"\r\nbuild --action_env TF_CUDA_VERSION=\"8.0\"\r\nbuild --action_env GCC_HOST_COMPILER_PATH=\"/usr/bin/gcc\"\r\nbuild --action_env TF_CUDNN_VERSION=\"5\"\r\nbuild --action_env CUDNN_INSTALL_PATH=\"/usr/local/cuda-8.0\"\r\nbuild --action_env TF_CUDA_COMPUTE_CAPABILITIES=\"6.1\"\r\n```\r\n\r\n### fail logs\r\n\r\ncommand\r\n\r\n```\r\n$ bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures --action_env=PYENV_VERSION=tf1.2\r\n --action_env=PYENV_ROOT=\"$HOME/.pyenv\" --action_env=PATH=\"$PYENV_ROOT/bin:$PATH\" --action_env=PYENV_VIRTUAL_ENV=/home/yusuke/.pyenv/versions/3.5.2/envs/tf1.2 --action_env=VIRTUAL_ENV=/home/yusuke/.pyenv/v\r\nersions/3.5.2/envs/tf1.2 --action_env=PYENV_ROOT=/home/yusuke/.pyenv --action_env=PYENV_SHELL=bash --action_env=DYLD_LIBRARY_PATH=/usr/local/cuda/lib:/usr/local/cuda/lib --action_env=LD_LIBRARY_PATH=/usr/l\r\nocal/cuda/lib:/usr/local/cuda/lib: --action_env=PYENV_VIRTUALENV_INIT=1 -s \r\n```\r\nerror log\r\n\r\n```\r\nERROR: /home/yusuke/.cache/bazel/_bazel_yusuke/072dea721cfe39744fc124596230e888/external/farmhash_archive/BUILD.bazel:12:1: C++ compilation of rule '@farmhash_archive//:farmhash' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command \r\n  (cd /home/yusuke/.cache/bazel/_bazel_yusuke/072dea721cfe39744fc124596230e888/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/usr/local/cuda/lib:/usr/local/cuda/lib: \\\r\n    PATH=/home/yusuke/bin:/home/yusuke/.local/bin:/home/yusuke/.local/bin:/home/yusuke/.pyenv/plugins/pyenv-virtualenv/shims:/home/yusuke/.pyenv/shims:/home/yusuke/.pyenv/bin:/home/yusuke/bin:/home/yusuke/.local/bin:/home/yusuke/.local/bin:/home/yusuke/.pyenv/plugins/pyenv-virtualenv/shims:/home/yusuke/.pyenv/shims:/home/yusuke/.pyenv/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/usr/local/cuda/bin:/snap/bin:/usr/local/cuda/bin \\\r\n    PWD=/proc/self/cwd \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -g0 '-std=c++11' -g0 -MD -MF bazel-out/host/bin/external/farmhash_archive/_objs/farmhash/external/farmhash_archive/src/farmhash.d '-frandom-seed=bazel-out/host/bin/external/farmhash_archive/_objs/farmhash/external/farmhash_archive/src/farmhash.o' -iquote external/farmhash_archive -iquote bazel-out/host/genfiles/external/farmhash_archive -iquote external/bazel_tools -iquote bazel-out/host/genfiles/external/bazel_tools -isystem external/farmhash_archive/src -isystem bazel-out/host/genfiles/external/farmhash_archive/src -isystem external/bazel_tools/tools/cpp/gcc3 -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fno-canonical-system-headers -c external/farmhash_archive/src/farmhash.cc -o bazel-out/host/bin/external/farmhash_archive/_objs/farmhash/external/farmhash_archive/src/farmhash.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 2.\r\npython: can't open file 'external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc': [Errno 2] No such file or directory\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 0.345s, Critical Path: 0.07s\r\n```\r\n\r\nother command\r\n\r\n```\r\n$ bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures  -s\r\n```\r\n\r\nerror log\r\n\r\n```\r\nERROR: /home/yusuke/.cache/bazel/_bazel_yusuke/072dea721cfe39744fc124596230e888/external/protobuf/BUILD:241:1: C++ compilation of rule '@protobuf//:js_embed' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command \r\n  (cd /home/yusuke/.cache/bazel/_bazel_yusuke/072dea721cfe39744fc124596230e888/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/usr/local/cuda/lib:/usr/local/cuda/lib: \\\r\n    PATH=/home/yusuke/bin:/home/yusuke/.local/bin:/home/yusuke/.local/bin:/home/yusuke/.pyenv/plugins/pyenv-virtualenv/shims:/home/yusuke/.pyenv/shims:/home/yusuke/.pyenv/bin:/home/yusuke/bin:/home/yusuke/.local/bin:/home/yusuke/.local/bin:/home/yusuke/.pyenv/plugins/pyenv-virtualenv/shims:/home/yusuke/.pyenv/shims:/home/yusuke/.pyenv/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/usr/local/cuda/bin:/snap/bin:/usr/local/cuda/bin \\\r\n    PWD=/proc/self/cwd \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -g0 '-std=c++11' -g0 -MD -MF bazel-out/host/bin/external/protobuf/_objs/js_embed/external/protobuf/src/google/protobuf/compiler/js/embed.d '-frandom-seed=bazel-out/host/bin/external/protobuf/_objs/js_embed/external/protobuf/src/google/protobuf/compiler/js/embed.o' -iquote external/protobuf -iquote bazel-out/host/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/host/genfiles/external/bazel_tools -isystem external/bazel_tools/tools/cpp/gcc3 -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fno-canonical-system-headers -c external/protobuf/src/google/protobuf/compiler/js/embed.cc -o bazel-out/host/bin/external/protobuf/_objs/js_embed/external/protobuf/src/google/protobuf/compiler/js/embed.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 2.\r\npython: can't open file 'external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc': [Errno 2] No such file or directory\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 0.417s, Critical Path: 0.08s\r\n```\r\n", "comments": ["What version of gcc are you using?", "thanks.\r\nI use gcc 5.4.0\r\n\r\n```\r\n$ gcc --version\r\ngcc (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\r\n```", "I have no experience with pyenv. Does it work if you just use virtualenv directly?\r\nOh, also does it work if you try compiling without GPU support?\r\nAlso, can you specify exactly what non default configure options you used?\r\n\r\n@jart, do you have any ideas on this? I am kind of stumped.", "When I ommit GPU support, build successfully finished.", "I tried virtualenv only build.\r\nbuild and build_pip_package are successfully finished.\r\n\r\n```\r\nvirtualenv --python=/usr/bin/python3 build-env\r\n```\r\n\r\n```\r\ngit checkout r1.2\r\n```\r\n\r\nconfigure\r\n\r\n```\r\n$ cat ./.tf_configure.bazelrc \r\nbuild --action_env PYTHON_BIN_PATH=\"/home/yusuke/geekfield/build_tensorflow_1.2_temp/build-env/bin/python\"\r\nbuild --action_env PYTHON_LIB_PATH=\"/home/yusuke/geekfield/build_tensorflow_1.2_temp/build-env/lib/python3.5/site-packages\"\r\nbuild --define PYTHON_BIN_PATH=\"/home/yusuke/geekfield/build_tensorflow_1.2_temp/build-env/bin/python\"\r\nbuild --define PYTHON_LIB_PATH=\"/home/yusuke/geekfield/build_tensorflow_1.2_temp/build-env/lib/python3.5/site-packages\"\r\nbuild --force_python=py3\r\nbuild --host_force_python=py3\r\nbuild --python3_path=\"/home/yusuke/geekfield/build_tensorflow_1.2_temp/build-env/bin/python\"\r\ntest --force_python=py3\r\ntest --host_force_python=py3\r\ntest --define PYTHON_BIN_PATH=\"/home/yusuke/geekfield/build_tensorflow_1.2_temp/build-env/bin/python\"\r\ntest --define PYTHON_LIB_PATH=\"/home/yusuke/geekfield/build_tensorflow_1.2_temp/build-env/lib/python3.5/site-packages\"\r\nrun --define PYTHON_BIN_PATH=\"/home/yusuke/geekfield/build_tensorflow_1.2_temp/build-env/bin/python\"\r\nrun --define PYTHON_LIB_PATH=\"/home/yusuke/geekfield/build_tensorflow_1.2_temp/build-env/lib/python3.5/site-packages\"\r\nbuild --define with_jemalloc=true\r\nbuild --define with_xla_support=true\r\nbuild:opt --cxxopt=-march=native --copt=-march=native\r\nbuild --action_env TF_NEED_CUDA=\"1\"\r\nbuild --action_env TF_NEED_OPENCL=\"0\"\r\nbuild --action_env TF_CUDA_CLANG=\"0\"\r\nbuild --action_env CUDA_TOOLKIT_PATH=\"/usr/local/cuda\"\r\nbuild --action_env TF_CUDA_VERSION=\"8.0\"\r\nbuild --action_env GCC_HOST_COMPILER_PATH=\"/usr/bin/gcc\"\r\nbuild --action_env TF_CUDNN_VERSION=\"5\"\r\nbuild --action_env CUDNN_INSTALL_PATH=\"/usr/local/cuda-8.0\"\r\nbuild --action_env TF_CUDA_COMPUTE_CAPABILITIES=\"6.1\"\r\n```\r\n\r\nbuild command\r\n\r\n```\r\nbazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package \\\r\n    --verbose_failures -s \\\r\n    --action_env=PATH=\"/home/yusuke/geekfield/build_tensorflow_1.2_temp/build-env/bin:/home/yusuke/bin:$PATH\" \\\r\n    --action_env=VIRTUAL_ENV=\"/home/yusuke/geekfield/build_tensorflow_1.2_temp/build-env\" \\\r\n    --action_env=DYLD_LIBRARY_PATH=/usr/local/cuda/lib:/usr/local/cuda/lib \\\r\n    --action_env=LD_LIBRARY_PATH=/usr/local/cuda/lib:\r\n```\r\n\r\n\r\n", "I downgraded bazel to 0.4.5.\r\nbuild, create package, install package, are all successfully finished.\r\n\r\nI try bazel 0.5.3 .. failed\r\n\r\nOther person told me 0.5.2, 0.4.4, 0.5.0 .. failed\r\nhttps://www.facebook.com/groups/178559235921208/permalink/333019250475205/", "0.5.3 release have bug, 0.5.2 is usable", "https://github.com/bazelbuild/bazel/issues/3788#issuecomment-337872701 this approach might solve the problem. \r\nI append `sudo` to `$ bazel build ...`  instead of disabling pyenv at `.bashrc`. \r\nI guess it seems system python is used internally then solve the problem. ", "I was also getting the exact same error `crosstool_wrapper_driver_is_not_gcc failed` no matter what I did, tried also an older gcc, different bazels. It's now run to completion thanks to @YusukeSuzuki comment above. Two things which fixed it were\r\n\r\n- Use Python 3.5 rather than Python 3.6\r\n- Do not use `pyenv` as I was using for the virtual environment instead follow exactly the instructions [here](https://www.tensorflow.org/install/install_linux#installing_with_virtualenv) using the `activate` command for the `virtualenv` which is contained within the tensorflow repository which you clone when building from sources. \r\n\r\nOf course the CUDA and Cudnn paths had to be right. I just think tensorflow is somehow incompatible with `pyenv` there's even a post somewhere about it. It has made a bit of a mess of my folders, having most of the project in a `pyenv` and the tensorflow dependent section in a separate `virtualenv`  folder but at least at least it installed properly and runs without any complaints _\"Tensorflow was not installed according to...\"_", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Closing due to inactivity. If it's still a problem let us know and I'll reopen.", "Yep, definitely still a problem in current `master` (doh!)\r\n\r\n    python: can't open file 'external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc': [Errno 2] No such file or directory\r\n    Target //tensorflow/tools/pip_package:build_pip_package failed to build\r\n    Use --verbose_failures to see the command lines of failed build steps.\r\n    INFO: Elapsed time: 6.132s, Critical Path: 0.47s\r\n    INFO: 2 processes: 2 local."]}, {"number": 11735, "title": "python configure fails on Windows if \"bash on Ubuntu on Windows\" installed", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n    No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 10,  with \"bash on Ubuntu on Windows\" installed\r\n- **TensorFlow installed from (source or binary)**:\r\nsource\r\n- **TensorFlow version (use command below)**:\r\nec808c9b75af5dcabcb7233b10b72cfd1366fcde\r\n- **Python version**: \r\n3.5.3\r\n- **Bazel version (if compiling from source)**:\r\n9e62187df84ae425a5d7226b6baf1bef576f0a10\r\n- **CUDA/cuDNN version**:\r\nNone\r\n- **GPU model and memory**:\r\nNone\r\n- **Exact command to reproduce**:\r\nbazel --output_base C:\\t  clean --expunge\r\nbazel --output_base C:\\t build --features generate_pdb_file --action_env=USE_DYNAMIC_CRT=1 --action_env=NO_MSVC_WRAPPER=1 --color=no --compilation_mode fastbuild --verbose_failures --experimental_ui --copt=/Z7 --linkopt=/DEBUG:FASTLINK --copt=/DNDEBUG --host_copt=/DNDEBUG //tensorflow/tools/pip_package:build_pip_package\r\n\r\n### Describe the problem\r\nBuild tensorflow on windows with bazel may fail because  \"bash on Ubuntu on Windows\" is installed\r\nIt may invoke the wrong \"bash\" for executing these commands.\r\n\r\nRelated: https://github.com/bazelbuild/bazel/issues/3445\r\n\r\n### Source code / logs\r\n```\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package\r\nERROR: C:/os/tensorflow/third_party/py/numpy/BUILD:11:1: no such package '@local_config_python//': Traceback (most recent call last):\r\n        File \"C:/os/tensorflow/third_party/py/python_configure.bzl\", line 310\r\n                _create_local_python_repository(repository_ctx)\r\n        File \"C:/os/tensorflow/third_party/py/python_configure.bzl\", line 269, in _create_local_python_repository\r\n                _check_python_bin(repository_ctx, python_bin)\r\n        File \"C:/os/tensorflow/third_party/py/python_configure.bzl\", line 225, in _check_python_bin\r\n                _python_configure_fail(\"PYTHON_BIN_PATH is not executab...\")\r\n        File \"C:/os/tensorflow/third_party/py/python_configure.bzl\", line 37, in _python_configure_fail\r\n                fail((\"%sPython Configuration Error:%...)))\r\nPython Configuration Error: PYTHON_BIN_PATH is not executable.  Is it the python binary?\r\n```", "comments": ["This is due to bazel. Please see this page in bazel website:\r\nhttps://docs.bazel.build/versions/master/windows.html\r\n\r\n```\r\nSimilarly, if you have bash on Ubuntu on Windows installed, you should make sure c:\\tools\\msys64\\usr\\bin appears in PATH before c:\\windows\\system32, because otherwise Windows' bash.exe is used before msys2's.\r\n```", "Hi @gunan ,\r\n\r\nI set that.\r\nThis is how did I set the env vars before running bazel command\r\n\r\n```\r\nset PATH=C:\\Tools\\msys64\\usr\\bin;C:\\jdk\\bin;C:\\python35;C:\\python35\\scripts;C:\\bazel;%PATH%\r\nset BAZEL_SH=C:/Tools/msys64/usr/bin/bash.exe\r\nset JAVA_HOME=C:/jdk\r\nset BAZEL_PYTHON=C:/python35/python.exe\r\nset PYTHON_BIN_PATH=C:\\python35\\python.exe\r\nset PYTHON_LIB_PATH=C:\\python35\\lib\\site-packages\r\nset BAZEL_VS=C:/Program Files (x86)/Microsoft Visual Studio/2017/Enterprise\r\n```", "@meteorcloudy could you take a look?\n\nOn Jul 25, 2017 11:57 AM, \"Changming Sun\" <notifications@github.com> wrote:\n\n> Hi @gunan <https://github.com/gunan> ,\n>\n> I set that.\n> This is how did I set the env vars before running bazel command\n>\n> set PATH=C:\\Tools\\msys64\\usr\\bin;C:\\jdk\\bin;C:\\python35;C:\\python35\\scripts;C:\\bazel;%PATH%\n> set BAZEL_SH=C:/Tools/msys64/usr/bin/bash.exe\n> set JAVA_HOME=C:/jdk\n> set BAZEL_PYTHON=C:/python35/python.exe\n> set PYTHON_BIN_PATH=C:\\python35\\python.exe\n> set PYTHON_LIB_PATH=C:\\python35\\lib\\site-packages\n> set BAZEL_VS=C:/Program Files (x86)/Microsoft Visual Studio/2017/Enterprise\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/11735#issuecomment-317674051>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AHlCOZviDdzGL-1cL1y36XiSCAWBO-lLks5sRa37gaJpZM4OiDt3>\n> .\n>\n", "@gunan No problem, I'll reply in the corresponding bazel issue.", "How about this:\r\nadd a function\r\n\r\n```\r\ndef get_shell():\r\n    if os.name == 'Windows'\r\n         return env['BAZEL_SH']\r\n    else:\r\n         return 'bash'\r\n  ```", "I think the best solution would be avoiding invoking bash explicitly. \r\nWe can write the python code in a file first instead of using `bash -c \"python - <<END <content> END\"` syntax, then we can just do `repository_ctx.execute(['python', \"./find_python_lib.py\"])`\r\nexample:\r\n```\r\ndef test_bash(repository_ctx):\r\n  \"\"\"Gets the python lib path.\"\"\"\r\n  print_lib = (\r\n      \"from __future__ import print_function\\n\" +\r\n      \"import site\\n\" +\r\n      \"import os\\n\" +\r\n      \"\\n\" +\r\n      \"try:\\n\" +\r\n      \"  input = raw_input\\n\" +\r\n      \"except NameError:\\n\" +\r\n      \"  pass\\n\" +\r\n      \"\\n\" +\r\n      \"python_paths = []\\n\" +\r\n      \"if os.getenv('PYTHONPATH') is not None:\\n\" +\r\n      \"  python_paths = os.getenv('PYTHONPATH').split(':')\\n\" +\r\n      \"try:\\n\" +\r\n      \"  library_paths = site.getsitepackages()\\n\" +\r\n      \"except AttributeError:\\n\" +\r\n      \" from distutils.sysconfig import get_python_lib\\n\" +\r\n      \" library_paths = [get_python_lib()]\\n\" +\r\n      \"all_paths = set(python_paths + library_paths)\\n\" +\r\n      \"paths = []\\n\" +\r\n      \"for path in all_paths:\\n\" +\r\n      \"  if os.path.isdir(path):\\n\" +\r\n      \"    paths.append(path)\\n\" +\r\n      \"if len(paths) >=1:\\n\" +\r\n      \"  print(paths[0])\\n\")\r\n  repository_ctx.file(\"find_python_lib.py\", print_lib)\r\n  result = repository_ctx.execute(['python', \"./find_python_lib.py\"], quiet=False)\r\n  print(\"STDOUT: \" + result.stdout)\r\n  print(\"STDERR: \" + result.stderr)\r\n  if result.return_code == 1:\r\n    print('error')\r\n  print('end')\r\n  \r\npython_configure = repository_rule(\r\n    implementation = test_bash,\r\n    environ = [\"PATH\"]\r\n)\r\n\r\n\r\n```", "Hi @meteorcloudy , Do you have any future plans of this? Could you please also fix https://github.com/bazelbuild/bazel/issues/2675 , which breaks http://ci.tensorflow.org/job/tf-master-win-bzl/ for a long time.", "Hi @snnn\r\nI'll send a patch to fix this problem in python_configure.bzl using the solution I mentioned above.\r\n\r\nAs for bazelbuild/bazel#2675, we really want to fix it, but it's not reproducible at all, so we haven't had any clue to proceed.. And which failure exactly do you think is caused by it?", "Hi @meteorcloudy \r\nhttp://ci.tensorflow.org/job/tf-master-win-bzl/1425/console\r\n14:54:19 external/protobuf_archive/python/google/protobuf/internal/api_implementation.cc(31): fatal error C1083: Cannot open include file: 'Python.h': No such file or directory\r\n\r\nhttp://ci.tensorflow.org/job/tf-master-win-bzl/1422/console\r\n18:50:31 c:\\tmp\\_bazel_system\\424zmya1\\execroot\\org_tensorflow\\bazel-out\\msvc_x64-py3-opt\\genfiles\\external\\local_config_python\\numpy_include\\numpy\\npy_common.h(5): fatal error C1083: Cannot open include file: 'numpyconfig.h': No such file or directory\r\n\r\nhttp://ci.tensorflow.org/job/tf-master-win-bzl/1421/console\r\n17:18:10 bazel-out/msvc_x64-py3-opt/genfiles/external/local_config_python/python_include\\Python.h(70): fatal error C1083: Cannot open include file: 'typeslots.h': No such file or directory\r\n\r\nThey failed because the _read_dir function in third_party/py/python_configure.bzl returned an incomplete file list.  Currently I've no idea why it happens so often in CI systems, but , it's not reproducible on my local computer!\r\n\r\n", "@snnn , I see, thanks for pointing it out.", "Any updates here?\r\nWere we able to come to a resolution?", "There are actually two problems mentioned here.\r\n\r\n1. As the title says `python configure fails when \"bash on Ubuntu on Windows\" installed`. For this, I had a solution but forgot to implement it, sorry about that, will fix it soon.\r\n\r\n2. `C1083: Cannot open include file: 'Python.h': No such file or directory`\r\nThis is a flaky error happens a lot on tf-master-win-bzl, fortunately [the root cause](https://github.com/bazelbuild/bazel/issues/2675) has been identified and fixed, will be rollout in Bazel 0.8.0.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "We are now upgraded to bazel 0.8, which should fix the 2nd issue.\r\n@meteorcloudy any updates on (1)?", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @meteorcloudy: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @meteorcloudy: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @meteorcloudy: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @meteorcloudy: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @meteorcloudy: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @meteorcloudy: It has been 141 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Just checking again. Any updates?", "So sorry for the long delay here, sent a fix for this."]}, {"number": 11734, "title": "modrelu activation function", "body": "modrelu is widely used in complex domain. \r\nIt has been proved to be useful in several models:\r\nhttps://arxiv.org/abs/1511.06464, https://arxiv.org/abs/1612.05231\r\n\r\nThe implementation calculate the magnitude and phases of complex numbers then apply biased relu on the magnitude.", "comments": ["Can one of the admins verify this patch?", "Overall this looks fine, and since you're the author of the papers listed I presume you are implementing it to your spec, but can you take some time to look at https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md#contribution-guidelines-and-standards to make sure this PR matches the style of all other TensorFlow python code?  There's a lot that would likely fail our sanity check linter.\r\n\r\nYou will also want to expose the symbol in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/nn/__init__.py so it will be available as tf.contrib.nn.modrelu.", "Hi,\r\n\r\nI have updated the code according to the style document. It's also exposed in the __init__.\r\n", "@tensorflow-jenkins test this please", "@tensorflow-jenkins test this please", "@jingli9111 please resolve test errors.", "yeah the problem appears to be:\r\n\r\n```\r\nImportError: No module named 'tensorflow.contrib.nn.python.ops.mod_relu'\r\n```\r\n\r\nso that needs to be fixed.\r\n\r\nonce you rebase / fix the test, can you confirm by running a few tests locally and let us know if it's passing?  Thanks!", "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/nn/BUILD You also need to add the files and the test declaration to the BUILD file like the other operations.", "Thanks! I will fix it soon!", "@jingli9111 any news?", "@jingli9111 feel free to also pull rebase and push again. Thanks!", "@jingli9111 ping", "I will close this PR for inactivity. I can reopen after you fix the conflicts and the BUILD, or you can make a new PR."]}, {"number": 11733, "title": "update WORKSPACE uncommented line range to L19-L36", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "it's very helpful to me", "CLAs look good, thanks!\n\n<!-- ok -->", "it's very helpful to me", "it's very helpful to me"]}, {"number": 11732, "title": "Cherry-pick GradientsDebugger from master to r1.3, with fixes to GPU build issues", "body": "", "comments": ["@av8ramit has a separate channel to request for cherrypicks, you may want to contact him instead.", "@tensorflow-jenkins test this please"]}, {"number": 11731, "title": "Fix wrong template type name in QuantizedAddUsingEigen", "body": "input type is T1 and smaller input type is T2", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "Can one of the admins verify this patch?", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "@tensorflow-jenkins test this please\r\n\r\n(in practice, T1 and T2 were the same type, but this matches expectation)."]}, {"number": 11730, "title": "Using XLA JIT Compilation results in bad_alloc error", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: v1.0.1-0-ge895d5c-dirty 1.0.1\r\n- **Python version**: Python 3.5.2\r\n- **Bazel version (if compiling from source)**: Build label: 0.4.5- (@non-git)\r\n- **CUDA/cuDNN version**: 8.0/5.1\r\n- **GPU model and memory**: NVIDIA TX2\r\n- **Exact command to reproduce**: `python3 script.py`\r\n```\r\n# Config to turn on XLA JIT compilation\r\nconfig = tf.ConfigProto()\r\nconfig.graph_options.optimizer_options.global_jit_level = \\\r\n    tf.OptimizerOptions.ON_1\r\nwith tf.Session(config=config) as sess:\r\n```\r\n\r\n### Describe the problem\r\nBug in XLA JIT compilation. Script works as expected without assigning config with JIT optimizer option. \r\n\r\n### Source code / logs\r\nChanging the following code: \r\n```\r\nwith tf.Session() as sess:\r\n```\r\nTo:\r\n```\r\n# Config to turn on XLA JIT compilation\r\nconfig = tf.ConfigProto()\r\nconfig.graph_options.optimizer_options.global_jit_level = \\\r\n    tf.OptimizerOptions.ON_1\r\nwith tf.Session(config=config) as sess:\r\n```\r\nResults in the following error at runtime: \r\n```\r\nnvidia@tegra-ubuntu:~/dev$ python3 script.py\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:873] ARM has no NUMA node, hardcoding to return zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: GP10B\r\nmajor: 6 minor: 2 memoryClockRate (GHz) 1.3005\r\npciBusID 0000:00:00.0\r\nTotal memory: 7.67GiB\r\nFree memory: 4.32GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GP10B, pci bus id: 0000:00:00.0)\r\nE tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 4.03G (4323303424 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\nI tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices\r\nI tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 6 visible devices\r\nI tensorflow/compiler/xla/service/service.cc:180] XLA service executing computations on platform Host. Devices:\r\nI tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (0): <undefined>, <undefined>\r\nI tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices\r\nI tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 6 visible devices\r\nI tensorflow/compiler/xla/service/service.cc:180] XLA service executing computations on platform CUDA. Devices:\r\nI tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (0): GP10B, Compute Capability 6.2\r\nterminate called after throwing an instance of 'std::bad_alloc'\r\n  what():  std::bad_alloc\r\nAborted (core dumped)\r\n```", "comments": ["Can you try different values for `per_process_gpu_memory_fraction` in the following code and try to reproduce your code? \r\nThe following code will allocate GPU memory with  ` Total available GPU memory * per_process_gpu_memory_fraction`\r\n```\r\ngpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.2)\r\nsess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\r\n```", "@printdhruv, doing so results in no CUDA OOM errors, but the process still mysteriously quits. \r\n```\r\n# explicitly limit per_process_gpu_memory_fraction\r\ngpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.3)\r\n# config to turn on XLA JIT compilation\r\nconfig = tf.ConfigProto(gpu_options=gpu_options)\r\nconfig.graph_options.optimizer_options.global_jit_level = \\\r\n    tf.OptimizerOptions.ON_1\r\n```\r\nSee the error log below: \r\n``` tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:873] ARM has no NUMA node, hardcoding to return zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: GP10B\r\nmajor: 6 minor: 2 memoryClockRate (GHz) 1.3005\r\npciBusID 0000:00:00.0\r\nTotal memory: 7.67GiB\r\nFree memory: 4.04GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GP10B, pci bus id: 0000:00:00.0)\r\nI tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices\r\nI tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 6 visible devices\r\nI tensorflow/compiler/xla/service/service.cc:180] XLA service executing computations on platform Host. Devices:\r\nI tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (0): <undefined>, <undefined>\r\nI tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices\r\nI tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 6 visible devices\r\nI tensorflow/compiler/xla/service/service.cc:180] XLA service executing computations on platform CUDA. Devices:\r\nI tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (0): GP10B, Compute Capability 6.2\r\nKilled\r\n```", "@tatatodd, any ideas?", "This issue is automatically closed due to lack of activity. Please re-open if this is still an issue for you. Thanks!"]}, {"number": 11729, "title": "Branch 163011166", "body": "", "comments": []}, {"number": 11728, "title": "Bump the required protobuf version for the pip package", "body": "Forgot to do this as part of https://github.com/tensorflow/tensorflow/pull/10660\r\n\r\nRelated: b/62969990", "comments": ["XLA failure looks like infra failure, I suspect the other passing tests are a good signal this is working."]}]