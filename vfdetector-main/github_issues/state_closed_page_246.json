[{"number": 47123, "title": "Do not use TF mirror for the AMbiq SDK.", "body": "", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 47122, "title": "Memory leak loading keras model in loop", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):2.2\r\n- Python version:3.7\r\n\r\n**Problem Statement**\r\nRunning the following code:\r\n```\r\nimport tensorflow as tf\r\ndef process_start():\r\n  model = tf.keras.models.load_model(r\"/large/model/file\")\r\nwhile True:\r\n  process_start()\r\n```\r\nCrashes my VM after some time due to OOM. Takes about 40m with a 4gb VM.\r\n![image](https://user-images.githubusercontent.com/57200935/107836994-45c6b000-6d5c-11eb-96f3-54b4278e815b.png)\r\n\r\nI also get these messages:\r\n```\r\nTwo checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7f24557770d0> and <tensorflow.python.keras.layers.core.Dropout object at 0x7f2455771750>).\r\nWARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\r\n```\r\n\r\n**Describe the expected behavior**\r\nShould be able to run this in loops as needed.\r\n\r\n**More info**\r\nI saw from https://github.com/tensorflow/tensorflow/issues/24695 that _Keras Layers are numbered globally within the Python process_. My guess is that every time the model is loaded it's assigning some variables that don't get properly cleaned up.\r\n\r\nI believe this is a bug. Is there a suggested workaround or advice here?\r\n", "comments": ["@danzafar \r\nPlease share all dependencies for us to replicate the issue faced, I ran the code shared and face [this error](https://colab.research.google.com/gist/Saduf2019/159e5dc4670056f801c2ff2dac7b0181/untitled533.ipynb).", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47122\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47122\">No</a>\n"]}, {"number": 47121, "title": "[XLA:GPU] Allow to pass an llvm file to use", "body": "The first commit is in the same spirit as: https://github.com/tensorflow/tensorflow/pull/30759\r\nThis is for development. It allows to test some llvm changes before implementing the changes in the XLA codegen.", "comments": ["Propagating names looks separate from the \"llvm file\" stuff, could those be split?", "Done. I removed one commit from this PR and created https://github.com/tensorflow/tensorflow/pull/47164", "Technically \"llvm file\" is not a thing, could we specify what is it ? (LLVM IR before/after optimizations?)", "I changed the option name to `xla_gpu_llvm_ir_file` and updated its description to help clarify what it does.", "Could you squash into a single commit with a longer description on how to use this feature ? Same goes for the flag description: so far I can't figure out how to use it from the description alone.", "Done. Hopefully, this will clarify how to use this. If not, tell me what you understand and I'll try to clarify what is missing.", "Some questions about the design:\r\n\r\n1) IIRC XLA generates a separate .ll file per each kernel. How does your flag work with multiple kernels?\r\n2) Do you think .ll is a right boundary to inject custom binaries? Would it make more sense to provide custom PTX files instead? (or the cubins returned by ptxas?)\r\n3) Does it make sense as a generic XLA flag? Would seem like an option to `run_hlo_module` would be more appropriate?", "> Some questions about the design:\r\n> \r\n> 1. IIRC XLA generates a separate .ll file per each kernel. How does your flag work with multiple kernels?\r\n\r\nXLA generates one .ll per module. My changes request that we pass back a full .ll per module as my instruction describe.\r\n\r\n> 2. Do you think .ll is a right boundary to inject custom binaries? Would it make more sense to provide custom PTX files instead? (or the cubins returned by ptxas?)\r\n\r\nFor my current use cases, yes. I already upstreamed the switch for PTX files some times ago. \r\n\r\nMy current use cases is a kernel that is much slower then expected. There was multiple issues with it. Being able to prototype potential XLA codegen output without changing XLA itself help speed up finding the needed changes.\r\n\r\nThe PTX version of this flag helped confirm one of the issues, but it didn't tell me what changes in XLA codegen output is needed. \r\n\r\nSaid otherwise, for vectorization, we must align XLA codegen output to what LLVM optimization is able to vectorize. Being able to break the steps help implement the new optimized code faster then not being able to break this into 2 steps.\r\n\r\nI'll follow up with another PR that optimize the kernel (and similar kernel) after internal review and CI runs.\r\n\r\n> 3. Does it make sense as a generic XLA flag? Would seem like an option to `run_hlo_module` would be more appropriate?\r\n\r\nThis is debatable, but the PTX version of this flag is already a generic one. Also I use mostly replay_computation, so I would need to implement it into 2 executor. This isn't nice.\r\nUPDATE: Also, reimplementing this debug feature doesn't looks like a good use of my time. This does the works we need and we are sure to cover all needs.", "Generates this error:\r\n\r\n```\r\n/tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:23:10: error: module //tensorflow/compiler/xla/service/gpu:nvptx_compiler_impl does not depend on a module exporting 'third_party/llvm/llvm-project/llvm/include/llvm/IRReader/IRReader.h'\r\nsee http://go/cpp-features#layering_check; to fix run:\r\nbuild_cleaner //third_party/tensorflow/compiler/xla/service/gpu:nvptx_compiler_impl\r\n```\r\n", "Where is the tool build_cleaner?\r\nI'll to use it, but having access to it would be useful.", "Sorry that seems to be internal. I can run it on your behalf, or could you find which dependency you need to insert from other targets? Note that with `--config=cuda` dependency checking is not done, so I think you might be able to reproduce on your side by running without `--config=cuda`.", "I wasn't able to repro the error without --config=cuda.\r\nI tested a fix. If it isn't enough, can you run the tool?", "The CPU CI failure doesn't look related to my changes:\r\n\r\nhttps://source.cloud.google.com/results/invocations/530f84aa-d02d-4adb-b1f0-c2c1e319d417/targets;collapsed=/%2F%2Ftensorflow%2Fpython%2Fkeras%2Fintegration_test:forwardprop_test/tests;group=__main__.ForwardpropTest;test=testEmbeddingLayerInFunction;row=1"]}, {"number": 47120, "title": "Flex Delegate bazel build for C api", "body": "Hi, A bit unsure as to what category this would fall under so Iv chosen miscellaneous.\r\nThere is no documentation regarding the usage of flex delegates for the C api\r\nI have tried the command \r\n\r\nbazel build --config=android_arm64 --config=monolithic --cxxopt=--std=c++11 --define=with_select_tf_ops=true -c opt //tensorflow/lite/c:libtensorflowlite_c.so //tensorflow/lite/delegates/flex:delegate\r\n\r\nhowever it fails, i can provide the logs if required.\r\n\r\nWhat are the ways to go about building a libtensorflowlite_c.so file that support flex delegates for android?\r\nThank you\r\n", "comments": ["@henry8th \r\nCan you please refer to this [link](https://www.tensorflow.org/lite/guide/ops_select) and let us know.", "Hi thanks for getting back to me It includes details for all supported\nlanguages bar C,\nThe c++ option doesn't work for me.\nI have opted to use other languages as opposed to forcing it with C\nMany thanks\n\nOn Tue, 16 Feb 2021, 08:10 Saduf2019, <notifications@github.com> wrote:\n\n> @henry8th <https://github.com/henry8th>\n> Can you please refer to this link\n> <https://www.tensorflow.org/lite/guide/ops_select> and let us know.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/47120#issuecomment-779662393>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AP52P6YWJNJUX4WUAJH4V6LS7IR7TANCNFSM4XRGBCAA>\n> .\n>\n", "@thaink don't we have a way to build flex via C api ? (at least via selective build?)", "@terryheo @henry8th The //tensorflow/lite/delegates/flex:delegate rule is not intended to build standalone .so file for flex delegate. \r\nCan you try adding following line to //tensorflow/lite/delegates/flex/BUILD:\r\n```\r\nload(\"//tensorflow/lite:build_def.bzl\", \"tflite_cc_shared_object\")\r\n\r\ntflite_cc_shared_object(\r\n    name = \"tensorflowlite-select-tf-ops\",\r\n    features = [\"windows_export_all_symbols\"],\r\n    linkopts = select({\r\n        \"//tensorflow:macos\": [\r\n            \"-Wl,-exported_symbols_list,$(location //tensorflow/lite:tflite_exported_symbols.lds)\",\r\n        ],\r\n        \"//tensorflow:windows\": [],\r\n        \"//conditions:default\": [\r\n            \"-Wl,-z,defs\",\r\n            \"-Wl,--version-script,$(location //tensorflow/lite:tflite_version_script.lds)\",\r\n        ],\r\n    }),\r\n    per_os_targets = True,\r\n    deps = [\r\n        \":delegate\",\r\n        \"//tensorflow/lite:tflite_exported_symbols.lds\",\r\n        \"//tensorflow/lite:tflite_version_script.lds\",\r\n    ],\r\n)\r\n\r\n```\r\nThe build it with --nocheck_visibility and try it.\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47120\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47120\">No</a>\n"]}, {"number": 47119, "title": "installation issue in intel core2 cpu ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): linux ubuntu 20.0.4\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source \r\n- TensorFlow version:version 2.5.0\r\n- Python version:3.7.9\r\n- Installed using virtualenv? pip? conda? usig pip\r\n- Bazel version (if compiling from source):Bazel version 3 .7.2\r\n- GCC/Compiler version (if compiling from source):gcc version 9.3.0\r\n- CUDA/cuDNN version:NA\r\n- GPU model and memory:NA\r\n\r\n\r\n\r\n**Describe the problem**\r\nwhile installing tensorflow  2. 5.0 using source  in my old cpu (intel core 2 duo) i am getting error as :- attributeError: module 'tensorflow' has no attribute '__version__'  \r\n\r\nhow to solve this error ?\r\n\r\n\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n/python3.7 \r\n/import tensorflow as tf\r\n/print(tf.__version__)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nAttributeError: module 'tensorflow' has no attribute '__version__'\r\n\r\n\r\n\r\n\r\n**Any other info / logs**\r\n![error](https://user-images.githubusercontent.com/77532074/107810626-023b6880-6d93-11eb-887b-ead8f971e787.jpg)\r\n\r\nto diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@mortalx2,\r\nCould you please share the following details with us, so that we can look into the issue\r\n\r\n- output of `pip list` command\r\n- output of `conda list` command\r\n- the make and model of the CPU on your machine\r\n\r\nThanks!", "(base) mortal-x2@mortalx2-desktop:~$ pip list\r\nPackage                            Version\r\n---------------------------------- -----------------\r\nabsl-py                            0.10.0\r\naiofiles                           0.6.0\r\naiohttp                            3.6.3\r\nalabaster                          0.7.12\r\nanaconda-client                    1.7.2\r\nanaconda-navigator                 1.10.0\r\nanaconda-project                   0.8.3\r\nappdirs                            1.4.4\r\nAPScheduler                        3.6.3\r\nargh                               0.26.2\r\nargon2-cffi                        20.1.0\r\nasn1crypto                         1.4.0\r\nastroid                            2.4.2\r\nastropy                            4.0.2\r\nastunparse                         1.6.3\r\nasync-generator                    1.10\r\nasync-timeout                      3.0.1\r\natomicwrites                       1.4.0\r\nattrs                              20.2.0\r\nautopep8                           1.5.4\r\nBabel                              2.8.1\r\nbackcall                           0.2.0\r\nbackports.functools-lru-cache      1.6.1\r\nbackports.shutil-get-terminal-size 1.0.0\r\nbackports.tempfile                 1.0\r\nbackports.weakref                  1.0.post1\r\nbeautifulsoup4                     4.9.3\r\nbitarray                           1.6.1\r\nbkcharts                           0.2\r\nbleach                             3.2.1\r\nbokeh                              2.2.3\r\nboto                               2.49.0\r\nBottleneck                         1.3.2\r\nbrotlipy                           0.7.0\r\ncachetools                         4.2.0\r\ncertifi                            2020.6.20\r\ncffi                               1.14.3\r\nchardet                            3.0.4\r\nclick                              7.1.2\r\ncloudpickle                        1.4.1\r\nclyent                             1.2.2\r\ncolorama                           0.4.4\r\nconda                              4.9.2\r\nconda-build                        3.20.5\r\nconda-package-handling             1.7.2\r\nconda-verify                       3.4.2\r\ncontextlib2                        0.6.0.post1\r\ncryptography                       3.1.1\r\ncycler                             0.10.0\r\nCython                             0.29.21\r\ncytoolz                            0.11.0\r\ndask                               2.30.0\r\ndecorator                          4.4.2\r\ndefusedxml                         0.6.0\r\ndiff-match-patch                   20200713\r\ndistlib                            0.3.1\r\ndistributed                        2.30.1\r\ndm-tree                            0.1.5\r\ndocopt                             0.6.2\r\ndocutils                           0.16\r\nentrypoints                        0.3\r\net-xmlfile                         1.0.1\r\nfastcache                          1.1.0\r\nfbmessenger                        6.0.0\r\nfilelock                           3.0.12\r\nflake8                             3.8.4\r\nFlask                              1.1.2\r\nflatbuffers                        1.12\r\nfsspec                             0.8.3\r\nfuture                             0.18.2\r\ngast                               0.4.0\r\ngevent                             20.9.0\r\nglob2                              0.7\r\ngmpy2                              2.0.8\r\ngoogle-auth                        1.24.0\r\ngoogle-auth-oauthlib               0.4.2\r\ngoogle-pasta                       0.2.0\r\ngreenlet                           0.4.17\r\ngrpcio                             1.34.1\r\nh11                                0.9.0\r\nh5py                               3.1.0\r\nHeapDict                           1.0.1\r\nhtml5lib                           1.1\r\nhttpcore                           0.11.1\r\nhttptools                          0.1.1\r\nhttpx                              0.15.4\r\nidna                               2.10\r\nimageio                            2.9.0\r\nimagesize                          1.2.0\r\nimportlib-metadata                 2.0.0\r\niniconfig                          1.1.1\r\nintervaltree                       3.1.0\r\nipykernel                          5.3.4\r\nipython                            7.19.0\r\nipython-genutils                   0.2.0\r\nipywidgets                         7.5.1\r\nisort                              5.6.4\r\nitsdangerous                       1.1.0\r\njdcal                              1.4.1\r\njedi                               0.17.1\r\njeepney                            0.5.0\r\nJinja2                             2.11.2\r\njoblib                             0.17.0\r\njson5                              0.9.5\r\njsonschema                         3.2.0\r\njupyter                            1.0.0\r\njupyter-client                     6.1.7\r\njupyter-console                    6.2.0\r\njupyter-core                       4.6.3\r\njupyterlab                         2.2.6\r\njupyterlab-pygments                0.1.2\r\njupyterlab-server                  1.2.0\r\nkafka-python                       2.0.2\r\nKeras-Applications                 1.0.8\r\nKeras-Preprocessing                1.1.2\r\nkeyring                            21.4.0\r\nkiwisolver                         1.3.0\r\nlazy-object-proxy                  1.4.3\r\nlibarchive-c                       2.9\r\nllvmlite                           0.34.0\r\nlocket                             0.2.0\r\nlxml                               4.6.1\r\nMarkdown                           3.3.3\r\nMarkupSafe                         1.1.1\r\nmatplotlib                         3.3.2\r\nmccabe                             0.6.1\r\nmistune                            0.8.4\r\nmkl-fft                            1.2.0\r\nmkl-random                         1.1.1\r\nmkl-service                        2.3.0\r\nmock                               4.0.3\r\nmore-itertools                     8.6.0\r\nmpmath                             1.1.0\r\nmsgpack                            1.0.0\r\nmultidict                          4.7.6\r\nmultipledispatch                   0.6.0\r\nnavigator-updater                  0.2.1\r\nnbclient                           0.5.1\r\nnbconvert                          6.0.7\r\nnbformat                           5.0.8\r\nnest-asyncio                       1.4.2\r\nnetworkx                           2.5\r\nnltk                               3.5\r\nnose                               1.3.7\r\nnotebook                           6.1.4\r\nnumba                              0.51.2\r\nnumexpr                            2.7.1\r\nnumpy                              1.19.5\r\nnumpydoc                           1.1.0\r\noauthlib                           3.1.0\r\nolefile                            0.46\r\nopenpyxl                           3.0.5\r\nopt-einsum                         3.3.0\r\npackaging                          20.4\r\npandas                             1.1.3\r\npandocfilters                      1.4.3\r\nparso                              0.7.0\r\npartd                              1.1.0\r\npath                               15.0.0\r\npathlib2                           2.3.5\r\npathtools                          0.1.2\r\npatsy                              0.5.1\r\npep8                               1.7.1\r\npexpect                            4.8.0\r\npickleshare                        0.7.5\r\nPillow                             8.0.1\r\npip                                21.0.1\r\npkginfo                            1.6.1\r\npluggy                             0.13.1\r\nply                                3.11\r\nprometheus-client                  0.8.0\r\nprompt-toolkit                     3.0.8\r\nprotobuf                           3.14.0\r\npsutil                             5.7.2\r\npsycopg2-binary                    2.8.6\r\nptyprocess                         0.6.0\r\npy                                 1.9.0\r\npyasn1                             0.4.8\r\npyasn1-modules                     0.2.8\r\npycodestyle                        2.6.0\r\npycosat                            0.6.3\r\npycparser                          2.20\r\npycurl                             7.43.0.6\r\npydocstyle                         5.1.1\r\npyflakes                           2.2.0\r\nPygments                           2.7.2\r\nPyJWT                              1.7.1\r\npykwalify                          1.7.0\r\npylint                             2.6.0\r\npyodbc                             4.0.0-unsupported\r\npyOpenSSL                          19.1.0\r\npyparsing                          2.4.7\r\npyrsistent                         0.17.3\r\nPySocks                            1.7.1\r\npytest                             0.0.0\r\npython-crfsuite                    0.9.7\r\npython-dateutil                    2.8.1\r\npython-engineio                    3.13.2\r\npython-jsonrpc-server              0.4.0\r\npython-language-server             0.35.1\r\npython-socketio                    4.6.1\r\npython-telegram-bot                12.8\r\npytz                               2020.1\r\nPyWavelets                         1.1.1\r\npyxdg                              0.27\r\nPyYAML                             5.3.1\r\npyzmq                              19.0.2\r\nQDarkStyle                         2.8.1\r\nQtAwesome                          1.0.1\r\nqtconsole                          4.7.7\r\nQtPy                               1.9.0\r\nregex                              2020.9.27\r\nrequests                           2.24.0\r\nrequests-oauthlib                  1.3.0\r\nrequests-toolbelt                  0.9.1\r\nrfc3986                            1.4.0\r\nrocketchat-API                     1.9.1\r\nrope                               0.18.0\r\nrsa                                4.7\r\nRtree                              0.9.4\r\nruamel-yaml                        0.15.87\r\nruamel.yaml.clib                   0.2.2\r\nsanic                              20.12.1\r\nSanic-Cors                         0.10.0.post3\r\nSanic-Plugins-Framework            0.9.5\r\nscikit-image                       0.17.2\r\nscikit-learn                       0.23.2\r\nscipy                              1.5.2\r\nseaborn                            0.11.0\r\nSecretStorage                      3.1.2\r\nSend2Trash                         1.5.0\r\nsentry-sdk                         0.19.5\r\nsetuptools                         53.0.0\r\nsimplegeneric                      0.8.1\r\nsingledispatch                     3.4.0.3\r\nsip                                4.19.13\r\nsix                                1.15.0\r\nsklearn-crfsuite                   0.3.6\r\nslackclient                        2.9.3\r\nsniffio                            1.2.0\r\nsnowballstemmer                    2.0.0\r\nsortedcollections                  1.2.1\r\nsortedcontainers                   2.2.2\r\nsoupsieve                          2.0.1\r\nSphinx                             3.2.1\r\nsphinxcontrib-applehelp            1.0.2\r\nsphinxcontrib-devhelp              1.0.2\r\nsphinxcontrib-htmlhelp             1.0.3\r\nsphinxcontrib-jsmath               1.0.1\r\nsphinxcontrib-qthelp               1.0.3\r\nsphinxcontrib-serializinghtml      1.1.4\r\nsphinxcontrib-websupport           1.2.4\r\nspyder                             4.1.5\r\nspyder-kernels                     1.9.4\r\nSQLAlchemy                         1.3.20\r\nstatsmodels                        0.12.0\r\nsympy                              1.6.2\r\ntables                             3.6.1\r\ntabulate                           0.8.7\r\ntblib                              1.7.0\r\ntensorboard                        2.4.1\r\ntensorboard-plugin-wit             1.8.0\r\ntensorflow                         2.5.0\r\ntensorflow-estimator               2.4.0\r\ntensorflow-probability             0.11.1\r\ntermcolor                          1.1.0\r\nterminado                          0.9.1\r\nterminaltables                     3.1.0\r\ntestpath                           0.4.4\r\nthreadpoolctl                      2.1.0\r\ntifffile                           2020.10.1\r\ntoml                               0.10.1\r\ntoolz                              0.11.1\r\ntornado                            6.0.4\r\ntqdm                               4.50.2\r\ntraitlets                          5.0.5\r\ntwilio                             6.45.4\r\ntyping-extensions                  3.7.4.3\r\ntzlocal                            2.1\r\nujson                              3.2.0\r\nunicodecsv                         0.14.1\r\nurllib3                            1.25.11\r\nuvloop                             0.14.0\r\nvirtualenv                         20.4.0\r\nwatchdog                           0.10.3\r\nwcwidth                            0.2.5\r\nwebencodings                       0.5.1\r\nwebexteamssdk                      1.6\r\nwebsockets                         8.1\r\nWerkzeug                           1.0.1\r\nwheel                              0.36.2\r\nwidgetsnbextension                 3.5.1\r\nwrapt                              1.12.1\r\nwurlitzer                          2.0.1\r\nxlrd                               1.2.0\r\nXlsxWriter                         1.3.7\r\nxlwt                               1.3.0\r\nxmltodict                          0.12.0\r\nyapf                               0.30.0\r\nyarl                               1.6.3\r\nzict                               2.0.0\r\nzipp                               3.4.0\r\nzope.event                         4.5.0\r\nzope.interface                     5.1.2\r\n", "(base) mortal-x2@mortalx2-desktop:~$ conda list\r\n# packages in environment at /home/mortal-x2/anaconda3:\r\n#\r\n# Name                    Version                   Build  Channel\r\n_ipyw_jlab_nb_ext_conf    0.1.0                    py38_0  \r\n_libgcc_mutex             0.1                        main  \r\nabsl-py                   0.10.0                   pypi_0    pypi\r\naiofiles                  0.6.0                    pypi_0    pypi\r\naiohttp                   3.6.3                    pypi_0    pypi\r\nalabaster                 0.7.12                     py_0  \r\nanaconda                  2020.11                  py38_0  \r\nanaconda-client           1.7.2                    py38_0  \r\nanaconda-navigator        1.10.0                   py38_0  \r\nanaconda-project          0.8.4                      py_0  \r\napscheduler               3.6.3                    pypi_0    pypi\r\nargh                      0.26.2                   py38_0  \r\nargon2-cffi               20.1.0           py38h7b6447c_1  \r\nasn1crypto                1.4.0                      py_0  \r\nastroid                   2.4.2                    py38_0  \r\nastropy                   4.0.2            py38h7b6447c_0  \r\nastunparse                1.6.3                    pypi_0    pypi\r\nasync-timeout             3.0.1                    pypi_0    pypi\r\nasync_generator           1.10                       py_0  \r\natomicwrites              1.4.0                      py_0  \r\nattrs                     20.2.0                   pypi_0    pypi\r\nautopep8                  1.5.4                      py_0  \r\nbabel                     2.8.1              pyhd3eb1b0_0  \r\nbackcall                  0.2.0                      py_0  \r\nbackports                 1.0                        py_2  \r\nbackports.functools_lru_cache 1.6.1                      py_0  \r\nbackports.shutil_get_terminal_size 1.0.0                    py38_2  \r\nbackports.tempfile        1.0                        py_1  \r\nbackports.weakref         1.0.post1                  py_1  \r\nbeautifulsoup4            4.9.3              pyhb0f4dca_0  \r\nbitarray                  1.6.1            py38h27cfd23_0  \r\nbkcharts                  0.2                      py38_0  \r\nblas                      1.0                         mkl  \r\nbleach                    3.2.1                      py_0  \r\nblosc                     1.20.1               hd408876_0  \r\nbokeh                     2.2.3                    py38_0  \r\nboto                      2.49.0                   py38_0  \r\nbottleneck                1.3.2            py38heb32a55_1  \r\nbrotlipy                  0.7.0           py38h7b6447c_1000  \r\nbzip2                     1.0.8                h7b6447c_0  \r\nca-certificates           2020.10.14                    0  \r\ncachetools                4.2.0                    pypi_0    pypi\r\ncairo                     1.14.12              h8948797_3  \r\ncertifi                   2020.6.20          pyhd3eb1b0_3  \r\ncffi                      1.14.3           py38he30daa8_0  \r\nchardet                   3.0.4                 py38_1003  \r\nclick                     7.1.2                      py_0  \r\ncloudpickle               1.4.1                    pypi_0    pypi\r\nclyent                    1.2.2                    py38_1  \r\ncolorama                  0.4.4                      py_0  \r\nconda                     4.9.2            py38h06a4308_0  \r\nconda-build               3.20.5                   py38_1  \r\nconda-env                 2.6.0                         1  \r\nconda-package-handling    1.7.2            py38h03888b9_0  \r\nconda-verify              3.4.2                      py_1  \r\ncontextlib2               0.6.0.post1                py_0  \r\ncryptography              3.1.1            py38h1ba5d50_0  \r\ncurl                      7.71.1               hbc83047_1  \r\ncycler                    0.10.0                   py38_0  \r\ncython                    0.29.21          py38he6710b0_0  \r\ncytoolz                   0.11.0           py38h7b6447c_0  \r\ndask                      2.30.0                     py_0  \r\ndask-core                 2.30.0                     py_0  \r\ndbus                      1.13.18              hb2f20db_0  \r\ndecorator                 4.4.2                      py_0  \r\ndefusedxml                0.6.0                      py_0  \r\ndiff-match-patch          20200713                   py_0  \r\ndistributed               2.30.1           py38h06a4308_0  \r\ndm-tree                   0.1.5                    pypi_0    pypi\r\ndocopt                    0.6.2                    pypi_0    pypi\r\ndocutils                  0.16                     py38_1  \r\nentrypoints               0.3                      py38_0  \r\net_xmlfile                1.0.1                   py_1001  \r\nexpat                     2.2.10               he6710b0_2  \r\nfastcache                 1.1.0            py38h7b6447c_0  \r\nfbmessenger               6.0.0                    pypi_0    pypi\r\nfilelock                  3.0.12                     py_0  \r\nflake8                    3.8.4                      py_0  \r\nflask                     1.1.2                      py_0  \r\nflatbuffers               1.12                     pypi_0    pypi\r\nfontconfig                2.13.0               h9420a91_0  \r\nfreetype                  2.10.4               h5ab3b9f_0  \r\nfribidi                   1.0.10               h7b6447c_0  \r\nfsspec                    0.8.3                      py_0  \r\nfuture                    0.18.2                   py38_1  \r\ngast                      0.4.0                    pypi_0    pypi\r\nget_terminal_size         1.0.0                haa9412d_0  \r\ngevent                    20.9.0           py38h7b6447c_0  \r\nglib                      2.66.1               h92f7085_0  \r\nglob2                     0.7                        py_0  \r\ngmp                       6.1.2                h6c8ec71_1  \r\ngmpy2                     2.0.8            py38hd5f6e3b_3  \r\ngoogle-auth               1.24.0                   pypi_0    pypi\r\ngoogle-auth-oauthlib      0.4.2                    pypi_0    pypi\r\ngoogle-pasta              0.2.0                    pypi_0    pypi\r\ngraphite2                 1.3.14               h23475e2_0  \r\ngreenlet                  0.4.17           py38h7b6447c_0  \r\ngrpcio                    1.34.1                   pypi_0    pypi\r\ngst-plugins-base          1.14.0               hbbd80ab_1  \r\ngstreamer                 1.14.0               hb31296c_0  \r\nh11                       0.9.0                    pypi_0    pypi\r\nh5py                      3.1.0                    pypi_0    pypi\r\nharfbuzz                  2.4.0                hca77d97_1  \r\nhdf5                      1.10.4               hb1b8bf9_0  \r\nheapdict                  1.0.1                      py_0  \r\nhtml5lib                  1.1                        py_0  \r\nhttpcore                  0.11.1                   pypi_0    pypi\r\nhttptools                 0.1.1                    pypi_0    pypi\r\nhttpx                     0.15.4                   pypi_0    pypi\r\nicu                       58.2                 he6710b0_3  \r\nidna                      2.10                       py_0  \r\nimageio                   2.9.0                      py_0  \r\nimagesize                 1.2.0                      py_0  \r\nimportlib-metadata        2.0.0                      py_1  \r\nimportlib_metadata        2.0.0                         1  \r\niniconfig                 1.1.1                      py_0  \r\nintel-openmp              2020.2                      254  \r\nintervaltree              3.1.0                      py_0  \r\nipykernel                 5.3.4            py38h5ca1d4c_0  \r\nipython                   7.19.0           py38hb070fc8_0  \r\nipython_genutils          0.2.0                    py38_0  \r\nipywidgets                7.5.1                      py_1  \r\nisort                     5.6.4                      py_0  \r\nitsdangerous              1.1.0                      py_0  \r\njbig                      2.1                  hdba287a_0  \r\njdcal                     1.4.1                      py_0  \r\njedi                      0.17.1                   py38_0  \r\njeepney                   0.5.0              pyhd3eb1b0_0  \r\njinja2                    2.11.2                     py_0  \r\njoblib                    0.17.0                     py_0  \r\njpeg                      9b                   h024ee3a_2  \r\njson5                     0.9.5                      py_0  \r\njsonschema                3.2.0                      py_2  \r\njupyter                   1.0.0                    py38_7  \r\njupyter_client            6.1.7                      py_0  \r\njupyter_console           6.2.0                      py_0  \r\njupyter_core              4.6.3                    py38_0  \r\njupyterlab                2.2.6                      py_0  \r\njupyterlab_pygments       0.1.2                      py_0  \r\njupyterlab_server         1.2.0                      py_0  \r\nkafka-python              2.0.2                    pypi_0    pypi\r\nkeras-preprocessing       1.1.2                    pypi_0    pypi\r\nkeyring                   21.4.0                   py38_1  \r\nkiwisolver                1.3.0            py38h2531618_0  \r\nkrb5                      1.18.2               h173b8e3_0  \r\nlazy-object-proxy         1.4.3            py38h7b6447c_0  \r\nlcms2                     2.11                 h396b838_0  \r\nld_impl_linux-64          2.33.1               h53a641e_7  \r\nlibarchive                3.4.2                h62408e4_0  \r\nlibcurl                   7.71.1               h20c2e04_1  \r\nlibedit                   3.1.20191231         h14c3975_1  \r\nlibffi                    3.3                  he6710b0_2  \r\nlibgcc-ng                 9.1.0                hdf63c60_0  \r\nlibgfortran-ng            7.3.0                hdf63c60_0  \r\nliblief                   0.10.1               he6710b0_0  \r\nlibllvm10                 10.0.1               hbcb73fb_5  \r\nlibpng                    1.6.37               hbc83047_0  \r\nlibsodium                 1.0.18               h7b6447c_0  \r\nlibspatialindex           1.9.3                he6710b0_0  \r\nlibssh2                   1.9.0                h1ba5d50_1  \r\nlibstdcxx-ng              9.1.0                hdf63c60_0  \r\nlibtiff                   4.1.0                h2733197_1  \r\nlibtool                   2.4.6             h7b6447c_1005  \r\nlibuuid                   1.0.3                h1bed415_2  \r\nlibxcb                    1.14                 h7b6447c_0  \r\nlibxml2                   2.9.10               hb55368b_3  \r\nlibxslt                   1.1.34               hc22bd24_0  \r\nllvmlite                  0.34.0           py38h269e1b5_4  \r\nlocket                    0.2.0                    py38_1  \r\nlxml                      4.6.1            py38hefd8a0e_0  \r\nlz4-c                     1.9.2                heb0550a_3  \r\nlzo                       2.10                 h7b6447c_2  \r\nmarkdown                  3.3.3                    pypi_0    pypi\r\nmarkupsafe                1.1.1            py38h7b6447c_0  \r\nmatplotlib                3.3.2                         0  \r\nmatplotlib-base           3.3.2            py38h817c723_0  \r\nmccabe                    0.6.1                    py38_1  \r\nmistune                   0.8.4           py38h7b6447c_1000  \r\nmkl                       2020.2                      256  \r\nmkl-service               2.3.0            py38he904b0f_0  \r\nmkl_fft                   1.2.0            py38h23d657b_0  \r\nmkl_random                1.1.1            py38h0573a6f_0  \r\nmock                      4.0.2                      py_0  \r\nmore-itertools            8.6.0              pyhd3eb1b0_0  \r\nmpc                       1.1.0                h10f8cd9_1  \r\nmpfr                      4.0.2                hb69a4c5_1  \r\nmpmath                    1.1.0                    py38_0  \r\nmsgpack-python            1.0.0            py38hfd86e86_1  \r\nmultidict                 4.7.6                    pypi_0    pypi\r\nmultipledispatch          0.6.0                    py38_0  \r\nnavigator-updater         0.2.1                    py38_0  \r\nnbclient                  0.5.1                      py_0  \r\nnbconvert                 6.0.7                    py38_0  \r\nnbformat                  5.0.8                      py_0  \r\nncurses                   6.2                  he6710b0_1  \r\nnest-asyncio              1.4.2              pyhd3eb1b0_0  \r\nnetworkx                  2.5                        py_0  \r\nnltk                      3.5                        py_0  \r\nnose                      1.3.7                    py38_2  \r\nnotebook                  6.1.4                    py38_0  \r\nnumba                     0.51.2           py38h0573a6f_1  \r\nnumexpr                   2.7.1            py38h423224d_0  \r\nnumpy                     1.19.5                   pypi_0    pypi\r\nnumpy-base                1.19.2           py38hfa32c7d_0  \r\nnumpydoc                  1.1.0              pyhd3eb1b0_1  \r\noauthlib                  3.1.0                    pypi_0    pypi\r\nolefile                   0.46                       py_0  \r\nopenpyxl                  3.0.5                      py_0  \r\nopenssl                   1.1.1h               h7b6447c_0  \r\nopt-einsum                3.3.0                    pypi_0    pypi\r\npackaging                 20.4                       py_0  \r\npandas                    1.1.3            py38he6710b0_0  \r\npandoc                    2.11                 hb0f4dca_0  \r\npandocfilters             1.4.3            py38h06a4308_1  \r\npango                     1.45.3               hd140c19_0  \r\nparso                     0.7.0                      py_0  \r\npartd                     1.1.0                      py_0  \r\npatchelf                  0.12                 he6710b0_0  \r\npath                      15.0.0                   py38_0  \r\npath.py                   12.5.0                        0  \r\npathlib2                  2.3.5                    py38_0  \r\npathtools                 0.1.2                      py_1  \r\npatsy                     0.5.1                    py38_0  \r\npcre                      8.44                 he6710b0_0  \r\npep8                      1.7.1                    py38_0  \r\npexpect                   4.8.0                    py38_0  \r\npickleshare               0.7.5                 py38_1000  \r\npillow                    8.0.1            py38he98fc37_0  \r\npip                       20.2.4           py38h06a4308_0  \r\npixman                    0.40.0               h7b6447c_0  \r\npkginfo                   1.6.1            py38h06a4308_0  \r\npluggy                    0.13.1                   py38_0  \r\nply                       3.11                     py38_0  \r\nprometheus_client         0.8.0                      py_0  \r\nprompt-toolkit            3.0.8                      py_0  \r\nprompt_toolkit            3.0.8                         0  \r\nprotobuf                  3.14.0                   pypi_0    pypi\r\npsutil                    5.7.2            py38h7b6447c_0  \r\npsycopg2-binary           2.8.6                    pypi_0    pypi\r\nptyprocess                0.6.0                    py38_0  \r\npy                        1.9.0                      py_0  \r\npy-lief                   0.10.1           py38h403a769_0  \r\npyasn1                    0.4.8                    pypi_0    pypi\r\npyasn1-modules            0.2.8                    pypi_0    pypi\r\npycodestyle               2.6.0                      py_0  \r\npycosat                   0.6.3            py38h7b6447c_1  \r\npycparser                 2.20                       py_2  \r\npycurl                    7.43.0.6         py38h1ba5d50_0  \r\npydocstyle                5.1.1                      py_0  \r\npyflakes                  2.2.0                      py_0  \r\npygments                  2.7.2              pyhd3eb1b0_0  \r\npyjwt                     1.7.1                    pypi_0    pypi\r\npykwalify                 1.7.0                    pypi_0    pypi\r\npylint                    2.6.0                    py38_0  \r\npyodbc                    4.0.30           py38he6710b0_0  \r\npyopenssl                 19.1.0                     py_1  \r\npyparsing                 2.4.7                      py_0  \r\npyqt                      5.9.2            py38h05f1152_4  \r\npyrsistent                0.17.3           py38h7b6447c_0  \r\npysocks                   1.7.1                    py38_0  \r\npytables                  3.6.1            py38h9fd0a39_0  \r\npytest                    6.1.1                    py38_0  \r\npython                    3.8.5                h7579374_1  \r\npython-crfsuite           0.9.7                    pypi_0    pypi\r\npython-dateutil           2.8.1                      py_0  \r\npython-engineio           3.13.2                   pypi_0    pypi\r\npython-jsonrpc-server     0.4.0                      py_0  \r\npython-language-server    0.35.1                     py_0  \r\npython-libarchive-c       2.9                        py_0  \r\npython-socketio           4.6.1                    pypi_0    pypi\r\npython-telegram-bot       12.8                     pypi_0    pypi\r\npytz                      2020.1                     py_0  \r\npywavelets                1.1.1            py38h7b6447c_2  \r\npyxdg                     0.27               pyhd3eb1b0_0  \r\npyyaml                    5.3.1            py38h7b6447c_1  \r\npyzmq                     19.0.2           py38he6710b0_1  \r\nqdarkstyle                2.8.1                      py_0  \r\nqt                        5.9.7                h5867ecd_1  \r\nqtawesome                 1.0.1                      py_0  \r\nqtconsole                 4.7.7                      py_0  \r\nqtpy                      1.9.0                      py_0  \r\nreadline                  8.0                  h7b6447c_0  \r\nregex                     2020.9.27                pypi_0    pypi\r\nrequests                  2.24.0                     py_0  \r\nrequests-oauthlib         1.3.0                    pypi_0    pypi\r\nrequests-toolbelt         0.9.1                    pypi_0    pypi\r\nrfc3986                   1.4.0                    pypi_0    pypi\r\nripgrep                   12.1.1                        0  \r\nrocketchat-api            1.9.1                    pypi_0    pypi\r\nrope                      0.18.0                     py_0  \r\nrsa                       4.7                      pypi_0    pypi\r\nrtree                     0.9.4                    py38_1  \r\nruamel-yaml-clib          0.2.2                    pypi_0    pypi\r\nruamel_yaml               0.15.87          py38h7b6447c_1  \r\nsanic                     20.12.1                  pypi_0    pypi\r\nsanic-cors                0.10.0.post3             pypi_0    pypi\r\nsanic-plugins-framework   0.9.5                    pypi_0    pypi\r\nscikit-image              0.17.2           py38hdf5156a_0  \r\nscikit-learn              0.23.2           py38h0573a6f_0  \r\nscipy                     1.5.2            py38h0b6359f_0  \r\nseaborn                   0.11.0                     py_0  \r\nsecretstorage             3.1.2                    py38_0  \r\nsend2trash                1.5.0                    py38_0  \r\nsentry-sdk                0.19.5                   pypi_0    pypi\r\nsetuptools                50.3.1           py38h06a4308_1  \r\nsimplegeneric             0.8.1                    py38_2  \r\nsingledispatch            3.4.0.3                 py_1001  \r\nsip                       4.19.13          py38he6710b0_0  \r\nsix                       1.15.0           py38h06a4308_0  \r\nsklearn-crfsuite          0.3.6                    pypi_0    pypi\r\nslackclient               2.9.3                    pypi_0    pypi\r\nsniffio                   1.2.0                    pypi_0    pypi\r\nsnowballstemmer           2.0.0                      py_0  \r\nsortedcollections         1.2.1                      py_0  \r\nsortedcontainers          2.2.2                      py_0  \r\nsoupsieve                 2.0.1                      py_0  \r\nsphinx                    3.2.1                      py_0  \r\nsphinxcontrib             1.0                      py38_1  \r\nsphinxcontrib-applehelp   1.0.2                      py_0  \r\nsphinxcontrib-devhelp     1.0.2                      py_0  \r\nsphinxcontrib-htmlhelp    1.0.3                      py_0  \r\nsphinxcontrib-jsmath      1.0.1                      py_0  \r\nsphinxcontrib-qthelp      1.0.3                      py_0  \r\nsphinxcontrib-serializinghtml 1.1.4                      py_0  \r\nsphinxcontrib-websupport  1.2.4                      py_0  \r\nspyder                    4.1.5                    py38_0  \r\nspyder-kernels            1.9.4                    py38_0  \r\nsqlalchemy                1.3.20           py38h7b6447c_0  \r\nsqlite                    3.33.0               h62c20be_0  \r\nstatsmodels               0.12.0           py38h7b6447c_0  \r\nsympy                     1.6.2            py38h06a4308_1  \r\ntabulate                  0.8.7                    pypi_0    pypi\r\ntbb                       2020.3               hfd86e86_0  \r\ntblib                     1.7.0                      py_0  \r\ntensorboard               2.4.1                    pypi_0    pypi\r\ntensorboard-plugin-wit    1.8.0                    pypi_0    pypi\r\ntensorflow                2.5.0                    pypi_0    pypi\r\ntensorflow-estimator      2.4.0                    pypi_0    pypi\r\ntensorflow-probability    0.11.1                   pypi_0    pypi\r\ntermcolor                 1.1.0                    pypi_0    pypi\r\nterminado                 0.9.1                    py38_0  \r\nterminaltables            3.1.0                    pypi_0    pypi\r\ntestpath                  0.4.4                      py_0  \r\nthreadpoolctl             2.1.0              pyh5ca1d4c_0  \r\ntifffile                  2020.10.1        py38hdd07704_2  \r\ntk                        8.6.10               hbc83047_0  \r\ntoml                      0.10.1                     py_0  \r\ntoolz                     0.11.1                     py_0  \r\ntornado                   6.0.4            py38h7b6447c_1  \r\ntqdm                      4.50.2                     py_0  \r\ntraitlets                 5.0.5                      py_0  \r\ntwilio                    6.45.4                   pypi_0    pypi\r\ntyping_extensions         3.7.4.3                    py_0  \r\ntzlocal                   2.1                      pypi_0    pypi\r\nujson                     3.2.0                    pypi_0    pypi\r\nunicodecsv                0.14.1                   py38_0  \r\nunixodbc                  2.3.9                h7b6447c_0  \r\nurllib3                   1.25.11                    py_0  \r\nuvloop                    0.14.0                   pypi_0    pypi\r\nwatchdog                  0.10.3                   py38_0  \r\nwcwidth                   0.2.5                      py_0  \r\nwebencodings              0.5.1                    py38_1  \r\nwebexteamssdk             1.6                      pypi_0    pypi\r\nwebsockets                8.1                      pypi_0    pypi\r\nwerkzeug                  1.0.1                      py_0  \r\nwheel                     0.35.1                     py_0  \r\nwidgetsnbextension        3.5.1                    py38_0  \r\nwrapt                     1.12.1                   pypi_0    pypi\r\nwurlitzer                 2.0.1                    py38_0  \r\nxlrd                      1.2.0                      py_0  \r\nxlsxwriter                1.3.7                      py_0  \r\nxlwt                      1.3.0                    py38_0  \r\nxmltodict                 0.12.0                     py_0  \r\nxz                        5.2.5                h7b6447c_0  \r\nyaml                      0.2.5                h7b6447c_0  \r\nyapf                      0.30.0                     py_0  \r\nyarl                      1.6.3                    pypi_0    pypi\r\nzeromq                    4.3.3                he6710b0_3  \r\nzict                      2.0.0                      py_0  \r\nzipp                      3.4.0              pyhd3eb1b0_0  \r\nzlib                      1.2.11               h7b6447c_3  \r\nzope                      1.0                      py38_1  \r\nzope.event                4.5.0                    py38_0  \r\nzope.interface            5.1.2            py38h7b6447c_0  \r\nzstd                      1.4.5                h9ceee32_0  \r\n", "model no of the cpu is core 2 duo ", "@mortalx2,\r\nCould you please try installing TensorFlow in a new virtual environment and check if you are facing the same issue? Thanks! ", "kk let me try", "same issue is coming ", "@mortalx2,\r\nCould you please run the `cat /proc/cpuinfo` command in the terminal and share the output with us? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47119\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47119\">No</a>\n"]}, {"number": 47118, "title": "[tf.data] Switch to TF combinations instead of test_util", "body": "This PR switches the tests present in `tensorflow/python/data/util/` to use TF combinations instead of the `test_util` decorator to express the combination of graph/eager modes with TF1/TF2 environments for execution.\r\n\r\nAddresses point 1 in https://github.com/tensorflow/tensorflow/pull/46761#issuecomment-770059963\r\ncc: @jsimsa\r\n\r\nTEST RUNS (UPDATED):\r\n```\r\nINFO: Build completed successfully, 304 total actions\r\n//tensorflow/python/data/util:random_seed_test                           PASSED in 2.2s\r\n\r\nINFO: Build completed successfully, 2 total actions\r\n//tensorflow/python/data/util:sparse_test                                PASSED in 1.5s\r\n\r\nINFO: Build completed successfully, 2 total actions\r\n//tensorflow/python/data/util:convert_test                               PASSED in 1.4s\r\n\r\nINFO: Build completed successfully, 2 total actions\r\n//tensorflow/python/data/util:traverse_test                              PASSED in 1.4s\r\n\r\nINFO: Build completed successfully, 2 total actions\r\n//tensorflow/python/data/util:nest_test                                  PASSED in 1.4s\r\n\r\nINFO: Build completed successfully, 2 total actions\r\n//tensorflow/python/data/util:options_test                               PASSED in 1.3s\r\n\r\nINFO: Build completed successfully, 2 total actions\r\n//tensorflow/python/data/util:structure_test                             PASSED in 1.7s\r\n\r\n```", "comments": ["@jsimsa thanks for the info. I have refactored the tests and addressed a few sanity issues as well. Please let me know. ", "@jsimsa thanks for pointing me to the references. I have addressed the review comments. Please let me know how it looks.\r\n\r\nIn the functions which return `test combinations`, I have followed an approach in which all the parameters are `combinations.NamedObject`(s). This approach facilitated in resolving duplicate test name issues and keeps the parameterized values consistent with the arguments that the test cases need.", "@jsimsa sorry about this long PR. Will try to break up the large change items into multiple PR's next time.\r\nThanks for your patient review. Please let me know how it looks now.", "@jsimsa renamed the method. Thanks for the review."]}, {"number": 47117, "title": "ImportError: numpy.core._multiarray_umath failed to import ImportError: numpy.core.umath failed to import 2021-02-12 11:32:51.847320: F tensorflow/python/lib/core/bfloat16.cc:714] Check failed: PyBfloat16_Type.tp_base != nullptr  Aborted (core dumped)", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:NA\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version (use command below):2.4.0\r\n- Python version:3.8.5\r\n- Bazel version (if compiling from source):4.0.0\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:11.2/8.1.0\r\n- GPU model and memory:GTX1660 Ti\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nTensorflow not loading after installation.\r\n**Describe the expected behavior**\r\n`import tensorflow as tf`\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n`import tensorflow as tf\r\n2021-02-12 11:48:37.037515: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\nRuntimeError: module compiled against API version 0xe but this version of numpy is 0xd\r\nRuntimeError: module compiled against API version 0xe but this version of numpy is 0xd\r\nImportError: numpy.core._multiarray_umath failed to import\r\nImportError: numpy.core.umath failed to import\r\n2021-02-12 11:48:37.272212: F tensorflow/python/lib/core/bfloat16.cc:714] Check failed: PyBfloat16_Type.tp_base != nullptr \r\nAborted (core dumped)`\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n\r\n`pip freeze\r\nabsl-py==0.11.0\r\nanyio==2.1.0\r\nargon2-cffi==20.1.0\r\nastunparse==1.6.3\r\nasync-generator==1.10\r\nattrs==20.3.0\r\nBabel==2.9.0\r\nbackcall==0.2.0\r\nbleach==3.3.0\r\ncachetools==4.2.1\r\ncertifi==2020.12.5\r\ncffi==1.14.5\r\nchardet==4.0.0\r\ncloudpickle==1.6.0\r\ncycler==0.10.0\r\ndecorator==4.4.2\r\ndefusedxml==0.6.0\r\ndm-tree==0.1.5\r\nentrypoints==0.3\r\nflatbuffers==1.12\r\ngast==0.3.3\r\ngoogle-auth==1.26.1\r\ngoogle-auth-oauthlib==0.4.2\r\ngoogle-pasta==0.2.0\r\ngrpcio==1.32.0\r\nh5py==2.10.0\r\nidna==2.10\r\nipykernel==5.4.3\r\nipython==7.20.0\r\nipython-genutils==0.2.0\r\nipywidgets==7.6.3\r\njedi==0.18.0\r\nJinja2==2.11.3\r\njoblib==1.0.1\r\njson5==0.9.5\r\njsonschema==3.2.0\r\njupyter==1.0.0\r\njupyter-client==6.1.11\r\njupyter-console==6.2.0\r\njupyter-core==4.7.1\r\njupyter-server==1.3.0\r\njupyterlab==3.0.7\r\njupyterlab-pygments==0.1.2\r\njupyterlab-server==2.2.0\r\njupyterlab-widgets==1.0.0\r\nKeras-Preprocessing==1.1.2\r\nkiwisolver==1.3.1\r\nMarkdown==3.3.3\r\nMarkupSafe==1.1.1\r\nmatplotlib==3.3.4\r\nmistune==0.8.4\r\nnbclassic==0.2.6\r\nnbclient==0.5.2\r\nnbconvert==6.0.7\r\nnbformat==5.1.2\r\nnest-asyncio==1.5.1\r\nnotebook==6.2.0\r\nnumpy==1.19.5\r\noauthlib==3.1.0\r\nopt-einsum==3.3.0\r\npackaging==20.9\r\npandas==1.2.2\r\npandocfilters==1.4.3\r\nparso==0.8.1\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow==8.1.0\r\nprometheus-client==0.9.0\r\nprompt-toolkit==3.0.16\r\nprotobuf==3.14.0\r\nptyprocess==0.7.0\r\npyasn1==0.4.8\r\npyasn1-modules==0.2.8\r\npycparser==2.20\r\nPygments==2.7.4\r\npyparsing==2.4.7\r\npyrsistent==0.17.3\r\npython-dateutil==2.8.1\r\npytz==2021.1\r\npyzmq==22.0.3\r\nqtconsole==5.0.2\r\nQtPy==1.9.0\r\nrequests==2.25.1\r\nrequests-oauthlib==1.3.0\r\nrsa==4.7\r\nscikit-learn==0.24.1\r\nscipy==1.6.0\r\nSend2Trash==1.5.0\r\nsix==1.15.0\r\nsklearn==0.0\r\nsniffio==1.2.0\r\ntensorboard==2.4.1\r\ntensorboard-plugin-wit==1.8.0\r\ntensorflow==2.4.0\r\ntensorflow-estimator==2.4.0\r\ntensorflow-probability==0.12.1\r\ntermcolor==1.1.0\r\nterminado==0.9.2\r\ntestpath==0.4.4\r\nthreadpoolctl==2.1.0\r\ntornado==6.1\r\ntraitlets==5.0.5\r\ntyping-extensions==3.7.4.3\r\nurllib3==1.26.3\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nWerkzeug==1.0.1\r\nwidgetsnbextension==3.5.1\r\nwrapt==1.12.1`", "comments": ["@MedAbdelkaderAbba \r\nCould you please try :\r\n```pip install numpy --upgrade```\r\n\r\nand let us know, if the error persist please share indented stand alone code or a colab gist with the error reported.\r\nYpu may also refer to similar issues: [link](https://www.programmersought.com/article/6151650908/), [link1](https://www.programmersought.com/article/15483960097/), [link2](https://github.com/eldar/pose-tensorflow/issues/68).", "`pip install numpy --upgrade`\r\n`Collecting numpy`\r\n `Using cached numpy-1.20.1-cp38-cp38-manylinux2010_x86_64.whl (15.4 MB)`\r\n`ERROR: tensorflow 2.4.0 has requirement numpy~=1.19.2, but you'll have numpy 1.20.1 which is incompatible.`\r\n`Installing collected packages: numpy`\r\n  `Attempting uninstall: numpy`\r\n`    Found existing installation: numpy 1.19.5`\r\n`    Uninstalling numpy-1.19.5:`\r\n`      Successfully uninstalled numpy-1.19.5`\r\n`Successfully installed numpy-1.20.1`\r\n\r\napart from the pip ERROR warning tensorflow seems to work fime.\r\nThanks!", "@MedAbdelkaderAbba \r\nThank you for your response, please move the issue to close status.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47117\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47117\">No</a>\n"]}, {"number": 47115, "title": "tf.keras.experimental.CosineDecay() get wrong step after tf.keras.Model.load_weight()", "body": "**System information**\r\n-- NVIDIA RTX 2080ti 11G x2 ( with NVLink )\r\n-- Ubuntu 20.04 LTS\r\n-- Python 3.8.5 ( gcc / g++ 9.3.0 )\r\n-- CUDA Toolkit 11.1, cuDNN 8.0.4, TensorRT 7.2.2, NCCL 2.8.3\r\n-- tensorflow 2.4.1 ( build form release )\r\n\r\n**Describe the current behavior**\r\nKeras Model load weights saved with `tf.keras.callback.ModelCheckpoint()` makes `tf.keras.experimental.CosineDecay()` get wrong step in `Model.fit()`.\r\nUsually, this make `CosineDecay.__call__(step)` return 0 because step>decay_steps.\r\n**Describe the expected behavior**\r\nThe step should compute by inital_batch when call Model.fit(), but not the step in ckpt.", "comments": ["I find that `tf.keras.Optimizer` has attribute `iterations`, which saves in ckpt and compute the `step`when call `CosineDecay.__call__(step)`.\r\nIt's works right when I call `model.optimizer.iterations.assign(0)` after 'Model.load_weights()' and 'Model.compile()'.", "@HLSS-Hen,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the dataset you are using. Thanks!", "First run:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow_datasets as tfds\r\n\r\nEPOCHS = 120\r\nINITIAL_EPOCH = 0\r\nTRAIN_BATCH_SIZE = 256\r\n\r\ndef _parser(record):\r\n    image = record['image']\r\n    label = record['label']\r\n    image = tf.image.resize(image, (224, 224), tf.image.ResizeMethod.BICUBIC)\r\n    image = image / 255.\r\n    return image, label\r\n\r\nds = tfds.load('cifar10', split=['train'])[0]\r\nds = ds.map(lambda x: _parser(x),num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(TRAIN_BATCH_SIZE)\r\n\r\nmodel = tf.keras.applications.EfficientNetB0(classes=10,weights=None)\r\nmodel.compile(tf.keras.optimizers.SGD(tf.keras.experimental.CosineDecay(.1, 50000//TRAIN_BATCH_SIZE*EPOCHS), .9),\r\n              tf.keras.losses.SparseCategoricalCrossentropy(),\r\n              [tf.keras.metrics.SparseTopKCategoricalAccuracy(1, name='top1')])\r\n\r\nmodel.fit(ds_train,\r\n          epochs=EPOCHS,\r\n          initial_epoch=INITIAL_EPOCH,\r\n          callbacks=[tf.keras.callbacks.TensorBoard('logs', histogram_freq=1, profile_batch=0),\r\n                     tf.keras.callbacks.ModelCheckpoint('logs/ckpt', 'val_top1', 0, True, True, 'max')])\r\n```\r\n\r\nThen change(load weights):\r\n\r\n```\r\n\r\nmodel.compile(tf.keras.optimizers.SGD(tf.keras.experimental.CosineDecay(.1, 50000//TRAIN_BATCH_SIZE*EPOCHS), .9),\r\n              tf.keras.losses.SparseCategoricalCrossentropy(),\r\n              [tf.keras.metrics.SparseTopKCategoricalAccuracy(1, name='top1')])\r\nmodel.load_weights('logs/ckpt')  // <= Load weights\r\nmodel.fit(ds_train,\r\n          epochs=EPOCHS,\r\n          initial_epoch=INITIAL_EPOCH,\r\n          callbacks=[tf.keras.callbacks.TensorBoard('logs', histogram_freq=1, profile_batch=0),\r\n                     tf.keras.callbacks.ModelCheckpoint('logs/ckpt', 'val_top1', 0, True, True, 'max')])\r\n```\r\n\r\nLR get from CosineDecay is 0, becauese Optimizer have a param of run steps, which is also save in ckpt.\r\nWe need to use `model.optimizer.iterations.assign(0)` between `Model.load_weights()` and `Model.Fit()`\r\n@amahendrakar ", "@HLSS-Hen,\r\nOn running the given code snippet I am facing an error stating `NameError: name 'ds_train' is not defined`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/7a30f5975b5f971e79dd4c41a73dc6ea/47115.ipynb).\r\n\r\nCould you please provide the complete code snippet, so that we can reproduce the issue on our end. Alternatively, you can also run the code on [Google Colab](https://colab.research.google.com/) and share the notebook with us. Thanks!", "@amahendrakar [here](https://colab.research.google.com/drive/1sFaEse3NxATiyI9hTVNxYX1PNPD23ueU?usp=sharing)", "@HLSS-Hen,\r\nOn running the code, I am facing an error stating `NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for logs/0/ckpt`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/6fadd34d835958cdc4b62794a15c76c6/47115.ipynb#scrollTo=3PjN7uxli9Rs).\r\n\r\nCould you please confirm if this is the same error you are facing. Thanks!", "@amahendrakar this just my input error, [here](https://colab.research.google.com/drive/1sFaEse3NxATiyI9hTVNxYX1PNPD23ueU?usp=sharing). \r\nI have said before:\r\n> I find that `tf.keras.Optimizer` has attribute `iterations`. which saves in ckpt, compute the `step`when call `CosineDecay.__call__(step)`.\r\n> It's works right when I call `model.optimizer.iterations.assign(0)` after 'Model.load_weights()' and 'Model.compile()'.", "@amahendrakar \r\nWe're also facing the same issue. Is there any update on this? ", "@ymodak,\r\nColab notebook crashes on running the code with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/c87343c44e0c5459c887fdf78d663838/47115.ipynb). Thanks!", "Colab crashes on TF 2.6 Nightly due to OOM error.Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/68779064d7fae015281478dd4ed900a8/47115.ipynb).Thanks!", "@HLSS-Hen Sometimes, people wants to not only save the model parameters but also the optimizer's state, the 'iteration' you are referring to is one of the important optimizer's state that some people wants to recover. Other important optimizer's states include momentums, etc..\r\n\r\nIf you do not want to keep any optimizer's state, you can use model.save_weights and load_weights with HDF5 format. Then you need to compile the model again.\r\n\r\nOr\r\n\r\nyou can compile the model again with new optimizer instance after load_weights, i.e. model.compile(loss=loss,optimizer=new_instance_optimizer)\r\n\r\nOr \r\n\r\nIf you just wants to have other optimizer's states recovered except the iteration(which may not be reasonable), your way of directly resetting the hidden iteration attribute of the optimizer is acceptable.\r\n ", "Could you please check with the stable API [tf.keras.optimizers.schedules.CosineDecay](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/CosineDecay) and let us know if the issue still persists. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47115\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47115\">No</a>\n"]}, {"number": 47114, "title": "What is the best architecture that we can converted to coreml and run on ios?", "body": "I would like to know which architecture achieve the best resaults?\r\nFor example efficientdet or mobilenetv3.\r\nAlso, the model from this architecture must be able to convert to coreml and run on iOS.", "comments": ["@rafallukasik123 \r\nCan you share more details,In general EfficientDet is used for detection and Mobilenet for classification, Can you try Tflite delegate.\r\nIf this is not a bug or feature request please open this issue on [stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow) and move this to closed status.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 47113, "title": "Extend tensorflow/examples for raspberry_pi", "body": "Is there any plan to extend the TensorFlow/examples for raspberry_pi? Those which are shown at https://www.tensorflow.org/lite/examples are not all for raspberry_pi though ...", "comments": ["Hi @peter197321!\r\nWe are checking to see whether you still need help in this issue . Have you checked this [thread ](https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/raspberry_pi)yet? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 47112, "title": "Refactor conv to share code between reference and optimized kernels", "body": "Summary:\r\n\r\nMove shared structs / helper functions into conv_common.cc\r\nClean up some of the existing code to directly call the reference implementations (made possible by the refactor of the helper functions).\r\n\r\nTested with:\r\nmake -j8 -f tensorflow/lite/micro/tools/make/Makefile test_kernel_conv_test\r\n\r\nmake -j8 -f tensorflow/lite/micro/tools/make/Makefile OPTIMIZED_KERNEL_DIR=cmsis_nn TARGET=stm32f4 test_kernel_conv_test\r\n\r\nmake -f tensorflow/lite/micro/tools/make/Makefile -j8 TARGET=xtensa OPTIMIZED_KERNEL_DIR=xtensa TARGET_ARCH=hifimini XTENSA_CORE=mini1m1m_RG test_kernel_conv_test", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 47111, "title": "TF Lite benchmark NOT_EQUAL node takes up a lot of time.", "body": "Hi,\r\n\r\nTensorflow used for both model and benchmark: 2.3.1\r\nPlatform: Android\r\n\r\nI've got an internal company model (therefore can't share it, sorry). \r\nI've run tflite benchmark model on it and got weird results. Namely the NOT_EQUAL op apparently takes 73 ms to run, which is big part of computation time, the problem is that it does not block running other nodes (they run between the 1st ms and 38th ms of computation) therefore I'm not sure why benchmark reports that this node runs for 73ms if it doesn't actually block other nodes. \r\n\r\nScreen of the report:\r\n![perf_not_equal](https://user-images.githubusercontent.com/32575801/107762540-780ce900-6d2d-11eb-8c08-b30c3812f4cb.png)\r\n\r\nAs you can see the cast, expand_dims etc. nodes don't start after 73ms but rather instantaneously which is confusing because when it comes to the total running time of model these 73ms are counted and added to the X ms of rest of the model, therefore it reports the whole model running time to be 73+x ms. \r\n\r\nWhen it comes to the node it only takes one of the inputs to the model as the input to the node, nothing else, therefore in theory it shouldn't wait for anything (I assume it waits for something if it starts but doesn't block computation).\r\n\r\nCould you please give me some help about what's going on here? Thanks. \r\n", "comments": ["> I've got an internal company model (therefore can't share it, sorry).\r\n\r\n@Jkeezuz,\r\nIn this case, could you please provide a dummy model and code so that we can reproduce the issue on our end.\r\n\r\nAlso, please check if you are facing the same issue with TF v2.4.1 and TF-nightly as well. Thanks!\r\n\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 47109, "title": "Make Tensorflow 2.3 available through conda on macOS", "body": "### System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): conda\r\n- Python version: 3.7.9\r\n\r\n### Describe the problem\r\n\r\n`conda install tensorflow` installs version 2.0\r\n\r\nPlease, make tensorflow 2.3 available through conda.\r\n\r\nOther platforms support 2.3, however macOS is still stuck at 2.0:\r\nhttps://anaconda.org/anaconda/tensorflow\r\n<img width=\"202\" alt=\"Screen Shot 2021-02-12 at 10 15 22\" src=\"https://user-images.githubusercontent.com/73581880/107749654-396e3300-6d1b-11eb-85be-02a0472dc40a.png\">", "comments": ["TF provides pre built pip packages whereas conda packages are community supported.\r\nI think anaconda repo can be a right platform to raise this issue since they provide TF conda packages across various platforms.\r\nhttps://github.com/ContinuumIO/anaconda-issues/issues", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47109\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47109\">No</a>\n"]}, {"number": 47108, "title": "micro: port operator FLOOR_MOD kernel from lite with test", "body": "Complete implementation of TFLM operator FLOOR_MOD and associated TFLM test code.\r\n\r\nPR step 5 of the work to port operator FLOOR_MOD as tracked in Issue #45749", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "@ddavis-2015 This PR is in draft, any update on this? Please. Thanks!\r\n", "@ddavis-2015 Can you please resolve conflicts? Thanks!\r\n"]}, {"number": 47107, "title": "ConverterError: <unknown>:0: error: loc(callsite(callsite(\"map/TensorArrayV2_1@__inference_call_func_18494\" at \"StatefulPartitionedCall@__inference_signature_wrapper_22648\") at \"StatefulPartitionedCall\")): failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal <unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from", "body": "[saved_model.zip](https://github.com/tensorflow/tensorflow/files/5970743/saved_model.zip)\r\nI am trying to convert this model to tflite. But getting above error. \r\n", "comments": ["Please help me. I have tried various things but nothing is worked.", "@karanjakhar,\r\nIn order to reproduce the issue reported here, could you please provide the TensorFlow version, the complete code to build and convert the model and the dataset you are using. \r\n\r\nAlso, please take a look at issue [#43495](https://github.com/tensorflow/tensorflow/issues/43495) with a similar error log and check if you are facing the same error. Thanks!", "@karanjakhar \r\nPlease see the suggestion here\r\nhttps://github.com/tensorflow/tensorflow/issues/43495#issuecomment-698049054\r\n\r\n\r\nAlso, please share complete snippet on how you're loading/converting the model\r\n\r\nThanks", "https://colab.research.google.com/drive/1X-ShZMLAGMLtPuEHI3YAOhWEyz-j_hyC?usp=sharing\r\n\r\nThis colab notebook has everything. Please have a look and please guide me.", "Any updates @amahendrakar @karimnosseir? Please help.", "@karanjakhar did you try fixing the shape for your model so it has 1D tensorList ? currently we only support 1D tensorlist", "Yes, I tried it. But it didn't worked. I have shared the colab notebook\nabove. Please check it, and please give it a try.\n\nOn Thu, Feb 18, 2021, 12:13 PM Karim Nosseir <notifications@github.com>\nwrote:\n\n> @karanjakhar <https://github.com/karanjakhar> did you try fixing the\n> shape for your model so it has 1D tensorList ? currently we only support 1D\n> tensorlist\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/47107#issuecomment-781097252>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AHEHETGPWUGE7YVJSESRVJLS7SZI5ANCNFSM4XQLSB3Q>\n> .\n>\n", "The colab you shared doesn't fix the shape. The input \r\n```\r\ninput_tensor: uint8 Tensor, shape=(1, None, None, 3)\r\n```", "@karanjakhar,\r\nAny updates regarding this? Is this still an issue?\r\n\r\nCould you please take a look at the above comment and let us know if you are facing the same error. Thanks!", "I have tried it but no luck. https://colab.research.google.com/drive/1X-ShZMLAGMLtPuEHI3YAOhWEyz-j_hyC?usp=sharing\r\nyou can check that in this colab.", "@karanjakhar could you try conversion with the tf-nightly version? We have resolved the conversion issues related to TensorList recently by implementing Flex fallback.", "Okay, I try that, Thanks.\n\nOn Fri, Feb 26, 2021 at 12:45 PM Jae sung Chung <notifications@github.com>\nwrote:\n\n> @karanjakhar <https://github.com/karanjakhar> could you try conversion\n> with the tf-nightly version? I have resolved the conversion issues related\n> to TensorList recently by implementing Flex fallback.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/47107#issuecomment-786460738>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AHEHETD32HMXZUQXCVCQOMTTA5C7LANCNFSM4XQLSB3Q>\n> .\n>\n", "@karanjakhar,\r\nAs mentioned by @abattery, I was able to run the code without any errors using the latest TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/c2ea23a0ac5cdf619d705f5a03961c68/copy-of-object_detection.ipynb). Thanks!", "It worked !! Thankyou so much @abattery @amahendrakar @karimnosseir ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47107\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47107\">No</a>\n", "@abattery @amahendrakar @karimnosseir I follow the gist above and converted the model `mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8` from TF2 model zoo with the following code:\r\n\r\n```\r\nmodel_dir = r'C:\\Users\\yuh5\\PycharmProjects\\Convert1\\saved_model'\r\nsaved_model_dir = 'updated/saved_model'\r\nmodel = tf.saved_model.load(model_dir)\r\nconcrete_func = model.signatures['serving_default']\r\nconcrete_func.inputs[0].set_shape([1, 1024, 1024, 3])\r\ntf.saved_model.save(model, saved_model_dir)\r\n\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir, signature_keys=['serving_default'])\r\nconverter.experimental_new_converter = True\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\n\r\ntflite_model = converter.convert()\r\n\r\nwith tf.io.gfile.GFile('model.tflite', 'wb') as f:\r\n    f.write(tflite_model)\r\n\r\n# Used for adding metadata\r\npopulator = _metadata.MetadataPopulator.with_model_file(\"model.tflite\")\r\npopulator.load_associated_files([\"labels.txt\"])\r\npopulator.populate()\r\n```\r\n\r\nThe code run though successfully, however, the input tensor of the .tflite model has the shape shown in the image below:\r\n![Capture](https://user-images.githubusercontent.com/63370208/110393112-ffe9c880-8037-11eb-8397-b75c6710026f.PNG)\r\n\r\nIs this correct? When I use this model to run inference on Android with the demo code for object detection I got the follow error:\r\n\r\n`Caused by: java.lang.IllegalArgumentException: Cannot copy to a TensorFlowLite tensor (serving_default_input_tensor:0) with 3 bytes from a Java Buffer with 12582912 bytes.`\r\n\r\nHow should I modify the code to use maskRCNN model?\r\n", "@nlm-yuh5 could you file a separate issue to make this thread simple? And could you share your converted model file as well?", "@nlm-yuh5 could you file a separate issue to make this thread simple? And could you share your converted model file as well?", "sure\r\n", "I have followed the exact steps mentioned in  issue #43495, except that i am using tensorflow 2.5 instead of tensorflow-nightly to build the classification problem\r\nThe entire set up has been done on Google Colab, I am able to do correctly identify the results. Subsequent to this i have built the model.tflite file as well\r\n\r\nBut when i do inference using Interpreter in Python on Colab, i get the error as \r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-112-7ce8b910841d> in <module>()\r\n----> 1 interpreter.set_tensor(input_index, resized_image)\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/interpreter.py in set_tensor(self, tensor_index, value)\r\n    570       ValueError: If the interpreter could not set the tensor.\r\n    571     \"\"\"\r\n--> 572     self._interpreter.SetTensor(tensor_index, value)\r\n    573 \r\n    574   def resize_tensor_input(self, input_index, tensor_size, strict=False):\r\n\r\nValueError: Cannot set tensor: Dimension mismatch. Got 250 but expected 1 for dimension 1 of input 0.", "This is where i have maintained the entire set up\r\nhttps://colab.research.google.com/drive/1dpJ05nLl-stqu8lC9P4mwoIEbBmyxFBU#scrollTo=SiPTPXIbk-8L \r\n\r\n"]}, {"number": 47106, "title": "ValueError: Data cardinality is ambiguous:   x sizes: 60000   y sizes: 10000 Please provide data which shares the same first dimension.", "body": "\r\n![Screenshot (58)](https://user-images.githubusercontent.com/60438445/107751007-d0021a80-6d42-11eb-9326-ed9af5c643e3.png)\r\n![Screenshot (59)](https://user-images.githubusercontent.com/60438445/107751014-d395a180-6d42-11eb-802f-6c3313bf0999.png)\r\n![Screenshot (60)](https://user-images.githubusercontent.com/60438445/107750981-c37dc200-6d42-11eb-80a6-b4fffe5e445d.png)\r\n", "comments": ["i am working on jupypter notebook . please let me know how can i share my entire code here", "@saikrishna14343 \r\nPlease run your code on colab gist and add the gist here. [contrl+k will let u paste the gist executed on colab]", "i do not have colab . \r\n", "@saikrishna14343\r\nPlease use [google colab](https://colab.research.google.com/notebooks/) [[link](https://www.tutorialspoint.com/google_colab/index.htm) for reference],Labels used do not match the first dimension as feature as per your screen shots.", "what is your `x_test` and `y_test`, seems like there is shape mismatching, the first dimension should be same for both ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47106\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47106\">No</a>\n"]}, {"number": 47105, "title": "Data cardinality is ambiguous:   x sizes: 60000   y sizes: 10000 Please provide data which shares the same first dimension.", "body": "complete code here  [http://localhost:8888/notebooks/Desktop/minor%20proj/Untitled-Copy1.ipynb](url) \r\n\r\nworking on mnist data set for handwriten recognition\r\n\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47105\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47105\">No</a>\n", "please someone help me out .. \r\nwaiting eagerly\r\n", "its actually the bug which i am getting \r\n", "@saikrishna14343,\r\nIn order to reproduce the issue reported here, could you please provide the TensorFlow version, the complete code and the dataset you are using. \r\n\r\nAlso, please take a look at [this comment](https://stackoverflow.com/a/62606245) from a similar StackOverflow query and check if helps.\r\n\r\nThanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47105\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47105\">No</a>\n"]}, {"number": 47104, "title": "Do not rely on ADL when invoking std::sort", "body": "This PR is similar with protobuf/#7639.\r\n\r\nAn attempt to use ADL with std::vector breaks when std::vector::iterator is a raw pointer typedef.\r\n\r\nThere is no need to use ADL here.", "comments": []}, {"number": 47103, "title": "Snapshot Op Reader::MakeNestedDataset didn't handle the empty shard case properly (divide by 0 error)", "body": "Hi @frankchn, I'm using snapshot op for distributed training with parameter server strategy in which one of the workers didn't get data and produces snapshot folder with empty shard. However, for the next run I got an exception _Reader::MakeNestedDataset()_ as the shard was empty. I think the existing code was written with the assumption that shard won't be empty  (start_index % shard_dirs.size()) and caused divide by 0 error. Could you please confirm.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/582c8d236cb079023657287c318ff26adb239002/tensorflow/core/kernels/data/experimental/snapshot_util.cc#L590", "comments": ["Hello! Can you provide more details, like what is the error you encountered, what are the parameters of the `snapshot` call, and the internal directory structure of the snapshot directory?\r\n\r\nIt would be ideal if you can provide a test-case for this.", "Error:\r\n```\r\nChild process exited with exit code 134\r\n\r\n# Problematic frame:\r\n# C  [_pywrap_tensorflow_internal.so+0x8d2d59e]  tensorflow::data::snapshot_util::Reader::MakeNestedDataset(tensorflow::Env*, std::vector<std::string, std::allocator<std::string> > const&, std::string const&, int, absl::lts_2020_02_25::InlinedVector<tensorflow::DataType, 4ul, std::allocator<tensorflow::DataType> > const&, std::vector<tensorflow::PartialTensorShape, std::allocator<tensorflow::PartialTensorShape> > const&, long long, tensorflow::data::DatasetBase**)+0x41e\r\n```\r\n\r\nsnapshot call :\r\n`dataset = dataset.apply(tf.data.experimental.snapshot(\"snapshot/path\"))`\r\n\r\nThe snapshot directory structure:\r\n```\r\n<>/hash_id\r\n       /run_id\r\n       snapshot.metadata\r\n```\r\n I observed that there was no shard folders inside run_id due to no input data for that particular worker. \r\n I won't be able to give you this distributed PS test. However, you can call the  _Reader::MakeNestedDataset()_ with empty shard data (shard_dirs.size()=0) and then you can reproduce the same error.", "@arde171 Thanks! Managed to reproduce this on our side and a fix is going through internal code review now and should be pushed out next week and included with the next release."]}, {"number": 47102, "title": "Fix the bazel build as part of the github continuous integration.", "body": "To keep the bazel build short, we maintain a copy of the subset of packages that are needed for the TFLM (+ shared TfLite) bazel targets.\r\n\r\nEigen was updated for TF with b26252b38334ab18dc7be2547c41e91e78257d60 and we make the corresponding change in TFLM's pared down version of workspace.bzl with this change.\r\n", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 47101, "title": "tf.All support as TFlite buildin op", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): PIP\r\n- TensorFlow version (or github SHA if from source): 2.4.1\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n```\r\nSome ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select\r\nTF Select ops: All, RandomUniform\r\nDetails:\r\ntf.All {device = \"\", keep_dims = false}\r\ntf.RandomUniform {device = \"\", seed = 0 : i64, seed2 = 0 : i64}\r\n```\r\n\r\n**Standalone code to reproduce the issue** \r\nI have a model in [Tensorflow.](https://github.com/TensorSpeech/TensorFlowTTS/blob/master/notebooks/TensorFlowTTS_Tacotron2_with_TFLite.ipynb)\r\nIf I use this \r\nconverter.target_spec.supported_ops = [\r\ntf.lite.OpsSet.TFLITE_BUILTINS,\r\ntf.lite.OpsSet.SELECT_TF_OPS]\r\nmodel is converted into TFLite but have Flex Delegate.\r\n\r\nFlex delegate do not worked on edge board. \r\nRequesting to please provide tf.All and tf.RandomUniform support as buildin op.\r\nPlease suggest some solution for now. I know, Custom op is one way, but how to do ?\r\nCan I expect the support for Ops soon or in tf-nightly versions?", "comments": ["TFLite supports Reduce_any. It makes sense to support Reduce_All as well.", "> TFLite supports Reduce_any. It makes sense to support Reduce_All as well.\r\n\r\nI don't get the point. Your mean, I have to replace tf.reduce_all with tf.reduce_any. Right?\r\nIn the code, there is about 20 TF op like tf.reduce_all,tf.reduce_sum,tf.tile . I have tried to replace with their equivalent numpy functions. But issue is still persist.", "@neso613 I didn't mean that. It is just a statement to support adding Reduce_All as a builtin op.", "> @neso613 I didn't mean that. It is just a statement to support adding Reduce_All as a builtin op.\r\n\r\nok. Do you know, where this tf.All() and tf.RandomUniform() used in the model. Can we replace these op with np equivalents.", "Any ETA for op support?", "ETA ", "looking forward for op support\r\n\r\n", "It is in out to-do-list.", "The op is now supported in the master branch."]}, {"number": 47100, "title": "NotFoundError:  Resource localhost/_AnonymousVar29/N10tensorflow22SummaryWriterInterfaceE does not exist.", "body": "tf 2.4.1\r\n```\r\n---------------------------------------------------------------------------\r\nNotFoundError                             Traceback (most recent call last)\r\n<ipython-input-10-92bfedd73a83> in <module>\r\n      2 tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, update_freq='batch')\r\n      3 \r\n----> 4 model.fit(x, y, initial_epoch=20, epochs=25, callbacks=[tensorboard_callback])\r\n\r\n~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n   1098                 _r=1):\r\n   1099               callbacks.on_train_batch_begin(step)\r\n-> 1100               tmp_logs = self.train_function(iterator)\r\n   1101               if data_handler.should_sync:\r\n   1102                 context.async_wait()\r\n\r\n~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    826     tracing_count = self.experimental_get_tracing_count()\r\n    827     with trace.Trace(self._name) as tm:\r\n--> 828       result = self._call(*args, **kwds)\r\n    829       compiler = \"xla\" if self._experimental_compile else \"nonXla\"\r\n    830       new_tracing_count = self.experimental_get_tracing_count()\r\n\r\n~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    853       # In this case we have created variables on the first call, so we run the\r\n    854       # defunned version which is guaranteed to never create variables.\r\n--> 855       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n    856     elif self._stateful_fn is not None:\r\n    857       # Release the lock early so that multiple threads can perform the call\r\n\r\n~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)\r\n   2940       (graph_function,\r\n   2941        filtered_flat_args) = self._maybe_define_function(args, kwargs)\r\n-> 2942     return graph_function._call_flat(\r\n   2943         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\r\n   2944 \r\n\r\n~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n   1916         and executing_eagerly):\r\n   1917       # No tape is watching; skip to running the function.\r\n-> 1918       return self._build_call_outputs(self._inference_function.call(\r\n   1919           ctx, args, cancellation_manager=cancellation_manager))\r\n   1920     forward_backward = self._select_forward_and_backward_functions(\r\n\r\n~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)\r\n    553       with _InterpolateFunctionError(self):\r\n    554         if cancellation_manager is None:\r\n--> 555           outputs = execute.execute(\r\n    556               str(self.signature.name),\r\n    557               num_outputs=self._num_outputs,\r\n\r\n~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     57   try:\r\n     58     ctx.ensure_initialized()\r\n---> 59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n     60                                         inputs, attrs, num_outputs)\r\n     61   except core._NotOkStatusException as e:\r\n\r\nNotFoundError:  Resource localhost/_AnonymousVar29/N10tensorflow22SummaryWriterInterfaceE does not exist.\r\n\t [[{{node cond/then/_0/batch_loss}}]] [Op:__inference_train_function_9310]\r\n\r\nFunction call stack:\r\ntrain_function\r\n```", "comments": ["@GF-Huang \r\n\r\nPlease, fill [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\nPlease, share colab link or simple standalone code with supporting files to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47100\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47100\">No</a>\n", "> tf 2.4.1\r\n> \r\n> ```\r\n> ---------------------------------------------------------------------------\r\n> NotFoundError                             Traceback (most recent call last)\r\n> <ipython-input-10-92bfedd73a83> in <module>\r\n>       2 tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, update_freq='batch')\r\n>       3 \r\n> ----> 4 model.fit(x, y, initial_epoch=20, epochs=25, callbacks=[tensorboard_callback])\r\n> \r\n> ~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n>    1098                 _r=1):\r\n>    1099               callbacks.on_train_batch_begin(step)\r\n> -> 1100               tmp_logs = self.train_function(iterator)\r\n>    1101               if data_handler.should_sync:\r\n>    1102                 context.async_wait()\r\n> \r\n> ~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n>     826     tracing_count = self.experimental_get_tracing_count()\r\n>     827     with trace.Trace(self._name) as tm:\r\n> --> 828       result = self._call(*args, **kwds)\r\n>     829       compiler = \"xla\" if self._experimental_compile else \"nonXla\"\r\n>     830       new_tracing_count = self.experimental_get_tracing_count()\r\n> \r\n> ~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n>     853       # In this case we have created variables on the first call, so we run the\r\n>     854       # defunned version which is guaranteed to never create variables.\r\n> --> 855       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n>     856     elif self._stateful_fn is not None:\r\n>     857       # Release the lock early so that multiple threads can perform the call\r\n> \r\n> ~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)\r\n>    2940       (graph_function,\r\n>    2941        filtered_flat_args) = self._maybe_define_function(args, kwargs)\r\n> -> 2942     return graph_function._call_flat(\r\n>    2943         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\r\n>    2944 \r\n> \r\n> ~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n>    1916         and executing_eagerly):\r\n>    1917       # No tape is watching; skip to running the function.\r\n> -> 1918       return self._build_call_outputs(self._inference_function.call(\r\n>    1919           ctx, args, cancellation_manager=cancellation_manager))\r\n>    1920     forward_backward = self._select_forward_and_backward_functions(\r\n> \r\n> ~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)\r\n>     553       with _InterpolateFunctionError(self):\r\n>     554         if cancellation_manager is None:\r\n> --> 555           outputs = execute.execute(\r\n>     556               str(self.signature.name),\r\n>     557               num_outputs=self._num_outputs,\r\n> \r\n> ~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n>      57   try:\r\n>      58     ctx.ensure_initialized()\r\n> ---> 59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n>      60                                         inputs, attrs, num_outputs)\r\n>      61   except core._NotOkStatusException as e:\r\n> \r\n> NotFoundError:  Resource localhost/_AnonymousVar29/N10tensorflow22SummaryWriterInterfaceE does not exist.\r\n> \t [[{{node cond/then/_0/batch_loss}}]] [Op:__inference_train_function_9310]\r\n> \r\n> Function call stack:\r\n> train_function\r\n> ```\r\n\r\n@GF-Huang, have you found a solution to this issue. If so, kindly share your solution here. I'm facing similar issue.", "I forget what's the problem, maybe restart the python kernel will be help."]}, {"number": 47099, "title": "tf.keras.metrics.Metric not returning actual result value over batches", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Microsoft Windows 10 Enterprise Version 10.0.18363 Build 18363\r\n- TensorFlow installed from (source or binary): binary (pip install tensorflow)\r\n- TensorFlow version : v2.4.0-49-g85c8b2a817f 2.4.1\r\n- Python version: 3.7.6\r\n\r\n**Describe the current behavior**\r\nThe `result()` method of the `tf.keras.metrics.Metric` class as defined [here](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Metric#result) is supposed to return the calculation over state variables. The values it returns seem to be affected by some kind of decorator over it that is not allowing to return of the actual value rather a generalized version of value considering the batch number\r\n\r\n**Describe the expected behavior**\r\nIt should return what it is calculating without any transformations \r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nclass AddAllOnes(tf.keras.metrics.Metric):\r\n  \"\"\" A simple metric that adds all the one's in current batch and suppose to return the total ones seen at every end of batch\"\"\"\r\n    def __init__(self, name=\"add_all_ones\", **kwargs):\r\n        super(AddAllOnes, self).__init__(name=name, **kwargs)\r\n        self.total = self.add_weight(name=\"total\", initializer=\"zeros\")\r\n\r\n    def update_state(self, y_true, y_pred, sample_weight=None):    \r\n        self.total.assign_add(tf.cast(tf.reduce_sum(y_true), dtype=tf.float32))\r\n        \r\n    def result(self):\r\n        print('')\r\n        print('inside result...', self.total)\r\n        return self.total\r\n\r\nX_train = np.random.random((512, 8))\r\ny_train = np.random.randint(0, 2, (512, 1))\r\n\r\nK.clear_session()\r\nmodel_inputs = Input(shape=(8,))\r\nmodel_unit = Dense(256, activation='linear', use_bias=False)(model_inputs)\r\nmodel_unit = BatchNormalization()(model_unit)\r\nmodel_unit = Activation('sigmoid')(model_unit)\r\nmodel_outputs = Dense(1, activation='sigmoid')(model_unit)\r\noptim = Adam(learning_rate=0.001)\r\nmodel = Model(inputs=model_inputs, outputs=model_outputs)\r\nmodel.compile(loss='binary_crossentropy', optimizer=optim, metrics=[AddAllOnes()], run_eagerly=True)\r\nmodel.fit(X_train, y_train, verbose=1, batch_size=32)\r\n```\r\n\r\n**Other info / logs**\r\nDo you see the difference between the printed value within the result and the returned value on the epoch logs (except the first iteration everything is different)\r\n\r\nE.g. In the first iteration the metric saw a total of 19 ones and so returned 19.0 in epoch logs however in the 5th iteration it is supposed to return 79 but returned 49 in epoch logs! \r\n\r\n```\r\ninside result... <tf.Variable 'total:0' shape=() dtype=float32, numpy=19.0>\r\n 1/16 [>.............................] - ETA: 0s - loss: 0.6744 - add_all_ones: 19.0000\r\ninside result... <tf.Variable 'total:0' shape=() dtype=float32, numpy=35.0>\r\n\r\ninside result... <tf.Variable 'total:0' shape=() dtype=float32, numpy=53.0>\r\n\r\ninside result... <tf.Variable 'total:0' shape=() dtype=float32, numpy=61.0>\r\n\r\ninside result... <tf.Variable 'total:0' shape=() dtype=float32, numpy=79.0>\r\n 5/16 [========>.....................] - ETA: 0s - loss: 0.7072 - add_all_ones: 49.4000\r\ninside result... <tf.Variable 'total:0' shape=() dtype=float32, numpy=93.0>\r\n\r\ninside result... <tf.Variable 'total:0' shape=() dtype=float32, numpy=108.0>\r\n\r\ninside result... <tf.Variable 'total:0' shape=() dtype=float32, numpy=120.0>\r\n 8/16 [==============>...............] - ETA: 0s - loss: 0.7084 - add_all_ones: 71.0000\r\ninside result... <tf.Variable 'total:0' shape=() dtype=float32, numpy=135.0>\r\n\r\ninside result... <tf.Variable 'total:0' shape=() dtype=float32, numpy=149.0>\r\n\r\ninside result... <tf.Variable 'total:0' shape=() dtype=float32, numpy=158.0>\r\n11/16 [===================>..........] - ETA: 0s - loss: 0.7074 - add_all_ones: 91.8182\r\ninside result... <tf.Variable 'total:0' shape=() dtype=float32, numpy=169.0>\r\n\r\ninside result... <tf.Variable 'total:0' shape=() dtype=float32, numpy=183.0>\r\n\r\ninside result... <tf.Variable 'total:0' shape=() dtype=float32, numpy=203.0>\r\n14/16 [=========================>....] - ETA: 0s - loss: 0.7063 - add_all_ones: 111.7857\r\ninside result... <tf.Variable 'total:0' shape=() dtype=float32, numpy=220.0>\r\n\r\ninside result... <tf.Variable 'total:0' shape=() dtype=float32, numpy=238.0>\r\n16/16 [==============================] - 0s 17ms/step - loss: 0.7070 - add_all_ones: 133.0000\r\n<tensorflow.python.keras.callbacks.History at 0x1d8213676c8>\r\n```\r\n", "comments": ["Was able to reproduce the issue with [TF v2.4.1](https://colab.research.google.com/gist/amahendrakar/135940fbd8671cd3a6b8886bacdfa754/47099.ipynb) and TF-nightly. \r\n\r\nHowever, code works as expected with [TF v2.3.2](https://colab.research.google.com/gist/amahendrakar/dd908612f7e1cd7ba018feaa126ffe8a/47099-2-3.ipynb). Please check the linked gist for reference. Thanks!", "Hi all! Looks like an issue described in #46713. Still awaiting response.", "Could that be a running average with some exp decay parameter? i.e. not a simple average.\r\nMight be linked to https://github.com/tensorflow/tensorflow/issues/39448\r\n", "Investigation into this shows that this is because Progbar doesn't have the correct stateful metrics information. Will work on a fix for this. Thanks for your patience.", "@rchao thanks for looking into this. Could you please tell in your opinion what the Progbar displayed metric values are at the moment?\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47099\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47099\">No</a>\n", "@ricvo it would basically average the metric across batches, which is incorrect for stateful metrics like \"AddAllOnes\" used in the example repro."]}, {"number": 47098, "title": "Use xa_nnlib for svdf for Fusion F1.", "body": "The code in this change is the subset of functionality needed for int8 svdf for Hifi4 copied from https://github.com/pnikam-cad/tensorflow/blob/a737c1e3945bc70022259479ad24133a343ec906/tensorflow/lite/micro/kernels/xtensa_hifi/svdf.cc\r\n\r\nNote that the current change has not pulled in either the floating point implementation or the Hifi5 implementation.\r\n\r\nProfiled the keryword_benchmark with the following command:\r\n```\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=xtensa OPTIMIZED_KERNEL_DIR=xtensa TARGET_ARCH=fusion_f1 XTENSA_CORE=F1_190305_swupgrade run_keyword_benchmark -j8\r\n```\r\n\r\ngives a latency of 38516 ticks with this change vs 152642 ticks without this change.\r\n\r\nPer OP latency with this change:\r\n```\r\nKeywordRunNIerations(1) took 38516 ticks (38 ms)\r\nQUANTIZE took 3758 ticks (3 ms).\r\nSVDF took 4753 ticks (4 ms).\r\nFULLY_CONNECTED took 1353 ticks (1 ms).\r\nSVDF took 4211 ticks (4 ms).\r\nFULLY_CONNECTED took 1353 ticks (1 ms).\r\nSVDF took 3145 ticks (3 ms).\r\nFULLY_CONNECTED took 1353 ticks (1 ms).\r\nSVDF took 4211 ticks (4 ms).\r\nFULLY_CONNECTED took 1353 ticks (1 ms).\r\nSVDF took 2890 ticks (2 ms).\r\nSVDF took 3583 ticks (3 ms).\r\nSVDF took 3054 ticks (3 ms).\r\nFULLY_CONNECTED took 1091 ticks (1 ms).\r\nSOFTMAX took 2042 ticks (2 ms).\r\nQUANTIZE took 366 ticks (0 ms).\r\n```\r\n\r\nWithout this change:\r\n```\r\nKeywordRunNIerations(1) took 152642 ticks (152 ms)\r\nQUANTIZE took 3758 ticks (3 ms).\r\nSVDF took 38003 ticks (38 ms).\r\nFULLY_CONNECTED took 1353 ticks (1 ms).\r\nSVDF took 18803 ticks (18 ms).\r\nFULLY_CONNECTED took 1353 ticks (1 ms).\r\nSVDF took 18803 ticks (18 ms).\r\nFULLY_CONNECTED took 1353 ticks (1 ms).\r\nSVDF took 18803 ticks (18 ms).\r\nFULLY_CONNECTED took 1353 ticks (1 ms).\r\nSVDF took 13907 ticks (13 ms).\r\nSVDF took 15827 ticks (15 ms).\r\nSVDF took 15827 ticks (15 ms).\r\nFULLY_CONNECTED took 1091 ticks (1 ms).\r\nSOFTMAX took 2042 ticks (2 ms).\r\nQUANTIZE took 366 ticks (0 ms).\r\n```\r\n\r\nAlso confirmed that the kernel_svdf_test passes with:\r\n```\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=xtensa OPTIMIZED_KERNEL_DIR=xtensa TARGET_ARCH=fusion_f1 XTENSA_CORE=F1_190305_swupgrade test_kernel_svdf_test -j8\r\n```\r\n\r\nProgress towards http://b/177457688", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "tagging @pnikam-cad @nyadla-sys @bhanuprakashbv"]}, {"number": 47097, "title": "post-quantizing and loading a a trained model in keras using tflite issue", "body": "**System information**\r\n- google colab ( intended to be used on raspberry pi)\r\n- TensorFlow 1.14\r\n- python 2.7 ( i know its old and not supported but i have to use it) \r\n-\r\n\r\n**Provide the text output from tflite_convert**\r\n```\r\n/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/python/convert.pyc in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n\r\nConverterError: See console for info.\r\n2021-02-11 22:29:16.405546: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: AddV2\r\n2021-02-11 22:29:16.424912: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 57 operators, 100 arrays (0 quantized)\r\n2021-02-11 22:29:16.425598: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 57 operators, 100 arrays (0 quantized)\r\n2021-02-11 22:29:16.427571: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 25 operators, 53 arrays (0 quantized)\r\n2021-02-11 22:29:17.452115: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 24 operators, 52 arrays (0 quantized)\r\n2021-02-11 22:29:17.452530: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 23 operators, 50 arrays (0 quantized)\r\n2021-02-11 22:29:17.452823: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 23 operators, 50 arrays (0 quantized)\r\n2021-02-11 22:29:17.453000: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 23 operators, 50 arrays (0 quantized)\r\n2021-02-11 22:29:17.453320: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 16777216 bytes, theoretical optimal value: 16777216 bytes.\r\n2021-02-11 22:29:17.453614: E tensorflow/lite/toco/toco_tooling.cc:456] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONV_2D, FULLY_CONNECTED, MAX_POOL_2D, MUL, SOFTMAX. Here is a list of operators for which you will need custom implementations: AddV2.\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/toco_from_protos\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 59, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/usr/local/lib/python2.7/dist-packages/absl/app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python2.7/dist-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 33, in execute\r\n    output_str = tensorflow_wrap_toco.TocoConvert(model_str, toco_str, input_str)\r\nException: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONV_2D, FULLY_CONNECTED, MAX_POOL_2D, MUL, SOFTMAX. Here is a list of operators for which you will need custom implementations: AddV2.\r\n\r\n```\r\n\r\n**Standalone code to reproduce the issue** \r\n\r\n# WHOLE MODEL\r\nimport tensorflow as tf\r\nfrom tensorflow import lite\r\nfrom tensorflow import keras\r\nfrom keras.models import load_model\r\nimport os\r\n\r\n\r\nmodel=keras.models.load_model('/content/drive/MyDrive/disease classification/AGAIN/end_model_acc1.h5')\r\nallow_custom_ops=True \r\n#--enable_select_tf_ops\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n\r\ntfmodel = converter.convert()\r\nopen (\"model.tflite\" , \"wb\") .write(tfmodel)\r\n\r\n\r\n#loading quantized model and interprete it \r\n\r\n\r\ninterpreter = tf.lite.Interpreter(model_content=tfmodel)\r\ninterpreter.allocate_tensors()\r\ninput_details = interpreter.get_input_details()\r\noutput_details= interpreter.get_output_details()\r\n#interpreter.resize_tensor_input(input_details[0]['index'],(10, 224, 224, 3))\r\n#interpreter.resize_tensor_input(output_details[0]['index'], (15, 224,224,3))\r\ninterpreter.allocate_tensors()\r\nos.chdir(\"/content/drive/MyDrive/disease classification/The End/\") \r\n!pwd\r\n\r\n\r\n**Any other info / logs**\r\nthe model is used for image classification of 10 classes using CNN to be performed on the raspberry pi , i would appreciate any feedback regarding the process as i am new to this. thank you. ", "comments": ["There is an TF operator, that isn't covered by TFLite builtin kernels. You can enable select TF option for this case. https://www.tensorflow.org/lite/guide/ops_select\r\n\r\n```\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.target_spec.supported_ops = [\r\n  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\r\n  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\r\n]\r\ntfmodel = converter.convert()\r\n```", "Thank you very much! it worked. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47097\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47097\">No</a>\n"]}, {"number": 47096, "title": "Remove code and scripts related to xtensa_hifi", "body": "This work has now been consolidated in common locations (such as kernels/xtensa, xtensa_makefile.inc etc.)\r\n\r\nAddresses http://b/173043817\r\n", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "tagging @pnikam-cad @nyadla-sys @bhanuprakashbv"]}, {"number": 47095, "title": "*system info* ", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (or github SHA if from source):\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\n# Copy and paste here\r\n```\r\n\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem.\r\nIf including tracebacks, please include the full traceback. Large logs and files\r\nshould be attached.\r\n", "comments": []}, {"number": 47094, "title": "Add an individual kernel test with Renode to the CI.", "body": "This will help prevent issues like #46186 and #45348\r\n", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 47093, "title": "Fix LayerNormalization on CPU", "body": "Fix #46366 . `LayerNormalization` layer crashes on empty inputs on CPU. This pull request would help `LayerNormalization` return the input as the output if the input value is `[]` .  This is a similar condition to `LayerNormalization on GPU` and `BatchNormalization` which returns back the empty input without throwing in an error.", "comments": ["@gbaned, can you please review this pull request or request someone else a review ? Thanks."]}, {"number": 47092, "title": "RaggedTensor support for sparse_categorical_crossentropy.", "body": "Attempt to support RaggedTensors in ```sparse_categorical_crossentropy``` loss.\r\n\r\n", "comments": ["Independently to the `OP_REQUIRES` issue, which I could not tackle, is the `sparse_categorical_crossentropy` expected to work in case there are multiple ragged dimensions? For example, the batch examples are images and we classify every pixel?\r\n\r\nIt seems that such a scenario works with `binary_crossentropy` from #47075, but if crashes here. Notably, the following seems to work:\r\n```python\r\nsce_obj = tf.losses.SparseCategoricalCrossentropy()\r\ny_true = tf.ragged.constant([[1, 1], [0]])\r\ny_pred = tf.ragged.constant([[[0.1, 0.9], [0.1, 0.9]], [[0.9, 0.1]]])\r\nprint(sce_obj(y_true, y_pred))\r\n```\r\nbut after adding another ragged dimension\r\n```python\r\ny_true = tf.ragged.constant([[[1, 1]], [[0]]])\r\ny_pred = tf.ragged.constant([[[[0.1, 0.9], [0.1, 0.9]]], [[[0.9, 0.1]]]]) # both without and with `inner_shape=(2,)`\r\nprint(sce_obj(y_true, y_pred))\r\n```\r\nit crashes with `ValueError: TypeError: object of type 'RaggedTensor' has no len()`.\r\n\r\nIt seems to be connected to `_convert_to_dense` in `_ragged_tensor_apply_loss`, because if the `_convert_to_dense` just passes through the inputs unchanged, the example above works.", "@foxit Added a test with the example you provided and changed the approach a bit to avoid the warning generated by the previous code.", "A gentle bump after two weeks -- we would be grateful for a review.\r\n\r\nThanks & cheers.", "@pedro-r-marques can you please check build failures ?", "@rthadur Fixed. It was a pylint error for an unused import.\r\n", "@rthadur Can you please check why the CL doesn't built internally to google ?", "@pedro-r-marques seeing this error internally \r\n\r\n\r\n```\r\ntensorflow/python/util/dispatch.py\", line 206, in wrapper\r\n   return target(*args, **kwargs)\r\n File \"/tensorflow/python/keras/losses.py\", line 1736, in sparse_categorical_crossentropy\r\n   y_pred = ops.convert_to_tensor_v2_with_dispatch(y_pred)\r\n File \"/tensorflow/python/util/dispatch.py\", line 206, in wrapper\r\n   return target(*args, **kwargs)\r\n File \"/tensorflow/python/framework/ops.py\", line 1429, in convert_to_tensor_v2_with_dispatch\r\n   value, dtype=dtype, dtype_hint=dtype_hint, name=name)\r\n File \"/tensorflow/python/framework/ops.py\", line 1439, in convert_to_tensor_v2\r\n   as_ref=False)\r\n File \"/tensorflow/python/profiler/trace.py\", line 163, in wrapped\r\n   return func(*args, **kwargs)\r\n File \"/tensorflow/python/framework/ops.py\", line 1564, in convert_to_tensor\r\n   ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n File \"/tensorflow/python/framework/constant_op.py\", line 340, in _constant_tensor_conversion_function\r\n   return constant(v, dtype=dtype, name=name)\r\n File \"/tensorflow/python/framework/constant_op.py\", line 266, in constant\r\n   allow_broadcast=True)\r\n File \"/tensorflow/python/framework/constant_op.py\", line 277, in _constant_impl\r\n   return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n File \"/tensorflow/python/framework/constant_op.py\", line 302, in _constant_eager_impl\r\n   t = convert_to_eager_tensor(value, ctx, dtype)\r\n File \"/tensorflow/python/framework/constant_op.py\", line 99, in convert_to_eager_tensor\r\n   return ops.EagerTensor(value, ctx.device_name, dtype)\r\nValueError: TypeError: object of type 'RaggedTensor' has no len()\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n File \"/py/absl/testing/parameterized.py\", line 314, in bound_param_test\r\n   return test_method(self, **testcase_params)\r\n File \"/tensorflow/python/framework/test_combinations.py\", line 367, in decorated\r\n   execute_test_method()\r\n File \"/tensorflow/python/framework/test_combinations.py\", line 350, in execute_test_method\r\n   test_method(**kwargs_to_pass)\r\n File \"/tensorflow/python/keras/losses_test.py\", line 1180, in test_ragged_tensors_3d\r\n   loss = cce_obj(y_true, y_pred)\r\n File \"/tensorflow/python/keras/losses.py\", line 155, in __call__\r\n   losses = call_fn(y_true, y_pred)\r\n File \"/tensorflow/python/keras/losses.py\", line 259, in call\r\n   return ag_fn(y_true, y_pred, **self._fn_kwargs)\r\n File \"/tensorflow/python/util/dispatch.py\", line 210, in wrapper\r\n   result = dispatch(wrapper, args, kwargs)\r\n File \"/tensorflow/python/util/dispatch.py\", line 122, in dispatch\r\n   result = dispatcher.handle(args, kwargs)\r\n File \"/tensorflow/python/util/dispatch.py\", line 154, in handle\r\n   return self._override_func(*args, **kwargs)\r\n File \"/tensorflow/python/keras/losses.py\", line 1762, in _ragged_tensor_sparse_categorical_crossentropy\r\n   return _ragged_tensor_apply_loss(fn, y_true, y_pred, y_pred_extra_dim=True)\r\n File \"/tensorflow/python/keras/losses.py\", line 1291, in _ragged_tensor_apply_loss\r\n   assertion_list = ragged_util.assert_splits_match(nested_splits_list)\r\n File \"/tensorflow/python/ops/ragged/ragged_util.py\", line 52, in assert_splits_match\r\n   raise ValueError(error_msg)\r\nValueError: Inputs must have identical ragged splits\r\n\r\n```", "@rthadur\r\nI've updated the patch with the following change in  _ragged_tensor_apply_loss:\r\n```\r\n-  if y_pred_extra_dim and y_pred.shape[-1] is None:\r\n+  if y_pred_extra_dim:\r\n     nested_splits_list[1] = nested_splits_list[1][:-1]\r\n```\r\n\r\nThe flag y_pred_extra_dim is only set when calculating losses for sparse categorical cross entropy since we expect the shape of y_pred to have one extra dimension. This if statement had an extra check which is both unnecessary and incorrect. I would appreciate it if you could trigger the google internal CI and check that the patch passes the tests.", "@tomerk @rthadur Please retrigger the CI."]}]