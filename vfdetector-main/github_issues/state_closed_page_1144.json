[{"number": 18892, "title": "Build libtensorflow.so and libtensorflow_framework.so for Raspberry Pi.", "body": "Build libtensorflow.so and libtensorflow_framework.so binaries for Raspberry Pi during CI builds.\r\n\r\nI'm looking to add C# support for Tensorflow on ARM (Raspberry Pi, etc.) to TensorFlowSharp (https://github.com/migueldeicaza/TensorFlowSharp), and this would allow me to move forward more easily.\r\n\r\nFixes #17850 ", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "@petewarden may want to take a look, who is looking into support for Raspberry Pi", "Nagging Assignee @ekelsen: It has been 17 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Thanks @gunan!"]}, {"number": 18891, "title": "Android Example won't run: AndroidRuntime: FATAL EXCEPTION NullPointerException", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Android 6.0.1\r\n- **TensorFlow installed from (source or binary)**: not used\r\n- **TensorFlow version (use command below)**: not used\r\n- **Python version**:  not used\r\n- **Bazel version (if compiling from source)**: not used\r\n- **GCC/Compiler version (if compiling from source)**: not used\r\n- **CUDA/cuDNN version**: not used\r\n- **GPU model and memory**: not used\r\n- **Exact command to reproduce**: download android example project https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android, set `def nativeBuildSystem = 'none'`, try to start **Detector Activity**\r\n\r\n### Describe the problem\r\n**AndroidRuntime: FATAL EXCEPTION NullPointerException**\r\n\r\n### Source code / logs\r\n```\r\n04-26 09:43:01.808 2417-2475/? E/AndroidRuntime: FATAL EXCEPTION: inference\r\n    Process: org.tensorflow.demo, PID: 2417\r\n    java.lang.NullPointerException: Attempt to invoke interface method 'java.util.List org.tensorflow.demo.Classifier.recognizeImage(android.graphics.Bitmap)' on a null object reference\r\n        at org.tensorflow.demo.DetectorActivity$3.run(DetectorActivity.java:289)\r\n        at android.os.Handler.handleCallback(Handler.java:742)\r\n        at android.os.Handler.dispatchMessage(Handler.java:95)\r\n        at android.os.Looper.loop(Looper.java:157)\r\n        at android.os.HandlerThread.run(HandlerThread.java:61)\r\n```\r\n", "comments": ["so it run ok for next android studio run\r\n\r\nas temporary solution I added try...catch in case it will happen again\r\n\r\n ```\r\n  runInBackground(\r\n        new Runnable() {\r\n          @Override\r\n          public void run() {\r\n            try {\r\n              LOGGER.i(\"Running detection on image \" + currTimestamp);\r\n              final long startTime = SystemClock.uptimeMillis();\r\n              final List<Classifier.Recognition> results = detector.recognizeImage(croppedBitmap);\r\n              lastProcessingTimeMs = SystemClock.uptimeMillis() - startTime;\r\n\r\n              cropCopyBitmap = Bitmap.createBitmap(croppedBitmap);\r\n              final Canvas canvas = new Canvas(cropCopyBitmap);\r\n              final Paint paint = new Paint();\r\n              paint.setColor(Color.RED);\r\n              paint.setStyle(Style.STROKE);\r\n              paint.setStrokeWidth(2.0f);\r\n\r\n              float minimumConfidence = MINIMUM_CONFIDENCE_TF_OD_API;\r\n              switch (MODE) {\r\n                case TF_OD_API:\r\n                  minimumConfidence = MINIMUM_CONFIDENCE_TF_OD_API;\r\n                  break;\r\n                case MULTIBOX:\r\n                  minimumConfidence = MINIMUM_CONFIDENCE_MULTIBOX;\r\n                  break;\r\n                case YOLO:\r\n                  minimumConfidence = MINIMUM_CONFIDENCE_YOLO;\r\n                  break;\r\n              }\r\n\r\n              final List<Classifier.Recognition> mappedRecognitions =\r\n                      new LinkedList<Classifier.Recognition>();\r\n\r\n              for (final Classifier.Recognition result : results) {\r\n                final RectF location = result.getLocation();\r\n                if (location != null && result.getConfidence() >= minimumConfidence) {\r\n                  canvas.drawRect(location, paint);\r\n\r\n                  cropToFrameTransform.mapRect(location);\r\n                  result.setLocation(location);\r\n                  mappedRecognitions.add(result);\r\n                }\r\n              }\r\n\r\n              tracker.trackResults(mappedRecognitions, luminanceCopy, currTimestamp);\r\n              trackingOverlay.postInvalidate();\r\n\r\n              requestRender();\r\n              computingDetection = false;\r\n            } catch (NullPointerException e) {\r\n              e.printStackTrace();\r\n            }\r\n          }\r\n        });\r\n  }\r\n```", "It looks like the issue is now resolved. If you think you've found a bug, please make another issue with replication information. Thanks!", "@angersson  Could you please tell me what and where to solved this issue? ", "@xjohnxjohn I faced the same issue and I solved by following these steps,\r\n1. Sync gradle file if it asks\r\n2. Uninstall existing APKs\r\n3. Run again \r\n\r\n"]}, {"number": 18890, "title": "failed to allocate tensors on mobile device", "body": "### System information\r\nI minimize the model to very simple model with one input, convolution layer and pool is the output.\r\nI work on Ubuntu 16.04\r\nI compile TensorFlow Lite from source with Bazel\r\nTensorFlow version is 1.8\r\nPython 3.6\r\nBazel version 0.10.0\r\nGCC/Compiler version - gcc (Ubuntu 5.4.0-6ubuntu1~16.04.6) 5.4.0 20160609\r\nWorking on CPU\r\n\r\n\r\n### Describe the problem\r\nI am trying to run my Tensorflow model on samsung galaxy s9, \r\nI trained model with TensorFlow freeze it and convert it to .tflite model file with toco.\r\nI am running CPP program on the phone according to documentation and load the .tflite model file:\r\n\r\n    std::unique_ptr<tflite::FlatBufferModel> model(tflite::FlatBufferModel::BuildFromFile(modelFile));\r\n    if (!model) {\r\n        printf(\"Failed to mmap model %s\\n\", g_modelFile);\r\n    }\r\n    model->error_reporter();\r\n    tflite::ops::builtin::BuiltinOpResolver resolver;\r\n    std::unique_ptr<tflite::Interpreter> interpreter;\r\n    tflite::InterpreterBuilder(*model, resolver)(&interpreter);\r\n    if (!interpreter) {\r\n        printf(\"Failed to construct interpreter\\n\");\r\n    }\r\n    interpreter->UseNNAPI(false);\r\n    if (interpreter->AllocateTensors() != kTfLiteOk) {\r\n        printf(\"Failed to allocate tensors!\\n\");\r\n    }\r\n\r\n\r\nI succeed to initialize the model but failed to run **interpreter->AllocateTensors()**\r\nThere is no print of why it failed to allocate the tensors, just my print that the function failed\r\n\r\n    if (interpreter->AllocateTensors() != kTfLiteOk) {\r\n        printf(\"Failed to allocate tensors!\\n\");\r\n    }\r\n\r\nI minimized my model to include only reshape, convolution layer and pool and still failed to run AllocateTensors\r\n\r\nOutput with debug information:\r\n\r\nresolved reporter\r\ntensors size: 8\r\nnodes size: 3\r\ninputs: 1\r\ninput(0) name: patches\r\ninput(1) name: (null)\r\nReshape, 237552, 1, 0.000000, 0\r\nReshape/shape, 16, 2, 0.000000, 0\r\nconv1/Relu, 1861632, 1, 0.000000, 0\r\nconv1/convolution_bias, 128, 1, 0.000000, 0\r\nconv1/kernel, 3456, 1, 0.000000, 0\r\ninput/patches-input, 237552, 1, 0.000000, 0\r\noutput, 465408, 1, 0.000000, 0\r\npatches, 4, 1, 0.000000, 0\r\n\r\n**Failed to allocate tensors!**", "comments": ["We might need your help debugging this. Usually errors are reported through and ErrorReporter and the default reporter just prints to stderr. In your case, it looks like something is going wrong but not being properly reported. If you could trace the code in AllocateTensors to see what can be going wrong, great. Otherwise we might need access to your model.", "Hi,\r\n\r\nAfter some debugging I found the error:\r\ntensorflow/contrib/lite/simple_memory_arena.cc:82 it->size != alloc.size (4 != 0)\r\n\r\nIt happens on the first allocation,\r\n\r\nThe initialization succeeded but it fails with this allocation, can you please give me some directions where to look?\r\n\r\nMy model is very basic and consists weights and biases:\r\n\r\n    def my_model(patches, hidden_init):\r\n\r\n        patches = tf.reshape(patches, (101, 14, 14, 3))\r\n        hidden_init = tf.reshape(hidden_init, shape=[1, 512])\r\n\r\n        conv1 = tf.layers.conv2d(patches, 32, [3, 3], activation=tf.nn.relu, name='conv1')\r\n        pool1 = tf.layers.max_pooling2d(conv1, 2, 2)\r\n\r\n        output = tf.identity(pool1, 'output')\r\n\r\nThanks", "Hi,\r\n\r\nAnother thing I tried is to run Mobilenet model for tflite on the phone and it worked and succeeded to allocate the tensors.\r\n\r\nMaybe there is a problem on the way I have converted the files with Toco?\r\n(This is the command I ran, there was no errors when I used the following)\r\nbazel-bin/tensorflow/contrib/lite/toco/toco \r\n--input_format=TENSORFLOW_GRAPHDEF \r\n--input_file=/home/model_for_freezing/output_graph.pb \r\n--output_format=TFLITE \r\n--output_file=/tmp/my_model.tflite \r\n--inference_type=FLOAT \r\n--inference_input_type=FLOAT \r\n--input_arrays=patches\r\n--output_arrays=output                   \r\n\r\nThanks", "I have similar problem. \r\n\r\nLoaded model foo.tflite\r\nresolved reporter\r\nconstruct interpreter\r\ntensors size: 15\r\nnodes size: 5\r\ninputs: 1\r\ninput(0) name: input\r\n0: MatMul_bias, 48, 1, 0, 0\r\n1: Reshape, 15680, 1, 0, 0\r\n2: add, 48, 1, 0, 0\r\n3: fc1/MatMul_bias, 512, 1, 0, 0\r\n4: fc1/Relu, 512, 1, 0, 0\r\n5: fc1/W/transpose, 2007040, 1, 0, 0\r\n6: fc2/MatMul_bias, 512, 1, 0, 0\r\n7: fc2/Relu, 512, 1, 0, 0\r\n8: fc2/W/transpose, 65536, 1, 0, 0\r\n9: fc3/MatMul_bias, 512, 1, 0, 0\r\n10: fc3/Relu, 512, 1, 0, 0\r\n11: fc3/W/transpose, 65536, 1, 0, 0\r\n12: final_fc/transpose, 6144, 1, 0, 0\r\n13: input, 15840, 1, 0, 0\r\n14: labels_softmax, 48, 1, 0, 0\r\ninput: 13\r\nnumber of inputs: 1\r\nnumber of outputs: 1\r\ntensorflow/contrib/lite/simple_memory_arena.cc:82 it->size != alloc.size (15680 != 0)\r\nFailed to allocate tensors!Segmentation fault", "though, i am trying on raspberry pi.", "Linking to https://github.com/tensorflow/tensorflow/issues/19026. Both issues probably have same cause.", "My guess is The error is happening on first allocation. It is trying to deallocate a tensor which has not been allocated yet. But, why is not happening on example models?", "Nagging Assignee @aselle: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @aselle: It has been 30 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @aselle: It has been 45 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @aselle: It has been 60 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I think this is now resolved. Could you try a nightly or build from source. In particular, make sure whatever verison you use has this\r\nhttps://github.com/tensorflow/tensorflow/commit/85c518b8d306204cd7111f321a4b7b204fc554f4\r\nUnfortunately, this is not in r1.9, so you'll need to use master or the nightly.\r\n", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 18889, "title": "AttributeError: 'module' object has no attribute 'Exporter'", "body": "When I try to import tensorflow hub in python 2, I get the following error saying that 'module' object has no attribute 'Exporter'.\r\n\r\nAttributeErrorTraceback (most recent call last)\r\n<ipython-input-1-31fb71834c8c> in <module>()\r\n      1 # Install TF-Hub.\r\n      2 import tensorflow as tf\r\n----> 3 import tensorflow_hub as hub\r\n      4 import matplotlib.pyplot as plt\r\n      5 import numpy as np\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow_hub/__init__.py in <module>()\r\n     24 import tensorflow as tf\r\n     25 \r\n---> 26 from tensorflow_hub.estimator import LatestModuleExporter\r\n     27 from tensorflow_hub.estimator import register_module_for_export\r\n     28 from tensorflow_hub.feature_column import image_embedding_column\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow_hub/estimator.py in <module>()\r\n     59 \r\n     60 \r\n---> 61 class LatestModuleExporter(tf.estimator.Exporter):\r\n     62   \"\"\"Regularly exports registered modules into timestamped directories.\r\n     63 \r\n\r\nAttributeError: 'module' object has no attribute 'Exporter'`", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Hi,\r\nI just got the same error message:\r\n\r\nTraceback (most recent call last):\r\n  File \"retrain.py\", line 133, in <module>\r\n    import tensorflow_hub as hub\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_hub/__init__.py\", line 26, in <module>\r\n    from tensorflow_hub.estimator import LatestModuleExporter\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_hub/estimator.py\", line 61, in <module>\r\n    class LatestModuleExporter(tf.estimator.Exporter):\r\nAttributeError: 'module' object has no attribute 'Exporter'\r\n\r\nOS: Ubuntu 16.04 LTS\r\nTensorflow installed from pip, (newest version of pip), version 1.8.0\r\nGPU: GeForce 940MX with 2048 MB\r\nCUDA Version 8.0.61\r\nCommand: python2 retrain.py --image_dir /media/maks/Data/Inspiruj_Photos/img/categories/przedmioty\r\nIts the command from imagenet retraining procedure.\r\ncheers,\r\nMaks\r\n\r\nEDIT: its also python 2.7\r\ncudNN:\r\ncudnnGetVersion() : 7002 , CUDNN_VERSION from cudnn.h : 7002 (7.0.2)\r\nHost compiler version : GCC 5.4.0\r\nThere are 1 CUDA capable devices on your machine :\r\ndevice 0 : sms  4  Capabilities 5.0, SmClock 860.5 Mhz, MemSize (Mb) 2002, MemClock 2505.0 Mhz, Ecc=0, boardGroupID=0\r\n(successfull test)", "@agasparovic , can you advise? Looks like there might be some pathing issue here.", "Hi,\r\n\r\nI cannot reproduce this. Could you please run:\r\npip uninstall tensorflow tensorflow_hub\r\npip install tensorflow==1.8 tensorflow_hub==0.1.0\r\n\r\nand confirm that you are still getting the error?", "Hello,\r\nI did what you said, and I am still getting the error:\r\npython2 retrain.py \r\n\r\nTraceback (most recent call last):\r\n  File \"retrain.py\", line 133, in <module>\r\n    import tensorflow_hub as hub\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_hub/__init__.py\", line 26, in <module>\r\n    from tensorflow_hub.estimator import LatestModuleExporter\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_hub/estimator.py\", line 61, in <module>\r\n    class LatestModuleExporter(tf.estimator.Exporter):\r\nAttributeError: 'module' object has no attribute 'Exporter'", "Ok, so another idea:\r\n\r\n1) Create a file test.py with:\r\n```\r\nimport tensorflow as tf\r\n\r\nprint(tf.__version__)\r\nprint(tf.estimator.Exporter)\r\n```\r\n\r\n2) run `python2 test.py`", "python2 test.py \r\n1.3.0\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 4, in <module>\r\n    print(tf.estimator.Exporter)\r\nAttributeError: 'module' object has no attribute 'Exporter'\r\n\r\nI think I see where the mistake might come from - I have a tensorflow-gpu installed, which has the 1.3.0 version.", "So it seems that your python2 has tensorflow 1.3.0 installed. That hints to a problem with pip.\r\n\r\nA likely reason is that when you do `pip install tensorflow==1.8`, the `pip` is actually `pip3`.\r\n\r\nYou can therefore try:\r\n`pip2 show tensorflow tensorflow-gpu tf-nightly tensorflow-hub`\r\n`pip3 show tensorflow tensorflow-gpu tf-nightly tensorflow-hub`\r\n\r\nIf indeed your `pip` is actually `pip3` (you can check also with `which pip`), you'll have to call `pip2 install tensorflow==1.8 tensorflow_hub==0.1.0`.", "Sorry I missed your last sentence. Yes, that could very well be the issue.", "Hi,\r\nSo this is the pip2 output:\r\n```\r\npip2 show tensorflow tensorflow-gpu tf-nightly tensorflow-h\r\nub\r\nName: tensorflow\r\nVersion: 1.8.0\r\nSummary: TensorFlow helps the tensors flow\r\nHome-page: https://www.tensorflow.org/\r\nAuthor: Google Inc.\r\nAuthor-email: opensource@google.com\r\nLicense: Apache 2.0\r\nLocation: /usr/local/lib/python2.7/dist-packages\r\nRequires: astor, protobuf, gast, tensorboard, six, wheel, absl-py, backports.weakref, termcolor, enum34, numpy, grpcio, mock\r\nRequired-by: \r\n---\r\nName: tensorflow-gpu\r\nVersion: 1.3.0\r\nSummary: TensorFlow helps the tensors flow\r\nHome-page: http://tensorflow.org/\r\nAuthor: Google Inc.\r\nAuthor-email: opensource@google.com\r\nLicense: Apache 2.0\r\nLocation: /home/maks/.local/lib/python2.7/site-packages\r\nRequires: protobuf, six, tensorflow-tensorboard, wheel, backports.weakref, numpy, mock\r\nRequired-by: \r\nName: tensorflow-hub\r\nVersion: 0.1.0\r\nSummary: TensorFlow Hub is a library to foster the publication, discovery, and consumption of reusable parts of machine learning models.\r\nHome-page: https://github.com/tensorflow/hub\r\nAuthor: Google LLC\r\nAuthor-email: opensource@google.com\r\nLicense: Apache 2.0\r\nLocation: /usr/local/lib/python2.7/dist-packages\r\nRequires: protobuf, numpy, six\r\nRequired-by:\r\n```\r\n\r\nand pip3 output:\r\n\r\n```\r\npip3 show tensorflow tensorflow-gpu tf-nightly tensorflow-hub\r\n\r\nMetadata-Version: 2.0\r\nName: tensorflow\r\nVersion: 1.8.0\r\nSummary: TensorFlow helps the tensors flow\r\nHome-page: https://www.tensorflow.org/\r\nAuthor: Google Inc.\r\nAuthor-email: opensource@google.com\r\nInstaller: pip\r\nLicense: Apache 2.0\r\nLocation: /home/maks/.local/lib/python3.5/site-packages\r\nRequires: termcolor, grpcio, absl-py, wheel, gast, astor, numpy, six, protobuf, tensorboard\r\nClassifiers:\r\n  Development Status :: 4 - Beta\r\n  Intended Audience :: Developers\r\n  Intended Audience :: Education\r\n  Intended Audience :: Science/Research\r\n  License :: OSI Approved :: Apache Software License\r\n  Programming Language :: Python :: 2\r\n  Programming Language :: Python :: 2.7\r\n  Programming Language :: Python :: 3\r\n  Programming Language :: Python :: 3.4\r\n  Programming Language :: Python :: 3.5\r\n  Programming Language :: Python :: 3.6\r\n  Topic :: Scientific/Engineering\r\n  Topic :: Scientific/Engineering :: Mathematics\r\n  Topic :: Scientific/Engineering :: Artificial Intelligence\r\n  Topic :: Software Development\r\n  Topic :: Software Development :: Libraries\r\n  Topic :: Software Development :: Libraries :: Python Modules\r\nEntry-points:\r\n  [console_scripts]\r\n  freeze_graph = tensorflow.python.tools.freeze_graph:run_main\r\n  saved_model_cli = tensorflow.python.tools.saved_model_cli:main\r\n  tensorboard = tensorboard.main:run_main\r\n  toco = tensorflow.contrib.lite.toco.python.toco_wrapper:main\r\n  toco_from_protos = tensorflow.contrib.lite.toco.python.toco_from_protos:main\r\nYou are using pip version 8.1.1, however version 10.0.1 is available.\r\nYou should consider upgrading via the 'pip install --upgrade pip' command.`\r\n\r\n```\r\nFrom that I understand that for python 2 everything should be correctly installed, shouldn't it?\r\nEDIT: I run the test you supplied with python3 and it successfully ran, so everything should work with python3. The problem is I don't have the gpu-support for that version.", "The problem is that `import tensorflow` is importing tensorflow_gpu. If you have both tensorflow and tensorflow_gpu pip packages, which one will be imported by `import tensorflow` is undefined.\r\n\r\nThe correct way to fix it would be:\r\n1) decide whether to keep tensorflow or tensorflow_gpu, so for example tensorflow_gpu\r\n2) `pip2 uninstall tensorflow`\r\n3) `pip2 install tensorflow_gpu`\r\n", "Ok, but I still get the \r\n```\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 4, in <module>\r\n    print(tf.estimator.Exporter)\r\nAttributeError: 'module' object has no attribute 'Exporter'\r\n```\r\nerror, after I have uninstalled the tensorflow. Is there any way to make it run with the gpu accelerated version?", "You should have the latest tensorflow-gpu installed, so maybe `pip2 install tensorflow-gpu==1.8`?\r\n\r\nThen \r\n`pip2 show tensorflow-gpu`\r\n\r\nshould give:\r\n```\r\nName: tensorflow-gpu\r\nVersion: 1.8.0\r\n```", "Thanks. Latest version solved the issue."]}, {"number": 18888, "title": "[Intel MKL] Reverting changes from 495d511 that break install_pip_packages.sh in \u2026", "body": "\u2026Ubuntu 16.04 containers, causing nightly mkl ci builds to fail. The comments indicate that easy_install is not required in Ubuntu 16.04, but `pip2 install --upgrade pip==9.0.3` fails in nightly mkl CI builds:\r\n\r\n> 22:19:04 Step 7/13 : RUN /install/install_pip_packages.sh\r\n> 22:19:04  ---> Running in c508335088ed\r\n> 22:19:05 /install/install_pip_packages.sh: line 25: pip2: command not found\r\n> 22:19:05 The command '/bin/sh -c /install/install_pip_packages.sh' returned a non-zero code: 127\r\n\r\nSee http://ci.tensorflow.org/view/Nightly/job/nightly-mkl/198/console", "comments": ["@gunan Can you take a look at this? ", "I think this is a problem in dockerfiles not having pip installed on them.\r\nThese scripts will be deleted soon in favor of just using the devel dockerfiles we have.\r\nBut if this can get us through this issue, I think it is OK to submit now."]}, {"number": 18887, "title": "TypeError: Input 'input_sizes' of 'Conv3DBackpropInputV2' Op has type int64 that does not match expected type of int32", "body": "Please go to Stack Overflow for help and support:\r\ndeconv_shape1 = layer3.get_shape()\r\n    de_W1 = tf.Variable(tf.truncated_normal(shape=(4, 4, 4, deconv_shape1[4].value, 2), mean = mu, stddev = sigma))\r\n    de_b1 = tf.Variable(tf.zeros(deconv_shape1[4].value))\r\n    output_shape=x.get_shape().as_list()\r\n    output_shape[1] *= 2\r\n    output_shape[2] *= 2\r\n    output_shape[3] *= 2 \r\n    output_shape[4] = deconv_shape1[4].value\r\n    output_shape=np.asarray(output_shape)\r\n    output_shape=tf.convert_to_tensor(output_shape)\r\n    print(type(output_shape))\r\n    x = tf.nn.conv3d_transpose(x, de_W1, output_shape, strides=[1, 2, 2, 2, 1], padding=\"SAME\")\r\n    x = tf.nn.bias_add(x,de_b1)\r\n    first_down_layer=x\r\n\r\nI am getting these error on tensorflow 1.4 and python 2.7. The above code works fine on tensorflow 1.7 and python 3.6. I am a  newbie to tensorflow, please help ?\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["Nagging Assignee @aselle: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "It might be easier if you could provide the self-contained reproducible example code, as the code snippet in the issue is not self-contained.\r\n\r\nThe issue is that tf.nn.conv3d_transpose only support int32 type of output_shape. But the np.asarray(output_shape) by default will return int64 dtype.\r\n\r\nCreated a PR #19248 to have int64 support for `output_shape`."]}, {"number": 18886, "title": "Master branch fails to build", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Mint 18.2 Sonya (based on Ubuntu 16.04)\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: Github master (most recent commit: adf045607cc4126366ebb84ee2109f88c6ab25f)\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: 0.12.0\r\n- **GCC/Compiler version (if compiling from source)**: 7.3.0 (6.4.0 used for CUDA compiler)\r\n- **CUDA/cuDNN version**: CUDA 9.1, cuDNN 7.1, NCCL 2.1\r\n- **GPU model and memory**: GTX1080Ti 11GB\r\n- **Exact command to reproduce**: bazel build --config=opt --config=cuda //tensorflow/tools/... --verbose_failures\r\n\r\n```\r\n$ cat .tf_configure.bazelrc\r\nbuild --action_env PYTHON_BIN_PATH=\"/usr/bin/python3\"\r\nbuild --action_env PYTHON_LIB_PATH=\"/usr/local/lib/python3.5/dist-packages\"\r\nbuild --force_python=py3\r\nbuild --host_force_python=py3\r\nbuild --python_path=\"/usr/bin/python3\"\r\nbuild:gcp --define with_gcp_support=true\r\nbuild:hdfs --define with_hdfs_support=true\r\nbuild:s3 --define with_s3_support=true\r\nbuild:kafka --define with_kafka_support=true\r\nbuild:xla --define with_xla_support=true\r\nbuild:gdr --define with_gdr_support=true\r\nbuild:verbs --define with_verbs_support=true\r\nbuild --action_env TF_NEED_OPENCL_SYCL=\"0\"\r\nbuild --action_env TF_NEED_CUDA=\"1\"\r\nbuild --action_env CUDA_TOOLKIT_PATH=\"/usr/local/cuda\"\r\nbuild --action_env TF_CUDA_VERSION=\"9.1\"\r\nbuild --action_env CUDNN_INSTALL_PATH=\"/usr/local/cuda-9.1\"\r\nbuild --action_env TF_CUDNN_VERSION=\"7\"\r\nbuild --action_env NCCL_INSTALL_PATH=\"/usr/local/cuda-9.1\"\r\nbuild --action_env TF_NCCL_VERSION=\"2\"\r\nbuild --action_env TF_CUDA_COMPUTE_CAPABILITIES=\"6.1\"\r\nbuild --action_env LD_LIBRARY_PATH=\":/usr/local/cuda/extras/CUPTI/lib:/usr/local/cuda/extras/CUPTI/lib\"\r\nbuild --action_env TF_CUDA_CLANG=\"0\"\r\nbuild --action_env GCC_HOST_COMPILER_PATH=\"/usr/bin/gcc-6\"\r\nbuild --config=cuda\r\ntest --config=cuda\r\nbuild --define grpc_no_ares=true\r\nbuild:opt --copt=-march=native\r\nbuild:opt --copt=-mtune=native\r\nbuild:opt --host_copt=-march=native\r\nbuild:opt --define with_default_optimizations=true\r\nbuild --copt=-DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK\r\nbuild --host_copt=-DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK\r\n```\r\n\r\n### Describe the problem\r\nBuild experiences linker errors while building `tensorflow/tools/api/lib`.\r\n\r\n### Source code / logs\r\nOutput from build\r\n```\r\nERROR: /home/bidski/Projects/tensorflow/tensorflow/tools/api/lib/BUILD:14:1: Linking of rule '//tensorflow/tools/api/lib:api_objects_proto_cc' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command \r\n  (cd /home/bidski/.cache/bazel/_bazel_bidski/f3205cee2972cb6d709c5d3c6ebef87c/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    CUDA_TOOLKIT_PATH=/usr/local/cuda \\\r\n    CUDNN_INSTALL_PATH=/usr/local/cuda-9.1 \\\r\n    GCC_HOST_COMPILER_PATH=/usr/bin/gcc-6 \\\r\n    LD_LIBRARY_PATH=:/usr/local/cuda/extras/CUPTI/lib:/usr/local/cuda/extras/CUPTI/lib \\\r\n    NCCL_INSTALL_PATH=/usr/local/cuda-9.1 \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/usr/bin/python3 \\\r\n    PYTHON_LIB_PATH=/usr/local/lib/python3.5/dist-packages \\\r\n    TF_CUDA_CLANG=0 \\\r\n    TF_CUDA_COMPUTE_CAPABILITIES=6.1 \\\r\n    TF_CUDA_VERSION=9.1 \\\r\n    TF_CUDNN_VERSION=7 \\\r\n    TF_NCCL_VERSION=2 \\\r\n    TF_NEED_CUDA=1 \\\r\n    TF_NEED_OPENCL_SYCL=0 \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -shared -o bazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/libapi_objects_proto_cc.so -Wl,-no-as-needed -B/usr/bin/ -pie -Wl,-z,relro,-z,now -no-canonical-prefixes -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,--gc-sections -Wl,@bazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/libapi_objects_proto_cc.so-2.params)\r\n/usr/lib/gcc/x86_64-linux-gnu/6/../../../x86_64-linux-gnu/Scrt1.o: In function `_start':\r\n(.text+0x20): undefined reference to `main'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `void google::protobuf::internal::arena_destruct_object<google::protobuf::internal::InternalMetadataWithArenaBase<google::protobuf::UnknownFieldSet, google::protobuf::internal::InternalMetadataWithArena>::Container>(void*)':\r\napi_objects.pb.cc:(.text._ZN6google8protobuf8internal21arena_destruct_objectINS1_29InternalMetadataWithArenaBaseINS0_15UnknownFieldSetENS1_25InternalMetadataWithArenaEE9ContainerEEEvPv[_ZN6google8protobuf8internal21arena_destruct_objectINS1_29InternalMetadataWithArenaBaseINS0_15UnknownFieldSetENS1_25InternalMetadataWithArenaEE9ContainerEEEvPv]+0xc): undefined reference to `google::protobuf::UnknownFieldSet::ClearFallback()'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIMember::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const':\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api11TFAPIMember24SerializeWithCachedSizesEPN6google8protobuf2io17CodedOutputStreamE+0x6d): undefined reference to `google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, google::protobuf::io::CodedOutputStream*)'\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api11TFAPIMember24SerializeWithCachedSizesEPN6google8protobuf2io17CodedOutputStreamE+0x85): undefined reference to `google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, google::protobuf::io::CodedOutputStream*)'\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api11TFAPIMember24SerializeWithCachedSizesEPN6google8protobuf2io17CodedOutputStreamE+0x52): undefined reference to `google::protobuf::internal::WireFormat::SerializeUnknownFields(google::protobuf::UnknownFieldSet const&, google::protobuf::io::CodedOutputStream*)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIMethod::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const':\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api11TFAPIMethod24SerializeWithCachedSizesEPN6google8protobuf2io17CodedOutputStreamE+0x6e): undefined reference to `google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, google::protobuf::io::CodedOutputStream*)'\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api11TFAPIMethod24SerializeWithCachedSizesEPN6google8protobuf2io17CodedOutputStreamE+0x86): undefined reference to `google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, google::protobuf::io::CodedOutputStream*)'\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api11TFAPIMethod24SerializeWithCachedSizesEPN6google8protobuf2io17CodedOutputStreamE+0x9d): undefined reference to `google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, google::protobuf::io::CodedOutputStream*)'\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api11TFAPIMethod24SerializeWithCachedSizesEPN6google8protobuf2io17CodedOutputStreamE+0x52): undefined reference to `google::protobuf::internal::WireFormat::SerializeUnknownFields(google::protobuf::UnknownFieldSet const&, google::protobuf::io::CodedOutputStream*)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIMember::InternalSerializeWithCachedSizesToArray(bool, unsigned char*) const':\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api11TFAPIMember39InternalSerializeWithCachedSizesToArrayEbPh+0x4c): undefined reference to `google::protobuf::io::CodedOutputStream::WriteStringWithSizeToArray(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, unsigned char*)'\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api11TFAPIMember39InternalSerializeWithCachedSizesToArrayEbPh+0x64): undefined reference to `google::protobuf::io::CodedOutputStream::WriteStringWithSizeToArray(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, unsigned char*)'\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api11TFAPIMember39InternalSerializeWithCachedSizesToArrayEbPh+0x3c): undefined reference to `google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(google::protobuf::UnknownFieldSet const&, unsigned char*)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIMethod::InternalSerializeWithCachedSizesToArray(bool, unsigned char*) const':\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api11TFAPIMethod39InternalSerializeWithCachedSizesToArrayEbPh+0x4d): undefined reference to `google::protobuf::io::CodedOutputStream::WriteStringWithSizeToArray(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, unsigned char*)'\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api11TFAPIMethod39InternalSerializeWithCachedSizesToArrayEbPh+0x65): undefined reference to `google::protobuf::io::CodedOutputStream::WriteStringWithSizeToArray(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, unsigned char*)'\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api11TFAPIMethod39InternalSerializeWithCachedSizesToArrayEbPh+0x7c): undefined reference to `google::protobuf::io::CodedOutputStream::WriteStringWithSizeToArray(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, unsigned char*)'\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api11TFAPIMethod39InternalSerializeWithCachedSizesToArrayEbPh+0x3c): undefined reference to `google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(google::protobuf::UnknownFieldSet const&, unsigned char*)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIMember::ByteSizeLong() const':\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api11TFAPIMember12ByteSizeLongEv+0x85): undefined reference to `google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(google::protobuf::UnknownFieldSet const&)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIMethod::ByteSizeLong() const':\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api11TFAPIMethod12ByteSizeLongEv+0xb5): undefined reference to `google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(google::protobuf::UnknownFieldSet const&)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIObject::ByteSizeLong() const':\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api11TFAPIObject12ByteSizeLongEv+0x9d): undefined reference to `google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(google::protobuf::UnknownFieldSet const&)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIModule::ByteSizeLong() const':\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api11TFAPIModule12ByteSizeLongEv+0xc5): undefined reference to `google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(google::protobuf::UnknownFieldSet const&)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIClass::ByteSizeLong() const':\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api10TFAPIClass12ByteSizeLongEv+0x115): undefined reference to `google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(google::protobuf::UnknownFieldSet const&)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIObject::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const':\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api11TFAPIObject24SerializeWithCachedSizesEPN6google8protobuf2io17CodedOutputStreamE+0x6e): undefined reference to `google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(int, google::protobuf::MessageLite const&, google::protobuf::io::CodedOutputStream*)'\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api11TFAPIObject24SerializeWithCachedSizesEPN6google8protobuf2io17CodedOutputStreamE+0x86): undefined reference to `google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(int, google::protobuf::MessageLite const&, google::protobuf::io::CodedOutputStream*)'\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api11TFAPIObject24SerializeWithCachedSizesEPN6google8protobuf2io17CodedOutputStreamE+0x9d): undefined reference to `google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, google::protobuf::io::CodedOutputStream*)'\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api11TFAPIObject24SerializeWithCachedSizesEPN6google8protobuf2io17CodedOutputStreamE+0x52): undefined reference to `google::protobuf::internal::WireFormat::SerializeUnknownFields(google::protobuf::UnknownFieldSet const&, google::protobuf::io::CodedOutputStream*)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIModule::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const':\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api11TFAPIModule24SerializeWithCachedSizesEPN6google8protobuf2io17CodedOutputStreamE+0x39): undefined reference to `google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(int, google::protobuf::MessageLite const&, google::protobuf::io::CodedOutputStream*)'\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api11TFAPIModule24SerializeWithCachedSizesEPN6google8protobuf2io17CodedOutputStreamE+0x69): undefined reference to `google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(int, google::protobuf::MessageLite const&, google::protobuf::io::CodedOutputStream*)'\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api11TFAPIModule24SerializeWithCachedSizesEPN6google8protobuf2io17CodedOutputStreamE+0xa0): undefined reference to `google::protobuf::internal::WireFormat::SerializeUnknownFields(google::protobuf::UnknownFieldSet const&, google::protobuf::io::CodedOutputStream*)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIClass::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const':\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api10TFAPIClass24SerializeWithCachedSizesEPN6google8protobuf2io17CodedOutputStreamE+0x39): undefined reference to `google::protobuf::internal::WireFormatLite::WriteString(int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, google::protobuf::io::CodedOutputStream*)'\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api10TFAPIClass24SerializeWithCachedSizesEPN6google8protobuf2io17CodedOutputStreamE+0x69): undefined reference to `google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(int, google::protobuf::MessageLite const&, google::protobuf::io::CodedOutputStream*)'\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api10TFAPIClass24SerializeWithCachedSizesEPN6google8protobuf2io17CodedOutputStreamE+0x99): undefined reference to `google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(int, google::protobuf::MessageLite const&, google::protobuf::io::CodedOutputStream*)'\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api10TFAPIClass24SerializeWithCachedSizesEPN6google8protobuf2io17CodedOutputStreamE+0xd0): undefined reference to `google::protobuf::internal::WireFormat::SerializeUnknownFields(google::protobuf::UnknownFieldSet const&, google::protobuf::io::CodedOutputStream*)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIModule::InternalSerializeWithCachedSizesToArray(bool, unsigned char*) const':\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api11TFAPIModule39InternalSerializeWithCachedSizesToArrayEbPh+0x168): undefined reference to `google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(google::protobuf::UnknownFieldSet const&, unsigned char*)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIClass::InternalSerializeWithCachedSizesToArray(bool, unsigned char*) const':\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api10TFAPIClass39InternalSerializeWithCachedSizesToArrayEbPh+0x48): undefined reference to `google::protobuf::io::CodedOutputStream::WriteStringWithSizeToArray(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, unsigned char*)'\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api10TFAPIClass39InternalSerializeWithCachedSizesToArrayEbPh+0x1a8): undefined reference to `google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(google::protobuf::UnknownFieldSet const&, unsigned char*)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIObject::InternalSerializeWithCachedSizesToArray(bool, unsigned char*) const':\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api11TFAPIObject39InternalSerializeWithCachedSizesToArrayEbPh+0x13c): undefined reference to `google::protobuf::io::CodedOutputStream::WriteStringWithSizeToArray(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, unsigned char*)'\r\napi_objects.pb.cc:(.text._ZNK11third_party10tensorflow5tools3api11TFAPIObject39InternalSerializeWithCachedSizesToArrayEbPh+0x6e): undefined reference to `google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(google::protobuf::UnknownFieldSet const&, unsigned char*)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `void google::protobuf::internal::RepeatedPtrFieldBase::MergeFromInnerLoop<google::protobuf::RepeatedPtrField<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >::TypeHandler>(void**, void**, int, int)':\r\napi_objects.pb.cc:(.text._ZN6google8protobuf8internal20RepeatedPtrFieldBase18MergeFromInnerLoopINS0_16RepeatedPtrFieldINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEE11TypeHandlerEEEvPPvSE_ii[_ZN6google8protobuf8internal20RepeatedPtrFieldBase18MergeFromInnerLoopINS0_16RepeatedPtrFieldINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEE11TypeHandlerEEEvPPvSE_ii]+0x90): undefined reference to `google::protobuf::internal::ArenaImpl::AllocateAlignedAndAddCleanup(unsigned long, void (*)(void*))'\r\napi_objects.pb.cc:(.text._ZN6google8protobuf8internal20RepeatedPtrFieldBase18MergeFromInnerLoopINS0_16RepeatedPtrFieldINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEE11TypeHandlerEEEvPPvSE_ii[_ZN6google8protobuf8internal20RepeatedPtrFieldBase18MergeFromInnerLoopINS0_16RepeatedPtrFieldINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEE11TypeHandlerEEEvPPvSE_ii]+0xfa): undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto::InitDefaultsTFAPIMember()':\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto23InitDefaultsTFAPIMemberEv+0x26): undefined reference to `vtable for google::protobuf::internal::FunctionClosure0'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto23InitDefaultsTFAPIMemberEv+0x45): undefined reference to `google::protobuf::GoogleOnceInitImpl(long*, google::protobuf::Closure*)'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto23InitDefaultsTFAPIMemberEv+0x4d): undefined reference to `google::protobuf::internal::FunctionClosure0::~FunctionClosure0()'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto23InitDefaultsTFAPIMemberEv+0x65): undefined reference to `google::protobuf::internal::FunctionClosure0::~FunctionClosure0()'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto::InitDefaultsTFAPIMethod()':\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto23InitDefaultsTFAPIMethodEv+0x26): undefined reference to `vtable for google::protobuf::internal::FunctionClosure0'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto23InitDefaultsTFAPIMethodEv+0x45): undefined reference to `google::protobuf::GoogleOnceInitImpl(long*, google::protobuf::Closure*)'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto23InitDefaultsTFAPIMethodEv+0x4d): undefined reference to `google::protobuf::internal::FunctionClosure0::~FunctionClosure0()'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto23InitDefaultsTFAPIMethodEv+0x65): undefined reference to `google::protobuf::internal::FunctionClosure0::~FunctionClosure0()'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto::InitDefaultsTFAPIModule()':\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto23InitDefaultsTFAPIModuleEv+0x26): undefined reference to `vtable for google::protobuf::internal::FunctionClosure0'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto23InitDefaultsTFAPIModuleEv+0x45): undefined reference to `google::protobuf::GoogleOnceInitImpl(long*, google::protobuf::Closure*)'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto23InitDefaultsTFAPIModuleEv+0x4d): undefined reference to `google::protobuf::internal::FunctionClosure0::~FunctionClosure0()'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto23InitDefaultsTFAPIModuleEv+0x65): undefined reference to `google::protobuf::internal::FunctionClosure0::~FunctionClosure0()'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto::InitDefaultsTFAPIClass()':\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto22InitDefaultsTFAPIClassEv+0x26): undefined reference to `vtable for google::protobuf::internal::FunctionClosure0'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto22InitDefaultsTFAPIClassEv+0x45): undefined reference to `google::protobuf::GoogleOnceInitImpl(long*, google::protobuf::Closure*)'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto22InitDefaultsTFAPIClassEv+0x4d): undefined reference to `google::protobuf::internal::FunctionClosure0::~FunctionClosure0()'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto22InitDefaultsTFAPIClassEv+0x65): undefined reference to `google::protobuf::internal::FunctionClosure0::~FunctionClosure0()'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto::InitDefaultsTFAPIObject()':\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto23InitDefaultsTFAPIObjectEv+0x26): undefined reference to `vtable for google::protobuf::internal::FunctionClosure0'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto23InitDefaultsTFAPIObjectEv+0x45): undefined reference to `google::protobuf::GoogleOnceInitImpl(long*, google::protobuf::Closure*)'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto23InitDefaultsTFAPIObjectEv+0x4d): undefined reference to `google::protobuf::internal::FunctionClosure0::~FunctionClosure0()'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto23InitDefaultsTFAPIObjectEv+0x65): undefined reference to `google::protobuf::internal::FunctionClosure0::~FunctionClosure0()'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto::AddDescriptorsImpl()':\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto18AddDescriptorsImplEv+0x2a): undefined reference to `google::protobuf::DescriptorPool::InternalAddGeneratedFile(void const*, int)'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto18AddDescriptorsImplEv+0x3e): undefined reference to `google::protobuf::MessageFactory::InternalRegisterGeneratedFile(char const*, void (*)(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&))'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto::protobuf_AssignDescriptorsOnce()':\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto30protobuf_AssignDescriptorsOnceEv+0x26): undefined reference to `vtable for google::protobuf::internal::FunctionClosure0'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto30protobuf_AssignDescriptorsOnceEv+0x45): undefined reference to `google::protobuf::GoogleOnceInitImpl(long*, google::protobuf::Closure*)'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto30protobuf_AssignDescriptorsOnceEv+0x4d): undefined reference to `google::protobuf::internal::FunctionClosure0::~FunctionClosure0()'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto30protobuf_AssignDescriptorsOnceEv+0x65): undefined reference to `google::protobuf::internal::FunctionClosure0::~FunctionClosure0()'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto::protobuf_RegisterTypes(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)':\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto22protobuf_RegisterTypesERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x17): undefined reference to `google::protobuf::internal::RegisterAllTypes(google::protobuf::Metadata const*, int)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto::AddDescriptors()':\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto14AddDescriptorsEv+0x26): undefined reference to `vtable for google::protobuf::internal::FunctionClosure0'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto14AddDescriptorsEv+0x45): undefined reference to `google::protobuf::GoogleOnceInitImpl(long*, google::protobuf::Closure*)'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto14AddDescriptorsEv+0x4d): undefined reference to `google::protobuf::internal::FunctionClosure0::~FunctionClosure0()'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto14AddDescriptorsEv+0x65): undefined reference to `google::protobuf::internal::FunctionClosure0::~FunctionClosure0()'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto::protobuf_AssignDescriptors()':\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto26protobuf_AssignDescriptorsEv+0x68): undefined reference to `google::protobuf::internal::AssignDescriptors(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, google::protobuf::internal::MigrationSchema const*, google::protobuf::Message const* const*, unsigned int const*, google::protobuf::MessageFactory*, google::protobuf::Metadata*, google::protobuf::EnumDescriptor const**, google::protobuf::ServiceDescriptor const**)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIMember::SharedCtor()':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMember10SharedCtorEv+0x3): undefined reference to `google::protobuf::internal::fixed_address_empty_string[abi:cxx11]'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIMember::SharedDtor()':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMember10SharedDtorEv+0x17): undefined reference to `google::protobuf::internal::fixed_address_empty_string[abi:cxx11]'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIMember::~TFAPIMember()':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMemberD2Ev+0x47): undefined reference to `google::protobuf::UnknownFieldSet::ClearFallback()'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIMethod::SharedCtor()':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMethod10SharedCtorEv+0x3): undefined reference to `google::protobuf::internal::fixed_address_empty_string[abi:cxx11]'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIMethod::SharedDtor()':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMethod10SharedDtorEv+0x17): undefined reference to `google::protobuf::internal::fixed_address_empty_string[abi:cxx11]'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIMethod::~TFAPIMethod()':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMethodD2Ev+0x47): undefined reference to `google::protobuf::UnknownFieldSet::ClearFallback()'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIModule::~TFAPIModule()':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIModuleD2Ev+0x6a): undefined reference to `google::protobuf::UnknownFieldSet::ClearFallback()'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIClass::~TFAPIClass()':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api10TFAPIClassD2Ev+0x72): undefined reference to `google::protobuf::UnknownFieldSet::ClearFallback()'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIObject::SharedCtor()':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIObject10SharedCtorEv+0x3): undefined reference to `google::protobuf::internal::fixed_address_empty_string[abi:cxx11]'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIObject::SharedDtor()':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIObject10SharedDtorEv+0xe): undefined reference to `google::protobuf::internal::fixed_address_empty_string[abi:cxx11]'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIObject::~TFAPIObject()':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIObjectD2Ev+0x47): undefined reference to `google::protobuf::UnknownFieldSet::ClearFallback()'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `google::protobuf::internal::InternalMetadataWithArenaBase<google::protobuf::UnknownFieldSet, google::protobuf::internal::InternalMetadataWithArena>::~InternalMetadataWithArenaBase()':\r\napi_objects.pb.cc:(.text._ZN6google8protobuf8internal29InternalMetadataWithArenaBaseINS0_15UnknownFieldSetENS1_25InternalMetadataWithArenaEED2Ev[_ZN6google8protobuf8internal29InternalMetadataWithArenaBaseINS0_15UnknownFieldSetENS1_25InternalMetadataWithArenaEED5Ev]+0x3a): undefined reference to `google::protobuf::UnknownFieldSet::ClearFallback()'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto::InitDefaultsTFAPIMemberImpl()':\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto27InitDefaultsTFAPIMemberImplEv+0x1b): undefined reference to `google::protobuf::internal::VerifyVersion(int, int, char const*)'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto27InitDefaultsTFAPIMemberImplEv+0x20): undefined reference to `google::protobuf::internal::InitProtobufDefaults()'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto27InitDefaultsTFAPIMemberImplEv+0x37): undefined reference to `google::protobuf::internal::OnShutdownDestroyMessage(void const*)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto::InitDefaultsTFAPIMethodImpl()':\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto27InitDefaultsTFAPIMethodImplEv+0x1b): undefined reference to `google::protobuf::internal::VerifyVersion(int, int, char const*)'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto27InitDefaultsTFAPIMethodImplEv+0x20): undefined reference to `google::protobuf::internal::InitProtobufDefaults()'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto27InitDefaultsTFAPIMethodImplEv+0x37): undefined reference to `google::protobuf::internal::OnShutdownDestroyMessage(void const*)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto::InitDefaultsTFAPIObjectImpl()':\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto27InitDefaultsTFAPIObjectImplEv+0x1b): undefined reference to `google::protobuf::internal::VerifyVersion(int, int, char const*)'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto27InitDefaultsTFAPIObjectImplEv+0x20): undefined reference to `google::protobuf::internal::InitProtobufDefaults()'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto27InitDefaultsTFAPIObjectImplEv+0x41): undefined reference to `google::protobuf::internal::OnShutdownDestroyMessage(void const*)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto::InitDefaultsTFAPIModuleImpl()':\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto27InitDefaultsTFAPIModuleImplEv+0x1b): undefined reference to `google::protobuf::internal::VerifyVersion(int, int, char const*)'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto27InitDefaultsTFAPIModuleImplEv+0x20): undefined reference to `google::protobuf::internal::InitProtobufDefaults()'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto27InitDefaultsTFAPIModuleImplEv+0x41): undefined reference to `google::protobuf::internal::OnShutdownDestroyMessage(void const*)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto::InitDefaultsTFAPIClassImpl()':\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto26InitDefaultsTFAPIClassImplEv+0x1b): undefined reference to `google::protobuf::internal::VerifyVersion(int, int, char const*)'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto26InitDefaultsTFAPIClassImplEv+0x20): undefined reference to `google::protobuf::internal::InitProtobufDefaults()'\r\napi_objects.pb.cc:(.text._ZN63protobuf_tensorflow_2ftools_2fapi_2flib_2fapi_5fobjects_2eproto26InitDefaultsTFAPIClassImplEv+0x41): undefined reference to `google::protobuf::internal::OnShutdownDestroyMessage(void const*)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `void google::protobuf::Arena::Own<third_party::tensorflow::tools::api::TFAPIMember>(third_party::tensorflow::tools::api::TFAPIMember*)':\r\napi_objects.pb.cc:(.text._ZN6google8protobuf5Arena3OwnIN11third_party10tensorflow5tools3api11TFAPIMemberEEEvPT_[_ZN6google8protobuf5Arena3OwnIN11third_party10tensorflow5tools3api11TFAPIMemberEEEvPT_]+0x12): undefined reference to `google::protobuf::internal::ArenaImpl::AddCleanup(void*, void (*)(void*))'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `void google::protobuf::Arena::Own<third_party::tensorflow::tools::api::TFAPIMethod>(third_party::tensorflow::tools::api::TFAPIMethod*)':\r\napi_objects.pb.cc:(.text._ZN6google8protobuf5Arena3OwnIN11third_party10tensorflow5tools3api11TFAPIMethodEEEvPT_[_ZN6google8protobuf5Arena3OwnIN11third_party10tensorflow5tools3api11TFAPIMethodEEEvPT_]+0x12): undefined reference to `google::protobuf::internal::ArenaImpl::AddCleanup(void*, void (*)(void*))'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `void google::protobuf::Arena::Own<third_party::tensorflow::tools::api::TFAPIModule>(third_party::tensorflow::tools::api::TFAPIModule*)':\r\napi_objects.pb.cc:(.text._ZN6google8protobuf5Arena3OwnIN11third_party10tensorflow5tools3api11TFAPIModuleEEEvPT_[_ZN6google8protobuf5Arena3OwnIN11third_party10tensorflow5tools3api11TFAPIModuleEEEvPT_]+0x12): undefined reference to `google::protobuf::internal::ArenaImpl::AddCleanup(void*, void (*)(void*))'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `void google::protobuf::Arena::Own<third_party::tensorflow::tools::api::TFAPIClass>(third_party::tensorflow::tools::api::TFAPIClass*)':\r\napi_objects.pb.cc:(.text._ZN6google8protobuf5Arena3OwnIN11third_party10tensorflow5tools3api10TFAPIClassEEEvPT_[_ZN6google8protobuf5Arena3OwnIN11third_party10tensorflow5tools3api10TFAPIClassEEEvPT_]+0x12): undefined reference to `google::protobuf::internal::ArenaImpl::AddCleanup(void*, void (*)(void*))'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `void google::protobuf::Arena::Own<third_party::tensorflow::tools::api::TFAPIObject>(third_party::tensorflow::tools::api::TFAPIObject*)':\r\napi_objects.pb.cc:(.text._ZN6google8protobuf5Arena3OwnIN11third_party10tensorflow5tools3api11TFAPIObjectEEEvPT_[_ZN6google8protobuf5Arena3OwnIN11third_party10tensorflow5tools3api11TFAPIObjectEEEvPT_]+0x12): undefined reference to `google::protobuf::internal::ArenaImpl::AddCleanup(void*, void (*)(void*))'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `google::protobuf::internal::InternalMetadataWithArenaBase<google::protobuf::UnknownFieldSet, google::protobuf::internal::InternalMetadataWithArena>::mutable_unknown_fields_slow()':\r\napi_objects.pb.cc:(.text._ZN6google8protobuf8internal29InternalMetadataWithArenaBaseINS0_15UnknownFieldSetENS1_25InternalMetadataWithArenaEE27mutable_unknown_fields_slowEv[_ZN6google8protobuf8internal29InternalMetadataWithArenaBaseINS0_15UnknownFieldSetENS1_25InternalMetadataWithArenaEE27mutable_unknown_fields_slowEv]+0x38): undefined reference to `google::protobuf::internal::ArenaImpl::AllocateAlignedAndAddCleanup(unsigned long, void (*)(void*))'\r\napi_objects.pb.cc:(.text._ZN6google8protobuf8internal29InternalMetadataWithArenaBaseINS0_15UnknownFieldSetENS1_25InternalMetadataWithArenaEE27mutable_unknown_fields_slowEv[_ZN6google8protobuf8internal29InternalMetadataWithArenaBaseINS0_15UnknownFieldSetENS1_25InternalMetadataWithArenaEE27mutable_unknown_fields_slowEv]+0xa0): undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIMethod::Clear()':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMethod5ClearEv+0x6c): undefined reference to `google::protobuf::UnknownFieldSet::ClearFallback()'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIMember::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*)':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMember27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x75): undefined reference to `google::protobuf::internal::WireFormat::SkipField(google::protobuf::io::CodedInputStream*, unsigned int, google::protobuf::UnknownFieldSet*)'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMember27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x96): undefined reference to `google::protobuf::io::CodedInputStream::ReadTagFallback(unsigned int)'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMember27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0xd0): undefined reference to `google::protobuf::internal::fixed_address_empty_string[abi:cxx11]'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMember27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0xda): undefined reference to `google::protobuf::internal::WireFormatLite::ReadBytes(google::protobuf::io::CodedInputStream*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*)'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMember27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x11b): undefined reference to `google::protobuf::internal::fixed_address_empty_string[abi:cxx11]'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIMethod::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*)':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMethod27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x83): undefined reference to `google::protobuf::internal::WireFormat::SkipField(google::protobuf::io::CodedInputStream*, unsigned int, google::protobuf::UnknownFieldSet*)'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMethod27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0xa6): undefined reference to `google::protobuf::io::CodedInputStream::ReadTagFallback(unsigned int)'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMethod27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0xe0): undefined reference to `google::protobuf::internal::fixed_address_empty_string[abi:cxx11]'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMethod27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x10c): undefined reference to `google::protobuf::internal::fixed_address_empty_string[abi:cxx11]'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMethod27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x134): undefined reference to `google::protobuf::internal::fixed_address_empty_string[abi:cxx11]'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMethod27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x13e): undefined reference to `google::protobuf::internal::WireFormatLite::ReadBytes(google::protobuf::io::CodedInputStream*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIObject::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*)':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIObject27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x69): undefined reference to `google::protobuf::internal::WireFormat::SkipField(google::protobuf::io::CodedInputStream*, unsigned int, google::protobuf::UnknownFieldSet*)'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIObject27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x8a): undefined reference to `google::protobuf::io::CodedInputStream::ReadTagFallback(unsigned int)'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIObject27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0xc3): undefined reference to `google::protobuf::internal::fixed_address_empty_string[abi:cxx11]'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIObject27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0xd1): undefined reference to `google::protobuf::internal::WireFormatLite::ReadBytes(google::protobuf::io::CodedInputStream*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*)'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIObject27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x15e): undefined reference to `google::protobuf::io::CodedInputStream::ReadVarintSizeAsIntFallback()'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIObject27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x170): undefined reference to `google::protobuf::io::CodedInputStream::IncrementRecursionDepthAndPushLimit(int)'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIObject27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x1a2): undefined reference to `google::protobuf::io::CodedInputStream::DecrementRecursionDepthAndPopLimit(int)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIModule::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*)':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIModule27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x66): undefined reference to `google::protobuf::internal::WireFormat::SkipField(google::protobuf::io::CodedInputStream*, unsigned int, google::protobuf::UnknownFieldSet*)'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIModule27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x8b): undefined reference to `google::protobuf::io::CodedInputStream::ReadTagFallback(unsigned int)'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIModule27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x115): undefined reference to `google::protobuf::internal::ArenaImpl::AllocateAlignedAndAddCleanup(unsigned long, void (*)(void*))'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIModule27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x167): undefined reference to `google::protobuf::io::CodedInputStream::ReadVarintSizeAsIntFallback()'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIModule27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x17d): undefined reference to `google::protobuf::io::CodedInputStream::IncrementRecursionDepthAndPushLimit(int)'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIModule27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x1ec): undefined reference to `google::protobuf::io::CodedInputStream::DecrementRecursionDepthAndPopLimit(int)'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIModule27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x258): undefined reference to `google::protobuf::internal::ArenaImpl::AllocateAlignedAndAddCleanup(unsigned long, void (*)(void*))'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIModule27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x2d4): undefined reference to `google::protobuf::internal::RepeatedPtrFieldBase::Reserve(int)'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIModule27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x2f0): undefined reference to `google::protobuf::internal::RepeatedPtrFieldBase::Reserve(int)'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIModule27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x314): undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIModule27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x335): undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIClass::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*)':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api10TFAPIClass27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x71): undefined reference to `google::protobuf::internal::WireFormat::SkipField(google::protobuf::io::CodedInputStream*, unsigned int, google::protobuf::UnknownFieldSet*)'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api10TFAPIClass27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x96): undefined reference to `google::protobuf::io::CodedInputStream::ReadTagFallback(unsigned int)'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api10TFAPIClass27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x11d): undefined reference to `google::protobuf::internal::ArenaImpl::AllocateAlignedAndAddCleanup(unsigned long, void (*)(void*))'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api10TFAPIClass27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x159): undefined reference to `google::protobuf::internal::WireFormatLite::ReadBytes(google::protobuf::io::CodedInputStream*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*)'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api10TFAPIClass27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x1e1): undefined reference to `google::protobuf::internal::ArenaImpl::AllocateAlignedAndAddCleanup(unsigned long, void (*)(void*))'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api10TFAPIClass27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x281): undefined reference to `google::protobuf::internal::ArenaImpl::AllocateAlignedAndAddCleanup(unsigned long, void (*)(void*))'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api10TFAPIClass27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x2d3): undefined reference to `google::protobuf::io::CodedInputStream::ReadVarintSizeAsIntFallback()'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api10TFAPIClass27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x2ed): undefined reference to `google::protobuf::io::CodedInputStream::IncrementRecursionDepthAndPushLimit(int)'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api10TFAPIClass27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x323): undefined reference to `google::protobuf::io::CodedInputStream::DecrementRecursionDepthAndPopLimit(int)'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api10TFAPIClass27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x3c7): undefined reference to `google::protobuf::internal::RepeatedPtrFieldBase::Reserve(int)'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api10TFAPIClass27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x3e3): undefined reference to `google::protobuf::internal::RepeatedPtrFieldBase::Reserve(int)'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api10TFAPIClass27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x3ff): undefined reference to `google::protobuf::internal::RepeatedPtrFieldBase::Reserve(int)'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api10TFAPIClass27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x423): undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api10TFAPIClass27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x444): undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api10TFAPIClass27MergePartialFromCodedStreamEPN6google8protobuf2io16CodedInputStreamE+0x465): undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIMember::Clear()':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMember5ClearEv+0x5c): undefined reference to `google::protobuf::UnknownFieldSet::ClearFallback()'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIModule::Clear()':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIModule5ClearEv+0x51): undefined reference to `google::protobuf::UnknownFieldSet::ClearFallback()'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIClass::Clear()':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api10TFAPIClass5ClearEv+0x91): undefined reference to `google::protobuf::UnknownFieldSet::ClearFallback()'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIObject::Clear()':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIObject5ClearEv+0x5f): undefined reference to `google::protobuf::UnknownFieldSet::ClearFallback()'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIMember::MergeFrom(third_party::tensorflow::tools::api::TFAPIMember const&)':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMember9MergeFromERKS3_+0x44): undefined reference to `google::protobuf::internal::fixed_address_empty_string[abi:cxx11]'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMember9MergeFromERKS3_+0x6c): undefined reference to `google::protobuf::internal::fixed_address_empty_string[abi:cxx11]'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMember9MergeFromERKS3_+0xab): undefined reference to `google::protobuf::UnknownFieldSet::MergeFrom(google::protobuf::UnknownFieldSet const&)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIMember::MergeFrom(google::protobuf::Message const&)':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMember9MergeFromERKN6google8protobuf7MessageE+0x16): undefined reference to `typeinfo for google::protobuf::Message'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMember9MergeFromERKN6google8protobuf7MessageE+0x4b): undefined reference to `google::protobuf::internal::ReflectionOps::Merge(google::protobuf::Message const&, google::protobuf::Message*)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIMethod::MergeFrom(third_party::tensorflow::tools::api::TFAPIMethod const&)':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMethod9MergeFromERKS3_+0x4b): undefined reference to `google::protobuf::internal::fixed_address_empty_string[abi:cxx11]'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMethod9MergeFromERKS3_+0x75): undefined reference to `google::protobuf::internal::fixed_address_empty_string[abi:cxx11]'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMethod9MergeFromERKS3_+0x9b): undefined reference to `google::protobuf::internal::fixed_address_empty_string[abi:cxx11]'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMethod9MergeFromERKS3_+0xd3): undefined reference to `google::protobuf::UnknownFieldSet::MergeFrom(google::protobuf::UnknownFieldSet const&)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIMethod::MergeFrom(google::protobuf::Message const&)':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMethod9MergeFromERKN6google8protobuf7MessageE+0x16): undefined reference to `typeinfo for google::protobuf::Message'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIMethod9MergeFromERKN6google8protobuf7MessageE+0x4b): undefined reference to `google::protobuf::internal::ReflectionOps::Merge(google::protobuf::Message const&, google::protobuf::Message*)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `void google::protobuf::internal::RepeatedPtrFieldBase::MergeFromInnerLoop<google::protobuf::RepeatedPtrField<third_party::tensorflow::tools::api::TFAPIMember>::TypeHandler>(void**, void**, int, int)':\r\napi_objects.pb.cc:(.text._ZN6google8protobuf8internal20RepeatedPtrFieldBase18MergeFromInnerLoopINS0_16RepeatedPtrFieldIN11third_party10tensorflow5tools3api11TFAPIMemberEE11TypeHandlerEEEvPPvSD_ii[_ZN6google8protobuf8internal20RepeatedPtrFieldBase18MergeFromInnerLoopINS0_16RepeatedPtrFieldIN11third_party10tensorflow5tools3api11TFAPIMemberEE11TypeHandlerEEEvPPvSD_ii]+0x93): undefined reference to `google::protobuf::internal::ArenaImpl::AllocateAlignedAndAddCleanup(unsigned long, void (*)(void*))'\r\napi_objects.pb.cc:(.text._ZN6google8protobuf8internal20RepeatedPtrFieldBase18MergeFromInnerLoopINS0_16RepeatedPtrFieldIN11third_party10tensorflow5tools3api11TFAPIMemberEE11TypeHandlerEEEvPPvSD_ii[_ZN6google8protobuf8internal20RepeatedPtrFieldBase18MergeFromInnerLoopINS0_16RepeatedPtrFieldIN11third_party10tensorflow5tools3api11TFAPIMemberEE11TypeHandlerEEEvPPvSD_ii]+0xef): undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `void google::protobuf::internal::RepeatedPtrFieldBase::MergeFromInnerLoop<google::protobuf::RepeatedPtrField<third_party::tensorflow::tools::api::TFAPIMethod>::TypeHandler>(void**, void**, int, int)':\r\napi_objects.pb.cc:(.text._ZN6google8protobuf8internal20RepeatedPtrFieldBase18MergeFromInnerLoopINS0_16RepeatedPtrFieldIN11third_party10tensorflow5tools3api11TFAPIMethodEE11TypeHandlerEEEvPPvSD_ii[_ZN6google8protobuf8internal20RepeatedPtrFieldBase18MergeFromInnerLoopINS0_16RepeatedPtrFieldIN11third_party10tensorflow5tools3api11TFAPIMethodEE11TypeHandlerEEEvPPvSD_ii]+0x93): undefined reference to `google::protobuf::internal::ArenaImpl::AllocateAlignedAndAddCleanup(unsigned long, void (*)(void*))'\r\napi_objects.pb.cc:(.text._ZN6google8protobuf8internal20RepeatedPtrFieldBase18MergeFromInnerLoopINS0_16RepeatedPtrFieldIN11third_party10tensorflow5tools3api11TFAPIMethodEE11TypeHandlerEEEvPPvSD_ii[_ZN6google8protobuf8internal20RepeatedPtrFieldBase18MergeFromInnerLoopINS0_16RepeatedPtrFieldIN11third_party10tensorflow5tools3api11TFAPIMethodEE11TypeHandlerEEEvPPvSD_ii]+0xef): undefined reference to `google::protobuf::Arena::OnArenaAllocation(std::type_info const*, unsigned long) const'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIModule::MergeFrom(third_party::tensorflow::tools::api::TFAPIModule const&)':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIModule9MergeFromERKS3_+0x60): undefined reference to `google::protobuf::internal::RepeatedPtrFieldBase::InternalExtend(int)'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIModule9MergeFromERKS3_+0xc4): undefined reference to `google::protobuf::internal::RepeatedPtrFieldBase::InternalExtend(int)'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIModule9MergeFromERKS3_+0x11b): undefined reference to `google::protobuf::UnknownFieldSet::MergeFrom(google::protobuf::UnknownFieldSet const&)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIModule::MergeFrom(google::protobuf::Message const&)':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIModule9MergeFromERKN6google8protobuf7MessageE+0x16): undefined reference to `typeinfo for google::protobuf::Message'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIModule9MergeFromERKN6google8protobuf7MessageE+0x4b): undefined reference to `google::protobuf::internal::ReflectionOps::Merge(google::protobuf::Message const&, google::protobuf::Message*)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIClass::MergeFrom(third_party::tensorflow::tools::api::TFAPIClass const&)':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api10TFAPIClass9MergeFromERKS3_+0x70): undefined reference to `google::protobuf::internal::RepeatedPtrFieldBase::InternalExtend(int)'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api10TFAPIClass9MergeFromERKS3_+0xd4): undefined reference to `google::protobuf::internal::RepeatedPtrFieldBase::InternalExtend(int)'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api10TFAPIClass9MergeFromERKS3_+0x12c): undefined reference to `google::protobuf::internal::RepeatedPtrFieldBase::InternalExtend(int)'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api10TFAPIClass9MergeFromERKS3_+0x183): undefined reference to `google::protobuf::UnknownFieldSet::MergeFrom(google::protobuf::UnknownFieldSet const&)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIClass::MergeFrom(google::protobuf::Message const&)':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api10TFAPIClass9MergeFromERKN6google8protobuf7MessageE+0x16): undefined reference to `typeinfo for google::protobuf::Message'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api10TFAPIClass9MergeFromERKN6google8protobuf7MessageE+0x4b): undefined reference to `google::protobuf::internal::ReflectionOps::Merge(google::protobuf::Message const&, google::protobuf::Message*)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIObject::MergeFrom(third_party::tensorflow::tools::api::TFAPIObject const&)':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIObject9MergeFromERKS3_+0x4f): undefined reference to `google::protobuf::internal::fixed_address_empty_string[abi:cxx11]'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIObject9MergeFromERKS3_+0xf7): undefined reference to `google::protobuf::UnknownFieldSet::MergeFrom(google::protobuf::UnknownFieldSet const&)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o: In function `third_party::tensorflow::tools::api::TFAPIObject::MergeFrom(google::protobuf::Message const&)':\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIObject9MergeFromERKN6google8protobuf7MessageE+0x16): undefined reference to `typeinfo for google::protobuf::Message'\r\napi_objects.pb.cc:(.text._ZN11third_party10tensorflow5tools3api11TFAPIObject9MergeFromERKN6google8protobuf7MessageE+0x4b): undefined reference to `google::protobuf::internal::ReflectionOps::Merge(google::protobuf::Message const&, google::protobuf::Message*)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTIN11third_party10tensorflow5tools3api11TFAPIMemberE[_ZTIN11third_party10tensorflow5tools3api11TFAPIMemberE]+0x10): undefined reference to `typeinfo for google::protobuf::Message'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTIN11third_party10tensorflow5tools3api11TFAPIMethodE[_ZTIN11third_party10tensorflow5tools3api11TFAPIMethodE]+0x10): undefined reference to `typeinfo for google::protobuf::Message'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTIN11third_party10tensorflow5tools3api11TFAPIModuleE[_ZTIN11third_party10tensorflow5tools3api11TFAPIModuleE]+0x10): undefined reference to `typeinfo for google::protobuf::Message'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTIN11third_party10tensorflow5tools3api10TFAPIClassE[_ZTIN11third_party10tensorflow5tools3api10TFAPIClassE]+0x10): undefined reference to `typeinfo for google::protobuf::Message'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTIN11third_party10tensorflow5tools3api11TFAPIObjectE[_ZTIN11third_party10tensorflow5tools3api11TFAPIObjectE]+0x10): undefined reference to `typeinfo for google::protobuf::Message'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api11TFAPIMemberE[_ZTVN11third_party10tensorflow5tools3api11TFAPIMemberE]+0x20): undefined reference to `google::protobuf::Message::GetTypeName[abi:cxx11]() const'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api11TFAPIMemberE[_ZTVN11third_party10tensorflow5tools3api11TFAPIMemberE]+0x58): undefined reference to `google::protobuf::Message::InitializationErrorString[abi:cxx11]() const'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api11TFAPIMemberE[_ZTVN11third_party10tensorflow5tools3api11TFAPIMemberE]+0x60): undefined reference to `google::protobuf::Message::CheckTypeAndMergeFrom(google::protobuf::MessageLite const&)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api11TFAPIMemberE[_ZTVN11third_party10tensorflow5tools3api11TFAPIMemberE]+0x80): undefined reference to `google::protobuf::MessageLite::SerializeWithCachedSizesToArray(unsigned char*) const'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api11TFAPIMemberE[_ZTVN11third_party10tensorflow5tools3api11TFAPIMemberE]+0xb0): undefined reference to `google::protobuf::Message::DiscardUnknownFields()'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api11TFAPIMemberE[_ZTVN11third_party10tensorflow5tools3api11TFAPIMemberE]+0xb8): undefined reference to `google::protobuf::Message::SpaceUsedLong() const'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api11TFAPIMethodE[_ZTVN11third_party10tensorflow5tools3api11TFAPIMethodE]+0x20): undefined reference to `google::protobuf::Message::GetTypeName[abi:cxx11]() const'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api11TFAPIMethodE[_ZTVN11third_party10tensorflow5tools3api11TFAPIMethodE]+0x58): undefined reference to `google::protobuf::Message::InitializationErrorString[abi:cxx11]() const'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api11TFAPIMethodE[_ZTVN11third_party10tensorflow5tools3api11TFAPIMethodE]+0x60): undefined reference to `google::protobuf::Message::CheckTypeAndMergeFrom(google::protobuf::MessageLite const&)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api11TFAPIMethodE[_ZTVN11third_party10tensorflow5tools3api11TFAPIMethodE]+0x80): undefined reference to `google::protobuf::MessageLite::SerializeWithCachedSizesToArray(unsigned char*) const'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api11TFAPIMethodE[_ZTVN11third_party10tensorflow5tools3api11TFAPIMethodE]+0xb0): undefined reference to `google::protobuf::Message::DiscardUnknownFields()'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api11TFAPIMethodE[_ZTVN11third_party10tensorflow5tools3api11TFAPIMethodE]+0xb8): undefined reference to `google::protobuf::Message::SpaceUsedLong() const'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api11TFAPIModuleE[_ZTVN11third_party10tensorflow5tools3api11TFAPIModuleE]+0x20): undefined reference to `google::protobuf::Message::GetTypeName[abi:cxx11]() const'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api11TFAPIModuleE[_ZTVN11third_party10tensorflow5tools3api11TFAPIModuleE]+0x58): undefined reference to `google::protobuf::Message::InitializationErrorString[abi:cxx11]() const'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api11TFAPIModuleE[_ZTVN11third_party10tensorflow5tools3api11TFAPIModuleE]+0x60): undefined reference to `google::protobuf::Message::CheckTypeAndMergeFrom(google::protobuf::MessageLite const&)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api11TFAPIModuleE[_ZTVN11third_party10tensorflow5tools3api11TFAPIModuleE]+0x80): undefined reference to `google::protobuf::MessageLite::SerializeWithCachedSizesToArray(unsigned char*) const'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api11TFAPIModuleE[_ZTVN11third_party10tensorflow5tools3api11TFAPIModuleE]+0xb0): undefined reference to `google::protobuf::Message::DiscardUnknownFields()'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api11TFAPIModuleE[_ZTVN11third_party10tensorflow5tools3api11TFAPIModuleE]+0xb8): undefined reference to `google::protobuf::Message::SpaceUsedLong() const'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api10TFAPIClassE[_ZTVN11third_party10tensorflow5tools3api10TFAPIClassE]+0x20): undefined reference to `google::protobuf::Message::GetTypeName[abi:cxx11]() const'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api10TFAPIClassE[_ZTVN11third_party10tensorflow5tools3api10TFAPIClassE]+0x58): undefined reference to `google::protobuf::Message::InitializationErrorString[abi:cxx11]() const'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api10TFAPIClassE[_ZTVN11third_party10tensorflow5tools3api10TFAPIClassE]+0x60): undefined reference to `google::protobuf::Message::CheckTypeAndMergeFrom(google::protobuf::MessageLite const&)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api10TFAPIClassE[_ZTVN11third_party10tensorflow5tools3api10TFAPIClassE]+0x80): undefined reference to `google::protobuf::MessageLite::SerializeWithCachedSizesToArray(unsigned char*) const'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api10TFAPIClassE[_ZTVN11third_party10tensorflow5tools3api10TFAPIClassE]+0xb0): undefined reference to `google::protobuf::Message::DiscardUnknownFields()'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api10TFAPIClassE[_ZTVN11third_party10tensorflow5tools3api10TFAPIClassE]+0xb8): undefined reference to `google::protobuf::Message::SpaceUsedLong() const'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api11TFAPIObjectE[_ZTVN11third_party10tensorflow5tools3api11TFAPIObjectE]+0x20): undefined reference to `google::protobuf::Message::GetTypeName[abi:cxx11]() const'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api11TFAPIObjectE[_ZTVN11third_party10tensorflow5tools3api11TFAPIObjectE]+0x58): undefined reference to `google::protobuf::Message::InitializationErrorString[abi:cxx11]() const'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api11TFAPIObjectE[_ZTVN11third_party10tensorflow5tools3api11TFAPIObjectE]+0x60): undefined reference to `google::protobuf::Message::CheckTypeAndMergeFrom(google::protobuf::MessageLite const&)'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api11TFAPIObjectE[_ZTVN11third_party10tensorflow5tools3api11TFAPIObjectE]+0x80): undefined reference to `google::protobuf::MessageLite::SerializeWithCachedSizesToArray(unsigned char*) const'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api11TFAPIObjectE[_ZTVN11third_party10tensorflow5tools3api11TFAPIObjectE]+0xb0): undefined reference to `google::protobuf::Message::DiscardUnknownFields()'\r\nbazel-out/k8-py3-opt/bin/tensorflow/tools/api/lib/_objs/api_objects_proto_cc/tensorflow/tools/api/lib/api_objects.pb.pic.o:(.data.rel.ro._ZTVN11third_party10tensorflow5tools3api11TFAPIObjectE[_ZTVN11third_party10tensorflow5tools3api11TFAPIObjectE]+0xb8): undefined reference to `google::protobuf::Message::SpaceUsedLong() const'\r\ncollect2: error: ld returned 1 exit status\r\n```", "comments": ["I have observed a similar behavior which looks fairly related, although with TensorFlow 1.5. Linking a cc_library rule fails with various undefined references, including \"undefined reference to main\", with bazel 0.12 or greater but works with 0.11.1. I have looked at the command lines it invokes.\r\n\r\nWith bazel 0.13 (fails with similar error as in original issue):\r\n\r\n```\r\nexternal/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -shared -o bazel-out/k8-opt/bin/exp/vmu/common/libcommon.so -Wl,-no-as-needed -B/usr/bin/ -pie -Wl,-z,relro,-z,now -no-canonical-prefixes -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,--gc-sections -Wl,@bazel-out/k8-opt/bin/exp/vmu/common/libcommon.so-2.params\r\n```\r\n\r\nWith bazel 0.11.1 (links fine):\r\n\r\n```\r\nexternal/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -shared -o bazel-out/k8-opt/bin/exp/vmu/common/libcommon.so -Wl,-no-as-needed -B/usr/bin/ -Wl,-z,relro,-z,now -no-canonical-prefixes -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,--gc-sections -Wl,@bazel-out/k8-opt/bin/exp/vmu/common/libcommon.so-2.params\r\n```\r\n\r\nThe difference is the `-pie` flag that is added in the later version and indeed also when I run these commands manually the presence of the flag makes the linker invocation fail.", "The following patch allows my build to complete using the same command as I reported earlier (`bazel build --config=opt --config=cuda //tensorflow/tools/... --verbose_failures`). This was performed with the latest master (latest commit 8cb6e535f6ea14b380aa86d425169adad682cb8c).\r\n```\r\ndiff --git a/third_party/gpus/crosstool/CROSSTOOL_nvcc.tpl b/third_party/gpus/crosstool/CROSSTOOL_nvcc.tpl\r\nindex 05290d6..f518bde 100644\r\n--- a/third_party/gpus/crosstool/CROSSTOOL_nvcc.tpl\r\n+++ b/third_party/gpus/crosstool/CROSSTOOL_nvcc.tpl\r\n@@ -90,7 +90,7 @@ toolchain {\r\n   compiler_flag: \"-D_FORTIFY_SOURCE=1\"\r\n   compiler_flag: \"-fstack-protector\"\r\n   compiler_flag: \"-fPIE\"\r\n-  linker_flag: \"-pie\"\r\n   linker_flag: \"-Wl,-z,relro,-z,now\"\r\n \r\n   # Enable coloring even if there's no attached terminal. Bazel removes the\r\n```", "Nagging Assignee @shivaniag: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @shivaniag: It has been 30 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @shivaniag: It has been 46 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @shivaniag: It has been 61 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @shivaniag: It has been 76 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "As far as I can see from our builds, this issue should be resolved?", "I have not had this issue arise recently. I will close this issue."]}, {"number": 18885, "title": "Branch 194337205", "body": "", "comments": ["Sorry @yifeif @martinwicke I only just realized that I was on rotation for sync. Will request review once it's ready. Martin, I also just noticed you have another branch, feel free to submit that one instead if it's ready.", "Thanks @drpngx!"]}, {"number": 18884, "title": "ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory", "body": "ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory\r\n\r\nfirst,i have only installed cuda9.0,then,some days ago,it can easily run with it ,but today,it can't,and raise the error.i don't know how to fix it.please help...\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/33971685/39280811-fe4060cc-4933-11e8-83c2-62a7525920fc.png)\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Try making sure your `PATH` and `LD_LIBRARY_PATH` variables are being set properly; those were causing a similar issue for me.\r\n\r\nIn case you forgot to set those variables, add one of the following snippets to the end of your `~/.profile`:\r\n```\r\nexport PATH=/usr/local/cuda-9.0/bin${PATH:+:${PATH}}\r\nexport LD_LIBRARY_PATH=/usr/local/cuda-9.0/lib\\\r\n                         ${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\r\n```\r\nor, if you're running a 64-bit system:\r\n```\r\nexport PATH=/usr/local/cuda-9.0/bin${PATH:+:${PATH}}\r\nexport LD_LIBRARY_PATH=/usr/local/cuda-9.0/lib64\\\r\n                         ${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\r\n```\r\n\r\nthen run `source ~/.profile` and try running tensorflow again\r\n\r\n", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 18883, "title": "Fix critical metrics computation bug with Model in Eager mode.", "body": "", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to determine that you authored the commits in this PR.  Maybe you used a different email address in the git commits than was used to sign the CLA?  If someone else authored these commits, then please add them to this pull request and have them confirm that they're okay with them being contributed to Google.  If there are co-authors, make sure they're formatted properly.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- unknown_author -->", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->", "The author is a Googler."]}, {"number": 18882, "title": "Update tb-nightly dep to >= 1.9.0a0, < 1.10.0a0", "body": "Synchronize tf-nightly dep on current tb-nightly: https://pypi.org/project/tb-nightly/1.9.0a20180425/", "comments": []}, {"number": 18881, "title": "fix typo", "body": "fix typo", "comments": []}, {"number": 18880, "title": "[Feature Request] Dynamic RPC Address Resolution", "body": "Currently TensorFlow cluster is created statically with host name/port information defined in cluster spec. The host name and port information for a worker can't be changed during run-time. In a multi-tenancy environment where host name/port is assigned to worker by a job manager after worker failover happens, this static cluster spec prevents other workers to communicate with this new worker using the latest host name and port.\r\n\r\nWith dynamic RPC address resolution feature, the host name of each TF server is resolved against an RPC address registry before initiating each RPC call. This allows changing the host name and port of each TF server at run time, which is useful in the following cases:\r\n\r\n- A stateless TF worker fails over and gets assigned with new host name/port by an external job scheduler.\r\n\r\n- A stateful TF worker fails over and all workers get restarted without changing the cluster spec. The failed worker can be assigned with new host name/port.\r\n\r\nI have composed a design document [here](https://docs.google.com/document/d/1Fl-mMZ9NMBDaQkhhVpXe-UdYC-iYg6hlSj7bBZSMCSM/edit?usp=sharing). A prototype has been done as well based on this design. We hope to contribute this feature to the upstream. Any feedbacks for the design are welcome.\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Thank you, @make1980. @josh11b and @alextp , you each touch this space; thoughts?", "@saeta I think knows more about this than I do.", "@anj-s , FYI", "@saeta  @alextp @anj-s @josh11b Any comments for this proposal? Would appreciate your early feedback - we plan to submit a PR soon.", "Hey @make1980 ,\r\n\r\nAre you familiar with ClusterSpec propagation? [ClusterSpec propagation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/client/session_clusterspec_prop_test.py) in conjunction with [ClusterResolvers](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cluster_resolver/python/training/cluster_resolver.py) allows for a fully pluggable dynamic resolution of all the workers. \r\n\r\nHope this helps!\r\n-Brennan\r\n", "Hi @saeta ,\r\n\r\nThanks for the links. I looked at the implementation of ClusterSpec propagation and ClusterResolver which allows the following scenario if I understand correctly - a worker which initiated the session failed over, it can restart and construct a new cluster spec using a pluggable cluster resolver to restart a new session. ClusterSpec propagation allows all the workers participating in the new session to retrieve the IP/port of other workers (including the worker which just failed over) from the master. \r\n\r\nHowever, in this scenario for the sessions initiated from other workers, this failed-over worker can't rejoin the existing session on behalf of its previous incarnation(for example, in-graph replication case).\r\n\r\nThere are definitely more details that need to be figured out such as how failed-over workers rejoining an existing session would be able to recover its local state, and how failed-over ps can restore its variables. But as the first step, I think having a translation layer from a logical hostname to IP/port at runtime is more flexible and necessary.\r\n\r\nClusterSpec propagation can be used to enable scenarios such as auto-scaling but we need this dynamic RPC resolution feature to easily support the single worker fail-over scenario based on my understanding.", "To give a real-case scenario where ClusterSpec propagation isn't able to handle currently and won't be easily extended to handle -\r\n\r\nIn a 1 worker 1 ps setup, we start the worker first using cluster spec propagation. Then the machine which is supposed to run ps failed and ps ended up running on a different machine with a different IP. In this case the master service in the worker can't recognize the new ps since cluster resolver has already translated the IP/port information for the ps. To support this scenario we'll have to add logic to retry the cluster spec resolution logic (which is actually code in the user land if I understand correctly) instead of just adding retry logic where the master probes all the workers.", "Any comments @saeta? This feature is very important for large scale training scenario where cluster manager assigns different IP/port to a worker after fail-over and we really hope to contribute this to the community to avoid conflict in core when merging with the upstream, as well as allowing more customized implementations for dynamic address resolution.\r\n\r\nMoreover this feature should be able to work with cluster spec propagation/cluster resolver seamlessly since it provides address translation at a different layer.", "@saeta @alextp @anj-s @josh11b Any further comments? Let me know if I missed anything here.", "@saeta Could you comment on how to support this case using cluster spec propagation/cluster resolver?\r\n\r\nIn a 1 worker 1 ps setup, we start the worker first using cluster spec propagation. Then the machine which is supposed to run ps failed and ps ended up running on a different machine with a different IP. In this case the master service in the worker can't recognize the new ps since cluster resolver has already translated the IP/port information for the ps.", "Any comments? ", "Have you thought about just using DNS for the hostname instead of an IP? You can ensure that new hosts are mapped to the same failed hostname without needing to change anything in the TensorFlow codebase. If you're worried about port numbers, you might consider using DNS srv records and writing a custom ClusterResolver.", "Sorry @make1980 for the delayed reply. This thread got lost in my inbox. I apologize!\r\n\r\nIn general whenever there is a machine failure within a TensorFlow cluster, we have to be extra careful. This is because ops can be stateful. In short given a node failure at an arbitrary point after session creation, it's not correct to just re-try running those ops. Concretely in your scenario about 1 worker and 1 ps, if the parameter server fails after the variables have been initialized, it is not correct to begin executing the python training loop once the ps server comes back online. (Because the variables that are placed on it have not been initialized.) Even if we special-cased variables, there are many other stateful ops that also would need explicit handling. Because TensorFlow users can define custom operations, it's not possible to teach the C++-runtime how to automatically handle the failures within a session.\r\n\r\nAs a result, the failure handling strategy we adopt within TensorFlow is to close the session and create a new session (and optionally restoring from a checkpoint). When starting the new session, client code (e.g. python) can construct a new ClusterSpec and propagate it to all the nodes within the cluster. This also has the advantage of cleanly separating the core TensorFlow runtime from having to integrate with custom cluster-coordination systems (e.g. etcd, zookeeper, internal Google systems, Netflix's Eureka, k8s, etc.).\r\n\r\nHope this helps!", "Thanks for your response @saeta! This is exactly the discussion that I wanted to have. As you mentioned adding run-time address resolution will cause problem for stateful operations so we avoid it by recreating the session. While this also means we might need to add automatic state recovery mechanism to PS so this won't be a problem. Checkpoint based state recovery has its own limitation of requiring all the PS servers to restore the state in case there is only one PS failing. If ultimately this can be addressed, dynamic RPC resolution should still be applicable. Certainly we need to consider other cases like operations relying on local state can only be resumed if the intermediate local state can be recovered. \r\n\r\nSo I agree with you that this feature won't solve all the single-node failure problem and could be error-prone if not used properly. But it should still be useful in case the failed worker doesn't have intermediate state. For example, in an in-graph replication case where worker 1 fails before worker 2 starts the session and after worker 2 constructed the cluster spec, worker 2 doesn't need to restart the session to recognize a new worker 1. \r\n\r\nI understand that this is a special case where RPC resolution can bring some advantages compared with cluster spec propagation. However from the user's perspective having a consistent logical cluster view also seems to be simpler than defining different cluster specs among different workers and also using sparse cluster definition to avoid unrelated workers to wait for each other. Having a single cluster spec also provides potential opportunities for optimizations on op placement since TF can just treat all the workers in a holistic view.\r\n\r\nAlso - if worker state is the only concern for this feature request we can work on adding additional logic to avoid using this feature when the failed-over worker contains unrecoverable state. Just want to make sure the feature itself actually brings some value and we can invest more towards this direction.", "@ajbouh, thanks for your suggestion. I took a look at the DNS srv records and I agree that this can be used to solve some of the problems we're facing together with cluster resolver. I think the difference between dynamic RPC address resolution and cluster spec propagation is really around when the address translation happens instead of how the address is translated - whether through DNS or not we can do it in both approaches. For example, we can implement an RPC address resolver using DNS srv record as well.", "Perhaps a simple solution would be to actually only bring up the parts of\nthe session state that are stateful and affected by the failed worker?\n\nWe can see the subgraph of stateful/nonstateful operations pretty plainly\nin the graphdef. Perhaps there's a simple type of op we can introduce that\nreturns true or false if running on a replaced worker or not. Combining\nthis with a cond operator and some graph rewriting should be enough to\n\"automatically\" handle failures with the least disruption possible.\n\nDo I have that right?\n\nOn Mon, May 21, 2018, 14:30 make1980 <notifications@github.com> wrote:\n\n> @ajbouh <https://github.com/ajbouh>, thanks for your suggestion. I took a\n> look at the DNS srv records and I agree that this can be used to solve some\n> of the problems we're facing together with cluster resolver. I think the\n> difference between dynamic RCP address resolution and cluster spec\n> propagation is really around when the address translation happens instead\n> of how the address is translated - whether through DNS or not we can do it\n> in both approaches. For example, we can implement an RPC address resolver\n> using DNS srv record as well.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/18880#issuecomment-390788015>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAAcnY9fwNmSOkrelFFFo89FKN1ys4J3ks5t0zH9gaJpZM4TkRsG>\n> .\n>\n", "I don't think I fully understand your idea here - a simple solution I can imagine would be to let the op declare whether it's stateful or not and only allow a failed-over worker which has only executed stateless op to rejoin the session. And restart the session if it's not the case.", "We're in luck there as operations are already marked as being\nstateless/stateful for the graph optimizers to maintain correctness as they\nsimplify the graph.\n\nMy suggestion would make it possible to write custom (in graph) logic to\nhandle the stateful case as well.\n\nOn Mon, May 21, 2018, 17:52 make1980 <notifications@github.com> wrote:\n\n> I don't think I fully understand your idea here - a simple solution I can\n> imagine would be to let the op declare whether it's stateful or not and\n> only allow a failed-over worker which has only executed stateless op to\n> rejoin the session. And restart the session if it's not the case.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/18880#issuecomment-390828234>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAAcnajRU1Yaf7AO9sBbeHxTuwKCqULCks5t02FhgaJpZM4TkRsG>\n> .\n>\n", "@ajbouh I see. Essentially we want to reconstruct the state by re-computation on the failed over node. This is similar idea as checkpoint based state recovery. I think this is definitely helpful.", "A little, though jt's different from checkpoint recovery because it doesn't\nrequire restarting a session or an additional session.run for the current\none.\n\nOn Tue, May 22, 2018, 10:03 make1980 <notifications@github.com> wrote:\n\n> @ajbouh <https://github.com/ajbouh> I see. Essentially we want to\n> reconstruct the state by re-computation on the failed over node. This is\n> similar idea as checkpoint based state recovery. I think this is definitely\n> helpful.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/18880#issuecomment-391065282>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAAcnX5tCQMlZOEREKscMjHZyq9tVy4Cks5t1ET-gaJpZM4TkRsG>\n> .\n>\n", "@saeta Would appreciate if you can give some feedback on my comments above. I think address translation at run-time will still bring great value - we just need to make sure it only happens when appropriate.\r\n\r\nThe design already makes the feature an opt-in feature - we can add additional check to make sure the feature is only enabled for the right worker. ", "Hmm, this is a very nuanced topic that deserves careful thought. I guess I see 2 approaches to failure handling: either (1) we adopt the \"crash-only\" philosophy, or (2) we attempt some sort of \"online\" recovery to handle partial (e.g. single node) failures. Unfortunately, they don't mix terribly well.\r\n\r\nAdvantages of the first is that it dramatically simplifies the semantics as well as the system implementation. Because fewer code paths are required (and they are exercised constantly), software projects with this fault tolerance model can sometimes be more robust.\r\n\r\nThat said, in some domains this approach cannot meet certain system goals, and thus partial failures must be tolerated and handled correctly. (e.g. A distributed database.) Unfortunately, these systems are very complicated and are generally designed around handling failures. These systems have uptime measured over months / years and are distributed across hundreds, thousands, or more servers. By contrast, TensorFlow is instead focused on training jobs that last hours to days (weeks at most), and typically don't scale beyond hundreds of servers. Because of these differing requirements, TensorFlow has historically taken the crash-only approach. (Note: TensorFlow has actually been moving in the opposite direction; new distribution strategies centered around all-reduce and other HPC-style primitives are known to be higher performance (e.g. than parameter-server style configurations) but are easier to ensure they are working reliably in crash-only systems. Parameter-server style configurations running in an async approach are pretty resilient to workers going down.)\r\n\r\nIf we are to deviate from this, one way to think about it would be to answer the following questions:\r\n 1. What are the overall system goals? What application are we trying to meet that we can't meet today?\r\n 2. What is the end-to-end design? Are certain layers crash-only? If so, how does that mix with online recovery of other layers?\r\n 3. What is the expected implementation cost of the approach? Does it prevent easy implementation of other features on our roadmap?\r\n 4. Does the value of the applications outweigh the above costs?\r\n\r\nDropping down a level (if the above response is focused on the larger discussion, this is on a more detailed technical level), the cost of creating a new session is typically pretty cheap (assuming the graph is not gigantic). State can be stored in containers outside of specific sessions, so [some] more complicated partial-failure recovery can be implemented (e.g. in Python) on top of the core TF primitives today.", "I think a good solution to this family of problems should not make\nassumptions about layers or primitives \"above\" the abstractions that are\npart of the TF distributed abstractions.\n\nI also think that we are probably too early in the development and\ndeployment of these systems to be able to recognize and implement a good\npolicy for handling all the kinds of failures that may exist. Better would\nbe to implement the primitives we need to detect and handle failure and\nallow everyone to experiment with policies on their own.\n\nGiven the cost and scale of the training sessions people are running, it\nshould be easy to see why a robust and reliable training system is\ndesirable.\n\nIf others are in agreement about this approach, I suggest an even narrower\nset of questions:\n- what TF ops are missing that would allow in-graph detection of a worker\nfailure?\n- what ops are missing that would allow in-graph re-init of a\nrecovered/replaced worker?\n- what ops (or combinations of ops) exist today might be incompatible with\nin-graph recovery?\n\nIf the above were addressed, perhaps we could get away with a simple outer\nwhile loop that repeatedly calls session.run until the termination\ncondition has been reached?\n\n\nOn Tue, May 29, 2018, 09:36 Brennan Saeta <notifications@github.com> wrote:\n\n> Hmm, this is a very nuanced topic that deserves careful thought. I guess I\n> see 2 approaches to failure handling: either (1) we adopt the \"crash-only\"\n> philosophy, or (2) we attempt some sort of \"online\" recovery to handle\n> partial (e.g. single node) failures. Unfortunately, they don't mix terribly\n> well.\n>\n> Advantages of the first is that it dramatically simplifies the semantics\n> as well as the system implementation. Because fewer code paths are required\n> (and they are exercised constantly), software projects with this fault\n> tolerance model can sometimes be more robust.\n>\n> That said, in some domains this approach cannot meet certain system goals,\n> and thus partial failures must be tolerated and handled correctly. (e.g. A\n> distributed database.) Unfortunately, these systems are very complicated\n> and are generally designed around handling failures. These systems have\n> uptime measured over months / years and are distributed across hundreds,\n> thousands, or more servers. By contrast, TensorFlow is instead focused on\n> training jobs that last hours to days (weeks at most), and typically don't\n> scale beyond hundreds of servers. Because of these differing requirements,\n> TensorFlow has historically taken the crash-only approach. (Note:\n> TensorFlow has actually been moving in the opposite direction; new\n> distribution strategies centered around all-reduce and other HPC-style\n> primitives are known to be higher performance (e.g. than parameter-server\n> style configurations) but are easier to ensure they are working reliably in\n> crash-only systems. Parameter-server style configurations running in an\n> async approach are pretty resilient to workers going down.)\n>\n> If we are to deviate from this, one way to think about it would be to\n> answer the following questions:\n>\n>    1. What are the overall system goals? What application are we trying\n>    to meet that we can't meet today?\n>    2. What is the end-to-end design? Are certain layers crash-only? If\n>    so, how does that mix with online recovery of other layers?\n>    3. What is the expected implementation cost of the approach? Does it\n>    prevent easy implementation of other features on our roadmap?\n>    4. Does the value of the applications outweigh the above costs?\n>\n> Dropping down a level (if the above response is focused on the larger\n> discussion, this is on a more detailed technical level), the cost of\n> creating a new session is typically pretty cheap (assuming the graph is not\n> gigantic). State can be stored in containers outside of specific sessions,\n> so [some] more complicated partial-failure recovery can be implemented\n> (e.g. in Python) on top of the core TF primitives today.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/18880#issuecomment-392842564>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAAcne2F8tsnGDm3ptBdVVzFD-JvwpAXks5t3XkSgaJpZM4TkRsG>\n> .\n>\n", "@ajbouh You're asking some excellent questions!\r\n\r\nUnfortunately, I'm not sure that detecting worker failure can be done as an op. Ops (by design) are not allowed to know of each other, and only communicate through input and output tensors. So, if we're trying to detect failures at the (arbitrary) op level, we can't necessarily do it as a custom op. But, that's probably too hard a problem; let's scope down to just detecting worker failures, which we could detect by having an op right after the recv op (which handles the RPC communication between workers). If we wanted to go down this route, we could augment the graph re-write pass that adds in the send's and recv's to also add in our custom loaded failure detecting op. But, then two issues arise:\r\n\r\n(1) how does the custom failure detector op know when a failure has happened? A standard timeout? If so, what's too long? It's not clear to me, given the huge variety of workloads running in TF. Even within a workload, some recv's should complete within seconds, whereas others are expected to take many minutes or even longer.\r\n\r\n(2) Assuming we've solved (1), we now have an op (which runs on a worker) that knows a failure has occurred. The next question becomes what can be done about the failure. We'd then need to define an RPC protocol for the worker to either (a) communicate with the master to request a new graph to be executed on the failed worker to re-initialize it, or (b) have the (potentially many) workers directly re-initialize it after it comes back up, and the associated coordination required. Because RPC protocols can't be added to a gRPC server after it's been started, this would require some non-trivial re-architecting of the RPC stack. (And while this is doable, the question becomes what's the value? How many workloads can we unlock with this capability? Note that the capability itself does not solve the problem; it only allows others to write subtle and complicated C++ ops that could attempt to perform failure handling. Would any of these be sharable between TF users? Between different workloads?)\r\n\r\nAs an alternative, we could augment the TF Master to allow some custom failure handling instead of as an op. But unfortunately, it doesn't necessarily solve all the problems either (what's the expected time a worker should wait for an recv?), and introduces new challenges (e.g. we currently have no path for dynamically loading plugins into the master currently). Again, all of these are solveable with sufficient engineering resources. But there's an opportunity cost (in addition to the maintenance cost), so we have to understand the value. Given that the MTBF of machines (especially Google Compute Engine CPU VMs) is so high (a year or more), even a large cluster training for a couple days is not likely to experience a failure in the normal case. The question thus becomes, what workloads can we not serve today?\r\n\r\nDoes that make sense?", "Brennan, there are many ways to detect failure that should be adequate to\nimprove the situation. These criteria are orthogonal to the rest of the\ndesign. Let us assume for now that upon \"failure\" a worker cleanly shuts\ndown its TCP connections and rejects any future connection attempts.\n\nI assume that any waiting receive will raise an error of some kind. It\nmight be enough to modifying the receive op to *not* raise this error and\n*instead* evaluate some second tensor and return 2 outputs (1 output for\nthe error text/type, 1 output for the second tensor).\n\nAs for how frequently this would be needed, the dropping price for hardware\nand the availability of *preemptible* hardware are two trends that will\ngenerate unique training scenarios that push the limits of today's training\narchitectures much more than the MBTF of underlying hardware. The design\noutlined above is an initial step in that direction.\n\nTensorFlow is uniquely suited to enable these modes. I hope we succeed in\ndoing just that!\n\nThanks for the critical feedback! :)\n\n\nOn Thu, Jun 28, 2018, 08:51 Brennan Saeta <notifications@github.com> wrote:\n\n> @ajbouh <https://github.com/ajbouh> You're asking some excellent\n> questions!\n>\n> Unfortunately, I'm not sure that detecting worker failure can be done as\n> an op. Ops (by design) are not allowed to know of each other, and only\n> communicate through input and output tensors. So, if we're trying to detect\n> failures at the (arbitrary) op level, we can't necessarily do it as a\n> custom op. But, that's probably too hard a problem; let's scope down to\n> just detecting worker failures, which we could detect by having an op right\n> after the recv op (which handles the RPC communication between workers). If\n> we wanted to go down this route, we could augment the graph re-write pass\n> that adds in the send's and recv's to also add in our custom loaded failure\n> detecting op. But, then two issues arise:\n>\n> (1) how does the custom failure detector op know when a failure has\n> happened? A standard timeout? If so, what's too long? It's not clear to me,\n> given the huge variety of workloads running in TF. Even within a workload,\n> some recv's should complete within seconds, whereas others are expected to\n> take many minutes or even longer.\n>\n> (2) Assuming we've solved (1), we now have an op (which runs on a worker)\n> that knows a failure has occurred. The next question becomes what can be\n> done about the failure. We'd then need to define an RPC protocol for the\n> worker to either (a) communicate with the master to request a new graph to\n> be executed on the failed worker to re-initialize it, or (b) have the\n> (potentially many) workers directly re-initialize it after it comes back\n> up, and the associated coordination required. Because RPC protocols can't\n> be added to a gRPC server after it's been started, this would require some\n> non-trivial re-architecting of the RPC stack. (And while this is doable,\n> the question becomes what's the value? How many workloads can we unlock\n> with this capability? Note that the capability itself does not solve the\n> problem; it only allows others to write subtle and complicated C++ ops that\n> could attempt to perform failure handling. Would any of these be sharable\n> between TF users? Between different workloads?)\n>\n> As an alternative, we could augment the TF Master to allow some custom\n> failure handling instead of as an op. But unfortunately, it doesn't\n> necessarily solve all the problems either (what's the expected time a\n> worker should wait for an recv?), and introduces new challenges (e.g. we\n> currently have no path for dynamically loading plugins into the master\n> currently). Again, all of these are solveable with sufficient engineering\n> resources. But there's an opportunity cost (in addition to the maintenance\n> cost), so we have to understand the value. Given that the MTBF of machines\n> (especially Google Compute Engine CPU VMs) is so high (a year or more),\n> even a large cluster training for a couple days is not likely to experience\n> a failure in the normal case. The question thus becomes, what workloads can\n> we not serve today?\n>\n> Does that make sense?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/18880#issuecomment-401081301>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAAcnSTnsamo5KB_6WSAgvM7537T2L8lks5uBPuUgaJpZM4TkRsG>\n> .\n>\n", "If this work is moving forward, @ajbouh, sounds like it might make a good TensorFlow RFC, with @saeta as the sponsor. For more, see https://github.com/tensorflow/community/blob/master/governance/TF-RFCs.md ", "Thanks for the bump! It doesn't seem like @saeta has much buy-in.\n\nFor now I'm focused on working around this in my own projects by building\nproxies, libraries, and other components that make it easier to move\nquickly.\n\nHappy to contribute to any efforts by the community though!\n\nOn Mon, Aug 20, 2018, 11:38 Edd Wilder-James <notifications@github.com>\nwrote:\n\n> If this work is moving forward, @ajbouh <https://github.com/ajbouh>,\n> sounds like it might make a good TensorFlow RFC, with @saeta\n> <https://github.com/saeta> as the sponsor. For more, see\n> https://github.com/tensorflow/community/blob/master/governance/TF-RFCs.md\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/18880#issuecomment-414418302>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAAcndturHC1aL7y-vNW73H8ytFNCurFks5uSwIZgaJpZM4TkRsG>\n> .\n>\n", "Closing this issue out as we haven't made progress in quite some time. Thanks all! -Brennan", "@saeta Somehow I think this topic might worth revisiting with the new eager runtime. In remote eager client like the VM connect to remote GPU or CloudTPU, one does `connect_to_cluster` and place the default context on the remote worker. If the eager service crashes, it might not be easy for the user to recover by re-running their computations or re-registering functions which could be notebook cells and was evaluated without explicit checkpoints before the crash. Any chance we could support eager context switch or checkpoint on the service side that is transparent to the client? That would be helpful for preemptible GPU/TPU services as well. ", "@bramandia FYI", "@byronyi Launching jobs on multiple remote GPU workers is not supported. When we support it, probably via single-client architecture, checkpoints can be made periodically by the client. If any worker fails, there is already some mechanism to update the configuration of the cluster, clear eager context, rebuild resources, load from checkpoint etc. but there are other components missing to make remote task dispatching work properly. We will considering supporting that. cc @crccw"]}, {"number": 18879, "title": "[Windows custom ops] Compiled c++ and imported dll successfully, but custom ops are not visible from python?", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Win 7 64\r\n- **TensorFlow installed from (source or binary)**: sources\r\n- **TensorFlow version (use command below)**: 1.3.1\r\n- **Python version**: 2.7.13\r\n- **Bazel version (if compiling from source)**: NA\r\n- **GCC/Compiler version (if compiling from source)**: Visual Studio 15\r\n- **CUDA/cuDNN version**: 8.0/7.5\r\n- **GPU model and memory**: NA\r\n- **Exact command to reproduce**: Please see below.\r\n\r\n### Describe the problem\r\nTrying to build a library available at https://github.com/optas/latent_3d_points.\r\n\r\nIt has custom ops implemented in c++.\r\nI have successfully built the package therein specifically `structural_losses` from https://github.com/optas/latent_3d_points/tree/master/external/structural_losses with changes for compiling with Visual Studio 2015.\r\n\r\nIn python, I am also able to load the ops dlls e.g. using \r\n`approxmatch_module = tf.load_op_library(osp.join(base_dir, '_approxmatch.pyd')).\r\n`\r\n\r\nHowever, I don't see the operators approxmatch_module.approx_match,approxmatch_module.match_cost, etc. from the c++ getting exposed to the python tensorflow.\r\n\r\nI am getting the following error:\r\n`AttributeError: 'module' object has no attribute 'approx_match'\r\n`\r\n\r\nWhen I do the following\r\n```\r\nfrom structural_losses import approxmatch\r\ndir(approxmatch.approxmatch_module)\r\n```\r\nit lists only the following items\r\n`['LIB_HANDLE', 'OP_LIST', '_InitOpDefLibrary', '__builtins__', '__doc__', '__name__', '__package__', '_collections', '_common_shapes', '_op_def_lib', '_op_def_library', '_op_def_pb2', '_op_def_registry', '_ops']\r\n`\r\nwhere the actual operations from c++ are missing.\r\n\r\nWhat am I missing from proper compilation?\r\n\r\nOr is it that in windows custom ops is `unavailable/not implemented`?", "comments": ["Nagging Assignee @tatatodd: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@mrry might know more about Windows status.", "@cooltopics Are you certain that the custom library was built and linked correctly? One potential cause for this problem is if the static initializers for Op and Kernel registration are \"optimized\" out of the final DLL. The [`/WHOLEARCHIVE` option to `link.exe`](https://stackoverflow.com/a/39715978/3574081) might be useful here.", "@mrry Losing hope, I have downloaded Tensorflow version 1.7.1 sources and built anew for Python 3.6 win64. Using this versions combination, it is working. I propose to close this issue as I no longer have the builds for the particular combination mentioned in this issue.", "Hi, @cooltopics \r\n\r\nHave you solved the problem?\r\n\r\nI try to build a tensorflow user op under Window 10. Following the [Official Docs](https://www.tensorflow.org/extend/adding_an_op), I successfully generate a `zero_out.dll` using VS2017, But when I try to load and use it in python, \r\n```\r\nimport tensorflow as tf\r\nzero_out_module = tf.load_op_library('./kernel/zero_out.dll')\r\n\r\n\r\nuse_cpu = True\r\ndevice_count = {\"GPU\": 0} if use_cpu else {\"GPU\": 1}\r\nwith tf.Session(config=tf.ConfigProto(device_count=device_count)):\r\n  zero_out_module.zero_out([[1, 2], [3, 4]]).eval()\r\n```\r\nit produces an error with \r\n```\r\nAttributeError: module 'f21c708d1ddc75dcce283dd13fe531f7' has no attribute 'zero_out'\r\n```\r\n\r\nDo I miss something or make any mistakes? Do you have any suggestion?\r\n\r\nThanks a lot.\r\n\r\n", "Hi all,\r\n\r\nI just wanted to write that I had the same problem under Mac OS X, and after a lot of dead ends (including building tensorflow from source...!) I realised that I hadn't copied part of the example to my file. In particular, I was missing the `REGISTER_OP` part right at the top of the file. The following file works for me:\r\n\r\n```\r\n#include \"tensorflow/core/framework/op_kernel.h\"\r\n\r\n#include \"tensorflow/core/framework/op.h\"\r\n#include \"tensorflow/core/framework/shape_inference.h\"\r\n\r\nusing namespace tensorflow;\r\n\r\nREGISTER_OP(\"ZeroOut\")\r\n    .Input(\"to_zero: int32\")\r\n    .Output(\"zeroed: int32\")\r\n    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\r\n      c->set_output(0, c->input(0));\r\n      return Status::OK();\r\n    });\r\n\r\nclass ZeroOutOp : public OpKernel {\r\n public:\r\n  explicit ZeroOutOp(OpKernelConstruction* context) : OpKernel(context) {}\r\n\r\n  void Compute(OpKernelContext* context) override {\r\n    // Grab the input tensor\r\n    const Tensor& input_tensor = context->input(0);\r\n    auto input = input_tensor.flat<int32>();\r\n\r\n    // Create an output tensor\r\n    Tensor* output_tensor = NULL;\r\n    OP_REQUIRES_OK(context, context->allocate_output(0, input_tensor.shape(),\r\n                                                     &output_tensor));\r\n    auto output_flat = output_tensor->flat<int32>();\r\n\r\n    // Set all but the first element of the output tensor to 0.\r\n    const int N = input.size();\r\n    for (int i = 1; i < N; i++) {\r\n      output_flat(i) = 0;\r\n    }\r\n\r\n    // Preserve the first input value if possible.\r\n    if (N > 0) output_flat(0) = input(0);\r\n  }\r\n};\r\n\r\nREGISTER_KERNEL_BUILDER(Name(\"ZeroOut\").Device(DEVICE_CPU), ZeroOutOp);\r\n```\r\n\r\nYou guys may have a Windows-specific problem, but I thought I'd pass this on anyway.", "> @mrry Losing hope, I have downloaded Tensorflow version 1.7.1 sources and built anew for Python 3.6 win64. Using this versions combination, it is working. I propose to close this issue as I no longer have the builds for the particular combination mentioned in this issue.\r\n\r\nHi @cooltopics  Could  you share some information how you solved the problem? To build the user defined op in Windows, do you need to install the tensorflow from source and put the defined c++ in the tensorflow/core/.. ?  Looking forward to your comments!", "> Hi, @cooltopics\r\n> \r\n> Have you solved the problem?\r\n> \r\n> I try to build a tensorflow user op under Window 10. Following the [Official Docs](https://www.tensorflow.org/extend/adding_an_op), I successfully generate a `zero_out.dll` using VS2017, But when I try to load and use it in python,\r\n> \r\n> ```\r\n> import tensorflow as tf\r\n> zero_out_module = tf.load_op_library('./kernel/zero_out.dll')\r\n> \r\n> \r\n> use_cpu = True\r\n> device_count = {\"GPU\": 0} if use_cpu else {\"GPU\": 1}\r\n> with tf.Session(config=tf.ConfigProto(device_count=device_count)):\r\n>   zero_out_module.zero_out([[1, 2], [3, 4]]).eval()\r\n> ```\r\n> \r\n> it produces an error with\r\n> \r\n> ```\r\n> AttributeError: module 'f21c708d1ddc75dcce283dd13fe531f7' has no attribute 'zero_out'\r\n> ```\r\n> \r\n> Do I miss something or make any mistakes? Do you have any suggestion?\r\n> \r\n> Thanks a lot.\r\n\r\nHi~ @VVingerfly\r\n\r\nCould you solved this problem?\r\n\r\nI have the same problem. ", "> Hi all,\r\n> \r\n> I just wanted to write that I had the same problem under Mac OS X, and after a lot of dead ends (including building tensorflow from source...!) I realised that I hadn't copied part of the example to my file. In particular, I was missing the `REGISTER_OP` part right at the top of the file. The following file works for me:\r\n> \r\n> ```\r\n> #include \"tensorflow/core/framework/op_kernel.h\"\r\n> \r\n> #include \"tensorflow/core/framework/op.h\"\r\n> #include \"tensorflow/core/framework/shape_inference.h\"\r\n> \r\n> using namespace tensorflow;\r\n> \r\n> REGISTER_OP(\"ZeroOut\")\r\n>     .Input(\"to_zero: int32\")\r\n>     .Output(\"zeroed: int32\")\r\n>     .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\r\n>       c->set_output(0, c->input(0));\r\n>       return Status::OK();\r\n>     });\r\n> \r\n> class ZeroOutOp : public OpKernel {\r\n>  public:\r\n>   explicit ZeroOutOp(OpKernelConstruction* context) : OpKernel(context) {}\r\n> \r\n>   void Compute(OpKernelContext* context) override {\r\n>     // Grab the input tensor\r\n>     const Tensor& input_tensor = context->input(0);\r\n>     auto input = input_tensor.flat<int32>();\r\n> \r\n>     // Create an output tensor\r\n>     Tensor* output_tensor = NULL;\r\n>     OP_REQUIRES_OK(context, context->allocate_output(0, input_tensor.shape(),\r\n>                                                      &output_tensor));\r\n>     auto output_flat = output_tensor->flat<int32>();\r\n> \r\n>     // Set all but the first element of the output tensor to 0.\r\n>     const int N = input.size();\r\n>     for (int i = 1; i < N; i++) {\r\n>       output_flat(i) = 0;\r\n>     }\r\n> \r\n>     // Preserve the first input value if possible.\r\n>     if (N > 0) output_flat(0) = input(0);\r\n>   }\r\n> };\r\n> \r\n> REGISTER_KERNEL_BUILDER(Name(\"ZeroOut\").Device(DEVICE_CPU), ZeroOutOp);\r\n> ```\r\n> \r\n> You guys may have a Windows-specific problem, but I thought I'd pass this on anyway.\r\n\r\nHi @martiningram ~,I have met the same question on ubuntu. But the library complied by g++ works well. How did you solve this problem?", "@ZhuXinyan @sc1991327 @sunglowzhang @VVingerfly\r\nIt is likely that the building of the shared library did not include the header file correctly.\r\nIf this [particular line](https://github.com/tensorflow/custom-op/blob/master/Makefile#L5) is incorrect, the custom op interface will not find the method or attribute correctly."]}, {"number": 18878, "title": "the files of events.out.tfevnts.***.net while running deep learning model", "body": "Hi\r\n\r\nDuring running a tensorflow model, I found that it automatically generates the file as the follows\r\n\r\n```\r\nevents.out.tfevents.1524681518.xhl.net\r\nevents.out.tfevents.1524681541.xhl.net\r\n\r\n\r\n```\r\n\r\nWhat do these files stand for? Are there any ways to stop generating them. The files are saved along with model checkpoint file.\r\n\r\n![capture](https://user-images.githubusercontent.com/5430158/39276576-42440a56-48af-11e8-9bed-715db940125e.JPG)\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 18877, "title": "Cannot use freeze_graph.py and optimize_for_inference.py with any model ", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 x64\r\n- **TensorFlow installed from (source or binary):**: PIP Python 3.6\r\n- **TensorFlow version (use command below)**: 1.7.0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: .9.0\r\n- **GPU model and memory**: 2GB\r\n- **Exact command to reproduce**:\r\n\r\n> py -m tensorflow.python.tools.freeze_graph --input_graph=output_graph.pb --input_checkpoint=C:/tmp/_retrain_checkpoint --output_graph=/tmp/frozen_graph.pb --output_node_names=final_result --input_binary=true\r\n\r\n> py \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python36_64\\Lib\\site-packages\\tensorflow\\python\\tools\\optimize_for_inference.py\" --input=output_graph.pb --output=/tmp/optimazed_frozen_graph.pb --frozen_graph=true --input_names=\"Placeholder\" --output_names \"final_result\" --inference_type=float\r\n\r\n### Describe the problem\r\n\r\nI have generated model with this tutorial for my own classes: https://www.tensorflow.org/tutorials/image_retraining\r\n\r\nI cannot use generated .pb file with EmguCV or OpenCV, becouse of import error, it looks like some layers are unsupported,  so I was trying to run these scripts first:\r\n\r\nfreeze_graph.py\r\n\r\n> py C:\\tensorflow-master\\tensorflow\\python\\tools\\freeze_graph.py --input_graph=output_graph.pb --input_checkpoint=C:/tmp/_retrain_checkpoint --output_graph=/tmp/frozen_graph.pb --output_node_names=softmax --input_binary=true\r\n\r\nI have an error:\r\n\r\nNames_to_saveables must be a dict mapping string names to Tensors/Variables. Not a variable: Tensor(\"final_retrain_ops/biases/final_biases:0\", shape=(6,), dtype=float32)\r\n\r\nThen optimize_for_inference.py \r\n\r\nMultiple errors \r\n\r\n> WARNING:tensorflow:Didn't find expected Conv2D input to 'module_apply_default/MobilenetV2/expanded_conv_16/depthwise/BatchNorm/FusedBatchNorm'\r\n\r\nScripts doesn't work with any generated .pb file, even some I've downloaded from the Internet\r\n\r\nIt looks like im doing something wrong or these scripts doesn't work with model from tutorial. I there any solution for that?\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from", "Thinks it is related to this https://github.com/tensorflow/tensorflow/issues/16545#issuecomment-382204169", "@skye Labels has been updated.\r\n\r\n@LucasMahieu I actually can use my graph file with tensorflow. The problem is that I probably need to use these two scripts freeze_graph.py and optimize_for_inference.py before I can use it in EmguCV/OpenCV where I cannot even import it becouse of the \"Unknown layer type\" error, but I can import it without any problem using tensorflow 1.5 wrapper for .Net which is EmguTF. I can import model without any problem and test it, so I suppose model is correct, but inside there are some trash (training nodes? no idea) I need to remove before using it in EmguCV.\r\n\r\nI need to find some way to get these scripts work to see if I can import model then to EmguCV. I also need optimization, so Im following: https://www.tensorflow.org/mobile/prepare_models ", "@petewarden are you the right person to address this?", "I have a same problem with it. Without Batch-Norm Layer, I can import created *.pb model. But with batch-norm layer, I cannot import *pb file using opencv function \"ReadNetFromTensorflow\". If you solve this problem, please tell me how to fix it.", "optimize_for_inference \\ --input=frozen_mnist.pb \\ --output=opt_mnist_graph.pb \\ --frozen_graph=True \\ --input_names=input_tensor \\ --output_names=softmax_tensor\r\nhttps://github.com/LucasMahieu The above thing is my output when i command to optimize the freezed_graph! I got freezing the model.\r\n", "I believe this error usually happens when a graph that's already been frozen is fed into freeze_graph.py, and it's been a while since any updates, so closing this issue."]}, {"number": 18876, "title": "Fix link to original LSTM paper", "body": "Hi,\r\n\r\nthe url to the original LSTM paper in `tensorflow/contrib/lite/nnapi/NeuralNetworksShim.h` is no longer available (404 is returned), so this PR fixes it.", "comments": []}, {"number": 18875, "title": "1.7.0 fails to compile on aarch64 with TensorRT support", "body": "JetsonTX2 with JetPack 3.2 which has Cuda9, Cudnn7 and TensorRT 3.0. Here is the content in .tf_configure.bazelrc file:\r\n```\r\nbuild --action_env PYTHON_BIN_PATH=\"/usr/bin/python\"\r\nbuild --action_env PYTHON_LIB_PATH=\"/usr/local/lib/python2.7/dist-packages\"\r\nbuild --force_python=py2\r\nbuild --host_force_python=py2\r\nbuild --python_path=\"/usr/bin/python\"\r\nbuild --define with_jemalloc=true\r\nbuild --define with_gcp_support=true\r\nbuild --define with_hdfs_support=true\r\nbuild --define with_s3_support=true\r\nbuild:kafka --define with_kafka_support=true\r\nbuild:xla --define with_xla_support=true\r\nbuild:gdr --define with_gdr_support=true\r\nbuild:verbs --define with_verbs_support=true\r\nbuild --action_env TF_NEED_OPENCL_SYCL=\"0\"\r\nbuild --action_env TF_NEED_CUDA=\"1\"\r\nbuild --action_env CUDA_TOOLKIT_PATH=\"/usr/local/cuda\"\r\nbuild --action_env TF_CUDA_VERSION=\"9.0\"\r\nbuild --action_env CUDNN_INSTALL_PATH=\"/usr/lib/aarch64-linux-gnu\"\r\nbuild --action_env TF_CUDNN_VERSION=\"7\"\r\nbuild --action_env TENSORRT_INSTALL_PATH=\"/usr/lib/aarch64-linux-gnu\"\r\nbuild --action_env TF_TENSORRT_VERSION=\"4.0.4\"\r\nbuild --action_env TF_CUDA_COMPUTE_CAPABILITIES=\"3.5,5.2\"\r\nbuild --action_env LD_LIBRARY_PATH=\"/usr/local/cuda-9.0/lib64:\"\r\nbuild --action_env TF_CUDA_CLANG=\"0\"\r\nbuild --action_env GCC_HOST_COMPILER_PATH=\"/usr/bin/gcc\"\r\nbuild --config=cuda\r\ntest --config=cuda\r\nbuild --define grpc_no_ares=true\r\nbuild:opt --copt=-march=native\r\nbuild:opt --host_copt=-march=native\r\nbuild:opt --define with_default_optimizations=true\r\nbuild --copt=-DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK\r\nbuild --host_copt=-DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK\r\n```\r\nWhen building pip package:\r\n```\r\n.........................\r\nERROR: Skipping 'tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'build_defs.bzl': no such package '@local_config_tensorrt//': Traceback (most recent call last):\r\n\tFile \"/home/nvidia/sourcecode/tensorflow/third_party/tensorrt/tensorrt_configure.bzl\", line 167\r\n\t\t_trt_lib_version(repository_ctx, trt_install_path)\r\n\tFile \"/home/nvidia/sourcecode/tensorflow/third_party/tensorrt/tensorrt_configure.bzl\", line 77, in _trt_lib_version\r\n\t\t_find_trt_header_dir(repository_ctx, trt_install_path)\r\n\tFile \"/home/nvidia/sourcecode/tensorflow/third_party/tensorrt/tensorrt_configure.bzl\", line 60, in _find_trt_header_dir\r\n\t\tstr(repository_ctx.path((\"%s/../incl...)\r\n\tFile \"/home/nvidia/sourcecode/tensorflow/third_party/tensorrt/tensorrt_configure.bzl\", line 60, in str\r\n\t\trepository_ctx.path((\"%s/../include\" % trt_install_path)).realpath\r\n/usr/lib/include (No such file or directory)\r\nWARNING: Target pattern parsing failed.\r\nERROR: error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'build_defs.bzl': no such package '@local_config_tensorrt//': Traceback (most recent call last):\r\n\tFile \"/home/nvidia/sourcecode/tensorflow/third_party/tensorrt/tensorrt_configure.bzl\", line 167\r\n\t\t_trt_lib_version(repository_ctx, trt_install_path)\r\n\tFile \"/home/nvidia/sourcecode/tensorflow/third_party/tensorrt/tensorrt_configure.bzl\", line 77, in _trt_lib_version\r\n\t\t_find_trt_header_dir(repository_ctx, trt_install_path)\r\n\tFile \"/home/nvidia/sourcecode/tensorflow/third_party/tensorrt/tensorrt_configure.bzl\", line 60, in _find_trt_header_dir\r\n\t\tstr(repository_ctx.path((\"%s/../incl...)\r\n\tFile \"/home/nvidia/sourcecode/tensorflow/third_party/tensorrt/tensorrt_configure.bzl\", line 60, in str\r\n\t\trepository_ctx.path((\"%s/../include\" % trt_install_path)).realpath\r\n/usr/lib/include (No such file or directory)\r\n```\r\nWithout TensorRT support it compiles well.\r\n", "comments": ["Believe this is fixed by #17409.", "I encountered this issue, looks like something wrong with the path to tensorrt.\r\nDin't see any relationship with #17409."]}, {"number": 18874, "title": "Faulty numpy randomness when using GPU", "body": "### System information\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Tested on Slackware Linux 14.2 and Ubuntu 16.04\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: tested on both 1.4 and 1.6\r\n- Python version: 3.6\r\n- CUDA/cuDNN version: 8.0 for TF 1.4 and 9.0 for TF 1.6\r\n- Bazel version: N/A\r\n- GPU model and memory: tested on GTX 960M and GTX 1080\r\n- Exact command to reproduce: N/A\r\n\r\n\r\n### Describe the problem\r\nI am unable to reproduce random numbers generated from numpy when I use it in combination with TF. In the beginning of all my tests, I set\r\n```\r\ntf.set_random_seed(seed)\r\nnp.random.seed(seed)\r\n```\r\n\r\nI have been debugging, and when I use numpy and no TF, all results are reproducible. When I add the TF code, the random numbers stop being reproducible. When I use both TF and numpy, I get the following results:\r\n\r\n1. TF variables are initialized to the same value every time (OK)\r\n2. When I use `np.random.RandomState()` with a set seed instead of direct calls to `np.random.uniform()`, `np.random.normal()`, etc, results are reproducible (OK)\r\n3. When I use direct calls to `np.random.uniform()`, `np.random.normal()`, etc, results are reproducible on CPU but not on GPU (NOT OK)\r\n1080\r\nSince the results are reproducible when using CPU but not GPU, it made me think that this might be a possible bug. \r\n\r\nI am not using any threads so the problem is definitely not caused by race conditions. I am monitoring reproducibility of results only by the random numbers which are generated, which are not in any way affected by the training results from the TF neural net. What is really strange is that the piece of code that seems to be affecting the results is the part about computing and backpropagating gradients. I do not expect that this uses any random numbers generated by numpy in the backend. Furthermore, even if it did, the order of my calls to `np.random` and to `sess.run` is always deterministic, so the same random numbers should be observed between separate runs. \r\n\r\nMy code is somewhat too big at the moment to post. I can try to compile some simple example where the issue occurs, but I first wanted to make sure that this is indeed not the expected behavior.\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nBazel version\nGPU model and memory\nExact command to reproduce", "Updated", "Many GPU ops, like convolutions, are not deterministic. So even if you don't use any random numbers, you might get different results for GPU ops if you run them multiple times. See #12871.\r\n\r\nI'm going to assume this is the issue and close this, because you said this is only affecting the gradients, which often involve doing convolutions. Please comment/reopen if you think this is not the case.", "Thanks for the response. I think you misunderstood what I was saying, maybe I was not clear enough.\r\nHere is a mock up (just to illustrate the issue, it is not the *exact* piece of code which reproduces the problem):\r\n\r\n```\r\nseed = 42\r\nnp.random.seed(seed)\r\ntf.set_random_seed(seed)\r\n\r\n# build graph\r\nsess = tf.Session()\r\nrands = []\r\n\r\nfor i in range(30000):\r\n  r = np.random.uniform(0,1)\r\n  rands.append(r)\r\n  sess.run(train_op, feed_dict=...)\r\n```\r\n\r\nThe issue that I am experiencing is that `rands` ends up with different numbers between runs. This is happening only when using GPU. On CPU, the numbers are the same. When I remove the line `sess.run(train_op, feed_dict=...)`, everything works fine. Also if I use `prng = np.random.RandomState(); prng.seed(seed)` and then sample with `r = prng.uniform(0,1)`, the generated numbers are the same between runs on both CPU and GPU (`sess.run(train_op, feed_dict=...)` is also being executed).\r\n\r\nI was wondering whether this is expected behavior? If not, I will try to create a proper example which reproduces the problem so we can debug further.\r\n", "So the issue is that running TensorFlow sessions seems to affect the random numbers that numpy generates.\r\n\r\n/CC @zffchen78 do you know if this is expected? IMO this shouldn't occur, because TensorFlow should only use it's own seed for randomness.", "Yes, that seems to be the case for some reason. That's what I narrowed it down to while I was debugging my code.", "@nikonikolov Could check whether the error persists with TF1.12 or 1.13? Thanks!", "Closing due to lack of recent activity, but please let me know if I'm mistaken. Since this issue is old at this point, please reopen the issue if it still occurs when tried with the latest version of Tensorflow. Thank you.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=18874\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=18874\">No</a>\n"]}, {"number": 18873, "title": "Update interpreter.cc", "body": "Updated file to remove condition, reduce complexity and reduced lines.", "comments": ["Nagging Assignee @ekelsen: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@ekelsen Can you please check this changes? ", "Nagging Assignee @ekelsen: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ekelsen: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ekelsen: It has been 44 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ekelsen: It has been 59 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ekelsen: It has been 74 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ekelsen: It has been 89 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "It seems like there are conflicts. Please fix merge conflicts and ill get someone to review this.", "@case540 I have resolved conflicts. Please review it", "Sorry, I should have taken a closer look at this before asking you do fix the conflicts. Since this PR just changes around one if statement, going to close."]}, {"number": 18871, "title": "Tensorflow not working inside spyder IDE (Anaconda on Windows), even after activating it through command prompt .", "body": "### System information\r\nWindows 10 , Anaconda 3.6, 64 bit\r\nAnaconda installed using anaconda page https://www.anaconda.com/download/#windows\r\nPython version : 3.6.5\r\ntensorflow version : 3.6\r\n- Tensorflow was installed using  command :  conda create -n tensorflow pip python=3.6 \r\n\r\n### Describe the problem\r\nI have installed the package tensorflow using conda. After installation and also activation I tried to use it in Spyder IDE but it was not working. In Spyder IDE,for command - import tensorflow as tf , it is throwing error : ModuleNotFoundError: No module named 'tensorflow'.\r\n\r\n\r\n### Source code / logs\r\nCommand used on CMD prompt : conda create -n tfp3.6 phyton=3.6\r\nactivate tfp3.6\r\nspyder\r\n\r\ncommand used in Spyder IDE: import tensorflow as tf\r\nerror : ModuleNotFoundError: No module named 'tensorflow'\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "You have mentioned wrong versions in the system information. There is no Tensorflow version 3.6, could you update the information. Thank you.\r\n\r\n", "It has been 16 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 31 days with no activity and the `awaiting response` label was assigned. Is this still an issue?"]}, {"number": 18870, "title": "Clarified difference between GFile and FastGFile.", "body": "Fixes #12663", "comments": ["Nagging Assignee @ekelsen: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ekelsen: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ekelsen: It has been 44 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ekelsen: It has been 59 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ekelsen: It has been 74 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ekelsen: It has been 89 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 18869, "title": "Update version string to 1.8.0.", "body": "", "comments": []}, {"number": 18868, "title": "Adding the h5py dependency in devel docker files.", "body": "", "comments": ["According to https://github.com/keras-team/keras/pull/9830, the image also needs `apt-get install libhdf5-serial-dev`."]}, {"number": 18867, "title": "Updating release notes.", "body": "", "comments": []}, {"number": 18866, "title": "fix for AR not being defined.", "body": "This is the change as outlined in https://github.com/tensorflow/tensorflow/issues/14186", "comments": ["Nagging Assignee @ekelsen: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ekelsen: It has been 30 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ekelsen: It has been 45 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ekelsen: It has been 60 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ekelsen: It has been 75 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ekelsen: It has been 90 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ekelsen: It has been 105 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 18865, "title": "use freeze_graph and report TypeError: main() takes exactly 1 argument (0 given)", "body": "ubuntu@vm:~/code/tensorflow/tensorflow$ freeze_graph \\\r\n> --input_graph=/tmp/mobilenet_v1_1.0_224.pb \\\r\n> --input_meta_graph=/tmp/mobilenet_v1_1.0_224.ckpt.meta \\\r\n> --input_binary=true \\\r\n> --input_checkpoint=/tmp/checkpoints/mobilenet_v1_1.0_224.ckpt \\\r\n> --output_node_names=MobileNetV1/Predictions/Reshape_1 \\\r\n> --output_graph=/tmp/mobilenet_v1_1.0_224_frozen.pb\r\n/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/freeze_graph\", line 11, in <module>\r\n    sys.exit(main())\r\nTypeError: main() takes exactly 1 argument (0 given)", "comments": ["Try input_meta_graph=/tmp/mobilenet_v1_1.0_224.ckpt instead of .meta", "I found solution:\r\n\r\npython -m tensorflow.python.tools.freeze_graph \\\r\n--input_graph=/tmp/mobilenet_v1_1.0_224.pb \\\r\n--input_checkpoint=/tmp/checkpoints/mobilenet_v1_1.0_224.ckpt \\\r\n--input_binary=true \\\r\n--output_graph=/tmp/mobilenet_v1_1.0_224_frozen.pb \\\r\n--output_node_names=MobilenetV1/Predictions/Reshape_1"]}, {"number": 18864, "title": "Update download-models.gradle", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I m not getting it.\n\nOn Thu, May 10, 2018, 5:45 PM Alfred Sorten Wolf <notifications@github.com>\nwrote:\n\n> Nagging Assignee @ekelsen <https://github.com/ekelsen>: It has been 14\n> days with no activity and this issue has an assignee. Please update the\n> label and/or status accordingly.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/18864#issuecomment-388041967>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/Ae03YFLP-XN3_nXGcyOGD7cVahep1RSZks5txDZ2gaJpZM4TjsDK>\n> .\n>\n", "Alfered I have solve this problen long ago better to close this issue.\n\nOn Thu, Nov 15, 2018, 12:08 AM Alfred Sorten Wolf <notifications@github.com>\nwrote:\n\n> Nagging Reviewers @aselle <https://github.com/aselle>: You have been\n> added as a reviewer to this pull request. Please add your review or\n> reassign. It has been 95 days with no activity and the awaiting review\n> label has been applied.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/18864#issuecomment-438779116>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/Ae03YN1NGg2K4MRXrq2byZzolbe9tfytks5uvGo1gaJpZM4TjsDK>\n> .\n>\n", "Nagging Reviewer @aselle: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 74 days with no activity and the `awaiting review` label has been applied."]}, {"number": 18863, "title": "[Feature Request] Fold batch_norm with depthwise_conv transformation graph", "body": "Hi,\r\n\r\nI think it could be interesting to have a transformation graph function to fold batch_norms into depthwise_conv like with standard conv2d [like here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md#fold_batch_norms).", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "@rmlarsen Is this sort of graph transformation in the road map?", "@LucasMahieu,\r\nSorry for the delayed response. As per [this Github page](https://github.com/tensorflow/tensorflow/commits/master/tensorflow/tools/graph_transforms/README.md), **`Graph Transforms`** are not actively maintained since **`Tensorflow Version 2.x`** has been released. Can you please let us know if this feature request is still relevant? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Quick note: this is on our roadmap internally, though it might take a version or two until it's available."]}, {"number": 18862, "title": "failure when using Dataset to build a model with dilation convolutional layers", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution **:  Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.5.0\r\n- **Python version**: 3.6.4\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: \r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI happened to find this issue when I tried to add dilation convolution to my model. Here I give basic steps to reproduce the issue.\r\n\r\nFirst, I use placeholder to create a tiny network.\r\n```\r\n# [batch, 1, length, feat_dim]\r\ninput = tf.placeholder(tf.float32, shape=(128, 1, 100, 20), name='input')\r\nlabel = tf.placeholder(tf.int64, shape=(128,), name='label')\r\ninput_value = np.random.normal(size=(128,1,100,20))\r\nlabel_value = np.random.randint(9852, size=(128))\r\n\r\nconv0 = tf.layers.conv2d(input,\r\n                         512,\r\n                         (1, 5),\r\n                         dilation_rate=(1, 1),\r\n                         activation=tf.nn.relu,\r\n                         name='conv0')\r\n\r\nconv1 = tf.layers.conv2d(conv0,\r\n                         512,\r\n                         (1, 3),\r\n                         dilation_rate=(1, 2),\r\n                         activation=tf.nn.relu,\r\n                         name='conv1')\r\nconv1_squeeze, _ = tf.nn.moments(tf.squeeze(conv1, [1]), axes=[1])\r\nlogits = tf.layers.dense(conv1_squeeze, 9852, name='logits')\r\nloss = tf.losses.sparse_softmax_cross_entropy(labels=label, logits=logits, scope=\"loss\")\r\ntrain_op = tf.train.AdamOptimizer(0.01).minimize(loss)\r\n\r\ninit = tf.global_variables_initializer()\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(init)\r\n    _ = sess.run(train_op, feed_dict={input:input_value, label:label_value})\r\n    print(\"Here we are\")\r\n```\r\nI add two conv layers and the second one uses a dilation convolution with rate=2. It is actually 1d conv, though I use conv2d here. A mean pooling is performed before the fully connected layer. It works.\r\n\r\nThen I introduce the Dataset to build to the input pipeline:\r\n```\r\ndef _parse_tfrecord(example_proto):\r\n    dics = {'input': tf.FixedLenFeature(shape=(), dtype=tf.string),\r\n            'input_shape': tf.FixedLenFeature(shape=(2,), dtype=tf.int64),\r\n            'output': tf.FixedLenFeature(shape=(), dtype=tf.int64)}\r\n    parsed_example = tf.parse_single_example(example_proto, dics)\r\n    # the dtype of feature is 'float32'\r\n    parsed_example['input'] = tf.decode_raw(parsed_example['input'], tf.float32)\r\n    parsed_example['input'] = tf.reshape(parsed_example['input'], parsed_example['input_shape'])\r\n    return parsed_example\r\n\r\ndef create_variable_dataset(filenames, batch_size, feat_dim):\r\n    dataset = tf.data.Dataset.from_tensor_slices(filenames)\r\n    dataset = dataset.interleave(lambda filename:\r\n                               tf.data.TFRecordDataset(filename).map(\r\n                                   _parse_tfrecord, num_parallel_calls=8).padded_batch(\r\n                                       batch_size,\r\n                                       padded_shapes=({'input': [None, feat_dim], 'input_shape': [2], 'output': []})),\r\n                                cycle_length=len(filenames), block_length=1\r\n                               )\r\n\r\n    dataset = dataset.prefetch(5)\r\n    itr = dataset.make_initializable_iterator()\r\n    element = itr.get_next()\r\n    return itr, element['input'], element['output']\r\n\r\ntrain_itr, input, label = create_variable_train_dataset(['egs/egs.1.tfrecord'],\r\n                                                                      batch_size=64,\r\n                                                                      feat_dim=20)\r\ninput = tf.expand_dims(input, 1)\r\nconv0 = tf.layers.conv2d(input,\r\n                         512,\r\n                         (1, 5),\r\n                         dilation_rate=(1, 1),\r\n                         activation=tf.nn.relu,\r\n                         name='conv0')\r\n\r\nconv1 = tf.layers.conv2d(conv0,\r\n                         512,\r\n                         (1, 3),\r\n                         dilation_rate=(1, 2),\r\n                         activation=tf.nn.relu,\r\n                         name='conv1')\r\n\r\nconv1_squeeze, _ = tf.nn.moments(tf.squeeze(conv1, [1]), axes=[1])\r\nlogits = tf.layers.dense(conv1_squeeze, 9852, name='logits')\r\nloss = tf.losses.sparse_softmax_cross_entropy(labels=label, logits=logits, scope=\"loss\")\r\ntrain_op = tf.train.AdamOptimizer(0.01).minimize(loss)\r\n\r\ninit = tf.global_variables_initializer()\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(init)\r\n    sess.run(train_itr.initializer)\r\n    _ = sess.run(train_op)\r\n    print(\"Here we are\")\r\n```\r\nI load to the tfrecords which are made before. The data loaded has size [length, feat_dim]. With batch, it becomes [batch, length, feat_dim]. And it also works.\r\n\r\nNow, I slightly change the input pipeline to\r\n```\r\ndef create_variable_train_dataset(filenames, batch_size, feat_dim, shuffle_size=-1):\r\n    dataset = tf.data.Dataset.from_tensor_slices(filenames)\r\n    dataset = dataset.interleave(lambda filename:\r\n                               tf.data.TFRecordDataset(filename).map(\r\n                                   _parse_tfrecord, num_parallel_calls=8).apply(\r\n                                   tf.contrib.data.padded_batch_and_drop_remainder(\r\n                                       batch_size,\r\n                                       padded_shapes=({'input': [None, feat_dim], 'input_shape': [2], 'output': []}))),\r\n                                cycle_length=len(filenames), block_length=1\r\n                               )\r\n\r\n    dataset = dataset.prefetch(5)\r\n    itr = dataset.make_initializable_iterator()\r\n    element = itr.get_next()\r\n    return itr, element['input'], element['output']\r\n```\r\nIt breaks and throws the exception:\r\n```\r\n2018-04-25 22:07:04.779657: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\r\nTraceback (most recent call last):\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1350, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1329, in _run_fn\r\n    status, run_metadata)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 473, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: padded_shape[1]=97 is not divisible by block_shape[1]=2\r\n\t [[Node: conv1/SpaceToBatchND = SpaceToBatchND[T=DT_FLOAT, Tblock_shape=DT_INT32, Tpaddings=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv0/Relu, conv1/SpaceToBatchND/block_shape, conv1/strided_slice_2)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Program Files (x86)\\JetBrains\\PyCharm Community Edition 2016.1\\helpers\\pydev\\pydevd.py\", line 1530, in <module>\r\n    globals = debugger.run(setup['file'], None, None, is_module)\r\n  File \"C:\\Program Files (x86)\\JetBrains\\PyCharm Community Edition 2016.1\\helpers\\pydev\\pydevd.py\", line 937, in run\r\n    pydev_imports.execfile(file, globals, locals)  # execute the script\r\n  File \"C:\\Program Files (x86)\\JetBrains\\PyCharm Community Edition 2016.1\\helpers\\pydev\\_pydev_imps\\_pydev_execfile.py\", line 18, in execfile\r\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n  File \"G:/kaldi-master/egs/fisher/v3/xvector/train_model.py\", line 3, in <module>\r\n    from xvector_train import *\r\n  File \"G:/kaldi-master/egs/fisher/v3/xvector\\xvector_train.py\", line 48, in <module>\r\n    _ = sess.run(train_op)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 895, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1128, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1344, in _do_run\r\n    options, run_metadata)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1363, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: padded_shape[1]=97 is not divisible by block_shape[1]=2\r\n\t [[Node: conv1/SpaceToBatchND = SpaceToBatchND[T=DT_FLOAT, Tblock_shape=DT_INT32, Tpaddings=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv0/Relu, conv1/SpaceToBatchND/block_shape, conv1/strided_slice_2)]]\r\n\r\nCaused by op 'conv1/SpaceToBatchND', defined at:\r\n  File \"C:\\Program Files (x86)\\JetBrains\\PyCharm Community Edition 2016.1\\helpers\\pydev\\pydevd.py\", line 1530, in <module>\r\n    globals = debugger.run(setup['file'], None, None, is_module)\r\n  File \"C:\\Program Files (x86)\\JetBrains\\PyCharm Community Edition 2016.1\\helpers\\pydev\\pydevd.py\", line 937, in run\r\n    pydev_imports.execfile(file, globals, locals)  # execute the script\r\n  File \"C:\\Program Files (x86)\\JetBrains\\PyCharm Community Edition 2016.1\\helpers\\pydev\\_pydev_imps\\_pydev_execfile.py\", line 18, in execfile\r\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n  File \"G:/kaldi-master/egs/fisher/v3/xvector/train_model.py\", line 3, in <module>\r\n    from xvector_train import *\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"G:/kaldi-master/egs/fisher/v3/xvector\\xvector_train.py\", line 36, in <module>\r\n    name='conv1')\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\layers\\convolutional.py\", line 614, in conv2d\r\n    return layer.apply(inputs)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 762, in apply\r\n    return self.__call__(inputs, *args, **kwargs)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 652, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\layers\\convolutional.py\", line 167, in call\r\n    outputs = self._convolution_op(inputs, self.kernel)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 838, in __call__\r\n    return self.conv_op(inp, filter)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 502, in __call__\r\n    return self.call(inp, filter)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 493, in _with_space_to_batch_call\r\n    paddings=paddings)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 6670, in space_to_batch_nd\r\n    paddings=paddings, name=name)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): padded_shape[1]=97 is not divisible by block_shape[1]=2\r\n\t [[Node: conv1/SpaceToBatchND = SpaceToBatchND[T=DT_FLOAT, Tblock_shape=DT_INT32, Tpaddings=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv0/Relu, conv1/SpaceToBatchND/block_shape, conv1/strided_slice_2)]]\r\n```\r\nAll the examples in the tfrecords have the size [100, 20].The only thing changed is the batch function \"padded_batch_and_drop_remainder\". I don't know why it tell me the dilation operation cannot be performed because padding should be used in the operation. I felt stranger that if I change the dilation rate of the first layer (which is 1 now) to (1, 2), it works again!\r\n```\r\nconv0 = tf.layers.conv2d(input,\r\n                         512,\r\n                         (1, 5),\r\n                         dilation_rate=(1, 2),\r\n                         activation=tf.nn.relu,\r\n                         name='conv0')\r\n```\r\nCould anyone tell me what is going on here? Is anything wrong with the pipeline, or it is a bug ?\r\nI use TF 1.5.0 in a server.", "comments": ["@mrry can you take a look at this? I can't tell if it could be a bug or not.", "I think this is working as intended: if you specify `None` for a dimension in the `padded_shapes` then its size at runtime will be determined by the batch element with the largest size in that dimension. From the error message it appears that there is an element with size 97 in that dimension.\r\n\r\nTo fix this, you\u2019ll either need to ensure that the input data all have a size divisible by 2 in that dimension, or you\u2019ll need to add extra padding to make the resulting size divisible by 2 (e.g. using `tf.pad()`).", "@mrry If the input length is 100 (which is the case in the egs), after 1st conv, it should be 96. I don't know where 97 comes from? The actual length of the data is the same when using padded_batch and padded_batch_and_drop_remainder. But padded_batch _works_, which is weird.", "That does sound strange. Try computing `tf.shape(input)` and `tf.shape(label)` and printing their values to see if there\u2019s anything unexpected about the shapes being returned from the iterator.", "If padded_batch_and_drop_remainder is used, the shape is [128, ?, 20], which is [batch, length, dim], while padded_batch give me [?, ?, 20]. I think this is expected. The actual length is 100 in the examples and the only difference is the batch function I used.\r\nThe shapes between input and label seem to be consistent in both conditions. \r\nI just change padded_batch_and_drop_remainder to padded_batch in my code, and it works well now."]}]