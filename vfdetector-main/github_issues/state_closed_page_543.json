[{"number": 37430, "title": "MKL Error on Bazel 2.0 (TensorFlow 2.1 latest - nightly)", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10 x64 18363.693\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\n- TensorFlow installed from (source or binary): from git\r\n- TensorFlow version: TF 2.1 latest version\r\n- Python version: 3.7/3.8\r\n- Installed using virtualenv? pip? conda?: no\r\n- Bazel version (if compiling from source): 2.0.0\r\n- GCC/Compiler version (if compiling from source): VS 2019\r\n- CUDA/cuDNN version: 10.2\r\n- GPU model and memory: Nvidia 1070 ti\r\n\r\n\r\n\r\n**Describe the problem**\r\nAt the initial stage of the build, an error appears.\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.24.28314\\include\\xtr1common(163): note: see reference to class template instantiation 'std::integral_constant<bool,false>' being compiled\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.24.28314\\include\\xtr1common(163): note: see reference to class template instantiation 'std::disjunction<_Traits...>' being compiled\r\nERROR: C:/tensorflow/tensorflow/core/kernels/BUILD:8128:1: C++ compilation of rule '//tensorflow/core/kernels:mkl_aggregate_ops' failed (Exit 2)\r\n.\\tensorflow/core/util/mkl_util.h(1253): error C2131: expression did not evaluate to a constant\r\n.\\tensorflow/core/util/mkl_util.h(1252): note: failure was caused by a read of a variable outside its lifetime\r\n.\\tensorflow/core/util/mkl_util.h(1252): note: see usage of 'dim'\r\n.\\tensorflow/core/util/mkl_util.h(1254): error C2131: expression did not evaluate to a constant\r\n.\\tensorflow/core/util/mkl_util.h(1252): note: failure was caused by a read of a variable outside its lifetime\r\n.\\tensorflow/core/util/mkl_util.h(1252): note: see usage of 'dim'\r\n.\\tensorflow/core/util/mkl_util.h(1256): error C3863: array type 'dnnl_dim_t [kNumDims]' is not assignable\r\n.\\tensorflow/core/util/mkl_util.h(1257): error C3863: array type 'dnnl_dim_t [kNumDims]' is not assignable\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 2448.446s, Critical Path: 179.48s\r\nINFO: 4686 processes: 4686 local.\r\nFAILED: Build did NOT complete successfully\r\n", "comments": ["build cmd\r\nbazel --output_base=c:/bazel/output_dir/ build --config=mkl --config=opt --config=cuda  //tensorflow/tools/pip_package:build_pip_package", "@Expert73 \r\n\r\nCan you please provide us the error log. Thanks!", "Tensorflow 2.1 latest (nightly)\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.24.28314\\include\\xtr1common(163): note: see reference to class template instantiation 'std::integral_constant<bool,false>' being compiled\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.24.28314\\include\\xtr1common(163): note: see reference to class template instantiation 'std::disjunction<_Traits...>' being compiled\r\nERROR: C:/tensorflow/tensorflow/core/kernels/BUILD:8128:1: C++ compilation of rule '//tensorflow/core/kernels:mkl_aggregate_ops' failed (Exit 2)\r\n.\\tensorflow/core/util/mkl_util.h(1253): error C2131: expression did not evaluate to a constant\r\n.\\tensorflow/core/util/mkl_util.h(1252): note: failure was caused by a read of a variable outside its lifetime\r\n.\\tensorflow/core/util/mkl_util.h(1252): note: see usage of 'dim'\r\n.\\tensorflow/core/util/mkl_util.h(1254): error C2131: expression did not evaluate to a constant\r\n.\\tensorflow/core/util/mkl_util.h(1252): note: failure was caused by a read of a variable outside its lifetime\r\n.\\tensorflow/core/util/mkl_util.h(1252): note: see usage of 'dim'\r\n.\\tensorflow/core/util/mkl_util.h(1256): error C3863: array type 'dnnl_dim_t [kNumDims]' is not assignable\r\n.\\tensorflow/core/util/mkl_util.h(1257): error C3863: array type 'dnnl_dim_t [kNumDims]' is not assignable\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 2448.446s, Critical Path: 179.48s\r\nINFO: 4686 processes: 4686 local.\r\nFAILED: Build did NOT complete successfully", "I think, problem now here\r\n DCHECK_EQ(dim.size(), strides.size());\r\n#ifdef ENABLE_MKLDNN_V1\r\n  const int kNumDims = dim.size();\r\n  mkldnn_dim_t input_dims[kNumDims];\r\n  mkldnn_dim_t input_strides[kNumDims];\r\n  for (int i = 0; i < kNumDims; ++i) {\r\n    input_dims[i] = dim[i];\r\n    input_strides[i] = strides[i];\r\n  }\r\n\r\nin old (work code) was:\r\nDCHECK_EQ(dim.size(), strides.size());\r\n#ifdef ENABLE_MKLDNN_V1\r\n  mkldnn_dim_t input_dims[dim.size()];\r\n  mkldnn_dim_t input_strides[dim.size()];\r\n  for (size_t i = 0; i < dim.size(); ++i) {\r\n    input_dims[i] = dim[i];\r\n    input_strides[i] = strides[i];\r\n  }\r\n\r\nwhat do you think? how to fix the problem?", "I have the same problem with Tensorflow 2.2.0 and Visual Studio 2019.\r\nI solved the problem with a small patch, I don't know if a memory leak is possible or not like that.\r\n```\r\n#ifdef ENABLE_MKLDNN_V1\r\nconst int kNumDims = dim.size();\r\nmkldnn_dim_t input_dims[kNumDims];\r\nmkldnn_dim_t input_strides[kNumDims];\r\nfor (int i = 0; i < kNumDims; ++i) {\r\ninput_dims[i] = dim[i];\r\ninput_strides[i] = strides[i];\r\n  try {\r\n    mkldnn_memory_desc_init_by_strides(blocked_md, kNumDims, input_dims,\r\n                                       memory::convert_to_c(dtype),\r\n                                       input_strides);\r\n}\r\n......\r\n```\r\n\r\nbecome \r\n```\r\n#ifdef ENABLE_MKLDNN_V1\r\n  const int kNumDims = dim.size();\r\n  mkldnn_dim_t * input_dims = new mkldnn_dim_t[kNumDims];\r\n  mkldnn_dim_t * input_strides = new mkldnn_dim_t[kNumDims];\r\n  for (int i = 0; i < kNumDims; ++i) {\r\n    input_dims[i] = dim[i];\r\n    input_strides[i] = strides[i];\r\n  }\r\n  try {\r\n    mkldnn_memory_desc_init_by_strides(blocked_md, kNumDims, input_dims,\r\n                                       memory::convert_to_c(dtype),\r\n                                       input_strides);\r\n    delete[] input_dims;\r\n    delete[] input_strides;\r\n  } catch (mkldnn::error& e) {\r\n    delete[] input_dims;\r\n    delete[] input_strides;\r\n    return Status(error::Code::INTERNAL,\r\n                  tensorflow::strings::StrCat(\r\n                      \"Failed to create blocked memory descriptor.\",\r\n                      \"Status: \", e.status, \", message: \", e.message));\r\n  }\r\n```\r\nNow my compilation stop in /Eigen/src/Core/util/ReenableStupidWarnings.h \r\nI don't konw if there is a relation between my patch and this problem \r\n\r\nedit 1: \r\n\r\nNo relation between the patch and my error, its a compilation error where \r\nit can't cast from` vector<long int> to vector<int64_t>`\r\n", "I think this is a new problem", "ERROR: C:/tensorflow/tensorflow/core/kernels/BUILD:7897:1: C++ compilation of rule '//tensorflow/core/kernels:mkl_conv_op' failed (Exit 2)\r\n.\\tensorflow/core/kernels/mkl_conv_ops.h(157): error C2679: binary '=': no operator found which takes a right-hand operand of type 'std::vector<long,std::allocator<long>>' (or there is no acceptable conversion)\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.25.28610\\include\\vector(1175): note: could be 'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(std::initializer_list<_Ty>)'\r\n        with\r\n        [\r\n            _Ty=dnnl::memory::dim\r\n        ]\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.25.28610\\include\\vector(1167): note: or       'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(const std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &)'\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.25.28610\\include\\vector(664): note: or       'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &&) noexcept(<expr>)'\r\n.\\tensorflow/core/kernels/mkl_conv_ops.h(157): note: while trying to match the argument list '(dnnl::memory::dims, std::vector<long,std::allocator<long>>)'\r\n.\\tensorflow/core/kernels/mkl_conv_ops.h(182): error C2679: binary '=': no operator found which takes a right-hand operand of type 'std::vector<long,std::allocator<long>>' (or there is no acceptable conversion)\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.25.28610\\include\\vector(1175): note: could be 'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(std::initializer_list<_Ty>)'\r\n        with\r\n        [\r\n            _Ty=dnnl::memory::dim\r\n        ]\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.25.28610\\include\\vector(1167): note: or       'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(const std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &)'\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.25.28610\\include\\vector(664): note: or       'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &&) noexcept(<expr>)'\r\n.\\tensorflow/core/kernels/mkl_conv_ops.h(182): note: while trying to match the argument list '(dnnl::memory::dims, std::vector<long,std::allocator<long>>)'\r\n.\\tensorflow/core/kernels/mkl_conv_ops.h(246): error C2679: binary '=': no operator found which takes a right-hand operand of type 'std::vector<long,std::allocator<long>>' (or there is no acceptable conversion)\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.25.28610\\include\\vector(1175): note: could be 'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(std::initializer_list<_Ty>)'\r\n        with\r\n        [\r\n            _Ty=dnnl::memory::dim\r\n        ]\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.25.28610\\include\\vector(1167): note: or       'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(const std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &)'\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.25.28610\\include\\vector(664): note: or       'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &&) noexcept(<expr>)'\r\n.\\tensorflow/core/kernels/mkl_conv_ops.h(246): note: while trying to match the argument list '(dnnl::memory::dims, std::vector<long,std::allocator<long>>)'\r\n.\\tensorflow/core/kernels/mkl_conv_ops.h(254): error C2679: binary '=': no operator found which takes a right-hand operand of type 'std::vector<long,std::allocator<long>>' (or there is no acceptable conversion)\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.25.28610\\include\\vector(1175): note: could be 'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(std::initializer_list<_Ty>)'\r\n        with\r\n        [\r\n            _Ty=dnnl::memory::dim\r\n        ]\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.25.28610\\include\\vector(1167): note: or       'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(const std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &)'\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.25.28610\\include\\vector(664): note: or       'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &&) noexcept(<expr>)'\r\n.\\tensorflow/core/kernels/mkl_conv_ops.h(254): note: while trying to match the argument list '(dnnl::memory::dims, std::vector<long,std::allocator<long>>)'\r\n.\\tensorflow/core/kernels/mkl_conv_ops.h(283): error C2679: binary '=': no operator found which takes a right-hand operand of type 'std::vector<long,std::allocator<long>>' (or there is no acceptable conversion)\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.25.28610\\include\\vector(1175): note: could be 'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(std::initializer_list<_Ty>)'\r\n        with\r\n        [\r\n            _Ty=dnnl::memory::dim\r\n        ]\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.25.28610\\include\\vector(1167): note: or       'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(const std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &)'\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.25.28610\\include\\vector(664): note: or       'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &&) noexcept(<expr>)'\r\n.\\tensorflow/core/kernels/mkl_conv_ops.h(283): note: while trying to match the argument list '(dnnl::memory::dims, std::vector<long,std::allocator<long>>)'\r\n.\\tensorflow/core/kernels/mkl_conv_ops.h(474): error C2679: binary '=': no operator found which takes a right-hand operand of type 'std::vector<long,std::allocator<long>>' (or there is no acceptable conversion)\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.25.28610\\include\\vector(1175): note: could be 'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(std::initializer_list<_Ty>)'\r\n        with\r\n        [\r\n            _Ty=dnnl::memory::dim\r\n        ]\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.25.28610\\include\\vector(1167): note: or       'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(const std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &)'\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.25.28610\\include\\vector(664): note: or       'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &&) noexcept'\r\n.\\tensorflow/core/kernels/mkl_conv_ops.h(474): note: while trying to match the argument list '(dnnl::memory::dims, std::vector<long,std::allocator<long>>)'\r\n.\\tensorflow/core/kernels/mkl_conv_ops.h(482): error C2679: binary '=': no operator found which takes a right-hand operand of type 'std::vector<long,std::allocator<long>>' (or there is no acceptable conversion)\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.25.28610\\include\\vector(1175): note: could be 'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(std::initializer_list<_Ty>)'\r\n        with\r\n        [\r\n            _Ty=dnnl::memory::dim\r\n        ]\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.25.28610\\include\\vector(1167): note: or       'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(const std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &)'\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.25.28610\\include\\vector(664): note: or       'std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>>::operator =(std::vector<dnnl::memory::dim,std::allocator<dnnl::memory::dim>> &&) noexcept'\r\n.\\tensorflow/core/kernels/mkl_conv_ops.h(482): note: while trying to match the argument list '(dnnl::memory::dims, std::vector<long,std::allocator<long>>)'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 716.229s, Critical Path: 45.72s\r\nINFO: 2357 processes: 2357 local.\r\nFAILED: Build did NOT complete successfully", "i solved it too by changing the type from long int to memozy::dim, it seem cleaner for me\r\ntensorflow/core/kernels/mkl_conv_ops.h\r\n\r\n```\r\n-#define MKLDNN_SIZE_DTYPE long int\r\n+#define MKLDNN_SIZE_DTYPE memory::dim\r\n```\r\n\r\nNow the compilation takes many hours but don't want to end :(\r\n\r\nCompiling tensorflow/core/kernels/mkl_cwise_ops_common.cc; 9752s local\r\n", "I have i7-9700K\r\nFor examlpe for TF 2.1 mkl_cwise_ops_common.cc compiled 16000s\r\n\u0421omplete code build lasted 7-8 hours.\r\n", "without mkl \u0421omplete code build lasted 1-1,5 hours.", "Thanks, i was thinking it was a bug and stoped the compilation after 11000s :(\r\nI have a I7-9750H Laptop, i think it will take 12-15H then.\r\nI compile tensorflow for CUDA 10.2 but just add MKL for the fun.\r\nit's worth it or not ?\r\n\r\nI also created a  pull request for the change \r\nhttps://github.com/tensorflow/tensorflow/pull/37785", "stable gain of 3-5% when training models on my cpu.", "Thanks a lot!", "New error in next step.", "ERROR: C:/tensorflow/tensorflow/lite/python/optimize/BUILD:50:1: Linking of rule '//tensorflow/lite/python/optimize:_tensorflow_lite_wrap_calibration_wrapper.so' failed (Exit 1120)\r\nLINK : warning LNK4044: unrecognized option '/ldl'; ignored\r\nLINK : warning LNK4044: unrecognized option '/lm'; ignored\r\nLINK : warning LNK4044: unrecognized option '/lpthread'; ignored\r\nmklml.lib(mklml.dll) : warning LNK4006: __NULL_IMPORT_DESCRIPTOR already defined in libiomp5md.lib(libiomp5md.dll); second definition ignored\r\n   Creating library bazel-out/x64_windows-opt/bin/tensorflow/lite/python/optimize/lib_tensorflow_lite_wrap_calibration_wrapper.so.ifso and object bazel-out/x64_windows-opt/bin/tensorflow/lite/python/optimize/lib_tensorflow_lite_wrap_calibration_wrapper.so.exp\r\nLINK : warning LNK4217: symbol '?DEVICE_CPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_CPU)' defined in 'libtensor.lo(types.o)' is imported by 'libarithmetic_optimizer.a(arithmetic_optimizer.o)' in function '\"bool __cdecl tensorflow::grappler::`anonymous namespace'::NodeIsOnCpu(class tensorflow::NodeDef const &)\" (?NodeIsOnCpu@?A0x53e44b13@grappler@tensorflow@@YA_NAEBVNodeDef@3@@Z)'\r\nLINK : warning LNK4286: symbol '?DEVICE_CPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_CPU)' defined in 'libtensor.lo(types.o)' is imported by 'libmemory_optimizer.a(memory_optimizer.o)'\r\nLINK : warning LNK4286: symbol '?DEVICE_CPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_CPU)' defined in 'libtensor.lo(types.o)' is imported by 'libpin_to_host_optimizer.a(pin_to_host_optimizer.o)'\r\nLINK : warning LNK4286: symbol '?DEVICE_CPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_CPU)' defined in 'libtensor.lo(types.o)' is imported by 'libutils.a(utils.o)'\r\nLINK : warning LNK4286: symbol '?DEVICE_GPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_GPU)' defined in 'libtensor.lo(types.o)' is imported by 'libutils.a(utils.o)'\r\nLINK : warning LNK4217: symbol '?DEVICE_GPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_GPU)' defined in 'libtensor.lo(types.o)' is imported by 'libarithmetic_optimizer.a(arithmetic_optimizer.o)' in function '\"private: bool __cdecl tensorflow::grappler::`anonymous namespace'::ReorderCastLikeAndValuePreserving::NodeIsOnCpuOrGpu(class tensorflow::NodeDef const *)const \" (?NodeIsOnCpuOrGpu@ReorderCastLikeAndValuePreserving@?A0x53e44b13@grappler@tensorflow@@AEBA_NPEBVNodeDef@4@@Z)'\r\nLINK : warning LNK4286: symbol '?DEVICE_GPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_GPU)' defined in 'libtensor.lo(types.o)' is imported by 'libauto_mixed_precision.a(auto_mixed_precision.o)'\r\nLINK : warning LNK4286: symbol '?DEVICE_GPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_GPU)' defined in 'libtensor.lo(types.o)' is imported by 'libmemory_optimizer.a(memory_optimizer.o)'\r\nLINK : warning LNK4286: symbol '?DEVICE_GPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_GPU)' defined in 'libtensor.lo(types.o)' is imported by 'libpin_to_host_optimizer.a(pin_to_host_optimizer.o)'\r\nLINK : warning LNK4217: symbol '?g_trace_level@internal@profiler@tensorflow@@3U?$atomic@H@std@@A (struct std::atomic<int> tensorflow::profiler::internal::g_trace_level)' defined in 'libtraceme_recorder_impl.lo(traceme_recorder.o)' is imported by 'libbfc_allocator.a(bfc_allocator.o)' in function '\"public: __cdecl tensorflow::profiler::TraceMe::TraceMe<class <lambda_5d75ae6c1fc66f651c6900753282a5d3> >(class <lambda_5d75ae6c1fc66f651c6900753282a5d3>,int)\" (??$?0V<lambda_5d75ae6c1fc66f651c6900753282a5d3>@@@TraceMe@profiler@tensorflow@@QEAA@V<lambda_5d75ae6c1fc66f651c6900753282a5d3>@@H@Z)'\r\nLINK : warning LNK4217: symbol '?ThenBlasGemm@Stream@stream_executor@@QEAAAEAV12@W4Transpose@blas@2@0_K11MAEBV?$DeviceMemory@M@2@H2HMPEAV52@H@Z (public: class stream_executor::Stream & __cdecl stream_executor::Stream::ThenBlasGemm(enum stream_executor::blas::Transpose,enum stream_executor::blas::Transpose,unsigned __int64,unsigned __int64,unsigned __int64,float,class stream_executor::DeviceMemory<float> const &,int,class stream_executor::DeviceMemory<float> const &,int,float,class stream_executor::DeviceMemory<float> *,int))' defined in 'libstream_executor_pimpl.a(stream.o)' is imported by 'libcudnn_plugin.lo(cuda_dnn.o)' in function '\"public: virtual bool __cdecl stream_executor::gpu::CudnnSupport::DoMatMul(class stream_executor::Stream *,class stream_executor::DeviceMemory<float> const &,class stream_executor::DeviceMemory<float> const &,class stream_executor::dnn::BatchDescriptor const &,class stream_executor::dnn::BatchDescriptor const &,class stream_executor::DeviceMemory<float> *)\" (?DoMatMul@CudnnSupport@gpu@stream_executor@@UEAA_NPEAVStream@3@AEBV?$DeviceMemory@M@3@1AEBVBatchDescriptor@dnn@3@2PEAV53@@Z)'\r\nlibmkl_dnn.a(jit_utils.o) : error LNK2019: unresolved external symbol iJIT_GetNewMethodID referenced in function \"void __cdecl dnnl::impl::cpu::jit_utils::register_jit_code(void const *,unsigned __int64,char const *,char const *)\" (?register_jit_code@jit_utils@cpu@impl@dnnl@@YAXPEBX_KPEBD2@Z)\r\nlibmkl_dnn.a(jit_utils.o) : error LNK2019: unresolved external symbol iJIT_IsProfilingActive referenced in function \"void __cdecl dnnl::impl::cpu::jit_utils::register_jit_code(void const *,unsigned __int64,char const *,char const *)\" (?register_jit_code@jit_utils@cpu@impl@dnnl@@YAXPEBX_KPEBD2@Z)\r\nlibmkl_dnn.a(jit_utils.o) : error LNK2019: unresolved external symbol iJIT_NotifyEvent referenced in function \"void __cdecl dnnl::impl::cpu::jit_utils::register_jit_code(void const *,unsigned __int64,char const *,char const *)\" (?register_jit_code@jit_utils@cpu@impl@dnnl@@YAXPEBX_KPEBD2@Z)\r\nbazel-out\\x64_windows-opt\\bin\\tensorflow\\lite\\python\\optimize\\_tensorflow_lite_wrap_calibration_wrapper.so : fatal error LNK1120: 3 unresolved externals\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 6.072s, Critical Path: 4.15s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully", "what might the error be related to?", "I have a fix but it's not 100% clean.\r\nin the mkl-dnn/blob/master/src/cpu/jit_utils/, i copie the content of the sub folder jitprofiling.\r\nthen i replace\r\n\r\n```\r\n#ifndef DNNL_ENABLE_JIT_PROFILING\r\n#define DNNL_ENABLE_JIT_PROFILING 1\r\n#endif\r\n```\r\n\r\nbuy \r\n\r\n```\r\n#define DNNL_ENABLE_JIT_PROFILING 1\r\n```\r\n\r\nand \r\n\r\n`#include \"jitprofiling/jitprofiling.h\"`\r\n\r\nby \r\n\r\n`#include \"jitprofiling.h\"`\r\n\r\ni think there is no need to copy the content of the folder and edit the include just edit the define \r\n`#define DNNL_ENABLE_JIT_PROFILING 1`  \r\nwill make it work", " mkl-dnn/blob/master/src/cpu/jit_utils/\r\n\r\nwhere is it?", "my bad, i gived you the github folder path.\r\ni deleted my installation but i think it's in bazel temp folderin a folder named mkl_dnn_v1 or samething like this.\r\nmake a find jit_utils in the tensorflow folder, windows will find it\r\n\r\nedit 1 : \r\n`tensorflow\\bazel-tensorflow\\external\\mkl_dnn_v1\\src\\cpu\\jit_utils`", "khaled-besrour, thanks! all work!", "@Expert73 \r\n\r\nPlease close this thread if it solves your question. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37430\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37430\">No</a>\n"]}, {"number": 37429, "title": "Wrong Error Massage, when passing wrong datatype to tf.TensorArray", "body": "Hi, \r\nI hope i picked the right issue type, not sure if documentation or implementation was the right category\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Linux Mint 19.3 (ubuntu)\r\n- TensorFlow installed from (source or\r\nbinary): binatry\r\n- TensorFlow version (use command below): both tf-nightly and tf-2.1\r\n- Python version: 3.8 and 3.6\r\n\r\n**Describe the current behavior**\r\ntf.TensorArray(dtype=tf.float32, size=tf.cast(5, dtype = tf.float32), dynamic_size=False)\r\n\r\nError: Unreachable\r\n\r\n**Describe the expected behavior**\r\nError: Expected dtype int32 not dtype float32 for size argument\r\n\r\n**Standalone code to reproduce the issue** \r\n'''\r\ntf.TensorArray(dtype=tf.float32, size=tf.cast(5, dtype = tf.float32), dynamic_size=False)\r\n'''", "comments": ["@bela127,\r\nI tried running the above code with TF 2.1 and TF-nightly and got the error `TypeError: 'numpy.float32' object cannot be interpreted as an integer`. Please find the Gist [here](https://colab.sandbox.google.com/gist/amahendrakar/d041d143a9d6c97d6ed2024bf7c3b0cd/37429.ipynb). Thanks!", "interesting...\r\ni just checked again and now its working with:\r\ntf.TensorArray(dtype=tf.float32, size=tf.cast(5, dtype = tf.float32), dynamic_size=False)\r\ni try to reproduce the original bug and create test code...\r\n\r\n", "Cant reproduce it, and already changed the code that original produced the error, so i have no way to find it again.\r\n\r\nClosing for now...\r\n\r\ni will reopen the issue if im successful", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37429\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37429\">No</a>\n"]}, {"number": 37427, "title": "Add logging to intermediate layers in TFLite", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 1.15\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nCurrently tflite reuses memory for intermediate to limit its memory footprint on resource constrained devices as discussed [here](https://stackoverflow.com/questions/56885007/visualize-tflite-graph-and-get-intermediate-values-of-a-particular-node). This makes it hard to debug to what is happening at the intermediate layers on the final hardware (especially when using a delegate). The proposal is to add logging functionality to enable visibility into these intermediate layers.\r\n\r\n**Will this change the current api? How?**\r\nA candidate proposal is to add an api function to mark all/selected operation outputs as model outputs and then allow them to be inspected in the python interpreter.\r\n\r\n**Who will benefit with this feature?**\r\nAny developer trying to debug what is happening on an embedded tflite implementation\r\n\r\n**Any Other info.**\r\n", "comments": ["@suharshs didn't we add this functionality recently?", "No not yet. There is a pending change to enable this.", "Is there WIP branch that I can look at? Also is the approach/API similar to what I described? If this is coming out soon then I can just wait if not I can help contribute this change.", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information."]}, {"number": 37426, "title": "NotFoundError: No registered 'Identity' OpKernel for 'TPU' devices compatible with node", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Google Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: \r\n- TensorFlow installed from (source or\r\nbinary): \r\n- TensorFlow version (use command below): 2.1.0\r\n- Python version: - Bazel\r\nversion (if compiling from source):\r\n- GCC/Compiler version (if compiling from\r\nsource): \r\n- CUDA/cuDNN version: - GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nThrows error \"No registered 'Identity' OpKernel for 'TPU' devices compatible with node\".\r\nScript uses efficientnet.tfkeras from efficientnet python package 1.1.0 (pip install efficientnet).\r\n\r\n**Describe the expected behavior**\r\nScript should start training on TPU.\r\n\r\n**Standalone code to reproduce the issue** \r\nGoogle Colab:\r\nhttps://drive.google.com/open?id=1QALjqGEX4z5vTBjRBUbyn5WmElYzMJzR\r\n\r\nPublic access to GCS bucket is granted.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nefficientnet-b0 (Model)      (None, 1280)              4049564   \r\n_________________________________________________________________\r\ndense (Dense)                (None, 120)               153720    \r\n_________________________________________________________________\r\ndense_1 (Dense)              (None, 120)               14520     \r\n_________________________________________________________________\r\ndense_2 (Dense)              (None, 2)                 242       \r\n=================================================================\r\nTotal params: 4,218,046\r\nTrainable params: 4,176,030\r\nNon-trainable params: 42,016\r\n_________________________________________________________________\r\nWARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\r\nWARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\r\n[INFO] Modelul este salvat pe disc dupa fiecare epoca in formatul: nume_model_weights-epoca-training_set_accuracy-validation_set_accuracy.hdf5\r\nTrain for 17.0 steps, validate for 4.0 steps\r\nEpoch 1/25\r\n 0/17 [..............................] - ETA: 0s\r\n---------------------------------------------------------------------------\r\nNotFoundError                             Traceback (most recent call last)\r\n<ipython-input-1-35a575cce5e2> in <module>()\r\n    165     validation_data=valdataset,\r\n    166     validation_steps=np.ceil(totalVal / BS),\r\n--> 167     epochs=NUM_EPOCHS,\r\n    168     #callbacks=[checkpointer],\r\n    169 )\r\n\r\n13 frames\r\n/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)\r\n\r\nNotFoundError: No registered 'Identity' OpKernel for 'TPU' devices compatible with node {{node Identity}}\r\n\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_UINT8\r\n\t.  Registered:  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_HALF, DT_UINT32, DT_UINT64, DT_RESOURCE, DT_VARIANT]\r\n  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_HALF, DT_UINT32, DT_UINT64, DT_RESOURCE, DT_VARIANT]\r\n  device='XLA_TPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_BFLOAT16, DT_UINT32, DT_UINT64, DT_RESOURCE, DT_VARIANT]\r\n  device='XLA_CPU'; T in [DT_UINT8, DT_QUINT8, DT_UINT16, DT_INT8, DT_QINT8, ..., DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128, DT_BOOL, DT_BFLOAT16]\r\n  device='TPU'; T in [DT_INT32, DT_UINT32, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE, DT_BOOL, DT_COMPLEX64, DT_INT64, DT_UINT64]\r\n  device='TPU_SYSTEM'\r\n  device='GPU'; T in [DT_HALF]\r\n  device='GPU'; T in [DT_BFLOAT16]\r\n  device='GPU'; T in [DT_FLOAT]\r\n  device='GPU'; T in [DT_DOUBLE]\r\n  device='GPU'; T in [DT_INT64]\r\n  device='GPU'; T in [DT_UINT16]\r\n  device='GPU'; T in [DT_INT16]\r\n  device='GPU'; T in [DT_UINT8]\r\n  device='GPU'; T in [DT_INT8]\r\n  device='GPU'; T in [DT_COMPLEX64]\r\n  device='GPU'; T in [DT_COMPLEX128]\r\n  device='GPU'; T in [DT_VARIANT]\r\n  device='DEFAULT'; T in [DT_STRING]\r\n  device='DEFAULT'; T in [DT_VARIANT]\r\n  device='DEFAULT'; T in [DT_RESOURCE]\r\n  device='CPU'\r\n\r\n\t [[Identity]] [Op:MakeIterator]\r\n", "comments": ["I am able to replicate the issue, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/c31e0255179d513782e50bbf20609726/37426.ipynb).", "Having same issue [here](https://drive.google.com/open?id=1LCeeTcdJuXGXoddfSPAQAqDgigSdqQTl), although the model seems to work when using the GPU. I believe it may be related to the override of the Keras ImageGenerator but I have not enough knowledge to be sure.\r\n\r\nEDIT: I have converted the code to use `keras.utils.Sequence`s, the problem still holds. ", "I have the same issue here. For training in TPU, do we have to use the tfrecord or we could use our customized data generator?", "The error message indicates you're using uint8, which isn't supported on TPU. You can cast to uint32.", "> The error message indicates you're using uint8, which isn't supported on TPU. You can cast to uint32.\r\n\r\nCould you show how to do that when using a `kera.utils.Sequence`? Should you override it with a class?\r\n\r\nAlso,  I need to work with floating point number, am I right to assume that only `float16` is supported?\r\n\r\nEDIT: I managed to override the `Serquence` with:\r\n```python\r\nclass TypeOverrideSequence(Sequence):\r\n\r\n    original_generator = None\r\n    dtype = None\r\n\r\n    def __init__(self, generator, dtype= tf.float32 ):\r\n        self.original_generator = generator\r\n        self.dtype = dtype\r\n\r\n    def __len__(self):\r\n        return self.original_generator.__len__()\r\n\r\n    def on_epoch_end(self):\r\n        self.original_generator.on_epoch_end()\r\n\r\n    def __getitem__(self, idx):\r\n        data = self.original_generator.__getitem__(idx)\r\n        return (tf.convert_to_tensor(data[0],dtype=self.dtype), tf.convert_to_tensor(data[1],dtype=self.dtype))\r\n```\r\n\r\nThe original error is gone but this new one comes out #24099. I believe is due to not using `tf` only functions. Yet `tf` does not have easy ways of setting up a feeding pipeline of images from disk, while `keras` offers the `ImageDataGenerator` class. Also I have no idea how to proceed further.", "Jhseu, for me it is working now, per your suggestion.\r\n\r\nI am converting the uint8 image resulted from tf.io.decode_jpeg to float32 (or uint32 if I wish) using:\r\n`image = tf.image.decode_jpeg(\"image.jpg\", channels=3)`\r\n`image = tf.cast(image, tf.float32)`\r\n\r\nIf I want to also cast all values between 0 and 1 I use: \r\n`image = tf.cast(image, tf.float32)/255.0    # convert image to floats in [0, 1] range`\r\n\r\nAlso, I found using TFRecords to be very important, using just tf.data.Dataset is impossibly slow.\r\n\r\nThank you. I will close the issue.\r\n\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37426\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37426\">No</a>\n", "> I have the same issue here. For training in TPU, do we have to use the tfrecord or we could use our customized data generator?\r\n\r\nWe can use both data but the data should be in cloud storage for tpu training . Also for visualizing the logs to Tensorboard we should train the model only in Cloud TPU . I tried to run the model running in  Colab TPU having the storage bucket but it won't work like that ."]}, {"number": 37425, "title": "extending 'tf.keras.Model.evaluate' API to permit using class_weight directly.", "body": "Issue : #35825 ", "comments": ["Oh yes. Sorry, i missed that earlier. \r\n@qlzh727  I have made the changes.", "@qlzh727  #37463 I am facing this issue while performing the unit test", "@qlzh727  Can you help me with performing the unit test ? I am trying it for a long time, i am facing some problems.", "I would expect some new unit test being added for this new param, and I didn't find that in this PR.\r\n\r\nDo u have any trouble for writing new unit test? You can follow the existing example in the same package for the fit() method with class weights.", "I tried to write the unit test but got this error : TypeError: evaluate() got an unexpected keyword argument 'class_weight'\r\n\r\nI couldn't get how to solve this.", "I think the current PR looks reasonable. What's the issue u are seeing in the test? Btw, I am kicking off a test on our side, and we can see the test result soon.", "@qlzh727  I updated the docstring. Thank you.", "@ayushmankumar7 Can you please check build failures. Thanks!", "Is there any solution please to add class_weight to the evaluate() method?", "@qlzh727  I tried updating the API .pbtxt ... #38350 issue.  I am working on it. Will update it asap. Thank you.", "@qlzh727 Please check. I updated the golden files. Successfully regenerated the .pbtxt files. Thank you for the guidance. ", "@qlzh727 I made the requested changes\r\n", "@qlzh727 I am sorry for that small mistake. I missed a comma. I fixed it. Thank you. ", "@ayushmankumar7 Can you please fix build failures ? Thanks!", "@gbaned  I am encountering this error : \r\n\r\n![Screenshot from 2020-04-22 20-29-32](https://user-images.githubusercontent.com/41910134/79998364-3aa64900-84d8-11ea-91a9-ddc03976b429.png)\r\n\r\nI am not sure how to solve it. As suggested, i updated the golden file, wrote unit tests. If i get some help, i will be able to make the changes succesfully. Thank you. ", "Why we have the last commit for revert back? https://github.com/tensorflow/tensorflow/pull/37425/commits/0baa946a97098e51f1bb662b551ec9f264a5c0b6", "@qlzh727  I went though the master branch, i saw that i added 'class_weight' to evaluate_generator which wasn't the objective of the PR. So, i reverted it back to the what it was initially and concentrating only on evaluate. ", "I think the eval and eval_generator should have the same API interface for consistency.", "Okay, then i am making the changes. Thanks\r\n", "@qlzh727 I made the requested changes.  I am just facing problem with the Unit test. It's still showing \"TypeError: evaluate() got an unexpected keyword argument 'class_weight'\". I need some help in solving this error. Thanks.", "@qlzh727 I solved it. Please have a look. Thank you. \r\n", "What's the status of this PR ? @gbaned ", "@qlzh727  Thanks for the approval :)", "Sorry for the long wait. I checked with Francois about the PR, and seems that it is expected to not having class_weights for model.evaluate.\r\n\r\nQuote from Francois:\r\n\r\n\"The reason we don't support class weights in `evaluate` is that the class_weight argument represents sample weights that are computed from the labels, but the labels should not be an input to the model during evaluation. During training this is fine, but during evaluation this represents a data leak from the labels to your metrics. If you used class weighting in `evaluate`, your score would not be reproducible on real test data (when you don't have the labels).\r\n\r\nSo this is conceptually wrong.\"\r\n\r\nI am closing this PR since it is working as intended."]}, {"number": 37424, "title": "Fix typo for lite/micro/examples/person_detection/training_a_model.md", "body": "Missing backslash, just a typo", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37424) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37424) for more info**.\n\n<!-- ok -->", "We will not be encouraging one liner grammatical changes as this is expensive process, thank you for your interest.\r\nCC @mihaimaruseac @chanshah"]}, {"number": 37423, "title": "Failed to build TF 1.14 on Windows with CUDA 10.1", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 14393.0\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: branch r1.14\r\n- Python version: 3.6.8\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source): 0.25.1\r\n- GCC/Compiler version (if compiling from source): MSVC 14.24.28314 (Visual Studio 2019.4)\r\n- CUDA/cuDNN version: 10.1/7.6.5\r\n- GPU model and memory: GTX 1050 4GB\r\n\r\n**Describe the problem**\r\n\r\nI tried to compile TF 1.14 with CUDA 10.1 on windows several times and always encounter the following failure. There seems to be no related issues in this repo. I searched through the Internet and find nothing helpful. I am very appreciated if someone can help me.\r\n\r\n```\r\nH:\\workspace\\_bazel_cache\\3wteafhd\\execroot\\org_tensorflow\\external\\eigen_archive\\Eigen\\src/Core/util/Memory.h(85): warn\r\ning: ignoring return value from routine declared with \"nodiscard\" attribute\r\n\r\nH:\\workspace\\_bazel_cache\\3wteafhd\\execroot\\org_tensorflow\\external\\eigen_archive\\Eigen\\src/Core/CwiseBinaryOp.h(105): w\r\narning: __host__ annotation is ignored on a function(\"CwiseBinaryOp\") that is explicitly defaulted on its first declarat\r\nion\r\n\r\nH:\\workspace\\_bazel_cache\\3wteafhd\\execroot\\org_tensorflow\\external\\eigen_archive\\Eigen\\src/Core/CwiseBinaryOp.h(105): w\r\narning: __device__ annotation is ignored on a function(\"CwiseBinaryOp\") that is explicitly defaulted on its first declar\r\nation\r\n\r\n.\\tensorflow/core/kernels/cwise_ops.h(37): warning: type qualifier on return type is meaningless\r\n\r\n.\\tensorflow/core/kernels/cwise_ops.h(47): warning: type qualifier on return type is meaningless\r\n\r\n.\\tensorflow/core/kernels/cwise_ops.h(209): warning: __host__ annotation is ignored on a function(\"scalar_left\") that is\r\n explicitly defaulted on its first declaration\r\n\r\n.\\tensorflow/core/kernels/cwise_ops.h(209): warning: __device__ annotation is ignored on a function(\"scalar_left\") that\r\nis explicitly defaulted on its first declaration\r\n\r\n.\\tensorflow/core/kernels/cwise_ops.h(239): warning: __host__ annotation is ignored on a function(\"scalar_right\") that i\r\ns explicitly defaulted on its first declaration\r\n\r\n.\\tensorflow/core/kernels/cwise_ops.h(239): warning: __device__ annotation is ignored on a function(\"scalar_right\") that\r\n is explicitly defaulted on its first declaration\r\n\r\nH:\\workspace\\_bazel_cache\\3wteafhd\\execroot\\org_tensorflow\\external\\eigen_archive\\Eigen\\src/Core/functors/UnaryFunctors.\r\nh(112): warning: calling a __host__ function(\"std::conj<float> \") from a __host__ __device__ function(\"Eigen::internal::\r\nscalar_conjugate_op<    ::std::complex<float> > ::operator () const\") is not allowed\r\n\r\nH:\\workspace\\_bazel_cache\\3wteafhd\\execroot\\org_tensorflow\\external\\eigen_archive\\unsupported\\Eigen\\CXX11\\src/Tensor/Ten\r\nsorExecutor.h(334): error: calling a __host__ function(\"std::conj<float> \") from a __device__ function(\"Eigen::internal:\r\n:EigenMetaKernelEval< ::Eigen::TensorEvaluator<const  ::Eigen::TensorAssignOp< ::Eigen::TensorMap< ::Eigen::Tensor<    :\r\n:std::complex<float> , (int)1, (int)1, int> , (int)16,  ::Eigen::MakePointer> , const  ::Eigen::TensorCwiseUnaryOp< ::Ei\r\ngen::internal::scalar_conjugate_op<    ::std::complex<float> > , const  ::Eigen::TensorMap< ::Eigen::Tensor<const     ::\r\nstd::complex<float> , (int)1, (int)1, int> , (int)16,  ::Eigen::MakePointer> > > ,  ::Eigen::GpuDevice> , int, (bool)0>\r\n::run\") is not allowed\r\n\r\nH:\\workspace\\_bazel_cache\\3wteafhd\\execroot\\org_tensorflow\\external\\eigen_archive\\unsupported\\Eigen\\CXX11\\src/Tensor/Ten\r\nsorExecutor.h(334): error: identifier \"std::conj<float> \" is undefined in device code\r\n\r\nH:\\workspace\\_bazel_cache\\3wteafhd\\execroot\\org_tensorflow\\external\\eigen_archive\\Eigen\\src/Core/functors/UnaryFunctors.\r\nh(112): warning: calling a __host__ function(\"std::conj<double> \") from a __host__ __device__ function(\"Eigen::internal:\r\n:scalar_conjugate_op<    ::std::complex<double> > ::operator () const\") is not allowed\r\n\r\nH:\\workspace\\_bazel_cache\\3wteafhd\\execroot\\org_tensorflow\\external\\eigen_archive\\unsupported\\Eigen\\CXX11\\src/Tensor/Ten\r\nsorExecutor.h(334): error: calling a __host__ function(\"std::conj<double> \") from a __device__ function(\"Eigen::internal\r\n::EigenMetaKernelEval< ::Eigen::TensorEvaluator<const  ::Eigen::TensorAssignOp< ::Eigen::TensorMap< ::Eigen::Tensor<\r\n::std::complex<double> , (int)1, (int)1, int> , (int)16,  ::Eigen::MakePointer> , const  ::Eigen::TensorCwiseUnaryOp< ::\r\nEigen::internal::scalar_conjugate_op<    ::std::complex<double> > , const  ::Eigen::TensorMap< ::Eigen::Tensor<const\r\n ::std::complex<double> , (int)1, (int)1, int> , (int)16,  ::Eigen::MakePointer> > > ,  ::Eigen::GpuDevice> , int, (bool\r\n)0> ::run\") is not allowed\r\n\r\nH:\\workspace\\_bazel_cache\\3wteafhd\\execroot\\org_tensorflow\\external\\eigen_archive\\unsupported\\Eigen\\CXX11\\src/Tensor/Ten\r\nsorExecutor.h(334): error: identifier \"std::conj<double> \" is undefined in device code\r\n\r\n4 errors detected in the compilation of \"C:/Users/ASUS/AppData/Local/Temp/nvcc_inter_files_tmp_dir/cwise_op_gpu_conj.cu.\r\ncpp1.ii\".\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 6617.850s, Critical Path: 192.36s\r\nINFO: 4051 processes: 4051 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n`configure.py` output:\r\n```\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shut\r\ndown\".\r\nYou have bazel 0.25.1 installed.\r\nPlease specify the location of python. [Default is C:\\Program Files\\Python36\\python.exe]:\r\n\r\n\r\nFound possible Python library paths:\r\n  C:\\Program Files\\Python36\\lib\\site-packages\r\nPlease input the desired Python library path to use.  Default is [C:\\Program Files\\Python36\\lib\\site-packages]\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [y/N]:\r\nNo XLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]:\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nFound CUDA 10.1 in:\r\n    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1/lib/x64\r\n    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1/include\r\nFound cuDNN 7 in:\r\n    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1/lib/x64\r\n    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1/include\r\n\r\n\r\nPlease specify a list of comma-separated CUDA compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size, and that Te\r\nnsorFlow only supports compute capabilities >= 3.5 [Default is: 3.5,7.0]: 6.1\r\n\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is /a\r\nrch:AVX]: /arch:AVX2\r\n\r\n\r\nWould you like to override eigen strong inline for some C++ compilation to reduce the compilation time? [Y/n]:\r\nEigen strong inline overridden.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .baze\r\nlrc for more details.\r\n        --config=mkl            # Build with MKL support.\r\n        --config=monolithic     # Config for mostly static monolithic build.\r\n        --config=gdr            # Build with GDR support.\r\n        --config=verbs          # Build with libverbs support.\r\n        --config=ngraph         # Build with Intel nGraph support.\r\n        --config=numa           # Build with NUMA support.\r\n        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n        --config=noaws          # Disable AWS S3 filesystem support.\r\n        --config=nogcp          # Disable GCP support.\r\n        --config=nohdfs         # Disable HDFS support.\r\n        --config=noignite       # Disable Apache Ignite support.\r\n        --config=nokafka        # Disable Apache Kafka support.\r\n        --config=nonccl         # Disable NVIDIA NCCL support.\r\n```\r\ncommand used to build: `bazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package --jobs 2`\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@a5467021 \r\n\r\nCan you please try with the [tested build configuration](https://www.tensorflow.org/install/source_windows#gpu) and check whether the issue still persists. Thanks!", "I installed VS2017 build tools alongside my VS2019. The bazel build command was successful after swtiching to VS2017. But I encountered following new error when building pip package:\r\n```\r\n> bash tensorflow\\tools\\pip_package\\build_pip_package.sh tf-1.14\r\nTue Mar 10 10:40:05 2020 : === Preparing sources in dir: /tmp/tmp.yuyBwdvKxu\r\nUnzipping simple_console_for_windows.zip to create runfiles tree...\r\nerror:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/detail/functional/operators/compound_assignment_operators.h\r\n        No such file or directory\r\nerror:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/detail/type_traits/algorithm/intermediate_type_from_function_and_iterators.h\r\n        No such file or directory\r\nerror:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/iterator/detail/iterator_category_with_system_and_traversal.h\r\n        No such file or directory\r\nerror:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/agent/agent_radix_sort_downsweep.cuh\r\n        No such file or directory\r\nerror:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/agent/agent_radix_sort_upsweep.cuh\r\n        No such file or directory\r\nerror:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/agent/single_pass_scan_operators.cuh\r\n        No such file or directory\r\nerror:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/block/block_adjacent_difference.cuh\r\n        No such file or directory\r\ncheckdir error:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/block/specializations\r\n                 No such file or directory\r\n                 unable to process runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/block/specializations/block_histogram_atomic.cuh.\r\ncheckdir error:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/block/specializations\r\n                 No such file or directory\r\n                 unable to process runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/block/specializations/block_histogram_sort.cuh.\r\ncheckdir error:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/block/specializations\r\n                 No such file or directory\r\n                 unable to process runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/block/specializations/block_reduce_raking.cuh.\r\ncheckdir error:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/block/specializations\r\n                 No such file or directory\r\n                 unable to process runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/block/specializations/block_reduce_raking_commutative_only.cuh.\r\ncheckdir error:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/block/specializations\r\n                 No such file or directory\r\n                 unable to process runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/block/specializations/block_reduce_warp_reductions.cuh.\r\ncheckdir error:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/block/specializations\r\n                 No such file or directory\r\n                 unable to process runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/block/specializations/block_scan_raking.cuh.\r\ncheckdir error:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/block/specializations\r\n                 No such file or directory\r\n                 unable to process runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/block/specializations/block_scan_warp_scans.cuh.\r\ncheckdir error:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/block/specializations\r\n                 No such file or directory\r\n                 unable to process runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/block/specializations/block_scan_warp_scans2.cuh.\r\ncheckdir error:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/block/specializations\r\n                 No such file or directory\r\n                 unable to process runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/block/specializations/block_scan_warp_scans3.cuh.\r\nerror:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/device/device_run_length_encode.cuh\r\n        No such file or directory\r\nerror:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/device/device_segmented_radix_sort.cuh\r\n        No such file or directory\r\nerror:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/device/device_segmented_reduce.cuh\r\n        No such file or directory\r\nerror:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/device/dispatch/dispatch_histogram.cuh\r\n        No such file or directory\r\nerror:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/device/dispatch/dispatch_radix_sort.cuh\r\n        No such file or directory\r\nerror:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/device/dispatch/dispatch_reduce.cuh\r\n        No such file or directory\r\nerror:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/device/dispatch/dispatch_reduce_by_key.cuh\r\n        No such file or directory\r\nerror:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/device/dispatch/dispatch_rle.cuh\r\n        No such file or directory\r\nerror:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/device/dispatch/dispatch_scan.cuh\r\n        No such file or directory\r\nerror:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/device/dispatch/dispatch_select_if.cuh\r\n        No such file or directory\r\nerror:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/device/dispatch/dispatch_spmv_orig.cuh\r\n        No such file or directory\r\nerror:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/iterator/arg_index_input_iterator.cuh\r\n        No such file or directory\r\nerror:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/iterator/cache_modified_input_iterator.cuh\r\n        No such file or directory\r\nerror:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/iterator/cache_modified_output_iterator.cuh\r\n        No such file or directory\r\nerror:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/iterator/constant_input_iterator.cuh\r\n        No such file or directory\r\nerror:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/iterator/counting_input_iterator.cuh\r\n        No such file or directory\r\nerror:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/iterator/discard_output_iterator.cuh\r\n        No such file or directory\r\nerror:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/iterator/tex_obj_input_iterator.cuh\r\n        No such file or directory\r\nerror:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/iterator/tex_ref_input_iterator.cuh\r\n        No such file or directory\r\nerror:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/iterator/transform_input_iterator.cuh\r\n        No such file or directory\r\ncheckdir error:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/warp/specializations\r\n                 No such file or directory\r\n                 unable to process runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/warp/specializations/warp_reduce_shfl.cuh.\r\ncheckdir error:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/warp/specializations\r\n                 No such file or directory\r\n                 unable to process runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/warp/specializations/warp_reduce_smem.cuh.\r\ncheckdir error:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/warp/specializations\r\n                 No such file or directory\r\n                 unable to process runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/warp/specializations/warp_scan_shfl.cuh.\r\ncheckdir error:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/warp/specializations\r\n                 No such file or directory\r\n                 unable to process runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/system/cuda/detail/cub/warp/specializations/warp_scan_smem.cuh.\r\nerror:  cannot create ./bazel-bin/tensorflow/tools/pip_package/simple_console_for_window_unzip/runfiles/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/thrust/type_traits/is_operator_less_or_greater_function_object.h\r\n        No such file or directory\r\n```", "There maybe something wrong with the `unzip` command in my cmd environment. Some files are skipped. I executed the same command in MSYS2 bash and successfully built the wheel. The wheel is functioning. Great!", "@a5467021 \r\n\r\nLooks like issue got resolved.Please close this thread if your issue was resolved. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37423\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37423\">No</a>\n"]}, {"number": 37422, "title": "Specify python versio via build arg PYTHON_VERSION", "body": "Allow python version to be specified as requested in #25939 ", "comments": ["This is so cool ! Thank you! Hoping it will get merged soon ^^ ", "@ysgit Could you please resolve the conflicts? Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "similar changes are merged , so closing this PR, thank you for your contribution."]}, {"number": 37421, "title": "convert call to graph code", "body": "Convert ```layer.call``` to Tensorflow graph because of Keras convert ```layer.call``` to Tensorflow graph by default.", "comments": []}, {"number": 37420, "title": "NFC - minor spelling tweaks under lite/micro directory", "body": "This PR addresses minor spelling tweaks under `tensorflow/lite/micro` directory.\r\nfollow-on of #35286", "comments": ["cc @mihaimaruseac @gbaned"]}, {"number": 37419, "title": "Add close check", "body": "close callings lack error checks.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37419) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37419) for more info**.\n\n<!-- ok -->"]}, {"number": 37418, "title": "How to gray images in Android?", "body": "I want to identify the MNIST image on an Android device. How do I modify the following preprocessing code. How to grayscale the image\r\n\r\n\r\nhttps://github.com/tensorflow/examples/blob/f812d2c36469823c8784e387f690f43ad9d17683/lite/examples/image_classification/android/app/src/main/java/org/tensorflow/lite/examples/classification/tflite/Classifier.java#L307\r\n```java\r\n    ImageProcessor imageProcessor =\r\n        new ImageProcessor.Builder()\r\n            .add(new ResizeWithCropOrPadOp(cropSize, cropSize))\r\n            .add(new ResizeOp(imageSizeX, imageSizeY, ResizeMethod.NEAREST_NEIGHBOR))\r\n            .add(new Rot90Op(numRoration))\r\n            .add(getPreprocessNormalizeOp())\r\n            .build();\r\n    return imageProcessor.process(inputImageBuffer);\r\n```", "comments": ["You'll first need a model that can recognize a grayscale image. The image classification example app provided by tflite takes a RGB image instead. \r\n\r\nIf you do have a custom model that can recognize grayscale images, you then need to convert the image into ByteBuffer with proper preprocessing, such as resizing and cropping, and then pass it into tflite.interpreter. Unfortunately, TFLite Support library does not support gray scale at this moment. ", "> You'll first need a model that can recognize a grayscale image. The image classification example app provided by tflite takes a RGB image instead.\r\n> \r\n> If you do have a custom model that can recognize grayscale images, you then need to convert the image into ByteBuffer with proper preprocessing, such as resizing and cropping, and then pass it into tflite.interpreter. Unfortunately, TFLite Support library does not support gray scale at this moment.\r\n\r\nDoes TFLite support library include the RGB to Gray scale conversion in TF-Fall 2020 update??", "TFLite Support Library doesn't supporting the conversion from RGB to Grayscale. however, there are many related StackOverflow questions that you can refer to, such as [this one](https://stackoverflow.com/questions/8381514/android-converting-color-image-to-grayscale) ", "> TFLite Support Library doesn't supporting the conversion from RGB to Grayscale. however, there are many related StackOverflow questions that you can refer to, such as [this one](https://stackoverflow.com/questions/8381514/android-converting-color-image-to-grayscale)\r\n\r\nA model which requests a grayscale image as input requires only one channel/feature per pixel. These methods unfortunately all keep the rgb channels. \r\n\r\nThis works \ud83d\udc4d: https://stackoverflow.com/questions/62937309/grayscale-in-tensorflow-lite", "sorry for asking, does tensorflow support library already support conversion from rgb to grayscale now?", "@Alfyu07 Yes, please see my answer [here](https://github.com/tensorflow/tensorflow/issues/35211#issuecomment-871618298)."]}, {"number": 37417, "title": "tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,3,32] rhs shape= [3,3,1,32] \t [[{{node save/Assign_78}}]]", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Mint 19.1\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 1.14\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source):N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\n\r\n**Describe the problem**\r\nModel: ssd_mobilenet_v2_quantized_300x300_coco.config\r\n\r\nI am facing the issue of converting a custom trained model from checkpoint into inference graphs using the following commands:\r\n`python export_tflite_ssd_graph.py \\`\r\n`--pipeline_config_path=/training/ssd_mobilenet_v2_quantized_300x300_coco.config \\`\r\n`--trained_checkpoint_prefix=/training/model.ckpt-1000 \\`\r\n`--output_directory=/inference_graph/ \\`\r\n`--add_postprocessing_op=true`\r\n\r\n**Following is how my config file looks like:**\r\n ```\r\nmodel {\r\n  ssd {\r\n    num_classes: 6\r\n    box_coder {\r\n      faster_rcnn_box_coder {\r\n        y_scale: 10.0\r\n        x_scale: 10.0\r\n        height_scale: 5.0\r\n        width_scale: 5.0\r\n      }\r\n    }\r\n    matcher {\r\n      argmax_matcher {\r\n        matched_threshold: 0.5\r\n        unmatched_threshold: 0.5\r\n        ignore_thresholds: false\r\n        negatives_lower_than_unmatched: true\r\n        force_match_for_each_row: true\r\n      }\r\n    }\r\n    similarity_calculator {\r\n      iou_similarity {\r\n      }\r\n    }\r\n    anchor_generator {\r\n      ssd_anchor_generator {\r\n        num_layers: 6\r\n        min_scale: 0.2\r\n        max_scale: 0.95\r\n        aspect_ratios: 1.0\r\n        aspect_ratios: 2.0\r\n        aspect_ratios: 0.5\r\n        aspect_ratios: 3.0\r\n        aspect_ratios: 0.3333\r\n      }\r\n    }\r\n    image_resizer {\r\n      fixed_shape_resizer {\r\n        height: 300\r\n        width: 300\r\n      }\r\n    }\r\n    box_predictor {\r\n      convolutional_box_predictor {\r\n        min_depth: 0\r\n        max_depth: 0\r\n        num_layers_before_predictor: 0\r\n        use_dropout: false\r\n        dropout_keep_probability: 0.8\r\n        kernel_size: 1\r\n        box_code_size: 4\r\n        apply_sigmoid_to_scores: false\r\n        conv_hyperparams {\r\n          activation: RELU_6,\r\n          regularizer {\r\n            l2_regularizer {\r\n              weight: 0.00004\r\n            }\r\n          }\r\n          initializer {\r\n            truncated_normal_initializer {\r\n              stddev: 0.03\r\n              mean: 0.0\r\n            }\r\n          }\r\n          batch_norm {\r\n            train: true,\r\n            scale: true,\r\n            center: true,\r\n            decay: 0.9997,\r\n            epsilon: 0.001,\r\n          }\r\n        }\r\n      }Following is how my config file looks like:\r\n    }\r\n    feature_extractor {\r\n      type: 'ssd_mobilenet_v2'\r\n      min_depth: 16\r\n      depth_multiplier: 1.0\r\n      conv_hyperparams {\r\n        activation: RELU_6,\r\n        regularizer {\r\n          l2_regularizer {\r\n            weight: 0.00004\r\n          }\r\n        }\r\n        initializer {\r\n          truncated_normal_initializer {\r\n            stddev: 0.03\r\n            mean: 0.0\r\n          }\r\n        }\r\n        batch_norm {\r\n          train: true,\r\n          scale: true,\r\n          center: true,\r\n          decay: 0.9997,\r\n          epsilon: 0.001,\r\n        }\r\n      }\r\n    }\r\n    loss {\r\n      classification_loss {\r\n        weighted_sigmoid {\r\n        }\r\n      }\r\n      localization_loss {\r\n        weighted_smooth_l1 {\r\n        }\r\n      }\r\n      hard_example_miner {\r\n        num_hard_examples: 3000\r\n        iou_threshold: 0.99\r\n        loss_type: CLASSIFICATION\r\n        max_negatives_per_positive: 3\r\n        min_negatives_per_image: 3\r\n      }\r\n      classification_weight: 1.0\r\n      localization_weight: 1.0\r\n    }\r\n    normalize_loss_by_num_matches: true\r\n    post_processing {\r\n      batch_non_max_suppression {\r\n        score_threshold: 1e-8\r\n        iou_threshold: 0.6\r\n        max_detections_per_class: 100\r\n        max_total_detections: 100\r\n      }\r\n      score_converter: SIGMOID\r\n    }\r\n  }\r\n}\r\n\r\ntrain_config: {\r\n  batch_size: 5\r\n  optimizer {\r\n    rms_prop_optimizer: {\r\n      learning_rate: {\r\n        exponential_decay_learning_rate {\r\n          initial_learning_rate: 0.004\r\n          decay_steps: 800720\r\n          decay_factor: 0.95\r\n        }\r\n      }\r\n      momentum_optimizer_value: 0.9\r\n      decay: 0.9\r\n      epsilon: 1.0\r\n    }\r\n  }\r\n  fine_tune_checkpoint: \"/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03/model.ckpt\"\r\n  fine_tune_checkpoint_type:  \"detection\"\r\n  num_steps: 1000\r\n  data_augmentation_options {\r\n    random_horizontal_flip {\r\n    }\r\n  }\r\n  data_augmentation_options {\r\n    ssd_random_crop {\r\n    }\r\n  }\r\n  data_augmentation_options {\r\n    random_rgb_to_gray {\r\n    }\r\n  }\r\n\r\n data_augmentation_options {\r\n    random_adjust_brightness {\r\n    }\r\n  }\r\n\r\n data_augmentation_options {\r\n    random_adjust_contrast {\r\n    }\r\n  }\r\n  \r\n data_augmentation_options {\r\n    random_adjust_hue {\r\n    }\r\n  }\r\n  \r\n  \r\n data_augmentation_options {\r\n    random_adjust_saturation {\r\n    }\r\n  }\r\n  \r\n  \r\n data_augmentation_options {\r\n    rgb_to_gray {\r\n    }\r\n  }\r\n}\r\n\r\ntrain_input_reader: {\r\n  tf_record_input_reader {\r\n    input_path: \"/object_detection/train.record\"\r\n  }\r\n  label_map_path: \"/object_detection/training/labelmap.pbtxt\"\r\n}\r\n\r\neval_config: {\r\n  num_examples: 3\r\n  max_evals: 10\r\n}\r\n\r\neval_input_reader: {\r\n  tf_record_input_reader {\r\n    input_path: \"/object_detection/test.record\"\r\n  }\r\n  label_map_path: \"/object_detection/training/labelmap.pbtxt\"\r\n  shuffle: false\r\n  num_readers: 1\r\n}\r\n\r\ngraph_rewriter {\r\n  quantization {\r\n    delay: 48000\r\n    weight_bits: 8\r\n    activation_bits: 8\r\n  }\r\n} \r\n```\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nI have added the following lines of code for augmentation in the config file:\r\n ```\r\n data_augmentation_options {\r\n    random_rgb_to_gray {\r\n    }\r\n  }\r\n\r\n data_augmentation_options {\r\n    random_adjust_brightness {\r\n    }\r\n  }\r\n\r\n data_augmentation_options {\r\n    random_adjust_contrast {\r\n    }\r\n  }\r\n  \r\n data_augmentation_options {\r\n    random_adjust_hue {\r\n    }\r\n  }\r\n  \r\n  \r\n data_augmentation_options {\r\n    random_adjust_saturation {\r\n    }\r\n  }\r\n  \r\n  \r\n data_augmentation_options {\r\n    rgb_to_gray {\r\n    }\r\n  }\r\n\r\n```\r\n\r\n**Any other info / logs**\r\nHere is the error, I want to know the cause of the error and that, does addition of augmentation in config  also requires any other change?\r\n ```\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\r\nI0307 23:21:08.443011 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\r\nI0307 23:21:08.443283 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\r\nI0307 23:21:08.443521 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\r\nI0307 23:21:08.443677 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\r\nI0307 23:21:08.443905 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\r\nI0307 23:21:08.444058 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\r\nI0307 23:21:08.444283 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\r\nI0307 23:21:08.444431 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\r\nI0307 23:21:08.444655 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\r\nI0307 23:21:08.444802 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\r\nI0307 23:21:08.445024 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\r\nI0307 23:21:08.445170 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\r\nI0307 23:21:08.445389 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\r\nI0307 23:21:08.445536 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\r\nI0307 23:21:08.445757 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\r\nI0307 23:21:08.445903 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\r\nI0307 23:21:08.446130 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\r\nI0307 23:21:08.446278 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\r\nI0307 23:21:08.446502 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\r\nI0307 23:21:08.446648 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\r\nI0307 23:21:08.446869 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\r\nI0307 23:21:08.447014 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\r\nI0307 23:21:08.447235 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\r\nI0307 23:21:08.447381 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\r\nI0307 23:21:08.447600 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\r\nI0307 23:21:08.447747 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\r\nI0307 23:21:08.447968 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\r\nI0307 23:21:08.448114 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\r\nI0307 23:21:08.448335 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\r\nI0307 23:21:08.448482 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\r\nI0307 23:21:08.448699 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\r\nI0307 23:21:08.448843 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\r\nI0307 23:21:08.449064 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\r\nI0307 23:21:08.449210 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\r\nI0307 23:21:08.449432 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\r\nI0307 23:21:08.449569 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\r\nI0307 23:21:08.449709 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\r\nI0307 23:21:08.449849 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\r\nI0307 23:21:08.449984 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\r\nI0307 23:21:08.450125 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\r\nI0307 23:21:08.450264 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\r\nI0307 23:21:08.450404 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\r\nINFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\r\nI0307 23:21:08.450541 140338966099776 quantize.py:298] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\r\nWARNING:tensorflow:From /root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/object_detection-0.1-py3.6.egg/object_detection/export_tflite_ssd_graph_lib.py:259: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\r\n\r\nW0307 23:21:08.452883 140338966099776 deprecation_wrapper.py:119] From /root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/object_detection-0.1-py3.6.egg/object_detection/export_tflite_ssd_graph_lib.py:259: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\r\n\r\nWARNING:tensorflow:From /root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse standard file APIs to check for files with this prefix.\r\nW0307 23:21:08.877874 140338966099776 deprecation.py:323] From /root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse standard file APIs to check for files with this prefix.\r\nINFO:tensorflow:Restoring parameters from /home/models/research/object_detection/training/model.ckpt-0\r\nI0307 23:21:09.683899 140338966099776 saver.py:1280] Restoring parameters from /home/models/research/object_detection/training/model.ckpt-0\r\nTraceback (most recent call last):\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1356, in _do_call\r\n    return fn(*args)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1341, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1429, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,3,32] rhs shape= [3,3,1,32]\r\n\t [[{{node save/Assign_78}}]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1286, in restore\r\n    {self.saver_def.filename_tensor_name: save_path})\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 950, in run\r\n    run_metadata_ptr)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1173, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1350, in _do_run\r\n    run_metadata)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1370, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,3,32] rhs shape= [3,3,1,32]\r\n\t [[node save/Assign_78 (defined at /root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/object_detection-0.1-py3.6.egg/object_detection/export_tflite_ssd_graph_lib.py:259) ]]\r\n\r\nErrors may have originated from an input operation.\r\nInput Source operations connected to node save/Assign_78:\r\n FeatureExtractor/MobilenetV2/Conv/weights (defined at /root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/slim-0.1-py3.6.egg/nets/mobilenet/mobilenet.py:277)\r\n\r\nOriginal stack trace for 'save/Assign_78':\r\n  File \"export_tflite_ssd_graph.py\", line 137, in <module>\r\n    tf.app.run(main)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"export_tflite_ssd_graph.py\", line 133, in main\r\n    FLAGS.max_classes_per_detection)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/object_detection-0.1-py3.6.egg/object_detection/export_tflite_ssd_graph_lib.py\", line 259, in export_tflite_graph\r\n    saver = tf.train.Saver(**saver_kwargs)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 825, in __init__\r\n    self.build()\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 837, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 875, in _build\r\n    build_restore=build_restore)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 508, in _build_internal\r\n    restore_sequentially, reshape)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 350, in _AddRestoreOps\r\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/training/saving/saveable_object_util.py\", line 72, in restore\r\n    self.op.get_shape().is_fully_defined())\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 227, in assign\r\n    validate_shape=validate_shape)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 66, in assign\r\n    use_locking=use_locking, name=name)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\r\n    op_def=op_def)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"export_tflite_ssd_graph.py\", line 137, in <module>\r\n    tf.app.run(main)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"export_tflite_ssd_graph.py\", line 133, in main\r\n    FLAGS.max_classes_per_detection)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/object_detection-0.1-py3.6.egg/object_detection/export_tflite_ssd_graph_lib.py\", line 273, in export_tflite_graph\r\n    initializer_nodes='')\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py\", line 151, in freeze_graph_with_def_protos\r\n    saver.restore(sess, input_checkpoint)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1322, in restore\r\n    err, \"a mismatch between the current graph and the graph\")\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\r\n\r\nAssign requires shapes of both tensors to match. lhs shape= [3,3,3,32] rhs shape= [3,3,1,32]\r\n\t [[node save/Assign_78 (defined at /root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/object_detection-0.1-py3.6.egg/object_detection/export_tflite_ssd_graph_lib.py:259) ]]\r\n\r\nErrors may have originated from an input operation.\r\nInput Source operations connected to node save/Assign_78:\r\n FeatureExtractor/MobilenetV2/Conv/weights (defined at /root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/slim-0.1-py3.6.egg/nets/mobilenet/mobilenet.py:277)\r\n\r\nOriginal stack trace for 'save/Assign_78':\r\n  File \"export_tflite_ssd_graph.py\", line 137, in <module>\r\n    tf.app.run(main)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"export_tflite_ssd_graph.py\", line 133, in main\r\n    FLAGS.max_classes_per_detection)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/object_detection-0.1-py3.6.egg/object_detection/export_tflite_ssd_graph_lib.py\", line 259, in export_tflite_graph\r\n    saver = tf.train.Saver(**saver_kwargs)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 825, in __init__\r\n    self.build()\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 837, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 875, in _build\r\n    build_restore=build_restore)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 508, in _build_internal\r\n    restore_sequentially, reshape)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 350, in _AddRestoreOps\r\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/training/saving/saveable_object_util.py\", line 72, in restore\r\n    self.op.get_shape().is_fully_defined())\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 227, in assign\r\n    validate_shape=validate_shape)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 66, in assign\r\n    use_locking=use_locking, name=name)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\r\n    op_def=op_def)\r\n  File \"/root/anaconda3/envs/tensorflow1/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n```", "comments": ["Hi @saqibshakeel035,\r\n\r\nI don't know whether you have figured it out yourself. \r\n\r\nThe script export_tflite_ssd_graph.py is from [tensorflow/models/research/object_detection](https://github.com/tensorflow/models/blob/80444539849453d45fa2ecfcce7fbeb47d863897/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md), and maintained by the owners of the research project. It seems that your script is related to how to use the script from project [object_detection](https://github.com/tensorflow/models/tree/9bbf8015dba2133ab2343ec6d6b5096033504e36/research/object_detection) in particular. Would it be better to ask maintainers of the project there. \r\n\r\nThx! :-)", "> Hi @saqibshakeel035,\r\n> \r\n> I don't know whether you have figured it out yourself.\r\n> \r\n> The script export_tflite_ssd_graph.py is from [tensorflow/models/research/object_detection](https://github.com/tensorflow/models/blob/80444539849453d45fa2ecfcce7fbeb47d863897/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md), and maintained by the owners of the research project. It seems that your script is related to how to use the script from project [object_detection](https://github.com/tensorflow/models/tree/9bbf8015dba2133ab2343ec6d6b5096033504e36/research/object_detection) in particular. Would it be better to ask maintainers of the project there.\r\n> \r\n> Thx! :-)\r\n\r\nI came to know that the error is because of the augmentation \r\n```\r\ndata_augmentation_options {\r\n   random_rgb_to_gray {\r\n   }\r\n```\r\nGrey contains only 1 channel whereas RGB contains 3 color channels. I didn't dig out how to rectify this issue but removing this augmentation resolved this issue of shape mismatch.\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37417\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37417\">No</a>\n"]}, {"number": 37416, "title": "Precision at top_k does not compute the precision *on average* as stated in the API", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/metrics/Precision\r\n\r\n## Description of issue (what needs changing):\r\nThis method does not compute the precision *on average* when top_k is set. This could lead to bad evaluations, especially when the sample_weight is set and used as counts.\r\n\r\n### Clear description\r\n\r\nTo see the issue, it's enough to run \r\n```\r\nm = tf.keras.metrics.Precision(top_k=2)\r\nm.update_state([0, 0, 1, 1], [1, 1, 1., 1.])\r\n\r\nprint('Final result: ', m.result().numpy()) # Returns 0 but should return 0.5\r\n```\r\nIt always computes the precision according to the given order and returns 0. However it should return 0.5 if it's on average.\r\n", "comments": ["Was able to reproduce the issue with TF 2.1 and TF-nightly. Please find the Gist [here](https://colab.sandbox.google.com/gist/amahendrakar/835c0ddf7b10b0c134967080939efffe/37416.ipynb). Thanks!", "@LeechMuse \r\nIn the code provided by you `y_true` = [0, 0, 1, 1], `y_pred` = [1, 1, 1., 1.] , top_k = top-k classes to be considered to calculate precision. \r\n\r\nIf top_k = none it consider all the classes.\r\n\r\nPrecision is calculated by TP/TP+FP. So in the case top_k =1 it considers the first value only to calculate precision (ie y_true = [0]  and y_pred = [1]) so precision is zero. \r\n\r\nSimilarly top_k=2 considers first 2 values y_true` = [0, 0] and y_pred` = [1, 1] so precision is zero. \r\nIf top_k=3 then y_true` = [0, 0,1] and y_pred` = [1,1,1.] so precision is 0.33.\r\n\r\nIn this example top_k =4 or None is same because it uses all the values. In that case `y_true` = [0, 0, 1, 1], `y_pred` = [1, 1, 1., 1.]  so precision will be 0.5. Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/af71a7be1c9cc0e945f79536d540fbb3/untitled710.ipynb). Thanks!", "Sure, this is true, but in that case it's not on average, and instead you should say precision at top_k (ties are broken by the order in which the values are provided).\r\n\r\nIf it was on average, it should be expected to break ties according to expectation. So in the case of top_k=1, it should still be 0.5, because under random assignment of order (given that all y_hat are equal), 0.5 of the permutations will have 1 in the first element in the array.", "> @LeechMuse\r\n> In the code provided by you `y_true` = [0, 0, 1, 1], `y_pred` = [1, 1, 1., 1.] , top_k = top-k classes to be considered to calculate precision.\r\n> \r\n> If top_k = none it consider all the classes.\r\n> \r\n> Precision is calculated by TP/TP+FP. So in the case top_k =1 it considers the first value only to calculate precision (ie y_true = [0] and y_pred = [1]) so precision is zero.\r\n> \r\n> Similarly top_k=2 considers first 2 values y_true` = [0, 0] and y_pred` = [1, 1] so precision is zero.\r\n> If top_k=3 then y_true` = [0, 0,1] and y_pred` = [1,1,1.] so precision is 0.33.\r\n> \r\n> In this example top_k =4 or None is same because it uses all the values. In that case `y_true` = [0, 0, 1, 1], `y_pred` = [1, 1, 1., 1.] so precision will be 0.5. Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/af71a7be1c9cc0e945f79536d540fbb3/untitled710.ipynb). Thanks!\r\n\r\n@ravikyram , I think this example should also be added in the doc, so here it is. PR #37528 adds this example to doc."]}, {"number": 37415, "title": "Tensorflow2.0 is not supporting this code", "body": "Tensorflow2.0 is not supporting this `tf.contrib.training.bucket_by_sequence_length` and what can I use instead of this ", "comments": ["Perhaps [`tf.data.experimental.bucket_by_sequence_length`](tf.data.experimental.bucket_by_sequence_length) can help? It might require some modification to use [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset).\r\n", "@frytry \r\nplease let us know if the above comment helps.", "@frytry \r\ncould you please respond to the above comment", "No it will not work. Both are different... Please check the documentation.\n\nOn Mon, Mar 9, 2020, 11:36 AM Saduf2019 <notifications@github.com> wrote:\n\n> @frytry <https://github.com/frytry>\n> please let us know if the above comment helps.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/37415?email_source=notifications&email_token=AKYWWKUDFVXYCDWDQAPB7WLRGSBPFA5CNFSM4LDP2WF2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEOFYQNI#issuecomment-596346933>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AKYWWKVM3ODTMZQDCTTM73TRGSBPFANCNFSM4LDP2WFQ>\n> .\n>\n", "@frytry \r\nplease share a simple stand alone code for us to replicate the issue faced.\r\n\r\nyou could also check [link1](https://github.com/wcarvalho/jupyter_notebooks/blob/ebe762436e2eea1dff34bbd034898b64e4465fe4/tf.bucket_by_sequence_length/bucketing%20practice.ipynb) for reference", "@frytry\r\nplease update on above comment", "@frytry\r\nAutomatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 37414, "title": "ValueError: No gradients provided for any variable: ['dense_26/kernel:0', 'dense_26/bias:0']", "body": "**System information** \r\n- OS Platform and Distribution: Windows 10\r\n\r\n- TensorFlow installed from Anaconda 1.9.12. Channel: default.\r\nTensorflow Version: 2.1.0\r\n\r\n- Python version: 3.7.6\r\n\r\n- CUDA/cuDNN version:\r\ncudatoolkit: 10.1.243\r\ncuDNN: 7.6.5\r\n\r\n- GPU: NVidia GeForce GTX 1060, 6 GB\r\n\r\n**Describe the current behavior**\r\nI've been developing a Relativistic Style GAN, but when I try to train the discriminator, I keep getting ValueError: No gradients provided for any variable. I replaced the generator and discriminator with empty dummies in order to figure out what was causing the problem, but I still got the error.\r\n\r\nI suspect the loss function for while but then I recalled a simple functional non-style version of the RaGAN script used to work fine and without errors during training and produced blurry but recognizable results. When I tried that script again, I got this gradient error as well.\r\n\r\nI'm stumped at what could be causing this error.\r\n\r\n**Standalone code to reproduce the issue** \r\nI'm new to GitHub and couldn't manage to past the code in a coherent way so here's\r\na link to the Jupyter Notebook that replicates the problem:\r\n[MyBuggyRelStyle](https://github.com/beardwolf/beardwolf/blob/master/MyBuggyRelStyle.ipynb)\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\n`---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-55-39aabbcfc7eb> in <module>\r\n     20         z = np.random.normal(scale=.25, size=(batch_size, dl_size))\r\n     21         z2 = np.random.normal(scale=.25, size=(batch_size, dl_size))\r\n---> 22         disc_loss.append(disc_train.train_on_batch([data, z, z2], dummy_y))\r\n     23 \r\n     24         gen.trainable = True\r\n\r\n~\\Anaconda3\\envs\\deep-learning-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py in train_on_batch(self, x, y, sample_weight, class_weight, reset_metrics)\r\n   1076           self, x, y=y, sample_weight=sample_weight,\r\n   1077           class_weight=class_weight, reset_metrics=reset_metrics,\r\n-> 1078           standalone=True)\r\n   1079       outputs = (outputs['total_loss'] + outputs['output_losses'] +\r\n   1080                  outputs['metrics'])\r\n\r\n~\\Anaconda3\\envs\\deep-learning-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py in train_on_batch(model, x, y, sample_weight, class_weight, reset_metrics, standalone)\r\n    431       y,\r\n    432       sample_weights=sample_weights,\r\n--> 433       output_loss_metrics=model._output_loss_metrics)\r\n    434 \r\n    435   if reset_metrics:\r\n\r\n~\\Anaconda3\\envs\\deep-learning-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py in __call__(self, *args, **kwds)\r\n    566         xla_context.Exit()\r\n    567     else:\r\n--> 568       result = self._call(*args, **kwds)\r\n    569 \r\n    570     if tracing_count == self._get_tracing_count():\r\n\r\n~\\Anaconda3\\envs\\deep-learning-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py in _call(self, *args, **kwds)\r\n    604       # In this case we have not created variables on the first call. So we can\r\n    605       # run the first trace but we should fail if variables are created.\r\n--> 606       results = self._stateful_fn(*args, **kwds)\r\n    607       if self._created_variables:\r\n    608         raise ValueError(\"Creating variables on a non-first call to a function\"\r\n\r\n~\\Anaconda3\\envs\\deep-learning-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in __call__(self, *args, **kwargs)\r\n   2360     \"\"\"Calls a graph function specialized to the inputs.\"\"\"\r\n   2361     with self._lock:\r\n-> 2362       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n   2363     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n   2364 \r\n\r\n~\\Anaconda3\\envs\\deep-learning-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in _maybe_define_function(self, args, kwargs)\r\n   2698           and self.input_signature is None\r\n   2699           and call_context_key in self._function_cache.missed):\r\n-> 2700         return self._define_function_with_shape_relaxation(args, kwargs)\r\n   2701 \r\n   2702       self._function_cache.missed.add(call_context_key)\r\n\r\n~\\Anaconda3\\envs\\deep-learning-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in _define_function_with_shape_relaxation(self, args, kwargs)\r\n   2630         relaxed_arg_shapes)\r\n   2631     graph_function = self._create_graph_function(\r\n-> 2632         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\r\n   2633     self._function_cache.arg_relaxed[rank_only_cache_key] = graph_function\r\n   2634 \r\n\r\n~\\Anaconda3\\envs\\deep-learning-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   2591             arg_names=arg_names,\r\n   2592             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 2593             capture_by_value=self._capture_by_value),\r\n   2594         self._function_attributes,\r\n   2595         # Tell the ConcreteFunction to clean up its graph once it goes out of\r\n\r\n~\\Anaconda3\\envs\\deep-learning-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    976                                           converted_func)\r\n    977 \r\n--> 978       func_outputs = python_func(*func_args, **func_kwargs)\r\n    979 \r\n    980       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n~\\Anaconda3\\envs\\deep-learning-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py in wrapped_fn(*args, **kwds)\r\n    437         # __wrapped__ allows AutoGraph to swap in a converted function. We give\r\n    438         # the function a weak reference to itself to avoid a reference cycle.\r\n--> 439         return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    440     weak_wrapped_fn = weakref.ref(wrapped_fn)\r\n    441 \r\n\r\n~\\Anaconda3\\envs\\deep-learning-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py in wrapper(*args, **kwargs)\r\n    966           except Exception as e:  # pylint:disable=broad-except\r\n    967             if hasattr(e, \"ag_error_metadata\"):\r\n--> 968               raise e.ag_error_metadata.to_exception(e)\r\n    969             else:\r\n    970               raise\r\n\r\nValueError: in converted code:\r\n\r\n    C:\\Users\\Hudson\\Anaconda3\\envs\\deep-learning-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py:305 train_on_batch  *\r\n        outs, total_loss, output_losses, masks = (\r\n    C:\\Users\\Hudson\\Anaconda3\\envs\\deep-learning-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py:273 _process_single_batch\r\n        model.optimizer.apply_gradients(zip(grads, trainable_weights))\r\n    C:\\Users\\Hudson\\Anaconda3\\envs\\deep-learning-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py:426 apply_gradients\r\n        grads_and_vars = _filter_grads(grads_and_vars)\r\n    C:\\Users\\Hudson\\Anaconda3\\envs\\deep-learning-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py:1039 _filter_grads\r\n        ([v.name for _, v in grads_and_vars],))\r\n\r\n    ValueError: No gradients provided for any variable: ['dense_26/kernel:0', 'dense_26/bias:0'].\r\n0\r\n1\r\nPython 3 | Idle\r\nMyBuggyRelStyle.ipynb\r\nLn 22, Col 1\r\n`\r\n", "comments": ["@beardwolf \r\n\r\nWill it be possible to share the sample data , it helps us to reproduce the issue in our environment.Thanks!", "Sure. I've uploaded some data to my repository. In the script just change the directory variable to the directory where you put the data. Sorry about the double zip extension in the filename. I'm new to GitHub. It's a normal zip file, not double zipped. Thanks!\r\n\r\n[data.zip.zip](https://github.com/tensorflow/tensorflow/files/4307523/data.zip.zip)\r\n ", "@beardwolf \r\n\r\nI have tried on cloab with TF version 2.1.0 . Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/b2393f340fec1b5344e2f99bfb238ca9/untitled727.ipynb). Is this the expected behavior. Thanks!", "Sorry, but no. The gist has an OpenCV error thrown from the data generator that I didn't get when I ran it on my computer. The error I got was thrown from train_on_batch.", "@beardwolf this is an user generated error, not a bug. Please post this question in stackoverflow as there is a wider community to respond. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing this issue as it has been inactive for more than 3 weeks. Please add additional comments for us to open this issue again. Thanks!"]}, {"number": 37413, "title": "random output ", "body": " the chat i created it doesn't work correctly i guess it keep givin me this kind of result no matter how much time i train it \r\n \r\n\r\n> python3 ./translate.py  --en_vocab_size=40000 --fr_vocab_size=40000 --data_dir=/home/baba055h_s/ --train_dir=/home/baba055h_s/ --decode\r\n/home/baba055h_s/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:463: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\n/home/baba055h_s/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:464: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\n/home/baba055h_s/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:465: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\n/home/baba055h_s/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:466: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\n/home/baba055h_s/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:467: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\nWARNING:tensorflow:From /home/baba055h_s/ten3/tensorflow/tensorflow/models/rnn/translate/seq2seq_model.py:188 in __init__.: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\r\nInstructions for updating:\r\nPlease use tf.global_variables instead.\r\nCreated model with fresh parameters.\r\nWARNING:tensorflow:From ./translate.py:138 in create_model.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\r\nInstructions for updating:\r\nUse `tf.global_variables_initializer` instead.\r\n/> hi\r\nsample sample sample sample sample sample sample sample letter-sized letter-sized\r\n>/> what's up\r\nsample sample sample soil soil soil neski neski neski neski\r\n\r\n> as you notice the result are random 10 words at least and some words are repeated  like this :\"sample sample sample soil soil soil neski neski neski neski\"\r\n\r\n\r\n\r\n\r\n>>i'm using \r\ntensorflow 0.12.1\r\ntranslate script with branch r0.11\r\nprepare data using this script\r\nhttps://github.com/b0noI/dialog_converter/tree/master\r\ni trained it up to 4000 time and the same thing\r\n\r\nsee what is that all about is it something wrong with the data i provided\r\nplease help me ", "comments": ["@mohlondon,\r\nIn order to expedite the trouble-shooting process, could you please provide the minimal code to reproduce the issue reported here. Thanks!", "What code i did mention that i used the translate.py script of this project branch: r0.11", "@mohlondon,\r\nFrom the link you have provided, I was able to prepare the data. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/68e56a7f958a019dd72555dfcb43ac17/37413.ipynb).\r\n\r\nHowever, there is no translate script used. Could you please provide the link or the code of the  translate script you are using? Thanks!", "@mohlondon,\r\nAny updates regarding this issue? Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 37412, "title": "Cannot get accuracy for vgg19 in tflite", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: pip3(20.02)\r\n- **TensorFlow version (use command below)**: 2.1\r\n- **Python version**: 3.6.9\r\n- **Bazel version (if compiling from source)**:2.0.0\r\n- **GCC/Compiler version (if compiling from source)**: 7.4.0\r\n- **CUDA/cuDNN version**: 10.1\r\n- **GPU model and memory**: 1060 GTX - 6GB\r\n- **Exact command to reproduce**: \r\nbazel-bin/tensorflow/lite/tools/accuracy/ilsvrc/imagenet_accuracy_eval --model_file=../tensorflow_tests/models/vgg19.tflite --ground_truth_images_path=../val_imagenet/ --ground_truth_labels=ground_truth.txt --model_output_labels=./labels.txt --output_file_path=../vgg19_output_acc.txt --num_images=10\r\n\r\n### Describe the problem\r\nI have been running tflite accuracy script as defined [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/accuracy/ilsvrc) and I am able to run successfully, but when I am running the script for resnet or mobilenet, I am getting proper accurate results from top1 to top10, but when I am trying same with vgg19, I am not getting the  accuracy instead I am getting all values as zero or very low as below\r\n\r\nTop 1, Top 2, Top 3, Top 4, Top 5, Top 6, Top 7, Top 8, Top 9, Top 10\r\n0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000\r\n0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000\r\n0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000\r\n0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000\r\n0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000\r\n0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000\r\n0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000\r\n0.000, 0.000, 0.000, 12.500, 12.500, 12.500, 12.500, 12.500, 12.500, 12.500\r\n0.000, 0.000, 0.000, 11.111, 22.222, 22.222, 22.222, 22.222, 22.222, 22.222\r\n\r\nI tried changing the model_labels text file, but it's not working.\r\n\r\ndo I am making any mistake with vgg19 or what is happening?\r\nThanks in advance\r\n", "comments": ["Where did you get your model? if it's converted from [SLIM](https://github.com/tensorflow/models/tree/master/research/slim) checkpoints, notes that those VGG models were converted from caffe models so that they have different preprocessing part and classes (1000 instead of 1001).", "I have taken the model from Keras API.\r\nWhat is the difference in that preprocessing?", "note that there are two problems.\r\n\r\n1. preprocessing: keras supports 3 kinds of pre-processing: caffe, tf, and pytorch [1]. It seems Keras' VGG19 is from Caffe too, so it needs Caffe preprocessing [2]. Mobilenet uses tf preprocessing [3].\r\n\r\n2. number of classes: you need an off-by-one labels file \r\n\r\n[1] https://github.com/keras-team/keras-applications/blob/master/keras_applications/imagenet_utils.py#L18-L62\r\n[2] https://github.com/keras-team/keras-applications/blob/master/keras_applications/vgg19.py#L20\r\n[3] https://github.com/keras-team/keras-applications/blob/master/keras_applications/mobilenet.py#L75-L84", "@freedomtan thank you for your answer, but for calculating accuracy using tflite tool, do I need to make changes in the code of tflite accuracy tool for integrating Caffe preprocessing in it?", "Relevant code is there [1]. I never tried it personally.\r\n\r\n[1] https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/evaluation/stages", "@freedomtan Thank you, I will check it out once.", "@venkat-kittu, Any update for the @freedomtan's comment. Thanks!", "@venkat-kittu, Were you able to resolve this issue. Thanks!", "Sorry for the delay, I was able to solve the issue by running prediction image by image and got accuarcy, buy using preprocessing in this [link](https://github.com/calebrob6/imagenet_validation/blob/master/1.%20Preprocess%20ImageNet%20validation%20set.ipynb) "]}, {"number": 37411, "title": "Fix a go binding install error on windows platform", "body": "If running *go generate github.com/tensorflow/tensorflow/tensorflow/go/op* on windows platform, it well show \r\n\r\n> \\go_path/src/github.com/tensorflow/tensorflow: warning: directory does not exist.\r\nCannot convert path \"\\go_path/src/github.com/tensorflow/tensorflow/tensorflow/core/framework/*.proto\" to or from Windows style ..\\genop\\main.go:17: running \"bash\": exit status 1\r\n..\\github.com\\tensorflow\\tensorflow\\tensorflow\\go\\op\\generate.go:17: running \"go\": exit status 1\r\n\r\nSo this commit will automatically convert windows style slashes.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37411) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F37411) for more info**.\n\n<!-- ok -->", "@jhseu Can you please review this PR ? Thanks!", "@jhseu/@frankchn Can you please review this PR ? Thanks!", "@bbbboom Can you please check @frankchn's comments and keep us posted ? Thanks!"]}, {"number": 37410, "title": "Center Loss in TF 2.0", "body": "I am trying to implement center loss in Tensorflow 2.0 by referring to code in following repositories:\r\n\r\n- https://github.com/handongfeng/MNIST-center-loss\r\n\r\n- https://github.com/mjDelta/keras-center-loss-MNIST\r\n\r\n- https://github.com/Kakoedlinnoeslovo/center_loss\r\n\r\nI noticed that some arguments in the method \"self.add_update((self.centers,new_centers),x)\" when creating a custom layer, are deprecated. The code (linked above) does not throw any error, but the centers are never updated when run in Tensorflow 2.0. \r\n\r\nYou can find the related description for the problem here:\r\nhttps://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/engine/base_layer.py#L1170-L1259\r\n\r\nI am trying to update the weights of the layer after every forward pass so I can use it as tf.Variable which can persist the updated centroids for the next iteration.\r\n\r\nAny help on this would be appreciated.\r\nThanks\r\n", "comments": ["@suraj-maniyar \r\n\r\nThanks for reporting the issue. Can you please share the simple standalone code to reproduce the issue. It helps us in localizing the issue faster. Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "@suraj-maniyar \r\n\r\nAny update on this issue please. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "To update this, we need to use \r\n\r\n> tf.keras.backend.update(x, new_x)\r\n\r\n as the argument to the add_update function, as it expects an update operation."]}, {"number": 37409, "title": "OperatorNotAllowedInGraphError occur when using tf.function", "body": "**System information**\r\nPython 3.6.9 on Ubuntu 18.04\r\n\r\nUsing tensorflow 2.1.0-\r\n\r\nGPU Hardware: Quadro P6000\r\n\r\n**Issue description:**\r\nI try to use a map function to split a string to multiple tensors. with following sample code:\r\n```python\r\n@tf.function\r\ndef csv_text_parse(line):\r\n    f0, f1, f2 = tf.strings.split(line, sep=',')\r\n    return f0, f1, f2\r\n\r\ncsv_text_parse(b'0,2,hello')\r\n```\r\n![image](https://user-images.githubusercontent.com/731496/76136765-2fa27100-6070-11ea-9306-ad3279481df4.png)\r\n\r\nbut if change the above function to:\r\n```python\r\n@tf.function\r\ndef csv_text_parse2(line):\r\n    return tf.strings.split(line, sep=',')\r\n```\r\n\r\nthe result will be fine. ", "comments": ["i misunderstand the return value of tf.strings.split. it is NOT a bug. closed.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37409\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37409\">No</a>\n"]}, {"number": 37408, "title": "r2.2: cherry-pick request: fix profile traces too large and windows builds.", "body": "When profiling a large model, the trace cannot be successfully saved. Gzip the traces to reduce its trace size.\r\nFix windows builds: Use '\\' instead of '/' for paths.\r\nAlso don't use ':' for folder names in windows.\r\nAlso populate missing error message to end user to help with debugging.", "comments": []}, {"number": 37407, "title": " Tensorflow2.1.compat.v1 distributed training occasionally goes wrong", "body": "`TaskIndex: 4 | Episode: 1995/100000  | Episode Reward: 52.2229  | Running Time: 7.6459 | EnvStep Time: 0.7538 | Render Time: 0.0000\r\nTaskIndex: 1 | Episode: 1984/100000  | Episode Reward: 2.9837  | Running Time: 7.6459 | EnvStep Time: 1.4454 | Render Time: 0.0000\r\nTaskIndex: 6 | Episode: 1992/100000  | Episode Reward: 8.1637  | Running Time: 7.6850 | EnvStep Time: 1.0630 | Render Time: 0.0000\r\nTaskIndex: 0 | Episode: 2004/100000  | Episode Reward: -60.5018  | Running Time: 5.3829 | EnvStep Time: 2.2781 | Render Time: 0.9659\r\n2020-03-07 09:55:22.138197: I tensorflow/core/202distri0b-03uted-07 09_runtime/worker:55:22..138233: Ic c:t2enso04]rfl Caowncell/coaretion /dreqistriuebuted_rsted untifor meRun/worker.cc:2Grap04]h.\r\n Cancellation requested for RunGraph.\r\n2020-03-07 09:55:22.138365: I tensorflow/core/distributed_runtime/worker.cc:204] Can202cella0-tio03-07n  09:55:22re.13850que8: Ested  tensorflfor owRu/conGrre/aphdistribu.\r\nted_runtime/master_session.cc:1911] Cleanup partition error: Unavailable: Stream removed\r\nAdditional GRPC error information:\r\n{\"created\":\"@1583546122.138000000\",\"description\":\"Error received from peer\",\"file\":\"external/grpc/src/core/lib/surface/call.cc\",\"file_line\":1039,\"grpc_message\":\"Stream removed\",\"grpc_status\":2}\r\n2020-03-07 09:55:22.1382029208220-03-: 02020-03-07 09:55:22.139043: I tensorflow20/2c0-03-07 09:55o:20-Ir2e/d tensorflow/core/distributed_runtime/worker.cc:204] Cancellation reques2020ted- fo0r3- 07 09R7u 0n9::55250205.:122.1:39014:2G2 r.I1a 3ptensorfh9l.2o\r\n08: I tensorflow/core/distributed_runtime/worker.cc:204] Cancellation requested for RunGraph.\r\n03-07 09:55:22.w/core/distributed_runtime/worker.cc:204] Cancellation reistrq-03-07 0u138993eis39089: I tensorflow/core/distributed_runtime/worker.cc:204] Cancellation reqt: eb9u:Idu e5 fosted for RunGraph.\r\n5te:tnesod2r_2f.lo1rw3u/9nctoirmee//2wdistributed_runtime/worker.cc:204] Can7ocrkelelr6a:.tion  Ir ctensorflow/core/distributed_ruce:q2un0et4si]tmee d/C wafoornrkc eeRru.nGclcrl:ar Rph.2a\r\n04] Cancellation requested for RunGraph.\r\ntion requested for RunGraph.\r\nunGraph.\r\n2020-03-07 09:55:22.588608: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\r\n2020-03-07 09:55:22.588719: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\nC:\\Users\\zkx74\\Anaconda3\\envs\\RL\\lib\\site-packages\\pandas_datareader\\compat\\__init__.py:7: FutureWarning:\r\n\r\npandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.`\r\n\r\nIt can train normally for aobut hundreds episode, and the throw this error message.\r\nI used 1ps and 8 worker on 1CPU+1GPU", "comments": ["@zkx741481546 \r\n\r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nRequest you to share simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster. Please, fill [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).Thanks!\r\n\r\n\r\n", "> @zkx741481546\r\n> \r\n> Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n> \r\n> Request you to share simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster. Please, fill [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).Thanks!\r\n\r\nWin10 1903 \r\nanaconda \r\npython3.7\r\ntensorflow2.1 avx2 \r\ntebsorflow2.1-gpu avx2\r\n\r\nIt turns out to be a bug of pycharm, after this error, python program launched by pycharm can't find  cuda lib, but it works normally with powershell.\r\nAfter I restart pycharm, the problem never occored.", "@zkx741481546 \r\n\r\nlooks like issue got resolved. Please close this thread if it solves your question. Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing the issue since its resolved. Thanks!"]}, {"number": 37406, "title": "Fix a bug which may cause segmentation fault", "body": "", "comments": ["@PeterRK Thanks for the fix!"]}, {"number": 37405, "title": "TensorFlow 2.1.0: _FallbackException: This function does not handle the case of the path where all inputs are not already EagerTensors", "body": "I am writing a custom loss function which involves another (already trained) neural network, called model_weight, evaluating predictions on the input of the model I'm currently training:\r\nCode to fully reproduce: [https://colab.research.google.com/gist/adisurtya/387383b8f4e518dbb938ecd1af87b982/37405_full.ipynb](url)\r\n\r\nWhere the issue is: \r\n```\r\ndef weight(d):\r\n  f = model_weight.predict(d,steps = 1)\r\n  return (f)/(1-f)\r\n\r\nmyinputs = Input(shape=(1,), dtype = tf.float32)\r\nx = Dense(128, activation='relu')(myinputs)\r\nx2 = Dense(128, activation='relu')(x)\r\npredictions = Dense(1, activation='sigmoid')(x2)\r\nmodel = Model(inputs=myinputs, outputs=predictions)\r\nmodel.summary()\r\n\r\ndef my_loss_wrapper(inputs,val=0):\r\n  x  = inputs\r\n  theta = 0. #starting value\r\n  #theta0 = tf.constant(val, dtype= tf.float32)#target value\r\n\r\n  #creating tensor (filled with 1s) with same shape as inputs; multiply by val\r\n  theta0_stack = K.ones_like(x, dtype=tf.float32)*val \r\n\r\n  #combining and reshaping into correct format:\r\n  data = K.stack((x, theta0_stack), axis=-1) \r\n  data = K.squeeze(data, axis = 1)\r\n  #slice data to 500 entries to match batch_size\r\n  data = K.gather(data, np.arange(500))\r\n  print(data.shape)\r\n\r\n  w = weight(data)\r\n\r\n  def my_loss(y_true,y_pred):\r\n    t_loss = K.mean(y_true*(y_true - y_pred)**2+(w)**2*(1.-y_true)*(y_true - y_pred)**2)\r\n    return t_loss\r\n\r\n  return my_loss\r\n\r\nmodel.compile(optimizer='adam', loss=my_loss_wrapper(myinputs,theta),metrics=['accuracy'])\r\nmodel.fit(np.array(X_train), y_train, epochs=1, batch_size=500,validation_data=(np.array(X_test), y_test),verbose=1)\r\n```\r\n\r\nGetting an error when weight() calls model_weight.predict on \"data\". This function works fine on regular tensors that I initialize with strict values (e.g.\r\n\r\n```\r\ntf.Tensor(\r\n[[1 5]\r\n [2 5]\r\n [3 5]], shape=(3, 2), dtype=int32))\r\n```\r\nbut not on the tensor that includes \"x\" or \"inputs\". Error message when the model tries to compile:\r\n\r\n```\r\n_FallbackException                        Traceback (most recent call last)\r\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py in tensor_dataset(components, output_shapes, name)\r\n   5590         _ctx._context_handle, tld.device_name, \"TensorDataset\", name,\r\n-> 5591         tld.op_callbacks, components, \"output_shapes\", output_shapes)\r\n   5592       return _result\r\n\r\n_FallbackException: This function does not handle the case of the path where all inputs are not already EagerTensors.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-19-f74b0047add5> in <module>\r\n      4 \r\n      5 for theta in thetas:\r\n----> 6     model.compile(optimizer='adam', loss=my_loss_wrapper(myinputs,theta),metrics=['accuracy'])\r\n      7     model.fit(np.array(X_train), y_train, epochs=1, batch_size=500,validation_data=(np.array(X_test), y_test),verbose=1)\r\n      8     lvals+=[model.history.history['val_loss']]\r\n\r\n<ipython-input-18-3ac14760abd7> in my_loss_wrapper(inputs, val)\r\n     24     print(tf.executing_eagerly())\r\n     25     print(weight(test))\r\n---> 26     w = weight(data)\r\n     27 \r\n     28     def my_loss(y_true,y_pred):\r\n\r\n<ipython-input-14-c58e20e1428a> in weight(d)\r\n     27 '''\r\n     28 def weight(d):\r\n---> 29     f = model_weight.predict(d,steps = 1)\r\n     30     return (f)/(1-f)\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py in predict(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\r\n   1011         max_queue_size=max_queue_size,\r\n   1012         workers=workers,\r\n-> 1013         use_multiprocessing=use_multiprocessing)\r\n   1014 \r\n   1015   def reset_metrics(self):\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py in predict(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    496         model, ModeKeys.PREDICT, x=x, batch_size=batch_size, verbose=verbose,\r\n    497         steps=steps, callbacks=callbacks, max_queue_size=max_queue_size,\r\n--> 498         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\r\n    499 \r\n    500 \r\n\r\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py in _model_iteration(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    424           max_queue_size=max_queue_size,\r\n    425           workers=workers,\r\n--> 426           use_multiprocessing=use_multiprocessing)\r\n    427       total_samples = _get_total_number_of_samples(adapter)\r\n    428       use_sample = total_samples is not None\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py in _process_inputs(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\r\n    704       max_queue_size=max_queue_size,\r\n    705       workers=workers,\r\n--> 706       use_multiprocessing=use_multiprocessing)\r\n    707 \r\n    708   return adapter\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/data_adapter.py in __init__(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\r\n    355     indices_dataset = indices_dataset.flat_map(slice_batch_indices)\r\n    356 \r\n--> 357     dataset = self.slice_inputs(indices_dataset, inputs)\r\n    358 \r\n    359     if shuffle == \"batch\":\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/data_adapter.py in slice_inputs(self, indices_dataset, inputs)\r\n    381     dataset = dataset_ops.DatasetV2.zip((\r\n    382         indices_dataset,\r\n--> 383         dataset_ops.DatasetV2.from_tensors(inputs).repeat()\r\n    384     ))\r\n    385 \r\n\r\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py in from_tensors(tensors)\r\n    564       Dataset: A `Dataset`.\r\n    565     \"\"\"\r\n--> 566     return TensorDataset(tensors)\r\n    567 \r\n    568   @staticmethod\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py in __init__(self, element)\r\n   2769     variant_tensor = gen_dataset_ops.tensor_dataset(\r\n   2770         self._tensors,\r\n-> 2771         output_shapes=structure.get_flat_tensor_shapes(self._structure))\r\n   2772     super(TensorDataset, self).__init__(variant_tensor)\r\n   2773 \r\n\r\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py in tensor_dataset(components, output_shapes, name)\r\n   5594       try:\r\n   5595         return tensor_dataset_eager_fallback(\r\n-> 5596             components, output_shapes=output_shapes, name=name, ctx=_ctx)\r\n   5597       except _core._SymbolicException:\r\n   5598         pass  # Add nodes to the TensorFlow graph.\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py in tensor_dataset_eager_fallback(components, output_shapes, name, ctx)\r\n   5627         \"'tensor_dataset' Op, not %r.\" % output_shapes)\r\n   5628   output_shapes = [_execute.make_shape(_s, \"output_shapes\") for _s in output_shapes]\r\n-> 5629   _attr_Toutput_types, components = _execute.convert_to_mixed_eager_tensors(components, ctx)\r\n   5630   _inputs_flat = list(components)\r\n   5631   _attrs = (\"Toutput_types\", _attr_Toutput_types, \"output_shapes\",\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py in convert_to_mixed_eager_tensors(values, ctx)\r\n    281 def convert_to_mixed_eager_tensors(values, ctx):\r\n    282   v = [ops.convert_to_tensor(t, ctx=ctx) for t in values]\r\n--> 283   types = [t._datatype_enum() for t in v]  # pylint: disable=protected-access\r\n    284   return types, v\r\n    285 \r\n\r\n/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py in <listcomp>(.0)\r\n    281 def convert_to_mixed_eager_tensors(values, ctx):\r\n    282   v = [ops.convert_to_tensor(t, ctx=ctx) for t in values]\r\n--> 283   types = [t._datatype_enum() for t in v]  # pylint: disable=protected-access\r\n    284   return types, v\r\n    285 \r\n\r\nAttributeError: 'Tensor' object has no attribute '_datatype_enum'\r\n```", "comments": ["@adisurtya,\r\nWhen I tried to run the above code, I got an error stating `NameError: name 'theta' is not defined`. Please find the gist of it [here](https://colab.sandbox.google.com/gist/amahendrakar/170a8327e9da4d0372bfcc8561c74963/37405.ipynb).\r\n\r\nLooks like the given code is incomplete, in order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here. Thanks!", "@amahendrakar Sorry, forgot to include this. Here is the fully reproducible code: [https://colab.research.google.com/gist/adisurtya/387383b8f4e518dbb938ecd1af87b982/37405_full.ipynb](url)", "Was able to reproduce the issue. Please find the Gist [here](https://colab.research.google.com/gist/amahendrakar/6a36653e0eb856558137f66b37c9de41/37405.ipynb). Thanks!", "While trying to reproduce your issue in Tf Nightly faced different error, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/09596ba83256185b95e7c0e8a2057bf4/35650.ipynb). Thanks!", "@adisurtya \r\nAs the reported error has been resolved, can you please open this issue in keras repo\r\nPlease find [the gist here](https://colab.research.google.com/gist/Saduf2019/032fdba77d9ae7c66b99f21f6a293f6e/untitled638.ipynb) for the new error.\r\n\r\nPlease post this issue on keras-team/keras repo.\r\nTo know more refer to:\r\nhttps://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37405\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37405\">No</a>\n"]}, {"number": 37404, "title": "TFLite inference throwing error at one of the run", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): Followed official classifier example\r\n\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Android 9\r\n\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: Huawei 9 lite\r\n\r\n- TensorFlow version (use command below): \r\n    implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly'\r\n    implementation 'org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly'\r\n    implementation 'org.tensorflow:tensorflow-lite-support:0.0.0-nightly'\r\n    implementation 'org.tensorflow:tensorflow-lite-select-tf-ops:0.0.0-nightly'\r\n\r\n**Describe the current behavior**\r\nI have a model that has 1 input and 2 outputs. I have written the below code for inference using **run()** rather than **runForMultipleInputsOutputs**. So first I have a query:\r\nWould running it with runForMultipleInputsOutputs() rather than calling run() twice, make it run faster or does runForMultipleInputsOutputs does same internally?\r\n\r\nNow I get right inference for first output layer but for the 2nd output inference, I get the below error message.\r\n\r\n`java.lang.IllegalArgumentException: Cannot convert between a TensorFlowLite buffer with 32 bytes and a Java Buffer with 8 bytes.`\r\n\r\n**Describe the expected behavior**\r\nShould run OK.\r\n\r\n**Standalone code to reproduce the issue** \r\n\r\n      ```\r\n       // Initialization Code\r\n       tflite = new Interpreter(tfliteModel, tfliteOptions);\r\n\r\n        // Loads labels out from the label file.\r\n        labelsAge = ageLabels; //List\r\n\r\n        labelsGender = genderLabels; // List\r\n\r\n        // Reads type and shape of input and output tensors, respectively.\r\n        int imageTensorIndex = 0;\r\n        int[] imageShape = tflite.getInputTensor(imageTensorIndex).shape(); // {1, height, width, 3}\r\n\r\n        imageSizeY = imageShape[1];\r\n        imageSizeX = imageShape[2];\r\n        DataType imageDataType = tflite.getInputTensor(imageTensorIndex).dataType();\r\n\r\n        // Creates the input tensor.\r\n        inputImageBuffer = new TensorImage(imageDataType);\r\n\r\n        // For Outputs\r\n        //For Age\r\n        int probabilityAgeTensorIndex = 0; // Age\r\n        int[] probabilityAgeShape = tflite.getOutputTensor(probabilityAgeTensorIndex).shape(); // {1, NUM_CLASSES}\r\n        DataType probabilityAgeDataType = tflite.getOutputTensor(probabilityAgeTensorIndex).dataType();\r\n\r\n        // Creates the output tensor and its processor.\r\n        outputProbabilityAgeBuffer = TensorBuffer.createFixedSize(probabilityAgeShape, probabilityAgeDataType);\r\n\r\n        // Creates the post processor for the output probability.\r\n        probabilityAgeProcessor = new TensorProcessor.Builder().add(getPostprocessNormalizeOp()).build();\r\n\r\n        //For Gender\r\n        int probabilityGenderTensorIndex = 1; // Gender\r\n        int[] probabilityGenderShape = tflite.getOutputTensor(probabilityGenderTensorIndex).shape(); // {1, NUM_CLASSES}\r\n        DataType probabilityGenderDataType = tflite.getOutputTensor(probabilityGenderTensorIndex).dataType();\r\n\r\n        // Creates the output tensor and its processor.\r\n        outputProbabilityGenderBuffer = TensorBuffer.createFixedSize(probabilityGenderShape, probabilityGenderDataType);\r\n\r\n        // Creates the post processor for the output probability.\r\n        probabilityGenderProcessor = new TensorProcessor.Builder().add(getPostprocessNormalizeOp()).build();\r\n\r\n\r\n       //********  Inference code ************\r\n        public AgeGenderValues estimateAgeGender(final Bitmap bitmap) {\r\n        // Logs this method so that it can be analyzed with systrace.\r\n        Trace.beginSection(\"estimateImage\");\r\n\r\n        Trace.beginSection(\"loadImage\");\r\n        inputImageBuffer = loadImage(bitmap);\r\n        Trace.endSection();\r\n\r\n        // Runs the inference call.\r\n        Trace.beginSection(\"ageRunInference \");\r\n        tflite.run(inputImageBuffer.getBuffer(), outputProbabilityAgeBuffer.getBuffer().rewind());\r\n        Trace.endSection();\r\n\r\n        Trace.beginSection(\"genderRunInference \");\r\n        // ********** ERROR THROWN AT BELOW STATEMENT  **************\r\n        tflite.run(inputImageBuffer.getBuffer(), outputProbabilityGenderBuffer.getBuffer().rewind());\r\n        Trace.endSection();\r\n\r\n        // Gets the map of label and probability.\r\n        Map<String, Float> labeledAgeProbability = new TensorLabel(labelsAge, probabilityAgeProcessor.process(outputProbabilityAgeBuffer)).getMapWithFloatValue();\r\n        Map<String, Float> labeledGenderProbability = new TensorLabel(labelsGender, probabilityGenderProcessor.process(outputProbabilityGenderBuffer)).getMapWithFloatValue();\r\n        Trace.endSection();\r\n\r\n        AgeGenderValues tmpAgeGenderValues = new AgeGenderValues();\r\n        // Gets top-k results.\r\n        tmpAgeGenderValues.Age = getTopKProbability(labeledAgeProbability);\r\n        tmpAgeGenderValues.Gender = getTopKProbability(labeledGenderProbability);\r\n        return tmpAgeGenderValues;\r\n    }\r\n\r\n    ```\r\n\r\nGraph\r\n\r\n\r\n![agegendermultitaskspcnn](https://user-images.githubusercontent.com/7953422/76128759-3bb80f80-602b-11ea-9208-92f5716ad320.png)\r\n\r\n", "comments": ["Figured it out myself. Closing issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37404\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37404\">No</a>\n"]}, {"number": 37403, "title": "Ignore training=None when passed during Functional API construction.", "body": "PiperOrigin-RevId: 299283031\r\nChange-Id: I9a0654496fb403a304efca2d79f9cb1a56a2b3e5", "comments": []}, {"number": 37402, "title": "[r2.2:Cherrypick] Diable a test that fails on open source build to unblock the release.", "body": "PiperOrigin-RevId: 299389711\nChange-Id: If4b4f18c6141101b7a7d3034a3e77a0eaabc8810", "comments": []}, {"number": 37401, "title": "FasterRCNN_resnet101 .tflite conversion", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (or github SHA if from source): pip install tf-nightly\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\nimport tensorflow as tf\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(\"/content/trained_m2_data_38000steps_resnet101/saved_model\")\r\n\r\nconverter.experimental_new_converter = True  # Add this line\r\n\r\ntflite_model = converter.convert()\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\r\n---------------------------------------------------------------------------\r\nConverterError                            Traceback (most recent call last)\r\n<ipython-input-9-4edb7ba34fed> in <module>()\r\n      4 converter.experimental_new_converter = True  # Add this line\r\n      5 \r\n----> 6 tflite_model = converter.convert()\r\n      7 \r\n      8 '''\r\n\r\n2 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n    225       stdout = _try_convert_to_unicode(stdout)\r\n    226       stderr = _try_convert_to_unicode(stderr)\r\n--> 227       raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\n    228   finally:\r\n    229     # Must manually cleanup files.\r\n\r\nConverterError: See console for info.\r\n2020-03-06 20:56:59.840264: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:305] Ignored output_format.\r\n2020-03-06 20:56:59.840346: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:308] Ignored drop_control_dependency.\r\n2020-03-06 20:57:00.599028: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\r\nloc(\"FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/Pad\"): error: 'tfl.pad' op failed to verify that operand 0's rank equals operand 1's size\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/toco_from_protos\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 93, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 56, in execute\r\n    enable_mlir_converter)\r\nException: <unknown>:0: error: loc(\"FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/Pad\"): 'tfl.pad' op failed to verify that operand 0's rank equals operand 1's size\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\nhttps://gist.github.com/dkurt/1fe03728dcb51955c89d30dfe6c11a3d\r\n```\r\n\r\n**Failure details**\r\nIf the conversion is successful, but the generated model is wrong,\r\nstate what is wrong:\r\n- Producing wrong results and/or decrease in accuracy\r\n- Producing correct results, but the model is slower than expected (model generated from old converter)\r\n\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Is Padding layer not supported yet?", "@haozha111 and @ymodak  just wondering if there is any further update on this issue ? Thanks!", "I'm also facing the same issue when I'm converting the mask rcnn model from TF object detection API (mask_rcnn_resnet50_atrous_coco_2018_01_28) trained on custom dataset.\r\n\r\nReference: https://github.com/tensorflow/tensorflow/issues/34845\r\n\r\nCode:\r\n```\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\nconverter.experimental_new_converter = True\r\ntflite_model = converter.convert()\r\n```\r\n\r\nOutput:\r\n```\r\nConverterError: See console for info.\r\n2020-03-12 02:41:16.739086: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:305] Ignored output_format.\r\n2020-03-12 02:41:16.739166: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:308] Ignored drop_control_dependency.\r\n2020-03-12 02:41:17.295677: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\r\nloc(\"FirstStageFeatureExtractor/resnet_v1_50/resnet_v1_50/Pad\"): error: 'tfl.pad' op failed to verify that operand 0's rank equals operand 1's size\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/toco_from_protos\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 93, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 56, in execute\r\n    enable_mlir_converter)\r\nException: <unknown>:0: error: loc(\"FirstStageFeatureExtractor/resnet_v1_50/resnet_v1_50/Pad\"): 'tfl.pad' op failed to verify that operand 0's rank equals operand 1's size\r\n\r\n```", "@haozha111 do you have any updates on this issue?\r\n", "Have you ever tried the new MLIR based TF Lite converter?\r\n\r\nIt's already enabled by default in TF 2.2 or TF nightly.", "@haozha111 Yes I tried with tf-nightly with MLIR enabled in TF Lite converter. Still facing this issue.\r\n\r\nwere you able to run this successfully?", "@pushkalkatara @Namburger Take a look at the comments on [this issue](https://github.com/tensorflow/tensorflow/issues/34845#issuecomment-573156336).\r\n\r\nThere is a way to convert these MaskRCNN models from the TF object detection repository, but with static shapes & without the segmentation outputs. The simple reason is that these models are too large for mobile inference, so they usually cause memory/latency issues on typical devices.\r\n\r\nThe linked bug has a method for converting the model by modifying `pipeline.config` & using a script to export the inference graph. But its not the best way, mainly because we don't have a great mobile-friendly version of MaskRCNN, atleast in the TF model zoo.\r\n\r\nThe newer SSD MobileNetv3 have pretty good performance for bounding-box detection, and DeepLabv3 might be better suited for segmentation (but in a semantic way).", "What about Resnet 50 or 101 from the Object Detection framework (Model Zoo) to find bounding boxes (not segmentation) ? It uses FasterRCNN architecture.  Is it possible to convert these with TFLite and run them on the Coral Dev Board ?\r\n\r\nAlso can you provide the steps to do the pipeline.config mod to export the model with TFLite ? The specific work around for this error.\r\n\r\nThanks!", "The models should convert with the same changes as mentioned in that issue. You might have to change a couple of commands based on input size etc, which will be given in pipeline.config. Not sure about coral dev board.\r\n\r\nTBH, the new SSD MobileNet v3 (large) gives as good a COCO mAP as some of the FasterRCNN architectures, so you could see if that works for your use-case.", "@srjoglekar246 I think there would be a good difference in accuracy due to number of deep layers in the models - mobilenet-v3 vs resnet101. \r\nCurrently, FasterRCNN with Resnet101 is generally used for high accuracy and SSD-Mobilenet is used for higher inference speeds. But SSD conversion is supported by TFLite but not FasterRCNN (post says but the error above comes). What are the chances of optimization being successful if we train ssd with backbone resnet101 and achieve comparable accuracy as FasterRCNN-resnet101. ", "That could be a good idea. (though you will need to start training from scratch).\r\nSSD's post-processing & proposal generation is weaker than FasterRCNN, but having more layers in the back-bone should definitely improve accuracy.", "Training a model like resnet101 from scratch is far out of scope. :sweat_smile: . It is better to wait TFLite with FasterRCNN implementation i think.", "@pushkalkatara Could you please try on latest stable version of tf 2.5 or 2.4.1 and let us know if this is still an issue.Thanks!", "Hey @pushkalkatara , if this is still an issue, feel free to look at the `SSD ResNet50 V1 FPN 640x640 (RetinaNet50)` model from the [TF2 Detection Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md). It converts well to TFLite using [these instructions](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tf2.md), and should provide better accuracy (at cost of slower speed) than the MobileNet version.", "@pushkalkatara Could you please update as per the above [comment](https://github.com/tensorflow/tensorflow/issues/37401#issuecomment-879286909) and let us know if this is still an issue ? Thanks!", "It has been a long time since I worked on this project. Guessing it's supported now, so closing the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37401\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37401\">No</a>\n"]}, {"number": 37400, "title": "Add support for any Tensor type describable by TensorSpec to tf.data.Dataset.from_generator", "body": "This PR addresses the #35342 issue which proposes to add the support for different types of tensors to tf.data.Dataset.from_generator.\r\n\r\nInitially `from_generator` had two parameters: output_types and output_shapes (one mandatory and the other one optional) that allowed user to specify the dtypes and optionally shapes of the output objects, but not the types of the objects themselves thus making it impossible for a generator function to output more complicated types of objects like tf.RaggedTensor or tf.SparseTensor.\r\n\r\nI followed here the advice from @jsimsa and added the output_spec parameter that, being specified, overrides the output_types and output_spec parameters and allows uses to specify the nested \r\nstructure of tf.TypeSpec objects thus opening the way for any output objects describable by TypeSpec.\r\n\r\nHere is the exact new semantics of the function that I've copied from the new docstring:\r\n\r\n```\r\n   There are three ways to specify the output format:\r\n\r\n    * Using only `output_types` argument. In this case the output of the\r\n    function will be assumed to consist of `tf.Tensor` objects with the unknown\r\n    shapes and with the types defined by `output_types`.\r\n\r\n    * Using both `output_types` and `output_shapes` arguments. In this case the\r\n    output will be assumed to consist of `tf.Tensor` objects with the shapes\r\n    and types defined by these two arguments together.\r\n\r\n    * Using `output_spec` argument. In this case the output will be assumed to\r\n    consist of objects with the classes, shapes and types defined by\r\n    `tf.TypeSpec` objects from `output_spec` argument.\r\n\r\n    One of the `output_types` and `output_spec` arguments must be specified.\r\n    If used together, `output_spec` will override both `output_types` and\r\n    `output_shapes`.\r\n\r\n```\r\nNote:\r\nI've also had to add \"dtype\" property to RaggedTensorSpec to make internal implementation possible. This change looked natural, since RaggedTensorSpec really had the \"dtype\", like all the other TensorSpecs (SparseTensorSpec, TensorArraySpec, etc.). It was also that the Structure module internally relied on the assumption that incoming objects would have the \"dtype\" property (see get_flat_tensor_types function).\r\nI would've commited it as a standalone PR, but I'm new to Tensorflow contribution process and I wasn't sure what is the best way to do things, since this PR whould rely on the previous one.\r\n", "comments": ["Thank you, I will shepherd this PR through internal review.", "I see some tests failing in CI, trying to fix that, 1/3 is fixed", "@lithuak have all test failure been addressed?", "@jsimsa not yet, three tests have failed, I fixed one and looking into two others. One of them detects a memory leak o_0. I'll tag you when I'm done with it.", "@jsimsa Looks like I need some help here...\r\n\r\nSo, there is a test that fails, namely `testFromGenerator` from\r\n` //tensorflow/python/data/kernel_tests:memory_cleanup_test` target\r\n\r\nThe problem from the test can be reproduced with this simple piece of code:\r\n\r\n```\r\nimport gc\r\n\r\ndef test_leak():\r\n\r\n  def generator():\r\n    for i in range(0, 3):\r\n      yield i\r\n\r\n  dataset = tf.data.Dataset.from_generator(\r\n    generator,\r\n    output_spec=tensor_spec.TensorSpec((), dtype=tf.float32))\r\n\r\n  for x in dataset:\r\n    print(x)\r\n\r\ntest_leak()\r\n\r\ngc.collect()\r\n\r\ntensors_left = [o for o in gc.get_objects() if isinstance(o, tensor_like._TensorLike)]\r\n\r\nprint(tensors_left)\r\n```\r\n\r\nThis prints:\r\n\r\n`[<tf.Tensor: shape=(), dtype=float32, numpy=2.0>, <tf.Tensor: shape=(), dtype=int64, numpy=0>]\r\n`\r\nWhat happens here: the simple generator is being run via `from_generator` and after the run\r\nis complete, two objects of type `EagerTensor` are not being collected.\r\n\r\nAfter some time looking into it I'm almost certain that these two tensors are exactly the input and the output tensors of the last call of `generator_py_func` - the wrapped function returned by `generator_next_fn`.\r\n\r\nBefore my changes the `generator_py_func` was wrapped as `numpy_function` and after my changes it became wrapped as `eager_py_func` (because `numpy_function` wouldn't allow us to return the `variant` tensors to which RaggedTensor, etc. are being encoded as a numpy arrays).\r\n\r\nSo, now the inputs and outputs of this function are EagerTensors and by some reason they are not being collected. Moreover - if the dataset is being repeated, that is the generator is being rerun several times - after each run there will be two such EagerTensors left.\r\n\r\nThis is my first experience with TF codebase and I guess I'm a bit out of my depths here. Even EagerTensor looks to be implemented on the lower level.\r\n\r\nI would like to ask about some further directions where/how to dig.\r\n", "@kkimdev could you please take a look?\r\n\r\nIt looks like replacing `numpy_function` with `py_function` results in leaking tensors.", "I've also been able to reproduce this thing in a way separate from the specific tf.data code:\r\n\r\n```\r\ndef my_py_func(x):\r\n  return x * 2\r\n\r\ndef make_py_func(y):\r\n    return tf.py_function(my_py_func, inp=[y], Tout=tf.int32)\r\n\r\nprint(make_py_func(12).numpy())\r\n\r\ngc.collect()\r\n\r\ntensors = [\r\n  o for o in gc.get_objects() if isinstance(o, tensor_like._TensorLike)\r\n]\r\n\r\nprint(tensors)\r\n```\r\nThis would result in the same two tensors being uncollected.", "@jsimsa @kkimdev Ok, so here is where the py_functions get cached making their input/output tensors impossible to be collected:\r\n\r\nin tensorflow/python/ops/script_ops.py:\r\n\r\n```\r\n# Map from EagerPyFunc token to tuple (tape, eager args, eager outputs);\r\n# used for differentiation.\r\ntape_cache = {}\r\n```\r\n\r\nThis happens at `EagerFunc.__call__()`:\r\n\r\n```\r\n    tape_cache[compat.as_bytes(token)] = (tape, args, outputs)\r\n    return outputs\r\n```\r\nRunning\r\n\r\n```\r\nscript_ops.tape_cache = {}\r\n```\r\nfixes the leak.\r\n\r\nThe question now is - how to fix it correctly? Make a module-level method clear_tape_cache() at script_ops.py and call it explicitly when I need to? I don't know the code well and the intentions behind the architecture so I need advice here.\r\n", "@alextp is there a way to disable caching in `tape_cache` since we do not need it for tf.data?", "As a workaround, having an internal only function flag for disabling `tape_cache`  sounds OK to me.", "@lithuak does the suggestion from @kkimdev make sense? (Add internal API to script_ops.py that allows us to control whether the tensors are cached or not). I think it is a workable solution for this case.", "> @lithuak does the suggestion from @kkimdev make sense? (Add internal API to script_ops.py that allows us to control whether the tensors are cached or not). I think it is a workable solution for this case.\r\n\r\nI'm trying to make something in this way now (without touching the public API) though it looks quite ugly. I'll push it when it's done. Hope whatever we do here it will be a temporarily solution until the tape_cache is fixed.\r\n", "OK. I can also take a stab at this ahead of your PR if you would prefer.", "@jsimsa Please take a look. I realize this is very ad hoc-ish. If you preferred to do it your way ahead of this PR I wouldn't mind! I still have one more test to fix )", "Thanks, left one minor comment. It is about as good as it can be.", "@jsimsa ops, 7 tests have failed, looks like this workaround didn't work well so far..", "Haven't looked the tests closely yet but `tape_cache` is only used by `_EagerPyFuncGrad`, so if it's not computing gradient, then the only possibility I can think of is the lifetime of `(tape, args, outputs)` saved to `tape_cache`.", "@lithuak Can you please check build failures? Thanks!", "> @lithuak Can you please check build failures? Thanks!\r\n\r\nThere is one test left to fix, I'm working on it now.", "@jsimsa @gbaned The last failing test is fixed! This can be approved now )", "@jsimsa omg, now this were pylint issues, fixed that as well...", "Hang in there. I really appreciate your effort.", "> Hang in there. I really appreciate your effort.\r\n\r\nThank you :) Never thought my first contribution attempt would turn into such a wild ride ) Looks like all test are green now.", "@gbaned can you please close this PR internally? thanks", "@jsimsa internal meaning CL ?", "Internal tests surfaced a couple more failures:\r\n\r\n```\r\nFAIL: Found 1 non-whitelisted pylint errors:\r\ntensorflow/python/data/ops/dataset_ops.py:846: [C0301(line-too-long), ] Line too long (83/80)\r\n```\r\n\r\nThe `testFromGeneratorShapeError` and `testFromGeneratorTypeError` are failing with the following error message: `TypeError: `generator` yielded an element of TypeSpec(TensorShape([Dimension(4)]), tf.int64, None) where an element of TypeSpec(TensorShape([Dimension(3)]), tf.int64, None) was expected.` and `TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (TensorShape([Dimension(3)]), tf.int64, None), but the yielded element was ERROR.` respectively. \r\n\r\nLooking at your change it is not clear why though. Could you change the assertions to simply check for `InvalidArgumentError` without trying to pattern match the error string.\r\n\r\n", "@jsimsa according to github I'll have to still somehow address the change request from the other reviewer before this can be merged. As we decided not to make the proposed changes - what is the workflow then?..", "I will take care of making (internal) changes to this PR from now on to help it get over the finish line. So no further action needed on your part. No worries, you will still be credited for your commits.", "@jsimsa looks like last commit conflicted in some very minor way with the trunk", "The PR was merged and then automatically reverted because it broke some internal users. I plan to look into resolving the issue but have not had the time yet.", "@jsimsa So the code is merged now without mentioning me as the author of the changes? ", "Unfortunately, that's the outcome of me rolling back the roll back. Your change still counts as TensorFlow repository commits:\r\n- https://github.com/tensorflow/tensorflow/commits/master/tensorflow/python/data ", "@jsimsa This is extremely disappointing. What's the point of external contributing then if a contributor can't even have a proof of their involvement? Can this be replayed by rolling it back, me repeating the last commit and merging it back again in the trunk? ", "Please create a PR which reverts my last commit in one commit and then reapplies it in another commit (i.e. resulting in no changes whatsoever but changing the authorship) and I would be happy to review and merge it for you.", "@jsimsa thank you very much! The PR is: https://github.com/tensorflow/tensorflow/pull/37788", "Your commit is [still included in the history](https://github.com/tensorflow/tensorflow/commit/b76202fbf029b6d53c25c85d9916072aae430373) and your name will still be mentioned in the release notes on the next release which includes it.", "![Screenshot from 2020-03-23 16-33-13](https://user-images.githubusercontent.com/323199/77372928-20841a00-6d24-11ea-91ca-4f541d5ea7ec.png)\r\n", "@mihaimaruseac \r\n\r\nFrom the technical perspective there are still ways to fix this and get it right. E.g. one way to follow would be to roll back the `6c6f57ca2ae4c9c423885025dc7aa23a5f2b579d` commit and then `git commit --amend --author` it and roll forward again. We've already seen the roll back/roll forward approach while fixing a bug in this PR. The problem with commit authoring doesn't look any less serious than a bug fix. Another way that could potentially solve your problem with merging the PR #37788 is to merge the commits one by one without squashing them into one empty commit. I believe there are ways to solve this that are compliant with your internal processes.\r\n\r\nThank you for your time and help.\r\n", "@lithuak can you make some additional change in the PR #37788 that would result in non-empty delta? For example add a test or improve documentation of `from_generator` in some minor way.", "Commit is included in `git log`. I still fail to see what the problem is.\r\n\r\n```\r\n[tensorflow] \u03bb git status -sb\r\n## master...origin/master\r\n[tensorflow] \u03bb git log | grep '^commit b76202f' -A5\r\ncommit b76202fbf029b6d53c25c85d9916072aae430373\r\nAuthor: Ilya Persky <ilya.persky@gmail.com>\r\nDate:   Fri Mar 13 19:38:46 2020 +0200\r\n\r\n    Fixed pyling issues\r\n\r\n```", "All of your commits are showing up in `git log`\r\n\r\n```\r\n[tensorflow] \u03bb git log | grep '^Author: Ilya Persky' -B1 -A5\r\ncommit b76202fbf029b6d53c25c85d9916072aae430373\r\nAuthor: Ilya Persky <ilya.persky@gmail.com>\r\nDate:   Fri Mar 13 19:38:46 2020 +0200\r\n\r\n    Fixed pyling issues\r\n\r\ncommit 329dd2f9aca75168aa1292a896d0ec57d1a9082f\r\n--\r\ncommit 22f9d7f431fe9acb0fa4a2c357151c026926b246\r\nAuthor: Ilya Persky <ilya.persky@gmail.com>\r\nDate:   Fri Mar 13 18:52:35 2020 +0200\r\n\r\n    Fixed tests in kernel_tests/bucket_by_sequence_length_test\r\n\r\ncommit f409084ec60d1a362b8022a772b7e92dd4243e4d\r\n--\r\ncommit a007162bc2bbe092aa4c295efb4dc8e94e6a004e\r\nAuthor: Ilya Persky <ilya.persky@gmail.com>\r\nDate:   Thu Mar 12 23:02:20 2020 +0200\r\n\r\n    Fix the return statement for `eager_py_func`\r\n\r\ncommit 66ee5668782b6fd7f027967c461d96dd88040fd3\r\n--\r\nMerge: b4bd0ab0ba 6625cee185\r\nAuthor: Ilya Persky <ilya.persky@gmail.com>\r\nDate:   Thu Mar 12 22:17:41 2020 +0200\r\n\r\n    Merge branch 'master' into iss35342-from_generator\r\n\r\ncommit 00f041777ff498e1b4a6ee7825390deaaf04b5db\r\n--\r\ncommit b4bd0ab0bad66694c5535042aa6804b9b4895e12\r\nAuthor: Ilya Persky <ilya.persky@gmail.com>\r\nDate:   Thu Mar 12 21:19:39 2020 +0200\r\n\r\n    Adding _eager_py_func to control the using of `tape_cache`\r\n\r\ncommit 6625cee1858a04510193432d103458dfa42169b7\r\n--\r\ncommit feff4ad8f83533bd7fe500f938057f01843a94ef\r\nAuthor: Ilya Persky <ilya.persky@gmail.com>\r\nDate:   Thu Mar 12 18:18:49 2020 +0200\r\n\r\n    Workaround the  memory leak in script_ops\r\n\r\ncommit f8396d00c2572845774cce4b737858f264e015b6\r\n--\r\ncommit c054ade8ed6391e46401ac56f22b57bc94ef7618\r\nAuthor: Ilya Persky <ilya.persky@gmail.com>\r\nDate:   Mon Mar 9 21:11:16 2020 +0200\r\n\r\n    Fix iterator_test\r\n\r\ncommit f017686d248b3cd8721ab1ddce2f27be0eb32075\r\n--\r\ncommit 864e31180293af676ea6f00e4e7699cf93b1570d\r\nAuthor: Ilya Persky <ilya.persky@gmail.com>\r\nDate:   Mon Mar 9 20:02:21 2020 +0200\r\n\r\n    Update goldens\r\n\r\ncommit 8f5109a636b6617739559dd78db95ac3d8ca6b81\r\n--\r\ncommit 471f5aaa8dec6cf2a785fb48118925fbd1a3ec9b\r\nAuthor: Ilya Persky <ilya.persky@gmail.com>\r\nDate:   Mon Mar 9 19:50:39 2020 +0200\r\n\r\n    Verify arguments' correctness\r\n\r\ncommit 2e42540ddec394790ff6cd284b53ff210ca7062d\r\n--\r\ncommit 686a9aef26341146fcf66a6ecaf3a7014a457c7e\r\nAuthor: Ilya Persky <ilya.persky@gmail.com>\r\nDate:   Mon Mar 9 19:37:18 2020 +0200\r\n\r\n    Deprecating old arguments, rewriting docstring\r\n\r\ncommit 9a0a8031db44eb99f371454689b82f3b24194fba\r\n--\r\ncommit 330863b56588a7014292fc47e4e4bd192b34b330\r\nAuthor: Ilya Persky <ilya.persky@gmail.com>\r\nDate:   Mon Mar 9 16:36:56 2020 +0200\r\n\r\n    Fix 'NOTE's in docstrings\r\n\r\ncommit 0d7a1f8d037b13c6fd6271ee67f909d2d5042a19\r\n--\r\ncommit 6f6459880217b48dd0d0baa59fdea663bd311a94\r\nAuthor: Ilya Persky <ilya.persky@gmail.com>\r\nDate:   Fri Mar 6 22:35:10 2020 +0200\r\n\r\n    [tf.data] Add support for any Tensor describable by `tf.TypeSpec` to Dataset.from_generator\r\n\r\ncommit 5db7460fa8dddcc139684b404f37cc20725a1419\r\n--\r\ncommit 19b174ea81d1bfa770879863c0f74cec894ec068\r\nAuthor: Ilya Persky <ilya.persky@gmail.com>\r\nDate:   Fri Mar 6 22:31:48 2020 +0200\r\n\r\n    Add `dtype` property to RaggedTensorSpec\r\n\r\ncommit 6f795b7539a97fd15d98c8fb2f6cfddef0665fd3\r\n```", "There is another issue with this change, which seems non-trivial to fix and might be affecting backwards compatibility.\r\n\r\nAn internal user has reported the following error:\r\n\r\n```\r\nInvalid argument: TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was {'prefix': (TensorShape([]), tf.string, None), 'suffix': (TensorShape([]), tf.string, None), 'idx': (TensorShape([]), tf.int64, None), 'idxs': (TensorShape([Dimension(None)]), tf.int64, None), 'id': (TensorShape([]), tf.string, None), 'ids': (TensorShape([Dimension(None)]), tf.string, None)}, but the yielded element was {'idx': 1, 'idxs': (200, 201), 'id': 'b', 'ids': ('b1',), 'prefix': 'that', 'suffix': 'was another validation'}.\r\n```\r\n\r\nI am going to roll this change back again and ask the internal user to contribute a test to tf.data that is representative of their use case.\r\n\r\n@lithuak once the test is available, you can go ahead and create a new PR with the original change + whatever fix is needed for the newly discovered breakage. As a side effect, you will get credit for the change the way you like.", "@lithuak \r\n the change has been rolled back in https://github.com/tensorflow/tensorflow/commit/858bd4506a8b390fc5b2dcbeb3057f4a92e8a1e2 and the new test has been added in https://github.com/tensorflow/tensorflow/commit/0349c8ddf5b185ae102e62b5de2bddbe56773926\r\n\r\nYou are welcome to go ahead and create a new PR that reapplies the changes and makes sure that the newly added test is passing. Thanks.", "@jsimsa Sure, I'll try to take a look. As for credits, @mihaimaruseac made clear that logs are preserved so there is no need in any additional efforts here, thank you.", "@mihaimaruseac My comments got lost. Thank you for clarifying that for me! I was wrong, looks like I got lost in all the changes we went through during this PR. I see the commits now, it's fine, thank you.", "@jsimsa hey, so I believe that the test was supposed to catch the incorrect behaviour, but it looks like something was missed - it passes successfully for both versions: old and new.\r\n\r\nAlso, the behaviour of `from_generator` looks indistinguishable (to me) for both versions.\r\n\r\nChecking it manually with this piece of code (most of it is from the test):\r\n\r\n```\r\n  from inspect import signature\r\n\r\n  # Check for the version of the function to be sure\r\n  sig = signature(dataset_ops.DatasetV2.from_generator)\r\n  print(\"NEW VERSION\" if \"output_signature\" in sig.parameters else \"OLD VERSION\")\r\n\r\n  def generator():\r\n    yield {\"a\": \"foo\", \"b\": [1, 2]}\r\n    yield {\"a\": \"bar\", \"b\": [3, 4]}\r\n    yield {\"a\": \"baz\", \"b\": [5, 6]}\r\n\r\n  dataset = dataset_ops.Dataset.from_generator(\r\n    generator,\r\n    output_types={\"a\": dtypes.string, \"b\": dtypes.int32},\r\n    output_shapes={\"a\": [], \"b\": [None]})\r\n\r\n  for x in dataset:\r\n    print(x)\r\n```\r\n\r\n1) Old version: the source code is at 5d169b40e9069037608f15468b32557c791b5e38 - the changes are rolled back and the new test is already added.\r\n\r\nOutput:\r\n\r\n```\r\nOLD VERSION\r\n{'a': <tf.Tensor: shape=(), dtype=string, numpy=b'foo'>, 'b': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>}\r\n{'a': <tf.Tensor: shape=(), dtype=string, numpy=b'bar'>, 'b': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 4], dtype=int32)>}\r\n{'a': <tf.Tensor: shape=(), dtype=string, numpy=b'baz'>, 'b': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([5, 6], dtype=int32)>}\r\n```\r\n\r\n2) New version: the source code is originally at 0c4cb6e20734e7673eabfd30927f3ce6bf5219ef (right before your roll back) and the commit with the new test is cherry-picked:\r\n\r\n```\r\nNEW VERSION\r\n{'a': <tf.Tensor: shape=(), dtype=string, numpy=b'foo'>, 'b': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>}\r\n{'a': <tf.Tensor: shape=(), dtype=string, numpy=b'bar'>, 'b': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 4], dtype=int32)>}\r\n{'a': <tf.Tensor: shape=(), dtype=string, numpy=b'baz'>, 'b': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([5, 6], dtype=int32)>}\r\n```\r\n\r\nIt's either I'm missing something again or the test doesn't reproduce the problem.", "@jsimsa just reaching out to check if you've seen my comment above where I describe the problems with reproduction of the failure.", "@lithuak thank you for the reminder, I didn't have time to take a look as my availability is affected by COVID-19 but I asked @aaudiber to help shepherd this PR", "@lithuak Could you please resolve the conflicts? Thanks!", "@gbaned We have a serious problem described by jsimsa above and I'd rather fix it first (currently waiting for input on that) before making these changes\r\n", "@lithuak I'm also unable to reproduce the test failure. I will communicate with the test writer to get a test that reproduces the issue.", "@lithuak The test has been [updated](https://github.com/tensorflow/tensorflow/commit/c93a91e0e0edaaca0bfa20902c9c8a79d4beed4f), and I've confirmed that it now fails with this PR. It seems that the issue is in handling generators that produce tuples. Can you take a look?", "@aaudiber Hey, thanks! I definitely will. It will take some time though, the quarantine has confused all plans.", "@lithuak Can you please resolve conflicts? Thanks!", "@tensorflowbutler Yes, it's on my list. I'm planning to take on it this month. The COVID situation made things a bit unpredictable here.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "@tensorflowbutler slowly working on this, going to take a deeper look in two weeks", "Following this PR because I am interested in this functionality.", "@aaudiber @jsimsa @edloper An attempt to complete this feature.\r\n\r\nBriefly about the latest changes:\r\n\r\n3aff06b - adds all the changes that were made outside this topic branch back to it so that we can get the work back on track.\r\n\r\nd733662 - tries to merge these changes with the trunk (that has moved forward over the last months significantly). Although something probably didn't work here since I see a lot of conflicts reported.\r\n\r\ndaa0d58 - finally fixes the bug that got this PR stalled and also fixes the issue requested in review by @edloper \r\n\r\n", "@aaudiber @jsimsa @edloper It looks like after multiple roll-forwards/roll-backs of this PR, git incorrectly identifies the common ancestor when performing merge. May be the best way to go would be for me to create another PR/branch and try to move the changes there.", "Yes, this looks like a broken merge. Let's create a new PR.", "This PR will soon be closed are replaced by another PR to fight the broken merge problem"]}]