[{"number": 35170, "title": "tensorflow-lite-gpu.aar built from source is much slower than downloaded prebuilt library", "body": "### **System information**\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- Mobile device: LG G7\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version: r2.0\r\n- Python version: 3.5\r\n- Bazel version: 0.24.1\r\n- Android NDK version: r17c\r\n- GCC/Compiler version (if compiling from source): GCC 4.8\r\n\r\n\r\n\r\n### **Describe the problem**\r\nBuilt Tensorflow lite from source, but the inference is about 3 times slower than original.\r\n(What I mean by 'original' is the prebuilt tensorflow-lite downloaded from Maven repository.)\r\nFor example, the model which originally costs 20 ms on GPU takes 50 ms.\r\nI tried different versions of Tensorflow and Android NDK but resulted all same.\r\n\r\nBelow is the process I've done to build tensorflow lite libraries.\r\n\r\n\r\n**1. Download Tensorflow source code from github**\r\n```shell\r\n$ git clone https://github.com/tensorflow/tensorflow.git\r\n$ git checkout r2.0\r\n```\r\n\r\n**2. Download Android NDK and install standalone toolchains**\r\nDownload NDK r17c from [here](https://developer.android.com/ndk/downloads/older_releases.html).\r\nExtract files and move to Android Sdk directory.\r\n```shell\r\n$ cd Android/Sdk/android-ndk-r17c\r\n$ python build/tools/make_standalone_toolchain.py --arch arm64 --api 21\r\n$ export ANDROID_NDK=/path/to/ndk\r\n$ export ANDROID_NDK_HOME=$ANDROID_NDK\r\n```\r\n\r\n**3. Download and install Bazel**\r\nDownload installer script from [here](https://github.com/bazelbuild/bazel/releases/0.24.1).\r\n```shell\r\n$ cd /path/to/download\r\n$ chmod +x bazel-0.24.1-installer-linux-x86_64.sh\r\n$ ./bazel-0.24.1-installer-linux-x86_64.sh --user\r\n```\r\n\r\n**4. Build tensorflow-lite.aar and tensorflow-lite-gpu.aar**\r\n```shell\r\n$ cd tensorflow\r\n$ ./configure\r\n$ bazel build --cxxopt='--std=c++11' -c opt --fat_apk_cpu=arm64-v8a,armeabi-v7a tensorflow/lite/java:tensorflow-lite\r\n$ bazel build --cxxopt='--std=c++11' -c opt --fat_apk_cpu=arm64-v8a,armeabi-v7a tensorflow/lite/java:tensorflow-lite-gpu\r\n```\r\nOn `./configure`, set all 'n' for support question and leave others on default.\r\n\r\n| Configuration | Value |\r\n| --- | --- |\r\n| XLA JIT support | No |\r\n| OpenCL SYCL support | No |\r\n| ROCm support | No |\r\n| CUDA support | No |\r\n| Fresh released clang | No |\r\n| MPI support | No |\r\n| Bazel comilation option | Default |\r\n| Android ./WORKSPACE configuration | Yes |\r\n| Android NDK API level | 22 |\r\n| Android SDK path | Default |\r\n| Android SDK API level | Default (29) |\r\n| Android build tools version | Default (29.0.2) |\r\n\r\n**5. Import libraries to Android project**\r\nCopy the generated `.aar` files into Android project, and change `build.gradle` file:\r\n\r\n```gradle\r\ndependencies {\r\n    ...\r\n    implementation files('libs/tensorflow-lite.aar')\r\n    implementation files('libs/tensorflow-lite-gpu.aar')\r\n\r\n    // implementation 'org.tensorflow:tensorflow-lite:2.0.0'\r\n    // implementation 'org.tensorflow:tensorflow-lite-gpu:2.0.0'\r\n}\r\n```\r\n\r\n\r\n\r\nAny suggestion or help will be appreciated.\r\nThanks in advance.", "comments": ["**6. Execution result**\r\n\r\n| Tensorflow | Android NDK | Bazel | Inference on GPU | on CPU\r\n| --- | --- | --- | --- | --- |\r\n| r2.0 | r18b | 0.24.1 | 50 ms | 70 ms |\r\n| r2.0 | r17c | 0.24.1 | 50 ms | 70 ms |\r\n| r1.15 | r18b | 0.24.1 | 50 ms | 70 ms |\r\n| r1.15 | r17c | 0.24.1 | 50 ms | 70 ms |\r\n\r\nInference timecost on GPU should be 20 milliseconds as with prebuilt libraries.\r\nThe performance on CPU both with prebuilt and built-from-source are same.\r\n\r\nTried to build with other flags but all failed.\r\n\r\n**- Build with `--config=monolithic`**\r\n```shell\r\n$ bazel build --cxxopt='--std=c++11' -c opt --config=monolithic --fat_apk_cpu=arm64-v8a,armeabi-v7a tensorflow/lite/java:tensorflow-lite\r\n$ bazel build --cxxopt='--std=c++11' -c opt --config=monolithic --fat_apk_cpu=arm64-v8a,armeabi-v7a tensorflow/lite/java:tensorflow-lite-gpu\r\n```\r\n\r\n| Tensorflow | Android NDK | Bazel | Inference on GPU | on CPU\r\n| --- | --- | --- | --- | --- |\r\n| r2.0 | r18b | 0.24.1 | 50 ms | 70 ms |\r\n| r2.0 | r17c | 0.24.1 | 50 ms | 70 ms |\r\n| r1.15 | r18b | 0.24.1 | 50 ms | 70 ms |\r\n| r1.15 | r17c | 0.24.1 | 50 ms | 70 ms |\r\n\r\n**- Build using clang**\r\nSet 'yes' when executing `./configure`.\r\n\r\n| Tensorflow | Android NDK | Bazel | Inference on GPU | on CPU\r\n| --- | --- | --- | --- | --- |\r\n| r2.0 | r18b | 0.24.1 | 50 ms | 70 ms |\r\n| r1.15 | r18b | 0.24.1 | 50 ms | 70 ms |\r\n", "Hi Juhyun,  can you help take a look? thanks!", "Hm, that's complicated.\r\n\r\nFirst of all, I'm not sure what the Maven repository is.  If it is our nightly build, then you will be running things with OpenCL.\r\n\r\nNow, I'm not sure what GPU backend TF 2.0's TFLite has.  If it's only employing OpenGL (as OpenCL might not have made the cut), you can run into that issue.", "@impjdi \r\nThanks for your comment.\r\n\r\n> First of all, I'm not sure what the Maven repository is. If it is our nightly build, then you will be running things with OpenCL.\r\n> \r\n\r\nYes, I meant nightly build.\r\nOriginally, I've used the prebuilt library by adding dependencies on `build.gradle` file of my Android project:\r\n```gradle\r\ndependencies {\r\n    ...\r\n    implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly'     // or '2.0.0'\r\n    implementation 'org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly'\r\n}\r\n```\r\n\r\nSo after I built tensorflow-lite.aar and tensorflow-lite-gpu.aar from source,\r\nI changed the `build.gradle` like below:\r\n```gradle\r\ndependencies {\r\n    ...\r\n    implementation files('libs/tensorflow-lite.aar')\r\n    implementation files('libs/tensorflow-lite-gpu.aar')\r\n}\r\n```\r\n\r\nCan I ask what do you mean by '_you will be running things with OpenCL._' ?\r\nMaybe there's something missing in my build process, but I don't know what that is.\r\nOr should I change some options in my Android project?\r\n\r\nAs I mentioned in the first comment, the accuracy is fine.\r\nI mean, it's a pose estimation model, it detects body points well.\r\nOnly the performance is the problem.", "Could anyone reproduce the same issue?", "@gimgane \r\n\r\n> Can I ask what do you mean by 'you will be running things with OpenCL.' ?\r\n\r\nOpenCL is something that is shipped by the phone's manufacturer.  With the newest delegate, we check whether OpenCL is available.  If it is, we use that.  Otherwise, we fall back to OpenGL. \r\n On the nightly build which pulls in the master branch, it will use the OpenCL backend.\r\n\r\nIf you're building from TF 2.0, it's possible that the OpenCL backend was not included in the branch cut, and you might be only using the OpenGL backend, which is much slower than the OpenCL backend.", "@impjdi \r\nThanks for your kind explanation.\r\n\r\nTried [tensorflow-lite:2.0.0](https://mvnrepository.com/artifact/org.tensorflow/tensorflow-lite/2.0.0) in `build.gradle` file and [tensorflow-lite-gpu:2.0.0](https://mvnrepository.com/artifact/org.tensorflow/tensorflow-lite-gpu/2.0.0), the performance was same as when I used [tensorflow-lite:0.0.0-nightly](https://mvnrepository.com/artifact/org.tensorflow/tensorflow-lite/0.0.0-nightly) and [tensorflow-lite-gpu:0.0.0-nightly](https://mvnrepository.com/artifact/org.tensorflow/tensorflow-lite-gpu/0.0.0-nightly).\r\nUsing prebuilt libraries always shows the best performance.\r\nEven when I use [tensorflow-lite:1.15.0](https://mvnrepository.com/artifact/org.tensorflow/tensorflow-lite/1.15.0) and [tensorflow-lite-gpu:1.15.0](https://mvnrepository.com/artifact/org.tensorflow/tensorflow-lite-gpu/1.15.0).\r\n\r\n\r\n```gradle\r\ndependencies {\r\n\r\n    implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly'\r\n    implementation 'org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly'\r\n\r\n    // implementation 'org.tensorflow:tensorflow-lite:2.0.0'\r\n    // implementation 'org.tensorflow:tensorflow-lite-gpu:2.0.0'\r\n\r\n    // implementation 'org.tensorflow:tensorflow-lite:+' This equals to 2.0.0.\r\n    // implementation 'org.tensorflow:tensorflow-lite-gpu:+'\r\n\r\n    // implementation files('libs/tensorflow-lite.aar')\r\n    // implementation files('libs/tensorflow-lite-gpu.aar')\r\n}\r\n```\r\n\r\nOr is tensorflow branch r2.0 different from prebuilt tensorflow-lite 2.0.0?", "It works!\r\nIt was because of `.bazelrc` file!\r\nI will add a detailed comment and close this issue soon!", "### **SOLUTION**\r\n**1. Switch branch to master**\r\n**2. Edit .bazelrc file**\r\n\r\n\r\nAs  @impjdi mentioned,\r\nI changed tensorflow branch to master branch from r2.0.\r\nAnd tried to build with command below:\r\n```shell\r\n$ bazel build --cxxopt='-std=c++11' -c opt --fat_apk_cpu=armeabi-v7a,arm64-v8a tensorflow/lite/java:tensorflow-lite\r\n```\r\n\r\nBut it failed with logs:\r\n```\r\nINFO: Found applicable config definition build:linux in file /home/user/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels\r\n...\r\nERROR: /home/user/.cache/bazel/_bazel_user/9577482943a2ca4c440dd54204627b32/external/flatbuffers/BUILD.bazel:57:1: C++ compilation of rule '@flatbuffers//:flatc_library' failed (Exit 1)\r\ngcc: error: unrecognized command line option '-std=c++14'\r\nTarget //tensorflow/lite/java:tensorflow-lite failed to build\r\n```\r\nIt was strange since I surely gave `'--cxxopt=-std=c++11'` option as you can see in the build command above.\r\nI found it was defined as default in `.bazelrc` file.\r\n```\r\n# By default, build TF in C++ 14 mode.\r\nbuild:linux --cxxopt=-std=c++14\r\nbuild:linux --host_cxxopt=-std=c++14\r\n```\r\n\r\nChanged the file as below and built again, it worked.\r\nThe performance became as faster as the prebuilt libraries.\r\n```\r\n# By default, build TF in C++ 14 mode.\r\nbuild:linux --cxxopt=-std=c++11\r\nbuild:linux --host_cxxopt=-std=c++11\r\n```\r\n\r\nIt's weird because there was no configuration '`--cxxopt`' or '`--host_cxxopt`' defined in `.bazelrc` of previous tensorflow versions.\r\nOnly master branch has those options.\r\n\r\nHowever, regardless of the tensorflow version, every `BUILD` file in `/tensorflow/tensorflow/lite/java`,\r\nit says to build `tensorflow-lite.aar` use command below:\r\n```shell\r\n$ bazel build --cxxopt='-std=c++11' -c opt --fat_apk_cpu=x86,x86_64,arm64-v8a,armeabi-v7a tensorflow/lite/java:tensorflow-lite\r\n```\r\nStill don't get why `'--cxxopt=-std=c++11'` option is contained in the command while it's not defined in `.bazelrc` file.\r\nCould be my dumb mistake or lack of gcc knowledge.", "@gimgane,\r\n\r\nThanks for providing a detailed explanation about how you solved the problem. Can you confirm if we are good to close this issue as your problem is resolved? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35170\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35170\">No</a>\n"]}, {"number": 35169, "title": "TensorFlow Lite C++ image classification demo result error", "body": "I follow the guidelines of TensorFlow Lite C++ image classification demo. Firstly I clone TensorFlow and use to build label_image for Android armv8 by bazel 1.2.1.\r\n\r\n> bazel build -c opt --cxxopt=-std=c++11 --config=android_arm64 \\\r\n>   //tensorflow/lite/examples/label_image:label_image\r\n\r\n\r\nWhen I run the sample in the guide. I got the error result like below:\r\n\r\n> Loaded model ./mobilenet_v1_1.0_224.tflite\r\n> resolved reporter\r\n> INFO: Initialized TensorFlow Lite runtime.\r\n> invoked\r\n> average time: 52.036 ms\r\n> -nan: 1000 1000:toilet tissue, toilet paper, bathroom tissue\r\n> -nan: 999 999:ear, spike, capitulum\r\n> -nan: 998 998:bolete\r\n> -nan: 997 997:hen-of-the-woods, hen of the woods, Polyporus frondosus, Grifola frondosa\r\n> -nan: 996 996:earthstar\r\n\r\nAccording to the guide, the right result is below:\r\n\r\n> Loaded model /tmp/mobilenet_v1_1.0_224.tflite\r\n> resolved reporter\r\n> invoked\r\n> average time: 68.12 ms\r\n> 0.860174: 653 653:military uniform\r\n> 0.0481017: 907 907:Windsor tie\r\n> 0.00786704: 466 466:bulletproof vest\r\n> 0.00644932: 514 514:cornet, horn, trumpet, trump\r\n> 0.00608029: 543 543:drumstick\r\n\r\nBTW, The TensorFlow version is the latest commit of the master.\r\n`\r\ncommit 27e6c7b49f4558dfc4bd59a9c492bf4f390a77da\r\nAuthor: A. Unique TensorFlower <gardener@tensorflow.org>\r\nDate:   Mon Dec 16 01:03:06 2019 -0800\r\n\r\n    compat: Update forward compatibility horizon to 2019-12-16\r\n\r\n    PiperOrigin-RevId: 285720630\r\n    Change-Id: Ib744d5f7de70a6c6d73dd1a386712e404d0c2b99\r\n`\r\n", "comments": ["I got the right result by checkout the tag v2.0.0\r\n\r\n> Loaded model ./mobilenet_v1_1.0_224.tflite\r\n> resolved reporter\r\n> INFO: Initialized TensorFlow Lite runtime.\r\n> invoked\r\n> average time: 76.076 ms\r\n> 0.860174: 653 653:military uniform\r\n> 0.048102: 907 907:Windsor tie\r\n> 0.00786704: 466 466:bulletproof vest\r\n> 0.00644931: 514 514:cornet, horn, trumpet, trump\r\n> 0.0060803: 543 543:drumstick\r\n> ", "Closing this issue since its resolved. Thanks!"]}, {"number": 35168, "title": "Provided LSTM example doesn't work.", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): `pip install tensorflow`\r\n- Tensorflow version (commit SHA if source): 1.15.0\r\n\r\n**Describe the problem**\r\nThe example provided [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/experimental/examples/lstm/g3doc) doesn't work.\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\nIf I put together the example, it gives this : \r\n```\r\n# Note this needs to happen before import tensorflow.\r\nimport os\r\nos.environ['TF_ENABLE_CONTROL_FLOW_V2'] = '1'\r\nimport sys\r\nfrom absl import app\r\nimport argparse\r\nimport tensorflow as tf\r\n\r\n\r\nclass MnistLstmModel(object):\r\n  \"\"\"Build a simple LSTM based MNIST model.\r\n\r\n  Attributes:\r\n    time_steps: The maximum length of the time_steps, but since we're just using\r\n      the 'width' dimension as time_steps, it's actually a fixed number.\r\n    input_size: The LSTM layer input size.\r\n    num_lstm_layer: Number of LSTM layers for the stacked LSTM cell case.\r\n    num_lstm_units: Number of units in the LSTM cell.\r\n    units: The units for the last layer.\r\n    num_class: Number of classes to predict.\r\n  \"\"\"\r\n\r\n  def __init__(self, time_steps, input_size, num_lstm_layer, num_lstm_units,\r\n               units, num_class):\r\n    self.time_steps = time_steps\r\n    self.input_size = input_size\r\n    self.num_lstm_layer = num_lstm_layer\r\n    self.num_lstm_units = num_lstm_units\r\n    self.units = units\r\n    self.num_class = num_class\r\n\r\n  def build_model(self):\r\n    \"\"\"Build the model using the given configs.\r\n\r\n    Returns:\r\n      x: The input placehoder tensor.\r\n      logits: The logits of the output.\r\n      output_class: The prediction.\r\n    \"\"\"\r\n    x = tf.placeholder(\r\n        'float32', [None, self.time_steps, self.input_size], name='INPUT')\r\n    lstm_layers = []\r\n    for _ in range(self.num_lstm_layer):\r\n      lstm_layers.append(\r\n          # Important:\r\n          #\r\n          # Note here, we use `tf.lite.experimental.nn.TFLiteLSTMCell`\r\n          # (OpHinted LSTMCell).\r\n          tf.lite.experimental.nn.TFLiteLSTMCell(\r\n              self.num_lstm_units, forget_bias=0))\r\n    # Weights and biases for output softmax layer.\r\n    out_weights = tf.Variable(tf.random.normal([self.units, self.num_class]))\r\n    out_bias = tf.Variable(tf.zeros([self.num_class]))\r\n\r\n    # Transpose input x to make it time major.\r\n    lstm_inputs = tf.transpose(x, perm=[1, 0, 2])\r\n    lstm_cells = tf.keras.layers.StackedRNNCells(lstm_layers)\r\n    # Important:\r\n    #\r\n    # Note here, we use `tf.lite.experimental.nn.dynamic_rnn` and `time_major`\r\n    # is set to True.\r\n    outputs, _ = tf.lite.experimental.nn.dynamic_rnn(\r\n        lstm_cells, lstm_inputs, dtype='float32', time_major=True)\r\n\r\n    # Transpose the outputs back to [batch, time, output]\r\n    outputs = tf.transpose(outputs, perm=[1, 0, 2])\r\n    outputs = tf.unstack(outputs, axis=1)\r\n    logits = tf.matmul(outputs[-1], out_weights) + out_bias\r\n    output_class = tf.nn.softmax(logits, name='OUTPUT_CLASS')\r\n\r\n    return x, logits, output_class\r\n\r\ndef train(model,\r\n          model_dir,\r\n          batch_size=20,\r\n          learning_rate=0.001,\r\n          train_steps=200,\r\n          eval_steps=50,\r\n          save_every_n_steps=100):\r\n  \"\"\"Train & save the MNIST recognition model.\"\"\"\r\n  # Train & test dataset.\r\n  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\r\n  train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\r\n  train_iterator = train_dataset.shuffle(\r\n      buffer_size=1000).batch(batch_size).repeat().make_one_shot_iterator()\r\n  x, logits, output_class = model.build_model()\r\n  test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\r\n  test_iterator = test_dataset.batch(\r\n      batch_size).repeat().make_one_shot_iterator()\r\n  # input label placeholder\r\n  y = tf.placeholder(tf.int32, [\r\n      None,\r\n  ])\r\n  one_hot_labels = tf.one_hot(y, depth=model.num_class)\r\n  # Loss function\r\n  loss = tf.reduce_mean(\r\n      tf.nn.softmax_cross_entropy_with_logits(\r\n          logits=logits, labels=one_hot_labels))\r\n  correct = tf.nn.in_top_k(output_class, y, 1)\r\n  accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\r\n  # Optimization\r\n  opt = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\r\n\r\n  # Initialize variables\r\n  init = tf.global_variables_initializer()\r\n  saver = tf.train.Saver()\r\n  batch_x, batch_y = train_iterator.get_next()\r\n  batch_test_x, batch_test_y = test_iterator.get_next()\r\n  with tf.Session() as sess:\r\n    sess.run([init])\r\n    for i in range(train_steps):\r\n      batch_x_value, batch_y_value = sess.run([batch_x, batch_y])\r\n      _, loss_value = sess.run([opt, loss],\r\n                               feed_dict={\r\n                                   x: batch_x_value,\r\n                                   y: batch_y_value\r\n                               })\r\n      if i % 100 == 0:\r\n        tf.logging.info('Training step %d, loss is %f' % (i, loss_value))\r\n      if i > 0 and i % save_every_n_steps == 0:\r\n        accuracy_sum = 0.0\r\n        for _ in range(eval_steps):\r\n          test_x_value, test_y_value = sess.run([batch_test_x, batch_test_y])\r\n          accuracy_value = sess.run(\r\n              accuracy, feed_dict={\r\n                  x: test_x_value,\r\n                  y: test_y_value\r\n              })\r\n          accuracy_sum += accuracy_value\r\n        tf.logging.info('Training step %d, accuracy is %f' %\r\n                        (i, accuracy_sum / (eval_steps * 1.0)))\r\n        saver.save(sess, model_dir)\r\n\r\ndef export(model, model_dir, tflite_model_file,\r\n           use_post_training_quantize=True):\r\n  \"\"\"Export trained model to tflite model.\"\"\"\r\n  tf.reset_default_graph()\r\n  x, _, output_class = model.build_model()\r\n  saver = tf.train.Saver()\r\n  sess = tf.Session()\r\n  saver.restore(sess, model_dir)\r\n  # Convert to Tflite model.\r\n  converter = tf.lite.TFLiteConverter.from_session(sess, [x], [output_class])\r\n  converter.post_training_quantize = use_post_training_quantize\r\n  tflite = converter.convert()\r\n  with open(tflite_model_file, 'w') as f:\r\n    f.write(tflite)\r\n\r\ndef train_and_export(parsed_flags):\r\n  \"\"\"Train the MNIST LSTM model and export to TfLite.\"\"\"\r\n  model = MnistLstmModel(\r\n      time_steps=28,\r\n      input_size=28,\r\n      num_lstm_layer=2,\r\n      num_lstm_units=64,\r\n      units=64,\r\n      num_class=10)\r\n  tf.logging.info('Starts training...')\r\n  train(model, parsed_flags.model_dir)\r\n  tf.logging.info('Finished training, starts exporting to tflite to %s ...' %\r\n                  parsed_flags.tflite_model_file)\r\n  export(model, parsed_flags.model_dir, parsed_flags.tflite_model_file,\r\n         parsed_flags.use_post_training_quantize)\r\n  tf.logging.info(\r\n      'Finished exporting, model is %s' % parsed_flags.tflite_model_file)\r\n\r\n\r\ndef run_main(_):\r\n  \"\"\"Main in the TfLite LSTM tutorial.\"\"\"\r\n  parser = argparse.ArgumentParser(\r\n      description=('Train a MNIST recognition model then export to TfLite.'))\r\n  parser.add_argument(\r\n      '--model_dir',\r\n      type=str,\r\n      help='Directory where the models will store.',\r\n      required=True)\r\n  parser.add_argument(\r\n      '--tflite_model_file',\r\n      type=str,\r\n      help='Full filepath to the exported tflite model file.',\r\n      required=True)\r\n  parser.add_argument(\r\n      '--use_post_training_quantize',\r\n      action='store_true',\r\n      default=True,\r\n      help='Whether or not to use post_training_quantize.')\r\n  parsed_flags, _ = parser.parse_known_args()\r\n  train_and_export(parsed_flags)\r\n\r\n\r\ndef main():\r\n  app.run(main=run_main, argv=sys.argv[:1])\r\n\r\nif __name__ == '__main__':\r\n  main()\r\n```\r\n\r\nWhen ran simply like `python example.py --model_dir lstms/ --tflite_model_file lstms/model.tflite`, I get the following error message : \r\n```\r\nINFO:tensorflow:Starts training...\r\nI1216 23:55:41.555022 140529868711744 doc_example.py:159] Starts training...\r\nINFO:tensorflow:Training step 0, loss is 2.657418\r\nI1216 23:55:45.383375 140529868711744 doc_example.py:120] Training step 0, loss is 2.657418\r\nINFO:tensorflow:Training step 100, loss is 0.867711\r\nI1216 23:55:47.319205 140529868711744 doc_example.py:120] Training step 100, loss is 0.867711\r\nINFO:tensorflow:Training step 100, accuracy is 0.540000\r\nI1216 23:55:47.966933 140529868711744 doc_example.py:132] Training step 100, accuracy is 0.540000\r\nINFO:tensorflow:Finished training, starts exporting to tflite to lstm_doc/model.tflite ...\r\nI1216 23:55:50.603394 140529868711744 doc_example.py:162] Finished training, starts exporting to tflite to lstm_doc/model.tflite ...\r\nINFO:tensorflow:Restoring parameters from lstm_doc/\r\nI1216 23:55:50.832539 140529868711744 saver.py:1284] Restoring parameters from lstm_doc/\r\n2019-12-16 23:55:50.880481: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\r\n2019-12-16 23:55:50.880555: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2019-12-16 23:55:50.900838: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: graph_to_optimize\r\n2019-12-16 23:55:50.900867: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   function_optimizer: Graph size after: 412 nodes (0), 507 edges (0), time = 3.325ms.\r\n2019-12-16 23:55:50.900872: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   function_optimizer: Graph size after: 412 nodes (0), 507 edges (0), time = 5.794ms.\r\n2019-12-16 23:55:50.900875: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: hey_rnn_while_body_8743\r\n2019-12-16 23:55:50.900878: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2019-12-16 23:55:50.900882: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2019-12-16 23:55:50.900884: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: hey_rnn_while_cond_8742\r\n2019-12-16 23:55:50.900888: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2019-12-16 23:55:50.900891: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\nINFO:tensorflow:Froze 26 variables.\r\nI1216 23:55:50.942811 140529868711744 graph_util_impl.py:334] Froze 26 variables.\r\nINFO:tensorflow:Converted 26 variables to const ops.\r\nI1216 23:55:50.946878 140529868711744 graph_util_impl.py:394] Converted 26 variables to const ops.\r\n/home/mparient/.virtualenvs/decibel/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py:846: UserWarning: Property post_training_quantize is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\r\n  \" instead.\" % name)\r\n---------------------------------------------------------------------------\r\nConverterError                            Traceback (most recent call last)\r\n~/code_perso/decibel-light/prod/doc_example.py in <module>\r\n    195 \r\n    196 if __name__ == '__main__':\r\n--> 197   main()\r\n\r\n~/code_perso/decibel-light/prod/doc_example.py in main()\r\n    191 \r\n    192 def main():\r\n--> 193   app.run(main=run_main, argv=sys.argv[:1])\r\n    194 \r\n    195 \r\n\r\n~/.virtualenvs/decibel/lib/python3.6/site-packages/absl/app.py in run(main, argv, flags_parser)\r\n    297       callback()\r\n    298     try:\r\n--> 299       _run_main(main, args)\r\n    300     except UsageError as error:\r\n    301       usage(shorthelp=True, detailed_error=error, exitcode=error.exitcode)\r\n\r\n~/.virtualenvs/decibel/lib/python3.6/site-packages/absl/app.py in _run_main(main, argv)\r\n    248     sys.exit(retval)\r\n    249   else:\r\n--> 250     sys.exit(main(argv))\r\n    251 \r\n    252 \r\n\r\n~/code_perso/decibel-light/prod/doc_example.py in run_main(_)\r\n    187       help='Whether or not to use post_training_quantize.')\r\n    188   parsed_flags, _ = parser.parse_known_args()\r\n--> 189   train_and_export(parsed_flags)\r\n    190 \r\n    191 \r\n\r\n~/code_perso/decibel-light/prod/doc_example.py in train_and_export(parsed_flags)\r\n    162                   parsed_flags.tflite_model_file)\r\n    163   export(model, parsed_flags.model_dir, parsed_flags.tflite_model_file,\r\n--> 164          parsed_flags.use_post_training_quantize)\r\n    165   tf.logging.info(\r\n    166       'Finished exporting, model is %s' % parsed_flags.tflite_model_file)\r\n\r\n~/code_perso/decibel-light/prod/doc_example.py in export(model, model_dir, tflite_model_file, use_post_training_quantize)\r\n    144   converter = tf.lite.TFLiteConverter.from_session(sess, [x], [output_class])\r\n    145   converter.post_training_quantize = use_post_training_quantize\r\n--> 146   tflite = converter.convert()\r\n    147   with open(tflite_model_file, 'w') as f:\r\n    148     f.write(tflite)\r\n\r\n~/.virtualenvs/decibel/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py in convert(self)\r\n    981           input_tensors=self._input_tensors,\r\n    982           output_tensors=self._output_tensors,\r\n--> 983           **converter_kwargs)\r\n    984     else:\r\n    985       result = _toco_convert_graph_def(\r\n\r\n~/.virtualenvs/decibel/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)\r\n    447       input_data.SerializeToString(),\r\n    448       debug_info_str=debug_info_str,\r\n--> 449       enable_mlir_converter=enable_mlir_converter)\r\n    450   return data\r\n    451 \r\n\r\n~/.virtualenvs/decibel/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n    198       stdout = _try_convert_to_unicode(stdout)\r\n    199       stderr = _try_convert_to_unicode(stderr)\r\n--> 200       raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\n    201   finally:\r\n    202     # Must manually cleanup files.\r\n\r\nConverterError: See console for info.\r\n2019-12-16 23:55:52.418001: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReadVariableOp\r\n2019-12-16 23:55:52.418032: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReadVariableOp\r\n2019-12-16 23:55:52.418038: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReadVariableOp\r\n2019-12-16 23:55:52.418043: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReadVariableOp\r\n2019-12-16 23:55:52.418047: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReadVariableOp\r\n2019-12-16 23:55:52.418051: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReadVariableOp\r\n2019-12-16 23:55:52.418056: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReadVariableOp\r\n2019-12-16 23:55:52.418061: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReadVariableOp\r\n2019-12-16 23:55:52.418066: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReadVariableOp\r\n2019-12-16 23:55:52.418071: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReadVariableOp\r\n2019-12-16 23:55:52.418076: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReadVariableOp\r\n2019-12-16 23:55:52.418081: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReadVariableOp\r\n2019-12-16 23:55:52.418146: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReadVariableOp\r\n2019-12-16 23:55:52.418153: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReadVariableOp\r\n2019-12-16 23:55:52.418158: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReadVariableOp\r\n2019-12-16 23:55:52.418162: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReadVariableOp\r\n2019-12-16 23:55:52.418166: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReadVariableOp\r\n2019-12-16 23:55:52.418171: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReadVariableOp\r\n2019-12-16 23:55:52.418175: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReadVariableOp\r\n2019-12-16 23:55:52.418179: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReadVariableOp\r\n2019-12-16 23:55:52.418184: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReadVariableOp\r\n2019-12-16 23:55:52.418188: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReadVariableOp\r\n2019-12-16 23:55:52.418193: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReadVariableOp\r\n2019-12-16 23:55:52.418199: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ReadVariableOp\r\n2019-12-16 23:55:52.418227: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListReserve\r\n2019-12-16 23:55:52.418236: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-12-16 23:55:52.418479: F tensorflow/lite/toco/tooling_util.cc:1074] Check failed: name.substr(colon_pos + 1).find_first_not_of(\"0123456789\") == string::npos (0 vs. 18446744073709551615)Array 'stacked_rnn_cells/InputHint-UnidirectionalSequenceLstm-34aa74ee205711ea831bad6e4148a879-12-None-input_bias/ReadVariableOp:value' has non-digit characters after colon.\r\nFatal Python error: Aborted\r\n\r\nCurrent thread 0x00007f7ffc1c8740 (most recent call first):\r\n  File \"/home/mparient/.virtualenvs/decibel/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 52 in execute\r\n  File \"/home/mparient/.virtualenvs/decibel/lib/python3.6/site-packages/absl/app.py\", line 250 in _run_main\r\n  File \"/home/mparient/.virtualenvs/decibel/lib/python3.6/site-packages/absl/app.py\", line 299 in run\r\n  File \"/home/mparient/.virtualenvs/decibel/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py\", line 40 in run\r\n  File \"/home/mparient/.virtualenvs/decibel/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 89 in main\r\n  File \"/home/mparient/.virtualenvs/decibel/bin/toco_from_protos\", line 8 in <module>\r\nAborted\r\n```\r\n", "comments": ["the old ophint-based method does not work well with resource variables (but it should work fine with 1.15, I have just tried in colab)\r\n\r\nfor new keras lstm/rnn, please refer here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/experimental_new_converter/keras_lstm.ipynb\r\n\r\nthanks", "Thanks a lot for the example, I'm going to try that out. \r\n\r\n> the old ophint-based method does not work well with resource variables (but it should work fine with 1.15, I have just tried in colab)\r\n\r\nHmm, I did run this script with tf1.15.. Did you try the snippet I provided? Are you able to reproduce the error? \r\nAnd could I ask what you tried in colab? \r\n\r\n> for new keras lstm/rnn, please refer here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/experimental_new_converter/keras_lstm.ipynb\r\n\r\nThanks for that, where can I find some more info on the experimental_new_converter  please? I'm struggling with post-training quantization with pretrained LSTMs for a while now.. \r\n\r\n\r\n", "I used colab to import the python notebook and ran directly.\n\nCan you try the new approach and see if the post-training works for you?\n\nThanks a lot!\n\nOn Thu, Dec 19, 2019 at 3:12 PM Pariente Manuel <notifications@github.com>\nwrote:\n\n> Thanks a lot for the example, I'm going to try that out.\n>\n> the old ophint-based method does not work well with resource variables\n> (but it should work fine with 1.15, I have just tried in colab)\n> Hmm, I did run this script with tf1.15.. Did you try the snippet I\n> provided? Are you able to reproduce the error?\n> And could I ask what you tried in colab?\n>\n> for new keras lstm/rnn, please refer here:\n> https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/experimental_new_converter/keras_lstm.ipynb\n>\n> Thanks for that, where can I find some more info on the\n> experimental_new_converter please? I'm struggling with post-training\n> quantization with pretrained LSTMs for a while now..\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/35168?email_source=notifications&email_token=AIURNGKXI2OQXKXMIDIO6ETQZMNE7A5CNFSM4J3THI22YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEHIVCVA#issuecomment-567365972>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AIURNGKBUB4OWOMIYOZVIJ3QZMNE7ANCNFSM4J3THI2Q>\n> .\n>\n\n\n-- \nRenjie Liu\n\nrenjieliu@google.com\n+1 (650) 253-4359\n", "> I used colab to import the python notebook and ran directly.\r\nOk, that worked for me as well, I'll try to see why it failed with the script I made from the notebook..\r\n\r\n> Can you try the new approach and see if the post-training works for you? \r\n\r\nIt does not, sadly. \r\nIf I add : \r\n```python\r\nconverter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.inference_input_type = tf.uint8\r\nconverter.inference_output_type = tf.uint8\r\n```\r\nit works but the whole model is still in float32 (I saved the model and checked it with netron)\r\n\r\nIf I add, \r\n```python\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.inference_input_type = tf.uint8\r\nconverter.inference_output_type = tf.uint8\r\n```\r\nIt does not work. Here is the traceback :\r\n```\r\n2019-12-19 10:06:42.831816: E tensorflow/lite/tools/optimize/quantize_weights.cc:351] Quantize weights tool only supports tflite models with one subgraph.\r\nTraceback (most recent call last):\r\n  File \"/home/mparient/.virtualenvs/tf_dev/bin/toco_from_protos\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/home/mparient/.virtualenvs/tf_dev/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 93, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/mparient/.virtualenvs/tf_dev/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/home/mparient/.virtualenvs/tf_dev/lib/python3.6/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/home/mparient/.virtualenvs/tf_dev/lib/python3.6/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/home/mparient/.virtualenvs/tf_dev/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 56, in execute\r\n    enable_mlir_converter)\r\nException: Quantize weights transformation failed.\r\n```\r\n\r\nActually, sorry, I was not clear, I have been able to convert LSTM models to tflite in 1.15 using post-training quantization but some quantization nodes are left in the graph and the `edgetpu_compiler` seems not to like them.", "Hi Jian, can you help take a look about the lstm quantization? thanks", "Any update on this issue? ", "@mpariente we announced Keras TF 2.0 LSTM to fused TFLite LSTM conversion support. Please see below:\r\nhttps://groups.google.com/a/tensorflow.org/g/tflite/c/Ub4apUvblN8\r\n\r\nDo you want to try this? This is an e2e solution that works with the post training quantization for LSTM. Would love to see if this works for you.\r\n", "Going to throw in a plug here that I successfully dynamically quantized a Torch LSTM model and deployed it on a mobile device. Was also able to track internal state and do flow controlled updates to hidden states with a stateful Torch JIT'd object (impossible in TFLite). Full architecture 9 layer LSTM (quantized to 60 Mb) running at 2x real time on a mobile CPU that was streaming audio data for speech recognition.", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35168\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35168\">No</a>\n"]}, {"number": 35167, "title": "Batch norm internal variables keep changing during inference", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- Mobile device if the issue happens on mobile device: Dell Precision Tower 7910\r\n- TensorFlow installed from (source or binary): tensorflow-gpu 1.14.0\r\n- TensorFlow version (use command below): tensorflow-gpu 1.14.0\r\n- Installed from: conda\r\n- Python version: python 3.6\r\n- GCC/Compiler version (if compiling from source): 6.5.0\r\n- CUDA/cuDNN version: 10.1 but nvcc 7.5\r\n- GPU model and memory:Quadro M4000\r\n\r\n\r\n**Describe the current behavior**\r\nI've encountered weird behavior of batch normalization in TF1.14 (I will update ulteriorly for TF2). The accuracy decrease a lot after the graph freezing. I identified that the origin of this discrepency is due to the batch normalization. A smaller model code to reproduce this behavior is attached at the end of this post. \r\nAfter training, I freeze the graph with `tf.graph_util.convert_variables_to_constants()` then optimize with `optimize_for_inference()`. From the results below, you can see that the from training to testing it changed slightly but **just after** freezing, the **moving_avg, beta and gamma changed tremendously** but not the moving_std:\r\n\r\n> - [x] Training:   \r\n\r\n>0%|          | 0/100 [00:00<=X, X/its] mov_avg: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.],  mov_std: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.],  beta: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.],  gamma: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\r\n> \r\n> 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:01<00:00, 79.00it/s] mov_avg:\r\n> [**-0.18366139  0.24028867  0.91940075 -0.07153109**  0.08811506\r\n> -0.5552308\r\n>   0.12759416  0.11020644  0.47183645 -0.91372997 -0.35405988  0.5768641 ],  mov_std: [**0.36972958 0.36972958 0.36972958 0.36972958** 0.36972958 0.36972958\r\n>  0.36972958 0.36972958 0.36972958 0.36972958 0.36972958 0.36972958],  beta: [**0.         0.         0.         0.00995897** 0.         0.\r\n>  0.00995881 0.00995875 0.         0.00989968 0.         0.        ],  gamma: [**1.         1.         1.         1.0009596**  1.         1.\r\n>  **0.99905616 0.99986655 1.         1.0005279**  1.         1.        ]\r\n> \r\n> - [x] Testing: \r\n\r\n>0%|          | 0/5 [00:00<=X, Xit/s] mov_avg: [**-0.18473879  0.24169827  0.92479414 -0.07199407**  0.08863196\r\n> -0.5584879\r\n>   0.12828277  0.11082216  0.47460434 -0.9191201  -0.35613686  0.5802481 ],  mov_std: [**0.36603227 0.36603227 0.36603227 0.36603227** 0.36603227 0.36603227\r\n>  0.36603227 0.36603227 0.36603227 0.36603227 0.36603227 0.36603227],  beta: [**0.         0.         0.         0.01005934** 0.         0.\r\n>  0.01005919 0.01005913 0.         0.00999967 0.         0.        ],  gamma: [**1.         1.         1.         1.0009888**  1.         1.\r\n>  0.99904144 0.999887   1.         1.0005565  1.         1.        ]\r\n> \r\n> 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:00<00:00, 182.68it/s] mov_avg:\r\n> [**-0.18473879  0.24169827  0.92479414 -0.07199407  0.08863196**\r\n> -0.5584879\r\n>   0.12828277  0.11082216  0.47460434 -0.9191201  -0.35613686  0.5802481 ],  mov_std: [**0.36603227 0.36603227 0.36603227 0.36603227 0.36603227** 0.36603227\r\n>  0.36603227 0.36603227 0.36603227 0.36603227 0.36603227 0.36603227],  beta: [**0.         0.         0.         0.01005934 0.**         0.\r\n>  0.01005919 0.01005913 0.         0.00999967 0.         0.        ],  gamma: [**1.         1.         1.         1.0009888  1.**         1.\r\n>  0.99904144 0.999887   1.         1.0005565  1.         1.        ]\r\n\r\n> - [x] Optimized (is_training = False) \r\n\r\n>0%|          | 0/100 [00:00<=X, Xit/s] mov_avg: [ **0.31595632 -0.19200048 -0.80097497  0.22726376**\r\n> **-0.2556441**  -0.1720414\r\n>   0.05251308  0.5521817  -0.93566465 -0.14799471 -0.11172786 -0.03040024],  mov_std: [**0.36603227 0.36603227 0.36603227 0.36603227 0.36603227** 0.36603227\r\n>  0.36603227 0.36603227 0.36603227 0.36603227 0.36603227 0.36603227],  beta: [**0.         0.         0.         0.         0.00999963** 0.\r\n>  0.01005759 0.         0.         0.         0.         0.        ],  gamma: [**1.         1.         1.         1.         1.0017155**  1.\r\n>  0.99796325 1.         1.         1.         1.         1.        ]\r\n> \r\n> 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:00<00:00, 404.37it/s] mov_avg: [\r\n> 0.31595632 -0.19200048 -0.80097497  0.22726376 -0.2556441  -0.1720414\r\n>   0.05251308  0.5521817  -0.93566465 -0.14799471 -0.11172786 -0.03040024],  mov_std: [0.36603227 0.36603227 0.36603227 0.36603227 0.36603227 0.36603227\r\n>  0.36603227 0.36603227 0.36603227 0.36603227 0.36603227 0.36603227],  beta: [0.         0.         0.         0.         0.00999963 0.\r\n>  0.01005759 0.         0.         0.         0.         0.        ],  gamma: [1.         1.         1.         1.         1.0017155  1.\r\n>  0.99796325 1.         1.         1.         1.         1.        ]\r\n\r\n\r\n**Describe the expected behavior**\r\nI was expecting these local variables **not change when we switch the training parameter between True/False or while we freeze it**.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tqdm import tqdm\r\nimport numpy as np\r\nfrom util import print_nodes_name_shape, check_N_mkdir\r\nfrom tensorflow.python.tools.optimize_for_inference_lib import optimize_for_inference\r\nfrom tensorflow.python.framework import dtypes\r\nimport os\r\n\r\n\r\ninput_ph = tf.placeholder(tf.float32, shape=(None, 2, 2, 1), name='input_ph')\r\noutput_ph = tf.placeholder(tf.float32, shape=(None, 2, 2, 3), name='output_ph')\r\nis_training = tf.placeholder(tf.bool, shape=[], name='is_training')\r\n\r\n# build a one layer Full layer with BN and save 2 ckpts\r\nwith tf.name_scope('model'):\r\n    out = tf.reshape(input_ph, shape=(-1, 2 * 2 * 1), name='flatten')\r\n    with tf.variable_scope('dnn1', reuse=False):\r\n        w1 = tf.get_variable('w1', dtype=tf.float32, shape=[4 * 1, 4 * 3], initializer=tf.initializers.glorot_normal())\r\n        # b1 = tf.get_variable('b1', dtype=tf.float32, shape=[4 * 3], initializer=tf.initializers.glorot_normal())\r\n    # out = tf.matmul(out, w1) + b1\r\n    out = tf.matmul(out, w1)\r\n    out = tf.layers.batch_normalization(out, training=is_training, name='BN')\r\n    logits = tf.nn.relu(out)\r\n    logits = tf.reshape(logits, shape=(-1, 2, 2, 3))\r\n\r\nwith tf.name_scope('loss'):\r\n    MSE = tf.losses.mean_squared_error(labels=output_ph, predictions=logits)\r\n\r\nwith tf.name_scope('operations'):\r\n    opt = tf.train.AdamOptimizer(learning_rate=0.0001, name='Adam')\r\n    grads = opt.compute_gradients(MSE)\r\n    train_op = opt.apply_gradients(grads, name='apply_grad')\r\n\r\n# train\r\nwith tf.Session() as sess:\r\n    # prepare\r\n    graph = tf.get_default_graph()\r\n    print_nodes_name_shape(graph)\r\n    saver = tf.train.Saver()\r\n\r\n    # init variables\r\n    sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\r\n    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n    print(update_ops)  # note: [<tf.Operation 'model/BN/cond_2/Merge' type=Merge>, <tf.Operation 'model/BN/cond_3/Merge' type=Merge>]\r\n    saver.save(sess, './dummy/ckpt/step0')\r\n    # train\r\n    for i in tqdm(range(100)):\r\n        inputs = np.ones((8, 2, 2, 1)) + np.random.randn(8, 2, 2, 1)\r\n        outputs = np.arange(8 * 2 * 2 * 3).reshape((8, 2, 2, 3))\r\n        with tf.variable_scope('', reuse=True):\r\n            mov_avg, mov_std, beta, gamma = sess.run([tf.get_variable('BN/moving_mean'),\r\n                                         tf.get_variable('BN/moving_variance'),\r\n                                                      tf.get_variable('BN/beta'),\r\n                                                      tf.get_variable('BN/gamma')])\r\n        if i == 0 or i == 99:\r\n            print('\\nmov_avg: {}, \\nmov_std: {}, \\nbeta: {}, \\ngamma: {}'.format(mov_avg, mov_std, beta, gamma))\r\n        _, _ = sess.run([train_op, tf.get_collection(tf.GraphKeys.UPDATE_OPS)], feed_dict={\r\n            input_ph: inputs,\r\n            output_ph: outputs,\r\n            is_training: True,\r\n        })\r\n\r\n    for i in tqdm(range(100)):\r\n        inputs = np.ones((8, 2, 2, 1)) + np.random.randn(8, 2, 2, 1)\r\n        outputs = np.arange(8 * 2 * 2 * 3).reshape((8, 2, 2, 3))\r\n        with tf.variable_scope('', reuse=True):\r\n            mov_avg, mov_std, beta, gamma = sess.run([tf.get_variable('BN/moving_mean'),\r\n                                         tf.get_variable('BN/moving_variance'),\r\n                                                      tf.get_variable('BN/beta'),\r\n                                                      tf.get_variable('BN/gamma')])\r\n        if i == 0 or i == 99:\r\n            print('\\nmov_avg: {}, \\nmov_std: {}, \\nbeta: {}, \\ngamma: {}'.format(mov_avg, mov_std, beta, gamma))\r\n        _ = sess.run([graph.get_tensor_by_name('model/Reshape:0')], feed_dict={\r\n            input_ph: inputs,\r\n            is_training: False,\r\n        })\r\n\r\n        # print moving avg/std\r\n    saver.save(sess, './dummy/ckpt/step100')\r\n\r\n\r\ndef freeze_ckpt_for_inference(ckpt_path=None, conserve_nodes=None):\r\n    # clean graph first\r\n    tf.reset_default_graph()\r\n    # freeze ckpt then convert to pb\r\n    new_input = tf.placeholder(tf.float32, shape=[None, 10, 10, 1], name='new_input')\r\n    new_is_training = tf.placeholder(tf.bool, name='new_is_training')\r\n\r\n    restorer = tf.train.import_meta_graph(\r\n        ckpt_path + '.meta',\r\n        input_map={\r\n            'input_ph': new_input,\r\n            'is_training': new_is_training,\r\n        },\r\n        clear_devices=True,\r\n    )\r\n\r\n    input_graph_def = tf.get_default_graph().as_graph_def()\r\n    check_N_mkdir('./dummy/pb/')\r\n    check_N_mkdir('./dummy/tb/')\r\n\r\n    # freeze to pb\r\n    with tf.Session() as sess:\r\n        # restore variables\r\n        restorer.restore(sess, './dummy/ckpt/step100')\r\n        # convert variable to constant\r\n        output_graph_def = tf.graph_util.convert_variables_to_constants(\r\n            sess=sess,\r\n            input_graph_def=input_graph_def,\r\n            output_node_names=conserve_nodes,\r\n        )\r\n\r\n        # save to pb\r\n        with tf.gfile.GFile('./dummy/pb/freeze.pb', 'wb') as f:  # 'wb' stands for write binary\r\n            f.write(output_graph_def.SerializeToString())\r\n\r\n\r\ndef optimize_graph_for_inference(pb_dir=None, conserve_nodes=None):\r\n    tf.reset_default_graph()\r\n    check_N_mkdir(pb_dir)\r\n\r\n    # import pb file\r\n    with tf.gfile.FastGFile(pb_dir + 'freeze.pb', \"rb\") as f:\r\n        graph_def = tf.GraphDef()\r\n        graph_def.ParseFromString(f.read())\r\n\r\n    # optimize graph\r\n    optimize_graph_def = optimize_for_inference(input_graph_def=graph_def,\r\n                                                input_node_names=['new_input', 'new_is_training'],\r\n                                                output_node_names=conserve_nodes,\r\n                                                placeholder_type_enum=[dtypes.float32.as_datatype_enum,\r\n                                                                       dtypes.bool.as_datatype_enum,\r\n                                                                       dtypes.float32.as_datatype_enum,\r\n                                                                       ]\r\n                           )\r\n    with tf.gfile.GFile(pb_dir + 'optimize.pb', 'wb') as f:\r\n        f.write(optimize_graph_def.SerializeToString())\r\n\r\nconserve_nodes = ['model/Reshape']\r\nfreeze_ckpt_for_inference(ckpt_path='./dummy/ckpt/step100', conserve_nodes=conserve_nodes)\r\noptimize_graph_for_inference(pb_dir='./dummy/pb/', conserve_nodes=conserve_nodes)\r\n\r\n# cleaning\r\ntf.reset_default_graph()\r\n\r\n# load pb\r\nwith tf.gfile.FastGFile('./dummy/pb/optimize.pb', \"rb\") as f:\r\n    graph_def = tf.GraphDef()\r\n    graph_def.ParseFromString(f.read())\r\n\r\nprint('\\n Now inference*******************************')\r\n# inference\r\nwith tf.Session() as sess:\r\n    tf.graph_util.import_graph_def(\r\n        graph_def,\r\n    )\r\n    # prepare\r\n    G = tf.get_default_graph()\r\n    print_nodes_name_shape(G)\r\n    new_input = G.get_tensor_by_name('import/new_input:0')\r\n    new_is_training = G.get_tensor_by_name('import/new_is_training:0')\r\n    new_output = G.get_tensor_by_name('import/' + conserve_nodes[-1] + ':0')\r\n\r\n    # train\r\n    for i in tqdm(range(100)):\r\n        inputs = np.ones((8, 2, 2, 1)) + np.random.randn(8, 2, 2, 1)\r\n        outputs = np.arange(8 * 2 * 2 * 3).reshape((8, 2, 2, 3))\r\n        # print moving avg/std\r\n        with tf.variable_scope('', reuse=True):\r\n            mov_avg, mov_std, beta, gamma = sess.run([G.get_tensor_by_name('import/BN/moving_mean:0'),\r\n                                                      G.get_tensor_by_name('import/BN/moving_variance:0'),\r\n                                                      G.get_tensor_by_name('import/BN/beta:0'),\r\n                                                      G.get_tensor_by_name('import/BN/gamma:0')])\r\n        if i == 0 or i == 99:\r\n            print('\\nmov_avg: {}, \\nmov_std: {}, \\nbeta: {}, \\ngamma: {}'.format(mov_avg, mov_std, beta, gamma))\r\n        new_out = sess.run([new_output], feed_dict={\r\n            new_input: inputs,\r\n            new_output: outputs,\r\n            new_is_training: False,\r\n        })\r\n        # print('out: {}'.format(new_out))\r\n```\r\n\r\n\r\n\r\nIs this **an expected behavior?**. I don't think so, because the NN is very sensitive if we change even a very little bit of the beta and gamma. Is this be remedied in the 2.0 version? \r\n", "comments": ["The code is misleading the changes, since there's still one forward propagation after printing the local variables (mv_avg, mv_std, beta and gamma). But the optimize_for_inference() **DOES** prune the training param, since after that no-matter what you put as training (T/F), these 4 variables will not change."]}, {"number": 35166, "title": "Updating Readme.md with a link to new user survey", "body": "", "comments": ["@jvishnuvardhan - the linked survey appears to have ended.", "@dongreenberg Survey was ended but you could create a PR for the feature you are interested. Thanks!"]}, {"number": 35165, "title": "25X slower in-graph vs out-of-graph training loop on GPU in TF2.0 ", "body": "\r\n**Describe the current behavior**\r\n\r\nWhen training using a fully in-graph training loop for a custom model ([as described in the documentation](https://www.tensorflow.org/guide/function#define_the_training_loop)), training is 25x slower than when training the same model with an out-of-graph training loop. \r\n\r\n**Describe the expected behavior**\r\n\r\nI would think in-graph training should be faster because we are not shuttling data back and forth between the gpu and python runtimes.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport tensorflow.keras as keras\r\nimport time\r\nimport os\r\n\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\r\n\r\n\r\nclass MyModel(keras.Model):\r\n\r\n    def __init__(self):\r\n        super(MyModel, self).__init__()\r\n        self.conv1 = keras.layers.Conv2D(64, [3, 3])\r\n        self.conv2 = keras.layers.Conv2D(64, [3, 3])\r\n        self.flatten = keras.layers.Flatten()\r\n\r\n    def call(self, inputs, training):\r\n        images = inputs[0]\r\n        targets = inputs[1]\r\n        x = self.conv1(images)\r\n        x = self.conv2(x)\r\n        x = self.flatten(x)\r\n        loss = tf.reduce_mean(x, axis=1) - tf.reduce_mean(targets, axis=1)\r\n        return loss\r\n\r\ndef create_dataset():\r\n    X = np.zeros([10, 224, 224, 3], dtype=np.float32)\r\n    Y = np.zeros([10, 1000], dtype=np.float32)\r\n    x_ds = tf.data.Dataset.from_tensor_slices(X)\r\n    y_ds = tf.data.Dataset.from_tensor_slices(Y)\r\n    ds = tf.data.Dataset.zip((x_ds, y_ds))\r\n    ds = ds.batch(32)\r\n    return ds\r\n\r\n@tf.function\r\ndef train_one_step(model, optim, inputs):\r\n    with tf.GradientTape() as tape:\r\n        loss = model(inputs, training=True)\r\n        loss = tf.reduce_mean(loss)\r\n    grads = tape.gradient(loss, model.trainable_variables)\r\n    grads_and_vars = zip(grads, model.trainable_variables)\r\n    optim.apply_gradients(grads_and_vars)\r\n    return loss\r\n\r\n\r\n@tf.function\r\ndef in_graph_training_loop(model, optim, dataset):\r\n    step = 0\r\n    for inputs in dataset:\r\n        loss = train_one_step(model, optim, inputs)\r\n        step += 1\r\n\r\n\r\ndef out_graph_training_loop(model, optim, dataset):\r\n    step = 0\r\n    for inputs in dataset:\r\n        loss = train_one_step(model, optim, inputs)\r\n        step += 1\r\n\r\n\r\ndef main():\r\n    model = MyModel()\r\n    optim = keras.optimizers.Adam(1e-4)\r\n    dataset = create_dataset()\r\n\r\n    for i in range(5):\r\n        t0 = time.time()\r\n        in_graph_training_loop(model, optim, dataset)\r\n        t1 = time.time()\r\n        print('Time for in-graph training loop: %.3f secs' % (t1 - t0))\r\n\r\n    print('-' * 20)\r\n\r\n    for i in range(5):\r\n        t0 = time.time()\r\n        out_graph_training_loop(model, optim, dataset)\r\n        t1 = time.time()\r\n        print('Time for out-of-graph training loop: %.3f secs' % (t1 - t0))\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n\r\n```\r\nOutput:\r\n\r\n```\r\npython train/test.py \r\nTime for in-graph training loop: 2.064 secs\r\nTime for in-graph training loop: 1.031 secs\r\nTime for in-graph training loop: 1.013 secs\r\nTime for in-graph training loop: 1.018 secs\r\nTime for in-graph training loop: 1.012 secs\r\n--------------------\r\nTime for out-of-graph training loop: 2.079 secs\r\nTime for out-of-graph training loop: 0.014 secs\r\nTime for out-of-graph training loop: 0.041 secs\r\nTime for out-of-graph training loop: 0.041 secs\r\nTime for out-of-graph training loop: 0.041 secs\r\n```\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes but this is minimally divergent from stock examples in documentation\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0\r\n- Python version:  3.6.8\r\n- CUDA/cuDNN version: 10.0\r\n", "comments": ["Issue is replicating on colab with Tf 2.0.\r\nPlease find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/272664a42567299c1c6710ac865863c9/untitled314.ipynb). Thanks!", "Thanks for testing.  ", "@huyng @gadagashwini This issue is the same with my proposed recently, see https://github.com/tensorflow/tensorflow/issues/35206\r\n\r\nI have a temporary solution, add tf.function for all main invoked functions for in_graph_training_loop. In this example, they are MyModel.call and train_one_step.\r\n\r\nI suggest you use a large batch size for testing, and for out_graph_training_loop, do not add tf.function to train_one_step.\r\n\r\nIn  my testing, I enlarge the parameters, then in_graph_training_loop (add all tf.function) takes about **0.23s**, while **0.39s** for in_graph_training_loop (without any tf.function)\r\n", "There is a known issue with datasets in for loops in the 2.0 release that was causing the loop to be misplaced to the CPU, even when a GPU was available - #32138. That is fixed in tf-nightly. I'll have a closer look at the measurements.", "@SummerRainET2008 @mdanatg thanks for the response. I tried modifying and testing my code based on your comments (See below).\r\n\r\n---\r\n\r\n@SummerRainET2008 , I tried decorating the MyModel.call w/ tf.function and it doesn't seem to resolve the issue. Here are the timings\r\n\r\n```\r\nTime for in-graph training loop: 1.478 secs\r\nTime for in-graph training loop: 1.011 secs\r\nTime for in-graph training loop: 1.019 secs\r\nTime for in-graph training loop: 1.046 secs\r\nTime for in-graph training loop: 0.991 secs\r\n--------------------\r\nTime for out-of-graph training loop: 2.412 secs\r\nTime for out-of-graph training loop: 0.014 secs\r\nTime for out-of-graph training loop: 0.016 secs\r\nTime for out-of-graph training loop: 0.016 secs\r\nTime for out-of-graph training loop: 0.016 secs\r\n```\r\n\r\n---\r\n\r\n@mdanatg I tried adding `iter(dataset)` to my in-graph loop and it helped a lot! However, the in-graph loop is still 2x as slow as the out-of-graph loop.\r\n\r\nmodification:\r\n\r\n```python\r\n@tf.function\r\ndef in_graph_training_loop(model, optim, dataset):\r\n    step = 0\r\n    for inputs in iter(dataset):\r\n        loss = train_one_step(model, optim, inputs)\r\n        step += 1\r\n```\r\n\r\ntiming:\r\n```\r\nTime for in-graph training loop: 2.355 secs\r\nTime for in-graph training loop: 0.031 secs\r\nTime for in-graph training loop: 0.031 secs\r\nTime for in-graph training loop: 0.028 secs\r\nTime for in-graph training loop: 0.031 secs\r\n--------------------\r\nTime for out-of-graph training loop: 0.671 secs\r\nTime for out-of-graph training loop: 0.014 secs\r\nTime for out-of-graph training loop: 0.016 secs\r\nTime for out-of-graph training loop: 0.016 secs\r\nTime for out-of-graph training loop: 0.016 secs\r\n```\r\n\r\n---\r\n\r\nI then tried adding  a `tf.device` context manager but the out-of-graph loop still seems to be fastest.\r\n\r\nmodification:\r\n```python\r\n@tf.function\r\ndef in_graph_training_loop(model, optim, dataset):\r\n    step = 0\r\n    for inputs in iter(dataset):\r\n        with tf.device('/device:GPU:0'):\r\n            loss = train_one_step(model, optim, inputs)\r\n            step += 1\r\n```\r\n\r\ntiming:\r\n```\r\nTime for in-graph training loop: 2.356 secs\r\nTime for in-graph training loop: 0.031 secs\r\nTime for in-graph training loop: 0.032 secs\r\nTime for in-graph training loop: 0.032 secs\r\nTime for in-graph training loop: 0.032 secs\r\n--------------------\r\nTime for out-of-graph training loop: 0.674 secs\r\nTime for out-of-graph training loop: 0.014 secs\r\nTime for out-of-graph training loop: 0.016 secs\r\nTime for out-of-graph training loop: 0.016 secs\r\nTime for out-of-graph training loop: 0.016 secs\r\n```", "Edit: looks like our posts crossed :) This mainly repeats the findings reported by @huyng, and hopefully explains things a bit.\r\n\r\nI increased the dataset size so that the training loop runs 10 iterations, rather than just a single one.\r\n\r\nSo when applying the workaround suggested in #32138 (writing `for inputs in iter(dataset):`), the speed becomes comparable:\r\n\r\n```\r\nTime for in-graph training loop: 0.928 secs\r\nTime for in-graph training loop: 0.614 secs\r\nTime for in-graph training loop: 0.624 secs\r\nTime for in-graph training loop: 0.617 secs\r\nTime for in-graph training loop: 0.615 secs\r\n--------------------\r\nTime for out-of-graph training loop: 1.050 secs\r\nTime for out-of-graph training loop: 0.458 secs\r\nTime for out-of-graph training loop: 0.459 secs\r\nTime for out-of-graph training loop: 0.459 secs\r\nTime for out-of-graph training loop: 0.457 secs\r\n--------------------\r\nTime for in-graph training loop using tf.while: 0.750 secs\r\nTime for in-graph training loop using tf.while: 0.531 secs\r\nTime for in-graph training loop using tf.while: 0.532 secs\r\nTime for in-graph training loop using tf.while: 0.533 secs\r\nTime for in-graph training loop using tf.while: 0.530 secs\r\n```\r\n\r\nIn this case, we'd expect the performance to be comparable because the only difference between the in-graph and the out-of-graph training loops is whether the loop runs in Python or in the TF executor - otherwise, in both cases we have data flowing from one subgraph (the one created by the dataset) to another (the one created by train_one_step).\r\n\r\nAt head, they run at comparable speeds:\r\n\r\n```\r\nTime for in-graph training loop: 0.928 secs\r\nTime for in-graph training loop: 0.614 secs\r\nTime for in-graph training loop: 0.624 secs\r\nTime for in-graph training loop: 0.617 secs\r\nTime for in-graph training loop: 0.615 secs\r\n--------------------\r\nTime for out-of-graph training loop: 1.050 secs\r\nTime for out-of-graph training loop: 0.458 secs\r\nTime for out-of-graph training loop: 0.459 secs\r\nTime for out-of-graph training loop: 0.459 secs\r\nTime for out-of-graph training loop: 0.457 secs\r\n```\r\n\r\n@jsimsa @alextp @mhong @jaingaurav FYI\r\nIt's interesting to note that the out-of graph loop is still faster, which means that the TF runtime is a little slower than Pyhton at running basic loops. That will hopefully improve in the future."]}, {"number": 35164, "title": "TypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key.", "body": "**Describe the problem**\r\nI am having the the below problem\r\nTypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\ngen_optimizer = tf.keras.optimizers.Adam(1e-3, beta_1=0.5)\r\ndisc_optimizer = tf.keras.optimizers.RMSprop(1e-3)\r\n    \r\n# model\r\nmodel = VAEGAN(\r\n    enc = encoder,\r\n    dec = decoder,\r\n    vae_disc_function = vaegan_discrim,\r\n    lr_base_gen = 1e-3, # \r\n    lr_base_disc = 1e-4, # the discriminator's job is easier than the generators so make the learning rate lower\r\n    latent_loss_div=1, # this variable will depend on your dataset - choose a number that will bring your latent loss to ~1-10\r\n    sig_mult = 10, # how binary the discriminator's learning rate is shifted (we squash it with a sigmoid)\r\n    recon_loss_div = .001, # this variable will depend on your dataset - choose a number that will bring your latent loss to ~1-10\r\n)\r\n\r\nmodel.train(example_data)\r\n\r\n\r\n**Any other info / logs**\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-11-2112af51db2e> in <module>\r\n----> 1 model.train(example_data)\r\n\r\n<ipython-input-6-94ca8f8e5589> in train(self, x)\r\n     93 \r\n     94     def train(self, x):\r\n---> 95         enc_gradients, dec_gradients, disc_gradients = self.compute_gradients(x)\r\n     96         self.apply_gradients(enc_gradients, dec_gradients, disc_gradients)\r\n     97 \r\n\r\n<ipython-input-6-94ca8f8e5589> in compute_gradients(self, x)\r\n     74     def compute_gradients(self, x):\r\n     75         with tf.GradientTape() as enc_tape, tf.GradientTape() as dec_tape, tf.GradientTape() as disc_tape:\r\n---> 76             (_, latent_loss, discrim_layer_recon_loss, gen_fake_loss, disc_fake_loss, disc_real_loss,) = self.compute_loss(x)\r\n     77 \r\n     78             enc_loss = latent_loss + discrim_layer_recon_loss\r\n\r\n<ipython-input-6-94ca8f8e5589> in compute_loss(self, x)\r\n     48         # pass through network\r\n     49         q_z = self.dist_encode(x)\r\n---> 50         z = q_z.sample()\r\n     51         p_z = ds.MultivariateNormalDiag(loc=[0.0] * z.shape[-1], scale_diag=[1.0] * z.shape[-1])\r\n     52         xg = self.decode(z)\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_probability/python/distributions/distribution.py in sample(self, sample_shape, seed, name, **kwargs)\r\n    838       samples: a `Tensor` with prepended dimensions `sample_shape`.\r\n    839     \"\"\"\r\n--> 840     return self._call_sample_n(sample_shape, seed, name, **kwargs)\r\n    841 \r\n    842   def _call_log_prob(self, value, name, **kwargs):\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_probability/python/distributions/transformed_distribution.py in _call_sample_n(self, sample_shape, seed, name, **kwargs)\r\n    389       # work, it is imperative that this is the last modification to the\r\n    390       # returned result.\r\n--> 391       y = self.bijector.forward(x, **bijector_kwargs)\r\n    392       y = self._set_sample_static_shape(y, sample_shape)\r\n    393 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_probability/python/bijectors/bijector.py in forward(self, x, name, **kwargs)\r\n    931       NotImplementedError: if `_forward` is not implemented.\r\n    932     \"\"\"\r\n--> 933     return self._call_forward(x, name, **kwargs)\r\n    934 \r\n    935   def _inverse(self, y):\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_probability/python/bijectors/bijector.py in _call_forward(self, x, name, **kwargs)\r\n    902       if not self._is_injective:  # No caching for non-injective\r\n    903         return self._forward(x, **kwargs)\r\n--> 904       mapping = self._lookup(x=x, kwargs=kwargs)\r\n    905       if mapping.y is not None:\r\n    906         return mapping.y\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_probability/python/bijectors/bijector.py in _lookup(self, x, y, kwargs)\r\n   1341     if x is not None:\r\n   1342       # We removed x at caching time. Add it back if we lookup successfully.\r\n-> 1343       mapping = self._from_x[x].get(subkey, mapping).merge(x=x)\r\n   1344     if y is not None:\r\n   1345       # We removed y at caching time. Add it back if we lookup successfully.\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_probability/python/bijectors/bijector.py in __getitem__(self, key)\r\n    149   def __getitem__(self, key):\r\n    150     weak_key = HashableWeakRef(key, lambda w: self.pop(w, None))\r\n--> 151     return super(WeakKeyDefaultDict, self).__getitem__(weak_key)\r\n    152 \r\n    153   # This is the \"DefaultDict\" part.\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_probability/python/bijectors/bijector.py in __hash__(self)\r\n    179     x = self()\r\n    180     if not isinstance(x, np.ndarray):\r\n--> 181       return hash(x)\r\n    182     # Note: The following logic can never be reached by the public API because\r\n    183     # the bijector base class always calls `convert_to_tensor` before accessing\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py in __hash__(self)\r\n    711     if (Tensor._USE_EQUALITY and executing_eagerly_outside_functions() and\r\n    712         (g is None or g._building_function)):  # pylint: disable=protected-access\r\n--> 713       raise TypeError(\"Tensor is unhashable if Tensor equality is enabled. \"\r\n    714                       \"Instead, use tensor.experimental_ref() as the key.\")\r\n    715     else:\r\n\r\nTypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key.\r\n", "comments": ["@ShibaPrasad, Please provide the complete code and Tenosrflow version to replicate the reported issue here. Thanks!", "@ShibaPrasad, Any update on this issue!", "I'm getting this too, using a gpu on Colab", "@shaunster0, Can you share the colab gist here to analyze the issue. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Hi @gadagashwini!  I'm having this problem, too.\r\n\r\nI'm following along with the code linked in this article:\r\n\r\nhttps://blog.tensorflow.org/2019/03/variational-autoencoders-with.html\r\n\r\n...but using TF 2.x.\r\n\r\nhttps://colab.research.google.com/drive/1HonWNUBQaecB4GHAAGiVP6YBUDc33qOF\r\n\r\nThe error occurs when defining the encoder:\r\n\r\n```python\r\nencoder = tfk.Sequential([\r\n    tfkl.InputLayer(input_shape=input_shape),\r\n    tfkl.Lambda(lambda x: tf.cast(x, tf.float32) - 0.5),\r\n    tfkl.Conv2D(base_depth, 5, strides=1,\r\n                padding='same', activation=tf.nn.leaky_relu),\r\n    tfkl.Conv2D(base_depth, 5, strides=2,\r\n                padding='same', activation=tf.nn.leaky_relu),\r\n    tfkl.Conv2D(2 * base_depth, 5, strides=1,\r\n                padding='same', activation=tf.nn.leaky_relu),\r\n    tfkl.Conv2D(2 * base_depth, 5, strides=2,\r\n                padding='same', activation=tf.nn.leaky_relu),\r\n    tfkl.Conv2D(4 * encoded_size, 7, strides=1,\r\n                padding='valid', activation=tf.nn.leaky_relu),\r\n    tfkl.Flatten(),\r\n    tfkl.Dense(tfpl.MultivariateNormalTriL.params_size(encoded_size),\r\n               activation=None),\r\n    tfpl.MultivariateNormalTriL(\r\n        encoded_size,\r\n        activity_regularizer=tfpl.KLDivergenceRegularizer(prior)),\r\n])\r\n```\r\n\r\n```\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-10-f26eb36ef5f5> in <module>()\r\n     17     tfpl.MultivariateNormalTriL(\r\n     18         encoded_size,\r\n---> 19         activity_regularizer=tfpl.KLDivergenceRegularizer(prior)),\r\n     20 ])\r\n     21 \r\n```\r\n\r\n```\r\nTypeError: in converted code:\r\n\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_probability/python/layers/distribution_layer.py:212 call\r\n        inputs, *args, **kwargs)\r\n    /tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/layers/core.py:846 call\r\n        result = self.function(inputs, **kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_probability/python/layers/distribution_layer.py:160 _fn\r\n        d = make_distribution_fn(*fargs, **fkwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_probability/python/layers/distribution_layer.py:343 <lambda>\r\n        lambda t: MultivariateNormalTriL.new(t, event_size, validate_args),\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_probability/python/layers/distribution_layer.py:358 new\r\n        scale_tril=scale_tril(params[..., event_size:]),\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_probability/python/bijectors/bijector.py:803 __call__\r\n        return self._call_forward(value, name=name or \"forward\", **kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_probability/python/bijectors/bijector.py:904 _call_forward\r\n        mapping = self._lookup(x=x, kwargs=kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_probability/python/bijectors/bijector.py:1343 _lookup\r\n        mapping = self._from_x[x].get(subkey, mapping).merge(x=x)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_probability/python/bijectors/bijector.py:151 __getitem__\r\n        return super(WeakKeyDefaultDict, self).__getitem__(weak_key)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_probability/python/bijectors/bijector.py:181 __hash__\r\n        return hash(x)\r\n    /tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py:705 __hash__\r\n        raise TypeError(\"Tensor is unhashable if Tensor equality is enabled. \"\r\n\r\n    TypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key.\r\n```\r\n\r\nDoes this help or should I create a new issue?", "@stephenwithav, Can you open new issue with filling issue [Template](https://github.com/tensorflow/tensorflow/issues/new/choose) and include the colab gist also. Thanks! "]}, {"number": 35163, "title": "Cherrypick Windows DLL warning changes and related notes", "body": "This PR pulls in a documentation / helper change that raises a warning\nif necessary DLLs could not be found on the Windows system. See the messages\nfrom the included commits for more details.", "comments": ["Added @goldiegadde and @martinwicke since I'm adding new release notes; I'll need someone to double-check them."]}, {"number": 35162, "title": "Fixes issues with shape of output for `reduce_logsumexp` in graph mode", "body": "Also adds docs for `select_v2` (maybe could be removed from PR since not relevant)\r\naddr: #35099", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F35162) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F35162) for more info**.\n\n<!-- ok -->", "@rrkarim  Can you please resolve conflicts? Thanks!", "> @rrkarim Can you please resolve conflicts? Thanks!\r\n\r\nNot sure what do you mean by resolving the conflicts. I've resolved all the issues and addressed the lack of docs.", "@rrkarim  File tensorflow/python/ops/math_ops.py have conflicts. To check conflicts, please click on Resolve conflicts button. Please, resolve them. Thanks!", "@gbaned resolved, sorry for the delay on that."]}, {"number": 35161, "title": "why TF2.0+TRT6 (keras) slower than TF1+keras about 4 times ?", "body": "I'd like to understand the performance issue I faced :\r\nWhy TF2.0+TRT6 (keras) slower than TF1+keras about 4 times ?\r\n\r\nGPU K80\r\n\r\nbefore : TF1 + keras (as separate package)\r\nafter: TF2 + TRT6 integrated with integrated keras\r\n\r\non the same example TF2 is 4 times slower, when I'm waiting acceleration of training/predition in new version with TRT integration.\r\n\r\n", "comments": ["@VitaMusic \r\nRequest you to provide simple standalone code to reproduce the issue in our environment, then it is easy for localizing the issue faster. Thanks!", "I can not share my code for a IP reasons, but you can try any like VGG NN with any image set.", "@VitaMusic Can you please share a standalone code with a public data. Issue resolution is faster with a simple standalone code. Thanks!", "I can not share my code for a IP reasons, I shall see what I can do as a code example, but perhaps you can try any like VGG NN with any image set and it will be faster way for benchmarking. I see there are other issues on performance of tf2, they indicated to do eager mode off, but if I do it I'll have errors with dropout layers. I did not try yet the last TF2 RC1 version update, perhaps this problem was solved already ?\r\nFrom other side, I'd like to have a benchmark script on public data (training and predicion cases) where TF1+keras vs TF2 (keras inside) comparison done, if you can give me it please? I'll try to run it on my servers.\r\nPerhaps it is alse linked to gpu problem, as I recompiled TF2 for K80.", "@VitaMusic Can you please try recent TF versions (`TF2.2` and `tf-nightly`)? Can you please share a standalone code with a public data. Issue resolution is faster with a simple standalone code. Thanks!\r\n\r\nPlease feel to close the issue if this was already resolved for you. Thanks!", "Cause covid I have to standby this problem for sometime. Will test the new\nversion later. Sorry for this delay.\n\n\u0432\u0442, 2 \u0418\u044e\u043d 2020 \u0433., 2:49 Vishnuvardhan Janapati <notifications@github.com>:\n\n> @VitaMusic <https://github.com/VitaMusic> Can you please try recent TF\n> versions (TF2.2 and tf-nightly)? Can you please share a standalone code\n> with a public data. Issue resolution is faster with a simple standalone\n> code. Thanks!\n>\n> Please feel to close the issue if this was already resolved for you.\n> Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/35161#issuecomment-637202808>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AC7AFFMAND2KSQBTTN4YEW3RUREBHANCNFSM4J3NBJWA>\n> .\n>\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 35159, "title": "Cannot successfully serialize and restore model using either 'tf' or 'h5' format", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux on Google Cloud instance\r\n- TensorFlow installed from (source or binary): binary (pip)\r\n- TensorFlow version (use command below): 2.1.0.rc1\r\n- Python version: 3.7.3\r\n\r\n**Describe the current behavior**\r\n\r\nI've attempted to save a TF regression model in 'h5' format as follows:\r\n\r\n    model_mean.save(HITTER_MODEL_DIR + 'hitter_model_mean.h5', save_format='h5')\r\n\r\nhowever this fails:\r\n\r\n```\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-100-bf2d7187a55e> in <module>()\r\n----> 1 model_mean.save(HITTER_MODEL_DIR + 'hitter_model_mean.h5', save_format='h5')\r\n\r\n4 frames\r\n/usr/local/lib/python3.6/dist-packages/h5py/_hl/group.py in create_group(self, name, track_order)\r\n     58             name, lcpl = self._e(name, lcpl=True)\r\n     59             gcpl = Group._gcpl_crt_order if track_order else None\r\n---> 60             gid = h5g.create(self.id, name, lcpl=lcpl, gcpl=gcpl)\r\n     61             return Group(gid)\r\n     62 \r\n\r\nh5py/_objects.pyx in h5py._objects.with_phil.wrapper()\r\n\r\nh5py/_objects.pyx in h5py._objects.with_phil.wrapper()\r\n\r\nh5py/h5g.pyx in h5py.h5g.create()\r\n\r\nValueError: Unable to create group (name already exists)\r\n```\r\n\r\nI then attempt to save as 'tf' format:\r\n\r\n    model_mean.save(HITTER_MODEL_DIR + 'hitter_model_mean', save_format='tf')\r\n\r\nwhich succeeds, however, attempting to load the model fails:\r\n\r\n```\r\ntf.keras.models.load_model(HITTER_MODEL_DIR + 'hitter_model_mean')\r\n\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-99-37062ae44748> in <module>()\r\n----> 1 tf.keras.models.load_model(HITTER_MODEL_DIR + 'hitter_model_mean')\r\n\r\n17 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/function_deserialization.py in restored_function_body(*args, **kwargs)\r\n    260         .format(_pretty_format_positional(args), kwargs,\r\n    261                 len(saved_function.concrete_functions),\r\n--> 262                 \"\\n\\n\".join(signature_descriptions)))\r\n    263 \r\n    264   concrete_function_objects = []\r\n\r\nValueError: Could not find matching function to call loaded from the SavedModel. Got:\r\n  Positional arguments (1 total):\r\n    * Tensor(\"inputs:0\", shape=(None, 2), dtype=float32)\r\n  Keyword arguments: {}\r\n\r\nExpected these arguments to match one of the following 1 option(s):\r\n\r\nOption 1:\r\n  Positional arguments (1 total):\r\n    * [TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs/0')]\r\n  Keyword arguments: {}\r\n```\r\n", "comments": ["I've tried giving each layer in the model unique names, but it does not affect the 'h5' saving error at all.", "Forgot to mention that the model contains a TFP object (the output of the network); not sure if that's the reason I'm getting this. Otherwise the network is pretty simple. Here's the model:\r\n\r\n```python\r\ninputs = Input(shape=(X.shape[1],))\r\nhidden = BatchNormalization()(inputs)\r\nhidden = Dense(1024, activation=\"relu\")(hidden)\r\nhidden = Dropout(0.5)(hidden)\r\nhidden = BatchNormalization()(hidden)\r\nhidden = Dense(512, activation=\"relu\")(hidden)\r\nhidden = Dropout(0.5)(hidden)\r\nhidden = BatchNormalization()(hidden)\r\nhidden = Dense(256, activation=\"relu\")(hidden)\r\nhidden = Dropout(0.5)(hidden)\r\nhidden = BatchNormalization()(hidden)\r\nhidden = Dense(128, activation=\"relu\")(hidden)\r\nparams = Dense(2)(hidden)\r\ndist = tfp.layers.DistributionLambda(normal_sp)(params) \r\n \r\nmodel = Model(inputs=inputs, outputs=dist)\r\n```", "@fonnesbeck ,\r\nThank you for reporting the issue, could you please provide a standalone code to reproduce the error? ", "@fonnesbeck ,\r\nAny update on the issue?Thanks!", "It still does not work, but the data is proprietary so I need to take the time to make a working example without the data.", "@fonnesbeck ,\r\nHello,Got a chance build a working example?Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 35158, "title": "Update init_ops_v2.py  for  \"&gt;&gt\" instead of \">>>\"", "body": "html decode function added as a comment: for  \"&gt;&gt\" instead of \">>>\" in :https://www.tensorflow.org/api_docs/python/tf/constant_initializer\r\nIssue: #35085 \r\n", "comments": ["Why are you adding an html_decode function as a comment in the middle of a source file?"]}, {"number": 35157, "title": "Caching to file instead of memory of tf.data.dataset using 2 map functions with cache(filename) in between and (x, y) tuple not working", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nWindows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nNone\r\n- TensorFlow installed from (source or binary):\r\nbinary\r\n- TensorFlow version (use command below):\r\n2.0\r\n- Python version:\r\n3.6.8\r\n- Bazel version (if compiling from source):\r\nnone\r\n- GCC/Compiler version (if compiling from source):\r\nnone\r\n- CUDA/cuDNN version:\r\nnone\r\n- GPU model and memory:\r\nnone\r\n\r\nmap(), then caching a dataset of (image shape (224,224,3), and one_hot_encoded class index shape (n)) and subsequent map() works when simply using cache(); however when using file-based caching (which I need because of large dataset) using cache('cache.tmp') fails with the following error:\r\n(I tried making the one-hot same type as image shape (float64) instead of int32 but does not help)\r\nAlso not using a tuple but array gives same error.\r\n\r\nFirst I create dataset using tuple: (array of file names (str), array of class indices (str)) \r\nThen in map( lambda x, y : return (load_image(x) (float64 (224,224,3)), tf.one_hot(int(y), self.class_count, dtype=tf.float64))\r\n\r\nafterwards when cache('cache.tmp'); and using a second .map(lambda x, y : return (preprocess(x), y))\r\nthe error is produced\r\n\r\nCall stack:\r\n\r\n14:09:27.225818: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at iterator_ops.cc:929 : Invalid argument: {{function_node __inference_Dataset_map_preprocess_10622}} Expects arg[1] to be double but string is provided\r\nTraceback (most recent call last):\r\n    x, y = next(dataset_iterator)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py\", line 622, in __next__\r\n    return self.next()\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py\", line 666, in next\r\n    return self._next_internal()\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py\", line 651, in _next_internal\r\n    output_shapes=self._flat_output_shapes)\r\n  File \"C:\\Python36\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_dataset_ops.py\", line 2672, in iterator_get_next_sync\r\n    _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __inference_Dataset_map_preprocess_10622}} Expects arg[1] to be double but string is provided [Op:IteratorGetNextSync]\r\n\r\n\r\n**Describe the expected behavior**\r\nSuccessful caching of dataset\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@josdewitte, Could you provide the standalone code snippet to replicate the issue. Thanks!", "@gadagashwini, deleted the cache files manually this morning; now I cannot reproduce the issue. Maybe you can verify that these files are cleaned up on every dataset.cache(filename) locations. Should we close this ?", "@josdewitte, If issue is no longer exist we can close this. Thanks! "]}, {"number": 35156, "title": "Item assigment", "body": "I really want to know why tf can't support item assigment like numpy\r\n\r\n\r\n", "comments": ["In general, a TensorFlow tensor object is not assignable*, so you cannot use it on the left-hand side of an assignment.\r\nAnother way you can do it like this.\r\n```python3\r\naa=tf.Variable(tf.zeros(3, tf.int32))\r\naa=aa[2].assign(1)\r\n```\r\nthen the output is:\r\n```\r\narray([0, 0, 1], dtype=int32)\r\n```", "@sweetxiaoqizi, Did @dubesar's suggestion solved your issue. Thanks!", "@sweetxiaoqizi, Is this still an issue!", "@sweetxiaoqizi, \r\nPlease go through tf.Variable doc [here](https://www.tensorflow.org/api_docs/python/tf/Variable?version=stable).Looks like issue is resolved. Feel free to reopen if issue still persists. Thanks!"]}, {"number": 35155, "title": "Memory chunk error when train BoostedTreesRegressor in docker container", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS (in docker container)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): pip wheel\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.6.8 \r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n**Describe the current behavior**\r\nThe training is down due to low layer system call (corrupted size vs. prev_size). the process is immediately corrupted without much log to trace.\r\n\r\n**Describe the expected behavior**\r\nthe estimator (BoostedTreesRegressor) should be trained in normal.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport os\r\nimport uuid\r\nimport json\r\nfrom io import StringIO\r\n\r\nimport pandas as pd\r\nimport tensorflow as tf\r\nfrom sklearn.model_selection import train_test_split\r\nfrom tensorflow.estimator import BoostedTreesRegressor\r\n\r\ndef split_data(df: pd.DataFrame) -> (pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame):\r\n    \"\"\"Split data into train and test sets\r\n\r\n    Args:\r\n        df (DataFrame): pandas dataframe\r\n\r\n    Returns:\r\n        X_train, X_test, y_train, y_test\r\n    \"\"\"\r\n    feature_cols = [c for c in df.columns if c.startswith('FEATURE')]\r\n    label_col = [c for c in df.columns if c.startswith('LABEL')]\r\n\r\n    return train_test_split(df[feature_cols], df[label_col], test_size=.2, random_state=42)\r\n\r\n\r\ndef make_input_fn(X, y, n_epochs=None, shuffle=True):\r\n    def input_fn():\r\n        dataset = tf.data.Dataset.from_tensor_slices((dict(X), y))\r\n        if shuffle:\r\n            dataset = dataset.shuffle(len(y))\r\n        dataset = dataset.repeat(n_epochs)\r\n        dataset = dataset.batch(len(y))\r\n        return dataset\r\n    return input_fn\r\n\r\n\r\ndef make_serving_receiver_fn(df: pd.DataFrame):\r\n    feature_col_names = [c for c in df.columns if c.startswith('FEATURE')]\r\n    feature_cols = [tf.feature_column.numeric_column(fc) for fc in feature_col_names]\r\n    feature_spec = tf.feature_column.make_parse_example_spec(feature_cols)\r\n    return tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\r\n\r\n\r\ndef train_model(df: pd.DataFrame, **params) -> (BoostedTreesRegressor, dict, dict):\r\n    \"\"\"Train Boost Tree\r\n\r\n    Args:\r\n        df (DataFrame): pandas dataframe\r\n        params (**dict): parameters for training\r\n\r\n    Returns:\r\n        BoostTreesRegressor, saved model dir, a dict containing the evaluation metrics\r\n    \"\"\"\r\n    feature_col_names = [c for c in df.columns if c.startswith('FEATURE')]\r\n    label_col_name = [c for c in df.columns if c.startswith('LABEL')]\r\n    feature_cols = [tf.feature_column.numeric_column(fc_name) for fc_name in feature_col_names]\r\n    default_params = {\r\n        'feature_columns': feature_cols,\r\n        'n_batches_per_layer': 1,\r\n        'model_dir': os.path.join('../output', str(uuid.uuid4())),\r\n    }\r\n    default_params.update(params)\r\n    regressor = BoostedTreesRegressor(**default_params)\r\n    X_train, X_valid, y_train, y_valid = train_test_split(df[feature_col_names], df[label_col_name], test_size=0.2, random_state=42)\r\n    train_input_fn = make_input_fn(X_train, y_train)\r\n    evaluate_input_fn = make_input_fn(X_valid, y_valid, n_epochs=1)\r\n    regressor.train(input_fn=train_input_fn)\r\n    summary = regressor.evaluate(input_fn=evaluate_input_fn)\r\n    receiver_fn = make_serving_receiver_fn(df)\r\n    export_dir = regressor.export_saved_model(regressor.model_dir, receiver_fn)\r\n\r\n    summary = {k: float(v) for k, v in summary.items()}\r\n\r\n    return regressor, export_dir, summary\r\n```\r\n\r\n**Other info / logs**\r\nNo problem under environment __OSX 10.14.5__ with __pyenv virtualenv 3.7.0 (default, Nov 22 2019, 12:39:30) \\n[Clang 11.0.0 (clang-1100.0.33.12)]__\r\n\r\nNo problem when use google colab runtime (__Ubuntu 18.04.3 LTS Python 3.6.9 compiled by GCC 8.3.0__). See __[notebook shared](https://colab.research.google.com/drive/1aAjJCWOBd7R0Hb6w4d7UCSnkfk4c-xyE)__\r\n\r\nSame problem in Kaggle runtime (__Debian GNU/Linux 9 Python 3.6.6 Anaconda GCC 7.3.0__) using tensorflow 2.0.0.\r\n\r\nFull error log in docker using official image __tensorflow/tensorflow:2.0.0-py3__:\r\n\r\n```\r\nWARNING: Logging before flag parsing goes to stderr.\r\nI1216 13:01:22.775628 140590360139584 estimator.py:1800] Using default config.\r\nI1216 13:01:22.778364 140590360139584 estimator.py:212] Using config: {'_model_dir': '/app/WINDMIL_PoC_Data_FE/service/estimator/saved_model/8f979f53-4821-4def-bc6e-9692d868e2ea', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\r\ngraph_options {\r\n  rewrite_options {\r\n    meta_optimizer_iterations: ONE\r\n  }\r\n}\r\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdd837c5d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\r\nW1216 13:01:22.809657 140590360139584 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\nW1216 13:01:22.811977 140590360139584 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\r\nI1216 13:01:22.888739 140590360139584 estimator.py:1147] Calling model_fn.\r\nW1216 13:01:22.968535 140590360139584 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/head.py:437: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.cast` instead.\r\nI1216 13:01:23.278414 140590360139584 estimator.py:1149] Done calling model_fn.\r\nI1216 13:01:23.278981 140590360139584 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\r\nW1216 13:01:23.327183 140590360139584 meta_graph.py:448] Issue encountered when serializing resources.\r\nType is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\r\n'_Resource' object has no attribute 'name'\r\nI1216 13:01:23.468171 140590360139584 monitored_session.py:240] Graph was finalized.\r\n2019-12-16 13:01:23.468761: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-12-16 13:01:23.475253: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz\r\n2019-12-16 13:01:23.476582: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4ed0210 executing computations on platform Host. Devices:\r\n2019-12-16 13:01:23.476657: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\nI1216 13:01:23.541273 140590360139584 session_manager.py:500] Running local_init_op.\r\nI1216 13:01:23.561274 140590360139584 session_manager.py:502] Done running local_init_op.\r\nW1216 13:01:23.960061 140590360139584 meta_graph.py:448] Issue encountered when serializing resources.\r\nType is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\r\n'_Resource' object has no attribute 'name'\r\nI1216 13:01:24.019694 140590360139584 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /app/WINDMIL_PoC_Data_FE/service/estimator/saved_model/8f979f53-4821-4def-bc6e-9692d868e2ea/model.ckpt.\r\nW1216 13:01:24.100714 140590360139584 meta_graph.py:448] Issue encountered when serializing resources.\r\nType is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\r\n'_Resource' object has no attribute 'name'\r\nI1216 13:01:24.385114 140590360139584 basic_session_run_hooks.py:262] loss = 0.017109463, step = 0\r\nW1216 13:01:24.594182 140590360139584 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\r\ncorrupted size vs. prev_size\r\nAborted\r\n```\r\n", "comments": ["@Hujun Can you please test with latest version TensorFlow 2.2?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 35154, "title": "Cannot train keras model with 2 outputs", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Family\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.6.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10 / 7.6.4\r\n- GPU model and memory: GeForce 940M\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n`import tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras.layers import Dense, Input\r\nfrom tensorflow.keras import Model`\r\n\r\n\r\nA tf.keras model is created with 2 output heads:\r\n\r\n`inputs=Input(shape=(20))\r\nx=Dense(32, activation='relu')(inputs)\r\noutput1=Dense(3, activation='softmax')(x)\r\noutput2=Dense(6, activation='softmax')(x)\r\n\r\nmodel=Model(inputs=inputs, outputs=[output1, output2])\r\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy'])`\r\n\r\n\r\nThen an arbitary sized training sample is created:\r\n\r\n`labels=tf.constant([[0 for i in range(50)],[1 for i in range(50)]], shape=[50,2])\r\n\r\nsample=[]\r\nfor i in range(20):\r\n    if i%2==0:\r\n        sample.append(0)\r\n    else: sample.append(1)\r\n\r\ndata=tf.constant([sample for i in range(50)], shape=[50,20])`\r\n\r\n\r\nWhen the data is called for training,\r\n\r\n`model.fit(data, labels, epochs=1, batch_size=5)`\r\n\r\n an error occurs saying that the module expected 2 arrays, but when I swap out the validation dataset with a pair of 2 arrays:\r\n\r\n`model.fit(data, (labels1, labels2), epochs=1, batch_size=5)`\r\n\r\nanother error pops up saying that the x and y dimensions must be the same. To put simply, keras thinks that the pair of validation outputs is an array.\r\n\r\n**Describe the expected behavior**\r\nThe model.fit method runs and the model is trained for 1 epoch with 50 samples.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\ncopy the above code in order, with the last model.fit method not usable.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n`Traceback (most recent call last):\r\n  File \"C:\\Users\\admin\\Desktop\\working as intended\\CONSTANTINOPLE\\test\\test duo output.py\", line 25, in <module>\r\n    model.fit(data, labels, epochs=1, batch_size=8)\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 728, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 224, in fit\r\n    distribution_strategy=strategy)\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 547, in _process_training_inputs\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 594, in _process_inputs\r\n    steps=steps)\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 2519, in _standardize_user_data\r\n    exception_prefix='target')\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\", line 531, in standardize_input_data\r\n    str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\r\nValueError: Error when checking model target: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [<tf.Tensor: id=286, shape=(50, 2), dtype=int32, numpy=\r\narray([[0, 0],\r\n       [0, 0],\r\n       [0, 0],\r\n       [0, 0],\r\n       [0, 0],\r\n       [0, 0],\r\n       [0, 0],\r\n       [0, 0],\r\n       [0, 0],\r\n       [0...`", "comments": ["in model.fit() you don't need to include the batch_size as per my opinion use the callbacks if defined, let me show you an example by attaching a .\r\n![Screenshot (2)](https://user-images.githubusercontent.com/46572301/70909745-1f13c900-2034-11ea-8f1e-47497457b184.png)\r\nipynb file of code", "@darsh8200 I don't think you are getting what I was asking. I wanted to ask about how to train a network with 2 output heads. And also the batch size variable is arbitary and can be removed in this case.", "Hi,\r\n\r\nTo make the model training work, you need to pass labels as a list of two tensors (each associated with one of the outputs), _i.e._ `model.fit(x, [y1, y2])` with `x` of shape `(n, 20)`, `y1` of shape `(n,)` and `y2` of shape `(n,)` (note that you could also add a dimension for batch-size, but that is another topic).\r\n\r\nIf I go back to your initial definition of `data` and `labels` as two Tensors of respective shapes `(50, 20)` and `(50, 2)`, you can run : `model.fit(data, [labels[:, 0], labels[:, 1]], epochs=1, batch_size=5)`.\r\n\r\nI hope this helps :)", "@pandrey-fr I used your code and with some tweaking, the code ran flawlessly. I didn't know you can write grammar like `labels[:, 0]` before, seems like I have more stuff to learn :D Thanks for the help, apperciate it", "@ongoing0217 You are welcome ! The use of slice notation is only valid in Eager execution, so you should use it with parsimony, but it can be useful in debugging contexts :)"]}, {"number": 35153, "title": "Are there related APIs to determine savedmodel  whether batch is supported?", "body": "There have a savedmodel format model,have some method or API to judge that is support batch?", "comments": ["@zxgm, Please refer this [link](https://www.tensorflow.org/guide/saved_model). Thanks!", "@zxgm, Was the link resolved your issue.Thanks! ", "The ide not resolve my problem, but I have found other method.Thanks a lot!!!"]}, {"number": 35152, "title": "Memory leaks when using tf.strings.split in map_func for tf.data.Dataset.map with eager execution.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary):  binary\r\n- TensorFlow version (use command below): 2.1.0rc1\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): N/A \r\n- GCC/Compiler version (if compiling from source): N/A \r\n- CUDA/cuDNN version: N/A \r\n- GPU model and memory: N/A \r\n\r\n**Describe the current behavior**\r\nIf we use `tf.strings.split` in map_func to process each element in tf.data.Dataset, the used memory grows when we iterate the dataset and the used memory is not freed after iteration. What's more, the used memory continues to grow greatly if we repeatedly create the same tf.data.Dataset instance. However, the used memory keeps stable if we use tf.py_function to implement the split logic.\r\n![image](https://user-images.githubusercontent.com/18071380/70906668-debb4780-2041-11ea-945c-bf2a05cbb637.png)\r\n\r\n\r\n**Describe the expected behavior**\r\nThe used memory when iterating the dataset should be freed and should grow the create the same tf.data.Dataset instance.\r\n\r\n**Code to reproduce the issue**\r\n#### Experiment\r\n```python\r\nimport psutil\r\nimport tensorflow as tf\r\nimport pandas as pd\r\nimport numpy as np\r\n\r\nFEATURE_COUNT = 400\r\n\r\n# mock feature names and feature data\r\ndef gen_feature_names(feature_count):\r\n    feature_names = []\r\n    for i in range(feature_count):\r\n        feature_names.append(\"f{}\".format(i))\r\n    return feature_names\r\n\r\n\r\ndef gen_samples(feature_names, sample_count=5000):\r\n    samples = []\r\n    for _ in range(sample_count):\r\n        feature_str = \"\"\r\n        for name in feature_names:\r\n            feature_str += \"{};\".format(np.random.random())\r\n        feature_str += str(np.random.randint(0,2))\r\n        yield feature_str\r\n        \r\ndef dataset_fn(dataset):\r\n    def _py_parse_data(record):\r\n        record = record.numpy()\r\n        feature_labels = bytes.decode(record).split(\";\")\r\n        return feature_labels\r\n\r\n    def _parse_data(*record):\r\n        feature_values = record[0:-1]\r\n        features = {}\r\n        for i,feature_name in enumerate(FEATURE_NAMES):\r\n            features[feature_name] = feature_values[i]\r\n        label = tf.strings.to_number(record[-1], tf.int64)\r\n        return features, label\r\n    \r\n    tout = [tf.string] * FEATURE_COUNT\r\n    tout.append(tf.string)\r\n    \r\n    dataset = dataset.map(\r\n        lambda record: tf.py_function(\r\n            _py_parse_data,\r\n            [record],\r\n            tout\r\n        )\r\n    )\r\n    dataset = dataset.map(_parse_data)\r\n    dataset = dataset.shuffle(buffer_size=100)\r\n    return dataset\r\n\r\n\r\ndef dataset_fn_using_split(dataset):\r\n    def _parse_data(record):\r\n        feature_label = tf.strings.split([record], sep=';')[0]\r\n        feature_values = feature_label[0:-1]\r\n        features = {}\r\n        for i, feature_name in enumerate(FEATURE_NAMES):\r\n            features[feature_name] = feature_values[i]\r\n        label = feature_label[-1]\r\n\r\n        return features, label\r\n    \r\n    dataset = dataset.map(_parse_data)\r\n    dataset = dataset.shuffle(buffer_size=100)\r\n    return dataset\r\n\r\ndef create_dataset(feature_names, using_split=True):\r\n    dataset = tf.data.Dataset.from_generator(\r\n        lambda : gen_samples(feature_names), tf.string\r\n    )\r\n    if using_split:\r\n        dataset = dataset_fn_using_split(dataset)\r\n    else:\r\n        dataset = dataset_fn(dataset)\r\n    dataset = dataset.batch(512)\r\n    return dataset\r\n\r\n\r\ndef view_used_mem():\r\n    used_mem = psutil.virtual_memory().used\r\n    print('used memory: {} Mb'.format(used_mem / 1024 / 1024))\r\n\r\nFEATURE_NAMES = gen_feature_names(FEATURE_COUNT)\r\n\r\n# Test used memory by using tf.strings.split in `map_func`\r\nFEATURE_NAMES = gen_feature_names(FEATURE_COUNT)\r\n\r\nstart_time = time.time()\r\nfor i in range(4):\r\n    print(\"loop {}\".format(i))\r\n    view_used_mem()\r\n    dataset = create_dataset(FEATURE_NAMES, using_split=True)\r\n    for batch in dataset:\r\n        pass\r\nprint(\"Consume time : {}\".format(time.time() - start_time))\r\nprint(\"end\")\r\nview_used_mem()\r\n\r\n# Test used memory by using `tf.py_function`\r\nstart_time = time.time()\r\nfor i in range(4):\r\n    print(\"loop {}\".format(i))\r\n    view_used_mem()\r\n    dataset = create_dataset(FEATURE_NAMES, using_split=False)\r\n    for batch in dataset:\r\n        pass\r\nprint(\"Consume time : {}\".format(time.time() - start_time))\r\nprint(\"end\")\r\nview_used_mem()\r\n\r\n**Other info / logs**\r\nWe encounter this issue when building inputs pipeline using `tf.data.Dataset` in [ElasticDL](https://github.com/sql-machine-learning/elasticdl)\r\n", "comments": ["I could reproduce the issue with Tf 2.1.\r\nPlease take a look at colab [gist](https://colab.sandbox.google.com/gist/gadagashwini/4184e630cb4e5ff57c6bc0b5c3a800f3/untitled313.ipynb). Thanks!", "When I change the order in which the `tf.strings.split` and `tf.py_function` experiments are executed, I see fast memory growth for `tf.py_function` experiment and not the `tf.strings.split`. This suggests that the memory behavior you are observing is unrelated to `tf.strings.split` vs `tf.py_function` -- as it occurs irrespective of which experiment you run first -- and is more likely related to caching of objects inside of TensorFlow's implementation and the deferred nature of Python's garbage collection.\r\n", "But, I also see fast memory growth for the only `tf.strings.split` experiment and slow memory growth for the only `tf.py_function` experiment. \r\nUsing `tf.py_function` in `dataset_fn`, I see fast memory growth when the first dataset variable is created and slow memory growth when other dataset variables are created.\r\n![image](https://user-images.githubusercontent.com/18071380/71344373-4f5fe800-259d-11ea-9445-5ea64c0bf1a6.png)\r\n\r\nUsing `tf.strings.split` in `dataset_fn`, I see fast memory growth when every dataset variable is created.\r\n![image](https://user-images.githubusercontent.com/18071380/71344476-9948ce00-259d-11ea-86a1-9ba868120c3e.png)\r\n\r\n", "What happens when you run the `tf.strings.split` for 20 epochs? Does the memory use plateau?\r\n\r\nCan you reproduce the issue without `tf.data` (simply wrapping your `_parse_data` for both with and without `strings.split` in `tf.function` and applying it to elements generated by `gen_samples` in your inner loop)?", "The memory use does not plateau when running for 20 epochs.\r\n```\r\nloop 0 \r\nUsed memory:  303.28515625 Mb\r\nloop 1\r\nUsed memory:  457.7109375 Mb\r\nloop 2\r\nUsed memory:  591.4921875 Mb\r\nloop 3\r\nUsed memory:  714.41796875 Mb\r\nloop 4\r\nUsed memory:  797.890625 Mb\r\nloop 5\r\nUsed memory:  898.14453125 Mb\r\nloop 6\r\nUsed memory:  965.6875 Mb\r\nloop 7\r\nUsed memory:  1083.3515625 Mb\r\nloop 8\r\nUsed memory:  1150.41015625 Mb\r\nloop 9\r\nUsed memory:  1254.76171875 Mb\r\nloop 10\r\nUsed memory:  1310.88671875 Mb\r\nloop 11\r\nUsed memory:  1299.33203125 Mb\r\nloop 12\r\nUsed memory:  1377.38671875 Mb\r\nloop 13\r\nUsed memory:  1420.7109375 Mb\r\nloop 14\r\nUsed memory:  1489.80859375 Mb\r\nloop 15\r\nUsed memory:  1587.70703125 Mb\r\nloop 16\r\nUsed memory:  1652.21484375 Mb\r\nloop 17\r\nUsed memory:  1672.3828125 Mb\r\nloop 18\r\nUsed memory:  1680.796875 Mb\r\nloop 19\r\nUsed memory:  1739.9296875 Mb\r\n```\r\n\r\nHowever, the memory use plateaus if I use `dataset.repeat(20)` not create dataset instance for each epoch like:\r\n```python\r\nFEATURE_NAMES = gen_feature_names(FEATURE_COUNT)\r\n\r\nstart_time = time.time()\r\ndataset = create_dataset(FEATURE_NAMES, using_split=True)\r\ndataset = dataset.repeat(20)\r\n\r\nnum = 0\r\nfor batch in dataset:\r\n    num += 1\r\n    if num % 10 == 0:\r\n        view_used_mem()\r\n    pass\r\n```\r\n![image](https://user-images.githubusercontent.com/18071380/71793526-2dc02f80-3078-11ea-8a37-8140b8eac2f3.png)\r\n\r\nSo, i think the reason may be that TF retraces the graph in dataset map function when i create dataset instance for each epoch and does not release the graph even if i delete the dataset instance by `del dataset`.\r\n\r\n", "@kkimdev could you try running this through your tooling for checking leaks of Python objects? Thank you.", "- using_split=True https://paste.googleplex.com/6404943990751232\r\n- using_split=False https://paste.googleplex.com/5515399179272192\r\n\r\nIt looks both are leaking.\r\n\r\n`_GeneratorState` reference graph for \"using_split=True\" case.\r\nhttps://graphviz.corp.google.com/svg?graph_id=cfe456a9651f00885270edff9f269e4f\r\n\r\nIn the graph, I see `_py_funcs_used_in_graph` which is unexpected for \"using_split=True\" case.  Is there any place that tf.data uses py_function underneath?", "`from_generator` uses PyFunc", "If I apply this commit https://github.com/tensorflow/tensorflow/commit/3b74a63c0f7e1ec4618563958079f538cd9de076 then seems there is no more leak https://paste.googleplex.com/4555021112836096\r\n\r\nBut that commit unfortunately got reverted https://github.com/tensorflow/tensorflow/commit/8a0cd10c92f9c62f3dfbd261f0481fad93a6ae8c .  Sorry but re-landing that doesn't seem easy at this point and I don't have eta yet.\r\n\r\n", "@workingloong Looks like this was resolved in recent `tf-nightly`. I ran the loop 40 time and don't see memory increase. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/aa5e7857d176b5319390bba324a21c1d/untitled313.ipynb). \r\n\r\nPlease verify once and close the issue if this was resolved for you. Thanks!\r\n\r\n```\r\nloop 0\r\nused memory: 772.234375 Mb\r\nloop 1\r\nused memory: 772.10546875 Mb\r\nloop 2\r\nused memory: 772.71875 Mb\r\nloop 3\r\nused memory: 774.7421875 Mb\r\nConsume time : 58.04884696006775\r\nend\r\nused memory: 776.3984375 Mb\r\nloop 0\r\nused memory: 776.3984375 Mb\r\nloop 1\r\nused memory: 780.72265625 Mb\r\nloop 2\r\nused memory: 778.90625 Mb\r\nloop 3\r\nused memory: 778.30078125 Mb\r\nloop 4\r\nused memory: 778.12109375 Mb\r\nloop 5\r\nused memory: 778.40625 Mb\r\nloop 6\r\nused memory: 777.7109375 Mb\r\nloop 7\r\nused memory: 776.3046875 Mb\r\nloop 8\r\nused memory: 6938.546875 Mb\r\nloop 9\r\nused memory: 778.83984375 Mb\r\nloop 10\r\nused memory: 778.28515625 Mb\r\nloop 11\r\nused memory: 778.0703125 Mb\r\nloop 12\r\nused memory: 776.921875 Mb\r\nloop 13\r\nused memory: 776.703125 Mb\r\nloop 14\r\nused memory: 776.51171875 Mb\r\nloop 15\r\nused memory: 776.61328125 Mb\r\nloop 16\r\nused memory: 776.2578125 Mb\r\nloop 17\r\nused memory: 775.0234375 Mb\r\nloop 18\r\nused memory: 774.71875 Mb\r\nloop 19\r\nused memory: 774.38671875 Mb\r\nloop 20\r\nused memory: 773.9375 Mb\r\nloop 21\r\nused memory: 772.953125 Mb\r\nloop 22\r\nused memory: 775.59375 Mb\r\nloop 23\r\nused memory: 776.03515625 Mb\r\nloop 24\r\nused memory: 777.40625 Mb\r\nloop 25\r\nused memory: 776.89453125 Mb\r\nloop 26\r\nused memory: 776.49609375 Mb\r\nloop 27\r\nused memory: 777.05078125 Mb\r\nloop 28\r\nused memory: 776.2578125 Mb\r\nloop 29\r\nused memory: 779.3359375 Mb\r\nloop 30\r\nused memory: 778.94140625 Mb\r\nloop 31\r\nused memory: 779.13671875 Mb\r\nloop 32\r\nused memory: 778.921875 Mb\r\nloop 33\r\nused memory: 779.0546875 Mb\r\nloop 34\r\nused memory: 778.93359375 Mb\r\nloop 35\r\nused memory: 778.9921875 Mb\r\nloop 36\r\nused memory: 777.9140625 Mb\r\nloop 37\r\nused memory: 778.5625 Mb\r\nloop 38\r\nused memory: 777.80859375 Mb\r\nloop 39\r\nused memory: 777.97265625 Mb\r\nConsume time : 1582.0767142772675\r\nend\r\nused memory: 778.08203125 Mb\r\n```", "I am closing this issue as this was resolved. Please feel free to reopen if the issue persists again. Thanks!"]}, {"number": 35151, "title": "No data found in layer when fitting TF 2.0 Keras model with DenseFeatures as input", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux-4.14.106+-x86_64-with-debian-buster-sid\r\n- TensorFlow installed from (source or binary): pip install\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.6.6\r\n\r\n**Describe the current behavior**\r\nI am trying to train a model using:\r\n* TF 2.0 Keras functional API\r\n* Feature columns and `DenseFeatures` as the input layer\r\n* tf.data.Dataset API as the `x` parameter in model.fit()\r\n\r\nThis raises a ValueError, and I'm not sure why because this doesn't work even with (what I think is) a minimal example. I suspect that this might be due to TF trying to match the feature columns to the inputs by name, but the name of the Input tensor contains a suffix e.g. `age:0`, but I may very well be mistaken.\r\n\r\nMight be related to: https://github.com/tensorflow/tensorflow/issues/30143\r\n\r\n**Describe the expected behavior**\r\nI expect to be able to train a model using the Keras functional API using data from the Dataset API, with feature_columns being fed into Input layers.\r\n\r\n**Code to reproduce the issue**\r\nThe following test case does not represent my use case, but it does reproduce the problem. Despite what the simplistic example suggests, I explicitly require both feature_columns and the functional API so suggesting that I use other TF libraries would not be an option, unless I can replicate the same functionality with minimal effort.\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tensorflow.keras.layers import DenseFeatures, Dense, Input\r\n\r\ndef make_model(features):\r\n    feature_columns = [tf.feature_column.numeric_column(key) for key in features]\r\n    nn_input = {key: Input(name=key, shape=(), dtype=tf.float32) for key in features}\r\n\r\n    feat = DenseFeatures(feature_columns)(nn_input)\r\n    dense = Dense(16)(feat)\r\n    output = Dense(1)(dense)\r\n    model = tf.keras.Model(inputs=nn_input, outputs=output)\r\n    model.compile(\r\n        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\r\n        loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\r\n        metrics=[tf.keras.metrics.AUC()],\r\n    )\r\n    return model\r\n\r\nfeatures = [\"age\", \"income\"]\r\nlabel = \"is_male\"\r\n\r\ninput_dataset = tf.data.Dataset.from_tensor_slices(\r\n    {key: np.ones((1000, 1), dtype=np.float) for key in features}\r\n)\r\ntarget_dataset = tf.data.Dataset.from_tensor_slices(\r\n    {label: np.ones((1000, 1), dtype=np.int)}\r\n)\r\ncomplete_dataset = tf.data.Dataset.zip((input_dataset, target_dataset)).shuffle(10000)\r\n\r\nmodel = make_model(features)\r\nmodel.summary()\r\nmodel.fit(complete_dataset)\r\n```\r\n\r\nThis code references the issue created by @durandg12. Thank you.\r\n\r\n**Stack trace**\r\n```bash\r\n---------------------------------------------------------------------------\r\nKeyError                                  Traceback (most recent call last)\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix)\r\n    498           if data[x].__class__.__name__ == 'DataFrame' else data[x]\r\n--> 499           for x in names\r\n    500       ]\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py in <listcomp>(.0)\r\n    498           if data[x].__class__.__name__ == 'DataFrame' else data[x]\r\n--> 499           for x in names\r\n    500       ]\r\n\r\nKeyError: 'dense_1'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-1-0081a84113eb> in <module>\r\n     27 model = make_model(features)\r\n     28 model.summary()\r\n---> 29 model.fit(complete_dataset)\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    726         max_queue_size=max_queue_size,\r\n    727         workers=workers,\r\n--> 728         use_multiprocessing=use_multiprocessing)\r\n    729 \r\n    730   def evaluate(self,\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\r\n    322                 mode=ModeKeys.TRAIN,\r\n    323                 training_context=training_context,\r\n--> 324                 total_epochs=epochs)\r\n    325             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)\r\n    326 \r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\r\n    121         step=step, mode=mode, size=current_batch_size) as batch_logs:\r\n    122       try:\r\n--> 123         batch_outs = execution_function(iterator)\r\n    124       except (StopIteration, errors.OutOfRangeError):\r\n    125         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in execution_function(input_fn)\r\n     84     # `numpy` translates Tensors to values in Eager mode.\r\n     85     return nest.map_structure(_non_none_constant_value,\r\n---> 86                               distributed_function(input_fn))\r\n     87 \r\n     88   return execution_function\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    455 \r\n    456     tracing_count = self._get_tracing_count()\r\n--> 457     result = self._call(*args, **kwds)\r\n    458     if tracing_count == self._get_tracing_count():\r\n    459       self._call_counter.called_without_tracing()\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    501       # This is the first call of __call__, so we have to initialize.\r\n    502       initializer_map = object_identity.ObjectIdentityDictionary()\r\n--> 503       self._initialize(args, kwds, add_initializers_to=initializer_map)\r\n    504     finally:\r\n    505       # At this point we know that the initialization is complete (or less\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)\r\n    406     self._concrete_stateful_fn = (\r\n    407         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n--> 408             *args, **kwds))\r\n    409 \r\n    410     def invalid_creator_scope(*unused_args, **unused_kwds):\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n   1846     if self.input_signature:\r\n   1847       args, kwargs = None, None\r\n-> 1848     graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n   1849     return graph_function\r\n   1850 \r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   2148         graph_function = self._function_cache.primary.get(cache_key, None)\r\n   2149         if graph_function is None:\r\n-> 2150           graph_function = self._create_graph_function(args, kwargs)\r\n   2151           self._function_cache.primary[cache_key] = graph_function\r\n   2152         return graph_function, args, kwargs\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   2039             arg_names=arg_names,\r\n   2040             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 2041             capture_by_value=self._capture_by_value),\r\n   2042         self._function_attributes,\r\n   2043         # Tell the ConcreteFunction to clean up its graph once it goes out of\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    913                                           converted_func)\r\n    914 \r\n--> 915       func_outputs = python_func(*func_args, **func_kwargs)\r\n    916 \r\n    917       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py in wrapped_fn(*args, **kwds)\r\n    356         # __wrapped__ allows AutoGraph to swap in a converted function. We give\r\n    357         # the function a weak reference to itself to avoid a reference cycle.\r\n--> 358         return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    359     weak_wrapped_fn = weakref.ref(wrapped_fn)\r\n    360 \r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in distributed_function(input_iterator)\r\n     71     strategy = distribution_strategy_context.get_strategy()\r\n     72     outputs = strategy.experimental_run_v2(\r\n---> 73         per_replica_function, args=(model, x, y, sample_weights))\r\n     74     # Out of PerReplica outputs reduce or pick values to return.\r\n     75     all_outputs = dist_utils.unwrap_output_dict(\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py in experimental_run_v2(self, fn, args, kwargs)\r\n    758       fn = autograph.tf_convert(fn, ag_ctx.control_status_ctx(),\r\n    759                                 convert_by_default=False)\r\n--> 760       return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    761 \r\n    762   def reduce(self, reduce_op, value, axis):\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py in call_for_each_replica(self, fn, args, kwargs)\r\n   1785       kwargs = {}\r\n   1786     with self._container_strategy().scope():\r\n-> 1787       return self._call_for_each_replica(fn, args, kwargs)\r\n   1788 \r\n   1789   def _call_for_each_replica(self, fn, args, kwargs):\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py in _call_for_each_replica(self, fn, args, kwargs)\r\n   2130         self._container_strategy(),\r\n   2131         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\r\n-> 2132       return fn(*args, **kwargs)\r\n   2133 \r\n   2134   def _reduce_to(self, reduce_op, value, destinations):\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py in wrapper(*args, **kwargs)\r\n    290   def wrapper(*args, **kwargs):\r\n    291     with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\r\n--> 292       return func(*args, **kwargs)\r\n    293 \r\n    294   if inspect.isfunction(func) or inspect.ismethod(func):\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in train_on_batch(model, x, y, sample_weight, class_weight, reset_metrics)\r\n    251   x, y, sample_weights = model._standardize_user_data(\r\n    252       x, y, sample_weight=sample_weight, class_weight=class_weight,\r\n--> 253       extract_tensors_from_dataset=True)\r\n    254   batch_size = array_ops.shape(nest.flatten(x, expand_composites=True)[0])[0]\r\n    255   # If `model._distribution_strategy` is True, then we are in a replica context\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\r\n   2517           shapes=None,\r\n   2518           check_batch_axis=False,  # Don't enforce the batch size.\r\n-> 2519           exception_prefix='target')\r\n   2520 \r\n   2521       # Generate sample-wise weight values given the `sample_weight` and\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix)\r\n    501     except KeyError as e:\r\n    502       raise ValueError('No data provided for \"' + e.args[0] + '\". Need data '\r\n--> 503                        'for each key in: ' + str(names))\r\n    504   elif isinstance(data, (list, tuple)):\r\n    505     if isinstance(data[0], (list, tuple)):\r\n\r\nValueError: No data provided for \"dense_1\". Need data for each key in: ['dense_1']\r\n```\r\n", "comments": ["I've also borrowed code from [this medium tutorial](https://towardsdatascience.com/how-to-build-a-wide-and-deep-model-using-keras-in-tensorflow-2-0-2f7a236b5a4b), and it works up till the point of `model.compile()` but it fails when I try to run `model.fit()`. I suspect the format which the data is being passed to the fit function may be incorrect but I'm not too sure why.\r\n\r\nAny help here would be deeply appreciated. Thanks! ", "Simply calling the model on some inputs works:\r\n```\r\nfor x, y in complete_dataset.take(1):\r\n    pass\r\nmodel(x) \r\n```", "Your issue is not tied to feature columns nor the DenseFeatures layers, as this code reproduce your error:\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tensorflow.keras.layers import Dense, Input\r\n\r\ndef make_model(features):\r\n    nn_input = {key: Input(name=key, shape=(1), dtype=tf.float32) for key in features}\r\n    \r\n    dense = Dense(16, name='dense1')(nn_input['age'])\r\n    output = Dense(1, name='dense2')(dense)\r\n    model = tf.keras.Model(inputs=nn_input, outputs=output)\r\n    model.compile(\r\n        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\r\n        loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\r\n    )\r\n    return model\r\n\r\nfeatures = [\"age\"]\r\nlabel = \"is_male\"\r\n\r\ninput_dataset = tf.data.Dataset.from_tensor_slices(\r\n    {key: np.ones((1000, 1), dtype=np.float) for key in features}\r\n)\r\ntarget_dataset = tf.data.Dataset.from_tensor_slices(\r\n    {label: np.ones((1000, 1), dtype=np.int)}\r\n)\r\ncomplete_dataset = tf.data.Dataset.zip((input_dataset, target_dataset)).shuffle(10000)\r\n\r\nmodel = make_model(features)\r\nmodel.summary()\r\nmodel.fit(complete_dataset)\r\n```", "I have found the cause of your issue, it is because you feed target data as a dict instead of just a numpy array. If you feed a dict, the key of the dict must not be `label` but must be the name of the layer outputting your prediction, in this case, `dense_1`, so the two following modifications of your code work:\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tensorflow.keras.layers import DenseFeatures, Dense, Input\r\n\r\ndef make_model(features):\r\n    feature_columns = [tf.feature_column.numeric_column(key) for key in features]\r\n    nn_input = {key: Input(name=key, shape=(), dtype=tf.float32) for key in features}\r\n\r\n    feat = DenseFeatures(feature_columns)(nn_input)\r\n    dense = Dense(16)(feat)\r\n    output = Dense(1)(dense)\r\n    model = tf.keras.Model(inputs=nn_input, outputs=output)\r\n    model.compile(\r\n        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\r\n        loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\r\n        metrics=[],\r\n    )\r\n    return model\r\n\r\nfeatures = [\"age\", \"income\"]\r\nlabel = \"is_male\"\r\n\r\ninput_dataset = tf.data.Dataset.from_tensor_slices(\r\n    {key: np.ones((1000, 1), dtype=np.float) for key in features}\r\n)\r\ntarget_dataset = tf.data.Dataset.from_tensor_slices(\r\n    np.ones((1000, 1), dtype=np.int)\r\n)\r\ncomplete_dataset = tf.data.Dataset.zip((input_dataset, target_dataset)).shuffle(10000)\r\n\r\nmodel = make_model(features)\r\nmodel.summary()\r\nmodel.fit(complete_dataset)\r\n```\r\nor \r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tensorflow.keras.layers import DenseFeatures, Dense, Input\r\n\r\ndef make_model(features):\r\n    feature_columns = [tf.feature_column.numeric_column(key) for key in features]\r\n    nn_input = {key: Input(name=key, shape=(), dtype=tf.float32) for key in features}\r\n\r\n    feat = DenseFeatures(feature_columns)(nn_input)\r\n    dense = Dense(16)(feat)\r\n    output = Dense(1)(dense)\r\n    model = tf.keras.Model(inputs=nn_input, outputs=output)\r\n    model.compile(\r\n        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\r\n        loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\r\n        metrics=[],\r\n    )\r\n    return model\r\n\r\nfeatures = [\"age\", \"income\"]\r\nlabel = \"is_male\"\r\n\r\ninput_dataset = tf.data.Dataset.from_tensor_slices(\r\n    {key: np.ones((1000, 1), dtype=np.float) for key in features}\r\n)\r\ntarget_dataset = tf.data.Dataset.from_tensor_slices(\r\n    {'dense_1': np.ones((1000, 1), dtype=np.int)}\r\n)\r\ncomplete_dataset = tf.data.Dataset.zip((input_dataset, target_dataset)).shuffle(10000)\r\n\r\nmodel = make_model(features)\r\nmodel.summary()\r\nmodel.fit(complete_dataset)\r\n```\r\nIn the first I have replaced the dict by a numpy array, in the second I have changed the key of the dict.\r\nIn both modifications I have removed the metric as it caused another error.", "@durandg12 thank you, this works really well. I think the reason why there was an error calculating the AUC was that all of the target values were of the same class.\r\n\r\nOn a side note, is it intended behaviour for tensorflow to raise an exception when the final layer is not named according to the output tensors? Or does tensorflow only accept target inputs where the target is a list, instead of a dictionary of tensors as you would expect of the feature inputs?", "@thisisandreeeee Is this resolved. If this was resolved already, please close the issue. Thanks!"]}, {"number": 35150, "title": "SavedModelBundle.getSignatures() does not return outputs in correct order.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.1.0.rc0\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: Not relevant\r\n- GPU model and memory: Not relevant\r\n\r\n**Describe the current behavior**\r\nLoading a SavedModel in C++, the outputs (and probably also inputs, but I do not have models with multiple inputs) from the signature are returned in a random order, which then causes the network to fail when used for inference.\r\n\r\n**Describe the expected behavior**\r\nThe outputs (and probably inputs) should be returned in the correct order.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nstd::string model_dir = \"/path/to/my_model\";\r\nstd::vector<string> input_names;\r\nstd::vector<string> output_names;\r\ntensorflow::SavedModelBundleLite bundle; // Same with SavedModelBundle\r\n\r\n// Create default options.\r\ntensorflow::SessionOptions session_options;\r\ntensorflow::RunOptions run_options;\r\n\r\n// Load model.\r\nauto status = tensorflow::LoadSavedModel(\r\n\tsession_options,\r\n\trun_options,\r\n\tmodel_dir,\r\n\t{tensorflow::kSavedModelTagServe},\r\n\t&bundle\r\n);\r\n\r\n// Check if model has been loaded correctly.\r\nif (!status.ok()) {\r\n\tstd::cerr << status.ToString() << std::endl;\r\n\treturn;\r\n}\r\n\r\n// Get model signature.\r\nauto signatures = bundle.GetSignatures();\r\nif (!signatures.contains(\"serving_default\")) {\r\n\tstd::cerr << \"Could not find serving_default in model signatures.\" << std::endl;\r\n\treturn;\r\n}\r\n\r\n// Get the inputs names.\r\nfor (auto const & input : signatures.at(\"serving_default\").inputs()) {\r\n\tinput_names.push_back(input.second.name());\r\n}\r\n\r\n// Get the outputs names.\r\nfor (auto const & output : signatures.at(\"serving_default\").outputs()) {\r\n\toutput_names.push_back(output.second.name());\r\n}\r\nstd::vector<tensorflow::Tensor>  inputs = getMyInputs();  // Some compatible input vector.\r\nstd::vector<tensorflow::Tensor>  outputs;\r\n\r\n// Create a vector of pairs for associating inputs to their names.\r\nstd::vector<std::pair<std::string, tensorflow::Tensor>> input_pairs;\r\nfor (std::size_t i = 0; i < inputs.size(); ++i) {\r\n\tinput_pairs.push_back({input_names.at(i), inputs.at(i)});\r\n}\r\n\r\n// Run the network.\r\nbundle.GetSession()->Run(\r\n\tinput_pairs,\r\n\toutput_names,\r\n\t{},\r\n\t&outputs\r\n);\r\n```\r\n\r\nWhen running this the output order changes, giving a mismatch error (eg. `Check failed: dtype() == expected_dtype (3 vs. 1) float expected, got int32`) after calling `Run`. \r\n\r\n\r\n", "comments": ["Bump?", "Any news on this?", "Bump?", "@vcarpani We see that you are using older version of tensorflow .Many bug have been fixed in latest version. We recommend that you upgrade to latest stable version of tensorflow 2.6.0 and let us know if the issue still persists in newer versions .Thanks!", "Hello @sushreebarsa, I have changed my implementation, so I am not using this function anymore, closing the issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35150\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35150\">No</a>\n"]}, {"number": 35149, "title": "TensorFlow Serving cannot handle more than 350 requests/second", "body": "Docker Image: Tensorflow/Serving:latest\r\nModel: Fashion_Mnist (per the official Docs)\r\nDocker Version: 19.03.2, build 6a30dfc\r\n\r\nI'm using Docker Container to serve a Tensorflow SavedModel over the REST API Port 8501. The inference latency is 2ms which is great. \r\n\r\nProblem: I'm trying to perform load-testing and notice that the rate of requests stay constant at approximately 350 requests/sec. Beyond which the request fails. Every request has a single batch payload. \r\n\r\nObservation: At the point of failure, the resource usage is only 10%. Server throws error code 404 and 401.\r\n\r\nTroubleshooting: \r\n1. Have tried running `tensorflow_model_server` directly instead of the docker image and face the same issue. \r\n2. Have served different models (deep_mnist, custom models). Same issue persists.\r\n3. Built a docker image with suitable instruction set. Same issue persists.\r\n4. Deployed the Docker image on a K8 cluster. Set 4 Replicas behind a loadbalancer. Same issue persists. \r\n5. Pulled different tensorflow/serving image. Same issue persists. \r\n\r\nWhat have I been doing wrong?", "comments": ["@roshanzameer Duplicate of this [issue ](https://github.com/tensorflow/serving/issues/1517) in tensorflow serving. I am gonna close this issue as it is a seving issue and is being tracked there. Thanks!"]}, {"number": 35148, "title": "Reading checkpoint file fail will ignore all checkpoints", "body": "When restoring a checkpoint, if it read checkpoint file fail then all checkpoints will be ignored and train from scratch. I think it should throw exception rather than ignore, otherwise it will train from scratch silently. Especially read fail could happen when using distributed storage.\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/1125780/70891780-ea4b4600-2022-11ea-9ae0-fcf4572b1997.png)\r\n\r\nLink to the code:\r\nhttps://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/training/checkpoint_management.py#L287", "comments": ["I'd just check whether <dir>/checkpoint exists. If it does and that function returns None, you can throw an exception. Otherwise you can use the parsed proto.\r\n\r\nThrowing new exceptions here isn't backward compatible."]}, {"number": 35147, "title": "Size not changed when convert pb file to tflite file", "body": "I tried to convert my quantized pb file to tflite file. \r\nMy code is:\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow import lite\r\nFLAGS = tf.app.flags.FLAGS\r\ninputs=[\"input_images\"]\r\noutputs=[\"output_1\"]\r\nconverter = lite.TFLiteConverter.from_frozen_graph(\r\n    graph_def_file='./q/te.pb',\r\n    input_arrays=inputs,\r\n    output_arrays=outputs\r\n)\r\n#converter.post_training_quantize = False\r\nconverter.inference_input_type = lite.constants.QUANTIZED_UINT8\r\ninput_arrays = converter.get_input_arrays()\r\nconverter.quantized_input_stats = {input_arrays[0]:(0, 255)}\r\nconverter.default_ranges_stats = (0, 255)\r\ntflite_quantized_model = converter.convert()\r\nwith open('te.tflite', 'wb') as f:\r\n    f.write(tflite_quantized_model)\r\n\r\nThe pb was frozen by a model that had already been quantized by \"create_training_graph\" and \"create_eval_graph\". The size of my pb file is 83.45MB and the size of my tflite file is 83.15MB. How can I sovle this problem? I just want to quantize my pb file and get a smaller size file.", "comments": ["You may try full integer quantization of weights and activations to reduce your file size.\r\n```python\r\nconverter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\r\n```\r\nSee https://www.tensorflow.org/lite/convert/quantization\r\nhttps://www.tensorflow.org/lite/performance/post_training_quant#optimizing_an_existing_model"]}, {"number": 35146, "title": "Missing information when saving model in tf format", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): Binary (pip)\r\n- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d382ca 2.0.0\r\n- Python version: Python 3.6.8\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: CUDA 10.0.130_411.31; cuDNN 10.0 v7.6.5.32\r\n- GPU model and memory: NVIDIA Quadro P2000, 4 GB\r\n\r\n**Describe the current behavior**\r\nWhen the model is saved in the default tf format, warnings are logged when trying to serve the model.\r\n\r\nExamplary warning logs:\r\n```\r\nWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x000001ED79058730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\r\n```\r\n\r\nWhen the model is saved in the hdf5 format, the warnings do not occur.\r\n\r\n**Describe the expected behavior**\r\nThe save formats should be equivalent and behave in the same way.\r\n\r\n**Code to reproduce the issue**\r\nExecute the following scripts to create and serve model\r\n1. Run the first script with `format_ext = ''` which saves the model in tf format, **restart the Python console**, serve the model with the second script which creates the aforementioned warnings.\r\n1. When running the scripts with `format_ext = '.h5'`, the model is saved in hdf5 format and no warnings appear.\r\n\r\nModel creation:\r\n```python\r\nimport os\r\n\r\nimport tensorflow as tf\r\n\r\nformat_ext = ''  # '.h5' or empty for tf format\r\nmodel_path = os.path.join('out', 'mnist-classifier{}'.format(format_ext))\r\n\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\n\r\ntf.config.experimental.set_virtual_device_configuration(\r\n    gpus[0],\r\n    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=512),\r\n     tf.config.experimental.VirtualDeviceConfiguration(memory_limit=512),\r\n     tf.config.experimental.VirtualDeviceConfiguration(memory_limit=512)]\r\n)\r\n\r\nstrategy = tf.distribute.MirroredStrategy()\r\nwith strategy.scope():\r\n    inputs = tf.keras.Input(shape=(784,), name='digits')\r\n    x = tf.keras.layers.Dense(64, activation='relu', name='dense_1')(inputs)\r\n    x = tf.keras.layers.Dense(64, activation='relu', name='dense_2')(x)\r\n    outputs = tf.keras.layers.Dense(10, activation='softmax', name='predictions')(x)\r\n\r\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\r\n\r\n    model.compile(optimizer=tf.keras.optimizers.RMSprop(),  # Optimizer\r\n                  # Loss function to minimize\r\n                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\r\n                  # List of metrics to monitor\r\n                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\r\n\r\nmodel.save(model_path)\r\n```\r\n\r\nModel serving:\r\n```python\r\nimport os\r\n\r\nimport tensorflow as tf\r\n\r\nformat_ext = ''  # '.h5' or empty for tf format\r\nmodel_path = os.path.join('out', 'mnist-classifier{}'.format(format_ext))\r\n\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\n\r\ntf.config.experimental.set_virtual_device_configuration(\r\n    gpus[0],\r\n    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=512),\r\n     tf.config.experimental.VirtualDeviceConfiguration(memory_limit=512),\r\n     tf.config.experimental.VirtualDeviceConfiguration(memory_limit=512)]\r\n)\r\n\r\n(_, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\r\nx_test = x_test.reshape(10000, 784).astype('float32') / 255\r\n\r\nstrategy = tf.distribute.MirroredStrategy()\r\nwith strategy.scope():\r\n    loaded_model = tf.keras.models.load_model(model_path)\r\n    predictions = loaded_model.predict(x_test, batch_size=64)\r\n```\r\n\r\n**Other info / logs**\r\nThe warnings occur only if more than two vGPUs are used.", "comments": ["I could replicate the issue with Tf 2.0 on colab.\r\nPlease find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/c7b1b254f5ada8b480ec6125804f4d22/untitled310.ipynb). Thanks!", "@stekiri Can you please try with `TF2.1` and `tf-nightly`. When I ran it in colab, I am seeing different warning as follows. Thanks!\r\n\r\n```\r\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\r\n11493376/11490434 [==============================] - 0s 0us/step\r\nWARNING:tensorflow:NCCL is not supported when using virtual GPUs, fallingback to reduction to one device\r\nINFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n```\r\n", "With TF 2.1 the warning I mentioned does not appear for above script, however, if I use four virtual GPUs (in the serving script) instead of three, the warning is displayed again.\r\n\r\nYou can reproduce it with the following virtual device config:\r\n```\r\ntf.config.experimental.set_virtual_device_configuration(\r\n    gpus[0],\r\n    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=512),\r\n     tf.config.experimental.VirtualDeviceConfiguration(memory_limit=512),\r\n     tf.config.experimental.VirtualDeviceConfiguration(memory_limit=512),\r\n     tf.config.experimental.VirtualDeviceConfiguration(memory_limit=512)]\r\n)\r\n```", "@stekiri I cannot reproduce that warning. When I modify as you mentioned above, i get `RuntimeError` as follows. Please check the [gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/c8c16624491e1c0dbd48f4b12b767d21/untitled758.ipynb). Thanks!\r\n\r\n> RuntimeError                              Traceback (most recent call last)\r\n> <ipython-input-3-46b1744a240a> in <module>()\r\n>       9      tf.config.experimental.VirtualDeviceConfiguration(memory_limit=512),\r\n>      10      tf.config.experimental.VirtualDeviceConfiguration(memory_limit=512),\r\n> ---> 11      tf.config.experimental.VirtualDeviceConfiguration(memory_limit=512)]\r\n>      12 )\r\n>      13 \r\n> \r\n> 1 frames\r\n> /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/context.py in set_logical_device_configuration(self, dev, virtual_devices)\r\n>    1300     if self._context_handle is not None:\r\n>    1301       raise RuntimeError(\r\n> -> 1302           \"Virtual devices cannot be modified after being initialized\")\r\n>    1303 \r\n>    1304     self._virtual_device_map[dev] = virtual_devices\r\n> \r\n> RuntimeError: Virtual devices cannot be modified after being initialized", "You would need to restart the runtime in between running the save and load script as it's not possible to change virtual devices once they have been initialized.", "@stekiri I ran first part of your code and restarted runtime and ran second part of your code. I cannot reproduce the issue when I used recent `tf-nightly`. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/ab648c68555590549d566fb4a4d08703/untitled38.ipynb).\r\n\r\nCan you please check once and close the issue if this was resolved for you? Thanks!", "It seems to be resolved. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35146\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35146\">No</a>\n", "![image](https://user-images.githubusercontent.com/4510984/109937109-9735df80-7d09-11eb-98e7-367f4025afa3.png)\r\n\r\n![image](https://user-images.githubusercontent.com/4510984/109937184-9bfa9380-7d09-11eb-9bc7-05db57081e23.png)\r\n", "@GF-Huang Can you please open a new issue with a standalone code to reproduce the issue? thanks!", "> @GF-Huang Can you please open a new issue with a standalone code to reproduce the issue? thanks!\r\n\r\n#47554"]}, {"number": 35145, "title": " How to package My MFCC modules ", "body": "@tensorflow/micro\r\nI want to package the MFCC into my model tflite. like this(tensorflow/lite/android/conv_actions_frozen.tflite)\r\nBut I build my own keras layer. And conert to tflite.The Model is a mess where the MFCC func.Why ?", "comments": ["Hello, please answer the following questions and if possible, provide code to re-produce the results.\r\n\r\n-  Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n- Code, if any, to reproduce the results (eg: links to github repo, colab or jupyter notebook, etc)", "Closing the issue as we have not received a response. Re-open and provide more information to help us debug the issue."]}, {"number": 35144, "title": "Low performance in TF2.x Distributed Mirrored Strategy with 4 V100 GPUs", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 18.04.3 LTS\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0\r\n- Python version: Python 3.6.8\r\n- CUDA/cuDNN version: Driver Version: 440.33.01, CUDA Version: 10.2, cuDNN 7.6.2\r\n- GPU model and memory: Tesla V100-SXM2-16GB\r\n\r\n**Describe the current behavior**\r\nWith 4 V100 GPUs in Distributed Mirrored GPU Strategy training single step is around 3x slower than with single V100 GPU.\r\n\r\n**Describe the expected behavior**\r\nSingle step should be less than 2x slower.\r\n\r\n**Code to reproduce the issue**\r\nTraining loop (hierarchical VAE in the current configuration):\r\n  https://github.com/olegmyrk/SPADE-Tensorflow/blob/9c1ced5b7b24640aeb7726169e215f5e63d971d3/SPADE.py#L1121\r\n\r\nThe code is adapted from TF1.x repository:\r\n  https://github.com/olegmyrk/SPADE-Tensorflow/blob/8866a0b1457cbd4be5d6f549f9bf4075d49b2486/SPADE.py#L1045\r\nand is compiled using TF2.x @tf.function annotation.\r\n\r\nIt uses a dry-run of the model to pre-create variables using tf.compat.v1.variable_scope(scope, reuse=tf.compat.v1.AUTO_REUSE):\r\n  https://github.com/olegmyrk/SPADE-Tensorflow/blob/9c1ced5b7b24640aeb7726169e215f5e63d971d3/SPADE.py#L1144\r\nand then runs the actual training step(s)\r\n  https://github.com/olegmyrk/SPADE-Tensorflow/blob/9c1ced5b7b24640aeb7726169e215f5e63d971d3/SPADE.py#L1180\r\n\r\nThe total number of mirrored parameters is around 500MB.\r\n\r\nWith 4 V100 GPUs training step is around 3x slower than with single V100 GPU.\r\n\r\nCommand:\r\nnohup python3 main.py --dataset CelebAMask-HQ --img_height 256 --img_width 256 --ch 16 --img_ch 3 --phase train --save_freq 10000 --batch_size 18 --gan_type hinge --code_gan_type gan --n_critic 1 --code_num_layers=4 --code_dist_num_layers=0 --sn=False --train_main=true --train_nondet=false --lr 0.0002 --print_freq 100 &> train.CelebAMask-HQ.log &\r\n\r\n**Other info / logs**\r\n\r\nWith CUDA_VISIBLE_DEVICES=0\r\n* Startup time: ~9 min\r\n* GPU utilization: ~90%\r\n* Training step: 0.7 seconds\r\n* Log file: train.CelebAMask-HQ.1xgpu.log\r\n \r\nWith CUDA_VISIBLE_DEVICES=0,1,2,3\r\n* Startup time: ~30min\r\n  * Build variables (dry run): ~10min\r\n  * Build model: ~20min\r\n* GPU utilization: ~50%\r\n* Training step: 2 seconds\r\n* Log file: train.CelebAMask-HQ.4xgpu.log\r\n[train.CelebAMask-HQ.1xgpu.log](https://github.com/tensorflow/tensorflow/files/3965889/train.CelebAMask-HQ.1xgpu.log)\r\n[train.CelebAMask-HQ.4xgpu.log](https://github.com/tensorflow/tensorflow/files/3965890/train.CelebAMask-HQ.4xgpu.log)\r\n\r\n", "comments": ["Attaching some more logs:\r\n* CPU load is low enough so I don't think loading & feeding training data is an issue\r\n[cpu.log](https://github.com/tensorflow/tensorflow/files/3970649/cpu.log)\r\n* Typical GPU utilization: pretty low\r\n[nvidia-smi.log](https://github.com/tensorflow/tensorflow/files/3970636/nvidia-smi.log)\r\n* Typical NVLINK utilization: it looks that NVLINK is not used at all?\r\n[nvidia-smi-nvlink.log](https://github.com/tensorflow/tensorflow/files/3970646/nvidia-smi-nvlink.log)\r\n", "I've rerun the script using\r\n`NCCL_DEBUG=INFO NCCL_DEBUG_SUBSYS=ALL CUDA_VISIBLE_DEVICES=0,1,2,3`\r\n\r\nAttaching the NCCL logs\r\n[train.CelebAMask-HQ.4xgpu.nvlink.log](https://github.com/tensorflow/tensorflow/files/3970968/train.CelebAMask-HQ.4xgpu.nvlink.log)\r\n\r\nTo the extent I can read NCCL logs it seems that it should be working fine?\r\n```ip-172-31-78-131:88250:88431 [0] NCCL INFO NET/Socket : Using [0]ens3:172.31.78.131<0>\r\nip-172-31-78-131:88250:88431 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\r\nip-172-31-78-131:88250:88845 [0] NCCL INFO Setting affinity for GPU 0 to ffffffff\r\n...\r\nip-172-31-78-131:88250:88842 [3] NCCL INFO Channel 00 :    0   1   2   3\r\n...\r\nip-172-31-78-131:88250:88844 [1] NCCL INFO Ring 00 : 2[1] -> 3[0] via P2P/direct pointer\r\n...\r\nip-172-31-78-131:88250:88842 [3] NCCL INFO Using 256 threads, Min Comp Cap 7, Trees disabled\r\nip-172-31-78-131:88250:88845 [0] NCCL INFO comm 0x7f7628001850 rank 3 nranks 4 cudaDev 0 nvmlDev 0 - Init COMPLETE\r\n...\r\nip-172-31-78-131:88250:88837 [3] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f7956f63600 recvbuff 0x7f7956f63600 count 47422082 datatype 7 op 0 root 0 comm 0x7f762c0021a0 [nranks=4] stream 0x7f8b24007490\r\n...\r\nip-172-31-78-131:88250:88837 [3] NCCL INFO Launch mode Group/CGMD\r\n...```", "There is a perf regression w.r.t. prefetching data for mirrored strategy in 2.0 that is fixed later. Could you try nightly or 2.1-rc0?", "Switching to 2.1-rc0 helped with training step time, thanks!\r\n\r\nHowever it takes 3x longer to build models in multi-GPU setup: less than 10minutes on single GPU vs 30 minutes 4 GPUs. In both cases I am using the same code with Mirrored strategy.\r\n\r\nAdditionally enabling spectral normalization\r\nhttps://github.com/olegmyrk/SPADE-Tensorflow/blob/4203f30b6253a9d4743962087896fab26381c67b/ops.py#L579\r\nincreases the time to build models another 2x (60 minutes on 4 gpus), increases the training step duration 3x, and also seems to increase GPU memory required, effectively reducing the batch size. This happens only when multiple GPUs are enabled.\r\n\r\nSpectral normalization implementation does unnecessary synchronization of non-trainable, but deterministic (as a function of initialization and weights being normalized) variable:\r\n`u = tf.compat.v1.get_variable(\"u\", [1, w_shape[-1]], initializer=tf.compat.v1.random_normal_initializer(), trainable=False, aggregation=tf.VariableAggregation. ONLY_FIRST_REPLICA)`\r\nIs there a way to avoid this unnecessary synchronization?", "FYI: I've filed a separate follow-up issue:\r\n\r\nAutoGraph is compiled 5x slower in TF2.x Multi-GPU Distributed Mirrored Strategy\r\nhttps://github.com/tensorflow/tensorflow/issues/35346", "Also is there a better channel to ask about issues with Spectral Normalization in Mirrored Distributed mode?\r\nhttps://github.com/olegmyrk/SPADE-Tensorflow/blob/4203f30b6253a9d4743962087896fab26381c67b/ops.py#L579\r\n\r\nEssentially I need to convince TF Mirrored Distributed mode not to synchronize this variable across GPUs:\r\n```\r\nu = tf.compat.v1.get_variable(\"u\", [1, w_shape[-1]], initializer=tf.compat.v1.random_normal_initializer(), trainable=False, aggregation=tf.VariableAggregation. ONLY_FIRST_REPLICA)\r\n```", "> Essentially I need to convince TF Mirrored Distributed mode not to synchronize this variable across GPUs:\r\n>\r\n> ``u = tf.compat.v1.get_variable(\"u\", [1, w_shape[-1]], initializer=tf.compat.v1.random_normal_initializer(), trainable=False, aggregation=tf.VariableAggregation. ONLY_FIRST_REPLICA)``\r\n\r\nIf you are using tf.VariableAggregation.ONLY_FIRST_REPLICA then it is expected.", "I've posted more details about variable replication for spectral norm in a separate issue.\r\nhttps://github.com/tensorflow/tensorflow/issues/35347\r\n", "As the initial distributed dataset performance regression in 2.0 was resolved by @byronyi I propose that we close this issue. \r\n\r\nPlease have a look at followup issues:\r\nhttps://github.com/tensorflow/tensorflow/issues/35346\r\nhttps://github.com/tensorflow/tensorflow/issues/35347", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35144\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35144\">No</a>\n"]}, {"number": 35143, "title": "micro_speech example inference issue", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution\r\n      Answer: Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary):\r\n     Answer: source\r\n- Tensorflow version (commit SHA if source):\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):\r\n    Answer: x86\r\n**Describe the problem**\r\n   I build the x86 version of micro_speech example, run it with the g_yes_1000ms_sample_data file, but the result is \"Heard silence (0)\", it should be \"yes\"\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n   1. mkdir x86 under micro/examples/micro_speech directory\r\n   2. in the x86 folder, add \"command_responder.cc\":\r\nvoid RespondToCommand(tflite::ErrorReporter* error_reporter,\r\n                      int32_t current_time, const char* found_command,\r\n                      uint8_t score, bool is_new_command) {\r\n  //if (is_new_command) {\r\n    error_reporter->Report(\"Heard %s (%d) @%dms\", found_command, score,\r\n                           current_time);\r\n    sleep(2);\r\n  //}\r\n}\r\n   3. in the x86 folder, add audio_provider.cc:\r\nTfLiteStatus GetAudioSamples(tflite::ErrorReporter* error_reporter,\r\n                             int start_ms, int duration_ms,\r\n                             int* audio_samples_size, int16_t** audio_samples) {\r\n\r\n  const int yes_start = (0 * kAudioSampleFrequency) / 1000;\r\n  const int yes_end = (1000 * kAudioSampleFrequency) / 1000;\r\n  const int wraparound = (1000 * kAudioSampleFrequency) / 1000;\r\n  const int start_sample = (start_ms * kAudioSampleFrequency) / 1000;\r\n  for (int i = 0; i < kMaxAudioSampleSize; ++i) {\r\n    const int sample_index = (start_sample + i) % wraparound;\r\n    int16_t sample;\r\n    sample = g_yes_1000ms_sample_data[sample_index - yes_start];\r\n    g_dummy_audio_data[i] = sample;\r\n  }\r\n  *audio_samples_size = kMaxAudioSampleSize;\r\n  *audio_samples = g_dummy_audio_data;\r\n\r\n  return kTfLiteOk;\r\n}\r\n\r\nint32_t LatestAudioTimestamp()\r\n{\r\n     // This is how we let the outside world know that new audio data has arrived.\r\n     g_latest_audio_timestamp += 1000;\r\n    return g_latest_audio_timestamp;\r\n}\r\n\r\n4. build the example:\r\nmake -f tensorflow/lite/experimental/micro/tools/make/Makefile TARGET=x86 micro_speech\r\n5. run the example:\r\n   [~/tf-20191211/tensorflow-master/tensorflow/lite/experimental/micro/tools/make/gen/x86_x86_64/bin]./micro_speech\r\n   start_ms=40 duration_ms=30\r\n   start_ms=60 duration_ms=30\r\n   start_ms=80 duration_ms=30\r\n ...\r\n   Heard silence (0) @1000ms\r\n\r\nactually, the result is the same when I port this example to my EVB.\r\nBy the way, why the start_ms begin with 40 instead of 0?\r\n\r\nThanks for your support.\r\n\r\nruey-an", "comments": ["I may find the reason.\r\nIt should be caused by setting of RecognizeCommands(), after change the setting as below:\r\n  explicit RecognizeCommands(tflite::ErrorReporter* error_reporter,\r\n                             int32_t average_window_duration_ms = 0,\r\n                             uint8_t detection_threshold = 0,\r\n                             int32_t suppression_ms = 0,\r\n                             int32_t minimum_count = 0);\r\nthe result is correct now.", "@rayeh5,\r\nDid your code run several times correct for the word 'no' for me not, only for 'yes' it is working. \r\nCould you point me where my error is. Tried several Things but believe Audio Input and tensowork isn't in sync.\r\nDid you find the cause?\r\nThanks for any Feedback.\r\n"]}, {"number": 35142, "title": "Building from source: ERROR: kernels:training_ops", "body": "**System information**\r\n- **Linux Ubuntu 18.04**\r\n- TensorFlow installed from (source or binary): **source**\r\n- TensorFlow version: v2 (master)\r\n- Python version: python 3.7.5\r\n- Installed using virtualenv? conda:  conda 4.7.12\r\n- Bazel version (if compiling from source): **bazel 1.1.0**\r\n- GCC/Compiler version (if compiling from source): **gcc 8.3.0**\r\n- CUDA/cuDNN version: **CUDA 10.2/cuDNN7.6.5**\r\n- GPU model and memory: GeForce GTX670 4035Mb\r\n- CPU Intel i7860@2.80GHz\r\n- Kernel  Linux-headers-4.15.0-73\r\n- NVCC -  v2.5.6, for CUDA 10.2, Nov 19,2019\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nIt seems Bazel Build is disregarding my choice of **NOT INSTALLING XLA**.\r\n\r\nI installed CUDA and cuDNN, NCCL, created a python 3.7.5 environment and decided to build tensorflow from MASTER branch since my  GPU has capabilities 3.0 and the other installs I tried, from docker or conda, where complaining about a minimum capability of 3.5.\r\n\r\nThere were plenty of documentation for the need of a build from source for 3.0 capability and I decided to do it. \r\n\r\nFrom git I realized it was necessary to disable XLA. `./configure` asked for **XLA** capabitity and I answered **N** (Y was the default), it correctly detected python, cuda and gcc, I wrote **3.0** for desired capability, (A message showed me the need to disable XLA, what I already did). \r\n\r\nWhen I did the bazel build it took a huge lot of time and seemed to freeze with something like the piece below.\r\n````bash\r\n./tensorflow/compiler/xla/service/hlo_computation.h:562:3: note: in expansion of macro \u2018TF_RET_CHECK\u2019\r\n   TF_RET_CHECK(order.size() == instruction_count());\r\n   ^~~~~~~~~~~~\r\n./tensorflow/compiler/xla/service/hlo_computation.h: In instantiation of \u2018tensorflow::Status xla::HloComputation::AcceptOrdered(xla::DfsHloVisitorBase<HloInstructionPtr>*, absl::Span<xla::HloInstruction* const>) const [with HloInstructionPtr = const xla::HloInstruction*]\u2019:\r\n./tensorflow/compiler/xla/service/hlo_computation.h:588:61:   required from here\r\n./tensorflow/compiler/xla/service/hlo_computation.h:562:29: warning: comparison of integer expressions of different signedness: \u2018absl::Span<xla::HloInstruction* const>::size_type\u2019 {aka \u2018long unsigned int\u2019} and \u2018tensorflow::int64\u2019 {aka \u2018long long int\u2019} [-Wsign-compare]\r\n   TF_RET_CHECK(order.size() == instruction_count());\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro \u2018TF_PREDICT_FALSE\u2019\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/compiler/xla/service/hlo_computation.h:562:3: note: in expansion of macro \u2018TF_RET_CHECK\u2019\r\n   TF_RET_CHECK(order.size() == instruction_count());\r\n   ^~~~~~~~~~~~\r\n./tensorflow/compiler/xla/array.h: In instantiation of \u2018tensorflow::int64 xla::Array<T>::dim(tensorflow::int64) const [with T = int; tensorflow::int64 = long long int]\u2019:\r\n\r\n````\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n````bash \r\nbazel build --config=opt -- config=--local_ram_resources=6000  --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n````\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nThe pieces showing the actual error ocurrered as follows:\r\n````\r\nERROR: /home/lbarosi/Pythonia/tensorflow/tensorflow/core/kernels/BUILD:5735:1: C++ compilation of rule '//tensorflow/core/kernels:training_ops' failed (Exit 1)\r\nx86_64-linux-gnu-gcc-8: fatal error: Killed signal terminated program cc1plus\r\ncompilation terminated.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nERROR: /home/lbarosi/Pythonia/tensorflow/tensorflow/python/tools/BUILD:141:1 C++ compilation of rule '//tensorflow/core/kernels:training_ops' failed (Exit 1)\r\nINFO: Elapsed time: 4520.437s, Critical Path: 1586.97s\r\nINFO: 5492 processes: 5492 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\n````\r\n\r\nAny help is appreciated. I would like to try as much as possible to stick with this configurations without downgradings of CUDA or cuDNN.\r\n", "comments": ["I am having same issue when I try to build Tensorflow 2.3.0 in Jetson Nano using Docker.\r\n```Dockerfile\r\nRUN cd ~ \\\r\n  && git clone --recursive --branch \"v2.3.0-rc0\" https://github.com/tensorflow/tensorflow.git\r\n\r\nRUN cd ~/tensorflow \\\r\n  && PYTHON_BIN_PATH=$(which python3) \\\r\n  PYTHON_LIB_PATH=$(python3 -c 'import site; print(site.getsitepackages()[0])') \\\r\n  TF_NEED_OPENCL_SYCL=0 \\\r\n  TF_NEED_OPENCL=0 \\\r\n  TF_NEED_ROCM=0 \\\r\n  TF_NEED_CUDA=1 \\\r\n  TF_NEED_TENSORRT=1 \\\r\n  TF_CUDA_VERSION=10.2 \\\r\n  TF_TENSORRT_VERSION=7 \\\r\n  CUDA_TOOLKIT_PATH=/usr/local/cuda \\\r\n  CUDNN_INSTALL_PATH=/usr/lib/aarch64-linux-gnu \\\r\n  TENSORRT_INSTALL_PATH=/usr/lib/aarch64-linux-gnu \\\r\n  TF_CUDA_COMPUTE_CAPABILITIES=5.3 \\\r\n  TF_CUDA_CLANG=0 \\\r\n  TF_NEED_IGNITE=0 \\\r\n  TF_ENABLE_XLA=0 \\\r\n  TF_NEED_MPI=0 \\\r\n  GCC_HOST_COMPILER_PATH=$(which gcc) \\\r\n  CC_OPT_FLAGS=\"-march=native\" \\\r\n  TF_SET_ANDROID_WORKSPACE=0 \\\r\n  ./configure \\\r\n  && bazel build --config=opt --config=cuda --config=noaws \\\r\n   --config=nogcp --local_ram_resources=3000 //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\n```\r\nERROR: /root/tensorflow/tensorflow/core/kernels/BUILD:6109:1: C++ compilation of rule '//tensorflow/core/kernels:training_ops' failed (Exit 1)\r\naarch64-linux-gnu-gcc-8: fatal error: Killed signal terminated program cc1plus\r\ncompilation terminated.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n```\r\nAny insights on what the problem is about?", "Your problem is slightly differente @myaldiz. With CUDA capabilities 5.3 you may not need to compile at all, there is still hope for you. Though it seems clear that bazel is actually having problems with options. (Have you tryed enabling XLA to see if it works?)", "@lbarosi did you find a way to make it work with a capability 3.0 GPU? I'm right now in the same position. Noticed that the TF 2.3 configure script doesn't even ask if XLA support is desired.", "Quite a long time to answer, but I gave up. Moving to newer GPU.", "I am closing this issue for lack of support and interest. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35142\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35142\">No</a>\n"]}, {"number": 35141, "title": "tf.where should have optional dtype parameter", "body": "- TensorFlow version (you are using): 2.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n```\r\ntf.keras.backend.floatx = tf.float64\r\nf64 = tf.Variable([0,0.2,0.5,0.7,1], dtype=tf.float64)\r\ntf.where(f64 > 0.5, 1., 0. )\r\n\r\n<tf.Tensor: id=16, shape=(5,), dtype=float32, numpy=array([0., 0., 0., 1., 1.], dtype=float32)>\r\n```\r\n\r\nalternatives for tf.float64 models lead to difficult to read code\r\n\r\n```\r\ntf.where(f64 > 0.5, tf.constant(1., dtype=tf.float64), tf.constant(0., dtype=tf.float64) )\r\ntf.cast(tf.where(f64 > 0.5, 1., 0. ), dtype=tf.float64)\r\n```\r\n\r\nassuming that tf.where can't respect the float type of the input variable nor the floatx setting, as those change the api, better would be:\r\n\r\n```\r\ntf.where(f64 > 0.5, 1., 0. , dtype=tf.float64)\r\n```\r\n\r\n", "comments": ["Hi!  Thanks for the feedback!\r\n\r\nFirst, I believe that in the listed alternatives, only the first of those two is fully correct.  In the second, there could be e.g. loss of precision in the constants if the cast were to be done after the where().\r\n\r\nWhich comes back to the first case -- as float32 is the default for TensorFlow, the version `where(condition, tf.constant(<value>, dtype=tf.float64), ...)` is the expected way to do this.  Generally the type is set on the input constant.\r\n\r\nSo I think the first alternative is correct.  The \"visual clutter\" from the extra constant call is probably less common of a problem in practice, because constant initialization can happen on its own line -- which also gives them a name, and some implicit meaning, often helping readability.\r\n\r\nHaving a dtype parameter here would simplify some cases a little as suggested -- not just in where(), but also in other ops.  So if we do start adding a dtype parameter, we should be more intentional about adding it to ops outside of the creation methods.  In other words, I think before we would consider adding this we would need to look at the broader spectrum of ops and make sure we know the scope and benefit more holistically.\r\n"]}, {"number": 35140, "title": "[TF 2.1.0rc1] Fail to import package on Windows", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 2.1.0rc1\r\n- Python version: 3.7\r\n\r\n**Describe the current behavior**\r\nWhen trying to import tensorflow on a windows 10 machine with no GPU/CUDA setup I get a `DLL load failed` error. I suspect this is related to 2.1 now containing dynamic kernels (like in 1.15), but it doesn't seem to be falling back appropriately.\r\n\r\n**Describe the expected behavior**\r\nAble to import\r\n\r\n**Code to reproduce the issue**\r\n```\r\npip install tensorflow==2.0.0\r\n(win-tf2.0) python -c \"import tensorflow as tf; print(tf.__version__)\"\r\n2.0.0\r\n```\r\n\r\n\r\n```\r\npip install tensorflow==2.1.0rc1\r\n(win-tf2.1) python -c \"import tensorflow as tf; print(tf.__version__)\"\r\n```\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\SeanM\\Miniconda3\\envs\\win-tf2.1\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\SeanM\\Miniconda3\\envs\\win-tf2.1\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\SeanM\\Miniconda3\\envs\\win-tf2.1\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\SeanM\\Miniconda3\\envs\\win-tf2.1\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\SeanM\\Miniconda3\\envs\\win-tf2.1\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"C:\\Users\\SeanM\\Miniconda3\\envs\\win-tf2.1\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\Users\\SeanM\\Miniconda3\\envs\\win-tf2.1\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\SeanM\\Miniconda3\\envs\\win-tf2.1\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\SeanM\\Miniconda3\\envs\\win-tf2.1\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\SeanM\\Miniconda3\\envs\\win-tf2.1\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\SeanM\\Miniconda3\\envs\\win-tf2.1\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\SeanM\\Miniconda3\\envs\\win-tf2.1\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\SeanM\\Miniconda3\\envs\\win-tf2.1\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\SeanM\\Miniconda3\\envs\\win-tf2.1\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\SeanM\\Miniconda3\\envs\\win-tf2.1\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\SeanM\\Miniconda3\\envs\\win-tf2.1\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\SeanM\\Miniconda3\\envs\\win-tf2.1\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n```\r\n", "comments": ["Is this the same as  https://github.com/tensorflow/tensorflow/issues/35036", "I updated\n\nOn Sun, Dec 15, 2019, 3:50 PM Yifei Feng <notifications@github.com> wrote:\n\n> Is this the same as #35036\n> <https://github.com/tensorflow/tensorflow/issues/35036>\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/35140?email_source=notifications&email_token=AOBPXORBK2PQ6EOCTUF67ILQY2RDDA5CNFSM4J3BXB52YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEG5C56I#issuecomment-565849849>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AOBPXOSK5OL6D6RB43OW7BLQY2RDDANCNFSM4J3BXB5Q>\n> .\n>\n", "Thanks @yifeif same issue! Closing.", "Install The latest Visual C++ Runtime: \r\nhttps://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads"]}]