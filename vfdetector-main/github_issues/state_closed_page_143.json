[{"number": 50596, "title": "How to access elements of an input tensor in custom layers?", "body": "I wanted to assign an element of input tensor X to an element of an output tensor Y inside a custom layer like \r\n\r\nY[0,0,0,0] = X[0,1,1,1]\r\n\r\nFor example:\r\n\r\n```\r\nfrom keras.layers import Layer\r\nimport numpy as np\r\nfrom keras.layers import Input\r\nfrom keras.models import Model \r\n\r\nImages = [[[[255,0,0],[255,0,0]],[[255,0,0],[0,144,0]]]]\r\n\r\nInputTensor = np.array(Images)\r\n\r\nclass MyLayer(Layer):\r\n    def __init__(self, **kwargs):\r\n        super(MyLayer, self).__init__(**kwargs)\r\n    def build(self, input_shape):\r\n        self.built = True\r\n        super(MyLayer,self).build(input_shape)\r\n\r\n    def call(self, X):\r\n        Y = [[[[0,0,0,0]]]] # Output tensor\r\n        Y = np.array(Y)\r\n        Y[0,0,0,0] = X[0,1,1,1]   # <------ does not work because X[0,1,1,1] is a sequence instead a scalar\r\n        return np.ndarray.tolist(Y)\r\n    \r\ninputlayer = Input(shape = InputTensor[0].shape)\r\nlayer = MyLayer()(inputlayer)\r\n\r\nmodel = Model(inputlayer, layer ) \r\nmodel.summary()\r\n\r\nOutput = model.predict(InputTensor)\r\nOutput = np.array(Output)\r\nprint(\"Output = \"+str(Output))\r\n```\r\n\r\nIf the call-function returns X , then X[0,1,1,1] is not anymore a sequence after it passed the modell.\r\nIt make not sense to use custom layers if you have no access to the elements of an input tensor as expected.\r\nFor example:\r\n```\r\nfrom keras.layers import Layer\r\nimport numpy as np\r\nfrom keras.layers import Input\r\nfrom keras.models import Model \r\n\r\nImages = [[[[255,0,0],[255,0,0]],[[255,0,0],[0,144,0]]]]\r\n\r\nInputTensor = np.array(Images)\r\n\r\nclass MyLayer(Layer):\r\n    def __init__(self, **kwargs):\r\n        super(MyLayer, self).__init__(**kwargs)\r\n    def build(self, input_shape):\r\n        self.built = True\r\n        super(MyLayer,self).build(input_shape)\r\n\r\n    def call(self, X):\r\n        return X\r\n    \r\ninputlayer = Input(shape = InputTensor[0].shape)\r\nlayer = MyLayer()(inputlayer)\r\n\r\nmodel = Model(inputlayer, layer ) \r\nmodel.summary()\r\n\r\nOutput = model.predict(InputTensor)\r\nOutput = np.array(Output)\r\nprint(\"Output = \"+str(Output))\r\n```\r\n\r\nThe Output is:\r\n```\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ninput_78 (InputLayer)        [(None, 2, 2, 3)]         0         \r\n_________________________________________________________________\r\nmy_layer_77 (MyLayer)        (None, 2, 2, 3)           0         \r\n=================================================================\r\nTotal params: 0\r\nTrainable params: 0\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nOutput = [[[[255.   0.   0.][255.   0.   0.]][[255.   0.   0.][  0. 144.   0.]]]]\r\n```", "comments": ["@Oezkan23 ,\r\n\r\nCan you please fill the issue template from [here](https://github.com/tensorflow/tensorflow/issues/new/choose) and also please let us know the tensorflow version you are using.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50596\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50596\">No</a>\n"]}, {"number": 50594, "title": "tensorflow.data.experimental.load not working inside tensorflow.data.Dataset().flatmap", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 and Google Colab \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.5.0\r\n- Python version: 3.8.10\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: CPU 8GB\r\n\r\n\r\n**Describe the current behavior** tensorflow.data.experimental.load should return dataset when called from inside Dataset.interleave's map_function.\r\n\r\n**Describe the expected behavior** Throwing error 'TypeError: expected str, bytes or os.PathLike object, not Tensor'\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):yes\r\n- Briefly describe your candidate solution(if contributing): Create a constructor just like 'TextLineDataset' constructor which takes tensor and also strings of file paths.\r\n\r\n**Standalone code to reproduce the issue**\r\n````\r\nimport tensorflow as tf\r\npath = \"saved_data\"\r\n\r\n# Save a dataset\r\ndataset = tf.data.Dataset.range(2)\r\ntf.data.experimental.save(dataset, path)\r\nnew_dataset = tf.data.experimental.load(path)\r\nfor elem in new_dataset:\r\n  print(elem)\r\n\r\n\r\n\r\nfilenames = [path]\r\ndataset = tf.data.Dataset.from_tensor_slices(filenames)\r\ndef parse_fn(filename):\r\n  print(filename)\r\n  return tf.data.experimental.load(filename)\r\ndataset = dataset.flat_map(lambda x:\r\n    parse_fn(x))\r\n\r\nfor item in dataset.as_numpy_iterator():\r\n    print(item)\r\n````\r\n\r\n**Other info / logs** \r\n\r\n````\r\nTraceback (most recent call last):\r\n  File \"C:/Users/kurud/Documents/ineaurondeeplearn/internship/DrowsyDetectCNNmodel/DataPipelineIssues.py\", line 19, in <module>\r\n    dataset = dataset.interleave(lambda x:\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 2065, in interleave\r\n    return InterleaveDataset(self, map_func, cycle_length, block_length)\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 4596, in __init__\r\n    self._map_func = StructuredFunctionWrapper(\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 3712, in __init__\r\n    self._function = fn_factory()\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3134, in get_concrete_function\r\n    graph_function = self._get_concrete_function_garbage_collected(\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3100, in _get_concrete_function_garbage_collected\r\n    graph_function, _ = self._maybe_define_function(args, kwargs)\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3444, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3279, in _create_graph_function\r\n    func_graph_module.func_graph_from_py_func(\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 999, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 3687, in wrapped_fn\r\n    ret = wrapper_helper(*args)\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 3617, in wrapper_helper\r\n    ret = autograph.tf_convert(self._func, ag_ctx)(*nested_args)\r\n  File \"C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 695, in wrapper\r\nTensor(\"args_0:0\", shape=(), dtype=string)\r\n    raise e.ag_error_metadata.to_exception(e)\r\nTypeError: in user code:\r\n\r\n    C:/Users/kurud/Documents/ineaurondeeplearn/internship/DrowsyDetectCNNmodel/DataPipelineIssues.py:20 None  *\r\n        lambda x:\r\n    C:/Users/kurud/Documents/ineaurondeeplearn/internship/DrowsyDetectCNNmodel/DataPipelineIssues.py:18 parse_fn  *\r\n        return tf.data.experimental.load(filename)\r\n    C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\io.py:227 load  **\r\n        return _LoadDataset(\r\n    C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\io.py:134 __init__\r\n        with gfile.GFile(os.path.join(path, DATASET_SPEC_FILENAME), \"rb\") as f:\r\n    C:\\Users\\kurud\\Anaconda3\\envs\\DrowsyDetectCNNmodel\\lib\\ntpath.py:78 join\r\n        path = os.fspath(path)\r\n\r\n    TypeError: expected str, bytes or os.PathLike object, not Tensor\r\n````", "comments": ["@kurudinesh \r\nCould you please fill the [template](https://github.com/tensorflow/tensorflow/issues/new?assignees=&labels=type%3Abug&template=00-bug-issue.md) to analyse the issue reported here.Thanks!", "> @kurudinesh\r\n> Could you please fill the [template](https://github.com/tensorflow/tensorflow/issues/new?assignees=&labels=type%3Abug&template=00-bug-issue.md) to analyse the issue reported here.Thanks!\r\n\r\n@UsharaniPagadala \r\nI updated the issue with sample code to reproduce and system details. The code fails with interleave also and added almost same code to reproduce it also below. \r\n\r\n\r\n```\r\nimport tensorflow as tf\r\npath = \"saved_data\"\r\n\r\n# Save a dataset\r\ndataset = tf.data.Dataset.range(2)\r\ntf.data.experimental.save(dataset, path)\r\nnew_dataset = tf.data.experimental.load(path)\r\nfor elem in new_dataset:\r\n  print(elem)\r\n\r\n#interleave code\r\nfilenames = [path]\r\ndataset = tf.data.Dataset.from_tensor_slices(filenames)\r\ndef parse_fn(filename):\r\n  print(filename)\r\n  return tf.data.experimental.load(filename)\r\ndataset = dataset.interleave(\r\n    parse_fn)\r\n\r\nfor item in dataset.as_numpy_iterator():\r\n    print(item)\r\n```", "@kurudinesh \r\n\r\nCould you please provide the colab gist with all the dependencies to analyse the issue better.Thanks", "> @kurudinesh\r\n> \r\n> Could you please provide the colab gist with all the dependencies to analyse the issue better.Thanks\r\n\r\n\r\n@UsharaniPagadala created the colab \r\n[gist](https://colab.research.google.com/drive/1UezT01v-liBnqCSZsYehQXOb19Ep3fw2?usp=sharing)", "@Saduf2019 \r\n\r\nI was able to replicate the issue reported here.Please find the [gist](https://colab.research.google.com/gist/UsharaniPagadala/492fec48b85257202935a36ae5d19e0c/-50594.ipynb).Thanks", "@kurudinesh \r\nCan you please refer to these links and let us know.\r\n\r\n[link](https://stackoverflow.com/questions/55490951/an-error-about-typeerror-expected-str-bytes-or-os-pathlike-object-not-nonetyp)\r\n[link1](\r\nhttps://github.com/tensorflow/tensorflow/issues/33730#issuecomment-546725105)", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50594\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50594\">No</a>\n"]}, {"number": 50593, "title": "Multi-GPU doesn't work for model(inputs) nor when computing the gradients", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Desktop\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version (use command below): 2.4.0\r\n- Python version: 3.8.5\r\n- Bazel version (if compiling from source): 4.0.0\r\n- GCC/Compiler version (if compiling from source): 9.3.0\r\n- CUDA/cuDNN version: 11.0/8\r\n- GPU model and memory: RTX5000-16GB\r\n\r\n**Describe the current behavior**\r\n\r\nWhen using multiple GPUs to perform inference on a model (e.g. the call method: `model(inputs)`) and calculate its gradients, the machine only uses one GPU, leaving the rest idle. \r\n\r\n**Describe the expected behavior**\r\n\r\nI feel this should be the same as using `model.predict()` where all the GPUs are working. \r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport os\r\n\r\n# Make the tf-data\r\npath_filename_records = 'your_path_to_records'\r\nbs = 128\r\n\r\ndataset = tf.data.TFRecordDataset(path_filename_records)\r\ndataset = (dataset\r\n           .map(parse_record, num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\n           .batch(bs)\r\n           .prefetch(tf.data.experimental.AUTOTUNE)\r\n          )\r\n\r\n# Load model trained using MirroredStrategy\r\npath_to_resnet = 'your_path_to_resnet'\r\nmirrored_strategy = tf.distribute.MirroredStrategy()\r\nwith mirrored_strategy.scope():\r\n    resnet50 = tf.keras.models.load_model(path_to_resnet)\r\n\r\nfor pre_images, true_label in dataset:\r\n    with tf.GradientTape() as tape:\r\n       tape.watch(pre_images)\r\n       outputs = resnet50(pre_images)\r\n       grads = tape.gradient(outputs, pre_images)\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nYou can profile the behavior of the GPUs with nvidia-smi. I don't know if it is supposed to be like this, both the `model(inputs)` and `tape.gradient` to not have multi-GPU support. But if it is, then it's a big problem because if you have a large dataset and need to calculate the gradients with respect to the inputs (e.g. interpretability porpuses) it might take days with one GPU. \r\nAnother thing I tried was using `model.predict()` but this isn't possible with `tf.GradientTape`.\r\n", "comments": ["@miguelCalado ,\r\n\r\nTF v2.4 are built and tested against CUDA 11.0. Could you please check if you are facing the same error with CUDA 11.0 and cuDNN 8 and please let us know if you are facing same issue again.Please refer this link for [tested built configurations](https://www.tensorflow.org/install/source#gpu).Thanks!", "Yes, it still does. I edited the **system information** to not cause any more confusion.", "@miguelCalado,\r\nCan you please try specifying the **`GPU Devices`** in the **`Mirrored Strategy`** as shown in the [Documentation of Mirrored Strategy](https://www.tensorflow.org/guide/distributed_training#mirroredstrategy), like:\r\n\r\n**`mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])`**\r\n\r\nand let us know how it goes? Thanks!\r\n", "Yes, the behavior still stands!", "Hi, any more updates on this issue? \r\n\r\nHere's the list of things I've tried:\r\n1. Put all the code inside mirrored strategy scope.\r\n2. Used different GPUs: I've tried A100, A6000 and RTX5000. Also changed the number of graphic cards and varied the batch size.\r\n3. Specified a list of GPUs, for instance, `strategy = tf.distribute.MirroredStrategy(['/gpu:0', '/gpu:1'])`.\r\n4. Added this `strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())` as @Kaveh suggested.\r\n\r\n**How do I know that only one GPU is working?**\r\n\r\nI used the command `watch -n 1 nvidia-smi` in the terminal and observed that only one GPU is a 100%, the rest are at 0%.", "Here's a working example of it. I ask to whoever has more than one GPU to try and check if the issue still remains.\r\n\r\n**Notebook**: [Working Example.ipynb](https://drive.google.com/file/d/1CoYVckmEQXp2Wf_PRlGtnrlGnF8smxvt/view?usp=sharing)\r\n\r\n**Saved Model**: \r\n- [HDF5](https://drive.google.com/file/d/1Y0-fQytVsnHPs8JL6kKJr3tEL0mKNtjJ/view?usp=sharing)\r\n- [Saved Format](https://drive.google.com/file/d/19oSIaUTtEy1q6rlDj8GzuWIvwAq_7XMi/view?usp=sharing)", "Problem solved! https://stackoverflow.com/a/68404933/8527630\r\nFeel free to close this issue.\r\nThanks for all the help."]}, {"number": 50592, "title": "Closing as stale. Please reopen if you'd like to work on this further.", "body": "Closing as stale. Please reopen if you'd like to work on this further.\r\n\r\n_Originally posted by @google-ml-butler[bot] in https://github.com/tensorflow/tensorflow/issues/49920#issuecomment-873439262_", "comments": ["@mryusefVahedi01  The issue was closed due to the  stalled label and we re-opened the issue now. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@mryusefVahedi01  Closing the issue since the original issue was re opened. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50592\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50592\">No</a>\n"]}, {"number": 50591, "title": "Undefined symbols for architecture arm64", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac BigSur\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Ipad 2021\r\n- TensorFlow installed from (source or binary): \r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:  Mac Mini 2012\r\n\r\nSorry, I'm beginner programmer\r\nI don't know how to check some above info,\r\nBut it's not about hardward or the above I think\r\n\r\n**Describe the problem**\r\nI want to run mnist on ipad but get problem\r\nUndefined symbols for architecture arm64:\r\n  \"_OBJC_CLASS_$_MLModelConfiguration\", referenced from:\r\n      objc-class-ref in TensorFlowLiteCCoreML\r\n  \"_OBJC_CLASS_$_MLModel\", referenced from:\r\n      objc-class-ref in TensorFlowLiteCCoreML\r\n  \"_OBJC_CLASS_$_MLPredictionOptions\", referenced from:\r\n      objc-class-ref in  \r\n  \"_OBJC_CLASS_$_MLFeatureValue\", referenced from:\r\n      objc-class-ref in TensorFlowLiteCCoreML\r\n  \"_OBJC_CLASS_$_MLMultiArray\", referenced from:\r\n      objc-class-ref in TensorFlowLiteCCoreML\r\nld: symbol(s) not found for architecture arm64\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\n\r\n\r\nI think this may be solution\r\nhttps://github.com/tensorflow/tensorflow/issues/41039\r\nbut I don't know how to set it\r\n\r\n", "comments": ["I found solution by deleting TensorFlowLiteCCoreML.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50591\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50591\">No</a>\n"]}, {"number": 50590, "title": "C++ compilation of rule error with/ Error C2664 -> Build did NOT complete successfully", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64 bit\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.5.0\r\n- Python version: 3.8\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): 3.7.2\r\n- CUDA/cuDNN version: CUDA: 11.3, 8.0 \r\n- GPU model and memory: RTX 2060\r\n\r\n\r\n\r\n**Describe the problem**\r\nI'm trying to benchmark my tensorflow-lite models and I'm trying to follow along the [guide](https://www.tensorflow.org/lite/performance/measurement)\r\nI'm at the step where I'm building the native benchmark binary from source on my PC, but it results to an error.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nI'm executing the following command, but it results to an error\r\n`bazel build -c opt --cxxopt=/std:c++latest //tensorflow/lite/tools/benchmark:benchmark_model`\r\n\r\nI'm getting the following error:\r\n```\r\nERROR: /tensorflow/tensorflow/lite/delegates/external/BUILD:23:11: C++ compilation of rule '//tensorflow/lite/delegates/external:external_delegate' failed (Exit 2): cl.exe failed: error ex\r\necuting command\r\n  cd C:/users/administrator/_bazel_administrator/aj7l7svv/execroot/org_tensorflow\r\n  SET ANDROID_BUILD_TOOLS_VERSION=30.0.3\r\n    SET ANDROID_NDK_API_LEVEL=21\r\n    SET ANDROID_NDK_HOME=Sdk/android-ndk-r21e-windows-x86_64/android-ndk-r21e\r\n    SET ANDROID_SDK_API_LEVEL=30\r\n    SET ANDROID_SDK_HOME=Sdk/\r\n    SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.29.30037\\ATLMFC\\include;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.29.30037\\include;C:\\Prog\r\nram Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared;C:\\Program Files (x86)\\Windows Kits\r\n\\10\\include\\10.0.19041.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\winrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\cppwinrt\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\\\Extensions\\Microsoft\\IntelliCode\\CLI;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.29.30037\\bin\\HostX\r\n64\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;C:\\Program File\r\ns (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\MSBuild\\Current\\bin\\Roslyn;C:\\Program Files (\r\nx86)\\Microsoft Visual Studio\\2019\\Community\\Team Tools\\Performance Tools\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\\r\nCommon\\VSPerfCollectionTools\\vs2019\\\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;C:\\Program\r\n Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\Tools\\devinit;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.19041.0\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Microsoft Visual S\r\ntudio\\2019\\Community\\\\MSBuild\\Current\\Bin;C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Commu\r\nnity\\Common7\\Tools\\;;C:\\WINDOWS\\system32;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Co\r\nmmon7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=C:/ProgramData/Anaconda3/envs/tf-n-gpu/python.exe\r\n    SET PYTHON_LIB_PATH=C:/ProgramData/Anaconda3/envs/tf-n-gpu/lib/site-packages\r\n    SET RUNFILES_MANIFEST_ONLY=1\r\n    SET TEMP=C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\r\n    SET TF2_BEHAVIOR=1\r\n    SET TMP=C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\r\n  C:/Program Files (x86)/Microsoft Visual Studio/2019/Community/VC/Tools/MSVC/14.29.30037/bin/HostX64/x64/cl.exe /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0601 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS\r\n /bigobj /Zm500 /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/bin /showIncludes /MD /O2 /Oy- /DNDEBUG /wd4117 -D__DATE__=\"redacted\" -D__TIMESTAMP__=\"redacted\" -D__TIME__=\"redacted\" /Gy /Gw /W0 /D_US\r\nE_MATH_DEFINES -DWIN32_LEAN_AND_MEAN -DNOGDI /experimental:preprocessor /d2ReducedOptimizeHugeFunctions /std:c++14 /std:c++latest /Fobazel-out/x64_windows-opt/bin/tensorflow/lite/delegates/external/_objs/external_delegate/\r\nexternal_delegate.obj /c tensorflow/lite/delegates/external/external_delegate.cc\r\nExecution platform: @local_execution_config_platform//:platform\r\ncl : Command line warning D9035 : option 'experimental:preprocessor' has been deprecated and will be removed in a future release\r\ncl : Command line warning D9036 : use 'Zc:preprocessor' instead of 'experimental:preprocessor'\r\ncl : Command line warning D9025 : overriding '/std:c++14' with '/std:c++latest'\r\ntensorflow/lite/delegates/external/external_delegate.cc(35): error C2664: 'void *tflite::SharedLibrary::LoadLibraryA(const wchar_t *)': cannot convert argument 1 from 'const _Elem *' to 'const wchar_t *'\r\n        with\r\n        [\r\n            _Elem=char\r\n        ]\r\ntensorflow/lite/delegates/external/external_delegate.cc(35): note: Types pointed to are unrelated; conversion requires reinterpret_cast, C-style cast or function-style cast\r\n.\\tensorflow/lite/shared_library.h(32): note: see declaration of 'tflite::SharedLibrary::LoadLibraryA'\r\nTarget //tensorflow/lite/tools/benchmark:benchmark_model failed to build\r\n```", "comments": ["Please use c++14 instead of std:c++latest.", "> Please use c++14 instead of std:c++latest.\r\n\r\nThank you for your response, but apparently it didn't help. I'm starting to think this is an issue on compatibility of versions. I hope someone can provide here a complete list that contains system information and other necessary dependencies that leads to a successful build, so I can upgrade/downgrade as necessary", "@djbacad ,\r\n\r\nPlease refer the [link](https://www.tensorflow.org/install/source_windows#gpu) for tested built configurations which are compatible with tf v2.5. It helps.Thanks!", "\r\n@tilakrayal I already gave up with windows and what I did was I set up a VM with Ubuntu 18.04 and I was finally able to successfully build.", "@djbacad ,\r\n\r\nGlad the issue is resolved for you, please move this to closed status.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50590\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50590\">No</a>\n"]}, {"number": 50589, "title": "W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found", "body": "**System information**\r\n- OS Platform and Distribution: Windows 10\r\n- TensorFlow installed from (source or binary): pip \r\n- TensorFlow version: 2.5.0\r\n- Python version: 3.8.10\r\n- Installed using virtualenv? pip? conda?: pip\r\r\n- CUDA/cuDNN version: 11.4\r\n- GPU model and memory: NVIDIA GTX 1650Ti 4GB\r\n\r\n\r\n\r\nUpon writing `import tensorflow as tf` in the command prompt-bases python interpreter, it displays the following error\r\n\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/70141886/124354459-bdbd4600-dc29-11eb-9d18-178768bf98d7.png)\r\n![image](https://user-images.githubusercontent.com/70141886/124354446-a8481c00-dc29-11eb-9c96-a7728cfbbc66.png)\r\n![image](https://user-images.githubusercontent.com/70141886/124354485-d75e8d80-dc29-11eb-8e13-724ecd456265.png)\r\n![image](https://user-images.githubusercontent.com/70141886/124354596-6c618680-dc2a-11eb-950a-0fa956682c83.png)\r\n\r\n\r\nI have even set the 4 PATHs to be set for use\r\n\r\n`C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.4\\bin`\r\n`C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.4\\libnvvp`\r\n`C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.4\\include`\r\n`C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.4\\extras\\CUPTI\\lib64`\r\n\r\n\r\nI have gone through previous issues and other Google links before deciding to come here to create this issue. I have also restarted my computer several times in the hope that the path is updated, if that was the cause of this error. Please let me know how I can fix this problem. Thank you", "comments": ["Is this due to a possible conflict in versions of different packages?", "What cuDNN version are you using?  (you only mentioned CUDA)I was having the same problem before and I was able to solve it by installing versions that are suggested by the [tested build configurations](https://www.tensorflow.org/install/source#tested_build_configurations).", "CuDNN version 8.2.1, apparently. Seeing your link, it apparently is not compatible with said version as such. I am currently re-installing all the tools from scratch, and will check after that. Thank you", "Nope, does not solve the problem for me.\r\n\r\nCurrent versions :\r\nTensorflow - \r\n![image](https://user-images.githubusercontent.com/70141886/124381362-ab9ddf00-dcdf-11eb-838a-e894668a3d2b.png)\r\nKeras - \r\n![image](https://user-images.githubusercontent.com/70141886/124381368-b5bfdd80-dcdf-11eb-960c-0b4771379d76.png)\r\nCuDNN -\r\n![image](https://user-images.githubusercontent.com/70141886/124381384-d5ef9c80-dcdf-11eb-8db1-ebc646f39b87.png)\r\nCUDA -\r\n![image](https://user-images.githubusercontent.com/70141886/124381389-e7d13f80-dcdf-11eb-983b-607e1221b0df.png)\r\nPython - 3.9\r\nGCC - \r\n![image](https://user-images.githubusercontent.com/70141886/124381419-118a6680-dce0-11eb-91cf-c5f8a7a7aac9.png)\r\n\r\n\r\nI have only tried to do some stuff with Python. Could my GCC Version be the problem?", "In my understanding, you intend to utilize the GPU support right? Can you try doing `pip show tensorflow-gpu` and show the result? Also,[ guide](https://www.tensorflow.org/install/gpu#windows_setup) here tells that these (sample) are the necessary envi variables to be set:\r\n\r\n```\r\nSET PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.0\\bin;%PATH%\r\nSET PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.0\\extras\\CUPTI\\lib64;%PATH%\r\nSET PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.0\\include;%PATH%\r\nSET PATH=C:\\tools\\cuda\\bin;%PATH%\r\n```", "@djbacad As I read the guides, it said that after Tensorflow 2.5.0, we can simply use \n`pip install tensorflow`.\nDue to this, doing pip show tensorflow-gpu just doesn't do anything as such.\nAlso, all env variables mentioned here have been set. I did that as well, but this problem still crops up.", "@suvadityamuk \r\nCan you please refer to [this link ](https://stackoverflow.com/questions/59823283/could-not-load-dynamic-library-cudart64-101-dll-on-tensorflow-cpu-only-install)and let us know.", "@Saduf2019 I have tried going through these steps as well. The answer which involved shifting the file to the System32 path did end up working, but it seems to be nothing better than a stop-gap solution as such. Is there a better method to solve this problem once and for all?\r\n\r\nAlso, I just realised. I was running my programs within the .venv, but when I ran it outside the .venv, it was successfully imported. Does this mean that this was a problem for the program to access those files from within the .venv?", "@suvadityamuk \r\nYou have used pip install hence its working as expected outside the venv, this is not a bug or error it is working as expected.", "> @suvadityamuk \n> You have used pip install hence its working as expected outside the venv, this is not a bug or error it is working as expected.\n\nI ran the pip install within the venv, not outside. Is that still supposed to work as such?", "@suvadityamuk\r\n Please share the pip list for the venv you are using.", "`pip list`\r\n![image](https://user-images.githubusercontent.com/70141886/124460674-4adcd800-ddad-11eb-8071-14ca601c40b5.png)\r\n![image](https://user-images.githubusercontent.com/70141886/124460701-529c7c80-ddad-11eb-8f89-50ff1e801bfa.png)\r\n![image](https://user-images.githubusercontent.com/70141886/124460720-56c89a00-ddad-11eb-8a07-1a58011e38ab.png)\r\n![image](https://user-images.githubusercontent.com/70141886/124460736-5cbe7b00-ddad-11eb-9903-5f07fa7d71b4.png)\r\n![image](https://user-images.githubusercontent.com/70141886/124460754-61832f00-ddad-11eb-97ab-1a17a0db8c7e.png)\r\n", "@suvadityamuk \r\nCuda 11.4 is not tested, can you please refer to this link and use tested configurations, i suggest you can try 11.0 or 11.2 and let us know if the problem exist. [https://www.tensorflow.org/install/gpu]\r\n\r\nalso there seems to be the issue of a corrupted dll file due to which you have to explicitly mention the path in file 32 windows,\r\nyou can try rechecking this with a fresh venv install and and a fresh tf latest too. you may try this if the 11.0 does not help.", "@Saduf2019 I actually did reinstall Cuda 11.2, but that didn't do me any good as such.\nI shall try creating a new venv and checking if this problem persists. ", "@suvadityamuk \r\n\r\nDo you wana try with 11.0 as per [this comment](https://github.com/tensorflow/tensorflow/issues/43174#issuecomment-874019987), though you are using windows", "I tried that code snippet and added it to my program, but it did not solve the problem. \r\nI had previously used CUDA 11.0, but I have reverted back to 11.2 once again.\r\nI got the following trace:\r\n![image](https://user-images.githubusercontent.com/70141886/124553290-31da3280-de52-11eb-8f3d-27f17f32d4e7.png)\r\n![image](https://user-images.githubusercontent.com/70141886/124553325-3a326d80-de52-11eb-86a1-fc0a15105625.png)\r\n", "@suvadityamuk,\r\n\r\nCan you take a look at this [comment](https://github.com/tensorflow/tensorflow/issues/48868#issuecomment-841396124) from a similar issue and try if it helps in solving your issue? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50589\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50589\">No</a>\n"]}, {"number": 50588, "title": "Fix equations in Adam docs", "body": "Equations for Adam and other optimizers do not look good. My PR tries to fix it. \r\n\r\nI didn't find any good way to produce exact htmls from api_docs with working jax. I tried those changes locally and looks better:\r\n![image](https://user-images.githubusercontent.com/37601244/124335906-41c8ec80-db9c-11eb-9557-4722954d2a41.png)\r\n- [https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/apply-adam](https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/apply-adam)\r\n- [https://www.tensorflow.org/api_docs/python/tf/raw_ops/ApplyAdam](https://www.tensorflow.org/api_docs/python/tf/raw_ops/ApplyAdam)\r\n- [https://www.tensorflow.org/api_docs/python/tf/raw_ops/ResourceApplyAdam](https://www.tensorflow.org/api_docs/python/tf/raw_ops/ResourceApplyAdam)\r\n", "comments": ["@jpienaar, thanks for the review.\r\n\r\nThat's how 0337ba0c0 looks like:\r\n![image](https://user-images.githubusercontent.com/37601244/124520208-06bcf800-ddec-11eb-9495-5a3da49e1e47.png)"]}, {"number": 50587, "title": "custom implementation request: SparseReorder, SparseTensorDenseMatMul", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows10, x86-64\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (or github SHA if from source): 2.7.0-dev20210702\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\n2021-07-02 16:52:27.481365: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1851] The following operation(s) need TFLite custom op implementation(s):\r\nCustom ops: SparseReorder, SparseTensorDenseMatMul\r\n```\r\n\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem.\r\nIf including tracebacks, please include the full traceback. Large logs and files\r\nshould be attached.\r\n\r\nDetails:\r\n\ttf.SparseReorder(tensor<?x3xi64>, tensor<?xf32>, tensor<3xi64>) -> (tensor<?x3xi64>, tensor<?xf32>) : {T = f32, device = \"\"}\r\n\ttf.SparseTensorDenseMatMul(tensor<?x2xi64>, tensor<?xf32>, tensor<2xi64>, tensor<6400x256xf32>) -> (tensor<?x256xf32>) : {T = f32, Tindices = i64, adjoint_a = false, adjoint_b = false, device = \"\"}\r\n", "comments": ["I adding them  as Select TF Ops. Please wait a bit before it get merged.", "Thank you very much!", "the fixed is merged to master branch. You can try it in tomorrow nightly.\r\nHowever, you will need to treat them as Select TF Ops. Please follow https://www.tensorflow.org/lite/guide/ops_select\r\n"]}, {"number": 50586, "title": "Throw ValueError if shapes don't match in keras.layers.Softmax #50467", "body": "I think that we should raise ValueError in case Add is not successful. The reason is that after using tf.keras.layers.Masking, the timestep will be masked (skipped) in all downstream layers (as long as they support masking). The user may be not aware of that.", "comments": ["It looks like your PR relates to the Keras component. Please submit it to the [github.com/keras-team/keras](github.com/keras-team/keras) repository instead. Thank you."]}, {"number": 50585, "title": "Error in using next() method with DirectoryIterator", "body": "`\r\ntrain_images, train_labels = next(batch_obj['train'])\r\n`\r\n\r\nerrors out with,\r\n\r\n`\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-6-674a9be77381> in <module>\r\n----> 1 train_images, train_labels = next(batch_obj['train'])\r\n\r\n/opt/conda/lib/python3.8/site-packages/keras_preprocessing/image/iterator.py in __next__(self, *args, **kwargs)\r\n    102 \r\n    103     def __next__(self, *args, **kwargs):\r\n--> 104         return self.next(*args, **kwargs)\r\n    105 \r\n    106     def next(self):\r\n\r\n/opt/conda/lib/python3.8/site-packages/keras_preprocessing/image/iterator.py in next(self)\r\n    114         # The transformation of images is not under thread lock\r\n    115         # so it can be done in parallel\r\n--> 116         return self._get_batches_of_transformed_samples(index_array)\r\n    117 \r\n    118     def _get_batches_of_transformed_samples(self, index_array):\r\n\r\n/opt/conda/lib/python3.8/site-packages/keras_preprocessing/image/iterator.py in _get_batches_of_transformed_samples(self, index_array)\r\n    229                            target_size=self.target_size,\r\n    230                            interpolation=self.interpolation)\r\n--> 231             x = img_to_array(img, data_format=self.data_format)\r\n    232             # Pillow images should be closed after `load_img`,\r\n    233             # but not PIL images.\r\n\r\n/opt/conda/lib/python3.8/site-packages/keras_preprocessing/image/utils.py in img_to_array(img, data_format, dtype)\r\n    307     # or (channel, height, width)\r\n    308     # but original PIL image has format (width, height, channel)\r\n--> 309     x = np.asarray(img, dtype=dtype)\r\n    310     if len(x.shape) == 3:\r\n    311         if data_format == 'channels_first':\r\n\r\n/opt/conda/lib/python3.8/site-packages/numpy/core/_asarray.py in asarray(a, dtype, order)\r\n     81 \r\n     82     \"\"\"\r\n---> 83     return array(a, dtype, copy=False, order=order)\r\n     84 \r\n     85 \r\n\r\nTypeError: __array__() takes 1 positional argument but 2 were given\r\n`", "comments": ["Closing this as resolved.\r\nApparently, Pillow 8.3.0 was the culprit.\r\nDowngraded it to 8.2.0 and things are peachy now.\r\n\r\nBest,\r\nMahesh"]}, {"number": 50584, "title": "RBF Custom Layer in Tensorflow can not learn the centers (mu) parameters", "body": "Using Google Colab with TF version 2.5\r\n", "comments": ["[Bug.zip](https://github.com/tensorflow/tensorflow/files/6755781/Bug.zip)\r\n", "```\r\nfrom tensorflow.keras.layers import Layer\r\nfrom tensorflow.keras import backend as K\r\n\r\nclass RBFLayer(Layer):\r\n    def __init__(self, units, gamma, **kwargs):\r\n        super(RBFLayer, self).__init__(**kwargs)\r\n        self.units = units\r\n        self.gamma = K.cast_to_floatx(gamma)\r\n\r\n    def build(self, input_shape):\r\n        self.mu = self.add_weight(name='mu',\r\n                                  shape=(int(input_shape[1]), self.units),\r\n                                  initializer=tf.random_normal_initializer(),\r\n                                  trainable=True)\r\n        # self.gamma = self.add_weight(name='gamma',\r\n        #                           shape=(int(input_shape[1]),),\r\n        #                           initializer=tf.constant_initializer(1),\r\n        #                           trainable=True)\r\n        super(RBFLayer, self).build(input_shape)\r\n\r\n    def call(self, inputs):\r\n        diff = K.expand_dims(inputs) - self.mu\r\n        l2 = K.sum(K.pow(diff,2), axis=1)\r\n        res = K.exp(-0.5*self.gamma * l2)\r\n        return res\r\n\r\n    def compute_output_shape(self, input_shape):\r\n        return (input_shape[0], self.units)\r\n```", "Was able to reproduce the issue in TF 2.5. Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/7003c467af9a20aa61f7fb51b2c6da68/rbf_custom_layer_tf_2.ipynb). Thanks!", "@miladtoutounchian \r\nPlease post this issue on keras-team/[keras repo](https://github.com/keras-team/keras/issues).\r\nTo know more refer to:\r\nhttps://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50584\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50584\">No</a>\n"]}, {"number": 50583, "title": "[Colab TPU] [TF 2.5]  UnavailableError: Socket closed", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n  - Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n  - Google Colab  enviroment\r\n- TensorFlow version (use command below):\r\n - 2.5\r\n- Python version:\r\n  - 3.7.10\r\n\r\n### Context: \r\nMy model was training ok untill a certain number of steps then throwing the error mentioned in issue #50522 which i then came to realize that it was related to the in my tfrecord files causing different batch output sizes. As an attempt to fix it, i adapted the code to run with a dinamic batch size by using  ```tf.shape(x)```.  Coincidentally (or not) when trying to perform training the error ```UnavailableError: Socket closed``` began showing up.  After further research, as pointed by the [doc](https://cloud.google.com/tpu/docs/troubleshooting#dynamic_shapes_not_supported) i removed back the tf.shape op and added ```drop_remainder=True``` to my dataset.batch config. Despite that the error persisted, although after enabling drop_remainder the code was identical to the previous working version.\r\n\r\nObs: Dropping remainders and tf.shape were added as an attempt to deal with batch lenght different than the original configuration, as the data needs to be properly reshaped accordingly to the length of the augmented batch and the batch_size varies accordingly to the number of samples within my tfrecords that are not multiples. \r\n\r\nCode: \r\n```python\r\n\r\ndef train_model(train_path, validation_path, buffer_size, epochs, steps_per_epoch, model):\r\n  data_augmentation = preprocessing_model()\r\n\r\n  train_filenames = get_filenamesTPU(train_path)\r\n  random.shuffle(train_filenames)\r\n\r\n  validation_filenames = get_filenamesTPU(validation_path)\r\n  random.shuffle(validation_filenames)\r\n\r\n  dataset_length = 91758  \r\n  train_size =  dataset_length * 0.7\r\n  validation_size = dataset_length - train_size\r\n\r\n  batch_size = 42 * tpu_strategy.num_replicas_in_sync\r\n\r\n  shape = 32 * batch_size\r\n\r\n  data_reshape = lambda x,y: (tf.reshape(x,shape=(shape,224,224,3)), (tf.reshape(y[0],shape=(shape,1000)), tf.reshape(y[1],shape=(shape,516)),tf.reshape(y[2],shape=(shape,124))))\r\n  \r\n  augmentation_pipeline = lambda x,y: (data_augmentation(tf.expand_dims(x,axis=0)),(tf.tile(tf.reshape(y[0],[1,1000]),[32,1]),tf.tile(tf.reshape(y[1],[1,516]),[32,1]),tf.tile(tf.reshape(y[2],[1,124]),[32,1]))) # apply augment then tile the labels to the correct length\r\n  \r\n  AUTO = tf.data.AUTOTUNE\r\n  train_dataset = tf.data.TFRecordDataset(buffer_size=int(1e+8),num_parallel_reads=AUTO,filenames=train_filenames).map(parsing_fn,num_parallel_calls=AUTO).shuffle(buffer_size=buffer_size, reshuffle_each_iteration=True)\r\n  train_dataset = train_dataset.map(augmentation_pipeline, num_parallel_calls=AUTO).batch(batch_size=batch_size, drop_remainder=True)\r\n  train_dataset = train_dataset.map(data_reshape,num_parallel_calls=AUTO)\r\n  train_dataset = train_dataset.repeat()\r\n  train_dataset = train_dataset.prefetch(AUTO)\r\n \r\n  # Create a validation dataset\r\n  validation_dataset = tf.data.TFRecordDataset(num_parallel_reads=AUTO,filenames=validation_filenames).map(parsing_fn,num_parallel_calls=AUTO)\r\n  validation_dataset = validation_dataset.batch(batch_size)\r\n  validation_dataset = validation_dataset.prefetch(AUTO)\r\n  validation_dataset = validation_dataset.repeat(1)\r\n\r\n  validation_steps = validation_size / batch_size \r\n  history = model.fit(x=train_dataset,\r\n                          epochs=epochs,\r\n                          steps_per_epoch=steps_per_epoch,                        \r\n                          validation_data=validation_dataset,\r\n                          validation_steps=validation_steps)\r\n  return history\r\n```\r\n### Perform training\r\n```python\r\nloss={\r\n        \"class_0\": 'CategoricalCrossentropy',\r\n        \"class_1\": 'CategoricalCrossentropy',\r\n        \"class2\": 'CategoricalCrossentropy',\r\n},\r\n\r\nmetrics = ['categorical_accuracy']\r\noptimizer = Adam(learning_rate=5e-3)\r\n\r\nweight_file = None\r\nwith tpu_strategy.scope():\r\n  resnet_50V2 = load_and_configure_model(optimizer, loss, metrics, weight_file)\r\nresnet_50V2 = load_and_configure_model(optimizer, loss, metrics, weight_file)\r\nbase_directory = 'gs://2015_tfrecords'\r\n\r\ntrain_path = base_directory+'/train/'\r\nvalidation_path = base_directory+'/validation/'\r\n\r\nbuffer_size = 10240\r\nepochs = 30\r\nsteps_per_epoch = 192\r\n\r\nresnet_50V2.summary()\r\nhistory = train_model(train_path, validation_path, buffer_size, epochs, steps_per_epoch, resnet_50V2)\r\nplot_training_history3(history)\r\n```\r\n\r\n### Error\r\n```\r\n==================================================================================================\r\nTotal params: 26,925,160\r\nTrainable params: 7,825,000\r\nNon-trainable params: 19,100,160\r\n__________________________________________________________________________________________________\r\nEpoch 1/30\r\n\r\n---------------------------------------------------------------------------\r\n\r\nUnavailableError                          Traceback (most recent call last)\r\n\r\n<ipython-input-48-3332ce7f2ca9> in <module>()\r\n      4 \r\n      5 resnet_50V2.summary()\r\n----> 6 history = train_model(train_path, validation_path, buffer_size, epochs, steps_per_epoch, resnet_50V2)\r\n      7 plot_training_history3(history)\r\n      8 \r\n\r\n14 frames\r\n\r\n/usr/local/lib/python3.7/dist-packages/six.py in raise_from(value, from_value)\r\n\r\nUnavailableError: Socket closed\r\n```", "comments": ["@falcondai \r\n\r\nI am facing dependency errors,Could please provide the colab gist with all the required dependencies to analyse the issue.Thanks", "Working on that", "@UsharaniPagadala let me know if there are any permission issues\r\n\r\n[gist link](https://colab.research.google.com/drive/1ZTeOA8-2UUqljrqM6G3MblD_D7NZEOhl?usp=sharing)", "@FalsoMoralista \r\n\r\nCould you refer the similar [issue](https://github.com/tensorflow/tensorflow/issues/36136#issuecomment-627731715),hope it helps.Thanks", "Thank you but I have already checked this issue before. I have experimented with float32 labels as well but nothing happens. The thing is, as i mentioned before, the  same code was working fine on the previous issue that i've opened as you can check (#50522), the differences between that code and this one are: \r\n- removed augmentation on the validation step \r\n- set drop_remainder=True ", "@Saduf2019 \r\n\r\nI was able to replicate the issue reported here.Please find the [gist](https://colab.research.google.com/gist/UsharaniPagadala/76145dd8ea30c2a615bec17d957e227a/colab_gist.ipynb#scrollTo=5-e5xvVyggeZ).Thanks", "Any updates?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50583\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50583\">No</a>\n"]}, {"number": 50582, "title": "(0) Invalid argument:  In[0] mismatch In[1] shape: ", "body": " `tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.`\r\n`     (0) Invalid argument:  In[0] mismatch In[1] shape: 1108 vs. 1120: [42,1108] [1120,256] 0 0`\r\n `   [[node model/dense/MatMul (defined at rnn_flickr_fit.py:273) ]]`\r\n`   (1) Invalid argument:  In[0] mismatch In[1] shape: 1108 vs. 1120: [42,1108] [1120,256] 0 0`\r\n   ` [[node model/dense/MatMul (defined at rnn_flickr_fit.py:273) ]]`\r\n  `  [[Adam/Cast_6/ReadVariableOp/_6]]`\r\n `   0 successful operations.`\r\n`    0 derived errors ignored. [Op:__inference_train_function_7431]`\r\n    \r\n   ` Function call stack:`\r\n`    train_function -> train_function`\r\n    \r\n `   2021-07-02 14:23:52.766840: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.`\r\n`    \t [[{{node PyFunc}}]]`\r\n\r\nwhat should i check to solve it \r\n\r\ncode is \r\n\r\n`def define_model(vocab_size, max_length, curr_shape):`\r\n `   inputs1 = Input(shape=curr_shape)`\r\n  `  fe1 = Dropout(0.5)(inputs1)`\r\n   ` fe2 = Dense(256, activation='relu')(fe1)`\r\n    `inputs2 = Input(shape=(max_length,))`\r\n  `  se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)`\r\n   ` se2 = Dropout(0.5)(se1)`\r\n   ` se3 = LSTM(256)(se2)`\r\n   ` decoder1 = Concatenate()([fe2, se3])`\r\n    `decoder2 = Dense(256, activation='relu')(decoder1)`\r\n    `outputs = Dense(vocab_size, activation='softmax')(decoder2)`\r\n    `model = Model(inputs=[inputs1, inputs2], outputs=outputs)`\r\n   ` model.compile(loss='categorical_crossentropy', optimizer='adam')`\r\n    `return model`", "comments": ["@mathshangw ,\r\n\r\nCode shared is full of indentation errors, please share a colab gist with issue reported or complete code with dependencies.Also please share the tensorflow version you are using.Thanks", "`tensorflow          2.5.0`\r\n`tensorflow-gpu                1.15.0`\r\n\r\ni tried to write a code and avoid the indentation errors but couldn't .. How can i write it well ? ", "is there any help please ? ", "@mathshangw ,\r\n\r\nPlease refer this [link](https://www.geeksforgeeks.org/indentation-in-python/) for information on indentation.Without the reproducible code, it would be difficult for us to debug the issue. In order to expedite the trouble-shooting process, please provide the complete code.Thanks!\r\n\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 50581, "title": "[PluggableDevice] register default devices for functional ops", "body": "Register default devices for functional ops. This is for PluggableDevice.", "comments": ["@saxenasaurabh Can you please review this PR ? Thanks!", "The PR looks good, but it seems to block on some CI tests - tensorflow/core/kernels:while_op_test (specifically, WhileOpCPUBuildWithPluggableDevice) seems to fail in some configurations - could you have a look? ", "> The PR looks good, but it seems to block on some CI tests - tensorflow/core/kernels:while_op_test (specifically, WhileOpCPUBuildWithPluggableDevice) seems to fail in some configurations - could you have a look?\r\n\r\n@mdanatg Thanks for you review. For the failed UT, this PR has a denpendency to [PR50578](https://github.com/tensorflow/tensorflow/pull/50578) because of the absence of `_Arg` op's `DEVICE_DEFAULT` register.", "@mdanatg  Any update on this PR? Please. Thanks!\r\n", "Let's try the tests again now that the parent is merged.", "@mdanatg Sorry for the delay. I modify the UT(`WhileOpTest, WhileOpCPUBuildWithPluggableDevice`) in this PR. Let me explain that. The UT was also added by me because `While` op will crash when `TF CPU build + PluggableDevice`. In this UT, I register a device called `FAKE`, so `While`/`LessEqual`/`Mul` will use `DEVICE_DEFAULT` with `DT_FLOAT`(due to the limitation of `While` op's implementation, `DT_INT32`/`DT_INT64` will not run into the `PluggableDevice` path). But `LessEqual`/`Mul` with `DT_FLOAT` must not have `DEVICE_DEFAULT`(just `DT_INT32` available). So I add two `FunctionDef` to cast `DT_FLOAT` into `DT_INT32` before compute for them, convert them back to `DT_FLOAT` then. \r\nBefore I register `While` to `DEVICE_DEFAULT`, this UT was not actually ran. If this PR was merged before [50916](https://github.com/tensorflow/tensorflow/pull/50916), I would have a chance to fix this in 50916.\r\n", "Sounds good, but note that in the long term we don't want DType holes in kernel registrations, especially for such generic kernels as control flow. To capture these points in the code, please add the notes in code comments (in the test function would be fine), along with a TODO to support cast-free operation (and add the corresponding DEVICE_DEFAULTs)."]}, {"number": 50580, "title": "[PluggableDevice] register default device for wrapdataset ops", "body": "Add default device registers for wrapdataset ops. This is for PluggableDevice.", "comments": ["@saxenasaurabh  Can you please review this PR ? Thanks!", "@quintinwang5  Can you please resolve conflicts? Thanks!", "@penpornk Can you please review this PR ? Thanks!", "The placement of tf.data ops does not follow standard placement and should not rely on DEFAULT_DEVICE. Same rationale as #50605."]}, {"number": 50579, "title": "tf.data.Dataset.cache('filename') loads entire dataset into memory", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): bin (both pip and docker)\r\n- TensorFlow version (use command below): happens on 2.4.1, 2.5.0 and nightly (2.7.0-dev20210630)\r\n- Python version: 3.8.5\r\n\r\n**Describe the current behavior**\r\nWhen caching a data set on local disk Tensorflow first loads the entire data set into memory. This obviously crashes the job since we are using Dataset and caching on disk because of memory restrictions.\r\n\r\n**Describe the expected behavior**\r\nI expected Tensorflow to continuously write to disk while reading the data set from where ever it is coming from. In a streaming manner.  \r\nAlternatively, I could imagine a chunking approach where Tensorflow writes multiple files in the cache to limit the amount of data held in memory at any one time (or writes multiple times to the same file).\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no\r\n\r\n**Standalone code to reproduce the issue**\r\n[gist](https://gist.github.com/grofte/f617f12a8abef1d085ecaf64500be8b4)\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow_datasets as tfds\r\n\r\n# This data set is too big to run in Colaboratory, ~30 GB\r\ntrain = tfds.load(name=\"bair_robot_pushing_small:2.0.0\", split=\"train\",\r\n                  shuffle_files=False, data_dir='./tensorflow_datasets')\r\ntrain = train.cache('./cache/train')\r\n\r\n# We need to do some kind of operation over the data to trigger the caching\r\nbatch_size = 64\r\nn = train.batch(batch_size).reduce(0, lambda accum, _: accum + batch_size)\r\nprint(n)\r\n```\r\n\r\nThis is of course a minimal example. We first noticed this problem when loading our from TFRecords files. Caching on file is bad for the training data since you lose a lot of shuffling ability but it's fine for the validation data. If we cache it on a local disk then we can avoid network traffic if the data is elsewhere and the local disk is faster too in our case. So it is still useful - just not when it crashes your job. And really, we could run these training jobs faster if we cached the validation data in memory (but several jobs run on the same machines so we just have to get lucky and not have two RAM intensive parts running at the same time).\r\n\r\n", "comments": ["**Tiny feature request:**  \r\nIt would be cool if we could shuffle from cached data. Currently there's two ways to shuffle tf.data.Dataset: 1) shuffle the file paths 2) build a shuffle buffer. 1) is a problem because then I can't apply transformations and cache them (or exploit moving data) without doing all of the serialization and saving and loading and 2) is a problem because we are already using tf.data.Dataset because we run into memory limitations (and honestly a shuffle buffer is not a great shuffle). I am aware that problem 1) simply requires me to write and maintain more code but I thought the point of tf.data was to have clean data streams and transformations. And I think it works pretty well once you get used to it. Problem 2) is also weird because if you cache in memory then I still think you have to use a shuffle buffer - so now your data is two places in memory?", "@grofte,\r\nWe couldn't reproduce the issue as the **`Dataset`** is very huge (30 GB) but your point is taken.\r\n\r\nRegarding **`Feature Request`**, we request you to file it as a separate issue so that it can be tracked separately. Thanks!", "I chose a large data set for exactly that reason. If the data set fits in memory then it will be cached on file fine. But there's no incentive to cache a data set on file if it fits in memory. I will have a look at filing a feature request and see if I can link it here. I think both can be closed in one go though. ", "Hi @grofte, the [snapshot](https://www.tensorflow.org/api_docs/python/tf/data/experimental/snapshot) transformation could be closer to what you're looking for. Instead of storing all data in a single file like `cache`, it shards the data into a configurable number of files, and you can shuffle the files in a different way each time you read from the snapshot.", "@aaudiber Perfect Andrew! That is exactly what I was asking for. \r\n\r\nAnd I see that it is even out of experimental in the nightly build https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=nightly#snapshot"]}, {"number": 50578, "title": "[PluggableDevice]add default device for function ops", "body": "Add default device registers for function ops. This is for PluggableDevice.", "comments": ["Hi, @penpornk @saxenasaurabh can you help to review this PR and PR[50601](https://github.com/tensorflow/tensorflow/pull/50601)? Some models will crash if the ArgOp and DestroyResourceOp not registered as DEVICE_DEFAULT. Thanks very much", "@penpornk Can you please review this PR ? Thanks!", "Adding @mihaimaruseac to double check the safety of automatically injecting kernel ops. LGTM otherwise."]}, {"number": 50577, "title": "CMAKE ERROR for Android_arm64 of TFLite on MacOS.", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **MacOS Big Sur 11.2.3**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): **source**\r\n- TensorFlow version: **2.6.0**\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):  **cmake 3.20.0 && androidNDK-r20b**\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nCMAKE ERROR occurred when I cmake andoird_arm64 binary of TF-Lite.\r\n\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nI used cmake cmmand like [https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/guide/build_cmake.md](url) says:\r\n\r\n```\r\nmkdir tflite_build\r\ncd tflite_build\r\ncmake -DCMAKE_TOOLCHAIN_FILE=<NDK path>/build/cmake/android.toolchain.cmake \\\r\n  -DANDROID_ABI=arm64-v8a ../tensorflow_src/tensorflow/lite\r\n```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nCMAKE LOGs in terminal:\r\n\r\n```\r\n-- Setting build type to Release, for debug builds use'-DCMAKE_BUILD_TYPE=Debug'.\r\n-- ANDROID_PLATFORM not set. Defaulting to minimum supported version\r\n16.\r\n-- Detecting C compiler ABI info\r\n-- Detecting C compiler ABI info - done\r\n-- Check for working C compiler: /Users/Desktop/android-ndk-r20b/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang - skipped\r\n-- Detecting C compile features\r\n-- Detecting C compile features - done\r\n-- Detecting CXX compiler ABI info\r\n-- Detecting CXX compiler ABI info - done\r\n-- Check for working CXX compiler: /Users/Desktop/android-ndk-r20b/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang++ - skipped\r\n-- Detecting CXX compile features\r\n-- Detecting CXX compile features - done\r\nTFLITE_ENABLE_XNNPACK = OFF\r\nTFLITE_ENABLE_GPU = ON\r\n-- Looking for pthread.h\r\n-- Looking for pthread.h - found\r\n-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\r\n-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed\r\n-- Looking for pthread_create in pthreads\r\n-- Looking for pthread_create in pthreads - not found\r\n-- Looking for pthread_create in pthread\r\n-- Looking for pthread_create in pthread - not found\r\n-- Check if compiler accepts -pthread\r\n-- Check if compiler accepts -pthread - yes\r\n-- Found Threads: TRUE  \r\n-- Performing Test EIGEN_COMPILER_SUPPORT_CPP11\r\n-- Performing Test EIGEN_COMPILER_SUPPORT_CPP11 - Success\r\n-- Performing Test COMPILER_SUPPORT_std=cpp03\r\n-- Performing Test COMPILER_SUPPORT_std=cpp03 - Success\r\n-- Performing Test standard_math_library_linked_to_automatically\r\n-- Performing Test standard_math_library_linked_to_automatically - Failed\r\n-- Performing Test standard_math_library_linked_to_as_m\r\n-- Performing Test standard_math_library_linked_to_as_m - Failed\r\nCMake Error at build_arm64/eigen/CMakeLists.txt:105 (message):\r\n  Can't link to the standard math library.  Please report to the Eigen\r\n  developers, telling them about your platform.\r\n\r\n\r\n-- Configuring incomplete, errors occurred!\r\nSee also \"/lite/build_arm64/CMakeFiles/CMakeOutput.log\".\r\nSee also \"/lite/build_arm64/CMakeFiles/CMakeError.log\".\r\n```\r\n\r\nAnd some pieces of \u201cCMakeError.log\u201d:\r\n```\r\nPerforming C SOURCE FILE Test CMAKE_HAVE_LIBC_PTHREAD failed with the following output:\r\nChange Dir: /Users/Desktop/TFLite_test/lite/build_arm64/CMakeFiles/CMakeTmp\r\n\r\nRun Build Command(s):/usr/bin/make -f Makefile cmTC_0c08b/fast && /Applications/Xcode.app/Contents/Developer/usr/bin/make  -f CMakeFiles/cmTC_0c08b.dir/build.make CMakeFiles/cmTC_0c08b.dir/build\r\nBuilding C object CMakeFiles/cmTC_0c08b.dir/src.c.o\r\n/Users/Desktop/android-ndk-r20b/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang --target=aarch64-none-linux-android21 --gcc-toolchain=/Users/Desktop/android-ndk-r20b/toolchains/llvm/prebuilt/darwin-x86_64 --sysroot=/Users/Desktop/android-ndk-r20b/toolchains/llvm/prebuilt/darwin-x86_64/sysroot -DCMAKE_HAVE_LIBC_PTHREAD  -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -fno-addrsig -Wa,--noexecstack -Wformat -Werror=format-security   -fPIE -MD -MT CMakeFiles/cmTC_0c08b.dir/src.c.o -MF CMakeFiles/cmTC_0c08b.dir/src.c.o.d -o CMakeFiles/cmTC_0c08b.dir/src.c.o -c /Users/Desktop/TFLite_test/lite/build_arm64/CMakeFiles/CMakeTmp/src.c\r\n/Users/Desktop/TFLite_test/lite/build_arm64/CMakeFiles/CMakeTmp/src.c:13:3: warning: implicit declaration of function 'pthread_cancel' is invalid in C99 [-Wimplicit-function-declaration]\r\n  pthread_cancel(thread);\r\n  ^\r\n1 warning generated.\r\nLinking C executable cmTC_0c08b\r\n/usr/local/Cellar/cmake/3.20.0/bin/cmake -E cmake_link_script CMakeFiles/cmTC_0c08b.dir/link.txt --verbose=1\r\n/Users/Desktop/android-ndk-r20b/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang --target=aarch64-none-linux-android21 --gcc-toolchain=/Users/Desktop/android-ndk-r20b/toolchains/llvm/prebuilt/darwin-x86_64 --sysroot=/Users/Desktop/android-ndk-r20b/toolchains/llvm/prebuilt/darwin-x86_64/sysroot -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -fno-addrsig -Wa,--noexecstack -Wformat -Werror=format-security   -Wl,--exclude-libs,libgcc.a -Wl,--exclude-libs,libatomic.a -static-libstdc++ -Wl,--build-id -Wl,--warn-shared-textrel -Wl,--fatal-warnings -Wl,--no-undefined -Qunused-arguments -Wl,-z,noexecstack -Wl,--gc-sections   CMakeFiles/cmTC_0c08b.dir/src.c.o -o cmTC_0c08b  -latomic -lm \r\nCMakeFiles/cmTC_0c08b.dir/src.c.o: In function `main':\r\n/Users/Desktop/TFLite_test/lite/build_arm64/CMakeFiles/CMakeTmp/src.c:13: undefined reference to `pthread_cancel'\r\n/Users/Desktop/TFLite_test/lite/build_arm64/CMakeFiles/CMakeTmp/src.c:13: undefined reference to `pthread_cancel'\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\nmake[1]: *** [cmTC_0c08b] Error 1\r\nmake: *** [cmTC_0c08b/fast] Error 2\r\n```\r\n\r\n```\r\nPerforming C++ SOURCE FILE Test standard_math_library_linked_to_automatically failed with the following output:\r\nChange Dir: /Users/Desktop/TFLite_test/lite/build_arm64/CMakeFiles/CMakeTmp\r\n\r\nRun Build Command(s):/usr/bin/make -f Makefile cmTC_6117b/fast && /Applications/Xcode.app/Contents/Developer/usr/bin/make  -f CMakeFiles/cmTC_6117b.dir/build.make CMakeFiles/cmTC_6117b.dir/build\r\nBuilding CXX object CMakeFiles/cmTC_6117b.dir/src.cxx.o\r\n/Users/Desktop/android-ndk-r20b/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang++ --target=aarch64-none-linux-android21 --gcc-toolchain=/Users/Desktop/android-ndk-r20b/toolchains/llvm/prebuilt/darwin-x86_64 --sysroot=/Users/Desktop/android-ndk-r20b/toolchains/llvm/prebuilt/darwin-x86_64/sysroot -Dstandard_math_library_linked_to_automatically  -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -fno-addrsig -Wa,--noexecstack -Wformat -Werror=format-security   -std=c++03  -fPIE -MD -MT CMakeFiles/cmTC_6117b.dir/src.cxx.o -MF CMakeFiles/cmTC_6117b.dir/src.cxx.o.d -o CMakeFiles/cmTC_6117b.dir/src.cxx.o -c /Users/Desktop/TFLite_test/lite/build_arm64/CMakeFiles/CMakeTmp/src.cxx\r\nIn file included from /Users/Desktop/TFLite_test/lite/build_arm64/CMakeFiles/CMakeTmp/src.cxx:2:\r\n/Users/Desktop/android-ndk-r20b/toolchains/llvm/prebuilt/darwin-x86_64/sysroot/usr/include/c++/v1/cmath:622:68: error: too many arguments provided to function-like macro invocation\r\n  static_assert(is_same<_FloatT, float>::value || is_same<_FloatT, double>::value\r\n                                                                   ^\r\n/Users/Desktop/android-ndk-r20b/toolchains/llvm/prebuilt/darwin-x86_64/sysroot/usr/include/c++/v1/__config:861:13: note: macro 'static_assert' defined here\r\n#    define static_assert(__b, __m) _Static_assert(__b, __m)\r\n            ^\r\nIn file included from /Users/Desktop/TFLite_test/lite/build_arm64/CMakeFiles/CMakeTmp/src.cxx:2:\r\n/Users/Desktop/android-ndk-r20b/toolchains/llvm/prebuilt/darwin-x86_64/sysroot/usr/include/c++/v1/cmath:622:3: error: use of undeclared identifier 'static_assert'\r\n  static_assert(is_same<_FloatT, float>::value || is_same<_FloatT, double>::value\r\n  ^\r\n2 errors generated.\r\nmake[1]: *** [CMakeFiles/cmTC_6117b.dir/src.cxx.o] Error 1\r\nmake: *** [cmTC_6117b/fast] Error 2\r\n```\r\n\r\n**Seems like there are some problems in ndk who doesn't contain full pthread supports\uff1f\uff1f\uff1fPlease guys, I need your help ! thanks a lot!**", "comments": ["I've just tried this on my machine with android-ndk-r21b and it works well.\r\n\r\nCould you try it again with NDK version android-ndk-r21b ?", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50577\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50577\">No</a>\n", "> I've just tried this on my machine with android-ndk-r21b and it works well.\r\n> \r\n> Could you try it again with NDK version android-ndk-r21b ?\r\n\r\n@ymodak sorry i'm late\uff0c i changed to r22b\uff0cit works.   thanks a lot!"]}, {"number": 50576, "title": "add multiple classifications  without network", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):arm-linux\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version (or github SHA if from source):tensorflow1.13.0\r\nhello!\r\nUsers don't understand any code, and they may be in a environment without network. I'm using the classification algorithm model.How can users add multiple categories to the usage model? In addition, in model deployment, I use C + + to deploy the tflite model. What do I need to do on the tflite model node, hoping to give me a little idea?", "comments": ["@xzy-666 ,\r\n\r\nWe see that you are using tf version 1.13, 1.x is not actively supported, please update to 2.x and let us know if you are using same issue.Thanks!", "hello, @tilakrayal \r\nPersonally, I think my question has little to do with tensorflow. It is more about forward reasoning.Thanks!", "An example to run tflite with C++ API is here: https://www.tensorflow.org/lite/api_docs/cc/class/tflite/interpreter", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50576\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50576\">No</a>\n"]}, {"number": 50574, "title": "build fails on AArch64, Fedora 33 due to --config=numa, missing sysctl.h", "body": "[jw@cn05 master]$ bazel --output_user_root=/tmp/bazel build --local_ram_resources=6144 --config=numa //tensorflow/tools/pip_package:build_pip_package --verbose_failures\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=120\r\nINFO: Reading rc options for 'build' from /data/jw/tensorflow/master/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /data/jw/tensorflow/master/.bazelrc:\r\n  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true\r\nINFO: Reading rc options for 'build' from /data/jw/tensorflow/master/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/lib/python3.9/site-packages --python_path=/usr/bin/python3\r\nINFO: Found applicable config definition build:short_logs in file /data/jw/tensorflow/master/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /data/jw/tensorflow/master/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:numa in file /data/jw/tensorflow/master/.bazelrc: --define=with_numa_support=true\r\nINFO: Found applicable config definition build:linux in file /data/jw/tensorflow/master/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false\r\nINFO: Found applicable config definition build:dynamic_kernels in file /data/jw/tensorflow/master/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS\r\nDEBUG: /tmp/bazel/b636c1968d8e13825d4613e0f3304062/external/tf_runtime/third_party/cuda/dependencies.bzl:51:10: The following command will download NVIDIA proprietary software. By using the software you agree to comply with the terms of the license agreement that accompanies the software. If you do not agree to the terms of the license agreement, do not use the software.\r\nINFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded, 0 targets configured).\r\nINFO: Found 1 target...\r\nERROR: /tmp/bazel/b636c1968d8e13825d4613e0f3304062/external/hwloc/BUILD.bazel:229:11: C++ compilation of rule '@hwloc//:hwloc' failed (Exit 1): gcc failed: error executing command\r\n  (cd /tmp/bazel/b636c1968d8e13825d4613e0f3304062/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/opt/FJSVstclanga/default/lib64:/opt/FJSVstclanga/default/lib64: \\\r\n    PATH=/home/jw/c4aarch64_installer/bin:/home/jw/.sdkman/candidates/groovy/current/bin:/home/jw/.sdkman/candidates/gradle/current/bin:/opt/FJSVstclanga/default/bin:/usr/lib64/qt-3.3/bin:/usr/condabin:/usr/lib64/ccache:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/jw/.composer/vendor/bin:/home/jw/.dotnet/tools:/var/lib/snapd/snap/bin:/opt/FJSVstclanga/default/bin:/home/jw/.local/bin:/home/jw/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/usr/bin/python3 \\\r\n    PYTHON_LIB_PATH=/usr/lib/python3.9/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n  /usr/lib64/ccache/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -MD -MF bazel-out/aarch64-opt/bin/external/hwloc/_objs/hwloc/topology.d '-frandom-seed=bazel-out/aarch64-opt/bin/external/hwloc/_objs/hwloc/topology.o' -iquoteexternal/hwloc -iquotebazel-out/aarch64-opt/bin/external/hwloc -isystem external/hwloc/hwloc -isystem bazel-out/aarch64-opt/bin/external/hwloc/hwloc -isystem external/hwloc/include -isystem bazel-out/aarch64-opt/bin/external/hwloc/include -w -DAUTOLOAD_DYNAMIC_KERNELS -I. -Ihwloc -Iinclude -Wno-vla '-DHWLOC_DUMPED_HWDATA_DIR=' '-DRUNSTATEDIR=' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c external/hwloc/hwloc/topology.c -o bazel-out/aarch64-opt/bin/external/hwloc/_objs/hwloc/topology.o)\r\nExecution platform: @local_execution_config_platform//:platform\r\nexternal/hwloc/hwloc/topology.c:45:10: fatal error: sys/sysctl.h: No such file or directory\r\n   45 | #include <sys/sysctl.h>\r\n      |          ^~~~~~~~~~~~~~\r\ncompilation terminated.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nERROR: /data/jw/tensorflow/master/tensorflow/lite/toco/python/BUILD:89:10 C++ compilation of rule '@hwloc//:hwloc' failed (Exit 1): gcc failed: error executing command\r\n  (cd /tmp/bazel/b636c1968d8e13825d4613e0f3304062/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/opt/FJSVstclanga/default/lib64:/opt/FJSVstclanga/default/lib64: \\\r\n    PATH=/home/jw/c4aarch64_installer/bin:/home/jw/.sdkman/candidates/groovy/current/bin:/home/jw/.sdkman/candidates/gradle/current/bin:/opt/FJSVstclanga/default/bin:/usr/lib64/qt-3.3/bin:/usr/condabin:/usr/lib64/ccache:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/jw/.composer/vendor/bin:/home/jw/.dotnet/tools:/var/lib/snapd/snap/bin:/opt/FJSVstclanga/default/bin:/home/jw/.local/bin:/home/jw/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/usr/bin/python3 \\\r\n    PYTHON_LIB_PATH=/usr/lib/python3.9/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n  /usr/lib64/ccache/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -MD -MF bazel-out/aarch64-opt/bin/external/hwloc/_objs/hwloc/topology.d '-frandom-seed=bazel-out/aarch64-opt/bin/external/hwloc/_objs/hwloc/topology.o' -iquoteexternal/hwloc -iquotebazel-out/aarch64-opt/bin/external/hwloc -isystem external/hwloc/hwloc -isystem bazel-out/aarch64-opt/bin/external/hwloc/hwloc -isystem external/hwloc/include -isystem bazel-out/aarch64-opt/bin/external/hwloc/include -w -DAUTOLOAD_DYNAMIC_KERNELS -I. -Ihwloc -Iinclude -Wno-vla '-DHWLOC_DUMPED_HWDATA_DIR=' '-DRUNSTATEDIR=' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c external/hwloc/hwloc/topology.c -o bazel-out/aarch64-opt/bin/external/hwloc/_objs/hwloc/topology.o)\r\nExecution platform: @local_execution_config_platform//:platform\r\nINFO: Elapsed time: 3.058s, Critical Path: 0.74s\r\nINFO: 98 processes: 49 internal, 49 local.\r\nFAILED: Build did NOT complete successfully\r\n[jw@cn05 master]$ \r\n\r\nCf. issue #104801, which refers also to #45861. ", "comments": ["@LutzWeischerFujitsu \r\n\r\nWe see that the issue [template](https://github.com/tensorflow/tensorflow/issues/new?assignees=&labels=type%3Abuild%2Finstall&template=10-build-installation-issue.md) has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error]. Thanks\r\n", "Fedora 33\r\nA64FX\r\nsource code, (recent) master\r\nPython 3.9.5\r\nno virtualenv, standard pip, conda\r\nbazel 3.7.2- (@non-git), compiled from source \r\ngcc (GCC) 10.3.1 20210422 (Red Hat 10.3.1-1)\r\nno CUDA\r\nno GPU\r\n\r\n./configure, standard answers ", "Also getting this with the following command line (but with config set up with CUDA)\r\n\r\n```\r\nTMP=/tmp bazel build --jobs 12 -c opt --config=opt --config=v2 --config=mkl --config=numa     ... //tensorflow/tools/pip_package:build_pip_package --verbose_failures\r\n```\r\n\r\nCompiling on Fedora 34 with CUDA. Commenting out the line mentioned in #45861 fixes the issue.", "@utzWeischerFujitsu \r\nIn your case, have you set \"--config=mkl\" in the build cmd?", "@coderforlife \r\nIn your case, there is error of the build setting:\r\n  CUDA and \"--config=mkl\" can't be present in same time. \r\n  There is conflict of them in code path to implement the same OPs (like Conv2d). The result is unknown.\r\n\r\nPlease keep one of them in your build setting.\r\n\r\n", "Just noticed that ./configure already sets numa + mkl. ", "@LutzWeischerFujitsu \r\n\r\nI see you are using Fedora 33 which includes glibc version 2.3 as default.\r\nBut glibc 2.3 has removed sys/sysctl.h.\r\n\r\nCould you try glibc 2.2?\r\n\r\nThank you!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50574\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50574\">No</a>\n"]}, {"number": 50573, "title": "[CherryPick:r2.6]Fix deprecation notice.", "body": "`None` is the acceptable value here.\n\n`deprecation.py` fix description of `deprecated_args`'s `*deprecated_arg_names_or_tuples` argument. The Okay value should be a single value, not a list.\n\nPiperOrigin-RevId: 382287123\nChange-Id: Ief25b4a9db03bc0ff3bc7847692f2f130635fb61", "comments": []}, {"number": 50572, "title": "Update tf.keras engine sequential.py: add predict_classes, predict_proba deprecation warnings", "body": "`Model.predict_classes` and `Model.predict_proba` are deprecated and the warnings won't be seen by the users until they attempt to call the methods.\r\n\r\nThe messages should be in line with https://developers.google.com/devsite/reference/styles/notices#warning as discussed @lamberta @MarkDaoust", "comments": ["@8bitmp3  Please submit it to the [github.com/keras-team/keras](github.com/keras-team/keras) repository instead. Thank you!", "@gbaned @MarkDaoust The deprecated APIs were removed in `keras-team/keras` `sequential.py` https://github.com/keras-team/keras/commit/f4a382d66c12a7d20f9e7ad92be9a8e8bd4582bb#diff-3f56e791abb6fa7510fc1b987e6ad29cbc042b7e129af906d71be274bdb03e56 but `tensorflow/keras` `sequential.py` appears to still mention them https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/sequential.py ", "Yes, the team is still cleaning up those orphaned files in `tensorflow/python/keras`. In TensorFlow 2.6 (or tf-nightly) the source files are still there, but the public API is built from the source in `keras-team/keras`."]}, {"number": 50571, "title": "custom trained ssd_mobilenet_v1_fpn_shared_coco model cannot detect object with Tensorflow", "body": "### System information\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**:\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:MacOS BigSur version:11.2.1\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**:Not\r\n-   **TensorFlow installed from (source or binary)**:source\r\n-   **TensorFlow version (use command below)**:1.14.0\r\n-   **Python version**:3.6\r\n-   **Bazel version (if compiling from source)**:-\r\n-   **GCC/Compiler version (if compiling from source)**:\r\n-   **CUDA/cuDNN version**:-\r\n-   **GPU model and memory**:-\r\n-   **Exact command to reproduce**:-\r\n\r\n### Describe the problem\r\nHi all,\r\n\r\nI created a customer trained tflite model for my Tensorflow object detection project(which will be running on ios),\r\nbut somehow inferecing(object detection) does not work properly.\r\nDuring inferecing, the model detects always the first trained item(the first item which is in my labelmap.txt file) and\r\ngives some wrong scores as object detection prediction.\r\n\r\nDoes anyone an idea what the problem could be?\r\n\r\nHere is step by step my project flow:\r\n\r\n1- I trained my images with ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync model:\r\n1.1 Code:\r\nhttps://github.com/tensorflow/models\r\n(master branch)\r\n1.2 Command:\r\npython3.7 train.py\r\n--logtostderr\r\n--train_dir=/Users/Documents/Temp/tensorflow_last/models/train\r\n--pipeline_config_path=/Users/Documents/Temp/tensorflow_last/models/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync.config\r\nNote:I can also attach my config file, if it is related\r\n1.3 Output:\r\n...\r\nINFO:tensorflow:global step 89547: loss = 0.0628 (8.283 sec/step)\r\nI0629 19:34:56.030186 4505345536 learning.py:512] global step 89547: loss = 0.0128 (8.283 sec/step)\r\nINFO:tensorflow:global step 89548: loss = 0.0596 (9.801 sec/step)\r\nI0629 19:35:05.831597 4505345536 learning.py:512] global step 89548: loss = 0.0196 (9.801 sec/step)\r\n...\r\n\r\n2-Converted trained model to tflite_graph.pb file:\r\n2.1Code:\r\nhttps://github.com/tensorflow/models\r\n(master branch)\r\n2.2Command:\r\npython3.6 models/research/object_detection/object_detection/export_tflite_ssd_graph.py\r\n--pipeline_config_path=/Users/emre/Documents/Temp/tensorflow_last/models/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync.config\r\n--trained_checkpoint_prefix=/Users/emre/Documents/Temp/tensorflow_last/models/train/model.ckpt-90728\r\n--output_directory=/Users/emre/Documents/Temp/tensorflow_last/models/Lite\r\n2.3Output:\r\n/usr/local/bin/python3.6 /Users/emre/Documents/Temp/tensorflow_last/models/research/object_detection/object_detection/export_tflite_ssd_graph.py --pipeline_config_path=/Users/emre/Documents/Temp/tensorflow_last/models/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync.config --trained_checkpoint_prefix=/Users/emre/Documents/Temp/tensorflow_last/models/train/model.ckpt-89545 --output_directory=/Users/emre/Documents/Temp/tensorflow_last/models/Lite\r\n['/Users/emre/Documents/Temp/tensorflow_last/models/research/object_detection/object_detection', '/Users/emre/Documents/Temp/tensorflow_last/models/research/object_detection', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python36.zip', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/lib-dynload', '/Users/emre/Library/Python/3.6/lib/python/site-packages', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/aeosa', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/object_detection-0.1-py3.6.egg', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/lvis-0.5.3-py3.6.egg', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/apache_beam-2.27.0-py3.6-macosx-10.9-x86_64.egg', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/avro_python3-1.10.1-py3.6.egg', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_model_optimization-0.5.0-py3.6.egg', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_datasets-4.2.0-py3.6.egg', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_addons-0.12.1-py3.6-macosx-10.9-x86_64.egg', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/seqeval-1.2.2-py3.6.egg', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sentencepiece-0.1.95-py3.6-macosx-10.9-x86_64.egg', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/py_cpuinfo-7.0.0-py3.6.egg', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/psutil-5.8.0-py3.6-macosx-10.9-x86_64.egg', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/opencv_python_headless-4.5.1.48-py3.6-macosx-10.9-x86_64.egg', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/oauth2client-4.1.3-py3.6.egg', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/kaggle-1.5.10-py3.6.egg', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google_cloud_bigquery-2.7.0-py3.6.egg', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gin_config-0.4.0-py3.6.egg', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/dataclasses-0.8-py3.6.egg', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/opencv_python-4.5.1.48-py3.6-macosx-10.9-x86_64.egg', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pymongo-3.11.3-py3.6-macosx-10.9-x86_64.egg', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pydot-1.4.1-py3.6.egg', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pyarrow-2.0.0-py3.6-macosx-10.9-x86_64.egg', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mock-2.0.0-py3.6.egg', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/httplib2-0.17.4-py3.6.egg', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/hdfs-2.5.8-py3.6.egg', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/fastavro-1.3.1-py3.6-macosx-10.9-x86_64.egg', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/dill-0.3.1.1-py3.6.egg', '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/crcmod-1.7-py3.6-macosx-10.9-x86_64.egg']\r\n2021-06-29 19:23:16.734088: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\nINFO:tensorflow:Found and fixed 2 matches\r\nI0629 19:23:17.298635 4339817984 exporter.py:140] Found and fixed 2 matches\r\nINFO:tensorflow:Found and fixed 0 matches\r\nI0629 19:23:17.328562 4339817984 exporter.py:140] Found and fixed 0 matches\r\nWARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse standard file APIs to check for files with this prefix.\r\nW0629 19:23:17.652231 4339817984 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse standard file APIs to check for files with this prefix.\r\nINFO:tensorflow:Restoring parameters from /Users/emre/Documents/Temp/tensorflow_last/models/train/model.ckpt-89545\r\nI0629 19:23:18.414107 4339817984 saver.py:1280] Restoring parameters from /Users/emre/Documents/Temp/tensorflow_last/models/train/model.ckpt-89545\r\nWARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.compat.v1.graph_util.convert_variables_to_constants`\r\nW0629 19:23:19.047316 4339817984 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.compat.v1.graph_util.convert_variables_to_constants`\r\nWARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.compat.v1.graph_util.extract_sub_graph`\r\nW0629 19:23:19.047602 4339817984 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.compat.v1.graph_util.extract_sub_graph`\r\nINFO:tensorflow:Froze 333 variables.\r\nI0629 19:23:19.428654 4339817984 graph_util_impl.py:311] Froze 333 variables.\r\nINFO:tensorflow:Converted 333 variables to const ops.\r\nI0629 19:23:19.579565 4339817984 graph_util_impl.py:364] Converted 333 variables to const ops.\r\n2021-06-29 19:23:19.800005: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes\r\n\r\n3-Converted tflite_graph.pb to tflite file:\r\n3.1Code:\r\nhttps://github.com/tensorflow/models\r\n(master branch)\r\n3.2Command:\r\npython3.6 tflite_convert.py --output_file=test.tflite --graph_def_file=tflite_graph.pb --input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'  --input_shape=1,640,640,3 --allow_custom_ops\r\n3.3Output:\r\n2021-06-29 19:15:19.235482: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\nhallo\r\n2021-06-29 19:15:19.931976: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TFLite_Detection_PostProcess\r\n2021-06-29 19:15:19.976190: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 900 operators, 1329 arrays (0 quantized)\r\n2021-06-29 19:15:20.001280: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 900 operators, 1329 arrays (0 quantized)\r\n2021-06-29 19:15:20.111332: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 187 operators, 417 arrays (0 quantized)\r\n2021-06-29 19:15:20.116690: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 182 operators, 407 arrays (0 quantized)\r\n2021-06-29 19:15:20.121787: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 182 operators, 407 arrays (0 quantized)\r\n2021-06-29 19:15:20.124878: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 182 operators, 407 arrays (0 quantized)\r\n2021-06-29 19:15:20.132192: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 52428800 bytes, theoretical optimal value: 39321600 bytes.\r\n2021-06-29 19:15:20.133140: I tensorflow/lite/toco/toco_tooling.cc:433] Estimated count of arithmetic ops: 103.489 billion (note that a multiply-add is counted as 2 ops).\r\n2021-06-29 19:15:20.134138: W tensorflow/lite/toco/tflite/operator.cc:2112] Ignoring unsupported type in list attribute with key '_output_types'\r\n\r\n4-I downloaded following projects for tflite object detection and camera capture:\r\nCode:\r\nhttps://github.com/teticio/kivy-tensorflow-helloworld\r\nand\r\nhttps://kivy.org/doc/stable/examples/gen__camera__main__py.html\r\n\r\n5-I modified and merged them a little bit, so if I click the capture button, captures the camera view, it detects objects (which are trained in my model) from captured photo and prints out\r\nthe item number(class_id in labelmap.txt) and score of the detected object predication.\r\n\r\n6-If I execute my custom trained model(on Macos), my code prints out always the first class_id and some wrong scores, it does not matter which photos I show:\r\n6.1Ex:(first photo)\r\n2021-06-29 19:19:14.526 Python[14486:591568] Selected FPS (30) not available on this platform.\r\n{'bounding_box': array([0.77786434, 0.4134923 , 0.8920009 , 0.5161122 ], dtype=float32), 'class_id': 0.0, 'score': 0.84353364}\r\n6.2Ex:(second photo)\r\n2021-06-29 19:19:20.729 Python[14486:591568] Selected FPS (30) not available on this platform.\r\n{'bounding_box': array([0.7591856 , 0.41594303, 0.8673101 , 0.5112757 ], dtype=float32), 'class_id': 0.0, 'score': 0.9267361}\r\n{'bounding_box': array([0.42481518, 0.6758945 , 0.53535295, 0.7300209 ], dtype=float32), 'class_id': 0.0, 'score': 0.50106883}\r\n{'bounding_box': array([0.6508195 , 0.6713367 , 0.7614183 , 0.72627753], dtype=float32), 'class_id': 0.0, 'score': 0.4232775}\r\n6.3Ex:(third photo)\r\n2021-06-29 19:19:27.549 Python[14486:591568] Selected FPS (30) not available on this platform.\r\n{'bounding_box': array([0.6415653 , 0.2917411 , 0.7683315 , 0.38982102], dtype=float32), 'class_id': 0.0, 'score': 0.9865758}\r\n\r\nIf I use another tflite pre-trained model with my code(racoon and squirrel detection SD-MobileNet-V2-Quantized-COCO model\r\nlink:https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi)\r\nit works totally fine. I get following output if I show a squirrel or racoon photo to camera and capture.\r\n6.4 Ex: racoon\r\n2021-07-01 21:27:53.884 Python[21077:785260] Selected FPS (30) not available on this platform.\r\n{'bounding_box': array([0.10106477, 0.5392377 , 0.5041685 , 0.9078557 ], dtype=float32), 'class_id': 2.0, 'score': 0.9921875}\r\n6.5 Ex: squirrel\r\n2021-07-01 21:28:15.506 Python[21077:785260] Selected FPS (30) not available on this platform.\r\n{'bounding_box': array([0.28669962, 0.52812684, 0.83007085, 0.8363091 ], dtype=float32), 'class_id': 1.0, 'score': 0.95703125}\r\n\r\nAdditional Note: If I use pretrained frozen \u201cssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync\u201d model\r\nLink:https://docs.openvinotoolkit.org/latest/omz_models_model_ssd_mobilenet_v1_fpn_coco.html\r\n\r\nWith the code from following website:\r\nLink:https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10\r\nIt works also totally fine. So I do not think that ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync model has a basic problem.\r\nSo I guess something wrong is happening in Step 2(converting .pb file to tflite_graph.pb) and/or step3\r\n(converting tflite_graph.pb file to tflite)\r\n\r\nI would be grateful, if you give me some advices.\r\n\r\nThanks a lot in advance.\r\n\r\n### Source code / logs\r\n-\r\n", "comments": ["So does your TF model (before converting to TFLite) work properly?", "Hi Thaink, thanks for the advice. I have not tried it yet. Unfortunately I have just a saved model so I will try to convert it to frozen model with following code:\r\nhttps://blog.metaflow.fr/tensorflow-how-to-freeze-a-model-and-serve-it-with-a-python-api-d4f3596b3adc\r\n\r\nand execute it following code example:\r\nhttps://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10\r\n\r\nand then let you know.\r\n\r\nBest Regards\r\n", "@emre84 ,\r\n\r\nWe see that you are using tf version 1.14, 1.x is not actively supported, please update to 2.x and let us know if you are using same issue.", "Hi Tilakrayal, I upgraded my tf to 2.0.0, unfortunately it still occurs. \r\n\r\nHi Thaink, when I tried to convert my saved model to frozen model, I recognised that I do not have any defined output nodes. \r\n\r\nCode for frozen model creation:\r\nhttps://blog.metaflow.fr/tensorflow-how-to-freeze-a-model-and-serve-it-with-a-python-api-d4f3596b3adc\r\nAt Line 51:\r\noutput_node_names.split(\",\") \r\nError message:\r\nassert d in name_to_node, \"%s is not in graph\" % d\r\nAssertionError: detection_boxes is not in graph\r\n\r\nI saw that \"detection_boxes\" is not the right output node name. I tried to see which output nodes, I have. But unfortunately following line returns null:\r\n[n.name for n in tf.get_default_graph().as_graph_def().node]\r\n\r\nTherefore I can not create frozen model to check my model if it works fine or not. (before converting to TFLite as you recommended above)\r\nCan undefined output nodes be my problem? If it is so, do you have an idea, how I can fix it?\r\n\r\nThanks a lot in advance.", "Hi,\r\nYou can check if your saved model contains valid signature_def following: https://www.tensorflow.org/guide/saved_model\r\nStarting from:\r\n\r\n````\r\n\r\nloaded = tf.saved_model.load(mobilenet_save_path)\r\nprint(list(loaded.signatures.keys()))  # [\"serving_default\"]\r\n````\r\n\r\nIf the saved model does not contains input, output information, the conversion might not work properly.", "Hi Thank, thanks again for the response. When I try to  get loaded.signatures.keys, I am getting following error:\r\n\r\nOSError: SavedModel file does not exist at: /Users/emre/Documents/Temp/tensorflow_last/models/train/{saved_model.pbtxt|saved_model.pb}\r\n\r\nThe problem is, I do not have any .pb file in my train folder. The only files I have are:\r\n\r\ncheckpoint, events.out.tfevents.1613600796.emres-air, graph.pbtxt, model.ckpt-90728.meta, model.ckpt-90728.index, and pipeline.config\r\n\r\nSo I am trying to create frozen model from these files. Do I miss any point? \r\n\r\nNote:Exactly the same files as described in this website:\r\nhttps://blog.metaflow.fr/tensorflow-how-to-freeze-a-model-and-serve-it-with-a-python-api-d4f3596b3adc", "The graph.pbtxt is a text file. You might try to open it and find your input/output node names.", "Thanks again :) Perfect. You are right, all nodes are defined in this file. Do you know which node I have to use exactly?\r\n\r\n[graph.txt](https://github.com/tensorflow/tensorflow/files/6775603/graph.txt)\r\n", "I actually have no idea. You better asks the model authors about that.\r\nIf that is not possible, then you might make a script to search through the file for:\r\n - potential input nodes is node that is not output of any op\r\n - potential ouput nodes is node that is not input to any op\r\n\r\n", "Closing this issue as there is no activity and is not a bug or feature request in TF. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50571\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50571\">No</a>\n"]}, {"number": 50570, "title": "Cudnn frontend v0.4: Support of int8x4, API updates", "body": "Cudnn frontend v0.4 released: https://github.com/NVIDIA/cudnn-frontend/releases/tag/v0.4\r\n\r\nAccordingly, this PR does the following things:\r\n- Support vector data type (Currently only int8x4);\r\n- Change setDataType() in OperationBuilder to setComputePrecision()\r\n- Update setAlpha/Beta which can deduce the datatype from the compute precision instead of given alpha/beta.\r\n\r\ncc. @nluehr ", "comments": ["Also add awpr@ since he is working on these files as well.", "@awpr Thanks for your comments. Most of your feedback are resolved. PTAL.\r\n\r\nFor the int8x32 support, the IMMA kernels require the reordered filter/bias (more can be found https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnReorderFilterAndBias). So, for the frontend API, we are still working on if/how we should expose the reordering things to users. That is why in the v0.4 release note only contains the int8x4 samples.", "> So, for the frontend API, we are still working on if/how we should expose the reordering things to users.\r\n\r\nAt the risk of distracting from the PR: I'd like the ability to say \"I have already reordered it\" to be exposed in the frontend API.\r\n\r\nIdeally in XLA we will do the reordering ourselves.  That is, we'd like you to tell us what the reordering is (or I guess we'll figure it out by observing what ReorderFilterAndBias does).  Then we'll teach XLA to do this reordering itself.\r\n\r\nBy doing so, we'll be able to fuse the reordering operation into other ops, hopefully making it free.", "> > So, for the frontend API, we are still working on if/how we should expose the reordering things to users.\r\n> \r\n> At the risk of distracting from the PR: I'd like the ability to say \"I have already reordered it\" to be exposed in the frontend API.\r\n> \r\n> Ideally in XLA we will do the reordering ourselves. That is, we'd like you to tell us what the reordering is (or I guess we'll figure it out by observing what ReorderFilterAndBias does). Then we'll teach XLA to do this reordering itself.\r\n> \r\n> By doing so, we'll be able to fuse the reordering operation into other ops, hopefully making it free.\r\n\r\nExactly, we would like exposing this feature for advanced users like XLA who knows what's going on with manual filter/bias reordering. For now, the API will just assume filter/bias has already reordered if we simply change the `vectorCount` to 32 in the cudnn code sample or if we enable int8x32 in this PR.", "@kaixih hey, when I turn this on and try to use it, the graphs fail to build: `CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR: cudnnFinalize Failed`\r\n\r\nDo you know how to debug this?", "Can you try the `TF_CPP_VMODULE=cuda_dnn=4` to output the logs? Then, at lease we can get an idea of the conv shape. Also the cudnn logs would help us to repro the issue if we know it is a cudnn issue.\r\n\r\nMay I ask if this is for the normal convolution or fused conv?", "Hi, thanks so much for the reply!\r\n\r\nI'm looking at fused convs.  Here is a failure chosen at random.  This has cudnn logging plus some logs from TensorFlow showing the conv shape.\r\n\r\nhttps://gist.github.com/jlebar/a63d912cf20a422772e39f5c6d82c8c8", "Hi Justin, I did a quick check and it seems the problem is the bias tensor doesn't get vectorized:\r\nhttps://gist.github.com/jlebar/a63d912cf20a422772e39f5c6d82c8c8#file-gistfile0-txt-L3002-L3009 (The vectorCount and vectorDim lines are missing for this tensor.)\r\n\r\nCould you please check if the bias tensor is correctly vectorized? For example, here the `vector_size` should be 4: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/stream_executor/cuda/cuda_dnn.cc#L3583\r\n", "Thank you, @kaixih.  That gets me further.  Now the convs run but fail the test because of \"wrong\" results.  I think something is still wrong, but let me debug that first.\r\n\r\nIn the meantime, one other question if you don't mind.  For the legacy API, if you do a fused convolution with the identity activation, you must use `CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM`.  The other algorithms appear to do an implicit relu even if you don't ask for it.\r\n\r\nI'm seeing the same thing with the new API.  Some algorithm choices are doing a relu when I don't ask for it.\r\n\r\nIn the new API, what's the right way to check that I'm doing CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM?", "> Now the convs run but fail the test because of \"wrong\" results. I think something is still wrong, but let me debug that first.\r\n\r\nTurns out this was actually also the \"I ask for identity activation function but it does relu anyway\" problem.  That is, int8x4+relu seems to work fine with the fix you suggested!\r\n\r\nYay, we're almost there.\r\n\r\nI really appreciate your help, @kaixih.", "OK, an update on this.  We've figured out how to read the algorithm id!\r\n\r\nNew-algorithm 11 seems to correspond to the old IMPLICIT_PRECOMP_GEMM.\r\n\r\nIf the activation function is the identity function, is it correct to ignore all algs that are not new-algorithm-11?", "Yes, I just checked that the engine index 11 (or \"new algorithm\" in your comment) is an IMPLICIT_PRECOMP_GEMM_XXX engine, meaning it's just one of many IMPLECIT_PRECOMP_GEMM engines used inside the legacy algorithm IMPLICIT_PRECOMP_GEMM.\r\n\r\nFor the identity activation issue, I think the cudnn fusion still has limitation on supporting arbitrary no-op in the supported fusion pattern (but as mentioned in the email, the plan is to have more comprehensive support for runtime fusion for NHWC, at least for this particular pattern.).\r\n\r\nAlso, if your observation holds that ConvBiasAdd+No-op actually works when using engine 11 via the pattern of ConvBiasAddRelu (sorry, I couldn't confirm it right now), I think it is a good idea to file a bug towards cudnn to support this variant pattern (i.e. allowing Relu to be Indentity/No-Op) via an update over the heuristics/fallback, which IMO seems to be straightfoward.", "Thank you again, @kaixih.\r\n\r\nWe now have a new issue, sent on the google/nvidia mailing list, but in case you're not checking that right now:\r\n\r\nWe're encountering a strange issue when we combine\r\n\r\n - cudnn 8.2.1\r\n - the cudnn frontend, and\r\n - int8x4 fused-conv-bias-add operations.\r\n\r\nThe issue seems to have to do with the lifetime of cudnn frontend plans.\r\n\r\nWe observe that when we enable the cudnn frontend, then during and immediately after autotuning, our int8x4 convolutions behave as expected and output the correct result.  But when we come back and rerun the same conv at some point after, the conv with a saved ExecutionPlan gives the wrong answer.  Many values in the output are wrong by large amounts; I can't see a pattern in the wrong output.\r\n\r\nWhen the conv gives the wrong answer, we can rebuild a new ExecutionPlan and use it to get the *right* answer.  Unfortunately, this is very slow.\r\n\r\nAs far as I can tell, this doesn't affect fp32 or fp16 convs, only int8 convs.\r\n\r\nWe've done most of our testing on cudnn 8.2.1, but I also just this afternoon verified that 8.2.2 has the same behavior.  We can reproduce on V100 and sm75 with CUDA 11.3.\r\n\r\nDo you have any idea what might be going on?  Maybe there's some implicit lifetime in the ExecutionPlan that we're not respecting?  Or maybe there's something subtle that's broken with int8x4?", "Yes, sounds like a execution plan lifetime issue. Let me reply it in the email thread."]}, {"number": 50569, "title": "Support Cudnn Frontend Errata Filter", "body": "Cudnn frontend v0.4 introduces a new API to allow users to filtering out undesired engines: https://github.com/NVIDIA/cudnn-frontend/releases/tag/v0.4. Users can either hard-code a list of those engines or provide a JSON file via `CUDNN_ERRATA_JSON_FILE` during runtime. This feature could greatly improve the debugging process.\r\n\r\nThis PR integrate this feature by allowing both hard-coded errata list (intentionally blank for now) and runtime list. An example of using runtime list:\r\n```bash\r\n# cat /home/tmp/sample_errata.json\r\n{ \"version\" : 1,\r\n  \"rules\"   : [\r\n    { \"rule_id\"             : \"ConvFwd_eng1\",\r\n      \"operation\"           : \"ConvFwd\",\r\n      \"engine\"              : 1,\r\n      \"knob\"                : [],\r\n      \"cudnn_version_start\" : 8000,\r\n      \"cudnn_version_end\"   : -1\r\n    }\r\n  ]\r\n}\r\n\r\n# CUDNN_ERRATA_JSON_FILE=/home/tmp/sample_errata.json TF_CPP_VMODULE=cuda_dnn=4 python -u conv2d_tf2_func.py\r\n...\r\n2021-07-01 20:50:21.828423: I tensorflow/stream_executor/cuda/cuda_dnn.cc:4489] Exclude engine (runtime): ConvFwd_eng1_k2=3_k3=0\r\n2021-07-01 20:50:21.828626: I tensorflow/stream_executor/cuda/cuda_dnn.cc:4489] Exclude engine (runtime): ConvFwd_eng1_k2=0_k3=0\r\n...\r\n```\r\n\r\ncc. @nluehr ", "comments": ["Changed to use the cache for json handle and revert the previous related commit. PTAL. @timshen91 "]}, {"number": 50568, "title": "Update tf.keras engine training.py: deprecation doc strings", "body": "In line with https://developers.google.com/devsite/reference/styles/notices#warning as discussed @lamberta @MarkDaoust ", "comments": ["It looks like your PR relates to the Keras component. Please submit it to the [github.com/keras-team/keras](github.com/keras-team/keras) repository instead. Thank you!"]}, {"number": 50566, "title": "Update release notes with a more explicit \"Breaking changes\" section \u2026", "body": "\u2026for keras code.\r\n\r\nPiperOrigin-RevId: 382409626\r\nChange-Id: Iafa1921691aafc62ea5ec2b3b199df06e8495398", "comments": []}, {"number": 50565, "title": "Be explicit about the type signature of map_func", "body": "Highlight tf.data.Dataset such that the reader doesn't miss it. The typing was mentioned at the top of the doc but not immediately visible at the params table.\r\n\r\nMotivation for this change is that after studying this doc, a user still came up with code calling `interleave` with a function that takes element and returns element.", "comments": ["Thanks @rainwoodman, the new wording is clearer."]}, {"number": 50564, "title": "Cherry-pick: Fix deprecation notice.", "body": "`None` is the acceptable value here.\r\n\r\n`deprecation.py` fix description of `deprecated_args`'s `*deprecated_arg_names_or_tuples` argument. The Okay value should be a single value, not a list.\r\n\r\nb/192248069\r\nPiperOrigin-RevId: 382287123\r\nChange-Id: Ief25b4a9db03bc0ff3bc7847692f2f130635fb61", "comments": []}]