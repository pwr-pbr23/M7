[{"number": 302, "title": "Generating Data Flow Graph for existing code or IR, ByteCode, IL, Object Code, AST, etc.", "body": "There are a lot of existing libraries and code.  It will be good if there is a mechanism to generated the Dataflow representation of these programs in TensorFlow. Say I have a library you can analyse the Intermediate Code (ByteCode, IL, IR, Web Asm, Object Code, directly from particular languages code, etc.) and from this generate the DataFlow graph with a view to target GPU, FPGA, Other Accelerate or conventional scenarios.\n\nThere were some commercial products doing just the above but I have forgotten some of these vendors. https://www.maxeler.com/ also do this but just one of the vendors I remember.\n", "comments": ["This is out of scope for the main tensorflow project.  Projects that generate TF graphs from other intermediate representations are certainly possible, but they would belong in separate repos.\n"]}, {"number": 301, "title": "I think there is a small mistake in the tensorflow's documents", "body": "I don't know whether it's right to report documents mistakes in this place,i don't find other place to report mistakes...\nOn tensorflow's website, the introduce of [tf.transpose(a, perm=None, name='transpose')](http://tensorflow.org/api_docs/python/array_ops.md#transpose) in the doc says:\n\nFor example:\n\n```\n# 'x' is [[1 2 3]\n#         [4 5 6]]\ntf.transpose(x) ==> [[1 4]\n                     [2 5]\n                     [3 6]]\n\n# Equivalently\ntf.transpose(x perm=[0, 1]) ==> [[1 4]\n                                 [2 5]\n                                 [3 6]]\n```\n\nI think the perm should be [1, 0] , not [0, 1].\n", "comments": ["Thanks, we've noticed this and it should be in the next git sync. \n"]}, {"number": 300, "title": "visualizing feature maps using tensorboard?", "body": "After following the tensorboard intro guides and looking at the tensorboard data produced from the cifar example, I'm also wondering if tensorboard allows you to display feature maps like this:\n\nhttp://neuralnetworksanddeeplearning.com/images/net_full_layer_0.png\n", "comments": ["I actually was wondering the same and got an answer on stack overflow http://stackoverflow.com/questions/33802336/visualizing-output-of-convolutional-layer-in-tensorflow\n", "Thanks @panmari!  Yes, this is a better question for stackoverflow. \n", "thanks!\n"]}, {"number": 299, "title": "www.tensorflow.org returns a 404 :)", "body": "Which is funny, because it's indexed in Google Web Search as www.tensorflow.org :)\n\ntensorflow.org works though...\n", "comments": ["Thanks for reporting - we had a brief outage, but the site's back up now!\n"]}, {"number": 298, "title": "Correct links to rnn and sequence-to-sequence tutorials", "body": "", "comments": []}, {"number": 297, "title": "Navigation of docs has just become very difficult", "body": "The new docs pages have been changed so that the left navigation pane no longer has collapsable entries. This seems like a step back in many ways, as the API pages are virtually impossible to navigate now.\n", "comments": ["In my computer, there are some sections in the menu that are hidden at the bottom of the screen. The scrollbar reaches the end before these sections entries can be displayed on the side menu.\n", "We have fixed the bug @cesarsalgado found, it should appear soon. \n", "@martinwicke The problem persists as can be seen in this screenshot: https://goo.gl/photos/h1fEJ2KiE4yZrHA36\n", "Should be fixed now.\n", "@cesarsalgado's issue is fixed. The accordion is still not done.\n", "@martinwicke, @danmane: Is this still an issue? \n", "@girving I am still having the same problem: https://goo.gl/photos/RfPszQCKECafxocQA\n\nI can't see the Image Recognition sub-items. \n", "Also the API documentation still does not have the accordion. It's just a long list of entries that's very hard to navigate.\n", "@cesarsalgado What browser are  you using and on what OS? This works for me.\n", "Operating System: Ubuntu 14.04 LTS\nThe picture in my last comment was taken under Firefox 42.\n\nNow I tested on chrome Version 47.0.2526.73 (64-bit) and now I can scroll all the way to the bottom but the scroll bar disappear in the bottom of the screen: https://goo.gl/photos/DbTTZhEMXfD8gVXR8 \n", "My screen resolution is: 1366x768 (16:9)\n", "We're working on backend changes, this will eventually be resolved by that work. Hang tight.\n", "@martinwicke is this still being worked on?\n", "Yes. Will be addressed in docs infrastructure move. Can be closed but I\nleft it open so signal we are aware that it sucks.\nOn Mon, Aug 15, 2016 at 15:51 Alexandre Passos notifications@github.com\nwrote:\n\n> @martinwicke https://github.com/martinwicke is this still being worked\n> on?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/297#issuecomment-239952553,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AAjO_bR9jjp43efz6xoGQGy0vYUm9jv1ks5qgO1agaJpZM4GlyBs\n> .\n", "Reassigning for the honor of closing.\n", "With the website move, this should be resolved.\r\n@wolffg , I think we are now ready to close this issue.", "Docs navigation has accordions and twistdowns now for easier navigation.  I'm going to close this."]}, {"number": 296, "title": "Better support for composite dataflow variables and time series", "body": "Perhaps you can have better support for composite data flow variables. E.g. modelling a moving window multivariate time-series, where you have a series of vectors and as new vectors are added calculations are triggered only for values which need re calculation. Also if a calculation is dependent on a slice updates are propagated in the most optimal way that only the needed data is recalculated.\n\nThe composite values can be:\n- Same type:\n  - Vectors\n  - Matrices\n  - Arrays\n  - Series\n  - Data frames\n  - Slices\n- Different types:\n  - Tuples (also series with different types)\n  - Tables (also Data Frames with different types)\n  - Views (slices with different types)\n", "comments": ["This can include dataflow optimised data structures.\n", "This is somewhat covered by the queue functionality.\n"]}, {"number": 295, "title": "Better docs for node methods", "body": "I see that nodes / tensors have a number of available methods, like `eval` and `get_shape`, which are very useful for interrogating the graph in interactive sessions for debugging and such. But as far as I can tell they're not really documented anyway. Seems like very useful features that are worth drawing attention to.\n", "comments": ["Hi there,\n\nAre you referring to the API docs for Operation and Tensor? These are provided here:\n- http://tensorflow.org/api_docs/python/framework.html#Operation\n- http://tensorflow.org/api_docs/python/framework.html#Tensor\n\nIf there's anything that's not clear in here, or that you think would be worth adding, please let us know!\n", "Yeah I see them now. Perhaps the docs should be reorganized a bit more to make them accessible? I see that the interface of the docs has changed just now, although the lack of collapseable navigation on the left makes it really hard to discover things.\n", "I like to use ipython to check the documentation of the methods. Enter obj_name. and press `tab` to show the available methods for an object and enter obj_name.method_name? to see the documentation of the method.\n"]}, {"number": 294, "title": "Rewrite git history to purge large model files", "body": "As the following commit comment https://github.com/tensorflow/tensorflow/commit/7e1e25b16ba8d01edf6d53d442cac4f93deda2c1  mentioned, I think this would be a good idea. There is no reason to keep this burden in the history.\n", "comments": ["This was done, sort of.  We removed the large model files and some animated gifs, then rewrote the history.  Unfortunately, despite some checks on our side, the animated gifs made their way back in a more recent commit. :(\n\nThe repo is a lot smaller without the models in the history, and we don't want to rewrite the history again.  We'll live with our 20-30MiB mistake.\n"]}, {"number": 293, "title": "tensorflow/tensorflow/models/rnn/ptb/ptb_word_lm.py TypeError", "body": "when running ptb_word_lm.py:\n\nFile \"ptb_word_lm.py\", line 259, in main\n    config = get_config()\n  File \"ptb_word_lm.py\", line 122, in **init**\n    self._cost = cost = tf.reduce_sum(loss) / batch_size\nTypeError: unsupported operand type(s) for /: 'Tensor' and 'int'\n\nI replaced\n self._cost = cost = tf.reduce_sum(loss) / batch_size\nto\nself._cost = cost = tf.div(tf.reduce_sum(loss), batch_size)\nand it seems to work fine.\n", "comments": ["Do you have `from __future__ import division` at the top, and are you running against tensorflow installed via pip?  As part of #1 we added `__truediv__` support to tensorflow but made the mistake of using it in the tutorials.  It should work if you remove that import, and I'll fix it so that the HEAD tutorials are compatible with the 0.5.0 release.\n", "Oh, actually that isn't a tutorial.  I think we won't try to keep stuff in `models` at HEAD backwards compatible to older versions of tensorflow.  You can fix it locally by either removing that  import line or using the version of `ptb_word_lm.py` from the `0.5.0` tag.  In general, running part of tensorflow at `HEAD` against an older release is not guaranteed to work.\n", "Reopening until the diagnosis is confirmed.\n", "Closing for now, since I believe this is fixed.\n", "girving: I had the same issue. Commenting the division import line made it work.\n", "@darolt: This shouldn't be an issue now at 0.6.0 is out.  In general, there's no guarantee that git versions of tensorflow models will work against old releases.\n"]}, {"number": 292, "title": "Rank of Tensors", "body": "I think that there is an error in the description of the rank of the tensors.\nIn the example the tensor has  rank 3 i think but you wrote that it has rank 2. \n\nhttp://tensorflow.org/resources/dims_types.html\n\n\"\nRank\n\nIn the TensorFlow system, tensors are described by a unit of dimensionality known as rank. Tensor rank is not the same as matrix rank. Tensor rank (sometimes referred to as order or degree or n-dimension) is the number of dimensions of the tensor. For example, the following tensor (defined as a Python list) has a rank of -------2-------------:\n\nt = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n\nA rank two tensor is what we typically think of as a matrix, a rank one tensor is a vector. For a rank two tensor you can acccess any element with the syntax t[i, j]. For a rank three tensor you would need to address an element with 't[i, j, k]'.\n\"\nlet me know .\nThanks\ngg\n", "comments": ["It seems correct to me. A tensor rank refers to the number of dimensions, not the size of its elements. Therefore, a vector has rank 1, a matrix has rank 2, a cube has rank 3, and so on.\n\nThis is exemplified in the following sentence `A rank two tensor is what we typically think of as a matrix, a rank one tensor is a vector` and in the table below extracted from http://tensorflow.org/resources/dims_types.html.\n\n<img width=\"812\" alt=\"screen shot 2015-11-19 at 9 15 04 am\" src=\"https://cloud.githubusercontent.com/assets/2743105/11269428/0c63a4a0-8e9e-11e5-90dd-2f536260739f.png\">\n", "Yes, that tensor has rank 2, since it's a 2-dimensional array (list of lists).\n"]}, {"number": 291, "title": "Support for special functions", "body": "If the intent is for TensorFlow to be a general purpose computational tool for machine learning there should be more support for special functions (i.e. the functions in scipy.special). In particular, functions occurring in probability distributions such as the gamma(ln) are quite central to probabilistic machine learning.\n", "comments": ["Thanks, special functions are well worth adding, and we'd welcome contributions in this direction.\n", "I was just thinking of implementing some Bayesian learning on TensorFlow and realised that I would need the Gamma and also in particular LogGamma (this is just the log of the Gamma function computed directly). These are absolutely essential for many distributions (Beta, Dirichlet). I would love to help to add them, however could you please provide some small guidance on where to start? I see there are many levels of op implementation, description, Python wrapping etc. Thanks\n", "Found it: https://www.tensorflow.org/versions/master/how_tos/adding_an_op/index.html\n", "@ebrevdo is already half-way to implementing this, I think (I think he added it to Eigen for both CPU and GPU? not sure if it's been upstreamed yet).\n", "Yeah; this has been implemented and should make it into the next upstream release.  I've added lgamma to Eigen (both ours & upstream) and added an lgamma unary op.\n\nDigamma should also make its way in, in the next 2 weeks.\n", "@ebrevdo is it possible for me to pull the lgamma implementation from your repo? I can't see it in your profile, perhaps it's internal at your company, and I can't just pull changes from it? I really need lgamma soon, can't wait ;)\n", "@ebrevdo hi, I saw you implemented erf, erfc, and lgamma in Eigen. Why not also implement tgamma from the same section of \"cmath\" header, just so that all four functions from \"Error and gamma functions\" section would be available? http://en.cppreference.com/w/cpp/header/cmath\n\nLooking forward for them to become available as TensorFlow operations! Thank you\n", "@akuz I've been using a hack where you just define a series expansion within the TF graph. It's not pretty and I don't guarantee accuracy, but if you really can't wait for proper support it might be worth a try:\n\n```\ndef gammaln(x):\n    # fast approximate gammaln from paul mineiro\n    # http://www.machinedlearnings.com/2011/06/faster-lda.html\n    logterm = tf.log (x * (1.0 + x) * (2.0 + x))\n    xp3 = 3.0 + x\n    return -2.081061466 - x + 0.0833333 / xp3 - logterm + (2.5 + x) * tf.log (xp3)\n```\n", "It'll get pushed to the public repo next week.\nOn Jan 3, 2016 8:49 AM, \"David Moore\" notifications@github.com wrote:\n\n> @akuz https://github.com/akuz I've been using a hack where you just\n> define a series expansion within the TF graph. It's not pretty and I don't\n> guarantee accuracy, but if you really can't wait for proper support it\n> might be worth a try:\n> \n> def gammaln(x):\n>     # fast approximate gammaln from paul mineiro\n>     # http://www.machinedlearnings.com/2011/06/faster-lda.html\n>     logterm = tf.log (x \\* (1.0 + x) \\* (2.0 + x))\n>     xp3 = 3.0 + x\n>     return -2.081061466 - x + 0.0833333 / xp3 - logterm + (2.5 + x) \\* tf.log (xp3)\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/291#issuecomment-168517728\n> .\n", "CPU and GPU versions of lgamma, digamma, erf, and erfc are in, igamma/igammac/betainc are coming soon.  Marking as done.\n", "Sorry to dig this up again, but are there any plans to incorporate the polygamma function (1) in the near future? Anything using a Dirichlet / Beta prior distribution will utilise the digamma function, for which the gradient is the polygamma.\n", "As far as I can tell, the digamma function is only used for entropy and\nother log-expectation calculations.  The rest use gamma or log-gamma.\n\nOn Tue, Mar 15, 2016 at 4:48 AM, dush64 notifications@github.com wrote:\n\n> Sorry to dig this up again, but are there any plans to incorporate the\n> polygamma function (1) in the near future? Anything using a Dirichlet /\n> Beta prior distribution will utilise the digamma function, for which the\n> gradient is the polygamma.\n> \n> \u2014\n> You are receiving this because you modified the open/close state.\n> Reply to this email directly or view it on GitHub:\n> https://github.com/tensorflow/tensorflow/issues/291#issuecomment-196783111\n", "That's true - sorry, should have been more specific. The digamma/polygamma come up when computing expectations and KL divergences for dirichlet distributions. Is this general enough to warrant a place in Tensorflow, or should I be independently implementing it (or contributing it)?\n", "it is worthwhile to add trigamma or polygamma from cephes.  you will have to add it to Eigen first, and verify CUDA support works.  see bitbucket.org/eigen/eigen/ and specifically my PRs adding lgamma/digamma/igamma/igammac/erf/errfc to that repository.  happy to review your code there.\n", "However, let's split any new special functions off into a new issue.\n", "Agreed; this issue is closed.  First push changes to Eigen and then open an issue to bring tri/polygamma into TensorFlow once that's done.\n"]}, {"number": 290, "title": "Check code description in seq2seq.py - embedding_rnn_seq2seq", "body": "I'm checking the codes line by line to understand how TF works. \n\nPlease check following comments are correct or not. \n\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/seq2seq.py#L198-L199\n\nIt seems that the encoder_inputs for <code>embedding_rnn_seq2seq</code> should have indexs of vocabularies.\n\n<code> encoder_inputs: [batch_size] </code> \n<code> decoder_inputs: [batch_size] </code>\n\nIf not, give some tips to understand it. \n", "comments": ["You're right, they should be 1D batch-size tensors of integers. Correcting, great thanks for bringing this up!\n", "There are similar comment - mistakes in embedding_\\* classes. (It's not that serious though)\n", "If there are comments to be fixed, please send PRs for them -- I think we correct some of these already.\n"]}, {"number": 289, "title": "Website Issue; Some lines in tutorials should pass session data", "body": "I get this error when following the [tutorial](http://tensorflow.org/tutorials/mnist/pros/index.html#deep-mnist-for-experts), using the `eval` function:\n\n```\nin _eval_using_default_session\nraise ValueError(\"Cannot evaluate tensor using eval(): No default \"\nValueError: Cannot evaluate tensor using eval(): No default session is registered. Use 'with DefaultSession(sess)' or pass an explicit session to eval(session=sess)`\n```\n\nIt also happens with `run`, for instance in the line `train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})`.\n", "comments": ["Have you followed all of the steps in the tutorial in order? Near the beginning it has instructions to [start a `tf.InteractiveSession`](http://tensorflow.org/tutorials/mnist/pros/index.html#start-tensorflow-interactivesession). If you do so, that error should never be raised. \n", "I did, but I also went through the basic and then the advanced tutorial. Maybe those lines needed to be re-ran when starting the second tutorial? Seems like something I would have neglected to do...\n"]}, {"number": 288, "title": "Sorting tensors", "body": "how to sort a tensor (argsort)?\n", "comments": ["We don't have `sort` and `argsort` ops at the moment, but would welcome contributions.\n", "Hello @girving \nI guess there is a good reason why these functions are not included in the previous version,\nwould you please elaborate?\n", "The only reason is limited resources. :)  They should clearly exist, so we'd love contributions in case we don't get to it in the near term.\n", "What about using tf.nn.top_k, with k the number of elements in the (flattened) tensor? While possibly inefficient, it works.\n", "@girving What's the status for sorting op?\n", "@edgarriba you can sort array by using `nn.top_k` \n", "@yaroslavvb are those two functions differentiable though?\n", "@edgarriba nn.top_k is an evaluation op. Evaluation ops are non differentiable so the answer is no. \nYou can read a bit more here: https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#top_k\n", "@nmduc @edgarriba Looks differentiable to me: https://github.com/tensorflow/tensorflow/blob/43346a1c81d503f0f764e09bb2f12e31a793a168/tensorflow/python/ops/nn_grad.py#L525\n", "@girving Good to know. Thanks.\nThen the doc should be changed not to make confusion. \n", "Just chiming in to say that a GPU-friendly sort function would enable efficient projection oracles for the l1-ball and simplex (http://icml2008.cs.helsinki.fi/papers/361.pdf), which would in turn make TensorFlow useful for a wide range of large-scale constrained optimization problems beyond deep learning. This and some other efficient projection oracles (e.g. l2) could maybe be rolled into ProximalGradientDescentOptimizer long-term? (as projection is a proximal operator)\r\n\r\nAlso, issue #5719 which is a feature request for GPU-enabled topK is related. Maybe these can be handled at the same time?", "+1 for adding a dedicated sorting op.\r\n\r\nWhile trying to find the fastest way to sort tensors in tensorflow, I found that numpy is actually faster than using top_k. Here's the code I used to test:\r\n\r\n```python\r\n# assume vals is already defined\r\n*_, last_dim = [int(x) for x in vals.get_shape()]\r\n\r\nsorted1, _ = tf.nn.top_k(vals, k=last_dim)\r\nsorted2 = tf.py_func(np.sort, [vals], tf.float32, stateful=False)\r\nsorted2.set_shape(vals.get_shape())\r\n```\r\n\r\nIn my case `sorted1` takes around 2.7 ms, while `sorted2` takes around 1.7 ms. I find it disappointing the tensorflow is actually slower than calling out to Python.", "It looks like top_k uses [sequential heap sort](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/lib/gtl/top_n.h). It would be a big improvement to at least have parallel quicksort or merge sort on the CPU, and support sort and argsort. @ed-alertedh mentioned a GPU top-k implementation in #5719, but it sounds like it's only faster for huge tensors.\r\n\r\nOn the CPU, we can share code for parallel sort and top_k (using quicksort and [quickselect](https://en.wikipedia.org/wiki/Quickselect)). [GPU-Quicksort](http://www.cse.chalmers.se/~tsigas/papers/GPU-Quicksort-jea.pdf) might work well too.", "I'm just waiting for clearance from my employer to open source my work so far. I've been able to make use of the thrust template library included with the CUDA SDK which has a sort op which could be applied fairly easily to sort an entire tensor (I believe it internally uses a radix sort). If sorting along an axis is required then more work may be needed - I have struggled to get the thrust templates to perform well in this kind of use-case.", "@martinwicke Any obstacles to using thrust?  Having GPU sort would be great.", "Probably worth noting that Arrayfire claims that it generally performs better than thrust [1][2]. Particularly in \"row-wise\" cases. The advantage of thrust is that, as far as I can tell, it already works in the current build environment without needing to add any third_party headers. So I took this as the path of least resistance. I'm sure you're constantly fighting people trying to add more and more deps...\r\n\r\n[1] https://gist.github.com/pavanky/2407814\r\n[2] https://arrayfire.com/benchmarking-parallel-vector-libraries/", "There's no fundamental problem with, although I am less than excited to add another STL implementation. \r\n\r\nCan we use it instead of something else we're using in core/lib? Can we check what the effect on build times is (by adding it as a dependency in a PR)?\r\n\r\n", "If we implemented this ourselves, we could also add an efficient median function (using something like quickselect).", "Note that [NVIDIA cub](https://nvlabs.github.io/cub/) was added as a dependency in [this comment](https://github.com/tensorflow/tensorflow/commits/e073322452e41e76754314aa75d543d071003fc5/tensorflow/contrib/cmake/patches/cub/CMakeLists.txt) and contains primitives for radix sorting ints and floats. Some thought will be required to see if this can be extended to complex numbers.", "Will tensorflow include a topological_sort in the future?", "TopK on the GPU is now implemented using CUB's radix sort, so should be about as fast as is possible even when k == N.  CPU uses std::sort as well for k == N.  So I'm going to close this issue.", "@ekelsen maybe we should a `tf.sort()` function which redirects to `TopK`.\r\n\r\nThat would be more user friendly.", "FYI I've just added `tf.contrib.framework.sort()`, and I may be able to add `tf.contrib.framework.argsort()` in a followup.", "@ringw thanks great job!", "Hi @ringw, did you by chance ever have an opportunity to implement `tf.contrib.framework.argsort()`?", "@thomaspheiffer Thanks for reminding me, I've finally got my argsort wrapper working and it should be merged soon!", "@ringw thanks a lot!"]}, {"number": 287, "title": "sequence_length causes error when using GRU", "body": "Calling this works just fine:\noutputs, states = rnn.rnn(gru_cell, input, initial_state=initial_state)\n\nBut this causes an error:\noutputs, states = rnn.rnn(gru_cell, input, initial_state=initial_state, sequence_length=seq_length)\n\nWhere I have tried the following for seq_length:\nseq_length = tf.placeholder(tf.int64)\nseq_length = tf.placeholder(tf.int32)\nseq_length = tf.placeholder(tf.int64, shape=[1,1])\n\nThis is the error:\n\nFile \"/site-packages/tensorflow/models/rnn/rnn.py\", line 85, in rnn\n    output_state = cell(input_, state)\n  File \"/site-packages/tensorflow/models/rnn/rnn_cell.py\", line 120, in **call**\n    2 \\* self._num_units, True, 1.0))\n  File \"/site-packages/tensorflow/models/rnn/linear.py\", line 29, in linear\n    shapes = [a.get_shape().as_list() for a in args]\n  File \"/site-packages/tensorflow/python/framework/tensor_shape.py\", line 676, in as_list\n    return [dim.value for dim in self._dims]\nTypeError: 'NoneType' object is not iterable\n", "comments": ["bug confirmed\n", "Are you using the 0.6.0 package? This should be fixed in HEAD on github.\nOn Jan 31, 2016 6:28 PM, \"Hujie Wang\" notifications@github.com wrote:\n\n> bug confirmed\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/287#issuecomment-177717230\n> .\n", "Should be fixed in 0.7+\n"]}, {"number": 286, "title": "Spread Sheet Abstraction in TensorBoard", "body": "Spreadsheet abstraction is more convenient and familiar. Is it possible to add flow based Spreadsheet like modelling capabilities:\n- http://www.ankhor.com/\n- https://www.dadisp.com/\n- http://matrex.sourceforge.net/\n- https://www.quantrix.com/en/\n\nHere the inputs and outputs on each node in the Dataflow Graph are abstracted as cells to which you can link and perform computations which forms a sub graph but which is rendered as a spreadsheet.\n", "comments": ["Also make TensorBoard an embeddable UI editor which you can use in parts of other Web UIs. \n", "Do you think at something related to [FBP](http://www.jpaulmorrison.com/fbp/software.html)?\n", "It has some resemblance. In CS there is hardly anything new but just old wine in new bottles.\n\nSome other similar projects:\n- http://noflojs.org/\n- http://www.pothosware.com/\n- http://orcc.sourceforge.net/\n- etc.\n\nBut in this case I am looking for something in the like of Flow Sheets (http://www.ankhor.com/). Again there are some project perusing things similar like: http://unisonweb.org/ and perhaps http://www.witheve.com/ depending on how it evolves.\n", "Noflo was analyzed by the same author at http://www.jpaulmorrison.com/fbp/noflo.html\n", "OK\n", "This is out of scope for tensorboard, which is a visualization platform rather than a graph generation platform.  A separate project building on tensorflow might be interesting, though!\n"]}, {"number": 285, "title": "SKFlow - in CPP", "body": "Can you consider developing https://github.com/google/skflow in CPP with binding to other languages including Python than pure Python?\n", "comments": ["This looks like an issue for skflow, which is a separate project from tensorflow.\n", "Issue tracker is not enabled in SKFlow.\n", "Unfortunately it's still a separate project, so we can't track its issues here.\n", "OK. Sure. I though they were related.\n"]}, {"number": 284, "title": "Small typo in \"Basic usage\" docs", "body": "Looks like there is a comma missing in:\n\n\"A tensor has a static type a rank, and a shape\"\n\nhttp://tensorflow.org/get_started/basic_usage.html#tensors\n", "comments": ["Thanks! We'll update the docs accordingly.\n"]}, {"number": 283, "title": "Fix typo", "body": "There's a comma missing in the list of languages we hope the community will develop front ends for.\n", "comments": ["Ah, I see, you don't take pull requests.\n"]}, {"number": 282, "title": "install on mac gives ImportError: cannot import name symbol_database", "body": "protobuf is not happy. What can I do?\n\n```\nimport tensorflow\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/Users/philipteare/anaconda/lib/python2.7/site-packages/tensorflow/__init__.py\", line 4, in <module>\n    from tensorflow.python import *\n  File \"/Users/philipteare/anaconda/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 13, in <module>\n    from tensorflow.core.framework.graph_pb2 import *\n  File \"/Users/philipteare/anaconda/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py\", line 9, in <module>\n    from google.protobuf import symbol_database as _symbol_database\nImportError: cannot import name symbol_database\n```\n", "comments": ["Most likely the runtime is selecting too old a version of protobuf -- we require protobuf 3.0.0.a3 or higher.\n\nI'd see if any other installed version of protobuf is somehow interfering.\n", "I'm on a lower version. Anyone got tips on upgrading. Preferably on anaconda\nOn 18 Nov 2015 10:06 pm, \"Vijay Vasudevan\" notifications@github.com wrote:\n\n> Most likely the runtime is selecting too old a version of protobuf -- we\n> require protobuf 3.0.0.a3 or higher.\n> \n> I'd see if any other installed version of protobuf is somehow interfering.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/282#issuecomment-157879579\n> .\n", "If you have brew installed on OS X, you can use \"brew reinstall --devel protobuf\" to upgrade your protobuf to 3.0.x (experimental). This fixes the error.\n", "Thank you. Close, but:\n\n/usr/local/Cellar/protobuf/3.0.0-alpha-2/include/google/protobuf/stubs/pbconfig.h:3:37:\nnote: expanded from macro 'GOOGLE_PROTOBUF_HASH_MAP_H'\n\n #define GOOGLE_PROTOBUF_HASH_MAP_H <unordered_map>\n\n```\n                                ^\n```\n\n2 errors generated.\n\nerror: command 'clang' failed with exit status 1\n\n---\n\nPhil Teare\nevolu8 Ltd\n\n---\n\nOn Thu, Nov 19, 2015 at 10:13 PM, victorv notifications@github.com wrote:\n\n> If you have brew installed on OS X, you can use \"brew reinstall --devel\n> protobuf\" to upgrade your protobuf to 3.0.x (experimental). This fixes the\n> error.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/282#issuecomment-158216860\n> .\n", "Did you do a \"brew doctor\" to see if you have a unlinked packages or pathing issues?\nDid you \"brew update\"?\nIf these fail, try \"brew upgrade\" which will upgrade all installed packages to the latest versions.\n", "Related to not having the right version of protobuf installed, closing due to inactivity.\n", "Fixed by upgrading protobuf, like @vrv pointed."]}, {"number": 281, "title": "Reshape docs should mention that -1 can go anywhere", "body": "I.e., -1 is not just for flattening, which is what the current docs say.\n", "comments": ["Also, what happens when you pass the empty list? I see some code doing this and I would expect it to be saying to reshape to a scalar.\n", "In review, should show up in git fairly soon.\n"]}, {"number": 280, "title": "Android App Crash On Start", "body": "After building and installing an apk with bazel mobile-install, the Android application crashes on start.  Occurs on both a Nexus 10 and a Nexus 9 on 5.1.1.\n\nLOGCAT:\n\n11-18 12:53:53.614 427-28083/? I/ActivityManager: START u0 {act=android.intent.action.MAIN cat=[android.intent.category.LAUNCHER] flg=0x10200000 cmp=org.tensorflow.demo/.CameraActivity (has extras)} from uid 10012 on display 0\n11-18 12:53:53.671 427-1019/? I/ActivityManager: Start proc 1947:org.tensorflow.demo/u0a113 for activity org.tensorflow.demo/.CameraActivity\n11-18 12:53:53.935 1963-1963/? I/dex2oat: /system/bin/dex2oat --runtime-arg -classpath --runtime-arg  --instruction-set=arm --instruction-set-features=div --runtime-arg -Xrelocate --boot-image=/system/framework/boot.art --dex-file=/data/local/tmp/incrementaldeployment/org.tensorflow.demo/dex/incremental_classes1.dex --oat-fd=23 --oat-location=/data/data/org.tensorflow.demo/cache/incremental_classes1.dex --runtime-arg -Xms64m --runtime-arg -Xmx512m\n11-18 12:53:54.114 1947-1947/org.tensorflow.demo W/linker: libtensorflow_demo.so: unused DT entry: type 0x1d arg 0x1159c7e\n11-18 12:53:54.170 1947-1969/org.tensorflow.demo D/OpenGLRenderer: Use EGL_SWAP_BEHAVIOR_PRESERVED: true\n11-18 12:53:54.177 1947-1947/org.tensorflow.demo D/Atlas: Validating map...\n11-18 12:53:54.218 1947-1969/org.tensorflow.demo I/OpenGLRenderer: Initialized EGL, version 1.4\n11-18 12:53:54.231 1947-1969/org.tensorflow.demo D/OpenGLRenderer: Enabling debug mode 0\n11-18 12:53:54.234 1947-1969/org.tensorflow.demo D/mali_winsys: new_window_surface returns 0x3000\n11-18 12:53:54.263 1947-1947/org.tensorflow.demo I/CameraManagerGlobal: getCameraService: Reconnecting to camera service\n11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Adding size: 1440x1080\n11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Adding size: 1440x960\n11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Adding size: 1280x1024\n11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Adding size: 1280x720\n11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Adding size: 960x720\n11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Adding size: 768x576\n11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Adding size: 720x576\n11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Adding size: 800x480\n11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Adding size: 720x480\n11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Adding size: 640x480\n11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 352x288\n11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 320x240\n11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 240x160\n11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 176x144\n11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 128x96\n11-18 12:53:54.298 1947-1947/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Chosen size: 640x480\n11-18 12:53:54.305 1947-1947/org.tensorflow.demo I/CameraManager: Using legacy camera HAL.\n11-18 12:53:54.350 130-887/? I/Camera2ClientBase: Camera 0: Opened. Client: org.tensorflow.demo (PID 1947, UID 10113)\n11-18 12:53:54.550 1947-1968/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Opening camera preview: 640x480\n11-18 12:53:54.555 1947-1968/org.tensorflow.demo I/CameraDeviceState: Legacy camera service transitioning to state CONFIGURING\n11-18 12:53:54.556 1947-1996/org.tensorflow.demo I/RequestThread-0: Configure outputs: 3 surfaces configured.\n11-18 12:53:54.556 1947-1996/org.tensorflow.demo D/Camera: app passed NULL surface\n11-18 12:53:54.568 1947-1998/org.tensorflow.demo D/mali_winsys: new_window_surface returns 0x3000\n11-18 12:53:54.624 427-459/? I/ActivityManager: Displayed org.tensorflow.demo/.CameraActivity: +981ms\n11-18 12:53:54.673 1947-1968/org.tensorflow.demo I/CameraDeviceState: Legacy camera service transitioning to state IDLE\n11-18 12:53:54.676 1947-1968/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Getting assets.\n11-18 12:53:54.677 1947-1968/org.tensorflow.demo I/native: tensorflow/examples/android/jni/tensorflow_jni.cc:51 Loading Tensorflow.\n11-18 12:53:54.677 1947-1968/org.tensorflow.demo I/native: tensorflow/examples/android/jni/tensorflow_jni.cc:53 Making new SessionOptions.\n11-18 12:53:54.677 1947-1968/org.tensorflow.demo I/native: tensorflow/examples/android/jni/tensorflow_jni.cc:56 Got config, 0 devices\n11-18 12:53:54.678 427-459/? I/WindowManager: Screen frozen for +948ms due to Window{259ea1a0 u0 Starting org.tensorflow.demo}\n11-18 12:53:54.679 1947-1968/org.tensorflow.demo I/native: tensorflow/core/common_runtime/local_device.cc:25 Local device intra op parallelism threads: 4\n11-18 12:53:54.684 1947-1968/org.tensorflow.demo I/native: tensorflow/core/common_runtime/direct_session.cc:45 Direct session inter op parallelism threads: 4\n11-18 12:53:54.691 1947-1968/org.tensorflow.demo I/native: tensorflow/examples/android/jni/tensorflow_jni.cc:59 Session created.\n11-18 12:53:54.691 1947-1968/org.tensorflow.demo I/native: tensorflow/examples/android/jni/tensorflow_jni.cc:62 Graph created.\n11-18 12:53:54.692 1947-1968/org.tensorflow.demo I/native: tensorflow/examples/android/jni/tensorflow_jni.cc:66 Acquired AssetManager.\n11-18 12:53:54.692 1947-1968/org.tensorflow.demo I/native: tensorflow/examples/android/jni/tensorflow_jni.cc:68 Reading file to proto: file:///android_asset/tensorflow_inception_graph.pb\n11-18 12:53:54.693 1947-1968/org.tensorflow.demo I/native: tensorflow/examples/android/jni/jni_utils.cc:85 Opening asset tensorflow_inception_graph.pb from disk with zero-copy.\n11-18 12:53:54.709 1947-1968/org.tensorflow.demo A/native: tensorflow/examples/android/jni/jni_utils.cc:90 Check failed: message->ParseFromZeroCopyStream(&lis) \n11-18 12:53:54.710 1947-1968/org.tensorflow.demo A/libc: Fatal signal 6 (SIGABRT), code -6 in tid 1968 (CameraBackgroun)\n11-18 12:53:54.820 128-128/? I/DEBUG: pid: 1947, tid: 1968, name: CameraBackgroun  >>> org.tensorflow.demo <<<\n11-18 12:53:54.867 128-128/? W/debuggerd: type=1400 audit(0.0:100): avc: denied { search } for name=\"org.tensorflow.demo\" dev=\"mmcblk0p9\" ino=97888 scontext=u:r:debuggerd:s0 tcontext=u:object_r:app_data_file:s0 tclass=dir permissive=0\n11-18 12:53:54.867 128-128/? W/debuggerd: type=1400 audit(0.0:101): avc: denied { search } for name=\"org.tensorflow.demo\" dev=\"mmcblk0p9\" ino=97888 scontext=u:r:debuggerd:s0 tcontext=u:object_r:app_data_file:s0 tclass=dir permissive=0\n11-18 12:53:54.872 128-128/? W/debuggerd: type=1400 audit(0.0:102): avc: denied { search } for name=\"org.tensorflow.demo\" dev=\"mmcblk0p9\" ino=97888 scontext=u:r:debuggerd:s0 tcontext=u:object_r:app_data_file:s0 tclass=dir permissive=0\n11-18 12:53:54.883 128-128/? I/DEBUG: Abort message: 'tensorflow/examples/android/jni/jni_utils.cc:90 Check failed: message->ParseFromZeroCopyStream(&lis) '\n11-18 12:53:54.889 128-128/? I/DEBUG:     #05 pc 01c026a8  /data/app/org.tensorflow.demo-1/lib/arm/libtensorflow_demo.so (tensorflow::internal::LogMessage::GenerateLogMessage()+432)\n11-18 12:53:54.889 128-128/? I/DEBUG:     #06 pc 01c02b78  /data/app/org.tensorflow.demo-1/lib/arm/libtensorflow_demo.so (tensorflow::internal::LogMessageFatal::~LogMessageFatal()+80)\n11-18 12:53:54.889 128-128/? I/DEBUG:     #07 pc 0139e8d4  /data/app/org.tensorflow.demo-1/lib/arm/libtensorflow_demo.so (ReadFileToProto(AAssetManager_, char const_, google::protobuf::MessageLite*)+752)\n11-18 12:53:54.889 128-128/? I/DEBUG:     #08 pc 013a1ffc  /data/app/org.tensorflow.demo-1/lib/arm/libtensorflow_demo.so (Java_org_tensorflow_demo_TensorflowClassifier_initializeTensorflow+1016)\n11-18 12:53:54.889 128-128/? I/DEBUG:     #09 pc 0000419d  /data/data/org.tensorflow.demo/cache/incremental_classes1.dex\n11-18 12:53:56.039 427-2007/? W/ActivityManager:   Force finishing activity 1 org.tensorflow.demo/.CameraActivity\n", "comments": ["Unfortunately due to the large filesize the model file assets are no longer included in the git repo, but must be downloaded and installed separately.\n\nAdditional steps required (also in readme):\n$ wget https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip -O tensorflow/examples/android/assets/inception5h.zip\n$ unzip tensorflow/examples/android/assets/inception5h.zip -d tensorflow/examples/android/assets/\n\nI'm working on a fix to have this done automatically, but it will require an update to Bazel so that new_http_archive works properly with android_binary assets.\n", "To improve on the instructions above, you should delete the zip after extracting (or download it somewhere else in the first place) so that the resulting APK does not also bundle it.\n", "Had unzipped the file with the inception5h directory present in the assets folder.  Instructions above fix the issue.\n"]}, {"number": 279, "title": "ResourceExhaustedError when testing Deep MNIST for experts", "body": "tensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shapedim { size: 10000 } dim { size: 14 } dim { size: 14 } dim { size: 64 }\n     [[Node: Conv2D_1 = Conv2D[T=DT_FLOAT, padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](MaxPool, Variable_4)]]\n     [[Node: range_3/_21 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_207_range_3\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op u'Conv2D_1', defined at:\n\nA bit more info here \n\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 256 (256B) Pool: chunks: 64 free: 24 cumulative malloc: 73160 cumulative freed: 73120\nNumber of chunks: 64, in_use chunks: 40\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 512 (512B) Pool: chunks: 8 free: 8 cumulative malloc: 3040 cumulative freed: 3040\nNumber of chunks: 8, in_use chunks: 0\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 2048 (2.0KiB) Pool: chunks: 16 free: 16 cumulative malloc: 28080 cumulative freed: 28080\nNumber of chunks: 16, in_use chunks: 0\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 4096 (4.0KiB) Pool: chunks: 16 free: 5 cumulative malloc: 24035 cumulative freed: 24024\nNumber of chunks: 16, in_use chunks: 11\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 16384 (16.0KiB) Pool: chunks: 1 free: 1 cumulative malloc: 1 cumulative freed: 1\nNumber of chunks: 1, in_use chunks: 0\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 32768 (32.0KiB) Pool: chunks: 4 free: 2 cumulative malloc: 1002 cumulative freed: 1000\nNumber of chunks: 4, in_use chunks: 2\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 65536 (64.0KiB) Pool: chunks: 8 free: 3 cumulative malloc: 2011 cumulative freed: 2006\nNumber of chunks: 8, in_use chunks: 5\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 81920 (80.0KiB) Pool: chunks: 2 free: 1 cumulative malloc: 3 cumulative freed: 2\nNumber of chunks: 2, in_use chunks: 1\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 163840 (160.0KiB) Pool: chunks: 8 free: 8 cumulative malloc: 8020 cumulative freed: 8020\nNumber of chunks: 8, in_use chunks: 0\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 212992 (208.0KiB) Pool: chunks: 20 free: 15 cumulative malloc: 42248 cumulative freed: 42243\nNumber of chunks: 20, in_use chunks: 5\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 327680 (320.0KiB) Pool: chunks: 4 free: 4 cumulative malloc: 2000 cumulative freed: 2000\nNumber of chunks: 4, in_use chunks: 0\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 425984 (416.0KiB) Pool: chunks: 4 free: 4 cumulative malloc: 5 cumulative freed: 5\nNumber of chunks: 4, in_use chunks: 0\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 655360 (640.0KiB) Pool: chunks: 4 free: 4 cumulative malloc: 8020 cumulative freed: 8020\nNumber of chunks: 4, in_use chunks: 0\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 1310720 (1.25MiB) Pool: chunks: 6 free: 6 cumulative malloc: 12020 cumulative freed: 12020\nNumber of chunks: 6, in_use chunks: 0\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 2097152 (2.00MiB) Pool: chunks: 1 free: 1 cumulative malloc: 2020 cumulative freed: 2020\nNumber of chunks: 1, in_use chunks: 0\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 2621440 (2.50MiB) Pool: chunks: 8 free: 8 cumulative malloc: 16040 cumulative freed: 16040\nNumber of chunks: 8, in_use chunks: 0\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 5242880 (5.00MiB) Pool: chunks: 8 free: 8 cumulative malloc: 18060 cumulative freed: 18060\nNumber of chunks: 8, in_use chunks: 0\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 13631488 (13.00MiB) Pool: chunks: 8 free: 3 cumulative malloc: 2008 cumulative freed: 2003\nNumber of chunks: 8, in_use chunks: 5\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 31457280 (30.00MiB) Pool: chunks: 1 free: 1 cumulative malloc: 2 cumulative freed: 2\nNumber of chunks: 1, in_use chunks: 0\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 41943040 (40.00MiB) Pool: chunks: 1 free: 1 cumulative malloc: 1 cumulative freed: 1\nNumber of chunks: 1, in_use chunks: 0\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 251658240 (240.00MiB) Pool: chunks: 1 free: 0 cumulative malloc: 1 cumulative freed: 0\nNumber of chunks: 1, in_use chunks: 1\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 503316480 (480.00MiB) Pool: chunks: 0 free: 0 cumulative malloc: 0 cumulative freed: 0\nNumber of chunks: 0, in_use chunks: 0\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:339] Chunk size: 1006632960 (960.00MiB) Pool: chunks: 3 free: 3 cumulative malloc: 3 cumulative freed: 3\nNumber of chunks: 3, in_use chunks: 0\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:345] Aggregate Region Memory: 3576057856 (3.33GiB)\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:347] Aggregate Chunk Memory: 3539046400 (3.30GiB)\nW tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:89] Out of GPU memory, see memory state dump above\nW tensorflow/core/kernels/conv_ops.cc:162] Resource exhausted: OOM when allocating tensor with shapedim { size: 10000 } dim { size: 14 } dim { size: 14 } dim { size: 64 }\nW tensorflow/core/common_runtime/executor.cc:1027] 0x3c81ab0 Compute status: Resource exhausted: OOM when allocating tensor with shapedim { size: 10000 } dim { size: 14 } dim { size: 14 } dim { size: 64 }\n     [[Node: Conv2D_1 = Conv2D[T=DT_FLOAT, padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](MaxPool, Variable_4)]]\nW tensorflow/core/common_runtime/executor.cc:1027] 0x49fab20 Compute status: Resource exhausted: OOM when allocating tensor with shapedim { size: 10000 } dim { size: 14 } dim { size: 14 } dim { size: 64 }\n     [[Node: Conv2D_1 = Conv2D[T=DT_FLOAT, padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](MaxPool, Variable_4)]]\n     [[Node: range_3/_21 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_207_range_3\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nW tensorflow/core/common_runtime/executor.cc:1027] 0x49fab20 Compute status: Resource exhausted: OOM when allocating tensor with shapedim { size: 10000 } dim { size: 14 } dim { size: 14 } dim { size: 64 }\n     [[Node: Conv2D_1 = Conv2D[T=DT_FLOAT, padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](MaxPool, Variable_4)]]\n     [[Node: Cast_1/_19 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_206_Cast_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nTraceback (most recent call last):\n  File \"/home/andorremus/PycharmProjects/facial-keypoints/mnist.py\", line 93, in <module>\n    print \"test accuracy %g\" % accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob:1.0}, session=sess)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 405, in eval\n    return _eval_using_default_session(self, feed_dict, self.graph, session)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2728, in _eval_using_default_session\n    return session.run(tensors, feed_dict)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 345, in run\n    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 419, in _do_run\n    e.code)\ntensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shapedim { size: 10000 } dim { size: 14 } dim { size: 14 } dim { size: 64 }\n     [[Node: Conv2D_1 = Conv2D[T=DT_FLOAT, padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](MaxPool, Variable_4)]]\n     [[Node: range_3/_21 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_207_range_3\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op u'Conv2D_1', defined at:\n  File \"/home/andorremus/PycharmProjects/facial-keypoints/mnist.py\", line 63, in <module>\n    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2))\n  File \"/home/andorremus/PycharmProjects/facial-keypoints/mnist.py\", line 42, in conv2d\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 207, in conv2d\n    use_cudnn_on_gpu=use_cudnn_on_gpu, name=name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 633, in apply_op\n    op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1710, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 988, in __init__\n    self._traceback = _extract_stack()\n", "comments": ["Likely a dupe of: https://github.com/tensorflow/tensorflow/issues/136\n\nWe've fixed this at HEAD for reasonable GPU memory sizes, it will be in our next binary release.  If you feel comfortable building from source, you can make progress :)\n", "Yep, didn't see it. Thanks for pointing it out.\n", "I have also the exactly same issue. I use on CUDA "]}, {"number": 278, "title": "Provide a working example involving reading csv data", "body": "I have successfully read in csv data.  I have successfully trained/classified using the mnist data utility.  But I have not successfully been able to train from csv data.\n\nIt would also be helpful to clarify pack vs concat which is done on at StackOverflow for a given question but is left unexplained on the tensorflow site.\n", "comments": ["Agreed here. \n\nAnyone at 10+ hours of lib usage will figure out the simplicity of the data pipeline, but for people rolling through the tutorial, it would be helpful to have at least one sample batch-importer for a few other popular data formats.\n", "https://www.tensorflow.org/versions/master/how_tos/reading_data/index.html#csv-files\nis what we have now.  Is there a standard data set that comes in CSV format?\n", "Isn't Fisher's iris data set available in csv?  I would think that this\nwould be good for demonstration purposes in this case.\n\nOn Tue, Dec 8, 2015 at 2:47 PM, josh11b notifications@github.com wrote:\n\n> https://www.tensorflow.org/versions/master/how_tos/reading_data/index.html#csv-files\n> is what we have now. Is there a standard data set that comes in CSV format?\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/278#issuecomment-162993978\n> .\n", "https://www.tensorflow.org/versions/master/how_tos/reading_data/#csv-files\r\n\r\nIs this sufficient to close this issue?", "Well done. This is very clear.", "Just an FYI, this was Google search result #5 for me when I searched `tensorflow classification csv` but the link you guys mention is a 404.", "The guide has moved to this page:\r\nhttps://www.tensorflow.org/programmers_guide/reading_data", "Another FYI - the updated link gunan mentioned in his last reply to hdon doesn't contain the word \"csv\" at all.", "@noamaig I found one example here : https://www.tensorflow.org/get_started/datasets_quickstart#build_a_csv_line_parser\r\n\r\nJust type CSV in the tensorflow website search bar", "@rachellim ", "I am a C/C++ programmer who wanted to play with tf, not cats, not puppies, but let's say a set of strings and floats. I googled the csv and tf for hours, what I found is 1) a lot of talk about what a neuron and what the meaning of the word \"deep\". Then 2) a lot of hugely complicated python programs with flowers and such, using data I don't want. And some 3) short and incomplete or 4) long and complicated documents that does not say how to define a simple network, read the data from a txt file and print the results.\r\n\r\nIt is extremely frustrating.", "@lpere -- thanks for the feedback, and sorry to hear it was frustrating. When I google \"tensorflow csv data\", the second result I get is [\"Importing Data | TensorFlow\" ](https://www.tensorflow.org/guide/datasets) (Note that if you click on the first result, there is a link on a page to this page too). \r\n\r\nYou'll see a section for \"Consuming CSV data\" on this page that I added on May 18. Does this fit your needs? If not, let me know I can improve the documentation there."]}, {"number": 272, "title": "softmax_cross_entropy_with_logits to take integer labels / avoid giant dense one-hot matrix", "body": "Currently to compute this loss for a classifier you need to generate a big dense matrix of one-hot vectors to pass to softmax_cross_entropy_with_logits, as in the example at http://tensorflow.org/tutorials/mnist/tf/index.html#loss\n\nThis is kinda fiddly to do, but also rather wasteful of memory especially in the case of a larger multiclass softmax. Could we have a version of this function which accepts a list of indices, e.g. like Theano's: http://deeplearning.net/software/theano/library/tensor/nnet/nnet.html#tensor.nnet.categorical_crossentropy ?\n", "comments": ["This is a good suggestion -- (we named the existing op _with_logits because we anticipated this request, not because we like long function names ;).  I don't have a roadmap for exactly when this will be done though, but thanks for filing the feature request!\n", "Cool, thanks!\n\nSlightly confused by the logits thing -- in the docs that refers to the first argument (the input to the softmax) not the 'labels'/one-hot-vectors argument, no? Even then, the inputs to the softmax are unnormalized log-probabilities, but are they logits? I thought logits were log(p / (1-p)), rather than log p + const.\n\nEdit: I'm guessing it was called 'logits' by (dodgy?) analogy to the corresponding argument in `sigmoid_cross_entropy_with_logits` ?\n", "Is it possible to create a generic \"select\" function for tensor? Example usage:\n\n```\n     batch_size = tf.size(labels)\n     logits_selected = tf.select(logits, tf.range(0, batch_size), labels)\n     ....\n```\n", "@chuanwen: I'm not sure what exactly you mean, is that some combination of tf.where and tf.gather?\n", "`sparse_softmax_cross_entropy_with_logits()` is now available\n"]}, {"number": 271, "title": "Predicting words instead of probabilities?", "body": "The tensorflow tutorial on language model allows to compute the probability of sentences :\n\nprobabilities = tf.nn.softmax(logits)\n\nin the comments below it also specifies a way of predicting the next word instead of probabilities but does not specify how this can be done. So how to output a word instead of probability using this example?\n\n```\nlstm = rnn_cell.BasicLSTMCell(lstm_size)\n# Initial state of the LSTM memory.\nstate = tf.zeros([batch_size, lstm.state_size])\n\nloss = 0.0\nfor current_batch_of_words in words_in_dataset:\n    # The value of state is updated after processing each batch of words.\n    output, state = lstm(current_batch_of_words, state)\n\n    # The LSTM output can be used to make next word predictions\n    logits = tf.matmul(output, softmax_w) + softmax_b\n    probabilities = tf.nn.softmax(logits)\n    loss += loss_function(probabilities, target_words)\n\n```\n", "comments": ["Hi @aliabbasjp: This kind of question is better suited to the StackOverflow forums or the discuss@tensorflow.org mailing list -- can you please repost there?  Thanks!\n", "Currently in the translate model, they take the argmax of these logits for the next word. The words aggregated together give the predicted sentence. \n"]}, {"number": 270, "title": "Error: tensorflow/core/common_runtime/executor.cc:1052] 0x400d2bbe0 Compute status: Not found: ./checkpoints_directory/translate.ckpt-200.tempstate9246663217899500702", "body": "I have described the  error  in detail with all the output:\nhttp://stackoverflow.com/questions/33772819/tensorflow-error-on-running-the-seq2seq-model\n\nThe other language model example is working and the library has also been built. As per comments I created the checkpoint directory , still throwing the same error: tensorflow/core/common_runtime/executor.cc:1052] 0x400d2bbe0 Compute status: Not found: ./checkpoints_directory/translate.ckpt-200.tempstate9246663217899500702\n", "comments": ["(Stack overflow is indeed the right venue for this type of question, given the information so far)\n"]}, {"number": 269, "title": "LLVM JIT / Runtime Code Re Optimisation", "body": "Some optimisations may not be apparent when statical set up. Perhaps TensorFlow can do some staging and optimisation of the execution while running based on usage patterns.\n\nPerhaps you can borrow some ideas from projects related to: https://scala-lms.github.io/\n", "comments": ["De-duping this with: https://github.com/tensorflow/tensorflow/issues/164 (try not to consolidate discussion about a feature request or topic if possible -- otherwise it makes it hard for us to keep track of all these issues :).  We'll split them into new issues if needed though).\n", "OK. Updated the above issue.\n"]}, {"number": 268, "title": "Can't install on ubuntu", "body": "New to ubuntu\n\nTrying to install tensorflow using\n\n$ sudo pip ...\n\nI get:\n\n......\n\n  \"Cannot compile 'Python.h'. Perhaps you need to \"\n\nSystemError: Cannot compile 'Python.h'. Perhaps you need to install python-dev|python-devel.\n\n---\n\nCleaning up...\nCommand /usr/bin/python -c \"import setuptools, tokenize;**file**='/tmp/pip_build_root/numpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(**file**).read().replace('\\r\\n', '\\n'), **file**, 'exec'))\" install --record /tmp/pip-yiRxwW-record/install-record.txt --single-version-externally-managed --compile failed with error code 1 in /tmp/pip_build_root/numpy\nTraceback (most recent call last):\n  File \"/usr/local/bin/pip\", line 9, in <module>\n    load_entry_point('pip==1.5.4', 'console_scripts', 'pip')()\n  File \"/usr/lib/python2.7/dist-packages/pip/**init**.py\", line 235, in main\n    return command.main(cmd_args)\n  File \"/usr/lib/python2.7/dist-packages/pip/basecommand.py\", line 161, in main\n    text = '\\n'.join(complete_log)\nUnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 72: ordinal not in range(128)\n\n$\n\nAny help is greatly appreciated\n", "comments": ["Did you do as suggested and apt-get install python-dev ?\n", "Thanks much vrv!\n\nAfter\n\n$ sudo apt-get install python-dev\n\nthe tenorflow installation worked\n\nThanks again!\n", "solved my problem,thks.:)\n", "it works.\n", "work for me too.\n2015\u5e7412\u670822\u65e5 20:48\uff0c\"mark-liuyanjun\" notifications@github.com\u5199\u9053\uff1a\n\n> it works.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/268#issuecomment-166609019\n> .\n"]}]