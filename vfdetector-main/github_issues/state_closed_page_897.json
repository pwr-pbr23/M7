[{"number": 26567, "title": "Tensorflow 2.0 with CUDA 9", "body": "The default installation were on CUDA 10 of tensorflow 2.\r\n\r\nHow to install tensorflow 2.0 with cuda 9?", "comments": ["You have to build TF from sources yourself for cuda 9 with TF 2.0"]}, {"number": 26566, "title": "Unknown default keras 'categorical_crossentropy' loss function when converting with .h5 to .tflite ", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n-> I used just default code from the rstudio/keras library, no custom loss function\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n-> Ubuntu 16.04.5 LTS (Xenial Xerus) debian\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n-> tensorflow installed via rstudio/keras and install.packages(\"tensorflow\")\r\n- **TensorFlow version (use command below)**:\r\n->1.13.1\r\n- **Python version**:\r\n-> 2.7.12\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n-> Cuda compilation tools, release 9.0, V9.0.176\r\n- **GPU model and memory**:\r\n-> P2-Instance AWS EC\"\r\n     8*  K80-GPUs from NVIDIA, 64 vCPUs, 732 GiB Host-Speicher \r\n- **Exact command to reproduce**:\r\n`import tensorflow as tf\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model_file(\"test.h5\")\r\ntflite_model = converter.convert()\r\nopen(\"converted_model.tflite\", \"wb\").write(tflite_model)`\r\n\r\n\r\n### Describe the problem\r\nI am trying to convert a keras model from .h5 to .tflite file.\r\nI created the model in R using rstudio/keras and everything works fine.\r\nOnce I saved the model as .h5 file, I'm switching to Python (because there is no R converter from .5 to .tflite). But when I'm trying to convert the keras model with the default code from the TensorFlow Lite documentation: [,](https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter) I am getting the following error:\r\n\r\n`Traceback (most recent call last):\r\n  File \"/tmp/RtmpWIBDmu/chunk-code-849197e0a8f.txt\", line 3, in <module>\r\n    converter = tf.lite.TFLiteConverter.from_keras_model_file(\"test.h5\")\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/lite/python/lite.py\", line 370, in from_keras_model_file\r\n    keras_model = _keras.models.load_model(model_file)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/saving.py\", line 266, in load_model\r\n    sample_weight_mode=sample_weight_mode)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/checkpointable/base.py\", line 442, in _method_wrapper\r\n    method(self, *args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 282, in compile\r\n    loss_function = training_utils.get_loss_function(loss)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/training_utils.py\", line 873, in get_loss_function\r\n    return losses.get(loss)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/losses.py\", line 594, in get\r\n    return deserialize(identifier)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/losses.py\", line 585, in deserialize\r\n    printable_module_name='loss function')\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py\", line 212, in deserialize_keras_object\r\n    function_name)\r\nValueError: Unknown loss function:loss_categorical_crossentropy`\r\n\r\nBut as you can see in the source code, I am using the a default keras loss function?\r\n\r\n### Source code / logs\r\nThis is the Code to create and train the model\r\n`library(keras)\r\nbatch_size <- 128\r\nnum_classes <- 10\r\nepochs <- 5\r\n\r\n# Input image dimensions\r\nimg_rows <- 28\r\nimg_cols <- 28\r\nfashion_mnist <- dataset_fashion_mnist()\r\ntrain_images <- fashion_mnist$train$x\r\ntrain_labels <- fashion_mnist$train$y\r\ntest_images <- fashion_mnist$test$x\r\ntest_labels <- fashion_mnist$test$y\r\n\r\ntrain_images <- array_reshape(train_images, c(nrow(train_images), img_rows, img_cols, 1))\r\ntest_images <- array_reshape(test_images, c(nrow(test_images), img_rows, img_cols, 1))\r\ninput_shape <- c(img_rows, img_cols, 1)\r\n\r\n# Transform RGB values into [0,1] range\r\ntrain_images <- train_images / 255\r\ntest_images <- test_images / 255\r\n\r\ntrain_labels <- to_categorical(train_labels, num_classes)\r\ntest_labels <- to_categorical(test_labels, num_classes)\r\n\r\nmodel <- keras_model_sequential() %>%\r\n  layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = 'relu',input_shape = input_shape) %>% \r\n  layer_max_pooling_2d(pool_size = c(2, 2)) %>% \r\n  layer_flatten() %>% \r\n  layer_dense(units = 128, activation = 'relu') %>% \r\n  layer_dense(units = num_classes, activation = 'softmax')\r\n\r\nmodel %>% compile(\r\n  loss = loss_categorical_crossentropy,\r\n  optimizer = optimizer_adadelta(),\r\n  metrics = c('accuracy')\r\n)\r\n\r\nmodel %>% fit(\r\n  train_images, train_labels,\r\n  batch_size = batch_size,\r\n  epochs = epochs,\r\n  validation_split = 0.2,\r\n  callbacks = list(callback_tensorboard(log_dir = \"./logs/mnist\")\r\n))\r\n\r\nscore <- model %>% evaluate(test_images, test_labels)\r\n\r\ncat('Test loss:', score$loss, \"\\n\")\r\ncat('Test accuracy:', score$acc, \"\\n\")\r\n\r\nsave_model_hdf5(model,\"test.h5\")\r\n`\r\n", "comments": ["@jokerstudios , could you please try with\r\nmodel %>% compile(\r\nloss = categorical_crossentropy,\r\noptimizer = optimizer_adadelta(),\r\nmetrics = c('accuracy')\r\n)\r\n\r\nHope this will help you", "@joyalbin thank you for your reply.\r\nsadly if I try your solution, I get the following error whenI'm  trying to compile the model.\r\n`Error in compile(., loss = categorical_crossentropy, optimizer = optimizer_adadelta(), : object 'categorical_crossentropy' not found`\r\n\r\nUPDATE:\r\nif you put some quotation marks around the loss function you proposed, it works!! \r\nmodel %>% compile(\r\nloss = 'categorical_crossentropy',\r\noptimizer = optimizer_adadelta(),\r\nmetrics = c('accuracy')\r\n)\r\n\r\nI think it would be great if this could be communicated to the rstudio/keras team, so people wont have to train their models again when they want to compile them to .tflite ", "@jokerstudios I understand that it was resolved by @joyalbin .\r\nCould you reframe title of the issue so that it will be more helpful to the community? Thanks.\r\nClose the issue if everything was resolved. Thanks! ", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing the issue as it was resolved. thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=26566\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=26566\">No</a>\n"]}, {"number": 26565, "title": "bazel build tensorflow/python/tools:freeze_graph Error:no package '@icu//'", "body": "when i use freeza_graph ,i face a problem:\r\n$bazel build tensorflow/python/tools:freeze_graph\r\nStarting local Bazel server and connecting to it...\r\nINFO: Invocation ID: 1327e781-b5f7-4f42-9ce5-dc35448da7db\r\nERROR: /mnt/hgfs/share1/tensorflow-master/tensorflow/core/kernels/BUILD:4791:1: no such package '@icu//': java.io.IOException: thread interrupted and referenced by '//tensorflow/core/kernels:string_util'\r\nERROR: Analysis of target '//tensorflow/python/tools:freeze_graph' failed; build aborted: no such package '@icu//': java.io.IOException: thread interrupted\r\nINFO: Elapsed time: 612.379s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (194 packages loaded, 10048 target\\\r\ns configured)\r\n    Fetching @icu; fetching 547s\r\nHow I can solove this problem?", "comments": ["CUDA 10.0\r\nCuDNN 7.4\r\nOS Linux ***.iu.edu 3.10.0-862.6.3.el7.x86_64\r\nbazel 0.22\r\nNVidia P100 and V100\r\n\r\nI reproduce the initial error (no such package...) but the java.io.. error is different:\r\n\r\n$bazel build --config=opt --config=noaws --config=nogcp --config=nohdfs --config=noignite --config=nokafka //tensorflow/tools/pip_package:build_pip_package\r\nINFO: Invocation ID: d790060c-7ae2-4ecd-8834-8fda6454b5f4\r\nERROR: /N/dc2/projects/osg-storage/Python-3.7.2/tensorflow/tensorflow/tools/pip_package/BUILD:147:1: no such package '@icu//': java.io.IOException: Disk quota exceeded and referenced by '//tensorflow/tools/pip_package:licenses'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: no such package '@icu//': java.io.IOException: Disk quota exceeded\r\nINFO: Elapsed time: 85.256s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded, 0 targets configured)\r\n\r\nThe /N/dc2 filesystem has 414 TB of free space, I suspect the error messages after the icu error are spurious.\r\n", "turns out it was my home directory that was getting fragged. Bazel is rather aggressive with cacheing and was using /home/... rather than the large FS I thought it would use. Deleting /home/.cache/bazel did no harm and fixed my problem. ", "@steige2 Is this resolved? Please close it if it was resolved. Thanks!", "I\u2019ve decided to abandon MPI support for this at my institution after the support situation was explained.\nI was the ticket in a closed state and I did not reopen it, it must be the other reporter.\nS\n\nIf you tear a hole in a net you have fewer holes\n\nScott Teige PhD\nDeep Learning\nIndiana University Research Technologies\nsteige@iu.edu\nOffice: +1 812 856 7331\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n> On Mar 12, 2019, at 5:58 PM, Vishnuvardhan Janapati <notifications@github.com> wrote:\n> \n> @steige2 <https://github.com/steige2> Is this resolved? Please close it if it was resolved. Thanks!\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub <https://github.com/tensorflow/tensorflow/issues/26565#issuecomment-472196300>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AKfDqXZmfeEPEI_SB2ZzANQbAC-HsXALks5vWCL9gaJpZM4bn-CZ>.\n> \n\n", "I think it was resolved. I am closing the issue. If you think I made a mistake, please open another issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=26565\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=26565\">No</a>\n"]}, {"number": 26564, "title": "Homepage display issue: www.tensorflow.org", "body": "It is ok. Thanks!\r\n\u0421\u043f\u0430\u0441\u0438\u0431\u043e!", "comments": []}, {"number": 26563, "title": "Removed duplicates and rectified the example Code", "body": "Fixed Duplicates and rectified the example code in the file.", "comments": []}, {"number": 26562, "title": "`max_pool_with_argmax` GPU kernel supports `include_batch_in_index`", "body": "Fix #22025, #24067\r\n\r\nRelated PR: #25241, #23993", "comments": ["@reedwm @alextp Hi, Reed, Alexandre, could you take a look? Thanks."]}, {"number": 26561, "title": "Support run_forever used by low-latency usecases", "body": "`run_forever` is an explicit option which is not enabled by default.\r\n\r\nThis PR corresponds with https://github.com/tensorflow/tensorflow/issues/26318.\r\n\r\nUsage sample:\r\n```python\r\nopts = tf.RunOptions(experimental=tf.RunOptions.Experimental(run_forever=True))\r\nsess.run(tf.print(tf.constant(1)), options=opts)\r\n```", "comments": ["Thanks for your contribution! Since we've announced that `tf.Session` is being deprecated and removed from TensorFlow 2.0, I don't think we'll be accepting any new features in that API, and I'm going to close this issue.\r\n\r\nThis particular case seems like it would be handled reasonably well by existing control mechanisms in TensorFlow, such as `tf.while_loop()` or `Dataset.map()` (over an infinite dataset of dummy values). In particular, the new implementation of `tf.while_loop()` for TensorFlow V2 should have lower overhead for calling the body function than repeatedly executing a `DirectSession::RunInternal()` call.", "@mrry How to `while_loop` a basic `tf.print`, is it possible?"]}, {"number": 26560, "title": "Update initializers.py", "body": "Added missing documentation string", "comments": ["Nagging Reviewer @fchollet, @pavithrasv: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 14 days with no activity and the `awaiting review` label has been applied.", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F26560) for more info**.\n\n<!-- need_author_cla -->", "@penpornk I have accepted your suggestion, can you do cla check. Thanks", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F26560) for more info**.\n\n<!-- cla_yes -->", "@PariksheetPinjari909 Could you please resolve the conflict?", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F26560) for more info**.\n\n<!-- need_author_cla -->", "I am closing the PR as the changes are already taken. "]}, {"number": 26559, "title": "tensorflow1.12 hangs at LocalMaster::RunStep with tf.train.MonitoredTrainingSession", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source \r\n- TensorFlow version (use command below): 1.12\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): 0.18\r\n- GCC/Compiler version (if compiling from source): 5.4\r\n- CUDA/cuDNN version: \r\n- GPU model and memory:\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\nb'v1.12.0-18-gd60b574' 1.12.0\r\n\r\n**Describe the current behavior**\r\nIn distributed tensorflow, some workers hang at the last batch of dataset when the dataset epoch is 1 and the step in StopAtStepHook() is very large. What's more, the number of samples in the last batch of dataset may less than the batch_size.\r\nIf we use tf.train.StopAtStepHook() to stop training, all workers can exit successfully.\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nIn local_master.cc, WaitForNotification() function is as follows:\r\n```\r\nStatus WaitForNotification(CallOptions* call_options,\r\n                           const int64 default_timeout_in_ms, Notification* n) {\r\n  int64 timeout_in_ms = call_options->GetTimeout();\r\n  if (timeout_in_ms == 0) {\r\n    timeout_in_ms = default_timeout_in_ms;\r\n  }\r\n  if (timeout_in_ms > 0) {\r\n    int64 timeout_in_us = timeout_in_ms * 1000;\r\n    bool notified = WaitForNotificationWithTimeout(n, timeout_in_us);\r\n    if (!notified) {\r\n      call_options->StartCancel();\r\n      // The call has borrowed pointers to the request and response\r\n      // messages, so we must still wait for the call to complete.\r\n      n->WaitForNotification();\r\n      return errors::DeadlineExceeded(\"Operation timed out.\");\r\n    }\r\n  } else {\r\n    n->WaitForNotification();\r\n  }\r\n  return Status::OK();\r\n}\r\n```\r\nWorkers hang at 'n->WaitForNotification()'. We confuse that WaitForNotificationWithTimeout(n, timeout_in_us) has been called, why WaitForNotification() is called again ?\r\n\r\nbt is as follows:\r\n```\r\n#0  syscall () at ../sysdeps/unix/sysv/linux/x86_64/syscall.S:38\r\n#1  0x00007f475f56e1ac in nsync::futex (uaddr=0x555c3d471368, op=393, val=0, timeout=0x0, uaddr2=0x0, val3=-1) at external/nsync/platform/linux/src/nsync_semaphore_futex.c:21\r\n#2  0x00007f475f56e357 in nsync::nsync_mu_semaphore_p_with_deadline (s=0x555c3d471368, abs_deadline=...) at external/nsync/platform/linux/src/nsync_semaphore_futex.c:108\r\n#3  0x00007f475f56d1f6 in nsync::nsync_sem_wait_with_cancel_ (w=0x555c3d471360, abs_deadline=..., cancel_note=0x0) at external/nsync/internal/sem_wait.c:36\r\n#4  0x00007f475f569277 in nsync::nsync_cv_wait_with_deadline_generic (pcv=0x7fff46c23e20, pmu=0x7fff46c23e10, lock=0x7f475f568fdf <nsync::void_mu_lock(void*)>, \r\n    unlock=0x7f475f568ffa <nsync::void_mu_unlock(void*)>, abs_deadline=..., cancel_note=0x0) at external/nsync/internal/cv.c:246\r\n#5  0x00007f475f5699f5 in nsync::nsync_cv_wait_with_deadline (pcv=0x7fff46c23e20, pmu=0x7fff46c23e10, abs_deadline=..., cancel_note=0x0) at external/nsync/internal/cv.c:440\r\n#6  0x00007f475f569a32 in nsync::nsync_cv_wait (pcv=0x7fff46c23e20, pmu=0x7fff46c23e10) at external/nsync/internal/cv.c:450\r\n#7  0x00007f474de90bf5 in tensorflow::condition_variable::wait (this=0x7fff46c23e20, lock=...) at tensorflow/core/platform/default/mutex.cc:72\r\n#8  0x00007f4756864a5d in tensorflow::Notification::WaitForNotification (this=0x7fff46c23e10) at ./tensorflow/core/platform/default/notification.h:54\r\n#9  0x00007f4756c3dc34 in tensorflow::(anonymous namespace)::WaitForNotification (call_options=0x7fff46c24090, default_timeout_in_ms=0, n=0x7fff46c23e10)\r\n    at tensorflow/core/distributed_runtime/local_master.cc:39\r\n#10 0x00007f4756c3e439 in tensorflow::LocalMaster::RunStep (this=0x555c3ba54780, call_options=0x7fff46c24090, request=0x555c38dbae60, response=0x555c38dbb110)\r\n    at tensorflow/core/distributed_runtime/local_master.cc:105\r\n#11 0x00007f475686d03d in tensorflow::GrpcSession::RunProto (this=0x555c3b986280, call_options=0x7fff46c24090, req=0x555c38dbae60, resp=0x555c38dbb110)\r\n    at tensorflow/core/distributed_runtime/rpc/grpc_session.cc:289\r\n#12 0x00007f475686c7d6 in tensorflow::GrpcSession::RunHelper (this=0x555c3b986280, run_options=..., inputs=std::vector of length 0, capacity 0, \r\n    output_tensor_names=std::vector of length 4, capacity 4 = {...}, target_node_names=std::vector of length 1, capacity 1 = {...}, outputs=0x7fff46c242f0, run_metadata=0x7fff46c24350, \r\n    prun_handle=\"\") at tensorflow/core/distributed_runtime/rpc/grpc_session.cc:221\r\n#13 0x00007f475686ce35 in tensorflow::GrpcSession::Run (this=0x555c3b986280, run_options=..., inputs=std::vector of length 0, capacity 0, \r\n    output_tensor_names=std::vector of length 4, capacity 4 = {...}, target_node_names=std::vector of length 1, capacity 1 = {...}, outputs=0x7fff46c242f0, run_metadata=0x7fff46c24350)\r\n    at tensorflow/core/distributed_runtime/rpc/grpc_session.cc:270\r\n#14 0x00007f4756832f34 in tensorflow::SessionRef::Run (this=0x555c3ba38880, run_options=..., inputs=std::vector of length 0, capacity 0, \r\n    output_tensor_names=std::vector of length 4, capacity 4 = {...}, target_node_names=std::vector of length 1, capacity 1 = {...}, outputs=0x7fff46c242f0, run_metadata=0x7fff46c24350)\r\n    at tensorflow/python/client/session_ref.cc:427\r\n#15 0x00007f4756aeeabc in TF_Run_Helper (session=0x555c3ba38880, handle=0x0, run_options=0x555c38437160, input_pairs=std::vector of length 0, capacity 0, \r\n    output_tensor_names=std::vector of length 4, capacity 4 = {...}, c_outputs=0x7fff46c246d8, target_oper_names=std::vector of length 1, capacity 1 = {...}, run_metadata=0x555c38dd9b70, \r\n    status=0x555c38ddf6d0) at tensorflow/c/c_api.cc:783\r\n```\r\n\r\n\r\nUsing 'thread apply all bt' in gdb, we can see there are two threads wait at cond_var_.wait(l) in BackgroundWorker::WorkerLoop() method.\r\n```\r\n(gdb) thread apply all bt\r\nThread 204 (Thread 0x7f366b7fe700 (LWP 457)):\r\n#0  syscall () at ../sysdeps/unix/sysv/linux/x86_64/syscall.S:38\r\n#1  0x00007f3a48857cac in nsync::futex (uaddr=0x7f379c001d08, op=393, val=0, timeout=0x0, uaddr2=0x0, val3=-1) at external/nsync/platform/linux/src/nsync_semaphore_futex.c:21\r\n#2  0x00007f3a48857e57 in nsync::nsync_mu_semaphore_p_with_deadline (s=0x7f379c001d08, abs_deadline=...) at external/nsync/platform/linux/src/nsync_semaphore_futex.c:108\r\n#3  0x00007f3a48856cf6 in nsync::nsync_sem_wait_with_cancel_ (w=0x7f379c001d00, abs_deadline=..., cancel_note=0x0) at external/nsync/internal/sem_wait.c:36\r\n#4  0x00007f3a48852d77 in nsync::nsync_cv_wait_with_deadline_generic (pcv=0x558523ec4f98, pmu=0x558523ec4f88, lock=0x7f3a48852adf <nsync::void_mu_lock(void*)>, \r\n    unlock=0x7f3a48852afa <nsync::void_mu_unlock(void*)>, abs_deadline=..., cancel_note=0x0) at external/nsync/internal/cv.c:246\r\n#5  0x00007f3a488534f5 in nsync::nsync_cv_wait_with_deadline (pcv=0x558523ec4f98, pmu=0x558523ec4f88, abs_deadline=..., cancel_note=0x0) at external/nsync/internal/cv.c:440\r\n#6  0x00007f3a48853532 in nsync::nsync_cv_wait (pcv=0x558523ec4f98, pmu=0x558523ec4f88) at external/nsync/internal/cv.c:450\r\n#7  0x00007f3a3717abf5 in tensorflow::condition_variable::wait (this=0x558523ec4f98, lock=...) at tensorflow/core/platform/default/mutex.cc:72\r\n#8  0x00007f3a36ccb475 in tensorflow::data::BackgroundWorker::WorkerLoop (this=0x558523ec4f80) at tensorflow/core/framework/dataset.cc:318\r\n#9  0x00007f3a36ccb1f5 in tensorflow::data::BackgroundWorker::BackgroundWorker(tensorflow::Env*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)::{lambda()#1}::operator()() const () at tensorflow/core/framework/dataset.cc:287\r\n#10 0x00007f3a36ccb887 in std::_Function_handler<void(), tensorflow::data::BackgroundWorker::BackgroundWorker(tensorflow::Env*, const string&)::<lambda()> >::_M_invoke(const std::_Any_data &) (__functor=...) at /usr/include/c++/5/functional:1871\r\n#11 0x00007f3a36cab688 in std::function<void ()>::operator()() const (this=0x558522569ff8) at /usr/include/c++/5/functional:2267\r\n#12 0x00007f3a3717d7c8 in std::_Bind_simple<std::function<void ()> ()>::_M_invoke<>(std::_Index_tuple<>) (this=0x558522569ff8) at /usr/include/c++/5/functional:1531\r\n#13 0x00007f3a3717d765 in std::_Bind_simple<std::function<void ()> ()>::operator()() (this=0x558522569ff8) at /usr/include/c++/5/functional:1520\r\n#14 0x00007f3a3717d704 in std::thread::_Impl<std::_Bind_simple<std::function<void ()> ()> >::_M_run() (this=0x558522569fe0) at /usr/include/c++/5/thread:115\r\n#15 0x00007f3a5475f678 in std::execute_native_thread_routine_compat (__p=<optimized out>)\r\n    at /opt/conda/conda-bld/compilers_linux-64_1534514838838/work/.build/x86_64-conda_cos6-linux-gnu/src/gcc/libstdc++-v3/src/c++11/thread.cc:94\r\n#16 0x00007f3a68b266ba in start_thread (arg=0x7f366b7fe700) at pthread_create.c:333\r\n#17 0x00007f3a6885c41d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109\r\n\r\nThread 203 (Thread 0x7f3805137700 (LWP 456)):\r\n#0  syscall () at ../sysdeps/unix/sysv/linux/x86_64/syscall.S:38\r\n#1  0x00007f3a48857cac in nsync::futex (uaddr=0x7f378d8850a8, op=393, val=0, timeout=0x0, uaddr2=0x0, val3=-1) at external/nsync/platform/linux/src/nsync_semaphore_futex.c:21\r\n#2  0x00007f3a48857e57 in nsync::nsync_mu_semaphore_p_with_deadline (s=0x7f378d8850a8, abs_deadline=...) at external/nsync/platform/linux/src/nsync_semaphore_futex.c:108\r\n#3  0x00007f3a48856cf6 in nsync::nsync_sem_wait_with_cancel_ (w=0x7f378d8850a0, abs_deadline=..., cancel_note=0x0) at external/nsync/internal/sem_wait.c:36\r\n#4  0x00007f3a48852d77 in nsync::nsync_cv_wait_with_deadline_generic (pcv=0x5585225338f0, pmu=0x5585225338e0, lock=0x7f3a48852adf <nsync::void_mu_lock(void*)>, \r\n    unlock=0x7f3a48852afa <nsync::void_mu_unlock(void*)>, abs_deadline=..., cancel_note=0x0) at external/nsync/internal/cv.c:246\r\n#5  0x00007f3a488534f5 in nsync::nsync_cv_wait_with_deadline (pcv=0x5585225338f0, pmu=0x5585225338e0, abs_deadline=..., cancel_note=0x0) at external/nsync/internal/cv.c:440\r\n#6  0x00007f3a48853532 in nsync::nsync_cv_wait (pcv=0x5585225338f0, pmu=0x5585225338e0) at external/nsync/internal/cv.c:450\r\n#7  0x00007f3a3717abf5 in tensorflow::condition_variable::wait (this=0x5585225338f0, lock=...) at tensorflow/core/platform/default/mutex.cc:72\r\n#8  0x00007f3a36ccb475 in tensorflow::data::BackgroundWorker::WorkerLoop (this=0x5585225338d8) at tensorflow/core/framework/dataset.cc:318\r\n#9  0x00007f3a36ccb1f5 in tensorflow::data::BackgroundWorker::BackgroundWorker(tensorflow::Env*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)::{lambda()#1}::operator()() const () at tensorflow/core/framework/dataset.cc:287\r\n#10 0x00007f3a36ccb887 in std::_Function_handler<void(), tensorflow::data::BackgroundWorker::BackgroundWorker(tensorflow::Env*, const string&)::<lambda()> >::_M_invoke(const std::_Any_data &) (__functor=...) at /usr/include/c++/5/functional:1871\r\n#11 0x00007f3a36cab688 in std::function<void ()>::operator()() const (this=0x558523c0df78) at /usr/include/c++/5/functional:2267\r\n#12 0x00007f3a3717d7c8 in std::_Bind_simple<std::function<void ()> ()>::_M_invoke<>(std::_Index_tuple<>) (this=0x558523c0df78) at /usr/include/c++/5/functional:1531\r\n#13 0x00007f3a3717d765 in std::_Bind_simple<std::function<void ()> ()>::operator()() (this=0x558523c0df78) at /usr/include/c++/5/functional:1520\r\n#14 0x00007f3a3717d704 in std::thread::_Impl<std::_Bind_simple<std::function<void ()> ()> >::_M_run() (this=0x558523c0df60) at /usr/include/c++/5/thread:115\r\n#15 0x00007f3a5475f678 in std::execute_native_thread_routine_compat (__p=<optimized out>)\r\n    at /opt/conda/conda-bld/compilers_linux-64_1534514838838/work/.build/x86_64-conda_cos6-linux-gnu/src/gcc/libstdc++-v3/src/c++11/thread.cc:94\r\n#16 0x00007f3a68b266ba in start_thread (arg=0x7f3805137700) at pthread_create.c:333\r\n#17 0x00007f3a6885c41d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109\r\n```", "comments": ["Please assign to the owner of this code. I am not the owner. ", "@mrry -- any guesses here?", "From the bug description, all we know is that some `Session.run()` call is blocked (from the thread blocked in `WaitForNotification()`) and the session is still active (from the two tf.data background threads). \r\n\r\nWithout a way to reproduce the problem, there's no way to tell *why* it's blocked. From previous experience, it's possible that the termination logic in `Estimator` (with or without `StopAtStepHook`) has a race condition. One case that I've seen is the past is that there might be an accidental dependency between worker tasks, where when one worker exits cleanly, another worker might start a concurrent `Session.run()` call that depends on the exited worker, and will block forever waiting for that worker to come back up. However, I would have expected the default worker device filter to prevent it, based on the code here: https://github.com/tensorflow/tensorflow/blob/5b0c5251806c0fc8a704f5454a89d7c2b65c4e12/tensorflow/python/estimator/run_config.py#L567\r\n\r\nAre you using that device filter? Which tasks (worker or PS) have exited (if any) when you observe the hang?", "> From the bug description, all we know is that some `Session.run()` call is blocked (from the thread blocked in `WaitForNotification()`) and the session is still active (from the two tf.data background threads).\r\n> \r\n> Without a way to reproduce the problem, there's no way to tell _why_ it's blocked. From previous experience, it's possible that the termination logic in `Estimator` (with or without `StopAtStepHook`) has a race condition. One case that I've seen is the past is that there might be an accidental dependency between worker tasks, where when one worker exits cleanly, another worker might start a concurrent `Session.run()` call that depends on the exited worker, and will block forever waiting for that worker to come back up. However, I would have expected the default worker device filter to prevent it, based on the code here:\r\n> \r\n> [tensorflow/tensorflow/python/estimator/run_config.py](https://github.com/tensorflow/tensorflow/blob/5b0c5251806c0fc8a704f5454a89d7c2b65c4e12/tensorflow/python/estimator/run_config.py#L567)\r\n> \r\n> Line 567 in [5b0c525](/tensorflow/tensorflow/commit/5b0c5251806c0fc8a704f5454a89d7c2b65c4e12)\r\n> \r\n>  device_filters = ['/job:ps', '/job:worker/task:%d' % self._task_id] \r\n> Are you using that device filter? Which tasks (worker or PS) have exited (if any) when you observe the hang?\r\n\r\nIt workers", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=26559\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=26559\">No</a>\n", "> > From the bug description, all we know is that some `Session.run()` call is blocked (from the thread blocked in `WaitForNotification()`) and the session is still active (from the two tf.data background threads).\r\n> > Without a way to reproduce the problem, there's no way to tell _why_ it's blocked. From previous experience, it's possible that the termination logic in `Estimator` (with or without `StopAtStepHook`) has a race condition. One case that I've seen is the past is that there might be an accidental dependency between worker tasks, where when one worker exits cleanly, another worker might start a concurrent `Session.run()` call that depends on the exited worker, and will block forever waiting for that worker to come back up. However, I would have expected the default worker device filter to prevent it, based on the code here:\r\n> > [tensorflow/tensorflow/python/estimator/run_config.py](https://github.com/tensorflow/tensorflow/blob/5b0c5251806c0fc8a704f5454a89d7c2b65c4e12/tensorflow/python/estimator/run_config.py#L567)\r\n> > Line 567 in [5b0c525](/tensorflow/tensorflow/commit/5b0c5251806c0fc8a704f5454a89d7c2b65c4e12)\r\n> > device_filters = ['/job:ps', '/job:worker/task:%d' % self._task_id]\r\n> > Are you using that device filter? Which tasks (worker or PS) have exited (if any) when you observe the hang?\r\n> \r\n> It workers\r\n\r\nHi, did you find why there is an accidental dependency between worker tasks?\r\n"]}, {"number": 26558, "title": "Posenet Tensorflow.js documentation doesn't specify how to feed it video ", "body": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version:\r\n- Doc Link:\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n", "comments": ["This issue is more suitable on tensorflow javascript repo. Please post it on [tfjs repo](https://github.com/tensorflow/tfjs/issues). Thanks!"]}, {"number": 26557, "title": "tf.keras.optimizers.Adam with tf.stop_gradient leads to ValueError: An operation has `None` for gradient.", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n\r\n### **System information**\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nUbuntu 16.04.5 LTS (GNU/Linux 4.15.0-45-generic x86_64)\r\n\r\nTensorFlow installed from (source or binary):\r\npip\r\n\r\nTensorFlow version (use command below):\r\n'1.12.0'\r\n\r\nPython version:\r\nPython 3.5.2\r\n\r\nBazel version (if compiling from source):\r\nN/A\r\n\r\nGCC/Compiler version (if compiling from source):\r\nN/A\r\n\r\nCUDA/cuDNN version:\r\n9.0.176\r\n\r\nGPU model and memory:\r\nTesla V100\r\n\r\nExact command to reproduce:\r\n```\r\nimport os\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras.layers import (LSTM, Activation, BatchNormalization, Bidirectional,\r\n                                     Conv1D, Dense, Dropout, Input, Lambda, Masking,\r\n                                     TimeDistributed)\r\n\r\nimport numpy as np\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\r\n\r\n\r\nInput_layer = Input(shape=(2, ))\r\nDense1 = Dense(8, input_shape=(2, ))(Input_layer)\r\nDense1_stop = Lambda(lambda x: tf.stop_gradient(x))(Dense1)\r\nDense2 = Dense(4)(Dense1_stop)\r\nDense3 = Dense(1, activation='softmax')(Dense2)\r\nmodel = Model(inputs=Input_layer, outputs=Dense3)\r\n\r\n# model.compile(optimizer=tf.train.AdamOptimizer(), loss='mse')\r\nmodel.compile(optimizer=tf.keras.optimizers.Adam(), loss='mse')\r\n\r\n\r\nx = np.random.uniform(0, 1, (100, 2))\r\ny = np.random.uniform(0, 1, (100, 1))\r\nmodel.fit(x=x, y=y, validation_split=0.2)\r\n```\r\n### **Describe the problem\uff1a**\r\nThis problem occurs when I change tf.train.AdamOptimizer to tf.keras.optimizers.Adam. I'm not sure whether it is a bug or I wrongly written the codes. Therefore, I put it here. Thanks for your attention.\r\n\r\n### **Source code / logs\uff1a**\r\n```\r\nTraceback (most recent call last):\r\n  File \"optimizer_test.py\", line 25, in <module>\r\n    model.fit(x=x, y=y, validation_split=0.2)\r\n  File \"/home/jcc/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\", line 1639, in fit\r\n    validation_steps=validation_steps)\r\n  File \"/home/jcc/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_arrays.py\", line 86, in fit_loop\r\n    model._make_train_function()\r\n  File \"/home/jcc/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\", line 700, in _make_train_function\r\n    params=self._collected_trainable_weights, loss=self.total_loss)\r\n  File \"/home/jcc/.local/lib/python3.5/site-packages/tensorflow/python/keras/optimizers.py\", line 457, in get_updates\r\n    grads = self.get_gradients(loss, params)\r\n  File \"/home/jcc/.local/lib/python3.5/site-packages/tensorflow/python/keras/optimizers.py\", line 85, in get_gradients\r\n    raise ValueError('An operation has `None` for gradient. '\r\nValueError: An operation has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\r\n```", "comments": ["@Fordacre have u faced any problem after using `tf.train.AdamOptimizer()`\r\nThe reason for the failure is that there is no gradient calculation for the Dense1 tensor because of  `tf.stop_gradient(x)`, could you please help me to understand what you are trying out with the line `Dense1_stop = Lambda(lambda x: tf.stop_gradient(x))(Dense1)`", "@joyalbin I'm sorry for the ambiguity of my description. I just wrote a demo about when will this problem occurs. I want the first dense layer doesn't influence the loss in this demo.\r\nHowever, in my practical application, it is a Multi outputs model with multi losses. What I want to do is to prevent some part of my model from influencing one of those losses.\r\nIn addition, if I use tf.train.AdamOptimizer which has been commented instead this error won't occur.\r\nThanks.", "@Fordacre \r\n\r\nDo I understand correctly that you want to train Dense2-Dense3 and Dense3-output while keeping Dense1-Dense2 and Input-Dense1 fixed?", "@timudk Sorry, but I'm not quite understand why you put two layers together. Actually, I just want to keep variables of Dense1 fixed.", "@Fordacre Could you try TF2.0 and check whether same bug persists? thanks!", "@jvishnuvardhan I test it on my PC with TF2.0, unfortunately, tf.keras.optimizers.Adam() doesn't work and even tf.optimizers.Adam() doesn't work.\r\n```\r\nraise ValueError(\"An operation has `None` for gradient. \"\r\nValueError: An operation has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\r\n\r\n```\r\nIn addition, the same problem occurs when I use tensorboard with `histogram_freq` in 1.12 version.", "Can you update tf version to 1.13.1 and see if it goes away?", "```\r\nTraceback (most recent call last):\r\n  File \"<input>\", line 1, in <module>\r\n  File \"D:\\Program Files\\JetBrains\\PyCharm 2018.3.1\\helpers\\pydev\\_pydev_bundle\\pydev_umd.py\", line 197, in runfile\r\n    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script\r\n  File \"D:\\Program Files\\JetBrains\\PyCharm 2018.3.1\\helpers\\pydev\\_pydev_imps\\_pydev_execfile.py\", line 18, in execfile\r\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n  File \"D:/workplace/apg_net_win/test/optimizer_test.py\", line 25, in <module>\r\n    model.fit(x=x, y=y, validation_split=0.2)\r\n  File \"C:\\Users\\John\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 880, in fit\r\n    validation_steps=validation_steps)\r\n  File \"C:\\Users\\John\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\", line 195, in model_iteration\r\n    f = _make_execution_function(model, mode)\r\n  File \"C:\\Users\\John\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\", line 122, in _make_execution_function\r\n    return model._make_execution_function(mode)\r\n  File \"C:\\Users\\John\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1983, in _make_execution_function\r\n    self._make_fit_function()\r\n  File \"C:\\Users\\John\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1926, in _make_fit_function\r\n    '_fit_function', [self.total_loss] + metrics_tensors)\r\n  File \"C:\\Users\\John\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1895, in _make_train_function_helper\r\n    params=self._collected_trainable_weights, loss=self.total_loss)\r\n  File \"C:\\Users\\John\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\optimizers.py\", line 485, in get_updates\r\n    grads = self.get_gradients(loss, params)\r\n  File \"C:\\Users\\John\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\optimizers.py\", line 95, in get_gradients\r\n    raise ValueError('An operation has `None` for gradient. '\r\nValueError: An operation has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\r\n```\r\n@tanzhenyu I test it on my PC with tf version 1.13.1 again. Thanks for your advice, however, it doesn't help. ", "I think as mentioned above, you have variables in your model that is not in the backprop path because of stop_gradient. while tf.train.AdamOptimizer does not explicitly check for None gradient, tf.keras.optimizers.Adam does. The entire Keras model.fit has been relying on the fact that all variables needs to be present for training. If this is not your case, I'd suggest instead of using stop_gradient, you should try Keras + customized training loop, see:\r\nhttps://www.tensorflow.org/tutorials/eager/custom_training_walkthrough", "I have the same issue. The code runs perfectly in tensorflow 1.14. But not in tensorflow 2.0. \r\n\r\nOddly, tf.keras.optimizers.Adam works in tensorflow 1.14.\r\n\r\nExact same situation.", "@Nephalen I think original issue was resolved by @tanzhenyu suggestion. I am closing this issue. \r\n\r\nPlease open a new issue with details about your issue, platform details and a standalone code to reproduce the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/26557\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/26557\">No</a>\n"]}, {"number": 26556, "title": "Modified activation functions according to tf.keras.activations.tanh #25827", "body": "I modified tanh(),sigmoid() and exp() functions", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F26556) for more info**.\n\n<!-- need_sender_cla -->", "i have updated it", "in this commit i have just added details to exp() function, if you will ask me i will also update tanh ,linear and sigmoid functions.", "There's a better fix in #26603 \r\n\r\nThink we can close this @alextp @rthadur "]}, {"number": 26555, "title": "Does \"TensorFlow-experimental\" has a new version for iOS?  ", "body": "\"TensorFlow-experimental\" pod's version now is 1.1.1\uff0cI need a new version to match the latest source code, and how can I build a \"TensorFlow-experimental\" framework?", "comments": ["This is an old issue, and hopefully you've figured it out already, but let me close the loop here.\r\n\r\nThe new standard way of using TensorFlow on iOS is via `TensorFlowLiteSwift` / `TensorFlowLiteObjC` pods. Please refer to the official [iOS quickstart guide](https://www.tensorflow.org/lite/guide/ios)."]}, {"number": 26554, "title": "fix Apache License 2.0", "body": "The text in the Apache License 2.0 appendix is not intended to be substituted in LICENSE - only when deployed in file headers. Related info, see https://github.com/github/choosealicense.com/issues/558", "comments": ["Thank you for your suggestions, but neither of the suggested changes make a difference. I consulted our open source legal advisers."]}, {"number": 26553, "title": "tf-2.0.0-alpha0 bazel build failure in Docker - Extension file not found. Unable to load package for '//tensorflow:version_check.bzl':", "body": "**System information**\r\n- Linux Ubuntu 18.04.2 LTS:\r\n- TensorFlow installed from tar.gz source file\r\n- TensorFlow version: 2.0.0.alpha0\r\n- Python version: 3.5.2 (provided in Docker image)\r\n- Build inside Docker container (https://www.tensorflow.org/install/source#gpu_support_2)\r\n- Bazel version - 0.19.2 (provided in docker image)\r\n- GCC/Compiler version (if compiling from source): gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.11)  (provided in docker image)\r\n- CUDA/cuDNN version: /usr/local/cuda-10.0 (provided in docker image)\r\n- GPU model and memory: i7 980x  - no AVX instruction set so building locally with GPU support\r\n\r\n**Describe the problem**\r\nThe bazel build step fails with the following messages:\r\n\r\nroot@67e84911cbdf:/tensorflow# bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\nStarting local Bazel server and connecting to it...\r\nWARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.\r\nINFO: Repository rule 'build_bazel_rules_swift' returned: {\"remote\": \"https://github.com/bazelbuild/rules_swift.git\", \"commit\": \"001736d056d7eae20f1f4da41bc9e6f036857296\", \"shallow_since\": \"2019-01-18\", \"init_submodules\": False, \"verbose\": False, \"strip_prefix\": \"\", \"patches\": [], \"patch_tool\": \"patch\", \"patch_args\": [\"-p0\"], \"patch_cmds\": [], \"name\": \"build_bazel_rules_swift\"}\r\nERROR: error loading package '': Extension file not found. Unable to load package for '//tensorflow:version_check.bzl': BUILD file not found on package path\r\nERROR: error loading package '': Extension file not found. Unable to load package for '//tensorflow:version_check.bzl': BUILD file not found on package path\r\nINFO: Elapsed time: 8.103s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\nroot@67e84911cbdf:\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nFollowing the instructions here: https://www.tensorflow.org/install/source#gpu_support_2\r\n\r\nNOTE: These instructions work fine for the included tf-1.12 source and I've used them with a different Docker image for tf-1.13/\r\n\r\n1) Start a Docker container using this command to mount a tf-2.0.0 directory within Docker\r\n\r\ndocker run --runtime=nvidia -it -w /tensorflow -v /home/mark/Docker_Run:/mnt -v /home/mark/CODE/tensorflow-2.0.0-alpha0:/tensorflow_source -e HOST_PERMS=\"$(id -u):$(id -g)\"     tensorflow/tensorflow:devel-gpu-py3 bash\r\n\r\nThis image provides python-3.5.2, bazel-0.19.2 & cuda-10. It has a /tensorflow_src directory with tf-1.12 and nothing in the /tensorflow directory.\r\n\r\n2) Copy the tf-2.0.0-alpha0 code from the external mounted /tensorflow_source directory into the internal /tensorflow directory:\r\n\r\nrm -rf /tensorflow\r\nmkdir /tensorflow\r\ncp -R /tensorflow_source/. /tensorflow\r\n\r\n3) Run the configure step accepting all default values\r\n\r\ncd /tensorflow\r\n./configure\r\n\r\n4) Run the bazel build step which fails with the message above.\r\n\r\nNOTE: I've looked at a lot of Docker images and felt this one had the right stuff other than the alpha0 tensorflow codebase. If there's a better docker image or a better way to get the alpha0 code into the Docker image than mounting it outside of Docker please advise.", "comments": ["When I compiled tensorflow2.0-alpha0 with the source code in conda, I encountered the same problem with the following error message. \r\n\r\nLoading: \r\nLoading: 0 packages loaded\r\nERROR: error loading package '': Encountered error while reading extension file 'swift/repositories.bzl': no such package '@build_bazel_rules_swift//swift': Traceback (most recent call last):\r\n\tFile \"/home/wangli/.cache/bazel/_bazel_wangli/4e43e44ac24356d1161b2a510501b361/external/bazel_tools/tools/build_defs/repo/git.bzl\", line 166\r\n\t\t_clone_or_update(ctx)\r\n\tFile \"/home/wangli/.cache/bazel/_bazel_wangli/4e43e44ac24356d1161b2a510501b361/external/bazel_tools/tools/build_defs/repo/git.bzl\", line 72, in _clone_or_update\r\n\t\tfail((\"error cloning %s:\\n%s\" % (ctx....)))\r\nerror cloning build_bazel_rules_swift:\r\n+ cd /home/wangli/.cache/bazel/_bazel_wangli/4e43e44ac24356d1161b2a510501b361/external\r\n+ rm -rf /home/wangli/.cache/bazel/_bazel_wangli/4e43e44ac24356d1161b2a510501b361/external/build_bazel_rules_swift /home/wangli/.cache/bazel/_bazel_wangli/4e43e44ac24356d1161b2a510501b361/external/build_bazel_rules_swift\r\n+ git clone --depth=1 https://github.com/bazelbuild/rules_swift.git /home/wangli/.cache/bazel/_bazel_wangli/4e43e44ac24356d1161b2a510501b361/external/build_bazel_rules_swift\r\n+ git -C /home/wangli/.cache/bazel/_bazel_wangli/4e43e44ac24356d1161b2a510501b361/external/build_bazel_rules_swift reset --hard tags/0.6.0\r\nUnknown option: -C\r\nusage: git [--version] [--help] [-c name=value]\r\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\r\n           [-p|--paginate|--no-pager] [--no-replace-objects] [--bare]\r\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\r\n           <command> [<args>]\r\n+ git -C /home/wangli/.cache/bazel/_bazel_wangli/4e43e44ac24356d1161b2a510501b361/external/build_bazel_rules_swift fetch --depth=1 origin tags/0.6.0:tags/0.6.0\r\nUnknown option: -C\r\nusage: git [--version] [--help] [-c name=value]\r\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\r\n           [-p|--paginate|--no-pager] [--no-replace-objects] [--bare]\r\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\r\n           <command> [<args>]\r\n+ git -C /home/wangli/.cache/bazel/_bazel_wangli/4e43e44ac24356d1161b2a510501b361/external/build_bazel_rules_swift fetch origin tags/0.6.0:tags/0.6.0\r\nUnknown option: -C\r\nusage: git [--version] [--help] [-c name=value]\r\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\r\n           [-p|--paginate|--no-pager] [--no-replace-objects] [--bare]\r\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\r\n           <command> [<args>]\r\nERROR: error loading package '': Encountered error while reading extension file 'swift/repositories.bzl': no such package '@build_bazel_rules_swift//swift': Traceback (most recent call last):\r\n\tFile \"/home/wangli/.cache/bazel/_bazel_wangli/4e43e44ac24356d1161b2a510501b361/external/bazel_tools/tools/build_defs/repo/git.bzl\", line 166\r\n\t\t_clone_or_update(ctx)\r\n\tFile \"/home/wangli/.cache/bazel/_bazel_wangli/4e43e44ac24356d1161b2a510501b361/external/bazel_tools/tools/build_defs/repo/git.bzl\", line 72, in _clone_or_update\r\n\t\tfail((\"error cloning %s:\\n%s\" % (ctx....)))\r\nerror cloning build_bazel_rules_swift:\r\n+ cd /home/wangli/.cache/bazel/_bazel_wangli/4e43e44ac24356d1161b2a510501b361/external\r\n+ rm -rf /home/wangli/.cache/bazel/_bazel_wangli/4e43e44ac24356d1161b2a510501b361/external/build_bazel_rules_swift /home/wangli/.cache/bazel/_bazel_wangli/4e43e44ac24356d1161b2a510501b361/external/build_bazel_rules_swift\r\n+ git clone --depth=1 https://github.com/bazelbuild/rules_swift.git /home/wangli/.cache/bazel/_bazel_wangli/4e43e44ac24356d1161b2a510501b361/external/build_bazel_rules_swift\r\n+ git -C /home/wangli/.cache/bazel/_bazel_wangli/4e43e44ac24356d1161b2a510501b361/external/build_bazel_rules_swift reset --hard tags/0.6.0\r\nUnknown option: -C\r\nusage: git [--version] [--help] [-c name=value]\r\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\r\n           [-p|--paginate|--no-pager] [--no-replace-objects] [--bare]\r\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\r\n           <command> [<args>]\r\n+ git -C /home/wangli/.cache/bazel/_bazel_wangli/4e43e44ac24356d1161b2a510501b361/external/build_bazel_rules_swift fetch --depth=1 origin tags/0.6.0:tags/0.6.0\r\nUnknown option: -C\r\nusage: git [--version] [--help] [-c name=value]\r\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\r\n           [-p|--paginate|--no-pager] [--no-replace-objects] [--bare]\r\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\r\n           <command> [<args>]\r\n+ git -C /home/wangli/.cache/bazel/_bazel_wangli/4e43e44ac24356d1161b2a510501b361/external/build_bazel_rules_swift fetch origin tags/0.6.0:tags/0.6.0\r\nUnknown option: -C\r\nusage: git [--version] [--help] [-c name=value]\r\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\r\n           [-p|--paginate|--no-pager] [--no-replace-objects] [--bare]\r\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\r\n           <command> [<args>]\r\nINFO: Elapsed time: 7.566s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\nERROR: Couldn't start the build. Unable to run tests\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n\r\n\r\nAnd System information\r\nLinux centos 7:\r\nTensorFlow version: 2.0.0.alpha0\r\nPython version: 3.6\r\nBazel version - 0.19.2 (provided in docker image)\r\nGCC/Compiler version 4.8\r\n\r\nCompile only the pure CPU version, using the compile command:\r\nbazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n--", "ping @angersson ", "Can you (austin) verify the build works on the image, if needed we can escalate to the GPU team to get a clear ownership.", "Thanks for the ping, I missed this. I'm testing the builds now, but it'll take a while to get results.", "@tfboyd @goldiegadde This seems like a use case for the development docker images I didn't plan for. I can't build the released 2.0 source because our latest `devel` image has a version of Bazel that is too new (the `devel` images, which are built nightly, were only planned to support building from master or recent branches).\r\n\r\nSo I can't build from the 2.0.0 alpha release's source code, but the latest `devel` image does build the included source code as well as the current master after a `git pull`. I can also build the `r2.0` branch with no problem, so this... *seems* like WAI, although this issue indicates that the availability of the source code may be confusing.\r\n\r\nFor anyone that runs into a similar problem: if you are building TensorFlow 2.0 from source, please check out the `r2.0` branch and build from there, as the branch is more up-to-date than the release (our releases correspond to binary releases; I don't believe we intend for the source code archives to be used).\r\n\r\n```bash\r\n$ git clone https://www.github.com/tensorflow/tensorflow\r\n$ git checkout -b r2.0 origin/r2.0\r\n$ ./configure\r\n\r\n# If you are using the devel Docker images:\r\n$ cd /tensorflow_src\r\n$ git fetch --all\r\n$ git checkout -b r2.0 origin/r2.0\r\n$ ./configure\r\n```\r\n\r\nI'll close this because I was able to build the `r2.0` branch in the Docker images.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=26553\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=26553\">No</a>\n", "Austin,\n   First, thanks for your efforts.\n\n   Second, before you move on could you possibly clarify a couple of things?\n\n1) When you say 'the latest devel image does build the included source code\nas well as the current master after a git pull'is this inside a Docker\nimage with GPU support? For my needs I can use any r2.0 version with GPU\nsupport. What docker image and what git pull commands so that I can\nduplicate here.\n\n2) I have managed to build r2.0-alpha without GPU support outside of Docker\nusing just regular Kubuntu and Python-3.6 and bazel-0.23.0 using\n\ngit clone https://github.com/tensorflow/tensorflow.git -b r2.0\n--single-branch\n\nand then generally following the instructions on the tensorflow website. I\ndon't know if it functions correctly yet. I will be attempting to add GPU\nsupport later this week.\n\n   Any info you can poss on about getting the right Docker image and\ngetting it updated to duplicate your results would be appreciated.\n\nThanks,\nMark\n\nOn Mon, Apr 1, 2019 at 10:58 AM Austin Anderson <notifications@github.com>\nwrote:\n\n> @tfboyd <https://github.com/tfboyd> @goldiegadde\n> <https://github.com/goldiegadde> This seems like a use case for the\n> development docker images I didn't plan for. I can't build the released 2.0\n> source because our latest devel image has a version of Bazel that is too\n> new (the devel images, which are built nightly, were only planned to\n> support building from master).\n>\n> So I can't build from the 2.0.0 alpha release's source code, but the\n> latest devel image does build the included source code as well as the\n> current master after a git pull. I can also build the r2.0 branch with no\n> problem, so this... *seems* like WAI, although this issue indicates that\n> the availability of the source code may be confusing.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/26553#issuecomment-478679690>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AEfnRpDwUD4WkrMK2LdJJ19HTm04y7jGks5vcki6gaJpZM4bng-C>\n> .\n>\n"]}, {"number": 26552, "title": " Feature Request: Better control of train and evaluation modes", "body": "**System information**\r\n- TensorFlow version (you are using): tf 2.0 alpha\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\nCurrent approach for handling train and evaluation modes involves passing additional argument to `call` method like this\r\n\r\n```\r\ndef call(self, inputs, training=None):\r\n    ...\r\n```\r\n\r\nIf we would consider that we have some model with deep nested layers that contain `Dropout`, `Batch Norm` and other layers, then it would be necessary to pass `training` argument to all of them through several calls.\r\n\r\nThis approach have several drawbacks.\r\n\r\nFirst of all, it could be potential bug in the model, since programmer could forget that propagation of some layer depends on training state.\r\nAlso, passing `training` argument is extremely verbose.\r\n\r\nAt the same time, PyTorch solves this task in much more elegant way \u2013 every layer have additional state `train: bool`. Since we are aware of nested layers for some model, setting `training = False` on topmost layer will set all children layers to this mode without being necessary to explicitly handle passing training state argument.\r\n\r\nImplementation of this feature will not change current API, but will add new methods/functionality to TensorFlow. It could be two additional methods `Model.train()` and `Model.eval()` that recursively change every layer state, which affects on `call` method like `training` argument do.\r\n\r\nThis feature will simplify creation of custom models for both production and research tasks. It will make code much more clear and will make TensorFlow more attractive for active PyTorch users.\r\n", "comments": ["@kefirski great idea, support you, man!", "i am willing to work on this issue please anybody guide me a little bit.", "@kefirski I'm assuming you are talking about Keras models specifically. If so, can you provide some sample code that shows the expected outcome? I don't entirely follow your solution here. CC @tomerk , FYI.", "@karmel, hi! @kefirski said about opportunity to change mode (training or evaluation) of model in one method like in PyTorch. See source code [here](https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.train) or attached screenshot. \r\n![image](https://user-images.githubusercontent.com/17337773/59145317-d0350900-89ea-11e9-9f0f-c5695016463b.png)\r\n\r\nIt's really convenient, because you don't need to push `training` variable in every module that I create. \r\n", "@omalleyt12 as you've been thinking in this direction recently.", "Yep @kefirski I think we've been thinking in similar directions :) Models like this now work:\r\n\r\n```\r\nclass MyModel(tf.keras.Model):\r\n  def __init__(self):\r\n    super(MyModel, self).__init__()\r\n    self.bn = tf.keras.layers.BatchNormalization()\r\n    self.dropout = tf.keras.layers.Dropout()\r\n\r\n  def call(self, inputs):\r\n   x = self.dropout(inputs)\r\n   return self.bn(x)\r\n\r\n# `training` value passed to a top-level layer is used as the default for sublayers\r\nmodel = MyModel()\r\nmodel(x, training=True) # BN and Dropout run in training mode\r\nmodel(x, training=False) # BN and Dropout run in inference mode\r\n```\r\nThat is, the `training` arg in `__call__` is still kept as the way to set training/inference mode on a Layer/Model (so as not to introduce too many different ways to handle this), but propagation of this arg is automatically handled for you (unless you explicitly pass in `training` to sublayers). Thus `model(..., training=True)` is the equivalent to what you are suggesting via `model.train()`.\r\n\r\nThe order of preference for how the `training` arg evaluates in a sublayer is:\r\n\r\n1) The value explicitly passed to the layer, if any\r\n2) The value passed to the layer's caller, if any\r\n3) The learning_phase if set via `tf.keras.backend.set_learning_phase`\r\n4) The default value of  `training` in the Layer's signature", "Why did you close it, @kefirski? This feature has been already done?", "@Oktai15 yes this feature is now implemented in the latest 2.0 preview :)"]}, {"number": 26551, "title": "Unable to install on Raspbian Stretch with Virtual Environments", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Raspbian Stretch Lite\r\n- TensorFlow installed from (source or binary): using `pip` \r\n- TensorFlow version: 1.12\r\n- Python version: 2.7\r\n- Installed using virtualenv? pip? conda?: `virtualenv`\r\n\r\n**Describe the problem**\r\nI wanted to install Tensorflow for Python 2.7 over a clean install of Raspbian Stretch Lite on Raspberry Pi 3 B+, these are the steps I followed before encountering the problem:\r\n\r\n1. `sudo apt-get update && sudo apt-get upgrade`\r\n1. `wget https://bootstrap.pypa.io/get-pip.py`\r\n1. `sudo python3 get-pip.py`\r\n1. `sudo pip install virtualenv virtualenvwrapper`\r\n1. `nano ~/.bashrc` (_add standard paths for virtualenvs_)\r\n1. `source .bashrc`\r\n1. `mkvirtualenv tf -p python2`\r\n1. `sudo apt-get install libhdf5-serial-dev libopenblas-dev liblapack-dev libeigen3-dev python-dev`\r\n1. `pip install tensorflow`\r\n`  Could not find a version that satisfies the requirement tensorflow (from versions: )`\r\n`No matching distribution found for tensorflow`\r\n\r\nAny idea why it did not find the Tensorflow package? Isn't `(from versions: )` strange since it should detect the installed Python?\r\n\r\nMany thanks\r\n\r\n**UPDATE**: I tried also creating a Python 3 virtual environment and repeat the installation, but I receive the same error", "comments": ["This seems like a virtualenv issue, since the pip works otherwise, so I don't think we can help on this unfortunately."]}, {"number": 26550, "title": "Fix a couple of typos", "body": "Bunch of smaller typos", "comments": ["Additionally, I'd like to open up a question: I've noticed, that If a user happens to install not GPU version `is_gpu_available ` would be always saying no.\r\n\r\nWould it make sense to add a more explicit message saying, that you see this mostly because the installation is not for GPU. I would imagine this could save some time for some of the users.", "> Additionally, I'd like to open up a question: I've noticed, that If a user happens to install not GPU version `is_gpu_available ` would be always saying no.\r\n> \r\n> Would it make sense to add a more explicit message saying, that you see this mostly because the installation is not for GPU. I would imagine this could save some time for some of the users.\r\n\r\n@yifeif what do you think about improving this message to be more explicit? \u261d\ufe0f "]}, {"number": 26549, "title": "[Lite] Assertion failure if shape of dynamic output tensor changes between invoke()s", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 1.13.1 (cpu)\r\n- Python version: 3.6.7\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n**Moved from #26248.**\r\n\r\nIf an op:\r\n\r\n* depends on a (1) dynamic tensor, and (2) a normal intermediate tensor\r\n* the computation of (2) is performed before (1)\r\n* dims of (1) change between `Interpreter::invoke()`s\r\n\r\nThen assertion failure `ERROR: tensorflow/lite/simple_memory_arena.cc:100 erased_allocs_count != 1 (0 != 1)` is triggered.\r\n\r\nAn unit test is attached in #26248. On my box it is also reproducible by the Python snippet below, which generate a model dynamically. However, my reviewer can only reproduce the issue by unit test, but not by script, so the script may miss something. To help debugging, a TFLite model file which I can reproduce the issue with is uploaded: [failed.tar.gz](https://github.com/tensorflow/tensorflow/files/2949840/failed.tar.gz)\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n\r\ni = tf.placeholder(name='i', dtype=tf.float32, shape=[1])\r\np = tf.placeholder(name='p', dtype=tf.int32, shape=[1, 2])\r\na = tf.placeholder(name='a', dtype=tf.float32, shape=[1])\r\n\r\nn = tf.negative(a)\r\no = tf.add(tf.pad(i, p), n)\r\n\r\ntest_input = np.array([0], dtype=np.float32)\r\ntest_pad = np.array([[2,2]], dtype=np.int32)\r\ntest_pad_2 = np.array([[4,4]], dtype=np.int32)\r\ntest_a = np.array([1], dtype=np.float32)\r\n\r\n\r\ndef test_tf():\r\n    with tf.Session() as sess:\r\n        out = sess.run(o, {i: test_input, p: test_pad, a: test_a})\r\n        assert out.shape == (5,)\r\n\r\n        out = sess.run(o, {i: test_input, p: test_pad_2, a: test_a})\r\n        assert out.shape == (9,)\r\n\r\ntest_tf()\r\n\r\n\r\n# convert\r\nwith tf.Session() as sess:\r\n    conv = tf.lite.TFLiteConverter.from_session(sess, [i, p, a], [o])\r\n    lite_model_bytes = conv.convert()\r\n\r\n    # with open('failed.tflite', mode='wb') as fp:\r\n    #     fp.write(lite_model_bytes)\r\n\r\n\r\ndef test_tflite():\r\n    interp = tf.lite.Interpreter(model_content=lite_model_bytes)\r\n\r\n    #### I just hard-coded them:\r\n    # print(interp.get_input_details())\r\n    # print(interp.get_output_details())\r\n\r\n    interp.allocate_tensors()\r\n    interp.set_tensor(4, test_input)\r\n    interp.set_tensor(5, test_pad)\r\n    interp.set_tensor(3, test_a)\r\n\r\n    interp.invoke()\r\n    assert interp.get_tensor(0).shape == (5,)\r\n\r\n    interp.set_tensor(5, test_pad_2)\r\n\r\n    interp.invoke()\r\n    assert interp.get_tensor(0).shape == (9,)\r\n\r\ntest_tflite()\r\n\r\n```\r\n", "comments": ["Hi Scott,\r\n\r\nSorry for late reply! Can you still reproduce this issue? I tested it on tf-nightly but no assertion errors show up again.", "The unit test added in #26248 still failed with latest commit on master (b0432d52). As for the python script, it is not always reproducible.", "@scottcjt : The issue is resolved in Tensorflow 1.14. Would you please check and confirm.\r\nIf still you are facing issue, please let me know, Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=26549\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=26549\">No</a>\n", "@ANSHUMAN87 can you point me to the specific location where this is fixed in 1.14? I am facing similar issue with 1.14", "@umangmehta12 : Are you able to reproduce the issue in 1.14, using the scripts provided by the author of this issue? There is big difference most of the time between similar and same issue. If not able to reproduce the issue with the script, then try to raise a new issue with your reproducible script and issue details. I can help you. You can TAG me if you are raising a new one."]}, {"number": 26548, "title": "refuse\ufeff find example ", "body": "add example learning TensorFlow 2.0 to comment type of warning ecology place. Sample https://photos.google.com/search/battery https://photos.google.com/search/refuse\ufeff", "comments": ["It looks like you haven't used a template to create this issue. Please resubmit your issue using a template from [here](https://github.com/tensorflow/tensorflow/issues/new/choose). We ask users to use the template because it reduces overall time to resolve a new issue by avoiding extra communication to get to the root of the issue. We will close this issue in lieu of the new one you will create from the template. Thank you for your cooperation.\r\n"]}, {"number": 26547, "title": "Tutorial: TF 2.0 - Text generation with keras.layer.LSTM - Fails to Generate Sensible Text", "body": "**System information**\r\n- TensorFlow version: `'2.0.0-alpha0'`\r\n- Doc Link: https://www.tensorflow.org/alpha/tutorials/sequences/text_generation#generate_text\r\n\r\n**Describe the documentation issue**\r\n\r\nThe model, after 10 epochs (the default), generates \"unreadable\" text. This is through running the default Colab notebook via the docs/as loaded from GitHub: https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/tutorials/sequences/text_generation.ipynb\r\n\r\n```py\r\nprint(generate_text(model, start_string=u\"ROMEO: \"))\r\n```\r\n```sh\r\n# Output\r\nROMEO: VINLNKENKJVENVJNKJ3NKJKENqUKCJUKENQENVENJVENKNQKJJNKJQNK$$zzzzzzzzzzz33YYWK3JVAYYYY3NJV3NKJVJQNUKKENJNVAJJNKKxJJNKJKKJJJNKYYYJJNUJNUKC$UJVENKEVBWENVQNKJjUSJHJJJNKDENVKENVQVQVKENU$UJHENJJNJNXQGDVxjUKAQCHENKYYYJJ3NVJVMANQNKJQKENVENVJNNJNHJQUKENXENKENV3NJNUMENSENVVENVENVANQNVJQKQVHMJJNJNJNYUKENJVJNKNVANUKEVxx3NXUKENVQVUJKEN3NKJHJUKENX$qUKENQKJJNKJNNUKENKENVNQNVJKYJJNUJHENVJHYJJVANJJKYV3NVYWQJK3KJVJQUKKCJKYNVJQKEQNKEENNKJQJJNKYV3NKJJNUQDNKJKzzxJ3NV3NQNUKENKEQNKENV3NKYVQVANCHENKJJNKYVJYAN$YY33YYVJXMANQNKENVNVAVDNVANKJQNLYVQVHIVAJKJQUKENKENKJJqUKEJNNQSKCjUKENJHIVEN3NENVUVENVNVANJNVAYYVENQVKEJV3NKJx3NKYJJxQVNVHENVANMJVYYJQNUSQ3VKENVYYVNVAQXKENNKYVJJNKJQNKENX3NJXYNVJVUKJQKKJxJQNQKKENV3NKYVANJjUJQVENNKEMx3NXJNQUVQNKENRQKENQKEXKNRJNKYYYVQNVQVOVE3NHJJXKKENNQVHENVANJKENJJNN$VQUJKHENVQCHINQEVK:JVJHYYYYWqUKEMKYVJJNQVQVKAJENJQQKKENUSK$JJHEV:NVENV3NVJNJVENVENKYVJVMAYB$YYVJJNJJNUKCUKExxx3NVAQYEYYYYY3Y3VJYYYVJMJNJKK3JJNKKYV3NJNKYVQVJQNKEKYCjUKYV3NVEVJKYYYJJJjUKCENDNzzzzRNUVENVVQLNJVAKKENKJNNEQKEJNNKYYV$\r\n```\r\n\r\nTraining output w/ loss:\r\n```py\r\nhistory = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])\r\n```\r\n```sh\r\nEpoch 1/10\r\n172/172 [==============================] - 37s 213ms/step - loss: 2.6031\r\nEpoch 2/10\r\n172/172 [==============================] - 33s 190ms/step - loss: 1.9073\r\nEpoch 3/10\r\n172/172 [==============================] - 34s 198ms/step - loss: 1.6539\r\nEpoch 4/10\r\n172/172 [==============================] - 33s 194ms/step - loss: 1.5161\r\nEpoch 5/10\r\n172/172 [==============================] - 34s 196ms/step - loss: 1.4312\r\nEpoch 6/10\r\n172/172 [==============================] - 33s 189ms/step - loss: 1.3695\r\nEpoch 7/10\r\n172/172 [==============================] - 33s 190ms/step - loss: 1.3196\r\nEpoch 8/10\r\n172/172 [==============================] - 34s 199ms/step - loss: 1.2751\r\nEpoch 9/10\r\n172/172 [==============================] - 34s 196ms/step - loss: 1.2337\r\nEpoch 10/10\r\n172/172 [==============================] - 34s 196ms/step - loss: 1.1941\r\n```\r\n\r\nI've validated:\r\n\r\n* The source data on GCS is OK - https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\r\n* The char2idx mapping is correct / reversible (as expected; no typos)\r\n* Reduced the temperature - predictions are still invalid (as expected; they aren't really close to what we attempted to train)\r\n* Ran for 30 epochs (loss: 0.6435)\r\n\r\nContinuing to debug (far from an expert) but filing this as a heads-up.", "comments": ["OK - I diffed this against [the notebook on master](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/sequences/text_generation.ipynb) (targeting v1.13).\r\n\r\nThe only real difference is the use of a CuDNNGRU layer in the v1.13 version vs. the unified LSTM layer in the v2.0.0-alpha version.\r\n\r\nChanging the layer in v2.0.0-alpha to the GRU layer yields expected results from the prediction:\r\n\r\n```diff\r\n-    tf.keras.layers.LSTM(rnn_units, \r\n-                        return_sequences=True, \r\n-                        stateful=True, \r\n-                        recurrent_initializer='glorot_uniform'),\r\n+    tf.keras.layers.GRU(rnn_units, \r\n+                        return_sequences=True, \r\n+                        stateful=True, \r\n+                        recurrent_initializer='glorot_uniform'),\r\n```\r\n```sh\r\nROMEO: Through drops of ease,\r\nMay young lip and tear it.\r\n\r\nMARCAUDINA:\r\nI'll tell not, there lies Murcidous sought subject.\r\n\r\nTRANIO:\r\nTriel, to Finst Ricelent is ready. See 'twixtwer to Buckingham--\r\nTo make your patren: say the king set us heavy sakning well o'\r\n<snip>\r\n```\r\n\r\nThoughts:\r\n\r\n* Is there a bug with the unified LSTM layer here? \r\n* Does this manifest on CPU (about to force CPU only and test...) - *Update*: No issues - predicted text output is as expected after a couple of epochs.", "I also tried this locally on a 20-series GPU:\r\n```\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2018 NVIDIA Corporation\r\nBuilt on Sat_Aug_25_21:08:04_Central_Daylight_Time_2018\r\nCuda compilation tools, release 10.0, V10.0.130 # Same patch version as Colab has installed\r\n```\r\n\r\n... with the same nonsensical results.\r\n\r\nChanging the layer to the UnifiedGRU layer resolved the problem as well - which indicates there is definitely an issue with how the UnifiedLSTM layer is implemented on GPUs (only).", "Thank for reporting the issue. let me take a look. ", "I have tried with unmodified code with GPU setting for predication, its interesting to see that it will randomly generate some text first and then suddenly produce reasonable text afterwards. Its like there are some junk text in memory need to flush first before it can probably work. Not sure why, need to dig more.\r\n\r\n=======================================================\r\nROMEO: NG&UZSEkzjjUPCQHOUJKUNSKOT:!KQWIUS;\r\nWISTETHAMNIAN:\r\nI pray thee thy king is prosper thee:\r\nBut I bristle rascals intainted lost!\r\nOr Clarence is good nor increase, I see, the comfort is but stay.\r\n\r\nWERWICK:\r\nThere were they never with a house of conseat:\r\nDown, misfave you do not best.\r\n\r\nMANCANIUS:\r\nWhat, may I think\r\nYour perform friends. I'll have no suffer:\r\nLivelour to Mercutio's same to see him.\r\n\r\nFirst Lord:\r\nNo, not wash their weeping good which is the\r\nwhich in a lowly adwise to our age! Where\r\nyou come to be\r\nOf once towards Lach:\r\nAs that do private write resort to hard\r\nFrom their friend of thine eyes I go to\r\nher, now ades might other.\r\nO horse\r\nTo give him, back'd with belons, an unsign to think\r\nYourselves I see she's Romeo! enjoy's very\r\nliesk:\r\nThis darks give her head to yard and wretches\r\nMasterness not likeway.\r\n\r\nLEONTES:\r\nWhat, was my special queen?'s not so pack as for youth,\r\nThe thought to bear me less than he is fare\r\nAs you can stay.\r\n\r\nDUKE VINCENTIO:\r\nOut; because as porthless chessen nobl\r\n\r\n==================================================\r\n\r\nROMEO: w3SxBREY:\r\nWHORTHER:\r\nNo, Signior Balingbrock's soldiers purson me\r\nwrithering up his gorder, womb; thou art too sour age\r\nonjurying: I respect I said yet he brears your king.\r\nAnd is a hundard man whose pertiace\r\nShoworigate to be wish'd his speaches to shave\r\nTo save him drunk,--why, thys; and I go shall inter?\r\nTut spiders for Rome; I shall revost it still as Jupe this?\r\nHalf thou to chose happy bark an ack of nature\r\nWas strew\r\nAnd call me pawn; the charges be gote to thee.\r\n\r\nYORK:\r\nExe once asked it in their deeds: where thou wert wonder'd here,\r\nHath yet not with the king news: they say.\r\n\r\n=========================================================\r\n\r\nROMEO: 'OTBMNWQOURIDQU3KCFvIUKXWMISMKSTILISSzUTZNGZKBYUETzXHXV&MATUdKFNOXRHMNYUK:\r\nMIXSSSTCENUT:Cus fight in him, for Gredio.\r\n\r\nBUCKINGHAM:\r\nYou do not come to intember, nothing have fought\r\nIn her ristress'd, it most unknown shall four high\r\nSubjection: that thou tert it is in heavy,\r\nTo vengered Berauade.\r\n\r\nCLO:\r\nMy father set bey made\r\nTo see a town, a maident, revenge,, they\r\nhard, unluckity.\r\n\r\nANGELO:\r\nI had as you lough; I do resalve thyself\r\nHave taken. They have Warwick;\r\nAnd, if I very tribut of revenuman's crown,\r\nYou are thereof.\r\n\r\nSLY:\r\nAge to calt my father; he hast thou give me stip of.\r\n\r\nTYRREL:\r\nProth, that's by no chearing thee,\r\n\r\n========================================================\r\n", "Also, it seems that the model works properly with the custom training loop. The prediction output for the model from custom training loop always produce reasonable result.", "Also noticed the difference between custom training loop and standard keras fit. The model.reset_states() is not call at the beginning of per epoch. After adding that, the model is producing reasonable text quite constantly. \r\n\r\nHaving said that, this still doesn't explain why the CPU and V1 code works properly without reset_states().", "Spent some time debugging this with @fchollet last Friday, it seems that cudnn kernel will spit out junk result sometime. The chances are reduced when change to use a smaller number of LSTM size. ", "Sorry for the long wait. I think there was a backend kernel error somewhere. I rerun the same code in tutoral with LSTM layer and TF 2.1, it was able to generate reasonable result without issue. Please verify this on ur end as well. I am closing this bug and feel free to reopen it if you still see same error.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/26547\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/26547\">No</a>\n"]}, {"number": 26546, "title": " ModuleNotFoundError: No module named 'tensorflow.compat.v2'", "body": "Was going through the Jupyter notebook on TFP that was associated with the TF Dev Summit:\r\n\r\nhttps://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Probabilistic_Layers_Regression.ipynb\r\nRun\r\n\r\nRunning the line \r\n\r\n`import tensorflow.compat.v2 as tf`\r\n\r\nReturns the error:\r\n\r\n> ModuleNotFoundError: No module named 'tensorflow.compat.v2'\r\n\r\nRunning tf.VERSION shows it's 1.13. \r\n\r\nI'm assuming this is related to not having TF 2.0 installed, and only having T 1.13 installed.\r\nIs a separate, 2nd installation of TF (2.0) needed to import tensorflow.compat.v2 or can both be installed into the same virtual environment?\r\n\r\nJust want to make sure installing both alongside each other won't break either or both.\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n> b'unknown' 1.13.1\r\n", "comments": ["@cpoptic Could you try changing \"v2\" to \"v1\". Like\r\nimport tensorflow.compat.v1 as tf\r\n\r\nIt worked for me. Please let us know how it progresses. We will correct the typo. Thanks!", "Yes that works, but the issue is with the tensorflow_probability\r\n\r\n```\r\n# import tensorflow.compat.v2 as tf\r\nimport tensorflow.compat.v1 as tf\r\nimport tensorflow_probability as tfp\r\n\r\ntf.enable_v2_behavior()\r\n```\r\n\r\n> \r\nAttributeError: module 'tensorflow.compat' has no attribute 'v2'\r\n\r\n\r\n> ---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-10-6713d3750cfa> in <module>\r\n     17 # import tensorflow.compat.v2 as tf\r\n     18 import tensorflow.compat.v1 as tf\r\n---> 19 import tensorflow_probability as tfp\r\n     20 \r\n     21 tf.enable_v2_behavior()\r\n\r\n/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_probability/__init__.py in <module>\r\n     76 \r\n     77 # from tensorflow_probability.google import staging  # DisableOnExport\r\n---> 78 from tensorflow_probability.python import *  # pylint: disable=wildcard-import\r\n     79 from tensorflow_probability.python.version import __version__\r\n     80 # pylint: enable=g-import-not-at-top\r\n\r\n/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_probability/python/__init__.py in <module>\r\n     27 from tensorflow_probability.python import mcmc\r\n     28 from tensorflow_probability.python import monte_carlo\r\n---> 29 from tensorflow_probability.python import optimizer\r\n     30 from tensorflow_probability.python import positive_semidefinite_kernels\r\n     31 from tensorflow_probability.python import stats\r\n\r\n/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_probability/python/optimizer/__init__.py in <module>\r\n     28 from tensorflow_probability.python.optimizer.proximal_hessian_sparse import minimize as proximal_hessian_sparse_minimize\r\n     29 from tensorflow_probability.python.optimizer.proximal_hessian_sparse import minimize_one_step as proximal_hessian_sparse_one_step\r\n---> 30 from tensorflow_probability.python.optimizer.sgld import StochasticGradientLangevinDynamics\r\n     31 from tensorflow_probability.python.optimizer.variational_sgd import VariationalSGD\r\n     32 \r\n\r\n/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_probability/python/optimizer/sgld.py in <module>\r\n     32 \r\n     33 \r\n---> 34 class StochasticGradientLangevinDynamics(tf.compat.v2.optimizers.Optimizer):\r\n     35   \"\"\"An optimizer module for stochastic gradient Langevin dynamics.\r\n     36 \r\n\r\nAttributeError: module 'tensorflow.compat' has no attribute 'v2'", "@cpoptic just want to add my observation here,\r\nin my understanding `tensorflow-probability` is not installed along with `tensorflow`.\r\nCould please try with your test script after installing `pip install --user --upgrade tensorflow-probability`\r\nHope this will help you", "Yes I ran   pip install tensorflow and pip install tensorflow-probability\n separately\nSo I'm double sure they are both installed\n\n\nOn Mon, Mar 11, 2019, 2:54 AM Albin Joy <notifications@github.com> wrote:\n\n> @cpoptic <https://github.com/cpoptic> just want to add my observation\n> here,\n> in my understanding tensorflow-probability is not installed along with\n> tensorflow.\n> Could please try with your test script after installing pip install\n> --user --upgrade tensorflow-probability\n> Hope this will help you\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/26546#issuecomment-471423722>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AG5i1dg_-9GYTEwuhLX1UnK_Z-rsRxdmks5vVf23gaJpZM4bnVwo>\n> .\n>\n", "@cpoptic  Can you please check in which path` tensorflow-probability` got installed and that python path only is used?", "is this problem solved? please help I faced the same error.", "I am having the same error as well", "I am having the same error.", "Had the same issue, if you cloned the github repo, make sure to checkout the v0.6.0-rc1 tag to run the examples with the 0.6.0 version from pip. I guess the examples in master is made to work with tf2.\r\nWorks for me at least..", "I don't have that issue with TensorFlow 1.13 and this installation of probability:\r\n\r\n```bash\r\ngit clone -b r0.6 --single-branch git@github.com:tensorflow/probability.git\r\n```", "@cpoptic Can you follow the suggestion by @jonjo442 and let us know whether your issue resolved or not. thanks!", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will open a new issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=26546\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=26546\">No</a>\n", "ModuleNotFoundError: No module named 'tensorflow.compat.v2' , it is still there. tf probability version is 0.6 and tensorflow version is 1.13", "ModuleNotFoundError: No module named 'tensorflow.compat.v2' , it is still there. tf probability version is 0.6 and tensorflow version is 1.13", "i have installed tensorflow==1.8.0, i have to run a file in order to star my training. but I am getting this error.\r\nModuleNotFoundError: No module named 'tensorflow.compat' \r\nthen i wrote this command \"pip install tensorflow.compat\" i got following error\r\nERROR: Could not find a version that satisfies the requirement tensorflow.compat (from versions: none)\r\nERROR: No matching distribution found for tensorflow.compat\r\n", "Hi Everyone, \r\n\r\nWhen this was published, it required tf-nightly or any of preview releases of tensorflow\r\n-2.0. That was the original source of confusion.\r\n\r\nThe tf.compat.v2 module was added in 1.14. Upgrade to 1.14 , 1.15, or 2.0  and this will work fine.\r\n\r\n```\r\npip install -U \"tensorflow==1.15\" \r\npip install -U \"tensorflow==2.0\" \r\n```\r\nThere is absolutely no way to run it with 1.13, or 1.8, sorry!", "> i have installed tensorflow==1.8.0, i have to run a file in order to star my training. but I am getting this error.\r\n> ModuleNotFoundError: No module named 'tensorflow.compat'\r\n> then i wrote this command \"pip install tensorflow.compat\" i got following error\r\n> ERROR: Could not find a version that satisfies the requirement tensorflow.compat (from versions: none)\r\n> ERROR: No matching distribution found for tensorflow.compat\r\n\r\nI am getting the same error when importing tensorflow.compat.v1 as tf. Any further suggestions as I would like to use tensorflow==1.8.0?", "I have tensorflow 1.4.0 with Cuda 8 and cudnn 7. And I get the following error. \r\n\r\n`    import tensorflow.compat.v1 as tf\r\nImportError: No module named 'tensorflow.compat'\r\n`\r\n\r\nAfter installing `tensorflow-probability`, I still get the same error. ", "@himanshisyadav upgrade to at least TF 1.14.", "@MarkDaoust I looked the tensorflow_gpu version for CUDA 8 and CudNN 7 and it was 1.4.1. Now, I am getting a bunch of warnings and the script won't run. \r\n\r\nWhy should I upgrade 1.14?", "@MarkDaoust I fixed it by install tf-nightly-gpu. ", "If your problem is with RASA CORE, in my case, I executed the following commands:\r\npip install -U tensorflow==1.15 \r\npip install -U tensorflow==2.0 \r\npip install -U gast==0.3.3\r\npip install -U tf-nightly-gpu\r\npip install -U tensorboard==1.15.0\r\npip install -U tensorflow==1.15 ", "@MarkDaoust  \r\n\r\n> pip install -U \"tensorflow==2.0\"\r\n\r\nworked for me ", "pip install -U \"tensorflow==2.0\" is ok", "I am facing an issue with module not found error \"tf.compat.v1\" for this. I have Tensorflow version1.14 installed. I did pip un-install TensorFlow & installed it again..same did with tensorflow_estimator and tensorflow_probability. ", "Still have the issue", "One common way to get stuck in a particular tensorflow version is to have an old version of python or pip.\r\n\r\nIf you try to install a specific version and it fails then check your python and pip versions.\r\n\r\n```\r\npip install -U \"tensorflow==1.15.*\"\r\npip install -U \"tensorflow==2.2.*\"\r\n```\r\n\r\n`pip install tensorflow` only gets you the latest version if those are up to date.", "> I am facing an issue with module not found error \"tf.compat.v1\" for this. I have Tensorflow version1.14 installed. I did pip un-install TensorFlow & installed it again..same did with tensorflow_estimator and tensorflow_probability.\r\n\r\n@SharadSirsat did this work as a solution to  \"tensorflow.compat.v1\"  or are you saying that the problem exists even when you reinstalled TF?", "`!pip install -U \"tensorflow==2.0\" `\r\n\r\nI was facing similar issues but this solved the problem for me. Thanks!", "I followed the steps above. However, I am still getting error.\r\n\r\nI cannot upgrade tensorflow==2.0 due to my project requirements. \r\nI can only use tensorflow==1.14.0 , tensorflow-gpu==1.5.0\r\n\r\nI am getting\r\n`ModuleNotFoundError: No module named 'tensorflow.compat'`\r\n\r\nHow do I go about solving it?", "Same here", "Idk if this is solved or not, but upgrading to tensorflow 2.0 solved the issue for me.\r\n`pip3 install --user tensorflow==2.0`\r\n", "Solution: https://github.com/tensorflow/tensorflow/issues/38800#issuecomment-660535430", "@cpoptic @miguelmorin I have the same problem with tensorflow 1.13.1, please how i can fix it", "@marwazaa I no longer use TensorFlow, sorry. Can you try the latest version of TensorFlow, or at least version 2?", "I'm getting error with: import tensorflow.compat.v2 as tf", "\u4f60\u7684\u6765\u4fe1\u5df2\u6536\u5230\uff0c\u8c22\u8c22\uff01", "> I followed the steps above. However, I am still getting error.\r\n> \r\n> I cannot upgrade tensorflow==2.0 due to my project requirements. I can only use tensorflow==1.14.0 , tensorflow-gpu==1.5.0\r\n> \r\n> I am getting `ModuleNotFoundError: No module named 'tensorflow.compat'`\r\n> \r\n> How do I go about solving isa\r\n\r\n> I followed the steps above. However, I am still getting error.\r\n> \r\n> I cannot upgrade tensorflow==2.0 due to my project requirements. I can only use tensorflow==1.14.0 , tensorflow-gpu==1.5.0\r\n> \r\n> I am getting `ModuleNotFoundError: No module named 'tensorflow.compat'`\r\n> \r\n> How do I go about solving it?\r\n\r\nsame situation. I can only use tensorflow==1.4\r\ndid you solve it?", "\u4f60\u7684\u6765\u4fe1\u5df2\u6536\u5230\uff0c\u8c22\u8c22\uff01"]}, {"number": 26545, "title": "Issue on converting yolo to tflite with bazel-bin toco", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.10\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (or github SHA if from source):  master\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\nI tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: ExtractImagePatches\r\n2019-03-10 16:38:02.722378: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 211 operators, 370 arrays (0 quantized)\r\n2019-03-10 16:38:02.727060: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 211 operators, 370 arrays (0 quantized)\r\n2019-03-10 16:38:03.193935: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 97 operators, 189 arrays (0 quantized)\r\n2019-03-10 16:38:03.195613: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 97 operators, 189 arrays (0 quantized)\r\n2019-03-10 16:38:03.196705: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 97 operators, 189 arrays (0 quantized)\r\n2019-03-10 16:38:03.198405: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 68550208 bytes, theoretical optimal value: 66453504 bytes.\r\n2019-03-10 16:38:03.202350: E tensorflow/lite/toco/toco_tooling.cc:456] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONCATENATION, CONV_2D, MAXIMUM, MAX_POOL_2D, MUL, PAD. Here is a list of operators for which you will need custom implementations: ExtractImagePatches.\r\nWe are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONCATENATION, CONV_2D, MAXIMUM, MAX_POOL_2D, MUL, PAD. Here is a list of operators for which you will need custom implementations: ExtractImagePatches.\r\n\r\n```\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\nModel is retrainer yolo\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@antonino-tocco Could you add more details on the context of the issue and the process you followed leading to the bug? Please provide a  code to reproduce the bug. Thanks!", "Hi @jvishnuvardhan, thanks for your help.\r\nI follow this tutorial for retrain yolo: https://www.tooploox.com/blog/card-detection-using-yolo-on-android.\r\nI train my model, convert it to protobuf with darkflow and then i try to convert it to tflite for embedd it on my Android app with baze-bin toco. I receive issue for non tflite operators such as ExtractImagePatches.", "@antonino-tocco Could you provide full command of tflite_convert? Thanks!", "Sure.\r\n/bazel-bin/tensorflow/lite/toco/toco   --input_file=yolo-obj.pb   --output_file=foo.tflite    --input_format=TENSORFLOW_GRAPHDEF   --output_format=TFLITE   --input_arrays=input   --input_shapes=1,416,416,3\r\nThanks for your help.", "Hi, any news?", "It's missing an ExtractImagePatches op in TensorFlow Lite. \r\n@talumbau could you take a look to see should we implement it as a TensorFlow Lite builtin op?\r\n\r\nMeanwhile, we have an experimental feature that you can use TensorFlow kernel in TensorFlow Lite. \r\nFeel free to try it if you're interested and give us feedbacks. \r\nhttps://www.tensorflow.org/lite/guide/ops_select", "2019-03-27 14:56:19.740750: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.746180: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.746229: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.746244: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.746260: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.746272: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.746287: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.746297: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.746312: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.746324: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.746369: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.746383: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.746407: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.746418: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.746434: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.746446: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.746459: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.746470: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.746485: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.746496: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.746539: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.746552: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.746576: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.746587: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.746706: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.746718: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.746733: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.746744: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.746761: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.746772: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.746814: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.746827: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.746852: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.746864: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.746880: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.746891: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.746907: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.746918: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.746933: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.746944: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.746985: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.746998: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.747025: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.747036: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.747053: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.747065: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.747081: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.747092: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.747110: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.747122: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.747172: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.747185: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.747212: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.747225: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.747242: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.747254: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.747271: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.747282: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.747299: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.747310: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.747351: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.747364: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.747390: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.747402: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.747419: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.747431: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.747447: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.747459: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.747475: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.747488: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.747531: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.747544: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.747573: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.747586: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.747603: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.747615: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.747632: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.747644: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.747661: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.747673: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.747720: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.747733: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.747763: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.747776: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.747793: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.747804: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.747822: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.747834: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.747852: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.747863: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.747906: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.747920: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.747948: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.747961: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.747980: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.747992: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.748010: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.748021: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.748038: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.748050: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.748093: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.748106: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.748136: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.748149: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.748166: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.748179: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.748196: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.748207: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.748224: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.748236: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.748282: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.748295: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.748323: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.748336: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.748353: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.748364: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.748381: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.748393: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.748410: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.748421: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.748464: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.748477: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.748506: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.748519: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.748536: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.748548: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.748565: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.748577: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.748594: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.748605: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.748651: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.748665: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.748697: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.748710: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.748732: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.748744: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.748766: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.748778: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.748800: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.748811: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.748854: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.748867: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.748897: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.748910: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.748928: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.748940: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.748957: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.748993: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.749016: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.749037: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.749088: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.749119: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.749149: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.749181: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.749200: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.749211: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.749230: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.749250: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.749279: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.749290: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.749337: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.749359: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.749385: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.749397: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.749413: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.749424: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.749441: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.749451: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.749466: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.749485: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.749522: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.749533: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.749563: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.749575: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.749594: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.749605: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.749624: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.749634: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.749653: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.749664: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.749699: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.749710: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.749744: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.749756: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.749776: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.749786: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.749804: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.749814: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.749833: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.749843: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.749882: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.749894: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.749924: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.749935: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.749954: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.749964: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.749983: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.749993: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.750011: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.750021: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.750060: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.750072: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.750097: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.750108: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.750123: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.750133: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.750147: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.750157: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.750172: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.750182: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.750234: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.750246: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.750276: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.750288: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.750306: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.750317: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.750335: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.750345: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.750364: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.750374: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.750410: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.750421: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.750436: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: VariableV2\r\n2019-03-27 14:56:19.750447: I tensorflow/lite/toco/import_tensorflow.cc:1335] Converting unsupported operation: Assign\r\n2019-03-27 14:56:19.755191: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 619 operators, 829 arrays (0 quantized)\r\n2019-03-27 14:56:19.761903: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 391 operators, 419 arrays (0 quantized)\r\n2019-03-27 14:56:19.766917: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 391 operators, 419 arrays (0 quantized)\r\n2019-03-27 14:56:19.772167: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 278 operators, 351 arrays (0 quantized)\r\n2019-03-27 14:56:19.775999: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 278 operators, 351 arrays (0 quantized)\r\n2019-03-27 14:56:19.779054: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 278 operators, 351 arrays (0 quantized)\r\n2019-03-27 14:56:19.782410: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 94371840 bytes, theoretical optimal value: 94371840 bytes.\r\n2019-03-27 14:56:19.783404: E tensorflow/lite/toco/toco_tooling.cc:456] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, CONV_2D, LEAKY_RELU, MAX_POOL_2D, MUL, RESHAPE, RSQRT, TRANSPOSE. Here is a list of operators for which you will need custom implementations: BatchNormalization, VariableV2.\r\nWe are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\n\r\n\r\n\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, CONV_2D, LEAKY_RELU, MAX_POOL_2D, MUL, RESHAPE, RSQRT, TRANSPOSE. Here is a list of operators for which you will need custom implementations: BatchNormalization, VariableV2.\r\n\r\n\r\n\r\n\r\n\r\nI had a same issue with yolo. \r\nI have used  command `/bazel-bin/tensorflow/lite/toco/toco   --input_file=/newhd/dev/darkflowToTensorflow/data/yolo-voc.pb   --output_file=foo.tflite    --input_format=TENSORFLOW_GRAPHDEF   --output_format=TFLITE   --input_arrays=input   --input_shapes=1,416,416,3   --output_arrays=yolov2/convolutional23/BiasAdd    --target_ops=TFLITE_BUILTINS,SELECT_TF_OPS`", "Can you try rerun the tutorial from the \"Convert .weights to a frozen graph\" step on the latest nightly? This might have been fixed in by https://github.com/tensorflow/tensorflow/commit/0f486fc67070ba888204741c404a55a5f1a41fbc.", "Hi, thank you to all for the help. I can retry on this weekend. I will update you", "@himanshurobo Hi, I have the same issue with you. I also have added --target_ops. But it's still not working. Have you fixed it? Thanks", "Hi!\r\n\r\nI've download tf folder from here: [https://github.com/tensorflow/tensorflow](https://github.com/tensorflow/tensorflow) and I run this command\r\n\r\n\r\n```bash\r\n$ cd tensorflow-master   \r\n$ bazel run tensorflow/lite/toco:toco -- \\\r\n    --input_file=my.pb \\\r\n    --output_file=out.tflite \\\r\n    --input_shapes=1,416,416,3 \\\r\n    --input_arrays='input_1' \\\r\n    --output_format=TFLITE \\\r\n    --output_arrays='output_0','output_1' \\\r\n    --inference_type=QUANTIZED_UINT8 \\\r\n    --std_dev_values=128 --mean_values=128 \\\r\n    --default_ranges_min=-6 --default_ranges_max=6 \\\r\n    --change_concat_input_ranges=false \\\r\n    --allow_custom_ops\r\n```\r\n\r\nand it works!\r\n\r\nBy the way, in my post elaboration I've a overflow problem\r\n\r\n`RuntimeWarning: overflow encountered in exp`\r\n\r\nHow manage output vector?\r\n", "Hi @antonino-tocco ! I converted the yolo frozen graph to tflite file using [TFlite converter api](https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter). Attaching [gist ](https://colab.sandbox.google.com/gist/mohantym/8712339f9de1757e114589f657da06fb/github_26545.ipynb)for reference. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/26545\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/26545\">No</a>\n"]}, {"number": 26544, "title": "Timing hook giving wrong execution time", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google colab env\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): !pip3 install -U tensorflow-gpu==2.0.0-alpha0\r\n- TensorFlow version (use command below): 2.0.0-alpha0\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\nTiming hook is showing the training time as 12.11 sec, whereas elapsed time from python by getting time info before and after the step is : 70.4 sec\r\n\r\nTiming hook and elapsed time should be same within a limit\r\n[Fashion_mnist_estimators.zip](https://github.com/tensorflow/tensorflow/files/2949587/Fashion_mnist_estimators.zip)\r\n\r\n\r\n**Code to reproduce the issue**\r\nAttached ehere\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@anirbankonar123 Please check it again with a Stopwatch. On my Mac it took 85.64 sec and it was correct as my stopwatch showed 87 sec. \r\nPlease post these kind of support questions in stackoverflow. Thanks!", "As I mentioned, I hv checked number of times, time given by Time hook is\nmuch less than elapsed time rpted by time lib of python. The variation is\nsignificant. Its a bug.\n\nits not something for stackoverflow, as i am not getting stuck up in a\nsyntax, or dnt know how to use something.\n\nThanks,\nAnirban\n\nOn Sun, 10 Mar 2019 at 21:27, Vishnuvardhan Janapati <\nnotifications@github.com> wrote:\n\n> @anirbankonar123 <https://github.com/anirbankonar123> Please check it\n> again with a Stopwatch. On my Mac it took 85.64 sec and it was correct as\n> my stopwatch showed 87 sec.\n> Please post these kind of support questions in stackoverflow. Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/26544#issuecomment-471318231>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ANFvt0OT5ZlPEcqDRKD0lsoHzaC9mctKks5vVSt8gaJpZM4bnTOe>\n> .\n>\n", "@anirbankonar123 Could you provide a link to the file as you shared in other issue? Thanks!", "Sure, heres the link\nhttps://colab.research.google.com/drive/1_F13vQd_G_imOyrVtO7Sauw7O9tQvoWM\n\nThanks\n\nOn Sun, 10 Mar 2019 at 21:48, Vishnuvardhan Janapati <\nnotifications@github.com> wrote:\n\n> @anirbankonar123 <https://github.com/anirbankonar123> Could you provide a\n> link to the file as you shared in other issue? Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/26544#issuecomment-471319923>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ANFvt0NuHnRmiAhfGs4AAb6MVBzYHzBsks5vVTBggaJpZM4bnTOe>\n> .\n>\n"]}, {"number": 26543, "title": "loss becoming 'nan' and accuracy dropping to 5% using tf.keras", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google colab env\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): !pip3 install -U tensorflow==2.0.0-alpha0\r\n- TensorFlow version (use command below): 2.0.0-alpha0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: no GPU used\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n\"loss becoming 'nan' and accuracy dropping to 5% using tf.keras, with fashion-mnist, on 4th epoch (sometimes it happens on 7th / 8th epoch)\r\n\r\n\"loss should not become 'nan' and accuracy should never drop unexpectedly\r\nPrint output : \r\nEpoch #1\t Loss: 0.679400\tAccuracy: 0.729167\r\nEpoch #2\t Loss: 0.558087\tAccuracy: 0.770833\r\nEpoch #3\t Loss: 0.487591\tAccuracy: 0.812500\r\nEpoch #4\t Loss: 0.429859\tAccuracy: 0.833333\r\n**Epoch #5\t Loss: nan\t        Accuracy: 0.052083**\r\n[Fashion_mnist_with_keras_eager_and_tf_data.zip](https://github.com/tensorflow/tensorflow/files/2949581/Fashion_mnist_with_keras_eager_and_tf_data.zip)\r\n\r\n\r\n**Code to reproduce the issue**\r\nCode attached in jupyter notebook format\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@anirbankonar123 I don't see any issue with your code. Please post this kind of support questions in stackoverflow. Thanks!\r\nMy output as follows\r\nEpoch #1\t Loss: 0.634148\tAccuracy: 0.739583\r\nEpoch #2\t Loss: 0.524849\tAccuracy: 0.770833\r\nEpoch #3\t Loss: 0.454392\tAccuracy: 0.833333\r\nEpoch #4\t Loss: 0.390557\tAccuracy: 0.885417\r\nEpoch #5\t Loss: 0.346580\tAccuracy: 0.885417\r\n78.02320790290833\r\n\r\nWhen I ran it again\r\nEpoch #1\t Loss: 0.579839\tAccuracy: 0.791667\r\nEpoch #2\t Loss: 0.431964\tAccuracy: 0.833333\r\nEpoch #3\t Loss: 0.382009\tAccuracy: 0.895833\r\nEpoch #4\t Loss: 0.381249\tAccuracy: 0.895833\r\nEpoch #5\t Loss: 0.360117\tAccuracy: 0.895833\r\n81.38940477371216\r\n\r\nAs you see, accuracy is increasing each epoch. you could increase accuracy by following other tutorials on performance. Thanks", "I got this on 8th epoch last time. I hv attached jupyter notebook also, it\nis happening randomly at diff epochs. pls see my log here\nhttps://colab.research.google.com/drive/1NmxW4FuBRH5-0t87YMl21Y-OKKRKCjun\n\nThere is something wrong here, loss shd never become nan, never seen this\nin keras or Tf 1.x\n\nThanks\n\nOn Sun, 10 Mar 2019 at 20:44, Vishnuvardhan Janapati <\nnotifications@github.com> wrote:\n\n> @anirbankonar123 <https://github.com/anirbankonar123> I don't see any\n> issue with your code. Please post this kind of support questions in\n> stackoverflow. Thanks!\n> My output as follows\n> Epoch #1 <https://github.com/tensorflow/tensorflow/issues/1> Loss:\n> 0.634148 Accuracy: 0.739583\n> Epoch #2 <https://github.com/tensorflow/tensorflow/issues/2> Loss:\n> 0.524849 Accuracy: 0.770833\n> Epoch #3 <https://github.com/tensorflow/tensorflow/issues/3> Loss:\n> 0.454392 Accuracy: 0.833333\n> Epoch #4 <https://github.com/tensorflow/tensorflow/issues/4> Loss:\n> 0.390557 Accuracy: 0.885417\n> Epoch #5 <https://github.com/tensorflow/tensorflow/issues/5> Loss:\n> 0.346580 Accuracy: 0.885417\n> 78.02320790290833\n>\n> When I ran it again\n> Epoch #1 <https://github.com/tensorflow/tensorflow/issues/1> Loss:\n> 0.579839 Accuracy: 0.791667\n> Epoch #2 <https://github.com/tensorflow/tensorflow/issues/2> Loss:\n> 0.431964 Accuracy: 0.833333\n> Epoch #3 <https://github.com/tensorflow/tensorflow/issues/3> Loss:\n> 0.382009 Accuracy: 0.895833\n> Epoch #4 <https://github.com/tensorflow/tensorflow/issues/4> Loss:\n> 0.381249 Accuracy: 0.895833\n> Epoch #5 <https://github.com/tensorflow/tensorflow/issues/5> Loss:\n> 0.360117 Accuracy: 0.895833\n> 81.38940477371216\n>\n> As you see, accuracy is increasing each epoch. you could increase accuracy\n> by following other tutorials on performance. Thanks\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/26543#issuecomment-471314607>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ANFvtz2A9Y9Tu391of39SIskL-hNkikzks5vVSFQgaJpZM4bnTCe>\n> .\n>\n", "@anirbankonar123 Again, I ran your shared file. \r\nhttps://colab.sandbox.google.com/gist/jvishnuvardhan/becdfc18f1510f27bca54176048b3ba7/copy-of-fashion-mnist-with-keras-eager-and-tf-data.ipynb\r\n\r\nEpoch #1\t Loss: 0.547747\tAccuracy: 0.791667\r\nEpoch #2\t Loss: 0.412555\tAccuracy: 0.833333\r\nEpoch #3\t Loss: 0.339921\tAccuracy: 0.854167\r\nEpoch #4\t Loss: 0.353694\tAccuracy: 0.916667\r\nEpoch #5\t Loss: 0.355032\tAccuracy: 0.895833\r\n222.52565932273865\r\n\r\nCould you try running in other system or \"reset all runtimes\" in google colab and run it. Thanks!", "As I mentioned, its not a reproducible issue, i got it initially on 7th\nepoch, then didnt get it for a while, again got it twice today morning on\n4th epoch. I generally reset all runtimes, its kind of mandatory for me as\nI install fresh version of TF and need to make sure this is happpening\nproperly ! I understand its not coming now, for me too it was working\nyesterday, but an issue all the while, as I didnt make a single code change\nin this time. and its the same env as well...Thanks\n\nOn Sun, 10 Mar 2019 at 21:47, Vishnuvardhan Janapati <\nnotifications@github.com> wrote:\n\n> @anirbankonar123 <https://github.com/anirbankonar123> Again, I ran your\n> shared file.\n>\n> https://colab.sandbox.google.com/gist/jvishnuvardhan/becdfc18f1510f27bca54176048b3ba7/copy-of-fashion-mnist-with-keras-eager-and-tf-data.ipynb\n>\n> Epoch #1 <https://github.com/tensorflow/tensorflow/issues/1> Loss:\n> 0.547747 Accuracy: 0.791667\n> Epoch #2 <https://github.com/tensorflow/tensorflow/issues/2> Loss:\n> 0.412555 Accuracy: 0.833333\n> Epoch #3 <https://github.com/tensorflow/tensorflow/issues/3> Loss:\n> 0.339921 Accuracy: 0.854167\n> Epoch #4 <https://github.com/tensorflow/tensorflow/issues/4> Loss:\n> 0.353694 Accuracy: 0.916667\n> Epoch #5 <https://github.com/tensorflow/tensorflow/issues/5> Loss:\n> 0.355032 Accuracy: 0.895833\n> 222.52565932273865\n>\n> Could you try running in other system or \"reset all runtimes\" in google\n> colab and run it. Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/26543#issuecomment-471319781>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ANFvty9OwcT3Vp-CGu8Hdb6bfo6NnvScks5vVTADgaJpZM4bnTCe>\n> .\n>\n", "Ran just now, after doing 'reset all runtimes' , installing tensorflow now\ngetting loss = nan on 3rd epoch :\nhttps://colab.research.google.com/drive/1NmxW4FuBRH5-0t87YMl21Y-OKKRKCjun#scrollTo=kNgnUKPvgSCz\n\nPlease see here.\nThanks\n\nOn Sun, Mar 10, 2019 at 9:47 PM Vishnuvardhan Janapati <\nnotifications@github.com> wrote:\n\n> @anirbankonar123 <https://github.com/anirbankonar123> Again, I ran your\n> shared file.\n>\n> https://colab.sandbox.google.com/gist/jvishnuvardhan/becdfc18f1510f27bca54176048b3ba7/copy-of-fashion-mnist-with-keras-eager-and-tf-data.ipynb\n>\n> Epoch #1 <https://github.com/tensorflow/tensorflow/issues/1> Loss:\n> 0.547747 Accuracy: 0.791667\n> Epoch #2 <https://github.com/tensorflow/tensorflow/issues/2> Loss:\n> 0.412555 Accuracy: 0.833333\n> Epoch #3 <https://github.com/tensorflow/tensorflow/issues/3> Loss:\n> 0.339921 Accuracy: 0.854167\n> Epoch #4 <https://github.com/tensorflow/tensorflow/issues/4> Loss:\n> 0.353694 Accuracy: 0.916667\n> Epoch #5 <https://github.com/tensorflow/tensorflow/issues/5> Loss:\n> 0.355032 Accuracy: 0.895833\n> 222.52565932273865\n>\n> Could you try running in other system or \"reset all runtimes\" in google\n> colab and run it. Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/26543#issuecomment-471319781>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ANFvty9OwcT3Vp-CGu8Hdb6bfo6NnvScks5vVTADgaJpZM4bnTCe>\n> .\n>\n", "Epoch #1 Loss: 0.549081 Accuracy: 0.718750 Epoch #2 Loss: 0.430481\nAccuracy: 0.822917 Epoch #3 Loss: nan Accuracy: 0.166667 Epoch #4 Loss: nan\nAccuracy: 0.166667 Epoch #5 Loss: nan Accuracy: 0.166667\n\nOn Sun, Mar 10, 2019 at 9:47 PM Vishnuvardhan Janapati <\nnotifications@github.com> wrote:\n\n> @anirbankonar123 <https://github.com/anirbankonar123> Again, I ran your\n> shared file.\n>\n> https://colab.sandbox.google.com/gist/jvishnuvardhan/becdfc18f1510f27bca54176048b3ba7/copy-of-fashion-mnist-with-keras-eager-and-tf-data.ipynb\n>\n> Epoch #1 <https://github.com/tensorflow/tensorflow/issues/1> Loss:\n> 0.547747 Accuracy: 0.791667\n> Epoch #2 <https://github.com/tensorflow/tensorflow/issues/2> Loss:\n> 0.412555 Accuracy: 0.833333\n> Epoch #3 <https://github.com/tensorflow/tensorflow/issues/3> Loss:\n> 0.339921 Accuracy: 0.854167\n> Epoch #4 <https://github.com/tensorflow/tensorflow/issues/4> Loss:\n> 0.353694 Accuracy: 0.916667\n> Epoch #5 <https://github.com/tensorflow/tensorflow/issues/5> Loss:\n> 0.355032 Accuracy: 0.895833\n> 222.52565932273865\n>\n> Could you try running in other system or \"reset all runtimes\" in google\n> colab and run it. Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/26543#issuecomment-471319781>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ANFvty9OwcT3Vp-CGu8Hdb6bfo6NnvScks5vVTADgaJpZM4bnTCe>\n> .\n>\n", "@jvishnuvardhan Let's investigate this one further. There might be an environment/device specific issue.", "cc myself ", "@anirbankonar123 Is this still an issue? Could you check with `tf-nightly-gpu-2.0-preview` and let us know how it progresses. I ran several times today, never saw `nan`. Thanks!", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=26543\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=26543\">No</a>\n"]}, {"number": 26542, "title": "Extended tf.print to support more options", "body": "Right now `tf.print` lacks the support of options like `end` or `sep` known from python's `print` function. Adding support for those options might make it easier for people to migrate existing code to TensorFlow (e.g. see [issue 26510](https://github.com/tensorflow/tensorflow/issues/26510)).  This pull request tries to solve this. \r\n\r\nOnly small modifications had to be done to support the `end` and `sep` keyword. At the moment one unit test still fails; but it rather looks like a problem in the configuration of the test than a bug in the real code.", "comments": ["@petewarden Will you have the time to review this PR or should someone else take over?", "Nagging Reviewer @petewarden: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 14 days with no activity and the `awaiting review` label has been applied.", "@rthadur If @petewarden does not have time to review this PR can someone else take over?", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F26542) for more info**.\n\n<!-- need_author_cla -->", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F26542) for more info**.\n\n<!-- ok -->", "@tomerk \r\n> 1. Do the C++ logging ops tests still pass after this change?\r\n\r\nYes, I made sure of that. I have also added a new unit test to verify the behavior of the new options.\r\n\r\n> It might make sense to add an optional \"end\" string attribute to the C++ PrintV2 op.\r\n\r\nOkay. I will take care of that!\r\n**Edit**: I added this option in commit [f34e08a](https://github.com/tensorflow/tensorflow/pull/26542/commits/f34e08a09092a62ee285e9ba637f5a06cf0c3f85).\r\n\r\n> 2. Can you make sure to also update `PrintToPythonStdout` in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/eager/pywrap_tfe_src.cc\r\n>    to make sure that this will work in Jupyter notebooks + colabs?\r\n\r\nThis should be solved by now, too.\r\n\r\n", "@FlashTek please resolve conflicts.", "@rthadur I solved the conflicts\r\n", "> @rthadur I solved the conflicts\r\n\r\nThank you , we will wait for @tomerk review.", "Fantastic, thank you!"]}, {"number": 26541, "title": "Fixed minor typos", "body": "Mega typo fix PR, review pleasee @rthadur @dynamicwebpaige ?????", "comments": ["@kyscg please rebase your branch", "Where should I rebase it to? I'm new to this, sorry if I'm holding up stuff", "> Where should I rebase it to? I'm new to this, sorry if I'm holding up stuff\r\n\r\nrebase to master , i meant resolve conflicts.", "Hi, why isn't this being merged, should I make anything better? @rthadur @chsigg ", "@rthadur Gentle ping to pull, all changes have been approved\r\n", "It's not being merged because tests fail (the exception check is case sensitive). I will fix it and submit."]}, {"number": 26540, "title": "updated documentation for tf.math.argmin and tf.math.argmax operations", "body": "PR for issue #26530 and #26532\r\n\r\nAdded usage examples for tf.math.argmin and tf.math.argmax functions with this patch.\r\nUpdated docstring in tensorflow/python/ops/math_ops.py", "comments": ["Yes, will make the change today.", "@mihaimaruseac have made the changes", "@mihaimaruseac thanks for the thorough comments! Will take care going forward :)", "This will need changes as internal tests fail with\r\n\r\n```Invalid argument: No matching input/output/attr for name 'inputs' from Doc() for Op ArgMax```", "There is another failure (`bazel test //tensorflow/core/api_def:api_test`)\r\n\r\n```\r\nValue of: op.summary().empty()\r\n  Actual: false\r\nExpected: true\r\nOpDef for ArgMax has a doc string. Doc strings must be defined in ApiDef instead of OpDef. Please, add summary and descriptions in api_def_ArgMax.pbtxt file instead\r\n[  FAILED  ] BaseApiTest.OpDefsShouldNotHaveDocs (74 ms)\r\n```", "@mihaimaruseac I have now removed the doctring from OpDefs", "Done, had mistakenly deleted the shape function"]}, {"number": 26539, "title": "[TF 2.0 API Docs] tf.zeros_like", "body": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version:  2.0\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/zeros_like\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\n- **Raises listed and defined**\r\n  No raises listed\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n", "comments": ["@mandroid6 @jvishnuvardhan I want to work on this Issue. can you please help me get started with updating docs. Thanks", "@ParthS007 yes sure. Just find the relevant py file and update the doc string in the *zeros_like* function. \r\n\r\nAlso can you take up other similar issues which require docstring update, it would be helpful to have a single PR for them!\r\n\r\n", "I agree with @mandroid6. I would be happy to see a single (mostly two) PR(s) to close these 8 similar issues. Thanks @ParthS007 .\r\n\r\n", "okay @mandroid6 @jvishnuvardhan I am going through the Issues and will ask here if I face any difficulty.\r\nThanks for the responses. :+1: ", "@mandroid6 Do I have to make PR in this repo: https://github.com/tensorflow/docs", "@ParthS007 Create a PR in TF/TF repo [here](https://github.com/tensorflow/tensorflow/pulls). Thanks!", "okay @jvishnuvardhan, Will send a PR soon :+1: ", "@mandroid6 @jvishnuvardhan What I have to update exactly?\r\nI have found the functions `zeros_like` is defined here - https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/array_ops.py#L1876\r\nWhat more should I add in the documentation?\r\nThanks for the help. :+1: ", "Update the docstring of the functions you need to improve the documentation\nof.\n\nOn Thu, Mar 14, 2019 at 3:56 AM, Parth Shandilya <notifications@github.com>\nwrote:\n\n> @mandroid6 <https://github.com/mandroid6> @jvishnuvardhan\n> <https://github.com/jvishnuvardhan> What I have to update exactly?\n> I have found the functions zeros_like is defined here -\n> https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/array_ops.py#L1876\n> What more should I add in the documentation?\n> Thanks for the help. \ud83d\udc4d\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/26539#issuecomment-472629126>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ASrYl1Xrjog_vmY1Pb67oVkJdfAJs2ubks5vWXsBgaJpZM4bnP4T>\n> .\n>\n", "`zeros_like` does not raise any errors directly, and we do not list transitive raises"]}, {"number": 26538, "title": "[TF 2.0 API Docs] tf.zeros_initializer", "body": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version:  2.0\r\n- Doc Link: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/zeros_initializer\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\n- **Raises listed and defined**\r\n  No raises listed\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n", "comments": ["Closing this issue as I combined this issue with another similar issue (#26532). Thanks!"]}]