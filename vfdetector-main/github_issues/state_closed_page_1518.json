[{"number": 7386, "title": "Make this not UnboundLocalError if the actual TF_NewStatus failed.", "body": "Closes #7356.\r\n\r\nDoesn't look like there are previous tests here, so unfortunately submitting this without any new tests, but if I've missed where they live let me know.", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it!\r\n\r\nAs usual, after having to spend 5 minutes reverse engineering how that CLA page handles switching between multiple signed-in Google accounts. Seems it's impervious to the `/u/1/` that GMail uses, and to the `&authuser=1` that other places use. Glad this is easy in 2017.\r\n\r\nSorry, it's early in the morning, snark is irresistable.", "CLAs look good, thanks!\n\n<!-- ok -->", "Thank you!  I'll merge once the tests complete.", "Jenkins, test this please.", "@Julian Thank you for the fix!", "Thank you!\n\nOn Feb 9, 2017 13:12, \"Geoffrey Irving\" <notifications@github.com> wrote:\n\n> @Julian <https://github.com/Julian> Thank you for the fix!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/7386#issuecomment-278724468>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAUIXq1i0v3asJVY8K0FzHtNWjHySDv_ks5ra1bXgaJpZM4L8K2z>\n> .\n>\n"]}, {"number": 7385, "title": "[Tensorboard Request]Ignoring specific subdirectories", "body": "I think this will be simple but very useful feature for Tensorboard.\r\n\r\nWhat I want is the ignoring specific subdirectories.\r\n\r\nTensorboard load all of subdirectries and display them, but it become slower as more subfolders are added. So, I just want to ignore some directories without moving them.\r\n\r\nThere's several options to do this.\r\n1. If there is special character(like #) in folder name, just ignore it.\r\n2. Like git, .ignore file manage folders to ignore.\r\n3. If .nolog file in the folder to ignore.(Like .nomedia file)\r\n\r\nI think option 3 is best, because folder structure can be changed.", "comments": ["@dandelionmane Do you like any of these options?", "I've migrated this to our new repository at https://github.com/tensorflow/tensorboard/issues/70. Feel free to continue discussion there."]}, {"number": 7384, "title": "freeze_graph.py script fails with FailedPreconditionError: 01", "body": "I want to freeze a graph for the usage on a mobile device. The code I wrote was motivated by the freeze_graph_test.py script.\r\n\r\nimport modules\r\n```\r\nimport os\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nfrom tensorflow.core.framework import graph_pb2\r\nfrom tensorflow.core.protobuf import saver_pb2\r\nfrom tensorflow.python.client import session\r\n\r\nimport imp\r\ngraph_io = imp.load_source('graph_io.py', \r\n'/export/home/oblum/bibs/tensorflow/tensorflow/python/framework/graph_io.py')   \r\n\r\nfrom tensorflow.python.framework import ops\r\nfrom tensorflow.python.framework import test_util\r\nfrom tensorflow.python.ops import math_ops\r\nfrom tensorflow.python.ops import variables\r\nfrom tensorflow.python.platform import test\r\nfrom tensorflow.python.tools import freeze_graph\r\nfrom tensorflow.python.training import saver as saver_lib\r\n```\r\n\r\nset path and file names\r\n```\r\ncheckpoint_prefix     = \"01/saved_checkpoint\"\r\ncheckpoint_state_name = \"checkpoint_state\"\r\ninput_graph_name      = \"input_graph.pb\"\r\noutput_graph_name     = \"output_graph.pb\"\r\ncheckpoint_path       = \"01\"\r\n```\r\n\r\ndefine the graph, load weights and and save checkpoint\r\n```\r\nwith ops.Graph().as_default():\r\n\r\n\r\n    # load weights\r\n    fname = \"alex_finetuned.npy\"\r\n    pretrained_net = np.load(fname).item()\r\n\r\n    # save weights in dictionary\r\n    weights = { \r\n            \"conv1\": tf.Variable(pretrained_net[\"conv1\"][0]),\r\n            \"conv2\": tf.Variable(pretrained_net[\"conv2\"][0]),\r\n            \"conv3\": tf.Variable(pretrained_net[\"conv3\"][0]),\r\n            \"conv4\": tf.Variable(pretrained_net[\"conv4\"][0]),\r\n            \"conv5\": tf.Variable(pretrained_net[\"conv5\"][0]),\r\n            \"fc6\": tf.Variable(pretrained_net[\"fc6\"][0]),\r\n            \"fc7\": tf.Variable(pretrained_net[\"fc7\"][0]),\r\n            \"fc8\": tf.Variable(pretrained_net[\"fc8\"][0])\r\n              }\r\n\r\n    # save biases to dictionary\r\n    biases = { \r\n            \"conv1\": tf.Variable(pretrained_net[\"conv1\"][1]),\r\n            \"conv2\": tf.Variable(pretrained_net[\"conv2\"][1]),\r\n            \"conv3\": tf.Variable(pretrained_net[\"conv3\"][1]),\r\n            \"conv4\": tf.Variable(pretrained_net[\"conv4\"][1]),\r\n            \"conv5\": tf.Variable(pretrained_net[\"conv5\"][1]),\r\n            \"fc6\": tf.Variable(pretrained_net[\"fc6\"][1]),\r\n            \"fc7\": tf.Variable(pretrained_net[\"fc7\"][1]),\r\n            \"fc8\": tf.Variable(pretrained_net[\"fc8\"][1])\r\n              }\r\n\r\n\r\n    def conv(input, kernel, biases, k_h, k_w, c_o, s_h, s_w,  \r\n             padding=\"VALID\", group=1):\r\n        '''\r\n        From https://github.com/ethereon/caffe-tensorflow\r\n        '''\r\n        c_i = input.get_shape()[-1]\r\n        assert c_i%group==0\r\n        assert c_o%group==0\r\n        convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], \r\n                                             padding=padding)\r\n\r\n\r\n        if group==1:\r\n            conv = convolve(input, kernel)\r\n        else:\r\n            input_groups = tf.split(3, group, input)\r\n            kernel_groups = tf.split(3, group, kernel)\r\n            output_groups = [convolve(i, k) for i,k in zip(input_groups, \r\n                                                           kernel_groups)]\r\n            conv = tf.concat(3, output_groups)\r\n        return  tf.reshape(tf.nn.bias_add(conv, biases), \r\n                           [-1]+conv.get_shape().as_list()[1:])\r\n\r\n\r\n    # input\r\n    #####################################################################\r\n    x = tf.placeholder(tf.float32, (None, 227, 227, 3), name=\"input\")\r\n    #####################################################################\r\n\r\n    #conv1\r\n    k_h = 11; k_w = 11; c_o = 96; s_h = 4; s_w = 4\r\n    conv1_in = conv(x, weights[\"conv1\"], biases[\"conv1\"], k_h, k_w, c_o, \r\n                    s_h, s_w, padding=\"SAME\", group=1)\r\n    conv1 = tf.nn.relu(conv1_in)\r\n\r\n    #lrn1\r\n    radius = 2; alpha = 2e-05; beta = 0.75; bias = 1.0\r\n    lrn1 = tf.nn.local_response_normalization(conv1,\r\n                                              depth_radius=radius,\r\n                                              alpha=alpha,\r\n                                              beta=beta,\r\n                                              bias=bias)\r\n\r\n    #maxpool1\r\n    k_h = 3; k_w = 3; s_h = 2; s_w = 2; padding = 'VALID'\r\n    maxpool1 = tf.nn.max_pool(lrn1, ksize=[1, k_h, k_w, 1], \r\n                              strides=[1, s_h, s_w, 1], padding=padding)\r\n\r\n\r\n    #conv2\r\n    k_h = 5; k_w = 5; c_o = 256; s_h = 1; s_w = 1; group = 2\r\n    conv2_in = conv(maxpool1, weights[\"conv2\"], biases[\"conv2\"], k_h, k_w, \r\n                    c_o, s_h, s_w, padding=\"SAME\", group=group)\r\n    conv2 = tf.nn.relu(conv2_in)\r\n\r\n\r\n    #lrn2\r\n    radius = 2; alpha = 2e-05; beta = 0.75; bias = 1.0\r\n    lrn2 = tf.nn.local_response_normalization(conv2,\r\n                                              depth_radius=radius,\r\n                                              alpha=alpha,\r\n                                              beta=beta,\r\n                                              bias=bias)\r\n\r\n    #maxpool2\r\n    k_h = 3; k_w = 3; s_h = 2; s_w = 2; padding = 'VALID'\r\n    maxpool2 = tf.nn.max_pool(lrn2, ksize=[1, k_h, k_w, 1], \r\n                              strides=[1, s_h, s_w, 1], padding=padding)\r\n\r\n    #conv3\r\n    k_h = 3; k_w = 3; c_o = 384; s_h = 1; s_w = 1; group = 1\r\n    conv3_in = conv(maxpool2, weights[\"conv3\"], biases[\"conv3\"], k_h, k_w, \r\n                    c_o, s_h, s_w, padding=\"SAME\", group=group)\r\n    conv3 = tf.nn.relu(conv3_in)\r\n\r\n    #conv4\r\n    k_h = 3; k_w = 3; c_o = 384; s_h = 1; s_w = 1; group = 2\r\n    conv4_in = conv(conv3, weights[\"conv4\"], biases[\"conv4\"], k_h, k_w, \r\n                    c_o, s_h, s_w, padding=\"SAME\", group=group)\r\n    conv4 = tf.nn.relu(conv4_in)\r\n\r\n\r\n    #conv5\r\n    k_h = 3; k_w = 3; c_o = 256; s_h = 1; s_w = 1; group = 2\r\n    conv5_in = conv(conv4, weights[\"conv5\"], biases[\"conv5\"], k_h, k_w, \r\n                    c_o, s_h, s_w, padding=\"SAME\", group=group)\r\n    conv5 = tf.nn.relu(conv5_in)\r\n\r\n    #maxpool5\r\n    k_h = 3; k_w = 3; s_h = 2; s_w = 2; padding = 'VALID'\r\n    maxpool5 = tf.nn.max_pool(conv5, ksize=[1, k_h, k_w, 1], \r\n                              strides=[1, s_h, s_w, 1], padding=padding)\r\n\r\n    #fc6\r\n    reshape = tf.reshape(maxpool5,\r\n                         [-1, int(np.prod(maxpool5.get_shape()[1:]))]) \r\n    fc6 = tf.nn.relu(tf.matmul(reshape,  weights[\"fc6\"]) + biases[\"fc6\"])\r\n\r\n    #fc7\r\n    fc7 = tf.nn.relu(tf.matmul(fc6, weights[\"fc7\"]) + biases[\"fc7\"])\r\n\r\n    #fc8\r\n    fc8 = tf.nn.xw_plus_b(fc7, weights[\"fc8\"], biases[\"fc8\"])\r\n\r\n    # output\r\n    #####################################################################\r\n    prob = tf.nn.softmax(fc8, name = \"output\")\r\n    #####################################################################\r\n        \r\n    sess = session.Session()\r\n    \r\n    init = variables.global_variables_initializer()\r\n    sess.run(init)\r\n    \r\n#     output = sess.run(prob)\r\n    \r\n#     self.assertNear(2.0, output, 0.00001)\r\n    \r\n    saver = saver_lib.Saver()\r\n    checkpoint_path = saver.save(\r\n      sess,\r\n      checkpoint_prefix,\r\n      global_step = 0,\r\n      latest_filename = checkpoint_state_name)\r\n    \r\n    graph_io.write_graph(sess.graph, \"01\", input_graph_name)\r\n    \r\n```\r\n\r\nset further paths for freezing the graph\r\n```\r\ninput_graph_path     = input_graph_name\r\ninput_saver_def_path = \"01\"\r\ninput_binary         = False\r\noutput_node_names    = \"output\"\r\nrestore_op_name      = \"save/restore_all\"\r\nfilename_tensor_name = \"save/Const:0\"\r\noutput_graph_path    = output_graph_name\r\nclear_devices        = False\r\ninitializer_nodes    = \"input\"\r\n```\r\n\r\nfreeze the graph\r\n```\r\nfreeze_graph.freeze_graph(input_graph_path, input_saver_def_path,\r\n                          input_binary, checkpoint_path, output_node_names,\r\n                          restore_op_name, filename_tensor_name,\r\n                          output_graph_path, clear_devices, initializer_nodes)\r\n```\r\n\r\nwhen I run the code I get an **FailedPreconditionError: 01** error in the last function freeze_graph.freeze_graph():\r\n```\r\nFailedPreconditionError                   Traceback (most recent call last)\r\n<ipython-input-6-5251505a5d45> in <module>()\r\n      2                           input_binary, checkpoint_path, output_node_names,\r\n      3                           restore_op_name, filename_tensor_name,\r\n----> 4                           output_graph_path, clear_devices, initializer_nodes)\r\n\r\n/net/hciserver03/storage/oblum/bibs/venv_new/local/lib/python2.7/site-packages/tensorflow/python/tools/freeze_graph.pyc in freeze_graph(input_graph, input_saver, input_binary, input_checkpoint, output_node_names, restore_op_name, filename_tensor_name, output_graph, clear_devices, initializer_nodes)\r\n    111           saver_def.ParseFromString(f.read())\r\n    112         else:\r\n--> 113           text_format.Merge(f.read(), saver_def)\r\n    114         saver = tf.train.Saver(saver_def=saver_def)\r\n    115         saver.restore(sess, input_checkpoint)\r\n\r\n/net/hciserver03/storage/oblum/bibs/venv_new/local/lib/python2.7/site-packages/tensorflow/python/lib/io/file_io.pyc in read(self, n)\r\n    110       else:\r\n    111         length = n\r\n--> 112       return pywrap_tensorflow.ReadFromStream(self._read_buf, length, status)\r\n    113 \r\n    114   def seek(self, position):\r\n\r\n/usr/lib/python2.7/contextlib.pyc in __exit__(self, type, value, traceback)\r\n     22         if type is None:\r\n     23             try:\r\n---> 24                 self.gen.next()\r\n     25             except StopIteration:\r\n     26                 return\r\n\r\n/net/hciserver03/storage/oblum/bibs/venv_new/local/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.pyc in raise_exception_on_not_ok_status()\r\n    467           None, None,\r\n    468           compat.as_text(pywrap_tensorflow.TF_Message(status)),\r\n--> 469           pywrap_tensorflow.TF_GetCode(status))\r\n    470   finally:\r\n    471     pywrap_tensorflow.TF_DeleteStatus(status)\r\n\r\nFailedPreconditionError: 01\r\n```\r\n\r\ndoes anyone has suggestions how to resolve this?", "comments": ["Please don't use `load_source` to pull a file from deep inside TensorFlow.  We only support using TensorFlow through the toplevel `tensorflow` Python module.  If you need help writing out a graph in a standard way, please ask on StackOverflow."]}, {"number": 7383, "title": "use cuda7.5 on windows", "body": "I installed tensorflow-gpu with pip on windows. But it does not work with cuda7.5. And there is no way to update cuda due to driver limit. Is there any way to use cuda7.5 on windows with tensorflow-gpu? Or is there any tutorial about how to compile tensorflow with cuda7.5 on windows?  Thanks.", "comments": ["Please ask questions like this on StackOverflow.  Github issues are for feature requests and bug reports."]}, {"number": 7382, "title": "[TensorBoard] load data from relative path", "body": "To embed tensorBoard the data needs to be loaded from a relative directory, not /data.", "comments": ["We would need more details to know what kind of issue you are having.", "we embed TensorBoard in our platform and mount the wsgi app under a certain path, eg. /extension/tb/12345/. So TB should get its data from /extension/tb/12345/data instead of /data", "I'm pretty sure we still need more details, but @dandelionmane may have a clearer idea.", "I believe removing the leading slash [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/components/tf_backend/router.ts#L39) would fix it?\r\n\r\n\r\nDo you want to submit a pull request?\r\n\r\nn.b. currently Bazel doesn't compile TensorBoard. We're actively fixing this right now. But until the next release, you will need to [recompile the TensorBoard frontend yourself](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/DEVELOPMENT.md) to test the fix. ", "Hi!\r\n\r\nYes, thats it! I removed the slash from the compiled js code and it works. Preparing a PR. Thanks!", "okay, will not prepare an PR since i would have to undergo all the CLA for just one character.", "Haha, I can do it on my end :)", "@dandelionmane \r\nAnother place that still has the similar problem is the request of project plugin data in Embeddings panel,\r\ne.g.  /data/plugin/projector/runs still requests in a absolute path.\r\nI found the code  [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/components/tf_tensorboard/tf-tensorboard.html#L134)\r\nThere is a leading slash for the `route-prefix` property in `vz-projector-dashboard`.\r\nIf it's correct, I will submit a PR. Thanks!\r\n\r\nAnother question is when will the tensorboard be recompiled. As now in version 1.0 these features are not included."]}, {"number": 7381, "title": "Tensorflow gemmlowp preformance", "body": "I ran the tensorflow android demo on android with the google inception model. I used the quantized model transformed from tools/quantize_graph but  was sad to found that the gemmlowp works worse than float Eigen convolution on Android. Any suggestions to this , thanks a lot.", "comments": ["Please ask questions like on StackOverflow; Github issues are for feature requests and bug reports.  If you want to report a performance issue, we would need a lot more information."]}, {"number": 7380, "title": "[Discussion] Limit the exported symbols from _pywrap_tensorflow.so", "body": "TensorFlow statically links many fundamental libraries and exported all their symbols, this can cause version conflict for other modules outside of TensorFlow which links against a different version library, see [the symbol lookup rules](http://stackoverflow.com/questions/12666248/elf-dynamic-loader-symbol-lookup-ordering).\r\n\r\nFor example, I have a script which involves TensorFlow and matplotlib. Just start a Python CLI and execute:\r\n```\r\nimport tensorflow af tf\r\nimport matplotlib.pyplot as plt\r\n# ...\r\nplt.show()\r\n```\r\nThe matplotlib may links to libpng symbols from _pywrap_tensorflow.so instead of libpng even though the only installed libpng is the correct one. And it will complains and fails:\r\n```\r\nlibpng warning: Application was compiled with png.h from libpng-1.6.21\r\nlibpng warning: Application  is  running with png.c from libpng-1.2.53\r\nlibpng error: Incompatible libpng version in application and library\r\n```\r\nSimilar to #1927 and #1924\r\n\r\nFortunately, we have a clear interface, the SWIG APIs. So we may consider only exporting these symbols, [here is the guide](https://www.gnu.org/software/gnulib/manual/html_node/Exported-Symbols-of-Shared-Libraries.html).\r\n\r\nThis also applies to other shared libraries like libtensorflow.so which export C/C++ interfaces.", "comments": ["@martinwicke Care to comment?  I'm not sure if Bazel supports this, and we'd have to maintain it.", "I wonder if that may be to blame for crashes we've seen with some tensorflow import orders.\r\nFor instance we found that to avoid crash we need to import opencv before TensorFlow, also to import [go-vncdriver](https://github.com/openai/go-vncdriver) before TensorFlow", "It seems there's already some limiting going on, @keveman added `exported_symbols_list` to `extra_linkopts ` in https://github.com/tensorflow/tensorflow/commit/5405394ecbc92baf9c45e612185ab42b1dcd0a30 to fix a crash in https://github.com/tensorflow/tensorflow/issues/1992 , so perhaps it's just a matter of adding those `extra_linkopts` to whichever target builds `libtensorflow.so`?", "I would love it if we limited what is exported from that library. Where\ndoes this `.lds` file come from? @keveman can probably help more than I do.\n", "@yaroslavvb is correct, `_pywrap_tensorflow.so` only exports symbols that have `tensorflow` in them. It is indeed strange that the `png*` symbols are leaked from`_pywrap_tensorflow.so`  even with the [linker script](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tf_version_script.lds) only allowing `tensorflow` symbols. @llhe, do you have any ideas why this may be?", "@keveman I found the root cause. We build tensorflow by ourself, and made some changes on the bazel build script and misused the [bazel select feature](https://bazel.build/versions/master/docs/be/functions.html#select), which disabled the version-script settings. So this should also explain the mysterious segfaults when using HDFS in our build reported in #5399. ", "@yaroslavvb I checked the official _pywrap_tensorflow.so, it exports expected symbols, so it should not be the cause. Also checked CUDA  library\r\n```\r\nfind /usr/local/cuda/lib64/ -name *cu*.so -exec nm -D {} \\; | grep \" T \"\r\n```\r\nGenerally, only symbols prefixed cu are exported except some fftw symbols which should also be expected I guess (and also the official opencv is not linked with fftw?):\r\n```\r\n0000000000008610 T fftw_cleanup\r\n0000000000008590 T fftw_cost\r\n0000000000008ef0 T fftw_destroy_plan\r\n0000000000009260 T fftw_execute\r\n0000000000009250 T fftw_execute_dft\r\n0000000000009230 T fftw_execute_dft_c2r\r\n0000000000009240 T fftw_execute_dft_r2c\r\n0000000000008d60 T fftw_export_wisdom_to_file\r\n0000000000008620 T fftwf_cleanup\r\n00000000000085a0 T fftwf_cost\r\n0000000000008f80 T fftwf_destroy_plan\r\n0000000000009210 T fftwf_execute\r\n0000000000009200 T fftwf_execute_dft\r\n00000000000091e0 T fftwf_execute_dft_c2r\r\n00000000000091f0 T fftwf_execute_dft_r2c\r\n0000000000008ee0 T fftwf_export_wisdom_to_file\r\n00000000000085e0 T fftwf_flops\r\n0000000000008630 T fftwf_free\r\n000000000000c7a0 T fftwf_import_wisdom_from_file\r\n00000000000085b0 T fftw_flops\r\n0000000000008650 T fftwf_malloc\r\n000000000000bd50 T fftwf_plan_dft\r\n000000000000c490 T fftwf_plan_dft_1d\r\n000000000000c230 T fftwf_plan_dft_2d\r\n000000000000bfb0 T fftwf_plan_dft_3d\r\n000000000000bcf0 T fftwf_plan_dft_c2r\r\n000000000000c450 T fftwf_plan_dft_c2r_1d\r\n000000000000c1d0 T fftwf_plan_dft_c2r_2d\r\n000000000000bf50 T fftwf_plan_dft_c2r_3d\r\n000000000000bd20 T fftwf_plan_dft_r2c\r\n000000000000c470 T fftwf_plan_dft_r2c_1d\r\n000000000000c200 T fftwf_plan_dft_r2c_2d\r\n000000000000bf80 T fftwf_plan_dft_r2c_3d\r\n000000000000a350 T fftwf_plan_guru_dft\r\n0000000000009fd0 T fftwf_plan_guru_dft_c2r\r\n000000000000a190 T fftwf_plan_guru_dft_r2c\r\n000000000000b5e0 T fftwf_plan_many_dft\r\n000000000000b500 T fftwf_plan_many_dft_c2r\r\n000000000000b570 T fftwf_plan_many_dft_r2c\r\n0000000000008d50 T fftwf_print_plan\r\n0000000000008640 T fftw_free\r\n0000000000008580 T fftwf_set_timelimit\r\n000000000000c5d0 T fftw_import_wisdom_from_file\r\n0000000000008660 T fftw_malloc\r\n000000000000be80 T fftw_plan_dft\r\n000000000000c5b0 T fftw_plan_dft_1d\r\n000000000000c370 T fftw_plan_dft_2d\r\n000000000000c0f0 T fftw_plan_dft_3d\r\n000000000000be20 T fftw_plan_dft_c2r\r\n000000000000c570 T fftw_plan_dft_c2r_1d\r\n000000000000c310 T fftw_plan_dft_c2r_2d\r\n000000000000c090 T fftw_plan_dft_c2r_3d\r\n000000000000be50 T fftw_plan_dft_r2c\r\n000000000000c590 T fftw_plan_dft_r2c_1d\r\n000000000000c340 T fftw_plan_dft_r2c_2d\r\n000000000000c0c0 T fftw_plan_dft_r2c_3d\r\n000000000000a8c0 T fftw_plan_guru_dft\r\n000000000000a520 T fftw_plan_guru_dft_c2r\r\n000000000000a6f0 T fftw_plan_guru_dft_r2c\r\n000000000000b730 T fftw_plan_many_dft\r\n000000000000b650 T fftw_plan_many_dft_c2r\r\n000000000000b6c0 T fftw_plan_many_dft_r2c\r\n0000000000008c20 T fftw_print_plan\r\n0000000000008570 T fftw_set_timelimit\r\n```\r\n`nm` is nice tool to verify the shared libraries symbols.", "LG_DEBUG may also be useful for debug.", "Nice investigation! Bazel's select brings back some memories....we spent time debugging why we couldn't package our custom GPU ops as a Bazel project that depends on TensorFlow as a submodule....turned it out that Bazel's select is [not sensitive](http://stackoverflow.com/questions/41153199/building-a-tensorflow-based-android-app-with-tensorflow-as-a-repository) to workspace it's defined in, and custom_op/cuda had a bunch of those.", "Feel free to close this issue unless there's something that's not addressed", "Asking for some comments: TF is now hiding all protobuf symbols, this makes it annoying when I want to write a custom op which uses protobuf symbols. It seems like I have to find the version of protobuf that tensorflow is linked to, and link to it when compiling the op. (some discussions: https://github.com/ppwwyyxx/tensorpack/issues/221#issuecomment-292654997)\r\nCan we export protobuf symbols as well?", "@ppwwyyxx \r\n\r\n```diff\r\n--- a/tensorflow/tf_version_script.lds\t2017-04-07 22:37:11.949060397 +0000\r\n+++ b/tensorflow/tf_version_script.lds\t2017-04-07 22:36:25.300982684 +0000\r\n@@ -2,6 +2,9 @@\r\n   global:\r\n     *tensorflow*;\r\n     *perftools*gputools*;\r\n+    extern \"C++\" {\r\n+      google::protobuf::MessageLite::*;\r\n+    };\r\n   local:\r\n     *;\r\n };\r\n```\r\n\r\n```\r\n% bazel build --config=opt /* I need a graphics card... \ud83d\ude2d\ud83d\ude2d\ud83d\ude2d \u545c\u545c\u545c --config=cuda */ //tensorflow/tools/pip_package:build_pip_package\r\n% nm -CD bazel-out/local-py3-opt/bin/tensorflow/python/_pywrap_tensorflow_internal.so | grep ParseFromArray\r\n0000000002879f60 T google::protobuf::MessageLite::ParseFromArray(void const*, int)\r\n```\r\n\r\n"]}, {"number": 7379, "title": "Compile error: use of deleted function", "body": "### Environment info\r\nOperating System: Rocks OS (CentOS 6.5)\r\n\r\nInstalled version of CUDA and cuDNN:  CUDA 8.0 and cuDNN 5.1\r\n\r\n1. The commit hash (`git rev-parse HEAD`)\uff1av1.0.0-rc2 1536a84f32f1fe77efd3fee6e5933a1dfe4e10bb\r\n2. The output of `bazel version`\uff1a\r\nBuild label: 0.4.4- (@non-git)\r\nBuild target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Wed Feb 8 08:15:45 2017 (1486541745)\r\nBuild timestamp: 1486541745\r\nBuild timestamp as int: 1486541745\r\n\r\n### Logs or other output that would be helpful\r\n![image](https://cloud.githubusercontent.com/assets/1501158/22772919/544cc3ee-eeda-11e6-9130-88c52db9206a.png)\r\n\r\nI can successfully compile v0.12.1. However, i don't know how to solve this problem after switching to v1.0.0-rc2. This problem appear on master, v1.0.0-rc1,v1.0.0-rc2 branches. And all of these branches can be built on another Ubuntu 16.04 server.\r\n\r\nSomeone please help me.", "comments": ["After update gcc from 4.9 to 5.3, i can compile tensorflow on CentOS 6.5. Close this issue."]}, {"number": 7378, "title": "Seg fault when using tf session with opencv 3", "body": "Hi, \r\n\r\nWe noticed that when we try to use tensorflow with opencv 3, it consistently seg faults and crashes. The commands are:\r\n\r\n```\r\nimport cv2\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nwith tf.Session() as sess:\r\n    img = cv2.imread('messi5.jpg', 0)\r\n    rows, cols = img.shape\r\n    M = np.float32([[1, 0, 100], [0, 1, 50]])\r\n    dst = cv2.warpAffine(img, M, (cols, rows))\r\n    cv2.imshow('img', dst)\r\n    cv2.waitKey(0)\r\n    cv2.destroyAllWindows()\r\n```\r\n\r\nAssuming you have a messi5.jpg in the folder (https://raw.githubusercontent.com/abidrahmank/OpenCV2-Python-Tutorials/master/data/messi5.jpg)\r\n\r\nWe see this issue when we use tensorflow 0.12 GPU enabled, opencv 3.2.0 and python 2.7.6, CUDA 8.0 and CuDNN 5.1.5 . We did not observe this issue with opencv version 2.4.13 or 2.4.9.\r\n\r\nWe will also filed a bug report on opencv (https://github.com/opencv/opencv/issues/8155)\r\n\r\n", "comments": ["@mkabra Can you check if importing TensorFlow first solves the problem (as mentioned by @yaroslavvb)?  This is not a great fix, but it might help with localization.", "Also you can try `export CUDA_VISIBLE_DEVICES=` to see if GPU is the factor. I've met bug reports failing to use opencv with TF because they used unofficial builds of opencv with cuda enabled.", "That can happen with official OpenCV version too. I've hit similar crash, and looking at gdb backtrace it was in some OpenCV function checking if OpenCL was enabled. My guess is that TensorFlow GPU binary unintentionally includes some OpenCL symbols which confuses opencv\r\n \r\nThe solution was to set the following before running your script\r\n\r\n`export OPENCV_OPENCL_RUNTIME=`", "Importing tensorflow first didn't help. But (de-)setting CUDA_VISIBLE_DEVICES or OPENCV_OPENCL_RUNTIME individually worked. If this is an accepted solution, then feel free to close the bug.\r\n\r\nThanks!\r\n\r\nAnd here is the stack trace if that helps:\r\n\r\nCore was generated by `python test_warpaffine.py'.\r\nProgram terminated with signal SIGSEGV, Segmentation fault.\r\n#0 __GI___pthread_mutex_lock (mutex=0x0) at ../nptl/pthread_mutex_lock.c:66\r\n66 ../nptl/pthread_mutex_lock.c: No such file or directory.\r\n#0 __GI___pthread_mutex_lock (mutex=0x0) at ../nptl/pthread_mutex_lock.c:66\r\n#1 0x00007fd68579e008 in ?? ()\r\nfrom /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.1\r\n#2 0x00007fd685852671 in ?? ()\r\nfrom /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.1\r\n#3 0x00007fd6858527e5 in ?? ()\r\nfrom /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.1\r\n#4 0x00007fd6857a3cb4 in ?? ()\r\nfrom /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.1\r\n#5 0x00007fd6857a54e7 in ?? ()\r\nfrom /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.1\r\n#6 0x00007fd685778c66 in ?? ()\r\nfrom /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.1\r\n#7 0x00007fd685677f3d in ?? ()\r\nfrom /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.1\r\n#8 0x00007fd685677ed8 in ?? ()\r\nfrom /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.1\r\n---Type to continue, or q to quit---\r\n#9 0x00007fd69c1fa022 in ?? () from /usr/local/cuda/lib64/libOpenCL.so\r\n#10 0x00007fd69c1fbd42 in ?? () from /usr/local/cuda/lib64/libOpenCL.so\r\n#11 0x00007fd69c1fb4d0 in clGetPlatformIDs ()\r\nfrom /usr/local/cuda/lib64/libOpenCL.so\r\n#12 0x00007fd7139e4635 in (anonymous namespace)::opencl_fn3<58, int, unsigned int, _cl_platform_id**, unsigned int*>::switch_fn(unsigned int, _cl_platform_id**, unsigned int*) ()\r\nfrom /localhome/kwaki/theano-env/extras/opencv-3.1.0/build/lib/libopencv_core.so.3.1\r\n#13 0x00007fd71393ebf3 in cv::ocl::haveOpenCL() ()\r\nfrom /localhome/kwaki/theano-env/extras/opencv-3.1.0/build/lib/libopencv_core.so.3.1\r\n#14 0x00007fd71394ace5 in cv::ocl::useOpenCL() ()\r\nfrom /localhome/kwaki/theano-env/extras/opencv-3.1.0/build/lib/libopencv_core.so.3.1\r\n#15 0x00007fd711c8273a in cv::warpAffine(cv::_InputArray const&, cv::OutputArray const&, cv::InputArray const&, cv::Size, int, int, cv::Scalar const&) ()\r\nfrom /localhome/kwaki/theano-env/extras/opencv-3.1.0/build/lib/libopencv_imgproc.so.3.1\r\n---Type to continue, or q to quit---\r\n#16 0x00007fd714a7bd03 in pyopencv_cv_warpAffine(_object*, _object*, _object*) () from /localhome/kwaki/theano-env/local/lib/python2.7/site-packages/cv2.so\r\n#17 0x000000000049968d in PyEval_EvalFrameEx ()\r\n#18 0x00000000004a1634 in ?? ()\r\n#19 0x000000000044e4a5 in PyRun_FileExFlags ()\r\n#20 0x000000000044ec9f in PyRun_SimpleFileExFlags ()\r\n#21 0x000000000044f904 in Py_Main ()\r\n#22 0x00007fd715963f45 in __libc_start_main (main=0x44f9c2\r\n, argc=2,\r\nargv=0x7ffd98ead878, init=, fini=,\r\nrtld_fini=, stack_end=0x7ffd98ead868) at libc-start.c:287\r\n#23 0x0000000000578c4e in _start ()\r\n", "I believe that this will be difficult to reliably fix to never happen, but we should definitely include this in our documentation somewhere.", "To be precise, the issue to document is that Python client can't use both \"tensorflow-gpu\" and \"someotherlibrary\" where someotherlibrary uses OpenCL.\r\n\r\nMy guess at what's happening is that when you enable GPU, something in tensorflow loads `libnvidia-opencl.so.1`, and when you use `opencv`, it resolves its OpenCL symbols to `libnvidia-opencl.so.1` instead of using correct version of .so (the one it was compiled for). The fundamental fix would need tracking down why OpenCL-related stuff is being touched by tensorflow that's not configured to use OpenCL", "I am also experiencing this issue on a daily basis, very annoying! It seems to be stochastic, which makes it very hard to pinpoint the cause. But I am also running OpenCV 3.2 and TF v1.0, so I guess there is the problem.", "@tomrunia  the solution above with `OPENCV_OPENCL_RUNTIME=''` doesn't work? New OpenCV has GPU routines and TensorFlow doesn't like to share the GPU. ", "I have the same issue seg fault in in tensorflow cv3 is imported (python) got around this by using pygame and sci-image..", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "where do we put export OPENCV_OPENCL_RUNTIME= ?\r\nDo we put that in the bashrc file?", "It looks as if the solution suggests\r\n\r\nexport OPENCV_OPENCL_RUNTIME=\r\n\r\nin your shell, e.g. bash on linux.", "Just compile --config=monolithic :libtensorflow_cc and then it'll work at least in C++. There appears to be something with tensorflow_framework library that is interfering with opencv", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It is, because now boost does not work for me in the same programs where I'm using tensorflow because I had to set ABI=0 during compilation, but boost expects ABI=1", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 67 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!", "I have the same error. I have built the binaries for both libraries in C++. None of the proposed solutions in this thread have worked to me. I installed latest versions of each library.", "I have the same issue and setting `export OPENCV_OPENCL_RUNTIME=` didn't work"]}, {"number": 7377, "title": "Merge release branch back into master.", "body": "In merge conflicts, I picked master branch's version for most. PTAL", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "This also fixes #7364 ", "will also trigger xla tests to make sure.", "http://ci.tensorflow.org/job/tensorflow-pull-requests-xla/4/", "Oops, did you forget to push your fixes?  I don't see them, and the XLA tests failed with the duplicated code block.\r\n\r\nhttp://ci.tensorflow.org/job/tensorflow-pull-requests-xla/4/", "sigh, yes :)\r\nTerminal was stuck with login stuff.\r\nNow restarting all tests :(", "http://ci.tensorflow.org/job/tensorflow-pull-requests-xla/5/", "one test timed out, looks unrelated.\r\nMerging."]}, {"number": 7376, "title": "Distributed mnist training in synchronous mode raises a ValueError in worker node", "body": "I am trying to run distributed mnist training using the file given here: [https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/python/mnist_replica.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/python/mnist_replica.py)\r\n\r\nThe async mode doesn't have any issues but I cannot get the sync mode to work. As soon as I start a worker in the sync mode I get a ValueError exception.\r\n\r\nThe command used to start the worker is:\r\n```\r\npython mnist_replica.py --ps_hosts=localhost:2222 --worker_hosts=localhost:2223 --task_index=0 --job_name=worker --sync_replicas=True\r\n```\r\n\r\nFor python2 the Traceback looks something like this:\r\n```\r\nTraceback (most recent call last):\r\n  File \"mnist_replica.py\", line 279, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 43, in run\r\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\r\n  File \"mnist_replica.py\", line 184, in main\r\n    train_step = opt.minimize(cross_entropy, global_step=global_step)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 279, in minimize\r\n    name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/sync_replicas_optimizer.py\", line 751, in apply_gradients\r\n    array_ops.reshape(self._replica_id, (1,)),\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 2448, in reshape\r\n    name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 503, in apply_op\r\n    as_ref=input_arg.is_ref).dtype.name\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 669, in convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 176, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/constant_op.py\", line 165, in constant\r\n    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_util.py\", line 360, in make_tensor_proto\r\n    raise ValueError(\"None values not supported.\")\r\nValueError: None values not supported.\r\n```\r\n\r\nFor python3 it looks something like this:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 490, in apply_op\r\n    preferred_dtype=default_dtype)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 669, in convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/constant_op.py\", line 176, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/constant_op.py\", line 165, in constant\r\n    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py\", line 360, in make_tensor_proto\r\n    raise ValueError(\"None values not supported.\")\r\nValueError: None values not supported.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"mnist_replica.py\", line 279, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py\", line 43, in run\r\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\r\n  File \"mnist_replica.py\", line 184, in main\r\n    train_step = opt.minimize(cross_entropy, global_step=global_step)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/optimizer.py\", line 279, in minimize\r\n    name=name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/sync_replicas_optimizer.py\", line 751, in apply_gradients\r\n    array_ops.reshape(self._replica_id, (1,)),\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 2448, in reshape\r\n    name=name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 503, in apply_op\r\n    as_ref=input_arg.is_ref).dtype.name\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 669, in convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/constant_op.py\", line 176, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/constant_op.py\", line 165, in constant\r\n    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py\", line 360, in make_tensor_proto\r\n    raise ValueError(\"None values not supported.\")\r\nValueError: None values not supported.\r\n```\r\n\r\nI have tried running the example on Python2 and Python3 on Ubuntu 14.04 and Ubuntu 16.04 in cpu only mode. In all the 4 cases the version of tensorflow used was 0.12.0.\r\n\r\nThis issue is very similar to the one here: [https://github.com/tensorflow/tensorflow/issues/6687](https://github.com/tensorflow/tensorflow/issues/6687) except that I'm using v0.12.0 and running in CPU only mode. That issue mentions that the example was running in 0.12.0 but that is not the case for me.\r\n", "comments": ["Can you insert a print statement to print `self._replica_id` before using it in `training/sync_replicas_optimizer.py:751`? I suspect that value is None, in which case @jmchen-g may  know why that would happen", "This is a known issue that mnist example with sync_rep is not working as expected. We need to troubleshoot this... @caisq ", "> Can you insert a print statement to print self._replica_id before using it in training/sync_replicas_optimizer.py:751? I suspect that value is None, in which case @jmchen-g may know why that would happen\r\n\r\n@yaroslavvb : You are right, it is None.", "The _replica_id should no longer be in the file though... It is a variable used in the old optimizer...", "This issue no longer exists in version 1 of tensorflow.", "I guess you shall close this issue if it doesn't exist in version 1.0?"]}, {"number": 7375, "title": "tensorboard show empty page (master)", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\n[#5341](https://github.com/tensorflow/tensorflow/issues/5341)\r\n\r\n\r\n### Environment info\r\nUbuntu 14.04 LTS. \r\ngit clone https://github.com/tensorflow/tensorflow\r\n./configure\r\nbazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\nbazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\r\npip install /tmp/tensorflow_pkg/tensorflow-1.0.0rc1-cp35-cp35m-linux_x86_64.whl \r\n\r\nThe output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n1.0.0-rc1\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\nbd4a1c58d28734c77ecb17d719e72c45c6c33077\r\n2. The output of `bazel version`\r\nBuild label: 0.4.4\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\nI use a tensorboard example that I think is quite easy to reproduce the issue. \r\n```shell\r\ngit clone https://github.com/normanheckscher/mnist-tensorboard-embeddings\r\ncd mnist-tensorboard-embeddings/\r\n\r\n# modify the path at line 97 and 99 in mnist_t-sne.py\r\npython mnist_t-sne.py\r\n# start tensorboard\r\ntensorboard --logdir=/home/chih-yao/Documents/mnist-tensorboard-embeddings/logs/\r\n```\r\n### What other attempted solutions have you tried?\r\n- [x] Make sure my `tensorboard --logdir=/home/chih-yao/Documents/mnist-tensorboard-embeddings/logs/` path is correct\r\n- [x] Reinstall tensorflow from source\r\n- [x] Make sure the metadata and event files exist in the `logdir`\r\n\r\n### Logs or other output that would be helpful\r\n```\r\ntensorboard --logdir=/home/chih-yao/Documents/mnist-tensorboard-embeddings-master/logs\r\nStarting TensorBoard b'46' on port 6006\r\n(You can navigate to http://127.0.1.1:6006)\r\n * Running on http://0.0.0.0:6006/ (Press CTRL+C to quit)\r\n127.0.0.1 - - [08/Feb/2017 21:06:07] \"GET /webcomponentsjs/webcomponents-lite.min.js HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /lib/css/global.css HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /plottable/plottable.css HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /dist/bazel-html-imports.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /dist/tf-tensorboard.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /polymer/polymer.html HTTP/1.1\" 404 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /numericjs_numeric_min_js/file/numeric.min.js HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-icons/iron-icons.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-tabs/paper-tabs.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-checkbox/paper-checkbox.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-toolbar/paper-toolbar.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-dialog/paper-dialog.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-button/paper-button.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-icon-button/paper-icon-button.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-header-panel/paper-header-panel.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-icon/iron-icon.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-iconset-svg/iron-iconset-svg.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /three_js_three_min_js/file/three.min.js HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-resizable-behavior/iron-resizable-behavior.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-flex-layout/iron-flex-layout.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-menu-behavior/iron-menubar-behavior.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-tabs/paper-tabs-icons.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-styles/color.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-styles/default-theme.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-tabs/paper-tab.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-behaviors/paper-checked-element-behavior.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-styles/typography.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /neon-animation/neon-animation-runner-behavior.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-dialog-behavior/paper-dialog-behavior.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-dialog-behavior/paper-dialog-shared-styles.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-material/paper-material.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-ripple/paper-ripple.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-behaviors/paper-button-behavior.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-behaviors/paper-inky-focus-behavior.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-meta/iron-meta.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-menu-behavior/iron-menu-behavior.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-behaviors/iron-control-state.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-behaviors/iron-button-state.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /three_js_orbitcontrols_js/file/OrbitControls.js HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-behaviors/paper-ripple-behavior.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /font-roboto/roboto.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /neon-animation/neon-animatable-behavior.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-checked-element-behavior/iron-checked-element-behavior.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-overlay-behavior/iron-overlay-behavior.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-styles/shadow.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-material/paper-material-shared-styles.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-a11y-keys-behavior/iron-a11y-keys-behavior.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-selector/iron-multi-selectable.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /weblas_weblas_js/file/weblas.js HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /neon-animation/animations/opaque-animation.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-validatable-behavior/iron-validatable-behavior.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-form-element-behavior/iron-form-element-behavior.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-fit-behavior/iron-fit-behavior.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-overlay-behavior/iron-overlay-manager.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-overlay-behavior/iron-focusables-helper.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-selector/iron-selectable.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /neon-animation/neon-animation-behavior.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-overlay-behavior/iron-overlay-backdrop.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /neon-animation/web-animations.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-selector/iron-selection.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /web-animations-js/web-animations-next-lite.min.js HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-input/paper-input.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-slider/paper-slider.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /lodash/lodash.min.js HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-input/paper-input-error.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-input/iron-input.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-input/paper-input-char-counter.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-input/paper-input-container.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-input/paper-input-behavior.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-range-behavior/iron-range-behavior.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-progress/paper-progress.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-a11y-announcer/iron-a11y-announcer.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-input/paper-input-addon-behavior.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /d3/d3.js HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-styles/paper-styles.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-flex-layout/classes/iron-flex-layout.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-flex-layout/classes/iron-shadow-flex-layout.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-item/paper-item.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-menu/paper-menu.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-dropdown-menu/paper-dropdown-menu.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-item/paper-item-shared-styles.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-item/paper-item-behavior.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-menu-button/paper-menu-button.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-dropdown-menu/paper-dropdown-menu-icons.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-menu/paper-menu-shared-styles.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-dropdown-menu/paper-dropdown-menu-shared-styles.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /neon-animation/animations/fade-in-animation.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /neon-animation/animations/fade-out-animation.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-dropdown/iron-dropdown.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-menu-button/paper-menu-button-animations.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-dropdown/iron-dropdown-scroll-manager.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-collapse/iron-collapse.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /plottable/plottable.js HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-toggle-button/paper-toggle-button.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /graphlib/dist/graphlib.core.js HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /dagre/dist/dagre.core.js HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-item/all-imports.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-list/iron-list.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-item/paper-item-body.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-item/paper-icon-item.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-scroll-target-behavior/iron-scroll-target-behavior.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-radio-group/paper-radio-group.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-tooltip/paper-tooltip.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-radio-button/paper-radio-button.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-listbox/paper-listbox.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-toast/paper-toast.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-icons/image-icons.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-spinner/paper-spinner-lite.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-dialog-scrollable/paper-dialog-scrollable.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-input/paper-textarea.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-spinner/paper-spinner-behavior.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /paper-spinner/paper-spinner-styles.html HTTP/1.1\" 200 -\r\n127.0.0.1 - - [08/Feb/2017 21:06:08] \"GET /iron-autogrow-textarea/iron-autogrow-textarea.html HTTP/1.1\" 200 -\r\n```", "comments": ["Same here. It is the white page!", "Same here (at commit 088b2d49e9dd0ce752b0019c7e543c249e0a8052) and #7317 might be related. ", "Tensorboard has been broken for several days now. You can revert the past few days of commits to \"solve\" this issue:\r\n\r\ngit reset --hard 8dc43a3\r\n\r\nI suspect this is what broke it:\r\nhttps://github.com/tensorflow/tensorflow/commit/5d56ddbe3d84ff2ccf15c87de95e70840d56b7e7\r\n\r\nMaybe tb still works in Chrome? That could explain why core developers aren't seeing this. I'm in Firefox.", "On it.", "@jart it looks like this was broken by the webfiles build changes.", "Also, contrary to the initial issue description, I think this is broken on master but not in the release candidate. (phew)", "Currently investigating.\r\n\r\n**Unrelated:** I'm noticing there's a lot of stuff in this pip package that has no business being there. We need to fix that.\r\n\r\n![image](https://cloud.githubusercontent.com/assets/49262/22850345/ab3b954e-efbc-11e6-9a42-bbc5e6451e1a.png)\r\n\r\n**Unrelated:** Shouldn't `purelib/external/` directory should probably be named `purelib/tensorflow/_external/` or something, so it's less likely to collide with other stuff.\r\n\r\nCC: @gunan ", "I'm pretty confident #7431 is going to fix this. Would anyone from the community mind patching that tiny change and seeing it TensorBoard works again?", "For slimming down the pip package:\r\n@caisq working to remove some of the external libraries from pip package.\r\n@keveman just removed protobuf from our pip package.", "@jart Pulled your3e1973688  patch and tested it.\r\n\r\nTensorboard works again. Seems snappier too when reloading boards.", "is tensorboard down again? working fine last tonight - today I get the white page, no tabs.", "I am also having this issue, tensorboard 2.1.0", "Same issue, tensorboard 2.1.0, Win 7, Python 3.7, training with torch 1.1\r\nDowngrading to tensorboard 2.0.0 fixes the issue for now", "Same issue with tensorboard 2.1.0, Win 10, Python 3.7, tensorflow: 2.1, keras:2.3.1", "Same issue, Win 10 ver 1909, Python 3.7.6, Tensorboard 2.1.1, TensorFlow-gpu 2.1.0\r\nSome files are created during 'fit'-process, but tensorboard page is empty in Chrome and Opera browsers", "Hi, I have the same problem in Win 10 [Version 10.0.18363.836]. I do get a file in my browser but it just shows an empty page. Looking into the HTML file (see attached) it seems to be damaged. Line 24 - 224 ist somehow missing.  Is this a bug in the tensorboard? \r\n[tensorboard_HTML.txt](https://github.com/tensorflow/tensorflow/files/4632784/tensorboard_HTML.txt)\r\n"]}, {"number": 7374, "title": "Issues with Eigen when building tf_tutorials_example_trainer on Windows 10", "body": "I'm attempting to build Tensorflow C++ on Windows 10 following the instructions of the cmake readme. However, I'm getting issues with compiling at the Eigen step.\r\n\r\n```Compiling the Fortran compiler identification source file \"CMakeFortranCompilerId.F\" failed.\r\nCompiler:  \r\nBuild flags: \r\nId flags: \r\n\r\nThe output was:\r\n1\r\n\r\nMicrosoft Visual Studio 2015 Version 14.0.25420.1.\r\nCopyright (C) Microsoft Corp. All rights reserved.\r\n\r\nThe license for Visual Studio has expired.\r\n\r\nThe evaluation period for this product has ended.\r\n\r\nPerforming C++ SOURCE FILE Test COMPILER_SUPPORT_FASTMATH failed with the following output:\r\nChange Dir: C:/Users/Irene/Documents/tensorflow/tensorflow/contrib/cmake/build/eigen/src/eigen-build/CMakeFiles/CMakeTmp\r\n\r\nRun Build Command:\"C:/Program Files (x86)/MSBuild/14.0/bin/MSBuild.exe\" \"cmTC_70ffc.vcxproj\" \"/p:Configuration=Debug\" \"/p:VisualStudioVersion=14.0\"\r\nMicrosoft (R) Build Engine version 14.0.25420.1\r\n\r\nCopyright (C) Microsoft Corporation. All rights reserved.\r\n\r\n\r\n\r\nBuild started 9/02/2017 3:13:30 PM.\r\n\r\nProject \"C:\\Users\\Irene\\Documents\\tensorflow\\tensorflow\\contrib\\cmake\\build\\eigen\\src\\eigen-build\\CMakeFiles\\CMakeTmp\\cmTC_70ffc.vcxproj\" on node 1 (default targets).\r\n\r\nPrepareForBuild:\r\n\r\n  Creating directory \"cmTC_70ffc.dir\\Debug\\\".\r\n\r\n  Creating directory \"C:\\Users\\Irene\\Documents\\tensorflow\\tensorflow\\contrib\\cmake\\build\\eigen\\src\\eigen-build\\CMakeFiles\\CMakeTmp\\Debug\\\".\r\n\r\n  Creating directory \"cmTC_70ffc.dir\\Debug\\cmTC_70ffc.tlog\\\".\r\n\r\nInitializeBuildStatus:\r\n\r\n  Creating \"cmTC_70ffc.dir\\Debug\\cmTC_70ffc.tlog\\unsuccessfulbuild\" because \"AlwaysCreate\" was specified.\r\n\r\nClCompile:\r\n\r\n  C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\bin\\x86_amd64\\CL.exe /c /Zi /W4 /WX- /Od /Ob0 /D WIN32 /D _WINDOWS /D _CRT_SECURE_NO_WARNINGS /D _SCL_SECURE_NO_WARNINGS /D COMPILER_SUPPORT_FASTMATH /D _DEBUG /D \"CMAKE_INTDIR=\\\"Debug\\\"\" /D _MBCS /Gm- /EHsc /RTC1 /MDd /GS /fp:precise /Zc:wchar_t /Zc:forScope /Zc:inline /GR /Fo\"cmTC_70ffc.dir\\Debug\\\\\" /Fd\"cmTC_70ffc.dir\\Debug\\vc140.pdb\" /Gd /TP /wd4127 /wd4505 /wd4714 /errorReport:queue  -ffast-math \"C:\\Users\\Irene\\Documents\\tensorflow\\tensorflow\\contrib\\cmake\\build\\eigen\\src\\eigen-build\\CMakeFiles\\CMakeTmp\\src.cxx\"\r\n\r\n  Microsoft (R) C/C++ Optimizing Compiler Version 19.00.24215.1 for x64\r\n\r\n  Copyright (C) Microsoft Corporation.  All rights reserved.\r\n\r\n  \r\n\r\n  cl /c /Zi /W4 /WX- /Od /Ob0 /D WIN32 /D _WINDOWS /D _CRT_SECURE_NO_WARNINGS /D _SCL_SECURE_NO_WARNINGS /D COMPILER_SUPPORT_FASTMATH /D _DEBUG /D \"CMAKE_INTDIR=\\\"Debug\\\"\" /D _MBCS /Gm- /EHsc /RTC1 /MDd /GS /fp:precise /Zc:wchar_t /Zc:forScope /Zc:inline /GR /Fo\"cmTC_70ffc.dir\\Debug\\\\\" /Fd\"cmTC_70ffc.dir\\Debug\\vc140.pdb\" /Gd /TP /wd4127 /wd4505 /wd4714 /errorReport:queue  -ffast-math \"C:\\Users\\Irene\\Documents\\tensorflow\\tensorflow\\contrib\\cmake\\build\\eigen\\src\\eigen-build\\CMakeFiles\\CMakeTmp\\src.cxx\"\r\n\r\n  \r\n\r\ncl : Command line warning D9002: ignoring unknown option '-ffast-math' [C:\\Users\\Irene\\Documents\\tensorflow\\tensorflow\\contrib\\cmake\\build\\eigen\\src\\eigen-build\\CMakeFiles\\CMakeTmp\\cmTC_70ffc.vcxproj]\r\n\r\n  src.cxx\r\n\r\nLink:\r\n\r\n  C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\bin\\x86_amd64\\link.exe /ERRORREPORT:QUEUE /OUT:\"C:\\Users\\Irene\\Documents\\tensorflow\\tensorflow\\contrib\\cmake\\build\\eigen\\src\\eigen-build\\CMakeFiles\\CMakeTmp\\Debug\\cmTC_70ffc.exe\" /INCREMENTAL /NOLOGO kernel32.lib user32.lib gdi32.lib winspool.lib shell32.lib ole32.lib oleaut32.lib uuid.lib comdlg32.lib advapi32.lib /MANIFEST /MANIFESTUAC:\"level='asInvoker' uiAccess='false'\" /manifest:embed /DEBUG /PDB:\"C:/Users/8i/Documents/tensorflow/tensorflow/contrib/cmake/build/eigen/src/eigen-build/CMakeFiles/CMakeTmp/Debug/cmTC_70ffc.pdb\" /SUBSYSTEM:CONSOLE /TLBID:1 /DYNAMICBASE /NXCOMPAT /IMPLIB:\"C:/Users/8i/Documents/tensorflow/tensorflow/contrib/cmake/build/eigen/src/eigen-build/CMakeFiles/CMakeTmp/Debug/cmTC_70ffc.lib\" /MACHINE:X64  /machine:x64 cmTC_70ffc.dir\\Debug\\src.obj\r\n\r\n  cmTC_70ffc.vcxproj -> C:\\Users\\Irene\\Documents\\tensorflow\\tensorflow\\contrib\\cmake\\build\\eigen\\src\\eigen-build\\CMakeFiles\\CMakeTmp\\Debug\\cmTC_70ffc.exe\r\n\r\nFinalizeBuildStatus:\r\n\r\n  Deleting file \"cmTC_70ffc.dir\\Debug\\cmTC_70ffc.tlog\\unsuccessfulbuild\".\r\n\r\n  Touching \"cmTC_70ffc.dir\\Debug\\cmTC_70ffc.tlog\\cmTC_70ffc.lastbuildstate\".\r\n\r\nDone Building Project \"C:\\Users\\Irene\\Documents\\tensorflow\\tensorflow\\contrib\\cmake\\build\\eigen\\src\\eigen-build\\CMakeFiles\\CMakeTmp\\cmTC_70ffc.vcxproj\" (default targets).\r\n\r\n\r\n\r\nBuild succeeded.\r\n\r\n\r\n\r\n\"C:\\Users\\Irene\\Documents\\tensorflow\\tensorflow\\contrib\\cmake\\build\\eigen\\src\\eigen-build\\CMakeFiles\\CMakeTmp\\cmTC_70ffc.vcxproj\" (default target) (1) ->\r\n\r\n(ClCompile target) -> \r\n\r\n  cl : Command line warning D9002: ignoring unknown option '-ffast-math' [C:\\Users\\Irene\\Documents\\tensorflow\\tensorflow\\contrib\\cmake\\build\\eigen\\src\\eigen-build\\CMakeFiles\\CMakeTmp\\cmTC_70ffc.vcxproj]\r\n\r\n\r\n\r\n    1 Warning(s)\r\n\r\n    0 Error(s)\r\n\r\n\r\n\r\nTime Elapsed 00:00:00.54\r\n\r\n\r\nSource file was:\r\nint main() { return 0; }\r\nDetermining if the include file pthread.h exists failed with the following output:\r\nChange Dir: C:/Users/Irene/Documents/tensorflow/tensorflow/contrib/cmake/build/eigen/src/eigen-build/CMakeFiles/CMakeTmp\r\n\r\nRun Build Command:\"C:/Program Files (x86)/MSBuild/14.0/bin/MSBuild.exe\" \"cmTC_55681.vcxproj\" \"/p:Configuration=Debug\" \"/p:VisualStudioVersion=14.0\"\r\nMicrosoft (R) Build Engine version 14.0.25420.1\r\n\r\nCopyright (C) Microsoft Corporation. All rights reserved.\r\n\r\n\r\n\r\nBuild started 9/02/2017 3:13:37 PM.\r\n\r\nProject \"C:\\Users\\Irene\\Documents\\tensorflow\\tensorflow\\contrib\\cmake\\build\\eigen\\src\\eigen-build\\CMakeFiles\\CMakeTmp\\cmTC_55681.vcxproj\" on node 1 (default targets).\r\n\r\nPrepareForBuild:\r\n\r\n  Creating directory \"cmTC_55681.dir\\Debug\\\".\r\n\r\n  Creating directory \"C:\\Users\\Irene\\Documents\\tensorflow\\tensorflow\\contrib\\cmake\\build\\eigen\\src\\eigen-build\\CMakeFiles\\CMakeTmp\\Debug\\\".\r\n\r\n  Creating directory \"cmTC_55681.dir\\Debug\\cmTC_55681.tlog\\\".\r\n\r\nInitializeBuildStatus:\r\n\r\n  Creating \"cmTC_55681.dir\\Debug\\cmTC_55681.tlog\\unsuccessfulbuild\" because \"AlwaysCreate\" was specified.\r\n\r\nClCompile:\r\n\r\n  C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\bin\\x86_amd64\\CL.exe /c /Zi /W3 /WX- /Od /Ob0 /D WIN32 /D _WINDOWS /D _DEBUG /D \"CMAKE_INTDIR=\\\"Debug\\\"\" /D _MBCS /Gm- /RTC1 /MDd /GS /fp:precise /Zc:wchar_t /Zc:forScope /Zc:inline /Fo\"cmTC_55681.dir\\Debug\\\\\" /Fd\"cmTC_55681.dir\\Debug\\vc140.pdb\" /Gd /TC /errorReport:queue \"C:\\Users\\Irene\\Documents\\tensorflow\\tensorflow\\contrib\\cmake\\build\\eigen\\src\\eigen-build\\CMakeFiles\\CMakeTmp\\CheckIncludeFile.c\"\r\n\r\n  Microsoft (R) C/C++ Optimizing Compiler Version 19.00.24215.1 for x64\r\n\r\n  Copyright (C) Microsoft Corporation.  All rights reserved.\r\n\r\n  \r\n\r\n  cl /c /Zi /W3 /WX- /Od /Ob0 /D WIN32 /D _WINDOWS /D _DEBUG /D \"CMAKE_INTDIR=\\\"Debug\\\"\" /D _MBCS /Gm- /RTC1 /MDd /GS /fp:precise /Zc:wchar_t /Zc:forScope /Zc:inline /Fo\"cmTC_55681.dir\\Debug\\\\\" /Fd\"cmTC_55681.dir\\Debug\\vc140.pdb\" /Gd /TC /errorReport:queue \"C:\\Users\\Irene\\Documents\\tensorflow\\tensorflow\\contrib\\cmake\\build\\eigen\\src\\eigen-build\\CMakeFiles\\CMakeTmp\\CheckIncludeFile.c\"\r\n\r\n  \r\n\r\n  CheckIncludeFile.c\r\n\r\nC:\\Users\\Irene\\Documents\\tensorflow\\tensorflow\\contrib\\cmake\\build\\eigen\\src\\eigen-build\\CMakeFiles\\CMakeTmp\\CheckIncludeFile.c(1): fatal error C1083: Cannot open include file: 'pthread.h': No such file or directory [C:\\Users\\Irene\\Documents\\tensorflow\\tensorflow\\contrib\\cmake\\build\\eigen\\src\\eigen-build\\CMakeFiles\\CMakeTmp\\cmTC_55681.vcxproj]\r\n\r\nDone Building Project \"C:\\Users\\Irene\\Documents\\tensorflow\\tensorflow\\contrib\\cmake\\build\\eigen\\src\\eigen-build\\CMakeFiles\\CMakeTmp\\cmTC_55681.vcxproj\" (default targets) -- FAILED.\r\n\r\n\r\n\r\nBuild FAILED.\r\n\r\n\r\n\r\n\"C:\\Users\\Irene\\Documents\\tensorflow\\tensorflow\\contrib\\cmake\\build\\eigen\\src\\eigen-build\\CMakeFiles\\CMakeTmp\\cmTC_55681.vcxproj\" (default target) (1) ->\r\n\r\n(ClCompile target) -> \r\n\r\n  C:\\Users\\Irene\\Documents\\tensorflow\\tensorflow\\contrib\\cmake\\build\\eigen\\src\\eigen-build\\CMakeFiles\\CMakeTmp\\CheckIncludeFile.c(1): fatal error C1083: Cannot open include file: 'pthread.h': No such file or directory [C:\\Users\\Irene\\Documents\\tensorflow\\tensorflow\\contrib\\cmake\\build\\eigen\\src\\eigen-build\\CMakeFiles\\CMakeTmp\\cmTC_55681.vcxproj]\r\n\r\n\r\n\r\n    0 Warning(s)\r\n\r\n    1 Error(s)\r\n\r\n\r\n\r\nTime Elapsed 00:00:00.24\r\n```\r\n\r\n", "comments": ["The line with the error is:\r\n\r\n`C:\\Users\\Irene\\Documents\\tensorflow\\tensorflow\\contrib\\cmake\\build\\eigen\\src\\eigen-build\\CMakeFiles\\CMakeTmp\\CheckIncludeFile.c(1): fatal error C1083: Cannot open include file: 'pthread.h': No such file or directory [C:\\Users\\Irene\\Documents\\tensorflow\\tensorflow\\contrib\\cmake\\build\\eigen\\src\\eigen-build\\CMakeFiles\\CMakeTmp\\cmTC_55681.vcxproj]`\r\n\r\nSo I guess the question is why is eigen trying to include `pthread.h` on Windows?\r\n\r\nI was able to reproduce this on my box, when previously (Nov 2016, commit 2531ebc0fe7fc96) it worked fine. However even that previously good commit no longer functions now. This suggests Eigen upstream has changed something to break the tensorflow cmake build.", "@mrry `pthread.h` on Windows does seem anomalous.", "@Katuali and @ferrouswheel: What command are you using to start the build? Since Eigen is header-only, we shouldn't need to build anything for it, and our [CI is currently green](http://ci.tensorflow.org/job/tensorflow-pr-win-cmake-py/), so I suspect something is different in your configuration.\r\n\r\nAlso, @Katuali, I notice that MSBuild seems to be building in `Debug` configuration. For various reasons, we haven't been able to build on Windows in `Debug`, but you can instead try `Release` or `RelWithDebInfo` (if you need symbols).", "I tried `MSBuild /p:Configuration=Release tf_tutorials_example_trainer.vcxproj` and `MSBuild /p:Configuration=Release tf_python_build_pip_package.vcxproj`. So definitely using `Release` configuration\r\n\r\nBoth result in the same issue. I've tried building master branch, tag v1.0.0, and an older commit. Which suggests this may be our environment somehow.\r\n\r\nI've found the build log from the CI, so I'm going to try to track down where things diverge and report back here!\r\n", "That's weird! I can confirm that it builds correctly for me, in a fresh checkout. It's possible that the CMake build leaves some droppings behind (sadly, it's not hermetic like the Bazel build) and this could be causing the build to fail. Looking forward to hear what you find out....", "I've tracked this down to a Windows Boost distribution with a bad CMakeLists.txt. It would set `BOOST_ROOT` in the windows environment, and eigen would try and configure against it and then fail.\r\n\r\nSorry for the noise! Please feel free to close this.", "@ferrouswheel Thank you for tracking it down!", "@ferrouswheel Thanks for looking into this! I took a look at the Eigen CMakeLists, and it looks like we're doing more than we need to in the Eigen build\u2014when in fact all we really need to do is copy some headers to the right location. The build testing is enabled by default, and attempts to pick up Boost. I'm not sure why it breaks, but we can at least avoid the problem in future by avoiding that part of the build.", "@mrry Nice - I'm glad our Boost hiccup will help speed up the tensorflow build :-)"]}, {"number": 7373, "title": "there is a error when i import tensorflow in python script", "body": "after i finish 'Configure the installation' step without finishing 'create the pip package and install'step.\r\nthere is a error when i import tensorflow in python script.\r\ni type 'import tensorflow' in my python script and run it.i get this error:\r\n`Traceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py\", line 60, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\r\nImportError: libcudart.so.8.0: cannot open shared object file: No such file or directory\r\n\r\n\r\nError importing tensorflow.  Unless you are using bazel,\r\nyou should not try to import tensorflow from its source directory;\r\nplease exit the tensorflow source tree, and relaunch your python interpreter\r\nfrom there.\r\n`\r\ni install the latest version tensorflow from sourse on ubuntu15.04 with cuda7.5 and cudnn5. in 'Configure the installation' step,i set cuda version 7.5.", "comments": ["Are you building it from sources, but still trying to import an installed version?  How did TensorFlow get into `/usr/local/lib/python2.7/dist-packages`?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 7372, "title": "`Estimator.evaluate` froze", "body": "### Environment info\r\nOperating System:\r\n\r\n`Linux 3.13.0-107-generic #154-Ubuntu SMP Tue Dec 20 09:57:27 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux`\r\n\r\nInstalled version of CUDA and cuDNN: \r\n\r\n`None`\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n\r\n`a7338d74be3b07968dd2c2a94167db7b9ae1a9f8`\r\n\r\n2. The output of `bazel version`\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\nI implement a customized function for an Estimator class and run fit and evaluate with the Estimator model. The training works fine but it will stops at `evaluate` with around 220% CPU usage.\r\n\r\nThe following is a script to reproduce the similar problem. If you comment the `evaluate` function, this example script works fine, otherwise it will freeze at that part. \r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.layers.python.layers.optimizers import optimize_loss\r\nfrom tensorflow.contrib.learn.python.learn.estimators import model_fn\r\nfrom tensorflow.contrib.learn.python.learn.estimators.estimator import Estimator\r\nfrom tensorflow.python import debug as tf_debug\r\nfrom tensorflow.python.framework import ops\r\n\r\n\r\ndef main(_):\r\n    hooks = [tf_debug.LocalCLIDebugHook()]\r\n\r\n    def func(features, targets, mode, params):\r\n        idx = tf.concat([features['a'], features['b']], axis=1)\r\n\r\n        embedding = tf.get_variable(\"embed\", [10, 20], dtype=tf.float32)\r\n\r\n        pred = tf.reduce_sum(tf.nn.embedding_lookup(embedding, idx))\r\n\r\n        train_op = optimize_loss(loss=pred,\r\n                                 global_step=tf.train.get_global_step(),\r\n                                 learning_rate=0.001,\r\n                                 optimizer='Adam',\r\n                                 variables=tf.trainable_variables(),\r\n                                 name=\"training_loss_optimizer\")\r\n\r\n        eval_metric_dict = dict()\r\n        eval_metric_dict['metric'] = pred\r\n\r\n        return model_fn.ModelFnOps(mode=mode,\r\n                                   predictions=pred,\r\n                                   loss=pred,\r\n                                   train_op=train_op,\r\n                                   eval_metric_ops=eval_metric_dict)\r\n\r\n    model = Estimator(func, params={})\r\n\r\n    model.fit(\r\n        input_fn=lambda: (\r\n            {'a': ops.convert_to_tensor([[1, 2, 3, 4, 5]]), 'b': ops.convert_to_tensor([[2, 3, 4, 3, 5]])},\r\n            None), max_steps=10, monitors=hooks)\r\n    model.evaluate(\r\n         input_fn=lambda: (\r\n             {'a': ops.convert_to_tensor([[1, 2, 3, 4, 5]]), 'b': ops.convert_to_tensor([[2, 3, 4, 3, 5]])},\r\n             None))\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    tf.app.run()\r\n\r\n```\r\n\r\n### Logs or other output that would be helpful\r\n\r\nIf I press `ctrl + c`, the stack info are:\r\n\r\n```\r\nWARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp5jemyudd\r\n\r\n\r\n1q^CTraceback (most recent call last):\r\n  File \"estimator_test.py\", line 48, in <module>\r\n    tf.app.run()\r\n  File \"/data/bshi/py3env/lib/python3.4/site-packages/tensorflow/python/platform/app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"estimator_test.py\", line 42, in main\r\n    input_fn=lambda: (\r\n  File \"/data/bshi/py3env/lib/python3.4/site-packages/tensorflow/python/util/deprecation.py\", line 281, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/data/bshi/py3env/lib/python3.4/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 507, in evaluate\r\n    log_progress=log_progress)\r\n  File \"/data/bshi/py3env/lib/python3.4/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 825, in _evaluate_model\r\n    config=config_pb2.ConfigProto(allow_soft_placement=True))\r\n  File \"/data/bshi/py3env/lib/python3.4/site-packages/tensorflow/contrib/training/python/training/evaluation.py\", line 442, in evaluate_once\r\n    session.run(eval_ops, feed_dict)\r\n  File \"/data/bshi/py3env/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 469, in run\r\n    run_metadata=run_metadata)\r\n  File \"/data/bshi/py3env/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 793, in run\r\n    run_metadata=run_metadata)\r\n  File \"/data/bshi/py3env/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 751, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/data/bshi/py3env/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 898, in run\r\n    run_metadata=run_metadata)\r\n  File \"/data/bshi/py3env/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py\", line 751, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/data/bshi/py3env/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 767, in run\r\n    run_metadata_ptr)\r\n  File \"/data/bshi/py3env/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 965, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/data/bshi/py3env/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1015, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/data/bshi/py3env/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1022, in _do_call\r\n    return fn(*args)\r\n  File \"/data/bshi/py3env/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1004, in _run_fn\r\n    status, run_metadata)\r\nKeyboardInterrupt\r\n^C\u23ce\r\n```\r\n", "comments": ["Were you able to solve this issue? I'm getting the same behavior.", "I also have the same problem."]}, {"number": 7371, "title": "docs: add  a new 0.7.0 release with TF 0.12.1", "body": "docs: add  a new 0.7.0 release with TF 0.12.1 in the History part.", "comments": ["Can one of the admins verify this patch?", "The container that I have tagged 0.7.0 right now does not work, because it picks up the notebooks at the head of the tree which are not compatible with 0.12.1. I am waiting for a new TF container to be created.", "Hi !\r\nThe 0.7.0 tag version is what I actually use inside docker **with the udacity project** and it is compatible with the version 0.12.1 of tensorflow [**print(tf.--version--)** in the notebook].\r\nWith this version the last update of initializer : **tf.global_variables_initializer()** is applied but not with the 0.6.0 tag.\r\nSo if you release another version, please udpate the readme so that everyone be informed, the new initializer is faster.", "@Kjeanclaude assignment 6 will not work under current 0.7.0"]}, {"number": 7370, "title": "number of class mismatch between .py file and .ckpt, which makes wrong prediction.", "body": "the total class which is assigned num_classes=1000 in the file below.\r\n\r\nhttps://github.com/tensorflow/models/blob/master/slim/nets/inception_v2.py\r\n\r\nhowever, the published checkpoint file on the page below  for inception v2 is 1001.\r\n\r\nhttps://github.com/tensorflow/models/tree/master/slim\r\n\r\nThe prediction use this check point file is wrong, even if we update num_classes=1001 in the code. the wrong prediction is not shift 1 position, but completely mess.\r\n\r\n\r\n", "comments": ["@nathansilberman Do you know the source of the off-by-one error?", "@nathansilberman @sguada  could you take a look? Thank you!", "For training we reserve the class 0 for back-ground.\r\nSee https://github.com/tensorflow/models/blob/master/slim/datasets/imagenet.py#L59", "@sguada Okay, but I don't think this resolves the main concern here:\r\n> The prediction use this check point file is wrong, even if we update num_classes=1001 in the code. the wrong prediction is not shift 1 position, but completely mess."]}, {"number": 7369, "title": "resize_image_with_crop_or_pad can work with batch of images", "body": "Closes #7359", "comments": ["Can one of the admins verify this patch?", "@gpapan ping on calling it `_GetImageShapeWithRankMaybeRequireStatic`?", "@gpapan PTAL?", "@tensorflow-jenkins Test this please", "will tests run again?", "Jenkins, test this please", "Mind fixing the test failure? Search for the word \"failed\" here:\r\nhttps://ci.tensorflow.org/job/tensorflow-pull-requests-cpu/4077/consoleFull", "Jenkins, test this please"]}, {"number": 7368, "title": "Feature Request: Official Docker base image with python 3.5 (and not only 3.4)", "body": "I was building my Dockerfile for my docker image and when I ran containers, I noticed that python 3.4 was the one that was used. I installed python 3.5 successfully on the image but I was still unable to use tensorflow. Is it possible to request a base image that is always with the latest version of TensorFlow and also uses other version of pyhton 3? Like 3.5.\r\n\r\nI am aware I can just pip install it directly, but that doesn't keep it up to date with the latest. A base image with python 3.5 seems the most appropriate answer.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for \r\nRelated Stack Over Flow: http://stackoverflow.com/questions/42122826/can-one-use-python-3-5-in-a-docker-container-based-out-of-the-tensorflow-docker\r\n\r\n### Environment info\r\nUbuntu/Linux and Mac OS X. \r\n\r\n### What other attempted solutions have you tried?\r\nYou can install python 3.5 here:\r\n\r\nhttp://askubuntu.com/questions/682869/how-do-i-install-newer-python-versions-using-apt-get\r\n\r\nand then fix pip and numpy with:\r\n\r\nhttp://stackoverflow.com/questions/42122639/how-does-one-install-fix-a-failed-numpy-installation-that-works-on-python-3-4-bu/42124828?noredirect=1#comment71418540_42124828\r\n\r\nand then one can directly install python 3.5 with pip:\r\n\r\nexport TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.1-cp35-cp35m-linux_x86_64.whl\r\npython3.5 -m pip install TF_BINARY_URL\r\n\r\n(note pip3 will **not** work if all this is done in the docker container).\r\n\r\nThis should work but doesn't start from an official base image using python 3.5 and doesn't get the latest version of TensorFlow automatically.\r\n", "comments": ["@caisq Is there a reason to not upgrade the docker?  3.5 would be backwards compatible with 3.4, right?", "The primary reason for this is our docker images build on top of ubuntu 14.04. We are still at this version, because our base nvidia docker images (`cuda8 cudnn5`) are based off of ubuntu 14.04. So we kept all our docker images at the same ubuntu version to keep consistency. Unfortunately, ubuntu 14.04 only supports up to python 3.4.\r\n\r\nWe can install python as you described, but we decided to stay with officially supported version to avoid any unprecedented issues non-offical packages may cause. \r\n\r\nWe will soon be exploring upgrading all our dockerfiles to latest ubuntu LTS version, which will allow us to upgrade python. Sorry for the inconvenience this delay may have caused.", "As @jhseu recently pointed out, cuda 8 is now based on ubuntu:16.04. So this old roadblock doesn't exist anymore. We'll confirm that everything else is okay and if so, go ahead with the Python version update in the py3 docker images.", "cool, so when will this be solved? Just curious.", "This is resolved. nightly py3 images pushed onto Docker Hub (https://hub.docker.com/r/tensorflow/tensorflow/tags/) are already based on ubuntu 16.04 and Python 3.5. "]}, {"number": 7367, "title": "TF Slim batch_norm does not expose beta_regularizer or gamma_regularizer", "body": "[`batch_normalization`](https://github.com/tensorflow/tensorflow/blob/b00fc538638f87ac45be9105057b9865f0f9418b/tensorflow/python/layers/normalization.py#L255-L256) takes in a `beta_regularizer` and `gamma_regularizer` but the [TF slim `batch_norm` layer does not expose this](https://github.com/tensorflow/tensorflow/blob/bd4a1c58d28734c77ecb17d719e72c45c6c33077/tensorflow/contrib/layers/python/layers/layers.py#L362-L380).\r\n\r\nCompare this to other TF slim layers, such as `convolution` which do expose the regularizers: https://github.com/tensorflow/tensorflow/blob/bd4a1c58d28734c77ecb17d719e72c45c6c33077/tensorflow/contrib/layers/python/layers/layers.py#L789-L791 ", "comments": ["@cancan101 Seems like a reasonable request.\r\n\r\n@sguada I'll mark this contributions welcome, but let me know if there's a reason against it.", "Do you think it should have one regularizer param like for the `initializer` param on batch_norm? Or be consistent with how `convolution` has a param for each regularizer? (note: `convolution` also has a param for each `initializer` which is not consistent with `batch_norm`). I would vote for the one param.", "I think one param is a good idea."]}, {"number": 7366, "title": "set correct target directory for tar extractall()", "body": "fixes a wrong path when data_root is other than '.'", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please."]}, {"number": 7365, "title": "Update protobuf only to track down jenkins failures", "body": "", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "Closing in favor of https://github.com/tensorflow/tensorflow/pull/7338. I think I tracked down the failure (well, it works locally now)."]}, {"number": 7364, "title": "Can't build MacOS GPU pip because odf nccl_archive errors", "body": "Looks like Google CI build is having the same issue:\r\nhttps://ci.tensorflow.org/view/Nightly/job/nightly-matrix-mac-gpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=gpu-mac/lastFailedBuild/console\r\n\r\n```\r\n90 errors detected in the compilation of \"/var/folders/9l/c8y8z62s0kjgnpgx6jwh0g9r0000gn/T//tmpxft_0000aebc_00000000-7_reduce_scatter.cu.cpp1.ii\".\r\nERROR: /private/var/tmp/_bazel_yaroslav/8430f3ac1504aea2a8d4e6b016af31c5/external/nccl_archive/BUILD.bazel:33:1: output 'external/nccl_archive/_objs/nccl/external/nccl_archive/src/all_reduce.cu.pic.o' was not created.\r\nERROR: /private/var/tmp/_bazel_yaroslav/8430f3ac1504aea2a8d4e6b016af31c5/external/nccl_archive/BUILD.bazel:33:1: output 'external/nccl_archive/_objs/nccl/external/nccl_archive/src/reduce.cu.pic.o' was not created.\r\nERROR: /private/var/tmp/_bazel_yaroslav/8430f3ac1504aea2a8d4e6b016af31c5/external/nccl_archive/BUILD.bazel:33:1: Couldn't build file external/nccl_archive/_objs/nccl/external/nccl_archive/src/all_reduce.cu.pic.o: not all outputs were created or valid.\r\nERROR: /private/var/tmp/_bazel_yaroslav/8430f3ac1504aea2a8d4e6b016af31c5/external/nccl_archive/BUILD.bazel:33:1: Couldn't build file external/nccl_archive/_objs/nccl/external/nccl_archive/src/reduce.cu.pic.o: not all outputs were created or valid.\r\nERROR: /private/var/tmp/_bazel_yaroslav/8430f3ac1504aea2a8d4e6b016af31c5/external/nccl_archive/BUILD.bazel:33:1: output 'external/nccl_archive/_objs/nccl/external/nccl_archive/src/reduce_scatter.cu.pic.o' was not created.\r\nERROR: /private/var/tmp/_bazel_yaroslav/8430f3ac1504aea2a8d4e6b016af31c5/external/nccl_archive/BUILD.bazel:33:1: Couldn't build file external/nccl_archive/_objs/nccl/external/nccl_archive/src/reduce_scatter.cu.pic.o: not all outputs were created or valid.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 2.220s, Critical Path: 1.47s\r\n```", "comments": ["fixing this will enable me to add the first macos XLA wheel to https://github.com/yaroslavvb/tensorflow-community-wheels", "This seems to be an issue in nccl.\r\nWe have conributed a fix, and testing the mac gpu build with it right now:\r\nhttp://ci.tensorflow.org/job/tensorflow-pull-requests-mac-gpu/7/", "After getting master, those errors are gone, but now pip package won't build with a bunch of errors like below\r\n\r\n\r\n```\r\n2 errors detected in the compilation of \"/var/folders/9l/c8y8z62s0kjgnpgx6jwh0g9r0000gn/T//tmpxft_00015b3d_00000000-7_one_hot_op_gpu.cu.cpp1.ii\".\r\nERROR: /Users/yaroslav/git/tensorflow/tensorflow/core/kernels/BUILD:612:1: output 'tensorflow/core/kernels/_objs/one_hot_op_gpu/tensorflow/core/kernels/one_hot_op_gpu.cu.pic.o' was not created.\r\nERROR: /Users/yaroslav/git/tensorflow/tensorflow/core/kernels/BUILD:612:1: Couldn't build file tensorflow/core/kernels/_objs/one_hot_op_gpu/tensorflow/core/kernels/one_hot_op_gpu.cu.pic.o: not all outputs were created or valid.\r\nINFO: From Compiling tensorflow/core/kernels/reverse_op_gpu.cu.cc:\r\nexternal/protobuf/src/google/protobuf/stubs/atomicops_internals_generic_c11_atomic.h(52): error: static assertion failed with \"incompatible 32-bit atomic layout\"\r\n\r\nexternal/protobuf/src/google/protobuf/stubs/atomicops_internals_generic_c11_atomic.h(145): error: static assertion failed with \"incompatible 64-bit atomic layout\"\r\n\r\n2 errors detected in the compilation of \"/var/folders/9l/c8y8z62s0kjgnpgx6jwh0g9r0000gn/T//tmpxft_000159ab_00000000-7_reverse_op_gpu.cu.cpp1.ii\".\r\nERROR: /Users/yaroslav/git/tensorflow/tensorflow/core/kernels/BUILD:642:1: output 'tensorflow/core/kernels/_objs/reverse_op_gpu/tensorflow/core/kernels/reverse_op_gpu.cu.pic.o' was not created.\r\nERROR: /Users/yaroslav/git/tensorflow/tensorflow/core/kernels/BUILD:642:1: Couldn't build file tensorflow/core/kernels/_objs/reverse_op_gpu/tensorflow/core/kernels/reverse_op_gpu.cu.pic.o: not all outputs were created or valid.\r\nINFO: From Compiling tensorflow/core/kernels/slice_op_gpu.cu.cc:\r\nexternal/protobuf/src/google/protobuf/stubs/atomicops_internals_generic_c11_atomic.h(52): error: static assertion failed with \"incompatible 32-bit atomic layout\"\r\n\r\nexternal/protobuf/src/google/protobuf/stubs/atomicops_internals_generic_c11_atomic.h(145): error: static assertion failed with \"incompatible 64-bit atomic layout\"\r\n\r\n2 errors detected in the compilation of \"/var/folders/9l/c8y8z62s0kjgnpgx6jwh0g9r0000gn/T//tmpxft_0001597f_00000000-7_slice_op_gpu.cu.cpp1.ii\".\r\nERROR: /Users/yaroslav/git/tensorflow/tensorflow/core/kernels/BUILD:660:1: output 'tensorflow/core/kernels/_objs/slice_op_gpu/tensorflow/core/kernels/slice_op_gpu.cu.pic.o' was not created.\r\n```", "@jhseu Looks like protobuf update broke mac gpu build?\r\nCould you take a look?", "Looks like it's https://github.com/google/protobuf/issues/2545 and https://github.com/google/protobuf/commit/ecc460ab1bf37d18f10511533bdf6ce6f746ab4d.\r\n\r\nCan't really revert that change because macOS atomics are deprecated in favor of C++11 atomics. Not sure why nvcc is hitting both static_asserts when it should only reach one... Will investigate later today.", "Fixed in https://github.com/google/protobuf/pull/2699. Will have to update workspace.bzl after that's merged.", "https://github.com/tensorflow/tensorflow/pull/7425", "I was able to build the pip package successfully. Now running all tests on it, but as the build is  successful, closing this issue.\r\nThanks @jhseu "]}, {"number": 7363, "title": "tf.decode_csv() seems to read the second field which actually doesn't exist.", "body": "### Environment info\r\nOperating System:\r\n```\r\n$ lsb_release -a\r\nNo LSB modules are available.\r\nDistributor ID:\tUbuntu\r\nDescription:\tUbuntu 14.04.5 LTS\r\nRelease:\t14.04\r\nCodename:\ttrusty\r\n```\r\n\r\nInstalled version of CUDA and cuDNN: \r\n```\r\n$ ls -l /usr/local/cuda-8.0/lib64/libcud*\r\n-rw-r--r-- 1 root root   558720 11\uc6d4  4 05:18 /usr/local/cuda-8.0/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root root       16 11\uc6d4  4 05:18 /usr/local/cuda-8.0/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root root       19 11\uc6d4  4 05:18 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\r\n-rwxr-xr-x 1 root root   415432 11\uc6d4  4 05:18 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.44\r\n-rw-r--r-- 1 root root   775162 11\uc6d4  4 05:18 /usr/local/cuda-8.0/lib64/libcudart_static.a\r\n-rwxr-xr-x 1 root root 79337624 11\uc6d4  4 05:20 /usr/local/cuda-8.0/lib64/libcudnn.so\r\n-rwxr-xr-x 1 root root 79337624 11\uc6d4  4 05:20 /usr/local/cuda-8.0/lib64/libcudnn.so.5\r\n-rwxr-xr-x 1 root root 79337624 11\uc6d4  4 05:20 /usr/local/cuda-8.0/lib64/libcudnn.so.5.1.5\r\n-rw-r--r-- 1 root root 69756172 11\uc6d4  4 05:20 /usr/local/cuda-8.0/lib64/libcudnn_static.a\r\n```\r\n\r\nTensorflow version:\r\n```\r\n$ python -c \"import tensorflow; print(tensorflow.__version__)\"\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\r\n0.12.1\r\n```\r\n\r\nI tried following ['A typical pipeline for reading records from' in 'Reading data'](https://www.tensorflow.org/how_tos/reading_data/).\r\n\r\nI wanted to read just one csv file including file name of MS COCO dataset.\r\nThe content of csv file is the following : \r\n```\r\n$ head -n 5 train_file_list.csv \r\n./train2014/COCO_train2014_000000322402.jpg,\r\n./train2014/COCO_train2014_000000441507.jpg,\r\n./train2014/COCO_train2014_000000555318.jpg,\r\n./train2014/COCO_train2014_000000380820.jpg,\r\n./train2014/COCO_train2014_000000496662.jpg,\r\n$ tail -n 5 train_file_list.csv \r\n./val2014/COCO_val2014_000000283947.jpg,\r\n./val2014/COCO_val2014_000000027620.jpg,\r\n./val2014/COCO_val2014_000000067310.jpg,\r\n./val2014/COCO_val2014_000000044520.jpg,\r\n./val2014/COCO_val2014_000000027617.jpg,\r\n```\r\n\r\nI have repeatedly confirmed that the field in csv is the only one containing the filename. I can attach pictures for the provement, but I will not. Of course, the 'train2014' and 'val2014' directories contain corresponding pictures, but that is not the case here.\r\n\r\nTrying to test for reproducing the above tutorial, I wrote code which is the following : \r\n```python\r\nimport tensorflow as tf\r\n \r\nfilename_queue = tf.train.string_input_producer(['/path/to/train_file_list.csv'])\r\n\r\nreader = tf.TextLineReader()\r\nkey, value = reader.read(filename_queue)\r\n\r\nrecord_defaults = [['aa']]\r\nfname = tf.decode_csv(value, record_defaults=record_defaults)\r\n\r\nwith tf.Session() as sess:\r\n    coord = tf.train.Coordinator()\r\n    threads = tf.train.start_queue_runners(coord=coord)\r\n\r\n    for i in range(5):\r\n        example = sess.run([fname])\r\n        print(example)\r\n    coord.request_stop()\r\n    coord.join(threads)\r\n```\r\n\r\nbut it raise the error which is the following : \r\n```\r\n(tensorflow)mikigom@mikigom-desktop:~/github/HSP2P/Training$ python input_test.py \r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: GeForce GTX 1070\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.797\r\npciBusID 0000:01:00.0\r\nTotal memory: 7.92GiB\r\nFree memory: 6.41GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)\r\nTraceback (most recent call last):\r\n  File \"input_test.py\", line 20, in <module>\r\n    example = sess.run([fname])\r\n  File \"/path/to/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 766, in run\r\n    run_metadata_ptr)\r\n  File \"/path/to/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 964, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/path/to/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1014, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/path/to/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1034, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Expect 1 fields but have 2 in record 0\r\n\t [[Node: DecodeCSV = DecodeCSV[OUT_TYPE=[DT_STRING], field_delim=\",\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](ReaderRead:1, DecodeCSV/record_defaults_0)]]\r\n\r\nCaused by op u'DecodeCSV', defined at:\r\n  File \"input_test.py\", line 11, in <module>\r\n    fname = tf.decode_csv(value, record_defaults=record_defaults)\r\n  File \"/path/to/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_parsing_ops.py\", line 45, in decode_csv\r\n    field_delim=field_delim, name=name)\r\n  File \"/path/to/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\r\n    op_def=op_def)\r\n  File \"/path/to/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/path/to/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): Expect 1 fields but have 2 in record 0\r\n\t [[Node: DecodeCSV = DecodeCSV[OUT_TYPE=[DT_STRING], field_delim=\",\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](ReaderRead:1, DecodeCSV/record_defaults_0)]]\r\n```\r\n\r\nIt seems that ```tf.decode_csv()``` reads the second field which actually doesn't exist.\r\nTo temporarily solve this problem, I changed ```record_defaults``` in the above code to:\r\n```python\r\nrecord_defaults = [['aa'], ['aa']]\r\n```\r\n\r\nAnd if you run the code again, it will return normally.\r\n```\r\n$ python input_test.py \r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: GeForce GTX 1070\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.797\r\npciBusID 0000:01:00.0\r\nTotal memory: 7.92GiB\r\nFree memory: 6.40GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)\r\n[['./train2014/COCO_train2014_000000322402.jpg', 'aa']]\r\n[['./train2014/COCO_train2014_000000441507.jpg', 'aa']]\r\n[['./train2014/COCO_train2014_000000555318.jpg', 'aa']]\r\n[['./train2014/COCO_train2014_000000380820.jpg', 'aa']]\r\n[['./train2014/COCO_train2014_000000496662.jpg', 'aa']]\r\n```\r\n\r\nI think this is a bug in ```tf.decode_csv()```.", "comments": ["I don't think CSV supports trailing commas, so `'a,'` means `['a', '']`.\r\n\r\nhttps://en.wikipedia.org/wiki/Comma-separated_values", "Even I got the same issue. Removing all the blank lines at the end in the csv file solved my problem"]}, {"number": 7362, "title": "Clean up SegmentReduction Ops", "body": "The segment reduction ops are currently inconsistent, they include different ops for sorted/unsorted/ and sparse/dense tensors.\r\nI guess it would make sense to provide the same reduction ops  for these - I'd be happy to work on this and build on nikste's work.\r\n\r\nFor similar previous issues @andydavis1, @drpngx were responsible for reviewing, so I link you here.\r\n\r\nThings to possibly consider:\r\n- Replace the sorted segment options by the more general unsorted options. I did a quick, non-extensive benchmark for  unsorted_segment_max vs  segment_max, the processing time is about the same (with the unsorted op even being a bit faster sometimes).\r\nThe drawback would be, that num_segments needs to be specified or needs to be computed before the reduction.\r\n- Include the feature request \"Extend tf.unsorted_segment_sum to allow 'rejecting' entries\" #478\r\n- Address the ToDo in UnsortedSegmentMax: `// todo: Remove duplicate code in UnsortedSegmentSumFunctor and UnsortedSegmentMaxFunctor.`\r\nTo sum up, I'd suggest to replace and extend the currently provided functions\r\n```\r\ntf.segment_sum(data, segment_ids, name=None)\r\ntf.segment_prod(data, segment_ids, name=None)\r\ntf.segment_min(data, segment_ids, name=None)\r\ntf.segment_max(data, segment_ids, name=None)\r\ntf.segment_mean(data, segment_ids, name=None)\r\ntf.unsorted_segment_sum(data, segment_ids, num_segments, name=None)\r\ntf.sparse_segment_sum(data, indices, segment_ids, name=None)\r\ntf.sparse_segment_mean(data, indices, segment_ids, name=None)\r\ntf.sparse_segment_sqrt_n(data, indices, segment_ids, name=None)\r\n```\r\nwith \r\n```\r\n# all dense/sparse ops support unsorted segments\r\ntf.segment_sum(data, segment_ids, num_segements=None, name=None) \r\ntf.segment_prod(data, segment_ids, num_segements=None, name=None)\r\ntf.segment_min(data, segment_ids, num_segements=None, name=None)\r\ntf.segment_max(data, segment_ids, num_segements=None, name=None) \r\ntf.segment_mean(data, segment_ids, num_segements=None, name=None)\r\ntf.segment_sqrt_n(data, segment_ids, num_segements=None, name=None)  # new\r\n\r\ntf.sparse_segment_sum(data, indices, segment_ids, name=None)\r\ntf.sparse_segment_prod(data, indices, segment_ids, name=None)  # new\r\ntf.sparse_segment_min(data, indices, segment_ids, name=None)  # new\r\ntf.sparse_segment_max(data, indices, segment_ids, name=None)  # new\r\ntf.sparse_segment_mean(data, indices, segment_ids, name=None)\r\ntf.sparse_segment_sqrt_n(data, indices, segment_ids, name=None)\r\n```\r\n\r\n(Or `tf.unsorted_segment_reduce_op` instead of `tf.segement_reduceop` to not break backward compability)", "comments": ["I don't think we'll replace the sorted versions with unsorted versions.  The feature requested in https://github.com/tensorflow/tensorflow/issues/478 is covered by https://github.com/tensorflow/tensorflow/issues/478, so we don't need to ask for it twice here.  The remaining new bits are adding missing ops and fixing the TODO, both of which we would be happy to accept PRs for.", "However, it would be better to have targeted feature requests rather than this grab bag mixing things we don't want and things we do, so I'm going to close this issue for now.  Would you be willing to file more specific issues for the two aspects I mentioned?"]}, {"number": 7361, "title": "Cherrypicks for release test fixes.", "body": "For bazel and cmake: maybe better to set this at runtime instead\r\nof compile time.", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Windows cmake GPU build:\r\nhttp://ci.tensorflow.org/job/tf-pr-win-cmake-gpu/12/", "Mac GPU build\r\nhttp://ci.tensorflow.org/job/tensorflow-pull-requests-mac-gpu/6/\r\n\r\nJenkins, test this please.", "the builds were also successful.\r\nMerging."]}, {"number": 7360, "title": "Fix unsorted_segment_max for negative floats", "body": "Fixes the following bug due to std::numeric_limits<float>::min() returning the smallest positive value of a float.\r\n\r\n```\r\nwith tf.Session() as sess:\r\n    x = tf.constant([-1.0, -2.0, -3.0, -4.0])\r\n    segment_ids = tf.constant([0, 1, 2, 3])\r\n    unsorted_seg_max = tf.unsorted_segment_max(x, segment_ids, 4)\r\n    print(sess.run(unsorted_seg_max))\r\n>>> [  1.17549435e-38   1.17549435e-38   1.17549435e-38   1.17549435e-38]\r\n```\r\n", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it!", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->", "Added second e-mail address to github account.\r\nI signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Jenkins, test this please."]}, {"number": 7359, "title": "resize_image_with_crop_or_pad should work with batch of images", "body": "This is a repost of https://github.com/tensorflow/tensorflow/issues/2284 [per comment](https://github.com/tensorflow/tensorflow/issues/2284#issuecomment-277339057) from @mrry (CC @ziky90).\r\n\r\n`resize_image_with_crop_or_pad` should be modified to take either a single image or a batch of images. Right now the signature of the function specifies:\r\n```\r\n    image: 3-D tensor of shape `[height, width, channels]`\r\n```\r\n\r\nFor a reference of what the api should look like, see [`resize_images(images,....)`](https://github.com/tensorflow/tensorflow/blob/4c192f060cf9ff897911d240c140299d6db257b6/tensorflow/python/ops/image_ops_impl.py#L605-L608):\r\n```\r\n    images: 4-D Tensor of shape `[batch, height, width, channels]` or\r\n            3-D Tensor of shape `[height, width, channels]`.\r\n```\r\n\r\nSome commentary:\r\n* docs for `resize_images` say: \" Resized images will be distorted if their original aspect ratio is not the same as `size`.  To avoid distortions see [`resize_image_with_crop_or_pad`].\" However the method referenced _cannot_ be currently used in some cases for which `resize_images` works due to the above mentioned limitations.\r\n* the entire operation can be implemented using slice operations on the tensor batch. This is what `resize_image_with_crop_or_pad` does but it has the following logic which would be nice not to copy and paste (there is some subtlety with round down vs up):\r\n```python\r\n  width_diff = target_width - width\r\n  offset_crop_width = max_(-width_diff // 2, 0)\r\n  offset_pad_width = max_(width_diff // 2, 0)\r\n\r\n  height_diff = target_height - height\r\n  offset_crop_height = max_(-height_diff // 2, 0)\r\n  offset_pad_height = max_(height_diff // 2, 0)\r\n```\r\n* the fact this one image op method does not handle batches leads to confusion and various [SO](http://stackoverflow.com/questions/33944683/tensorflow-map-operation-for-tensor) posts. People even resort to solving the problem using all sorts of crazy solutions (e.g. `tf.while_loop`).\r\n* this method is useful in combination with concatenation operations. For example see the[ Lasagne `ConcatLayer`](http://lasagne.readthedocs.io/en/latest/modules/layers/merge.html#lasagne.layers.ConcatLayer).", "comments": ["@shlens Can you comment?  Ages ago we stripped most of these image preprocessing ops down to 3-D only; what do you think about people raising them back up again?\r\n\r\n@cancan101 The motivation for 3-D only is that image processing pipelines that take images of different sizes have to handle separate images as separate tensors anyways, at least until after the resizing step happens.  And this op is the resizing step.", "@girving Where I am using this, and likely others as well (this was the same use case that Lasagne handles) is in the NN portion graph itself when doing an upsample. I want to upsample and then concatenate across channels but I need to take a center crop to make sure spatial dimensionality  matches.", "@cancan101 Okay, I think fixing this is quite reasonable.  However, if it's fixed it should work for any rank >= 3.  This shouldn't be much more complicated than doing it for just 3D and 4D, since the higher ranks all mean map.", "@girving I think adding support for 4D sounds reasonable -- especially if it leads to consistency in the API across image resizing functions.", "@cancan101 Great, we're all in agreement that this is a good change.  Would you be interested in submitting a PR?", "Is it okay to change the api of this method? Perhaps with some sort of deprecation to take in `images` rather than `image`?", "@cancan101 Please leave it image, then document that image can be higher rank."]}, {"number": 7358, "title": "name 'DATA_CFG' is not defined, Extension 'tensorflow/tensorflow.bzl' has errors", "body": "Hi!\r\n\r\nI was following the [Nvidia instruction](http://www.nvidia.com/object/gpu-accelerated-applications-tensorflow-installation.html) on how to install tensorflow with CUDA/cuDNN when I faced with the next problem (step 5, \"call bazel to build the TensorFlow pip package\"):\r\n```\r\n~/tensorflow$ bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package \r\nERROR: /home/user/tensorflow/tensorflow/tensorflow.bzl:478:19: name 'DATA_CFG' is not defined.\r\nERROR: com.google.devtools.build.lib.packages.BuildFileContainsErrorsException: error loading package '': Extension 'tensorflow/tensorflow.bzl' has errors.\r\nINFO: Elapsed time: 0.108s\r\n```\r\nCould you suggest something to overcome this issue?\r\n\r\nAdditional information:\r\n```\r\n~$ lsb_release -a\r\nNo LSB modules are available.\r\nDistributor ID:\tUbuntu\r\nDescription:\tUbuntu 16.04.1 LTS\r\nRelease:\t16.04\r\nCodename:\txenial\r\n~$ ls -l /usr/local/cuda/lib64/libcud*\r\n-rw-r--r-- 1 root root    558720 \u0441\u0435\u043d 15 02:02 /usr/local/cuda/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root root        16 \u0441\u0435\u043d 15 02:05 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root root        19 \u0441\u0435\u043d 15 02:05 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\r\n-rw-r--r-- 1 root root    415432 \u0441\u0435\u043d 15 02:02 /usr/local/cuda/lib64/libcudart.so.8.0.44\r\n-rw-r--r-- 1 root root    775162 \u0441\u0435\u043d 15 02:02 /usr/local/cuda/lib64/libcudart_static.a\r\nlrwxrwxrwx 1 user users       13 \u043d\u043e\u044f  7 10:00 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\r\nlrwxrwxrwx 1 user users       18 \u043d\u043e\u044f  7 10:00 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.10\r\n-rwxr-xr-x 1 user users 84163560 \u043d\u043e\u044f  7 09:47 /usr/local/cuda/lib64/libcudnn.so.5.1.10\r\n-rw-r--r-- 1 user users 70364814 \u043d\u043e\u044f  7 09:47 /usr/local/cuda/lib64/libcudnn_static.a\r\n~/tensorflow$ git rev-parse HEAD\r\n70de76e696c21da617fd2e6435cf7fedab220db8\r\n~$ bazel version\r\nBuild label: 0.4.4\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Wed Feb 1 18:54:21 2017 (1485975261)\r\nBuild timestamp: 1485975261\r\nBuild timestamp as int: 1485975261\r\n```", "comments": ["What version of TensorFlow are you using?", "As I mention above: master 70de76e696c21da617fd2e6435cf7fedab220db8", "Sorry, I've closed the issue accidentally.\r\n\r\nMore precisely, tensorflow was cloned this way:\r\n```\r\n~$ git clone https://github.com/tensorflow/tensorflow\r\n~$ cd tensorflow \r\n~/tensorflow $ git reset --hard 70de76e\r\n```", "@OLEGator30 That commit is from July.  Please try a newer version.", "Yeah, now it works, thanks! Nvidia instruction is completely out of date.", "I am facing the same issue on the cuda_osx branch. \r\n\r\n```\r\ngit clone --recurse-submodules https://github.com/tensorflow/tensorflow\r\ngit fetch origin pull/664/head:cuda_osx\r\ngit checkout cuda_osx\r\n```\r\n\r\n```\r\nadmins-MacBook-Pro:tensorflow admin$ bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer\r\nWARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.build/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.\r\nERROR: /Users/admin/udacity/tensorflow/tensorflow/tensorflow.bzl:418:42: name 'DATA_CFG' is not defined.\r\nERROR: com.google.devtools.build.lib.packages.BuildFileContainsErrorsException: error loading package '': Extension 'tensorflow/tensorflow.bzl' has errors.\r\n```", "@mishra69 Random commits from August are not supported.  Please use something more recent.", "Anyone know of a version that will compile with both GPU support and work with the current version of TFLearn?", "@krautt Have you tried 1.0?  https://github.com/tensorflow/tensorflow/releases/tag/v1.0.0", "Yes it worked but didn't seem to play well with the tflearn stuff i was doing. I compiled the head of the 0.12 branch and it's working for me.  Thanks.", "@krautt In case it's useful: there's a good chance that everything you want is still there, just possibly in a different namespace.  There was a bunch of code movement right before 1.0, since after 1.0 we've promised not to move things for quite a while (unless it's in `tf.contrib`).", "Hi,\r\nI call bazel to build the TensorFlow pip package but I have the same error as @OLEGator30 , knowing that :Ubuntu 16.10\r\nbazel 0.4.4\r\ntensorflow: 70de76e\r\n", "if I used the newest tensoflow version I've got this error:  \r\n:~/tensorflow$ ./configure \r\nPlease specify the location of python. [Default is /usr/bin/python]: /usr/bin/python2.7\r\nPlease specify optimization flags to use during compilation [Default is -march=native]: \r\nDo you wish to use jemalloc as the malloc implementation? (Linux only) [Y/n] \r\njemalloc enabled on Linux\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] \r\nNo Google Cloud Platform support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with Hadoop File System support? [y/N] \r\nNo Hadoop File System support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] \r\nNo XLA support will be enabled for TensorFlow\r\nFound possible Python library paths:\r\n  /usr/local/lib/python2.7/dist-packages\r\n  /usr/lib/python2.7/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]\r\n\r\nUsing python library path: /usr/local/lib/python2.7/dist-packages\r\nDo you wish to build TensorFlow with OpenCL support? [y/N] n\r\nNo OpenCL support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with CUDA support? [y/N] y\r\nCUDA support will be enabled for TensorFlow\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0\r\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\nPlease specify the Cudnn version you want to use. [Leave empty to use system default]: 5\r\nPlease specify the location where cuDNN 5 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size.\r\n[Default is: \"3.5,5.2\"]: 3.0\r\nINFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.\r\n.........\r\nERROR: /home/tensorflow/tensorflow/core/kernels/BUILD:2349:1: no such package '@libxsmm_archive//': Error downloading [http://bazel-mirror.storage.googleapis.com/github.com/hfp/libxsmm/archive/1.6.1.tar.gz, https://github.com/hfp/libxsmm/archive/1.6.1.tar.gz] to /home/razen/.cache/bazel/_bazel_razen/fca8cfb97533c9eba80d6f329ce32777/external/libxsmm_archive/1.6.1.tar.gz: Tried to reconnect at offset 594,903 but server didn't support it and referenced by '//tensorflow/core/kernels:conv_ops'.\r\nERROR: /home/tensorflow/tensorflow/core/kernels/BUILD:2030:1: no such package '@libxsmm_archive//': Error downloading [http://bazel-mirror.storage.googleapis.com/github.com/hfp/libxsmm/archive/1.6.1.tar.gz, https://github.com/hfp/libxsmm/archive/1.6.1.tar.gz] to /home/razen/.cache/bazel/_bazel_razen/fca8cfb97533c9eba80d6f329ce32777/external/libxsmm_archive/1.6.1.tar.gz: Tried to reconnect at offset 594,903 but server didn't support it and referenced by '//tensorflow/core/kernels:sparse_matmul_op'.\r\nERROR: Evaluation of query \"deps((//tensorflow/... - //tensorflow/examples/android/...))\" failed: errors were encountered while computing transitive closure.\r\n"]}, {"number": 7357, "title": "there is a error when i run 'bazel build --config opt //tensorflow/tools/pip_package:build_pip_package'", "body": "INFO: Found 1 target...\r\nERROR: /home/ben/.cache/bazel/_bazel_ben/a552231fe7b7da49217bcb6530531abd/external/protobuf/BUILD:73:1: C++ compilation of rule '@protobuf//:protobuf_lite' failed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG ... (remaining 38 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\ngcc: error: cuda: No such file or directory\r\ngcc: error: cuda: No such file or directory\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 5.769s, Critical Path: 1.60s\r\n", "comments": ["Do you have cuda installed?  What version?  What planform are you on, and what version of TensorFlow do you have?", "i have installed cuda7.5 and the latest tensorflow on Ubuntu 15.04.i install tensorflow from sourse and set cuda version 7.5.but it didn't work when import tensorflow in python script.\n\n\u53d1\u81ea\u6211\u7684 iPhone\n\n> \u5728 2017\u5e742\u67088\u65e5\uff0c23:19\uff0cGeoffrey Irving <notifications@github.com> \u5199\u9053\uff1a\n> \n> Do you have cuda installed? What version? What planform are you on, and what version of TensorFlow do you have?\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub, or mute the thread.\n> \n", "Try running bazel with `--subcommands` to see the whole gcc command that is failing.", "i type 'bazel build --subcommands //tensorflow/tools/pip_package:build_pip_package',and i get error:\r\n\r\n\r\nERROR: /home/ben/tensorflow/tensorflow/core/BUILD:1089:1: C++ compilation of rule '//tensorflow/core:lib_internal' failed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG ... (remaining 106 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\nIn file included from ./tensorflow/core/lib/gtl/array_slice.h:101:0,\r\n                 from ./tensorflow/core/lib/strings/str_util.h:23,\r\n                 from tensorflow/core/lib/strings/str_util.cc:16:\r\n./tensorflow/core/lib/gtl/array_slice_internal.h:232:38: error: 'tensorflow::gtl::array_slice_internal::ArraySliceImplBase<const T>::ArraySliceImplBase' names constructor\r\n./tensorflow/core/lib/gtl/array_slice_internal.h:252:32: error: 'tensorflow::gtl::array_slice_internal::ArraySliceImplBase<T>::ArraySliceImplBase' names constructor\r\nIn file included from ./tensorflow/core/lib/gtl/array_slice.h:102:0,\r\n                 from ./tensorflow/core/lib/strings/str_util.h:23,\r\n                 from tensorflow/core/lib/strings/str_util.cc:16:\r\n./tensorflow/core/lib/gtl/inlined_vector.h: In member function 'void tensorflow::gtl::InlinedVector<T, N>::Destroy(T*, int)':\r\n./tensorflow/core/lib/gtl/inlined_vector.h:396:10: error: 'is_trivially_destructible' is not a member of 'std'\r\n./tensorflow/core/lib/gtl/inlined_vector.h:396:42: error: expected primary-expression before '>' token\r\n./tensorflow/core/lib/gtl/inlined_vector.h:396:43: error: '::value' has not been declared\r\n", "The lack of `std::is_trivially_destructable` is odd.  It would imply your version of g++ is too old: we don't support anything without good C++11 support.  However, your version of Ubuntu is reasonably recent.  What version of g++ do you have?  Is there some other reason you'd lack part of the standard library?", "the version of g++ is 4.7.4.which version of g++ i should head?", "@mathfinder Looks like gcc 4.9, or any recent version of clang."]}]