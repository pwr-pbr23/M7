[{"number": 25673, "title": "Update the environment capture script for system information.", "body": "for @dynamicwebpaige 's issue #25461\r\nadded\r\n* **Python** version\r\n* **Bazel** version (if compiling from source)\r\n\r\ntensorflow installed info (pip show tensorflow) to better discern if tf was installed from binary or source\r\nit adds package location and author-email info to output", "comments": ["Adding miaout17@ for review.", "Nagging Reviewer @aselle, @miaout17: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 74 days with no activity and the `awaiting review` label has been applied."]}, {"number": 25672, "title": "Remove duplicated file of kafka_ops.cc", "body": "The kafka_ops.cc is the same as dataset_ops.cc and is\r\nnot being used by BUILD file.\r\n\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 25671, "title": "Cherry pick fix to 1.13 for python 3", "body": "This addresses b/122973623 which was hitting the 1.13rc0 and rc1", "comments": []}, {"number": 25670, "title": "Unable to use keras.application within TF Estimator", "body": "I am having problems using keras.applications within an estimator. After much trying out myself, I came up with a minimal version to indicate the problem. I presume that it is caused by keras only having one session at a time while estimators set up several sessions for training and evaluation.\r\n\r\nThis is my [original post from stackoverflow](https://stackoverflow.com/questions/54589386/tensorflow-integrate-keras-model-in-estimator-model-fn)\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, see below\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.12.0\r\n- Python version: 3.6.7\r\n\r\n**Describe the current behavior**\r\nThe estimator apparently does not learn the data, which can be observed by a constant loss (in evaluation) and a stagnant loss during training.\r\n\r\n**Describe the expected behavior**\r\nThe estimator should learn the MNIST dataset at least as good from the model features as from the raw data.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nfrom keras.datasets import mnist\r\n\r\n\r\n# switch to example 1/2/3\r\nEXAMPLE_CASE = 1\r\n\r\n# flag for initial weights loading of keras model\r\n_W_INIT = True\r\n\r\n\r\ndef dense_net(features, labels, mode, params):\r\n    # --- code to load a keras application ---\r\n\r\n    # commenting in this line leads to a bump in the loss everytime the\r\n    # evaluation is run, this indicating that keras does not handle well the\r\n    # two sessions of the estimator API\r\n    # tf.keras.backend.set_learning_phase(mode == tf.estimator.ModeKeys.TRAIN)\r\n    global _W_INIT\r\n\r\n    model = tf.keras.applications.MobileNet(\r\n        input_tensor=features,\r\n        input_shape=(128, 128, 3),\r\n        include_top=False,\r\n        pooling='avg',\r\n        weights='imagenet' if _W_INIT else None)\r\n\r\n    # only initialize weights once\r\n    if _W_INIT:\r\n        _W_INIT = False\r\n\r\n    # switch cases\r\n    if EXAMPLE_CASE == 1:\r\n        # model.output is the same as model.layers[-1].output\r\n        img = model.layers[-1].output\r\n    elif EXAMPLE_CASE == 2:\r\n        img = model(features)\r\n    elif EXAMPLE_CASE == 3:\r\n        # do not use keras features\r\n        img = tf.keras.layers.Flatten()(features)\r\n    else:\r\n        raise NotImplementedError\r\n\r\n    # --- regular code from here on ---\r\n    for units in params['dense_layers']:\r\n        img = tf.keras.layers.Dense(units=units, activation='relu')(img)\r\n\r\n    logits = tf.keras.layers.Dense(units=10,\r\n                                   activation='relu')(img)\r\n\r\n    # compute predictions\r\n    probs = tf.nn.softmax(logits)\r\n    predicted_classes = tf.argmax(probs, 1)\r\n\r\n    # compute loss\r\n    loss = tf.losses.sparse_softmax_cross_entropy(labels, logits)\r\n\r\n    acc = tf.metrics.accuracy(labels, predicted_classes)\r\n    metrics = {'accuracy': acc}\r\n    tf.summary.scalar('accuarcy', acc[1])\r\n\r\n    if mode == tf.estimator.ModeKeys.EVAL:\r\n        return tf.estimator.EstimatorSpec(\r\n            mode, loss=loss, eval_metric_ops=metrics)\r\n\r\n    # create training operation\r\n    assert mode == tf.estimator.ModeKeys.TRAIN\r\n\r\n    optimizer = tf.train.AdagradOptimizer(learning_rate=0.01)\r\n    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\r\n    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\r\n\r\n\r\ndef prepare_dataset(in_tuple, n):\r\n    feats = in_tuple[0][:n, :, :]\r\n    labels = in_tuple[1][:n]\r\n    feats = feats.astype(np.float32)\r\n    feats /= 255\r\n    labels = labels.astype(np.int32)\r\n    return (feats, labels)\r\n\r\n\r\ndef _parse_func(features, labels):\r\n    feats = tf.expand_dims(features, -1)\r\n    feats = tf.image.grayscale_to_rgb(feats)\r\n    feats = tf.image.resize_images(feats, (128, 128))\r\n    return (feats, labels)\r\n\r\n\r\ndef load_mnist(n_train=10000, n_test=3000):\r\n    train, test = mnist.load_data()\r\n    train = prepare_dataset(train, n_train)\r\n    test = prepare_dataset(test, n_test)\r\n    return train, test\r\n\r\n\r\ndef train_input_fn(imgs, labels, batch_size):\r\n    dataset = tf.data.Dataset.from_tensor_slices((imgs, labels))\r\n    dataset = dataset.map(_parse_func)\r\n    dataset = dataset.shuffle(500)\r\n    dataset = dataset.repeat().batch(batch_size)\r\n    return dataset\r\n\r\n\r\ndef eval_input_fn(imgs, labels, batch_size):\r\n    dataset = tf.data.Dataset.from_tensor_slices((imgs, labels))\r\n    dataset = dataset.map(_parse_func)\r\n    dataset = dataset.batch(batch_size)\r\n    return dataset\r\n\r\n\r\ndef main(m_dir=None):\r\n    # fetch data\r\n    (x_train, y_train), (x_test, y_test) = load_mnist()\r\n\r\n    train_spec = tf.estimator.TrainSpec(\r\n        input_fn=lambda: train_input_fn(\r\n            x_train, y_train, 30),\r\n        max_steps=150)\r\n\r\n    eval_spec = tf.estimator.EvalSpec(\r\n        input_fn=lambda: eval_input_fn(\r\n            x_test, y_test, 30),\r\n        steps=100,\r\n        start_delay_secs=0,\r\n        throttle_secs=0)\r\n\r\n    run_cfg = tf.estimator.RunConfig(\r\n        model_dir=m_dir,\r\n        tf_random_seed=2,\r\n        save_summary_steps=2,\r\n        save_checkpoints_steps=10,\r\n        keep_checkpoint_max=1)\r\n\r\n    # build network\r\n    classifier = tf.estimator.Estimator(\r\n        model_fn=dense_net,\r\n        params={\r\n            'dense_layers': [256]},\r\n        config=run_cfg)\r\n\r\n    # fit the model\r\n    tf.estimator.train_and_evaluate(\r\n        classifier,\r\n        train_spec,\r\n        eval_spec)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\n**Other info / logs**\r\n\r\n", "comments": ["This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. I have seen your clear problem description on Stackoverflow and I think community will respond to your question soon. Thanks!", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)", "I think this should be a bug, how can it be that you cannot train an estimator using a Keras application? This is a super common use-case. We've had to resort to saving the Keras application as a saved model and loading it as a predictor in the input_fn, to deploy we've had to merge the two saved models together in a separate script.\r\n\r\nAll this doesn't make sense. If TFHub enabled you to have variable image input size all would be fine, but it doesn't, that leaves keras as the only source for easy-to-use general purpose pretrained models, but if you cannot fine tune them using the estimator then the high-level API of Tensorflow is broken. ", "I agree with @cgarciae since it is said everywhere that Keras and Tensorflow work hand in hand - though when using the estimator function `train_and_evaluate`, it apparently breaks.\r\n\r\nIt would be good to have an official answer from somebody who fully understands the inner workings. E.g. I can only assume that a problem arises from Keras only having one session while `train_and_evaluate` (as far as I know) creates a training session in the beginning and a new evaluation session on each evaluation.\r\n\r\nSo in my opinion, this should be considered a bug. Fine-tuning the layers of a pretrained model is a very common use-case. And if not a functionality bug, then it should at least be considered a documentation issue: The documentation should state clearly that you (probably) cannot use pretrained keras models in the estimator.\r\n\r\n@jvishnuvardhan can you at least confirm/explain how Keras and Tensorflow Estimators handle the sessions if used together?", "I would like to add that this seems to be not only wonky for keras.application models but also for regular keras models. I have a functional keras model that trains wonderfully through model.fit but when using estimators, it never converges.\r\n\r\nWhat struck me weird is that also the metrics for the estimator seem totally wrong. I am attaching metrics to the keras model plus some on the EvalSpecs of the estimator\r\n\r\nSo when using tensorflow.metrics on the estimator, I get\r\n\r\n```\r\neg.\r\ndef eval_metrics(features, labels, predictions):\r\n    return {\r\n        'streaming_true_positives': metrics.true_positives(labels=labels, predictions=predictions['final']),\r\n        'streaming_true_negatives': metrics.true_negatives(labels=labels, predictions=predictions['final']),\r\n        'streaming_false_positives': metrics.false_positives(labels=labels, predictions=predictions['final']),\r\n        'streaming_false_negatives': metrics.false_negatives(labels=labels, predictions=predictions['final'])  \r\n    }\r\n\r\nstreaming_false_negatives = 0.0\r\nstreaming_false_positives = 304213.0\r\nstreaming_true_negatives = 0.0\r\nstreaming_true_positives = 3883.0\r\n```\r\n\r\nas result for the eval set, but my batch wise keras metrics give me\r\neg.\r\n```\r\ndef true_positives(y_true, y_pred):\r\n  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\r\n  return true_positives\r\n\r\nfalse_negatives = 1.4632323\r\nfalse_positives = 0.0756128\r\ntrue_negatives = 126.31117\r\ntrue_positives = 0.14997923\r\n```\r\n-> These are mean values per batch\r\n\r\nSo the estimator completely fails to work with the data somehow.\r\n", "@wirtsi Could you provide any code to reproduce the bug? Thanks!", "Hah, I got it ... that took me really long to figure out because at first my sample case was working. But I was able to reproduce this! The estimator metrics completely freak out if there is a Keras Embedding in the Graph, it appears as if the model never learns.\r\n\r\nMy test case is here: https://colab.research.google.com/drive/194Puigi-LdzxZup6LNREk47l9uP0_Dx9\r\n\r\nSo when training the model with keras model.fit() it works as expected\r\n\r\n> Epoch 1/100\r\n>  - 4s - loss: 0.6918 - acc: 0.5367 - true_positives: 146.4400 - true_negatives: 121.8800 - false_positives: 128.0600 - false_negatives: 103.5600 - recall: 0.5859 - precision: 0.5361 - val_loss: 0.6925 - val_acc: 0.5250 - val_true_positives: 130.9000 - val_true_negatives: 131.6000 - val_false_positives: 116.1000 - val_false_negatives: 121.4000 - val_recall: 0.5190 - val_precision: 0.5300\r\n> ...\r\n> Epoch 100/100\r\n>  - 3s - loss: 0.0040 - acc: 1.0000 - true_positives: 249.9600 - true_negatives: 249.9800 - false_positives: 0.0000e+00 - false_negatives: 0.0000e+00 - recall: 1.0000 - precision: 1.0000 - **val_loss: 0.1620 - val_acc: 0.9492 - val_true_positives: 237.6000 - val_true_negatives: 237.0000 - val_false_positives: 11.5000 - val_false_negatives: 13.9000 - val_recall: 0.9447 - val_precision: 0.9539**\r\n\r\nSo it learned the case alright. Now when resetting the workspace and running the estimator training instead of model.fit, I get\r\n\r\n> INFO:tensorflow:Saving dict for global step 162: binary_accuracy = 0.7645, false_negatives = 55.25, false_negatives_streaming = 0.0, false_positives = 62.5, false_positives_streaming = 992.0, global_step = 162, loss = 0.52764004, precision = 0.7601666, precision_streaming = 0.504, recall = 0.78157234, recall_streaming = 1.0, true_negatives = 185.5, true_negatives_streaming = 0.0, true_positives = 196.75, true_positives_streaming = 1008.0\r\n> ...\r\n> (({'binary_accuracy': 0.9345, 'false_negatives': 21.25, **'false_negatives_streaming': 0.0**, 'false_positives': 11.5, '**false_positives_streaming': 992.0,** 'loss': 0.17386678, 'precision': 0.9526271, **'precision_streaming': 0.504**, 'recall': 0.915865, **'recall_streaming': 1.0,** 'true_negatives': 236.5, **'true_negatives_streaming': 0.0**, 'true_positives': 230.75, **'true_positives_streaming': 1008.0**, 'global_step': 2000}, [])\r\n\r\nSo in fact the model seems to train alright, but the eval_metrics (from the estimator) are messed up. According to the *_streaming metrics, all the model ever does is predict true for everything, even though that doesn't seem to be the case.\r\n\r\n\r\n", "I cannot speak for @wirtsi but the fact that you cannot seamlessly use `keras.applications` inside a `tf.estimator` remains a problem", "I have been digging around this for a while, it seems to be a general problem with using Keras models in Tensorflow. I have documented my findings here: \r\n\r\nhttps://stackoverflow.com/questions/54910215/tensorflow-estimator-fails-to-converge-on-model-converted-from-keras-when-using\r\n\r\nIn my case that means: Keras is totally happy to use a single neuron output layer for a binary classification task. If you use this model (which works in Keras!) and give it to an Estimator, it will not converge but only predict trues. You _must_ use two output neurons for this to work.\r\n\r\nI can only guess that this might have to do with different ways of backpropagation but at that depth level, I am lost ....\r\n\r\nSo without wanting to hijack this issue, I would assume that this might be a similiar problem.", "I see guide of tf2.0 [here](https://www.tensorflow.org/alpha/guide/migration_guide#using_a_custom_model_fn) about using custom model_fn with keras model. \r\nDon't know if it can help you, but there are some code snippets that lack detailed explanations.", "Update: Seems like even using code same as document above, keras application still can not use within estimator. \r\n\r\nTesting environment: tf 1.12 and 1.13, 2.0 not tested.", "Any updates on this?", "As far as I can tell, this issue persists in TF2 while using a custom training loop. If I define a MobilenetV2 Keras model myself (by copying the author's code), then I can train it just fine, but if I use tf.keras.applications.MobileNetV2(weights=None), it simply ignores the gradient tape, and I can't update the weights of the network at all.", "The problem in TF 1.x was related to `tf.keras` having a global session different to the one used by the estimator. Given that sessions are no longer a thing in 2.0 I am surprised its not working @cmcneil, you should report this as a separate bug.", "Any update on this? It seems that the problem still reserves now in TF2.3. @cgarciae @sgasse  @cmcneil ", "Any update on this issue? I'm using TF1 and seeing training issues whenever enabled Keras in estimator.", "@sgasse,\r\nCan you please confirm if this issue is still relevant in **`Tensorflow 2.x Version`**, as we predominantly use [Keras Layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers) instead of [Estimators](https://www.tensorflow.org/guide/estimator) and that [tf.keras.applications](https://www.tensorflow.org/api_docs/python/tf/keras/applications) works fine with TF Keras's, [Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) or [Functional](https://www.tensorflow.org/guide/keras/functional) Models?\r\n\r\nThanks!", "@rmothukuru  sry I am not working on the project that I worked on when I initially reported this issue.\r\n\r\nThe main issue back then was that Estimators handle multiple sessions (for parallel training and eval) while `tf.keras.applications` were backed by a single session handled by the `tf.keras` backend`. I know that many layer APIs are now predominantly available/used through `tf.keras` - though I guess this is still different from using a `tf.keras.applications` module.\r\n\r\nHas the architecture in that regard changed? E.g. would keras understand/allow to use several sessions if initialized in the model part of an estimator? @golden0080 have you maybe tested with TF2.X?", "@sgasse,\r\nEven **`Sessions`** are deprecated in **`Tensorflow 2.x`**.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/25670\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/25670\">No</a>\n"]}, {"number": 25669, "title": "Docker images with tags `1.13.0rc0` and `1.13.0rc0-py3` contains wrong version of TensorFlow Estimator", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Ubuntu 17.04**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **-**\r\n- TensorFlow installed from (source or binary): **Binary/Docker**\r\n- TensorFlow version: **???**\r\n- Python version: **2.7**, **3.5**\r\n- Installed using virtualenv? pip? conda?: **Docker**\r\n- Bazel version (if compiling from source): **-**\r\n- GCC/Compiler version (if compiling from source): **-**\r\n- CUDA/cuDNN version: **-**\r\n- GPU model and memory: **-**\r\n\r\nThe problem is that Docker [images](https://hub.docker.com/r/tensorflow/tensorflow/tags) with tags `1.13.0rc0` and `1.13.0rc0-py3` contains wrong version of `tensorflow_estimator` (this [repository](https://github.com/tensorflow/estimator)).\r\n\r\nJust to show:\r\n```\r\n$ docker run -it tensorflow/tensorflow:1.13.0rc0 bash\r\n\r\n________                               _______________                \r\n___  __/__________________________________  ____/__  /________      __\r\n__  /  _  _ \\_  __ \\_  ___/  __ \\_  ___/_  /_   __  /_  __ \\_ | /| / /\r\n_  /   /  __/  / / /(__  )/ /_/ /  /   _  __/   _  / / /_/ /_ |/ |/ / \r\n/_/    \\___//_/ /_//____/ \\____//_/    /_/      /_/  \\____/____/|__/\r\n\r\nroot@d1f1dd416bdd:/# pip show tensorflow_estimator\r\npip show tensorflow_estimator\r\nDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\r\nName: tensorflow-estimator\r\nVersion: 1.10.12\r\n```", "comments": ["I guess it's related to https://github.com/tensorflow/tensorflow/issues/25611.", "Edit: ignore this suggestion; I forgot that Pip dependency specifications exist.\r\n\r\nHmm. I'm not sure if we can handle this in a good way. TF submodules like `tensorflow-estimator`  aren't guaranteed (as far as I know) to have a pre-release version that aligns with TensorFlow's prerelease versions. And they're not guaranteed to be available when the final images are built, either -- they're not orchestrated by the same release team, I don't think.\r\n\r\nOne possible fix would be to adjust the CI such that Docker images based on pre-releases provide `--pre` to `pip install`, although that would apply to every available package specified in the command line.\r\n\r\n@gunan, do you have any thoughts on this?", "Actually, this problem was already discussed in https://github.com/tensorflow/tensorflow/issues/25165 and it looks like the correct version of estimator in our case is [1.13.0rc0](https://pypi.org/project/tensorflow-estimator/1.13.0rc0/).\r\n\r\nMy problem is that without correct version of `estimator` some functionality of distributed learning doesn't work in `tensorflow`. In my local case I fixed it building Docker image with `pip3 install tensorflow_estimator==1.13.0rc0` layer. \r\n\r\nBesides, Docker image of `tensorflow` version `1.13.0rc1` seems to have a correct version of `estimator` out of the box.", "Oh, I see. I forgot about the Pip installation specifications.\r\n\r\nIt looks like the dependency was incorrectly specified in rc0. That's a bug in TF, not in the Docker containers, so I don't think this needs any attention, especially since rc1 is working fine."]}, {"number": 25668, "title": "removing extra copy on unordered_set", "body": "removing extra copy on unordered_set", "comments": []}, {"number": 25667, "title": "Trigger point of object detection in tensorflow lite", "body": "I am doing object detection using tensorflow  lite. My code detects the object & add a label with it & also display the label with it, but after that, I want to display the label of an object which is detected separately.\r\n& I want that point (trigger point) in code from where the label is displayed .\r\ncan you please help me to find out code .\r\n I am giving link of  my source code :\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/android", "comments": ["@chiragmak10 Could you mention more details about the issue and its context. Please provide as many details as possible to find a solution faster. Also, I noticed that you forgot to provide link to your source code. The link you provided is from TF Lite examples. Thanks! ", "@chiragmak10 If your referring to the label on the tracked output, its being set at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/android/app/src/main/java/org/tensorflow/demo/tracking/MultiBoxTracker.java#L188", "Closing this support issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). Thanks!"]}, {"number": 25666, "title": "tf.GradientTape.gradient raises error with tf.math.segment_max", "body": "**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): installed by pip\r\n- TensorFlow version (use command below): 1.13-rc1\r\n- Python version: 3.6\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ntf.enable_eager_execution()\r\n\r\ninputs = np.random.randn(5)\r\ninputs_tensor = tf.Variable(inputs, dtype=tf.float32)\r\nseg_ids = tf.convert_to_tensor([0, 0, 0, 1, 1])\r\nwith tf.GradientTape() as tape:\r\n    y = tf.math.segment_max(inputs_tensor, seg_ids)\r\n    loss = (y - tf.convert_to_tensor([1., 1.], tf.float32)) ** 2\r\n    loss = tf.reduce_mean(loss, 0)\r\n\r\ngrads = tape.gradient(loss, inputs_tensor)\r\n```\r\n\r\n**Other info / logs**\r\n```\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-2-b33dd17ed2d8> in <module>\r\n      6     loss = tf.reduce_mean(loss, 0)\r\n      7 print(y)\r\n----> 8 grads = tape.gradient(loss, inputs_tensor)\r\n\r\n/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py in gradient(self, target, sources, output_gradients, unconnected_gradients)\r\n    944         flat_sources,\r\n    945         output_gradients=output_gradients,\r\n--> 946         unconnected_gradients=unconnected_gradients)\r\n    947 \r\n    948     if not self._persistent:\r\n\r\n/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/tensorflow/python/eager/imperative_grad.py in imperative_grad(tape, target, sources, output_gradients, unconnected_gradients)\r\n     70       sources,\r\n     71       output_gradients,\r\n---> 72       compat.as_str(unconnected_gradients.value))\r\n\r\n/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py in _gradient_function(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads)\r\n    129     return [None] * num_inputs\r\n    130 \r\n--> 131   return grad_fn(mock_op, *out_grads)\r\n    132 \r\n    133 \r\n\r\n/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py in _SegmentMaxGrad(op, grad)\r\n    277 def _SegmentMaxGrad(op, grad):\r\n    278   \"\"\"Gradient for SegmentMax.\"\"\"\r\n--> 279   return _SegmentMinOrMaxGrad(op, grad)\r\n    280 \r\n    281 \r\n\r\n/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py in _SegmentMinOrMaxGrad(op, grad)\r\n    257   print('op:', op)\r\n    258   print('op.outputs:', op.outputs)\r\n--> 259   gathered_outputs = array_ops.gather(op.outputs[0], op.inputs[1])\r\n    260   is_selected = math_ops.equal(op.inputs[0], gathered_outputs)\r\n    261   num_selected = math_ops.segment_sum(math_ops.cast(is_selected, grad.dtype),\r\n\r\nTypeError: 'NoneType' object is not subscriptable\r\n```\r\nI find that op.outputs for 'segment_max' is None, and is there any solution for that?", "comments": ["Can you see if this is fixed in master?", "The issue persists with TF 1.13.0-rc2 and tf-nightly build.", "I still see the same issue with unsorted_segment_max (and tf.reduce_max on ragged tensors).", "I think if you look at the change I listed you can see the steps to fix\nthis issue. Do you want to send a PR with a fix and a unit test?\n\nOn Wed, Feb 27, 2019 at 11:26 AM danecor <notifications@github.com> wrote:\n\n> I still see the same issue with unsorted_segment_max (and tf.reduce_max on\n> ragged tensors).\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/25666#issuecomment-467995374>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxa6GVkMaIswUBZoPVYwqkqMtWJMvks5vRtv1gaJpZM4a0MzS>\n> .\n>\n\n\n-- \n - Alex\n", "> I think if you look at the change I listed you can see the steps to fix this issue. Do you want to send a PR with a fix and a unit test?\r\n\r\nSure"]}, {"number": 25665, "title": "Type Error caused by using AttentionCellWrapper: Tensors cannot be iterated.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Manjaro Illyria 18.0.2\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:no mobile device related\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below): ('v1.12.0-0-ga6d8ffae09', '1.12.0')\r\n- Python version:2.7.15\r\n- Bazel version (if compiling from source):installed from binary\r\n- GCC/Compiler version (if compiling from source):installed from binary\r\n- CUDA/cuDNN version:no CUDA\r\n- GPU model and memory:no computing GPU\r\n\r\n**Describe the current behavior**\r\nI am trying to add tf.contrib.rnn.AttentionCellWrapper to tf.nn.rnn_cell.GRUCell. Before adding the wrapper, the program is completely running normally. After adding the wrapper, the program reports an error shown in the traceback below.\r\n\r\nThe error `Tensor objects are only iterable when eager execution is enabled` is confusing me, since I have tried enable the eager execution and the results are the same.\r\nI have changed GRUCell to LSMMCell or other RNN-related Cell and the results are the same.\r\nI have tried multiple tensorflow versions and the results are the same.\r\nThe code I am modifying is the same as [this code](https://github.com/Songweiping/GRU4Rec_TensorFlow/blob/master/model.py), and what I am trying is to add AttentionCellWrapper between 126 and 127 lines.\r\n\r\n**Describe the expected behavior**\r\nThe program should just work fine without any error. All the changes I made compared to the normal code were to add the AttentionCellWrapper.\r\nThe official documentation also has no explanation for the cause of this error.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nAs described above, the normal code with a AttentionCellWrapper, and the function that triggered the error is as follows. The complete code also covers other files in the [repo](https://github.com/Songweiping/GRU4Rec_TensorFlow).\r\n\r\n```\r\ndef build_model(self):\r\n        \r\n        self.X = tf.placeholder(tf.int32, [self.batch_size], name='input')\r\n        self.Y = tf.placeholder(tf.int32, [self.batch_size], name='output')\r\n        self.state = [tf.placeholder(tf.float32, [self.batch_size, self.rnn_size], name='rnn_state') for _ in xrange(self.layers)]\r\n        self.global_step = tf.Variable(0, name='global_step', trainable=False)\r\n\r\n        with tf.variable_scope('gru_layer'):\r\n            sigma = self.sigma if self.sigma != 0 else np.sqrt(6.0 / (self.n_items + self.rnn_size))\r\n            if self.init_as_normal:\r\n                initializer = tf.random_normal_initializer(mean=0, stddev=sigma)\r\n            else:\r\n                initializer = tf.random_uniform_initializer(minval=-sigma, maxval=sigma)\r\n            embedding = tf.get_variable('embedding', [self.n_items, self.rnn_size], initializer=initializer)\r\n            softmax_W = tf.get_variable('softmax_w', [self.n_items, self.rnn_size], initializer=initializer)\r\n            softmax_b = tf.get_variable('softmax_b', [self.n_items], initializer=tf.constant_initializer(0.0))\r\n\r\n            cell = rnn_cell.GRUCell(self.rnn_size, activation=self.hidden_act)\r\n            attn_cell = tf.contrib.rnn.AttentionCellWrapper(cell, attn_length=20)  # state_is_tuple is True by default\r\n            drop_cell = rnn_cell.DropoutWrapper(attn_cell, output_keep_prob=self.dropout_p_hidden)\r\n            stacked_cell = rnn_cell.MultiRNNCell([drop_cell] * self.layers)\r\n            \r\n            inputs = tf.nn.embedding_lookup(embedding, self.X)\r\n            output, state = stacked_cell(inputs, tuple(self.state))\r\n            self.final_state = state\r\n\r\n        if self.is_training:\r\n            '''\r\n            Use other examples of the minibatch as negative samples.\r\n            '''\r\n            sampled_W = tf.nn.embedding_lookup(softmax_W, self.Y)\r\n            sampled_b = tf.nn.embedding_lookup(softmax_b, self.Y)\r\n            logits = tf.matmul(output, sampled_W, transpose_b=True) + sampled_b\r\n            self.yhat = self.final_activation(logits)\r\n            self.cost = self.loss_function(self.yhat)\r\n        else:\r\n            logits = tf.matmul(output, softmax_W, transpose_b=True) + softmax_b\r\n            self.yhat = self.final_activation(logits)\r\n\r\n        if not self.is_training:\r\n            return\r\n\r\n        self.lr = tf.maximum(1e-5,tf.train.exponential_decay(self.learning_rate, self.global_step, self.decay_steps, self.decay, staircase=True)) \r\n        \r\n        '''\r\n        Try different optimizers.\r\n        '''\r\n        #optimizer = tf.train.AdagradOptimizer(self.lr)\r\n        optimizer = tf.train.AdamOptimizer(self.lr)\r\n        #optimizer = tf.train.AdadeltaOptimizer(self.lr)\r\n        #optimizer = tf.train.RMSPropOptimizer(self.lr)\r\n\r\n        tvars = tf.trainable_variables()\r\n        gvs = optimizer.compute_gradients(self.cost, tvars)\r\n        if self.grad_cap > 0:\r\n            capped_gvs = [(tf.clip_by_norm(grad, self.grad_cap), var) for grad, var in gvs]\r\n        else:\r\n            capped_gvs = gvs \r\n        self.train_op = optimizer.apply_gradients(capped_gvs, global_step=self.global_step)\r\n```\r\n\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/syh/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/183.5429.31/helpers/pydev/pydevd.py\", line 1741, in <module>\r\n    main()\r\n  File \"/home/syh/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/183.5429.31/helpers/pydev/pydevd.py\", line 1735, in main\r\n    globals = debugger.run(setup['file'], None, None, is_module)\r\n  File \"/home/syh/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/183.5429.31/helpers/pydev/pydevd.py\", line 1135, in run\r\n    pydev_imports.execfile(file, globals, locals)  # execute the script\r\n  File \"/run/media/syh/0D11080D0D11080D/workspace/Recommender-System/exp/GRU4Rec_TensorFlow-master/main.py\", line 86, in <module>\r\n    gru4rec = model.GRU4Rec(sess, args)\r\n  File \"/run/media/syh/0D11080D0D11080D/workspace/Recommender-System/exp/GRU4Rec_TensorFlow-master/model.py\", line 72, in __init__\r\n    self.build_model()\r\n  File \"/run/media/syh/0D11080D0D11080D/workspace/Recommender-System/exp/GRU4Rec_TensorFlow-master/model.py\", line 142, in build_model\r\n    output, state = multi_cell(inputs, tuple(self.state))\r\n  File \"/run/media/syh/0D11080D0D11080D/workspace/Recommender-System/exp/venv/lib/python2.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 233, in __call__\r\n    return super(RNNCell, self).__call__(inputs, state)\r\n  File \"/run/media/syh/0D11080D0D11080D/workspace/Recommender-System/exp/venv/lib/python2.7/site-packages/tensorflow/python/layers/base.py\", line 374, in __call__\r\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\r\n  File \"/run/media/syh/0D11080D0D11080D/workspace/Recommender-System/exp/venv/lib/python2.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 757, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"/run/media/syh/0D11080D0D11080D/workspace/Recommender-System/exp/venv/lib/python2.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 1486, in call\r\n    cur_inp, new_state = cell(cur_inp, cur_state)\r\n  File \"/run/media/syh/0D11080D0D11080D/workspace/Recommender-System/exp/venv/lib/python2.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 1282, in __call__\r\n    output, new_state = self._cell(inputs, state, scope=scope)\r\n  File \"/run/media/syh/0D11080D0D11080D/workspace/Recommender-System/exp/venv/lib/python2.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 233, in __call__\r\n    return super(RNNCell, self).__call__(inputs, state)\r\n  File \"/run/media/syh/0D11080D0D11080D/workspace/Recommender-System/exp/venv/lib/python2.7/site-packages/tensorflow/python/layers/base.py\", line 374, in __call__\r\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\r\n  File \"/run/media/syh/0D11080D0D11080D/workspace/Recommender-System/exp/venv/lib/python2.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 757, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"/run/media/syh/0D11080D0D11080D/workspace/Recommender-System/exp/venv/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/rnn_cell.py\", line 1190, in call\r\n    state, attns, attn_states = state\r\n  File \"/run/media/syh/0D11080D0D11080D/workspace/Recommender-System/exp/venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 459, in __iter__\r\n    \"Tensor objects are only iterable when eager execution is \"\r\nTypeError: Tensor objects are only iterable when eager execution is enabled. To iterate over this tensor use tf.map_fn.\r\n```\r\n", "comments": ["Could you:\r\n* print out what \"state\" is?\r\n* trace down where the state comes from and who creates it?", "`state`: `<type 'tuple'>: (<tf.Tensor 'rnn_state:0' shape=(50, 100) dtype=float32>,)`\r\n\\_\\_len\\_\\_ = 1\r\n\r\n`state` is returned by this statement `output, state = multi_cell(inputs, tuple(self.state))`\r\nwhere \r\n`self.state = [tf.placeholder(tf.float32, [self.batch_size, self.rnn_size], name='rnn_state') for _ in xrange(self.layers)]`\r\n`multi_cell = rnn_cell.MultiRNNCell([cell] * self.layers)`\r\n`inputs = tf.nn.embedding_lookup(embedding, self.X)`\r\n\r\n`state` is created by `class RNNCell` in `tensorflow/python/ops/rnn_cell_impl.py`\r\nHowever, I can't see `state` is created by which statement in class `RNNCell` through the debugger.", "I come across the same issue with you, but I was trying to use `AttentionCellWrapper` for `tf.nn.dynamic_rnn`:\r\n```python\r\n                # RNN\r\n                gru_cell = rnn.GRUCell((self.rnn_size), activation=self.hidden_act)\r\n                # attention\r\n                if self.ATTENTION:\r\n                    atten_cell = rnn.AttentionCellWrapper(gru_cell, attn_length=40, state_is_tuple=True)\r\n                    drop_cell = rnn.DropoutWrapper(atten_cell, output_keep_prob=self.dropout)\r\n                else:\r\n                    drop_cell = rnn.DropoutWrapper(gru_cell, output_keep_prob=self.dropout)\r\n                \r\n                rnn_outputs, final_state = tf.nn.dynamic_rnn(drop_cell, inputs, sequence_length=self.seqlen,\r\n                                                            initial_state=self.init_state)\r\n                \r\n```\r\nIf `self.ATTENTION` is False, everything is ok, but once added `AttentionCellWrapper` to the cell, it would get the same error message above.", "> I come across the same issue with you, but I was trying to use `AttentionCellWrapper` for `tf.nn.dynamic_rnn`:\r\n> \r\n> ```python\r\n>                 # RNN\r\n>                 gru_cell = rnn.GRUCell((self.rnn_size), activation=self.hidden_act)\r\n>                 # attention\r\n>                 if self.ATTENTION:\r\n>                     atten_cell = rnn.AttentionCellWrapper(gru_cell, attn_length=40, state_is_tuple=True)\r\n>                     drop_cell = rnn.DropoutWrapper(atten_cell, output_keep_prob=self.dropout)\r\n>                 else:\r\n>                     drop_cell = rnn.DropoutWrapper(gru_cell, output_keep_prob=self.dropout)\r\n>                 \r\n>                 rnn_outputs, final_state = tf.nn.dynamic_rnn(drop_cell, inputs, sequence_length=self.seqlen,\r\n>                                                             initial_state=self.init_state)\r\n>                 \r\n> ```\r\n> \r\n> If `self.ATTENTION` is False, everything is ok, but once added `AttentionCellWrapper` to the cell, it would get the same error message above.\r\n\r\nIf the architecture of your model is seq2seq, maybe you could try to use tf.contrib.seq2seq.AttentionWrapper instead.", "> > I come across the same issue with you, but I was trying to use `AttentionCellWrapper` for `tf.nn.dynamic_rnn`:\r\n> > ```python\r\n> >                 # RNN\r\n> >                 gru_cell = rnn.GRUCell((self.rnn_size), activation=self.hidden_act)\r\n> >                 # attention\r\n> >                 if self.ATTENTION:\r\n> >                     atten_cell = rnn.AttentionCellWrapper(gru_cell, attn_length=40, state_is_tuple=True)\r\n> >                     drop_cell = rnn.DropoutWrapper(atten_cell, output_keep_prob=self.dropout)\r\n> >                 else:\r\n> >                     drop_cell = rnn.DropoutWrapper(gru_cell, output_keep_prob=self.dropout)\r\n> >                 \r\n> >                 rnn_outputs, final_state = tf.nn.dynamic_rnn(drop_cell, inputs, sequence_length=self.seqlen,\r\n> >                                                             initial_state=self.init_state)\r\n> >                 \r\n> > ```\r\n> > \r\n> > \r\n> > If `self.ATTENTION` is False, everything is ok, but once added `AttentionCellWrapper` to the cell, it would get the same error message above.\r\n> \r\n> If the architecture of your model is seq2seq, maybe you could try to use tf.contrib.seq2seq.AttentionWrapper instead.\r\n\r\nThanks for your suggestion, but I'm not trying to build a `seq2seq`, my model is for item recommendation, so I don't need a decoder (or in other word my decoder is just an item embedding vector which is doing inner product with the RNN encoder's output vector) . And what I'm doing is trying to add Attention mechanism to my RNN encoder (GRU/LSTM), so in this kind of situation, what kind of wrapper should I use? ( I've tried `AttentionCellWrapper` but it got me wrong )", "> > > I come across the same issue with you, but I was trying to use `AttentionCellWrapper` for `tf.nn.dynamic_rnn`:\r\n> > > ```python\r\n> > >                 # RNN\r\n> > >                 gru_cell = rnn.GRUCell((self.rnn_size), activation=self.hidden_act)\r\n> > >                 # attention\r\n> > >                 if self.ATTENTION:\r\n> > >                     atten_cell = rnn.AttentionCellWrapper(gru_cell, attn_length=40, state_is_tuple=True)\r\n> > >                     drop_cell = rnn.DropoutWrapper(atten_cell, output_keep_prob=self.dropout)\r\n> > >                 else:\r\n> > >                     drop_cell = rnn.DropoutWrapper(gru_cell, output_keep_prob=self.dropout)\r\n> > >                 \r\n> > >                 rnn_outputs, final_state = tf.nn.dynamic_rnn(drop_cell, inputs, sequence_length=self.seqlen,\r\n> > >                                                             initial_state=self.init_state)\r\n> > >                 \r\n> > > ```\r\n> > > \r\n> > > \r\n> > > If `self.ATTENTION` is False, everything is ok, but once added `AttentionCellWrapper` to the cell, it would get the same error message above.\r\n> > \r\n> > \r\n> > If the architecture of your model is seq2seq, maybe you could try to use tf.contrib.seq2seq.AttentionWrapper instead.\r\n> \r\n> Thanks for your suggestion, but I'm not trying to build a `seq2seq`, my model is for item recommendation, so I don't need a decoder (or in other word my decoder is just an item embedding vector which is doing inner product with the RNN encoder's output vector) . And what I'm doing is trying to add Attention mechanism to my RNN encoder (GRU/LSTM), so in this kind of situation, what kind of wrapper should I use? ( I've tried `AttentionCellWrapper` but it got me wrong )\r\n\r\nIn fact, this is also what I am trying to do. But I did not find that TensorFlow r1.12 has any similar wrapper. And of course, pytorch does not have a similar wrapper...", "This issue persists after updating the tensorflow version to 1.13.1.", "Any updates on this?", "> Any updates on this?\r\n\r\nIn fact, the API has been canceled in tensorflow 2.0 and the problem has not been resolved.", "> > Any updates on this?\r\n> \r\n> In fact, the API has been canceled in tensorflow 2.0 and the problem has not been resolved.\r\n\r\nGood to know. Thanks", "Hi There,\n\n We are checking to see if you still need help on this issue, as you are using an older version of tensorflow(1.x) which is officially considered as end of life. We recommend that you upgrade to 2.4 or later version and let us know if the issue still persists in newer versions. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, Please open a new issue for any help you need against 2.x, and we will get you the right help. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/25665\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/25665\">No</a>\n"]}, {"number": 25664, "title": "[InputContext] Add input_context examples in simple_estimator_example.py", "body": "Hi @yuefengz ,\r\n  This PR is just an example of using input_context in Estimator and it has been tested locally. This [PR](https://github.com/tensorflow/estimator/pull/15) \r\nshows the details of integration with `Estimator`. Please merge that before accept this mofification. Thanks.\r\n", "comments": ["Integration test has been added. @yuefengz ", "@yuefengz More comments have been added.", "@yuefengz gentle ping to review new changes ", "Can one of the admins verify this patch?", "closing this PR as `contrib` folder will be depricated in 2.0, thank you. \r\nCC @mihaimaruseac "]}, {"number": 25663, "title": "[FR] Adding alpha channel support", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: latest from apt\r\n- **Python version**: 3.6.4\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**: not relevant\r\n- **CUDA/cuDNN version**: not relevant\r\n- **GPU model and memory**: not relevant\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nI am creating an artistic neural network and it would be amazing to handle the transparency. Unfortunately as I noticed, Tensorflow doesn't have such feature. Is there any particular reason why it's not a thing? Or would you mind considering adding it?\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["Can you clarify where you want alpha channel support?", "Sure!\r\n\r\nRight now I am working with images mainly and I got a dataset with many images with transparency. However I cannot get images with transparency as an output back even though I did nothing that can cause the loss of them. The original transparent pixels are now always blue.", "I want to work on this issue please can somebody guide me in this?\r\n"]}, {"number": 25662, "title": "Lite: Pack Operator Negative Axis Support", "body": "1:> TFLite: Pack operator Negative axis support added.\r\n2:> Test cases added for the same feature.", "comments": ["Nagging Reviewer @jianlijianli: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 14 days with no activity and the `awaiting review` label has been applied.", "Closing as Tensorflow internally committed the same changes."]}, {"number": 25660, "title": "TFL Detect app crash while using NNAPI", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Ubuntu 16.04**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **Xiaomi Mi 8**\r\n- TensorFlow installed from (source or binary): **binary**\r\n- TensorFlow version (use command below): **1.12**\r\n- Python version: **3.5**\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: **9.0/7.5**\r\n- GPU model and memory: **GTX 1050 - 4GB**\r\n\r\n\r\n**Describe the current behavior**\r\nI am trying to build the [TF Lite detect app](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/android) with using NNAPI, but when I set useNNAPI to **true** it crashes with an exception:\r\n`Process: org.tensorflow.lite.demo, PID: 32661\r\n    java.lang.IllegalArgumentException: Internal error: Failed to run on the given Interpreter: \r\n        at org.tensorflow.lite.NativeInterpreterWrapper.run(Native Method)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:145)\r\n        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:229)\r\n        at org.tensorflow.demo.TFLiteObjectDetectionAPIModel.recognizeImage(TFLiteObjectDetectionAPIModel.java:196)\r\n        at org.tensorflow.demo.DetectorActivity$3.run(DetectorActivity.java:247)\r\n        at android.os.Handler.handleCallback(Handler.java:873)\r\n        at android.os.Handler.dispatchMessage(Handler.java:99)\r\n        at android.os.Looper.loop(Looper.java:201)\r\n        at android.os.HandlerThread.run(HandlerThread.java:65)`\r\n\r\nBut, when I set useNNAPI to **false** it runs without any issue. On the other hand, I also tried to use NNAPI with [TFL Classifier app](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/android/app/src/main/java/org/tensorflow/demo/TFLiteImageClassifier.java) and it runs flawlessly (it means there is no problem with my phone). The question is that, is it possible to use NNAPI with detector app or not? \r\n\r\n**Code to reproduce the issue**\r\nChanged few lines in [TFLiteObjectDetectionAPIModel.java](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/android/app/src/main/java/org/tensorflow/demo/TFLiteObjectDetectionAPIModel.java#L120):\r\n`\r\nd.tfliteOptions.setUseNNAPI(true);\r\n    try {\r\n       d.tfLite = new Interpreter(loadModelFile(assetManager, modelFilename), d.tfliteOptions);\r\n    } catch (Exception e) {\r\n      throw new RuntimeException(e);\r\n    }\r\n`\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Post-processing ops of the model used by the TF Lite detect app are not supported by NNAPI.", "Thanks for your answer. Do you have any update when will NNAPI support that Post-processing op?", "The new NNAPI delegate should support this path, and doesn't require the full model be delegated.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/25660\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/25660\">No</a>\n"]}, {"number": 25659, "title": "Keras Concatenate : AttributeError: 'list' object has no attribute 'shape'", "body": "I am using Google Colab.\r\nHere is a small code I have written:\r\n```python\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, Conv1D, Reshape, Concatenate\r\n\r\nbranch1 = Sequential()\r\nbranch1.add(Conv1D(2,3,activation='tanh',input_shape=(100, 1)))\r\nbranch1.add(Conv1D(4,3,activation='tanh'))\r\nbranch1.add(Conv1D(6,3,activation='tanh'))\r\nbranch1.add(Dropout(0.2))\r\nbranch1.add(Conv1D(8,3,activation='tanh'))\r\nbranch1.add(Conv1D(10,3,activation='relu'))\r\nbranch1.add(Flatten())\r\nbranch1.add(Dense(10))\r\n\r\n\r\nbranch2 = Sequential()\r\nbranch2.add(Dense(10,input_dim=1))\r\nbranch2.add(Dense(10,activation='linear'))\r\n\r\n# Concatenate([branch1,branch2])\r\n\r\n\r\nmodel = Sequential()\r\nmodel.add(Concatenate([branch1, branch2]))\r\nmodel.add(Dense(1,activation='relu'))\r\n# branch1.add(Dropout(0.4))\r\nmodel.add(Dense(1,activation='relu'))\r\nmodel.compile(loss='mean_squared_error', optimizer='rmsprop')\r\n\r\nmodel_info = model.fit([data_cnn,data_mw], target, epochs=1000, batch_size=100, verbose=2,validation_data=([val_data_cnn,val_data_mw],val_target))\r\n```\r\n\r\nSome Info about data : \r\n*  `data_cnn` : type = numpy.ndarray | shape = (2580, 100, 1) \r\n*  `data_mw` : type = numpy.ndarray | shape = (2580, 1)\r\n*  `val_data_cnn` : type = numpy.ndarray | shape = (645, 100, 1)\r\n*  `val_data_mw` : type = numpy.ndarray | shape = (645, 1)\r\n\r\nLink to the notebook : https://colab.research.google.com/drive/1kpopbk_4u7Tsuaxoc9EbRCKzN1aZ4kSM", "comments": ["And here is the traceback that I got:\r\n```python\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-93-668d2c5caf25> in <module>()\r\n      1 \r\n----> 2 model_info = model.fit([data_cnn,data_mw], target, epochs=1000, batch_size=100, verbose=2,validation_data=([val_data_cnn,val_data_mw],val_target))\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    774         steps=steps_per_epoch,\r\n    775         validation_split=validation_split,\r\n--> 776         shuffle=shuffle)\r\n    777 \r\n    778     # Prepare validation data.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle)\r\n   2287         else:\r\n   2288           cast_inputs = x\r\n-> 2289         self._set_inputs(cast_inputs)\r\n   2290     else:\r\n   2291       dict_inputs = isinstance(self.inputs, dict)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/checkpointable/base.py in _method_wrapper(self, *args, **kwargs)\r\n    440     self._setattr_tracking = False  # pylint: disable=protected-access\r\n    441     try:\r\n--> 442       method(self, *args, **kwargs)\r\n    443     finally:\r\n    444       self._setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _set_inputs(self, inputs, outputs, training)\r\n   2501         input_shape = (None,)\r\n   2502       else:\r\n-> 2503         input_shape = (None,) + tuple(inputs.shape[1:])\r\n   2504       self._build_input_shape = input_shape\r\n   2505 \r\n\r\nAttributeError: 'list' object has no attribute 'shape'\r\n```", "`model.fit` requires numpy arrays. This error occurs when you are using normal python lists and not numpy arrays. You might want to check if `data_cnn`, `data_mw` etc. were all initialized as proper numpy arrays using `np.array()`.\r\n\r\nAssuming that they indeed are proper numpy arrays, you should use `np.concatenate` and not `[data_cnn, data_mw]` if you are trying to concatenate them. ", "Hey, @Sudeepam97 they are indeed proper numpy arrays. \r\nAnd I don't need to concatenate the arrays. I need to pass multiple inputs to my models.\r\nSo I don't see how `np.concatenate` would help :confused: \r\n\r\nHere is a link to the notebook.  https://colab.research.google.com/drive/1kpopbk_4u7Tsuaxoc9EbRCKzN1aZ4kSM", "`data_cnn` and `data_mw` are numpy arrays, your error is because of the fact that writing\r\n`[data_cnn, data_mw]` concatenates them and returns a python list.\r\n\r\nTry to run this to get a better understanding of what I mean...\r\n```\r\nimport numpy as np\r\na = np.array([ [[1, 2]], [[2, 3]], [[3, 4]] ])\r\nprint (a)\r\nprint (a.shape)\r\nb = np.array([ [[2]], [[3]], [[4]] ])\r\nprint (b)\r\nprint (b.shape)\r\nc = [a, b]\r\nprint (c)\r\nprint (c.shape)", "I get that `[data_cnn, data_mw]` is a list. \r\nBut **that is how you are supposed to** pass inputs to the `model.fit()` in case your model has multiple inputs. _(If you see my model definition you can see there are two branches which I accept two inputs)_\r\n\r\nSee this : https://stackoverflow.com/a/43196972/6507303\r\n\r\nAlso see the Concatenation documentation at : https://keras.io/layers/merge/#Concatenate\r\nIt says it accepts \"a list of inputs\".", "> I get that `[data_cnn, data_mw]` is a list.\r\n> But **that is how you are supposed to** pass inputs to the `model.fit()` in case your model has multiple inputs. _(If you see my model definition you can see there are two branches which I accept two inputs)_\r\n> \r\n> See this : https://stackoverflow.com/a/43196972/6507303\r\n> \r\n> Also see the Concatenation documentation at : https://keras.io/layers/merge/#Concatenate\r\n> It says it accepts \"a list of inputs\".\r\n\r\nOh, pardon me. Indeed in this case, this is how you'll pass inputs to `fit()`. I can't help you any more without actually running your code and I'll have to study this architecture so please allow some time. Meanwhile, Someone else may also help you out. As a final note, I am not observing any `model.compile` statement, maybe your error is because your model with two inputs is not compiled?", "Sorry, I forgot to include the `compile()` here. It's there in the actual code.\r\nDoesn't make a difference.", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose). Thanks!\r\n"]}, {"number": 25658, "title": "test\u65f6\u4ee3\u5927\u53a6\u591a", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n", "comments": ["Please provide useful information in your issue."]}, {"number": 25657, "title": "TFLite GPU Delegate will block the thread who is calling interpreter.run()", "body": "**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- Mobile device: OnePlus 3, One Plus 5 and Pixel 2 XL\r\n- TensorFlow Lite version on Android: 0.0.0-gpu-experimental\r\n- Have I written custom code: a GitHub repo contains the codes to reproduce the issue. \r\nhttps://github.com/dailystudio/ml/tree/master/deeplab\r\n- DeepLab v3 TFLite model: [DeepLab segmentation (257x257)](https://storage.googleapis.com/download.tensorflow.org/models/tflite/gpu/deeplabv3_257_mv_gpu.tflite)\r\n\r\n**Describe the current behavior**\r\nUsing the following code snippet to create an Interpreter with GPU delegate\r\n```java\r\n        Interpreter.Options options = new Interpreter.Options();\r\n\r\n        GpuDelegate delegate = new GpuDelegate();\r\n        options.addDelegate(delegate);\r\n        \r\n\r\n        Interpreter interpreter = new Interpreter(mModelBuffer, options);\r\n```\r\nCalling the run() of the Interpreter with following lines of codes:\r\n```java\r\n        interpreter.run(mImageData, mOutputs);\r\n```\r\nIf these two code snippets are called in two different threads, the thread which calls interpreter.run() will be blocked. interpreter.run() will never return.\r\nIf these two code snippets are called in the same thread, interpreter.run() will be executed properly and output correct results.\r\n\r\n**Describe the expected behavior**\r\nDevelopers needn't care about which threads are used for calling these APIs. Even these APIs are called in different threads, interpreter.run() should return correctly with blocking issue.\r\n\r\n**Code to reproduce the issue**\r\nThe full code can be found here:\r\nhttps://github.com/dailystudio/ml/blob/master/deeplab/app/src/main/java/com/dailystudio/deeplab/ml/DeepLabLite.java\r\nCurrently, the code in repository works fine because the new Interpreter() and interpreter.run() are called in the same thread. \r\nThe DeepLabLite class has two important functions: **initialize()** and **segment()**. In **intialize()**, we read TFLite model from asset/ directory into a MappedByteBuffer:\r\n```java\r\n\r\n    @Override\r\n    public boolean initialize(Context context) {\r\n        if (context == null) {\r\n            return false;\r\n        }\r\n\r\n        mModelBuffer = loadModelFile(context, MODEL_PATH);\r\n        if (mModelBuffer == null) {\r\n            return false;\r\n        }\r\n\r\n        ...\r\n    }\r\n```\r\nIn **segment()**, we use that MappedByteBuffer to create an Interpreter and call run() for inference:\r\n```java\r\n        ...\r\n        Interpreter.Options options = new Interpreter.Options();\r\n\r\n        if (USE_GPU) {\r\n            GpuDelegate delegate = new GpuDelegate();\r\n            options.addDelegate(delegate);\r\n        }\r\n\r\n        Interpreter interpreter = new Interpreter(mModelBuffer, options);\r\n        ...\r\n        final long start = System.currentTimeMillis();\r\n        interpreter.run(mImageData, mOutputs);\r\n        final long end = System.currentTimeMillis();\r\n        ...\r\n```\r\nThe DeepLabLite.initialize() is called in an AsyncTask after application is launched, while the DeepLabLite.segment() is called a Loader after users pick an image for segmentation. These codes will be no problem.  \r\nBut if we keep the codes of calling these two methods unchanged and move the following line from **segment()** to **initialize()**:\r\n```java\r\n        Interpreter interpreter = new Interpreter(mModelBuffer, options);\r\n```\r\n> P.S.: Of course, we need to declare a class member to hold this Interpreter for future using in segment().\r\n\r\nThen the calling of interpreter.run() will be blocked forever. \r\n\r\n**Other information**\r\nWith my tests, I suspect this problem is independent of devices. It would happen on all Android devices. It should be related to GpuDelegate. If you do not call options.addDelegate() to add a GpuDelegate, the interpreter.run() will also run well.", "comments": ["@dailystudio \r\n\r\n> Developers needn't care about which threads are used for calling these APIs.\r\n\r\nUnfortunately, that is not the case when using OpenGL.  OpenGL is a state machine, and a proper GL context needs to be kept around.  This GL context is bound to the thread that it was created on.\r\n\r\nhttps://www.khronos.org/opengl/wiki/OpenGL_and_multithreading\r\n\r\nThere are mechanisms to transfer GL contexts or use parent / children GL contexts for multithreaded architectures, but at the current level of developer preview, the exposed APIs probably don't give you enough control to do this.  Open sourcing GPU is just around the corner, at which point you will have more fine-grained control of the GPU processing with respect to your multithreaded programming model.", "> @dailystudio\r\n> \r\n> > Developers needn't care about which threads are used for calling these APIs.\r\n> \r\n> Unfortunately, that is not the case when using OpenGL. OpenGL is a state machine, and a proper GL context needs to be kept around. This GL context is bound to the thread that it was created on.\r\n> \r\n> https://www.khronos.org/opengl/wiki/OpenGL_and_multithreading\r\n> \r\n> There are mechanisms to transfer GL contexts or use parent / children GL contexts for multithreaded architectures, but at the current level of developer preview, the exposed APIs probably don't give you enough control to do this. Open sourcing GPU is just around the corner, at which point you will have more fine-grained control of the GPU processing with respect to your multithreaded programming model.\r\n\r\nHmm..., but I am not using OpenGL in my demo application. I understand your points, but from my point of view, as a developer who is using TFLite, I only care about how to use your APIs to achieve my own goals. In my codes, there are no OpenGL related codes. So, let me learn and understand the concept of OpenGL contexts or multi-threads architectures seems like an imposition. \r\nI think my case is quite typical. First, you load a model from assets and create an Interpreter for using in the future. Then when you really need it, you call run() to inference the results. Calling these two steps in the main thread is absolutely not acceptable, especially in a real product. That means in most cases, these two steps will be called in different threads and probably be called in two different threads You couldn't suppose every developer who uses TFLite will have acknowledgment about everything. If I am using OpenGL to write the application, yes, I may be aware that there would be some multi-thread issues. But I am just a developer who is writing a standard application which is using TF to segment image. To be honest, I had used an entire afternoon to find out the root cause of this issue. Just because I am quite interested and have enthusiastic in Tensorflow.\r\nI am not challenging the work what you have already done. I just want it to be better and can be accepted by more people. My suggestions are:\r\n- You can handle the OpenGL context issues in the implementation of TFLite libraries. Of course, I am not an expert in this direction and that may be perfect but impossible. ;)\r\n- You can throw a runtime exception to warn the developer that they are using the API incorrectly and they should keep creation and inference in the same thread.\r\nBut no matter which solution you finally decide to use, just simply adding some tips on the related section of the Tensorflow official website to tell the developers about this. \r\n\r\nThanks for your patient to pay attention to my issue and I hope my advice could help the TFLite become better in the future.", "@dailystudio \r\n\r\nThat's actually pretty good feedback and one of the reason's why we put out a developer \"preview\" to gather feedback like yours.  We really appreciate it.\r\n\r\n> You can handle the OpenGL context issues in the implementation of TFLite libraries.\r\n\r\nThe fact that you have to be mindful of the GL context is inevitable, especially when you work in multithreaded settings.  We actually tried our best to hide that away from the users (and that's why you don't see the GL context in the API), but maybe hiding that was a bad thing.  If the API requires you to provide the GL context (or maybe the thread that owns the GL context), maybe that might have been better.\r\n\r\n> You can throw a runtime exception to warn the developer that they are using the API incorrectly and they should keep creation and inference in the same thread.\r\n\r\nThat's a great idea.  We'll see how we can add that check without losing performance.  Doing a GL context check before every `runInference` is probably not the right way to go ;)\r\n\r\n> But no matter which solution you finally decide to use, just simply adding some tips on the related section of the Tensorflow official website to tell the developers about this.\r\n\r\nWill do.\r\n\r\n\r\nFor now, I guess the easiest trick you can employ (if you want to go down the path of multithreading) is to have a dedicated thread that does initialization and inference all there, and you send a signal to the thread to run the inference.\r\n", "@impdji\r\nGreat! I am looking forward to these updates. ; ) ", "+1 to adding some sort of warning or runtime exception that @dailystudio already mentioned. I ran into this today so luckily there was already an issue open for it :) When I hit the issue while trying out gpu delegate, my app just froze and after debugging, saw that it was on ```tflite.run```.", "+1 as well, took me quite a while to find out why .run is not returning. anyway guys, keep up the good job, it is really appreciated and it is really cool to watch how TF is evolving. 2 yrs ago something ondevice GPU support was hard to imagine for me.", "One note to this that might or might NOT relate to the single thread issue.\r\n\r\nOn most older devices (however with Open GL 3.2 capable), when inference is run on GPU, preview frame rate tend to drop after few seconds. So even though it runs inference faster than on CPU, it probably blocks Texture View somehow. Is there some general recommendation on which GPUs is makes sense to use GPUDelegate?", "@bazinac \r\n\r\nWe have seen frame rate dropping when the device overheats.  Otherwise, we have not experienced performance degradations from other factors.  I mostly work on C++ layer, so I don't know whether Java can cause any issues, but given that the MobileNet demo app just runs fine in Java, I'm wondering whether it's device overheating.\r\n\r\nre: recommendation.  The ideal use case is the following:\r\n\r\n1. You get the camera input in the form of a surface texture.\r\n2. Create an OpenGL shader storage buffer object (SSBO).\r\n3. Use `GPUDelegate.bindGlBufferToTensor()` to associate that SSBO with the input tensor.\r\n4. Write a small shader program to dump surface texture of [1] into that SSBO of [2] efficiently.\r\n5. Run inference.\r\n\r\nThere is also similar optimization you can do for output.\r\n\r\nOnce project is fully open sourced, you should even have access to the command buffer queue, and can directly render the output of the network, if your network's output is something that can be directly rendered on screen.  We didn't expose that through API, because it would be too complicated without showing the code what's going on.", "Thanks for prompt answer. However I am not refering to situation, that could be caused by overheating. Even when running here provided demo on some older devices (like Samsung Galaxy J5 2017, Galaxy Tab S2), frame rate drops right after few seconds (like 3-5) when you switch to GPU. When using CPU, this does not happen. \r\n\r\nAlso thanks for recommendation for some input feeding optimalization, will try. ", "@bazinac \r\n\r\nIf it's not an overheat issue, we have seen slowdowns sometimes:\r\n- On some Huawei devices, GPU frequency drops to half after boot up, comes back after a while, and repeats this fluctuation.\r\n- On some devices, we had a driver bug that would slowly leak memory, and eventually blows up after several hundreds of thousand calls.\r\n\r\nHowever, none of these is really applicable to your situation =/\r\n\r\nIs your phone's OpenGL driver up to date?", "Anyone who has subscribed to this:\r\n\r\nI have just submitted the change with checking whether init's EGLContext is the same as invoke's EGLContext.  The phrase \"submitted\" applies to the internal code for now.  I'm not sure when this will go live to the public; we are trying to decide whether we should do another dev preview release, or whether we should just go with open source, as we're pretty close ;)", "Not officially announced yet, but FYI: GPU code is now visible at:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/delegates/gpu\r\n\r\nif you need the code for better insight what is happening.", "Now that the code of checking gl context is live, I'm gonna close this issue.  Please reopen if things don't work as expected.", "@impjdi Could you provide some example on how to work with SSBO in TFLite classification android app..", "@SanthoshRajendiran \r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/26297\r\n\r\nhas some shader code and its invocation around it.  The shader code there is mapping GlTexture to SSBO.", "But it only works sometimes... :/", "@jsolves \r\n\r\nFrom past reports, we know that it hangs when you don't have the right OpenGL context than when it was initialized.  Make sure that your interpreter initialization & interpreter invoke (well, run in Java) is happening on the same thread.  We had a way of throwing an exception, but that collided with something else, so that we had to revert that change :(", "Yes, I know. I was refering to #26297."]}, {"number": 25656, "title": "Distributed training using grpc+verbs got an assertion in verbs/rdma.cc:1557", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): \r\nCustom code using tf.estimator.DNNLinearCombinedClassifier\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): privileged ubuntu 16.04 docker \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): \r\nsource built with verbs feature\r\nbazel build --config=mkl -c opt --config=verbs //tensorflow/tools/pip_package:build_pip_package\r\n\r\n- TensorFlow version (use command below): 1.12.0\r\n- Python version: python3.6\r\n- Bazel version (if compiling from source): 0.18\r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 5.4.0-6ubuntu1~16.04.10)\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: CPU only\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\nb'v1.12.0-5-g7317495' 1.12.0\r\n\r\n**Describe the current behavior**\r\nI deployed one chief, one PS and one worker with protocol 'grpc+verbs'. This case uses only CPU device. The master and PS works properly. The worker meets an assertion, and exits.\r\nSwitched to protocol grpc, the code works well.\r\nThe result of rping shows that RDMA configure is good.\r\n\r\n```\r\n2019-02-11 14:16:19.248897: F tensorflow/contrib/verbs/rdma.cc:1557] Check failed: mr_ != nullptr  No memory region found for address 0x7f1b40000bc0: /job:ps/replica:0/task:0/device:CPU:0;dc5bce4913999973;/job:worker/replica:0/task:0/device:CPU:0;edge_247_report_uninitialized_variables_1/VarIsInitializedOp_4;0:0\r\n```\r\n\r\n**Describe the expected behavior**\r\nThe worker should run normally.\r\n\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\n    server = tf.train.Server(cluster_spec,\r\n                           job_name=job_name,\r\n                           task_index=task_index,\r\n                            protocol = 'grpc+verbs')\r\n\r\n  estimator = tf.estimator.DNNLinearCombinedClassifier(...)\r\n  estimator.train()\r\n```\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n[worker-20190211-141600.log](https://github.com/tensorflow/tensorflow/files/2850045/worker-20190211-141600.log)\r\n\r\n", "comments": ["@highfly22 Could you please check if this workload runs free of errors in a non-mkl build?", "It seems the contrib/verbs modules is out of date. \r\n\r\nThe method RdmaMgr::RegMemVisitors of verbs/rdma_mgr.cc try to register allocation visitor in the ProcessState. But the ProcessState allocator is not the default one any more.\r\n\r\nI added a class ProcessStateAllocatorFactory, and register this class. Then the assertion dismissed.\r\nThis issue will appear in the mkl build.\r\n\r\n```\r\nnamespace {\r\nclass ProcessStateAllocatorFactory : public AllocatorFactory {\r\n public:\r\n  Allocator* CreateAllocator() {\r\n    return ProcessState::singleton()->GetCPUAllocator(0);\r\n  }\r\n\r\n  SubAllocator* CreateSubAllocator(int numa_node) {\r\n    return 0;\r\n  }\r\n};\r\n\r\nREGISTER_MEM_ALLOCATOR(\"ProcessStateCPUAllocator\", 200, ProcessStateAllocatorFactory);\r\n}\r\n```", "I believe it\u2019s fixed in current master with #24250. Could you try again?", "@jvishnuvardhan I believe this issue has been fixed. Could you close it?", "Thanks @byronyi . I am closing the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=25656\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=25656\">No</a>\n"]}, {"number": 25655, "title": "Set max and min default range of values for UINT8 TFlite quantization", "body": "tflite_convert takes many arguments by default to perform the model conversion.\r\nThis commit set default values of the min and max quantization ranges.", "comments": ["@suharshs - Can you please take a look at this? While applying a range seems reasonable, I'm not sure it's best to use the hard-coded value here.", "Closing, since this is not what default_range_stats is intended for. And this will result in unexpected poor accuracy."]}, {"number": 25654, "title": "Added missing scenarios for the tensor_content", "body": "Added the TCs for validation of content set via tensor_content()\r\nThis is also a TODO item in the TC mentioned", "comments": ["Over to @miaout17 as I'l be OOO for the next several weeks.", "@shahzadlone , thanks for your review comments, i have updated the code as per your comments, kindly approve the PR", "@shahzadlone , @miaout17 & @pragyaak , I have updated the code as per the review comments, can you pls review and approve the PR.", "Thanks for the contribution!\r\n\r\nThere is a corner case to be tested. If the number of elements in data is less than the number of elements in shape, the last element need to be repeated. \r\nFor example, if the shape is {2, 3} and data is [1, 2], it would be interpreted as\r\n\r\n    [[1, 2, 2]\r\n     [2, 2, 2]]\r\n\r\nSee also the code [here](https://github.com/tensorflow/tensorflow/blob/1acee1498ce0ec9b0eac391091f1de9c0e2069d6/tensorflow/lite/toco/import_tensorflow.cc#L338)\r\n\r\nCould you help to add this test case?\r\n\r\n", "@miaout17 , thanks for spending time on the PR for review, I understood what you are telling but i guess that scenario is already covered by ContentImportTest , where they are removing the elements and the last element is getting repeated. Some of the examples are : -\r\n1. TEST_F(ContentImportTest, Int32) \r\n2. TEST_F(ContentImportTest, Int64)\r\n.... and other data types, \r\nIf you want i can add a TC like the below : -\r\nTEST_F(ContentImportTest, LessBool) {\r\nconstexpr ArrayDataType kType = ArrayDataType::kBool;\r\n NodeDef node;\r\nBuildConstNode({1, 2, 3}, DT_BOOL, 2, &node);\r\nEXPECT_THAT(ImportAndGetData<kType>(node), ElementsAre(1, 0, 0, 0, 0, 0));\r\n}\r\n\r\nLet me know your opinion.\r\n\r\nRegards\r\nAmit \r\n\r\n"]}, {"number": 25653, "title": "Minor updates to TF2 upgrade script", "body": "Just before merging the bigger part, that is going to arrive the next days", "comments": ["I was also wondering if we should return errors in the case of `SyntaxError` -> https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/compatibility/ast_edits.py#L513\r\n\r\ncc @martinwicke "]}, {"number": 25652, "title": "export_saved_model raises TypeError: Failed to convert object of type <class 'dict_values'> to Tensor.", "body": "`TPUEstimator.export_saved_model` raises `TypeError` (when used on CPU). The same code with TPUEstimator replaced with Estimator works correctly.\r\n\r\nThe error is:\r\n\r\n```\r\nTypeError: Failed to convert object of type <class 'dict_values'> to Tensor. Contents: dict_values([<tf.Tensor 'sat_prob:0' shape=(?,) dtype=float32>, <tf.Tensor 'policy_prob:0' shape=(?, ?, 2) dtype=float32>]). Consider casting elements to a supported type.\r\n```\r\n\r\n**The relevant code**\r\n\r\n```\r\ndef serving_input_receiver_fn():\r\n    feature = tf.placeholder(tf.float32, shape=[None, None, None, 2])\r\n\r\n    return tf.estimator.export.TensorServingInputReceiver(feature, feature)\r\n\r\nestimator.export_saved_model(FLAGS.export_dir, serving_input_receiver_fn)\r\n```\r\n\r\n\r\n**Current behaviour**\r\n\r\n`export_saved_model` fails with `TypeError`. \r\n\r\n**Expected behaviour**\r\n\r\n`export_saved_model` should export the model successfully.\r\n\r\n**System information**\r\n\r\nMacOS, Python 3.6, Tensorflow 1.12.0 from PyPI.\r\n\r\n**Full code**\r\n\r\nSince exporting a model requires a trained model, it wasn't easy to fully isolate the failing code, so I'm posting a full model file (with as much irrelevant stuff removed as possible).\r\n\r\nWith TPUEstimator, failing: https://gist.github.com/mluszczyk/d60ed4205060eb7ef53c309c490fbe48\r\n\r\nWith Estimator, working: https://gist.github.com/mluszczyk/bbd4f9136fc4788251079ac5b2176a01\r\n\r\n**Traceback**\r\n\r\n```\r\n...\r\nWARNING:tensorflow:From /Users/michal/.virtualenvs/deepsat/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py:1044: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPass your op to the equivalent parameter main_op instead.\r\nINFO:tensorflow:Assets added to graph.\r\nINFO:tensorflow:No assets to write.\r\nWARNING:tensorflow:rewrite_for_inference (from tensorflow.contrib.tpu.python.tpu.tpu) is experimental and may change or be removed at any time, and without warning.\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:Running infer on CPU\r\nERROR:tensorflow:Operation of type Placeholder (policy_labels) is not supported on the TPU. Execution will fail if this op is used in the graph. \r\nERROR:tensorflow:Operation of type Placeholder (sat_labels) is not supported on the TPU. Execution will fail if this op is used in the graph. \r\nINFO:tensorflow:Done calling model_fn.\r\nTraceback (most recent call last):\r\n  File \"/Users/michal/.virtualenvs/deepsat/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\", line 527, in make_tensor_proto\r\n    str_values = [compat.as_bytes(x) for x in proto_values]\r\n  File \"/Users/michal/.virtualenvs/deepsat/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\", line 527, in <listcomp>\r\n    str_values = [compat.as_bytes(x) for x in proto_values]\r\n  File \"/Users/michal/.virtualenvs/deepsat/lib/python3.6/site-packages/tensorflow/python/util/compat.py\", line 61, in as_bytes\r\n    (bytes_or_text,))\r\nTypeError: Expected binary or unicode string, got dict_values([<tf.Tensor 'sat_prob:0' shape=(?,) dtype=float32>, <tf.Tensor 'policy_prob:0' shape=(?, ?, 2) dtype=float32>])\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"neurosat_tpu.py\", line 253, in <module>\r\n    tf.app.run()\r\n  File \"/Users/michal/.virtualenvs/deepsat/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"neurosat_tpu.py\", line 248, in main\r\n    estimator.export_saved_model(FLAGS.export_dir, serving_input_receiver_fn)\r\n  File \"/Users/michal/.virtualenvs/deepsat/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 734, in export_saved_model\r\n    strip_default_attrs=True)\r\n  File \"/Users/michal/.virtualenvs/deepsat/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 663, in export_savedmodel\r\n    mode=model_fn_lib.ModeKeys.PREDICT)\r\n  File \"/Users/michal/.virtualenvs/deepsat/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 789, in _export_saved_model_for_mode\r\n    strip_default_attrs=strip_default_attrs)\r\n  File \"/Users/michal/.virtualenvs/deepsat/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 907, in _export_all_saved_models\r\n    mode=model_fn_lib.ModeKeys.PREDICT)\r\n  File \"/Users/michal/.virtualenvs/deepsat/lib/python3.6/site-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2188, in _add_meta_graph_for_mode\r\n    check_variables=False))\r\n  File \"/Users/michal/.virtualenvs/deepsat/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 984, in _add_meta_graph_for_mode\r\n    config=self.config)\r\n  File \"/Users/michal/.virtualenvs/deepsat/lib/python3.6/site-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2192, in _call_model_fn\r\n    return self._call_model_fn_for_inference(features, labels, mode, config)\r\n  File \"/Users/michal/.virtualenvs/deepsat/lib/python3.6/site-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2253, in _call_model_fn_for_inference\r\n    new_tensors.append(array_ops.identity(t))\r\n  File \"/Users/michal/.virtualenvs/deepsat/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 81, in identity\r\n    return gen_array_ops.identity(input, name=name)\r\n  File \"/Users/michal/.virtualenvs/deepsat/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3454, in identity\r\n    \"Identity\", input=input, name=name)\r\n  File \"/Users/michal/.virtualenvs/deepsat/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 513, in _apply_op_helper\r\n    raise err\r\n  File \"/Users/michal/.virtualenvs/deepsat/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 510, in _apply_op_helper\r\n    preferred_dtype=default_dtype)\r\n  File \"/Users/michal/.virtualenvs/deepsat/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1146, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/Users/michal/.virtualenvs/deepsat/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 229, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n  File \"/Users/michal/.virtualenvs/deepsat/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 208, in constant\r\n    value, dtype=dtype, shape=shape, verify_shape=verify_shape))\r\n  File \"/Users/michal/.virtualenvs/deepsat/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\", line 531, in make_tensor_proto\r\n    \"supported type.\" % (type(values), values))\r\nTypeError: Failed to convert object of type <class 'dict_values'> to Tensor. Contents: dict_values([<tf.Tensor 'sat_prob:0' shape=(?,) dtype=float32>, <tf.Tensor 'policy_prob:0' shape=(?, ?, 2) dtype=float32>]). Consider casting elements to a supported type.\r\n```\r\n\r\n**Output of the variant with Estimator**\r\n\r\n```\r\nWARNING:tensorflow:From /Users/michal/.virtualenvs/deepsat/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py:1044: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPass your op to the equivalent parameter main_op instead.\r\nINFO:tensorflow:Assets added to graph.\r\nINFO:tensorflow:No assets to write.\r\nINFO:tensorflow:SavedModel written to: ../models/export/ex20/temp-b'1549813434'/saved_model.pb\r\n```\r\n\r\n**Flags**\r\nFlag values to the attached files:\r\n```\r\npython neurosat_tpu.py --use_tpu=False --tpu=$TPU_NAME --train_file=$TRAIN_FILE --test_file=$TEST_FILE --train_steps=10 --test_steps=0 --model_dir=$MODEL_DIR --variable_number=8 --clause_number=80 --train_files_gzipped=False --batch_size=1 --iterations=1 --export_dir=$EXPORT_DIR --level_number=0\r\n```", "comments": ["@mluszczyk When I run it in google colab with TPU, i see different kinds of error for both the codes. Are you sure it is related to Bug/performance? If it is a support kind of question, please ask it in [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!", "Thanks for looking into it, @jvishnuvardhan. I created two public colabs reproducing the behaviour. I believe this is a bug.\r\n\r\nThe error can be seen here: https://colab.research.google.com/drive/1FEvd47JRZtAJZcwB10gqKDhSCWx_cRCW\r\n\r\nWorking version is here:\r\nhttps://colab.research.google.com/drive/1bzpxlevnmDriBUrg3RihxXGOI4pmtYQQ\r\n\r\nI've found out that the error occurs with tensorflow 1.12.0 and not with 1.13.0rc0, which is installed on Colab by default. So the working version in Colab uses TPUEstimator with Tensorflow 1.13.0rc0 rather than non-TPU Estimator with Tensorflow 1.12.0 as in the original issue description (which should be as good, I can create the colab with Estimator if you'd like, too).\r\n\r\nSo it looks like the error is fixed in 1.13. However, TPUs with TF 1.13 are not available in Google Cloud, so I still cannot use my model. I think a backport of the fix (or a workaround) would be very useful.", "When I tried to use `TPUEstimator.export_saved_model`, I saw the same error:\r\n\r\n```\r\nTypeError: Failed to convert object of type <class 'dict_values'> to Tensor. Contents: dict_values([<tf.Tensor 'Softmax:0' shape=(?, 10) dtype=float32>]). Consider casting elements to a supported type.\r\n```\r\n\r\nIs there another way to export SavedModel from TPUEstimator?", "I found we can avoid the error as below:\r\n\r\n```python\r\nestimator = tf.contrib.tpu.TPUEstimator(..., export_to_tpu=False)\r\n```\r\n\r\nWe (except Googlers) need not to serve our model on TPU, so I guess the above idea might be helpful.", "Marking this as fixed as it has been fixed in 1.13 and using `export_to_tpu=False` resolves the issue for earlier versions."]}, {"number": 25649, "title": "How to fix - ImportError: DLL load failed, when importing keras", "body": "\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64\r\n- TensorFlow installed from (source or binary): Using pip, binary\r\n- TensorFlow version: 1.12.0\r\n- Python version: 3.6.0\r\n- Installed using virtualenv? pip? conda?: Installed Using Pip and virtualenv\r\n- CUDA/cuDNN version:  ??\r\n- GPU model and memory: Intel(R) HD Graphics, 1664 MB\r\n\r\nI am trying to install keras with tensorflow backend\r\n\r\nI have run `pip install keras` at first, and then `pip install tensorflow` both commands finished succesfully, now when i'm trying to import Sequential from keras.models I get error\r\n\r\nHere is my code\r\n![image](https://user-images.githubusercontent.com/41778180/52533028-41b7c000-2d47-11e9-9b98-08ea334e8eb8.png)\r\n\r\nHere is error\r\n\r\n```\r\nUsing TensorFlow backend.\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: \u041f\u0440\u043e\u0438\u0437\u043e\u0448\u0435\u043b \u0441\u0431\u043e\u0439 \u0432 \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0435 \u0438\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0438 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0438 \u0434\u0438\u043d\u0430\u043c\u0438\u0447\u0435\u0441\u043a\u043e\u0439 \u043a\u043e\u043c\u043f\u043e\u043d\u043e\u0432\u043a\u0438 (DLL).\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:/Users/Admin/PycharmProjects/keras/test.py\", line 3, in <module>\r\n    from keras.models import Sequential\r\n  File \"C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\backend\\__init__.py\", line 89, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: \u041f\u0440\u043e\u0438\u0437\u043e\u0448\u0435\u043b \u0441\u0431\u043e\u0439 \u0432 \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0435 \u0438\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0438 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0438 \u0434\u0438\u043d\u0430\u043c\u0438\u0447\u0435\u0441\u043a\u043e\u0439 \u043a\u043e\u043c\u043f\u043e\u043d\u043e\u0432\u043a\u0438 (DLL).\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n```\r\n\r\nI don't know why error is in Russian, maybe it is because of my system language, but here is translation\r\n\r\n`Original error:\r\nImportError: DLL load failed: \u041f\u0440\u043e\u0438\u0437\u043e\u0448\u0435\u043b \u0441\u0431\u043e\u0439 \u0432 \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0435 \u0438\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0438 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0438 \u0434\u0438\u043d\u0430\u043c\u0438\u0447\u0435\u0441\u043a\u043e\u0439 \u043a\u043e\u043c\u043f\u043e\u043d\u043e\u0432\u043a\u0438 (DLL)`\r\n\r\n`Translation:\r\nImportError: DLL load failed: A crash occurred in the dynamic link library initialization program. (DLL)`\r\n\r\nI am using\r\n\r\n![image](https://user-images.githubusercontent.com/41778180/52533043-804d7a80-2d47-11e9-80c7-161e436504b3.png)\r\n\r\nAnd Python 3.6.0\r\n\r\nWhat can I do to solve this issue?", "comments": ["Can you try ```from tensorflow.keras import Sequential```", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 25648, "title": "Merge pull request #1 from tensorflow/master", "body": "Merge with latest changes", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "@rthangam please sign the cla in order to proceed with the PR. Thanks!", "closing this PR as there are no changes to merge"]}, {"number": 25647, "title": "Use rate instead of keep_prob in rnn_cell_impl.py", "body": "While running rnn_cell_test found the following warning:\r\n```\r\ntensorflow/python/ops/rnn_cell_impl.py:1376: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\r\n```\r\n\r\nThis fix replaces deprecated dropout with dropout_v2, and use rate instead\r\nto fix the warning.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["@ebrevdo Thanks for the review. The PR has be updated. Please take a look.", "Nagging Reviewer @ebrevdo: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 29 days with no activity and the `awaiting review` label has been applied."]}, {"number": 25646, "title": "Fix issue of rnn.ResidualWrapper not compatible with keras.layers", "body": "This fix tries to fix the issue raised in #25641 where rnn.ResidualWrapper\r\nis not compatible with keras.layers. The issue was that parent class may not\r\nbe invoked to process zero_state.\r\n\r\nThis fix fixes #25641.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Any reason to not call super() always?", "Thanks @ebrevdo for the review. With direct super the following test:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/kernel_tests/core_rnn_cell_test.py#L977-L987\r\n\r\nwill fail:\r\n```\r\nFAIL: testDropoutWrapperZeroState(<class 'tensorflow.python.ops.rnn_cell_impl.DropoutWrapper'>) (__main__.DropoutWrapperTest)\r\ntestDropoutWrapperZeroState(<class 'tensorflow.python.ops.rnn_cell_impl.DropoutWrapper'>) (__main__.DropoutWrapperTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/ubuntu/.cache/bazel/_bazel_ubuntu/ad1e09741bb4109fbc70ef8216b59ee2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/rnn/core_rnn_cell_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 971, in decorated\r\n    f(self, *args, **kwargs)\r\n  File \"/home/ubuntu/.cache/bazel/_bazel_ubuntu/ad1e09741bb4109fbc70ef8216b59ee2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/rnn/core_rnn_cell_test.runfiles/absl_py/absl/testing/parameterized.py\", line 266, in bound_param_test\r\n    test_method(self, testcase_params)\r\n  File \"/home/ubuntu/.cache/bazel/_bazel_ubuntu/ad1e09741bb4109fbc70ef8216b59ee2/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/rnn/core_rnn_cell_test.runfiles/org_tensorflow/tensorflow/contrib/rnn/python/kernel_tests/core_rnn_cell_test.py\", line 998, in testDropoutWrapperZeroState\r\n    \"wrapped_cell_zero_state\")\r\nAssertionError: <tf.Tensor 'DropoutWrapperZeroState/Dropo[52 chars]at32> != 'wrapped_cell_zero_state'\r\n```", "Adding @arthurarg, who worked on updating the wrapper to support keras layer/cell.", "Yes my update was on allowing Wrapper to be used in keras.layers.RNN.\r\n\r\nI don't think it can yet be applied to keras cells for now, at least for the following reasons:\r\n- keras state format is different from rnn cell state format\r\n- keras cells don't have a zero_state\r\n(i actually had started it in a change before reverting this part for simplicity).\r\n\r\nI was thinking of doing this change at some point but didn't prioritize it as current keras cells have a dropout argument.", "@arthurarg  and  @qlzh727  please suggest the steps ahead. ", "Sorry for the late reply, I will take a look very soon. In the meantime, can u fix the merge conflict? Thanks.", "One more thing: `ResidualWrapper` does not set `self.built` flag, breaking `model.summary()`, etc.", "Thanks for the contribution. The underlying issue has been fixed by https://github.com/tensorflow/tensorflow/commit/42a1de008f301fb2d4c575ef5f817b5513156328 and https://github.com/tensorflow/tensorflow/commit/76a22b340814425b6a8b6e0c0bb81bcd162c458b. I think this PR can be closed now."]}, {"number": 25645, "title": "Inconsistent eigh gradients", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Mojave\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): `conda install -c conda-forge tensorflow` in a Python 3.6 environment\r\n- TensorFlow version (use command below): v1.10.0-rc1-19-g656e7a2b34 1.10.0\r\n- Python version: Python 3.6.8 :: Anaconda, Inc.\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nI'm porting an optimization involving calls to `eigh` from the [`autograd`](https://github.com/HIPS/autograd) library to Tensorflow. When computing the gradient of a loss function involving a subset of eigenvectors, I see fairly large large differences (in terms of `norm(grad_np - grad_tf)`).\r\n\r\nIn my application, this causes the optimization to fail completely under TensorFlow while succeeding with the `autograd` library (using same optimizer, step size etc). \r\n\r\n**Describe the expected behavior**\r\nDifferent numerical implementations of derivatives should be consistent.  Comparing all other operations in the AD graph between autograd and TF showed no problems, and the same would be expected for eigh.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ndef loss_z_np(z, G, w, ne=3):\r\n    from autograd import jacobian, grad\r\n    def loss(z):\r\n        import autograd.numpy as np\r\n        d = 2*z - np.sum(w, axis=1)\r\n        e, v = np.linalg.eigh(np.diag(d) + w)\r\n        ssev = np.sum(np.square(e[-ne:] * v[:, -ne:]), axis=-1)\r\n        return np.sum(np.dot(G, ssev))\r\n    return grad(loss)(z)\r\n\r\ndef lsa_loss(z, G, w, ne=3):\r\n    d = 2*z - tf.reduce_sum(w, 1)\r\n    e, v = tf.linalg.eigh(tf.diag(d) + w)\r\n    ssev = tf.reduce_sum(tf.square(e[-ne:] * v[:, -ne:]), 1)\r\n    return tf.reduce_sum(tf.matmul(G, tf.expand_dims(ssev, 1)))\r\n\r\ndef loss_z_tf(z, G, w, ne=3):\r\n    G, w = [tf.convert_to_tensor(_, dtype=tf.float32) for _ in (G, w)]\r\n    z = tf.Variable(tf.convert_to_tensor(z, dtype=tf.float32))\r\n    loss = lsa_loss(z, G, w, ne=ne)\r\n    lg = tf.gradients(loss, z)\r\n    model = tf.global_variables_initializer()\r\n    trace = []\r\n    with tf.Session() as session:\r\n        session.run(model)\r\n        lg_np = session.run(lg)\r\n    return lg_np\r\n\r\n\r\nm, n = 79, 164\r\nnorms = []\r\nfor _ in range(30):\r\n    G = np.random.rand(m, n).astype('f')\r\n    w = np.random.rand(n, n).astype('f')\r\n    z = - np.random.rand(n).astype('f')\r\n    lg_np = loss_z_np(z, G, w, ne=10)\r\n    lg_tf = loss_z_tf(z, G, w, ne=10)\r\n    norms.append(np.linalg.norm(lg_np - lg_tf))\r\nprint('average norm', sum(norms)/len(norms))\r\n```\r\nThis prints an average of ~30~ 16.\r\n\r\n**Other info / logs**\r\n\r\nn/a\r\n\r\n_edit_ to switch the NumPy code to float32; problem persists.", "comments": ["@maedoc I think it was due to incorrect dtype used in the code. The dtype of lg_np was float64 where as dtype of lg.tf was float32. Because of the mismatch in the dtype, the difference in precision level of each result affect the norm. I modified the code here.\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ndef loss_z_np(z, G, w, ne=3):\r\n    from autograd import jacobian, grad\r\n    def loss(z):\r\n        import autograd.numpy as np\r\n        d = 2*z - np.sum(w, axis=1)\r\n        e, v = np.linalg.eigh(np.diag(d) + w)\r\n        ssev = np.sum(np.square(e[-ne:] * v[:, -ne:]), axis=-1)\r\n        return np.sum(np.dot(G, ssev))\r\n    return grad(loss)(z)\r\n\r\ndef lsa_loss(z, G, w, ne=3):\r\n    d = 2*z - tf.reduce_sum(w, 1)\r\n    e, v = tf.linalg.eigh(tf.diag(d) + w)\r\n    ssev = tf.reduce_sum(tf.square(e[-ne:] * v[:, -ne:]), 1)\r\n    return tf.reduce_sum(tf.matmul(G, tf.expand_dims(ssev, 1)))\r\n\r\ndef loss_z_tf(z, G, w, ne=3):\r\n    G, w = [tf.convert_to_tensor(_, dtype=tf.float64) for _ in (G, w)]\r\n    z = tf.Variable(tf.convert_to_tensor(z, dtype=tf.float64))\r\n    loss = lsa_loss(z, G, w, ne=ne)\r\n    lg = tf.gradients(loss, z)\r\n    model = tf.global_variables_initializer()\r\n    trace = []\r\n    with tf.Session() as session:\r\n        session.run(model)\r\n        lg_np = session.run(lg)\r\n    return lg_np\r\n\r\n\r\nm, n = 79, 164\r\nnorms = []\r\nfor _ in range(30):\r\n    G = np.random.rand(m, n).astype(np.float64)\r\n    np.array([1,], dtype=np.uint64)\r\n    w = np.random.rand(n, n).astype(np.float64)\r\n    z = - np.random.rand(n).astype(np.float64)\r\n    lg_np = loss_z_np(z, G, w, ne=10)\r\n    lg_tf = loss_z_tf(z, G, w, ne=10)\r\n    norms.append(np.linalg.norm(lg_np - lg_tf))\r\nprint('average norm', sum(norms)/len(norms))\r\n\r\nPlease let me know what you think. If you are agree with the solution, please close the issue. Thanks!\r\n", "Thanks for your reply.  Indeed switching float64 does produce a smaller norm. However, I realized that comparing autograd and TF is not necessary to demonstrate the issue, here is a repro which compares TF's gradient to a finite difference, \r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ndef loss_np(z, G, w, ne=3):\r\n    e, v = np.linalg.eigh(np.diag(2*z - np.sum(w, axis=1)) + w)\r\n    ssev = np.sum(np.square(e[-ne:] * v[:, -ne:]), axis=1)\r\n    return np.sum(np.dot(G, ssev))\r\n\r\ndef fd_grad(z, G, w, ne=3, d=1e-3):\r\n    f = lambda z: loss_np(z, G, w, ne=ne)\r\n    d_i = lambda i: d * (np.r_[:z.size] == i)\r\n    f_z = f(z)\r\n    return np.array([(f(z + d_i(i)) - f_z) / d for i in np.r_[:z.size]])\r\n\r\ndef loss_tf(z, G, w, ne=3):\r\n    e, v = tf.linalg.eigh(tf.diag(2*z - tf.reduce_sum(w, 1)) + w)\r\n    ssev = tf.reduce_sum(tf.square(e[-ne:] * v[:, -ne:]), 1)\r\n    return tf.reduce_sum(tf.matmul(G, tf.expand_dims(ssev, 1)))\r\n\r\ndef tf_grad(z, G, w, ne=3):\r\n    z, G, w = [tf.convert_to_tensor(_, dtype=tf.float64) for _ in (z, G, w)]\r\n    z = tf.Variable(z)\r\n    grad = tf.gradients(loss_tf(z, G, w), z)\r\n    model = tf.global_variables_initializer()\r\n    with tf.Session() as session:\r\n        session.run(model)\r\n        grad = session.run(grad)\r\n    return grad\r\n\r\n\r\nm, n = 79, 164\r\nG = np.random.rand(m, n).astype(np.float64)\r\nw = np.random.rand(n, n).astype(np.float64)\r\nz = - np.random.rand(n).astype(np.float64)\r\n\r\nprint(np.linalg.norm(fd_grad(z, G, w, d=1e-3) - tf_grad(z, G, w)))\r\n```\r\nwhich shows errors too large to be accounted for by machine precision, IMO.\r\n\r\nI have noticed the errors in the gradient are consistently smaller when the matrix input to `tf.linalg.eigh` is positive definite.  Is there an undocumented assumption about the input?", "I have compared the TensorFlow gradient result with PyTorch gradient result. There is no big difference between them. So I don't think this is a TensorFlow bug. Maybe there is something wrong with the numpy calculation.\r\n\r\nThis is my code to compare:\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport torch\r\nfrom torch.autograd import Variable as V\r\n\r\ndef loss_np(z, G, w, ne=3):\r\n    e, v = np.linalg.eigh(np.diag(2*z - np.sum(w, axis=1)) + w)\r\n    ssev = np.sum(np.square(e[-ne:] * v[:, -ne:]), axis=1)\r\n    return np.sum(np.dot(G, ssev))\r\n\r\ndef fd_grad(z, G, w, ne=3, d=1e-3):\r\n    f = lambda z: loss_np(z, G, w, ne=ne)\r\n    d_i = lambda i: d * (np.r_[:z.size] == i)\r\n    f_z = f(z)\r\n    return np.array([(f(z + d_i(i)) - f_z) / d for i in np.r_[:z.size]])\r\n\r\ndef loss_tf(z, G, w, ne=3):\r\n    e, v = tf.linalg.eigh(tf.linalg.diag(2*z - tf.reduce_sum(w, 1)) + w)\r\n    ssev = tf.reduce_sum(tf.square(e[-ne:] * v[:, -ne:]), 1)\r\n    return tf.reduce_sum(tf.matmul(G, tf.expand_dims(ssev, 1)))\r\n\r\ndef tf_grad(z, G, w, ne=3):\r\n    z, G, w = [tf.convert_to_tensor(_, dtype=tf.float64) for _ in (z, G, w)]\r\n    z = tf.Variable(z)\r\n    with tf.GradientTape() as g:\r\n        g.watch(z)\r\n        out = loss_tf(z, G, w)\r\n    return g.gradient(out, z).numpy()\r\n\r\ndef loss_pt(z, G, w, ne=3):\r\n    e, v = torch.symeig(torch.diag(2*z - torch.sum(w, dim=1)) + w, eigenvectors=True, upper=False)\r\n    ssev = torch.sum(torch.pow(e[-ne:] * v[:, -ne:], 2), dim=1)\r\n    return torch.sum(torch.matmul(G, ssev.reshape((164, 1))))\r\n\r\ndef pt_grad(z, G, w, ne=3):\r\n    z = V(torch.from_numpy(z), requires_grad=True)\r\n    G = V(torch.from_numpy(G), requires_grad=True)\r\n    w = V(torch.from_numpy(w), requires_grad=True)\r\n    #out = loss_pt(z1, G1, w1)\r\n    e, v = torch.symeig(torch.diag(2*z - torch.sum(w, dim=1)) + w, eigenvectors=True, upper=False)\r\n    ssev = torch.sum(torch.pow(e[-ne:] * v[:, -ne:], 2), dim=1)\r\n    out = torch.matmul(G, ssev.reshape((164, 1))).sum()\r\n    out.backward()\r\n    return np.array(z.grad)\r\n\r\n\r\nm, n = 79, 164\r\nG = np.random.rand(m, n).astype(np.float64)\r\nw = np.random.rand(n, n).astype(np.float64)\r\nz = - np.random.rand(n).astype(np.float64)\r\n\r\nprint(np.linalg.norm(fd_grad(z, G, w, d=1e-3) - tf_grad(z, G, w)))\r\nprint(np.linalg.norm(pt_grad(z, G, w) - tf_grad(z, G, w)))\r\n```\r\n\r\nThe outputs are:\r\n```\r\n16.9599469169133\r\n1.789755161380324e-08\r\n```", "Thanks for taking a look.  I tried PyTorch as well, but didn't include here since this is the TF repo.  That both TF & PT produce similar results is hardly suprising if they use the same underlying cuSolver library? </guess>\r\n\r\nIn any case, I came across this because when I tried to optimize my loss function, autograd (based on numpy) had no problem and produced correct results, whereas TF & PT both failed to make progress.  Given the three are all gradient-based, the only explanation is that TF & PT eigh solvers produce wrong results for non-positive-definite matrices. ", "Hi There,\n\n We are checking to see if you still need help on this issue, as you are using an older version of tensorflow(1.x) which is officially considered as end of life. We recommend that you upgrade to 2.4 or later version and let us know if the issue still persists in newer versions. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, Please open a new issue for any help you need against 2.x, and we will get you the right help. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/25645\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/25645\">No</a>\n"]}, {"number": 25644, "title": "Illegal ambiguous match on configurable attribute \"deps\" in //tensorflow/tools/pip_package:included_headers_gather", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- Ubuntu 18.04:\r\n- \r\n- TensorFlow installed from source\r\n- TensorFlow version:\r\n- Python version: 3.6.7\r\n- Installed using virtualenv:\r\n- Bazel version : 0.22.0\r\n- GCC/Compiler version : 7.3\r\n- CUDA/cuDNN version: 7.4\r\n- GPU model and memory: RTX 2080 Ti\r\n\r\n\r\n\r\n./configure\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nINFO: Invocation ID: 9cf9c46b-c379-4fdc-a9f5-13ad76711061\r\nYou have bazel 0.22.0 installed.\r\nPlease specify the location of python. [Default is /home/peter/PycharmProjects/Virtual_envs/tensorflow/bin/python]: \r\n\r\n\r\nFound possible Python library paths:\r\n  /home/peter/PycharmProjects/Virtual_envs/tensorflow/lib/python3.6/site-packages\r\n  /usr/local/lib/python3.6/dist-packages\r\n  /usr/lib/python3/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/home/peter/PycharmProjects/Virtual_envs/tensorflow/lib/python3.6/site-packages]\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [Y/n]: y\r\nXLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: n\r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: n\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nPlease specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 10.0]: 10.0\r\n\r\n\r\nPlease specify the location where CUDA 10.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\n\r\n\r\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7]: 7.4\r\n\r\n\r\nPlease specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\n\r\n\r\nDo you wish to build TensorFlow with TensorRT support? [y/N]: n\r\nNo TensorRT support will be enabled for TensorFlow.\r\n\r\nPlease specify the locally installed NCCL version you want to use. [Default is to use https://github.com/nvidia/nccl]: \r\n\r\n\r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 7.5]: \r\n\r\n\r\nDo you want to use clang as CUDA compiler? [y/N]: y\r\nClang will be used as CUDA compiler.\r\n\r\nDo you wish to download a fresh release of clang? (Experimental) [y/N]: y\r\nClang will be downloaded and used to compile tensorflow.\r\n\r\nDo you wish to build TensorFlow with MPI support? [y/N]: n\r\nNo MPI support will be enabled for TensorFlow.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]: \r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n\t--config=mkl         \t# Build with MKL support.\r\n\t--config=monolithic  \t# Config for mostly static monolithic build.\r\n\t--config=gdr         \t# Build with GDR support.\r\n\t--config=verbs       \t# Build with libverbs support.\r\n\t--config=ngraph      \t# Build with Intel nGraph support.\r\n\t--config=dynamic_kernels\t# (Experimental) Build kernels into separate shared objects.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n\t--config=noaws       \t# Disable AWS S3 filesystem support.\r\n\t--config=nogcp       \t# Disable GCP support.\r\n\t--config=nohdfs      \t# Disable HDFS support.\r\n\t--config=noignite    \t# Disable Apache Ignite support.\r\n\t--config=nokafka     \t# Disable Apache Kafka support.\r\n\t--config=nonccl      \t# Disable NVIDIA NCCL support.\r\nConfiguration finished\r\n(tensorflow) peter@Peter-Ubuntu:~/tensorflow$ ./bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\r\nbash: ./bazel-bin/tensorflow/tools/pip_package/build_pip_package: No such file or directory\r\n(tensorflow) peter@Peter-Ubuntu:~/tensorflow$ ./bazel-bin/tensorflow/tools/pip_package/build_pip_package/tmp/tensorflow_pkg\r\nbash: ./bazel-bin/tensorflow/tools/pip_package/build_pip_package/tmp/tensorflow_pkg: No such file or directory\r\n(tensorflow) peter@Peter-Ubuntu:~/tensorflow$ bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\nStarting local Bazel server and connecting to it...\r\nINFO: Invocation ID: e9e2dd08-b8a0-4807-b1fe-cd6842a67a51\r\nDEBUG: Rule 'build_bazel_rules_swift' modified arguments {\"commit\": \"001736d056d7eae20f1f4da41bc9e6f036857296\", \"shallow_since\": \"1547844730 -0800\"} and dropped [\"tag\"]\r\nDEBUG: /home/peter/.cache/bazel/_bazel_peter/21121c77bac67ad4a1aed68d97d6cb00/external/build_bazel_rules_apple/apple/repositories.bzl:35:5: \r\nWARNING: `build_bazel_rules_apple` depends on `bazel_skylib` loaded from https://github.com/bazelbuild/bazel-skylib.git (tag 0.6.0), but we have detected it already loaded into your workspace from None (tag None). You may run into compatibility issues. To silence this warning, pass `ignore_version_differences = True` to `apple_rules_dependencies()`.\r\n\r\nERROR: /home/peter/tensorflow/tensorflow/tools/pip_package/BUILD:34:1: Illegal ambiguous match on configurable attribute \"deps\" in //tensorflow/tools/pip_package:included_headers_gather:\r\n@local_config_cuda//cuda:using_nvcc\r\n@local_config_cuda//cuda:using_clang\r\nMultiple matches are not allowed unless one is unambiguously more specialized.\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: \r\n\r\n/home/peter/tensorflow/tensorflow/tools/pip_package/BUILD:34:1: Illegal ambiguous match on configurable attribute \"deps\" in //tensorflow/tools/pip_package:included_headers_gather:\r\n@local_config_cuda//cuda:using_nvcc\r\n@local_config_cuda//cuda:using_clang\r\nMultiple matches are not allowed unless one is unambiguously more specialized.\r\nINFO: Elapsed time: 41.489s\r\nINFO: 0 processes.\r\n", "comments": ["Tensorflow: 1.12", "Please find the [tested build configurations](https://www.tensorflow.org/install/source#linux). TF 1.12 was tested and supported with Bazel 0.15.0. Could you follow the instructions [here](https://github.com/rnreich/ubuntu-tensorflow-gpu-all-versions) and let us know how it works. I recently used those steps and successfully installed tensorflow-gpu. If you had already resolved the issue, please close the issue or let us know. Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing this issue due to lack of recent activity. Please open a new ticker when new information is available. Thanks!"]}, {"number": 25643, "title": "Maybe create a new project tensorflow/help?", "body": "Hi, I have recently started contributing to the TensorFlow community, and I'm seeing that a lot of issues that people post are essentially some questions meant for Stack Overflow.\r\n\r\nThese issues clutter the issue tracker of the main repository which is meant for development purposes, since a maintainer who is not familiar with the answer to the question would usually not close the issue right away, and would wait for someone else to address it, and then close it after it has been addressed.\r\n\r\nI propose that we create another repository called **help** under the organization page of TensorFlow. All the issues that are essentially some questions meant for Stack Overflow can be [transferred](https://help.github.com/articles/transferring-an-issue-to-another-repository/) to that repository, so that anyone who is willing to answer them can do it over there.\r\n\r\nThe advantage would be that the issue tracker of the main repository would become less cluttered, since anyone who has the rights to both the repositories would be able to shift these issues to the help repository immediately, while also be assured that these questions would not go unanswered.", "comments": ["Thanks @Sudeepam97 . Good Idea. We are currently working on minimizing clutter by routing support questions to [Stackoverflow](https://stackoverflow.com/search?q=tensorflow). We are also measuring few metrics that may help us to take right approach to minimize \"support\" questions. Thanks again!", "@Sudeepam97 Great Idea.\r\nThis process could also be easily automated by a simple bot or a [GitHub action](https://github.com/features/actions) that transfers the issue when a maintainer adds a `type:support` or `type:help` label.", "@lgeiger, I'll be willing to work on a bot if everyone agrees. We can also try GitHub Actions but seems like it's in a beta release. Will be alright to try a beta feature?", "I am closing this issue. Thanks for the ideas and support. We are improving constantly by optimizing the process. Thanks!"]}, {"number": 25642, "title": "fixed the documentation of glorot_normal according to issue 25564", "body": "PR for issue #25564. Modified the documentation of `tf.keras.initializers.glorot_normal` to specify that the 'stddev' argument refers to the standard deviation of the truncated normal distribution and not the standard deviation of the underling normal distribution.", "comments": ["I think we should then update also the doc for the others. If you agree, I can submit a PR for that.", "I think any contribution is welcome. Let's be careful, and only fix the documents which look misleading if we don't correct them :-)", " I got an e-mail that said \"Closed #25564.\" Is the issue fixed now? I don't see any change yet from the web https://www.tensorflow.org/api_docs/python/tf/keras/initializers/glorot_normal", "Hi, we close the issue because its fix has been merged into master branch. And the web page will be updated after next release version (perhaps tf 2.0).", "@facaiy Well done. Now, I understand what is the GitHub for."]}, {"number": 25641, "title": "tf.rnn wrappers are incompatible with tf.keras.layers cells", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Ubuntu 16.04\r\n- TensorFlow installed: binary\r\n- TensorFlow version: `2.0.0-dev20190206`\r\n- Python version: 3.6.6\r\n\r\n**Describe the current behavior**\r\n\r\nIn the TensorFlow 2.0 preview, the `tf.rnn.DropoutWrapper` and `tf.rnn.ResidualWrapper` wrappers are incompatible with cells from `tf.keras.layers`. It raises an error for missing a `zero_state` method.\r\n\r\n**Describe the expected behavior**\r\n\r\nThe classes in `tf.rnn` should be compatible with cells defined in `tf.keras.layers`.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\ncell = tf.keras.layers.LSTMCell(10)\r\ncell = tf.rnn.ResidualWrapper(cell)\r\ncell.get_initial_state(batch_size=4, dtype=tf.float32)\r\n```\r\n\r\n**Other info / logs**\r\n\r\n```text\r\nTraceback (most recent call last):\r\n  File \"test/rnn_v2.py\", line 5, in <module>\r\n    cell.get_initial_state(batch_size=4, dtype=tf.float32)\r\n  File \"/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 307, in get_initial_state\r\n    return self.zero_state(batch_size, dtype)\r\n  File \"/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 1545, in zero_state\r\n    return self._cell.zero_state(batch_size, dtype)\r\nAttributeError: 'LSTMCell' object has no attribute 'zero_state'\r\n```\r\n\r\n(If this API is not ready yet, please ignore this issue.)", "comments": ["Added a PR #25646 for the fix.", "This should be fixed by https://github.com/tensorflow/tensorflow/commit/76a22b340814425b6a8b6e0c0bb81bcd162c458b and https://github.com/tensorflow/tensorflow/commit/42a1de008f301fb2d4c575ef5f817b5513156328", "Btw, the tf.rnn.* namespace has been moved to tf.nn.RNNCell* to consolidate the namespace.", "How about the progress?I also meet the same problems.", "@lycanthropes As mentioned by @qlzh727 it was resolved in TF2.0.0-alpha0 by \r\n```\r\n!pip install tensorflow==2.0.0-alpha0\r\nimport tensorflow as tf\r\n\r\ncell = tf.keras.layers.LSTMCell(10)\r\ncell = tf.nn.RNNCellResidualWrapper(cell)\r\ncell.get_initial_state(batch_size=4, dtype=tf.float32)\r\n```", "I have the same issues with the dropoutwrapper in 1.13. \r\nit states that a lstm cell has no attribute zero state.", "Btw, the tf.nn.RNNCell*Wrapper has different implementation between v1 and v2 TF binary. You will probably still hit the same issue if you are using TF 1.x binary."]}]