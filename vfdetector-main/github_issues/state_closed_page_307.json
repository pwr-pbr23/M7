[{"number": 45045, "title": "XLA tests compiled even when XLA is not enabled", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL 7.5\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.4.0-rc2\r\n- Python version: 3.7.4\r\n\r\n**Describe the problem**\r\n\r\nIn my efforts in getting the TF unit tests to run I ran into a problem where the tests seem to require XLA but that isn't available and hence the tests fail with\r\n`ImportError: Unable to import _pywrap_tfcompile; you must build TensorFlow with XLA.  You may need to build tensorflow with flag --define=with_xla_support=true.  Original error: cannot import name '_pywrap_tfcompile' from 'tensorflow.python'`\r\n\r\nChecking this further it seems to be a call to `saved_model_compile_aot` with `name = \"aot_compiled_vars_and_arithmetic\",` and `force_without_xla_support_flag = False,` so that looks all fine.\r\n\r\nIs there any advice or solution you can provide? Some bug in the TF bazel files?\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n```\r\nbazel  test --compilation_mode=opt --config=opt --subcommands --verbose_failures --config=noaws --jobs=64 --copt=\"-fPIC\" --action_env=PYTHONPATH --action_env=PYTHONNOUSERSITE=1 --distinct_host_configuration=false --local_test_jobs=1  -- //tensorflow/python/... -//tensorflow/python/integration_testing/...\r\n```\r\n\r\n**Any other info / logs**\r\n\r\nError from log (paths shortened):\r\n\r\n```\r\nERROR: /tmp/tensorflow-r2.4/tensorflow/python/tools/BUILD:461:24: Executing genrule //tensorflow/python/tools:aot_compiled_vars_and_arithmetic_gen failed (Exit 1): bash failed: error executing command \r\n  (cd /tmp/output_base/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    [env vars] \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/ppc-opt/bin/tensorflow/python/tools/saved_model_cli aot_compile_cpu --dir \"$(dirname tensorflow/cc/saved_model/testdata/VarsAndArithmeticObjectGraph/saved_model.pb)\" --output_prefix bazel-out/ppc-opt/bin/tensorflow/python/tools/aot_compiled_vars_and_arithmetic --cpp_class VarsAndArithmetic --variables_to_feed variable_x --signature_def_key serving_default --multithreading False --target_triple ppc64le-ibm-linux-gnu --tag_set serve ')\r\nExecution platform: @local_execution_config_platform//:platform\r\n2020-11-20 15:36:23.668303: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\nTraceback (most recent call last):\r\n  File \"/tmp/output_base/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/python/tools/saved_model_cli.runfiles/org_tensorflow/tensorflow/python/tools/saved_model_cli.py\", line 1196, in <module>\r\n    sys.exit(main())\r\n  File \"/tmp/output_base/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/python/tools/saved_model_cli.runfiles/org_tensorflow/tensorflow/python/tools/saved_model_cli.py\", line 1192, in main\r\n    args.func(args)\r\n  File \"/tmp/output_base/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/python/tools/saved_model_cli.runfiles/org_tensorflow/tensorflow/python/tools/saved_model_cli.py\", line 835, in aot_compile_cpu\r\n    multithreading=args.multithreading.lower() not in ('f', 'false', '0'))\r\n  File \"/tmp/output_base/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/python/tools/saved_model_cli.runfiles/org_tensorflow/tensorflow/python/tools/saved_model_aot_compile.py\", line 259, in aot_compile_cpu_meta_graph_def\r\n    raise _pywrap_tfcompile_import_error  # pylint: disable=raising-bad-type\r\nImportError: Unable to import _pywrap_tfcompile; you must build TensorFlow with XLA.  You may need to build tensorflow with flag --define=with_xla_support=true.  Original error: cannot import name '_pywrap_tfcompile' from 'tensorflow.python' (/tmp/output_base/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/python/tools/saved_model_cli.runfiles/org_tensorflow/tensorflow/python/__init__.py)\r\n```\r\n\r\nThere is also no mentioning of XLA (like `--config=xla`) in the log/output", "comments": ["Looks like this is caused by *not* using `--build_tests_only`, so I guess this is a non-issue as passing that flag solves it.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45045\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45045\">No</a>\n"]}, {"number": 45044, "title": "OP_REQUIRES failed at conv_ops.cc:1106 : Not found: No algorithm worked!", "body": "**System information**\r\n- Linux Ubuntu 20.04\r\n- TensorFlow installed from Docker tensorflow/tensorflow:2.4.0rc1\r\n- TensorFlow version: 2.4.0rc2\r\n- Python version: 3.6.9\r\n- Installed using [Docker](https://hub.docker.com/layers/tensorflow/tensorflow/2.4.0rc1-gpu/images/sha256-6e74a947ed5bc7b64c87575a3824427e462aaafb6bf7c9664e8154cc57f1d1a4?context=explore)\r\n- CUDA/cuDNN version: CUDA 11.1 cuDNN v8\r\n- GPU model and memory: RTX 3080 FE 10GB\r\n\r\n\r\n\r\n**Describe the problem**\r\nWhile training custom resnet 50 model I get the following build error:\r\n```\r\n2020-11-20 12:05:01.826720: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at conv_ops.cc:1106 : Not found: No algorithm worked!\r\n```\r\nI don't think the code has any issues. It works fine when training with CPU.\r\n\r\n**Any other info / logs**\r\n```\r\n2020-11-20 12:04:55.291380: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\r\n2020-11-20 12:04:55.291414: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\r\n2020-11-20 12:04:55.291455: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs\r\n2020-11-20 12:04:55.360280: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so.11.0\r\n2020-11-20 12:04:55.491657: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\r\n2020-11-20 12:04:55.491780: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed\r\n2020-11-20 12:04:56.592756: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\r\n2020-11-20 12:04:56.610956: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3899970000 Hz\r\nEpoch 1/30\r\n2020-11-20 12:04:58.010569: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\r\n2020-11-20 12:04:58.802284: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\r\n2020-11-20 12:04:58.807134: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\r\n2020-11-20 12:05:01.826720: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at conv_ops.cc:1106 : Not found: No algorithm worked!\r\nTraceback (most recent call last):\r\n  File \"custom_resnet.py\", line 131, in <module>\r\n    train_model()\r\n  File \"custom_resnet.py\", line 105, in train_model\r\n    callbacks=[tensorboard_callback]\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 1100, in fit\r\n    tmp_logs = self.train_function(iterator)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 828, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 888, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 2943, in __call__\r\n    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1919, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 560, in call\r\n    ctx=ctx)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\r\n    inputs, attrs, num_outputs)\r\ntensorflow.python.framework.errors_impl.NotFoundError:  No algorithm worked!\r\n\t [[node model/conv1/Conv2D (defined at custom_resnet.py:105) ]] [Op:__inference_train_function_8452]\r\n\r\nFunction call stack:\r\ntrain_function\r\n\r\n2020-11-20 12:05:01.905250: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.\r\n\t [[{{node PyFunc}}]]\r\n```\r\n\r\nnvidia-smi\r\n```\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 455.32.00    Driver Version: 455.32.00    CUDA Version: 11.1     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce RTX 3080    On   | 00000000:2B:00.0  On |                  N/A |\r\n|  0%   43C    P8    25W / 320W |    857MiB /  9995MiB |      1%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                                  |\r\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n|        ID   ID                                                   Usage      |\r\n|=============================================================================|\r\n+-----------------------------------------------------------------------------+\r\n```\r\nnvcc --version\r\n```\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2020 NVIDIA Corporation\r\nBuilt on Wed_Jul_22_19:09:09_PDT_2020\r\nCuda compilation tools, release 11.0, V11.0.221\r\nBuild cuda_11.0_bu.TC445_37.28845127_0\r\n```\r\ntf.test.is_gpu_available()\r\n```\r\nWARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.config.list_physical_devices('GPU')` instead.\r\n2020-11-20 12:10:11.234638: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-11-20 12:10:11.235502: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n2020-11-20 12:10:11.269174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-20 12:10:11.269569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:2b:00.0 name: GeForce RTX 3080 computeCapability: 8.6\r\ncoreClock: 1.71GHz coreCount: 68 deviceMemorySize: 9.76GiB deviceMemoryBandwidth: 707.88GiB/s\r\n2020-11-20 12:10:11.269584: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n2020-11-20 12:10:11.271142: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\r\n2020-11-20 12:10:11.271167: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\r\n2020-11-20 12:10:11.271830: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2020-11-20 12:10:11.271954: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2020-11-20 12:10:11.273538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2020-11-20 12:10:11.273878: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\r\n2020-11-20 12:10:11.273963: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\r\n2020-11-20 12:10:11.274040: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-20 12:10:11.274432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-20 12:10:11.274959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2020-11-20 12:10:11.274975: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n2020-11-20 12:10:11.593266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-11-20 12:10:11.593303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \r\n2020-11-20 12:10:11.593309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \r\n2020-11-20 12:10:11.593483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-20 12:10:11.593857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-20 12:10:11.594195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-20 12:10:11.594517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 8743 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3080, pci bus id: 0000:2b:00.0, compute capability: 8.6)\r\nTrue\r\n```\r\n\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Can you check the CUDA/CUDNN versions in the image/container against this https://github.com/tensorflow/tensorflow/issues/43718#issuecomment-725734491?", "@bhack \r\nThe versions from docker are:\r\nCUDA=11.0\r\nCUDNN=8.0.4.30-1\r\nThe only difference being CUDA 11.1 vs 11.0. An earlier [comment](https://github.com/tensorflow/tensorflow/issues/43718#issuecomment-711057497) in the same issue stated that 11.0 worked for their 3090. ", "See https://github.com/tensorflow/tensorflow/issues/44832#issuecomment-728785647", "@AZdora Can you try to run a Resnet (https://keras.io/api/applications/resnet/) in on your 3080 GPU with your working Docker container?", "try adding this just after importing everthing. \r\nphysical_devices = tf.config.list_physical_devices('GPU') tf.config.experimental.set_memory_growth(physical_devices[0], True)", "@king398 When doing that I got the following error:\r\n```\r\n2020-11-23 14:12:00.220322: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\r\n2020-11-23 14:12:00.220363: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\r\n2020-11-23 14:12:00.220398: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs\r\n2020-11-23 14:12:00.221167: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so.11.0\r\n2020-11-23 14:12:00.319763: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\r\n2020-11-23 14:12:00.319890: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed\r\n2020-11-23 14:12:02.049733: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\r\n2020-11-23 14:12:02.069156: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3899740000 Hz\r\nEpoch 1/10\r\n2020-11-23 14:12:04.273239: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\r\n2020-11-23 14:12:04.680420: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\r\n2020-11-23 14:12:05.356500: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\r\n2020-11-23 14:12:06.524399: W tensorflow/stream_executor/gpu/asm_compiler.cc:235] Your CUDA software stack is old. We fallback to the NVIDIA driver for some compilation. Update your CUDA version to get the best performance. The ptxas error was: ptxas fatal   : Value 'sm_86' is not defined for option 'gpu-name'\r\n\r\n2020-11-23 14:12:06.524575: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Unimplemented: /usr/local/cuda-11.0/bin/ptxas ptxas too old. Falling back to the driver to compile.\r\nRelying on driver to perform ptx compilation. \r\nModify $PATH to customize ptxas location.\r\nThis message will be only logged once.\r\n2020-11-23 14:12:49.805540: W tensorflow/stream_executor/gpu/asm_compiler.cc:235] Your CUDA software stack is old. We fallback to the NVIDIA driver for some compilation. Update your CUDA version to get the best performance. The ptxas error was: ptxas fatal   : Value 'sm_86' is not defined for option 'gpu-name'\r\n```", "You are using cuda 11.0 which is not compatible with rtx 30 series. Try installing cuda 11.1 And you can also try installing through pip instead of docker. it says in the warning to upgrade your cuda software and  Your CUDA software stack is old.Also please tell your driver version\r\n\r\n", "@king398 I have a lot of issues trying to run it using pip.\r\nSpecifically being:\r\n```\r\n2020-11-29 10:04:29.124995: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\n```\r\nI'm not sure what I'm missing. I've downloaded CUDA 11.1 and CUDNN.\r\n\r\nI find that using a docker container is much better since all of the dependencies are packaged by TensorFlow themselves. If there's an issue with the CUDA version that is provided through the docker image from TensorFlow then that should be looked into.\r\n\r\nThis issue still exists with version rc3.", "same issue with nvidia/cuda:11.0-cudnn8-devel-ubuntu18.04 and RTX 3080\r\n\r\nusing cuda 11.1 cause :\r\n\r\n`Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory`\r\n\r\ntried with rc0 -> rc4\r\n\r\n**Edit : Fixed**\r\n\r\ndocker image : nvidia/cuda:11.1-cudnn8-devel-ubuntu18.04\r\ntf version : tf-nightly-gpu\r\n\r\nNeed to change LD_LIBRARY_PATH in order to make simlink\r\n\r\n`ENV LD_LIBRARY_PATH=/usr/local/cuda-11.1/targets/x86_64-linux/lib`\r\n\r\nMake simlink so libcusolver.so.10 is defined\r\n\r\n`RUN ln -s /usr/local/cuda-11.1/targets/x86_64-linux/lib/libcusolver.so.11 /usr/local/cuda-11.1/targets/x86_64-linux/lib/libcusolver.so.10`\r\n\r\nif you have cublas error you can try this :\r\n\r\n```\r\nconfig = tf.compat.v1.ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nsession = tf.compat.v1.Session(config=config)\r\n\r\n```", "I've found a temporary solution by using software provided by [lambda stack](https://lambdalabs.com/blog/install-tensorflow-and-pytorch-on-rtx-30-series/). It works on ubuntu 20.04 for all RTX 30 series GPUs.", "TF 2.4 is built & tested against CUDA 11.0, not 11.1.", "I have the exact same problem trying to make TF work with my RTX 3070. CUDA 11.1 + CUDNN 8.0.5.39 + TF2.4.0\r\n\r\nNote: I had to make the symlink trick so TF could find the libcusolver.so.10 which is obviously not available in the CUDA 11.1 package", "I experienced this issue on an MSI GL65 with an RTX2070 on Ubuntu 20.04.\r\n\r\nDynamic libraries are the following:\r\n\r\n```python\r\nIn [1]: import tensorflow                                                                                                                                                                                          \r\n2021-01-28 16:05:15.891481: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n\r\nIn [2]: tensorflow.__version__                                                                                                                                                                                     \r\nOut[2]: '2.4.0'\r\n\r\nIn [3]: tensorflow.config.experimental.list_physical_devices('GPU')                                                                                                                                                \r\n2021-01-28 16:06:40.579904: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-01-28 16:06:40.588165: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n2021-01-28 16:06:40.619240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-01-28 16:06:40.619800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce RTX 2070 computeCapability: 7.5\r\ncoreClock: 1.455GHz coreCount: 36 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 327.88GiB/s\r\n2021-01-28 16:06:40.619823: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n2021-01-28 16:06:40.627330: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\r\n2021-01-28 16:06:40.627382: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\r\n2021-01-28 16:06:40.631550: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2021-01-28 16:06:40.633606: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2021-01-28 16:06:40.642000: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2021-01-28 16:06:40.644472: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\r\n2021-01-28 16:06:40.645649: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\r\n2021-01-28 16:06:40.645749: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-01-28 16:06:40.646153: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-01-28 16:06:40.646490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\nOut[3]: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\r\n```\r\n\r\nAdding the lines indicated by @king398 solved my issue.\r\n\r\n> try adding this just after importing everthing.\r\n> physical_devices = tf.config.list_physical_devices('GPU') tf.config.experimental.set_memory_growth(physical_devices[0], True)\r\n\r\n", "Adding the lines indicated by @king398 solved my Issue too on my GL65 with RTX2070 on Ubuntu 20.04", "If the error persists after setting the GPU memory growth configuration, as indicated by @king398, you might want to try dropping the batch size during training.", "One additional hint since it took me some time to figure it out. The set_memory_growth() didn't take effect in my setup until I added the os.environ['CUDA_VISIBLE_DEVICES']=\"0\" (note I have only one GPU). \r\n\r\nBTW, this still looks like a workaround to me and ideally we would have to fix this (I didn't face this problem with the older versions of CUDA and cuDNN compatible with the RTX20xx series).", "@Harsh188 \r\nCould you please let us know if this is still an issue in latest stable TF v2.6.0 ?Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "@Saduf2019 there are no issues with v2.6.0 ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45044\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45044\">No</a>\n"]}, {"number": 45043, "title": "use hooks to fine_tune in Estimator", "body": "**System information**\r\n- TensorFlow version (you are using):tf.1.14\r\n- Are you willing to contribute it (Yes/No):yes\r\n\r\n**1. Describe the feature and the current behavior/state.**\r\n\r\nwhen I use hook to fine_tune in estimator, I got such a error:RuntimeError: Graph is finalized and cannot be modified.\r\n\r\nMy hooks is defined as follows:\r\nclass RestoreHook(tf.train.SessionRunHook):\r\n    def __init__(self, checkpoint_path, include=None, exclude=None):\r\n        self.checkpoint_path =  tf.train.latest_checkpoint(checkpoint_path)\r\n        self.include = include\r\n        self.exclude = exclude\r\n\r\n    def after_create_session(self, session, coord=None):\r\n        var_list = tf.contrib.framework.get_variables_to_restore(include=self.include, exclude=self.exclude)\r\n\r\n        self.init_fn = tf.contrib.framework.assign_from_checkpoint_fn(\r\n            self.checkpoint_path,\r\n            var_list=var_list,\r\n            ignore_missing_vars=True\r\n        )\r\n        if session.run(tf.train.get_or_create_global_step()) == 0:\r\n            # suppress WARN\r\n            log_level = tf.logging.get_verbosity()\r\n            tf.logging.set_verbosity(tf.logging.ERROR)\r\n            self.init_fn(session)\r\n            tf.logging.set_verbosity(log_level)\r\n\r\n2\u3001My calling method\uff1a\r\n\r\ninit_checkpoint = './my_model/'\r\n        from finetune import get_tvars\r\n        assignment_map ,assignment_map_keys = get_tvars(init_checkpoint)\r\n        for dict in assignment_map:\r\n            if \"global\" in dict:\r\n                assignment_map.pop(dict)\r\n        include_var = list(assignment_map_keys)\r\n        checkpoint_path = init_checkpoint\r\n        restore_hook = RestoreHook(checkpoint_path, include=include_var)\r\n    else:\r\n        restore_hook = None\r\n    train_spec = tf.estimator.TrainSpec(\r\n        input_fn=input_fn\r\n        max_steps=100000,\r\n        hooks=[restore_hook]\r\n)\r\n\r\n\r\n", "comments": ["Can you try to use a modern version of TF? Generally it is hard to receive support for tf.1.14 here.", "> Can you try to use a modern version of TF? Generally it is hard to receive support for tf.1.14 here.\r\n\r\nBut I don't think the upgrade will solve this problem.The evaluate will return a global_step parameter in the API of tf 2.3.0 ,as the same as tf1.14  ,I think it is the global step parameter returned by loading the old model that conflicts with the global step of the current model.So is there any method to solve this problem?", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information."]}, {"number": 45042, "title": "Fix typo in reshape.cc", "body": "", "comments": []}, {"number": 45041, "title": "tf2.3  keras model can't save  big embedding:  tensorflow.SavedModel exceeds maximum protobuf size of 2GB", "body": " # what\r\nWhen we try to save a simple keras model with  embedding layer,which shape is (1e7,16),  we got error `ValueError: Message tensorflow.SavedModel exceeds maximum protobuf size of 2GB: 9789558077` .\r\nWe want to save it as SavedModel format ,so that we can use tf serving to serve the model. \r\n\r\n# related problems\r\n[Tensorflow graph bigger than 2GB](https://stackoverflow.com/questions/59558170/tensorflow-graph-bigger-than-2gb)\r\n\r\n# simple code that reproduce the error\r\n```python\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\nimport numpy as np\r\nvocab_size = 10**7\r\nemb_dim = 16\r\nglobal_emb_weights = np.random.random(size=(vocab_size,emb_dim))\r\nemb = keras.layers.Embedding( mask_zero=True, input_dim=vocab_size, output_dim=emb_dim,\r\n                                     embeddings_initializer=keras.initializers.Constant(\r\n                                         global_emb_weights),trainable=True)\r\n\r\nx = keras.Input((100,))\r\nout = emb(x)\r\nmodel = keras.Model(inputs=x,outputs=out)\r\nmodel.save(\"/tmp/test_tf\",save_format=\"tf\",overwrite=True)\r\n\r\n``` \r\n# error\r\n>    File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save.py\", line 80, in save\r\n>     save_lib.save(model, filepath, signatures, options)\r\n>   File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py\", line 1006, in save\r\n>     path, saved_model.SerializeToString(deterministic=True))\r\n> ValueError: Message tensorflow.SavedModel exceeds maximum protobuf size of 2GB: 9789558077\r\n\r\n", "comments": ["Please check https://github.com/tensorflow/hub/blob/master/examples/text_embeddings/export.py#L204-L219", "I ran the code shared and colab crashes, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/15e03498f196eda58d47f32f2a6c3572/untitled466.ipynb).", " \r\n\r\n> Please check https://github.com/tensorflow/hub/blob/master/examples/text_embeddings/export.py#L204-L219\r\n\r\nIt uses the tf1.x low level api.  How can we solve this  in keras's style.", "What I would suggest doing is simply:\r\n\r\n```python\r\nemb = keras.layers.Embedding( mask_zero=True, input_dim=vocab_size, output_dim=emb_dim, trainable=True)\r\nemb.set_weights([global_emb_weights])\r\n```\r\n\r\nBasically, move the weight init outside of the model definition, so that the weights don't get saved as part of the model config (since the model config captures \"model definition\").", "It was a quite frequent request on stackoverflow probably it needs to be documented.", "> What I would suggest doing is simply:\r\n> \r\n> ```python\r\n> emb = keras.layers.Embedding( mask_zero=True, input_dim=vocab_size, output_dim=emb_dim, trainable=True)\r\n> emb.set_weights([global_emb_weights])\r\n> ```\r\n> \r\n> Basically, move the weight init outside of the model definition, so that the weights don't get saved as part of the model config (since the model config captures \"model definition\").\r\n\r\nIt works,  but `set_weights` should placed after  layer operation,for example `x = keras.Input((1,));out = emb(x)`.\r\nAnd embedding matrix is in `variables.data` file ,not `saved_model.pb` , which avoids the protobuf  limit  size of 2GB.\r\n\r\nCode that works:\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nimport numpy as np\r\n\r\nvocab_size =  10**7\r\nemb_dim = 16\r\nnp.random.seed(0)\r\nglobal_emb_weights = np.random.random(size=(vocab_size,emb_dim))\r\nemb = keras.layers.Embedding( mask_zero=True, input_dim=vocab_size, output_dim=emb_dim,\r\n                                     trainable=True,input_length=10)\r\nx = keras.Input((1,))\r\nout = emb(x)\r\nemb.set_weights([global_emb_weights]) #  move the weight init outside of the model definition,\r\nmodel = keras.Model(inputs=x,outputs=out)\r\nx1 = model.predict([list(range(10))])\r\n \r\n\r\nmodel.save(\"/tmp/test_tf\",save_format=\"tf\",overwrite=True)\r\nmodel2 = tf.keras.models.load_model(\"/tmp/test_tf\")\r\nx2 = model2.predict([list(range(10))])\r\nprint(\"x1=x2:{}\".format((x1==x2).all()))\r\n```\r\n\r\nCode that raises error:\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nimport numpy as np\r\n\r\nvocab_size =  10**7\r\nemb_dim = 16\r\nnp.random.seed(0)\r\nglobal_emb_weights =  np.random.random(size=(vocab_size,emb_dim))\r\nemb = keras.layers.Embedding( mask_zero=True, input_dim=vocab_size, output_dim=emb_dim,\r\n                                     trainable=True,input_length=10)\r\n# emb.set_weights should placed  after  out = emb(x)\r\nemb.set_weights([global_emb_weights]) #  move the weight init outside of the model definition,\r\n\r\nx = keras.Input((1,))\r\nout = emb(x)\r\nmodel = keras.Model(inputs=x,outputs=out)\r\nx1 = model.predict([list(range(10))])\r\n \r\n\r\nmodel.save(\"/tmp/test_tf\",save_format=\"tf\",overwrite=True)\r\nmodel2 = tf.keras.models.load_model(\"/tmp/test_tf\")\r\nx2 = model2.predict([list(range(10))])\r\nprint(\"x1=x2:{}\".format((x1==x2).all()))\r\n```\r\n```\r\nFile \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 1810, in set_weights\r\n    (self.name, len(weights), expected_num_weights, str(weights)[:50]))\r\nValueError: You called `set_weights(weights)` on layer \"embedding\" with a weight list of length 1, but the layer was expecting 0 weights. Provided weights: [array([[0.5488135 , 0.7151893\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45041\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45041\">No</a>\n"]}, {"number": 45040, "title": "TFLu: Suppress compiler error for generated segfault", "body": "Suppress -Wnull-dereference for both Armclang and GCC, when\r\nintentionally generating a segfault in patched code.\r\n\r\nFix for: https://github.com/tensorflow/tensorflow/issues/44971\r\n", "comments": []}, {"number": 45039, "title": "Fixed typo in documentation", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F45039) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "We will not be encouraging one liner changes as this is expensive process, if possible please include more such changes in a single PR.Thank you\r\nCC @mihaimaruseac "]}, {"number": 45038, "title": "[TFLite] Experimental new quantizer calculates the wrong scaling when the input range doesn't include 0", "body": "Hello,\r\n\r\nWhen creating a quantized network with the new experimental quantizer it seems there is a problem with the scaling of the nodes when the input range provided by the representative dataset doesn't include 0 (e.g. [2.3, 5.4] or [-1.2, -0.4] range). \r\n\r\nThe small example below creates a network with a single multiply operator and the representative dataset provides a [1.3, 1.4] input range. The expected result, and the one provided with the stable quantizer, of the 1.4*1.4 multiplication is 1.96 but the returned result is 0.00952942. \r\n\r\nThe new experimental quantizer seems to calculate the input scaling of the multiply node as (1.4 - 1.3)/255 with a -128 zero-point instead of (1.4 - 0.0)/255 with the same zero-point as done by the stable quantizer. Changing the input range of the representative dataset to [0.0, 1.4] solves the problem. \r\n\r\nI know the new quantizer is experimental so it isn't too much of a problem yet but it's mainly to report the problem if it isn't already known.\r\n\r\nTested version: tf-nightly-2.5.0.dev20201119\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n\r\ninput = tf.keras.Input(shape=(1))\r\noutput = tf.keras.layers.Multiply()([input, input])\r\nmodel = tf.keras.Model(inputs=input, outputs=output)\r\n\r\n\r\ndef representative_data_gen():\r\n    yield [np.array([[1.3]], dtype=np.float32)]\r\n    yield [np.array([[1.4]], dtype=np.float32)]\r\n    # It works with this line if _experimental_new_quantizer=True\r\n    # yield [np.array([[0.0]], dtype=np.float32)]\r\n\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.representative_dataset = representative_data_gen\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter._experimental_new_quantizer = True\r\n\r\ntflite_model = converter.convert()\r\n\r\ninterpreter = tf.lite.Interpreter(model_content=tflite_model)\r\ninterpreter.allocate_tensors()\r\n\r\ninput = np.array([[1.4]], dtype=np.float32)\r\ninterpreter.set_tensor(interpreter.get_input_details()[0][\"index\"], input)\r\ninterpreter.invoke()\r\noutput = interpreter.get_tensor(interpreter.get_output_details()[0][\"index\"])\r\n\r\nprint(\"input \", input)\r\nprint(\"output \", output)\r\n```", "comments": ["I have tried in colab with TF nightly version(`2.5.0-dev20201203`) and was able to reproduce the issue. Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/508c562adc928bf62d651853fdfe8184/untitled566.ipynb).Thanks!", "@liufengdb @daverim can you take a look?", "It seems the problem was solved by commit 05303d0dcee5c415c2e39233b023f660914b5b8, I will thus close the issue. Thanks @liufengdb!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45038\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45038\">No</a>\n"]}, {"number": 45037, "title": "tensorflow version 2.2.0 ;question:WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023B864321F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1.  It must be a bug, a feature request, or a significant problem with the\r\n    documentation (for small docs fixes please send a PR instead).\r\n2.  The form below must be filled out.\r\n3.  It shouldn't be a TensorBoard issue. Those go\r\n    [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**:\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**:\r\n-   **TensorFlow installed from (source or binary)**:\r\n-   **TensorFlow version (use command below)**:\r\n-   **Python version**:\r\n-   **Bazel version (if compiling from source)**:\r\n-   **GCC/Compiler version (if compiling from source)**:\r\n-   **CUDA/cuDNN version**:\r\n-   **GPU model and memory**:\r\n-   **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["@wanghao0225,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and the dataset you are using.\r\n\r\nAlso, please take a look at [this comment](https://github.com/tensorflow/tensorflow/issues/34481#issuecomment-697824244) from a similar issue and let us know if it helps. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45037\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45037\">No</a>\n"]}, {"number": 45036, "title": "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc1 in position 50: invalid start byte", "body": "`Traceback (most recent call last):\r\n  File \"object_detection/train.py\", line 167, in <module>\r\n    tf.compat.v1.app.run()\r\n  File \"C:\\Users\\info\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"C:\\Users\\info\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\absl\\app.py\", line 303, in run\r\n    _run_main(main, args)\r\n  File \"C:\\Users\\info\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\absl\\app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"object_detection/train.py\", line 163, in main\r\n    worker_job_name, is_chief, FLAGS.train_dir)\r\n  File \"C:\\Users\\info\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\object_detection-0.1-py3.7.egg\\object_detection\\legacy\\trainer.py\", line 279, in train\r\n    train_config.prefetch_queue_capacity, data_augmentation_options)\r\n  File \"C:\\Users\\info\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\object_detection-0.1-py3.7.egg\\object_detection\\legacy\\trainer.py\", line 58, in create_input_queue\r\n    tensor_dict = create_tensor_dict_fn()\r\n  File \"object_detection/train.py\", line 120, in get_next\r\n    dataset_builder.build(config)).get_next()\r\n  File \"C:\\Users\\info\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\object_detection-0.1-py3.7.egg\\object_detection\\builders\\dataset_builder.py\", line 231, in build\r\n    config.input_path[:], input_reader_config, filename_shard_fn=shard_fn)\r\n  File \"C:\\Users\\info\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\object_detection-0.1-py3.7.egg\\object_detection\\builders\\dataset_builder.py\", line 150, in read_dataset\r\n    filename_shard_fn)\r\n  File \"C:\\Users\\info\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\object_detection-0.1-py3.7.egg\\object_detection\\builders\\dataset_builder.py\", line 76, in _read_dataset_internal\r\n    filenames = tf.gfile.Glob(input_files)\r\n  File \"C:\\Users\\info\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\", line 350, in get_matching_files\r\n    return get_matching_files_v2(filename)\r\n  File \"C:\\Users\\info\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\", line 415, in get_matching_files_v2\r\n    for single_filename in pattern\r\n  File \"C:\\Users\\info\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\", line 417, in <listcomp>\r\n    compat.as_bytes(single_filename))\r\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xc1 in position 50: invalid start byte\r\n[ERROR|main.py:37] 2020-11-20 18:26:38,251 > Transfer leaarning Error\r\n`\r\n\r\nI can't find what is the problem.\r\nI set tf_example_decoder.py > dct_method='INTEGER_FAST'  (NOT WORK)\r\nWhen read TFRecord and Make TFRecord, I can see this error.\r\nhelp me!\r\n\r\nI used Anaconda 4.3 / Tensorflow 2.3.0 / Python 3.7", "comments": ["We don't officially support Anaconda here. Can you share a  very minimal \"copy and run\" example or Colab to reproduce this?", "@qufdl0357 \r\nWe see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced]", "I fixed it. It was a problem with data input type or path.\r\nI changed xml files tag <path>. \r\nThanks for trying to help! \r\n(but still cannot saved checkpoint type \"classification\" check point)"]}, {"number": 45035, "title": "tf.keras.layers.LSTM don't check mask shape(tensorflow-gpu with cuda)", "body": "use tensorflow-gpu with cuda, LSTM don't check mask shape\u3002but it check in tensorflow-cpu. it cause the code below failed in cpu but work in GPU.\r\nerror information:  tensorflow.python.framework.errors_impl.OutOfRangeError: Tried to read from index 5 but array size is: 5\r\n```\r\ninputs = tf.random.normal([4, 6, 4])\r\nlstm=tf.keras.layers.LSTM(4,return_sequences=True)\r\nmasks=tf.sequence_mask(\r\n    [1,2,3,4],\r\n    maxlen=5,\r\n    dtype=tf.bool\r\n)\r\n# or \r\n# masks=tf.sequence_mask(\r\n#     [1,2,3,4,4],\r\n#     maxlen=5,\r\n#     dtype=tf.bool\r\n# )\r\noutput=lstm(inputs,mask=masks)\r\n```\r\n", "comments": ["@lieberman94 \r\n\r\nI tried in colab with TF version 2.4-rc1 and i am seeing the error message with [cpu](https://colab.research.google.com/gist/ravikyram/e0267a08df64b67f5ec315269da17cfa/untitled525.ipynb) and [gpu](https://colab.research.google.com/gist/ravikyram/a1b0be72e845cde8091c78ade83f2d78/untitled525.ipynb) also.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45035\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45035\">No</a>\n"]}, {"number": 45034, "title": "setup.py is missing tblib dependency", "body": "As the title says: tblib is used at https://github.com/tensorflow/tensorflow/blob/5e48683fe0983d5f35f1305f426d1b06904329a4/tensorflow/python/distribute/multi_process_runner.py but not declared as a dependency in setup.py\r\n\r\nThis is for current master and 2.4rc2", "comments": ["Cause I see that it is only related to CI", "I see it is seemingly optional.\r\n\r\nMaybe @crccw can clarify why/how that dependency is required?", "It's only needed in multi worker tests.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45034\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45034\">No</a>\n", "Shouldn't this then go to the `TEST_PACKAGES` in `setup.py`?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45034\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45034\">No</a>\n"]}, {"number": 45033, "title": "tensorflow/lite/micro/tools/make/Makefile:403: *** Something went wrong with the flatbuffers download: .  Stop.", "body": "\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:N\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version:2.3.1\r\n- Python version:3.8.3\r\n- Installed using virtualenv? pip? conda?:pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nThe code I entered is\uff1a\r\nPS E:\\tensorflow> make -f tensorflow/lite/micro/tools/make/Makefile test_hello_world_test\r\nThe output result is\uff1a\r\nprocess_begin: CreateProcess(NULL, uname -m, ...) failed.\r\nprocess_begin: CreateProcess(NULL, bash E:\\tensorflow\\tensorflow\\lite\\micro\\tools\\make\\flatbuffers_download.sh tensorflow/lite/micro/tools/make/downloads, ...) failed.\r\ntensorflow/lite/micro/tools/make/Makefile:403: *** Something went wrong with the flatbuffers download: .  Stop.\r\n\r\nWhat is the reason?", "comments": ["I see in your template `TensorFlow version:2.3.1` but in your log `E:\\tensorflow\\tensorflow\\lite\\micro\\tools\\make\\flatbuffers_download.sh` and this file was not in `2.3.1` code base.\r\n\r\nOn what version are you working?", "> in your log and this file was not in code base\r\n\r\nI'm very sorry.I can't understand what you mean, my tensorflow is version 2.3.1.", "On master it was moved in a standalone script but I don't know if it was a bugfix or a feature request cause the ticket was internal (b/143904317) https://github.com/tensorflow/tensorflow/pull/44860  /cc @advaitjain \r\n", "> On master it was moved in a standalone script but I don't know if it was a bugfix or a feature request cause the ticket was internal (b/143904317) #44860 /cc @advaitjain\r\n\r\nSo which version should I use?", "process_begin: CreateProcess(NULL, bash E:\\tensorflow\\tensorflow\\lite\\micro\\tools\\make\\flatbuffers_download.sh tensorflow/lite/micro/tools/make/downloads, ...) failed. \r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/tools/make/flatbuffers_download.sh\r\nThis file failed\uff0cbut i don't know why.\r\nI am very anxious", "With https://github.com/tensorflow/tensorflow/pull/44860 and a few related PRs, we are moving towards having the downloads take place via stand-alone scripts with the goal of making things more stable and easier to maintain.\r\n\r\nSo yes, using flatbuffer_download.sh is the way to go.\r\n\r\nThe Linux build is ok (you can check the badge here):\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro#continuous-build-status\r\n\r\n@YANxu-666: we don't have any continuous integration for Windows so it is possible that something in the script is not Windows-compatible. Can you try running the following command and report any errors:\r\n```\r\ntensorflow/lite/micro/tools/make/flatbuffers_download.sh tensorflow/lite/micro/tools/make/downloads\r\n```", "There is a good solution to this from the TinyML Forum:\r\n\r\nhttps://forums.tinyml.org/t/make-doesnt-work-on-hello-world-test-from-tinyml-book/344", "@YANxu-666 Could you please try on the latest stable TF v2.6.0 and  refer to the [comment](https://github.com/tensorflow/tensorflow/issues/45033#issuecomment-810610882) above ? Please let us know if it helps?Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45033\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45033\">No</a>\n"]}, {"number": 45032, "title": "Wheel repairing broken when using tensorflow/tensorflow:custom-op-gpu-ubuntu16 docker image", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: nightly (master branch)\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: n/a\r\n- Bazel version (if compiling from source): 3.1.0 (installed by bazelisk v1.3.0 using install_bazelisk from tensorflow/tools/ci_build/release/common.sh)\r\n- GCC/Compiler version (if compiling from source): gcc7_manylinux2010-nvcc-cuda10.1\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\nWhen building \"manylinux2010\" TensorFlow wheel package using custom-op-gpu-ubuntu16 docker image, the repair step using auditwheel package fails with the following stack trace:\r\n\r\n> Traceback (most recent call last):\r\n>   File \"/usr/local/bin/auditwheel\", line 8, in <module>\r\n>     sys.exit(main())\r\n>   File \"/usr/local/lib/python3.6/dist-packages/auditwheel/main.py\", line 47, in main\r\n>     rval = args.func(args, p)\r\n>   File \"/usr/local/lib/python3.6/dist-packages/auditwheel/main_repair.py\", line 45, in execute\r\n>     from .repair import repair_wheel\r\n>   File \"/usr/local/lib/python3.6/dist-packages/auditwheel/repair.py\", line 14, in <module>\r\n>     from .wheeltools import InWheelCtx, add_platforms\r\n>   File \"/usr/local/lib/python3.6/dist-packages/auditwheel/wheeltools.py\", line 15, in <module>\r\n>     from wheel.util import urlsafe_b64encode, open_for_csv, native  # type: ignore\r\n> ImportError: cannot import name 'open_for_csv' \r\n> \r\n\r\nThe exact command that causes the error is\r\nauditwheel repair --plat manylinux2010_x86_64 -w . tf_nightly_v2-2.5.0-cp36-cp36m-linux_x86_64.whl \r\n\r\nIt appears that the failure may be related to [this change](https://github.com/tensorflow/tensorflow/commit/38bc69da9c441e9811d0364fe5cad576c654db3f) that pins down the version of wheel package to a relatively new 0.35 while auditwheel version stayed at 2.0.0, as installed in the docker image using [install_auditwheel.sh](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/install/install_auditwheel.sh).\r\n\r\nIt is possible to work around this problem by, for example, installing a newer version of auditwheel after calling [install_ubuntu_16_pip_deps](https://github.com/tensorflow/tensorflow/blob/84d0c4e84036e24fe5bd2765428c1624300cc8b4/tensorflow/tools/ci_build/release/common.sh#L106), but a proper fix should probably be done. I am not a specialist in TensorFlow build system and I would not be able to test such a fix thoroughly, but I could provide the initial patch to update the version of auditwheel in [install_auditwheel.sh](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/install/install_auditwheel.sh). Would that be the right course of action, or am I doing something wrong?\r\n", "comments": ["/cc @mihaimaruseac ", "@akarmi Could you please try using latest stable version of `TF 2.6.0` and let us know if the issue still persists? Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "@sushreebarsa, thank you for your suggestions. We checked it and got some compilation errors when building tensorflow.\r\n\r\nI am closing this issue as it is a very old one. We switched to using tensorflow-testing/nosla-cuda11.2-cudnn8.1-ubuntu18.04-manylinux2010-multipython docker image a few months ago since tensorflow/tensorflow:custom-op-gpu-ubuntu16 does not get updated any more.\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45032\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45032\">No</a>\n"]}, {"number": 45031, "title": "[INTEL_MKL] Enable MatMul + Bias + LeakyRelu fusion", "body": "This PR enables  MatMul + Bias + LeakyRelu fusion with both MKL and Eigen implementation", "comments": ["Merge conflict is resolved. Please review this PR. Thanks", "Thanks for the review. The code is changed based on comments.", "The UT failure is fixed.  \r\nMatMul+Bias+Tanh fusion is enabled in MKL only currently. It should not be tested in RemapperTest with normal Tensorflow.   \r\nMerry Christmas."]}, {"number": 45029, "title": "Update PCRE library from 8.42 to 8.44", "body": "This PR updates PCRE library from 8.42 to 8.44.\r\n\r\nNote there is a CVE related to old 8.42 (https://nvd.nist.gov/vuln/detail/CVE-2019-20838#VulnChangeHistorySection)\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Sorry for the delay, a bug in GitHub made me not see this notification in time."]}, {"number": 45028, "title": "CUDNN_STATUS_NOT_INITIALIZED error with tensorflow-gpu 2.4.0-rc2 RTX3070 CUDA11.0 cudnn8.0.2 windows10 and pip", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: --\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.4.0rc2\r\n- Python version :3.8.5\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): --\r\n- GCC/Compiler version (if compiling from source): --\r\n- CUDA/cuDNN version: CUDA11.0 cudnn-11.0-windows-x64-v8.0.2.39  graphics driver version: 457.30\r\n- GPU model and memory: RTX 3070 8G\r\n\r\n\r\n\r\n**Describe the problem**\r\nI install cuda cudnn following the requirement for TensorFlow-gpu 2.4.0-rc2 as shown in https://github.com/tensorflow/tensorflow/releases, but get cudnn initialization error. I have uninstalled and reinstalled for several times, and I also tried TensorFlow-gpu 2.4.0-rc1 several days ago, the same errer was raised.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nThe following is the code to re produce the error:\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.keras.models import Sequential\r\n\r\n\r\nx = np.random.normal(size=(100, 28, 28, 1)).astype(np.float32)\r\ny = np.zeros([100, 10], dtype=np.float32)\r\ny[:, 1] = 1.\r\n\r\ntrain_ds = tf.data.Dataset.from_tensor_slices((x, y)).shuffle(buffer_size=100).batch(32)\r\nnum_classes = 10\r\n\r\nmodel = Sequential([\r\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\r\n  layers.MaxPooling2D(),\r\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\r\n  layers.MaxPooling2D(),\r\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\r\n  layers.MaxPooling2D(),\r\n  layers.Flatten(),\r\n  layers.Dense(128, activation='relu'),\r\n  layers.Dense(num_classes)\r\n])\r\nmodel.compile(optimizer='adam',\r\n              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\r\n              metrics=['accuracy'])\r\nepochs=10\r\nhistory = model.fit(\r\n  train_ds,\r\n  epochs=epochs\r\n)\r\n```\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nlogs:\r\n```\r\n2020-11-20 11:38:38.097262: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2020-11-20 11:38:40.566842: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-11-20 11:38:40.568068: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll\r\n2020-11-20 11:38:40.604223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:65:00.0 name: GeForce RTX 3070 computeCapability: 8.6\r\ncoreClock: 1.815GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\r\n2020-11-20 11:38:40.604439: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2020-11-20 11:38:40.618831: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2020-11-20 11:38:40.618938: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2020-11-20 11:38:40.622412: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n2020-11-20 11:38:40.623498: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n2020-11-20 11:38:40.631377: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\r\n2020-11-20 11:38:40.633911: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n2020-11-20 11:38:40.634568: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2020-11-20 11:38:40.634734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2020-11-20 11:38:40.635316: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-11-20 11:38:40.636515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:65:00.0 name: GeForce RTX 3070 computeCapability: 8.6\r\ncoreClock: 1.815GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\r\n2020-11-20 11:38:40.637060: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2020-11-20 11:38:40.637713: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2020-11-20 11:38:40.638072: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2020-11-20 11:38:40.638277: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n2020-11-20 11:38:40.638448: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n2020-11-20 11:38:40.638724: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\r\n2020-11-20 11:38:40.638921: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n2020-11-20 11:38:40.639189: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2020-11-20 11:38:40.639443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2020-11-20 11:38:41.262522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-11-20 11:38:41.262635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \r\n2020-11-20 11:38:41.262694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \r\n2020-11-20 11:38:41.262900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6177 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3070, pci bus id: 0000:65:00.0, compute capability: 8.6)\r\n2020-11-20 11:38:41.263873: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\nEpoch 1/10\r\n2020-11-20 11:38:42.052106: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\r\n2020-11-20 11:38:42.135350: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2020-11-20 11:38:42.994775: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2020-11-20 11:38:43.000109: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2020-11-20 11:38:43.875475: E tensorflow/stream_executor/cuda/cuda_dnn.cc:336] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED\r\n2020-11-20 11:38:43.875620: E tensorflow/stream_executor/cuda/cuda_dnn.cc:340] Error retrieving driver version: Unimplemented: kernel reported driver version not implemented on Windows\r\n2020-11-20 11:38:43.877456: E tensorflow/stream_executor/cuda/cuda_dnn.cc:336] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED\r\n2020-11-20 11:38:43.877755: E tensorflow/stream_executor/cuda/cuda_dnn.cc:340] Error retrieving driver version: Unimplemented: kernel reported driver version not implemented on Windows\r\nTraceback (most recent call last):\r\n  File \"F:/python_ws/helloworld/main.py\", line 29, in <module>\r\n    history = model.fit(\r\n  File \"C:\\Users\\dell\\Anaconda3\\envs\\tf24rcpy38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1100, in fit\r\n    tmp_logs = self.train_function(iterator)\r\n  File \"C:\\Users\\dell\\Anaconda3\\envs\\tf24rcpy38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 828, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"C:\\Users\\dell\\Anaconda3\\envs\\tf24rcpy38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 888, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"C:\\Users\\dell\\Anaconda3\\envs\\tf24rcpy38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2942, in __call__\r\n    return graph_function._call_flat(\r\n  File \"C:\\Users\\dell\\Anaconda3\\envs\\tf24rcpy38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1918, in _call_flat\r\n    return self._build_call_outputs(self._inference_function.call(\r\n  File \"C:\\Users\\dell\\Anaconda3\\envs\\tf24rcpy38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 555, in call\r\n    outputs = execute.execute(\r\n  File \"C:\\Users\\dell\\Anaconda3\\envs\\tf24rcpy38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 59, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[node sequential/conv2d/Conv2D (defined at F:/python_ws/helloworld/main.py:29) ]] [Op:__inference_train_function_830]\r\n\r\nFunction call stack:\r\ntrain_function\r\n\r\n\r\nProcess finished with exit code 1\r\n```", "comments": ["Same issue here on linux\r\n\r\n## System \r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04 LTS\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: --\r\nTensorFlow installed from (source or binary): binary\r\nTensorFlow version: 2.5.0-dev20201119\r\nPython version :3.8.5\r\nInstalled using virtualenv? pip? conda?: pip\r\nBazel version (if compiling from source): --\r\nCC/Compiler version (if compiling from source): --\r\nCUDA/cuDNN version: CUDA 11.1 - cudnn 8.0.5\r\nGPU model and memory: RTX 3080 10016MiB\r\n\r\n\r\n```\r\n/usr/bin/python3.8 /home/noobzik/Documents/deep_learning_day2/test.py\r\n2020-11-20 09:08:11.149682: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n2020-11-20 09:08:12.068627: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-11-20 09:08:12.069149: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n2020-11-20 09:08:12.098515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-20 09:08:12.099146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1727] Found device 0 with properties: \r\npciBusID: 0000:08:00.0 name: GeForce RTX 3080 computeCapability: 8.6\r\ncoreClock: 1.71GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s\r\n2020-11-20 09:08:12.099167: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n2020-11-20 09:08:12.101469: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\r\n2020-11-20 09:08:12.101524: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\r\n2020-11-20 09:08:12.102397: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2020-11-20 09:08:12.102612: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2020-11-20 09:08:12.105025: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2020-11-20 09:08:12.105664: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\r\n2020-11-20 09:08:12.105792: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\r\n2020-11-20 09:08:12.105901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-20 09:08:12.106646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-20 09:08:12.107247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1869] Adding visible gpu devices: 0\r\n2020-11-20 09:08:12.107522: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-11-20 09:08:12.108178: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-11-20 09:08:12.108256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-20 09:08:12.108699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1727] Found device 0 with properties: \r\npciBusID: 0000:08:00.0 name: GeForce RTX 3080 computeCapability: 8.6\r\ncoreClock: 1.71GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s\r\n2020-11-20 09:08:12.108716: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n2020-11-20 09:08:12.108728: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\r\n2020-11-20 09:08:12.108736: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\r\n2020-11-20 09:08:12.108744: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2020-11-20 09:08:12.108752: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2020-11-20 09:08:12.108760: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2020-11-20 09:08:12.108768: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\r\n2020-11-20 09:08:12.108785: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\r\n2020-11-20 09:08:12.108846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-20 09:08:12.109331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-20 09:08:12.109761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1869] Adding visible gpu devices: 0\r\n2020-11-20 09:08:12.109787: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n2020-11-20 09:08:12.519303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-11-20 09:08:12.519333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1273]      0 \r\n2020-11-20 09:08:12.519339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1286] 0:   N \r\n2020-11-20 09:08:12.519512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-20 09:08:12.520184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-20 09:08:12.520627: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-20 09:08:12.521050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1413] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8306 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3080, pci bus id: 0000:08:00.0, compute capability: 8.6)\r\nEpoch 1/10\r\n2020-11-20 09:08:12.960040: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:127] None of the MLIR optimization passes are enabled (registered 2)\r\n2020-11-20 09:08:12.962440: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3193620000 Hz\r\n2020-11-20 09:08:13.021345: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\r\n2020-11-20 09:08:13.564688: I tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Loaded cuDNN version 8005\r\n2020-11-20 09:08:14.155647: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256\r\n2020-11-20 09:08:14.198183: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \r\nRelying on driver to perform ptx compilation. \r\nModify $PATH to customize ptxas location.\r\nThis message will be only logged once.\r\n2020-11-20 09:08:15.458184: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\r\n2020-11-20 09:08:15.543012: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2020-11-20 09:08:16.853135: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2020-11-20 09:08:18.129453: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2020-11-20 09:08:18.131488: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2020-11-20 09:08:18.131506: W tensorflow/stream_executor/stream.cc:1455] attempting to perform BLAS operation using StreamExecutor without BLAS support\r\nTraceback (most recent call last):\r\n  File \"/home/noobzik/Documents/deep_learning_day2/test.py\", line 28, in <module>\r\n    history = model.fit(\r\n  File \"/home/noobzik/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 1103, in fit\r\n    tmp_logs = self.train_function(iterator)\r\n  File \"/home/noobzik/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 784, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/home/noobzik/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 844, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"/home/noobzik/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 2971, in __call__\r\n    return graph_function._call_flat(\r\n  File \"/home/noobzik/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 1947, in _call_flat\r\n    return self._build_call_outputs(self._inference_function.call(\r\n  File \"/home/noobzik/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 556, in call\r\n    outputs = execute.execute(\r\n  File \"/home/noobzik/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.InternalError:  Blas xGEMM launch failed : a.shape=[1,32,576], b.shape=[1,576,128], m=32, n=128, k=576\r\n\t [[node sequential/dense/MatMul (defined at /Documents/deep_learning_day2/test.py:28) ]] [Op:__inference_train_function_830]\r\n\r\nFunction call stack:\r\ntrain_function\r\n\r\n\r\nProcess finished with exit code 1\r\n```", "I'm also experiencing similar issue for the following minimum example, with an RTX 3070.\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.keras.layers as layers\r\nimport numpy as np\r\n\r\nx = np.random.normal(size=(100, 28, 28, 1)).astype(np.float32)\r\ny = np.zeros([100, 10], dtype=np.float32)\r\ny[:, 1] = 1.\r\n\r\ntrain_ds = tf.data.Dataset.from_tensor_slices((x, y)).shuffle(buffer_size=100).batch(32)\r\nnum_classes = 10\r\n\r\nmodel = tf.keras.Sequential([\r\n    layers.Conv2D(16, 3, padding='same', activation='relu'),\r\n    layers.MaxPooling2D(),\r\n    layers.Flatten(),\r\n    layers.Dense(128, activation='relu'),\r\n    layers.Dense(num_classes)\r\n])\r\nmodel.compile(optimizer='adam',\r\n    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\r\n    metrics=['accuracy'])\r\nepochs=10\r\nhistory = model.fit(\r\n    train_ds,\r\n    epochs=epochs\r\n)\r\n```\r\n\r\nRunning the script above produces this error.\r\n\r\n```\r\n2020-11-23 16:25:25.510389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7208 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6)\r\nEpoch 1/10\r\n2020-11-23 16:25:25.887983: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\r\n2020-11-23 16:25:25.901960: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3699850000 Hz\r\n2020-11-23 16:25:25.948792: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\r\n2020-11-23 16:25:26.513272: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\r\n2020-11-23 16:25:26.515165: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\r\n2020-11-23 16:25:26.969194: E tensorflow/stream_executor/cuda/cuda_dnn.cc:336] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\n2020-11-23 16:25:26.971093: E tensorflow/stream_executor/cuda/cuda_dnn.cc:336] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\nTraceback (most recent call last):\r\n  File \"problem.py\", line 31, in <module>\r\n    epochs=epochs\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 1100, in fit\r\n    tmp_logs = self.train_function(iterator)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 828, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 888, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 2943, in __call__\r\n    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1919, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 560, in call\r\n    ctx=ctx)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\r\n    inputs, attrs, num_outputs)\r\ntensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n         [[node sequential/conv2d/Conv2D (defined at problem.py:31) ]] [Op:__inference_train_function_654]\r\n\r\nFunction call stack:\r\ntrain_function\r\n```\r\n\r\n**System information**\r\n\r\n* OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 in docker image `nvidia/cuda:11.0-cudnn8-runtime-ubuntu18.04`\r\n* Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: --\r\n* TensorFlow installed from (source or binary): binary\r\n* TensorFlow version: `2.4.0rc2`\r\n* Python version: `3.6.9`\r\n* Installed using virtualenv? pip? conda?: `pip`\r\n* Bazel version (if compiling from source): --\r\n* GCC/Compiler version (if compiling from source): --\r\n* CUDA/cuDNN version: CUDA 11.0\r\n* GPU model and memory: RTX 3070 8G", "Add this to the start of your code \r\n`physical_devices = tf.config.list_physical_devices('GPU') tf.config.experimental.set_memory_growth(physical_devices[0], True)`. I tried the code on my system and without it this does not work. After adding the above code it works. ", "I am having the same issues.\r\n\r\nAfter king398's fix, error CUDNN_STATUS_NOT_INITIALIZED error no longer appears, but epochs do not run. \r\n\r\n\r\n\r\nWindows 10, RTX 3070", "@Bchi1994 Please give your console log because when i tried it with my fix it worked.\r\n\r\n![image](https://user-images.githubusercontent.com/58468909/99986403-252e3000-2dd5-11eb-85aa-34e15900e657.png)\r\n", "console log below. Notebook stops at Epoch 1/10. First epoch doesn't even run.\r\n\r\n![image](https://user-images.githubusercontent.com/66197527/99986697-5b7f9700-2d64-11eb-8c2f-e8395773114f.png)\r\n\r\n![image](https://user-images.githubusercontent.com/66197527/99986749-72be8480-2d64-11eb-9c75-7a33b3d7f067.png)\r\n", "@Bchi1994 That is weird because  i also have a rtx 3070 and it works fine and the console log have nothing wrong. Can your try something other than jupyter notebook and something like vscode or pycharm.\r\n  ", "Try this code:\r\n`\r\nimport tensorflow as tf\r\nimport tensorflow.keras.layers as layers\r\nimport numpy as np\r\nphysical_devices = tf.config.list_physical_devices('GPU')\r\ntf.config.experimental.set_memory_growth(physical_devices[0], True)\r\nx = np.random.normal(size=(100, 28, 28, 1)).astype(np.float32)\r\ny = np.zeros([100, 10], dtype=np.float32)\r\ny[:, 1] = 1.\r\n\r\ntrain_ds = tf.data.Dataset.from_tensor_slices((x, y)).shuffle(buffer_size=100).batch(32)\r\nnum_classes = 10\r\n\r\nmodel = tf.keras.Sequential([\r\n    layers.Conv2D(16, 3, padding='same', activation='relu'),\r\n    layers.MaxPooling2D(),\r\n    layers.Flatten(),\r\n    layers.Dense(128, activation='relu'),\r\n    layers.Dense(num_classes)\r\n])\r\nmodel.compile(optimizer='adam',\r\n    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\r\n    metrics=['accuracy'])\r\nepochs=10\r\nhistory = model.fit(\r\n    train_ds,\r\n    epochs=epochs\r\n)\r\n`", "Please give me your code you are using\r\n.", "Just tried that code. Same issue.\r\n\r\nWhat versions of tesnforflow, CUDA and cudnn are you using?\r\n\r\nAlso versions of Numpy and Keras?\r\n\r\n", "Tensorflow version- 2.4.0rc2\r\nCUDA - 11.1\r\nCuddn - 8.0.4\r\n", "Try using tf.keras instead of keras\r\n", "Keras - 2.3.1\r\nNumpy - 1.19.3", "Ok. Thank. I am going to try a fresh install of CUDA, Cudnn files and a new kernel", "Wait. It just did something funky. Check this out. It is running on my GPU. Epochs continue to run, but slowly.\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/66197527/99987515-6d156e80-2d65-11eb-8a1e-b4ebb667852e.png)\r\n", "What funky  stuff you did\r\n", "Also try reinstalling tensorflow with this\r\n`pip install tensorflow-gpu==2.4.0rc2`", "Ah found what you did wrong. You are using cuda 11.0 use cuda 11.1 instead\r\n", "So it runs. First epoch takes forever. I will try CUDA 11.1 Still getting subprocess errors\r\n\r\n![image](https://user-images.githubusercontent.com/66197527/99989188-2d4f8680-2d67-11eb-9d76-3d70f5464ccb.png)\r\n\r\n", "Still better than no training at all. Please share your results  with cuda 11.1 I think it will solve the issue.Also if any error arise tell me because I also had many during my installation. I think it is an issue of ptx compile  because of you using cuda 11.0 not 11.1\r\n", "King, thanks for all of the help. I will report back with CUDA 11.1", "King - Can you please try running this. Let me know if this works (zip file attached).\r\n\r\nCUDA 11.1 did speed up the code you pasted and I was able to get that to run. But still can't run the attached code in the zip file. Are you able to successfully run the attached code?\r\n[tensorflow-gpu-tutorial.zip](https://github.com/tensorflow/tensorflow/files/5585014/tensorflow-gpu-tutorial.zip)\r\n\r\nI am on Keras 2.3.1 now - Just an FYI.\r\n![image](https://user-images.githubusercontent.com/66197527/100004391-47479400-2d7c-11eb-8249-21f74af7d66a.png)\r\n\r\nThe problems seems to be sources from anything imported from \"tensorflow.keras.utils\". Other code with this import will not work. \r\n", "> Add this to the start of your code\r\n> `physical_devices = tf.config.list_physical_devices('GPU') tf.config.experimental.set_memory_growth(physical_devices[0], True)`. I tried the code on my system and without it this does not work. After adding the above code it works.\r\n\r\nYep, It works, But slowly...like with CPU...My last card(2070s) much better...\r\nMaybe we need to wait for TensorFlow 2.4.0 stable?..", "@iMacroC What is your cuda version Because my 3070 is much faster than my cpu", "@Bchi1994 the code works after adding my fix. Try this\r\n`import tensorflow as tf \r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense\r\nfrom tensorflow.keras.layers import Dropout\r\nfrom tensorflow.keras.layers import LSTM\r\nfrom tensorflow.keras.layers import Embedding\r\nfrom tensorflow.keras.layers import Flatten\r\nfrom tensorflow.keras.callbacks import ModelCheckpoint\r\nfrom keras.utils import np_utils\r\nphysical_devices = tf.config.list_physical_devices('GPU')\r\ntf.config.experimental.set_memory_growth(physical_devices[0], True)\r\n# reshape X to be [samples, time steps, features]\r\n#X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\r\nX = numpy.reshape(dataX, (n_patterns, seq_length, 1))\r\n\r\n# normalize\r\nX = X / float(n_vocab)\r\n\r\n# one hot encode the output variable\r\ny = np_utils.to_categorical(dataY)\r\n\r\n\r\n# define the LSTM model\r\nmodel = Sequential()\r\nmodel.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]),return_sequences=True))\r\nmodel.add(Dropout(0.25))\r\nmodel.add(LSTM(128))\r\nmodel.add(Dropout(0.25))\r\nmodel.add(Dense(y.shape[1], activation='softmax'))\r\nmodel.compile(loss='categorical_crossentropy', optimizer='adam')\r\n\r\n\r\n# define the checkpoint\r\nfilepath=\"weights\\weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\r\ncheckpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\r\ncallbacks_list = [checkpoint]\r\n\r\n\r\nhistory = model.fit(X, y, epochs=10, batch_size=128, callbacks=callbacks_list)`", "> @iMacroC What is your cuda version Because my 3070 is much faster than my cpu\r\n\r\nthanks for your reply, my cuda version is 11.1 and cudnn 8.0.5(i also tried 8.0.4), and I tried tf-nightly latest.", "@iMacroC update your driver version and please give your cuda version", "> @iMacroC update your driver version and please give your cuda version\r\nmy graphcard version is the latest. cuda version:11.1\r\n", "driver version:457.30", "@king398 the added code did not resolve the issue.\r\n\r\n![image](https://user-images.githubusercontent.com/66197527/100039550-47ff1b00-2dba-11eb-8f75-2e9345f18989.png)\r\n\r\ndriver version:457.30 as well\r\n", "> @iMacroC update your driver version and please give your cuda version\r\n\r\n![image](https://user-images.githubusercontent.com/38845682/100040037-7ecc4400-2e41-11eb-9158-92397faa5d98.png)\r\nand the GPU always take up less than 10%", "@iMacroC Well because  the tensor core usage does not show up in task manager. And please give your code.", "@iMacroC Please downgrade your cudnn version 8.0.4", "> @iMacroC Well because the tensor core usage does not show up in task manager. And please give your code.\r\n\r\nI'm sure that bug is nothing to do with any code Because It still likes that when I run another code.", "> @iMacroC Please downgrade your cudnn version 8.0.4\r\n\r\nI'm trying.", "> @iMacroC Well because the tensor core usage does not show up in task manager. And please give your code.\r\n\r\nWell, I think it works, I saw It took up 3.9GB of GPU memory, and I ran it with CPU that really much faster than CPU.\r\nMaybe It works a few days ago but I didn't notice it, I'm dumb\ud83d\ude02.\r\nThank you a lot, king have a nice day~", "> Add this to the start of your code\r\n> `physical_devices = tf.config.list_physical_devices('GPU') tf.config.experimental.set_memory_growth(physical_devices[0], True)`. I tried the code on my system and without it this does not work. After adding the above code it works.\r\n\r\nThanks. After doing this, it works, but with a lot of \" **SubProcess ended with return code**: 4294967295\" logs.\r\nHere are the logs:\r\n\r\n```\r\nC:\\Users\\dell\\Anaconda3\\envs\\tf24rcpy38\\python.exe F:/python_ws/helloworld/main.py\r\n2020-11-24 11:00:38.194273: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2020-11-24 11:00:42.903949: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-11-24 11:00:42.913020: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll\r\n2020-11-24 11:00:43.020016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:65:00.0 name: GeForce RTX 3070 computeCapability: 8.6\r\ncoreClock: 1.815GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\r\n2020-11-24 11:00:43.020975: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2020-11-24 11:00:43.704812: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2020-11-24 11:00:43.705024: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2020-11-24 11:00:43.819171: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n2020-11-24 11:00:43.882861: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n2020-11-24 11:00:44.261355: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\r\n2020-11-24 11:00:44.553173: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n2020-11-24 11:00:44.561022: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2020-11-24 11:00:44.561879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2020-11-24 11:00:44.573103: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-11-24 11:00:44.575050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:65:00.0 name: GeForce RTX 3070 computeCapability: 8.6\r\ncoreClock: 1.815GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\r\n2020-11-24 11:00:44.575246: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2020-11-24 11:00:44.575382: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2020-11-24 11:00:44.575508: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2020-11-24 11:00:44.575607: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n2020-11-24 11:00:44.575703: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n2020-11-24 11:00:44.575798: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\r\n2020-11-24 11:00:44.575892: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n2020-11-24 11:00:44.575989: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2020-11-24 11:00:44.576126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2020-11-24 11:00:45.884370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-11-24 11:00:45.884634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \r\n2020-11-24 11:00:45.884828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \r\n2020-11-24 11:00:45.886725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6177 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3070, pci bus id: 0000:65:00.0, compute capability: 8.6)\r\n2020-11-24 11:00:45.890140: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\nEpoch 1/10\r\n2020-11-24 11:00:46.609881: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\r\n2020-11-24 11:00:46.727182: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2020-11-24 11:00:48.641407: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2020-11-24 11:00:48.664931: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2020-11-24 11:00:55.465955: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 0\r\n\r\n2020-11-24 11:00:55.476935: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 4294967295\r\n\r\n2020-11-24 11:00:55.477355: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code -1, output: \r\nRelying on driver to perform ptx compilation. \r\nModify $PATH to customize ptxas location.\r\nThis message will be only logged once.\r\n2020-11-24 11:00:55.495264: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 4294967295\r\n\r\n2020-11-24 11:00:55.505659: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 4294967295\r\n\r\n2020-11-24 11:00:55.513483: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 4294967295\r\n\r\n...(lots of SubProcess ended with return code: 4294967295)\r\n\r\n2020-11-24 11:00:56.210145: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\r\n...(lots of SubProcess ended with return code: 4294967295)\r\n\r\n1/4 [======>.......................] - ETA: 48s - loss: 2.4265 - accuracy: 0.0000e+002020-11-24 11:01:02.215221: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 4294967295\r\n\r\n...(lots of SubProcess ended with return code: 4294967295)\r\n\r\n4/4 [==============================] - 18s 601ms/step - loss: 1.8508 - accuracy: 0.5053\r\nEpoch 2/10\r\n4/4 [==============================] - 0s 5ms/step - loss: 0.0721 - accuracy: 1.0000\r\nEpoch 3/10\r\n4/4 [==============================] - 0s 5ms/step - loss: 4.0893e-05 - accuracy: 1.0000\r\nEpoch 4/10\r\n4/4 [==============================] - 0s 6ms/step - loss: 3.6856e-09 - accuracy: 1.0000\r\nEpoch 5/10\r\n4/4 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000\r\nEpoch 6/10\r\n4/4 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000\r\nEpoch 7/10\r\n4/4 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\r\nEpoch 8/10\r\n4/4 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000\r\nEpoch 9/10\r\n4/4 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000\r\nEpoch 10/10\r\n4/4 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000\r\n\r\nProcess finished with exit code 0\r\n```", "@SilenceEagle Well at least it works nonetheless. Also the reason for it is that you are using cuda 11.0 use 11.1 instead.", "> > @iMacroC Well because the tensor core usage does not show up in task manager. And please give your code.\r\n> \r\n> Well, I think it works, I saw It took up 3.9GB of GPU memory, and I ran it with CPU that really much faster than CPU.\r\n> Maybe It works a few days ago but I didn't notice it, I'm dumb\ud83d\ude02.\r\n> Thank you a lot, king have a nice day~\r\n\r\nHaha glad it works. installing tensor flow is harder than using it ", "> > > @iMacroC Well because the tensor core usage does not show up in task manager. And please give your code.\r\n> > \r\n> > \r\n> > Well, I think it works, I saw It took up 3.9GB of GPU memory, and I ran it with CPU that really much faster than CPU.\r\n> > Maybe It works a few days ago but I didn't notice it, I'm dumb\ud83d\ude02.\r\n> > Thank you a lot, king have a nice day~\r\n> \r\n> Haha glad it works. installing tensor flow is harder than using it\r\n\r\nty~", "> @SilenceEagle Well at least it works nonetheless. Also the reason for it is that you are using cuda 11.0 use 11.1 instead.\r\n\r\nthanks again", "@king398, what cudatoolkit version do you have when you conda list?", "@Bchi1994 i am using pip", "@king398, what cudatoolkit version do you have when you pip list?", "@Bchi1994 cuda 11.1 and cudnn 8.0.4", "@king398, thanks! I will create a new ticket", "@Bchi1994 I hope I helped you", "@king398  I update to cuda11.1 and cudnn 8.0.4 on win10, then re run the code , then get ERROR: **could not load dynamic library 'cusolver64_10.dll'; dlerror: cusolver64_10.dll not found**, here are the logs:\r\n```\r\nC:\\Users\\dell\\Anaconda3\\envs\\tf24rc1py36\\python.exe F:/python_ws/helloworld/main.py\r\n2020-11-24 15:31:41.471855: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2020-11-24 15:31:43.575381: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-11-24 15:31:43.575947: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll\r\n2020-11-24 15:31:43.604386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:65:00.0 name: GeForce RTX 3070 computeCapability: 8.6\r\ncoreClock: 1.815GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\r\n2020-11-24 15:31:43.604578: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2020-11-24 15:31:43.619126: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2020-11-24 15:31:43.619306: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2020-11-24 15:31:43.622735: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n2020-11-24 15:31:43.623815: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n2020-11-24 15:31:43.624574: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cusolver64_10.dll'; dlerror: cusolver64_10.dll not found\r\n2020-11-24 15:31:43.627545: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n2020-11-24 15:31:43.628190: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2020-11-24 15:31:43.628767: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\nTraceback (most recent call last):\r\n  File \"F:/python_ws/helloworld/main.py\", line 7, in <module>\r\n    tf.config.experimental.set_memory_growth(physical_devices[0], True)\r\nIndexError: list index out of range\r\n\r\nProcess finished with exit code 1\r\n```\r\nThen I follow the suggest from [https://github.com/tensorflow/tensorflow/issues/44291#issuecomment-716165602](https://github.com/tensorflow/tensorflow/issues/44291#issuecomment-716165602) to copy the cusolver64_10.dll from 11.0\\bin to 11.1\\bin. It works, but also raises a lot of **SubProcess ended with return code: 4294967295** with cuda11.1:\r\n```\r\nC:\\Users\\dell\\Anaconda3\\envs\\tf24rc1py36\\python.exe F:/python_ws/helloworld/main.py\r\n2020-11-24 15:40:49.251398: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2020-11-24 15:40:51.479650: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-11-24 15:40:51.480425: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll\r\n2020-11-24 15:40:51.517736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:65:00.0 name: GeForce RTX 3070 computeCapability: 8.6\r\ncoreClock: 1.815GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\r\n2020-11-24 15:40:51.517929: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2020-11-24 15:40:51.539764: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2020-11-24 15:40:51.540060: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2020-11-24 15:40:51.544531: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n2020-11-24 15:40:51.545737: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n2020-11-24 15:40:51.550261: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\r\n2020-11-24 15:40:51.553451: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n2020-11-24 15:40:51.554099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2020-11-24 15:40:51.554297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2020-11-24 15:40:51.558503: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-11-24 15:40:51.559314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:65:00.0 name: GeForce RTX 3070 computeCapability: 8.6\r\ncoreClock: 1.815GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\r\n2020-11-24 15:40:51.559535: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2020-11-24 15:40:51.559632: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2020-11-24 15:40:51.559726: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2020-11-24 15:40:51.559827: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n2020-11-24 15:40:51.559920: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n2020-11-24 15:40:51.560022: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\r\n2020-11-24 15:40:51.560117: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n2020-11-24 15:40:51.560214: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2020-11-24 15:40:51.560372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2020-11-24 15:40:52.181967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-11-24 15:40:52.182085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \r\n2020-11-24 15:40:52.182148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \r\n2020-11-24 15:40:52.182387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6177 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3070, pci bus id: 0000:65:00.0, compute capability: 8.6)\r\n2020-11-24 15:40:52.183284: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\nEpoch 1/10\r\n2020-11-24 15:40:52.605971: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\r\n2020-11-24 15:40:52.674317: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2020-11-24 15:40:53.621868: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2020-11-24 15:40:53.626698: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2020-11-24 15:40:55.528792: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 0\r\n\r\n2020-11-24 15:40:55.540214: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 4294967295\r\n\r\n2020-11-24 15:40:55.540714: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code -1, output: \r\nRelying on driver to perform ptx compilation. \r\nModify $PATH to customize ptxas location.\r\nThis message will be only logged once.\r\n2020-11-24 15:40:55.553723: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 4294967295\r\n2020-11-24 15:40:55.565792: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 4294967295\r\n...(lots of )\r\n2020-11-24 15:40:56.419765: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\r\nEpoch 1/10\r\n1/4 [======>.......................] - ETA: 16s - loss: 2.4413 - accuracy: 0.0000e+002020-11-24 15:40:57.710428: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 4294967295\r\n4/4 [==============================] - 7s 603ms/step - loss: 1.7298 - accuracy: 0.5053\r\nEpoch 2/10\r\n4/4 [==============================] - 0s 7ms/step - loss: 0.0242 - accuracy: 1.0000\r\nEpoch 3/10\r\n4/4 [==============================] - 0s 8ms/step - loss: 2.5926e-05 - accuracy: 1.0000\r\nEpoch 4/10\r\n4/4 [==============================] - 0s 8ms/step - loss: 1.4742e-08 - accuracy: 1.0000\r\nEpoch 5/10\r\n4/4 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000\r\nEpoch 6/10\r\n4/4 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\r\nEpoch 7/10\r\n4/4 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\r\nEpoch 8/10\r\n4/4 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000\r\nEpoch 9/10\r\n4/4 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - accuracy: 1.0000\r\nEpoch 10/10\r\n4/4 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000\r\n\r\nProcess finished with exit code 0\r\n```\r\nIt seems the **SubProcess ended with return code: 4294967295** couldn't be solved by updating to cuda11.1.\r\n\r\nHowever, the code works, so my primary issue has been solved. Thanks again!", "@SilenceEagle No problem. You can raise a issue for that ", ">  No problem. You can raise a issue for that\r\nhey king need help same issue 3070 not picking up  by the tensorflow \r\n\r\n", "@rahat14  what problems does it give", "cusolver64-10.dll not found but I have Cuda 11.1 and cudnn lastest one . \r\nTF Version -2.5.0-dev2020112 @king398", "@rahat14 see this https://github.com/tensorflow/tensorflow/issues/44159", "@king398 hi king, i met the same issue. my environment is: cuda 11.1, nvidia-driver: 457.51, cudnn: 8.0.4 , os:win10. tensorflow-gpu:2.4.0. \r\n![image](https://user-images.githubusercontent.com/76204413/102598290-c307e700-4156-11eb-8298-9013e5ddb08d.png)\r\n thanks sooo much if you could help.\r\ni have tried cudnn8.0.5, the save issue.\r\n", "Add this to the start of your code\nphysical_devices = tf.config.list_physical_devices('GPU') tf.config.experimental.set_memory_growth(physical_devices[0], True). I tried the code on my system and without it this does not work. After adding the above code it works.", "@king398 Hi King, the two lines above solved for me too! Thanks!!\r\n\r\nMy setup:\r\ntensorflow 2.4.0\r\n\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 452.56       Driver Version: 452.56       CUDA Version: 11.0     |\r\n|-------------------------------+----------------------+----------------------+\r\n\r\nCuda compilation tools, release 11.0, V11.0.221\r\nBuild cuda_11.0_bu.relgpu_drvr445TC445_37.28845127_0\r\n\r\ncuDNN 8.0.5\r\n", "@mschio No problem \r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45028\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45028\">No</a>\n"]}, {"number": 45027, "title": "Fixed typo in documentation", "body": "", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 45025, "title": "AttributeError: 'TFLiteConverter' object has no attribute 'target_spec'", "body": " URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/lite/performance/post_training_quantization\r\n\r\n## Description of issue:\r\n\r\ni want to quant my model with int8, my code like this:\r\n\r\n\r\nimport tensorflow as tf\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model_file(\"./tf_keras_mnist_model/cifar10_vgg16.h5\")\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\ndef representative_dataset_gen():\r\n  for _ in range(10):\r\n    # Get sample input data as a numpy array in a method of your choosing.\r\n    yield [input]\r\nconverter.representative_dataset = representative_dataset_gen\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.inference_input_type = tf.int8  # or tf.uint8\r\nconverter.inference_output_type = tf.int8  # or tf.uint8\r\ntflite_quant_model = converter.convert()\r\nopen(\"./tf_keras_mnist_model/cifar10_vgg16_quant8.tflite\", \"wb\").write(tflite_quant_model)\r\n\r\nthis code is also in your example provided, but I get the error like the title.\r\n my tf is 1.14.\r\nhow can i solute this problem?\r\n\r\nthe second question is :\r\nwhen i use   tf.lite.TFLiteConverter.from_keras_model,   i got the error TFLiteConverter has no attribute from_keras_model, i also encount the problem   TFLiteConverter has no attribute from_saved_model?\r\n\r\nthis two api need the tf version?\r\n\r\nthanks \r\n\r\nappreciate to get your apply!\r\n", "comments": ["@lxiao217,\r\nTensorFlow 1.x is not actively supported. Could you please update TensorFlow to v2.3 and check if you are facing the same error?\r\n\r\n> when i use tf.lite.TFLiteConverter.from_keras_model, i got the error TFLiteConverter has no attribute from_keras_model, i also encount the problem TFLiteConverter has no attribute from_saved_model?\r\n\r\nSeems like you are running code meant for TF 2.x, on TF 1.x. `from_keras_model` and `from_saved_model` are APIs of TensorFlow 2.x. For more information please take a look at the [documentation](https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter#from_keras_model) for TFLiteConverter. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "> @lxiao217,\r\n> TensorFlow 1.x is not actively supported. Could you please update TensorFlow to v2.3 and check if you are facing the same error?\r\n> \r\n> > when i use tf.lite.TFLiteConverter.from_keras_model, i got the error TFLiteConverter has no attribute from_keras_model, i also encount the problem TFLiteConverter has no attribute from_saved_model?\r\n> \r\n> Seems like you are running code meant for TF 2.x, on TF 1.x. `from_keras_model` and `from_saved_model` are APIs of TensorFlow 2.x. For more information please take a look at the [documentation](https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter#from_keras_model) for TFLiteConverter. Thanks!\r\n\r\nthanks for your reply, i think the problem is I trained the model on 1.x while i use the 2.x apis to convert.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45025\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45025\">No</a>\n"]}, {"number": 45024, "title": "Could not create TensorFlow Graph: Not found: Op type not registered 'AddV2'  IOS", "body": "Using tensorFlow_gpu==1.15.0, ssD_mobilenet_V1 is trained through TensorFlow API. Then  \r\nmodels-master\\research\\object_detection>python export_inference_graph.py\r\n --input_type image_tensor \r\n--pipeline_config_path  /data/pipeline.config \r\n--trained_checkpoint_prefix  /training/model.ckpt-200000 \r\n--output_directory  convert_pb/\r\n Get frozen_inference_graph.pb,\r\nThis frozen_inference_graph.pb file is applied to IOS to report an error,\r\n/Users/zhao/Desktop/tensorflow-1.15.0/tensorflow/examples/ios/camera/tensorflow_utils.mm:140] Could not create TensorFlow Graph: Not found: Op type not registered 'AddV2'\r\n", "comments": ["@zhidk \r\nWe see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced]\r\nPlease upgrade to 2.x and let us know if the issue exist as there is no support for 1.x", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45024\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45024\">No</a>\n", "yes.thankyou."]}, {"number": 45023, "title": "Invalid argument:  assertion failed: [Unable to decode bytes as JPEG, PNG, GIF, or BMP]", "body": "2020-11-19 17:13:14.386367: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:172] Filling up shuffle buffer (this may take a while): 168 of 256\r\n2020-11-19 17:13:24.373184: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:172] Filling up shuffle buffer (this may take a while): 213 of 256\r\n2020-11-19 17:13:26.240500: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:221] Shuffle buffer filled.\r\n 6/83 [=>............................] - ETA: 1:13 - loss: 1.0636 - accuracy: 0.4635Traceback (most recent call last):\r\n  File \"model_vgg.py\", line 241, in <module>\r\n    loss0, accuracy0 = model.evaluate(validation_dataset)\r\n  File \"/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1379, in evaluate\r\n    tmp_logs = test_function(iterator)\r\n  File \"/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 780, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 807, in _call\r\n    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n  File \"/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2829, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1848, in _filtered_call\r\n    cancellation_manager=cancellation_manager)\r\n  File \"/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1924, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 550, in call\r\n    ctx=ctx)\r\n  File \"/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\r\n    inputs, attrs, num_outputs)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\r\n  (0) Invalid argument:  assertion failed: [Unable to decode bytes as JPEG, PNG, GIF, or BMP]\r\n\t [[{{node decode_image/cond_jpeg/else/_1/decode_image/cond_jpeg/cond_png/else/_20/decode_image/cond_jpeg/cond_png/cond_gif/else/_39/decode_image/cond_jpeg/cond_png/cond_gif/Assert/Assert}}]]\r\n\t [[IteratorGetNext]]\r\n\t [[IteratorGetNext/_4]]\r\n  (1) Invalid argument:  assertion failed: [Unable to decode bytes as JPEG, PNG, GIF, or BMP]\r\n\t [[{{node decode_image/cond_jpeg/else/_1/decode_image/cond_jpeg/cond_png/else/_20/decode_image/cond_jpeg/cond_png/cond_gif/else/_39/decode_image/cond_jpeg/cond_png/cond_gif/Assert/Assert}}]]\r\n\t [[IteratorGetNext]]\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_test_function_1802]\r\n\r\nFunction call stack:\r\ntest_function -> test_function", "comments": ["@Liquidten \r\n\r\nPlease, fill [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nRequest you to share colab link or simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 45022, "title": "[XLA] Lower TF/XLA overhead by creating less objects", "body": "This remove the creation of MaybeOwningDeviceMemory and ExecutionInput objects in TF/XLA. This lower XLA launch overhead.\r\nNot creating the MaybeOwningDeviceMemory in TF1 gave us a 2% e2e speed up on Bert.\r\nExecutionInput didn't existed in TF1.\r\n\r\n@cheshire", "comments": ["TBH I don't really like this patch, as it adds another overload, and then a whole lot of complexity, and then in addition this complexity is added only for a GPU backend even though it's not GPU-specific.\r\n\r\nIf you really need this speed-up, I think this should be done at a different abstraction level. As far as I understand the root of the problem here is that for autoclustering, all inputs buffers are always passed as unowned, and we are using the `ExecutionInput` datastructure which allows differentiating buffers per-tuple-index, which causes a costly conversion.\r\n\r\nWDYT about e.g. adding an optimization to `ExecutionInput` instead, where instead of storing a `ShapeTree<MaybeOwningDeviceMemory>` it would store a variant (differentiate per index, or store all as unowned?) Or maybe another similar technique is more appropriate.\r\n\r\nAt least in this case the complexity would be restricted to private implementation details of `ExecutionInput`.", "@nouiz  Can you please check @cheshire's comments and keep us posted ? Thanks!\r\n", "@cheshire \r\nIn TF1, Only MaybeOwningDeviceMemory exist. ExecutionInput was introduced in TF2.\r\nExecutionInput is more complex than MaybeOwningDeviceMemory. So if MaybeOwningDeviceMemory cause overhead in TF1, then ExecutionInput will also cause at least as much overhead in TF2 (except if TF2 is slower then TF1).\r\n\r\nYour new suggestion help make the changes more local. But it will lose speed compared to the current implementation as it won't save the construction of ExecutionInput .\r\n\r\nI have another suggestion. I can use templates and make both classes have compatible interface when needed by this function. This will keep the full speed up. It will hide the optimization in the classes. But it will increase the binary sizes due to the template.\r\n\r\nI'll recap the 4 options that I currently see:\r\n1) Keep the PR as it. Best speed up.\r\n2) Change this PR to use a std::variant instead of passing 2 ptr. Best speed up, function signature a little bit more clean.\r\n3) Optimize ExecutionInput: less speed up. Cleaner interface and changes more localized.\r\n4) Use Template: Best Speed up. Cleaner interface and changes more localized. Bigger binary and compilation time and probably more code changes.\r\n\r\nThe overhead is getting more and more troublesome. So I think we should target the best speed up. Which keep only option 1,2 and 4. I prefer option 2 then 1 as it clean up the interface.\r\n\r\nSo this left option 2 and 4 in my head. I do not longer compilation and bigger binary. So this make option 2 win with the constraint I mentioned. But maybe you evaluate this differently than me.\r\n\r\nAlso, do not forget that the std::variant is contained inside the gpu_executable.{cc,h} files. It doesn't change executable interface, except that one function is not virtual. So it doesn't affect other backend then the GPU back-end.\r\n", "@nouiz Sorry for the delay.\r\n\r\n> In TF1, Only MaybeOwningDeviceMemory exist. ExecutionInput was introduced in TF2.\r\n\r\nBut we are talking about the nightly branch, right?\r\n\r\n> But it will lose speed compared to the current implementation as it won't save the construction of ExecutionInput\r\n\r\nFrom your profile picture, it seems we are losing time in the `MakeMaybeOwningDeviceMemoryTree`, right?\r\nThat function iterates over all elements in the tuple, so for a giant tuple it's natural it would take a while. Why do you think that constructing a single wrapper object will take time? In my understanding it's not showing up at all in the profiler.\r\n\r\n", "> > In TF1, Only MaybeOwningDeviceMemory exist. ExecutionInput was introduced in TF2.\r\n> \r\n> But we are talking about the nightly branch, right?\r\n\r\nI do not know a nightly branch, only the master branch. The only nightly something I know is about the installer or docker images.\r\nMy only point is that ExecutionInput was added in one version of TF2. I do not remember which version and I do not think it makes a difference.\r\n\r\n> > But it will lose speed compared to the current implementation as it won't save the construction of ExecutionInput\r\n> \r\n> From your profile picture, it seems we are losing time in the `MakeMaybeOwningDeviceMemoryTree`, right?\r\n> That function iterates over all elements in the tuple, so for a giant tuple it's natural it would take a while. Why do you think that constructing a single wrapper object will take time? In my understanding it's not showing up at all in the profiler.\r\n\r\nIn TF1, it creates an MaybeOwningDeviceMemory object per XLA inputs. In TF2, it creates one MaybeOwningDeviceMemory  and one ExecutionInput per XLA inputs. We create as many MaybeOwningDeviceMemory object as ExecutionInput object.\r\n\r\nI suppose the creation time of MaybeOwningDeviceMemory and ExecutionInput is approximately as time consuming. So I want to prevent the creation of both objects in TF2. Otherwise I would have the same problem as in TF1.\r\n\r\nI do not see the creation of ExecutionInput as \"a single wrapper object\". Creating a single objects like ExecutionInput**S** that keep a vector of ExecutionInput or a vector MaybeOwningDeviceMemory can hide the difference inside one object. Conceptually, it looks good. But to not slow down this codepath, i'll would try to make all the code in a header so that the compiler can inline all calls.\r\n\r\nDoes that sound good? Was that what you suggested?", "Hi Frederic,\r\n\r\nAll the extra time is spent in [this](https://cs.opensource.google/tensorflow/tensorflow/+/master:tensorflow/compiler/xla/service/executable.cc;l=93-100?q=MakeMaybeOwningDeviceMemoryTree) function, right? This function potentially takes many iterations if shaped buffer is a giant tuple, which often occurs in autoclustering.\r\n\r\nIn my understanding, if we could optimize the `ExecutionInput` so it can store the `ShapedBuffer` directly without iterating over it, this would achieve your goal, right?\r\n\r\n", "> Hi Frederic,\r\n> \r\n> All the extra time is spent in [this](https://cs.opensource.google/tensorflow/tensorflow/+/master:tensorflow/compiler/xla/service/executable.cc;l=93-100?q=MakeMaybeOwningDeviceMemoryTree) function, right? This function potentially takes many iterations if shaped buffer is a giant tuple, which often occurs in autoclustering.\r\n\r\nYes. I didn't investigate why it takes times. Currently it is called once per inputs. So here, we end up with a double loop:\r\n```\r\nfor input in xla.inputs:\r\n    for ... in input.shape_elements()\r\n```\r\n> In my understanding, if we could optimize the `ExecutionInput` so it can store the `ShapedBuffer` directly without iterating over it, this would achieve your goal, right?\r\n\r\nYour suggestion remove the inner for loop. I have no idea it that would be enough and knowing this will request that I implement the full solution.\r\n\r\nAll my current proposition will remove both loops. I know this fix the problem. This also make XLA overhead less dependent on the number of inputs. Which is a good thing. Making temp object that aren't useful isn't great.\r\n\r\nIf you do not want the small unboxed solution with dual ptr (or an std::variant at the top level). Then as in my previous comments, making an `ExecutionInputs` object will allow to encapsulate the changes.\r\n\r\nWhat do you think of that solution to give the property you and keep all the speed up?", "std::variant is from c++17: https://en.cppreference.com/w/cpp/utility/variant\r\nBut opensource TF is still built with c++14: https://github.com/tensorflow/tensorflow/blob/master/.bazelrc#L300\r\n\r\nSo I can't change the interface of `ExecuteAsyncOnStreamImpl()` to use std::variant instead of 2 ptrs.\r\nSo I think we should keep that PR as is and when the default compiler changes, we can do this clean up?", "> But opensource TF is still built with c++14\r\n\r\nIf only we had a library which could bring us new C++ features sooner :P \r\nhttps://cs.opensource.google/search?q=absl::variant%20file:tensorflow%2Fcompiler&sq=", "I updated this PR to use absl::variant instead of 2 ptrs.", "@nouiz  Can you please check @cheshire's comments and keep us posted ? Thanks!\r\n", "All suggestion that applied is done.", "There is conflict. I'm working on that.", "Rebased to fix the conflict. I also squashed all commis to help the rebase.", "@nouiz One of the tests appears to be failing:\r\n```\r\n[ RUN      ] BufferDonationTest.TestMustAliasNotDonated\r\ntensorflow/compiler/xla/tests/buffer_donation_test.cc:129: Failure\r\nValue of: output_status.ok()\r\n  Actual: true\r\nExpected: false\r\nStack trace:\r\n0x7f52441718f7: xla::(anonymous namespace)::BufferDonationTest::RunAndCheck(std::__u::unique_ptr<xla::HloModule, std::__u::default_delete<xla::HloModule> >, absl::Span<xla::Literal const>, absl::Span<bool const>, absl::Span<bool const>, xla::Literal const&, std::__u::basic_string<char, std::__u::char_traits<char>, std::__u::allocator<char> >) @ ??:??\r\n0x7f5244177f74: xla::(anonymous namespace)::BufferDonationTest_TestMustAliasNotDonated_Test::TestBody() @ ??:??\r\n0x7f5235ab1d89: testing::Test::Run() @ ??:??\r\n0x7f5235ab332c: testing::TestInfo::Run() @ ??:??\r\n\r\n[  FAILED  ] BufferDonationTest.TestMustAliasNotDonated (167 ms)\r\n```"]}, {"number": 45020, "title": "Building r2.3 branch fails on Windows 10 x64", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64 build 19041.630\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.3 (commit 5681c179eff80bce00e526303950b67b23cad14c)\r\n- Python version: 3.6.8\r\n- Installed using virtualenv? pip? conda?: N/A\r\n- Bazel version (if compiling from source): 3.7.0\r\n- GCC/Compiler version (if compiling from source): msvc 19.28.29333\r\n- CUDA/cuDNN version: CUDA 10.1.243; cuDNN version 8\r\n- GPU model and memory: GTX 1080 8GB\r\n\r\n**Describe the problem**\r\nTensorFlow branch r2.3 fails to compile on Windows 10 (see log section)\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nSetup as per https://www.tensorflow.org/install/source_windows. Every setting set to default, except for CUDA support which was enabled.\r\n`bazel build //tensorflow/tools/pip_package:build_pip_package`\r\n\r\n**Any other info / logs**\r\n(Most of the log skipped as it is a normal build until around this point)\r\n```\r\nexternal/com_google_absl\\absl/time/clock.h(70): error C2065: 'Duration': undeclared identifier\r\nexternal/com_google_absl\\absl/time/clock.h(70): error C2146: syntax error: missing ')' before identifier 'duration'\r\nexternal/com_google_absl\\absl/time/clock.h(70): error C2143: syntax error: missing ';' before '{'\r\nexternal/com_google_absl\\absl/time/clock.h(70): error C2447: '{': missing function header (old-style formal list?)\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 720.763s, Critical Path: 176.43s\r\nINFO: 860 processes: 860 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nBonus: I get an entirely different error in the current master as of this writing (6de8d69b23ebc26c7f364ce4bc775aa45a063937):\r\n```\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/lite/tools/optimize/model_utils.cc':\r\n  'external/com_google_absl/absl/strings/string_view.h'\r\n  'external/com_google_absl/absl/base/internal/throw_delegate.h'\r\n```", "comments": ["Can you please try with bazel version 3.1.0 https://github.com/tensorflow/tensorflow/blob/r2.3/.bazelversion? \r\nAlso mentioned in the [tested build configurations](https://www.tensorflow.org/install/source#gpu). Thanks!", "System information\r\n\r\n-OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04.1 LTS\r\n-Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n-TensorFlow installed from (source or binary): source\r\n-TensorFlow version: 2.3\r\n-Python version: 3.8.5\r\n-Installed using virtualenv? pip? conda?: N/A\r\n-Bazel version (if compiling from source): 3.1.0\r\n-GCC/Compiler version (if compiling from source): 9.3.0 (Ubuntu 9.3.0-17ubuntu1~20.04)\r\n-CUDA/cuDNN version: cuda_11.1.TC455_06.29190527_0; cuDNN version 8.0.5\r\n-GPU model and memory: GTX-1080Ti\r\n\r\nDescribe the problem\r\nTensorFlow branch r2.3 fails to compile\r\n\r\nProvide the exact sequence of commands / steps that you executed before running into the problem\r\n\r\n`./configure`\r\n\r\n> \r\n> You have bazel 3.1.0 installed.\r\n> Please specify the location of python. [Default is /usr/bin/python3]: \r\n> \r\n> \r\n> Found possible Python library paths:\r\n>   /usr/local/lib/python3.8/dist-packages\r\n>   /usr/lib/python3/dist-packages\r\n> Please input the desired Python library path to use.  Default is [/usr/local/lib/python3.8/dist-packages]\r\n> \r\n> Do you wish to build TensorFlow with ROCm support? [y/N]: n\r\n> No ROCm support will be enabled for TensorFlow.\r\n> \r\n> Do you wish to build TensorFlow with CUDA support? [y/N]: y\r\n> CUDA support will be enabled for TensorFlow.\r\n> \r\n> Do you wish to build TensorFlow with TensorRT support? [y/N]: y\r\n> TensorRT support will be enabled for TensorFlow.\r\n> \r\n> Found CUDA 11.1 in:\r\n>     /usr/local/cuda-11.1/targets/x86_64-linux/lib\r\n>     /usr/local/cuda-11.1/targets/x86_64-linux/include\r\n> Found cuDNN 8 in:\r\n>     /usr/lib/x86_64-linux-gnu\r\n>     /usr/include\r\n> Found TensorRT 7 in:\r\n>     /usr/lib/x86_64-linux-gnu\r\n>     /usr/include/x86_64-linux-gnu\r\n> \r\n> \r\n> Please specify a list of comma-separated CUDA compute capabilities you want to build with.\r\n> You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus. Each capability can be specified as \"x.y\" or \"compute_xy\" to include both virtual and binary GPU code, or as \"sm_xy\" to only include the binary code.\r\n> Please note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 6.1]: \r\n> \r\n> \r\n> Do you want to use clang as CUDA compiler? [y/N]: n\r\n> nvcc will be used as CUDA compiler.\r\n> \r\n> Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \r\n> \r\n> \r\n> Please specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]: \r\n> \r\n> \r\n> Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n\r\n> Not configuring the WORKSPACE for Android builds.\r\n> \r\n\r\n```\r\nsudo rm -Rf ~/.cache/bazel\r\nbazel build --copt=\"-fPIC\" --config=opt --config=cuda --noincompatible_strict_action_env //tensorflow/tools/pip_package:build_pip_package --verbose_failures\r\n\r\n```\r\n\r\n> INFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (416 packages loaded, 33269 targets configured).\r\n> INFO: Found 1 target...\r\n> ERROR: /home/olivier/tensorflow/tensorflow/lite/tools/optimize/BUILD:140:1: undeclared inclusion(s) in rule '//tensorflow/lite/tools/optimize:model_utils':\r\n> this rule is missing dependency declarations for the following files included by 'tensorflow/lite/tools/optimize/model_utils.cc':\r\n>   'external/com_google_absl/absl/strings/string_view.h'\r\n>   'external/com_google_absl/absl/base/internal/throw_delegate.h'\r\n> Target //tensorflow/tools/pip_package:build_pip_package failed to build\r\n> INFO: Elapsed time: 5701.973s, Critical Path: 144.65s\r\n> INFO: 10343 processes: 10343 local.\r\n> FAILED: Build did NOT complete successfully\r\n\r\n", "> Can you please try with bazel version 3.1.0 https://github.com/tensorflow/tensorflow/blob/r2.3/.bazelversion?\r\n> Also mentioned in the [tested build configurations](https://www.tensorflow.org/install/source#gpu). Thanks!\r\n\r\nJust tried with bazel version 3.1.0, had a few different build errors so I decided to re-clone and build from scratch again with bazel 3.1.0; this resulted in the same error as the original issue.", "I'm seeing this same problem with TF v2.3.1 / Bazel v3.10 / MSVC 2017 / CUDA 10.1.  It's happening when building `tensorflow/core/kernels/histogram_op_gpu.cu.cc`.\r\n\r\nThe problem is that nvcc is changing the input code in a way that is incompatible with MSVC 2017.  The original `external/com_google_absl\\absl/time/clock.h` has this:\r\n```\r\ninline void absl::SleepFor(absl::Duration duration) {\r\n  AbslInternalSleepFor(duration);\r\n}\r\n```\r\n\r\nThen nvcc generates a temp `histogram_op_gpu.cu.cudafe1.cpp` and tries to build it with `cl`.  This file has already had the preprocessor run on it (presumably by nvcc?), so all its macros/includes have been expanded.  The section corresponding to the above `clock.h` code looks like this:\r\n```\r\n#line 70\r\ninline void absl::SleepFor(Duration duration) { \r\n#line 71\r\nAbslInternalSleepFor(duration); \r\n#line 72\r\n} \r\n```\r\n\r\nNote that `absl::Duration` has changed to `Duration`.  This is fine for gcc/clang, but is a bug with MSVC (see this [SO post.](https://stackoverflow.com/questions/55181616/using-type-from-inline-namespace-in-cpp-file-does-not-work-in-msvs))\r\n\r\n\r\n\r\n\r\n\r\n", "@Masterchef365 Could you please try using latest stable version of **TF 2.6.0** and let us know if the issue still persists? Please have a look at the [Build from source ](https://www.tensorflow.org/install/source#gpu) for reference .Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45020\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45020\">No</a>\n"]}, {"number": 45019, "title": "Error while loading .jpg images. Please help", "body": "Traceback (most recent call last):\r\n  File \"/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/eager/context.py\", line 2102, in execution_mode\r\n    yield\r\n  File \"/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 758, in _next_internal\r\n    output_shapes=self._flat_output_shapes)\r\n  File \"/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 2610, in iterator_get_next\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 6843, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Expected image (JPEG, PNG, or GIF), got unknown format starting with '\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000'\r\n\t [[{{node DecodeJpeg}}]] [Op:IteratorGetNext]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"model_vgg.py\", line 212, in <module>\r\n    model, base_model = make_model(IMG_SIZE = IMG_SIZE, num_classes=3)\r\n  File \"model_vgg.py\", line 161, in make_model\r\n    image_batch, label_batch = next(iter(train_ds))\r\n  File \"/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 736, in __next__\r\n    return self.next()\r\n  File \"/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 772, in next\r\n    return self._next_internal()\r\n  File \"/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 764, in _next_internal\r\n    return structure.from_compatible_tensor_list(self._element_spec, ret)\r\n  File \"/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/contextlib.py\", line 99, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/eager/context.py\", line 2105, in execution_mode\r\n    executor_new.wait()\r\n  File \"/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/eager/executor.py\", line 67, in wait\r\n    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Expected image (JPEG, PNG, or GIF), got unknown format starting with '\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000'\r\n\t [[{{node DecodeJpeg}}]]\r\n2020-11-19 13:35:49.049747: W tensorflow/core/kernels/data/cache_dataset_ops.cc:798] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.", "comments": ["Can you try renaming your .jpg images with .jpeg extensions and try again.\r\nRefer [StackOverflow thread](https://stackoverflow.com/questions/57719879/invalidargumenterror-expected-image-jpeg-png-or-gif-got-unknown-format-sta)", "@ymodak I tried changing the file names to .png seems like there might be some corrupt files. Do you think that might have caused the issue?\r\nTraceback (most recent call last):\r\n  File \"convetpic.py\", line 21, in <module>\r\n    im = Image.open(filename)\r\n  File \"/tensorflow-gpu/lib/python3.6/site-packages/PIL/Image.py\", line 2862, in open\r\n    \"cannot identify image file %r\" % (filename if filename else fp)\r\nPIL.UnidentifiedImageError: cannot identify image file 'Best/keratosis/20196301.jpg'", "Can you try to update to latest `PIL` version and try again. If issue still exists then you may want to remove the corrupt images.", "@ravikyram  issue solved Thanks", "@Liquidten \r\n\r\nPlease, close this thread if your issue was resolved. Thanks!"]}, {"number": 45018, "title": "Make open source CI closer to the internal tests.", "body": "", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 45017, "title": "Filling values when rotating an image using functions like tfa.image.rotate() and tfa.image.translate()", "body": "**System information**\r\n- TensorFlow version (you are using): 2.3.0\r\n- Are you willing to contribute it (Yes/No): Yes. I'm not a great programmer, but I'm willing to help in any way I can.\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\n_This feature request stems from a separate issue that was described [here](https://github.com/tensorflow/tensorflow/issues/44059)._\r\n\r\nWhen you use skimage to [rotate](https://scikit-image.org/docs/dev/api/skimage.transform.html#skimage.transform.rotate) or translate an image, you are given the option to fill in the values that the image loses by performing these operations with reflected values or symmetric values, for example. I used to have an augmentation function that used this functionality successfully, but then the functionality stopped. \r\n\r\nI updated the augmentation to use the functions from tensorflow_addons listed in the title. However, I've now lost this ability to fill in lost values to utilize some of the original information. I think it'd be a good idea to add this as an option to these functions in tfa.\r\n\r\n**Will this change the current api? How?**\r\n\r\nNot sure.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nML practitioners, remote sensing practitioners, geospatial professionals in general.\r\n\r\n**Any Other info.**\r\n\r\nThe modes that skimage includes for these fill values are in line with the behavior of [numpy.pad](https://numpy.org/doc/stable/reference/generated/numpy.pad.html#numpy.pad).\r\n", "comments": ["Can you check https://github.com/tensorflow/addons/pull/2153 /cc @WindQAQ ", "Yes, I've checked it. It seems similar to this issue. Should the issues be merged? Should this issue be closed?", "That PR is already merged", "@bjarrell15  Tensorflow-Addons will support it after TF2.4 releases. Alternatively, you can use `tf.keras.layers.experimental.preprocessing.Random*` in tf-nightly to achieve it.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/preprocessing/image_preprocessing.py#L818-L824", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n"]}, {"number": 45016, "title": "Memory leak with tf.GradientTape, tf.while_loop and tf.function", "body": "**System information**\r\n- I have a minimal working example of some custom code which highlights the bug. My code is just a very trimmed down scematic of a larger code I have written, that functions perfectly, it just has a memory leak that requires restarting the process regularly.\r\n- The platform is Linux. Python version 3.8\r\n3.6.8 (default, Nov  3 2020, 19:58:28)\r\n[GCC 7.2.1 20170829 (Red Hat 7.2.1-1)]\r\n\r\n- I did not install TensorFlow on this system, so I'm unsure of the details.\r\n- Tensorflow version is 2.3.0\r\n- I'm not using GPU, I typically get this kind of message reported to my python session when running TensorFlow\r\nThis TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX512F\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n\r\nI have written a short piece of code that performs a basic regression.\r\nI'm forming a prediction y_hat using an input of dimension = 100 and 100 trainable variables stored in \"w\".\r\n\r\nI have two ways of forming the prediction vector with which I calculate my loss (MSE).\r\n\r\n1. One method is the standard way that you would expect any sane person to do it: exploit vector arithmitic. If I evaluate the gradient of the loss calculated this way, and iterate, I see no growth in the memory footprint of my process over time.\r\n\r\n2. If however, I use a tf.while_loop and build the MSE loss by summing increments then each time I evaluate a gradient, the memory footprint of my process grows and I don't know how to clear it.\r\n\r\nFinally, note that if you remove the @tf.function decorator then the memory leak vanishes. Suggesting the problem arises somehow through autograph applied to loops.\r\n\r\nNote: I have tried reformulating my code as both an (autographed) for loop as well as tf.scan, and I see the same memory growth in all cases.\r\n\r\nAlthough in the example I have shown, there is no need for the loop, and I can easily avoid this memory leak by not using it. I can also avoid the memory leak by not using tf.function and running my code in eager mode. In reality my original code is significantly more complex and I do many operations inside the loop and depend on TensorArrays to do further operations on the output. Furthermore, performance is critical, so running in eager mode is not an option.\r\n\r\n```\r\nimport tensorflow as tf\r\nimport os\r\nimport psutil\r\n\r\n# simulate a basic loop\r\ndef get_loss(w, x, y, use_loop=True):\r\n\r\n    # infer the length of our loop form the size of our inputs\r\n    T = tf.shape(y)[0]\r\n\r\n    # creating the vector of predictions is unnecessarily complicated\r\n    # when using the tensor array, but this is just a minimal use case\r\n    # that exposes exposes the memory leak\r\n    if use_loop:\r\n\r\n        # what we do at each iteration of the loop\r\n        def body(t, loss):\r\n\r\n            # get the prediction\r\n            y_hat = tf.reduce_sum(x[t] * w, axis=-1)\r\n\r\n            # into the next\r\n            return t+1, loss + tf.square(y[t,0] - y_hat)\r\n\r\n        # run the while loop\r\n        t, loss = tf.while_loop(lambda t, *args: t < T,\r\n                                 body,\r\n                                 [tf.constant(0), tf.constant(0.)],\r\n                                 name='main_loop')\r\n\r\n        # unstack the tensor array to get the vector of predictions\r\n        loss /= tf.cast(T, tf.float32)\r\n\r\n        # return the loss\r\n        return loss\r\n\r\n    else:\r\n\r\n        # other wise just broadcast\r\n        y_hat_vector = tf.reduce_sum(x * w, axis=1, keepdims=True)\r\n\r\n        # minimize some loss\r\n        return tf.reduce_mean(tf.square(y - y_hat_vector))\r\n\r\n# get the gradient\r\n@tf.function\r\ndef get_gradient(w, x, y, use_loop):\r\n\r\n    with tf.GradientTape() as g:\r\n        loss = get_loss(w, x, y, use_loop)\r\n    return g.gradient(loss, w)\r\n\r\n# function to get memory usage\r\ndef get_memory_usage():\r\n    pid = os.getpid()\r\n    py = psutil.Process(pid)\r\n    return py.memory_info()[0]/2.**30  # memory use in GB...I think\r\n\r\n# now run the training loop\r\nw = tf.Variable(tf.random.normal((100,)))\r\nx = tf.constant(tf.random.normal((1024, 100)))\r\ny = tf.constant(tf.random.normal((1024, 1)))\r\n\r\n# simulate a training loop\r\n# don't actually apply the gradients, just calculate them on the same data\r\n# over and over again\r\n# this loop produces no memory leak\r\nfor i in range(20):\r\n\r\n    # each iteration we calculate the gradient of our loss\r\n    grad = get_gradient(w, x, y, use_loop=False)\r\n    tf.print('avg. grad:', tf.reduce_mean(grad),\r\n             '\\tmem usage:', get_memory_usage())\r\n\r\n# but if we use the while loop\r\n# the memory footprint of this process just grows and grows and goes\r\n# until eventually a training loop would be killed by the operating system\r\nfor i in range(20):\r\n\t# each iteration we calculate the gradient of our loss\r\n\tgrad = get_gradient(w, x, y, use_loop=True)\r\n\ttf.print('avg. grad:', tf.reduce_mean(grad),\r\n\t\t  '\\tmem usage:', get_memory_usage())\r\n```\r\n\r\n", "comments": ["Ok, problem seems to be resolved now by putting the training loop itself in a tf.function", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45016\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45016\">No</a>\n", "Actually no, it's not fixed. Putting the training loop into a @tf.function just gave the false impression that the memory was not increasing, by evaluating get_memory_usage() once at the initial autograph tracing.\r\n\r\nIn fact the problem is unrelated to TensorArray, I have reduced the complexity of my minimal example again by removing the TensorArray", "@shardiman \r\nCan you please share a colab gist with the error reported, and try on later version of tf.", "> \r\n> \r\n> @shardiman\r\n> Can you please share a colab gist with the error reported, and try on later version of tf.\r\n\r\nThanks for the reply!\r\nGive me some time and I will do this for you. Thanks", "I don't know if this would help, but I have been through a tough time trying to solve the memory leaking issue the last few days. Now I solved my issue, and want to share my solution here even though it may not fit your problem description. Just want people with similar experience to see this. \r\n\r\nThe solution first: Tensorflow docker image from Nvidia NGC saved my life. \r\n\r\nI recently got a 30 series GPU and in order to make it work, I upgraded my Cuda to 11.1, cudnn to 8.0.5, python to 3.8, and TensorFlow to 2.4+ (tried both nightly and 2.4, currently 2.3 doesn't support 30 series). All of a sudden, my previously working model started to leak memory. Even when I'm using my non-30 series GPU.\r\n\r\nThe release notes of Tensorflow 2.4+ says operations that are previously susceptible to memory leaking may become more likely to do so (ok... then what are the susceptible operations?). I tried every possible solution found on the internet, including replacing all the tf. based tensor operations in graph building (because they may generate new graphs each iteration), forcing garbage collector after each epoch, modified and even stopped using image-data-generator (one of the most frequent search results of memory leakage), and switched between Windows and Linux. None of them worked. I was using a perfectly normal U-Net structure for image segmentation, there is no reason I should do more hacking to stop the leakage.\r\n\r\nThen I realized Nvidia NGC recently released a docker image that brings Tensorflow 2.3 and Cuda 11.1 together, I never used docker before but I immediately tried it. It works like a charm, everything backs to normal.\r\n\r\nI guess there are some compatibility issues between Tensorflow 2.4+ and the new Cuda toolkits that caused the problem. Anybody who recently upgraded their hardware or software should definitely try this.\r\n\r\n ", "Ok thanks for the suggestions and taking the time to look at my issue,\r\n\r\nAfter running my code on Colab, I can confirm that the bug no longer seems to persist on this colab environment.\r\nI guess the problem must be specific to my hardware/architecture/installation. Unfortunately I don't really have control over this environment, so I'll have to contact and my system administrators and work with them!\r\n\r\nThanks for your advice mrwildddogg!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45016\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45016\">No</a>\n", "@deephog can you give me a link for the docker container please?", "> @deephog can you give me a link for the docker container please?\r\n\r\nhttps://ngc.nvidia.com/catalog/containers/nvidia:tensorflow\uff0c here it is. I think it will get you to the login page of Nvidia NGC, you need to register then login to access the resources. On the front page after you lonin, you will see the TensorFlow tile, just click into it, it will get you to the most recent docker container release from nvidia. It is no longer the same version as mine, but I guess it should still work. "]}, {"number": 45015, "title": "Do not call tf.shape on a ragged tensor when computing losses.", "body": "For a ragged tensor use bounding_shape(). In losses_utils do not attempt\r\nto convert a tensor before determining that the dimensions needs to be\r\nsqueezed. Conversion does not work for ragged tensors.\r\n\r\nFixes issue #44988 ", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F45015) for more info**.\n\n<!-- need_author_cla -->", "@pedro-r-marques Can you please address Ubuntu Sanity errors? Thanks!", "@gbaned Fixed the pylint error. Apologies, I was not aware of the failure until I saw your message.", "@gbaned The Windows Bazel build failure seems unrelated to my CL. Any suggestions on how to address it ?", "@edloper Can you please assist on above comments from @pedro-r-marques. Thanks!", "@edloper @gbaned \r\n\r\nAs far as I can tell the Windows CI build error is:\r\n```\r\nTraceback (most recent call last):\r\n  File \"\\\\?\\T:\\tmp\\Bazel.runfiles_803oyzof\\runfiles\\org_tensorflow\\py_test_dir\\t\r\nensorflow\\python\\keras\\benchmarks\\benchmark_util_test.py\", line 23, in <module>\r\n    from tensorflow.python.keras.benchmarks import benchmark_util\r\nModuleNotFoundError: No module named 'tensorflow.python.keras.benchmarks'\r\n```\r\n\r\nThis test appears to have been added recently (3af08c5f47003e69accd0dda3d28314bf4673407). And as far as I understand it my branch was not synced to it. I just rebased my branch to the current master. That may address this issue. Can you please re-trigger a CI run ?", "@gbaned \r\nThe macOS CI failures seems to be:\r\n```\r\nExecuting tests from //tensorflow/lite/kernels/parse_example:parse_example_test\r\n```\r\n\r\nThe Windows CI failure:\r\n```\r\nExecuting genrule //tensorflow/lite/python/testdata:permute_float failed (Exit 1): bash.exe failed: error executing command\r\n```\r\n\r\nThis PR doesn't touch tensorflow lite... I'm assuming that the failures are completely unrelated to the PR.\r\n\r\nIs it possible that the CIs fail with old PRs ? It took 5 days to trigger this PR run... I've rebased it again. Is there anything more proactive I can do ?\r\n", "I'm triggering a new run and will try to get this in.\r\n\r\nNote that we are during holidays now and most people are OOO. So if this needs additional review from people who are not in office it will probably stall again until January. Apologies for this."]}, {"number": 45014, "title": "Cannot use Hexagon delegate in Oneplus 6t. Failed to fetch Hexagon NN version. Not working since 18-Nov-2020.", "body": "\r\n2020-11-18 23:49:31.577 10150-10267/org.tensorflow.lite.examples.alerts.debug E/org.tensorflow.lite.examples.alerts.debug: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/apps_std_imp.c:728:Error 45: fopen failed for libhexagon_nn_skel_v65.so. (No such file or directory)\r\n\r\n2020-11-18 23:49:31.578 929-961/? E//vendor/bin/cdsprpcd: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/apps_std_imp.c:728:Error 45: fopen failed for libhexagon_nn_skel_v65.so. (No such file or directory)\r\n\r\n2020-11-18 23:49:31.578 10150-10232/org.tensorflow.lite.examples.alerts.debug D/org.tensorflow.lite.examples.alerts.debug: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:921: Error fffffffb: remote handle open domain failed. domain 3, name file:///libhexagon_nn_skel_v65.so?hexagon_nn_domains_skel_handle_invoke&_modver=1.0&_dom=cdsp, dlerror cannot open libhexagon_nn_skel_v65.so\r\n\r\n2020-11-18 23:49:31.578 10150-10232/org.tensorflow.lite.examples.alerts.debug D/org.tensorflow.lite.examples.alerts.debug: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:958: Error fffffffb: remote handle64 open failed. name file:///libhexagon_nn_skel_v65.so?hexagon_nn_domains_skel_handle_invoke&_modver=1.0&_dom=cdsp\r\n\r\n2020-11-18 23:49:31.578 10150-10232/org.tensorflow.lite.examples.alerts.debug W/tflite: Failed to fetch Hexagon NN version. This might be because you're using incompatible versions of libhexagon_interface and libhexagon_nn_skel. You must use compatible versions. Refer to Tensorflow Lite Hexagon Delegate Guide.\r\n\r\n2020-11-18 23:49:31.578 10150-10232/org.tensorflow.lite.examples.alerts.debug I/tflite: Hexagon Delegate is not supported.\r\n", "comments": ["@ibrahimgharyali \r\n\r\nPlease, fill [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\nProvide the exact sequence of commands / steps that you executed before running into the problem.Thanks!", "<em>Please make sure that this is a bug. As per our\r\n<a href=\"https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md\">GitHub Policy</a>,\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOs Mojave (running on Android 9)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Oneplus 6t Snapdragon 845 SoC.\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): TFLite 2.3.0\r\n- Python version: 1.15.2\r\n- Bazel version (if compiling from source): \r\n- GCC/Compiler version (if compiling from source): \r\n- CUDA/cuDNN version:\r\n- GPU model and memory: mobilenet_v2, GPU- Adreno 630\r\n\r\n**Adding Hexagon delegate to tflite interpreter throws error `Hexagon Delegate is not supported.`**\r\n\r\n**I was able to run it till yesterday. I believe there is a new update in the `tensorflow-lite-hexagon:0.0.0-nightly` and it stops working for my device**\r\n\r\n                    HexagonDelegate hexagonDelegate = null;\r\n                    try {\r\n                        Interpreter.Options tfliteOptions = new Interpreter.Options();\r\n                        hexagonDelegate = new HexagonDelegate(context);\r\n                        tfliteOptions.addDelegate(hexagonDelegate);\r\n                      \r\n                    } catch (UnsupportedOperationException e) {\r\n                        e.printStackTrace();\r\n                    }`\r\n\r\nError Logs: \r\n```\r\n2020-11-18 23:49:31.577 10150-10267/org.tensorflow.lite.examples.alerts.debug E/org.tensorflow.lite.examples.alerts.debug: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/apps_std_imp.c:728:Error 45: fopen failed for libhexagon_nn_skel_v65.so. (No such file or directory)\r\n\r\n2020-11-18 23:49:31.578 929-961/? E//vendor/bin/cdsprpcd: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/apps_std_imp.c:728:Error 45: fopen failed for libhexagon_nn_skel_v65.so. (No such file or directory)\r\n\r\n2020-11-18 23:49:31.578 10150-10232/org.tensorflow.lite.examples.alerts.debug D/org.tensorflow.lite.examples.alerts.debug: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:921: Error fffffff: remote handle open domain failed. domain 3, name file:///libhexagon_nn_skel_v65.so?hexagon_nn_domains_skel_handle_invoke&_modver=1.0&_dom=cdsp, dlerror cannot open libhexagon_nn_skel_v65.so\r\n\r\n2020-11-18 23:49:31.578 10150-10232/org.tensorflow.lite.examples.alerts.debug D/org.tensorflow.lite.examples.alerts.debug: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:958: Error fffffff: remote handle64 open failed. name file:///libhexagon_nn_skel_v65.so?hexagon_nn_domains_skel_handle_invoke&_modver=1.0&_dom=cdsp\r\n\r\n2020-11-18 23:49:31.578 10150-10232/org.tensorflow.lite.examples.alerts.debug W/tflite: Failed to fetch Hexagon NN version. This might be because you're using incompatible versions of libhexagon_interface and libhexagon_nn_skel. You must use compatible versions. Refer to Tensorflow Lite Hexagon Delegate Guide.\r\n\r\n2020-11-18 23:49:31.578 10150-10232/org.tensorflow.lite.examples.alerts.debug I/tflite: Hexagon Delegate is not supported.\r\n\r\n```", "> Provide the exact sequence of commands / steps that you executed before running into the problem.Thanks!\r\n\r\nTrying to run a mobilenet_v2 int8 model in my android device.\r\nI followed this guide: https://www.tensorflow.org/lite/performance/hexagon_delegate\r\nAdd gradle dependencies for tflite, tflite-gpu, tflite-hexagon:\r\n   ```\r\n    implementation \"org.tensorflow:tensorflow-lite:2.3.0\"\r\n    implementation \"org.tensorflow:tensorflow-lite-gpu:2.3.0\"\r\n    implementation 'org.tensorflow:tensorflow-lite-hexagon:0.0.0-nightly'\r\n```\r\n\r\ncopied `.so`files (`libhexagon_nn_skel.so`, `libhexagon_nn_skel_v65.so`, `libhexagon_nn_skel_v66.so`) extracting from `tflite_hexagon_nn_skel_v1.20.0.0.run` into path `project -> app -> src -> main -> jniLibs -> {arm64-v8a, armeabi, armeabi-v7a, mips, mips64, x86, x86_64}` .\r\n\r\n\r\nThe model is running on cpu as well as on GPU Delegate.", "1) Can you capture the whole logcat ?\r\n2) Can you verify that the files are in the expected locations on the device\r\n\r\nIn the initialize line for the delegate\r\n(e.g.) hexagonDelegate = new HexagonDelegate(activity);\r\nCan you print\r\nactivity.getApplicationInfo().nativeLibraryDir\r\nand check that the shared lib files are on the device under the same path.\r\nadb shell ls -al <PATH_PRINTED_FROM_ABOVE>\r\n\r\nIf you can paste the results in the reply will be good.\r\n\r\nThanks", "> @ibrahimgharyali\r\n> \r\n> Please, fill [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n> Provide the exact sequence of commands / steps that you executed before running into the problem.Thanks!\r\n\r\ndone", "@ibrahimgharyali Please reply to https://github.com/tensorflow/tensorflow/issues/45014#issuecomment-731474874\r\n\r\nThanks", "\r\n\r\n> 1. Can you capture the whole logcat ?\r\n> 2. Can you verify that the files are in the expected locations on the device\r\n> \r\n> In the initialize line for the delegate\r\n> (e.g.) hexagonDelegate = new HexagonDelegate(activity);\r\n> Can you print\r\n> activity.getApplicationInfo().nativeLibraryDir\r\n> and check that the shared lib files are on the device under the same path.\r\n> adb shell ls -al <PATH_PRINTED_FROM_ABOVE>\r\n> \r\n> If you can paste the results in the reply will be good.\r\n> \r\n> Thanks\r\n\r\nprint activity.getApplicationInfo().nativeLibraryDir = `/data/app/com.package.name-XXXXXXXXXXX==/lib/arm64`\r\n\r\nlog from `adb shell ls -al /data/app/com.package.name-XXXXXXXXXXX==/lib/arm64`\r\n```\r\ntotal 16\r\ndrwxr-xr-x 2 system system 4096 2021-07-06 11:19 .\r\ndrwxr-xr-x 3 system system 4096 2021-07-06 11:19 ..\r\n```\r\n", "@ibrahimgharyali Based on what you shared, the libraries are not packaged with your app. You need to get them packaged to be able to run the delegate.", "@karimnosseir \r\nHow do you package them in the app correctly? I also followed the instructions in the Hexagon delegate guide but I am getting the same error...\r\n\r\n> Failed to fetch Hexagon NN version. This might be because you're using incompatible versions of libhexagon_interface and libhexagon_nn_skel. You must use compatible versions. Refer to Tensorflow Lite Hexagon Delegate Guide.\r\n\r\nI ran the command ```adb shell ls -al /data/app/com.package.name-XXXXXXXXXXX==/lib/arm64``` and also didn't find my packages.\r\n```\r\ntotal 6\r\ndrwxr-xr-x 2 system system 3452 2021-10-13 16:22 .\r\ndrwxr-xr-x 3 system system 3452 2021-10-13 16:22 ..\r\n```", "Any updates on this issue?", "There are multiple ways to correctly package your .so files. For example, [this](https://www.geeksforgeeks.org/how-to-include-so-library-in-android-studio/) explain how to do it. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45014\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45014\">No</a>\n"]}, {"number": 45012, "title": "Add s390x support for compiler related TCs", "body": "Multiple compiler related test cases were failing with this error:\r\n`Internal: TargetRegistry::lookupTarget failed: No available targets are compatible with triple \"x86_64-pc-linux\"`\r\nThe test cases were retrieving default value, \"x86_64-pc-linux\" as target architecture.\r\n\r\nThis PR adds support for s390x as target architecture and fixes 15 compiler related TCs on s390x.\r\n ", "comments": []}]