[{"number": 23425, "title": "NameError name 'uses_learning_phase' is not defined when using Keras TimeDistributed with batch_shape on Input", "body": "I have an LSTM layer where I am using `stateful=True`. As a result I need to specify `batch_shape` on my `Input` layers:\r\n\r\n    input_xs = tf.keras.layers.Input(batch_shape=(batch_size,seq_length))\r\n\r\nI have a layer where I add a context vector to each input *at each timestep*. I currently achieve this with `TimeDistributed` and a `Lambda` layer as follows:\r\n\r\n    concatenator = tf.keras.layers.TimeDistributed(tf.keras.layers.Lambda(lambda x: tf.keras.layers.Concatenate()([x,concat_context])))\r\n\r\nBut the moment I added the `batch_shape` to my inputs I started getting the following error:\r\n\r\n```\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 769, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\wrappers.py\", line 250, in call\r\n    unroll=False)\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 3193, in rnn\r\n    outputs, _ = step_function(inputs[0], initial_states + constants)\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\wrappers.py\", line 242, in step\r\n    uses_learning_phase)\r\nNameError: name 'uses_learning_phase' is not defined\r\n```\r\n\r\nThis seems related to: https://github.com/keras-team/keras/issues/4178\r\n\r\nWould appreciate any thoughts on what is happening here.", "comments": ["Hi @rickdzekman , can u provide the version information for the TF you are running? This might help us understand and narrow down the window for the source of the bug.\r\n\r\n### System information\r\n- **What is the top-level directory of the model you are using**:\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n\r\n", "> Hi @rickdzekman , can u provide the version information for the TF you are running? This might help us understand and narrow down the window for the source of the bug.\r\n> \r\n> ### System information\r\n> * **What is the top-level directory of the model you are using**:\r\n> * **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n> * **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n> * **TensorFlow installed from (source or binary)**:\r\n> * **TensorFlow version (use command below)**:\r\n> * **Bazel version (if compiling from source)**:\r\n> * **CUDA/cuDNN version**:\r\n> * **GPU model and memory**:\r\n> * **Exact command to reproduce**:\r\n> \r\n> You can collect some of this information using our environment capture script:\r\n> \r\n> https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n> \r\n> You can obtain the TensorFlow version with\r\n> \r\n> python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n> \r\n> ### Describe the problem\r\n> Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n> \r\n> ### Source code / logs\r\n> Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n@rickdzekman  -  Any update ?", "Before following up on the bug I thought I would describe my workaround for anyone else experiencing this problem. You can manually implement TimeDistributed using `tf.keras.backend.rnn` like so:\r\n\r\n```\r\ndef apply_concats(layer,context):\r\n    concat_lambda = tf.keras.layers.Lambda(lambda x: tf.keras.layers.Concatenate()([x,context]))\r\n    input_shape = tf.keras.backend.int_shape(layer)\r\n    def lambda_step(x, _):\r\n        return concat_lambda(x), []\r\n\r\n    _, outputs, _ = tf.keras.backend.rnn(\r\n        lambda_step,\r\n        layer,\r\n        initial_states=[],\r\n        input_length=input_shape[1],\r\n        unroll=False\r\n    )\r\n    return outputs\r\n\r\nconcatenator = tf.keras.layers.Lambda(lambda x: apply_concats(x[0],x[1]),name=\"input_concat\")\r\nconcatenated = concatenator([input_sequence,sequence_context])\r\n```\r\n\r\nNote: you **must** pass both layers into the lambda otherwise those layers will not be trained. In my case, I first tried passing the `sequence_context` into the function as a closure, this resulted in the weights for the `sequence_context` not being trained. ", "Hi @harshini-gadige\r\n\r\nSorry for the delayed reply.\r\n\r\n\r\n**What is the top-level directory of the model you are using:**\r\nI'm not sure what this means?\r\n\r\n**Have I written custom code (as opposed to using a stock example script provided in TensorFlow):**\r\nI am not using any stock example scripts\r\n\r\n**OS Platform and Distribution (e.g., Linux Ubuntu 16.04):**\r\nWindows 10\r\n\r\n**TensorFlow installed from (source or binary):**\r\nBinary installed with pip\r\n\r\n**TensorFlow version (use command below):**\r\nFrom my `pip list` >> `tensorflow-gpu      1.11.0`\r\n\r\n**CUDA/cuDNN version:**\r\nCUDA Version 9.0.176\r\ncudnn-9.0-windows10-x64-v7.3.0.29\r\n\r\n**GPU model and memory:**\r\nGeForce GTX 850M (4.0GB)\r\n\r\n**Exact command to reproduce:**\r\nA minimal example to reproduce the error is below:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nbatch_size = 64\r\ndict_size = 100\r\nword_vec_size = 20\r\ninput_length = 10\r\ncontext_size = 2\r\n\r\ninput_xs = tf.keras.layers.Input(batch_shape=(batch_size,input_length),dtype=\"int32\",name=\"input_xs\")\r\ncontext = tf.keras.layers.Input(batch_shape=(batch_size,2),dtype=\"float32\",name=\"input_context\")\r\n\r\nword_embedding = tf.keras.layers.Embedding(dict_size, word_vec_size, input_length=input_length, name='word_embedding')\r\nword_vecs = word_embedding(input_xs)\r\n\r\nconcatenator = tf.keras.layers.TimeDistributed(tf.keras.layers.Lambda(lambda x: tf.keras.layers.Concatenate()([x,context])))\r\noutputs = concatenator(word_vecs)\r\n\r\nmodel = tf.keras.models.Model(inputs=[input_xs,context],outputs=outputs)\r\n```\r\nThe full error output:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"td_error.py\", line 18, in <module>\r\n    outputs = concatenator(word_vecs)\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 769, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\wrappers.py\", line 250, in call\r\n    unroll=False)\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 3193, in rnn\r\n    outputs, _ = step_function(inputs[0], initial_states + constants)\r\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\wrappers.py\", line 242, in step\r\n    uses_learning_phase)\r\nNameError: name 'uses_learning_phase' is not defined\r\n```\r\n\r\nThis error **only** occurs if the `batch_shape` argument is passed to the input layer(s). Changing the input like so does not generate an error:\r\n\r\n```\r\ninput_xs = tf.keras.layers.Input(shape=(input_length,),dtype=\"int32\",name=\"input_xs\")\r\ncontext = tf.keras.layers.Input(shape=(2,),dtype=\"float32\",name=\"input_context\")\r\n```\r\n\r\nHowever I am using a stateful RNN in my actual model so I have to specify the `batch_shape`.\r\n \r\nIf I implement the concatenation manually using `tf.keras.backend.rnn` the error goes away but a new problem is introduced:\r\n\r\n```\r\ndef apply_concats(layer,context):\r\n    concat_lambda = tf.keras.layers.Lambda(lambda x: tf.keras.layers.Concatenate()([x,context]))\r\n    input_shape = tf.keras.backend.int_shape(layer)\r\n    def lambda_step(x, _):\r\n        return concat_lambda(x), []\r\n\r\n    _, outputs, _ = tf.keras.backend.rnn(\r\n        lambda_step,\r\n        layer,\r\n        initial_states=[],\r\n        input_length=input_shape[1],\r\n        unroll=False\r\n    )\r\n    return outputs\r\n\r\nconcatenator = tf.keras.layers.Lambda(lambda x: apply_concats(x,context))\r\noutputs = concatenator(word_vecs)\r\nmodel = tf.keras.models.Model(inputs=[input_xs,context],outputs=outputs)\\\r\nmodel.compile(optimizer='adam',\r\n              loss='sparse_categorical_crossentropy')\r\nprint(model.summary())\r\n```\r\nThe output for `print(model.summary())` shows:\r\n```\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #\r\n=================================================================\r\ninput_xs (InputLayer)        (64, 10)                  0\r\n_________________________________________________________________\r\nword_embedding (Embedding)   (64, 10, 20)              2000\r\n_________________________________________________________________\r\nlambda (Lambda)              (64, 10, 22)              0\r\n=================================================================\r\nTotal params: 2,000\r\nTrainable params: 2,000\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\n```\r\nWhich does not include the context layer because it is in the Lambda as a closure.\r\n\r\nThis same problem occurs when using the `TimeDistributed` layer:\r\n\r\n```\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #\r\n=================================================================\r\ninput_xs (InputLayer)        (None, 10)                0\r\n_________________________________________________________________\r\nword_embedding (Embedding)   (None, 10, 20)            2000\r\n_________________________________________________________________\r\ntime_distributed (TimeDistri (None, 10, 22)            0\r\n=================================================================\r\nTotal params: 2,000\r\nTrainable params: 2,000\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\n```\r\n\r\nBut if I change my `Lambda` layer in my fixed version everything is fixed:\r\n\r\n```\r\nconcatenator = tf.keras.layers.Lambda(lambda x: apply_concats(x[0],x[1]))\r\noutputs = concatenator([word_vecs,context])\r\n```\r\nIn this version the context is explicitly passed to the lambda instead of in the closure. Now the model summary includes all layers:\r\n```\r\n__________________________________________________________________________________________________\r\nLayer (type)                    Output Shape         Param #     Connected to\r\n==================================================================================================\r\ninput_xs (InputLayer)           (64, 10)             0\r\n__________________________________________________________________________________________________\r\nword_embedding (Embedding)      (64, 10, 20)         2000        input_xs[0][0]\r\n__________________________________________________________________________________________________\r\ninput_context (InputLayer)      (64, 2)              0\r\n__________________________________________________________________________________________________\r\nlambda (Lambda)                 (64, 10, 22)         0           word_embedding[0][0]\r\n                                                                 input_context[0][0]\r\n==================================================================================================\r\nTotal params: 2,000\r\nTrainable params: 2,000\r\nNon-trainable params: 0\r\n__________________________________________________________________________________________________\r\n```", "> Hi @harshini-gadige\r\n> \r\n> Sorry for the delayed reply.\r\n> \r\n> **What is the top-level directory of the model you are using:**\r\n> I'm not sure what this means?\r\n> \r\n> **Have I written custom code (as opposed to using a stock example script provided in TensorFlow):**\r\n> I am not using any stock example scripts\r\n> \r\n> **OS Platform and Distribution (e.g., Linux Ubuntu 16.04):**\r\n> Windows 10\r\n> \r\n> **TensorFlow installed from (source or binary):**\r\n> Binary installed with pip\r\n> \r\n> **TensorFlow version (use command below):**\r\n> From my `pip list` >> `tensorflow-gpu 1.11.0`\r\n> \r\n> **CUDA/cuDNN version:**\r\n> CUDA Version 9.0.176\r\n> cudnn-9.0-windows10-x64-v7.3.0.29\r\n> \r\n> **GPU model and memory:**\r\n> GeForce GTX 850M (4.0GB)\r\n> \r\n> **Exact command to reproduce:**\r\n> A minimal example to reproduce the error is below:\r\n> \r\n> ```\r\n> import tensorflow as tf\r\n> \r\n> batch_size = 64\r\n> dict_size = 100\r\n> word_vec_size = 20\r\n> input_length = 10\r\n> context_size = 2\r\n> \r\n> input_xs = tf.keras.layers.Input(batch_shape=(batch_size,input_length),dtype=\"int32\",name=\"input_xs\")\r\n> context = tf.keras.layers.Input(batch_shape=(batch_size,2),dtype=\"float32\",name=\"input_context\")\r\n> \r\n> word_embedding = tf.keras.layers.Embedding(dict_size, word_vec_size, input_length=input_length, name='word_embedding')\r\n> word_vecs = word_embedding(input_xs)\r\n> \r\n> concatenator = tf.keras.layers.TimeDistributed(tf.keras.layers.Lambda(lambda x: tf.keras.layers.Concatenate()([x,context])))\r\n> outputs = concatenator(word_vecs)\r\n> \r\n> model = tf.keras.models.Model(inputs=[input_xs,context],outputs=outputs)\r\n> ```\r\n> The full error output:\r\n> \r\n> ```\r\n> Traceback (most recent call last):\r\n>   File \"td_error.py\", line 18, in <module>\r\n>     outputs = concatenator(word_vecs)\r\n>   File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 769, in __call__\r\n>     outputs = self.call(inputs, *args, **kwargs)\r\n>   File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\wrappers.py\", line 250, in call\r\n>     unroll=False)\r\n>   File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 3193, in rnn\r\n>     outputs, _ = step_function(inputs[0], initial_states + constants)\r\n>   File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\wrappers.py\", line 242, in step\r\n>     uses_learning_phase)\r\n> NameError: name 'uses_learning_phase' is not defined\r\n> ```\r\n> This error **only** occurs if the `batch_shape` argument is passed to the input layer(s). Changing the input like so does not generate an error:\r\n> \r\n> ```\r\n> input_xs = tf.keras.layers.Input(shape=(input_length,),dtype=\"int32\",name=\"input_xs\")\r\n> context = tf.keras.layers.Input(shape=(2,),dtype=\"float32\",name=\"input_context\")\r\n> ```\r\n> However I am using a stateful RNN in my actual model so I have to specify the `batch_shape`.\r\n> \r\n> If I implement the concatenation manually using `tf.keras.backend.rnn` the error goes away but a new problem is introduced:\r\n> \r\n> ```\r\n> def apply_concats(layer,context):\r\n>     concat_lambda = tf.keras.layers.Lambda(lambda x: tf.keras.layers.Concatenate()([x,context]))\r\n>     input_shape = tf.keras.backend.int_shape(layer)\r\n>     def lambda_step(x, _):\r\n>         return concat_lambda(x), []\r\n> \r\n>     _, outputs, _ = tf.keras.backend.rnn(\r\n>         lambda_step,\r\n>         layer,\r\n>         initial_states=[],\r\n>         input_length=input_shape[1],\r\n>         unroll=False\r\n>     )\r\n>     return outputs\r\n> \r\n> concatenator = tf.keras.layers.Lambda(lambda x: apply_concats(x,context))\r\n> outputs = concatenator(word_vecs)\r\n> model = tf.keras.models.Model(inputs=[input_xs,context],outputs=outputs)\\\r\n> model.compile(optimizer='adam',\r\n>               loss='sparse_categorical_crossentropy')\r\n> print(model.summary())\r\n> ```\r\n> The output for `print(model.summary())` shows:\r\n> \r\n> ```\r\n> _________________________________________________________________\r\n> Layer (type)                 Output Shape              Param #\r\n> =================================================================\r\n> input_xs (InputLayer)        (64, 10)                  0\r\n> _________________________________________________________________\r\n> word_embedding (Embedding)   (64, 10, 20)              2000\r\n> _________________________________________________________________\r\n> lambda (Lambda)              (64, 10, 22)              0\r\n> =================================================================\r\n> Total params: 2,000\r\n> Trainable params: 2,000\r\n> Non-trainable params: 0\r\n> _________________________________________________________________\r\n> ```\r\n> Which does not include the context layer because it is in the Lambda as a closure.\r\n> \r\n> This same problem occurs when using the `TimeDistributed` layer:\r\n> \r\n> ```\r\n> _________________________________________________________________\r\n> Layer (type)                 Output Shape              Param #\r\n> =================================================================\r\n> input_xs (InputLayer)        (None, 10)                0\r\n> _________________________________________________________________\r\n> word_embedding (Embedding)   (None, 10, 20)            2000\r\n> _________________________________________________________________\r\n> time_distributed (TimeDistri (None, 10, 22)            0\r\n> =================================================================\r\n> Total params: 2,000\r\n> Trainable params: 2,000\r\n> Non-trainable params: 0\r\n> _________________________________________________________________\r\n> ```\r\n> But if I change my `Lambda` layer in my fixed version everything is fixed:\r\n> \r\n> ```\r\n> concatenator = tf.keras.layers.Lambda(lambda x: apply_concats(x[0],x[1]))\r\n> outputs = concatenator([word_vecs,context])\r\n> ```\r\n> In this version the context is explicitly passed to the lambda instead of in the closure. Now the model summary includes all layers:\r\n> \r\n> ```\r\n> __________________________________________________________________________________________________\r\n> Layer (type)                    Output Shape         Param #     Connected to\r\n> ==================================================================================================\r\n> input_xs (InputLayer)           (64, 10)             0\r\n> __________________________________________________________________________________________________\r\n> word_embedding (Embedding)      (64, 10, 20)         2000        input_xs[0][0]\r\n> __________________________________________________________________________________________________\r\n> input_context (InputLayer)      (64, 2)              0\r\n> __________________________________________________________________________________________________\r\n> lambda (Lambda)                 (64, 10, 22)         0           word_embedding[0][0]\r\n>                                                                  input_context[0][0]\r\n> ==================================================================================================\r\n> Total params: 2,000\r\n> Trainable params: 2,000\r\n> Non-trainable params: 0\r\n> __________________________________________________________________________________________________\r\n> ```\r\n\r\n@qlzh727  PTAL", "I can confirm the issue - I got the exact same error when applying a `TimeDistributed` layer with inputs specified with `batch_shape`.", "Me, too. Got the same problem.", "Hi all, sorry for the very late reply. I was able to repro this issue in 1.11 but not in tf-nightly. This indicates that the issue was recently been fixed. Looking at the code history, @fchollet has some recent global change for the uses_learning_phase, which might already fix the issue.\r\n\r\nCan you confirm that whether it as been fixed in the latest head by \"pip install -U tf-nightly\" or \"pip install -U tf-nightly-gpu\"?\r\n\r\nThanks.", "Assume the bug has already been fixed from my previous observation, closing the bug for now. Please reopen this issue if there are still outstanding issue."]}, {"number": 23424, "title": "Fix BZL_FILE_PATH detection in building tensorflow lite", "body": "Currently it will cause an error.\r\n`Could not find tensorflow/workspace.bzl:\r\nLikely you are not running this from the root directory of the repository.`", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Thank you @sunnycase, this fixes the issue for me.", "~~Also I believe [lite/experimental/micro/tools/make/download_dependencies.sh](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/micro/tools/make/download_dependencies.sh) will have the same problem.~~ It seems to work just fine.\r\n", "This has been fixed independently recently.", "> This has been fixed independently recently.\r\n\r\nCan this PR be closed as this issue is fixed ? Please correct me if I'm wrong.", "Nagging Reviewer @miaout17, @aselle: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 44 days with no activity and the `awaiting review` label has been applied."]}, {"number": 23423, "title": "Should use '_train_distribution' because Estimator doesn't have attribute '_distribution'", "body": "When I use tf.contrib.distribute.MirroredStrategy and training_hooks for one Estimator, like:\r\n\r\n```\r\ndistribution = tf.contrib.distribute.MirroredStrategy(\r\n      [\"/device:GPU:0\", \"/device:GPU:1\"])\r\nconfig = tf.estimator.RunConfig(train_distribute=distribution,\r\n                                  eval_distribute=distribution)\r\nestimator = tf.estimator.Estimator(\r\n      model_fn=build_model_fn_optimizer(), config=config)\r\nestimator.train(input_fn=input_fn, steps=10)\r\n```\r\n\r\nand\r\n\r\n```\r\n    logging_hook = tf.train.LoggingTensorHook({'logits' : logits})\r\n    return tf.estimator.EstimatorSpec(mode, loss=loss_fn(), train_op=train_op, training_hooks = [logging_hook])\r\n```\r\n\r\nIt will report error:\r\n```\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 356, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1179, in _train_model\r\n    return self._train_model_distributed(input_fn, hooks, saving_listeners)\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1309, in _train_model_distributed\r\n    grouped_estimator_spec.training_hooks)\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1305, in get_hooks_from_the_first_device\r\n    for per_device_hook in per_device_hooks\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1305, in <listcomp>\r\n    for per_device_hook in per_device_hooks\r\nAttributeError: 'Estimator' object has no attribute '_distribution'\r\n```\r\n\r\nThe solution is using '_train_distribution' instead of '_distribution'\r\n ", "comments": ["Just as a headsup, this looks like it is trying to fix tensorflow r1.11 (it seems fixed at head).", "It's already tf 1.12.0, and it's said tf 2.0 is coming. \r\nBut this is still a bug, and this fix is NOT merged yet.", "Closing this PR as this not against `master`, please open a new PR against `master` \r\nCC @mihaimaruseac"]}, {"number": 23422, "title": "a  confused problem about placeholder", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary):from pycharm(+anaconda)\r\n- TensorFlow version (use command below):1.9\r\n- Python version:3.6\r\n- CUDA/cuDNN version:8.0/5.1\r\n- GPU model and memory:1060/6g\r\n\r\n\r\nI want to  give values of lr and beta1 to adam with placeholder but there is an error'You must feed a value for placeholder tensor 'm' with dtype float'. it's confused because when i fix the beta1=0.5, the lr can deliver to the adam, once i want to deliver lr and beta1 to adam there will be error. \r\n\r\n`def build_training_pi_graph(x, y, ul_x, lr, unsup_weight, m):\r\n    global_step = tf.get_variable(\r\n        name=\"global_step\",\r\n        shape=[],\r\n        dtype=tf.float32,\r\n        initializer=tf.constant_initializer(0.0),\r\n        trainable=False,\r\n    )\r\n\r\n    z_label1 = PiModels.call(x)\r\n    z_label2 = PiModels.call(x)\r\n\r\n    z_unlabeled1 = PiModels.call(ul_x)\r\n    z_unlabeled2 = PiModels.call(ul_x)\r\n    with tf.variable_scope(tf.get_variable_scope(), reuse=True):\r\n        ce = tf.losses.softmax_cross_entropy(z_label1, y)\r\n        ul_loss = tf.losses.mean_squared_error(z_label1, z_label2)\r\n        l_loss = tf.losses.mean_squared_error(z_unlabeled1, z_unlabeled2)\r\n        loss = ce + unsup_weight * (ul_loss + l_loss)\r\n\r\n    opt = tf.train.AdamOptimizer(learning_rate=lr, beta1=m, beta2=0.999)\r\n    tvars = tf.trainable_variables()\r\n    grads_and_vars = opt.compute_gradients(loss, tvars)\r\n    train_op = opt.apply_gradients(grads_and_vars, global_step=global_step)\r\n\r\n    return loss, train_op, global_step`\r\n`def main():\r\n    with tf.Graph().as_default() as g:\r\n\r\n        with tf.device(\"/cpu:0\"):\r\n            train_labeled_iterator = inputs(batch_size=batch_size,\r\n                                    train=True,\r\n                                    validation=validation,\r\n                                    shuffle=True, num_epochs=num_epochs+1000)\r\n            train_x, train_y, label_index = train_labeled_iterator.get_next()\r\n\r\n            train_unlabeled_iterator = unlabeled_inputs(batch_size=ul_batch_size,\r\n                                        validation=validation,\r\n                                         shuffle=True,num_epochs=num_epochs)\r\n            ul_x, _, unlabel_index = train_unlabeled_iterator.get_next()\r\n\r\n            validation_iterator = inputs(batch_size=eval_batch_size,\r\n                                                          train=True,\r\n                                                          validation=True,\r\n                                                          shuffle=True)\r\n            val_x, val_y, _ = validation_iterator.get_next()\r\n\r\n            itest_iterator = inputs(batch_size=eval_batch_size,\r\n                                                        train=False,\r\n                                                        validation=validation,\r\n                                                        shuffle=True)\r\n            test_x, test_y, _= itest_iterator.get_next()\r\n\r\n        with tf.device(device):\r\n            lr = tf.placeholder(tf.float32, shape=[], name='learning_rate')\r\n            unsupervised_weight = tf.placeholder(tf.float32, shape=[], name='unsupervised_weight')\r\n            m = tf.placeholder(tf.float32, shape=[], name='m')\r\n            with tf.variable_scope('CNN', reuse=tf.AUTO_REUSE):\r\n                loss, train_op, global_step = build_training_pi_graph(train_x, train_y, ul_x, lr, unsupervised_weight, m)\r\n\r\n            init_op = tf.global_variables_initializer()\r\n\r\n        with tf.Session().as_default() as sess:\r\n            sess.run(init_op)\r\n            for ep in range(num_epochs):\r\n\r\n                sum_loss = 0\r\n\r\n                feed_dict = {lr: 0.001, unsupervised_weight: 0.5, m: 0.5}\r\n\r\n                start = time.time()\r\n                for i in range(num_iter_per_epoch):\r\n                    batch_loss, _, _ = sess.run([loss, train_op, global_step], feed_dict=feed_dict)\r\n                    sum_loss += batch_loss\r\n                end = time.time()\r\n                print('epoch:', ep, 'epoch train loss:', sum_loss / num_iter_per_epoch, 'epoch train time:',\r\n                      end - start)\r\n\r\nmain()`\r\n\r\n**Other info / logs**\r\nTraceback (most recent call last):\r\n  File \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1292, in _do_call\r\n    return fn(*args)\r\n  File \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1277, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1367, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'm' with dtype float\r\n\t [[{{node m}} = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/zw/PycharmProjects/self/tempens-self/piModel.py\", line 172, in <module>\r\n    main()\r\n  File \"/home/zw/PycharmProjects/self/tempens-self/piModel.py\", line 157, in main\r\n    sess.run(init_op)\r\n  File \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 887, in run\r\n    run_metadata_ptr)\r\n  File \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1110, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1286, in _do_run\r\n    run_metadata)\r\n  File \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1308, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'm' with dtype float\r\n\t [[{{node m}} = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n\r\nCaused by op 'm', defined at:\r\n  File \"/home/zw/PycharmProjects/self/tempens-self/piModel.py\", line 172, in <module>\r\n    main()\r\n  File \"/home/zw/PycharmProjects/self/tempens-self/piModel.py\", line 146, in main\r\n    m = tf.placeholder(tf.float32, shape=[], name='m')\r\n  File \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1745, in placeholder\r\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\r\n  File \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 5020, in placeholder\r\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\r\n  File \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3272, in create_op\r\n    op_def=op_def)\r\n  File \"/home/zw/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1768, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'm' with dtype float\r\n\t [[{{node m}} = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n\r\nany help, thanks", "comments": ["@aselle   PTAL", "Nagging Assignee @aselle: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "The traceback tells you that you need to provide m. It tells you where, in the \"init\" call\r\ni.e. change your sess.run(init_op) to sess.run(init_op, {m: .5})\r\n", "Closing this as it is in \"awaiting response\" status for more than 7 days. Feel free to add your comments and we will reopen(if required)."]}, {"number": 23421, "title": "Should use '_train_distribution' because Estimator doesn't have attribute '_distribution'", "body": "When I use tf.contrib.distribute.MirroredStrategy and training_hooks for one Estimator, like:\r\n\r\n```\r\ndistribution = tf.contrib.distribute.MirroredStrategy(\r\n      [\"/device:GPU:0\", \"/device:GPU:1\"])\r\nconfig = tf.estimator.RunConfig(train_distribute=distribution,\r\n                                  eval_distribute=distribution)\r\nestimator = tf.estimator.Estimator(\r\n      model_fn=build_model_fn_optimizer(), config=config)\r\nestimator.train(input_fn=input_fn, steps=10)\r\n```\r\n\r\nand\r\n\r\n```\r\n    logging_hook = tf.train.LoggingTensorHook({'logits' : logits})\r\n    return tf.estimator.EstimatorSpec(mode, loss=loss_fn(), train_op=train_op, training_hooks = [logging_hook])\r\n```\r\n\r\nIt will report error:\r\n```\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 356, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1179, in _train_model\r\n    return self._train_model_distributed(input_fn, hooks, saving_listeners)\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1309, in _train_model_distributed\r\n    grouped_estimator_spec.training_hooks)\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1305, in get_hooks_from_the_first_device\r\n    for per_device_hook in per_device_hooks\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1305, in <listcomp>\r\n    for per_device_hook in per_device_hooks\r\nAttributeError: 'Estimator' object has no attribute '_distribution'\r\n```\r\n\r\nThe solution is using '_train_distribution' instead of '_distribution'\r\n ", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!\r\n"]}, {"number": 23420, "title": "bazel build on Windows with mkl failed", "body": "I'm trying to compile tensorflow with MKL support on Windows 10 64bit via Bazel with command:\r\n`bazel build --config=mkl --config=opt //tensorflow/tools/pip_package:build_pip_package`\r\non the following environments:\r\n- Windows 10 64 bit\r\n- Tensorflow 1.12\r\n- Python 3.6.6\r\n- Bazel 0.18\r\n\r\nOn the same setup, I can successfully build it without --config=mkl term,  but when building with mkl it failed as following:\r\nwho can tell me if it has anything related to mkl?\r\n```\r\nERROR: F:/tools/tf1.12/tensorflow/tensorflow/python/BUILD:3766:1: Linking of rule '//tensorflow/python:_pywrap_tensorflow_internal.so' failed (Exit 1000): link.exe failed: error executing command\r\n  cd C:/users/10267/_bazel_10267/udaytyio/execroot/org_tensorflow\r\n  SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\LIB\\amd64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.10240.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\8.1\\lib\\winv6.3\\um\\x64;\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\amd64;C:\\WINDOWS\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\Tools;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Team Tools\\Performance Tools\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Windows Kits\\8.1\\bin\\x64;C:\\Program Files (x86)\\Windows Kits\\8.1\\bin\\x86;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;;C:\\WINDOWS\\system32\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=C:/Program Files/Python36/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Program Files/Python36/lib/site-packages\r\n    SET TEMP=C:\\Users\\10267\\AppData\\Local\\Temp\r\n    SET TF_DOWNLOAD_CLANG=0\r\n    SET TF_NEED_CUDA=0\r\n    SET TF_NEED_OPENCL_SYCL=0\r\n    SET TMP=C:\\Users\\10267\\AppData\\Local\\Temp\r\n  C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64/link.exe /nologo /DLL /SUBSYSTEM:CONSOLE -defaultlib:advapi32.lib -DEFAULTLIB:advapi32.lib /MACHINE:X64 @bazel-out/x64_windows-opt/bin/tensorflow/python/_pywrap_tensorflow_internal.so-2.params /OPT:ICF /OPT:REF /DEF:bazel-out/x64_windows-opt/genfiles/tensorflow/python/pywrap_tensorflow_filtered_def_file.def /ignore:4070\r\nLINK : warning LNK4044: unrecognized option '/lpthread'; ignored\r\n\r\nbazel-out/x64_windows-opt/bin/external/nsync/nsync_cpp.lib : fatal error LNK1000: Internal error during CImplib::EmitThunk\r\n\r\n  Version 14.00.24215.1\r\n\r\n  ExceptionCode            = C0000005\r\n  ExceptionFlags           = 00000000\r\n  ExceptionAddress         = 00007FF7E0686896 (00007FF7E0670000) \"C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\bin\\amd64\\link.exe\"\r\n  NumberParameters         = 00000002\r\n  ExceptionInformation[ 0] = 0000000000000000\r\n  ExceptionInformation[ 1] = 0000000000000008\r\n\r\nCONTEXT:\r\n  Rax    = 0000000000000000  R8     = 00007FF7E076FBE0\r\n  Rbx    = 0000000000000000  R9     = 00007FF7E076E9F0\r\n  Rcx    = 0000000000000000  R10    = 0000000000000000\r\n  Rdx    = 00007FF7E076FBD8  R11    = 0000000000000000\r\n  Rsp    = 000000082B71DE68  R12    = 00007FF7E073D950\r\n  Rbp    = 000001A60F8F8360  E13    = 0000000000000000\r\n  Rsi    = 0000000000008000  R14    = 0000000000000000\r\n  Rdi    = 000001A6102AA300  R15    = 0000000000000000\r\n  Rip    = 00007FF7E0686896  EFlags = 0000000000010246\r\n  SegCs  = 0000000000000033  SegDs  = 000000000000002B\r\n  SegSs  = 000000000000002B  SegEs  = 000000000000002B\r\n  SegFs  = 0000000000000053  SegGs  = 000000000000002B\r\n  Dr0    = 0000000000000000  Dr3    = 0000000000000000\r\n  Dr1    = 0000000000000000  Dr6    = 0000000000000000\r\n  Dr2    = 0000000000000000  Dr7    = 0000000000000000\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 3172.917s, Critical Path: 253.76s\r\nINFO: 3875 processes: 3875 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["@ufgtb24 We'll take a look.", "@TensorFlow-MKL  hi, folks, how is it going, any progress?  ", "https://github.com/tensorflow/tensorflow/issues/21886#issuecomment-416445710", "Here is a work-around:\r\n\r\n1.  Before following the [TensorFlow Windows build instructions](https://www.tensorflow.org/install/source_windows), install  \u201cVisual C++ Redistributable Packages for Visual Studio 2013\u201d. This is necessary to overcome a [linker issue](https://www.microsoft.com/en-us/download/details.aspx?id=40784)\r\n2. Follow the  [TensorFlow Windows build instructions](https://www.tensorflow.org/install/source_windows)--including the more recent version of the Microsoft tool chain--except the last step (`bazel build`).\r\n3. Edit the PATH environment variable to include the location of the [two libraries required by MKL-DNN](https://github.com/intel/mkl-dnn#windows). Use the same `path_to_output` in this step and step 4.\r\n`set PATH=%PATH%;path_to_output\\external\\mkl_windows\\lib`\r\n4. Use the following build command to build TensorFlow with support for Intel(R) MKL-DNN. The flag /FORCE:MULTIPLE is required to work around some the linker issues.\r\n`bazel --output_base=\u201dpath_to_output\u201d --config=mkl --linkopt=\"/FORCE:MULTIPLE\" -c opt //tensorflow/tools/pip_package:build_pip_package`\r\n\r\nThe problem lies with how MKL-DNN is being built. Currently, there is a small part that is not being built from source, and that library was built with an older version of the Microsoft compiler. A long-term solution will involve recompiling that library with a new version of the Microsoft tool chain.", "@ufgtb24 , have you tried the workaround? Is your issue solved? ", "Hi @TensorFlow-MKL ,\r\n\r\nI have the same problem.\r\nwhen running suggested workaround I get this error (similar link error but now on int128.lib).\r\nplease advice.\r\n\r\n  C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64/link.exe /nologo /DLL /SUBSYSTEM:CONSOLE /MACHINE:X64 /FORCE:MULTIPLE @bazel-out/x64_windows-opt/bin/tensorflow/lite/toco/python/_tensorflow_wrap_toco.so-2.params /OPT:ICF /OPT:REF\r\nExecution platform: @bazel_tools//platforms:host_platform\r\nLINK : warning LNK4044: unrecognized option '/ldl'; ignored\r\nLINK : warning LNK4044: unrecognized option '/lpthread'; ignored\r\nLINK : warning LNK4044: unrecognized option '/ldl'; ignored\r\n\r\nbazel-out/x64_windows-opt/bin/external/com_google_absl/absl/numeric/int128.lib : fatal error LNK1000: Internal error during CImplib::EmitThunk\r\n\r\n  Version 14.00.24210.0\r\n\r\n  ExceptionCode            = C0000005\r\n  ExceptionFlags           = 00000000\r\n  ExceptionAddress         = 000000013F4E6896 (000000013F4D0000) \"C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\bin\\amd64\\link.exe\"\r\n  NumberParameters         = 00000002\r\n  ExceptionInformation[ 0] = 0000000000000000\r\n  ExceptionInformation[ 1] = 0000000000000008\r\n\r\nCONTEXT:\r\n  Rax    = 0000000000000000  R8     = 000000013F5CFBE0\r\n  Rbx    = 0000000000000000  R9     = 000000013F5CE9F0\r\n  Rcx    = 0000000000000000  R10    = 0000000000000000\r\n  Rdx    = 000000013F5CFBD8  R11    = 0000000000000000\r\n  Rsp    = 000000000014E148  R12    = 000000013F59D950\r\n  Rbp    = 0000000002B857C0  E13    = 0000000000000000\r\n  Rsi    = 0000000000008000  R14    = 0000000000000000\r\n  Rdi    = 0000000003162100  R15    = 0000000000000000\r\n  Rip    = 000000013F4E6896  EFlags = 0000000000010246\r\n  SegCs  = 0000000000000033  SegDs  = 000000000000002B\r\n  SegSs  = 000000000000002B  SegEs  = 000000000000002B\r\n  SegFs  = 0000000000000053  SegGs  = 000000000000002B\r\n  Dr0    = 0000000000000000  Dr3    = 0000000000000000\r\n  Dr1    = 0000000000000000  Dr6    = 0000000000000000\r\n  Dr2    = 0000000000000000  Dr7    = 0000000000000000\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 2512.426s, Critical Path: 1053.25s\r\nINFO: 4028 processes: 4028 local.\r\nFAILED: Build did NOT complete successfully\r\nFAILED: Build did NOT complete successfully\r\n\r\nThanks", "I also got above error even with workaround. ", "we are working to get a fast resolution on this https://github.com/tensorflow/tensorflow/issues/25213#issuecomment-459091124", "D:\\CodeSofteware\\tensorflow-r1.13\\bazel-bin-copy\\tensorflow\\libtensorflow_cc.so.if.lib : **fatal error LNK1000: Internal error during CImplib::EmitThunk**\r\n    Version 14.00.24215.1\r\n    ExceptionCode            = C0000005\r\n    ExceptionFlags           = 00000000\r\n    ExceptionAddress         = 00C1D798 (00C00000) \"D:\\CodeSofteware\\VisualStudio2015\\VC\\bin\\x86_amd64\\link.exe\"\r\n    NumberParameters         = 00000002\r\n    ExceptionInformation[ 0] = 00000000\r\n    ExceptionInformation[ 1] = 00000004\r\n  CONTEXT:\r\n    Eax    = 000DD70A  Esp    = 009BE4BC\r\n    Ebx    = 00CD2E44  Ebp    = 009BE4C0\r\n    Ecx    = 00000000  Esi    = 00000000\r\n    Edx    = 00CD3C68  Edi    = 00000000\r\n    Eip    = 00C1D798  EFlags = 00010296\r\n    SegCs  = 00000023  SegDs  = 0000002B\r\n    SegSs  = 0000002B  SegEs  = 0000002B\r\n    SegFs  = 00000053  SegGs  = 0000002B\r\n    Dr0    = 00000000  Dr3    = 00000000\r\n    Dr1    = 00000000  Dr6    = 00000000\r\n    Dr2    = 00000000  Dr7    = 00000000\r\n> ========== Build: 0 succeeded, 1 failed, 0 up-to-date, 0 skipped ==========\r\n\r\n\r\nalso encounter this questions, anyone can help me ? THANK YOU", "The mkl issue with TensorFlow on windos is fixed. Please find the build instructions here:\r\n[https://software.intel.com/en-us/articles/intel-optimization-for-tensorflow-installation-guide#wind_B_S](https://software.intel.com/en-us/articles/intel-optimization-for-tensorflow-installation-guide#wind_B_S)", "@preethivenkatesh That's great, thanks! BTW, MKL-DNN 1.0 no longer requires MKL or MKLML: https://github.com/intel/mkl-dnn/issues/341 So once TensorFlow is updated to that version, we won't need to worry about linking issues with MKLML.", "Either ways you don't have to worry about MKLML, MKLML is recompiled to be compatible with the newer VC++ compiler. Also, the bug was caused not only by MKLML compiled with an older compiler, but also the  /WHOLEARCHIVE switch used along with link.exe.", "@ufgtb24 could you please close this issue if we have provided a resolution ", "closing this issue. Resolution provided. please reopen this ticket in case you experience this issue again", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=23420\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=23420\">No</a>\n"]}, {"number": 23419, "title": "install adanet model got wrong ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["hi , i want to install the model \"adanet\"\r\n1 \u3001tensorflow version: 1.7.0\r\n2\u3001installed bazel:  bazel-0.17.2-installer-linux-x86_64.sh\r\n3\u3001but  when  `bazel test -c opt //...` , it got the error:\r\nINFO: Analysed 36 targets (0 packages loaded).\r\nINFO: Found 22 targets and 14 test targets...\r\nFAIL: //adanet/core:estimator_test (shard 11 of 20) (see /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_11_of_20/test.log)\r\nFAIL: //adanet/examples:simple_dnn_test (see /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/examples/simple_dnn_test/test.log)\r\nFAIL: //adanet/core:report_accessor_test (see /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/report_accessor_test/test.log)\r\nFAIL: //adanet/core:estimator_test (shard 3 of 20) (see /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_3_of_20/test.log)\r\nFAIL: //adanet/core:estimator_test (shard 17 of 20) (see /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_17_of_20/test.log)\r\nFAIL: //adanet/core:estimator_test (shard 10 of 20) (see /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_10_of_20/test.log)\r\nFAIL: //adanet/core:estimator_test (shard 14 of 20) (see /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_14_of_20/test.log)\r\nFAIL: //adanet/core:estimator_test (shard 7 of 20) (see /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_7_of_20/test.log)\r\nFAIL: //adanet/core:estimator_test (shard 8 of 20) (see /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_8_of_20/test.log)\r\nFAIL: //adanet/core:estimator_test (shard 5 of 20) (see /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_5_of_20/test.log)\r\nFAIL: //adanet/core:estimator_test (shard 2 of 20) (see /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_2_of_20/test.log)\r\nFAIL: //adanet/core:estimator_test (shard 9 of 20) (see /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_9_of_20/test.log)\r\nFAIL: //adanet/core:estimator_test (shard 1 of 20) (see /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_1_of_20/test.log)\r\nFAIL: //adanet/core:estimator_test (shard 15 of 20) (see /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_15_of_20/test.log)\r\nFAIL: //adanet/core:estimator_test (shard 12 of 20) (see /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_12_of_20/test.log)\r\nFAIL: //adanet/core:estimator_test (shard 6 of 20) (see /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_6_of_20/test.log)\r\nFAIL: //adanet/core:estimator_test (shard 13 of 20) (see /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_13_of_20/test.log)\r\nFAIL: //adanet/core:estimator_test (shard 4 of 20) (see /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_4_of_20/test.log)\r\nFAIL: //adanet/core:estimator_test (shard 16 of 20) (see /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_16_of_20/test.log)\r\nFAIL: //adanet/core:estimator_test (shard 19 of 20) (see /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_19_of_20/test.log)\r\nFAIL: //adanet/core:estimator_test (shard 20 of 20) (see /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_20_of_20/test.log)\r\n\r\nFAILED: //adanet/core:estimator_test (Summary)\r\n      /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_11_of_20/test.log\r\n      /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_3_of_20/test.log\r\n      /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_17_of_20/test.log\r\n      /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_10_of_20/test.log\r\n      /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_14_of_20/test.log\r\n      /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_7_of_20/test.log\r\n      /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_8_of_20/test.log\r\n      /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_5_of_20/test.log\r\n      /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_2_of_20/test.log\r\n      /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_9_of_20/test.log\r\n      /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_1_of_20/test.log\r\n      /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_15_of_20/test.log\r\n      /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_12_of_20/test.log\r\n      /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_6_of_20/test.log\r\n      /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_13_of_20/test.log\r\n      /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_4_of_20/test.log\r\n      /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_16_of_20/test.log\r\n      /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_19_of_20/test.log\r\n      /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_20_of_20/test.log\r\n      /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_18_of_20/test.log\r\nFAIL: //adanet/core:estimator_test (shard 18 of 20) (see /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_18_of_20/test.log)\r\nINFO: Elapsed time: 2.128s, Critical Path: 1.47s\r\nINFO: 22 processes: 22 processwrapper-sandbox.\r\nINFO: Build completed, 3 tests FAILED, 23 total actions\r\n//adanet/core:candidate_test                                    (cached) PASSED in 3.5s\r\n//adanet/core:ensemble_test                                     (cached) PASSED in 18.7s\r\n//adanet/core:evaluator_test                                    (cached) PASSED in 2.6s\r\n//adanet/core:freezer_test                                      (cached) PASSED in 4.9s\r\n//adanet/core:input_utils_test                                  (cached) PASSED in 2.2s\r\n//adanet/core:iteration_test                                    (cached) PASSED in 12.2s\r\n//adanet/core:report_materializer_test                          (cached) PASSED in 2.2s\r\n//adanet/core:summary_test                                      (cached) PASSED in 2.1s\r\n//adanet/core:timer_test                                        (cached) PASSED in 2.5s\r\n//adanet/core/subnetwork:generator_test                         (cached) PASSED in 2.1s\r\n//adanet/core/subnetwork:report_test                            (cached) PASSED in 2.0s\r\n//adanet/core:report_accessor_test                                       FAILED in 0.6s\r\n  /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/report_accessor_test/test.log\r\n//adanet/examples:simple_dnn_test                                        FAILED in 0.6s\r\n  /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/examples/simple_dnn_test/test.log\r\n//adanet/core:estimator_test                                             FAILED in 20 out of 20 in 0.8s\r\n  Stats over 20 runs: max = 0.8s, min = 0.6s, avg = 0.7s, dev = 0.0s\r\n  /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_11_of_20/test.log\r\n  /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_3_of_20/test.log\r\n  /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_17_of_20/test.log\r\n  /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_10_of_20/test.log\r\n  /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_14_of_20/test.log\r\n  /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_7_of_20/test.log\r\n  /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_8_of_20/test.log\r\n  /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_5_of_20/test.log\r\n  /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_2_of_20/test.log\r\n  /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_9_of_20/test.log\r\n  /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_1_of_20/test.log\r\n  /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_15_of_20/test.log\r\n  /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_12_of_20/test.log\r\n  /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_6_of_20/test.log\r\n  /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_13_of_20/test.log\r\n  /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_4_of_20/test.log\r\n  /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_16_of_20/test.log\r\n  /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_19_of_20/test.log\r\n  /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_20_of_20/test.log\r\n  /root/.cache/bazel/_bazel_root/015a6089d8b90e272be423ca56fb1611/execroot/org_adanet/bazel-out/k8-opt/testlogs/adanet/core/estimator_test/shard_18_of_20/test.log\r\n\r\nExecuted 3 out of 14 tests: 11 tests pass and 3 fail locally.\r\nINFO: Build completed, 3 tests FAILED, 23 total actions\r\n\r\n4 \u3001so when import adanet . it got the error:\r\n\r\n>>> import adanet \r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/caojinrong/adanet/adanet/__init__.py\", line 22, in <module>\r\n    from adanet.core import Ensemble\r\n  File \"/home/caojinrong/adanet/adanet/core/__init__.py\", line 25, in <module>\r\n    from adanet.core.estimator import Estimator\r\n  File \"/home/caojinrong/adanet/adanet/core/estimator.py\", line 33, in <module>\r\n    from adanet.core.report_accessor import _ReportAccessor\r\n  File \"/home/caojinrong/adanet/adanet/core/report_accessor.py\", line 24, in <module>\r\n    from adanet.core import report_pb2 as report_proto\r\nImportError: cannot import name 'report_pb2'\r\n\r\n", "Hi,\r\nThis issue is better suited on [adanet repo](https://github.com/tensorflow/adanet/issues).\r\nClosing this issue, feel free to post this issue on adanet repo. Thanks!"]}, {"number": 23418, "title": "im wrong", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": []}, {"number": 23417, "title": "WARNING:tensorflow:Tensor._shape is private, use Tensor.shape instead. Tensor._shape will eventually be removed.", "body": "**System information**\r\n- Linux Ubuntu 16.04\r\n- TensorFlow installed from  binary:\r\n- TensorFlow version :1.11\r\n- Python version :3.5\r\n- CUDA/cuDNN version:9.0/7.1\r\n- GPU model and memory:GeForce GTX TITAN X \r\n\r\n**Describe the current behavior**\r\n(tfzkl) ddc@:~/zklcode/leapmotion$ cd /home/zklcode/leapmotion ; env \"PYTHONIOENCODING=UTF-8\" \"PYTHONUNBUFFERED=1\" /home/anaconda3/envs/tfzkl/bin/python3.5 /home/ddc/.vscode/extensions/ms-python.python-2018.9.1/pythonFiles/experimental/ptvsd_launcher.py 41383 /home/zklcode/leapmotion/leap/leaptf/tfleap.train.py\r\ndataset shape:(100, 2)\r\nBackend TkAgg is interactive backend. Turning interactive mode on.\r\nWARNING:tensorflow:Tensor._shape is private, use Tensor.shape instead. Tensor._shape will eventually be removed.\r\nWARNING:tensorflow:Tensor._shape is private, use Tensor.shape instead. Tensor._shape will eventually be removed.\r\n\r\nmy code don`t call tf.shape() function, why show this WARNING? anyone have this issue?\r\n", "comments": ["/home/anaconda3/envs/tfzkl/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\r\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\r\n\r\nwhere do this happen? how I debug my code ", "@tanzhenyu  PTAL", "@zkl99999   -  In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "> @zkl99999 - In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n\r\n@zkl99999  -  Any update ?", "In \"awaiting response\" status for more than 3 days. Hence closing this. Please post the updates here if any, we will reopen the issue. Thanks !"]}, {"number": 23416, "title": "Error in compile  tensorflowr1.8 on windows by vs2015 (Error: LNK1189 \uff1aMore than 65535 object restrictions)", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Windows 10):\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version:1.8\r\n- Python version:3.6\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:9.0/7\r\n- GPU model and memory:2\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["I have compiled the tensorlfowr1.8 in Release mode with GPU version and get the tensorflow.dll. When to debug mode, all project have been compiled successed except \"tensorflow\" project, and I compile it alone (Enable GPU) but Error of \"LNK1189 \uff1aMore than 65535 object restrictions\" occured. Any suggestions? Looking forward your reply~", "If possible can you please use the latest version of TensorFlow and build again ?", "Is this still an issue for you? Can you please provide following information:\r\nOS Platform and Distribution (e.g., Windows 10):\r\nInstalled using virtualenv? pip? conda?:\r\nBazel version (if compiling from source):\r\nThanks!", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 23415, "title": "API documentation updates for tf.b*", "body": "This PR contains miscellaneous API documentation updates that cover the API functions whose names start with \"tf.b\". Some of the changes correct typos, while others document aspects of these functions that weren't obvious to me without reading the source code.\r\n\r\nI've generated and reviewed the Markdown files for the documentation after these changes.", "comments": ["Pushed some changes to address review comments.", "@frreiss please rebase your branch", "changes are merged in to master , closing this PR"]}, {"number": 23414, "title": "Improve shape function of tf.sparse_reduce_sum", "body": "This fix tries to address the issue raised in #23114 where\r\nthe shape function of tf.sparse_reduce_sum did not\r\ninfer the shape even if the input shape were known.\r\n\r\nThis fix improves the shape function.\r\n\r\nThis fix fixes #23114.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Thanks @akshaym, the PR has been updated with shape function applied to SparseReduceMax as well. Additional test cases have also been added. Please take a look and let me know if there are any issues.", "Thanks @akshaym for the review. The PR has been updated. Please take a look and let me know if there are any issues.", "Nagging Assignee @akshaym: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 23413, "title": "Models cannot be loaded", "body": "### System information\r\n- **What is the top-level directory of the model you are using**:  ~/\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, written a simple MWE script\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04.1\r\n- **TensorFlow installed from (source or binary)**: Compiled from source\r\n- **TensorFlow version (use command below)**: 1.11.0\r\n- **Python version**: 3.6.6\r\n- **Bazel version (if compiling from source)**: 0.16.1\r\n- **GCC/Compiler version**: 7.3.0\r\n- **CUDA/cuDNN version**: Cuda: 9.2.148, cuDNN: 9.2-v7.3.1.20 \r\n- **GPU model and memory**: GeForce GTX1080Ti, 11GB\r\n- **Exact command to reproduce**:\r\n\r\nMinimal working example code\r\n\r\n```\r\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, ReLU, Flatten, Dense, Input\r\nfrom tensorflow.keras.models import Model\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.models import load_model\r\n\r\n\r\ndef cnn_model(rows, cols, channels):\r\n    model = Model()\r\n    inputs = Input(shape=(rows, cols, channels), dtype='float32')\r\n\r\n    conv1 = Conv2D(64, (3, 3),activation='linear',kernel_initializer='he_uniform')(inputs)\r\n    relu1 = ReLU()(conv1)\r\n    pooling1 = MaxPooling2D(pool_size=(5, 5))(relu1)\r\n\r\n    flatten = Flatten()(pooling1)\r\n\r\n    dense1 = Dense(512)(flatten)\r\n\r\n    relu2 = ReLU()(dense1)\r\n    predictions = Dense(4, activation='softmax')(relu2)\r\n\r\n    model = Model(inputs=inputs, outputs=predictions)\r\n\r\n    return model\r\n\r\n\r\nbatch_size = 16\r\nrows = 128\r\ncols = 128\r\nchannels = 1\r\nmodel_input = np.random.randint(0, 255, (batch_size, rows, cols, channels))\r\nmodel_labels = np.random.randint(0, 1, (batch_size, 4))\r\n\r\nmodel = cnn_model(rows, cols,channels)\r\n\r\nadam = tf.train.AdamOptimizer(learning_rate=0.01, beta1=0.9, beta2=0.999, epsilon=1e-8)\r\n\r\nmodel.compile(loss='categorical_crossentropy',\r\n              optimizer=adam,\r\n              metrics=['categorical_accuracy'])\r\nmodel.fit(x=model_input,\r\n          y=model_labels,\r\n          epochs=2)\r\n\r\nmodel.save(\"/home/svdvoort/test_model.hdf5\")\r\nload_model(\"/home/svdvoort/test_model.hdf5\")\r\n```\r\n\r\n### Describe the problem\r\n\r\nReturns the following output (error included):\r\n\r\n```\r\nEpoch 1/2\r\n2018-10-31 19:09:12.162738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 10.91GiB freeMemory: 10.76GiB\r\n2018-10-31 19:09:12.290346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 1 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683\r\npciBusID: 0000:02:00.0\r\ntotalMemory: 10.92GiB freeMemory: 10.76GiB\r\n2018-10-31 19:09:12.291317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0, 1\r\n2018-10-31 19:09:12.750668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-10-31 19:09:12.750702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 1 \r\n2018-10-31 19:09:12.750707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N Y \r\n2018-10-31 19:09:12.750710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 1:   Y N \r\n2018-10-31 19:09:12.751100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10404 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2018-10-31 19:09:12.855072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10407 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\r\n16/16 [==============================] - 3s 201ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\r\nEpoch 2/2\r\n16/16 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\r\nWARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\r\nTraceback (most recent call last):\r\n  File \"Loading_error_example.py\", line 47, in <module>\r\n    load_model(\"/home/svdvoort/test_model.hdf5\")\r\n  File \"/packages/tensorflow/1.11.0/Python-3.6.6/tensorflow/python/keras/engine/saving.py\", line 230, in load_model\r\n    model = model_from_config(model_config, custom_objects=custom_objects)\r\n  File \"/packages/tensorflow/1.11.0/Python-3.6.6/tensorflow/python/keras/engine/saving.py\", line 310, in model_from_config\r\n    return deserialize(config, custom_objects=custom_objects)\r\n  File \"/packages/tensorflow/1.11.0/Python-3.6.6/tensorflow/python/keras/layers/serialization.py\", line 64, in deserialize\r\n    printable_module_name='layer')\r\n  File \"/packages/tensorflow/1.11.0/Python-3.6.6/tensorflow/python/keras/utils/generic_utils.py\", line 173, in deserialize_keras_object\r\n    list(custom_objects.items())))\r\n  File \"/packages/tensorflow/1.11.0/Python-3.6.6/tensorflow/python/keras/engine/network.py\", line 1292, in from_config\r\n    process_layer(layer_data)\r\n  File \"/packages/tensorflow/1.11.0/Python-3.6.6/tensorflow/python/keras/engine/network.py\", line 1278, in process_layer\r\n    layer = deserialize_layer(layer_data, custom_objects=custom_objects)\r\n  File \"/packages/tensorflow/1.11.0/Python-3.6.6/tensorflow/python/keras/layers/serialization.py\", line 64, in deserialize\r\n    printable_module_name='layer')\r\n  File \"/packages/tensorflow/1.11.0/Python-3.6.6/tensorflow/python/keras/utils/generic_utils.py\", line 175, in deserialize_keras_object\r\n    return cls.from_config(config['config'])\r\n  File \"/packages/tensorflow/1.11.0/Python-3.6.6/tensorflow/python/keras/engine/base_layer.py\", line 1617, in from_config\r\n    return cls(**config)\r\n  File \"/packages/tensorflow/1.11.0/Python-3.6.6/tensorflow/python/keras/layers/advanced_activations.py\", line 310, in __init__\r\n    if max_value is not None and max_value < 0.:\r\nTypeError: '<' not supported between instances of 'dict' and 'float'\r\n```\r\nSame is true for all other models that are being trained\r\n\r\n\r\n\r\n### Source code / logs\r\nOutput of tf_env attached\r\n[tf_env.txt](https://github.com/tensorflow/models/files/2535750/tf_env.txt)\r\n\r\n", "comments": ["After some testing the problem can be resolved by replacing the model with:\r\n\r\n```\r\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, Activation\r\nfrom tensorflow.keras.models import Model\r\n\r\ndef cnn_model(rows, cols, channels):\r\n    model = Model()\r\n    inputs = Input(shape=(rows, cols, channels), dtype='float32')\r\n\r\n    conv1 = Conv2D(64, (3, 3),activation='linear',kernel_initializer='he_uniform')(inputs)\r\n    relu1 = Activation('relu')(conv1)\r\n    pooling1 = MaxPooling2D(pool_size=(5, 5))(relu1)\r\n\r\n    flatten = Flatten()(pooling1)\r\n\r\n    dense1 = Dense(512)(flatten)\r\n\r\n    relu2 = Activation('relu')(dense1)\r\n    flatten = Flatten()(conv1)\r\n    predictions = Dense(4, activation='softmax')(flatten)\r\n\r\n    model = Model(inputs=inputs, outputs=predictions)\r\n\r\n    return model\r\n```\r\n\r\nBut it seems strange that replacing that replacing the ReLU solves the issue (and the error is quite unclear). ", "@fchollet  -  PTAL", "Hi all,\r\nI am experiencing the same problem.\r\nHowever, simply replacing `layers.RelU()` with `layers.Activation(\"relu\")` does not yield the same training result in my case. Of course, I checked if I randomized the data in a non-deterministic way, but in all usages of randomization I explicitely set the seed to the same value.\r\nIs there a systematic difference between `ReLU` and `Activation(\"relu\")` which I fail to see?\r\n\r\nThanks for your help!", "I was able to execute your code snippet successfully using TF 1.13.0-rc0 Thanks!"]}, {"number": 23412, "title": "Unable to import tensorflow  after successful installation ", "body": ">>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\cmwas\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\cmwas\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\cmwas\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\cmwas\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\cmwas\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\cmwas\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 22, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\cmwas\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\cmwas\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\cmwas\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\cmwas\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\cmwas\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\cmwas\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\cmwas\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "comments": ["> (base) C:\\Users\\cmwas\\Documents>python\r\nPython 3.6.2 |Anaconda custom (64-bit)| (default, Sep 19 2017, 08:03:39) [MSC v.1900 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\cmwas\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\cmwas\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\cmwas\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\cmwas\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\cmwas\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\cmwas\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 22, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\cmwas\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\cmwas\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\cmwas\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\cmwas\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\cmwas\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\cmwas\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\cmwas\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "It looks like you haven't used a template to create this issue. Please resubmit your issue using a template from [here](https://github.com/tensorflow/tensorflow/issues/new/choose). We ask users to use the template because it reduces overall time to resolve a new issue by avoiding extra communication to get to the root of the issue. We will close this issue in lieu of the new one you will create from the template. Thank you for your cooperation.\r\n"]}, {"number": 23411, "title": "Couldn't find field google.protobuf.FileOptions.javanano_use_deprecated_package\"", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubunto 16.04\r\n\r\n- TensorFlow version: 1.4.0\r\n- Python version:2.7.1\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):\r\n\r\n\r\n\r\nwhenever i run a command such as : python pythonFile.py\r\ni got this error : \r\nTraceback (most recent call last):\r\n  File \"111.py\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"/home/lenovo/.local/lib/python2.7/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"/home/lenovo/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 54, in <module>\r\n    from tensorflow.core.framework.graph_pb2 import *\r\n  File \"/home/lenovo/.local/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py\", line 10, in <module>\r\n    from google.protobuf import descriptor_pb2\r\n  File \"/home/lenovo/.local/lib/python2.7/site-packages/google/protobuf/descriptor_pb2.py\", line 964, in <module>\r\n    options=None),\r\n  File \"/home/lenovo/.local/lib/python2.7/site-packages/google/protobuf/descriptor.py\", line 505, in __new__\r\n    return _message.default_pool.FindFieldByName(full_name)\r\nKeyError: \"Couldn't find field google.protobuf.FileOptions.javanano_use_deprecated_package\"\r\n\r\n\r\ni tried all solutions such as uninstalling and installing protobuf==3.5.0.post1  , but nothing helped , any ideas ?\r\n", "comments": ["I see that you are using very old version of TensorFlow. Can you please upgrade to the latest version of TensorFlow and build again?", "Is this still an issue for you?\r\n", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 23410, "title": "UnboundLocalError: local variable 'a' referenced before assignment", "body": "hi there, i have install phyton 3.7 with the following build : v1.11.0-rc2-4-gc19e29306c 1.11.0\r\n\r\nhere the phyton sample code: \r\n\r\nkeras_file = \"keras_model.h5\"\r\ntf.keras.models.save_model(model, keras_file)\r\n\r\n# Convert to TensorFlow Lite model.\r\nconverter = tf.contrib.lite.TocoConverter.from_keras_model_file(keras_file)\r\ntflite_model = converter.convert()\r\nopen(\"converted_model.tflite\", \"wb\").write(tflite_model)\r\n\r\nwhen it try to execute : converter = tf.contrib.lite.TocoConverter.from_keras_model_file(keras_file)\r\n\r\nand throw the following error:\r\n\r\nconverter = tf.contrib.lite.TocoConverter.from_keras_model_file(keras_file)\r\n  File \"/Users/htan/venv/lib/python3.7/site-packages/tensorflow/contrib/lite/python/lite.py\", line 354, in from_keras_model_file\r\n    _keras.backend.clear_session()\r\n  File \"/Users/htan/venv/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\", line 335, in clear_session\r\n    False, shape=(), name='keras_learning_phase')\r\n  File \"/Users/htan/venv/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 5148, in placeholder_with_default\r\n    \"PlaceholderWithDefault\", input=input, shape=shape, name=name)\r\n  File \"/Users/htan/venv/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 510, in _apply_op_helper\r\n    preferred_dtype=default_dtype)\r\n  File \"/Users/htan/venv/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1144, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/Users/htan/venv/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 228, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n  File \"/Users/htan/venv/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 207, in constant\r\n    value, dtype=dtype, shape=shape, verify_shape=verify_shape))\r\n  File \"/Users/htan/venv/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py\", line 542, in make_tensor_proto\r\n    append_fn(tensor_proto, proto_values)\r\n  File \"tensorflow/python/framework/fast_tensor_util.pyx\", line 134, in tensorflow.python.framework.fast_tensor_util.AppendBoolArrayToTensorProto\r\n  File \"/Users/htan/venv/lib/python3.7/site-packages/numpy/lib/type_check.py\", line 489, in asscalar\r\n    return a.item()\r\nUnboundLocalError: local variable 'a' referenced before assignment", "comments": ["I get the same error on OSX with v1.12.0 but if I run it via docker it does not have the error. I also avoid the error by not doing a dropout.\r\nCauses error:\r\n```python\r\nmodel = Sequential()\r\nmodel.add(Dense(500, input_shape = (TRAIN_SIZE, )))\r\nmodel.add(Activation('relu'))\r\nmodel.add(Dropout(0.25))\r\nmodel.add(Dense(250))\r\n```\r\nCompiles without error:\r\n```python\r\nmodel = Sequential()\r\nmodel.add(Dense(500, input_shape = (TRAIN_SIZE, )))\r\nmodel.add(Activation('relu'))\r\n#model.add(Dropout(0.25))\r\nmodel.add(Dense(250))\r\n```", "I'd like to chime in that I've also been getting this error since upgrading to Python 3.7 (from Python 3.6) on OSX, unrelated to Keras. Replacing the call to `tf.placeholder_with_default` with `tf.placeholder` has fixed it for me.\r\n\r\nUpdate: https://github.com/tensorflow/tensorflow/issues/23410#issuecomment-447679999", "I keep getting this error too, but while running object detection training using model_main.py. I also get a very similar error when training using legacy/train.py. Here is my error:\r\n\r\nTraceback (most recent call last):\r\n  File \"object_detection/model_main.py\", line 109, in <module>\r\n    tf.app.run()\r\n  File \"/Users/Kirthika/Documents/gitroot/MODvenv/lib/python3.7/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"object_detection/model_main.py\", line 105, in main\r\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\r\n  File \"/Users/Kirthika/Documents/gitroot/MODvenv/lib/python3.7/site-packages/tensorflow/python/estimator/training.py\", line 471, in train_and_evaluate\r\n    return executor.run()\r\n  File \"/Users/Kirthika/Documents/gitroot/MODvenv/lib/python3.7/site-packages/tensorflow/python/estimator/training.py\", line 610, in run\r\n    return self.run_local()\r\n  File \"/Users/Kirthika/Documents/gitroot/MODvenv/lib/python3.7/site-packages/tensorflow/python/estimator/training.py\", line 711, in run_local\r\n    saving_listeners=saving_listeners)\r\n  File \"/Users/Kirthika/Documents/gitroot/MODvenv/lib/python3.7/site-packages/tensorflow/python/estimator/estimator.py\", line 354, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/Users/Kirthika/Documents/gitroot/MODvenv/lib/python3.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1207, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"/Users/Kirthika/Documents/gitroot/MODvenv/lib/python3.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1234, in _train_model_default\r\n    input_fn, model_fn_lib.ModeKeys.TRAIN))\r\n  File \"/Users/Kirthika/Documents/gitroot/MODvenv/lib/python3.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1075, in _get_features_and_labels_from_input_fn\r\n    self._call_input_fn(input_fn, mode))\r\n  File \"/Users/Kirthika/Documents/gitroot/MODvenv/lib/python3.7/site-packages/tensorflow/python/estimator/estimator.py\", line 1162, in _call_input_fn\r\n    return input_fn(**kwargs)\r\n  File \"/Users/Kirthika/Documents/gitroot/Libraries-ObjectDetection/models/research/object_detection/inputs.py\", line 479, in _train_input_fn\r\n    batch_size=params['batch_size'] if params else train_config.batch_size)\r\n  File \"/Users/Kirthika/Documents/gitroot/Libraries-ObjectDetection/models/research/object_detection/builders/dataset_builder.py\", line 134, in build\r\n    config.input_path[:], input_reader_config)\r\n  File \"/Users/Kirthika/Documents/gitroot/Libraries-ObjectDetection/models/research/object_detection/builders/dataset_builder.py\", line 80, in read_dataset\r\n    sloppy=config.shuffle))\r\n  File \"/Users/Kirthika/Documents/gitroot/MODvenv/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1190, in apply\r\n    dataset = transformation_func(self)\r\n  File \"/Users/Kirthika/Documents/gitroot/MODvenv/lib/python3.7/site-packages/tensorflow/python/data/experimental/ops/interleave_ops.py\", line 87, in _apply_fn\r\n    buffer_output_elements, prefetch_input_elements)\r\n  File \"/Users/Kirthika/Documents/gitroot/MODvenv/lib/python3.7/site-packages/tensorflow/python/data/ops/readers.py\", line 136, in __init__\r\n    sloppy, dtype=dtypes.bool, name=\"sloppy\")\r\n  File \"/Users/Kirthika/Documents/gitroot/MODvenv/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1050, in convert_to_tensor\r\n    as_ref=False)\r\n  File \"/Users/Kirthika/Documents/gitroot/MODvenv/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1146, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/Users/Kirthika/Documents/gitroot/MODvenv/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 229, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n  File \"/Users/Kirthika/Documents/gitroot/MODvenv/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 208, in constant\r\n    value, dtype=dtype, shape=shape, verify_shape=verify_shape))\r\n  File \"/Users/Kirthika/Documents/gitroot/MODvenv/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py\", line 542, in make_tensor_proto\r\n    append_fn(tensor_proto, proto_values)\r\n  File \"tensorflow/python/framework/fast_tensor_util.pyx\", line 134, in tensorflow.python.framework.fast_tensor_util.AppendBoolArrayToTensorProto\r\n  File \"/Users/Kirthika/Documents/gitroot/MODvenv/lib/python3.7/site-packages/numpy/lib/type_check.py\", line 489, in asscalar\r\n    return a.item()\r\nUnboundLocalError: local variable 'a' referenced before assignment\r\n\r\nI haven't been able to solve it and any recommendations are welcome. \r\n\r\n", "I'm also getting this error on OSX with TF 1.12 and Python 3.7 anytime I use the a seemingly random set of Keras layers.\r\n\r\nSeems to throw the error when using Keras' `Dropout` and `BatchNormalization` layers for me.", "Facing similar issue on Mac-10.12.6, python-3.7\r\n----\r\nPartial stack-trace\r\n  File \"/Users/pbodigut/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 217, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n  File \"/Users/pbodigut/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 196, in constant\r\n    value, dtype=dtype, shape=shape, verify_shape=verify_shape))\r\n  File \"/Users/pbodigut/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py\", line 536, in make_tensor_proto\r\n    append_fn(tensor_proto, proto_values)\r\n  File \"tensorflow/python/framework/fast_tensor_util.pyx\", line 127, in tensorflow.python.framework.fast_tensor_util.AppendBoolArrayToTensorProto\r\n  File \"/Users/pbodigut/anaconda3/lib/python3.7/site-packages/numpy/lib/type_check.py\", line 489, in asscalar\r\n    return a.item()", "Any updates on this? I am facing the same issue.", "Uninstalling Python 3.7 and installing Python 3.6 fixed it for me.", "> I'd like to chime in that I've also been getting this error since upgrading to Python 3.7 (from Python 3.6) on OSX, unrelated to Keras. Replacing the call to `tf.placeholder_with_default` with `tf.placeholder` has fixed it for me.\r\n\r\nFollowing up on this, I've noticed that the bug is caused anytime I try to create a tf.variable or tf.placeholder of type `tf.bool`. Hope this helps in fixing this issue.", "MacOs and Python 3.7 gives the same error when running `python census_main.py` to train the official [wide and deep model](https://github.com/tensorflow/models/tree/master/official/wide_deep).", "> I'd like to chime in that I've also been getting this error since upgrading to Python 3.7 (from Python 3.6) on OSX, unrelated to Keras. Replacing the call to `tf.placeholder_with_default` with `tf.placeholder` has fixed it for me.\r\n\r\nany chance you could expand on this? I tried changing the call to PlaceholderWithDefault in gen_array_ops.py line 5334 but it just triggered another error.", "Same problem here", "> > I'd like to chime in that I've also been getting this error since upgrading to Python 3.7 (from Python 3.6) on OSX, unrelated to Keras. Replacing the call to `tf.placeholder_with_default` with `tf.placeholder` has fixed it for me.\r\n> \r\n> any chance you could expand on this? I tried changing the call to PlaceholderWithDefault in gen_array_ops.py line 5334 but it just triggered another error.\r\n\r\nThe bug had nothing to do with the placeholders, it occurs whenever I try to create anything of type `tf.bool`. Changing `tf.placeholder_with_default` to `tf.placeholder` had fixed the bug for me because the default value was a `tf.bool` :)\r\n\r\nSee update here: https://github.com/tensorflow/tensorflow/issues/23410#issuecomment-447679999", "@theeheng You might want to change the labels (if you can) as this issue seems to be unrelated to Keras and directly related to booleans.\r\n\r\nHere's some minimal examples to get the error:\r\n\r\n```python\r\nimport tensorflow as tf\r\ntf.Variable(True)\r\n```\r\n\r\n```python\r\nimport tensorflow as tf\r\ntf.get_variable('test_bool', 1, tf.bool)\r\n```", "---------------------------------------------------------------------------\r\nUnboundLocalError                         Traceback (most recent call last)\r\n<ipython-input-54-3ac8632ef42a> in <module>\r\n      6     training_targets=training_targets,\r\n      7     validation_examples=validation_examples,\r\n----> 8     validation_targets=validation_targets)\r\n\r\n<ipython-input-53-a1aff9531558> in train_linear_classifier_model(learning_rate, steps, batch_size, training_examples, training_targets, validation_examples, validation_targets)\r\n     42         linear_classifier.train(\r\n     43             input_fn=training_input_fn,\r\n---> 44             steps=steps_per_period\r\n     45         )\r\n     46         # Take a break and compute predictions.\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)\r\n    352 \r\n    353       saving_listeners = _check_listeners_type(saving_listeners)\r\n--> 354       loss = self._train_model(input_fn, hooks, saving_listeners)\r\n    355       logging.info('Loss for final step: %s.', loss)\r\n    356       return self\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)\r\n   1205       return self._train_model_distributed(input_fn, hooks, saving_listeners)\r\n   1206     else:\r\n-> 1207       return self._train_model_default(input_fn, hooks, saving_listeners)\r\n   1208 \r\n   1209   def _train_model_default(self, input_fn, hooks, saving_listeners):\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/estimator/estimator.py in _train_model_default(self, input_fn, hooks, saving_listeners)\r\n   1232       features, labels, input_hooks = (\r\n   1233           self._get_features_and_labels_from_input_fn(\r\n-> 1234               input_fn, model_fn_lib.ModeKeys.TRAIN))\r\n   1235       worker_hooks.extend(input_hooks)\r\n   1236       estimator_spec = self._call_model_fn(\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/estimator/estimator.py in _get_features_and_labels_from_input_fn(self, input_fn, mode)\r\n   1073     \"\"\"Extracts the `features` and labels from return values of `input_fn`.\"\"\"\r\n   1074     return estimator_util.parse_input_fn_result(\r\n-> 1075         self._call_input_fn(input_fn, mode))\r\n   1076 \r\n   1077   def _extract_batch_length(self, preds_evaluated):\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/estimator/estimator.py in _call_input_fn(self, input_fn, mode)\r\n   1160       kwargs['config'] = self.config\r\n   1161     with ops.device('/cpu:0'):\r\n-> 1162       return input_fn(**kwargs)\r\n   1163 \r\n   1164   def _call_model_fn(self, features, labels, mode, config):\r\n\r\n<ipython-input-53-a1aff9531558> in <lambda>()\r\n     22     training_input_fn = lambda: my_input_fn(training_examples, \r\n     23                                           training_targets[\"Survived\"],\r\n---> 24                                           batch_size=batch_size)\r\n     25     predict_training_input_fn = lambda: my_input_fn(training_examples, \r\n     26                                                   training_targets[\"Survived\"],\r\n\r\n<ipython-input-49-7697e01877f6> in my_input_fn(features, targets, batch_size, shuffle, num_epochs)\r\n     17    # Construct a dataset, and configure batching/repeating.\r\n     18    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\r\n---> 19    ds = ds.batch(batch_size).repeat(num_epochs)\r\n     20 \r\n     21    # Shuffle the data, if specified.\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py in batch(self, batch_size, drop_remainder)\r\n    885       Dataset: A `Dataset`.\r\n    886     \"\"\"\r\n--> 887     return BatchDataset(self, batch_size, drop_remainder)\r\n    888 \r\n    889   def padded_batch(self,\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py in __init__(self, input_dataset, batch_size, drop_remainder)\r\n   2349         batch_size, dtype=dtypes.int64, name=\"batch_size\")\r\n   2350     self._drop_remainder = ops.convert_to_tensor(\r\n-> 2351         drop_remainder, dtype=dtypes.bool, name=\"drop_remainder\")\r\n   2352 \r\n   2353   def _as_variant_tensor(self):\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, preferred_dtype)\r\n   1048       name=name,\r\n   1049       preferred_dtype=preferred_dtype,\r\n-> 1050       as_ref=False)\r\n   1051 \r\n   1052 \r\n\r\n/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx)\r\n   1144 \r\n   1145     if ret is None:\r\n-> 1146       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n   1147 \r\n   1148     if ret is NotImplemented:\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)\r\n    227                                          as_ref=False):\r\n    228   _ = as_ref\r\n--> 229   return constant(v, dtype=dtype, name=name)\r\n    230 \r\n    231 \r\n\r\n/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py in constant(value, dtype, shape, name, verify_shape)\r\n    206   tensor_value.tensor.CopyFrom(\r\n    207       tensor_util.make_tensor_proto(\r\n--> 208           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\r\n    209   dtype_value = attr_value_pb2.AttrValue(type=tensor_value.tensor.dtype)\r\n    210   const_tensor = g.create_op(\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py in make_tensor_proto(values, dtype, shape, verify_shape)\r\n    540     raise TypeError(\r\n    541         \"Element type not supported in TensorProto: %s\" % numpy_dtype.name)\r\n--> 542   append_fn(tensor_proto, proto_values)\r\n    543 \r\n    544   return tensor_proto\r\n\r\ntensorflow/python/framework/fast_tensor_util.pyx in tensorflow.python.framework.fast_tensor_util.AppendBoolArrayToTensorProto()\r\n\r\n/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/lib/type_check.py in asscalar(***failed resolving arguments***)\r\n    487 \r\n    488     \"\"\"\r\n--> 489     return a.item()\r\n    490 \r\n    491 #-----------------------------------------------------------------------------\r\n\r\nUnboundLocalError: local variable 'a' referenced before assignment\r\n\r\n\r\n\u200b\r\nThis is my error. Need help to resolve....", "Same problem here! I'm using virtualenv with MacOS. Minimal example from @msmsajjadi gives me the error!", "Problem solved for me using Python 2.7 and the nightly build from https://pypi.org/project/tf-nightly/", "> Problem solved for me using Python 2.7 and the nightly build from https://pypi.org/project/tf-nightly/\r\n\r\nThanks.Also solved with python3.7.", "I am using python3.7 as well, and get the same error. Any luck resolving without switching to 2.7 or 3.6?", "> I am using python3.7 as well, and get the same error. Any luck resolving without switching to 2.7 or 3.6?\r\nhttps://pypi.org/project/tf-nightly/#files\uff08CPU\uff09\r\nhttps://pypi.org/project/tf-nightly-gpu/#files\uff08GPU\uff09\r\nThis GPU version needs CUDA10.", "use nightly build that solved for me\r\n`pip install tf-nightly`", "`Traceback (most recent call last):\r\n  File \"/Users/wuming/CodeRepo/TSPADSystem/model/sequence_model/lstm_model.py\", line 129, in <module>\r\n    model.build_model()\r\n  File \"/Users/wuming/CodeRepo/TSPADSystem/model/sequence_model/lstm_model.py\", line 47, in build_model\r\n    model.add(keras.layers.Dropout(self.drop_rate))\r\n  File \"/Users/wuming/tools/virtual/py3ts/lib/python3.7/site-packages/tensorflow/python/training/checkpointable/base.py\", line 474, in _method_wrapper\r\n    method(self, *args, **kwargs)\r\n  File \"/Users/wuming/tools/virtual/py3ts/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py\", line 175, in add\r\n    output_tensor = layer(self.outputs[0])\r\n  File \"/Users/wuming/tools/virtual/py3ts/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 757, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"/Users/wuming/tools/virtual/py3ts/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py\", line 139, in call\r\n    training = K.learning_phase()\r\n  File \"/Users/wuming/tools/virtual/py3ts/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\", line 387, in learning_phase\r\n    False, shape=(), name='keras_learning_phase')\r\n  File \"/Users/wuming/tools/virtual/py3ts/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 5334, in placeholder_with_default\r\n    \"PlaceholderWithDefault\", input=input, shape=shape, name=name)\r\n  File \"/Users/wuming/tools/virtual/py3ts/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 510, in _apply_op_helper\r\n    preferred_dtype=default_dtype)\r\n  File \"/Users/wuming/tools/virtual/py3ts/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1146, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/Users/wuming/tools/virtual/py3ts/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 229, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n  File \"/Users/wuming/tools/virtual/py3ts/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 208, in constant\r\n    value, dtype=dtype, shape=shape, verify_shape=verify_shape))\r\n  File \"/Users/wuming/tools/virtual/py3ts/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py\", line 542, in make_tensor_proto\r\n    append_fn(tensor_proto, proto_values)\r\n  File \"tensorflow/python/framework/fast_tensor_util.pyx\", line 134, in tensorflow.python.framework.fast_tensor_util.AppendBoolArrayToTensorProto\r\n  File \"/Users/wuming/tools/virtual/py3ts/lib/python3.7/site-packages/numpy/lib/type_check.py\", line 489, in asscalar\r\n    return a.item()\r\nUnboundLocalError: local variable 'a' referenced before assignment`\r\n\r\nhow to fix it ?", "> Here's some minimal examples to get the error:\r\n> \r\n> ```python\r\n> import tensorflow as tf\r\n> tf.Variable(True)\r\n> ```\r\n> \r\n> ```python\r\n> import tensorflow as tf\r\n> tf.get_variable('test_bool', 1, tf.bool)\r\n> ```\r\n\r\nI can confirm that both examples above now work without errors on the latest TensorFlow pip package v1.13.0rc1.", "i have the same issue with a fresh install of everything (keras / tensorflow...) but via RStudio. any idea how to solve this in R?", "> I am using python3.7 as well, and get the same error. Any luck resolving without switching to 2.7 or 3.6?\r\n\r\nEven Im using python 3.7, can you try installing pip install tf-nightly, because it solved my problem", "> use nightly build that solved for me\r\n> `pip install tf-nightly`\r\n\r\nThank you. This works for me.", "> i have the same issue with a fresh install of everything (keras / tensorflow...) but via RStudio. any idea how to solve this in R?\r\n\r\n@ChristelSwift: I was able to get this working by reinstalling the `r-tensorflow` env. using `install_tensorflow(version = \"nightly\")`. `keras` points to `r-tensorflow` so it won't work if your nightly build environment is named anything but that.", "Same issue here, going to python 3.7 on OSX, using conda-forge built tensorflow 1.13.1, gives the same error.\r\n\r\nIs there any timeline on when there will be a release that solves this in a production-ready fashion? I know beggars cant be choosers, but this hiccup in going to python 3.7 comes at a bad time, so a fix would be much appreciated. If the nightly takes care of it, it seems pushing out a patch release should be in the cards, no?\r\n\r\nThanks!", "Same issue here running on python 3.7. Many of the recommendations above didn't work for due to a **constraint** on the tensorflow version (1.5.0) on the backend of Keras in my case. \r\n\r\nUltimately, I reverted back to Python 3.6.8 using [pyenv](https://github.com/pyenv/pyenv#homebrew-on-macos). that did the trick", "This issue still exists on Python 3.7.x and TensorFlow v1.13.1 running on macOS.", "> > i have the same issue with a fresh install of everything (keras / tensorflow...) but via RStudio. any idea how to solve this in R?\r\n> \r\n> @ChristelSwift: I was able to get this working by reinstalling the `r-tensorflow` env. using `install_tensorflow(version = \"nightly\")`. `keras` points to `r-tensorflow` so it won't work if your nightly build environment is named anything but that.\r\n\r\nThanks, this solved it for me in R with macOS 10.14.4.", "I am using \r\nwindows 7 \r\nAnaconda 2019.0.7 and Python 3.7.3\r\ntensorflow 1.15.0-dev20190718\r\nkeras 2.2.4\r\nerror still exist but now it is a different variable\r\nUnboundLocalError: local variable 'arith_flex' referenced before assignment", "Hello again, I think i solve my problem whenever upgrade c++ runtime version or install msvc_runtime\u201114.21.27702\u2011cp3x\u2011cp3xm\u2011win_amd64.whl (in my case x==7)\r\npython enviroment broken. Continue with c++ runtime version 19.15\r\nThere is might be a conflict between c++ runtime and tensorflow compiled versions.\r\nI am using tensorflow 2.0.0b1 and cuda 10.0\r\ncuda 10.1 is not working.", "Any update on this?  Getting  the same error  on mac with python 3.7.\r\nwhile using import pandas as pd\r\nError:\r\nUnboundLocalError: local variable 'arith_flex' referenced before assignment", "This issue is fixed with recent TF versions (1.14). Thanks!\r\n@vasulakkaraju Can you please post a new issue to discuss your problem? Thanks!"]}, {"number": 23409, "title": "[INTEL MKL] clean up code in mkl_concat_ops.cc file", "body": "Remove the code block under #ifdef INTEL_MKL_ML_ONLY condition, because INTEL_MKL_ML_ONLY was defeatured.", "comments": []}, {"number": 23408, "title": "Fix concat optimization infinite loop", "body": "This is a fix for the issue identified in https://github.com/tensorflow/tensorflow/issues/23383", "comments": ["@skye  -  PTAL", "@ezhulenev are you the right person to review this?", "Yes, I'll take a look later today or tomorrow", "> Yes, I'll take a look later today or tomorrow\r\n\r\nThank you !", "@drasmuss  Please address the failures. Thanks !", "I fixed the one formatting error that I could see.  The other failures don't give any indication as to the cause (I can't see the build log), but I rebased this branch onto the latest `master` as well, in case that helps.", "@ezhulenev  Request you to take a look and approve this PR. Thanks !", "Nagging Reviewer @ezhulenev, @rmlarsen: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 74 days with no activity and the `awaiting review` label has been applied.", "@ezhulenev Could you please review and approve this PR? Thanks !"]}, {"number": 23407, "title": "Tensorflow eager version fails, while Tensorflow static graph works", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Archlinux\r\n- TensorFlow installed from (source or binary): repository\r\n- TensorFlow version (use command below): 1.11\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: cuda 10, cudnn 7\r\n- GPU model and memory: nvidia 1080ti\r\n\r\n**Describe the current behavior**\r\n\r\nI'm porting a ML model ( https://github.com/samet-akcay/ganomaly ) implemented in pytorch to tensorflow (using the keras layers, knowing that tf 2.0 will come soon).\r\n\r\nThe first implementation was using the eager version to do the train, but the model collapses, nothing works.\r\n\r\nThe same model definition has been reused but it has been used to first define a static graph and then train the model: it works perfectly.\r\n\r\n**Describe the expected behavior**\r\n\r\nThe static graph version and the eager version should have the same behavior.\r\n\r\n**Code to reproduce the issue**\r\n\r\n### Model description (same for both eager and static)\r\n\r\n```python\r\nfrom typing import Dict\r\nimport tensorflow as tf\r\nimport tensorflow.keras as k\r\nimport numpy as np\r\n\r\nconv_initializer = k.initializers.random_normal(0.0, 0.02)\r\nbatchnorm_inizializer = k.initializers.random_normal(1.0, 0.02)\r\n\r\neps = 1e-5\r\nmomentum = 0.99\r\n\r\n\r\nclass Decoder(k.models.Model):\r\n    \"\"\"\r\n    Decoder (Generator) Network\r\n    \"\"\"\r\n\r\n    def __init__(self, output_depth: int = 1):\r\n        super(Decoder, self).__init__()\r\n\r\n        self.conv1 = k.layers.Conv2DTranspose(\r\n            filters=256,\r\n            kernel_size=(4, 4),\r\n            strides=(1, 1),\r\n            kernel_initializer=conv_initializer,\r\n            input_shape=(-1, 1, 1, 100),\r\n            use_bias=False,\r\n        )\r\n        self.batchnorm1 = k.layers.BatchNormalization(\r\n            epsilon=eps,\r\n            momentum=momentum,\r\n            beta_initializer=batchnorm_inizializer,\r\n            gamma_initializer=batchnorm_inizializer,\r\n        )\r\n\r\n        self.conv2 = k.layers.Conv2DTranspose(\r\n            filters=128,\r\n            kernel_size=(4, 4),\r\n            strides=(2, 2),\r\n            padding=\"same\",\r\n            kernel_initializer=conv_initializer,\r\n            use_bias=False,\r\n        )\r\n        self.batchnorm2 = k.layers.BatchNormalization(\r\n            epsilon=eps,\r\n            momentum=momentum,\r\n            beta_initializer=batchnorm_inizializer,\r\n            gamma_initializer=batchnorm_inizializer,\r\n        )\r\n\r\n        self.conv3 = k.layers.Conv2DTranspose(\r\n            filters=64,\r\n            kernel_size=(4, 4),\r\n            strides=(2, 2),\r\n            padding=\"same\",\r\n            kernel_initializer=conv_initializer,\r\n            use_bias=False,\r\n        )\r\n        self.batchnorm3 = k.layers.BatchNormalization(\r\n            epsilon=eps,\r\n            momentum=momentum,\r\n            beta_initializer=batchnorm_inizializer,\r\n            gamma_initializer=batchnorm_inizializer,\r\n        )\r\n\r\n        self.conv4 = k.layers.Conv2DTranspose(\r\n            filters=output_depth,\r\n            kernel_size=(4, 4),\r\n            strides=(2, 2),\r\n            padding=\"same\",\r\n            kernel_initializer=conv_initializer,\r\n            use_bias=False,\r\n        )\r\n\r\n    def call(self, x, training=True):\r\n        # print(\"X.SHAPE: \", x.shape)\r\n\r\n        x = self.conv1(x)\r\n        x = self.batchnorm1(x, training=training)\r\n        x = tf.nn.relu(x)\r\n\r\n        x = self.conv2(x)\r\n        x = self.batchnorm2(x, training=training)\r\n        x = tf.nn.relu(x)\r\n\r\n        x = self.conv3(x)\r\n        x = self.batchnorm3(x, training=training)\r\n        x = tf.nn.relu(x)\r\n\r\n        x = self.conv4(x)\r\n        x = tf.nn.tanh(x)  # image\r\n\r\n        # print(\"Decoder call output size: \", x.shape)\r\n\r\n        return x\r\n\r\n\r\nclass Encoder(k.models.Model):\r\n\r\n    def __init__(self, latent_dimensions: int = 100):\r\n        super(Encoder, self).__init__()\r\n\r\n        self.conv0 = k.layers.Conv2D(\r\n            filters=64,\r\n            kernel_size=(4, 4),\r\n            strides=(2, 2),\r\n            padding=\"same\",\r\n            kernel_initializer=conv_initializer,\r\n            input_shape=(-1, 32, 32, 1),\r\n            use_bias=False,\r\n        )\r\n\r\n        self.conv1 = k.layers.Conv2D(\r\n            filters=128,\r\n            kernel_size=(4, 4),\r\n            strides=(2, 2),\r\n            padding=\"same\",\r\n            kernel_initializer=conv_initializer,\r\n            use_bias=False,\r\n        )\r\n        self.batchnorm1 = k.layers.BatchNormalization(\r\n            epsilon=eps,\r\n            momentum=momentum,\r\n            beta_initializer=batchnorm_inizializer,\r\n            gamma_initializer=batchnorm_inizializer,\r\n        )\r\n\r\n        self.conv2 = k.layers.Conv2D(\r\n            filters=256,\r\n            kernel_size=(4, 4),\r\n            strides=(2, 2),\r\n            padding=\"same\",\r\n            kernel_initializer=conv_initializer,\r\n            use_bias=False,\r\n        )\r\n        self.batchnorm2 = k.layers.BatchNormalization(\r\n            epsilon=eps,\r\n            momentum=momentum,\r\n            beta_initializer=batchnorm_inizializer,\r\n            gamma_initializer=batchnorm_inizializer,\r\n        )\r\n\r\n        self.conv3 = k.layers.Conv2D(\r\n            filters=latent_dimensions,\r\n            kernel_size=(4, 4),\r\n            strides=(1, 1),\r\n            padding=\"valid\",\r\n            kernel_initializer=conv_initializer,\r\n            use_bias=False,\r\n        )\r\n\r\n    def call(self, x, training=True):\r\n        # x = self.conv0(x, input_shape=x.shape[1:])\r\n\r\n        x = self.conv0(x)\r\n        x = tf.nn.leaky_relu(x)\r\n\r\n        x = self.conv1(x)\r\n        x = self.batchnorm1(x, training=training)\r\n        x = tf.nn.leaky_relu(x)\r\n\r\n        x = self.conv2(x)\r\n        x = self.batchnorm2(x, training=training)\r\n        x = tf.nn.leaky_relu(x)\r\n\r\n        x = self.conv3(x)\r\n        # x = tf.nn.tanh(x)       # latent space unitary sphere [-1,1] TODO: temporary?\r\n\r\n        # print(\"Encoder call output size: \", x.shape)\r\n\r\n        return x\r\n\r\n\r\nclass Discriminator(k.models.Model):\r\n\r\n    def __init__(self):\r\n        super(Discriminator, self).__init__()\r\n\r\n        self.conv0 = k.layers.Conv2D(\r\n            filters=64,\r\n            kernel_size=(4, 4),\r\n            strides=(2, 2),\r\n            padding=\"same\",\r\n            kernel_initializer=conv_initializer,\r\n            use_bias=False,\r\n        )\r\n\r\n        self.conv1 = k.layers.Conv2D(\r\n            filters=128,\r\n            kernel_size=(4, 4),\r\n            strides=(2, 2),\r\n            padding=\"same\",\r\n            kernel_initializer=conv_initializer,\r\n            use_bias=False,\r\n        )\r\n        self.batchnorm1 = k.layers.BatchNormalization(\r\n            epsilon=eps,\r\n            momentum=momentum,\r\n            beta_initializer=batchnorm_inizializer,\r\n            gamma_initializer=batchnorm_inizializer,\r\n        )\r\n\r\n        self.conv2 = k.layers.Conv2D(\r\n            filters=256,\r\n            kernel_size=(4, 4),\r\n            strides=(2, 2),\r\n            padding=\"same\",\r\n            kernel_initializer=conv_initializer,\r\n            use_bias=False,\r\n        )\r\n        self.batchnorm2 = k.layers.BatchNormalization(\r\n            epsilon=eps,\r\n            momentum=momentum,\r\n            beta_initializer=batchnorm_inizializer,\r\n            gamma_initializer=batchnorm_inizializer,\r\n        )\r\n\r\n        self.conv3 = k.layers.Conv2D(\r\n            filters=1,\r\n            kernel_size=(4, 4),\r\n            strides=(1, 1),\r\n            padding=\"valid\",\r\n            kernel_initializer=conv_initializer,\r\n            use_bias=False,\r\n        )\r\n\r\n    def call(self, x, training=True):\r\n        x = self.conv0(x)\r\n        x = tf.nn.leaky_relu(x)\r\n\r\n        x = self.conv1(x)\r\n        x = self.batchnorm1(x, training=training)\r\n        x = tf.nn.leaky_relu(x)\r\n\r\n        x = self.conv2(x)\r\n        x = self.batchnorm2(x, training=training)\r\n        x = tf.nn.leaky_relu(x)\r\n\r\n        x = self.conv3(x)\r\n\r\n        return x\r\n```\r\n\r\nAlso, the following variable definitions are shared in both the eager and static implementations\r\n\r\n```python\r\n            global_step = tf.train.get_or_create_global_step()\r\n            generator_optimizer = tf.train.AdamOptimizer(2e-4, 0.5)\r\n            discriminator_optimizer = tf.train.AdamOptimizer(2e-4, 0.5)\r\n            discirminator = Discriminator()\r\n            g_encoder = Encoder()\r\n            g_decoder = Decoder()\r\n            encoder = Encoder()\r\n```\r\n\r\n### Eager training\r\n\r\nI show just a single training update, that's run in a training loop\r\n```python\r\n            # Discriminator training\r\n            with tf.GradientTape() as tape:\r\n\r\n                discriminator.trainable = True\r\n                disc_x = tf.squeeze(discriminator(x, training=False), axis=[1, 2])\r\n\r\n                disc_real_loss = tf.losses.sigmoid_cross_entropy(  # discriminator loss on result disc_x\r\n                    multi_class_labels=tf.ones_like(disc_x), logits=disc_x\r\n                )\r\n                g_encoder.trainable = False\r\n                g_decoder.trainable = False\r\n                # recreate the data (=> x_hat), starting from real data x\r\n                z = g_encoder(x, training=True)  # Not training\r\n                x_hat = g_decoder(z, training=True)  # Not training\r\n\r\n                disc_x_hat = tf.squeeze(discriminator(x_hat, training=False), axis=[1, 2])\r\n                disc_gen_loss = tf.losses.sigmoid_cross_entropy(  # discriminator loss on result disc_x_hat\r\n                    multi_class_labels=tf.zeros_like(disc_x_hat), logits=disc_x_hat\r\n                )\r\n                disc_loss = disc_real_loss + disc_gen_loss\r\n\r\n            discriminator_gradients = tape.gradient(\r\n                disc_loss, discriminator.trainable_variables\r\n            )\r\n\r\n            discriminator_optimizer.apply_gradients(\r\n                zip(discriminator_gradients, discriminator.trainable_variables)\r\n            )\r\n\r\n            # Generator Training\r\n            with tf.GradientTape() as tape:\r\n\r\n                # err_g_bce\r\n                g_encoder.trainable = True\r\n                g_decoder.trainable = True\r\n                encoder.trainable = True\r\n                z = g_encoder(x, training=True)\r\n                x_hat = g_decoder(z, training=True)\r\n                disc_x_hat = tf.squeeze(\r\n                    discriminator(x_hat, training=False), axis=[1, 2]\r\n                ) \r\n                bce_loss = tf.losses.sigmoid_cross_entropy(\r\n                    multi_class_labels=tf.ones_like(disc_x_hat),\r\n                    logits=disc_x_hat,  # G wants to generate reals so ones_like\r\n                )\r\n\r\n                l1_loss = tf.losses.absolute_difference(x, x_hat)\r\n                # err_g_enc\r\n                z_hat = encoder(x_hat, training=True)\r\n                l2_loss = tf.losses.mean_squared_error(z, z_hat)\r\n\r\n                gen_loss = 1* bce_loss + 50 * l1_loss + 1 * l2_loss\r\n                \r\n            trainable_variable_list = (\r\n                g_encoder.trainable_variables\r\n                + g_decoder.trainable_variables\r\n                + encoder.trainable_variables\r\n            )\r\n\r\n            generator_gradients = tape.gradient(gen_loss, trainable_variable_list)\r\n\r\n            generator_optimizer.apply_gradients(\r\n                zip(generator_gradients, trainable_variable_list),\r\n                global_step=global_step,\r\n            )\r\n```\r\n\r\n### Static graph training\r\nFirst I show the graph definition,then how is used in the training loop\r\n\r\n#### Graph def\r\n```python\r\n\r\n    # Discriminator on real\r\n    D_x = discriminator(x)\r\n    D_x = tf.squeeze(D_x, axis=[1, 2])\r\n\r\n    # Generate fake\r\n    z = g_encoder(x)\r\n    x_hat = g_decoder(z)\r\n\r\n    D_x_hat = discriminator(x_hat)\r\n    D_x_hat = tf.squeeze(D_x_hat, axis=[1, 2])\r\n    ## Discriminator\r\n    d_loss = tf.losses.sigmoid_cross_entropy( \r\n                    multi_class_labels=tf.ones_like(D_x), logits=D_x) + tf.losses.sigmoid_cross_entropy(\r\n                    multi_class_labels=tf.zeros_like(D_x_hat), logits=D_x_hat)\r\n\r\n    # encode x_hat to z_hat\r\n    z_hat = encoder(x_hat)\r\n\r\n    ## Generator\r\n    bce_loss = tf.losses.sigmoid_cross_entropy(tf.ones_like(D_x_hat), D_x_hat)\r\n    l1_loss = tf.losses.absolute_difference(x, x_hat)\r\n    l2_loss = tf.losses.mean_squared_error(z, z_hat)\r\n\r\n    g_loss = 1 * bce_loss + 1 * l1_loss + 1 * l2_loss\r\n    global_step = tf.train.get_or_create_global_step()\r\n\r\n    # Define the D train op\r\n    train_d = tf.train.AdamOptimizer(\r\n        lr, beta1=0.5).minimize(\r\n            d_loss, var_list=D.trainable_variables)\r\n\r\n    # train G_e G_d E\r\n    train_g = tf.train.AdamOptimizer(\r\n        lr, beta1=0.5).minimize(\r\n            g_loss,\r\n            global_step=global_step,\r\n            var_list=g_encoder.trainable_variables + g_decoder.trainable_variables +\r\n            encoder.trainable_variables)\r\n```\r\n\r\nAnd this is what's inside the training loop (executed in a MonitoredSession):\r\n\r\n```python\r\n            # extract from tf.data.Dataset, x is a placeholder and x_ is the iterator.get_next\r\n            real = sess.run(x_) \r\n            feed_dict = {x: real}\r\n\r\n            # train D\r\n            _, d_loss_value = sess.run([train_d, d_loss], feed_dict)\r\n\r\n            # train G+E\r\n            _, g_loss_value, step = sess.run([train_g, g_loss, global_step],\r\n                                             feed_dict)\r\n````\r\n\r\nThe model definition is the same, the loss definition is the same, the training steps and the same, the only difference is the eager mode enabled or disabled. The results with eager on are:\r\n\r\nD loss: collapses to zero, that's wrong since its aim is to stay around 0.5\r\n![bad d](https://user-images.githubusercontent.com/8427788/47802503-b2a31100-dd30-11e8-8d53-ef024f30879d.png)\r\n\r\nGenerated images: wrong, bad reconstructions since D collapsed\r\n![bad_gen](https://user-images.githubusercontent.com/8427788/47802519-bafb4c00-dd30-11e8-9a70-16b2c27d69b7.png)\r\n\r\nWhile when eager is off, the discriminator loss looks correct and the generated output are the one expected:\r\n\r\nD loss:\r\n![good d](https://user-images.githubusercontent.com/8427788/47802443-8e473480-dd30-11e8-8525-38ec50040a16.png)\r\n\r\nGenerated output:\r\n![good_gen](https://user-images.githubusercontent.com/8427788/47802455-930be880-dd30-11e8-85c3-efdd87311530.png)\r\n\r\n", "comments": ["@galeone - Please try with Python 3.6.", "@harshini-gadige I tried. Same exact results: D collapses in eager version, D works correctly in static graph version.\r\n\r\nFor this test:\r\n- Python 3.6.6\r\n- Tensorflow: 1.11.0\r\n\r\n", "I wonder whether it's possible to narrow this down a little. Maybe by logging a bunch f tensors to see where the differences first appear?\r\n\r\nAlso, I recommend Sequential, it'll dramatically simplify the model definition. ", "@martinwicke I  add debug operations in both versions and I'll try to spot where the difference starts.\r\nI'll update the thread as soon as I have some insight ", "The eager code you shared should also work in graph mode to produce training ops (one from the generator and one from the discriminator, which you can session.run separately). Can you do that and see if you also observe the collapse?", "@alextp can you please show me in which way should I change the code to run it in a Session?\r\nBecause I'm not used to mixing session evaluation and eager mode thus I'm not sure where to place the session creation, and when to run sess.run (if it was in static-graph mode there would be no problem)", "I meant replacing your static graph training code block with\r\n\r\n\r\n```python\r\n            # Discriminator training\r\n            x = tf.placeholder(....)\r\n            with tf.GradientTape() as tape:\r\n\r\n                discriminator.trainable = True\r\n                disc_x = tf.squeeze(discriminator(x, training=False), axis=[1, 2])\r\n\r\n                disc_real_loss = tf.losses.sigmoid_cross_entropy(  # discriminator loss on result disc_x\r\n                    multi_class_labels=tf.ones_like(disc_x), logits=disc_x\r\n                )\r\n                g_encoder.trainable = False\r\n                g_decoder.trainable = False\r\n                # recreate the data (=> x_hat), starting from real data x\r\n                z = g_encoder(x, training=True)  # Not training\r\n                x_hat = g_decoder(z, training=True)  # Not training\r\n\r\n                disc_x_hat = tf.squeeze(discriminator(x_hat, training=False), axis=[1, 2])\r\n                disc_gen_loss = tf.losses.sigmoid_cross_entropy(  # discriminator loss on result disc_x_hat\r\n                    multi_class_labels=tf.zeros_like(disc_x_hat), logits=disc_x_hat\r\n                )\r\n                disc_loss = disc_real_loss + disc_gen_loss\r\n\r\n            discriminator_gradients = tape.gradient(\r\n                disc_loss, discriminator.trainable_variables\r\n            )\r\n\r\n            d_loss = disc_loss\r\n            train_d = discriminator_optimizer.apply_gradients(\r\n                zip(discriminator_gradients, discriminator.trainable_variables)\r\n            )\r\n\r\n            # Generator Training\r\n            with tf.GradientTape() as tape:\r\n\r\n                # err_g_bce\r\n                g_encoder.trainable = True\r\n                g_decoder.trainable = True\r\n                encoder.trainable = True\r\n                z = g_encoder(x, training=True)\r\n                x_hat = g_decoder(z, training=True)\r\n                disc_x_hat = tf.squeeze(\r\n                    discriminator(x_hat, training=False), axis=[1, 2]\r\n                ) \r\n                bce_loss = tf.losses.sigmoid_cross_entropy(\r\n                    multi_class_labels=tf.ones_like(disc_x_hat),\r\n                    logits=disc_x_hat,  # G wants to generate reals so ones_like\r\n                )\r\n\r\n                l1_loss = tf.losses.absolute_difference(x, x_hat)\r\n                # err_g_enc\r\n                z_hat = encoder(x_hat, training=True)\r\n                l2_loss = tf.losses.mean_squared_error(z, z_hat)\r\n\r\n                gen_loss = 1* bce_loss + 50 * l1_loss + 1 * l2_loss\r\n                \r\n            trainable_variable_list = (\r\n                g_encoder.trainable_variables\r\n                + g_decoder.trainable_variables\r\n                + encoder.trainable_variables\r\n            )\r\n\r\n            generator_gradients = tape.gradient(gen_loss, trainable_variable_list)\r\n\r\n           g_loss = gen_loss\r\n            train_g = generator_optimizer.apply_gradients(\r\n                zip(generator_gradients, trainable_variable_list),\r\n                global_step=global_step,\r\n            )\r\n```\r\n\r\nand then running your session.run loop for training unchanged:\r\n```python\r\n            # extract from tf.data.Dataset, x is a placeholder and x_ is the iterator.get_next\r\n            real = sess.run(x_) \r\n            feed_dict = {x: real}\r\n\r\n            # train D\r\n            _, d_loss_value = sess.run([train_d, d_loss], feed_dict)\r\n\r\n            # train G+E\r\n            _, g_loss_value, step = sess.run([train_g, g_loss, global_step],\r\n                                             feed_dict)\r\n ```\r\n", "Here we go:\r\n\r\nThe discriminator does not collapse\r\n```\r\n[0] d: 1.4126055240631104 - g: 51.892757415771484\r\n[100] d: 1.4121590852737427 - g: 10.285645484924316\r\n[200] d: 1.136518955230713 - g: 8.836201667785645\r\n[300] d: 1.3435794115066528 - g: 7.9710540771484375\r\n[400] d: 1.2257683277130127 - g: 8.381233215332031\r\n[500] d: 1.3684046268463135 - g: 7.7494797706604\r\n[600] d: 1.274878740310669 - g: 8.12108039855957\r\n[700] d: 1.0551540851593018 - g: 7.315877437591553\r\n[800] d: 1.1707713603973389 - g: 6.710018634796143\r\n```\r\n\r\nand the generator works correctly\r\n![works](https://user-images.githubusercontent.com/8427788/48186136-6a3eb100-e337-11e8-9903-39201020c773.png)\r\n\r\nTherefore there's something different between in the execution in eager mode vs graph mode.\r\n\r\n\r\n\r\n", "Hi @galeone,\r\n\r\nI tried to reproduce the problems, but I'm not able to. The only changes I made were to add this loop (and print the losses).  \r\n```python\r\ndef main(_):\r\n  tf.enable_eager_execution()\r\n\r\n  (train_images, train_labels), _ = k.datasets.fashion_mnist.load_data()\r\n\r\n  train_images = train_images / 255.0\r\n  train_images = train_images.astype(np.float32)\r\n  train_images = np.expand_dims(train_images, -1)\r\n\r\n  train_dataset = tf.data.Dataset.from_tensor_slices(\r\n      (train_images, train_labels)).shuffle(10000).repeat().batch(128).map(lambda x, y: (tf.image.resize_images(x, [32, 32]), y))\r\n\r\n  global_step = tf.train.get_or_create_global_step()\r\n  generator_optimizer = tf.train.AdamOptimizer(2e-4, 0.5)\r\n  discriminator_optimizer = tf.train.AdamOptimizer(2e-4, 0.5)\r\n  discriminator = Discriminator()\r\n  g_encoder = Encoder()\r\n  g_decoder = Decoder()\r\n  encoder = Encoder()\r\n\r\n  it = iter(train_dataset)\r\n  for i in range(10000):\r\n    x, _ = it.next()\r\n    train(encoder, g_encoder, g_decoder, generator_optimizer, discriminator,\r\n          discriminator_optimizer, global_step, x)\r\n```\r\n\r\nI get after 2000 steps:\r\n```\r\nstep <tf.Variable 'global_step:0' shape=() dtype=int64, numpy=1000>, g: 4.06344842911, d: 1.27861332893                                                                                                                                                                                   \r\nstep <tf.Variable 'global_step:0' shape=() dtype=int64, numpy=2000>, g: 3.98709654808, d: 0.57758295536\r\n```\r\n\r\nNote that I tried this with/without a GPU, and on 1.11 as well as nightly and wasn't able to reproduce it. \r\n\r\nPerhaps you can paste your full code so that I can reproduce this better?", "Yes, no problem.\r\n\r\nThe models are the one posted earlier and are inside the `models/ganomaly.py` file.\r\n\r\nThe dataset definition (common to both version too) is placed inside `ops/input_fn/fashion_mnist.py`:\r\n\r\n```python\r\n\"\"\"Load Fashion MNIST Dataset.\"\"\"\r\n\r\nfrom typing import Callable, Dict, Tuple\r\n\r\nimport numpy as np\r\nimport sklearn.model_selection as sk\r\nfrom skimage.transform import resize\r\nfrom matplotlib import pyplot as plt\r\nimport tensorflow as tf\r\nimport tensorflow.keras as k\r\n\r\nDataset = Dict[str, np.ndarray]\r\nCompleteDataset = Dict[str, Dataset]\r\n\r\n\r\ndef arrays_dataset_to_generator(dataset: Dataset) -> Callable:\r\n    # DOCUMENT\r\n    def _generator():\r\n        for i in range(len(dataset[\"x\"])):\r\n            yield dataset[\"x\"][i], dataset[\"y\"][i]\r\n\r\n    return _generator\r\n\r\n\r\ndef extract_label(\r\n    features: np.ndarray, labels: np.ndarray, target_label: int\r\n) -> Tuple[Dataset, Dataset]:\r\n    \"\"\"\r\n    Extract all features whose label is ``target_labels``.\r\n\r\n    Args:\r\n        features: Dataset features\r\n        labels: Dataset labels\r\n        target_label: The label used as filter\r\n\r\n    Returns:\r\n        All the features with the ``target_labels`` as label.\r\n\r\n    \"\"\"\r\n    bool_filter = labels == target_label\r\n    normal_features = features[~bool_filter]\r\n    normal_labels = labels[~bool_filter]\r\n    anomalous_features = features[bool_filter]\r\n    anomalous_labels = labels[bool_filter]\r\n    return (\r\n        {\"x\": normal_features, \"y\": normal_labels},\r\n        {\"x\": anomalous_features, \"y\": anomalous_labels},\r\n    )\r\n\r\n\r\ndef _process_features(feature, image_size):\r\n    feature = tf.squeeze(tf.image.resize_images(tf.expand_dims(tf.expand_dims(feature, axis=2), axis=0), size=(32, 32)),\r\n                         axis=0)  # resize change to float32\r\n\r\n    # Normalize features between -1 and 1\r\n    feature = (feature * 2) - 1\r\n\r\n    return feature.numpy()\r\n\r\n\r\nclass FashionMNIST:\r\n    \"\"\"\r\n    DigitsMNIST Dataset.\r\n\r\n    Attributes:\r\n        train_datasets (Dict[str, np.ndarray]): Dictionary of features for training..\r\n            The dictionary has keys in the form of ``non_{label}`` meaning that each\r\n            key holds the 80% of the features whose labels is not ``{label}``\r\n        test_datasets (Dict[str, np.ndarray]): Dictionary of features for testing.\r\n            The dictionary has keys in the form of ``only_{label}`` meaning that each\r\n            key holds the all the features whose label is ``{label}`` and 20% of all\r\n            the other features as non-anomalies\r\n\r\n    \"\"\"\r\n\r\n    train_datasets: CompleteDataset\r\n    test_datasets: CompleteDataset\r\n\r\n    # def __init__(self, image_size: Tuple[int, int, int] = (28, 28, 1)) -> None:\r\n    def __init__(self, image_size: Tuple[int, int, int] = (32, 32, 1)) -> None:\r\n        \"\"\"\r\n        Fetch the dataset and partition it for training and testing.\r\n\r\n        Retrieve the dataset from the Keras builtin, split each class 80-20 and\r\n        using these splits build all the datasets required for training and testing.\r\n\r\n        Args:\r\n            image_size: Size of each image\r\n\r\n        Returns:\r\n            None.\r\n\r\n        \"\"\"\r\n        self.image_size = image_size\r\n        self.train_datasets = {}\r\n        self.test_datasets = {}\r\n\r\n        mnist_train_set, _ = k.datasets.fashion_mnist.load_data()\r\n        mnist_x, mnist_y = mnist_train_set\r\n\r\n        mnist_x = np.array([_process_features(x, self.image_size) for x in mnist_x])\r\n\r\n        for n in range(10):\r\n            # print(n)\r\n            normal_data, anomalous_data = extract_label(mnist_x, mnist_y, n)\r\n            n_train_x, n_test_x, n_train_y, n_test_y = sk.train_test_split(\r\n                normal_data[\"x\"], normal_data[\"y\"], test_size=0.2, random_state=42\r\n            )\r\n\r\n            # print(n_train_x.shape[0], n_test_x.shape[0], anomalous_data[\"x\"].shape[0])\r\n\r\n            self.train_datasets[f\"anomaly_{n}\"] = {\"x\": n_train_x, \"y\": n_train_y}\r\n            self.test_datasets[f\"anomaly_{n}\"] = {\r\n                \"x\": np.concatenate((n_test_x, anomalous_data[\"x\"])),\r\n                \"y\": np.concatenate((n_test_y, anomalous_data[\"y\"])),\r\n            }\r\n\r\n    def to_tf_dataset(self, arrays_dataset: Dataset, hyper: Dict) -> tf.data.Dataset:\r\n        \"\"\"\r\n        Convert ``features`` and ``labels`` into a `tf.data.Datasets``.\r\n\r\n        Args:\r\n            features: Array of features\r\n            labels: Array of labels\r\n            hyper: Dictionary of hyperparameters\r\n\r\n        Returns:\r\n            `tf.data.Dataset` of batch(image, label).\r\n\r\n        \"\"\"\r\n        generator = arrays_dataset_to_generator(arrays_dataset)\r\n        dataset = tf.data.Dataset.from_generator(generator, (tf.float32, tf.uint8))\r\n        dataset = (\r\n            dataset.shuffle(hyper[\"buffer_size\"], seed=42)\r\n            .batch(hyper[\"batch_size\"], drop_remainder=True)\r\n            .prefetch(1)\r\n        )\r\n        dataset = dataset.repeat(hyper[\"epochs\"]) if hyper.get(\"epochs\") else dataset\r\n\r\n        return dataset\r\n\r\n```\r\n\r\n## Eager version\r\n\r\nThis is the training definition: \r\n\r\n```python\r\nfrom __future__ import annotations\r\n\r\nimport os\r\nimport time\r\nfrom typing import Callable, Dict, Optional\r\n\r\nimport tensorflow as tf\r\nimport tensorflow.keras as k\r\nfrom models.ganomaly import Discriminator\r\nimport statistics as s\r\nimport copy\r\n\r\nLOGGED: Dict = {}\r\n\r\n\r\nclass GANomaly:\r\n    \"\"\"\r\n    GANomaly\r\n    \"\"\"\r\n\r\n    g_encoder: k.models.Model  # bow-tie encoder (encoder)\r\n    g_decoder: k.models.Model  # bow-tie decoder (generator)\r\n    encoder: k.models.Model  # encoder\r\n    discriminator: k.models.Model  # discriminator\r\n\r\n    generator_optimizer: tf.train.AdamOptimizer\r\n    discriminator_optimizer: tf.train.AdamOptimizer\r\n\r\n    dataset: tf.data.Dataset\r\n\r\n    checkpoint: tf.train.Checkpoint\r\n    logging_fn: Optional[Callable]\r\n\r\n    def __init__(\r\n        self,\r\n        g_encoder: k.models.Model,\r\n        g_decoder: k.models.Model,\r\n        encoder: k.models.Model,\r\n        discriminator: k.models.Model,\r\n        dataset: tf.data.Dataset,\r\n        model_dir: str,\r\n        hyper: Dict,\r\n        logging_fn: Optional[Callable] = None,\r\n    ) -> None:\r\n\r\n        # Model\r\n        self.g_encoder = g_encoder()\r\n        self.g_decoder = g_decoder()\r\n        self.encoder = encoder()\r\n        self.discriminator = discriminator()\r\n        self.hyper = hyper\r\n\r\n        # Optimizers\r\n\r\n        # this is for g_encode, g_decoder and encoder\r\n        self.global_step = tf.train.get_or_create_global_step()\r\n        self.learning_rate = self.hyper[\"learning_rate\"]\r\n\r\n        # with decay, 2 optimizer\r\n        self.generator_optimizer = tf.train.AdamOptimizer(\r\n            self.learning_rate, hyper[\"beta1\"]\r\n        )\r\n\r\n        self.discriminator_optimizer = tf.train.AdamOptimizer(\r\n            self.learning_rate, hyper[\"beta1\"]\r\n        )\r\n        # Data\r\n        self.dataset = dataset\r\n\r\n        # Checkpoints\r\n        self.checkpoint = tf.train.Checkpoint(\r\n            generator_optimizer=self.generator_optimizer,\r\n            discriminator_optimizer=self.discriminator_optimizer,\r\n            g_encoder=self.g_encoder,\r\n            g_decoder=self.g_decoder,\r\n            encoder=self.encoder,\r\n            discriminator=self.discriminator,\r\n        )\r\n\r\n        self.checkpoint_prefix = os.path.join(model_dir, \"ckpt\")\r\n        self.summary_writer = tf.contrib.summary.create_file_writer(\r\n            model_dir, flush_millis=10000\r\n        )\r\n\r\n        self.saved_model_dir = model_dir\r\n\r\n        # Logging\r\n        self.logging_fn = logging_fn\r\n\r\n    def train(  # TODO: reduce complexity\r\n        self,\r\n        steps_per_epoch: int,\r\n        batch_size: int,\r\n        noise_dims: int,\r\n        epochs: float,\r\n        checkpoint_frequency: int,\r\n        logging_enabled: bool = False,\r\n        discriminator_passes: int = 2,\r\n    ) -> None:\r\n        # global_step = tf.train.get_or_create_global_step()\r\n\r\n        # self.g_enc_dec_weights = []\r\n        epoch = 0\r\n        epoch_start = time.time()\r\n        for x, _ in self.dataset:\r\n            tf.Print(self.global_step, [self.global_step], \"GLOBAL STEP\")\r\n            if int(self.global_step.numpy()) % steps_per_epoch == 0:\r\n                tf.logging.info(\"---------------[NEW EPOCH]---------------\")\r\n                tf.logging.info(f\"Current Epoch {epoch + 1} | Total Epochs: {epochs}\")\r\n                tf.logging.info(\r\n                    f\"Step {self.global_step.numpy()} \"\r\n                    f\"| Total Steps: {steps_per_epoch * epochs}\"\r\n                )\r\n                tf.logging.info(f\"Epoch time: {time.time() - epoch_start}\")\r\n                epoch_start = time.time()\r\n                epoch += 1\r\n            step_start = time.time()\r\n\r\n            # Discriminator training\r\n            with tf.GradientTape() as tape:\r\n\r\n                self.discriminator.trainable = True\r\n                disc_x = tf.squeeze(\r\n                    self.discriminator(x, training=False), axis=[1, 2]\r\n                )  # discriminator on real data x. Training on.\r\n\r\n                # I save the weights here because here I know they are not zero\r\n                if int(self.global_step.numpy()) == 0:\r\n                    print(\"Saving weights...\")\r\n                    self.discriminator.save_weights()\r\n\r\n                disc_real_loss = tf.losses.sigmoid_cross_entropy(  # discriminator loss on result disc_x\r\n                    multi_class_labels=tf.ones_like(disc_x), logits=disc_x\r\n                )\r\n\r\n                self.g_encoder.trainable = False\r\n                self.g_decoder.trainable = False\r\n                # recreate the data (=> x_hat), starting from real data x\r\n                z = self.g_encoder(x, training=True)  # Not training\r\n                x_hat = self.g_decoder(z, training=True)  # Not training\r\n\r\n                disc_x_hat = tf.squeeze(\r\n                    self.discriminator(x_hat, training=False), axis=[1, 2]\r\n                )  # discriminator on recreated data. Training on.\r\n                disc_gen_loss = tf.losses.sigmoid_cross_entropy(  # discriminator loss on result disc_x_hat\r\n                    multi_class_labels=tf.zeros_like(disc_x_hat), logits=disc_x_hat\r\n                )\r\n                disc_loss = disc_real_loss + disc_gen_loss\r\n\r\n            discriminator_gradients = tape.gradient(\r\n                disc_loss, self.discriminator.trainable_variables\r\n            )\r\n\r\n            self.discriminator_optimizer.apply_gradients(\r\n                zip(discriminator_gradients, self.discriminator.trainable_variables)\r\n            )\r\n\r\n            # Generator Training\r\n            with tf.GradientTape() as tape:\r\n\r\n                # err_g_bce\r\n                self.g_encoder.trainable = True\r\n                self.g_decoder.trainable = True\r\n                self.encoder.trainable = True\r\n                z = self.g_encoder(x, training=True)\r\n                x_hat = self.g_decoder(z, training=True)\r\n                disc_x_hat = tf.squeeze(\r\n                    self.discriminator(x_hat, training=False), axis=[1, 2]\r\n                )  # Training false\r\n                bce_loss = tf.losses.sigmoid_cross_entropy(\r\n                    multi_class_labels=tf.ones_like(disc_x_hat),\r\n                    logits=disc_x_hat,  # G wants to generate reals so ones_like\r\n                )\r\n\r\n                # print(\"disc_x_hat.shape::::::::\", disc_x_hat.shape)\r\n\r\n                # err_g_l1l\r\n                l1_loss = tf.losses.absolute_difference(x, x_hat)\r\n\r\n                # err_g_enc\r\n                z_hat = self.encoder(x_hat, training=True)\r\n                l2_loss = tf.losses.mean_squared_error(z, z_hat)\r\n\r\n                # final generator loss\r\n                gen_loss = (\r\n                    self.hyper[\"adversarial_w\"] * bce_loss\r\n                    + self.hyper[\"contextual_w\"] * l1_loss\r\n                    + self.hyper[\"encoder_w\"] * l2_loss\r\n                )\r\n\r\n            trainable_variable_list = (\r\n                self.g_encoder.trainable_variables\r\n                + self.g_decoder.trainable_variables\r\n                + self.encoder.trainable_variables\r\n            )\r\n            generator_gradients = tape.gradient(gen_loss, trainable_variable_list)\r\n\r\n            self.generator_optimizer.apply_gradients(\r\n                zip(generator_gradients, trainable_variable_list),\r\n                global_step=self.global_step,\r\n            )\r\n\r\n            if disc_loss < 1e-4:\r\n                print(\"RESET WEIGHTS\")\r\n                self.discriminator.reset_weights()\r\n                # self.discriminator = Discriminator()\r\n\r\n            step_time_delta = time.time() - step_start\r\n\r\n            LOGGED.update(\r\n                {  # HACK: Find better way\r\n                    \"generated_data\": x_hat,\r\n                    \"real_data\": x,\r\n                    \"encoded_real\": z,\r\n                    \"gen_loss\": gen_loss,\r\n                    \"disc_loss\": disc_loss,\r\n                    \"gen_bce_loss\": bce_loss,\r\n                    \"gen_cont_loss\": l1_loss,\r\n                    \"gen_enc_loss\": l2_loss,\r\n                    \"step\": self.global_step,\r\n                    # \"learning_rate\": self.learning_rate(),\r\n                    \"learning_rate\": self.learning_rate,\r\n                }\r\n            )\r\n\r\n            # TODO: Move the logging to a separate function\r\n            # TODO: Divide Epoch-wise logging from Step-wise logging\r\n            # TODO: Add support for metrics\r\n\r\n            if logging_enabled:\r\n                if self.logging_fn:\r\n                    self.logging_fn(self.summary_writer, LOGGED)\r\n                else:\r\n                    tf.logging.error(\"Logging enabled but no logging_fn was provided.\")\r\n\r\n        tf.logging.info(\"# ############ [Training Complete] ##############\")\r\n        self.checkpoint.save(file_prefix=self.checkpoint_prefix)\r\n```\r\n\r\nAnd this is the file that runs the train:\r\n\r\n```python\r\n\"\"\"\r\nRun the model.\r\n\"\"\"\r\nfrom typing import Optional\r\n\r\nimport fire\r\nimport tensorflow as tf\r\n\r\nfrom models.anogan import AnoGAN\r\nimport GANomaly as ganomaly\r\nimport models.ganomaly as m_ganomaly\r\n\r\ntf.enable_eager_execution()\r\ntf.logging.set_verbosity(tf.logging.INFO)\r\n\r\n\r\ndef main(gan: str, mnist_type: Optional[str] = None) -> None:\r\n    \"\"\"Execute the training script.\"\"\"\r\n    print(\"main -- checking fire arguments\")\r\n    if gan.lower() == \"dummy\":\r\n        tf.logging.info(f\"Starting DummyGAN\")\r\n        from models.dummy import Generator, Discriminator, stepwise_train_logging\r\n        from ops.input_fn.dummy import DummyData\r\n\r\n        hyper = {\r\n            \"mean\": 10.0,\r\n            \"std\": 0.01,\r\n            \"points\": 10000,\r\n            \"batch_size\": 1000,\r\n            \"epochs\": 2200,\r\n            \"buffer_size\": 10000,\r\n            \"noise_dims\": 100,\r\n            \"learning_rate\": 0.0002,\r\n            \"beta1\": 0.5,\r\n        }\r\n\r\n        config = {\"checkpoint_frequency\": 500}\r\n\r\n        dataset = DummyData(hyper[\"mean\"], hyper[\"std\"], hyper[\"points\"])\r\n        train_dataset = dataset.to_tf_dataset(\r\n            dataset.train_features,\r\n            batch_size=hyper[\"batch_size\"],\r\n            buffer_size=hyper[\"buffer_size\"],\r\n            epochs=hyper[\"epochs\"],\r\n        )\r\n\r\n        dummy_gan = AnoGAN(\r\n            Generator,\r\n            Discriminator,\r\n            train_dataset,\r\n            \"logs/dummy\",\r\n            logging_fn=stepwise_train_logging,\r\n            hyper=hyper,\r\n        )\r\n\r\n        dummy_gan.train(\r\n            steps_per_epoch=int(hyper[\"points\"] / hyper[\"batch_size\"]),\r\n            batch_size=int(hyper[\"batch_size\"]),\r\n            noise_dims=int(hyper[\"noise_dims\"]),\r\n            checkpoint_frequency=int(config[\"checkpoint_frequency\"]),\r\n            logging_enabled=True,\r\n            epochs=hyper[\"epochs\"],\r\n        )\r\n\r\n    elif (gan.lower() == \"mnist\") and mnist_type is not None:\r\n        print(\"Category: MNIST\")\r\n        tf.logging.info(f\"Starting MnistGAN\")\r\n        from models.ganomaly import stepwise_train_logging\r\n        from ops.input_fn.fashion_mnist import FashionMNIST\r\n        from ops.input_fn.mnist import DigitsMNIST\r\n\r\n        config = {\"checkpoint_frequency\": 1}\r\n\r\n        # ----------------------------------- fashion mnist\r\n        if mnist_type.lower() == \"fashion\":\r\n            print(\"Sub-Category: FASHION\")\r\n\r\n            hyper = {\r\n                \"batch_size\": 64,\r\n                \"epochs\": 2000,     # 500\r\n                \"buffer_size\": 6000,\r\n                \"noise_dims\": 100,  # 128\r\n                \"dataset_length\": 6000,\r\n                \"learning_rate\": 0.0002,\r\n                \"beta1\": 0.5,\r\n                \"adversarial_w\": 1,    # 1\r\n                \"contextual_w\": 50,     # 50\r\n                \"encoder_w\": 1,        # 1\r\n            }\r\n\r\n            dataset = FashionMNIST()\r\n            n = 0\r\n            train_dataset = dataset.to_tf_dataset(\r\n                dataset.train_datasets[f\"anomaly_{n}\"],\r\n                hyper=hyper,\r\n            )\r\n\r\n            dummy_gan = ganomaly.GANomaly(\r\n                m_ganomaly.Encoder,\r\n                m_ganomaly.Decoder,\r\n                m_ganomaly.Encoder,\r\n                m_ganomaly.Discriminator,\r\n                train_dataset,\r\n                \"logs/ganomaly\",\r\n                logging_fn=stepwise_train_logging,\r\n                hyper=hyper,\r\n            )\r\n\r\n            dummy_gan.train(\r\n                steps_per_epoch=int(hyper[\"dataset_length\"] / hyper[\"batch_size\"]),\r\n                batch_size=int(hyper[\"batch_size\"]),\r\n                noise_dims=int(hyper[\"noise_dims\"]),\r\n                checkpoint_frequency=int(config[\"checkpoint_frequency\"]),\r\n                logging_enabled=True,\r\n                epochs=hyper[\"epochs\"],\r\n            )\r\n\r\nif __name__ == \"__main__\":\r\n    fire.Fire(main)\r\n```\r\n\r\n^ This version produces the D collapse.\r\n\r\nWhile inside a session, (with ops generated by the eager as @alextp told me to do or using the static graph definition as I showed in the first post) it does not.", "Hi @galeone,\r\n\r\nI'm still unable to reproduce this (the scale of the loss is different, but it doesn't seem to collapse). I am able to fix the scaling by updating the _process_features function to include as the first line:\r\n```python\r\nfeature = feature / 255.\r\n```\r\n\r\nI am also not saving/restoring discriminator weights.\r\n\r\nCould you try to replace your dataset using the dataset code I posted above, and see if it still collapses?\r\n\r\nThat might point to some environment differences which are contributing to this.\r\n\r\nThanks", "Update: The eager version with the `feature /= 255.` does not collapses, it works.\r\n\r\nBut the question is: why in my setup the missing feature scaling makes the model collapse while in yours it doesn't?", "Which Python version? Did rounding change maybe?\n", "Python 3.6 and Python 3.7 (with tensorflow compiled and packaged by the archlinux maintainers with cuda 10)", "Maybe this comes down just to random seeds? Eager and graph happen to use\nslightly different random seeds for the weights unless you explicitly pass\nseeds to the initializer ops.\n\nOn Mon, Nov 12, 2018 at 7:06 AM Paolo Galeone <notifications@github.com>\nwrote:\n\n> Python 3.6 and Python 3.7 (with tensorflow compiled and packaged by the\n> archlinux maintainers with cuda 10)\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/23407#issuecomment-437912922>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxU_GKaUUZLn8I5uFqsY664Y_CZPnks5uuY58gaJpZM4YEcrD>\n> .\n>\n\n\n-- \n - Alex\n", "It might be, but I repeated the tests several times and the behavior was always the same", "Hi @galeone,\r\n\r\nTaking a step back, I want to confirm that it is actually broken without the ```feature /= 255.``` line? \r\n\r\nThe images that were generated initially (from your screenshot in https://github.com/tensorflow/tensorflow/issues/23407#issue-376045885) seem reasonable enough (at the very least not broken/collapsed).\r\n\r\nCan you print the disc_loss out in python for the eager case as well (as I mentioned when I did this, the loss was small, but not 0.0). \r\n\r\nThanks!", "Yes, without the `feature /= 255.` line the eager code is broken.\r\n\r\nThe `disc_loss` value in eager mode, with the feature scaling, is:\r\n\r\n```\r\nD loss:  tf.Tensor(2.5863452, shape=(), dtype=float32)\r\nGLOBAL STEP[1]\r\nD loss:  tf.Tensor(3.7927284, shape=(), dtype=float32)\r\nGLOBAL STEP[2]\r\nD loss:  tf.Tensor(1.7489786, shape=(), dtype=float32)\r\nGLOBAL STEP[3]\r\nD loss:  tf.Tensor(2.4115205, shape=(), dtype=float32)\r\nGLOBAL STEP[4]\r\nD loss:  tf.Tensor(1.479794, shape=(), dtype=float32)\r\nGLOBAL STEP[5]\r\nD loss:  tf.Tensor(1.857255, shape=(), dtype=float32)\r\nGLOBAL STEP[6]\r\nD loss:  tf.Tensor(1.3435516, shape=(), dtype=float32)\r\nGLOBAL STEP[7]\r\nD loss:  tf.Tensor(1.4879988, shape=(), dtype=float32)\r\nGLOBAL STEP[8]\r\nD loss:  tf.Tensor(1.4008305, shape=(), dtype=float32)\r\nGLOBAL STEP[9]\r\nD loss:  tf.Tensor(1.3350534, shape=(), dtype=float32)\r\nGLOBAL STEP[10]\r\nD loss:  tf.Tensor(1.3525255, shape=(), dtype=float32)\r\nGLOBAL STEP[11]\r\nD loss:  tf.Tensor(1.3573906, shape=(), dtype=float32)\r\nGLOBAL STEP[12]\r\nD loss:  tf.Tensor(1.3513403, shape=(), dtype=float32)\r\nGLOBAL STEP[13]\r\nD loss:  tf.Tensor(1.3532543, shape=(), dtype=float32)\r\nGLOBAL STEP[14]\r\nD loss:  tf.Tensor(1.3461918, shape=(), dtype=float32)\r\nGLOBAL STEP[15]\r\nD loss:  tf.Tensor(1.351814, shape=(), dtype=float32)\r\nGLOBAL STEP[16]\r\nD loss:  tf.Tensor(1.3492448, shape=(), dtype=float32)\r\nGLOBAL STEP[17]\r\nD loss:  tf.Tensor(1.3633372, shape=(), dtype=float32)\r\nGLOBAL STEP[18]\r\nD loss:  tf.Tensor(1.3482394, shape=(), dtype=float32)\r\nGLOBAL STEP[19]\r\nD loss:  tf.Tensor(1.3703191, shape=(), dtype=float32)\r\nGLOBAL STEP[20]\r\nD loss:  tf.Tensor(1.3946171, shape=(), dtype=float32)\r\nGLOBAL STEP[21]\r\nD loss:  tf.Tensor(1.4548875, shape=(), dtype=float32)\r\nGLOBAL STEP[22]\r\nD loss:  tf.Tensor(1.6209935, shape=(), dtype=float32)\r\nGLOBAL STEP[23]\r\nD loss:  tf.Tensor(1.9088718, shape=(), dtype=float32)\r\nGLOBAL STEP[24]\r\nD loss:  tf.Tensor(2.0123127, shape=(), dtype=float32)\r\nGLOBAL STEP[25]\r\nD loss:  tf.Tensor(1.7655286, shape=(), dtype=float32)\r\nGLOBAL STEP[26]\r\nD loss:  tf.Tensor(1.5841687, shape=(), dtype=float32)\r\nGLOBAL STEP[27]\r\nD loss:  tf.Tensor(1.5094138, shape=(), dtype=float32)\r\nGLOBAL STEP[28]\r\nD loss:  tf.Tensor(1.4937377, shape=(), dtype=float32)\r\nGLOBAL STEP[29]\r\nD loss:  tf.Tensor(1.4909501, shape=(), dtype=float32)\r\nGLOBAL STEP[30]\r\nD loss:  tf.Tensor(1.5101626, shape=(), dtype=float32)\r\n```\r\n\r\nWhile removing the feature scaling the value becomes:\r\n\r\n```\r\nD loss:  tf.Tensor(2.5409622, shape=(), dtype=float32)\r\nGLOBAL STEP[1]\r\nD loss:  tf.Tensor(1.0496982, shape=(), dtype=float32)\r\nGLOBAL STEP[2]\r\nD loss:  tf.Tensor(0.05322905, shape=(), dtype=float32)\r\nGLOBAL STEP[3]\r\nD loss:  tf.Tensor(0.026622836, shape=(), dtype=float32)\r\nGLOBAL STEP[4]\r\nD loss:  tf.Tensor(0.00439855, shape=(), dtype=float32)\r\nGLOBAL STEP[5]\r\nD loss:  tf.Tensor(0.011926692, shape=(), dtype=float32)\r\nGLOBAL STEP[6]\r\nD loss:  tf.Tensor(0.0012371272, shape=(), dtype=float32)\r\nGLOBAL STEP[7]\r\nD loss:  tf.Tensor(0.0125416275, shape=(), dtype=float32)\r\nGLOBAL STEP[8]\r\nD loss:  tf.Tensor(0.0067688944, shape=(), dtype=float32)\r\nGLOBAL STEP[9]\r\nD loss:  tf.Tensor(0.0018801485, shape=(), dtype=float32)\r\nGLOBAL STEP[10]\r\nD loss:  tf.Tensor(0.012362722, shape=(), dtype=float32)\r\nGLOBAL STEP[11]\r\nD loss:  tf.Tensor(0.004985124, shape=(), dtype=float32)\r\nGLOBAL STEP[12]\r\nD loss:  tf.Tensor(0.001480296, shape=(), dtype=float32)\r\nGLOBAL STEP[13]\r\nD loss:  tf.Tensor(0.0015711666, shape=(), dtype=float32)\r\nGLOBAL STEP[14]\r\nD loss:  tf.Tensor(0.0035329773, shape=(), dtype=float32)\r\nGLOBAL STEP[15]\r\nD loss:  tf.Tensor(0.0061537297, shape=(), dtype=float32)\r\nGLOBAL STEP[16]\r\nD loss:  tf.Tensor(0.0015294439, shape=(), dtype=float32)\r\nGLOBAL STEP[17]\r\nD loss:  tf.Tensor(0.0018317825, shape=(), dtype=float32)\r\nGLOBAL STEP[18]\r\nD loss:  tf.Tensor(0.0015391075, shape=(), dtype=float32)\r\nGLOBAL STEP[19]\r\nD loss:  tf.Tensor(0.0017354895, shape=(), dtype=float32)\r\nGLOBAL STEP[20]\r\nD loss:  tf.Tensor(0.0014736701, shape=(), dtype=float32)\r\nGLOBAL STEP[21]\r\nD loss:  tf.Tensor(0.0015135503, shape=(), dtype=float32)\r\nGLOBAL STEP[22]\r\nD loss:  tf.Tensor(0.0013820046, shape=(), dtype=float32)\r\nGLOBAL STEP[23]\r\nD loss:  tf.Tensor(0.0013579719, shape=(), dtype=float32)\r\nGLOBAL STEP[24]\r\nD loss:  tf.Tensor(0.0020369224, shape=(), dtype=float32)\r\nGLOBAL STEP[25]\r\nD loss:  tf.Tensor(0.0014253389, shape=(), dtype=float32)\r\nGLOBAL STEP[26]\r\nD loss:  tf.Tensor(0.0012767054, shape=(), dtype=float32)\r\nGLOBAL STEP[27]\r\nD loss:  tf.Tensor(0.001459129, shape=(), dtype=float32)\r\nGLOBAL STEP[28]\r\nD loss:  tf.Tensor(0.0017556315, shape=(), dtype=float32)\r\nGLOBAL STEP[29]\r\nD loss:  tf.Tensor(0.007157793, shape=(), dtype=float32)\r\nGLOBAL STEP[30]\r\nD loss:  tf.Tensor(0.011590726, shape=(), dtype=float32)\r\n```", "Ah, so the loss is similar for me with/without scaling (which at the very least means we are on the same page with regards to reproducibility :). The loss is small, but I'd expect 0.0s or NaNs if the model had collapsed, so I was saying that this hadn't collapsed.\r\n\r\nIs it possible that the datasets and preprocessing steps are different between graph and eager? If so, can you try the graph version with an identical dataset?", "But the model collapses since if I let the training run for more steps, it collapses to 0.0.\r\n\r\nYes, it is possible the input datasets are different. But, when I tried to put inside a session the ops generated by the eager mode, the dataset was the same and the behavior was different (graph generated by the eager mode executed inside a session, and eager training - both with the same input).\r\n\r\nThis is the strangest part. ", "Update: maybe https://github.com/tensorflow/tensorflow/issues/23882 is related", "Indeed, this could be the case.\n\nOn Wed, Nov 21, 2018 at 10:41 AM Paolo Galeone <notifications@github.com>\nwrote:\n\n> Update: maybe #23882\n> <https://github.com/tensorflow/tensorflow/issues/23882> is related\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/23407#issuecomment-440768781>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxfGlJwn0r_NCybbAFpLM4Vicdr1Aks5uxZ4-gaJpZM4YEcrD>\n> .\n>\n\n\n-- \n - Alex\n", "Nagging Assignee @alextp: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I think the RNG is probably the source, so I'll close this. Please reopen if there's evidence otherwise.", "FYI, we are addressing this problem by a comprehensive revamp in RFC tensorflow/community#38. Please comment on that."]}, {"number": 23406, "title": "TPUEstimator cant save checkpoint at google colab", "body": "Error recorded from training_loop: File system scheme '[local]' not implemented (file: '/tmp/tmpu0amtet8/model.ckpt-0_temp_b2eedcafbb1e42d1949c6e0ec2f85501')\r\n\t [[node save/SaveV2 (defined at /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py:2403)  = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=\"/job:worker/replica:0/task:0/device:CPU:0\"](save/ShardedFilename, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, ReadVariables_2242190548333892376/_1:2, ReadVariables_2242190548333892376/_1, ReadVariables_2242190548333892376/_1:1, ReadVariables_2242190548333892376/_1:5, ReadVariables_2242190548333892376/_1:3, ReadVariables_2242190548333892376/_1:4, ReadVariables_2242190548333892376/_1:8, ReadVariables_2242190548333892376/_1:6, ReadVariables_2242190548333892376/_1:7, ReadVariables_2242190548333892376/_1:11, ReadVariables_2242190548333892376/_1:9, ReadVariables_2242190548333892376/_1:10, ReadVariables_2242190548333892376/_1:14, ReadVariables_2242190548333892376/_1:12, ReadVariables_2242190548333892376/_1:13, ReadVariables_2242190548333892376/_1:17, ReadVariables_2242190548333892376/_1:15, ReadVariables_2242190548333892376/_1:16, ReadVariables_2242190548333892376/_1:20, ReadVariables_2242190548333892376/_1:18, ReadVariables_2242190548333892376/_1:19, ReadVariables_2242190548333892376/_1:23, ReadVariables_2242190548333892376/_1:21, ReadVariables_2242190548333892376/_1:22, ReadVariables_2242190548333892376/_1:26, ReadVariables_2242190548333892376/_1:24, ReadVariables_2242190548333892376/_1:25, ReadVariables_2242190548333892376/_1:29, ReadVariables_2242190548333892376/_1:27, ReadVariables_2242190548333892376/_1:28, ReadVariables_2242190548333892376/_1:32, ReadVariables_2242190548333892376/_1:30, ReadVariables_2242190548333892376/_1:31, ReadVariables_2242190548333892376/_1:35, ReadVariables_2242190548333892376/_1:33, ReadVariables_2242190548333892376/_1:34, ReadVariables_2242190548333892376/_1:38, ReadVariables_2242190548333892376/_1:36, ReadVariables_2242190548333892376/_1:37, ReadVariables_2242190548333892376/_1:41, ReadVariables_2242190548333892376/_1:39, ReadVariables_2242190548333892376/_1:40, ReadVariables_2242190548333892376/_1:44, ReadVariables_2242190548333892376/_1:42, ReadVariables_2242190548333892376/_1:43, ReadVariables_2242190548333892376/_1:47, ReadVariables_2242190548333892376/_1:45, ReadVariables_2242190548333892376/_1:46, ReadVariables_2242190548333892376/_1:50, ReadVariables_2242190548333892376/_1:48, ReadVariables_2242190548333892376/_1:49, ReadVariables_2242190548333892376/_1:53, ReadVariables_2242190548333892376/_1:51, ReadVariables_2242190548333892376/_1:52, ReadVariables_2242190548333892376/_1:56, ReadVariables_2242190548333892376/_1:54, ReadVariables_2242190548333892376/_1:55, ReadVariables_2242190548333892376/_1:59, ReadVariables_2242190548333892376/_1:57, ReadVariables_2242190548333892376/_1:58, ReadVariables_2242190548333892376/_1:62, ReadVariables_2242190548333892376/_1:60, ReadVariables_2242190548333892376/_1:61, ReadVariables_2242190548333892376/_1:65, ReadVariables_2242190548333892376/_1:63, ReadVariables_2242190548333892376/_1:64, ReadVariables_2242190548333892376/_1:68, ReadVariables_2242190548333892376/_1:66, ReadVariables_2242190548333892376/_1:67, ReadVariables_2242190548333892376/_1:71, ReadVariables_2242190548333892376/_1:69, ReadVariables_2242190548333892376/_1:70, ReadVariables_2242190548333892376/_1:74, ReadVariables_2242190548333892376/_1:72, ReadVariables_2242190548333892376/_1:73, ReadVariables_2242190548333892376/_1:77, ReadVariables_2242190548333892376/_1:75, ReadVariables_2242190548333892376/_1:76, ReadVariables_2242190548333892376/_1:80, ReadVariables_2242190548333892376/_1:78, ReadVariables_2242190548333892376/_1:79, ReadVariables_2242190548333892376/_1:83, ReadVariables_2242190548333892376/_1:81, ReadVariables_2242190548333892376/_1:82, ReadVariables_2242190548333892376/_1:86, ReadVariables_2242190548333892376/_1:84, ReadVariables_2242190548333892376/_1:85, ReadVariables_2242190548333892376/_1:89, ReadVariables_2242190548333892376/_1:87, ReadVariables_2242190548333892376/_1:88, ReadVariables_2242190548333892376/_1:92, ReadVariables_2242190548333892376/_1:90, ReadVariables_2242190548333892376/_1:91, ReadVariables_2242190548333892376/_1:95, ReadVariables_2242190548333892376/_1:93, ReadVariables_2242190548333892376/_1:94, ReadVariables_2242190548333892376/_1:98, ReadVariables_2242190548333892376/_1:96, ReadVariables_2242190548333892376/_1:97, ReadVariables_2242190548333892376/_1:101, ReadVariables_2242190548333892376/_1:99, ReadVariables_2242190548333892376/_1:100, ReadVariables_2242190548333892376/_1:104, ReadVariables_2242190548333892376/_1:102, ReadVariables_2242190548333892376/_1:103, ReadVariables_2242190548333892376/_1:107, ReadVariables_2242190548333892376/_1:105, ReadVariables_2242190548333892376/_1:106, ReadVariables_2242190548333892376/_1:110, ReadVariables_2242190548333892376/_1:108, ReadVariables_2242190548333892376/_1:109, ReadVariables_2242190548333892376/_1:113, ReadVariables_2242190548333892376/_1:111, ReadVariables_2242190548333892376/_1:112, ReadVariables_2242190548333892376/_1:116, ReadVariables_2242190548333892376/_1:114, ReadVariables_2242190548333892376/_1:115, ReadVariables_2242190548333892376/_1:119, ReadVariables_2242190548333892376/_1:117, ReadVariables_2242190548333892376/_1:118, ReadVariables_2242190548333892376/_1:122, ReadVariables_2242190548333892376/_1:120, ReadVariables_2242190548333892376/_1:121, ReadVariables_2242190548333892376/_1:125, ReadVariables_2242190548333892376/_1:123, ReadVariables_2242190548333892376/_1:124, ReadVariables_2242190548333892376/_1:126, ReadVariables_2242190548333892376/_1:127, ReadVariables_2242190548333892376/_1:128, ReadVariables_2242190548333892376/_1:129, ReadVariables_2242190548333892376/_1:130)]]\r\n\r\nCaused by op 'save/SaveV2', defined at:\r\n\r\nWhole code:\r\nhttps://colab.research.google.com/drive/101FjBAIMVuXyNyeUvq_Vfx-Z6CR3g4df?authuser=1#scrollTo=Sh3TpyAI8Oln\r\n\r\nMay be i do wrong something", "comments": ["It looks like you haven't used a template to create this issue. Please resubmit your issue using a template from [here](https://github.com/tensorflow/tensorflow/issues/new/choose). We ask users to use the template because it reduces overall time to resolve a new issue by avoiding extra communication to get to the root of the issue. Thank you for your cooperation.\r\n", "@harshini-gadige \r\nI used Issue: Other Issues template couz i can't say it performance, installation, documentation or feature request.", "@jhseu   PTAL", "You can't save checkpoints locally, but if you have permissions, you can save them through Google Cloud Storage.", "Ok, it doesn't work and problem not in mine code, but isn't it should be fixed?\r\n\r\nI want to use colab and tpu.\r\nDocs advise to use TPU estimator. But it doesnt work in colab.\r\n\r\nCan I at least disable autosaving? I have not found such an option in docs.", "If you set the save_checkpoint options to None, it should disable saving:\r\nhttps://www.tensorflow.org/api_docs/python/tf/contrib/tpu/RunConfig#save_checkpoints_secs", "Thanks", "@jhseu \r\nThis thing doesnt seems right for me, did I understand correctly that it loads, and then immediately saves? Can I fix this, so it save only at the end of work?\r\n\r\nINFO:tensorflow:Restoring parameters from gs://nero_test_tacotron2/model.ckpt-5000\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nINFO:tensorflow:Saving checkpoints for 5000 into gs://nero_test_tacotron2/model.ckpt."]}, {"number": 23405, "title": "build with default cuda options fails with \"/bin/bash: CUDA_TOOLKIT_PATH: unbound variable\"", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 16.04.5  x86_64\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): master branch from 10/31/18 - \r\n- Python version:\r\n- Bazel version (if compiling from source): 0.18.0\r\n- GCC/Compiler version (if compiling from source): 5.4.0 20160609\r\n- CUDA/cuDNN version: 9.0/7\r\n- GPU model and memory: 2x Tesla P100 16 GB\r\n\r\n**Describe the current behavior**\r\nConfiguring TF to build with CUDA support and choosing all the default option for all the other questions in ./configure including the default for NCCL \"Please specify the locally installed NCCL version you want to use. [Default is to use https://github.com/nvidia/nccl]:\", the build fails with \"/bin/bash: CUDA_TOOLKIT_PATH: unbound variable\"\r\n\r\nThis has been broken since this commit:\r\nhttps://github.com/tensorflow/tensorflow/commit/fc6cd33c334f88759ce637e29e1586733076e094\r\n\r\nRunning in the docker container: nvidia/cuda:9.0-cudnn7-devel (for ease of setup)\r\nexport TF_NEED_CUDA=1\r\n\"\" | ./configure\r\nbazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n\r\nfailed with:\r\nERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/nccl_archive/BUILD.bazel:139:1: Executing genrule @nccl_archive//:device_code_fatbin_h failed (Exit 1)\r\n/bin/bash: CUDA_TOOLKIT_PATH: unbound variable\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 267.057s, Critical Path: 93.66s\r\nINFO: 3606 processes: 3606 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\n\r\n**Describe the expected behavior**\r\nBuild should succeed. \r\n\r\n**Code to reproduce the issue**\r\nexport TF_NEED_CUDA=1\r\n\"\" | ./configure\r\nbazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n\r\n**Other info / logs**\r\nFails on both x86 and ppc64le, tried with both bazel 0.15.0 and 0.18.0\r\n", "comments": ["\u6211\u4e5f\u9047\u5230\u4e86\u540c\u6837\u7684\u95ee\u9898\uff0c\u611f\u89c9 bazel \u5c31\u662f\u4e00\u4e2a\u9e21\u808b", "@wdirons  -  Hi, this should not be an issue with GCC 4.8 and Bazel 0.15.0 combination. Please try.", "Just tried on a ppc64le redhat container with gcc 4.8.5 and bazel 0.15.0 (cuda10) and the results are the same: \r\n\r\n```\r\n[builder@203325a6deb2 ~]$ bazel version\r\nExtracting Bazel installation...\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nBuild label: 0.15.0- (@non-git)\r\nBuild target: bazel-out/ppc-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Thu Oct 25 03:43:57 2018 (1540439037)\r\nBuild timestamp: 1540439037\r\nBuild timestamp as int: 1540439037\r\n\r\n[builder@203325a6deb2 ~]$ gcc --version\r\ngcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-28)\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n[builder@203325a6deb2 tensorflow]$ bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n.\r\n.\r\n.\r\nERROR: /home/builder/.cache/bazel/_bazel_builder/3ae15484c762cfa61bbd3dade07b5cf3/external/nccl_archive/BUILD.bazel:139:1: Executing genrule @nccl_archive//:device_code_fatbin_h failed (Exit 1)\r\n/bin/bash: CUDA_TOOLKIT_PATH: unbound variable\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 262.728s, Critical Path: 156.49s\r\nINFO: 4641 processes: 4641 local.\r\nFAILED: Build did NOT complete successfully\r\n```", "@gunan  -  PTAL", "I'm seeing the same while building against CUDA 10.\r\nOS - Ubuntu 18.04.1/x86_64\r\nCUDA/cuDNN - 10.0.130/7.3.1\r\nbazel - bazel-0.18.1\r\nGCC - gcc (Ubuntu 7.3.0-27ubuntu1~18.04) 7.3.0\r\nCUDA_HOME=/opt/cuda-10.0\r\nCUDA_TOOLKIT_PATH=/opt/cuda-10.0\r\n\r\n```\r\n$ bazel version  \r\nWARNING: Processed legacy workspace file /scratch/opt/tensorflow-1.12.0/src/tensorflow/tools/bazel.rc. This file will not be processed in the next release of Bazel. Please read https://github.com/bazelbuild/bazel/issues/6319 for further information, including how to upgrade.\r\nWARNING: Output base 'homes/fultz/.cache/bazel/_bazel_fultz/a3796d4ff5cfe6f876d63615ff95821d' is on NFS. This may lead to surprising failures and undetermined behavior.\r\nBuild label: 0.18.1\r\nBuild target: bazel-out/k8-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Wed Oct 31 14:46:05 2018 (1540997165)\r\nBuild timestamp: 1540997165\r\nBuild timestamp as int: 1540997165\r\n\r\n$ CUDA_TOOLKIT_PATH=/opt/cuda-10.0 bazel build --config=noaws --config=nogcp --config=nohdfs --config=noignite --config=nokafka //tensorflow/tools/pip_packa\r\nge:build_pip_package\r\n...\r\nERROR: /homes/fultz/.cache/bazel/_bazel_fultz/a3796d4ff5cfe6f876d63615ff95821d/external/nccl_archive/BUILD.bazel:139:1: Executing genrule @nccl_archive//:device_code_fatbin_h failed (Exit 1)\r\n/bin/bash: CUDA_TOOLKIT_PATH: unbound variable\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 41.210s, Critical Path: 26.82s\r\nINFO: 277 processes: 277 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n", "This commit appears to fix the problem: https://github.com/tensorflow/tensorflow/commit/456e6927c0c0ff6b497b07875c0043cb59086414\r\n\r\nI'm verifying with a build now."]}, {"number": 23404, "title": "TFLite Android: My lite Model file does not loaded", "body": "I'm having a problem with loading a lite model to the using the android tensorflow lite Interpreter.\r\nI am trying to use the workflow of  Tensorflow-for-poets-2 TFLite tutorial, [https://codelabs.developers.google.com/codelabs/tensorflow-for-poets-2-tflite/#6](url)\r\n\r\ninstead of using the function:\r\n```\r\nprivate MappedByteBuffer loadModelFile(Activity activity,String MODEL_FILE) throws IOException {\r\n    AssetFileDescriptor fileDescriptor = activity.getAssets().openFd(MODEL_FILE);\r\n    FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor());\r\n    FileChannel fileChannel = inputStream.getChannel();\r\n    long startOffset = fileDescriptor.getStartOffset();\r\n    long declaredLength = fileDescriptor.getDeclaredLength();\r\n    return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength);\r\n```\r\nin order to load my model, I use: \r\n\r\n```\r\nAssetFileDescriptor fileDescriptor = null;\r\ntry {\r\nfileDescriptor = getAssets().openFd(MODEL_PATH);\r\n} catch (IOException e) {\r\ne.printStackTrace();\r\n }\r\nFileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor());\r\nFileChannel fileChannel = inputStream.getChannel();\r\nlong startOffset = fileDescriptor.getStartOffset();\r\nlong declaredLength = fileDescriptor.getDeclaredLength();\r\ntry {\r\nMByteBuffer = fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength);\r\n} catch (IOException e) {\r\ne.printStackTrace();\r\n}\r\n\r\n```\r\nthen, I use the tflite Interpreter by calling:\r\n`tflite = new Interpreter(MByteBuffer);`\r\n\r\nUsing this snippet of an android code, I am able to laod the .lite graph that i got following the Tensorflow-for-poets-2 TFLite tutorial, [https://codelabs.developers.google.com/codelabs/tensorflow-for-poets-2-tflite/#6](url)\r\n\r\nBut when i try to load my .lite model I got the following error:\r\n\r\n`A/libc: Fatal signal 6 (SIGABRT), code -6 (SI_TKILL) in tid 9320 (flitecamerademo), pid 9320 (flitecamerademo)`\r\n\r\nI want to notify that my model works (preforms a style transfer). I test it using python API, in the following way:\r\n\r\n```\r\ntflite_graph_filename = 'debug_graph.lite' # this is my model\r\n# Load TFLite model and allocate tensors.\r\ninterpreter = tf.contrib.lite.Interpreter(model_path=tflite_graph_filename)\r\ninterpreter.allocate_tensors()\r\n\r\n# Get input and output tensors.\r\ninput_details = interpreter.get_input_details()\r\nprint('input_details: \\n{}\\n'.format(input_details))\r\noutput_details = interpreter.get_output_details()\r\nprint('output_details: \\n{}\\n'.format(output_details))\r\n\r\n# Test model on random input data.\r\ninput_shape = input_details[0]['shape']\r\nprint('input_shape: \\n{}\\n'.format(input_shape))\r\n\r\nX = np.zeros(input_shape,np.float32)\r\nX[0] = content_image\r\n\r\ninput_data = X # np.array(np.random.random_sample(input_shape), dtype=np.float32)\r\ninterpreter.set_tensor(input_details[0]['index'], input_data)\r\n\r\ninterpreter.invoke()\r\noutput_data = interpreter.get_tensor(output_details[0]['index'])\r\n\r\n```\r\nThe above test is working so I assume my model is successfully converted to .lite format.\r\n\r\nuse the following command to toco convert:\r\n\r\n`toco --graph_def_file=/fullpathto/debug_graph.pb  --output_file=/fullpathto/debug_graph.lite --input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE --input_shape=1,474,712,3 --input_array=img_placeholder --output_array=transform/up-sample/mul --inference_type=FLOAT   --input_data_type=FLOAT`\r\n\r\nCan you please help me with ideas on how to solve such problem or how can I debug this?\r\n\r\nThanks,\r\nVadim\r\n\r\n", "comments": ["> But when i try to load my .lite model I got the following error:\r\n> A/libc: Fatal signal 6 (SIGABRT), code -6 (SI_TKILL) in tid 9320 (flitecamerademo), pid 9320 (flitecamerademo)\r\n\r\nIs there nothing else in the logcat? Perhaps an exception being thrown or a more descriptive error?\r\n\r\n", "It has been 44 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 23403, "title": "tf.MonitoredSession accessing raw session raw_session like in SingularMonitoredSession", "body": "**System information**\r\n- TensorFlow version (you are using): 1.11.0\r\n- Are you willing to contribute it (Yes/No): yes\r\n\r\n**Will this change the current api? How?**\r\nnot substantially\r\n\r\n**Who will benefit with this feature?**\r\nPotentially everybody using a MonitoredTrainingSession\r\n\r\n**Any Other info.**\r\nNone\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nI am using tf.MonitoredSession, it happens sometimes that you want to evaluate some nodes but you don't want to proceed in the training step, so you do not want to use the Hooks to log stuffs. It seems that the session is wrapped several times and the raw session is stored in a nested way: https://github.com/tensorflow/tensorflow/issues/8425 but it can also be retrieved with method _tf_sess() https://github.com/tensorflow/tensorflow/issues/11971\r\n\r\nTo recap I think there are two possible ways to run without hooks (to the best of my knowledge):\r\n\r\n1. use step_fn https://www.tensorflow.org/api_docs/python/tf/train/MonitoredSession#run_step_fn\r\n2. access the raw session with raw_session = sess._tf_sess()\r\n\r\nI think way 2. is the more intuitive for me if I want to be free from the hooks, but is it proper practice are there some problems in doing this? I wonder why is it private and it is not contemplated to have a method to access the raw session like in SingularMonitoredSession.raw_session()? https://www.tensorflow.org/api_docs/python/tf/train/SingularMonitoredSession \r\n\r\nAt line 1010 in https://github.com/tensorflow/tensorflow/blob/r1.11/tensorflow/python/training/monitored_session.py I can see that raw_session is defined exactly returning self._tf_sess(), so I wonder why the explicit choice to not have the user the possibility to access the raw session in MonitoredSession, is it possible to incur in some problems using sess._tf_sess()? I wonder if it has something to do with some problems in the distributed setting..\r\n\r\nSummarizing: Would it be possible to have a method to access the raw session in MonitoredSession, are there some counter-indications with this kind of procedure?\r\n(accessing the raw session with sess._tf_sess() )\r\n\r\n", "comments": ["It's by design MonitoredSession prevents access to raw_session. It re-creates raw_session time to time in case of specific exceptions.\r\nplease consider using `MonitoredSession.run_step_fn` for your use case.", "Nagging Assignee @karmel: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Closing, as @ispirmustafa provided the preferred method of access."]}, {"number": 23402, "title": "Failure to build TF 1.12 from source - multiple definitions in grpc", "body": "**System information**\r\n- Linux Ubuntu 16.04\r\n- TensorFlow installed from source\r\n- TensorFlow version: 1.12\r\n- Python version: 2.7\r\n- Bazel version (if compiling from source): 0.19\r\n- GCC/Compiler version (if compiling from source): 5.4.0\r\n\r\n**Describe the problem**\r\nI've cloned tensorflow and checked out 1.12 branch\r\nI've run configure and then build as instructed in the \"build from source\" page at TF website.\r\nI've configured using all the default options and disabled XLA.\r\nAt the end of the build I get the following error:\r\n\r\nsrc/main/tools/linux-sandbox.cc:204: child exited normally with exitcode 0\r\nERROR: /home/ogabbay/trees/tensorflow/tensorflow/python/BUILD:3865:1: Linking of rule '//tensorflow/python:_pywrap_tensorflow_internal.so' failed (Exit 1) linux-sandbox failed: error executing command \r\n  (cd /home/ogabbay/.cache/bazel/_bazel_ogabbay/336c59c3c10f4f0f593d30a996172c97/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/home/ogabbay/builds/latest \\\r\n    PATH=/home/ogabbay/bin:/home/ogabbay/.local/bin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/snap/bin:/usr/local/installs/SW/eclipse/oxygen-M2/:/usr/lib/jvm/java-8-oracle/bin:/usr/lib/jvm/java-8-oracle/db/bin:/usr/lib/jvm/java-8-oracle/jre/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    TMPDIR=/tmp \\\r\n  /home/ogabbay/.cache/bazel/_bazel_ogabbay/336c59c3c10f4f0f593d30a996172c97/execroot/org_tensorflow/_bin/linux-sandbox -t 15 -w /home/ogabbay/.cache/bazel/_bazel_ogabbay/336c59c3c10f4f0f593d30a996172c97/sandbox/linux-sandbox/1889/execroot/org_tensorflow -w /tmp -w /dev/shm -D -- /usr/bin/gcc -shared -o bazel-out/host/bin/tensorflow/python/_pywrap_tensorflow_internal.so -Wl,--version-script bazel-out/host/bin/tensorflow/python/pywrap_tensorflow_internal_versionscript.lds '-Wl,-rpath,$ORIGIN/,-rpath,$ORIGIN/..' -Wl,-soname,_pywrap_tensorflow_internal.so -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread '-fuse-ld=gold' -Wl,-no-as-needed -Wl,-z,relro,-z,now -B/usr/bin -B/usr/bin -pass-exit-codes -Wl,--gc-sections -Wl,-S -Wl,@bazel-out/host/bin/tensorflow/python/_pywrap_tensorflow_internal.so-2.params): linux-sandbox failed: error executing command \r\n  (cd /home/ogabbay/.cache/bazel/_bazel_ogabbay/336c59c3c10f4f0f593d30a996172c97/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/home/ogabbay/builds/latest \\\r\n    PATH=/home/ogabbay/bin:/home/ogabbay/.local/bin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/snap/bin:/usr/local/installs/SW/eclipse/oxygen-M2/:/usr/lib/jvm/java-8-oracle/bin:/usr/lib/jvm/java-8-oracle/db/bin:/usr/lib/jvm/java-8-oracle/jre/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    TMPDIR=/tmp \\\r\n  /home/ogabbay/.cache/bazel/_bazel_ogabbay/336c59c3c10f4f0f593d30a996172c97/execroot/org_tensorflow/_bin/linux-sandbox -t 15 -w /home/ogabbay/.cache/bazel/_bazel_ogabbay/336c59c3c10f4f0f593d30a996172c97/sandbox/linux-sandbox/1889/execroot/org_tensorflow -w /tmp -w /dev/shm -D -- /usr/bin/gcc -shared -o bazel-out/host/bin/tensorflow/python/_pywrap_tensorflow_internal.so -Wl,--version-script bazel-out/host/bin/tensorflow/python/pywrap_tensorflow_internal_versionscript.lds '-Wl,-rpath,$ORIGIN/,-rpath,$ORIGIN/..' -Wl,-soname,_pywrap_tensorflow_internal.so -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread '-fuse-ld=gold' -Wl,-no-as-needed -Wl,-z,relro,-z,now -B/usr/bin -B/usr/bin -pass-exit-codes -Wl,--gc-sections -Wl,-S -Wl,@bazel-out/host/bin/tensorflow/python/_pywrap_tensorflow_internal.so-2.params)\r\nsrc/main/tools/linux-sandbox.cc:154: linux-sandbox-pid1 has PID 26733\r\nsrc/main/tools/linux-sandbox-pid1.cc:175: working dir: /home/ogabbay/.cache/bazel/_bazel_ogabbay/336c59c3c10f4f0f593d30a996172c97/sandbox/linux-sandbox/1889/execroot/org_tensorflow\r\nsrc/main/tools/linux-sandbox-pid1.cc:194: writable: /home/ogabbay/.cache/bazel/_bazel_ogabbay/336c59c3c10f4f0f593d30a996172c97/sandbox/linux-sandbox/1889/execroot/org_tensorflow\r\nsrc/main/tools/linux-sandbox-pid1.cc:194: writable: /tmp\r\nsrc/main/tools/linux-sandbox-pid1.cc:194: writable: /dev/shm\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /dev\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /dev/pts\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount rw: /dev/shm\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /dev/mqueue\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /dev/hugepages\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /run\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /run/lock\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /run/rpc_pipefs\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /run/user/0\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /run/user/108\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /run/user/108/gvfs\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /sys\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /sys/kernel/security\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /sys/fs/cgroup\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /sys/fs/cgroup/systemd\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /sys/fs/cgroup/perf_event\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /sys/fs/cgroup/pids\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /sys/fs/cgroup/freezer\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /sys/fs/cgroup/devices\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /sys/fs/cgroup/blkio\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /sys/fs/cgroup/net_cls,net_prio\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /sys/fs/cgroup/cpu,cpuacct\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /sys/fs/cgroup/rdma\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /sys/fs/cgroup/cpuset\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /sys/fs/cgroup/memory\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /sys/fs/cgroup/hugetlb\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /sys/fs/pstore\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /sys/kernel/config\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /sys/fs/fuse/connections\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /sys/kernel/debug\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /proc\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /proc/sys/fs/binfmt_misc\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /boot\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /software\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /vlsi/h3\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /vlsi/h2\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /tools/hl_shared_dir\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /usr/local/installs\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /usr/local/installs/SW\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /vovlogs\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /syntmp\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /utils\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount ro: /home/ogabbay/.gvfs\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount rw: /home/ogabbay/.cache/bazel/_bazel_ogabbay/336c59c3c10f4f0f593d30a996172c97/sandbox/linux-sandbox/1889/execroot/org_tensorflow\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount rw: /home/ogabbay/.cache/bazel/_bazel_ogabbay/336c59c3c10f4f0f593d30a996172c97/sandbox/linux-sandbox/1889/execroot/org_tensorflow\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount rw: /tmp\r\nsrc/main/tools/linux-sandbox-pid1.cc:265: remount rw: /dev/shm\r\nsrc/main/tools/process-tools.cc:118: sigaction(32, &sa, nullptr) failed\r\nsrc/main/tools/process-tools.cc:118: sigaction(33, &sa, nullptr) failed\r\n/usr/bin/ld.gold: error: bazel-out/host/bin/external/grpc/_objs/grpc_nanopb/pb_common.pic.o: multiple definition of 'pb_field_iter_begin'\r\n/usr/bin/ld.gold: bazel-out/host/bin/external/grpc/third_party/nanopb/_objs/nanopb/pb_common.pic.o: previous definition here\r\n/usr/bin/ld.gold: error: bazel-out/host/bin/external/grpc/_objs/grpc_nanopb/pb_common.pic.o: multiple definition of 'pb_field_iter_next'\r\n/usr/bin/ld.gold: bazel-out/host/bin/external/grpc/third_party/nanopb/_objs/nanopb/pb_common.pic.o: previous definition here\r\n/usr/bin/ld.gold: error: bazel-out/host/bin/external/grpc/_objs/grpc_nanopb/pb_common.pic.o: multiple definition of 'pb_field_iter_find'\r\n/usr/bin/ld.gold: bazel-out/host/bin/external/grpc/third_party/nanopb/_objs/nanopb/pb_common.pic.o: previous definition here\r\n/usr/bin/ld.gold: error: bazel-out/host/bin/external/grpc/_objs/grpc_nanopb/pb_decode.pic.o: multiple definition of 'pb_read'\r\n/usr/bin/ld.gold: bazel-out/host/bin/external/grpc/third_party/nanopb/_objs/nanopb/pb_decode.pic.o: previous definition here\r\n/usr/bin/ld.gold: error: bazel-out/host/bin/external/grpc/_objs/grpc_nanopb/pb_decode.pic.o: multiple definition of 'pb_istream_from_buffer'\r\n/usr/bin/ld.gold: bazel-out/host/bin/external/grpc/third_party/nanopb/_objs/nanopb/pb_decode.pic.o: previous definition here\r\n/usr/bin/ld.gold: error: bazel-out/host/bin/external/grpc/_objs/grpc_nanopb/pb_decode.pic.o: multiple definition of 'pb_decode_varint'\r\n/usr/bin/ld.gold: bazel-out/host/bin/external/grpc/third_party/nanopb/_objs/nanopb/pb_decode.pic.o: previous definition here\r\n/usr/bin/ld.gold: error: bazel-out/host/bin/external/grpc/_objs/grpc_nanopb/pb_decode.pic.o: multiple definition of 'pb_decode_tag'\r\n/usr/bin/ld.gold: bazel-out/host/bin/external/grpc/third_party/nanopb/_objs/nanopb/pb_decode.pic.o: previous definition here\r\n/usr/bin/ld.gold: error: bazel-out/host/bin/external/grpc/_objs/grpc_nanopb/pb_decode.pic.o: multiple definition of 'pb_skip_field'\r\n/usr/bin/ld.gold: bazel-out/host/bin/external/grpc/third_party/nanopb/_objs/nanopb/pb_decode.pic.o: previous definition here\r\n/usr/bin/ld.gold: error: bazel-out/host/bin/external/grpc/_objs/grpc_nanopb/pb_decode.pic.o: multiple definition of 'pb_make_string_substream'\r\n/usr/bin/ld.gold: bazel-out/host/bin/external/grpc/third_party/nanopb/_objs/nanopb/pb_decode.pic.o: previous definition here\r\n/usr/bin/ld.gold: error: bazel-out/host/bin/external/grpc/_objs/grpc_nanopb/pb_decode.pic.o: multiple definition of 'pb_close_string_substream'\r\n/usr/bin/ld.gold: bazel-out/host/bin/external/grpc/third_party/nanopb/_objs/nanopb/pb_decode.pic.o: previous definition here\r\n/usr/bin/ld.gold: error: bazel-out/host/bin/external/grpc/_objs/grpc_nanopb/pb_decode.pic.o: multiple definition of 'pb_decode_noinit'\r\n/usr/bin/ld.gold: bazel-out/host/bin/external/grpc/third_party/nanopb/_objs/nanopb/pb_decode.pic.o: previous definition here\r\n/usr/bin/ld.gold: error: bazel-out/host/bin/external/grpc/_objs/grpc_nanopb/pb_decode.pic.o: multiple definition of 'pb_decode'\r\n/usr/bin/ld.gold: bazel-out/host/bin/external/grpc/third_party/nanopb/_objs/nanopb/pb_decode.pic.o: previous definition here\r\n/usr/bin/ld.gold: error: bazel-out/host/bin/external/grpc/_objs/grpc_nanopb/pb_decode.pic.o: multiple definition of 'pb_decode_delimited'\r\n/usr/bin/ld.gold: bazel-out/host/bin/external/grpc/third_party/nanopb/_objs/nanopb/pb_decode.pic.o: previous definition here\r\n/usr/bin/ld.gold: error: bazel-out/host/bin/external/grpc/_objs/grpc_nanopb/pb_decode.pic.o: multiple definition of 'pb_decode_svarint'\r\n/usr/bin/ld.gold: bazel-out/host/bin/external/grpc/third_party/nanopb/_objs/nanopb/pb_decode.pic.o: previous definition here\r\n/usr/bin/ld.gold: error: bazel-out/host/bin/external/grpc/_objs/grpc_nanopb/pb_decode.pic.o: multiple definition of 'pb_decode_fixed32'\r\n/usr/bin/ld.gold: bazel-out/host/bin/external/grpc/third_party/nanopb/_objs/nanopb/pb_decode.pic.o: previous definition here\r\n/usr/bin/ld.gold: error: bazel-out/host/bin/external/grpc/_objs/grpc_nanopb/pb_decode.pic.o: multiple definition of 'pb_decode_fixed64'\r\n/usr/bin/ld.gold: bazel-out/host/bin/external/grpc/third_party/nanopb/_objs/nanopb/pb_decode.pic.o: previous definition here\r\n/usr/bin/ld.gold: error: bazel-out/host/bin/external/grpc/_objs/grpc_nanopb/pb_encode.pic.o: multiple definition of 'pb_ostream_from_buffer'\r\n/usr/bin/ld.gold: bazel-out/host/bin/external/grpc/third_party/nanopb/_objs/nanopb/pb_encode.pic.o: previous definition here\r\n/usr/bin/ld.gold: error: bazel-out/host/bin/external/grpc/_objs/grpc_nanopb/pb_encode.pic.o: multiple definition of 'pb_write'\r\n/usr/bin/ld.gold: bazel-out/host/bin/external/grpc/third_party/nanopb/_objs/nanopb/pb_encode.pic.o: previous definition here\r\n/usr/bin/ld.gold: error: bazel-out/host/bin/external/grpc/_objs/grpc_nanopb/pb_encode.pic.o: multiple definition of 'pb_encode_varint'\r\n/usr/bin/ld.gold: bazel-out/host/bin/external/grpc/third_party/nanopb/_objs/nanopb/pb_encode.pic.o: previous definition here\r\n/usr/bin/ld.gold: error: bazel-out/host/bin/external/grpc/_objs/grpc_nanopb/pb_encode.pic.o: multiple definition of 'pb_encode_svarint'\r\n/usr/bin/ld.gold: bazel-out/host/bin/external/grpc/third_party/nanopb/_objs/nanopb/pb_encode.pic.o: previous definition here\r\n/usr/bin/ld.gold: error: bazel-out/host/bin/external/grpc/_objs/grpc_nanopb/pb_encode.pic.o: multiple definition of 'pb_encode_fixed32'\r\n/usr/bin/ld.gold: bazel-out/host/bin/external/grpc/third_party/nanopb/_objs/nanopb/pb_encode.pic.o: previous definition here\r\n/usr/bin/ld.gold: error: bazel-out/host/bin/external/grpc/_objs/grpc_nanopb/pb_encode.pic.o: multiple definition of 'pb_encode_fixed64'\r\n/usr/bin/ld.gold: bazel-out/host/bin/external/grpc/third_party/nanopb/_objs/nanopb/pb_encode.pic.o: previous definition here\r\n/usr/bin/ld.gold: error: bazel-out/host/bin/external/grpc/_objs/grpc_nanopb/pb_encode.pic.o: multiple definition of 'pb_encode_tag'\r\n/usr/bin/ld.gold: bazel-out/host/bin/external/grpc/third_party/nanopb/_objs/nanopb/pb_encode.pic.o: previous definition here\r\n/usr/bin/ld.gold: error: bazel-out/host/bin/external/grpc/_objs/grpc_nanopb/pb_encode.pic.o: multiple definition of 'pb_encode_tag_for_field'\r\n/usr/bin/ld.gold: bazel-out/host/bin/external/grpc/third_party/nanopb/_objs/nanopb/pb_encode.pic.o: previous definition here\r\n/usr/bin/ld.gold: error: bazel-out/host/bin/external/grpc/_objs/grpc_nanopb/pb_encode.pic.o: multiple definition of 'pb_encode'\r\n/usr/bin/ld.gold: bazel-out/host/bin/external/grpc/third_party/nanopb/_objs/nanopb/pb_encode.pic.o: previous definition here\r\n/usr/bin/ld.gold: error: bazel-out/host/bin/external/grpc/_objs/grpc_nanopb/pb_encode.pic.o: multiple definition of 'pb_get_encoded_size'\r\n/usr/bin/ld.gold: bazel-out/host/bin/external/grpc/third_party/nanopb/_objs/nanopb/pb_encode.pic.o: previous definition here\r\n/usr/bin/ld.gold: error: bazel-out/host/bin/external/grpc/_objs/grpc_nanopb/pb_encode.pic.o: multiple definition of 'pb_encode_string'\r\n/usr/bin/ld.gold: bazel-out/host/bin/external/grpc/third_party/nanopb/_objs/nanopb/pb_encode.pic.o: previous definition here\r\n/usr/bin/ld.gold: error: bazel-out/host/bin/external/grpc/_objs/grpc_nanopb/pb_encode.pic.o: multiple definition of 'pb_encode_submessage'\r\n/usr/bin/ld.gold: bazel-out/host/bin/external/grpc/third_party/nanopb/_objs/nanopb/pb_encode.pic.o: previous definition here\r\n/usr/bin/ld.gold: error: bazel-out/host/bin/external/grpc/_objs/grpc_nanopb/pb_encode.pic.o: multiple definition of 'pb_encode_delimited'\r\n/usr/bin/ld.gold: bazel-out/host/bin/external/grpc/third_party/nanopb/_objs/nanopb/pb_encode.pic.o: previous definition here\r\ncollect2: error: ld returned 1 exit status\r\nsrc/main/tools/linux-sandbox-pid1.cc:437: waitpid returned 2\r\nsrc/main/tools/linux-sandbox-pid1.cc:457: child exited with code 1\r\nsrc/main/tools/linux-sandbox.cc:204: child exited normally with exitcode 1\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 1603.699s, Critical Path: 114.71s, Remote (0.00% of the time): [queue: 0.00%, setup: 0.00%, process: 0.00%]\r\nINFO: 1907 processes: 1905 linux-sandbox, 2 local.\r\nFAILED: Build did NOT complete successfully\r\n", "comments": ["I am getting this same error with GCC. I also notice some suspicious warnings related to nanopb when I start my build:\r\n```\r\nWARNING: /home/evan/.cache/bazel/_bazel_evan/f72c3ae5f60bd568267520cabb8bf371/external/grpc/BUILD:1992:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_common.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /home/evan/.cache/bazel/_bazel_evan/f72c3ae5f60bd568267520cabb8bf371/external/grpc/bazel/grpc_build_system.bzl:172:12\r\nWARNING: /home/evan/.cache/bazel/_bazel_evan/f72c3ae5f60bd568267520cabb8bf371/external/grpc/BUILD:1992:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_decode.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /home/evan/.cache/bazel/_bazel_evan/f72c3ae5f60bd568267520cabb8bf371/external/grpc/bazel/grpc_build_system.bzl:172:12\r\nWARNING: /home/evan/.cache/bazel/_bazel_evan/f72c3ae5f60bd568267520cabb8bf371/external/grpc/BUILD:1992:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_encode.c' directly. You should either move the file to thi\r\n```", "Getting the very same with:\r\n\r\nArch Linux\r\nTensorFlow installed from source\r\nTensorFlow version: 1.12\r\nPython version: 3.7\r\nBazel version (if compiling from source): 0.19\r\nGCC/Compiler version (if compiling from source): 8.2.1 (gcc 7.3.1 for CUDA stuff)\r\n", "Same here with bazel 0.19 and python 3.7\r\n", "it works just fine with bazel 0.18 fwiw", "@svenstaro `makedepends=('bazel=0.18'....)` ?", "Well now, that's not how do things @kgizdov :) Gotta patch that upstream.", "If I'm understanding correctly, the `workspace.bzl` says `grpc` pulls their own `nanopb` and thus it is explicitly listed as dep, but then it is built again by `third_party/nanopb.BUILD`. So one of those should be dropped?\r\nNot to mention this:\r\nhttps://github.com/tensorflow/tensorflow/blob/c2516aa0663f015d021a958012b7bfff1bcd78cb/tensorflow/workspace.bzl#L848-L851\r\nhttps://github.com/tensorflow/tensorflow/blob/c2516aa0663f015d021a958012b7bfff1bcd78cb/tensorflow/workspace.bzl#L880-L883", "@meteorcloudy and @case540 can you check why we might see this error with bazel 0.19 but not 0.18?\r\nI wonder if this PR be related: https://github.com/tensorflow/tensorflow/pull/21374\r\nsince there is this comment: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/workspace.bzl#L847\r\n", "21374 was reverted. the new one is in https://github.com/tensorflow/tensorflow/pull/22964", "Same issue on my side.\r\nMy configuration:\r\n- Linux Ubuntu 18.04\r\n- TensorFlow installed from source\r\n- TensorFlow version: 1.12\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): 0.19\r\n- GCC/Compiler version (if compiling from source): 7.3.0", "@annarev I believe this is because Bazel 0.19.0 doesn't read `tools/bazel.rc` anymore, but we need `build --define=grpc_no_ares=true` which is defined at https://github.com/tensorflow/tensorflow/blob/70794a8447204d8ef14103ffa25b2738dd399479/tools/bazel.rc#L85\r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/23583 will fix this issue. But eventually, we want to merge @perfinion 's #22964, but that requires upgrading Bazel to 0.18.x or later on all CI machines, which isn't currently true based on the presubmit result.\r\n", "Hi @meteorcloudy,\r\n\r\nIt is probably possible to provide this option (--define=grpc_no_ares=true) in the command line for bazel build of tensorflow?\r\nThat would be at least temporary solution.\r\nThanks in advance for the response.\r\n\r\nRegards.", "@vyepishov Yes, you can do that. Or you can also cherry-pick #23583, it's a quite a simple change.", "@meteorcloudy Thanks for the answer and good news! I will stick to the option to add the argument to the command line :)"]}, {"number": 23401, "title": "Build from source -> build the pip package -> GPU support -> bazel build -> ERROR: Config value cuda is not defined in any .rc file", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): Source \r\n- TensorFlow version: v1.12.0-rc2\r\n- Python version: Python 3.7.0\r\n- Installed using virtualenv? pip? conda?: conda 4.5.11 \r\n- Bazel version (if compiling from source): 0.19.0\r\n- GCC/Compiler version (if compiling from source): GCC 7.2.0\r\n- CUDA/cuDNN version: 10.0 / 7.3.1\r\n- GPU model and memory: nvidia GTX 1070 / 8GB\r\n\r\n\r\n\r\n**Describe the problem**\r\nGot error while building pip package from source\r\nERROR: Config value cuda is not defined in any .rc file\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\ngopi@gp:~/tensorflow$ ./configure \r\nWARNING: The following rc files are no longer being read, please transfer their contents or import their path into one of the standard rc files:\r\n/home/gopi/tensorflow/tools/bazel.rc\r\nWARNING: Running Bazel server needs to be killed, because the startup options are different.\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nYou have bazel 0.19.0 installed.\r\nPlease specify the location of python. [Default is /home/gopi/anaconda3/bin/python]: \r\n\r\n\r\nFound possible Python library paths:\r\n  /home/gopi/anaconda3/lib/python3.7/site-packages\r\nPlease input the desired Python library path to use.  Default is [/home/gopi/anaconda3/lib/python3.7/site-packages]\r\n\r\nDo you wish to build TensorFlow with Apache Ignite support? [Y/n]: n\r\nNo Apache Ignite support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [Y/n]: n\r\nNo XLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: N\r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: N\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nPlease specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 9.0]: 10.0\r\n\r\n\r\nPlease specify the location where CUDA 10.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\n\r\n\r\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7]: \r\n\r\n\r\nPlease specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\n\r\n\r\nDo you wish to build TensorFlow with TensorRT support? [y/N]: N\r\nNo TensorRT support will be enabled for TensorFlow.\r\n\r\nPlease specify the NCCL version you want to use. If NCCL 2.2 is not installed, then you can use version 1.3 that can be fetched automatically but it may have worse performance with multiple GPUs. [Default is 2.2]: 1.3\r\n\r\n\r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 6.1]: \r\n\r\n\r\nDo you want to use clang as CUDA compiler? [y/N]: N\r\nnvcc will be used as CUDA compiler.\r\n\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \r\n\r\n\r\nDo you wish to build TensorFlow with MPI support? [y/N]: N\r\nNo MPI support will be enabled for TensorFlow.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: \r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: N\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See tools/bazel.rc for more details.\r\n\t--config=mkl         \t# Build with MKL support.\r\n\t--config=monolithic  \t# Config for mostly static monolithic build.\r\n\t--config=gdr         \t# Build with GDR support.\r\n\t--config=verbs       \t# Build with libverbs support.\r\n\t--config=ngraph      \t# Build with Intel nGraph support.\r\nConfiguration finished\r\ngopi@gp:~/tensorflow$ bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\nWARNING: The following rc files are no longer being read, please transfer their contents or import their path into one of the standard rc files:\r\n/home/gopi/tensorflow/tools/bazel.rc\r\nStarting local Bazel server and connecting to it...\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=204\r\nINFO: Reading rc options for 'build' from /home/gopi/tensorflow/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/home/gopi/anaconda3/bin/python --action_env PYTHON_LIB_PATH=/home/gopi/anaconda3/lib/python3.7/site-packages --python_path=/home/gopi/anaconda3/bin/python --action_env TF_NEED_OPENCL_SYCL=0 --action_env TF_NEED_ROCM=0 --action_env TF_NEED_CUDA=1 --action_env CUDA_TOOLKIT_PATH=/usr/local/cuda --action_env TF_CUDA_VERSION=10.0 --action_env CUDNN_INSTALL_PATH=/usr/local/cuda-10.0 --action_env TF_CUDNN_VERSION=7 --action_env TF_NCCL_VERSION=1 --action_env TF_CUDA_COMPUTE_CAPABILITIES=6.1 --action_env LD_LIBRARY_PATH=:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64 --action_env TF_CUDA_CLANG=0 --action_env GCC_HOST_COMPILER_PATH=/usr/bin/gcc --config=cuda\r\nERROR: Config value cuda is not defined in any .rc file\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["This is an issue with bazel 0.19.0, either use bazel 0.18.0, or follow the warning message:\r\n\r\nWARNING: The following rc files are no longer being read, please transfer their contents or import their path into one of the standard rc files:\r\n/home/gopi/tensorflow/tools/bazel.rc\r\n\r\nand add the contents of that file to your .tf_configure.bazelrc", "Thanks William :)\r\nUsing the same version of bazel 0.19.0, Added the content of file \"/home/gopi/tensorflow/tools/bazel.rc\" on top of (hidden) file \"/home/gopi/tensorflow/.tf_configure.bazelrc\" & build happens.\r\n ", "build tensorflow 1.11.0 I have do this,in source file  add context \"\r\nimport /home/ai/ver/tensorflow-r1.11/tools/bazel.rc \" on top line of(hide file) \"/home/ai/ver/tensorflow-r1.11/.bazelrc \"  and not .tf_configure.bazelrc\r\n\r\n", "> build tensorflow 1.11.0 I have do this,in source file add context \"\r\n> import /home/ai/ver/tensorflow-r1.11/tools/bazel.rc \" on top line of(hide file) \"/home/ai/ver/tensorflow-r1.11/.bazelrc \" and not .tf_configure.bazelrc\r\n\r\nThis worked for me too. Thanks !", "> tensorflow\r\n\r\nhow is this ? A example pls .... \r\n\r\nI found TensorFlow\\models\\research\\syntaxnet\\tools\\bazel.rc   and  now ?? ", "I had an issue with version 0.20.0 as well with building with mkl support. I downgraded to 0.18.1 and all was well.\r\n\r\nBad version:\r\n```\r\n[root@crobiso1-container tensorflow]# bazel version\r\nWARNING: The following rc files are no longer being read, please transfer their contents or import their path into one of the standard rc files:\r\n/tensorflow/tools/bazel.rc\r\nWARNING: detected http_proxy set in env, setting no_proxy for localhost.\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nINFO: Invocation ID: 4ca86d39-5a93-4068-8467-4f4298a986c8\r\nBuild label: 0.20.0\r\nBuild target: bazel-out/k8-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Fri Nov 30 14:39:01 2018 (1543588741)\r\nBuild timestamp: 1543588741\r\nBuild timestamp as int: 1543588741\r\n```\r\n\r\nFailing build:\r\n```\r\n[root@crobiso1-container tensorflow]# echo $TF_BAZEL_BUILD_OPTIONS\r\n--config=mkl --cxxopt=-D_GLIBCXX_USE_CXX11_ABI=0 --copt=-march=corei7-avx --copt=-mtune=core-avx-i --copt=-O3\r\n[root@crobiso1-container tensorflow]# bazel build -c opt \\\r\n>         ${TF_BAZEL_BUILD_OPTIONS} \\\r\n>         tensorflow/tools/pip_package:build_pip_package\r\nWARNING: The following rc files are no longer being read, please transfer their contents or import their path into one of the standard rc files:\r\n/tensorflow/tools/bazel.rc\r\nWARNING: detected http_proxy set in env, setting no_proxy for localhost.\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=189\r\nINFO: Reading rc options for 'build' from /etc/bazel.bazelrc:\r\n  'build' options: --spawn_strategy=standalone --genrule_strategy=standalone\r\nINFO: Reading rc options for 'build' from /tensorflow/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/lib/python3.4/site-packages --python_path=/usr/bin/python3 --define with_ignite_support=true --define with_xla_support=true --action_env TF_NEED_OPENCL_SYCL=0 --action_env TF_NEED_ROCM=0 --action_env TF_NEED_CUDA=0 --action_env TF_DOWNLOAD_CLANG=0\r\nERROR: Config value mkl is not defined in any .rc file\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nINFO: Invocation ID: 5ab95a91-820d-4262-9a8a-1c6312316ba0\r\n[root@crobiso1-container tensorflow]# echo $?\r\n2\r\n```", "This was broken by this commit:\r\nhttps://github.com/tensorflow/tensorflow/pull/22964\r\n\r\nPR raised to fix it here:\r\nhttps://github.com/tensorflow/tensorflow/pull/25114\r\n\r\nYou'll probably need to cherry-pick this commit if you are compiling with cuda support:\r\nhttps://github.com/tensorflow/tensorflow/commit/09feb6963d691ce12c41fd20ff7638daa89aea11", "Or edit the `.bazel.rc` file in-place with `sed`:\r\n\r\n```\r\nsed -i -E 's#\\.tf_configure\\.bazelrc#tools/bazel.rc#' .bazelrc\r\n```", "I can't find `.tf_configure.bazelrc` when it should appear?", "@mrgloom, .tf_configure.bazelrc is created by running ./configure\r\n\r\nYour answers from ./configure are stored in .tf_configure.bazelrc", "> Thanks William :)\r\n> Using the same version of bazel 0.19.0, Added the content of file \"/home/gopi/tensorflow/tools/bazel.rc\" on top of (hidden) file \"/home/gopi/tensorflow/.tf_configure.bazelrc\" & build happens.\r\n\r\nhow can I find hidden file .tf_configure.bazelrc?", "> Thanks William :)\r\n> Using the same version of bazel 0.19.0, Added the content of file \"/home/gopi/tensorflow/tools/bazel.rc\" on top of (hidden) file \"/home/gopi/tensorflow/.tf_configure.bazelrc\" & build happens.\r\n\r\nOK\uff0cI' known\uff0cuse \u201cls -a\u201d to see hidden file \uff0cthank you"]}, {"number": 23400, "title": "Fix downloading protobuf dependency", "body": "Protobuf has been failing due to its repository having dependencies. Downloading the .tar.gz form GitHub doesn't work because it does not bring its dependencies with it.\r\n\r\nThis PR introduces a function to clone a repository, initializa and update its submodules. The function is used to download protobuf as a repository dependency, rather than just a file.\r\n\r\nThe function is also implemented in a generic way, so if in the future other dependencies fall into the same situation, it can be reused.\r\n\r\nWith these changes, `tensorflow/workspace.bzl` goes back to using the commit sha in `PROTOBUF_URLS` and `PROTOBUF_STRIP_PREFIX`, rather than the tag of a release.\r\n\r\nA command at the end of the `download_dependencies.sh` script was commented out. The comment says for it to be removed once protobug is fixed. Perhaps no longer necessary.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "CLAs look good, thanks!\n\n<!-- ok -->", "Conflict has been resolved. The PR is ready for review.", "@therc Can I proceed with next steps to merge this PR ? I don't see \"approved\" check and so want to get clarified on proceeding. Please keep me posted. ", "I'm not a tensorflow project member, I only added a drive-by comment. :)", "Hi @harshini-gadige , it would be great to see this PR merged. I have been using this for a while, without any issues. Is there anything I can do to help?", "@dcirne  Waiting for the reviewer approval.\r\n@petewarden  @wolffg  -  Any update ?", "Resolved a conflict that appeared since our last contact.", "@harshini-gadige with the news that 1.13 will be branching on Dec 13th, is there any chance this PR gets merged before that, in time to make the cut?", "> @dcirne Waiting for the reviewer approval.\r\n> @petewarden @wolffg - Any update ?\r\n\r\n@petewarden  @wolffg  -  Please review and approve this PR. If you are not the right person, please assign to the respective person. \r\n", "Hi @penpornk , thank you for the links, they helped in debugging. It seems that the tests failing was not related to the content of the PR itself, but to the version of flatbuffer, which seems somehow dependent on protobuf version 3.6.1.2. Since This PR originally used protobuf version 3.6.1, the file couldn't be found. (See snippet from the tests below.)\r\n\r\n```bash\r\ndownloading https://github.com/google/flatbuffers/archive/1f5eae5d6a135ff6811724f6c57f911d1f46bb15.tar.gz\r\n650\r\nCloning into 'tensorflow/contrib/makefile/downloads/protobuf'...\r\n651\r\nerror: pathspec 'v3.6.1.2.tar.gz' did not match any file(s) known to git.\r\n652\r\n================================================================================\r\n653\r\n//tensorflow/tools/ci_build/builds:gen_makefile_out                      FAILED in 0.1s\r\n```\r\n\r\nI updated the PR to use protobuf version 3.6.1.2. I hope this will fix the tests.\r\n", "@penpornk apologies for an earlier mistake. The commit I pushed about half an hour ago had an error in the URL to download version 3.6.1.2 of protobuf.\r\n\r\nI have just corrected it and pushed a new commit. All the tests I could run on my side worked.", "@dcirne I just saw your new comment after submitting my review. Sorry for not addressing your comment earlier! I'm rerunning the tests.", "@penpornk thank you for the feedback. I have just pushed a new commit addressing all the points from your review.", "Only `Windows Bazel` and `Windows Bazel GPU` failed. These are existing failures. We are good to go. Thank you again for the PR! "]}, {"number": 23399, "title": "TFLite failed to allocate tensors when changing the input size", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: iPhone 7 simulator\r\n- TensorFlow installed from (source or binary): source \r\n- TensorFlow version (use command below): master\r\n- Python version: 2.7\r\n- Bazel version (if compiling from source): 0.15.0\r\n- GCC/Compiler version (if compiling from source): None\r\n- CUDA/cuDNN version: None\r\n- GPU model and memory: None\r\n\r\n**Describe the current behavior**\r\nI convert the TF model to TFLite model by tflite_convert command with float inference_type, and input_shapes set to 1,W,H,3; when I run the model with input shape W*H, **it works well**; However, when I **change** the input shapes to different values, it would give error like \"tensorflow/contrib/lite/kernels/kernel_util.cc:125 d1 == d2 || d1 == 1 || d2 == 1 was not true; Node number xx (ADD) failed to prepare\" for tf.add op. Similar errors appear for other ops like CONCAT and RESHAPE. When I set breakpoints in tflite codes, it seems to always check/use the tensor shapes when converting the model, even the input shape has changed. \r\n\r\nPart of the codes are like this:\r\n\r\n```\r\nint input = interpreter->inputs()[0];\r\n    interpreter->ResizeInputTensor(input, new_input_sizes);\r\n    if (interpreter->AllocateTensors() != kTfLiteOk) {\r\n        NSLog(@\"Failed to allocate tensors for model.\");\r\n        exit(-1);\r\n    }\r\n```\r\n", "comments": ["#22377 similar to this issue @aselle ", "@shawn-tian could you specify what shapes you have been trying? Could you provide more reproducibility information.", "@aselle [Here](https://drive.google.com/drive/folders/1JaVBD6Z_9H4YedZ1Oe8DgGAYzM0MGrDT?usp=sharing) are the models with corresponding tflite converted ones. The models are converted with input_shapes=1,1280,960,3. \r\n\r\nIf i set the new_input_sizes = {1,1280,960,3}, everything works well. If I set it to any other values, it would lead to aforementioned errors. \r\n```\r\nint input = interpreter->inputs()[0];\r\n    interpreter->ResizeInputTensor(input, new_input_sizes);\r\n    if (interpreter->AllocateTensors() != kTfLiteOk) {\r\n        NSLog(@\"Failed to allocate tensors for model.\");\r\n        exit(-1);\r\n    }\r\n```\r\nPlease help to take a look and let me know if any other details are required.", "https://github.com/tensorflow/tensorflow/issues/22377#issuecomment-444550814", "Duplicate of #24311", "OK, this issue is subtly different from issue #24311. In this case, the graph has a conv2d_transpose operation. This op takes as input a 1D vector which controls the output shape (see https://www.tensorflow.org/api_docs/python/tf/nn/conv2d_transpose). You need to make that value an input tensor to your graph (during conversion), and change that (new) input tensor's *value* when you change the shape of the (existing) input image tensor.", "@jdduke Thanks for you advice. I have two questions. 1. So it means during inference in TFLite, it cannot accept the value computed dynamically? 2. If I change conv2d_transpose to  resize_bilinear op, I also have to follow your above steps, feeding another input tensor to the graph during conversion? Please help to clarify my doubts. ", ">  1. So it means during inference in TFLite, it cannot accept the value computed dynamically?\r\n\r\nIt's model-dependent. Many models will allow resizing without problem. Other models have various (coupled) inputs that would all need updating if you plan on resizing the shape of a given input.\r\n\r\n>  2. If I change conv2d_transpose to resize_bilinear op, I also have to follow your above steps, feeding another input tensor to the graph during conversion? \r\n\r\nAgain, it depends on the model and how the resize_bilinear op is used. If it (or any downstream ops) make any assumptions about the relative sizes between the resize_bilinear op, and the input that you're resizing, then it might require a dynamic input that is passed into resize_bilinear.", "@jdduke Thank you for the detailed explanation. But I think most segmentation network with resize_bilinear op will have some assumptions about the relative sizes between op and input. Is there any plan to fix this in the future? "]}, {"number": 23398, "title": "Cannot build libtensorflow.so with bazel 0.19", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Archlinux\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.12\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): Build label: 0.19.0- (@non-git)\r\n- GCC/Compiler version (if compiling from source): gcc 8.2.1\r\n- CUDA/cuDNN version: cuda 10, cudnn 7\r\n- GPU model and memory: nvidia 1080 ti\r\n\r\n**Describe the problem**\r\n\r\nWhen I try to compile tensorflow from sources running:\r\n\r\n```\r\ngo get -d github.com/tensorflow/tensorflow/tensorflow/go\r\ncd ${GOPATH}/src/github.com/tensorflow/tensorflow\r\ngit checkout origin/r1.12\r\n./configure\r\nbazel build -c opt //tensorflow:libtensorflow.so\r\n```\r\nI got this warning from bazel:\r\n\r\n```\r\nWARNING: The following rc files are no longer being read, please transfer their contents or import their path into one of the standard rc files:\r\n/data/pgaleone/go/src/github.com/tensorflow/tensorflow/tools/bazel.rc\r\n```\r\n\r\nand this error next:\r\n\r\n```\r\nStarting local Bazel server and connecting to it...\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=271\r\nINFO: Reading rc options for 'build' from /data/pgaleone/go/src/github.com/tensorflow/tensorflow/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python --action_env PYTHON_LIB_PATH=/usr/lib/python3.7/site-packages --python_path=/usr/bin/python --define with_ignite_support=true --define with_xla_support=true --action_env TF_NEED_OPENCL_SYCL=0 --action_env TF_NEED_ROCM=0 --action_env TF_NEED_CUDA=1 --action_env CUDA_TOOLKIT_PATH=/opt/cuda --action_env TF_CUDA_VERSION=10.0 --action_env CUDNN_INSTALL_PATH=/opt/cuda --action_env TF_CUDNN_VERSION=7 --action_env NCCL_INSTALL_PATH=/usr/lib --action_env NCCL_HDR_PATH=/usr/lib/../include --action_env TF_NCCL_VERSION=2 --action_env TF_CUDA_COMPUTE_CAPABILITIES=6.1 --action_env LD_LIBRARY_PATH=/opt/cuda/lib64:/opt/cuda/extras/CUPTI/lib64:/home/pgaleone/sources/ml/tensorflow/bazel-bin/tensorflow/ --action_env TF_CUDA_CLANG=0 --action_env GCC_HOST_COMPILER_PATH=/usr/bin/gcc-7 --config=cuda\r\nERROR: Config value cuda is not defined in any .rc file\r\n```\r\n", "comments": ["```\r\nERROR: Config value cuda is not defined in any .rc file\r\n```\r\n\ud83d\udc4d", "@galeone : Add  the below line to your `.bazelrc` file in your checkout tensorflow source\r\n```\r\nimport /data/pgaleone/go/src/github.com/tensorflow/tensorflow/tools/bazel.rc\r\n```\r\nor whatever that path of your tensorflow source to `tools/bazel.rc`", "Thank you @neofob - now it works!\r\nHowever, shouldn't this line being added automatically to the `.bazelrc` file? Probably this is a bug (although your fix works well)"]}, {"number": 23397, "title": "parallel_for: No converter defined for MaxPoolGradGrad", "body": "I have written a `fwd_gradients`-based implementation of `batch_jacobian` (comparable to the `tf.gradients`-based `tensorflow.python.ops.parallel_for.batch_jacobian`). To efficiently implement `batch_jacobian`, TensorFlow added support `parallel_for`: unfortunately, `pfor` does not support the `MaxPoolGradGrad` op, requiring a fallback to a slow while loop. For performance reasons, it would be great to add a converter for `MaxPoolGradGrad` to `parallel_for`.\r\n\r\n**Code to reproduce the issue**\r\nThe following code is a minimal example to reproduce the issue and can be run as is.\r\n\r\n```python\r\n#!/usr/bin/env python3\r\nimport tensorflow as tf\r\nfrom tensorflow.python.ops.parallel_for import control_flow_ops\r\nfrom tensorflow.contrib.nn.python.ops.fwd_gradients import fwd_gradients\r\nfrom tensorflow.python.platform import flags\r\nimport sys\r\nimport numpy as np\r\n\r\n\r\ndef main():\r\n    sess = tf.InteractiveSession()\r\n\r\n    print(tf.__version__)\r\n\r\n    flags.FLAGS(sys.argv)\r\n\r\n    x = tf.placeholder(tf.float32, (None, 2, 2, 1))\r\n    y = tf.nn.max_pool(x, (1, 2, 2, 1), strides=(1, 1, 1, 1), padding='SAME')\r\n\r\n    input_shape = tf.shape(x)\r\n    batch_size = input_shape[0]\r\n\r\n    input_size = 4\r\n    one_hot_vectors = tf.eye(input_size)\r\n\r\n    def loop_fn(i):\r\n        one_hot = tf.gather(one_hot_vectors, i)\r\n        one_hot = one_hot[tf.newaxis]\r\n        grad_inputs = tf.tile(one_hot, (batch_size, 1))\r\n        grad_inputs = tf.reshape(grad_inputs, input_shape)\r\n        g = fwd_gradients([y], [x], [grad_inputs])\r\n        assert len(g) == 1\r\n        print(g[0])\r\n        return g[0]\r\n\r\n    J = control_flow_ops.pfor(loop_fn, 4)\r\n\r\n    x_ = np.array([4, 1, 2, 3]).reshape(1, 2, 2, 1)\r\n    y_, J_ = sess.run([y, J], feed_dict={x: x_})\r\n    print(x_.squeeze())\r\n    print(y_.squeeze())\r\n    print(J_.squeeze())\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n\r\n**Describe the current behavior**\r\n```\r\n1.11.0\r\nTensor(\"loop_body/gradients_1/loop_body/gradients/MaxPool_grad/MaxPoolGrad_grad/MaxPoolGradGrad:0\", shape=(?, 2, 2, 1), dtype=float32)\r\nTraceback (most recent call last):\r\n  File \"./minimal_example.py\", line 46, in <module>\r\n    main()\r\n  File \"./minimal_example.py\", line 36, in main\r\n    J = control_flow_ops.pfor(loop_fn, 4)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py\", line 129, in pfor\r\n    outputs.append(converter.convert(loop_fn_output))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/parallel_for/pfor.py\", line 1077, in convert\r\n    output = self._convert_helper(y)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/parallel_for/pfor.py\", line 1223, in _convert_helper\r\n    \"which may run slower\" % (y_op.type, y_op, converted_inputs))\r\nValueError: No converter defined for MaxPoolGradGrad\r\nname: \"loop_body/gradients_1/loop_body/gradients/MaxPool_grad/MaxPoolGrad_grad/MaxPoolGradGrad\"\r\nop: \"MaxPoolGradGrad\"\r\ninput: \"Placeholder\"\r\ninput: \"MaxPool\"\r\ninput: \"loop_body/gradients_1/grad_ys_0\"\r\nattr {\r\n  key: \"T\"\r\n  value {\r\n    type: DT_FLOAT\r\n  }\r\n}\r\nattr {\r\n  key: \"data_format\"\r\n  value {\r\n    s: \"NHWC\"\r\n  }\r\n}\r\nattr {\r\n  key: \"ksize\"\r\n  value {\r\n    list {\r\n      i: 1\r\n      i: 2\r\n      i: 2\r\n      i: 1\r\n    }\r\n  }\r\n}\r\nattr {\r\n  key: \"padding\"\r\n  value {\r\n    s: \"SAME\"\r\n  }\r\n}\r\nattr {\r\n  key: \"strides\"\r\n  value {\r\n    list {\r\n      i: 1\r\n      i: 1\r\n      i: 1\r\n      i: 1\r\n    }\r\n  }\r\n}\r\n\r\ninputs: [WrappedTensor(t=<tf.Tensor 'Placeholder:0' shape=(?, 2, 2, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'MaxPool:0' shape=(?, 2, 2, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/gradients_1/grad_ys_0/pfor/Identity:0' shape=(4, ?, 2, 2, 1) dtype=float32>, is_stacked=True, is_sparse_stacked=False)]. \r\nEither add a converter or set --op_conversion_fallback_to_while_loop=True, which may run slower\r\n```\r\n\r\n**Describe the expected behavior**\r\n(produced by running the above script with `--op_conversion_fallback_to_while_loop`)\r\n\r\n```\r\n1.11.0\r\nTensor(\"loop_body/gradients_1/loop_body/gradients/MaxPool_grad/MaxPoolGrad_grad/MaxPoolGradGrad:0\", shape=(?, 2, 2, 1), dtype=float32)\r\nWARNING:tensorflow:Using a while_loop for converting MaxPoolGradGrad\r\n[[4 1]\r\n [2 3]]\r\n[[4. 3.]\r\n [3. 3.]]\r\n[[[1. 0.]\r\n  [0. 0.]]\r\n\r\n [[0. 0.]\r\n  [0. 0.]]\r\n\r\n [[0. 0.]\r\n  [0. 0.]]\r\n\r\n [[0. 1.]\r\n  [1. 1.]]]\r\n```\r\n\r\nP.S. If you are interested, I'd be happy to contribute my `fwd_gradients`-based `batch_jacobian` to TensorFlow once this performance issue with MaxPool ops is fixed and I've cleaned up my code.", "comments": ["@agarwal-ashish , can you take a look?", "A converter for MaxPoolGradGrad has been added and should make its way to a nightly build soon.\r\n\r\nHowever I suspect there might be a bunch of other ops that would turn up as not having converters given that you are relying on second order gradients.", "Thanks @agarwal-ashish for fixing this so fast! Works :)"]}, {"number": 23396, "title": "Fix the case when input value are MirroredVariable for assign_moving_average", "body": "Fix the case when the input value of assign_moving_average are type of Mirrored. (#23291)", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it", "CLAs look good, thanks!\n\n<!-- ok -->", "hi @yuefengz ,\r\n  Currently MovingAverage in `DistributionStrategy` is not very mature. This is a small bug fix. Please take a look. Thanks\r\n", "Some tests failed, while it seems that these are errors are not related to this modification.", "@yuefengz Sorry to bother you but any update?", "@harshini-gadige could you please help merge this PR? Thank you!", "Conflicts have been fixed.", "> @harshini-gadige could you please help merge this PR? Thank you!\r\n\r\nTrying to merge it. Looking into the kokoro failures. Will keep you posted.", "@harshini-gadige It seems that the movement of implementation of MirroredStrategy results in this conflicts, kindly let me know when you are ready inside and then I will fix the conflicts. Thanks!", "> @harshini-gadige It seems that the movement of implementation of MirroredStrategy results in this conflicts, kindly let me know when you are ready inside and then I will fix the conflicts. Thanks!\r\n\r\nSure. You can work on it now. I can rerun the checks once you are done. Please keep me posted. ", "> > @harshini-gadige It seems that the movement of implementation of MirroredStrategy results in this conflicts, kindly let me know when you are ready inside and then I will fix the conflicts. Thanks!\r\n> \r\n> Sure. You can work on it now. I can rerun the checks once you are done. Please keep me posted.\r\n\r\n@harshini-gadige Conflicts have been fixed, thanks!", "> > > @harshini-gadige It seems that the movement of implementation of MirroredStrategy results in this conflicts, kindly let me know when you are ready inside and then I will fix the conflicts. Thanks!\r\n> > \r\n> > \r\n> > Sure. You can work on it now. I can rerun the checks once you are done. Please keep me posted.\r\n> \r\n> @harshini-gadige Conflicts have been fixed, thanks!\r\n\r\n@josh11b  @yuefengz   Please review and approve.", "@yuefengz @josh11b Taking a review please, thanks!"]}]