[{"number": 32860, "title": "Mark tf.keras.utils.multi_gpu_model as deprecated.", "body": "", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F32860) for more info**.\n\n<!-- need_author_consent -->"]}, {"number": 32859, "title": "Warming tensorflow: Entity could not be transformed and will be executed as-is.", "body": "**System information**\r\n- Custom layers of tf.layer.Layers \r\n- Linux Ubuntu 16.04)\r\n- TensorFlow installed from: Conda\r\n- TensorFlow version: 1.14\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: 10.0.130/7.6.0\r\n- GPU model and memory: Nvidia TitanX 1080Ti, 12GB\r\n\r\n**a Snippet of Error message**\r\n\r\n> ERROR:tensorflow:Error converting <bound method EmbeddingSharedWeights.call of <model.EmbeddingSharedWeights object at 0x7fede45b6828>>\r\n> Traceback (most recent call last):\r\n>   File \"/home/username/data3/conda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 524, in to_graph\r\n>     return conversion.convert(entity, program_ctx)\r\n>   File \"/home/username/data3/conda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 306, in convert\r\n>     entity, program_ctx, free_nonglobal_var_names)\r\n>   File \"/home/username/data3/conda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 229, in _convert_with_cache\r\n>     entity, program_ctx)\r\n>   File \"/home/username/data3/conda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 433, in convert_entity_to_ast\r\n>     nodes, name, entity_info = convert_func_to_ast(o, program_ctx)\r\n>   File \"/home/username/data3/conda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 624, in convert_func_to_ast\r\n>     node = node_to_graph(node, context)\r\n>   File \"/home/username/data3/conda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/conversion.py\", line 667, in node_to_graph\r\n>     node = converter.apply_(node, context, return_statements)\r\n>   File \"/home/username/data3/conda3/lib/python3.7/site-packages/tensorflow/python/autograph/core/converter.py\", line 380, in apply_\r\n>     node = converter_module.transform(node, context)\r\n>   File \"/home/username/data3/conda3/lib/python3.7/site-packages/tensorflow/python/autograph/converters/return_statements.py\", line 412, in transform\r\n>     node = transformer.visit(node)\r\n>   File \"/home/username/data3/conda3/lib/python3.7/site-packages/tensorflow/python/autograph/core/converter.py\", line 317, in visit\r\n>     return super(Base, self).visit(node)\r\n>   File \"/home/username/data3/conda3/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transformer.py\", line 480, in visit\r\n>     result = super(Base, self).visit(node)\r\n>   File \"/home/username/data3/conda3/lib/python3.7/ast.py\", line 262, in visit\r\n>     return visitor(node)\r\n>   File \"/home/username/data3/conda3/lib/python3.7/site-packages/tensorflow/python/autograph/converters/return_statements.py\", line 363, in visit_FunctionDef\r\n>     converted_body = self._visit_statement_block(node, node.body)\r\n>   File \"/home/username/data3/conda3/lib/python3.7/site-packages/tensorflow/python/autograph/converters/return_statements.py\", line 287, in _visit_statement_block\r\n>     nodes = self.visit_block(nodes, after_visit=self._postprocess_statement)\r\n>   File \"/home/username/data3/conda3/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transformer.py\", line 371, in visit_block\r\n>     replacement = self.visit(node)\r\n>   File \"/home/username/data3/conda3/lib/python3.7/site-packages/tensorflow/python/autograph/core/converter.py\", line 317, in visit\r\n>     return super(Base, self).visit(node)\r\n>   File \"/home/username/data3/conda3/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transformer.py\", line 480, in visit\r\n>     result = super(Base, self).visit(node)\r\n>   File \"/home/username/data3/conda3/lib/python3.7/ast.py\", line 262, in visit\r\n>     return visitor(node)\r\n>   File \"/home/username/data3/conda3/lib/python3.7/site-packages/tensorflow/python/autograph/converters/return_statements.py\", line 237, in visit_Return\r\n>     retval=retval)\r\n>   File \"/home/username/data3/conda3/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/templates.py\", line 260, in replace\r\n>     replacements[k] = _convert_to_ast(replacements[k])\r\n>   File \"/home/username/data3/conda3/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/templates.py\", line 222, in _convert_to_ast\r\n>     return gast.Name(id=n, ctx=None, annotation=None)\r\n>   File \"/home/username/data3/conda3/lib/python3.7/site-packages/gast/gast.py\", line 19, in create_node\r\n>     format(Name, nbparam, len(Fields))\r\n> AssertionError: Bad argument number for Name: 3, expecting 4\r\n> WARNING:tensorflow:Entity <bound method EmbeddingSharedWeights.call of <model.EmbeddingSharedWeights object at 0x7fede45b6828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method EmbeddingSharedWeights.call of <model.EmbeddingSharedWeights object at 0x7fede45b6828>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\n\r\n[error.log](https://github.com/tensorflow/tensorflow/files/3660952/error.log)\r\n**Describe the expected behavior**\r\nThere should be no error messages.\r\n**a Snippet of Code to reproduce the issue**\r\n```python\r\n\r\nimport tensorflow as tf\r\n\r\n\r\nclass LayerNormalization(tf.layers.Layer):\r\n    \"\"\"Applies layer normalization.\"\"\"\r\n\r\n    def __init__(self, hidden_size):\r\n        super().__init__()\r\n        self.hidden_size = hidden_size\r\n\r\n    def build(self, input_shape):\r\n        with tf.variable_scope(\"layer_norm\"):\r\n            self.scale = tf.get_variable(\"layer_norm_scale\", [self.hidden_size], \r\n              initializer=tf.ones_initializer())\r\n            self.bias = tf.get_variable(\"layer_norm_bias\", [self.hidden_size], \r\n              initializer=tf.zeros_initializer())\r\n        self.built = True\r\n\r\n    def call(self, x, epsilon=1e-6):\r\n        mean = tf.reduce_mean(x, axis=[-1], keepdims=True)\r\n        variance = tf.reduce_mean(tf.square(x - mean), axis=[-1], keepdims=True)\r\n        norm_x = (x - mean) * tf.rsqrt(variance + epsilon)\r\n        return norm_x * self.scale + self.bias\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    x = tf.random_uniform((23, 29))\r\n    ln = LayerNormalization(29)\r\n\r\n    y = ln(x)\r\n\r\n    config = tf.ConfigProto()\r\n    config.gpu_options.allow_growth = True\r\n\r\n    sess = tf.Session(config=config)\r\n    sess.run(tf.global_variables_initializer())\r\n    sess.run(y)\r\n\r\n```\r\n", "comments": ["In order to expedite the trouble-shooting process, please provide a minimal standalone code with proper indentation to reproduce the issue reported here. Thanks!", "> \r\n> \r\n> In order to expedite the trouble-shooting process, please provide a minimal standalone code with proper indentation to reproduce the issue reported here. Thanks!\r\n\r\nI have updated a segment of standalone and reproducible code.", "#32383 \r\nHad similar issue. Using gast 0.2.2 seems to have solved it for me ", "@WingsBrokenAngel \r\nCan you please confirm if @Jonathan-Oehley's workaround is working for you by installing gast ( `pip install gast==0.2.2`).Thanks!", "> \r\n> \r\n> @WingsBrokenAngel\r\n> Can you please confirm if @Jonathan-Oehley's workaround is working for you by installing gast ( `pip install gast==0.2.2`).Thanks!\r\n\r\nThe problem has been resolved. Thanks!", "Downgrading from `gast==0.3.2` to `gast==0.2.2` also solved the problem for me", "I confirm the warning also happen to me using TF 2.0.0. Downgrading to 0.2.2 also worked.", "same here, downgraded gast to gast == 0.2.2 using ``` pip install gast==0.2.2 ``` and it resolved the issue", "Confirming for TF 1.14.0, `conda install gast=0.2.2` removed the warning.", "After installing `gast 0.2.2` (which requried uninstalling `gast 0.3.3`):\r\n\r\n```\r\n\u279c pip install \"gast==0.2.2\"\r\nProcessing /Users/dima/Library/Caches/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd/gast-0.2.2-cp37-none-any.whl\r\nInstalling collected packages: gast\r\n  Attempting uninstall: gast\r\n    Found existing installation: gast 0.3.3\r\n    Uninstalling gast-0.3.3:\r\n      Successfully uninstalled gast-0.3.3\r\nSuccessfully installed gast-0.2.2\r\n```\r\n\r\nI confirm that it helped to solve the issue.", "Hello, I followed the instructions above, uninstalled gast==0.3.3 and installed gast==0.2.2, but it shows **No module named 'gast'**. Cound anybody help me? Thanks.\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\__init__.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 73, in <module>\r\n    from tensorflow.python.ops.standard_ops import *\r\n  File \"D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\standard_ops.py\", line 25, in <module>\r\n    from tensorflow.python import autograph\r\n  File \"D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\__init__.py\", line 37, in <module>\r\n    from tensorflow.python.autograph.core.converter import ConversionOptions\r\n  File \"D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\core\\converter.py\", line 69, in <module>\r\n    from tensorflow.python.autograph.pyct import anno\r\n  File \"D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\anno.py\", line 27, in <module>\r\n    import gast\r\nModuleNotFoundError: No module named 'gast'\r\n```", "> \r\n> \r\n> Hello, I followed the instructions above, uninstalled gast==0.3.3 and installed gast==0.2.2, but it shows **No module named 'gast'**. Cound anybody help me? Thanks.\r\n> \r\n> ```\r\n> Traceback (most recent call last):\r\n>   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n>   File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n>   File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\r\n>   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\r\n>   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n>   File \"D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\__init__.py\", line 28, in <module>\r\n>     from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n>   File \"D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 73, in <module>\r\n>     from tensorflow.python.ops.standard_ops import *\r\n>   File \"D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\standard_ops.py\", line 25, in <module>\r\n>     from tensorflow.python import autograph\r\n>   File \"D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\__init__.py\", line 37, in <module>\r\n>     from tensorflow.python.autograph.core.converter import ConversionOptions\r\n>   File \"D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\core\\converter.py\", line 69, in <module>\r\n>     from tensorflow.python.autograph.pyct import anno\r\n>   File \"D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\anno.py\", line 27, in <module>\r\n>     import gast\r\n> ModuleNotFoundError: No module named 'gast'\r\n> ```\r\n\r\nPlease make sure you have installed gast to the python that the conda calls.", "> > Hello, I followed the instructions above, uninstalled gast==0.3.3 and installed gast==0.2.2, but it shows **No module named 'gast'**. Cound anybody help me? Thanks.\r\n> > ```\r\n> > Traceback (most recent call last):\r\n> >   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n> >   File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n> >   File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\r\n> >   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\r\n> >   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n> >   File \"D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\__init__.py\", line 28, in <module>\r\n> >     from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n> >   File \"D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 73, in <module>\r\n> >     from tensorflow.python.ops.standard_ops import *\r\n> >   File \"D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\standard_ops.py\", line 25, in <module>\r\n> >     from tensorflow.python import autograph\r\n> >   File \"D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\__init__.py\", line 37, in <module>\r\n> >     from tensorflow.python.autograph.core.converter import ConversionOptions\r\n> >   File \"D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\core\\converter.py\", line 69, in <module>\r\n> >     from tensorflow.python.autograph.pyct import anno\r\n> >   File \"D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\anno.py\", line 27, in <module>\r\n> >     import gast\r\n> > ModuleNotFoundError: No module named 'gast'\r\n> > ```\r\n> \r\n> Please make sure you have installed gast to the python that the conda calls.\r\n\r\nYes. I am sure gast==0.2.2 is properly installed by checking `pip show gast`\r\nIf I uninstall the gast==0.2.2 and install gast==0.3.3, it reports the warning again.\r\n`Warming tensorflow: Entity could not be transformed and will be executed as-is.`", "> \r\n> \r\n> > > Hello, I followed the instructions above, uninstalled gast==0.3.3 and installed gast==0.2.2, but it shows **No module named 'gast'**. Cound anybody help me? Thanks.\r\n> > > ```\r\n> > > Traceback (most recent call last):\r\n> > >   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n> > >   File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n> > >   File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\r\n> > >   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\r\n> > >   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n> > >   File \"D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\__init__.py\", line 28, in <module>\r\n> > >     from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n> > >   File \"D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 73, in <module>\r\n> > >     from tensorflow.python.ops.standard_ops import *\r\n> > >   File \"D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\standard_ops.py\", line 25, in <module>\r\n> > >     from tensorflow.python import autograph\r\n> > >   File \"D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\__init__.py\", line 37, in <module>\r\n> > >     from tensorflow.python.autograph.core.converter import ConversionOptions\r\n> > >   File \"D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\core\\converter.py\", line 69, in <module>\r\n> > >     from tensorflow.python.autograph.pyct import anno\r\n> > >   File \"D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\anno.py\", line 27, in <module>\r\n> > >     import gast\r\n> > > ModuleNotFoundError: No module named 'gast'\r\n> > > ```\r\n> > \r\n> > \r\n> > Please make sure you have installed gast to the python that the conda calls.\r\n> \r\n> Yes. I am sure gast==0.2.2 is properly installed by checking `pip show gast`\r\n> If I uninstall the gast==0.2.2 and install gast==0.3.3, it reports the warning again.\r\n> `Warming tensorflow: Entity could not be transformed and will be executed as-is.`\r\n\r\nYou may try\r\n`which pip`\r\n`which conda`\r\n`which python`.", "i installed gast 0.2.2 still the issue persists\r\nSystem info:\r\nOS: WIndows 8.1\r\nPython 3.7.7\r\nTensorflow 2.0\r\n\r\nWarning:\r\nWARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x00000075305C23A8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\r\nWARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x00000075305C23A8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\r\nWARNING: Entity <function _get_dataset_from_filename at 0x00000075305C23A8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\r\nWARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\r\n    'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\r\n    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\r\n})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\r\n    'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\r\n    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\r\n})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\r\nWARNING: Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\r\n    'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\r\n    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\r\n})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x00000075305C23A8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\r\nWARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x00000075305C23A8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\r\nWARNING: Entity <function _get_dataset_from_filename at 0x00000075305C23A8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\r\nWARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\r\n    'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\r\n    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\r\n})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\r\n    'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\r\n    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\r\n})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\r\nWARNING: Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\r\n    'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\r\n    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\r\n})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4", "> @WingsBrokenAngel\r\n> Can you please confirm if @Jonathan-Oehley's workaround is working for you by installing gast ( `pip install gast==0.2.2`).Thanks!\r\n\r\nfix it thy \r\n"]}, {"number": 32858, "title": "when will tensor flow support python3.7 ?", "body": "when will tenor flow support python 3.7 ? tried the installation with 2.0 , which also does not support python 3.7.", "comments": ["@devitnow15 \r\n\r\nPlease, go through #32718 and see if it helps you. Thanks!", "As given in #32718 , tried pip3 install tensorflow==2.0.0rc2 , it does not work.\r\nI am using windows10 with Pythin 3.7 , is this issue fixed for windows in tensorflow2.0 or is this fixed only for mac ?", "tf rc is available for py 3.7. What's your pip version? It requires pip >= 19.0", "using 19.2.3. , please view the attachment\r\n![tensor_flow](https://user-images.githubusercontent.com/55172847/65749660-28bc1d80-e124-11e9-9f45-ef68c6109a86.PNG)\r\n\r\n", "Is that 32-bit python? Tensorflow is available for only 64-bit python.", "Thanks for pointing out , it worked.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32858\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32858\">No</a>\n"]}, {"number": 32857, "title": "TFLite Reshape not supporting resizeInputTensor with -1", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Pixel 3, Pixel 2\r\n- TensorFlow installed from (source or binary): Anaconda\r\n- TensorFlow version (use command below): 1.14\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI am trying to deploy Deepspeech 2 with `tf.lite.experimental.nn.bidirectional_dynamic_rnn` on android. Inside the inference since the input audio is of dynamic length, I try to call `resizeInputTensor` in the c++ api on Android to match the length of the audio, which throws \r\n`tensorflow/contrib/lite/kernels/reshape.cc:58 num_input_elements != num_output_elements`\r\nsimilar to #23600. In the inference code there is a line of `reshape` which is from [-1, 1, 38, 25] to   [-1, 1, 38*25], (note that it collapses the fourth dimension but doesn't do anything with the batch dimension. After reading the source code for `reshape.cc` it seems like even if the batch size is indicated as -1, during conversion the batch size is explicitly computed and stored in the model, which is the main cause of this bug.\r\n\r\n**Describe the expected behavior**\r\n`reshape` conversion recomputes the reshape size whenever `resizeInputTensor` is called. \r\n \r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```\r\nstd::vector<int> sizes = {1, 240, 240, 3};\r\n\r\ninterpreter_->ResizeInputTensor(interpreter_->inputs()[0], sizes);\r\n\r\nif (interpreter_->AllocateTensors() != kTfLiteOk) {\r\n    LOG(INFO) << \"Failed to allocate tensors!\" << \"\\n\";\r\n    return false;\r\n```\r\nGiven that interpreter_ contains resizeops with -1 specified.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.", "comments": ["@liyunlu0618 Is a solution available for the same?? I am facing the same issue.", "@liyunlu0618  any updates?\r\n", "I think that the latest `2.3.1` version \"resolves\" the issue. When `-1` occurs in the `Reshape` parameter a chain of shapes, gathers, reshapes and concatenations is injected to dynamically compute the correct shape.\r\n- Shape to get the shape of the input tensor\r\n- Gather and Reshape to extract the batch size\r\n- Concatenate to join the extracted batch size with the other specified dimensions\r\n- Again Reshape to do an actual reshape with the dynamically computed shape\r\n\r\n**UNFORTUNATELY**\r\nThis also introduce some weird combination of `Where`, `SparseToDense` and `AddV2`, that I am yet to understand. The last op is the issue here because it is **not supported by TFLite** - this is a special version of `Add` used for `int64`.\r\n\r\nUpdate:\r\nI made this observation with an ONNX model that I can not share. I recently tried to reproduce it with a bare `tf.function` in multiple ways but I get different results. It seems like TFLite's `Reshape` actually supports `-1` as an argument but for some reason it's not properly translated in my model. Might be `onnx-tf` issue as well - I'm not sure when exactly the conversion happens (I only know that ONNX model has the correct Reshape).", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32857\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32857\">No</a>\n"]}, {"number": 32856, "title": "Fix tf.image.*_jpeg_quality docs -- they only accept single image, docs say multiple", "body": "* Update `tf.image.adjust_jpeg_quality` and `tf.image.random_jpeg_quality` docs to state that only one image (3D, not 4D) can be passed in.\r\n* Update `tf.image.random_jpeg_quality` to clarify it can also accept a 1-channel input, instead of just 3-channel..\r\n\r\nPython code showing the one-image restraints, and allowing of 1-channel input:\r\n\r\n```python\r\n>>> import tensorflow as tf\r\n>>> tf.__version__\r\n'2.0.0-rc2'\r\n>>> import numpy as np\r\n>>> tf.image.adjust_jpeg_quality(np.random.random((10, 100, 100, 3)), 75).numpy().shape\r\n<extended traceback>\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: image must be 3-dimensional[10,100,100,3] [Op:EncodeJpegVariableQuality]\r\n>>> tf.image.random_jpeg_quality(np.random.random((10, 100, 100, 3)), 75, 95).numpy().shape\r\n<extended traceback>\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: image must be 3-dimensional[10,100,100,3] [Op:EncodeJpegVariableQuality]\r\n>>> tf.image.random_jpeg_quality(np.random.random((100, 100, 1)), 75, 95).numpy().shape\r\n(100, 100, 1)\r\n```", "comments": ["cool, @alextp let me know if you need anything else from me!\r\n"]}, {"number": 32855, "title": "Hash mismatch", "body": "<em>Cannot install tensorflow on Raspberry Pi 0W v1.3 owing to hash mismatch. tag:bug_template</em>\r\n\r\n**System information**\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Raspbian Buster\r\n- TensorFlow installed from (source or binary): using pip\r\n- TensorFlow version (use command below): n/a; not installed yet\r\n- Python version: 3.7\r\n\r\n**Describe the current behavior**\r\nHash mismatch for \r\nhttps://www.piwheels.org/simple/tensorflow/tensorflow-1.13.1-cp37-none-linux_armv6l.whl#sha256=25f4ff027beec1e568baf8e90a07bad59d354560533d6b37318b9efeb70beeb1:\r\n**Describe the expected behavior**\r\nExpected sha256 25f4ff027beec1e568baf8e90a07bad59d354560533d6b37318b9efeb70beeb1\r\n\r\n**Code to reproduce the issue**\r\nGot        3aad2c162168a62adae30e226bcddfef74e5db1ca98bec1383958fb580e67123\r\n\r\n```\r\n$ python3 -m pip install tensorflow\r\nLooking in indexes: https://pypi.org/simple, https://www.piwheels.org/simple\r\nCollecting tensorflow\r\n  Downloading https://www.piwheels.org/simple/tensorflow/tensorflow-1.13.1-cp37-none-linux_armv6l.whl (87.1MB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 87.1MB 644bytes/s \r\nTHESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE. If you have updated the package versions, please update the hashes. Otherwise, examine the package contents carefully; someone may have tampered with them.\r\n    tensorflow from https://www.piwheels.org/simple/tensorflow/tensorflow-1.13.1-cp37-none-linux_armv6l.whl#sha256=25f4ff027beec1e568baf8e90a07bad59d354560533d6b37318b9efeb70beeb1:\r\n        Expected sha256 25f4ff027beec1e568baf8e90a07bad59d354560533d6b37318b9efeb70beeb1\r\n             Got        3aad2c162168a62adae30e226bcddfef74e5db1ca98bec1383958fb580e67123\r\n\r\n$ \r\n```\r\nThanks for any guidance on resolving the issue.\r\n\r\nKind regards.\r\n", "comments": ["Does this reproduce with the newer versions of TF?", "Thanks.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32855\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32855\">No</a>\n"]}, {"number": 32854, "title": "[API Docs] Add three examples for tf.data.Dataset.from_tensor_slices docs", "body": "This PR clarifies the use of `tf.data.Dataset.from_tensor_slices` with three concrete examples, which have proven useful in my explanation of the method in one of my projects.", "comments": ["> Thanks for contributing back these examples @splovyt! I left a couple comments\r\n\r\nSure thing, thanks for the review!\r\nI have applied your suggestions; let me know if there's anything else you would like to see changed."]}, {"number": 32853, "title": "[r1.15-CherryPick]: Fix licenses in C, java and python packages.", "body": "", "comments": []}, {"number": 32852, "title": "[r2.0-CherryPick]: Fix licenses in C, java and python packages.", "body": "", "comments": []}, {"number": 32851, "title": "\"/device:GPU:0\" or \"/device:XLA_GPU:0\"  ? ", "body": "When XLA is enabled with  TF_XLA_FLAGS=--tf_xla_auto_jit=2, should I see \"/device:GPU:0\" or \"/device:XLA_GPU:0\" in  Tensorflow output ?   ", "comments": ["You should ignore the XLA_GPU devices in the log output.  They are a legacy way to use XLA that we don't recommend for end users.\r\n\r\nIf TF detected a `/device:GPU:0` then you're good to go.  If not, TF (with or without `TF_XLA_FLAGS=--tf_xla_auto_jit=2`) will not use a GPU.", "@sgambient Please close this thread if it solves your question. Thanks!", "Thanks, that  addresses by concern. "]}, {"number": 32850, "title": "Support the 3D convolution ops for auto_mixed_precision", "body": "Previous TF auto_mixed_precision doesn't support 3D convolutions.\r\n\r\nSince the cuDNN enhanced the performance of 3D convolutions since v7.6.2 (https://docs.nvidia.com/deeplearning/sdk/cudnn-release-notes/rel_762.html#rel_762), this PR added the support and related tests.\r\n\r\nfyi @nluehr @benbarsdell ", "comments": ["@houtoms Could you please check reviewer comments and keep us posted. Thanks!", "Sure, working on it.", "Thx, I've made the changes. ", "Please fix the failing tests. Looks like you need to import `unittest`."]}, {"number": 32849, "title": "TFlite conversion of tf.keras model fails", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): pip install\r\n- TensorFlow version (use command below):v2.0.0-beta1-0-g8e423e3d56 2.0.0-beta1\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source): 7.4.0\r\n- CUDA/cuDNN version: No\r\n- GPU model and memory: Nvidia titan-Xp\r\n\r\n**Describe the current behavior**\r\n```\r\nimport tensorflow as tf\r\nmodel = tf.keras.models.load_model('keras_model.h5')\r\nmodel.summary()\r\nModel: \"model\"\r\n__________________________________________________________________________________________________\r\nLayer (type)                    Output Shape         Param #     Connected to\r\n==================================================================================================\r\ninput_1 (InputLayer)            [(None, 1048576)]    0\r\n__________________________________________________________________________________________________\r\nembedding (Embedding)           (None, 1048576, 8)   2056        input_1[0][0]\r\n__________________________________________________________________________________________________\r\nconv1d (Conv1D)                 (None, 2097, 128)    512128      embedding[0][0]\r\n__________________________________________________________________________________________________\r\nconv1d_1 (Conv1D)               (None, 2097, 128)    512128      embedding[0][0]\r\n__________________________________________________________________________________________________\r\nmultiply (Multiply)             (None, 2097, 128)    0           conv1d[0][0]\r\n                                                                 conv1d_1[0][0]\r\n__________________________________________________________________________________________________\r\nglobal_max_pooling1d (GlobalMax (None, 128)          0           multiply[0][0]\r\n__________________________________________________________________________________________________\r\ndense (Dense)                   (None, 128)          16512       global_max_pooling1d[0][0]\r\n__________________________________________________________________________________________________\r\ndense_1 (Dense)                 (None, 1)            129         dense[0][0]\r\n==================================================================================================\r\nTotal params: 1,042,953\r\nTrainable params: 1,042,953\r\nNon-trainable params: 0\r\n__________________________________________________________________________________________________\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n```\r\nThe converter fails to convert the model\r\n```\r\n>>> converter.convert()\r\n2019-09-26 14:39:27.048354: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n2019-09-26 14:39:27.048553: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session\r\n2019-09-26 14:39:27.065544: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize\r\n2019-09-26 14:39:27.066324: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2019-09-26 14:39:27.066655: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\nTraceback (most recent call last):\r\n  File \"/home/sridhar/PE_CSV/malenv3/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 427, in import_graph_def\r\n    graph._c_graph, serialized, options)  # pylint: disable=protected-access\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Input 0 of node model/embedding/embedding_lookup was passed float from model/embedding/embedding_lookup/Read/ReadVariableOp/resource:0 incompatible with expected resource.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/sridhar/PE_CSV/malenv3/lib/python3.6/site-packages/tensorflow/lite/python/lite.py\", line 348, in convert\r\n    self._funcs[0])\r\n  File \"/home/sridhar/PE_CSV/malenv3/lib/python3.6/site-packages/tensorflow/python/framework/convert_to_constants.py\", line 252, in convert_variables_to_constants_v2\r\n    new_output_names)\r\n  File \"/home/sridhar/PE_CSV/malenv3/lib/python3.6/site-packages/tensorflow/python/eager/wrap_function.py\", line 607, in function_from_graph_def\r\n    wrapped_import = wrap_function(_imports_graph_def, [])\r\n  File \"/home/sridhar/PE_CSV/malenv3/lib/python3.6/site-packages/tensorflow/python/eager/wrap_function.py\", line 585, in wrap_function\r\n    collections={}),\r\n  File \"/home/sridhar/PE_CSV/malenv3/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 716, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/home/sridhar/PE_CSV/malenv3/lib/python3.6/site-packages/tensorflow/python/eager/wrap_function.py\", line 80, in __call__\r\n    return self.call_with_variable_creator_scope(self._fn)(*args, **kwargs)\r\n  File \"/home/sridhar/PE_CSV/malenv3/lib/python3.6/site-packages/tensorflow/python/eager/wrap_function.py\", line 86, in wrapped\r\n    return fn(*args, **kwargs)\r\n  File \"/home/sridhar/PE_CSV/malenv3/lib/python3.6/site-packages/tensorflow/python/eager/wrap_function.py\", line 605, in _imports_graph_def\r\n    importer.import_graph_def(graph_def, name=\"\")\r\n  File \"/home/sridhar/PE_CSV/malenv3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/sridhar/PE_CSV/malenv3/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 431, in import_graph_def\r\n    raise ValueError(str(e))\r\nValueError: Input 0 of node model/embedding/embedding_lookup was passed float from model/embedding/embedding_lookup/Read/ReadVariableOp/resource:0 incompatible with expected resource.\r\n```\r\nI'm able to use the model on a python based inference engine. I'm trying to just compress the model to deploy it on smaller setup and consume via a c/c++ wrapper.", "comments": ["any update on this Were you able to fix this issue", "@codeyman I don't see any issue with tf_lite conversion of keras model in TF2.0. [Here](https://colab.sandbox.google.com/gist/jvishnuvardhan/6ff9f60fcc2245727ef380070e0951d1/tf32849.ipynb) is the gist.\r\n\r\n```\r\n!pip install tensorflow==2.0.0\r\nimport tensorflow as tf\r\nmnist = tf.keras.datasets.mnist\r\n\r\n(x_train, y_train),(x_test, y_test) = mnist.load_data()\r\nx_train, x_test = x_train / 255.0, x_test / 255.0\r\n\r\nmodel = tf.keras.models.Sequential([\r\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\r\n  tf.keras.layers.Dense(128, activation='relu'),\r\n  tf.keras.layers.Dropout(0.2),\r\n  tf.keras.layers.Dense(10, activation='softmax')\r\n])\r\n\r\nmodel.compile(optimizer='adam',\r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\nmodel.fit(x_train, y_train, epochs=5)\r\nmodel.evaluate(x_test, y_test)\r\nmodel.save(\"keras_model.h5\")\r\n\r\nnew_model=tf.keras.models.load_model(\"keras_model.h5\")\r\nnew_model.summary()\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(new_model)\r\ntflite_model = converter.convert()\r\nopen(\"converted_model.tflite\", \"wb\").write(tflite_model)\r\n```\r\n\r\nI am closing this issue. Please feel free to open it if the issue persists with TF2.0. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32849\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32849\">No</a>\n", "Could you please use the model from the summary that I provided? I understand that it works on the sample code. Can you please try with the same layers?", "@codeyman Can you please create the model and follow the steps I mentioned in the code I shared. If there is any issue, please create a colab gist and share it here. Thanks!", "@jvishnuvardhan Please look at my bug creation code. It is exactly the same:\r\nimport tensorflow as tf\r\nmodel = tf.keras.models.load_model('keras_model.h5')\r\nmodel.summary()\r\nconverter.convert() <-- This throws the error\r\n", "@codeyman Could you share a standalone code to reproduce the issue? I cannot run your code as I don't have `keras_model.h5` and also you didn't instantiate `converter`. Please provide entire standalone code to proceed further in resolving the issue. Thanks!", "@jvishnuvardhan Please see the standalone code [Here](https://colab.research.google.com/drive/1F1F3wp0QFOs7UKVk6J7t42UdU2ccurfW).", "@jvishnuvardhan Can you please reopen this issue?", "@codeyman I could reproduce the issue. I think this is more related to `embedding`. Were you able to train this model without any issues? Thanks!", "@jvishnuvardhan Yeah, no issues while training. Note that is the standard malconv model: https://arxiv.org/pdf/1710.09435.pdf", "Any news on this? We are running into the same issue with a network using an embedding layer.", "We encountered a very similar issue in our model and it is consistent in tf2.0 official release, but it looks it is gone in the latest TF-nightly build.", "Closing this issue because the code snippet in https://github.com/tensorflow/tensorflow/issues/32849#issuecomment-539646714 works on the nightly (`pip install tf-nightly`).\r\n\r\n@codeyman Please request to reopen if you experience additional problems.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32849\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32849\">No</a>\n", "@gargn Could you please provide the bug that fixes this issue? I have to compile tensorflow on my setup and I'd like to just cherry-pick just this changeset over the tf-2.0 release.", "> Closing this issue because the code snippet in [#32849 (comment)](https://github.com/tensorflow/tensorflow/issues/32849#issuecomment-539646714) works on the nightly (`pip install tf-nightly`).\r\n> \r\n> @codeyman Please request to reopen if you experience additional problems.\r\n\r\nwhat if I need Tensorflow 1.11.0 for example? I cannot just `pip install tf-nightly`, because my customer's code is not compatible with tf 2.x.", "I am getting this exception in 2.3.0. There seems to be a workaround (see https://github.com/usimarit/TiramisuASR/blob/main/tiramisu_asr/models/layers/embedding.py) but I am not a big fan of having my own Embedding-layer implementation in my code. Is there another way?", "Any exact solutions? Meet the same issue for LSTM."]}, {"number": 32848, "title": "[r1.15-CherryPick]: Allow MLIR external repository to be created from non-tensorflow repository.", "body": "TF serving repo needs this to release its 1.15.", "comments": []}, {"number": 32847, "title": "Add a unit test for training and validation callbacks", "body": "The test is to check that the progress bar shown by Keras during the training process is working properly when training and validating with inputs of unknown sizes.", "comments": ["Can you verify that progress bar logger looks good and works as expected? i remember trying this and something was failing, don't recall what now. ", "Well, I tried with the same code as the one I wrote in #32819, and it worked as expected. However, I don\u2019t think I\u2019m in the position to guarantee that it doesn\u2019t break anything. I assumed the test suite would catch if there had been any problems.", "Sounds good, can you add a test case for the two Dataset use case you tested in callbacks_test? There are existing unit tests that check Progbar, may be we can add something similar for this case?", "The current status is that all tests in `keras` pass with the proposed change:\r\n\r\n```\r\nbazel test //tensorflow/python/keras/...\r\n...\r\nExecuted 151 out of 152 tests: 152 tests pass.\r\nINFO: Build completed successfully, 771 total actions\r\n```\r\n\r\n(There was apparently one skipped, but I suspect it was due to a previous run.)\r\n\r\nI will then add a test, as it was suggested.", "Thank you for adding the test, can you confirm that the test you added fails without the change?", "I did the following on master (earlier I reported results with respect to what comes with `tensorflow/tensorflow:devel-py3` without pulling).\r\n\r\nWithout any changes and any new tests, the following one was failing under `keras`:\r\n\r\n```\r\nbazel test //tensorflow/python/keras/...\r\n...\r\n//tensorflow/python/keras/distribute:multi_worker_fault_tolerance_test   FAILED in 14 out of 14 in 9.2s\r\n...\r\nExecuted 152 out of 152 tests: 151 tests pass and 1 fails locally.\r\nINFO: Build completed, 1 test FAILED, 16920 total actions\r\n```\r\n\r\nI assumed it was irrelevant.\r\n\r\nThen I focused on `keras:callbacks_test`, added the test there, and got a failure:\r\n\r\n```\r\nbazel test //tensorflow/python/keras:callbacks_test\r\n...\r\n//tensorflow/python/keras:callbacks_test                                 FAILED in 3 out of 4 in 38.8s\r\n...\r\nINFO: Build completed, 1 test FAILED, 5 total actions\r\n```\r\n\r\n```\r\n[ RUN      ] KerasCallbacksTest.test_progbar_logging_training_validation_v1_session_sequential\r\n[  FAILED  ] KerasCallbacksTest.test_progbar_logging_training_validation_v1_session_sequential\r\n[ RUN      ] KerasCallbacksTest.test_progbar_logging_training_validation_v2_eager_subclass\r\n[       OK ] KerasCallbacksTest.test_progbar_logging_training_validation_v2_eager_subclass\r\n[ RUN      ] KerasCallbacksTest.test_progbar_logging_training_validation_v2_function_functional\r\n[       OK ] KerasCallbacksTest.test_progbar_logging_training_validation_v2_function_functional\r\n```\r\n\r\nHowever, it was due to a different reason (not what the test was asserting):\r\n\r\n```\r\n  File \"\u2026/tensorflow/python/keras/callbacks_test.py\", line 352, in test_progbar_logging_training_validation\r\n    steps_per_epoch=20)\r\n...\r\nValueError: When using data tensors as input to a model, you should specify the `steps_per_epoch` argument.\r\n```\r\n\r\nIt complained that `steps_per_epoch` was not given, but it was. I thought it was due to a bug or lack of support in version 1, since it was coming from `training.py`, not `training_v2.py` (the latter is what this pull request makes an adjustment to). I forced the test to exclusion version 1:\r\n\r\n```python\r\n@keras_parameterized.run_all_keras_modes(always_skip_v1=True)\r\n```\r\n\r\nStill without any changes outside the tests, the new test succeeded. I confirmed that the test was properly executed by changing the expected output and seeing it fail.\r\n\r\nI thought it was fixed on master and checked out `v1.15.0-rc1`. Without any changes and any new tests, there was already one failure:\r\n\r\n```python\r\nbazel test //tensorflow/python/keras/...\r\n...\r\n//tensorflow/python/keras:callbacks_test                                 FAILED in 4 out of 4 in 61.1s\r\n...\r\nExecuted 153 out of 153 tests: 152 tests pass and 1 fails locally.\r\nINFO: Build completed, 1 test FAILED, 10644 total actions\r\n```\r\n\r\nAnd it was `test_progbar_logging_validation_split`, which the new test was actually based on. The new test with `always_skip_v1=True` gave the following:\r\n\r\n```\r\n[ RUN      ] KerasCallbacksTest.test_progbar_logging_training_validation_v2_eager_sequential\r\n[  FAILED  ] KerasCallbacksTest.test_progbar_logging_training_validation_v2_eager_sequential\r\n[ RUN      ] KerasCallbacksTest.test_progbar_logging_training_validation_v2_funcgraph_subclass\r\n[       OK ] KerasCallbacksTest.test_progbar_logging_training_validation_v2_funcgraph_subclass\r\n```\r\n\r\nAnd it was, as expected, due to `AssertionError: Regex didn't match\u2026`. Then I changed the calculation of `validation_callbacks`, as shown in the patch, and got the following:\r\n\r\n```\r\n[ RUN      ] KerasCallbacksTest.test_progbar_logging_training_validation_v2_eager_sequential\r\n[       OK ] KerasCallbacksTest.test_progbar_logging_training_validation_v2_eager_sequential\r\n[ RUN      ] KerasCallbacksTest.test_progbar_logging_training_validation_v2_funcgraph_subclass\r\n[       OK ] KerasCallbacksTest.test_progbar_logging_training_validation_v2_funcgraph_subclass\r\n```\r\n\r\n(`test_progbar_logging_validation_split` was failing as before.)\r\n\r\nIn summary, the proposed change fixes a bug in 1.15.0-rc1 but doesn\u2019t seem to be needed for what is on the master branch. I think this is the following commit fixed it: https://github.com/tensorflow/tensorflow/commit/327c5bee1a7d28d75f46a747669e605f4753eecb.\r\n\r\nSo what do we do with all this? The change doesn\u2019t affect master; then it\u2019s probably better to do not touch if it\u2019s not broken. The test might be helpful still, though.", "Thank you for the detailed notes, i agree about adding the test case since it will be useful and we can call the issue done. ", "I\u2019ve rebased and removed the first commit.", "Done!", "I\u2019ve looked through the failed builds, and one was them was due to the new code. There was incorrect indentation on two lines. Fixed.", "Seems auto-merge is not happening but the changes are now committed so we can close this. Thank you for the PR."]}, {"number": 32846, "title": "Un-blacklist Softmax & Log in auto_mixed_precision", "body": "- These ops have no dynamic-range issues in their outputs, and their implementations are accurate in DT_HALF, so we consider them safe to convert.\r\n- Softmax is used in the trunk of some popular models (e.g., attention), so this change may improve performance in those cases.\r\n- This commit also adds tests for these ops as well as all of the other graylisted activation-like functions.\r\n\r\ncc @nluehr @reedwm ", "comments": []}, {"number": 32845, "title": "tensorboard connection problem", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Ubuntu 18.04**\r\n- TensorFlow installed from (source or binary): pip (docker)\r\n- TensorFlow version: 1.13.2\r\n- Python version: 3\r\n- Installed using virtualenv? pip? conda?: pip\r\n- CUDA/cuDNN version:10.1\r\n- GPU model and memory: Quadro P3000\r\n\r\nGood afternoon!\r\n\r\nI am using the tensorflow image from [docker](https://hub.docker.com/r/tensorflow/tensorflow/tags?page=1&name=1.13) and am having trouble getting tensorboard to run in my container.  I run the following command to start the container:\r\n\r\n`\r\nsudo docker container run -p 8888:8888 -p 6006:6006 -it --rm --runtime=nvidia -v $(pwd):/opt/ -v $(pwd)/:/tf/ '$image-name\r\n`\r\nWhen I run my trial notebook, I get the following error image (see attached file).  I'm not sure what I'm doing wrong.  If I need to provide more I will.  Thank you!\r\n\r\n\r\n![issue](https://user-images.githubusercontent.com/40045042/65709154-cac10480-e055-11e9-88d1-f4d7dfe00351.png)\r\n", "comments": ["@spiegelss What browser are you using? I cannot point you out to the exact cause of the issue but the issue mostly with your browser.", "I am using firefox.  I will check if it's my ad block.  I forgot I had that on.  ", "@spiegelss Does your issue still persists or is it resolved?", "Closing this issue as it has been resolved", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32845\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32845\">No</a>\n", "I have the same problem but w/ TF2.0-GPU, and I am on Chrome/Ubuntu, running it inside a docker container w/ juypter, miniconda, cuda-x, tensorrt. The error I get says: The connection was reset when trying to display it in the notebook, despite everything else working fine. (I'm not sure, but even when I goto localhost:6006 it doesn't load either).\r\n\r\n**Error 1:**\r\n![1](https://user-images.githubusercontent.com/5199900/66453018-6f651e00-ea28-11e9-8db4-6961c3cd15cc.png)\r\n\r\n**Error 2:**\r\n![2](https://user-images.githubusercontent.com/5199900/66453028-7be97680-ea28-11e9-890a-ec46d30abe9b.png)\r\n\r\n**Dockerfile:**\r\n```\r\nFROM nvidia/cuda:10.0-cudnn7-devel-ubuntu18.04\r\n\r\n# Core Linux Deps\r\nRUN DEBIAN_FRONTEND=noninteractive apt-get update && apt-get install -y --fix-missing --no-install-recommends apt-utils \\\r\n        build-essential \\\r\n        curl \\\r\n\tbinutils \\\r\n\tgdb \\\r\n        git \\\r\n\tfreeglut3 \\\r\n\tfreeglut3-dev \\\r\n\tlibxi-dev \\\r\n\tlibxmu-dev \\\r\n\tgfortran \\\r\n        pkg-config \\\r\n\tpython-numpy \\\r\n\tpython-dev \\\r\n\tpython-setuptools \\\r\n\tlibboost-python-dev \\\r\n\tlibboost-thread-dev \\\r\n        pbzip2 \\\r\n        rsync \\\r\n        software-properties-common \\\r\n        libblas3 \\\r\n        liblapack3 \\\r\n        liblapack-dev \\\r\n        libblas-dev \\\r\n        libboost-all-dev \\\r\n        libopenblas-dev \\ \r\n        libtbb2 \\\r\n        libtbb-dev \\\r\n        libjpeg-dev \\\r\n        libpng-dev \\\r\n        libtiff-dev \\\r\n\tlibgraphicsmagick1-dev \\\r\n        libavresample-dev \\\r\n        libavformat-dev \\\r\n        libhdf5-dev \\\r\n        libpq-dev \\\r\n\tlibgraphicsmagick1-dev \\\r\n\tlibavcodec-dev \\\r\n\tlibgtk2.0-dev \\\r\n\tliblapack-dev \\\r\n        liblapacke-dev \\\r\n\tlibswscale-dev \\\r\n\tlibcanberra-gtk-module \\\r\n        libboost-dev \\\r\n\tlibboost-all-dev \\\r\n        libeigen3-dev \\\r\n\twget \\\r\n        vim \\\r\n        qt5-default \\\r\n        unzip \\\r\n\tzip \\ \r\n        && \\\r\n    apt-get clean && \\\r\n    rm -rf /var/lib/apt/lists/*  && \\\r\n    apt-get clean && rm -rf /tmp/* /var/tmp/*\r\n\r\n\r\n# Install cmake version that supports anaconda python path\r\nRUN wget -O cmake.tar.gz https://github.com/Kitware/CMake/releases/download/v3.15.4/cmake-3.15.4-Linux-x86_64.tar.gz\r\nRUN tar -xvf cmake.tar.gz\r\nWORKDIR /cmake-3.15.4-Linux-x86_64\r\nRUN cp -r bin /usr/\r\nRUN cp -r share /usr/\r\nRUN cp -r doc /usr/share/\r\nRUN cp -r man /usr/share/\r\nWORKDIR /\r\nRUN rm -rf cmake-3.15.4-Linux-x86_64\r\nRUN rm -rf cmake.tar.gz\r\n\r\n\r\n# Install TensorRT (TPU Access)\r\nRUN apt-get update && \\\r\n        apt-get install -y nvinfer-runtime-trt-repo-ubuntu1804-5.0.2-ga-cuda10.0 && \\\r\n        apt-get update && \\\r\n        apt-get install -y libnvinfer5=5.0.2-1+cuda10.0\r\n\r\nRUN file=\"$(ls -1 /usr/local/)\" && echo $file\r\n\r\n\r\n# Fix conda errors per Anaconda team until they can fix\r\nRUN mkdir ~/.conda\r\n\r\n\r\n# Install Anaconda\r\nRUN wget --quiet https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh && \\\r\n/bin/bash Miniconda3-latest-Linux-x86_64.sh -f -b -p /opt/conda && \\\r\nrm Miniconda3-latest-Linux-x86_64.sh\r\nENV PATH /opt/conda/bin:$PATH\r\n\r\n\r\n# For CUDA profiling, TensorFlow requires CUPTI.\r\nENV LD_LIBRARY_PATH /usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH\r\n\r\nARG PYTHON=python3\r\nARG PIP=pip3\r\n\r\n# See http://bugs.python.org/issue19846\r\nENV LANG C.UTF-8\r\n\r\nRUN apt-get update && apt-get install -y \\\r\n    ${PYTHON} \\\r\n    ${PYTHON}-pip\r\n\r\nRUN ${PIP} --no-cache-dir install --upgrade \\\r\n    pip \\\r\n    setuptools \\\r\n    hdf5storage \\\r\n    h5py \\\r\n    matplotlib \\\r\n    pyinstrument\r\n\r\n# Add auto-complete to Juypter\r\nRUN pip install jupyter-tabnine\r\nRUN pip install pydash\r\n\r\nRUN conda update -n base -c defaults conda\r\nRUN conda install -c anaconda jupyter \r\nRUN conda install pytorch torchvision cudatoolkit=10.0 -c pytorch\r\nRUN conda update conda\r\nRUN conda install numba\r\nRUN conda install -c anaconda cupy \r\nRUN conda install -c anaconda ipykernel \r\nRUN conda install -c anaconda seaborn \r\nRUN conda install -c anaconda ipython \r\n\r\n\r\n# Some TF tools expect a \"python\" binary\r\nRUN ln -s $(which ${PYTHON}) /usr/local/bin/python \r\n\r\nRUN pip install tf-nightly-gpu-2.0-preview\r\n#RUN pip install tensorflow-gpu\r\n\r\n#COPY bashrc /etc/bash.bashrc\r\n#RUN chmod a+rwx /etc/bash.bashrc\r\n\r\nRUN ${PIP} --no-cache-dir install jupyter  \r\n\r\n\r\nWORKDIR /\r\nRUN wget -O opencv.zip https://github.com/opencv/opencv/archive/master.zip\r\nRUN wget -O opencv_contrib.zip https://github.com/opencv/opencv_contrib/archive/master.zip\r\nRUN unzip opencv.zip\r\nRUN unzip opencv_contrib.zip\r\nRUN mv opencv-master opencv\r\nRUN mv opencv_contrib-master opencv_contrib\r\nRUN mkdir /opencv/build\r\nWORKDIR /opencv/build\r\n\r\nRUN cmake -DBUILD_TIFF=ON \\\r\n\t\t  -DBUILD_opencv_java=OFF \\\r\n\t\t  -DWITH_CUDA=ON \\\r\n\t\t  -DENABLE_FAST_MATH=1 \\\r\n\t\t  -DCUDA_FAST_MATH=1 \\\r\n\t\t  -DWITH_CUBLAS=1 \\\r\n\t\t  -DENABLE_AVX=ON \\\r\n\t\t  -DWITH_OPENGL=ON \\\r\n\t\t  -DWITH_OPENCL=OFF \\\r\n\t\t  -DWITH_IPP=ON \\\r\n\t\t  -DWITH_TBB=ON \\\r\n\t\t  -DWITH_EIGEN=ON \\\r\n\t\t  -DWITH_V4L=ON \\\r\n\t\t#   -DBUILD_TESTS=OFF \\\r\n\t\t#   -DBUILD_PERF_TESTS=OFF \\\r\n\t\t  -DCMAKE_BUILD_TYPE=RELEASE \\\r\n\t\t  -DCMAKE_INSTALL_PREFIX=$(python -c \"import sys; print(sys.prefix)\") \\\r\n\t\t  -D PYTHON3_EXECUTABLE=$(which python3) \\\r\n                  -D PYTHON_INCLUDE_DIR=$(python3 -c \"from distutils.sysconfig import get_python_inc; print(get_python_inc())\") \\\r\n                  -D PYTHON_INCLUDE_DIR2=$(python3 -c \"from os.path import dirname; from distutils.sysconfig import get_config_h_filename; print(dirname(get_config_h_filename()))\") \\\r\n                  -D PYTHON_LIBRARY=$(python3 -c \"from distutils.sysconfig import get_config_var;from os.path import dirname,join ; print(join(dirname(get_config_var('LIBPC')),get_config_var('LDLIBRARY')))\") \\\r\n                  -D PYTHON3_PACKAGES_PATH=$(python3 -c \"from distutils.sysconfig import get_python_lib; print(get_python_lib())\") \\\r\n                  -DOPENCV_ENABLE_NONFREE=ON \\\r\n                  -DOPENCV_EXTRA_MODULES_PATH=/opencv_contrib/modules \\\r\n                  -DBUILD_EXAMPLES=ON \\\r\n                  -D CUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda-10.0 \\\r\n                  -DWITH_QT=ON ..\r\n                 \r\nRUN make -j4 \\\r\n        && make install \\\r\n\t&& rm /opencv.zip \\\r\n        && rm /opencv_contrib.zip \\\r\n\t&& rm -rf /opencv \\\r\n        && rm -rf /opencv_contrib\r\n\r\n\r\nWORKDIR /\r\n\r\n\r\n# dlib\r\nRUN cd ~ && \\\r\n    mkdir -p dlib && \\\r\n    git clone -b 'v19.16' --single-branch https://github.com/davisking/dlib.git dlib/ && \\\r\n    cd  dlib/ && \\\r\n    python3 setup.py install --yes USE_AVX_INSTRUCTIONS --yes DLIB_USE_CUDA --clean\r\n\r\n\r\nRUN mkdir /.local && chmod a+rwx /.local\r\n\r\nWORKDIR /tf\r\nEXPOSE 8888 6006\r\n\r\n\r\nRUN useradd -ms /bin/bash container_user\r\n\r\n\r\nRUN ${PYTHON} -m ipykernel.kernelspec\r\n\r\n\r\nCMD [\"bash\", \"-c\", \"source /etc/bash.bashrc && jupyter notebook --notebook-dir=/tf --ip 0.0.0.0 --no-browser --allow-root --NotebookApp.custom_display_url='http://localhost:8888'\"]\r\n\r\n```"]}, {"number": 32844, "title": "RPi0W - no go", "body": "<em>Using instructions at [https://www.tensorflow.org/lite/guide/build_rpi](https://www.tensorflow.org/lite/guide/build_rpi )for installation on Raspberry Pi Zero W v1.3. Perhaps impractical owing to ARMv6 processor rev 7 (v6l)</em>\r\n\r\n**System information**\r\nprocessor\t: 0\r\nmodel name\t: ARMv6-compatible processor rev 7 (v6l)\r\nBogoMIPS\t: 697.95\r\nFeatures\t: half thumb fastmult vfp edsp java tls \r\nCPU implementer\t: 0x41\r\nCPU architecture: 7\r\nCPU variant\t: 0x0\r\nCPU part\t: 0xb76\r\nCPU revision\t: 7\r\n\r\nHardware\t: BCM2835\r\nRevision\t: 9000c1\r\n\r\n- Linux 4.19.66+ #1253 Thu Aug 15 11:37:30 BST 2019 armv6l GNU/Linux\r\n\r\n- TensorFlow installed from (source or binary): [source](https://github.com/tensorflow/tensorflow))\r\n- TensorFlow version: sorry, don't know :(\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: [script](./tensorflow/lite/tools/make/download_dependencies.sh)\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): gcc as in Raspbian Buster (no user mods)\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory:\r\n\r\n```\r\nMemTotal:         443080 kB\r\nMemFree:          160252 kB\r\nMemAvailable:     327036 kB\r\n```\r\n\r\n**Describe the problem**\r\n\r\n**sh\r\n+ set -e\r\n+++ dirname ./tensorflow/lite/tools/make/build_rpi_lib.sh\r\n++ cd ./tensorflow/lite/tools/make\r\n++ pwd\r\n+ SCRIPT_DIR=/home/pi/projects/tensorflow/tensorflow/lite/tools/make\r\n+ TENSORFLOW_DIR=/home/pi/projects/tensorflow/tensorflow/lite/tools/make/../../../..\r\n+ make -j 4 TARGET=rpi -C /home/pi/projects/tensorflow/tensorflow/lite/tools/make/../../../.. -f tensorflow/lite/tools/make/Makefile\r\nmake: Entering directory '/home/pi/projects/tensorflow'\r\nmake: Nothing to be done for 'all'.\r\nmake: Leaving directory '/home/pi/projects/tensorflow'\r\n**\r\n\r\n**Any other info / logs**\r\nWill be glad to provide any upon specific request because I really don't know what is happening beneath the covers of the installation script\r\n", "comments": ["You may try installing pre-built TF-Pi0 wheels . See [packages](https://www.tensorflow.org/install/pip#package-location).\r\nThanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32844\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32844\">No</a>\n"]}, {"number": 32843, "title": "TF-TRT 3D pooling", "body": "Allow conversion of AvgPool3D and MaxPool3D ops for TensorRT offload. TensorRT 6+ supports these operators. In medical imaging applications 3D convolutions are often paired with 3D pooling. Since https://github.com/tensorflow/tensorflow/commit/a2fa0c58dcd81307a3eac76ccc2b81a42b71583c 3D convolutions can be offloaded to TRT 6+ and this change allows offloading 3D pooling too. This PR allows to run 3D U-Nets through TF-TRT.", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F32843) for more info**.\n\n<!-- need_author_cla -->", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F32843) for more info**.\n\n<!-- ok -->", "Thanks @ralovich for the PR.\r\nI only had a small comment.", "Dear @aaroey and @pooyadavoodi , all points should be addressed now. Could you please verify?"]}, {"number": 32842, "title": "Using Dataset.map with python dicts as dataset elements passes Tensors without numpy values to the mapping function", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **YES**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Windows 10**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): **Pycharm, pip-install**\r\n- TensorFlow version (use command below): **v2.0.0-rc1-51-g2646d23074 2.0.0-rc2**\r\n- Python version: **3.6**\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nI'm doing a simple pipeline where I load a dataset from a csv file, convert the dataset to a dict structure (where one element of the dataset is a dict with strings as keys and tf.Tensor as values) and then try to use this resulting dataset. The issue is that, when I create the dict-based dataset, I can see that the numpy values are there in the Tensors, BUT when I use Dataset.map to apply a function to the dict-based dataset, I can't access the numpy values inside this function. The numpy values \"\"disappear\"\".\r\n\r\n**Describe the expected behavior**\r\n\r\nI should be able to see and use the numpy values.\r\n\r\n**Code to reproduce the issue**\r\n\r\nIMPORTANT: replace the TODO in the beginning of the code with the path that the csv I provided after the code, below, will have in your system.\r\n\r\n```\r\nimport os\r\nimport tensorflow as tf\r\n\r\n#TODO REPLACE THE LINE BELOW BY ONE THAT DESCRIBES THE PATH OF THE CSV IN YOUR SYSTEM\r\ndata_source = os.path.join(\".\", \"Data\", \"mini.csv\")\r\n\r\n#Help function to convert tuples of Tensors to dicts, so I have the column names from the csv as keys\r\ndef _convert_to_dict(*el):\r\n    base_list = [\"var1\", \"var2\", \"var3\"] #as in the csv header\r\n    dicto = dict()\r\n    for i in range(len(base_list)):\r\n        dicto[base_list[i]] = el[i]\r\n    return dicto\r\n\r\n#Simple function which will try to investigate and use the numpy values inside the Tensors in the datapoints\r\ndef _use_dict(dicto, key):\r\n    \"\"\"\r\n    dicto: dict with string keys and Tensors as values\r\n    :param key: a specific string key\r\n    :return:\r\n    \"\"\"\r\n    print(\"Printing inspections from _use_dict function\")\r\n    print(dicto) #Here we print the dataset element passed to the function, which is a dictionary, and see that no numpy value is associated with the Tensors\r\n    print(dicto[key]) #We look closer, no numpy values\r\n    print(dicto[key].numpy()) #No numpy value, so we get an exception here\r\n    return None\r\n\r\ndef load_and_preprocess_dataset(): #Main function which will load the dataset from csv and transform to a dict-like structure\r\n    #Load the dataset from CSV\r\n    dataset = tf.data.experimental.CsvDataset(\r\n        header=True,\r\n        filenames=data_source,\r\n        record_defaults=[\r\n            tf.int64,\r\n            tf.string,\r\n            tf.float64,\r\n        ]\r\n    )\r\n    #Convert each element from the dataset from a tuple of Tensors to a dict with keys being the csv header values, and values being the corresponding Tensors\r\n    dataset = dataset.map(map_func=_convert_to_dict)\r\n    #Here we inspect the values of the dataset, and observe that the Tensors contain numpy values\r\n    print(\"Printing dataset elements after transforming to dict-like structure\")\r\n    for a in dataset:\r\n        print(a)\r\n    #Here we try to apply a function which accepts a dict-like structured dataset element as input\r\n    dataset = dataset.map(map_func=lambda x: _use_dict(dicto=x, key=\"var1\"))\r\n    return dataset\r\n\r\nif __name__ == '__main__':\r\n    dataset = load_and_preprocess_dataset()\r\n```\r\n\r\nCsv file content:\r\n\r\n```\r\nvar1,var2,var3\r\n2,\"foo\",1.3\r\n3,\"bar\",1.5\r\n4,\"barfoo\",1.8\r\n```\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\nStack trace:\r\n\r\n2019-09-26 16:49:14.948332: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\nPrinting dataset elements after transforming to dict-like structure\r\n{'var1': <tf.Tensor: id=27, shape=(), dtype=int64, numpy=2>, 'var2': <tf.Tensor: id=28, shape=(), dtype=string, numpy=b'foo'>, 'var3': <tf.Tensor: id=29, shape=(), dtype=float64, numpy=1.3>}\r\n{'var1': <tf.Tensor: id=30, shape=(), dtype=int64, numpy=3>, 'var2': <tf.Tensor: id=31, shape=(), dtype=string, numpy=b'bar'>, 'var3': <tf.Tensor: id=32, shape=(), dtype=float64, numpy=1.5>}\r\n{'var1': <tf.Tensor: id=33, shape=(), dtype=int64, numpy=4>, 'var2': <tf.Tensor: id=34, shape=(), dtype=string, numpy=b'barfoo'>, 'var3': <tf.Tensor: id=35, shape=(), dtype=float64, numpy=1.8>}\r\nPrinting inspections from _use_dict function\r\n{'var1': <tf.Tensor 'args_0:0' shape=() dtype=int64>, 'var2': <tf.Tensor 'args_1:0' shape=() dtype=string>, 'var3': <tf.Tensor 'args_2:0' shape=() dtype=float64>}\r\nTensor(\"args_0:0\", shape=(), dtype=int64)\r\nTraceback (most recent call last):\r\n  File \"...temp.py\", line 50, in <module>\r\n    dataset = load_and_preprocess_dataset()\r\n  File \"...temp.py\", line 46, in load_and_preprocess_dataset\r\n    dataset = dataset.map(map_func=lambda x: _use_dict(dicto=x, key=\"var1\"))\r\n  File \"...site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 1211, in map\r\n    return MapDataset(self, map_func, preserve_cardinality=True)\r\n  File \"...site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 3416, in __init__\r\n    use_legacy_function=use_legacy_function)\r\n  File \"...site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 2695, in __init__\r\n    self._function = wrapper_fn._get_concrete_function_internal()\r\n  File \"...site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1854, in _get_concrete_function_internal\r\n    *args, **kwargs)\r\n  File \"...site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1848, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"...site-packages\\tensorflow_core\\python\\eager\\function.py\", line 2150, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"...site-packages\\tensorflow_core\\python\\eager\\function.py\", line 2041, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"...site-packages\\tensorflow_core\\python\\framework\\func_graph.py\", line 915, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"...site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 2689, in wrapper_fn\r\n    ret = _wrapper_helper(*args)\r\n  File \"...site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 2634, in _wrapper_helper\r\n    ret = autograph.tf_convert(func, ag_ctx)(*nested_args)\r\n  File \"...site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\", line 237, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nAttributeError: in converted code:\r\n    relative to ...:\r\n\r\n    temp.py:46 None  *\r\n        dataset = dataset.map(map_func=lambda x: _use_dict(dicto=x, key=\"var1\"))\r\n    temp.py:25 _use_dict  *\r\n        print(dicto[key].numpy()) #No numpy value, so we get an exception here\r\n\r\n    AttributeError: 'Tensor' object has no attribute 'numpy'\r\n\r\n\r\nProcess finished with exit code 1\r\n\r\n```\r\n", "comments": ["I wonder if it is related to the closed (but maybe not solved?) issue https://github.com/tensorflow/tensorflow/issues/27519", "Try this on top-\r\n**tf.enable_eager_execution()**\r\n", "@Efaq ,\r\nCan you try @AkashNagaraj suggestion? Thanks!", "@AkashNagaraj @oanush Tried it now, and I'm getting:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"...\", line 3, in <module>\r\n    tf.enable_eager_execution()\r\nAttributeError: module 'tensorflow' has no attribute 'enable_eager_execution'\r\n\r\nProcess finished with exit code 1\r\n```\r\n\r\nI'm in Tensorflow 2.0 rc2, so I supposed the eager execution would be enabled by default. Shouldn't it be the case?\r\n\r\nAlso,` tf.executing_eagerly()` returns `True`, what would make me believe that I'm already in eager execution.\r\n\r\nThank you for the help!", "@oanush just noticed that you labeled this issue as **rc0**, while I have the version **v2.0.0-rc1-51-g2646d23074 2.0.0-rc2**", "I was able to replicate the issue for TF-2.0rc2 and TF-nightly-2.0-preview, kindly find the [gist](https://colab.sandbox.google.com/gist/oanush/7cb7982ed907c4ed4f534fb029a904e3/32842.ipynb) of colab.Thanks!", "> @oanush just noticed that you labeled this issue as **rc0**, while I have the version **v2.0.0-rc1-51-g2646d23074 2.0.0-rc2**\r\n\r\n@Efaq ,\r\nWe just have 2.0rc0 label available now as the latest version in Github.", "@oanush alright!", "This is expected behavior. tf.data traces all of its user-defined functions and data objects observable by user-defined functions will be `Tensor`s and not `EagerTensor`s (and `Tensor`s do not have `.numpy()`). If you would like to execute (a subset of) tf.data user-defined function in eager mode, use [py_function](https://www.tensorflow.org/api_docs/python/tf/py_function). Note that the use of `py_function` has limitations, including no parallel execution (because of GIL) and precluding TensorFlow from applying static optimizations to your program.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32842\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32842\">No</a>\n", "@jsimsa Alright, thanks! Could you please exemplify how to change the code provided in order to correctly run eagerly?\r\n\r\nI was really expecting that TF 2.0, when saying it has eager execution by default, would really execute the whole code eagerly, and not only parts of it...", "@Efaq How did you resolve this issue?", "@AlbinDavid I haven't. Asked some extra help from @jsimsa above but haven't gotten an example.\r\n\r\nMore specifically, after 2 years dealing with Tensorflow and more recently with Tensorflow Extended, I changed my attention to scikit-learn and pure Keras and I have never been happier. So if you are not tied to very high performance, I would recommend considering the same.\r\n\r\nCheers", "@Efaq thanks for your response", "https://github.com/tensorflow/tensorflow/issues/30653", "Following code worked:\r\n\r\n    def parse_str(str_tensor):\r\n        raw_string = str_tensor.numpy().decode(\"utf-8\") \r\n    \r\n        # play with raw string\r\n        raw_string = 'AAA'+raw_string     \r\n        return raw_string\r\n    \r\n\r\nCall parse function:\r\n\r\n\r\n    def tf_pre_processing(row):\r\n      return tf.py_function(parse_str, [row['context']], [tf.string])\r\n    \r\n    \r\n    train = t.map(tf_pre_processing).batch(1).take(1)\r\n    \r\n    list(train)\r\n\r\n"]}, {"number": 32841, "title": "Problems running mnist_estimator in distributed mode", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.12\r\n- Python version: 3.6.5\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\nRunning below code that I found in many pages on the net, I faced some problems:\r\n\r\n```\r\nimport json\r\nimport os\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\r\ndata_dir = '.\\\\MNIST_data'\r\nlog_dir = '.\\log_dist'\r\nbatch_size = 512\r\ntf.logging.set_verbosity(tf.logging.INFO)\r\n\r\ndef keras_model(lr, decay):\r\n    \"\"\"Return a CNN Keras model\"\"\"\r\n    input_tensor = tf.keras.layers.Input(shape=(784,), name='input')\r\n\r\n    temp = tf.keras.layers.Reshape([28, 28, 1], name='input_image')(input_tensor)\r\n    for i, n_units in enumerate([32, 64]):\r\n        temp = tf.keras.layers.Conv2D(n_units, kernel_size=3, strides=(2, 2),\r\n                                      activation='relu', name='cnn'+str(i))(temp)\r\n        temp = tf.keras.layers.Dropout(0.5, name='dropout'+str(i))(temp)\r\n    temp = tf.keras.layers.GlobalAvgPool2D(name='average')(temp)\r\n    output = tf.keras.layers.Dense(10, activation='softmax', name='output')(temp)\r\n\r\n    model = tf.keras.models.Model(inputs=input_tensor, outputs=output)\r\n    optimizer = tf.keras.optimizers.Adam(lr=lr, decay=decay)\r\n    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\r\n    print(model.summary())\r\n    return model\r\n\r\n\r\ndef main():\r\n    \"\"\"Main function\"\"\"\r\n    data = read_data_sets(data_dir,\r\n                          one_hot=False,\r\n                          fake_data=False)\r\n    model = keras_model(lr=0.001, decay=0.001)\r\n    config = tf.estimator.RunConfig(\r\n                model_dir=log_dir,\r\n                save_summary_steps=1,\r\n                save_checkpoints_steps=100)\r\n    estimator = tf.keras.estimator.model_to_estimator(model, model_dir=log_dir, config=config)\r\n\r\n    train_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n                         x={'input': data.train.images},\r\n                         y=data.train.labels,\r\n                         num_epochs=None,   # run forever\r\n                         batch_size=batch_size,\r\n                         shuffle=True)\r\n    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n                         x={'input': data.test.images},\r\n                         y=data.test.labels,\r\n                         num_epochs=1,\r\n                         shuffle=False)\r\n\r\n    train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn,\r\n                                        max_steps=2000)\r\n    eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn,\r\n                                      #throttle_secs=1,\r\n                                      steps=None    # until the end of evaluation data\r\n                                      )\r\n\r\n    evaluate_result = tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\r\n    print(\"Evaluation results:\")\r\n    for key in evaluate_result[0].keys():\r\n        print(\"   {}: {}\".format(key, evaluate_result[0][key]))\r\n```\r\n\r\nAnd then the rest of the code just included the TF_CONFIG definition for chief, worker and ps. I faced below issues:\r\n\r\n- I was able to run this code on Tensorflow 1.12 but not on Tensorflow 1.13, where I got the error `ValueError: Can not squeeze dim[1], expected a dimension of 1, got 10 for 'metrics/acc/remove_squeezable_dimensions/Squeeze' (op: 'Squeeze') with input shapes: [512,10]`. What is the reason?\r\n- I could get evaluation results printed at the end of training when I was running program in non-distributed mode, but I get below error when it tries to print the final evaluation results in distributed mode:\r\n```\r\nTraceback (most recent call last):\r\n  File \"mnist_estimator.py\", line 81, in <module>\r\n    main()\r\n  File \"mnist_estimator.py\", line 62, in main\r\n    for key in evaluate_result[0].keys():\r\nTypeError: 'NoneType' object is not subscriptable\r\n```\r\n- The final loss for distributed learning was higher than non-distributed learning (for the same number of training steps). What can be the reason? Is it the nature of distribution?\r\n- When running in distributed mode, the chief or worker are not waiting for the other party to start and immediately starts training (when the other party joins they do the task together, though). I thought they should wait for each other to be ready (as it was in my previous experiences with Tensorflow distributed training), isn't it?\r\n- What I read in Tensorflow-related pages about data-parallelism is that there are the same copies of code for different servers except in assignment in TF_CONFIG. The chief synchronizes the parameters update and parameter servers keeps the parameters, but I don't clearly understand who split the data between different workers. Is there just one copy at the chief server and it will split the data and send batches to the workers, or the workers each have a local copy of data and do the splitting and skip some data themselves?", "comments": ["Can you please help us in providing full code along with TF_CONFIG to reproduce the issue in our environment.Thanks!", "@ravikyram \r\nThanks. The above is the full code. Just add below TF_CONFIG definition (replacing ... with your ip addresses and selecting any of chief/worker/ps according to the server):\r\n\r\n```\r\nif __name__ == '__main__':\r\n    TF_CONFIG = {\r\n        'task': {\r\n            'type': 'chief/worker/ps',\r\n            'index': 0\r\n        },\r\n        'cluster': {\r\n            'chief': [...],\r\n            'worker': [...],\r\n            'ps': [...]\r\n        }\r\n    }\r\n    os.environ['TF_CONFIG'] = json.dumps(TF_CONFIG)\r\n    main()\r\n\r\n```", "Is it possible for you to try latest TF versions (`!pip install tensorflow==1.15.0-rc1`) and let us know whether the issue persists? There were lots of performance improvements in the latest versions. Thanks!", "@ravikyram \r\nI tried TF 1.15.0-rc1 but it can not be loaded on my system and I get this error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"D:\\Shahriar\\tf1.15_venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"D:\\Shahriar\\tf1.15_venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"D:\\Shahriar\\tf1.15_venv\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"D:\\Shahriar\\tf1.15_venv\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"D:\\Shahriar\\tf1.15_venv\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n```", "@shahriar49,\r\n\r\n1. Regarding `ValueError`: If you face problem in installing 1.15-rc0, you can try installing 1.14 and check if the issue still persists. Also, you can refer this [Stack Overflow Issue](https://stackoverflow.com/questions/49083984/valueerror-can-not-squeeze-dim1-expected-a-dimension-of-1-got-3-for-sparse) and check if it helps.\r\n2. I could get evaluation results printed at the end of training when I was running program in non-distributed mode, but I get below error when it tries to print the final evaluation results in distributed mode: ====> Can you please confirm if you able to run this in 1.12?", "@rmothukuru \r\nI checked again and I can run the code in 1.12 but not in 1.13. I will check 1.14 as well.", "@rmothukuru \r\nI ran the code in TF 1.14 and the below problems still exist:\r\n\r\n- I could get evaluation results printed at the end of training when I was running program in non-distributed mode, but I get below error when it tries to print the final evaluation results in distributed mode:\r\n```\r\nTraceback (most recent call last):\r\n  File \"mnist_estimator.py\", line 81, in <module>\r\n    main()\r\n  File \"mnist_estimator.py\", line 62, in main\r\n    for key in evaluate_result[0].keys():\r\nTypeError: 'NoneType' object is not subscriptable\r\n```\r\n\r\n- When running in distributed mode, the chief is not waiting for the worker and immediately starts training (when the other party joins they do the task together, though). I thought they should wait for each other to be ready (as it was in my previous experiences with Tensorflow distributed training), isn't it?\r\n\r\n- What I read in Tensorflow-related pages about data-parallelism is that there are the same copies of code for different servers except in assignment in TF_CONFIG. The chief synchronizes the parameters update and parameter servers keeps the parameters, but I don't clearly understand who split the data between different workers. Is there just one copy at the chief server and it will split the data and send batches to the workers, or the workers each have a local copy of data and do the splitting and skip some data themselves?", "@shahriar49,\r\nPlease confirm if we can consider this issue as duplicate of #32787, as the Code is same and as we to use `tf.distributionstrategy` for distributed training. Thanks!", "@rmothukuru \r\nYes the code is almost the same, but the problems that I mentioned here is different than the other one. Here I am not using strategy clause and get some issues. There I am using strategy clause and it fails to work. So the problems discussed in each case is different.", "@shahriar49 Can you try `TF1.15.0rc3` and let us know whether issue persists with latest TF1.x version? Thanks!", "@jvishnuvardhan \r\nI will do, but can somebody at least answer my last question:\r\n\r\n- What I read in Tensorflow-related pages about data-parallelism is that there are the same copies of code for different servers except in assignment in TF_CONFIG. The chief synchronizes the parameters update and parameter servers keeps the parameters, but I don't clearly understand who split the data between different workers. Is there just one copy at the chief server and it will split the data and send batches to the workers, or the workers each have a local copy of data and do the splitting and skip some data themselves?", "@yuefengz / @rchao  for the final question here.", "Hello @shahriar49, if I understand correctly here we're using `model_to_estimator` without a tf.distribute strategy. With classic estimator training, I am not aware of any data splitting among the workers. The same copy of code is run on chief and workers, and if the training `input_fn` is configured to raise `OutOfRangeError` after one epoch, the total epochs trained will be the number of all workers.\r\n\r\nYou can find more information here: https://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate", "@rchao \r\nSo you mean that without strategy clause each worker will do its job independently without data splitting? My observation says something else.", "Mind sharing what you observed?", "@shahriar49 \r\nI faced the same issue with you, did you solve it?", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32841\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32841\">No</a>\n"]}, {"number": 32840, "title": "TFLite Different behaviour after upgrading gradle", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Samsung S9\r\n- TensorFlow version (use command below): tensorflow-lite and tensorflow-lite-gpu nightly\r\n\r\n**Describe the current behavior**\r\nI have a project that uses the android camera and every 500ms processes a frame in the background thread. I'm using a GPU delegate.  \r\n\r\nI recently upgraded the gradle-wrapper from `5.1.1` to `5.6.2`. After this everything seemed to remain the same, except for:\r\n1. model is inferring much faster (15%-30% faster)\r\n2. model is taking much more time to initialize inferences (about 8 seconds, before it was around 1 second)\r\n\r\nEven though I'm pleased with the apparent improved inference times, the 7 second waiting to start running inferences is a pain.. Is there any reason for that?\r\n\r\nI've checked the logs (which I attach) and realized I have - at least - a new additional print in the 5.6.2 version:\r\n`Initialized OpenCL-based API.`\r\nThe inferences only start after this print so I imagine it might have to due with the delay mentioned.\r\n\r\nThank you for your help!\r\n\r\nPS: I've attached the logs but I don't know how much of an help they could be\r\n\r\n[android-debug 5.1.1.log](https://github.com/tensorflow/tensorflow/files/3658022/android-debug.5.1.1.log)\r\n[android-debug 5.6.2.log](https://github.com/tensorflow/tensorflow/files/3658023/android-debug.5.6.2.log)\r\n", "comments": ["Any ideia on what might be happening? In a Xiaomi Redmi Note 4 the performance decreased from 230 to +400ms and there is no information about `OpenCL-based API`", "@impjdi any clue on what's happening? \r\nI've started to use tflite gpu in may/june and haven't since updated anything on jcenter or maven, do you think it might have to due with that? I've also seen you and @jdduke speaking about a v1 and v2 versions of delegate (opengl and opencl), is it possible I might be stuck in between?", "@tgpsantos \r\n\r\nThe reason why things may be faster now, may be due to our OpenCL backend.  While the OpenCL code may be executed behind the scenes when you're using the `TfLiteGpuDelegate`, we haven't publicly announced because documentation is missing; we'll prepare them soon.\r\n\r\nThe slow startup time may be also related to OpenCL, but it's difficult to say at the moment.  Can you track down the whether OpenGL is executed or OpenCL?", "In my case, the model initialization time tooks 17 seconds when gpuDelegate is used, 500ms for using CPU only. I tryed tensorflow-lite-nightly, 2.0.0 and 1.15.0, they work the same. The gradle version is 5.4.1 and android gradle version is 3.5.2.", "> \r\n> \r\n> @tgpsantos\r\n> \r\n> The reason why things may be faster now, may be due to our OpenCL backend. While the OpenCL code may be executed behind the scenes when you're using the `TfLiteGpuDelegate`, we haven't publicly announced because documentation is missing; we'll prepare them soon.\r\n> \r\n> The slow startup time may be also related to OpenCL, but it's difficult to say at the moment. Can you track down the whether OpenGL is executed or OpenCL?\r\n\r\nIn my log I got: \r\n> Initialized OpenCL-based API\r\n\r\nIs there a more reliable way of confirming this?", "@tgpsantos \r\n\r\nUnless you see \"Falling back to OpenGL\", you are on OpenCL land :)", "According to those logs then I am on OpenCL land :)\r\n\r\nRegarding the slowdown to start doing inferences, any clue on what might be happening? This is a huge pain :( In Samsung S9 (Mali-G72) I've seen an increase in performance but the slowdown to start inferences kills me... In a different smartphone (Xiaomi Redmi Note 4 - Adreno 506 - OpenCL 2.0) not only have a slowdown to start but there is also a significant drop in performance. ", "8 secs load time sounds indeed ridiculous.  Do you have a TFLite model you can share?", "Sorry for just reporting back now. Can I send you an email with the tflite model? ", "Sure.", "Where can I find it ? :)", "at google dot com :)", "We seem to encounter the same issue. With OpenCL the load times are extremely long often in the 10s range.\r\nDo you have an update on this?", "We continued the discussion on an email thread.   You can use `TFLITE_GPU_INFERENCE_PREFERENCE_FAST_SINGLE_ANSWER` for faster initialization.", "thx, will try"]}, {"number": 32839, "title": "Inputs to eager execution function cannot be Keras symbolic tensors", "body": "Version:\r\n2.0.0-rc\r\n\r\nPython Version:\r\npython 3.7\r\n\r\n\r\n**this is the shape check function!**\r\n'''@tf.function\r\ndef shape_check(input_channels,filters,bottom ,second):\r\n    shortcut = tf.cond(\r\n                            tf.equal(input_channels, filters),\r\n                            lambda :bottom,\r\n                            lambda :second \r\n                        )\r\n    return shortcut'''\r\n\r\n\r\n\r\n**The Error is poping here**\r\nthis is a class function and i tried writing tf.cond() but it got different error!\r\n'''def _basic_block(self, bottom, filters):\r\n        input_channels = tf.shape(bottom)[-1]\r\n        conv = self._conv_bn_activation(bottom, filters, 3, 1)\r\n        conv = self._conv_bn_activation(conv, filters, 3, 1)\r\n        input_channels = tf.shape(bottom)[-1]\r\n        shortcut = shape_check(input_channels,filters,bottom,self._conv_bn_activation(bottom, filters, 1, 1))\r\n        \r\n        return conv + shortcut'''\r\n\r\n\r\n\r\n\r\n", "comments": ["@kartik4949, In order to expedite the trouble-shooting process, please provide a standalone code to reproduce the issue reported here. Thanks!\r\n", "```\r\n# -*- coding: utf-8 -*-\r\n\"\"\"\r\nCreated on Thu Sep 26 15:23:42 2019\r\n\r\n@author: ACIPLE1088\r\n\"\"\"\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\n@tf.function\r\ndef shape_check(input_channels,filters,bottom ,second):\r\n    bottom = tf.convert_to_tensor(bottom)\r\n    second = tf.convert_to_tensor(second)\r\n    shortcut = tf.cond(\r\n                            tf.equal(input_channels, filters),\r\n                            lambda :bottom,\r\n                            lambda :second \r\n                        )\r\n    return shortcut\r\n\r\nclass CenterNet:\r\n    def __init__(self, input_shape=(300, 300, 3), activation=None, l2_reg=0.001, num_classes=3, weight_decay=None, batch_size=16, score_threshold=0.60, mode='train'):\r\n        self.input_shape = input_shape\r\n        self.num_classes = num_classes\r\n        self.weight_decay = weight_decay\r\n        self.batch_size = batch_size\r\n        self.score_threshold = score_threshold\r\n        self.mode = mode\r\n        self.l2_reg = tf.keras.regularizers.l2(0.0005)\r\n        if(activation is None):\r\n            self.activation = self.mish\r\n        else:\r\n            self.activation = activation\r\n    def build_model(self):\r\n        #with tf.name_scope('backbone'):\r\n        input_layer = tf.keras.layers.Input(shape=self.input_shape)\r\n        conv = self._conv_bn_activation(\r\n            input_layer, filters=16, kernel_size=7, strides=1)\r\n\r\n        conv = self._conv_bn_activation(\r\n            conv, filters=16, kernel_size=3, strides=1)\r\n\r\n        conv = self._conv_bn_activation(\r\n            conv, filters=32, kernel_size=3, strides=2)\r\n\r\n        intermediate1 = self._dla_generator(conv, 64, 1, self._basic_block)\r\n        intermediate1 = self._max_pooling(intermediate1, 2, 2)\r\n        print(intermediate1.shape)\r\n\r\n\r\n        dla_stage4 = self._dla_generator(intermediate1, 128, 1, self._basic_block)\r\n        residual = self._conv_bn_activation(intermediate1, 128, 1, 1)\r\n        residual = self._avg_pooling(residual, 2, 2)\r\n        dla_stage4 = self._max_pooling(dla_stage4, 2, 2)\r\n\r\n        dla_stage4 = dla_stage4 + residual\r\n        print('dla_stage4 =',dla_stage4.shape)\r\n\r\n        dla_stage5 = self._dla_generator(dla_stage4, 256, 1, self._basic_block)\r\n        print('dla_stage5 =',dla_stage5.shape)\r\n        residual = self._conv_bn_activation(dla_stage4, 256, 1, 1)\r\n        residual = self._avg_pooling(residual, 2, 2)\r\n        dla_stage5 = self._max_pooling(dla_stage5, 2, 2)\r\n        dla_stage5 = dla_stage5 + residual\r\n        print('dla_stage5 =',dla_stage5.shape)\r\n\r\n        dla_stage6 = self._dla_generator(dla_stage5, 512, 1, self._basic_block)\r\n        residual = self._conv_bn_activation(dla_stage5, 512, 1, 1)\r\n        residual = self._avg_pooling(residual, 2, 2)\r\n        dla_stage6 = self._max_pooling(dla_stage6, 2, 2)\r\n        dla_stage6 = dla_stage6 + residual\r\n        print('dla_stage6 =',dla_stage6.shape)\r\n   #with tf.name_scope('upsampling'):\r\n        dla_stage6 = self._conv_bn_activation(dla_stage6, 256, 1, 1)\r\n        print('dla_stage6--- =',dla_stage6.shape)\r\n        dla_stage6_5 = self._dconv_bn_activation(dla_stage6, 256, 4, 2)\r\n        print('dla_stage6_5--- =',dla_stage6_5.shape)\r\n        dla_stage6_4 = self._dconv_bn_activation(dla_stage6_5, 256, 4, 2)\r\n        print('dla_stage6_4--- =',dla_stage6_4.shape)\r\n        dla_stage6_3 = self._dconv_bn_activation(dla_stage6_4, 256, 4, 2)\r\n        print('dla_stage6_3--- =',dla_stage6_3.shape)\r\n        #dla_stage5 = self._conv_bn_activation(dla_stage5, 256, 1, 1)\r\n        print('dla_stage--- =',dla_stage5.shape)\r\n        dla_stage5 = tf.keras.layers.ZeroPadding2D()(dla_stage5)\r\n        print('dla_stage--- =',dla_stage5.shape)\r\n\r\n        #print( dla_stage4.shape,dla_stage5.shape,dla_stage6.shape ,dla_stage5.shape , dla_stage6_5.shape)\r\n        dla_stage5_4 = self._conv_bn_activation(dla_stage5+dla_stage6_5, 256, 3, 1)\r\n\r\n\r\n        dla_stage5_4 = self._dconv_bn_activation(dla_stage5_4, 256, 4, 2)\r\n        dla_stage5_3 = self._dconv_bn_activation(dla_stage5_4, 256, 4, 2)\r\n\r\n        dla_stage4 = self._conv_bn_activation(dla_stage4, 256, 1, 1)\r\n        dla_stage4_3 = self._conv_bn_activation(dla_stage4+dla_stage5_4+dla_stage6_4, 256, 3, 1)\r\n        dla_stage4_3 = self._dconv_bn_activation(dla_stage4_3, 256, 4, 2)\r\n\r\n        features = self._conv_bn_activation(dla_stage6_3+dla_stage5_3+dla_stage4_3, 256, 3, 1)\r\n        features = self._conv_bn_activation(features, 256, 1, 1)\r\n        stride = 4.0\r\n\r\n    #with tf.name_scope('center_detector'):\r\n        keypoints = self._conv_bn_activation(features, self.num_classes, 3, 1, None)\r\n        offset = self._conv_bn_activation(features, 2, 3, 1, None)\r\n        size = self._conv_bn_activation(features, 2, 3, 1, None)\r\n\r\n        model = tf.keras.Model(inputs = input_layer , outputs = [keypoints,offset,size])\r\n        model.compile(experimental_run_tf_function=False)\r\n        return model\r\n\r\n\r\n\r\n    def visiualize_model(self):\r\n        model = self.build_model()\r\n        model.summary()\r\n\r\n    def mish(self,inputs):\r\n        return inputs * tf.math.tanh(tf.math.softplus(inputs))\r\n\r\n    \r\n\r\n\r\n\r\n    #@tf.function\r\n    def _conv_bn_activation(self, input_layer, filters=16, kernel_size=7, strides=1):\r\n        input_layer = tf.keras.layers.Conv2D(filters=filters,\r\n                                             kernel_size=kernel_size, padding='same',\r\n                                             strides=strides, kernel_initializer='he_uniform', kernel_regularizer=self.l2_reg)(input_layer)\r\n\r\n        input_layer = tf.keras.layers.BatchNormalization()(input_layer)\r\n        activation = tf.keras.layers.Activation(\r\n            activation=self.activation)(input_layer)\r\n        return activation\r\n    \r\n    #@tf.function    \r\n    def _basic_block(self, bottom, filters):\r\n        conv = self._conv_bn_activation(bottom, filters, 3, 1)\r\n        conv = self._conv_bn_activation(conv, filters, 3, 1)\r\n        input_channels = tf.shape(bottom)[-1]\r\n        shortcut = shape_check(input_channels,filters,bottom,self._conv_bn_activation(bottom, filters, 1, 1))\r\n        \r\n\r\n        '''shortcut = tf.cond(\r\n            tf.equal(input_channels, filters),\r\n            lambda :bottom,\r\n            lambda : self._conv_bn_activation(bottom, filters, 1, 1)\r\n        )'''\r\n        return conv + shortcut\r\n\r\n    \r\n\r\n    #@tf.function\r\n    def _dla_generator(self, bottom, filters, levels, stack_block_fn):\r\n        if levels == 1:\r\n            block1 = stack_block_fn(bottom, filters)\r\n            block2 = stack_block_fn(block1, filters)\r\n            aggregation = block1 + block2\r\n            aggregation = self._conv_bn_activation(aggregation, filters, 3, 1)\r\n        else:\r\n            block1 = self._dla_generator(bottom, filters, levels-1, stack_block_fn)\r\n            block2 = self._dla_generator(block1, filters, levels-1, stack_block_fn)\r\n            aggregation = block1 + block2\r\n            aggregation = self._conv_bn_activation(aggregation, filters, 3, 1)\r\n        return aggregation\r\n    #@tf.function\r\n    def _max_pooling(self , inputs , pool_size ,strides):\r\n        \r\n        return tf.keras.layers.MaxPool2D( pool_size = pool_size ,strides = strides, padding = 'same')(inputs)\r\n    \r\n    def _dconv_bn_activation(self, bottom, filters, kernel_size, strides):\r\n        conv = tf.keras.layers.Conv2DTranspose(\r\n            filters=filters,\r\n            kernel_size=kernel_size,\r\n            strides=strides,\r\n            padding='same',\r\n        )(bottom)\r\n\r\n        bn = self._bn(conv)\r\n        bn = self.mish(bn)\r\n        return bn\r\n    def _bn(self,inputs):\r\n        return tf.keras.layers.BatchNormalization()(inputs)\r\n\r\n    def _separable_conv_layer(self, bottom, filters, kernel_size, strides, activation=None):\r\n        conv = tf.keras.layers.SeparableConv2D(\r\n            filters=filters,\r\n            kernel_size=kernel_size,\r\n            strides=strides,\r\n            padding='same',\r\n            use_bias=False,\r\n        )(bottom)\r\n        bn = self._bn(conv)\r\n        bn = self.mish(bn)\r\n        return bn\r\n\r\n    #@tf.function\r\n    def _avg_pooling(self,inputs , pool_size ,strides):\r\n         return tf.keras.layers.AveragePooling2D(pool_size = pool_size ,strides = strides , padding = 'same')(inputs)\r\n    #@tf.function\r\n    def _dropout(self,inputs,prob):\r\n        return tf.keras.layers.Dropout(prob)(inputs)\r\n\r\n\r\nif __name__ == '__main__':\r\n    centernet = CenterNet()\r\n    centernet.visiualize_model()\r\n```", "> @kartik4949, In order to expedite the trouble-shooting process, please provide a standalone code to reproduce the issue reported here. Thanks!\r\n\r\n```\r\n# -*- coding: utf-8 -*-\r\n\"\"\"\r\nCreated on Thu Sep 26 15:23:42 2019\r\n\r\n@author: ACIPLE1088\r\n\"\"\"\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\n@tf.function\r\ndef shape_check(input_channels,filters,bottom ,second):\r\n    bottom = tf.convert_to_tensor(bottom)\r\n    second = tf.convert_to_tensor(second)\r\n    shortcut = tf.cond(\r\n                            tf.equal(input_channels, filters),\r\n                            lambda :bottom,\r\n                            lambda :second \r\n                        )\r\n    return shortcut\r\n\r\nclass CenterNet:\r\n    def __init__(self, input_shape=(300, 300, 3), activation=None, l2_reg=0.001, num_classes=3, weight_decay=None, batch_size=16, score_threshold=0.60, mode='train'):\r\n        self.input_shape = input_shape\r\n        self.num_classes = num_classes\r\n        self.weight_decay = weight_decay\r\n        self.batch_size = batch_size\r\n        self.score_threshold = score_threshold\r\n        self.mode = mode\r\n        self.l2_reg = tf.keras.regularizers.l2(0.0005)\r\n        if(activation is None):\r\n            self.activation = self.mish\r\n        else:\r\n            self.activation = activation\r\n    def build_model(self):\r\n        #with tf.name_scope('backbone'):\r\n        input_layer = tf.keras.layers.Input(shape=self.input_shape)\r\n        conv = self._conv_bn_activation(\r\n            input_layer, filters=16, kernel_size=7, strides=1)\r\n\r\n        conv = self._conv_bn_activation(\r\n            conv, filters=16, kernel_size=3, strides=1)\r\n\r\n        conv = self._conv_bn_activation(\r\n            conv, filters=32, kernel_size=3, strides=2)\r\n\r\n        intermediate1 = self._dla_generator(conv, 64, 1, self._basic_block)\r\n        intermediate1 = self._max_pooling(intermediate1, 2, 2)\r\n        print(intermediate1.shape)\r\n\r\n\r\n        dla_stage4 = self._dla_generator(intermediate1, 128, 1, self._basic_block)\r\n        residual = self._conv_bn_activation(intermediate1, 128, 1, 1)\r\n        residual = self._avg_pooling(residual, 2, 2)\r\n        dla_stage4 = self._max_pooling(dla_stage4, 2, 2)\r\n\r\n        dla_stage4 = dla_stage4 + residual\r\n        print('dla_stage4 =',dla_stage4.shape)\r\n\r\n        dla_stage5 = self._dla_generator(dla_stage4, 256, 1, self._basic_block)\r\n        print('dla_stage5 =',dla_stage5.shape)\r\n        residual = self._conv_bn_activation(dla_stage4, 256, 1, 1)\r\n        residual = self._avg_pooling(residual, 2, 2)\r\n        dla_stage5 = self._max_pooling(dla_stage5, 2, 2)\r\n        dla_stage5 = dla_stage5 + residual\r\n        print('dla_stage5 =',dla_stage5.shape)\r\n\r\n        dla_stage6 = self._dla_generator(dla_stage5, 512, 1, self._basic_block)\r\n        residual = self._conv_bn_activation(dla_stage5, 512, 1, 1)\r\n        residual = self._avg_pooling(residual, 2, 2)\r\n        dla_stage6 = self._max_pooling(dla_stage6, 2, 2)\r\n        dla_stage6 = dla_stage6 + residual\r\n        print('dla_stage6 =',dla_stage6.shape)\r\n   #with tf.name_scope('upsampling'):\r\n        dla_stage6 = self._conv_bn_activation(dla_stage6, 256, 1, 1)\r\n        print('dla_stage6--- =',dla_stage6.shape)\r\n        dla_stage6_5 = self._dconv_bn_activation(dla_stage6, 256, 4, 2)\r\n        print('dla_stage6_5--- =',dla_stage6_5.shape)\r\n        dla_stage6_4 = self._dconv_bn_activation(dla_stage6_5, 256, 4, 2)\r\n        print('dla_stage6_4--- =',dla_stage6_4.shape)\r\n        dla_stage6_3 = self._dconv_bn_activation(dla_stage6_4, 256, 4, 2)\r\n        print('dla_stage6_3--- =',dla_stage6_3.shape)\r\n        #dla_stage5 = self._conv_bn_activation(dla_stage5, 256, 1, 1)\r\n        print('dla_stage--- =',dla_stage5.shape)\r\n        dla_stage5 = tf.keras.layers.ZeroPadding2D()(dla_stage5)\r\n        print('dla_stage--- =',dla_stage5.shape)\r\n\r\n        #print( dla_stage4.shape,dla_stage5.shape,dla_stage6.shape ,dla_stage5.shape , dla_stage6_5.shape)\r\n        dla_stage5_4 = self._conv_bn_activation(dla_stage5+dla_stage6_5, 256, 3, 1)\r\n\r\n\r\n        dla_stage5_4 = self._dconv_bn_activation(dla_stage5_4, 256, 4, 2)\r\n        dla_stage5_3 = self._dconv_bn_activation(dla_stage5_4, 256, 4, 2)\r\n\r\n        dla_stage4 = self._conv_bn_activation(dla_stage4, 256, 1, 1)\r\n        dla_stage4_3 = self._conv_bn_activation(dla_stage4+dla_stage5_4+dla_stage6_4, 256, 3, 1)\r\n        dla_stage4_3 = self._dconv_bn_activation(dla_stage4_3, 256, 4, 2)\r\n\r\n        features = self._conv_bn_activation(dla_stage6_3+dla_stage5_3+dla_stage4_3, 256, 3, 1)\r\n        features = self._conv_bn_activation(features, 256, 1, 1)\r\n        stride = 4.0\r\n\r\n    #with tf.name_scope('center_detector'):\r\n        keypoints = self._conv_bn_activation(features, self.num_classes, 3, 1, None)\r\n        offset = self._conv_bn_activation(features, 2, 3, 1, None)\r\n        size = self._conv_bn_activation(features, 2, 3, 1, None)\r\n\r\n        model = tf.keras.Model(inputs = input_layer , outputs = [keypoints,offset,size])\r\n        model.compile(experimental_run_tf_function=False)\r\n        return model\r\n\r\n\r\n\r\n    def visiualize_model(self):\r\n        model = self.build_model()\r\n        model.summary()\r\n\r\n    def mish(self,inputs):\r\n        return inputs * tf.math.tanh(tf.math.softplus(inputs))\r\n\r\n    \r\n\r\n\r\n\r\n    #@tf.function\r\n    def _conv_bn_activation(self, input_layer, filters=16, kernel_size=7, strides=1):\r\n        input_layer = tf.keras.layers.Conv2D(filters=filters,\r\n                                             kernel_size=kernel_size, padding='same',\r\n                                             strides=strides, kernel_initializer='he_uniform', kernel_regularizer=self.l2_reg)(input_layer)\r\n\r\n        input_layer = tf.keras.layers.BatchNormalization()(input_layer)\r\n        activation = tf.keras.layers.Activation(\r\n            activation=self.activation)(input_layer)\r\n        return activation\r\n    \r\n    #@tf.function    \r\n    def _basic_block(self, bottom, filters):\r\n        conv = self._conv_bn_activation(bottom, filters, 3, 1)\r\n        conv = self._conv_bn_activation(conv, filters, 3, 1)\r\n        input_channels = tf.shape(bottom)[-1]\r\n        shortcut = shape_check(input_channels,filters,bottom,self._conv_bn_activation(bottom, filters, 1, 1))\r\n        \r\n\r\n        '''shortcut = tf.cond(\r\n            tf.equal(input_channels, filters),\r\n            lambda :bottom,\r\n            lambda : self._conv_bn_activation(bottom, filters, 1, 1)\r\n        )'''\r\n        return conv + shortcut\r\n\r\n    \r\n\r\n    #@tf.function\r\n    def _dla_generator(self, bottom, filters, levels, stack_block_fn):\r\n        if levels == 1:\r\n            block1 = stack_block_fn(bottom, filters)\r\n            block2 = stack_block_fn(block1, filters)\r\n            aggregation = block1 + block2\r\n            aggregation = self._conv_bn_activation(aggregation, filters, 3, 1)\r\n        else:\r\n            block1 = self._dla_generator(bottom, filters, levels-1, stack_block_fn)\r\n            block2 = self._dla_generator(block1, filters, levels-1, stack_block_fn)\r\n            aggregation = block1 + block2\r\n            aggregation = self._conv_bn_activation(aggregation, filters, 3, 1)\r\n        return aggregation\r\n    #@tf.function\r\n    def _max_pooling(self , inputs , pool_size ,strides):\r\n        \r\n        return tf.keras.layers.MaxPool2D( pool_size = pool_size ,strides = strides, padding = 'same')(inputs)\r\n    \r\n    def _dconv_bn_activation(self, bottom, filters, kernel_size, strides):\r\n        conv = tf.keras.layers.Conv2DTranspose(\r\n            filters=filters,\r\n            kernel_size=kernel_size,\r\n            strides=strides,\r\n            padding='same',\r\n        )(bottom)\r\n\r\n        bn = self._bn(conv)\r\n        bn = self.mish(bn)\r\n        return bn\r\n    def _bn(self,inputs):\r\n        return tf.keras.layers.BatchNormalization()(inputs)\r\n\r\n    def _separable_conv_layer(self, bottom, filters, kernel_size, strides, activation=None):\r\n        conv = tf.keras.layers.SeparableConv2D(\r\n            filters=filters,\r\n            kernel_size=kernel_size,\r\n            strides=strides,\r\n            padding='same',\r\n            use_bias=False,\r\n        )(bottom)\r\n        bn = self._bn(conv)\r\n        bn = self.mish(bn)\r\n        return bn\r\n\r\n    #@tf.function\r\n    def _avg_pooling(self,inputs , pool_size ,strides):\r\n         return tf.keras.layers.AveragePooling2D(pool_size = pool_size ,strides = strides , padding = 'same')(inputs)\r\n    #@tf.function\r\n    def _dropout(self,inputs,prob):\r\n        return tf.keras.layers.Dropout(prob)(inputs)\r\n\r\n\r\nif __name__ == '__main__':\r\n    centernet = CenterNet()\r\n    centernet.visiualize_model()\r\n```\r\n\r\n", "@kartik4949, Thanks for providing the full code. I could replicate the issue on colab. Please see the [gist here](https://colab.sandbox.google.com/gist/gadagashwini/747ad1d17997ca02678ce45dcee2cc26/untitled167.ipynb). Thanks!", "> @kartik4949, Thanks for providing the full code. I could replicate the issue on colab. Please see the [gist here](https://colab.sandbox.google.com/gist/gadagashwini/747ad1d17997ca02678ce45dcee2cc26/untitled167.ipynb). Thanks!\r\nSweet!\r\ni tried like everything to make it work!\r\n", "> @kartik4949, Thanks for providing the full code. I could replicate the issue on colab. Please see the [gist here](https://colab.sandbox.google.com/gist/gadagashwini/747ad1d17997ca02678ce45dcee2cc26/untitled167.ipynb). Thanks!\r\n```\r\n# -*- coding: utf-8 -*-\r\n\"\"\"\r\nCreated on Thu Sep 26 15:23:42 2019\r\n\r\n@author: ACIPLE1088\r\n\"\"\"\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\nl2_reg = tf.keras.regularizers.l2(0.0005)\r\n\r\n\r\ndef mish(inputs):\r\n    return inputs * tf.math.tanh(tf.math.softplus(inputs))\r\n\r\n\r\nclass _conv_bn_activation(tf.keras.Model):\r\n    def __init__(self, filters = 16 ,kernel_size = 7 ,strides=1 , activation=None):\r\n        super().__init__()\r\n        self.model = tf.keras.models.Sequential([\r\n             tf.keras.layers.Conv2D(filters, kernel_size, strides=strides, padding='same', kernel_initializer='he_uniform', kernel_regularizer=l2_reg),\r\n             tf.keras.layers.BatchNormalization(),\r\n             tf.keras.layers.Activation(activation=mish)\r\n\r\n                                                    ])\r\n        \r\n    def call(self,x,training=None):\r\n        x = self.model(x,training)\r\n        return x\r\n\r\n\r\n\r\n\r\nclass _basic_block(tf.keras.Model):\r\n    def __init__(self, filters,**kwargs):\r\n        super().__init__(**kwargs)\r\n        self.filters = filters\r\n        self.conv1 = _conv_bn_activation(self.filters, 3, 1)\r\n        self.conv2 = _conv_bn_activation(self.filters, 3, 1)\r\n        conv3 = _conv_bn_activation( self.filters, 1, 1)\r\n\r\n        \r\n    def call(self,x):\r\n        x = self.conv1(x)\r\n        input_channels = tf.shape(x)[-1]\r\n        shortcut = tf.cond(tf.equal(input_channels,self.filters),\r\n            lambda : x,\r\n            lambda :self.conv2(x))\r\n        '''if(input_channels==self.filters):\r\n            shortcut = conv2\r\n        else:\r\n            shortcut = self.conv3(x ,training=training)'''\r\n        return x + shortcut\r\n\r\n\r\n\r\n\r\nclass _dla_generator(tf.keras.layers.Layer):\r\n    def __init__(self,   filters, levels, stack_block_fn,**kwargs):\r\n        super().__init__(**kwargs)\r\n        self.filters = filters\r\n        self.levels = levels\r\n        self.stack_block_fn = stack_block_fn( filters)\r\n        self.conv1 = _conv_bn_activation( filters, 3, 1)\r\n        \r\n\r\n    def call(self,x):\r\n        block1 = self.stack_block_fn(x)\r\n        aggregation = self.conv1(block1 )\r\n        return aggregation\r\n\r\n\r\nclass CenterNet(tf.keras.Model):\r\n    def __init__(self ,l2_reg=0.001, num_classes=3, weight_decay=None, batch_size=16, score_threshold=0.60, mode='train',**kwargs):\r\n        super().__init__(**kwargs)\r\n        self.num_classes = num_classes\r\n        self.weight_decay = weight_decay\r\n        self.batch_size = batch_size\r\n        self.score_threshold = score_threshold\r\n        self.mode = mode\r\n        self.l2_reg = tf.keras.regularizers.l2(0.0005)\r\n        self.conv1 = _conv_bn_activation()\r\n        self.basic =_basic_block(16)\r\n        \r\n        #self._dla_generator1 = _dla_generator(16,1,_basic_block)\r\n        #self.model = tf.keras.models.Sequential(name='final')\r\n        #self.model.add(basic)\r\n    def call(self,x , training =None):\r\n        #x = self.model(x,training = training)\r\n\r\n        x = self.conv1(x,training = training)\r\n        \"\"\"\r\n        If We donot build the model is gives error in tensorflow 2.0\r\n        \r\n        \"\"\"\r\n        self.basic.build(input_shape = x.shape)\r\n        x = self.basic(x)\r\n        return x\r\n\r\nmodel = CenterNet()\r\n\r\nmodel.build(input_shape = (None,300,300,3)) \r\nmodel.summary()\r\n```\r\n\r\n\r\n\r\n\r\n\r\n\r\nIS THIS GOOD??\r\n\r\nTHIS IS THE ONLY WORKING SOLUTION I CAN MAKE AT THIS MOMENT\r\nSO BASICALLY IS MADE COMPOSITION LAYERS CLASSES RATHER THAN FUNCTION AS PREVIOUS \r\nAND I MADE THEM AS SPERATE MODEL!\r\nPLEASE REVIEW THEM!\r\n,THANKS.\r\n", "The above structure looks good. You can also refer to [Writing custom layers and models with Keras](https://www.tensorflow.org/guide/keras/custom_layers_and_models) article.\r\nThanks!", "Ok...so there is no issue in implementing model structure like this right? i mean performance?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32839\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32839\">No</a>\n"]}, {"number": 32838, "title": "only copy binaries required by cuda", "body": "As per https://github.com/tensorflow/tensorflow/issues/32244, only copy binaries actually required by `cuda`.", "comments": []}, {"number": 32837, "title": "Missing GPU implementation", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Linux Kubuntu 18.04\r\n- TensorFlow installed from: binary (with pip3)\r\n- TensorFlow version: 1.14.0 (v1.14.0-rc1-22-gaf24dc91b5)\r\n- Python version: 3.6.8\r\n- CUDA/cuDNN version: 10.0.130\r\n- GPU model and memory: NVidia Titan Xp\r\n\r\n**Describe the current behavior**\r\nThe op tf.norm cannot be assigned to the GPU in all configurations (see minimal example below).\r\n\r\n**Describe the expected behavior**\r\nI see no theoretical reason for the tf.norm op not to be fully portable to the GPU. I suspect this is a bug, not an intended behavior.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\n\r\nb = 10\r\nwidth = 16\r\nheight = 16\r\nchannels = 3\r\n\r\ndef norm_simple(X):\r\n  return tf.norm(X,axis=[1,2],ord=2)\r\n\r\ndef norm_custom(X):\r\n  X_r = tf.reshape(X,shape=[b,width*height,channels])\r\n  return tf.norm(X_r,axis=1,ord=2)\r\n\r\ns = tf.Session()\r\n\r\nA = tf.ones(shape=[b,width,height,channels])\r\n\r\nwith tf.device('/cpu:0'):\r\n  n1_cpu = norm_simple(A)\r\ns.run(n1_cpu)\r\nprint(\" === norm_simple works on CPU\")\r\n\r\nwith tf.device('/cpu:0'):\r\n  n2_cpu = norm_custom(A)\r\ns.run(n2_cpu)\r\nprint(\" === norm_custom works on CPU\")\r\n\r\nwith tf.device('/gpu:0'):\r\n n2_gpu = norm_custom(A)\r\ns.run(n2_gpu)\r\nprint(\" === norm_custom works on GPU\")\r\n\r\nwith tf.device('/gpu:0'):\r\n n1_gpu = norm_simple(A)\r\ns.run(n1_gpu)\r\nprint(\" === norm_simple works on GPU\")\r\n\r\n```\r\n\r\n**Other info / logs**\r\nExecution of the above code on my machine:\r\n```\r\n === norm_simple works on CPU\r\n === norm_custom works on CPU\r\n === norm_custom works on GPU\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1356, in _do_call\r\n    return fn(*args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1339, in _run_fn\r\n    self._extend_graph()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1374, in _extend_graph\r\n    tf_session.ExtendSession(self._session)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation norm_3/map/TensorArray: Could not satisfy explicit device specification '' because the node {{colocation_node norm_3/map/TensorArray}} was colocated with a group of nodes that required incompatible device '/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:1, /job:localhost/replica:0/task:0/device:XLA_CPU:0, /job:localhost/replica:0/task:0/device:GPU:0, /job:localhost/replica:0/task:0/device:GPU:1]. \r\nColocation Debug Info:\r\nColocation group had the following types and supported devices: \r\nRoot Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='' supported_device_types_=[CPU, XLA_CPU, XLA_GPU] possible_devices_=[]\r\nSwitch: GPU CPU XLA_CPU XLA_GPU \r\nTensorArrayScatterV3: CPU XLA_CPU XLA_GPU \r\nTensorArrayReadV3: CPU XLA_CPU XLA_GPU \r\nEnter: GPU CPU XLA_CPU XLA_GPU \r\nTensorArrayV3: CPU XLA_CPU XLA_GPU \r\nConst: GPU CPU XLA_CPU XLA_GPU \r\n\r\nColocation members, user-requested devices, and framework assigned devices, if any:\r\n  norm_3/Const (Const) /device:GPU:0\r\n  norm_3/map/TensorArray (TensorArrayV3) \r\n  norm_3/map/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3 (TensorArrayScatterV3) /device:GPU:0\r\n  norm_3/map/while/TensorArrayReadV3/Enter (Enter) /device:GPU:0\r\n  norm_3/map/while/TensorArrayReadV3 (TensorArrayReadV3) /device:GPU:0\r\n  norm_3/map/while/cond/Switch_1 (Switch) /device:GPU:0\r\n  norm_3/map/while/cond/add/Switch (Switch) /device:GPU:0\r\n\r\n         [[{{node norm_3/map/TensorArray}}]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"bugreport.py\", line 36, in <module>\r\n    s.run(n1_gpu)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 950, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1173, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1350, in _do_run\r\n    run_metadata)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1370, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation norm_3/map/TensorArray: Could not satisfy explicit device specification '' because the node node norm_3/map/TensorArray (defined at bugreport.py:9) placed on device No device assignments were active during op 'norm_3/map/TensorArray' creation.  was colocated with a group of nodes that required incompatible device '/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:1, /job:localhost/replica:0/task:0/device:XLA_CPU:0, /job:localhost/replica:0/task:0/device:GPU:0, /job:localhost/replica:0/task:0/device:GPU:1]. \r\nColocation Debug Info:\r\nColocation group had the following types and supported devices: \r\nRoot Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='' supported_device_types_=[CPU, XLA_CPU, XLA_GPU] possible_devices_=[]\r\nSwitch: GPU CPU XLA_CPU XLA_GPU \r\nTensorArrayScatterV3: CPU XLA_CPU XLA_GPU \r\nTensorArrayReadV3: CPU XLA_CPU XLA_GPU \r\nEnter: GPU CPU XLA_CPU XLA_GPU \r\nTensorArrayV3: CPU XLA_CPU XLA_GPU \r\nConst: GPU CPU XLA_CPU XLA_GPU \r\n\r\nColocation members, user-requested devices, and framework assigned devices, if any:\r\n  norm_3/Const (Const) /device:GPU:0\r\n  norm_3/map/TensorArray (TensorArrayV3) \r\n  norm_3/map/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3 (TensorArrayScatterV3) /device:GPU:0\r\n  norm_3/map/while/TensorArrayReadV3/Enter (Enter) /device:GPU:0\r\n  norm_3/map/while/TensorArrayReadV3 (TensorArrayReadV3) /device:GPU:0\r\n  norm_3/map/while/cond/Switch_1 (Switch) /device:GPU:0\r\n  norm_3/map/while/cond/add/Switch (Switch) /device:GPU:0\r\n\r\n         [[node norm_3/map/TensorArray (defined at bugreport.py:9) ]]Additional information about colocations:No node-device colocations were active during op 'norm_3/map/TensorArray' creation.\r\nNo device assignments were active during op 'norm_3/map/TensorArray' creation.\r\n\r\nOriginal stack trace for 'norm_3/map/TensorArray':\r\n  File \"bugreport.py\", line 35, in <module>\r\n    n1_gpu = norm_simple(A)\r\n  File \"bugreport.py\", line 9, in norm_simple\r\n    return tf.norm(X,axis=[1,2],ord=2)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/linalg_ops.py\", line 600, in norm\r\n    ops.convert_to_tensor(axis))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/map_fn.py\", line 228, in map_fn\r\n    for elem in elems_flat]\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/map_fn.py\", line 228, in <listcomp>\r\n    for elem in elems_flat]\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py\", line 1086, in __init__\r\n    name=name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py\", line 164, in __init__\r\n    self._handle, self._flow = create()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py\", line 161, in create\r\n    name=scope)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 8085, in tensor_array_v3\r\n    tensor_array_name=tensor_array_name, name=name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\n```\r\n", "comments": ["@kvanhoey, Thanks for reporting this issue.\r\nI could reproduce the reported issue in TF1.x. Its fixed in TF 2.0.0rc2.\r\nPlease take a look at colab [gist](https://colab.sandbox.google.com/gist/gadagashwini/2ae2a31571acc201572fb9fa4e15e66c/untitled166.ipynb). You might want to give it a try instead. Thanks! ", "Thank you for getting back to me. Glad it's fixed in 2.0.\r\nI have a big project that I don't want to move to TF 2.0 yet, so I'll stay with my workaround (reshape first, then tf.norm on one dimension only).\r\n"]}, {"number": 32836, "title": "Detected cudnn out-of-bounds write in conv scratch buffer! This is likely a cudnn bug", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): both source and binary\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version:3.7\r\n- Bazel version (if compiling from source): 0.25.2\r\n- GCC/Compiler version (if compiling from source): 7.4.0\r\n- CUDA/cuDNN version: cuda10, cuda10.1,  7.6.0, 7.6.2\r\n- GPU model and memory: 2080Ti\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n2019-09-26 17:28:07.044771: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:157] Detected cudnn out-of-bounds write in conv input/output buffer! This is likely a cudnn bug. We will skip this algorithm in the future, but your GPU state may already be corrupted, leading to incorrect results. Within Google, no action is needed on your part. Outside of Google, please ensure you're running the latest version of cudnn. If that doesn't fix the problem, please file a bug with this full error message and we'll contact nvidia.\r\n2019-09-26 17:28:07.044827: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:166] Redzone mismatch in LHS redzone of buffer 0x7fd3e5090200 at offset 0; expected ffffffffffffffff but was 3b0387303ca4a820.\r\n2019-09-26 17:28:07.044863: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:167] HloInstruction %custom-call = (f32[5,5,2,64]{1,0,2,3}, u8[0]{0}) custom-call(f32[155,2,64,64]{3,2,1,0} %arg8.9, f32[155,64,60,60]{3,2,1,0} %select.42), window={size=5x5}, dim_labels=bf01_01io->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"HICO_1/gradients/HICO_0/resnet_v1_50_3/conv1_sp/Conv2D_grad/Conv2DBackpropFilter\"}, backend_config=\"{\\\"convResultScale\\\":1}\"\r\n2019-09-26 17:28:07.044874: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:112] Device: GeForce RTX 2080 Ti\r\n2019-09-26 17:28:07.044881: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:113] Platform: Compute Capability 7.5\r\n2019-09-26 17:28:07.044889: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:114] Driver: 10010 (418.87.0)\r\n2019-09-26 17:28:07.044896: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:115] Runtime: <undefined>\r\n2019-09-26 17:28:07.044907: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:122] cudnn version: 7.6.2\r\n2019-09-26 17:28:07.065798: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:157] Detected cudnn out-of-bounds write in conv input/output buffer! This is likely a cudnn bug. We will skip this algorithm in the future, but your GPU state may already be corrupted, leading to incorrect results. Within Google, no action is needed on your part. Outside of Google, please ensure you're running the latest version of cudnn. If that doesn't fix the problem, please file a bug with this full error message and we'll contact nvidia.\r\n2019-09-26 17:28:07.065836: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:166] Redzone mismatch in LHS redzone of buffer 0x7fd3e5090200 at offset 0; expected ffffffffffffffff but was 3b0387303ca4a820.\r\n2019-09-26 17:28:07.065866: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:167] HloInstruction %custom-call = (f32[5,5,2,64]{1,0,2,3}, u8[0]{0}) custom-call(f32[155,2,64,64]{3,2,1,0} %arg8.9, f32[155,64,60,60]{3,2,1,0} %select.42), window={size=5x5}, dim_labels=bf01_01io->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"HICO_1/gradients/HICO_0/resnet_v1_50_3/conv1_sp/Conv2D_grad/Conv2DBackpropFilter\"}, backend_config=\"{\\\"convResultScale\\\":1}\"\r\n2019-09-26 17:28:07.065877: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:112] Device: GeForce RTX 2080 Ti\r\n2019-09-26 17:28:07.065885: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:113] Platform: Compute Capability 7.5\r\n2019-09-26 17:28:07.065892: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:114] Driver: 10010 (418.87.0)\r\n2019-09-26 17:28:07.065899: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:115] Runtime: <undefined>\r\n2019-09-26 17:28:07.065909: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:122] cudnn version: 7.6.2\r\n2019-09-26 17:28:07.082404: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:157] Detected cudnn out-of-bounds write in conv input/output buffer! This is likely a cudnn bug. We will skip this algorithm in the future, but your GPU state may already be corrupted, leading to incorrect results. Within Google, no action is needed on your part. Outside of Google, please ensure you're running the latest version of cudnn. If that doesn't fix the problem, please file a bug with this full error message and we'll contact nvidia.\r\n2019-09-26 17:28:07.082436: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:166] Redzone mismatch in LHS redzone of buffer 0x7fd3e5090200 at offset 0; expected ffffffffffffffff but was 3b0387303ca4a820.\r\n2019-09-26 17:28:07.082464: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:167] HloInstruction %custom-call = (f32[5,5,2,64]{1,0,2,3}, u8[0]{0}) custom-call(f32[155,2,64,64]{3,2,1,0} %arg8.9, f32[155,64,60,60]{3,2,1,0} %select.42), window={size=5x5}, dim_labels=bf01_01io->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"HICO_1/gradients/HICO_0/resnet_v1_50_3/conv1_sp/Conv2D_grad/Conv2DBackpropFilter\"}, backend_config=\"{\\\"convResultScale\\\":1}\"\r\n2019-09-26 17:28:07.082474: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:112] Device: GeForce RTX 2080 Ti\r\n2019-09-26 17:28:07.082482: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:113] Platform: Compute Capability 7.5\r\n2019-09-26 17:28:07.082490: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:114] Driver: 10010 (418.87.0)\r\n2019-09-26 17:28:07.082497: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:115] Runtime: <undefined>\r\n2019-09-26 17:28:07.082506: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:122] cudnn version: 7.6.2\r\n2019-09-26 17:28:07.109990: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:157] Detected cudnn out-of-bounds write in conv input/output buffer! This is likely a cudnn bug. We will skip this algorithm in the future, but your GPU state may already be corrupted, leading to incorrect results. Within Google, no action is needed on your part. Outside of Google, please ensure you're running the latest version of cudnn. If that doesn't fix the problem, please file a bug with this full error message and we'll contact nvidia.\r\n2019-09-26 17:28:07.110017: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:166] Redzone mismatch in LHS redzone of buffer 0x7fd3e5090200 at offset 0; expected ffffffffffffffff but was 3b0387303ca4a820.\r\n2019-09-26 17:28:07.110045: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:167] HloInstruction %custom-call = (f32[5,5,2,64]{1,0,2,3}, u8[0]{0}) custom-call(f32[155,2,64,64]{3,2,1,0} %arg8.9, f32[155,64,60,60]{3,2,1,0} %select.42), window={size=5x5}, dim_labels=bf01_01io->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"HICO_1/gradients/HICO_0/resnet_v1_50_3/conv1_sp/Conv2D_grad/Conv2DBackpropFilter\"}, backend_config=\"{\\\"convResultScale\\\":1}\"\r\n2019-09-26 17:28:07.110055: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:112] Device: GeForce RTX 2080 Ti\r\n2019-09-26 17:28:07.110064: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:113] Platform: Compute Capability 7.5\r\n2019-09-26 17:28:07.110071: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:114] Driver: 10010 (418.87.0)\r\n2019-09-26 17:28:07.110078: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:115] Runtime: <undefined>\r\n2019-09-26 17:28:07.110088: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:122] cudnn version: 7.6.2\r\n2019-09-26 17:28:07.144289: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:157] Detected cudnn out-of-bounds write in conv input/output buffer! This is likely a cudnn bug. We will skip this algorithm in the future, but your GPU state may already be corrupted, leading to incorrect results. Within Google, no action is needed on your part. Outside of Google, please ensure you're running the latest version of cudnn. If that doesn't fix the problem, please file a bug with this full error message and we'll contact nvidia.\r\n2019-09-26 17:28:07.144361: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:166] Redzone mismatch in LHS redzone of buffer 0x7fd3e5090200 at offset 0; expected ffffffffffffffff but was 3b0387303ca4a820.\r\n2019-09-26 17:28:07.144396: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:167] HloInstruction %custom-call = (f32[5,5,2,64]{1,0,2,3}, u8[0]{0}) custom-call(f32[155,2,64,64]{3,2,1,0} %arg8.9, f32[155,64,60,60]{3,2,1,0} %select.42), window={size=5x5}, dim_labels=bf01_01io->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"HICO_1/gradients/HICO_0/resnet_v1_50_3/conv1_sp/Conv2D_grad/Conv2DBackpropFilter\"}, backend_config=\"{\\\"convResultScale\\\":1}\"\r\n2019-09-26 17:28:07.144406: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:112] Device: GeForce RTX 2080 Ti\r\n2019-09-26 17:28:07.144414: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:113] Platform: Compute Capability 7.5\r\n2019-09-26 17:28:07.144422: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:114] Driver: 10010 (418.87.0)\r\n2019-09-26 17:28:07.144429: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:115] Runtime: <undefined>\r\n2019-09-26 17:28:07.144440: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:122] cudnn version: 7.6.2\r\n2019-09-26 17:28:07.161422: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:157] Detected cudnn out-of-bounds write in conv input/output buffer! This is likely a cudnn bug. We will skip this algorithm in the future, but your GPU state may already be corrupted, leading to incorrect results. Within Google, no action is needed on your part. Outside of Google, please ensure you're running the latest version of cudnn. If that doesn't fix the problem, please file a bug with this full error message and we'll contact nvidia.\r\n2019-09-26 17:28:07.161467: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:166] Redzone mismatch in LHS redzone of buffer 0x7fd3e5090200 at offset 0; expected ffffffffffffffff but was 3b0387303ca4a820.\r\n2019-09-26 17:28:07.161501: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:167] HloInstruction %custom-call = (f32[5,5,2,64]{1,0,2,3}, u8[0]{0}) custom-call(f32[155,2,64,64]{3,2,1,0} %arg8.9, f32[155,64,60,60]{3,2,1,0} %select.42), window={size=5x5}, dim_labels=bf01_01io->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"HICO_1/gradients/HICO_0/resnet_v1_50_3/conv1_sp/Conv2D_grad/Conv2DBackpropFilter\"}, backend_config=\"{\\\"convResultScale\\\":1}\"\r\n2019-09-26 17:28:07.161512: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:112] Device: GeForce RTX 2080 Ti\r\n2019-09-26 17:28:07.161520: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:113] Platform: Compute Capability 7.5\r\n2019-09-26 17:28:07.161529: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:114] Driver: 10010 (418.87.0)\r\n2019-09-26 17:28:07.161536: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:115] Runtime: <undefined>\r\n2019-09-26 17:28:07.161547: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:122] cudnn version: 7.6.2\r\n2019-09-26 17:28:07.176122: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:157] Detected cudnn out-of-bounds write in conv input/output buffer! This is likely a cudnn bug. We will skip this algorithm in the future, but your GPU state may already be corrupted, leading to incorrect results. Within Google, no action is needed on your part. Outside of Google, please ensure you're running the latest version of cudnn. If that doesn't fix the problem, please file a bug with this full error message and we'll contact nvidia.\r\n2019-09-26 17:28:07.176175: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:166] Redzone mismatch in LHS redzone of buffer 0x7fd3e5090200 at offset 0; expected ffffffffffffffff but was 3b0387303ca4a820.\r\n2019-09-26 17:28:07.176206: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:167] HloInstruction %custom-call = (f32[5,5,2,64]{1,0,2,3}, u8[0]{0}) custom-call(f32[155,2,64,64]{3,2,1,0} %arg8.9, f32[155,64,60,60]{3,2,1,0} %select.42), window={size=5x5}, dim_labels=bf01_01io->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"HICO_1/gradients/HICO_0/resnet_v1_50_3/conv1_sp/Conv2D_grad/Conv2DBackpropFilter\"}, backend_config=\"{\\\"convResultScale\\\":1}\"\r\n2019-09-26 17:28:07.176217: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:112] Device: GeForce RTX 2080 Ti\r\n2019-09-26 17:28:07.176226: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:113] Platform: Compute Capability 7.5\r\n2019-09-26 17:28:07.176234: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:114] Driver: 10010 (418.87.0)\r\n2019-09-26 17:28:07.176241: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:115] Runtime: <undefined>\r\n2019-09-26 17:28:07.176253: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:122] cudnn version: 7.6.2\r\n2019-09-26 17:28:07.191145: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:157] Detected cudnn out-of-bounds write in conv input/output buffer! This is likely a cudnn bug. We will skip this algorithm in the future, but your GPU state may already be corrupted, leading to incorrect results. Within Google, no action is needed on your part. Outside of Google, please ensure you're running the latest version of cudnn. If that doesn't fix the problem, please file a bug with this full error message and we'll contact nvidia.\r\n2019-09-26 17:28:07.191200: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:166] Redzone mismatch in LHS redzone of buffer 0x7fd3e5090200 at offset 0; expected ffffffffffffffff but was 3b0387303ca4a820.\r\n2019-09-26 17:28:07.191232: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:167] HloInstruction %custom-call = (f32[5,5,2,64]{1,0,2,3}, u8[0]{0}) custom-call(f32[155,2,64,64]{3,2,1,0} %arg8.9, f32[155,64,60,60]{3,2,1,0} %select.42), window={size=5x5}, dim_labels=bf01_01io->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"HICO_1/gradients/HICO_0/resnet_v1_50_3/conv1_sp/Conv2D_grad/Conv2DBackpropFilter\"}, backend_config=\"{\\\"convResultScale\\\":1}\"\r\n2019-09-26 17:28:07.191243: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:112] Device: GeForce RTX 2080 Ti\r\n2019-09-26 17:28:07.191251: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:113] Platform: Compute Capability 7.5\r\n2019-09-26 17:28:07.191259: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:114] Driver: 10010 (418.87.0)\r\n2019-09-26 17:28:07.191266: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:115] Runtime: <undefined>\r\n2019-09-26 17:28:07.191279: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:122] cudnn version: 7.6.2\r\n2019-09-26 17:28:07.207762: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:157] Detected cudnn out-of-bounds write in conv input/output buffer! This is likely a cudnn bug. We will skip this algorithm in the future, but your GPU state may already be corrupted, leading to incorrect results. Within Google, no action is needed on your part. Outside of Google, please ensure you're running the latest version of cudnn. If that doesn't fix the problem, please file a bug with this full error message and we'll contact nvidia.\r\n2019-09-26 17:28:07.207808: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:166] Redzone mismatch in LHS redzone of buffer 0x7fd3e5090200 at offset 0; expected ffffffffffffffff but was 3b0387303ca4a820.\r\n2019-09-26 17:28:07.207856: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:167] HloInstruction %custom-call = (f32[5,5,2,64]{1,0,2,3}, u8[0]{0}) custom-call(f32[155,2,64,64]{3,2,1,0} %arg8.9, f32[155,64,60,60]{3,2,1,0} %select.42), window={size=5x5}, dim_labels=bf01_01io->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"HICO_1/gradients/HICO_0/resnet_v1_50_3/conv1_sp/Conv2D_grad/Conv2DBackpropFilter\"}, backend_config=\"{\\\"convResultScale\\\":1}\"\r\n2019-09-26 17:28:07.207867: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:112] Device: GeForce RTX 2080 Ti\r\n2019-09-26 17:28:07.207874: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:113] Platform: Compute Capability 7.5\r\n2019-09-26 17:28:07.207881: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:114] Driver: 10010 (418.87.0)\r\n2019-09-26 17:28:07.207889: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:115] Runtime: <undefined>\r\n2019-09-26 17:28:07.207901: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:122] cudnn version: 7.6.2\r\n2019-09-26 17:28:07.225787: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:157] Detected cudnn out-of-bounds write in conv input/output buffer! This is likely a cudnn bug. We will skip this algorithm in the future, but your GPU state may already be corrupted, leading to incorrect results. Within Google, no action is needed on your part. Outside of Google, please ensure you're running the latest version of cudnn. If that doesn't fix the problem, please file a bug with this full error message and we'll contact nvidia.\r\n2019-09-26 17:28:07.225859: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:166] Redzone mismatch in LHS redzone of buffer 0x7fd3e5090200 at offset 0; expected ffffffffffffffff but was 3b0387303ca4a820.\r\n2019-09-26 17:28:07.225900: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:167] HloInstruction %custom-call = (f32[5,5,2,64]{1,0,2,3}, u8[0]{0}) custom-call(f32[155,2,64,64]{3,2,1,0} %arg8.9, f32[155,64,60,60]{3,2,1,0} %select.42), window={size=5x5}, dim_labels=bf01_01io->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"HICO_1/gradients/HICO_0/resnet_v1_50_3/conv1_sp/Conv2D_grad/Conv2DBackpropFilter\"}, backend_config=\"{\\\"convResultScale\\\":1}\"\r\n2019-09-26 17:28:07.225934: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:112] Device: GeForce RTX 2080 Ti\r\n2019-09-26 17:28:07.225948: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:113] Platform: Compute Capability 7.5\r\n2019-09-26 17:28:07.225966: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:114] Driver: 10010 (418.87.0)\r\n2019-09-26 17:28:07.225981: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:115] Runtime: <undefined>\r\n2019-09-26 17:28:07.226003: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:122] cudnn version: 7.6.2\r\n2019-09-26 17:28:07.226796: E tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:525] Internal: All algorithms tried for convolution %custom-call = (f32[5,5,2,64]{1,0,2,3}, u8[0]{0}) custom-call(f32[155,2,64,64]{3,2,1,0} %arg8.9, f32[155,64,60,60]{3,2,1,0} %select.42), window={size=5x5}, dim_labels=bf01_01io->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"HICO_1/gradients/HICO_0/resnet_v1_50_3/conv1_sp/Conv2D_grad/Conv2DBackpropFilter\"}, backend_config=\"{\\\"convResultScale\\\":1}\" failed.  Falling back to default algorithm.\r\n", "comments": ["Can you please provide the exact sequence of commands / steps that you executed before running into the problem.Thanks!", "well, I just try to merge two branch (ResNet50) to construct new loss. And then, it will run into the problem occasionally. My program will continue to run even though running into that problem.\r\n\r\nhere is my peseude code:\r\n\r\n      with sess.graph.as_default(), tf.device('/cpu:0'):\r\n           \r\n            for i in range(2):\r\n                gpu_idx = i\r\n                if len(os.environ['CUDA_VISIBLE_DEVICES'].split(',')) == 1:  # 1 gpu is ok.\r\n                    gpu_idx = 0\r\n                with tf.device('/gpu:%d' % gpu_idx):\r\n                    with tf.name_scope('%s_%d' % ('test', i), ) as scope:\r\n\r\n                        self.net.set_ph(tensor_from_dataset_api) # image\r\n\r\n                        # Build the main computation graph\r\n                        layers = self.net.create_architecture(True)  # is_training flag: True\r\n\r\n                        # Define the loss\r\n                        loss = layers['total_loss']\r\n                        tower_losses.append(loss)\r\n                        if i == 1:\r\n                            variables = tf.trainable_variables()\r\n                            grads_and_vars = self.optimizer.compute_gradients(tf.reduce_sum(tower_losses), variables)\r\n\r\n            capped_gvs = [(tf.clip_by_norm(grad, 1.), var) for grad, var in grads_and_vars if grad is not None]\r\n            train_op = self.optimizer.apply_gradients(capped_gvs, global_step=global_step)\r\n            tf.summary.scalar('lr', lr)\r\n            # tf.summary.scalar('merge_loss', new_loss)\r\n            self.net.summary_op = tf.summary.merge_all()\r\n\r\n\r\nwhen I use the average_gradients style, everything is right. here is my successful code. \r\n\r\n       with sess.graph.as_default(), tf.device('/cpu:0'):\r\n            for i in range(2):\r\n                gpu_idx = i\r\n                if len(os.environ['CUDA_VISIBLE_DEVICES'].split(',')) == 1: \r\n                    gpu_idx = 0\r\n                with tf.device('/gpu:%d' % gpu_idx):\r\n                    with tf.name_scope('%s_%d' % ('test', i), ) as scope:\r\n         \r\n                        self.net.set_ph(tensor_from_dataset_api ) # image\r\n\r\n                        # Build the main computation graph\r\n                        layers = self.net.create_architecture(True)  # is_training flag: True\r\n\r\n                        # Define the loss\r\n                        loss = layers['total_loss']\r\n                        tower_losses.append(loss)\r\n                        variables = tf.trainable_variables()\r\n                        grads_and_vars = self.optimizer.compute_gradients(loss, variables)\r\n                        tower_grads.append(grads_and_vars)\r\n            grads_and_vars = self.average_gradients(tower_grads)\r\n            capped_gvs = [(tf.clip_by_norm(grad, 1.), var) for grad, var in grads_and_vars if grad is not None]\r\n            train_op = self.optimizer.apply_gradients(capped_gvs, global_step=global_step)\r\n            tf.summary.scalar('lr', lr)\r\n            self.net.summary_op = tf.summary.merge_all()\r\n\r\nNoticeably, the two images putted into GPU have different size. And my network is Resnet50 for Detection. It don't know whether it does matter.\r\n\r\nBesides, **if I run the code within one GPU, it won't run into that problem.**\r\n", "@xxxzhi \r\nLooks like code is incomplete.In order to expedite the trouble-shooting process, please provide a minimal standalone code to reproduce the issue reported here. Thanks!", "@xxxzhi \r\n\r\nAny update please?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 32835, "title": "TF doesn't build anymore with Bazel's --incompatible_remove_legacy_whole_archive", "body": "Some time ago we migrated Tensorflow to build with this flag flipped, but it regressed again (https://buildkite.com/bazel/bazel-at-head-plus-downstream/builds/1207#d1e5940d-bde3-46cd-8734-1b6f2fddabf5).\r\n\r\nThe incompatible flag: https://github.com/bazelbuild/bazel/issues/7362\r\n\r\nI'm looking into it. This is a tracking issue for this effort :)", "comments": ["(Assigning to @hlopko to detach this issue from our auto-assignment pipeline. Thanks for tracking this!)", "I have a fix for this.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32835\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32835\">No</a>\n"]}, {"number": 32834, "title": "[INTEL MKL] Add Weight caching in MKL Quantized Matmul Op", "body": "This PR adds weight buffer caching that improves the performance in scenarios where the weight buffer format is not same as the MKL-DNN expected format. This is achieved by reordering the weight for the first time and caching the same for re-using it in subsequent iterations. \r\n", "comments": ["@rgomathi Could you please check reviewer comments and keep us posted. Thanks!", "Hi @gbaned, I addressed the review comments and just double checking them with colleagues internally. I will submit them ASAP. Sorry for the delay.", "Hi @penpornk,  I've addressed the review comments and pushed the patch. Please review. Sorry for the delay....", "Hi @penpornk , I accepted the change and committed here itself . Hope it is fine. Thanks", "Hi @penpornk , Please let me know if anything else is pending from my side. Thanks", "No worries and Thanks !"]}, {"number": 32833, "title": "TF 2.0 RC Image Segmentation Tutorial", "body": "The tutorial is found here: https://www.tensorflow.org/beta/tutorials/images/segmentation\r\n\r\nIn cell 10, the provided Google Colab Notebook has the following error:\r\nOperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.\r\n", "comments": ["@calciver ,\r\nI tried executing the tutorial using TF-2.0rc2 and it worked fine. Kindly find the [gist](https://colab.sandbox.google.com/gist/oanush/621fbdbda1301e9e3ffeb4479916583e/untitled11.ipynb) of colab.Thanks!", "Thanks, that helped. Glad to know this was resolved in TF-2.0rc2.\r\nHope google colab supports the latest version of TF 2.0 in time.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32833\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32833\">No</a>\n"]}, {"number": 32832, "title": "Support TRANSPOSE on GPU Delegate", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android \r\n- TensorFlow installed from (source or binary): binary(tensorflow-lite-gpu:0.0.0-nightly)\r\n- TensorFlow version (or github SHA if from source):\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\n# Copy and paste here\r\n```\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\nMy model is quantilized to FP16.\r\n\r\n**Any other info / logs**\r\n05-19 15:05:29.819 +0000 21043 21043 W TFLiteInfer: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: Next operations are not supported by GPU delegate:\r\n05-19 15:05:29.819 +0000 21043 21043 W TFLiteInfer: TRANSPOSE: Operation is not supported.\r\n05-19 15:05:29.819 +0000 21043 21043 W TFLiteInfer: First 129 operations will run on the GPU, and the remaining 175 on the CPU.tensorflow/lite/kernels/fully_connected.cc:110 is_optional_bias_float != true (0 != 1)Node number 35 (FULLY_CONNECTED) failed to prepare.\r\n05-19 15:05:29.819 +0000 21043 21043 W TFLiteInfer: tensorflow/lite/kernels/conv.cc:259 bias->type != input_type (10 != 1)Node number 3 (CONV_2D) failed to prepare.\r\n", "comments": ["@liakopyangsir ,\r\nProvide the exact sequence of commands / steps that you executed before running into the problem.Thanks!\r\n", "@liakopyangsir ,\r\nAny update on the issue ?Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Same issue here, please reopen"]}, {"number": 32831, "title": "Failed to compile with CUDA 10.1 on Windows", "body": "Trying to build TF with CUDA 10.1 support with following env:\r\n\r\n**Enviroment**\r\n``` \r\nOS: Winwdows Pro 64 bits, 1903, 18362.356\r\nbazel : 0.26.1\r\nmsys64 : MYSIS2 64 Bit, 20190524\r\nVisual Studio: Community 2019,  Version 16.3.1\r\nCUDA: 10.1, cuda_10.1.243_426.00_win10\r\n  - cuDNN : cudnn-10.1-windows10-x64-v7.6.3.30\r\n  - TensorRT : TensorRT-6.0.1.5.Windows10.x86_64.cuda-10.1.cudnn7.6\r\nConda : 4.7.10, 64 bits\r\n  - Python : 3.6.9\r\nCPU: E5-2678 v3\r\nGPU: RTX 2080\r\n\r\n**Target** TF version: v2.0.0-rc1\r\n```\r\n\r\n**Steps to reproduce the issue**\r\nBasically, following https://www.tensorflow.org/install/source_windows on a fresh installed Windows OS.\r\n\r\nA detailed note: \r\nhttps://github.com/LiyuCode/blue_notes/blob/master/Windows/Tensorflow/tensorflow_with_latest_cuda_on_windows.md .\r\n\r\n**Problem**\r\nFailed to compile when executing the following command: \r\n\r\n```\r\nbazel build --config=opt --config=cuda --config=v2 --define=no_tensorflow_py_deps=true --copt=-nvcc_options=disable-warnings //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\nThe error message:\r\n```\r\nC:\\users\\lcode\\_bazel_lcode\\hagsv6rp\\execroot\\org_tensorflow\\external\\eigen_archive\\unsupported\\Eigen\\CXX11\\src/Tensor/TensorExecutor.h(381): error: calling a __host__ function(\"std::operator -<float> \") from a __device__ function(\"Eigen::internal::EigenMetaKernelEval< ::Eigen::TensorEvaluator<const  ::Eigen::TensorAssignOp< ::Eigen::TensorMap< ::Eigen::Tensor<    ::std::complex<float> , (int)1, (int)1, int> , (int)16,  ::Eigen::MakePointer> , const  ::Eigen::TensorCwiseUnaryOp< ::Eigen::internal::scalar_opposite_op<    ::std::complex<float> > , const  ::Eigen::TensorMap< ::Eigen::Tensor<const     ::std::complex<float> , (int)1, (int)1, int> , (int)16,  ::Eigen::MakePointer> > > ,  ::Eigen::GpuDevice> , int, (bool)0> ::run\") is not allowed\r\n\r\nC:\\users\\lcode\\_bazel_lcode\\hagsv6rp\\execroot\\org_tensorflow\\external\\eigen_archive\\unsupported\\Eigen\\CXX11\\src/Tensor/TensorExecutor.h(381): error: identifier \"std::operator -<float> \" is undefined in device code\r\n\r\nC:\\users\\lcode\\_bazel_lcode\\hagsv6rp\\execroot\\org_tensorflow\\external\\eigen_archive\\unsupported\\Eigen\\CXX11\\src/Tensor/TensorExecutor.h(381): error: calling a __host__ function(\"std::operator -<double> \") from a __device__ function(\"Eigen::internal::EigenMetaKernelEval< ::Eigen::TensorEvaluator<const  ::Eigen::TensorAssignOp< ::Eigen::TensorMap< ::Eigen::Tensor<    ::std::complex<double> , (int)1, (int)1, int> , (int)16,  ::Eigen::MakePointer> , const  ::Eigen::TensorCwiseUnaryOp< ::Eigen::internal::scalar_opposite_op<    ::std::complex<double> > , const  ::Eigen::TensorMap< ::Eigen::Tensor<const     ::std::complex<double> , (int)1, (int)1, int> , (int)16,  ::Eigen::MakePointer> > > ,  ::Eigen::GpuDevice> , int, (bool)0> ::run\") is not allowed\r\n\r\nC:\\users\\lcode\\_bazel_lcode\\hagsv6rp\\execroot\\org_tensorflow\\external\\eigen_archive\\unsupported\\Eigen\\CXX11\\src/Tensor/TensorExecutor.h(381): error: identifier \"std::operator -<double> \" is undefined in device code\r\n\r\n4 errors detected in the compilation of \"C:/Users/lcode/AppData/Local/Temp/nvcc_inter_files_tmp_dir/tmp_5sdgd1b/cwise_op_gpu_neg.cu.compute_75.cpp1.ii\".\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 1023.611s, Critical Path: 353.85s\r\nINFO: 3709 processes: 3709 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\n**Other info**\r\n1. Compillation was ok about two days ago with same steps on a different computer\r\n2. if checkout `v2.0.0-rc2` instead of `v2.0.0-rc1`, same error will occure.\r\n", "comments": ["@LiyuCode, Thanks for reporting this issue.\r\nCould you try compiling with CUDA 10.0. \r\nPlease take a look at [software requirements](https://www.tensorflow.org/install/gpu#software_requirements). Thanks! ", "@LiyuCode, Were you able resolve this issue. Thanks", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32831\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32831\">No</a>\n"]}]