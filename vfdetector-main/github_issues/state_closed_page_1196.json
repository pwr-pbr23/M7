[{"number": 17303, "title": "%matplotlib inline invalid syntax for Python 2.7, Python3.5, Python3.6 and IronPython 6.2.1", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOSX El Capitan\r\n- **TensorFlow installed from (source or binary)**: NO\r\n- **TensorFlow version (use command below)**: N/A\r\n- **Python version**: Tried 2.7, 3.5 and 3.6.4 as well as ipython 6.2.1 same issue\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: python <scriptname>\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nLet's not be ridiculous.\r\n\r\n### Describe the problem\r\nThis is an issue with this page on your site:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/1_notmnist.ipynb\r\n\r\nIt relates to the very first script on that page the last line of which is:\r\n%matplotlib inline\r\n\r\nThis line of code yields a syntax error on every single platform I have tested the script (copied verbatim) on.  There is obviously something missing from your documentation.\r\n\r\n### Source code / logs\r\nlesson1$ ipython importall.py \r\n  File \"/Users/****/MachineLearning/lesson1/importall.py\", line 17\r\n    %matplotlib inline\r\n    ^\r\nSyntaxError: invalid syntax\r\n\r\nlesson1$ python importall.py \r\n  File \"importall.py\", line 17\r\n    %matplotlib inline\r\n    ^\r\nSyntaxError: invalid syntax", "comments": ["This is invalid Python code, but it's valid in an IPython notebook (which is what that file is). You can safely drop it from that example, which doesn't actually use matplotlib to make plots."]}, {"number": 17302, "title": "Failed to load the native TensorFlow runtime", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: \r\n- **Python version**: tensorflow_gpu-1.5\r\n- **GCC/Compiler version (if compiling from source)**: 5.4\r\n- **CUDA/cuDNN version**: CUDA = 8, cuDNN = v6\r\n- **GPU model and memory**: Nvidia 920MX , 2 GB\r\n\r\n### Describe the problem\r\nNot able to import Tensorflow.\r\nIs it because I installed CUDA 8 rather than 9?\r\n\r\n### Source code / logs\r\nPython 3.5.2 (default, Nov 23 2017, 16:37:01) \r\n[GCC 5.4.0 20160609] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"/home/scene-analysis/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/home/scene-analysis/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/home/scene-analysis/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/usr/lib/python3.5/imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/usr/lib/python3.5/imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/scene-analysis/.local/lib/python3.5/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"/home/scene-analysis/.local/lib/python3.5/site-packages/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/home/scene-analysis/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/home/scene-analysis/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/home/scene-analysis/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/home/scene-analysis/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/usr/lib/python3.5/imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/usr/lib/python3.5/imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "Same problems here. Did you find a solution to this? Can't understand why tensorflow is looking for libcublas.so.9.0 while only cuda 8.0 is installed. We know that tensorflow 1.5 is compatible with cuda 8.0."]}, {"number": 17301, "title": "Tensorflow 1.5.0 manylinux binary requires Numpy 1.14.1", "body": "On Travis-CI using Python 3.6 Numpy 1.13.2 is installed. Trying to use the `tensorflow` manylinux binary from PyPi will result in:\r\n\r\n```\r\nRuntimeError: module compiled against API version 0xc but this version of numpy is 0xb\r\n```\r\n\r\nA log from a broken build is here:\r\n\r\nhttps://travis-ci.org/TwentyBN/ionn/jobs/344881411\r\n\r\nFixing the `.travis.yml` like so:\r\n\r\nhttps://github.com/TwentyBN/ionn/commit/24ced51bb26d78aa5fed265ed9196f47da4d7d6d\r\n\r\nProduces a green build like here:\r\n\r\nhttps://travis-ci.org/TwentyBN/ionn/jobs/346796560\r\n\r\nReading the build log, Numpy is updated like so:\r\n\r\n```\r\n$ pip install -U numpy\r\nCollecting numpy\r\n  Downloading numpy-1.14.1-cp36-cp36m-manylinux1_x86_64.whl (12.2MB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 12.2MB 57kB/s \r\nInstalling collected packages: numpy\r\n  Found existing installation: numpy 1.13.3\r\n    Uninstalling numpy-1.13.3:\r\n      Successfully uninstalled numpy-1.13.3\r\nSuccessfully installed numpy-1.14.1\r\n```\r\n\r\nPlease set the minimum version for Tensorflow 1.5.0 on Python 3.6 to Numpy 1.14.1. Thanks!", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Have I written custom code : no\r\nOS Platform and Distribution : Linux - Travis-CI - Trusty\r\nTensorFlow installed from : PyPi\r\nTensorFlow version: 1.5.0 (Python 3.6)\r\nBazel version : N/A\r\nCUDA/cuDNN version : N/A\r\nGPU model and memory : N/A\r\nExact command to reproduce : N/A", "Nagging Assignee @bignamehyp: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I'm not sure we are officially support travis-CI. So what's the current minimum version for Tensorflow 1.5.0 on Python 3.6?\r\n", "`1.14.1`", "@yifeif  can you please take a look? Thanks", "Nagging Assignee @bignamehyp: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @bignamehyp: It has been 30 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @bignamehyp: It has been 45 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Thanks for reporting @esc. Sorry missed this one. From TF 1.6+, we have updated the numpy dependency to >=1.13.3. Closing this."]}, {"number": 17300, "title": "Why Run a short TensorFlow program\uff0cprint b'Hello,TensorFlow' ", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["Instead of Hello, TensorFlow", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 17299, "title": "Branch 187165096", "body": "", "comments": ["@gunan Is this \"Ubuntu Makefile\" build failure existing?\r\nhttps://source.cloud.google.com/results/invocations/23166fad-c43f-4295-91f2-d62643238d02/targets", "It seems to be passing at head."]}, {"number": 17298, "title": "[XLA] Allow the large R1 slice tests to be disabled", "body": "The unit tests for the R1 slice have some large values.  This change moves the large valued tests into a different test name in order to allow the blacklist manifest mechanism to disable them for any specific backend/device.\r\n\r\n", "comments": ["fixed up the merge conflict.\r\n", "thanks :)\r\n", "hi - could we get this merged before merge conflicts cause a problem?  cheers."]}, {"number": 17297, "title": "Expectations of MonitoredTrainingSession for saving and restoring (fixes inside)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n\r\nNo, anything discussed here is valid with the cifar10 model script -- https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_train.p\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n\r\nUbuntu 16.04, but should be platform independent\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\n\r\nBinary\r\n\r\n- **TensorFlow version (use command below)**:\r\n\r\n1.5\r\n\r\n- **Python version**: \r\n\r\n3.5\r\n\r\n- **Bazel version (if compiling from source)**:\r\n\r\nN / A\r\n\r\n- **GCC/Compiler version (if compiling from source)**:\r\n\r\nN / A\r\n\r\n- **CUDA/cuDNN version**:\r\n\r\n7\r\n\r\n- **GPU model and memory**:\r\n\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\n\r\n`MonitoredTrainingSession` is the simplest and, to my knowledge, often recommended way to run a training session that can easily be saved and restored. I think there is some confusion here that could be cleared up by fixing two things:\r\n\r\n1) `MonitoredTrainingSession` does not restore the global step.\r\n\r\nIf one creates a step with `tf.train.get_or_create_global_step()`, and even if this is passed into the optimizer, `MonitoredTrainingSession` will not restore the correct value in a new session. Instead, it starts it again from 0. This has been mentioned several times, here are some references:\r\n\r\n- https://github.com/tensorflow/tensorflow/issues/6081\r\n- https://stackoverflow.com/questions/36113090/how-to-get-the-global-step-when-restoring-checkpoints-in-tensorflow\r\n- https://stackoverflow.com/questions/47932738/tensorflow-restoring-model-in-a-monitoredsession?rq=1\r\n\r\nThe only solution that I've found works is to extract the step from the checkpoint filename manually, and add an operation to set it on restore, via something like\r\n\r\n`step = int(os.path.basename(ckpt.model_checkpoint_path).split('-')[1])`\r\n\r\nIt would be great if this could be fixed so global steps are properly restored as well.\r\n\r\n2) Instead of `checkpoint_dir` as an argument, `MonitoredTrainingSession` should probably have a `save_checkpoint_dir` and a `restore_checkpoint_dir`.\r\n\r\nThe reason why this is important is that TensorBoard does not support appending to summary files. This means that a restored session, to my knowledge, can only be viewed in TensorBoard if a new directory is used to write the new event files instead of the directory it was restored from. If that is not done, TensorBoard simply strips the events away and does not display them. It took me time to understand this was what was happening.\r\n\r\nUnfortunately, `MonitoredTrainingSession` does not support a different save directory at the moment, so the way to make `MonitoredTrainingSession` work with TensorBoard on restore is to create your own summary hooks. But this defeats part of what `MonitoredTrainingSession` is supposed to do for you.\r\n\r\nI believe this would be fixed with different save and restore directory, as specified above. A comment about how a different save directory is needed for TensorBoard visualization would also be helpful in the `MonitoredTrainingSession` documentation.", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "It's actually both a bug report and a feature request.\r\n\r\nBug:\r\n```\r\nMonitoredTrainingSession does not restore the global step.\r\n```\r\n\r\nFeature request:\r\n```\r\nInstead of checkpoint_dir as an argument, MonitoredTrainingSession should probably have a save_checkpoint_dir and a restore_checkpoint_dir.\r\n```"]}, {"number": 17296, "title": "retraining on gpu causing high clone loss", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Linux 16.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.5.0\r\n- **Python version**: 3.6.3\r\n- **Bazel version (if compiling from source)**:  0.9\r\n- **GCC/Compiler version (if compiling from source)**: 5.4.0\r\n- **CUDA/cuDNN version**: 9.1\r\n- **GPU model and memory**: gtx 1050 ti\r\n- **Exact command to reproduce**:\r\n\r\nTensorflow gpu produces strange clone loss(very high) while retraining with resnet 50, the loss though is not produced while retraining on a cpu. What could be the cause of this behaviour?\r\n![resnet_50](https://user-images.githubusercontent.com/6937974/36727785-895590c4-1be4-11e8-8449-c5a8c7d28fc0.png)\r\n\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "Well, I feel it is a bug because this behaviour is not featured by other models. Also, I have already asked the question on stack overflow with no help and hence had to post it on git", "Hi @angersson have been trying to fix this from past 15 days but in vain, have already posted it on stack overflow, but have not been able to get any answers. Could you please give some clue to fix this problem?", "Hi, I had the same issue. For me it seems to have been related to memory issues on the GPU and occured when I ran evaluation jobs at the same time. "]}, {"number": 17295, "title": "[XLA] Ensure that the backend_deps is a non-frozen object", "body": "New code in the `xla_test()` generator writes to the `backend_deps` variable.  In the plugin backends this was referencing a piece of static data which was a frozen object.\r\n\r\nNow make a standard `backend_deps` variable and append the plugin information to it.\r\n\r\n", "comments": ["hi there.  wonder if we could get this one reviewed.  it is a very minor change.\r\n", "thanks :)\r\n\r\nI could be wrong, but i suspect that the particular failure isn't anything to do with these changes.", "hi - could we get this merged before merge conflicts cause a problem?  cheers."]}, {"number": 17294, "title": "FileWriter instance can not invoke close normally", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nyes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n4.9.0-4-amd64 #1 SMP Debian 4.9.65-3+deb9u1 (2017-12-23) x86_64 GNU/Linux\r\n- **TensorFlow installed from (source or binary)**:\r\nvia pip3 for python3.5.3 \r\n- **TensorFlow version (use command below)**:\r\nv1.5.0-0-g37aa430d84 1.5.0\r\n- **Python version**: \r\n3.5.3\r\n- **Bazel version (if compiling from source)**: NO\r\n- **GCC/Compiler version (if compiling from source)**: NO\r\n- **CUDA/cuDNN version**: NO\r\n- **GPU model and memory**: 256G RAM\r\n- **Exact command to reproduce**:\r\npython virtualenv and tensorboard\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\n### Describe the problem\r\nloggingMXNet summary data with tensorflow-tensorboard, but FileWriter close method can not execute successfully without any errors or warnings\r\n\r\n### Source code / logs\r\nin my case , without any extra info, but just i use minist dataset to training MXNet digits recongnition model and wrap tensorboard event writer into MXNet fit callback , by location, i found close method failed to exec.\r\n\r\n\r\nIS there anyone faced with similar/same issue? if exists, please share your ideas.\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 17293, "title": "Bazel Build fails after updating", "body": "After updating my local copy of TensorFlow from the github repository the Bazel build failed with the following error (see below). However, the same command successfully built version 1.5 of TensorFlow. \r\n\r\nOS: SLES12\r\nPython version: 3.6\r\nBazel version: Build label: 0.7.0- (@non-git)\r\ngcc version 7.2.0 (GCC)\r\nNo GPU\r\nNo CUDA\r\n\r\nbuild command:\r\nbazel build --config=mkl --copt=\"-DEIGEN_USE_VML\" -s -c opt //tensorflow/tools/pip_package:build_pip_package --verbose_failures\r\n\r\nERROR: /home/hpc/pr28fa/di72giz/TENSORFLOW/tensorflow/tensorflow/BUILD:399:12: Label '//tensorflow:tools/integration_tests/gcs_smoke_test/gcs_smoke.py' crosses boundary of subpackage 'tensorflow/tools/integration_tests/gcs_smoke_test' (perhaps you meant to put the colon here: '//tensorflow/tools/integration_tests/gcs_smoke_test:gcs_smoke.py'?).\r\nERROR: /home/hpc/pr28fa/di72giz/TENSORFLOW/tensorflow/tensorflow/BUILD:399:12: Label '//tensorflow:tools/integration_tests/gcs_smoke_test/setup.sh' crosses boundary of subpackage 'tensorflow/tools/integration_tests/gcs_smoke_test' (perhaps you meant to put the colon here: '//tensorflow/tools/integration_tests/gcs_smoke_test:setup.sh'?).\r\nERROR: /home/hpc/pr28fa/di72giz/TENSORFLOW/tensorflow/tensorflow/BUILD:399:12: Label '//tensorflow:tools/integration_tests/gcs_smoke_test/BUILD.bazel' crosses boundary of subpackage 'tensorflow/tools/integration_tests/gcs_smoke_test' (perhaps you meant to put the colon here: '//tensorflow/tools/integration_tests/gcs_smoke_test:BUILD.bazel'?).\r\nERROR: /home/hpc/pr28fa/di72giz/TENSORFLOW/tensorflow/tensorflow/BUILD:399:12: Label '//tensorflow:tools/integration_tests/gcs_smoke_test/teardown.sh' crosses boundary of subpackage 'tensorflow/tools/integration_tests/gcs_smoke_test' (perhaps you meant to put the colon here: '//tensorflow/tools/integration_tests/gcs_smoke_test:teardown.sh'?).\r\nERROR: /home/hpc/pr28fa/di72giz/TENSORFLOW/tensorflow/tensorflow/BUILD:399:12: Label '//tensorflow:tools/integration_tests/gcs_smoke_test/test_wrapper.sh' crosses boundary of subpackage 'tensorflow/tools/integration_tests/gcs_smoke_test' (perhaps you meant to put the colon here: '//tensorflow/tools/integration_tests/gcs_smoke_test:test_wrapper.sh'?).\r\nERROR: /home/hpc/pr28fa/di72giz/TENSORFLOW/tensorflow/tensorflow/tools/pip_package/BUILD:134:1: Target '//tensorflow:windows' contains an error and its package is in error and referenced by '//tensorflow/tools/pip_package:build_pip_package'.\r\nERROR: /home/hpc/pr28fa/di72giz/TENSORFLOW/tensorflow/tensorflow/tools/pip_package/BUILD:134:1: Target '//tensorflow:windows_msvc' contains an error and its package is in error and referenced by '//tensorflow/tools/pip_package:build_pip_package'.\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Loading failed.\r\n\r\n\r\n", "comments": ["I\u2018ve encountered the same problem.\r\n\r\nOS: Windows 10, x64,\r\nBazel 0.5.4,\r\nMSYS2, \r\nPython 2.7,\r\nGPU-support enabled: CUDA 9.0 Toolkit, cuDNN 7.0,\r\nVisual Studio 2017 community,\r\n\r\nbuild command issued in MSYS2: \r\n\r\n`bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 --copt=-march=native --config=mkl --config=win-cuda //tensorflow/tools/pip_package:build_pip_package`\r\n\r\n", "Can you try using a newer version of bazel (v0.11.0)?", "I had the same problem and it went away after updating to bazel 0.11.0\r\n\r\nThe configuration I had when I saw that error:\r\n\r\nOS: Ubuntu 16.04.3 LTS\r\nPython version: 2.7.12\r\nBazel version: Build label: 0.7.0- (@non-git)\r\ngcc version 5.4.0 (GCC)\r\nNo GPU\r\nNo CUDA\r\n\r\nThe configuration that works is the same, except:\r\n\r\nBazel version: Build label: 0.11.0- (@non-git)\r\n", "I had the same problem\r\nRROR: /media/berli/DataCenter/Test/tensorflow/tensorflow/BUILD:399:12: Label '//tensorflow:tools/integration_tests/gcs_smoke_test/gcs_smoke.py' crosses boundary of subpackage 'tensorflow/tools/integration_tests/gcs_smoke_test' (perhaps you meant to put the colon here: '//tensorflow/tools/integration_tests/gcs_smoke_test:gcs_smoke.py'?)\r\nERROR: /media/berli/DataCenter/Test/tensorflow/tensorflow/BUILD:399:12: Label '//tensorflow:tools/integration_tests/gcs_smoke_test/setup.sh' crosses boundary of subpackage 'tensorflow/tools/integration_tests/gcs_smoke_test' (perhaps you meant to put the colon here: '//tensorflow/tools/integration_tests/gcs_smoke_test:setup.sh'?)\r\nERROR: /media/berli/DataCenter/Test/tensorflow/tensorflow/BUILD:399:12: Label '//tensorflow:tools/integration_tests/gcs_smoke_test/BUILD.bazel' crosses boundary of subpackage 'tensorflow/tools/integration_tests/gcs_smoke_test' (perhaps you meant to put the colon here: '//tensorflow/tools/integration_tests/gcs_smoke_test:BUILD.bazel'?)\r\nERROR: /media/berli/DataCenter/Test/tensorflow/tensorflow/BUILD:399:12: Label '//tensorflow:tools/integration_tests/gcs_smoke_test/teardown.sh' crosses boundary of subpackage 'tensorflow/tools/integration_tests/gcs_smoke_test' (perhaps you meant to put the colon here: '//tensorflow/tools/integration_tests/gcs_smoke_test:teardown.sh'?)\r\nERROR: /media/berli/DataCenter/Test/tensorflow/tensorflow/BUILD:399:12: Label '//tensorflow:tools/integration_tests/gcs_smoke_test/test_wrapper.sh' crosses boundary of subpackage 'tensorflow/tools/integration_tests/gcs", "After updating to bazel version 0.11 the errors went away and was able to successfully build TensorFlow.", "yes, updating to bazel version 0.11, the errors went away and build successfully", "I had the same issue with version 0.11.0, having used the --user option at installation. Installing with sudo resolved the issue for me.", "Great ! That solved my problem too, in any case that you cannot update through \"sudo apt-get upgrade bazel\", install bazel again follow this instruction [here](https://docs.bazel.build/versions/master/install-ubuntu.html).", "Great to see the problem solved. "]}, {"number": 17292, "title": "Feature request: add operators support in tflite : ExpandDims, Prod, Slice", "body": "i have my own network trained, and when i want to convert it to tflite mode, the toco gives my the error:\r\n2018-02-27 16:57:12.122124: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:313] Total transient array allocated size: 103680 bytes, theoretical optimal value: 103680 bytes.\r\n2018-02-27 16:57:12.122280: F tensorflow/contrib/lite/toco/tflite/export.cc:303] Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops. Here is a list of operators for which you will need custom implementations: ExpandDims, Prod, Slice.\r\nAborted (core dumped)\r\nfor slice(for example, to change the tf.slice to [n:m] operator), i have tried several way but none of them work.", "comments": ["@aselle are these ops on the roadmap?", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Is there anything going on here? These seem to be fairly fundamental building blocks in most TF models.\r\n\r\nI would be interested in having an implementation for Slice even if it's still not completely stable.", "Nagging Assignee @cy89: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "We are hoping to get those implemented around the end of June.", "Nagging Assignee @andrehentz: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @andrehentz: It has been 30 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @andrehentz: It has been 45 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @andrehentz: It has been 60 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I'm closing this issue as it seems like the feature is already on the TF Lite team's radar.", "sadly still not supported", "Still not.\r\n"]}, {"number": 17291, "title": "Screen goes black - CUDA_ERROR_UNKNOWN  on TensorFlow-GPU 1.5", "body": "**Machine specs:**\r\nOperating System: Windows 7 64 bits\r\nTensorFlow version: 1.5.0 \r\nPython version: 3.6 (Anaconda)\r\nCUDA/cuDNN version: CUDA 9.0, cudNN 7.0.5\r\nGPU model and memory: Quadro K2000 2GB\r\nNote: GPU is also driving the display.\r\n\r\nWhile testing, my demo runs well until the screen goes black for a short instant of time and it crashes with the following error message:\r\n\r\n```\r\n2018-02-27 11:45:23.275524: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\3\r\n6\\tensorflow\\core\\platform\\cpu_feature_guard.cc:137] Your CPU supports instructi\r\nons that this TensorFlow binary was not compiled to use: AVX\r\n2018-02-27 11:45:23.533539: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\3\r\n6\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1105] Found device 0 with pro\r\nperties:\r\nname: Quadro K2000 major: 3 minor: 0 memoryClockRate(GHz): 0.954\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 2.00GiB freeMemory: 1.79GiB\r\n2018-02-27 11:45:23.552540: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\3\r\n6\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1195] Creating TensorFlow dev\r\nice (/device:GPU:0) -> (device: 0, name: Quadro K2000, pci bus id: 0000:01:00.0,\r\n compute capability: 3.0)\r\n[I 11:45:53.864 NotebookApp] Saving file at /Mask_RCNN/demo.ipynb\r\n2018-02-27 11:46:41.003970: W C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\3\r\n6\\tensorflow\\core\\common_runtime\\bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran\r\n out of memory trying to allocate 2.07GiB. The caller indicates that this is not\r\n a failure, but may mean that there could be performance gains if more memory is\r\n available.\r\n2018-02-27 11:46:52.468626: E C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\3\r\n6\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:1080] failed to synchronize the\r\n stop event: CUDA_ERROR_UNKNOWN\r\n2018-02-27 11:46:52.584632: E C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\3\r\n6\\tensorflow\\stream_executor\\cuda\\cuda_timer.cc:54] Internal: error destroying C\r\nUDA event in context 00000000258FE360: CUDA_ERROR_UNKNOWN\r\n2018-02-27 11:46:52.585632: E C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\3\r\n6\\tensorflow\\stream_executor\\cuda\\cuda_timer.cc:59] Internal: error destroying C\r\nUDA event in context 00000000258FE360: CUDA_ERROR_UNKNOWN\r\n2018-02-27 11:46:52.585632: F C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\3\r\n6\\tensorflow\\stream_executor\\cuda\\cuda_dnn.cc:2289] failed to set stream for cud\r\nnn handle: CUDNN_STATUS_MAPPING_ERROR\r\n[I 11:47:24.287 NotebookApp] KernelRestarter: restarting kernel (1/5), keep rand\r\nom ports\r\nWARNING:root:kernel 134641e2-3f62-4019-9536-be72010310fa restarted\r\n```\r\n\r\nI tried for several days different ideas from different issues:\r\nChecked carefully the video tutorial from youtube, nvidia installation manual, etc.\r\nReinstalled cuda, cudnn\r\nDowngrade tf, cuda, cudnn\r\n\r\nCould you suggest any method to detect what is wrong and how to solve the problem?\r\n\r\nPost-data:\r\n**Code works fine on tensorflow without GPU.**", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nBazel version\nExact command to reproduce", "Problem solved. It was a WDDM event. Increasing the TdrDelay value solved the problem."]}, {"number": 17290, "title": "Windows Compile Issue:  absl is not a class or namespace name", "body": "Hi,\r\nI am trying to compile tensorflow from source in windows using bazel 0.11.0 and vc14, and I am getting the following error:\r\n`~\\igwos0gz\\execroot\\org_tensorflow\\tensorflow\\core\\platform\\windows\\port.cc(153): error C2653: 'absl': is not a class or namespace name\r\n`\r\nHave I written custom code? no\r\nOS Platform and Distribution? windows 10 - x64\r\nTensorFlow installed from? git repo\r\nTensorFlow version? current master branch (1.7rc?)\r\nBazel version? 0.11.0\r\nCUDA/cuDNN version? 9.1/7\r\nGPU model and memory? nvidia 960m\r\nExact command to reproduce?\r\n`bazel build -c opt --action_env=USE_MSVC_WRAPPER=1 //tensorflow/tools/pip_package:build_pip_package`", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "Is this not a build bug?", "Hmm... I'm not sure how to verify this. @mrry, thoughts?", "@benoitsteiner added this call in 09138338ed81b56aeaff88b9ee5a11c3f6d77b70. I don't see any corresponding change to the includes, so it's possible this is broken in some build configurations.\r\n\r\n(Remember that we only support the CMake build on Windows right now, but hope to switch to Bazel soon.)\r\n\r\n/cc @meteorcloudy ", "I think https://github.com/tensorflow/tensorflow/pull/16905 is for fixing this issue.", "Nagging Assignee @benoitsteiner: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Fixed by b076804, closing"]}, {"number": 17289, "title": "TFLite 'Minimum' Operator", "body": "I have a fine-tuned MobileNet model, in frozen graph format. I ran Toco to create a TFLite model, but got the following error:\r\n\r\n```Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops. Here is a list of operators for which you will need custom implementations: TensorFlowMinimum.```\r\n\r\nExamining the ops in the graph, I see ones like `mobilenet_1.00_224/conv1_relu/Minimum`.\r\n\r\n", "comments": ["Same issue on my side.\r\n\r\nI have retrained a MobileNet model with Keras and converted it to TensorFlow. The model is ready for inference.\r\n\r\nWith `tensorflow==1.6.0.rc1`, it is the only operation which is said to be not supported.\r\nI'm a bit suprised, as [the doc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/tf_ops_compatibility.md) says that this kind of ops \"are usually removed from the graph\".", "In most cast 'minimum' will be removed from the graph because it is only attached to const nodes. It seems this is not the case with the retraining of mobilenet with keras. Hopefully we will have an implementation of 'minimum' soon.", "Nagging Assignee @cy89: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "TensorflowMinimum should be supported now. Closing, but please reopen if you still find issues.", "@SaqibS @aureliengervasi Did you manage to get rid of \"TensorFlowMinimum\" issue?", "I am still facing the issue", "@saeed68gm You may try to pull the latest TensorFlow from the master branch. Use \"bazel run ***\" command as mentioned here (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/g3doc/cmdline_examples.md) to convert the weights.", "Thanks @nixingyang I tried that but the build was broken due to a gcc version issue. I don't know if it has been resolved since two days ago.", "@nixingyang see this:\r\nhttps://github.com/tensorflow/tensorflow/issues/19434#issuecomment-394651764", "@saeed68gm It seems that you decided to use the 1.8 branch. For me, the release version of 1.8 still caused the \"TensorFlowMinimum\" issue. I used the master branch on May 25 and it worked as expected.", "@nixingyang yeah, correct. I did that because libtensorflow_inference.so was failing to build on master so I had to revert. I will try a bit later and see if the issues have been fixed for that. Do we know the commit that fixed this? I may just cherry-pick that and try.", "Seems get the same error on:\r\n```\r\ntensorflow.__version__\r\n'1.5.0\r\nkeras.__version__\r\n'2.1.6'\r\n```\r\nSame for :\r\n```\r\ntensorflow.__version__\r\n'1.6.0'\r\nkeras.__version__\r\n'2.1.6\r\n```\r\n\r\nSteps to reproduce:\r\n\r\n1. Create MobileNet\r\n\r\n```\r\nfrom keras.applications.mobilenet import MobileNet\r\n\r\nmodel = MobileNet(input_shape=(128, 128, 3),\r\n                      alpha=1.0,\r\n                      depth_multiplier=1,\r\n                      include_top=False,\r\n                      weights='imagenet'\r\n                      )\r\n\r\nmodel.summary()\r\n\r\nmodel.save('keras_model.h5')\r\n```\r\n\r\n2. Convert to tensorflow .pb\r\n```\r\nfrom keras import backend as K\r\nfrom keras.utils.generic_utils import CustomObjectScope\r\nimport keras\r\nfrom tensorflow.python.framework import graph_util\r\nfrom tensorflow.python.framework import graph_io\r\n\r\nK.set_learning_phase(0) # Leave only needed for inference in graph\r\n\r\nwith CustomObjectScope({'relu6': keras.applications.mobilenet.relu6,\r\n                        'DepthwiseConv2D': keras.applications.mobilenet.DepthwiseConv2D}):\r\n    model = keras.models.load_model('keras_model.h5')\r\n    sess = K.get_session()\r\n\r\n    output_node_names = [node.op.name for node in model.outputs]\r\n    print('output_node_names', output_node_names) # output_node_names ['conv_pw_13_relu/Minimum']\r\n    constant_graph = graph_util.convert_variables_to_constants(\r\n        sess,\r\n        sess.graph.as_graph_def(),\r\n        output_node_names)\r\n\r\n    graph_io.write_graph(constant_graph, '.', 'tf_model.pb', as_text=False) \r\n```\r\n\r\nTried to convert using `toco` tool:\r\n\r\nSimple version:\r\n\r\n```\r\ntoco --input_file=\"tf_model.pb\" --output_file=\"model.tflite\" --input_format=\"TENSORFLOW_GRAPHDEF\" --output_format=\"TFLITE\"\r\n\r\n2018-11-27 19:12:07.800286: F tensorflow/contrib/lite/toco/tooling_util.cc:1103] Check failed: model->flags.output_arrays_size() > 0 (0 vs. 0)This model does not define output arrays, so a --output_arrays flag must be given on the command-line.\r\nAbort trap: 6\r\n```\r\n\r\nWith specifying `--output_arrays`:\r\n\r\n```\r\ntoco --input_file=\"tf_model.pb\" --output_file=\"model.tflite\" --input_format=\"TENSORFLOW_GRAPHDEF\" --output_format=\"TFLITE\" --output_arrays='conv_pw_13_relu/Minimum'\r\n\r\n2018-11-27 19:13:13.433366: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 446 operators, 650 arrays (0 quantized)\r\n2018-11-27 19:13:13.457227: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 68 operators, 164 arrays (0 quantized)\r\n2018-11-27 19:13:13.458602: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 68 operators, 164 arrays (0 quantized)\r\n2018-11-27 19:13:13.459898: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:313] Total transient array allocated size: 0 bytes, theoretical optimal value: 0 bytes.\r\n2018-11-27 19:13:13.460489: F tensorflow/contrib/lite/toco/tflite/export.cc:303] Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops. Here is a list of operators for which you will need custom implementations: TensorFlowMinimum.\r\nAbort trap: 6\r\n```\r\n\r\nUsing `--allow_custom_ops`:\r\n\r\n```\r\ntoco --input_file=\"tf_model.pb\" --output_file=\"model.tflite\" --input_format=\"TENSORFLOW_GRAPHDEF\" --output_format=\"TFLITE\" --output_arrays='conv_pw_13_relu/Minimum' --allow_custom_ops\r\n2018-11-27 19:23:43.537074: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 446 operators, 650 arrays (0 quantized)\r\n2018-11-27 19:23:43.561828: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 68 operators, 164 arrays (0 quantized)\r\n2018-11-27 19:23:43.563117: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 68 operators, 164 arrays (0 quantized)\r\n2018-11-27 19:23:43.564334: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:313] Total transient array allocated size: 0 bytes, theoretical optimal value: 0 bytes.\r\n```\r\n\r\nNo errors, but not sure if everything is ok.", "Please try with a more recent version of tensorflow. Support for tf.min was added around mid-april.", "With \r\n```\r\ntensorflow.__version__\r\n'1.12.0'\r\nkeras.__version__\r\n'2.1.6\r\n```\r\nI have tried \r\n\r\n```\r\ntoco --keras_model_file='keras_model.h5' --output_file='model.tflite'\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/myuser/sandbox/tflite/bin/toco\", line 11, in <module>\r\n    sys.exit(main())\r\n  File \"/Users/myuser/sandbox/tflite/lib/python3.6/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 412, in main\r\n    app.run(main=run_main, argv=sys.argv[:1])\r\n  File \"/Users/myuser/sandbox/tflite/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/Users/myuser/sandbox/tflite/lib/python3.6/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 408, in run_main\r\n    _convert_model(tflite_flags)\r\n  File \"/Users/myuser/sandbox/tflite/lib/python3.6/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 100, in _convert_model\r\n    converter = _get_toco_converter(flags)\r\n  File \"/Users/myuser/sandbox/tflite/lib/python3.6/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 87, in _get_toco_converter\r\n    return converter_fn(**converter_kwargs)\r\n  File \"/Users/myuser/sandbox/tflite/lib/python3.6/site-packages/tensorflow/contrib/lite/python/lite.py\", line 368, in from_keras_model_file\r\n    keras_model = _keras.models.load_model(model_file)\r\n  File \"/Users/myuser/sandbox/tflite/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py\", line 230, in load_model\r\n    model = model_from_config(model_config, custom_objects=custom_objects)\r\n  File \"/Users/myuser/sandbox/tflite/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py\", line 310, in model_from_config\r\n    return deserialize(config, custom_objects=custom_objects)\r\n  File \"/Users/myuser/sandbox/tflite/lib/python3.6/site-packages/tensorflow/python/keras/layers/serialization.py\", line 64, in deserialize\r\n    printable_module_name='layer')\r\n  File \"/Users/myuser/sandbox/tflite/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py\", line 173, in deserialize_keras_object\r\n    list(custom_objects.items())))\r\n  File \"/Users/myuser/sandbox/tflite/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\", line 1292, in from_config\r\n    process_layer(layer_data)\r\n  File \"/Users/myuser/sandbox/tflite/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\", line 1278, in process_layer\r\n    layer = deserialize_layer(layer_data, custom_objects=custom_objects)\r\n  File \"/Users/myuser/sandbox/tflite/lib/python3.6/site-packages/tensorflow/python/keras/layers/serialization.py\", line 64, in deserialize\r\n    printable_module_name='layer')\r\n  File \"/Users/myuser/sandbox/tflite/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py\", line 175, in deserialize_keras_object\r\n    return cls.from_config(config['config'])\r\n  File \"/Users/myuser/sandbox/tflite/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1606, in from_config\r\n    return cls(**config)\r\n  File \"/Users/myuser/sandbox/tflite/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py\", line 330, in __init__\r\n    self.activation = activations.get(activation)\r\n  File \"/Users/myuser/sandbox/tflite/lib/python3.6/site-packages/tensorflow/python/keras/activations.py\", line 206, in get\r\n    return deserialize(identifier)\r\n  File \"/Users/myuser/sandbox/tflite/lib/python3.6/site-packages/tensorflow/python/keras/activations.py\", line 197, in deserialize\r\n    printable_module_name='activation function')\r\n  File \"/Users/myuser/sandbox/tflite/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py\", line 193, in deserialize_keras_object\r\n    function_name)\r\nValueError: Unknown activation function:relu6\r\n```\r\nSeems related: https://github.com/tensorflow/tensorflow/issues/17191\r\n\r\nAnd this command seems was runned without errors:\r\n`toco --graph_def_file=\"tf_model.pb\" --output_file=\"model.tflite\" --output_format=\"TFLITE\" --input_arrays='input_1_1' --output_arrays='conv_pw_13_relu_1/Minimum'`"]}, {"number": 17288, "title": "OutOfRangeError (see above for traceback): box_index has values outside [0, batch_size)", "body": "```\r\nSYSTEM INFO:\r\nOS: Ubuntu 16.04 LTS\r\nTensorflow version: 1.4.0\r\nPython version: 2.7.12\r\n```\r\nMy issue is very similar to this one here: [issue #10618](https://github.com/tensorflow/tensorflow/issues/10618)\r\nI have been doing a multi-GPU session and I get some weird behavior from Tensorflow. \r\nMy script only can finish its run in 1 out of 6 attempts, and in each finished execution, the result is slightly different from the single-GPU execution mode (unrepeatable error). If the execution cannot finish, most of the time it reports `OutOfRangeError (see above for traceback): box_index has values outside [0, batch_size)`\r\n, which is not supposed to appear for tensorflow 1.4 and above, according to the issue above. \r\nMoreover, sometimes it would report `InternalError (see above for traceback): Blas SGEMM launch failed : m=14700, n=2048, k=1024`\r\n\r\nAny advice would be greatly appreciated, thanks!", "comments": ["Please provide details about what platform you are using  (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?  Make sure you also include the exact command if possible to produce  the output included in your test case. If you are unclear what to include  see the issue template displayed in  [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\n We ask for this in the issue submission template, because    it is really difficult to help without that information. Thanks!", "@angersson, I did add my platform information. In case of mistake I state here again:\r\n\r\nSYSTEM INFO:\r\nOS: Ubuntu 16.04 LTS\r\nTensorflow version: 1.4.0\r\nPython version: 2.7.12\r\n\r\nMy code is a multi GPU session for testing in an open-sourced project [tf-faster-rcnn](https://github.com/endernewton/tf-faster-rcnn), and here is my `multi_gpu_demo.py` script.\r\n\r\n[multi_gpu_demo.zip](https://github.com/tensorflow/tensorflow/files/1766511/multi_gpu_demo.zip)\r\n", "Please provide all of the information listed in the [Github new issue template](https://github.com/tensorflow/tensorflow/issues/new)."]}, {"number": 17287, "title": "text manipulation in tensorflow", "body": "Hi,\r\nI want to make my text files in lower case. I tried following code:\r\n\r\n\r\n```\r\ndef _parse_line(line):\r\n\r\n       line_split = tf.string_split([line], '\\t')\r\n       raw_text = tf.py_func(lambda x: x.strip().lower(), [line_split.values[0]], tf.string)\r\n       label = tf.string_to_number(line_split.values[1], out_type=tf.int32)\r\n       return {\"raw_text\": raw_text, \"label\": label}\r\n\r\nsess = tf.Session()\r\nf = './test.txt'\r\ndataset = tf.data.TextLineDataset([f])\r\ndataset = dataset.map(_parse_line)\r\ni = dataset.make_one_shot_iterator()\r\nc = i.get_next()\r\nsess.run(c)\r\n```\r\n\r\nand unfortunately I got error:\r\n\r\nslice index 1 of dimension 0 out of bounds.\r\n\t [[Node: strided_slice_1 = StridedSlice[Index=DT_INT32, T=DT_STRING, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](StringSplit:1, strided_slice_1/stack, strided_slice_1/stack_1, strided_slice_1/stack_2)]]\r\n\t [[Node: IteratorGetNext_9 = IteratorGetNext[output_shapes=[[], <unknown>], output_types=[DT_INT32, DT_STRING], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_9)]]\r\n\r\nI'd be so grateful to help me.", "comments": ["Can you share your file  `./test.txt`. My guess is, the output of `tf.string_split([line], '\\t')` might have dimension of `values`  as 1.  Try to see output with only `line_split = tf.string_split([line], '\\t')` in your function _parse_line(..). \r\n\r\n       ", "Closing this due to lack of activity, feel free to reopen if this doesn't solve your issue."]}, {"number": 17286, "title": "Update tensor_shape.py", "body": "Correct two typos where 'if' were written as 'iff'", "comments": ["\nThanks for your pull request. t looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to `go/cla#troubleshoot`.\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "`iff` means `if and only if`. The uses of `iff` in these places seem appropriate.", "Noted! Thank you for the prompt response! I learnt something here."]}, {"number": 17285, "title": "tensorflow lite so cannot add opencv dependence, cause \"library not found\" error", "body": "Version info:\r\ntensorflow r1.4\r\nubuntu 14.04\r\narmv7 platform\r\nandroid 5.1.1\r\nndk version: r14\r\nandroid studio 2.3.1\r\nwhen compile tensorflow lite so, if i add the opencv dependence like:\r\ndeps = [\r\n        \"//tensorflow/contrib/lite:context\",\r\n        \"//tensorflow/contrib/lite:framework\",\r\n        \"//tensorflow/contrib/lite:schema_fbs_version\",\r\n        \"//tensorflow/contrib/lite/kernels:builtin_ops\",\r\n        \"@dlib_arm_v7//:dlib\",\r\n        \"@seeta_arm_v7//:seeta\",\r\n        #\"@opencv_jni//:opencv_jni\",\r\n    ],\r\nthe compiling is ok, but when i move the .so file to my android project, it will give the error cannot find the library.\r\nif i comment the opencv line, it is ok.\r\nit is a Compatibility problem between opencv and tensorflow lite.\r\n\r\n", "comments": ["the java code:\r\nstatic {\r\n        try {\r\n            System.loadLibrary(\"tensorflow_inference\");\r\n        } catch (UnsatisfiedLinkError e) {\r\n            android.util.Log.d(\"PeopleDet\", \"library not found!\");\r\n        }\r\n    }", "Could you include the full dlopen error from the logcat?", "Could you provide the full logcat of the dlopen() error (i.e. what symbols are unresolved when trying to load the dso should appear) maybe uf you logcat a e.ToString().  ", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 30 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 17284, "title": "tensor-valued seeds in tf.data API can result in nondeterministic results", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 17.10\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: v1.5.0-11-g4588350f20 1.5.0\r\n- **Python version**: 3.6.3\r\n- **Bazel version (if compiling from source)**: 0.11.0\r\n- **GCC/Compiler version (if compiling from source)**: 7.2.0\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: See code below\r\n\r\n### Describe the problem\r\nThe `tf.data` API allows/requires seeds to be provided that are `tf.tensor`s. This is an issue when the graph-level seed has been set to 0, and the provided op-level seed tensor takes on a value of 0. As noted in the comments in the code for `tf.get_seed`, a `(0, 0)` seed is problematic because the C++ ops assume this means nondeterminism. Of course, when a user is specifying these seeds, they're expecting deterministic behaviour. Unfortunately, `tf.get_seed` only checks for this issue for the case where the seeds are ints, not tensors. See the code below for an example.\r\n\r\nI would have been happy to submit a PR for this, but I have no idea where the fix should be for this bug. As I'm not especially familiar with the code base, it's not apparent whether it's even possible to have the code for `tf.get_seed` to check the value of a tensor seed. If not, I'm guessing the `tf.data` API would need to provide the checks.\r\n\r\n### Source code / logs\r\nThe following code reproduces the bug for me:\r\n```python\r\nimport tensorflow as tf\r\n\r\ntf.set_random_seed(0)\r\nseed_tensor = tf.placeholder(tf.int64, shape=[], name='data_seed')\r\ndata = tf.data.Dataset.range(10).shuffle(10, seed=seed_tensor)\r\niterator = tf.data.Iterator.from_structure(tf.int64, tf.TensorShape([]))\r\n\r\ninit = iterator.make_initializer(data)\r\nvalue = iterator.get_next()\r\n\r\nprint('First run: ', end='')\r\nwith tf.Session() as sess1:\r\n    sess1.run(init, feed_dict={seed_tensor: 0})\r\n    values = []\r\n    while True:\r\n        try:\r\n            values.append(str(sess1.run(value)))\r\n        except tf.errors.OutOfRangeError:\r\n            break\r\n\r\n    print(', '.join(values))\r\n\r\nprint('Second run: ', end='')\r\nwith tf.Session() as sess2:\r\n    sess2.run(init, feed_dict={seed_tensor: 0})\r\n    values = []\r\n    while True:\r\n        try:\r\n            values.append(str(sess2.run(value)))\r\n        except tf.errors.OutOfRangeError:\r\n            break\r\n\r\n    print(', '.join(values))\r\n```\r\n\r\nThe result I get is:\r\n```\r\nFirst run: 8, 4, 6, 9, 1, 0, 5, 7, 3, 2\r\nSecond run: 1, 6, 3, 0, 7, 5, 2, 9, 8, 4\r\n```\r\n\r\nI would expect the first and second runs to produce the exact same sequence, though the particular sequence might differ from environment to environment.\r\n\r\nIf I change the `feed_dict` to provide a value of `0` for `seed_tensor` for both runs, I get the expected result:\r\n\r\n```\r\nFirst run: 5, 2, 0, 1, 7, 4, 9, 3, 8, 6\r\nSecond run: 5, 2, 0, 1, 7, 4, 9, 3, 8, 6\r\n```\r\n\r\nIf I change the `shuffle()` call to take a value of 0 directly (i.e., `...shuffle(10, seed=0)), I get the expected result as well:\r\n\r\n```\r\nFirst run: 4, 8, 7, 1, 3, 2, 6, 9, 0, 5\r\nSecond run: 4, 8, 7, 1, 3, 2, 6, 9, 0, 5\r\n```\r\nFor the record, I encountered this issue because I'm using an `Iterator` via `Iterator.from_structure`, and when I use that iterator on a `Dataset.shuffle()` I get the same order for each epoch. To get around this, I provided the epoch number as a seed to `Dataset.shuffle()`, with the first epoch being epoch 0. In my case I can avoid this bug by just starting the epoch count at 1, but it took me a while to track down, and there may be other cases where the API is used in a similar way that would be problematic for those expecting deterministic results.", "comments": ["@mrry Can you look at this?", "I'm a bit confused by the code example. Why would you expect the shuffled order to be the same when you feed two *different* values for `seed_tensor`?\r\n\r\nIt might make sense to rewrite the seed, as `tf.get_seed()` does, when the runtime value is 0. Is that what you're suggesting?", "@mrry Ugh, sorry, that's my mistake. Both fed values should be 0. I copied-and-pasted the code I was using to test it and had changed one of them but not the other. I've edited the code to reflect my intention.\r\n\r\n> It might make sense to rewrite the seed, as tf.get_seed() does, when the runtime value is 0. Is that what you're suggesting?\r\n\r\nYes, exactly. the `tf.get_seed()` check is insufficient if tensor-valued seeds are allowed, as it only does an identity check against `0`.", "OK, that does seem like a bug, and the fix isn't too difficult. The gist is to set `seed = tf.where(seed == 0, tf.constant(2 ** 31 - 1, dtype=tf.int64), seed)` when `seed` is a `tf.Tensor`.\r\n\r\nWatch this space for a fix in the next few days.", "@mrry I'd be willing to submit a PR for this if no one's already working on it.", "Thanks for offering! I've already got a fix under review, so it should be merged soon."]}, {"number": 17283, "title": "Fix bug 17175", "body": "Fix bug reported at https://github.com/tensorflow/tensorflow/issues/17175", "comments": ["\nThanks for your pull request. t looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to `go/cla#troubleshoot`.\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->", "Used incorrect email in earlier commit. Fixed it.", "CLAs look good, thanks!\n\n<!-- ok -->", "Any idea why the \"Ubuntu CC\" check takes so long?", "@ebrevdo Any idea why the tests take so long? \r\n\r\nFor the first commit (https://github.com/tensorflow/tensorflow/pull/17283/commits/0a4bad1a79e60718dc8620e1213adaa4bcc9d0fe) it finished in a few hours with all the 15 tests. Now it seems stuck with the Ubuntu CC test", "Should improve by tomorrow.\n\nOn Fri, Mar 2, 2018, 8:09 PM Panos Ipeirotis <notifications@github.com>\nwrote:\n\n> @ebrevdo <https://github.com/ebrevdo> Any idea why the tests take so long?\n>\n> For the first commit (0a4bad1\n> <https://github.com/tensorflow/tensorflow/commit/0a4bad1a79e60718dc8620e1213adaa4bcc9d0fe>)\n> it finished in a few hours with all the 15 tests. Now it seems stuck with\n> the Ubuntu CC test\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/17283#issuecomment-370115732>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim1kWrTvfeGx-dzsIVmJMSlKXO-t9ks5tahdfgaJpZM4ST7E6>\n> .\n>\n", "@ebrevdo Can we get a forced run of the tests? ", "@protoget @ebrevdo @kokoro-team @googlebot How can we get the tests to run on this?", "Re @ipeirotis running tests."]}, {"number": 17282, "title": "Switch to v2 version of tf.unique to enable axis support", "body": "This fix is a follow up to #15654 to switch to unique_v2 for tf.unique so that axis support could be enabled.\r\n\r\nThis follows the compatibility workflow as PR 15654 has been merged 3+ weeks ago.\r\n\r\nThis fix is part of the effort for #15644.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Nagging Assignee @protoget: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Hi, when will this land in a tensorflow release?", "We are eagerly waiting for this release.\r\n", "@yongtang  could you address the test failure?", "I run tests on my GPU machine and could not reproduce the failure showed up in `GPU Python3`. Will spend some time investigating it.", "Nagging Assignee @protoget: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "So, FTR the error is:\r\n```\r\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'Adam/update_Variable/sub_3': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\r\n```\r\nWhen running:\r\n```\r\n    return optimizer._apply_sparse_duplicate_indices(g, self._v)\r\n```\r\n\r\nIt says that the kernel is not registered. I would guess that there's a convert to tensor that converts to a different type in py3 which is not implemented.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "It has been 43 days that this pull-request has stalled. Please create a new pull-request with the requested changes.", "Is there a current work around?"]}, {"number": 17281, "title": "R1.6", "body": "", "comments": ["Dropped TPU profiler version update."]}, {"number": 17280, "title": "Upgrade Jenkins/Docker build scripts to Bazel 0.11.0.", "body": "The 0.10.0 bazel has problems with static-linking on linux:\r\nhttps://github.com/bazelbuild/bazel/issues/4474. This PR bumps to the\r\nlatest bazel that produces proper binaries w/o the linking issue.", "comments": ["We should move our Kokoro as well then, @gunan @meteorcloudy if there is no objection.", "No objections from me.", "LGTM"]}, {"number": 17279, "title": "Branch 187038889", "body": "", "comments": []}, {"number": 17278, "title": "Update word2vec_basic.py", "body": "Collections can't receive slice as indexes", "comments": ["\nThanks for your pull request. t looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to `go/cla#troubleshoot`.\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "@Tyruiop please create a new PR to master and sign the CLA. Thanks."]}, {"number": 17277, "title": "Fix bad wrong jpeg/nasm mirror", "body": "", "comments": ["Suggested description: Move URL added in pull request #17234 to correct section.\r\n\r\n(I think the owner should be able to edit the description field of this PR.)"]}, {"number": 17276, "title": "Supplement Linear Model Tutorial on how trained model to make predictions", "body": "This is to fix #11440.\r\n\r\nThe current [Linear Model Tutorial](https://www.tensorflow.org/tutorials/wide) told how to train and evaluate a linear model but it doesn't seem that there are final steps to complete the tutorial: to take a set of given values, and predict income_bracket. \r\n\r\nThis fix of the tutorial is to provide a simple code example for newbies on how to extract final predictions after training the model.", "comments": []}, {"number": 17275, "title": "Feature request: tf.gather with multidimensional axis", "body": "As the title says, I would like to gather multiple dimensions in the tf.gather function. An example situation would be:\r\n\r\na = tf.random_normal([2,3,4])\r\nb = tf.gather(a, [[0, 0], [1, 0]], axis=[1,2])\r\nassert b[:, 0] == a[:, 0, 0]\r\nassert b[:, 1] == a[:, 1, 0]\r\n\r\nWhen a dimension in axis is not listed, the function will gather all the entries in that dimension, as shown above. Is this possible?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "What is the current behavior when you do this?", "@aselle WDYT?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Currently, it throws the following exception:\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: axis must be scalar [Op:GatherV2]"]}, {"number": 17273, "title": "Numerical error with tf.nn.conv2d, tf.nn.moments and tf.sqrt", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes (see code below)\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: SUSE Linux Enterprise Server 12.2 (x86_64)\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 1.5.0 (git v1.5.0-0-g37aa430d84) & also present in 1.4.0\r\n- **Python version**: 3.6.4\r\n- **Bazel version (if compiling from source)**: 0.10.1\r\n- **GCC/Compiler version (if compiling from source)**: GCC/7.2.0\r\n- **CUDA/cuDNN version**: None\r\n- **GPU model and memory**: None\r\n- **Exact command to reproduce**: See script below\r\n\r\n### Describe the problem\r\nThere is a numerical error with a very specific sequence of operations, that make tf.sqrt() return a tensor of zeros when applied on the output of tf.nn.moments (regardless of the value returned by tf.nn.moments). This error happens when the input of tf.nn.moments comes from tf.nn.conv2d, but not when removing the latter.\r\n\r\nThis error happens when running on a cluster where TensorFlow has been installed from source with \"-m64 -march=native -mtune=native\". We tried upgrading from 1.4.0 to 1.5.0, but the error still occurs. The following flags were used during compilation:\r\n\r\nTF_NEED_JEMALLOC=\"1\"\r\nTF_NEED_HDFS=\"1\"\r\nTF_NEED_OPENCL=\"0\"\r\nTF_NEED_CUDA=\"0\"\r\nTF_ENABLE_XLA=\"0\"\r\nTF_CUDA_CLANG=\"0\"\r\nTF_NEED_GCP=\"0\"\r\nTF_NEED_MKL=\"1\"\r\nTF_NEED_VERBS=\"0\"\r\nTF_NEED_MPI=\"1\"\r\nTF_NEED_S3=\"0\"\r\nTF_NEED_GDR=\"0\"\r\nTF_NEED_OPENCL_SYCL=\"0\"\r\nTF_MKL_ROOT=\"[DIR]/mkl-dnn/external/mklml_lnx_2018.0.1.20171007\"\r\nexport MPI_HOME=\"[DIR]/2018.1.038/compilers_and_libraries_2018.1.163/linux/mpi/intel64\"\r\n\r\nAndroid build: No.\r\n\r\nCompiled using Intel MPI plus complete MKL (2018.1.038) loaded in the environment.\r\n\r\n\r\nWe also tested this same code in two other machines, where it works properly. One of them is an older cluster, with TensorFlow compiled from source using the same configuration; the main difference is that the processors in this cluster do not support AVX512. The other machine is a laptop where TensorFlow was installed with pip.\r\n\r\n### Source code / logs\r\n\r\nThe smallest code to reproduce the error is the following:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n# TensorFlow version\r\nprint('TF version:', tf.__version__, tf.__git_version__, '\\n')\r\n\r\n# Create placeholders\r\no = tf.placeholder(tf.float32, [None, 84, 84, 4])\r\n\r\n# Create graph: conv(x, w) -> (x-mean(x))/std(x)\r\nx = o\r\n\r\nw = tf.get_variable(\"w\", [3, 3, x.get_shape()[-1], 16])\r\nx = tf.nn.conv2d(x, w, [1, 1, 1, 1], padding=\"SAME\")  # remove this and the error disappears...\r\n\r\navg, variance = tf.nn.moments(x, np.arange(len(x.get_shape().as_list()) - 1), keep_dims=True)\r\nepsilon = 1e-3  # for numerical stability in sqrt\r\n\r\nvariance = tf.Print(variance, [avg], message='mean(x): ')\r\nvariance = tf.Print(variance, [variance], message='variance(x): ')\r\nvariance = tf.Print(variance, [tf.sqrt(variance + epsilon)], message='sqrt(variance(x)): ')\r\nvariance = tf.Print(variance, [tf.sqrt(avg**2 + epsilon)], message='sqrt(mean(x)^2): ')\r\n\r\nx = (x - avg) / (tf.sqrt(variance + epsilon))\r\n\r\n# Run\r\nsess = tf.InteractiveSession()\r\nsess.run(tf.global_variables_initializer())\r\nsess.run(x, feed_dict={o: np.random.rand(32, 84, 84, 4)})\r\n```\r\n\r\nAnd the output:\r\n\r\nmean(x): [[[[0.176351935 -0.11745432 -0.17503795]]]...]\r\nvariance(x): [[[[0.0344150327 0.0378020629 0.0353332]]]...]\r\nsqrt(variance(x)): [[[[0 0 0]]]...]\r\nsqrt(mean(x)^2): [[[[0 0 0]]]...]\r\n", "comments": ["Thank you Victor @victorcampos7 for trying Tensorflow with MKL-DNN and for filing this detailed, easy to reproduce bug report. Please know that I have found at least this TF commit id (TF1.5, v1.5.0-2054-gabccb5d3cb ) and this TF commit id (v1.6.0-rc1-1587-g10cddb4268)\r\nproduced non-zero results. \r\n\r\nLog is below: (for the v1.5 one)\r\nmean(x): [[[[-0.105329745 -0.242625624 -0.45726034]]]...]\r\nvariance(x): [[[[0.02950803 0.0405935161 0.0426237248]]]...]\r\nsqrt(variance(x)): [[[[0.174665481 0.203944862 0.208862931]]]...]\r\nsqrt(mean(x)^2): [[[[0.109974332 0.244677722 0.458352506]]]...]\r\n\r\nfor the v1.6 one:\r\nmean(x): [[[[-0.253690451 0.0252816677 -0.101222448]]]...]\r\nvariance(x): [[[[0.0222420059 0.0317621827 0.0308733471]]]...]\r\nsqrt(variance(x)): [[[[0.152453288 0.181003273 0.178531066]]]...]\r\nsqrt(mean(x)^2): [[[[0.255653769 0.0404865742 0.106047086]]]...]\r\n\r\nI suggest trying this TF commit id: abccb5d3cb45da0d8703b526776883df2f575c87 \r\n\r\nPlease let us know if you still have issues!", "Also, below is from GPU TF as a FYI\r\n\r\nmean(x): [[[[-0.152227402 -0.730839372 -0.154905677]]]...]\r\nvariance(x): [[[[0.0293967575 0.0375702456 0.0372712091]]]...]\r\nsqrt(variance(x)): [[[[0.174346656 0.196393088 0.195630282]]]...]\r\nsqrt(mean(x)^2): [[[[0.15547727 0.731523156 0.158100501]]]...]", "Thanks for the feedback. We installed TF 1.6.0 (the version in the releases site) which already includes the commits you mention, but the error persists. Does it work properly for you in the stable version, or only in v1.6.0-rc1-1587-g10cddb4268?", "Should it be. I've double checked this commit, and it's applied in the v1.6.0 tag.\r\n\r\n@wei-v-wang @skye any ideas?", "@victorcampos7  It could be related to the configuration/build process. \r\nMay I know your build command and what architecture you are testing on?   I used \"-march=broadwell\" during the ask four \"-march=native\". \r\n\r\nIn the meanwhile, I will try the stable release version. ", "Read your post carefully, you indeed mentioned that on machines that do not support AVX512, things seemed to work. \r\nI think there is a known issue for Eigen AVX512 and we/Intel are working with Eigen community to fix that. https://bitbucket.org/eigen/eigen/pull-requests/361/fix-for-avx512/diff \r\nSo the workaround is please for now build with \"-march=broadwell\" before Eigen AVX512 issue is fully fixed. ", "Our native is skylake avx512.\n\nCarlos.\n\nEl vie., 23 mar. 2018 23:26, Wei Wang <notifications@github.com> escribi\u00f3:\n\n> @victorcampos7 <http:///victorcampos7> It could be related to the\n> configuration/build process.\n> May I know your build command and what architecture you are testing on? I\n> used \"-march=broadwell\" during the ask four \"-march=native\".\n>\n> In the meanwhile, I will try the stable release version.\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/17273#issuecomment-375814054>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AOc9-RZp9ZjZI5fbQVxTK5JOLYkr_RZsks5thXamgaJpZM4STGjj>\n> .\n>\n", "We use copt to add march mtune flags\n\nCarlos.\n\nEl vie., 23 mar. 2018 23:27, Carlos Tripiana Montes <tripiana@gmail.com>\nescribi\u00f3:\n\n> Our native is skylake avx512.\n>\n> Carlos.\n>\n> El vie., 23 mar. 2018 23:26, Wei Wang <notifications@github.com> escribi\u00f3:\n>\n>> @victorcampos7 <http:///victorcampos7> It could be related to the\n>> configuration/build process.\n>> May I know your build command and what architecture you are testing on? I\n>> used \"-march=broadwell\" during the ask four \"-march=native\".\n>>\n>> In the meanwhile, I will try the stable release version.\n>>\n>> \u2014\n>> You are receiving this because you are subscribed to this thread.\n>> Reply to this email directly, view it on GitHub\n>> <https://github.com/tensorflow/tensorflow/issues/17273#issuecomment-375814054>,\n>> or mute the thread\n>> <https://github.com/notifications/unsubscribe-auth/AOc9-RZp9ZjZI5fbQVxTK5JOLYkr_RZsks5thXamgaJpZM4STGjj>\n>> .\n>>\n>\n", "Please use -march=broadwell (for now), both from the ./configure stage, and the bazel build stage. ", "In the meantime, I will double check with stable r1.6 and -march=native -mtune=native. Thanks!", "I confirm with \"-march=native -mtune=native\", due to Eigen AVX512 failure (which we are fixing), will reproduce the bug. \r\nSo, the current workaround is to please temporarily use \"-march=broadwell\" (i.e. for Eigen pass, do not use AVX512). Please be assured that when code is executing in MKL-DNN pass, AVX512 will be used automatically if SKX is used.", "Please make sure to specify during the configure step. specifying in bazel build is not enough. \r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]: -march=broadwell", "I can confirm that our build with broadwell works as expected and the bug do no appear. Will it be superb to post here when TF will be working with avx512 again. Thanks for the support.", "Thanks @tripiana for trying with the workaround and your suggestion to post updates! Yes, definitely. I am planning to post here when there is good news.", "Eigen community included our fix for sqrt in the following commit https://mirror.bazel.build/bitbucket.org/eigen/eigen/get/87636bcbdf12.tar.gz \r\n\r\nWe have created and are testing a PR to tensorflow to use the above Eigen to fix avx512 sqrt/rsqrt issue. ", "I'm facing a similar problem with batch_normalization on TF 1.7 compiled with support of AVX512.\r\nI'm not even using tf.moments and instead set the variance as ones.\r\nWhen I pass it to the batch_normalization (along with any kind of variance_epsilon), the rsqrt operation (in the computation of \"inv\") returns NaN.\r\nEverything works correctly with the default pip tensorflow-gpu 1.7 package (which does not support AVX512)", "https://github.com/tensorflow/tensorflow/pull/18411 includes fix that will address Eigen rsqrt AVX512 issue. \r\nHowever, we are working on a complete solution to fully enable AVX512. More updates will be provided.\r\n", "@wei-v-wang any update on this?", "@skye we are still working on this. Looks like https://github.com/tensorflow/tensorflow/pull/18411 is having some conflicts that we need to address first. ", "Pending on the status of #18411 ", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}]