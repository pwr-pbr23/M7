[{"number": 12643, "title": "Safely read content from InputStream", "body": "Changed to use `ByteArrayOutputStream` on converting `InputStream` into `byte[]`, instead of relying on [`InputStream.available()`](https://docs.oracle.com/javase/8/docs/api/java/io/InputStream.html#available--).\r\n\r\nThe old way may cause problem in cases like reading from buffered input stream or a network stream.", "comments": ["@resec, thanks for your PR! By analyzing the history of the files in this pull request, we identified @andrewharp, @asimshankar and @tensorflower-gardener to be potential reviewers.", "Can one of the admins verify this patch?", "@asimshankar Hi, I updated as said in comment, also add a check to decide the byte array output stream init size. Please help reviewing the change again, thanks.", "@resec could you resolve the conflicts? Thank you!", "@asimshankar conflict resolved, thanks.", "@tensorflow-jenkins test this please", "fix io exception not caught, not sure if i can trigger jenkins, let me try.\r\n\r\n@tensorflow-jenkins test this please", ":( can not trigger full testing, please help to trigger the build again, thanks", "Thanks @resec! @tensorflow-jenkins test this please.", "@asimshankar thanks for the fix :)"]}, {"number": 12642, "title": "R1.3", "body": "", "comments": ["@Fred-Fan, thanks for your PR! By analyzing the history of the files in this pull request, we identified @alextp, @keveman and @mrry to be potential reviewers.", "Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->"]}, {"number": 12641, "title": "Improve all-in-memory file copy architecture (Python at least)", "body": "Current file copy (at least via Python `tf.gfile.Copy` ([gfile.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/platform/gfile.py#L22)\u2192 [file_io.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/lib/io/file_io.py#L371) \u2192 [file_io.i](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/lib/io/file_io.i#L113))) involves copying the source contents into memory, and then writing memory to the destination. For scenarios like https://github.com/tensorflow/tensorflow/issues/12630 which is working with an 11GB asset, this is unacceptable design.\r\n\r\n`file_system.h`'s `WritableFile` is not stubbed to allow anything like a streaming, though its `RandomAccessFile` is. (not entirely, entirely, true - i suppose `WriteableFile.Append(const StringPiece& data)` could be employed in a streamable fashion -ish.)\r\n\r\nTo cull the Python low hanging fruit, at least, please implement [file_io.i](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/lib/io/file_io.i#L113) using a regular streaming design instead of the above described current design.", "comments": ["Created a PR #12658 for that.", "Slurping the whole file into memory and writing it back out isn't exactly optimal. Streaming would be great. What would be even better is the [`sendfile`](http://man7.org/linux/man-pages/man2/sendfile.2.html) system call, which does it entirely in kernel space. If would be terrific if @rohan100jain was able to implement that when src and dst are Unix FS, and do streaming otherwise.", "The implementation of CopyFile in PR #12658 has been updated with calling `sendfile` in Linux for posix file systems. Please take a look.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "There's a PR somewhere adding in-kernel sendfile copy support I spent a lot of time helping to review a while back. I don't know what the status of that is, but I hope the author is generous enough to bring it to completion, because it'd be a great notch in his belt because this isn't an easy problem to solve.", "It's the PR cited above - #12658 "]}, {"number": 12640, "title": "Is there any  class similar to tf.contrib.learn.monitors.ValidationMonitor in TF-Slim for evalution in logging?", "body": "I want to evaluate my model using validation data when training and show the evalution result in logging,which is similar to tf.contrib.learn.monitors.ValidationMonitor,and i can customize my metrics to evaluate.Is there any one in TF-Slim?", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 12639, "title": "There are sudden change in validation line", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **Os platform version**: Win10\r\n- **install From conda:\r\n- **tensorflow version** :tensorflow 1.1\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 8.0 5.0\r\n- **GPU model and memory**: GTX1080ti\r\n\r\n\r\n\r\n### Describe the problem\r\n[I resume weights model from local. I find there are sudden change in validation line, but my train line don't this problem. I think maybe there are something wrong with tensorflow source code.]\r\nbelow is train history graph\r\n(https://github.com/xiaoerlaigeid/face-and-Pedestrian-detection-/blob/master/Figure_1.png)\r\n\r\n### Source code / logs\r\n`\t\tif RESUME:\r\n\t\t\tprint('Restoring previously trained model at %s' % MODEL_SAVE_PATH)\r\n\t\t\tsaver.restore(sess, MODEL_SAVE_PATH)\r\n\r\n\t\t\t# Restore previous loss history\r\n\t\t\twith open('loss_history.p', 'rb') as f:\r\n\t\t\t\tloss_history = pickle.load(f)\r\n\t\telse:\r\n\t\t\tprint('Training model from scratch')\r\n\t\t\t# Variable initialization\r\n\t\t\tsess.run(tf.global_variables_initializer())\r\n\r\n\t\t\t# For book-keeping, keep track of training and validation loss over epochs, like such:\r\n\t\t\t# [(train_acc_epoch1, valid_acc_epoch1), (train_acc_epoch2, valid_acc_epoch2), ...]\r\n\t\t\tloss_history = []`", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 12638, "title": "Fix: indices is out of bounds in _IndicatorColumn", "body": "The same bug of #12583 exists in `tf.feature_column` as well.  CF pr #12584.\r\n\r\n### What changes were proposed in this pull request?\r\n\r\nslice weighted_column to get rid of -1 index.\r\n\r\n### How was this patch tested?\r\n\r\n+ [x] add unit tests.\r\n+ [x] pass all tests.\r\n", "comments": ["@facaiy, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @ispirmustafa and @xiejw to be potential reviewers.", "Can one of the admins verify this patch?", "Thanks for review and approval, @ispirmustafa !", "Jenkins, test this please."]}, {"number": 12637, "title": "Adding image captioning examples for iOS (Im2txt) ", "body": "This is my first ever contribution, so please bear with me.\r\n\r\nRecently I've worked to implement [image captioning](https://github.com/tensorflow/models/tree/master/im2txt) with TensorFlow on iOS. To get a sense of what this is like, you can [check out my app](http://perigo.co). I've added an image captioning demo, along with links to the necessary graph and labels - I hope people find it helpful. On modern phones, inference should take a little more than a second. \r\n\r\nDue to the constraints of the C++ API, you'll see that I often have to traverse tensors using a for-loop. Less than ideal, but it seems to do the job.\r\n\r\nIf you have any questions, concerns, or critique, l'm happy to answer them! (here or via email: liamnakagawa [at] hunterschools.org)\r\n\r\n", "comments": ["@liamnaks, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @martinwicke and @aselle to be potential reviewers.", "Can one of the admins verify this patch?", "\u4e0b\u8a18\u308f\u304b\u308a\u307e\u3057\u305f\r\n\r\n\u3053\u3061\u3089\u306f\u3001\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u304c\u306a\u3044\u306e\u3067 descriopttion \u3068 claim\u306a\u3069\u306e\u5bfe\u6bd4\u304c\r\n\u30de\u30c3\u30c1\u3059\u308b\u3068\u3053\u308d\u304c\u306f\u3044\u308a\u307e\u3059\u3002\r\n\r\n\u30c6\u30b9\u30c8\u306e\u3057\u3088\u3046\u304c\u306a\u3044\u305f\u3081\u3002\r\n\r\n2017-08-28 8:09 GMT+09:00 Tensorflow Jenkins <notifications@github.com>:\r\n\r\n> Can one of the admins verify this patch?\r\n>\r\n> \u2014\r\n> You are receiving this because you are subscribed to this thread.\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/tensorflow/tensorflow/pull/12637#issuecomment-325230893>,\r\n> or mute the thread\r\n> <https://github.com/notifications/unsubscribe-auth/ABSDY4VZK1yP0_Vl5otRCcuBt3wZ4NVSks5scfdEgaJpZM4PD8xo>\r\n> .\r\n>\r\n\r\n\r\n\r\n-- \r\n/******************************************\r\n\u5bae\u7530 \u8ce2\u4e00\r\n*******************************************/\r\n", "Hi @miyataken999,\r\n\r\nWould you suggest something akin to the Grace Hopper test on other iOS examples?\r\n\r\nIf you download this [image](https://github.com/tensorflow/models/blob/master/research/im2txt/g3doc/COCO_val2014_000000224477.jpg), name it _wave.jpg_, and drop it into the app bundle, you should be able to add the following test of the provided  pre-trained model within the ViewController class.\r\n```swift \r\noverride func viewDidLoad() {\r\n        super.viewDidLoad()\r\n        ...\r\n        \r\n        print(\"Generated:\\n\" + v.generate_caption(UIImage(named: \"wave.jpg\")))\r\n        print(\"Expected:\\n0.041008 \\na man riding a wave on top of a surfboard \")\r\n}\r\n``` \r\n", "@andrewharp maybe something you'd be interested in reviewing?", "@andrewharp ping", "Any update on merging this? I have time over the weekend to resolve any stylistic critique, but I think the captioning demo is already completely functional as it is.", "ETA for fixes is around two weeks :) EDIT: Sometime in February", "@liamnaks no rush, but when you get around to it, please pull rebase and push again.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address on your commit.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot. The email used to register you as an authorized contributor must be the email used for the Git commit.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_sender_cla -->", "signed it (again)", "CLAs look good, thanks!\n\n<!-- ok -->", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @petewarden: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "It has been 61 days that this pull-request has stalled. Please create a new pull-request with the requested changes."]}, {"number": 12636, "title": "Removing slightly confusing \">\" from output", "body": "I found the `>` a bit confusing in the output of `import_pb_to_tensorboard.py`:\r\n```\r\n$ python import_pb_to_tensorboard.py --model_dir ~/mnist_model_graph.pb --log_dir /tmp/tensorflow_logdir\r\nModel Imported. Visualize by running: > tensorboard --logdir=/tmp/tensorflow_logdir\r\n```\r\nIf you include that symbol when trying to launch tensorboard, it fails:\r\n```\r\n$ > tensorboard --logdir=/tmp/tensorflow_logdir\r\n-bash: --logdir=/tmp/tensorflow_logdir: No such file or directory\r\n```\r\nYes, this is relatively obvious to a knowledgable programmer, but if this isn't there for a specific reason, then we may as well remove it. \u00af\\_(\u30c4)_/\u00af\r\n\r\n**AFTER THE FIX**\r\n\r\nTested on Mac OS X Siera 10.12.6.\r\n```\r\n$ python import_pb_to_tensorboard.py --model_dir ~/mnist_model_graph.pb --log_dir /tmp/tensorflow_logdir\r\nModel Imported. Visualize by running: tensorboard --logdir=/tmp/tensorflow_logdir\r\n```", "comments": ["Can one of the admins verify this patch?"]}, {"number": 12635, "title": "Training doesn't start when using batch_normalization,", "body": "I am following the article.\r\nhttps://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization\r\n\r\nWhen I use the below code, the training doesn't start.\r\n\r\n`update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n  with tf.control_dependencies(update_ops):\r\n    train_op = optimizer.minimize(loss)`\r\n\r\nAny help will be greatly appreciated.", "comments": ["what do you mean by saying \"don't start\"? does the training start with an error or just hang?", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 12634, "title": "Removing slightly confusing \">\" from output", "body": "I found the `>` a bit confusing in the output of `import_pb_to_tensorboard.py`:\r\n```\r\n$ python import_pb_to_tensorboard.py --model_dir ~/mnist_model_graph.pb --log_dir /tmp/tensorflow_logdir\r\nModel Imported. Visualize by running: > tensorboard --logdir=/tmp/tensorflow_logdir\r\n```\r\nIf you include that symbol when trying to launch tensorboard, it fails:\r\n```\r\n$ > tensorboard --logdir=/tmp/tensorflow_logdir\r\n-bash: --logdir=/tmp/tensorflow_logdir: No such file or directory\r\n```\r\nYes, this is relatively obvious to a knowledgable programmer, but if this isn't there for a specific reason, then we may as well remove it. \u00af\\_(\u30c4)_/\u00af\r\n\r\n**AFTER THE FIX**\r\n\r\nTested on Mac OS X Siera 10.12.6.\r\n```\r\n$ python import_pb_to_tensorboard.py --model_dir ~/mnist_model_graph.pb --log_dir /tmp/tensorflow_logdir\r\nModel Imported. Visualize by running: tensorboard --logdir=/tmp/tensorflow_logdir\r\n```", "comments": ["Can one of the admins verify this patch?", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_author_cla -->", "I've updated the email address in my GitHub so hopefully the CLA will pass now. :-)", "Recreated as https://github.com/tensorflow/tensorflow/pull/12636 with the correct email address used for my commits."]}, {"number": 12633, "title": "Update README.md", "body": "Edit the tutorial URL", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please"]}, {"number": 12632, "title": "tf.image.resize_images differs from PIL/scipy.misc.imresize", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYES\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux localhost.localdomain 3.10.0-514.el7.x86_64 #1 SMP Tue Nov 22 16:42:41 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"7 (Core)\"                                                              \r\nVERSION_ID=\"7\"                                                                  \r\nCENTOS_MANTISBT_PROJECT_VERSION=\"7\"                                             \r\nREDHAT_SUPPORT_PRODUCT_VERSION=\"7\"     \r\n\r\n- **TensorFlow installed from (source or binary)**:\r\nSource\r\n\r\n- **TensorFlow version (use command below)**:\r\ntf.VERSION = 1.2.1\r\ntf.GIT_VERSION = v1.2.1-0-gb4957ff\r\ntf.COMPILER_VERSION = v1.2.1-0-gb4957ff\r\nSanity check: array([1], dtype=int32)\r\n\r\n- **Python version**: \r\n2.7\r\n\r\n- **Bazel version (if compiling from source)**:\r\n0.4.5\r\n\r\n- **CUDA/cuDNN version**:\r\nCUDA8.0/CUDNN6.0\r\n\r\n- **GPU model and memory**:\r\nGeForce GTX 1080  8113MiB\r\n\r\n- **Exact command to reproduce**:\r\nSee Source code\r\n\r\n### Describe the problem\r\nAs the title states, tf.image.resize_images returns different values compared to imresize in scipy or PIL. This is important because we expect the same behaviour for migrating code originally written using scipy.misc.imresize or PIL.\r\n\r\n### Source code / logs\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom scipy.misc import imresize\r\n\r\nimage = (255 * np.random.rand(127, 127, 3)).astype(np.uint8)\r\nresize_size = [255, 255]\r\n\r\nimage_resized = tf.image.resize_images(image, resize_size, method=tf.image.ResizeMethod.BILINEAR)\r\nwith tf.Session() as sess:\r\n    image_resized_tf = sess.run(image_resized)\r\n\r\nimage_resized_np = imresize(image, resize_size, interp='bilinear')\r\n\r\ndiff = image_resized_np.astype(np.float32) - image_resized_tf.astype(np.float32)\r\nprint('resized image diff: {}'.format(np.mean(np.abs(diff))))\r\n# resized image diff: 31.6155033112\r\n```\r\n", "comments": ["https://github.com/tensorflow/tensorflow/issues/6720#issuecomment-298112231", "This seems to be a duplicate of #6720. Closing here."]}, {"number": 12631, "title": "Make Dataset.map not unpack namedtuple", "body": "The map method of tf.contrib.data.Dataset unpacks iterables before passing them to the mapped function. This is quite convenient. However, currently this also happens for namedtuples, which IMHO is not what one would expect. Consider, for example, the following code:\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.data import Dataset\r\nfrom collections import namedtuple\r\n\r\nExample = namedtuple(\"Example\", [\"label\", \"attributes\", \"bounding_box\", \"image\"])\r\n\r\n\r\ndef read_example(serialized_example):\r\n    # parse example\r\n    label = ...\r\n    attribute = ...\r\n    bounding_box = ...\r\n    image = ...\r\n    \r\n    return Example(label, attribute, bounding_box, image)\r\n\r\n\r\ndef preprocess_example(example):\r\n    image = some_function(example.image, example.bounding_box)\r\n    return example._replace(image=image)\r\n\r\n\r\ndataset = tf.contrib.data.TFRecordDataset(filename)\r\ndataset = dataset.map(read_example)\r\ndataset = dataset.map(preprocess_example)\r\n```\r\n\r\nThis does not work because the namedtuple instance is unpacked and its fields are passed as separate arguments to `preprocess_example`. So currently one has to reassemble the namedtuple manually. This is not a big deal, but it would be more convenient if namedtuples were not unpacked, as is also the case for dictionaries.\r\n\r\nThis can be easily achieved by making `_should_unpack_args` return False for namedtuples, as is done in this pull request.", "comments": ["@adaitche, thanks for your PR! By analyzing the history of the files in this pull request, we identified @mrry, @tensorflower-gardener and @saeta to be potential reviewers.", "Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Added a test case and simplified as suggested to `return type(args) is tuple`. This is indeed simpler. And also more explicit, i.e. now it is clear that only tuples will be unpacked. Before it was everything what is a Sequence but not a list, string or dict, which for example included a deque or some custom class derived from Sequence.\r\n\r\n@mrry I am wondering why in InterleaveDataset on line 2129 `nest.is_sequence` is used in contrast to `_should_unpack_args`. This means that e.g. dictionaries will be unpacked. Is this the intended behaviour?\r\n\r\n", "Thanks for adding the test! Code looks great now.\r\n\r\nAs for `InterleaveDataset`, I think that's a bug (probably my oversight when I added it...): we should be consistent across the various function-taking transformations, so it would be great if you could change it to use `_should_unpack_args()` as well.", "Changed InterleaveDataset to use `_should_unpack_args`.\r\n\r\n\r\n", "Awesome, thanks!\r\n\r\n@tensorflow-jenkins test this please."]}, {"number": 12630, "title": "It seems that tf.gfile.Copy can not support larget hdfs file", "body": "It seems that when using ``tf.gfile.Copy(\"hdfs://default/some_hdfs_file\",\"./test\")``, if `some_hdfs_file` are large file such as 11GB in my case, it will report Exception.  Change to a 3GB file works fine.\r\n\r\nI'm using the latest version of tensorflow.\r\n\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/x/anaconda2/lib/python2.7/site-packages/tensorflow/python/lib/io/file_io.py\", line 384, in copy\r\n    compat.as_bytes(oldpath), compat.as_bytes(newpath), overwrite, status)\r\n  File \"/home/x/anaconda2/lib/python2.7/contextlib.py\", line 24, in __exit__\r\n    self.gen.next()\r\n  File \"/home/x/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: hdfs://default/tmp/x/x/dmcluster_predict_data_v3/20170817/023645/part-00000\r\n```", "comments": ["Seems incredibly unlikely since it looks like you're on a unix-variant, but just to cover all bases: `\"./test\"` in this example wouldn't be on a FAT32 volume, would it?", "@quaeler  it's not fat32 volume.  I can download the file using \"hadoop fs -get \" but can not using tf.gfile.Copy.  I'm not sure if the limitation is 4GB, I will test it later by using a 4GB file.", "Could you monitor the memory consumption of the python process when attempting to do this; i might be looking at the wrong thing or looking at the right thing wrongly, because this will sound cuckoo-banana, but the code path looks like it is doing this copy in memory:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/platform/gfile.py#L22\r\n->\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/lib/io/file_io.py#L371\r\n->\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/lib/io/file_io.i#L113\r\n", "Please provide details about what platform you are using  (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?  Make sure you also include the exact command if possible to produce  the output included in your test case. If you are unclear what to include  see the issue template displayed in  [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\n We ask for this in the issue submission template, because    it is really difficult to help without that information. Thanks!", "This issue is automatically closed due to lack of activity. Please re-open if this is still an issue for you. Thanks!"]}, {"number": 12629, "title": "Update feature_column_ops.py", "body": "Using get_variables over model_variable", "comments": ["@alanyee, thanks for your PR! By analyzing the history of the files in this pull request, we identified @ispirmustafa, @tensorflower-gardener and @theweiho to be potential reviewers.", "Can one of the admins verify this patch?", "Ah yeah, I have noticed that. I was going to check if there was a way to add them into both graphs.", "I'm closing this for now. @alanyee feel free to reopen when you have an update. Thanks~"]}, {"number": 12628, "title": "tf.layers.conv2d does not accept higher dimension tensor", "body": "### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Win10 x64\r\n- **TensorFlow installed from (source or binary)**: pip install\r\n- **TensorFlow version (use command below)**: r1.3\r\n- **Python version**:  3.5 amd 64\r\n- **Bazel version (if compiling from source)**: Used binary\r\n- **CUDA/cuDNN version**: CUDA 8.0 + CuDNN 6.0\r\n- **GPU model and memory**:  GeForce GTX 1070 8.00GiB\r\n\r\nI am trying to feed a ```tf.layers.conv2d``` with tensor shape [batch_size, size_i_want_to_separate, width, height, channels] but I received ```ValueError: Input 0 of layer conv2d_1 is incompatible with the layer: expected ndim=4, found ndim=5. Full shape received: [1, 4, 640, 377, 3]```. I think it is OK to feed layer with high dimension as long as last three dimension is image.\r\n\r\nIf it is impossible to add this feature, may I try to merge first two dimensions together and feed it to conv2d layer. Then separate it to origin form but maintain the order? How to do it?   \r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 12627, "title": "Eager API String Tensors (and others that need to be copied) Fix", "body": "This PR partially fixes the issue related to string tensors, described in #12612. Note that there are still some issues remaining related to string tensors:\r\n1. There is a small inconsistency when dealing with TFE tensors now in that for the string data type, a copy of the provided `TF_Tensor` is created, whereas for others types that's not the case. This can be problematic when users of the API attempt to use the underlying tensor buffer directly (e.g., to read values of specific elements). The problem could potentially be alleviated if the same memory layout is used for string `TF_Tensor`s and `tensorflow::Tensor`s. I'm not sure why that's not the case and I'm also not sure what the memory layout for string tensors is internally (could someone provide some insight into that please?).\r\n2. The above-mentioned problem could be partially alleviated by providing a TFE function for obtaining a byte array representation of the `i`th element in the flattened (row-major) tensor. That is currently the only use I have found for directly accessing the underlying buffer.\r\n3. This fix resolves the issues specific to string tensors and the eager execution API, but one issue related to #12612 still remains. When I try to use some ops, such as the `Unpack` op, I get the following error (**no matter what the data type of the tensor is**): `C  [libtensorflow.so+0x20f0]  TFE_TensorHandleDeviceName+0x0`. I plan to look more into this, but please let me know if you can see a reason why this might be happening.\r\n\r\n@alextp could you please give me some information on what the memory layout is for string tensors internally and on why we cannot use the same representation for the C API `TF_Tensor`s? That would resolve points 1 and 2 above. I think that a function for obtaining the `i`th element would still be very useful though, in either case. :)", "comments": ["@eaplatanios, thanks for your PR! By analyzing the history of the files in this pull request, we identified @alextp, @asimshankar and @meheffernan to be potential reviewers.", "Can one of the admins verify this patch?", "Thanks for the PR. Indeed, I think the missing conversion is a bug.\r\nAnswering your questions:\r\n\r\n1. The layout for string `tensorflow::Tensor`s is a flattened array of `std::string` objects (so you'll see use of `flat<string>` at various places, like [this](https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/core/framework/tensor.cc#L870)). This layout isn't a contiguous piece of memory, so isn't quite amenably to say a single `memcpy` of the contents (and which is why there are various specializations for string-valued tensors to ensure their contents are contiguous, for example the helper for [`Tensor::AsProtoTensorContent`](https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/core/framework/tensor.cc#L161)).\r\n\r\n2. What you suggest might be possible, but might also open a separate can of worms. I'd be tempted to defer on this until there is a stronger demonstrated need for the performance benefit (are you using models that involve large string tensors as inputs/outputs?)\r\n\r\n3. Will have to look into this separately. (Could you provide a simple reproduction using the C API as opposed to using your Scala wrappers?)\r\n", "Thanks for the detailed response! :) I'll respond tomorrow because I'm going to bed now, but I just wanted to ask something about the requested changes. I also don't like ignoring the status. In my opinion, the right way to do this would be to change the function to take a status argument instead of creating one internally and just returning a nullptr. This would be better both because it'd be consistent with the rest of the API and because it would let the caller decide how to handle errors and maybe print information about them. I just didn't make that change because I don't know how you feel about changing the API. Would you like me to make that change or just create a new status in the function body for now?\n\nOn Aug 28, 2017, 1:06 AM -0400, Asim Shankar <notifications@github.com>, wrote:\n> @asimshankar requested changes on this pull request.\n> In tensorflow/c/eager/c_api.cc:\n> > @@ -151,9 +151,10 @@ TF_DeviceList* TFE_ContextListDevices(TFE_Context* ctx, TF_Status* status) {\n> }\n>\n> TFE_TensorHandle* TFE_NewTensorHandle(TF_Tensor* t) {\n> -  return new TFE_TensorHandle(\n> -      tensorflow::TensorCApi::MakeTensor(t->dtype, t->shape, t->buffer),\n> -      nullptr);\n> +  tensorflow::Tensor tensor;\n> +  // TODO: Add status argument and check on it.\n> +  tensorflow::TF_TensorToTensor(t, &tensor);\n> I'm worried about ignoring the status result.\n> At the very least, we should return nullptr if !status.ok()\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub, or mute the thread.\n", "@asimshankar In response to your answers:\r\n1. I sort of expected that but wasn't sure. Thanks for verifying. :)\r\n2. I can see this not being a priority and to be honest, I cannot really say what the potential bad side effects of this would be (assuming the obtained element was a copy of the corresponding bytes in the buffer). Just to put this into perspective though, and for future reference, I would like to describe why I think such a feature could be useful. Currently, I'm using the eager API to offer numpy-like functionality in Scala. I think many people might use it in that way, given that not many languages offer a tensor computation library as powerful as numpy. The current API works fine for creating and manipulating tensors within TensorFlow, but whenever one wants to obtain the value of a particular element they would have to first slice the tensor to obtain a scalar tensor containing that value, and then copy the result to CPU and resolve using the TFE resolve function. Then they can obtain a pointer to the `TF_Tensor` buffer and read that element. Furthermore, if they want to iterate over elements, they would need to do the same, without the slicing component. Therefore, a function for obtaining a single element given the flattened index, and a method for iterating over tensor elements, might be useful. I also noticed that such methods are already provided in `tensorflow::Tensor`, in C++, so I'm not sure why it would be bad to wrap them for TFE tensors.\r\n3. I'll try to submit an issue for this later today or tomorrow with a C++ code fragment. :)", "Thanks @eaplatanios . I agree that the more appropriate fix is to change the signature of `TFE_NewTensorHandle` so that it returns a status. If you're up for that, please do make the change.\r\n\r\nRegarding adding an API for iteration - I'm not suggesting that it will not be needed, just deferring till there is a more demonstrable need. It's always easier to add new APIs and harder to remove/change existing ones. Adding a function to provide the byte representation of the i-th flattened element will raise questions like: (1) Should that be mutable, as in, do we want to allow users to edit the value of the element as well? (2) If so, then who will own the memory if the length of the representation changes? (e.g., a longer or shorter string) and how will that length be specified? (3) If the representation meant to be friendly to serialization (like the numeric types?), or is it up to the user of the API to worry about encoding/decoding lengths? etc.\r\n\r\nWe can take positions on these, but it seems a bit premature to me for now, especially until we can more concretely demonstrate a (presumably performance) impact of this. Does that sound reasonable?\r\n\r\nThanks very much for digging into this and the fix!", "Thanks a lot Asim! That sounds good. I'll push the edits for the status flag later today. If that's ok, I will push the changes untested and let your CI system run them, because they take a very long time on my laptop.\r\n\r\nRegarding the points you raise. Yes, I agree they all make sense. I guess there is a big underlying question of whether you want tensors to be considered mutable or not. Currently they are assumed to be immutable (at least that's my understanding) and that's why I thought such an addition to the API would be fine. But you're right and it's not really very necessary. I'm currently resolving the tensors but I also think users wouldn't really need to do that much, as for the most part they would not be taking values out of tensors; most computation should be done within TensorFlow.", "I added the status as an extra argument. It should be good now. :)", "Jenkins, test this please", "Jenkins, test this please", "Jenkins, test this please", "Jenkins, test this please", "Sorry I forgot to revert one of the changes. It should be good now.", "@asimshankar Could you please run the tests for this to make sure it's fixed? Thank you! :)", "Jenkins, test this please.\n\nOn Wed, Aug 30, 2017 at 11:10 AM, Anthony Platanios <\nnotifications@github.com> wrote:\n\n> @asimshankar <https://github.com/asimshankar> Could you please run the\n> tests for this to make sure it's fixed? Thank you! :)\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/12627#issuecomment-326072614>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxY5YrZaokYKw1GgFlrhzQN05iFt5ks5sdaWZgaJpZM4PDsft>\n> .\n>\n\n\n\n-- \n - Alex\n", "Hmm...I'm not sure if there is a problem or if the tests simply timed out due to load.", "Jenkins, test this please", "I think this should be ready to be merged."]}, {"number": 12626, "title": "Eager API String Tensors (and others that need to be copied) Fix", "body": "This PR partially fixes the issue related to string tensors, described in #12612. Note that there are still some issues remaining related to string tensors:\r\n1. There is a small inconsistency when dealing with TFE tensors now in that for the string data type, a copy of the provided `TF_Tensor` is created, whereas for others types that's not the case. This can be problematic when users of the API attempt to use the underlying tensor buffer directly (e.g., to read values of specific elements). The problem could potentially be alleviated if the same memory layout is used for string `TF_Tensor`s and `tensorflow::Tensor`s. I'm not sure why that's not the case and I'm also not sure what the memory layout for string tensors is internally (could someone provide some insight into that please?).\r\n2. The above-mentioned problem could be partially alleviated by providing a TFE function for obtaining a byte array representation of the `i`th element in the flattened (row-major) tensor. That is currently the only use I have found for directly accessing the underlying buffer.\r\n3. This fix resolves the issues specific to string tensors and the eager execution API, but one issue related to #12612 still remains. When I try to use some ops, such as the `Unpack` op, I get the following error (**no matter what the data type of the tensor is**): `C  [libtensorflow.so+0x20f0]  TFE_TensorHandleDeviceName+0x0`. I plan to look more into this, but please let me know if you can see a reason why this might be happening.\r\n\r\n@alextp could you please give me some information on what the memory layout is for string tensors internally and on why we cannot use the same representation for the C API `TF_Tensor`s? That would resolve points 1 and 2 above. I think that a function for obtaining the `i`th element would still be very useful though, in either case. :)", "comments": ["Can one of the admins verify this patch?", "@eaplatanios, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @asimshankar and @keveman to be potential reviewers.", "For some reason the commits here are mixed with some I made for another PR. Sorry about that. I'll look into resolving it.", "I'll just make another PR."]}, {"number": 12625, "title": "Fix anchor tag in adding_an_op.md", "body": "Default anchor tag id is generated by the target text of the title. And it uses an underscore instead of hyphen.", "comments": ["@Lewuathe, thanks for your PR! By analyzing the history of the files in this pull request, we identified @keveman, @tensorflower-gardener and @vrv to be potential reviewers.", "Can one of the admins verify this patch?", "@MarkDaoust any opinion on this?", "I pushed a couple of minor fixes.\r\nI tested it with both g3doc and tensorflow.org.\r\n\r\nLGTM", "Jenkins, test this please.", "Jenkins, test this please.", "Jenkins seems to be out, somehow.\r\n\r\n@tensorflow-jenkins test this please.", "Jenkins, test this please."]}, {"number": 12624, "title": "expose build_default_serving_input_fn", "body": "For #12508, I find that `build_default_serving_input_fn` is hidden like #12568 . I don't know whether it is intentional. \r\n\r\nCF pr #12617.", "comments": ["@facaiy, thanks for your PR! By analyzing the history of the files in this pull request, we identified @martinwicke, @tensorflower-gardener and @ilblackdragon to be potential reviewers.", "Can one of the admins verify this patch?", "@davidsoergel any opinion on this?", "@davidsoergel ping"]}, {"number": 12623, "title": "Rename all BackProp to Backprop for consistency.", "body": "Resolving issue #12515.\r\nFirst attempt to start contributing to tensorflow.", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "@aseemraj, thanks for your PR! By analyzing the history of the files in this pull request, we identified @yuanbyu, @tensorflower-gardener and @keveman to be potential reviewers.", "@googlebot I signed.", "CLAs look good, thanks!\n\n<!-- ok -->", "Jenkins, test this please.", "Mac fails on\r\n`//tensorflow/cc:gradients_nn_grad_test` and `//tensorflow/go:test`. Trying again.\r\n\r\nJenkins, test this please."]}, {"number": 12622, "title": "[android demo] fix issue #12431 Java implementation of YUV420SP to ARGB8888 converting", "body": "This PR fix issue #12431\r\nJava implementation of `ImageUtils.convertYUV420SPToARGB8888` made and refactoring for Java implementation of `ImageUtils.convertYUV420ToARGB8888` made as well.\r\n\r\nDespite the fact that code looks a bit 'nuddle-style' that was made for efficiency reasons. Breaking down it into few, more readable functions (like it was made before at `ImageUtils.convertYUV420ToARGB8888`) lead into 3-time function execution increase:\r\nPrevious implementation of `ImageUtils.convertYUV420ToARGB8888` cause invocation inside double nested circles 307200 times (`640x480`) of `YUV2RGB` function and three times more `convertByteToInt` with `Math.min` and `Math.max` functions. \r\n\r\nTotal costs of classification at TF Classify was around 3000 ms on my test device (Meizu N2, API 22). Proposed implementation drops it down to 1000-1100 ms (which is comparable with native C implementation from `libtensorflow_demo.so`  ~700 ms).", "comments": ["@ArtsiomCh, thanks for your PR! By analyzing the history of the files in this pull request, we identified @andrewharp, @benoitsteiner and @keveman to be potential reviewers.", "Can one of the admins verify this patch?", "@andrewharp Please check the corrected version of ImageUtils.java\r\nI tried to find a compromise between readability of the code and performance. \r\nUnfortunately, there is no way to declare an in-line function in java. So using any additional function inside our double nested loops will create the overhead of making a function call. \r\nAs I mentioned before the original java implementation of `convertYUV420ToARGB8888` function took 3000 ms on my test device to show a result. After making Method Tracing I've found that majority of the time being spent on calling helping functions: `convertByteToInt` with `Math.min` and `Math.max`. And the actual classification work by TF took just ~500ms.\r\nMy original \"all-in-one\" implementation decrease the total time between showing result from 3000ms to 1000ms. Even adding YUV2RGB function (for readability and avoiding duplicating the code) already increase the total time from ~1000 ms to ~1100. I think this is acceptable, as it just 10%.\r\nPlease feel free to ask for any additional correctness.\r\n\r\nPS Looks like GitHub shows a bit mess in `Split` mode. It replaced `convertYUV420ToARGB8888` with `convertYUV420SPToARGB8888` code. And create new `convertYUV420ToARGB8888` instead of correct existing implementation. Any case resulting code looks clean enough.\r\n", "Thanks, I think this is a good compromise. IIRC on some devices Java already performed nearly equivalently to the native conversion, so I think you might be seeing one of the more extreme situations."]}, {"number": 12621, "title": "Calculating marginals in CRF", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": []}, {"number": 12620, "title": "[XLA] Add a check to the HLO verifier for badly formatted Broadcasts.", "body": "This adds a check to the HloVerifier which ensures that the Hlo Broadcast instructions are formatted correctly.  Since they are different from the UserComputation broadcast instructions (and therefore the XLA docs), examples of invalid instructions were appearing in the repo.\r\n\r\nAlso fix up the two cases where the code was creating invalid broadcasts.\r\n\r\n\r\n", "comments": ["Can one of the admins verify this patch?", "@DavidNorman, thanks for your PR! By analyzing the history of the files in this pull request, we identified @hawkinsp, @meheffernan and @tensorflower-gardener to be potential reviewers.", "Jenkins, test this please", "@jpienaar hi - seems like the code review thing has not run.  is that an automated thing?\r\n", "Jenkins, test this please.", "Jenkins, test this please.", "Ah - this Linux XLA error seems to be a memory/disk space issue with the docker builder.\r\n", "Jenkins, test this please", "Hmm.  I'm not really sure I understand the problem here.  it appears to be another build system error, but two in a row seems suspicious.\r\n\r\nis this happening to other CI builds too, or just this one?\r\n\r\nshould I be merging in the head of master?\r\n", "The 'Linux CPU Tests (Python 3)' failure is definitely not this PR - it contains only XLA changes, and the failure is something about a gRPC server.\r\n\r\nthe XLA one is harder to judge - is it a git merge problem?  or just an infrastructure problem?\r\n", "It is weird, I've tried prodding it too. And I do see passing cases post this. I've set off another round of building. And will ask around more if that doesn't work.", "Jenkins, test this please.", "@gunan, can we change \"TF Code Review\" to \"TF Test Suite\" to avoid confusion?\r\n\r\nJenkins, test this please.", "Renaming of the build complete.\n\nOn Thu, Sep 7, 2017 at 5:06 PM, Yifei Feng <notifications@github.com> wrote:\n\n> Merged #12620 <https://github.com/tensorflow/tensorflow/pull/12620>.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/12620#event-1239945686>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AHlCOeWp3JZcdsH3tbJ8IJdRn7hWMsdwks5sgIUJgaJpZM4PDeWe>\n> .\n>\n"]}, {"number": 12619, "title": "batch normalization", "body": "These days i have meet some problem about BN layers, code is here, i want run my net on mnist\r\ndataset, it worked when i am training, how when i verify on valiation data or test date,  when i change the state 'is_training'. what is wrong when i am verifing and how can i save mean and val in training state? \r\n\r\n``import tensorflow as tf\r\n\r\nfrom tensorflow.examples.tutorials.mnist import input_data\r\nmnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\r\n\r\n\r\n#define some weights\r\ndef weight_variable(shape):\r\n    initial = tf.truncated_normal(shape, stddev=0.01)\r\n    return tf.Variable(initial)\r\n\r\ndef bias_variable(shape):\r\n\tinitial = tf.constant(0.01, shape=shape)\r\n\treturn tf.Variable(initial)\r\n\r\ndef conv2d(input, in_features, out_features, kernel_size, with_bias=False):\r\n\tW = weight_variable([ kernel_size, kernel_size, in_features, out_features ])\r\n\tconv = tf.nn.conv2d(input, W, [ 1, 1, 1, 1 ], padding='SAME')\r\n\tif with_bias:\r\n\t\treturn conv + bias_variable([ out_features ])\r\n\treturn conv\r\n\r\ndef batch_activ_conv(current, in_features, out_features, kernel_size, is_training, keep_prob):\r\n    current = tf.contrib.layers.batch_norm(current, scale=True, is_training=is_training, updates_collections=None)\r\n    current = tf.nn.relu(current)\r\n    current = conv2d(current, in_features, out_features, kernel_size)\r\n    current = tf.nn.dropout(current, keep_prob)\r\n    return current\r\n\r\ndef block(input, layers, in_features, growth, is_training, keep_prob):\r\n    current = input\r\n    features = in_features\r\n    for idx in xrange(layers):\r\n        tmp = batch_activ_conv(current, features, growth, 3, is_training, keep_prob)\r\n        current = tf.concat([current, tmp],3)\r\n        features += growth\r\n    return current, features\r\n\r\ndef avg_pool(input, s):\r\n    return tf.nn.avg_pool(input, [ 1, s, s, 1 ], [1, s, s, 1 ], 'VALID')\r\n\r\n\r\n#define graph\r\n\r\nlayers =  12\r\nprint 'create graph ...'\r\n\r\nx = tf.placeholder(tf.float32, [None, 784])\r\ny_label = tf.placeholder(tf.float32, [None, 10])\r\nlr = tf.placeholder(tf.float32)\r\nkeep_prob = tf.placeholder(tf.float32)\r\nis_training = tf.placeholder(tf.bool, shape=[])\r\n\r\ncurrent = tf.reshape(x, [ -1, 28, 28, 1 ])\r\ncurrent = conv2d(current, 1, 16, 3)\r\n\r\ncurrent, features = block(current, layers, 16, 12, is_training, keep_prob)\r\ncurrent = batch_activ_conv(current, features, features, 1, is_training, keep_prob)\r\ncurrent = avg_pool(current, 2)  #14x14\r\ncurrent, features = block(current, layers, features, 12, is_training, keep_prob)\r\ncurrent = batch_activ_conv(current, features, features, 1, is_training, keep_prob)\r\ncurrent = avg_pool(current, 2)#7x7\r\ncurrent, features = block(current, layers, features, 12, is_training, keep_prob)\r\n\r\ncurrent = tf.contrib.layers.batch_norm(current, scale=True, is_training=is_training, updates_collections=None)\r\ncurrent = tf.nn.relu(current)\r\ncurrent = avg_pool(current, 7)\r\nfinal_dim = features\r\ncurrent = tf.reshape(current, [-1, final_dim])\r\nWfc = weight_variable([final_dim, 10])      #set classifiers\r\nbfc = bias_variable([10])\r\ny_predict = tf.nn.softmax(tf.matmul(current, Wfc) + bfc)\r\n\r\ncross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_label, logits=y_predict))\r\nl2 = tf.add_n([tf.nn.l2_loss(var) for var in tf.trainable_variables()])\r\nweight_decay = 1e-4\r\n#update moving_mean and moving_variance\r\nupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\nwith tf.control_dependencies(update_ops):\r\n    train_step = tf.train.GradientDescentOptimizer(lr).minimize(cross_entropy + l2 * weight_decay)\r\n\r\ncorrect_prediction = tf.equal(tf.argmax(y_predict, 1), tf.argmax(y_label, 1))\r\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))  # caculate the right numbers\r\n\r\ndef mytrain():\r\n    print 'train ...'\r\n    saver = tf.train.Saver()\r\n    with tf.Session() as sess:\r\n        sess.run(tf.global_variables_initializer())\r\n        for epoch in xrange(1, 10):    #train\r\n            if epoch < 150:\r\n                l = 0.5\r\n            elif epoch <200:\r\n                l = 0.1\r\n            else:\r\n                l = 0.01\r\n            print 'epoch: ',epoch\r\n            batch_x, batch_y = mnist.train.next_batch(500)\r\n            _,acc,loss = sess.run([train_step,accuracy,cross_entropy],\r\n                                     feed_dict={x: batch_x, y_label: batch_y, lr:l,is_training: True, keep_prob: 0.8})\r\n            print 'train acc : ',acc,\" loss: \",loss\r\n            #val\r\n            batch_x_val = mnist.validation.images\r\n            batch_y_val = mnist.validation.labels\r\n            acc,loss = sess.run([accuracy,cross_entropy],feed_dict={x: batch_x_val, y_label: batch_y_val, is_training: False, keep_prob: 0.8})\r\n            print 'val acc : ',acc,' loss: ',loss\r\n        saver.save(sess, 'temp/densenet.ckpt')\r\n\r\ndef mytest():\r\n    print 'test ...'\r\n    saver = tf.train.Saver()\r\n    with tf.Session() as sess:\r\n        saver.restore(sess, './temp/densenet.ckpt')\r\n        x_val = mnist.validation.images\r\n        y_val = mnist.validation.labels\r\n        val_results = sess.run(accuracy,\r\n                                 feed_dict={x: x_val, y_label: y_val, is_training: True, keep_prob: 1.})\r\n        print 'val acc: ', val_results\r\n        right = 0\r\n        for i in range(100):\r\n            x_test, y_test = mnist.validation.next_batch(500)\r\n            test_results = sess.run(accuracy,\r\n                                    feed_dict={x: x_test, y_label: y_test, is_training: False, keep_prob: 1.})\r\n            #right = right + test_results\r\n        print 'test:  acc: ', test_results\r\n\r\nif __name__ == '__main__':\r\n    mytrain()\r\n    mytest()\r\n\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 12618, "title": "Android Demo - SpeechActivity - Fatal Exception", "body": "Samsung Galaxy J1 - Android ver. 5.1.1\r\n\r\n08-26 11:56:55.226: I/TensorFlowInferenceInterface(14094): Model load took 41ms, TensorFlow version: 1.3.0\r\n08-26 11:56:55.226: I/TensorFlowInferenceInterface(14094): Successfully loaded model from 'file:///android_asset/conv_actions_frozen.pb'\r\n08-26 11:56:55.231: D/AndroidRuntime(14094): Shutting down VM\r\n08-26 11:56:55.231: E/AndroidRuntime(14094): **FATAL EXCEPTION**: main\r\n08-26 11:56:55.231: E/AndroidRuntime(14094): Process: org.tensorflow.demo, PID: 14094\r\n08-26 11:56:55.231: E/AndroidRuntime(14094): java.lang.NoSuchMethodError: **No virtual method requestPermissions**([Ljava/lang/String;I)V in class Lorg/tensorflow/demo/SpeechActivity; or its super classes (declaration of 'org.tensorflow.demo.SpeechActivity' appears in /data/app/org.tensorflow.demo-1/base.apk)\r\n08-26 11:56:55.231: E/AndroidRuntime(14094): \tat org.tensorflow.demo.SpeechActivity.requestMicrophonePermission(SpeechActivity.java:158)\r\n08-26 11:56:55.231: E/AndroidRuntime(14094): \tat org.tensorflow.demo.SpeechActivity.onCreate(SpeechActivity.java:153)\r\n08-26 11:56:55.231: E/AndroidRuntime(14094): \tat android.app.Activity.performCreate(Activity.java:6609)\r\n08-26 11:56:55.231: E/AndroidRuntime(14094): \tat android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1134)\r\n08-26 11:56:55.231: E/AndroidRuntime(14094): \tat android.app.ActivityThread.performLaunchActivity(ActivityThread.java:3086)\r\n08-26 11:56:55.231: E/AndroidRuntime(14094): \tat android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:3243)\r\n08-26 11:56:55.231: E/AndroidRuntime(14094): \tat android.app.ActivityThread.access$1000(ActivityThread.java:218)\r\n08-26 11:56:55.231: E/AndroidRuntime(14094): \tat android.app.ActivityThread$H.handleMessage(ActivityThread.java:1718)\r\n08-26 11:56:55.231: E/AndroidRuntime(14094): \tat android.os.Handler.dispatchMessage(Handler.java:102)\r\n08-26 11:56:55.231: E/AndroidRuntime(14094): \tat android.os.Looper.loop(Looper.java:145)\r\n08-26 11:56:55.231: E/AndroidRuntime(14094): \tat android.app.ActivityThread.main(ActivityThread.java:6917)\r\n08-26 11:56:55.231: E/AndroidRuntime(14094): \tat java.lang.reflect.Method.invoke(Native Method)\r\n08-26 11:56:55.231: E/AndroidRuntime(14094): \tat java.lang.reflect.Method.invoke(Method.java:372)\r\n08-26 11:56:55.231: E/AndroidRuntime(14094): \tat com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:1404)\r\n08-26 11:56:55.231: E/AndroidRuntime(14094): \tat com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1199)\r\n\r\n", "comments": ["Please provide details about what platform you are using  (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?  Make sure you also include the exact command if possible to produce  the output included in your test case. If you are unclear what to include  see the issue template displayed in  [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\n We ask for this in the issue submission template, because    it is really difficult to help without that information. Thanks!", "this error occurs from installed apk both from github and jeeves repositories. i would guess its the same apk, latest version of apk.\r\nIt will give the above error when trying to load. actually all 4 activities throw dofferent fatal errors and do not load. i copied the error output from android monitor tool in sdk. \r\n", "it is running on:\r\nSamsung Galaxy J1 - Android ver. 5.1.1\r\nwhen clicking on the TF Speech launch icon, it does not load and android pops a dialog \"Unfortunately,  Tensor Flow demo has stopped.\"", "This may be a problem with old versions of Android, since we're only testing on more recent OS's. We should have better version checking, but it's unlikely to be something we get to in the near term, so closing for now unless somebody external wants to take this on?"]}, {"number": 12617, "title": "expose sparse_column_with_vocabulary_file method", "body": "The bug is explained in #12568 . \r\n\r\nI am not familiar with build tool, however, I observe that the method is missing in `__init__.py`.", "comments": ["@facaiy, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @vrv and @martinwicke to be potential reviewers.", "Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "Could I get `queue_runner_test/test.log` ? Thanks.", "This is the full log:\r\n\r\n```\r\nFAIL: //bazel_pip/tensorflow/python:queue_runner_test (see /var/lib/jenkins/workspace/tensorflow-pull-requests-cpu-python3/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/eab0d61a99b6696edb3d2aff87b585e8/execroot/workspace/bazel-out/local-py3-opt/testlogs/bazel_pip/tensorflow/python/queue_runner_test/test.log).\r\nINFO: From Testing //bazel_pip/tensorflow/python:queue_runner_test:\r\n==================== Test output for //bazel_pip/tensorflow/python:queue_runner_test:\r\n2017-09-08 00:08:17.468320: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n.ERROR:tensorflow:Exception in QueueRunner: Fetch argument 'i fail' cannot be interpreted as a Tensor. (\"The name 'i fail' refers to an Operation not in the graph.\")\r\nERROR:tensorflow:Exception in QueueRunner: Fetch argument 'so fail' cannot be interpreted as a Tensor. (\"The name 'so fail' refers to an Operation not in the graph.\")\r\nException in thread QueueRunnerThread-fifo_queue-so fail:\r\nTraceback (most recent call last):\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 271, in __init__\r\n    fetch, allow_tensor=True, allow_operation=True))\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 3156, in as_graph_element\r\n    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 3216, in _as_graph_element_locked\r\n    \"graph.\" % repr(name))\r\nKeyError: \"The name 'so fail' refers to an Operation not in the graph.\"\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.4/threading.py\", line 920, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.4/threading.py\", line 868, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 233, in _run\r\n    enqueue_callable = sess.make_callable(enqueue_op)\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1184, in make_callable\r\n    fetch_handler = _FetchHandler(self._graph, fetches, {})\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 414, in __init__\r\n    self._fetch_mapper = _FetchMapper.for_fetch(fetches)\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 234, in for_fetch\r\n    return _ListFetchMapper(fetch)\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 341, in __init__\r\n    self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches]\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 341, in <listcomp>\r\n    self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches]\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 242, in for_fetch\r\n    return _ElementFetchMapper(fetches, contraction_fn)\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 281, in __init__\r\n    'Tensor. (%s)' % (fetch, str(e)))\r\nValueError: Fetch argument 'so fail' cannot be interpreted as a Tensor. (\"The name 'so fail' refers to an Operation not in the graph.\")\r\n\r\nException in thread QueueRunnerThread-fifo_queue-i fail:\r\nTraceback (most recent call last):\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 271, in __init__\r\n    fetch, allow_tensor=True, allow_operation=True))\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 3156, in as_graph_element\r\n    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 3216, in _as_graph_element_locked\r\n    \"graph.\" % repr(name))\r\nKeyError: \"The name 'i fail' refers to an Operation not in the graph.\"\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.4/threading.py\", line 920, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.4/threading.py\", line 868, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 233, in _run\r\n    enqueue_callable = sess.make_callable(enqueue_op)\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1184, in make_callable\r\n    fetch_handler = _FetchHandler(self._graph, fetches, {})\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 414, in __init__\r\n    self._fetch_mapper = _FetchMapper.for_fetch(fetches)\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 234, in for_fetch\r\n    return _ListFetchMapper(fetch)\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 341, in __init__\r\n    self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches]\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 341, in <listcomp>\r\n    self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches]\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 242, in for_fetch\r\n    return _ElementFetchMapper(fetches, contraction_fn)\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 281, in __init__\r\n    'Tensor. (%s)' % (fetch, str(e)))\r\nValueError: Fetch argument 'i fail' cannot be interpreted as a Tensor. (\"The name 'i fail' refers to an Operation not in the graph.\")\r\n\r\n.............ERROR:tensorflow:Exception in QueueRunner: Fetch argument 'bad_op' cannot be interpreted as a Tensor. (\"The name 'bad_op' refers to an Operation not in the graph.\")\r\nException in thread QueueRunnerThread-fifo_queue-bad_op:\r\nTraceback (most recent call last):\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 271, in __init__\r\n    fetch, allow_tensor=True, allow_operation=True))\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 3156, in as_graph_element\r\n    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 3216, in _as_graph_element_locked\r\n    \"graph.\" % repr(name))\r\nKeyError: \"The name 'bad_op' refers to an Operation not in the graph.\"\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.4/threading.py\", line 920, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.4/threading.py\", line 868, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 233, in _run\r\n    enqueue_callable = sess.make_callable(enqueue_op)\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1184, in make_callable\r\n    fetch_handler = _FetchHandler(self._graph, fetches, {})\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 414, in __init__\r\n    self._fetch_mapper = _FetchMapper.for_fetch(fetches)\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 234, in for_fetch\r\n    return _ListFetchMapper(fetch)\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 341, in __init__\r\n    self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches]\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 341, in <listcomp>\r\n    self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches]\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 242, in for_fetch\r\n    return _ElementFetchMapper(fetches, contraction_fn)\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 281, in __init__\r\n    'Tensor. (%s)' % (fetch, str(e)))\r\nValueError: Fetch argument 'bad_op' cannot be interpreted as a Tensor. (\"The name 'bad_op' refers to an Operation not in the graph.\")\r\n\r\nERROR:tensorflow:Exception in QueueRunner: Fetch argument 'bad_op' cannot be interpreted as a Tensor. (\"The name 'bad_op' refers to an Operation not in the graph.\")\r\nException in thread QueueRunnerThread-fifo_queue-bad_op:\r\nTraceback (most recent call last):\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 271, in __init__\r\n    fetch, allow_tensor=True, allow_operation=True))\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 3156, in as_graph_element\r\n    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 3216, in _as_graph_element_locked\r\n    \"graph.\" % repr(name))\r\nKeyError: \"The name 'bad_op' refers to an Operation not in the graph.\"\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.4/threading.py\", line 920, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.4/threading.py\", line 868, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 233, in _run\r\n    enqueue_callable = sess.make_callable(enqueue_op)\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 1184, in make_callable\r\n    fetch_handler = _FetchHandler(self._graph, fetches, {})\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 414, in __init__\r\n    self._fetch_mapper = _FetchMapper.for_fetch(fetches)\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 234, in for_fetch\r\n    return _ListFetchMapper(fetch)\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 341, in __init__\r\n    self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches]\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 341, in <listcomp>\r\n    self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches]\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 242, in for_fetch\r\n    return _ElementFetchMapper(fetches, contraction_fn)\r\n  File \"/workspace/pip_test/venv/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 281, in __init__\r\n    'Tensor. (%s)' % (fetch, str(e)))\r\nValueError: Fetch argument 'bad_op' cannot be interpreted as a Tensor. (\"The name 'bad_op' refers to an Operation not in the graph.\")\r\n\r\n...\r\n----------------------------------------------------------------------\r\nRan 17 tests in 0.958s\r\n\r\nOK\r\n```", "Thank you very much, @drpngx. \r\nThe stack trace is really odd for me. Could you please take a retest? I'll prepare a python3 environment for test later.", "Jenkins, test this please.\n\nOn Sep 13, 2017 5:31 PM, \"Yan Facai (\u989c\u53d1\u624d)\" <notifications@github.com> wrote:\n\n> Thank you very much, @drpngx <https://github.com/drpngx>.\n> The stack trace is really odd for me. Could you please take a retest? I'll\n> prepare a python3 environment for test later.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/12617#issuecomment-329334425>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbXmtyun9gOl1yUPJ-8Yuny1fUBOCks5siHPxgaJpZM4PDZG8>\n> .\n>\n", "Jenkins, test this please.\r\n\r\n(failing test should be fixed.)", "That doesn't seem to be related, can you check?\r\n\r\n```\r\n18:06:37  63/295 Test  #38: C:/tf_jenkins/home/workspace/tensorflow-pr-win-cmake-py/tensorflow/python/kernel_tests/batch_matmul_op_test.py ..................................***Failed   27.18 sec\r\n18:06:37 C:/tf_jenkins/home/workspace/tensorflow-pr-win-cmake-py/tensorflow/python/kernel_tests/batch_matmul_op_test.py:181: ComplexWarning: Casting complex values to real discards the imaginary part\r\n18:06:37   b * n * k).astype(dtype).reshape([b, n, k])\r\n18:06:37 C:/tf_jenkins/home/workspace/tensorflow-pr-win-cmake-py/tensorflow/python/kernel_tests/batch_matmul_op_test.py:185: ComplexWarning: Casting complex values to real discards the imaginary part\r\n18:06:37   b * k * m).astype(dtype).reshape([b, k, m])\r\n```", "@drpngx We have tested the PR for three times, however,  different test case is broken in each time:\r\n\r\n1. //tensorflow/python:queue_runner_test  ====> TimeOut\r\n2. //tensorflow/tools/api/tests:api_compatibility_test   ====> FAILED in 7.5s\r\n3. //tensorflow/python/kernel_tests:fft_ops_test   ====> Timeout\r\n\r\nIt seems totally random? I try to create a py3 environment to reproduce it.", "Yes, the `fft_ops_test` seems to be a recent timeout. The queue runner test was fixed earlier today, and same for the `api_compatibility_test`. How about the `batch_matmul_op`, does that ring a bell?", "Thanks for your help, @drpngx . I am confused why the PR will break unit tests. Do you mean all failures are brought by its own test case, not the PR, right?\r\n\r\nHow about rebasing the PR on the latest master branch? Will it resolve all failures?", "Jenkins, test this please.", "Ignoring `fft_ops_test` failure, fixed internally.", "Ignoring `fft_ops_test` which was fixed internally."]}, {"number": 12616, "title": "Update model_fn.py", "body": "Remove and replace contrib framework and function", "comments": ["@alanyee, thanks for your PR! By analyzing the history of the files in this pull request, we identified @davidsoergel, @martinwicke and @tensorflower-gardener to be potential reviewers.", "Can one of the admins verify this patch?", "@ispirmustafa any opinion here?", "@ispirmustafa ping\r\n\r\nJenkins, test this please", "@drpngx @ispirmustafa @sb2nov do these changes look good?", "@drpngx @ispirmustafa @sb2nov what is the check on \"Ubuntu CC\" mean?", "It's one of our tests, somehow it is stuck\r\n\r\nJenkins, test this please.", "Jenkins, test this please.", "@drpngx do these changes look good to you? I am not sure why the changes are failing all of the internal builds which I find is weird since the functions I replace should be equivalent.", "@gunan it might be one of these cases where some failure happened.", "Jenkins, test this please", "Could you check if that is related to the PR?\r\n\r\n```\r\nFAIL: //tensorflow/core:lib_monitoring_sampler_test (see /tmpfs/tmp/bazel/execroot/org_tensorflow/bazel-out/k8-opt/testlogs/tensorflow/core/lib_monitoring_sampler_test/test.log)\r\nINFO: From Testing //tensorflow/core:lib_monitoring_sampler_test:\r\nTraceback (most recent call last):\r\n  File \".asci-reserved/run_docker.py\", line 568, in <module>\r\n    main()\r\n  File \".asci-reserved/run_docker.py\", line 544, in main\r\n    cmd = setup_and_generate_command(sys.argv[1:])\r\n  File \".asci-reserved/run_docker.py\", line 145, in setup_and_generate_command\r\n    pull_spec_if_necessary(img_spec)\r\n  File \".asci-reserved/run_docker.py\", line 206, in pull_spec_if_necessary\r\n    if has_spec(img_spec):\r\n  File \".asci-reserved/run_docker.py\", line 234, in has_spec\r\n    return spec.digest in listing.split()\r\nAttributeError: 'NoneType' object has no attribute 'split'\r\n```", "@drpngx I think I managed to find what was wrong. The deprecated import seems to called everything from framework via `contrib_framework`, but if I replace that import with a non-deprecated version, that causes an import collision since all `framework` calls uses the non-deprecated version. To make sure, when contributing to the TF project, should I be making a broad import calls like `from tensorflow.python.framework import framework_lib` or smaller calls like `from tensorflow.python.framework import sparse_tensor`?", "Jenkins, test this please."]}, {"number": 12615, "title": "Update head.py", "body": "-Replace contrib framework with core framework\r\n-Replace contrib model_fn with core model_fn", "comments": ["Can one of the admins verify this patch?", "@alanyee, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @jhseu and @charlesnicholson to be potential reviewers."]}, {"number": 12614, "title": "Add deprecation notes", "body": "-Add or update deprecation notes to metrics_op.py and tensor_util.py\r\n-Minor comment fix in lookup_ops.py", "comments": ["@alanyee, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @jhseu and @lukaszkaiser to be potential reviewers.", "Can one of the admins verify this patch?", "@ispirmustafa what do you think?", "@ispirmustafa ping", "@sb2nov @drpngx do either of you want to run the test suite on my PR?", "Jenkins, test this please.", "Jenkins, test this please.\n\nOn Thu, Oct 12, 2017, 10:25 AM Alan Yee <notifications@github.com> wrote:\n\n> @sb2nov <https://github.com/sb2nov> @drpngx <https://github.com/drpngx>\n> do either of you want to run the test suite on my PR?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/12614#issuecomment-336206286>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbfQ-XnH1ity3scedXw9zhtyvRV78ks5srktxgaJpZM4PDYg6>\n> .\n>\n", "@drpngx could you test this again? i had to update it due to merge conflict?", "Jenkins, test this please\n\nOn Mon, Oct 23, 2017, 1:19 PM Alan Yee <notifications@github.com> wrote:\n\n> @drpngx <https://github.com/drpngx> could you test this again? i had to\n> update it due to merge conflict?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/12614#issuecomment-338782943>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbXLTRrFjFO-szG6fBMYROvoLB8eTks5svPTYgaJpZM4PDYg6>\n> .\n>\n", "@drpngx the Ubuntu CC test does not seem to have triggered?", "Can you look into the failures?", "Hmm I not sure why the tests would be failing since I am just adding deprecation notes. One test `failed to create symbolic link` and other has a docker build failing: `The command '/bin/sh -c /install/install_deb_packages.sh' returned a non-zero code: 100`", "Jenkins, test this please.", "Ignoring unrelated failure:\r\n```\r\nln: failed to create symbolic link '/workspace/tensorflow/contrib/makefile/gen/protobuf-host/protobuf': File exists\r\n```"]}]