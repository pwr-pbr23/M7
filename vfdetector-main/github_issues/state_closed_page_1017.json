[{"number": 22836, "title": "[INTEL MKL] Deleting  MKL ML only code in a few ops.", "body": "", "comments": ["Can you please run clang-format on your code. Or just fix the issues here...\r\n\r\nexec ${PAGER:-/usr/bin/less} \"$0\" || exit 1\r\nExecuting tests from //tensorflow/tools/ci_build:gen_ci_clang_format_out\r\n\r\n\r\ndiff --git a/tensorflow/core/kernels/mkl_aggregate_ops.cc b/tensorflow/core/kernels/mkl_aggregate_ops.cc\r\nindex ae1e6b6751..8eb334f2b4 100644\r\n--- a/tensorflow/core/kernels/mkl_aggregate_ops.cc\r\n+++ b/tensorflow/core/kernels/mkl_aggregate_ops.cc\r\n@@ -24,8 +24,8 @@ limitations under the License.\r\n #include \"tensorflow/core/lib/gtl/inlined_vector.h\"\r\n #include \"tensorflow/core/platform/logging.h\"\r\n-#include \"tensorflow/core/util/mkl_util.h\"\r\n #include \"mkldnn.hpp\"\r\n+#include \"tensorflow/core/util/mkl_util.h\"\r\n using mkldnn::stream;\r\n using mkldnn::sum;\r\ndiff --git a/tensorflow/core/kernels/mkl_reshape_op.cc b/tensorflow/core/kernels/mkl_reshape_op.cc\r\nindex 358233c913..342e2265ee 100644\r\n--- a/tensorflow/core/kernels/mkl_reshape_op.cc\r\n+++ b/tensorflow/core/kernels/mkl_reshape_op.cc\r\n@@ -24,8 +24,8 @@ limitations under the License.\r\n #include \"tensorflow/core/lib/core/status.h\"\r\n #include \"tensorflow/core/platform/logging.h\"\r\n-#include \"tensorflow/core/util/mkl_util.h\"\r\n #include \"mkldnn.hpp\"\r\n+#include \"tensorflow/core/util/mkl_util.h\"\r\n using mkldnn::stream;\r\n namespace tensorflow {\r\n\r\nThanks!", "@agramesh1 Hi, could you pls run clang-format and keep us posted.", "@harshini-gadige fixed clang errors thanks."]}, {"number": 22835, "title": "improve contrib/kafka/python/kernel_tests/kafka_test.sh", "body": "1. add `docker pull` step\r\n2. add some print message", "comments": ["The additional `\"` for echo messages is probably not necessary. Is that because of a different shell?", "@yongtang oh, that's because of my habit.I remove it tommorrow ", "> @yongtang oh, that's because of my habit.I remove it tommorrow\r\n\r\n@knightXun  Hello, is it updated now ?", "> > @yongtang oh, that's because of my habit.I remove it tommorrow\r\n> \r\n> @knightXun Hello, is it updated now ?\r\n\r\nupdated"]}, {"number": 22834, "title": "TensorFlow 1.11.0 fails on aarch64 platform", "body": "Building TensorFlow 1.11.0 from source fails on aarch64 platform\r\nUbuntu 16.04.5 LTS (GNU/Linux 4.4.77 aarch64)\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code**: N/A (a build problem)\r\n- **OS Platform and Distribution**: Ubuntu 16.04.5 LTS (GNU/Linux 4.4.77 aarch64)\r\n- **Mobile device**: N/A\r\n- **TensorFlow installed from**: source\r\n- **TensorFlow version**: 1.11\r\n- **Python version**: 2.7.12\r\n- **Bazel version**: 0.16.1\r\n- **GCC/Compiler version**: gcc (Ubuntu/Linaro 7.3.0-21ubuntu1~16.04) 7.3.0\r\n- **CUDA/cuDNN version**: Mobile device\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: Install dependencies and build via [CK-TensorFlow](https://github.com/ctuning/ck-tensorflow):\r\n\r\n```bash\r\n$ sudo apt install liblapack-dev libatlas-dev\r\n$ sudo pip install enum34 mock pillow wheel absl-py scipy ck\r\n$ ck pull repo:ck-tensorflow\r\n$ ck install ck-env:package:tool-bazel-0.16.1-linux\r\n$ ck install package:lib-tensorflow-1.11.0-src-cpu --env.CK_HOST_CPU_NUMBER_OF_PROCESSORS=1\r\n```\r\n**NB**: Restricting the number of building processes to 1 is necessary to prevent running out of memory on the platform with 4 GB and no swap enabled or similar.\r\n### Describe the problem\r\nBuilding TensorFlow 1.11.0 from source fails on aarch64 platform. Similar instruction for x86_64 platform works well:\r\n```\r\n$ ck install package:lib-tensorflow-1.7.0-src-cpu --env.CK_HOST_CPU_NUMBER_OF_PROCESSORS=1\r\n```\r\n\r\n### Logs:\r\n```\r\nERROR: /home/ivan/CK-TOOLS/lib-tensorflow-src-cpu-1.11.0-compiler.python-2.7.12-linux-64/src/tensorflow/BUILD:592:1: Executing genrule //tensorflow:tensorflow_python_api_gen failed (Exit 1)\r\nTraceback (most recent call last):\r\n  File \"/home/ivan/.cache/bazel/_bazel_ivan/6cdff2b5ba48d82461ef4df735b65391/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py\", line 27, in <module>\r\n    from tensorflow.python.tools.api.generator import doc_srcs\r\n  File \"/home/ivan/.cache/bazel/_bazel_ivan/6cdff2b5ba48d82461ef4df735b65391/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api.runfiles/org_tensorflow/tensorflow/python/__init__.py\", line 81, in <module>\r\n    from tensorflow.python import keras\r\n  File \"/home/ivan/.cache/bazel/_bazel_ivan/6cdff2b5ba48d82461ef4df735b65391/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api.runfiles/org_tensorflow/tensorflow/python/keras/__init__.py\", line 25, in <module>\r\n    from tensorflow.python.keras import applications\r\n  File \"/home/ivan/.cache/bazel/_bazel_ivan/6cdff2b5ba48d82461ef4df735b65391/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api.runfiles/org_tensorflow/tensorflow/python/keras/applications/__init__.py\", line 22, in <module>\r\n    import keras_applications\r\nImportError: No module named keras_applications\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 29255.108s, Critical Path: 262.73s\r\nINFO: 5693 processes: 5693 local.\r\nFAILED: Build did NOT complete successfully\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nMobile device", "Thanks. Mobile device: N/A . Issue is updated too. ", "install keras_applications and other pip wheels should help, see #21518", "It helps. After lowering  versions of keras_applications and keras_preprocessing TF was built.\r\nBut it not works without additional manual installation of python libraries: gast, astor and termcolor."]}, {"number": 22833, "title": "Internal error while saving an image to GCS (during evaluation)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian (c2-deeplearning-tf-1-11-cu100-20181001)\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: No\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.11.0\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 10.0\r\n- **GPU model and memory**: Nvidia V100 , 16GB\r\n- **Exact command to reproduce**: models/research/object_detection/legacy/eval.py\r\n\r\n### Describe the problem\r\nWhile evaluating my model using the [object detection API](https://github.com/tensorflow/models/tree/master/research/object_detection) , I am saving images with the export_dir flag. The images are saved to GCS (google cloud bucket).\r\nOnce in a while, I encounter an InternalError that I traced back to [here](https://github.com/tensorflow/tensorflow/blob/ce1cdd52eda4b40ff8fb8c09bc178210883b3773/tensorflow/core/platform/cloud/gcs_file_system.cc#L410)\r\nI am unable the reproduce it, since this happens unexpectedly, and on rare occasions, but it stops the evaluation job and requires restarting the machine.\r\n\r\nMight be related - just before this error, I recieve a RuntimeWarning about true_divide\r\n\r\n### Source code / logs\r\n`\r\nmodels/research/object_detection/utils/metrics.py:142: RuntimeWarning: invalid value encountered in true_divide\r\n  num_images_correctly_detected_per_class / num_gt_imgs_per_class)\r\nTraceback (most recent call last):\r\n  File \"object_detection/legacy/eval.py\", line 150, in <module>\r\n    tf.app.run()\r\n  File \"models/.env/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"models/.env/local/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 306, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"object_detection/legacy/eval.py\", line 146, in main\r\n    graph_hook_fn=graph_rewriter_fn)\r\n  File \"models/research/object_detection/legacy/evaluator.py\", line 276, in evaluate\r\n    losses_dict=losses_dict)\r\n  File \"models/research/object_detection/eval_util.py\", line 438, in repeated_checkpoint_run\r\n    losses_dict=losses_dict)\r\n  File \"models/research/object_detection/eval_util.py\", line 309, in _run_checkpoint_once\r\n    tensor_dict, sess, batch, counters, losses_dict=losses_dict)\r\n  File \"models/research/object_detection/legacy/evaluator.py\", line 238, in _process_batch\r\n    keep_image_id_for_visualization_export=eval_config.\r\n  File \"models/research/object_detection/eval_util.py\", line 196, in visualize_detection_results\r\n    vis_utils.save_image_array_as_png(image, export_path)\r\n  File \"models/research/object_detection/utils/visualization_utils.py\", line 76, in save_image_array_as_png\r\n    image_pil.save(fid, 'PNG')\r\n  File \"models/.env/local/lib/python2.7/site-packages/tensorflow/python/lib/io/file_io.py\", line 208, in __exit__\r\n    self.close()\r\n  File \"models/.env/local/lib/python2.7/site-packages/tensorflow/python/lib/io/file_io.py\", line 240, in close\r\n    pywrap_tensorflow.Set_TF_Status_from_Status(status, ret_status)\r\n  File \"models/.env/local/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py\", line 526, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.InternalError: Could not write to the internal temporary file.`", "comments": ["\r\nThe crash happened again during the weekend. I had 2 evaluation machines, they crashed within 5 minutes of each other (both of them were operating from the same region and writing to the same bucket).\r\n\r\n@wt-huang , do you have any suggestions?", "@Hafplo It is likely associated with the groud truth. In .config file under object_detection, see if you can capture some eval results. In the meantime, try to change `eval_config.num_examples` to the size of evalution data, also change `eval_input_reader.shuffle` to true.", "Closing this, feel free to reopen if problem persists.", "@wt-huang \r\nThank you for your response and sorry for delaying my response.\r\n\r\nI am aware of the importance of setting `num_examples` , and checked your suggestion of 'eval_input_reader.shuffle'.\r\nAccording to [this](https://github.com/tensorflow/models/issues/1856#issuecomment-315290571), it is a solution to the same issue of missing some labels since you don't evaluate over all of your dataset:\r\nLet's say you have 1000 images but only evaluates 100 of them, and assume they are ordered by labels. By shuffling the order you increase chances of getting images from the 'last' labels.\r\n\r\nSince I was evaluating all my images anyway, I don't think it will solve the problem if it persists.\r\nMy current guess is that for some reason, the model couldn't detect any objects of a specific label - this can occur even if you evaluates images with those objects, if the model simply 'misses' them (low accuracy, bad model etc.) - and this causes the error, or the error was caused by something else (perhaps OOM?).\r\n\r\nFor now, this error did not happen again - but it might - and I still don't have a solution. This causes me to invest time and effort in monitoring, which I would happily divert elsewhere, so I am eager to other suggestions.\r\n\r\nThank you. ", "@Hafplo \r\nI don't think this issue is TensorFlow related. \r\nMoreover this issue is not reproducible hence it is difficult for us to diagnose and provide solutions. Root cause analysis can point to numerous possibilities.\r\nI would suggest to capture some evaluation results and go from there. "]}, {"number": 22832, "title": "Can GANEstimator execute a forward pass in the discriminator after training?", "body": "Hi, \r\n\r\nI am looking at GANEstimator and am trying to pass a new data point `X` to `discriminator_fn`. I have a class `GAN` that has an attribute `self.model = tfgan.estimator.GANEstimator(...)`. Is there a way to do this? It looks like for now, there is a session problem (in order to have something like `sess.run([self.discriminator_fn(X)])`).\r\n\r\nThanks", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Hi,\r\nYes, I have custom code, TensorFlow 1.11 from Anaconda, GPU: Tesla V100.", "@alain-sam It is much easier to use TFGAN than GANEstimator\u00a0as the latter is canned estimator. You can write your own model_fn and feed new data. Please refer to [TFGAN](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/gan) for details.\r\n", "Closing this, feel free to reopen if running into any errors."]}, {"number": 22831, "title": "conv.cc:260 real_multiplier < 1.0 was not true.Node 0 failed to prepare.", "body": "### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 14.0.4\r\n- **Mobile device if the issue happens on mobile device**: MI 3s Prime\r\n- **TensorFlow installed from (source or binary)**: pip install\r\n- **TensorFlow version (use command below)**: 1.9.0\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: 0.16\r\n- **CUDA/cuDNN version**: 8\r\n- **GPU**: Nvidia GeForce GTX 1080 Ti\r\n- **Exact command to reproduce**:\r\nbazel-bin/tensorflow/contrib/lite/toco/toco --input_file=tflite_graph.pb --output_file=detect.tflite --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --inference_type=QUANTIZED_UINT8  --mean_values=128 --std_dev_values=128 --allow_custom_ops\r\n\r\n\r\n\r\n### Problem\r\nApp gets crashed while loading model with following error.\r\n\r\n### logs\r\nCaused by: java.lang.NullPointerException: Internal error: Cannot allocate memory for the interpreter: tensorflow/contrib/lite/kernels/conv.cc:260 real_multiplier < 1.0 was not true.Node 0 failed to prepare.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nCUDA/cuDNN version\nGPU model and memory", "Updated", "@Heetmadhu : Can you attach the model that you are trying to convert."]}, {"number": 22830, "title": "can tensorflow tensorRT be used for  optimization of object detection model", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["I am using the tensorRT for model optimization. i am confused how to use tensorRT for models with multiple ouput.", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 22829, "title": "can tensorflow tensorRT (with multiple outputs) be used for object dectection? can ", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["Duplicate of #22830 "]}, {"number": 22828, "title": "aws: tensorflow_model_server: /lib64/libm.so.6: version `GLIBC_2.23' not found", "body": "Hi team, \r\n\r\nI am trying to build tensorflow_model_server from source, I follow https://www.tensorflow.org/serving/setup and finish the building step. \r\n\r\nBut when I run it, I get the error message:\r\n\r\n```\r\nbazel-bin/tensorflow_serving/model_servers/tensorflow_model_server\r\n\r\nbazel-bin/tensorflow_serving/model_servers/tensorflow_model_server: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server)\r\n```\r\n\r\nThe platform is Amazon Linux 14, \r\ngcc (GCC) 7.2.1 20170915 (Red Hat 7.2.1-2)\r\ng++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-28)\r\n\r\n\r\nI am trying to build glibc 2.23 to get libm.so, but can not configure\r\n\r\n```\r\nloading cache ./config.cache\r\nchecking host system type... x86_64-unknown-linux-gnu\r\nchecking sysdep dirs... configure: error: The x86_64 is not supported.\r\n```\r\n\r\nAny idea? Thanks!", "comments": ["self addressed:\r\n\r\nThere are two versions of libm.so.6 in my aws ec2 instance. Since ec2 is a virtual machine, so the binary is built within the virtual environment using glibc 2.23 version and when running outside the virtual environment, it can not find that version. \r\n\r\nWhat i do is to find that version:\r\n\r\n```\r\nsudo find / -name \"libm.so.6\"\r\n\r\n/var/lib/docker/overlay2/422e54cc5ac5921a6d8f8db67f40162ea497cdcd0e6ebd22bd86ec39e55b8397/diff/lib/x86_64-linux-gnu/libm.so.6\r\n/var/lib/docker/overlay2/fe4ce1d185e5ea59f770f70daf2d13bdbc78d26f5e48e541c3338dcea4ae835a/diff/lib/x86_64-linux-gnu/libm.so.6\r\n/lib64/libm.so.6\r\n/home/ec2-user/anaconda3/pkgs/gcc_impl_linux-64-7.3.0-habb00fd_1/x86_64-conda_cos6-linux-gnu/sysroot/lib/libm.so.6\r\n/home/ec2-user/anaconda3/pkgs/gcc_impl_linux-64-7.2.0-habb00fd_3/x86_64-conda_cos6-linux-gnu/sysroot/lib/libm.so.6\r\n/home/ec2-user/anaconda3/envs/tensorflow_p36/x86_64-conda_cos6-linux-gnu/sysroot/lib/libm.so.6\r\n/home/ec2-user/anaconda3/envs/theano_p36/x86_64-conda_cos6-linux-gnu/sysroot/lib/libm.so.6\r\n/home/ec2-user/anaconda3/envs/theano_p27/x86_64-conda_cos6-linux-gnu/sysroot/lib/libm.so.6\r\n/home/ec2-user/anaconda3/envs/tensorflow_p27/x86_64-conda_cos6-linux-gnu/sysroot/lib/libm.so.6\r\n```\r\n\r\nthen check version for each libm:\r\n\r\n```\r\nstrings /var/lib/docker/overlay2/422e54cc5ac5921a6d8f8db67f40162ea497cdcd0e6ebd22bd86ec39e55b8397/diff/lib/x86_64-linux-gnu/libm.so.6  | grep GLIBC_\r\n\r\nGLIBC_2.2.5\r\nGLIBC_2.4\r\nGLIBC_2.15\r\nGLIBC_2.18\r\nGLIBC_2.23\r\nGLIBC_PRIVATE\r\n```\r\n\r\nthis is the version i need, and then add it to an existing ld_library_path:\r\n\r\n```\r\nsudo cp /var/lib/docker/overlay2/422e54cc5ac5921a6d8f8db67f40162ea497cdcd0e6ebd22bd86ec39e55b8397/diff/lib/x86_64-linux-gnu/libm.so.6 /lib/\r\n```\r\n\r\nThen tensorflow_server works\r\n", "In my case for swift for tensorflow, GLIBC_2.27 is needed. I've checked every single libm.so.6 file but none of seem to have GLIBC_2.27. What can be done in this case?", "+1 on the above issue - I can't find GLIBC_2.27", "Any updates?", "I have the same issue. Would you please share your solution/update if any? Thanks!\r\n\r\nMy system infor\r\nubuntu16.04\r\ntf1.9\r\nrk3399 board\r\n\r\n```\r\n\r\n./label_image: /lib/aarch64-linux-gnu/libm.so.6: version `GLIBC_2.27' not found (required by ./label_image)\r\n(tf1.13) root@firefly:/usb/tf/rk_tf1.9_label_image# strings /usr/lib/aarch64-linux-gnu/libstdc++.so.6 | grep GLIBC\r\nGLIBCXX_3.4\r\nGLIBCXX_3.4.1\r\nGLIBCXX_3.4.2\r\nGLIBCXX_3.4.3\r\nGLIBCXX_3.4.4\r\nGLIBCXX_3.4.5\r\nGLIBCXX_3.4.6\r\nGLIBCXX_3.4.7\r\nGLIBCXX_3.4.8\r\nGLIBCXX_3.4.9\r\nGLIBCXX_3.4.10\r\nGLIBCXX_3.4.11\r\nGLIBCXX_3.4.12\r\nGLIBCXX_3.4.13\r\nGLIBCXX_3.4.14\r\nGLIBCXX_3.4.15\r\nGLIBCXX_3.4.16\r\nGLIBCXX_3.4.17\r\nGLIBCXX_3.4.18\r\nGLIBCXX_3.4.19\r\nGLIBCXX_3.4.20\r\nGLIBCXX_3.4.21\r\nGLIBCXX_3.4.22\r\nGLIBCXX_3.4.23\r\nGLIBCXX_3.4.24\r\nGLIBCXX_3.4.25\r\nGLIBCXX_3.4.26\r\nGLIBC_2.17\r\nGLIBC_2.18\r\nGLIBCXX_DEBUG_MESSAGE_LENGTH\r\n```\r\nRelated solutions\r\nhttps://mikechan0731.gitbook.io/workspace/self_driving_lidar/xavier-environment-installation\r\nhttps://zhuanlan.zhihu.com/p/33059558\r\nhttp://www.linuxfromscratch.org/lfs/view/development/chapter05/glibc.html"]}, {"number": 22827, "title": "tensorflow c++ api session->Run segv for batch size>1", "body": "Hi,\r\n\r\n  i build tensorflow 1.4.0 to .so and call c++ session api Run to predict, when the input batch size is 1, the  Run api works well, but  batch_size    > 1, the Run will segv as follows:\r\n\r\n\r\n#12 0x00002b12e0122c72 in tensorflow::LaunchMatMulBase<Eigen::ThreadPoolDevice, float>::launch(tensorflow::OpKernelContext*, tensorflow::Tensor const&, tensorflow::Tensor const&, Eigen::array<Eigen::IndexPair<long>, 1ul> const&, std::vector<long long, std::allocator<long long> >*, bool, tensorflow::Tensor*) () from lib/64bit/libtensorflow_cc.so                                                                                                                                 \r\n#13 0x00002b12e0123231 in tensorflow::MatMulOp<Eigen::ThreadPoolDevice, float, false>::Compute(tensorflow::OpKernelContext*) () from lib/64bit/libtensorflow_cc.so                                                                                                                                           \r\n#14 0x00002b12e20e6a4c in tensorflow::ThreadPoolDevice::Compute(tensorflow::OpKernel*, tensorflow::OpKernelContext*) () from lib/64bit/libtensorflow_framework.so                                                                                                                                            \r\n#15 0x00002b12e20b7669 in tensorflow::(anonymous namespace)::ExecutorState::Process(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long) () from lib/64bit/libtensorflow_framework.so                                                                                                    \r\n#16 0x00002b12e20a6290 in std::_Function_handler<void ()(), std::_Bind<std::_Mem_fn<void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long)> ()(tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long)> >::_M_invoke(std::_Any_data const&) () from lib/64bit/libtensorflow_framework.so                                                  \r\n#17 0x00002b12e1d576b7 in Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) () from lib/64bit/libtensorflow_framework.so                                                                                                                                              \r\n#18 0x00002b12e1d565a2 in std::_Function_handler<void ()(), tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&) () from lib/64bit/libtensorflow_framework.so                                                                       \r\n#19 0x00002b12e7726f50 in execute_native_thread_routine_compat () from /icd/dlsh_t2b/luther/tf.integ2.dev/tools.lnx86/lib/64bit/libstdc++.so.6                                \r\n#20 0x0000000004385269 in create_head(void*) ()                                                                                                                               \r\n#21 0x00002b12e71309d1 in start_thread () from /lib64/libpthread.so.0        \r\n    \r\n*** Stack trace in log file.\r\nfree model\r\nterminate called after throwing an instance of 'std::system_error'\r\n  what():  Resource deadlock avoided\r\n\r\n\r\n\r\nthe predict code :\r\n   std::vector<tensorflow::Tensor> outputs;\r\n    tensorflow::Status run_status = session_->Run({input},{model_outputs_name_}, {}, &outputs);\r\n\r\nAfter i upgrade tensorflow to 1.8.0, crash too, please help to review this issue.\r\n\r\nchao\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Can you please test it against the latest version of TensorFlow and post your findings?\r\nThanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 22826, "title": "Win10 C++ TF1.9, error LNK2001, build by bazel  !", "body": "I have generated the TensorFlowV1.9's .so and .lib file successfully on Win10,  but when I use this in VS2017, it has errors as bellow :\r\n\r\nMFCTestTF1.9.obj : error LNK2001: \u65e0\u6cd5\u89e3\u6790\u7684\u5916\u90e8\u7b26\u53f7 \"char const * __cdecl tensorflow::core::GetVarint32PtrFallback(char const *,char const *,unsigned int *)\" (?GetVarint32PtrFallback@core@tensorflow@@YAPBDPBD0PAI@Z)\r\n1>D:\\ProgramData\\VS2017 Project\\MFCTestTF1.9\\Release\\MFCTestTF1.9.exe : fatal error LNK1120: 1 \u4e2a\u65e0\u6cd5\u89e3\u6790\u7684\u5916\u90e8\u547d\u4ee4\r\n1>\u5df2\u5b8c\u6210\u751f\u6210\u9879\u76ee\u201cMFCTestTF1.9.vcxproj\u201d\u7684\u64cd\u4f5c - \u5931\u8d25\u3002\r\n\r\n\r\nAnd I also build TensorFlowV1.8 with CMAKE, it work OK without LNK error.  But V1.9 can not build by CMAKE.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@EdwardVincentMa Try to use VS2015 as shown in the [installation document](https://www.tensorflow.org/install/source_windows). Please let us know if you run into any errors. You should be able to install TensorFlow 1.10 with Cmake.", "Closing this now, feel free to reopen if problem persists.", "@EdwardVincentMa How did you fix this link error?"]}, {"number": 22824, "title": "Sampled softmax in tf keras", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nno\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nUbuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\nno\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n- **TensorFlow version (use command below)**:\r\n1.11\r\n- **Python version**:\r\n3.5.3\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI want to do sampled softmax loss in tf keras.  I defined my own model by subclassing keras Model.  In __init__, I specify the layers I need including the last Dense projection layer.  But this Dense layer shouldn't be called in training as I want to do sampled softmax and only to use it's weights and biases.  Then I define the loss function like this:\r\n\r\n    class SampledSoftmax(Layer):\r\n        def __init__(self,\r\n                           num_sampled,\r\n                           num_classes,\r\n                           projection,\r\n                           bias,\r\n                           hidden_size):\r\n            self.weights = tf.transpose(projection)\r\n            self.bias = bias\r\n            self.num_classes = num_classes\r\n            self.num_sampled = num_sampled\r\n            self.hidden_size = hidden_size\r\n\r\n        def __call__(self, y_true, input):\r\n            \"\"\" reshaping of y_true and input to make them fit each other \"\"\"\r\n            input = tf.reshape(input, (-1,self.hidden_size))\r\n            y_true = tf.reshape(y_true, (-1,1))\r\n\r\n            return tf.nn.sampled_softmax_loss(\r\n                weights=self.weights,\r\n                biases=self.bias,\r\n                labels=y_true,\r\n                inputs=input,\r\n                num_sampled=self.num_sampled,\r\n                num_classes=self.num_classes,\r\n                partition_strategy='div')\r\n\r\nIt takes in the necessary parameters to initialize and the class call will be the needed sampled softmax loss function.  The catch is that to add loss to model compile I need the weights etc of the last Dense.  But 1) in training Dense is not included in the model, and 2) even if it does, the Dense layer would only be hooked up with input and thus get its input dimensions etc in __call__ of my custom model.  In short, the weights etc won't be available before compiling model.  Can anyone offer some help to point me to the right direction? \r\n\r\nBTW, the loss defined above would work in small test cases like the following.\r\n\r\n    x = Input(shape=(10,), name='input_x')\r\n    emb_out = Embedding(10000,200,input_length=10)(x)\r\n    lstm_out = LSTM(200, return_sequences=True)(emb_out)\r\n\r\n    dense = Dense(10000, activation='sigmoid')\r\n    output = dense(lstm_out)\r\n\r\n    sl = SampledSoftmax(10, 10000, dense.kernel, dense.bias)\r\n\r\n    model = Model(inputs=x, outputs=lstm_out)\r\n    model.compile(optimizer='adam', loss=sl)\r\n    model.summary()\r\n    model.fit(dataset, epochs=20, steps_per_epoch=5)", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n", "I think it is a feature request.  Being able to do sampled softmax loss should be a standard feature.  When someone makes a custom model and wants to train with sampling, the loss function should share the weights with the last dense layer.  But for now there's no easy way to do it because by the time of compiling the model with the loss function, the loss function can't be defined as all the layers haven't been hooked up into a model (only happens in model call) and thus dense won't have its dimensions ready to initialize the weights.  This conflict should really be addressed  ", "To provide an example that caused it to fail. I first subclassed model as follows:\r\n\r\n    class LanguageModel(tf.keras.Model):\r\n        def __init__(self, \r\n                 vocal_size=15003, \r\n                 embedding_size=512\r\n                 input_len=64)\r\n            self.embedding = Embedding(vocal_size, embedding_size, \r\n                                  input_length=input_len)\r\n            self.lstm = LSTM(hidden_size, return_sequences=True)\r\n            self.dense = Dense(vocal_size, activation='softmax')\r\n\r\n        def call(self, inputs, training=False):\r\n            emb_out = self.embedding(inputs)\r\n            lstm_out = self.lstm(embrace_out)\r\n            res = self.dense(lstm_out)\r\n            if (training)\r\n                ''' shouldn't use the last dense as we want to do sampling'''\r\n                return lstm_out\r\n            return res\r\n\r\nThen the part to train the model as below\r\n\r\n    sampled_loss = SampledSoftmax(num_sampled, vocal_size, \r\n                   model.dense.kernel, model.dense.bias,\r\n                   hidden_size)\r\n\r\n    model.compile(optimizer=tf.train.RMSPropOptimizer(lr),\r\n                  loss=sampled_loss)\r\n\r\nIt would fail however I play around with it, because model.dense.kernel is not accessible as by the time of compiling the model, dense layer has not been initialized in call method. Error message as below:\r\n\r\n    Traceback (most recent call last):\r\n      File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\r\n        \"__main__\", mod_spec)\r\n      File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\r\n        exec(code, run_globals)\r\n      File \"/home/wuxinyu/workspace/nlu/lm/main.py\", line 72, in <module>\r\n        train_main()\r\n      File \"/home/wuxinyu/workspace/nlu/lm/main.py\", line 64, in train_main\r\n        train_model.build_lm_model()\r\n      File \"/home/wuxinyu/workspace/nlu/lm/main.py\", line 26, in build_lm_model\r\n    self.model.dense.kernel,\r\n    AttributeError: 'Dense' object has no attribute 'kernel'\r\n\r\n\r\n", "@xinyu-Naturali Dense layer can be included in the model during training. \r\nYour first approach appears to be better than the second one, yet the code snippet pasted looks incomplete.\r\nMay want to check your SampledSoftmax signature, doesn't quite match. \r\n", "Closing, feel free to reopen if problem persists."]}, {"number": 22823, "title": "Error in importing tensorflow", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 Home\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: pip install tf-nightly-gpu\r\n- **TensorFlow version (use command below)**: Can't see (error while importing)\r\n- **Python version**: 3.6.0\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: Cuda 9.1; cuDNN 7.2.1\r\n- **GPU model and memory**: GTX 1060 6Gb\r\n- **Exact command to reproduce**: import tensorflow as tf\r\n\r\n### Describe the problem\r\nError while importing tensorflow.\r\nI have successfully installed via pip, but while I'm trying to import I get the log listed error.\r\nUnfortunately, the error dosen't describe which DLL is missing, and all tickets I've seen doesn't solved my problem.\r\n\r\n### Source code / logs\r\n\r\nPython 3.6.0 (v3.6.0:41df79263a11, Dec 23 2016, 08:06:12) [MSC v.1900 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"D:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"D:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"D:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"D:\\Program Files\\Python36\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"D:\\Program Files\\Python36\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"D:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"D:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"D:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"D:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"D:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"D:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"D:\\Program Files\\Python36\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"D:\\Program Files\\Python36\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version\nMobile device", "Updated as requested.", "I suspect you are using incorrect cuDNN version for Windows compatibility. Can you please try with [cuDNN  7.1.4](https://anaconda.org/anaconda/cudnn/7.1.4/download/win-64/cudnn-7.1.4-cuda9.0_0.tar.bz2). \r\nAlso please take a look at similar issue #22794", "I still got the same error.\r\n\r\nBut, reading the test bat it raised me one question, am I missing any env path?\r\nI have created the LIBRARY_INC, LIBRARY_LIB and LIBRARY_BIN paths, but I still got the same error.\r\n\r\nIs there any list about the environment variables I should have?\r\n\r\nThanks.\r\n", "There are two potential issues.\r\nFirst, we need to check your CPU model, does your CPU support AVX instruction sets?\r\nNext, MSVC 2015 redistributable update 3. It is listed here under windows:\r\nhttps://www.tensorflow.org/install/pip", "My current CPU supports AVX (I7 7700HQ), and tensorflow on CPU installs and runs fine.\r\nMSVC 2015 is also installed and working (since I've compiled dlib with GPU support).\r\n\r\nBy reading https://www.tensorflow.org/install/gpu, the \"Windows Setup\" part defined the path as v9.0, but mine is v9.1.\r\nIs the tensorflow expecting the v9.0?\r\nMy path var is setted to v9.1.\r\n\r\nThanks.", "Yes, tensorflow prebuilt libraries require CUDA 9.0 to run.\r\n", "It worked!\r\n**After installing the CUDA 9.0 (instead of 9.1) I was able to successfully import and print the current version of tensorflow-gpu.**\r\n\r\nI guess I'll have no more trouble in using tensorflow.\r\n\r\nThanks for all support and help,\r\nCarlos.", "![image](https://user-images.githubusercontent.com/22957479/53956677-4a12d900-4102-11e9-8c0a-b062efa3d363.png)\r\n\r\n\r\nI cannot import tensorflow. ", "Hi, please help me, I am getting this - same as person above. I think I did whole instalation properly, I tried it for 3 times but it always result in same error. I am using Python 3.7.2, anaconda, tensorflow-gpu 1.13.1, CUDA 10.1, cuDNN 7.5.", "Use cuda version 9 and cudnn 6.4.7\n\nOn Fri, Mar 22, 2019, 5:10 AM RostyxCZ <notifications@github.com> wrote:\n\n> Hi, please help me, I am getting this - same as person above. I think I\n> did whole instalation properly, I tried it for 3 times but it always result\n> in same error. I am using Python 3.7.2, anaconda, tensorflow-gpu 1.13.1,\n> CUDA 10.1, cuDNN 7.5.\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/22823#issuecomment-475442753>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AV5Np4Y64yC7e3xb54qrmwte76o-h7-Rks5vZBhcgaJpZM4XPLjC>\n> .\n>\n", "If required downgrade your python to 3.6 and tensorflow-gpu to 1.12 or\nlesser.\n\nOn Fri, Mar 22, 2019, 8:07 AM Gargi Srivastava <gargisri68@gmail.com> wrote:\n\n> Use cuda version 9 and cudnn 6.4.7\n>\n> On Fri, Mar 22, 2019, 5:10 AM RostyxCZ <notifications@github.com> wrote:\n>\n>> Hi, please help me, I am getting this - same as person above. I think I\n>> did whole instalation properly, I tried it for 3 times but it always result\n>> in same error. I am using Python 3.7.2, anaconda, tensorflow-gpu 1.13.1,\n>> CUDA 10.1, cuDNN 7.5.\n>>\n>> \u2014\n>> You are receiving this because you commented.\n>> Reply to this email directly, view it on GitHub\n>> <https://github.com/tensorflow/tensorflow/issues/22823#issuecomment-475442753>,\n>> or mute the thread\n>> <https://github.com/notifications/unsubscribe-auth/AV5Np4Y64yC7e3xb54qrmwte76o-h7-Rks5vZBhcgaJpZM4XPLjC>\n>> .\n>>\n>\n", "[SOLVED] Okay, so my problem is solved. Actually successfuly running on :\r\n CUDA 9.0, cuDNN 7.3.1,  python 3.6.0 (Anaconda), tensorflow 1.12 with my GPU Nvidia GTX 1050 Ti.\r\n\r\nThanks alot for your help and this tread in general \ud83d\udcaf ", "anybody can help me \r\nim running on: PyCharm 2019 1.3, Anaconda3 2019.03, Tensorflow 1.14.0 GPU Nvidia GTX 950 CUDA 10.0 cuDNN 7.1.4\r\n\r\nC:\\Users\\bonix\\Anaconda3\\envs\\tensor\\pythonw.exe C:/Users/bonix/PycharmProjects/TensorPye/testing.py\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\bonix\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\bonix\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\bonix\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\bonix\\Anaconda3\\envs\\tensor\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\bonix\\Anaconda3\\envs\\tensor\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:/Users/bonix/PycharmProjects/TensorPye/testing.py\", line 1, in <module>\r\n    import tensorflow\r\n  File \"C:\\Users\\bonix\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\__init__.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\bonix\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\bonix\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\bonix\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\bonix\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\bonix\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\bonix\\Anaconda3\\envs\\tensor\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\bonix\\Anaconda3\\envs\\tensor\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nProcess finished with exit code 1\r\n", "@Bocul16 try using CUDA 9.0"]}, {"number": 22822, "title": "[INTEL MKL] Fix bug in MklSlice op when allocating output tensor.", "body": "Wrongly \"+1\" for output shape, that will cause CopyFrom failure in MklToTf op because of tensor size and shape mismatch.", "comments": ["@penpornk Thanks to approve the fix! I see some CI build failed, but i can's see the detailed, can you tell me how to access the failure log? Thanks!", "@yiqianglee I reran the checks and they all passed now. :) Hopefully this will be imported sometime tomorrow.", "@penpornk Thanks for your help!"]}, {"number": 22821, "title": "tfrecords-only size-1 arrays can be converted to Python scalars error", "body": "\r\n![tfrecords_error](https://user-images.githubusercontent.com/26739210/46628024-f358a180-cb59-11e8-82e0-37f7eb7e8289.png)\r\n\r\n\r\n", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "### System information\r\n- I have not written any custom code\r\n- OS Platform and Distribution :Debian GNU/Linux 9.5(GCP instance)\r\n- Tensorflow installed using pip\r\n- TensorFlow version:1.10.1\r\n- Python version: 2.7.13\r\n- CUDA Version: 9.2.148\r\n- GPU model and memory: none\r\n- Exact command to reproduce:\r\nDataset- DeepFashion-https://drive.google.com/drive/folders/0B7EVK8r0v71pWGplNFhjc01NbzQ\r\nval_attr.npy file - https://drive.google.com/open?id=16Mya14JIojI8qOUnDtiR2etpKggkh7nn\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nval_attr=np.load('/home/balajib26/new_exp/DeepFashion-Tensorflow/val_attr.npy')\r\n\r\ndef _int64_feature(value):\r\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\r\n\r\ndef _bytes_feature(value):\r\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\r\n\r\nfeature = { 'val_attr': _int64_feature(val_attr)}\r\n\r\nerror:\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-27-d64c9fcc250b> in <module>()\r\n----> 1 feature = { 'val_attr': _int64_feature(val_attr)}\r\n\r\n<ipython-input-19-c554b2e04247> in _int64_feature(value)\r\n      1 def _int64_feature(value):\r\n----> 2     return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\r\n      3 \r\n      4 # _bytes is used for string/char values\r\n      5 \r\n\r\nTypeError: only size-1 arrays can be converted to Python scalars\r\n\r\n", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 22820, "title": "1.12-rc0 cherry-pick request: Reduce tolerances for rmsprop_test float16, to fix OSS builds.", "body": "PiperOrigin-RevId: 216200439", "comments": []}, {"number": 22819, "title": "Unable to disable build of AWS, HDFS, Kafka and GCP", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: any\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: any\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: master\r\n- **Python version**: N/A\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: ./configure\r\n\r\n### Describe the problem\r\nWhen building TensorFlow as a library (and in our case using `--config=monolithic`), we used to remove as much as possible of the not used features. Recently, this was removed from master in https://github.com/tensorflow/tensorflow/commit/d56c298f1ef14b5a738e1e0b7bbc66fcd736be3e for AWS, HDFS, Kafka and GCP.\r\n\r\nI understand that that having to deal with multiple optionnally-disabled features can be a huge burden for the future, but is it possible to have some way around ?", "comments": ["Discussed offline.\r\nI will need to reintroduce a way to disable building these into our build system.\r\nI am thinking having these default on, but having `--config` options such as `noaws`, `nogcp`, `nohdfs` and `nokafka`\r\nWhat do you think?", "I think that any solution that is okay for you in term of complexity and allows us to disable should be good :)", "Thanks for that!", "@gunan Hello, I'm testing that on current master, my build command line does include `--config=noaws --config=nogcp --config=nohdfs --config=nokafka --config=noignite` and yet, checking out the `bazel-out/` subdirectories, I find `.o` and `.d` files that have been rebuilt, under `aws-cpp-sdk-core`, `aws-cpp-sdk-kinesis` and `aws-cpp-sdk-s3`, am I missing something ?"]}, {"number": 22818, "title": "Is Latest Tensorflow not compatible with latest cuda release  i.e CUDA 10??", "body": "Hi Team,\r\nI have new  RTX 2080 Graphics card with cuda 10.0 and cudnn 7.3.1. But tensor flow-gpu doesn't works. Can you please tell whether  tensor flow is compatible with it or not. Because as per tensorflow.org installation it is only compatible with cuda 9. I there any way out for this??\r\nOr you guys are planning to release tensorflow with cuda 10 compatibility.??\r\n\r\n**Have I written custom code : NO\r\n- **OS : Ubuntu 18.04\r\n- **TensorFlow installed from (source or binary)**: Using pip\r\n- **TensorFlow version (use command below)**: TensorFlow 1.11\r\n- **Python version**: 3.6\r\n- **CUDA/cuDNN version**: CUDA 10.0/ cuDNN 7.3\r\n- **GPU model and memory**: RTX 2080/ 8GB\r\n- **Exact command to reproduce**: import tensorflow", "comments": ["I managed to build and use Tensorflow 1.11 with cuda 10 and cudnn 7.2", "Hi @jrabary,\r\n\r\nPlease guide me through the same. I am not able to use it", "TensorFlow officially supports CUDA 9.0. However it is compatible with CUDA 10.0 but not supported currently. For using TF with cuda 10, you have to build it from sources yourself. You can also take a look at [installations](https://medium.com/@vitali.usau/install-cuda-10-0-cudnn-7-3-and-build-tensorflow-gpu-from-source-on-ubuntu-18-04-3daf720b83fe) done by another users to make it work.", "See also #22664 if you're having problems compiling Tensorflow 1.11.0 with CUDA 10.0", "Hi @ymodak ,\r\n\r\nThankyou so much. It worked.", "Happy to help :-)", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)"]}, {"number": 22817, "title": "pull latest code", "body": "pull code", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->"]}, {"number": 22816, "title": "The usage of CUDA_VISIBLE_DEVICES.", "body": "I cannot figure out an ambigious definition of the env variable \"CUDA_VISIBLE_DEVICES\". As we know, the command `export CUDA_VISIBLE_DEVICES = 0`  means that we can only find the GPU:0. However, what's the defination of the command `export CUDA_VISIBLE_DEVICES = '' `? It means that we can either find all gpus or mask all gpus in our system?\r\n\r\nAnd another odd thing is that I am running a BiLSTM-CRF model to do some NER tasks with a 8-gpu server. Without using the command `export CUDA_VISIBLE_DEVICES = '' `, the model runs a bit slower than expected, and we can see the program running with all 8 gpus through the command `nvidia-smi`. However, the model runs extremely faster than before when I use the command `export CUDA_VISIBLE_DEVICES = '' `, in addition, I cannot find any program information with `nvidia-smi`. \r\n\r\nDid I run the model with CPU? But the CPU usage changed only a little. And there seems no posibility that the CPU runs extremely faster than GPU under BiLSTM-CRF model. What's the matter?  If any information is needed, I'll update later cuz I don't know what information to display now.", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 22814, "title": "PYTHON_LIB_PATH not set during compilation of tensorflow_python_api_gen from source", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: RHEL 7.5\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: NO\r\n- **TensorFlow installed from (source or binary)**: YES\r\n- **TensorFlow version (use command below)**: 1.11\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**:1.17.2\r\n- **GCC/Compiler version (if compiling from source)**: gcc version 6.4.1 20170720 (Advance-Toolchain-at10.0) IBM AT 10 branch, based on subversion id 250395. (GCC)\r\n- **CUDA/cuDNN version**: CUDA 9.2, CUDNN 7.2.1\r\n- **GPU model and memory**: V100\r\n- **Exact command to reproduce**: Installation of Tensorflow - see below\r\n\r\n### Describe the problem\r\nDuring installation from source, env variables are not loaded for the  compilation of:\r\n\r\n```//tensorflow:tensorflow_python_api_gen```\r\n\r\nThese are the variables that are missing:\r\n\r\n```\r\n    CUDA_TOOLKIT_PATH=/usr/local/cuda-9.2 \\\r\n    CUDNN_INSTALL_PATH=/usr/local/cudnn-9.2-v7.2.1 \\\r\n    GCC_HOST_COMPILER_PATH=/opt/at10.0/bin/gcc \\\r\n    NCCL_INSTALL_PATH=/usr/local/nccl-9.2-v2.2.13 \\\r\n    OMP_NUM_THREADS=1 \\\r\n    PATH=/hpc_modules/at10.0-based/deeplearning/tensorflow/tensorflow-v1.11.0_openmpi-3.1.2/bin:/hpc_modules/os-based/deeplearning/tensorflow/bazel-0.17.2/bin:/hpc_modules/at10.0-based/python-packages-3.5-mpi4py-3.0.0_openmpi-3.1.2/bin:/hpc_modules/at10.0-based/mpi/openmpi-3.1.2/bin:/hpc_modules/at10.0-based/python-packages-3.5/bin:/opt/at10.0/bin:/usr/local/cuda-9.2/nvvm/bin:/usr/local/cuda-9.2/bin:/usr/lib/jvm/java-openjdk/bin:/shared/lsf/10.1/linux3.10-glibc2.17-ppc64le/etc:/shared/lsf/10.1/linux3.10-glibc2.17-ppc64le/bin:/u/acm/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/afs/zurich.ibm.com/usr/bin \\\r\n    PYTHONPATH=/hpc_modules/at10.0-based/deeplearning/tensorflow/tensorflow-v1.11.0_openmpi-3.1.2/lib64/python3.5/site-packages:/hpc_modules/at10.0-based/python-packages-3.5-mpi4py-3.0.0_openmpi-3.1.2/lib64/python3.5/site-packages:/hpc_modules/at10.0-based/python-packages-3.5-mpi4py-3.0.0_openmpi-3.1.2/lib/python3.5/site-packages:/hpc_modules/at10.0-based/python-packages-3.5/lib64/python3.5/site-packages:/hpc_modules/at10.0-based/python-packages-3.5/lib/python3.5/site-packages:/hpc_modules/at10.0-based/python-packages-3.5/lib64/python3.5/site-packages \\\r\n    PYTHON_BIN_PATH=/opt/at10.0/bin/python3.5 \\\r\n    PYTHON_LIB_PATH=/opt/at10.0/lib64/python3.5/site-packages \\\r\n    TF_CUDA_CLANG=0 \\\r\n    TF_CUDA_COMPUTE_CAPABILITIES=7.0 \\\r\n    TF_CUDA_VERSION=9.2 \\\r\n    TF_CUDNN_VERSION=7 \\\r\n    TF_NCCL_VERSION=2 \\\r\n    TF_NEED_CUDA=1 \\\r\n    TF_NEED_OPENCL_SYCL=0 \\\r\n```\r\n\r\nIn my case, the lack of `PYTHON_LIB_PATH` caused the issue with numpy. A manual execution of the command with those env variable set solve the problem - however I cannot continue installation.\r\n\r\n### Source code / logs\r\n```\r\nSUBCOMMAND: # //tensorflow:tensorflow_python_api_gen [action 'Executing genrule //tensorflow:tensorflow_python_api_gen']\r\n(cd /ibm/gpfs-dataP/hpc_modules/rhel7-P9-2018-09-14/at10.0-based/deeplearning/tensorflow/tensorflow-v1.11.0_openmpi-3.1.2/bazel_tmp/_bazel_acm/89da28a486992b186bd01e39111a422f/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    CUDA_TOOLKIT_PATH=/usr/local/cuda-9.2 \\\r\n    CUDNN_INSTALL_PATH=/usr/local/cudnn-9.2-v7.2.1 \\\r\n    GCC_HOST_COMPILER_PATH=/opt/at10.0/bin/gcc \\\r\n    LD_LIBRARY_PATH=/usr/local/nccl-9.2-v2.2.13/lib:/opt/ibm/xlmass/9.1.0/lib:/usr/lib64/libibverbs:/hpc_modules/at10.0-based/mpi/openmpi-3.1.2/lib:/opt/at10.0/lib:/usr/local/cudnn-9.2-v7.2.1/lib64:/usr/local/cuda-9.2/extras/CUPTI/lib64:/usr/local/cuda-9.2/nvvm/lib64:/usr/lib64/nvidia:/usr/local/cuda-9.2/lib64:/usr/lib64/jna:/shared/lsf/10.1/linux3.10-glibc2.17-ppc64le/lib \\\r\n    NCCL_INSTALL_PATH=/usr/local/nccl-9.2-v2.2.13 \\\r\n    OMP_NUM_THREADS=1 \\\r\n    PATH=/hpc_modules/at10.0-based/deeplearning/tensorflow/tensorflow-v1.11.0_openmpi-3.1.2/bin:/hpc_modules/os-based/deeplearning/tensorflow/bazel-0.17.2/bin:/hpc_modules/at10.0-based/python-packages-3.5-mpi4py-3.0.0_openmpi-3.1.2/bin:/hpc_modules/at10.0-based/mpi/openmpi-3.1.2/bin:/hpc_modules/at10.0-based/python-packages-3.5/bin:/opt/at10.0/bin:/usr/local/cuda-9.2/nvvm/bin:/usr/local/cuda-9.2/bin:/usr/lib/jvm/java-openjdk/bin:/shared/lsf/10.1/linux3.10-glibc2.17-ppc64le/etc:/shared/lsf/10.1/linux3.10-glibc2.17-ppc64le/bin:/u/acm/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/afs/zurich.ibm.com/usr/bin \\\r\n    PYTHONPATH=/hpc_modules/at10.0-based/deeplearning/tensorflow/tensorflow-v1.11.0_openmpi-3.1.2/lib64/python3.5/site-packages:/hpc_modules/at10.0-based/python-packages-3.5-mpi4py-3.0.0_openmpi-3.1.2/lib64/python3.5/site-packages:/hpc_modules/at10.0-based/python-packages-3.5-mpi4py-3.0.0_openmpi-3.1.2/lib/python3.5/site-packages:/hpc_modules/at10.0-based/python-packages-3.5/lib64/python3.5/site-packages:/hpc_modules/at10.0-based/python-packages-3.5/lib/python3.5/site-packages:/hpc_modules/at10.0-based/python-packages-3.5/lib64/python3.5/site-packages \\\r\n    PYTHON_BIN_PATH=/opt/at10.0/bin/python3.5 \\\r\n    PYTHON_LIB_PATH=/opt/at10.0/lib64/python3.5/site-packages \\\r\n    TF_CUDA_CLANG=0 \\\r\n    TF_CUDA_COMPUTE_CAPABILITIES=7.0 \\\r\n    TF_CUDA_VERSION=9.2 \\\r\n    TF_CUDNN_VERSION=7 \\\r\n    TF_NCCL_VERSION=2 \\\r\n    TF_NEED_CUDA=1 \\\r\n    TF_NEED_OPENCL_SYCL=0 \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/tensorflow/create_tensorflow.python_api --root_init_template=tensorflow/api_template.__init__.py --apidir=bazel-out/ppc-opt/genfiles/tensorflow --apiname=tensorflow --apiversion=1 --package=tensorflow.python --output_package=tensorflow bazel-out/ppc-opt/genfiles/tensorflow/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/app/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/bitwise/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/compat/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/data/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/debugging/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/distributions/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/dtypes/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/errors/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/feature_column/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/gfile/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/graph_util/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/image/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/io/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/initializers/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/activations/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/applications/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/applications/densenet/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/applications/inception_resnet_v2/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/applications/inception_v3/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/applications/mobilenet/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/applications/mobilenet_v2/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/applications/nasnet/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/applications/resnet50/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/applications/vgg16/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/applications/vgg19/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/applications/xception/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/backend/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/callbacks/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/constraints/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/datasets/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/datasets/boston_housing/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/datasets/cifar10/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/datasets/cifar100/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/datasets/fashion_mnist/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/datasets/imdb/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/datasets/mnist/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/datasets/reuters/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/estimator/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/initializers/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/layers/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/losses/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/metrics/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/models/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/optimizers/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/preprocessing/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/preprocessing/image/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/preprocessing/sequence/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/preprocessing/text/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/regularizers/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/utils/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/wrappers/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/keras/wrappers/scikit_learn/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/layers/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/linalg/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/logging/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/losses/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/manip/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/math/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/metrics/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/nn/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/nn/rnn_cell/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/profiler/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/python_io/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/quantization/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/resource_loader/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/strings/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/saved_model/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/saved_model/builder/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/saved_model/constants/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/saved_model/loader/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/saved_model/main_op/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/saved_model/signature_constants/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/saved_model/signature_def_utils/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/saved_model/tag_constants/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/saved_model/utils/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/sets/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/sparse/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/spectral/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/summary/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/sysconfig/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/test/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/train/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/train/queue_runner/__init__.py bazel-out/ppc-opt/genfiles/tensorflow/user_ops/__init__.py')\r\nSUBCOMMAND: # //tensorflow:tensorflow_python_api_gen [action 'Executing genrule //tensorflow:tensorflow_python_api_gen [for host]']\r\n(cd /ibm/gpfs-dataP/hpc_modules/rhel7-P9-2018-09-14/at10.0-based/deeplearning/tensorflow/tensorflow-v1.11.0_openmpi-3.1.2/bazel_tmp/_bazel_acm/89da28a486992b186bd01e39111a422f/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/usr/local/nccl-9.2-v2.2.13/lib:/opt/ibm/xlmass/9.1.0/lib:/usr/lib64/libibverbs:/hpc_modules/at10.0-based/mpi/openmpi-3.1.2/lib:/opt/at10.0/lib:/usr/local/cudnn-9.2-v7.2.1/lib64:/usr/local/cuda-9.2/extras/CUPTI/lib64:/usr/local/cuda-9.2/nvvm/lib64:/usr/lib64/nvidia:/usr/local/cuda-9.2/lib64:/usr/lib64/jna:/shared/lsf/10.1/linux3.10-glibc2.17-ppc64le/lib \\\r\n    PATH=/hpc_modules/at10.0-based/deeplearning/tensorflow/tensorflow-v1.11.0_openmpi-3.1.2/bin:/hpc_modules/os-based/deeplearning/tensorflow/bazel-0.17.2/bin:/hpc_modules/at10.0-based/python-packages-3.5-mpi4py-3.0.0_openmpi-3.1.2/bin:/hpc_modules/at10.0-based/mpi/openmpi-3.1.2/bin:/hpc_modules/at10.0-based/python-packages-3.5/bin:/opt/at10.0/bin:/usr/local/cuda-9.2/nvvm/bin:/usr/local/cuda-9.2/bin:/usr/lib/jvm/java-openjdk/bin:/shared/lsf/10.1/linux3.10-glibc2.17-ppc64le/etc:/shared/lsf/10.1/linux3.10-glibc2.17-ppc64le/bin:/u/acm/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/afs/zurich.ibm.com/usr/bin \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/tensorflow/create_tensorflow.python_api --root_init_template=tensorflow/api_template.__init__.py --apidir=bazel-out/host/genfiles/tensorflow --apiname=tensorflow --apiversion=1 --package=tensorflow.python --output_package=tensorflow bazel-out/host/genfiles/tensorflow/__init__.py bazel-out/host/genfiles/tensorflow/app/__init__.py bazel-out/host/genfiles/tensorflow/bitwise/__init__.py bazel-out/host/genfiles/tensorflow/compat/__init__.py bazel-out/host/genfiles/tensorflow/data/__init__.py bazel-out/host/genfiles/tensorflow/debugging/__init__.py bazel-out/host/genfiles/tensorflow/distributions/__init__.py bazel-out/host/genfiles/tensorflow/dtypes/__init__.py bazel-out/host/genfiles/tensorflow/errors/__init__.py bazel-out/host/genfiles/tensorflow/feature_column/__init__.py bazel-out/host/genfiles/tensorflow/gfile/__init__.py bazel-out/host/genfiles/tensorflow/graph_util/__init__.py bazel-out/host/genfiles/tensorflow/image/__init__.py bazel-out/host/genfiles/tensorflow/io/__init__.py bazel-out/host/genfiles/tensorflow/initializers/__init__.py bazel-out/host/genfiles/tensorflow/keras/__init__.py bazel-out/host/genfiles/tensorflow/keras/activations/__init__.py bazel-out/host/genfiles/tensorflow/keras/applications/__init__.py bazel-out/host/genfiles/tensorflow/keras/applications/densenet/__init__.py bazel-out/host/genfiles/tensorflow/keras/applications/inception_resnet_v2/__init__.py bazel-out/host/genfiles/tensorflow/keras/applications/inception_v3/__init__.py bazel-out/host/genfiles/tensorflow/keras/applications/mobilenet/__init__.py bazel-out/host/genfiles/tensorflow/keras/applications/mobilenet_v2/__init__.py bazel-out/host/genfiles/tensorflow/keras/applications/nasnet/__init__.py bazel-out/host/genfiles/tensorflow/keras/applications/resnet50/__init__.py bazel-out/host/genfiles/tensorflow/keras/applications/vgg16/__init__.py bazel-out/host/genfiles/tensorflow/keras/applications/vgg19/__init__.py bazel-out/host/genfiles/tensorflow/keras/applications/xception/__init__.py bazel-out/host/genfiles/tensorflow/keras/backend/__init__.py bazel-out/host/genfiles/tensorflow/keras/callbacks/__init__.py bazel-out/host/genfiles/tensorflow/keras/constraints/__init__.py bazel-out/host/genfiles/tensorflow/keras/datasets/__init__.py bazel-out/host/genfiles/tensorflow/keras/datasets/boston_housing/__init__.py bazel-out/host/genfiles/tensorflow/keras/datasets/cifar10/__init__.py bazel-out/host/genfiles/tensorflow/keras/datasets/cifar100/__init__.py bazel-out/host/genfiles/tensorflow/keras/datasets/fashion_mnist/__init__.py bazel-out/host/genfiles/tensorflow/keras/datasets/imdb/__init__.py bazel-out/host/genfiles/tensorflow/keras/datasets/mnist/__init__.py bazel-out/host/genfiles/tensorflow/keras/datasets/reuters/__init__.py bazel-out/host/genfiles/tensorflow/keras/estimator/__init__.py bazel-out/host/genfiles/tensorflow/keras/initializers/__init__.py bazel-out/host/genfiles/tensorflow/keras/layers/__init__.py bazel-out/host/genfiles/tensorflow/keras/losses/__init__.py bazel-out/host/genfiles/tensorflow/keras/metrics/__init__.py bazel-out/host/genfiles/tensorflow/keras/models/__init__.py bazel-out/host/genfiles/tensorflow/keras/optimizers/__init__.py bazel-out/host/genfiles/tensorflow/keras/preprocessing/__init__.py bazel-out/host/genfiles/tensorflow/keras/preprocessing/image/__init__.py bazel-out/host/genfiles/tensorflow/keras/preprocessing/sequence/__init__.py bazel-out/host/genfiles/tensorflow/keras/preprocessing/text/__init__.py bazel-out/host/genfiles/tensorflow/keras/regularizers/__init__.py bazel-out/host/genfiles/tensorflow/keras/utils/__init__.py bazel-out/host/genfiles/tensorflow/keras/wrappers/__init__.py bazel-out/host/genfiles/tensorflow/keras/wrappers/scikit_learn/__init__.py bazel-out/host/genfiles/tensorflow/layers/__init__.py bazel-out/host/genfiles/tensorflow/linalg/__init__.py bazel-out/host/genfiles/tensorflow/logging/__init__.py bazel-out/host/genfiles/tensorflow/losses/__init__.py bazel-out/host/genfiles/tensorflow/manip/__init__.py bazel-out/host/genfiles/tensorflow/math/__init__.py bazel-out/host/genfiles/tensorflow/metrics/__init__.py bazel-out/host/genfiles/tensorflow/nn/__init__.py bazel-out/host/genfiles/tensorflow/nn/rnn_cell/__init__.py bazel-out/host/genfiles/tensorflow/profiler/__init__.py bazel-out/host/genfiles/tensorflow/python_io/__init__.py bazel-out/host/genfiles/tensorflow/quantization/__init__.py bazel-out/host/genfiles/tensorflow/resource_loader/__init__.py bazel-out/host/genfiles/tensorflow/strings/__init__.py bazel-out/host/genfiles/tensorflow/saved_model/__init__.py bazel-out/host/genfiles/tensorflow/saved_model/builder/__init__.py bazel-out/host/genfiles/tensorflow/saved_model/constants/__init__.py bazel-out/host/genfiles/tensorflow/saved_model/loader/__init__.py bazel-out/host/genfiles/tensorflow/saved_model/main_op/__init__.py bazel-out/host/genfiles/tensorflow/saved_model/signature_constants/__init__.py bazel-out/host/genfiles/tensorflow/saved_model/signature_def_utils/__init__.py bazel-out/host/genfiles/tensorflow/saved_model/tag_constants/__init__.py bazel-out/host/genfiles/tensorflow/saved_model/utils/__init__.py bazel-out/host/genfiles/tensorflow/sets/__init__.py bazel-out/host/genfiles/tensorflow/sparse/__init__.py bazel-out/host/genfiles/tensorflow/spectral/__init__.py bazel-out/host/genfiles/tensorflow/summary/__init__.py bazel-out/host/genfiles/tensorflow/sysconfig/__init__.py bazel-out/host/genfiles/tensorflow/test/__init__.py bazel-out/host/genfiles/tensorflow/train/__init__.py bazel-out/host/genfiles/tensorflow/train/queue_runner/__init__.py bazel-out/host/genfiles/tensorflow/user_ops/__init__.py')\r\nERROR: /ibm/gpfs-dataP/hpc_modules/rhel7-P9-2018-09-14/at10.0-based/deeplearning/tensorflow/tensorflow-v1.11.0_openmpi-3.1.2/tensorflow-git/tensorflow/BUILD:592:1: Executing genrule //tensorflow:tensorflow_python_api_gen failed (Exit 1): bash failed: error executing command\r\n  (cd /ibm/gpfs-dataP/hpc_modules/rhel7-P9-2018-09-14/at10.0-based/deeplearning/tensorflow/tensorflow-v1.11.0_openmpi-3.1.2/bazel_tmp/_bazel_acm/89da28a486992b186bd01e39111a422f/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/usr/local/nccl-9.2-v2.2.13/lib:/opt/ibm/xlmass/9.1.0/lib:/usr/lib64/libibverbs:/hpc_modules/at10.0-based/mpi/openmpi-3.1.2/lib:/opt/at10.0/lib:/usr/local/cudnn-9.2-v7.2.1/lib64:/usr/local/cuda-9.2/extras/CUPTI/lib64:/usr/local/cuda-9.2/nvvm/lib64:/usr/lib64/nvidia:/usr/local/cuda-9.2/lib64:/usr/lib64/jna:/shared/lsf/10.1/linux3.10-glibc2.17-ppc64le/lib \\\r\n    PATH=/hpc_modules/at10.0-based/deeplearning/tensorflow/tensorflow-v1.11.0_openmpi-3.1.2/bin:/hpc_modules/os-based/deeplearning/tensorflow/bazel-0.17.2/bin:/hpc_modules/at10.0-based/python-packages-3.5-mpi4py-3.0.0_openmpi-3.1.2/bin:/hpc_modules/at10.0-based/mpi/openmpi-3.1.2/bin:/hpc_modules/at10.0-based/python-packages-3.5/bin:/opt/at10.0/bin:/usr/local/cuda-9.2/nvvm/bin:/usr/local/cuda-9.2/bin:/usr/lib/jvm/java-openjdk/bin:/shared/lsf/10.1/linux3.10-glibc2.17-ppc64le/etc:/shared/lsf/10.1/linux3.10-glibc2.17-ppc64le/bin:/u/acm/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/afs/zurich.ibm.com/usr/bin \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/tensorflow/create_tensorflow.python_api --root_init_template=tensorflow/api_template.__init__.py --apidir=bazel-out/host/genfiles/tensorflow --apiname=tensorflow --apiversion=1 --package=tensorflow.python --output_package=tensorflow bazel-out/host/genfiles/tensorflow/__init__.py bazel-out/host/genfiles/tensorflow/app/__init__.py bazel-out/host/genfiles/tensorflow/bitwise/__init__.py bazel-out/host/genfiles/tensorflow/compat/__init__.py bazel-out/host/genfiles/tensorflow/data/__init__.py bazel-out/host/genfiles/tensorflow/debugging/__init__.py bazel-out/host/genfiles/tensorflow/distributions/__init__.py bazel-out/host/genfiles/tensorflow/dtypes/__init__.py bazel-out/host/genfiles/tensorflow/errors/__init__.py bazel-out/host/genfiles/tensorflow/feature_column/__init__.py bazel-out/host/genfiles/tensorflow/gfile/__init__.py bazel-out/host/genfiles/tensorflow/graph_util/__init__.py bazel-out/host/genfiles/tensorflow/image/__init__.py bazel-out/host/genfiles/tensorflow/io/__init__.py bazel-out/host/genfiles/tensorflow/initializers/__init__.py bazel-out/host/genfiles/tensorflow/keras/__init__.py bazel-out/host/genfiles/tensorflow/keras/activations/__init__.py bazel-out/host/genfiles/tensorflow/keras/applications/__init__.py bazel-out/host/genfiles/tensorflow/keras/applications/densenet/__init__.py bazel-out/host/genfiles/tensorflow/keras/applications/inception_resnet_v2/__init__.py bazel-out/host/genfiles/tensorflow/keras/applications/inception_v3/__init__.py bazel-out/host/genfiles/tensorflow/keras/applications/mobilenet/__init__.py bazel-out/host/genfiles/tensorflow/keras/applications/mobilenet_v2/__init__.py bazel-out/host/genfiles/tensorflow/keras/applications/nasnet/__init__.py bazel-out/host/genfiles/tensorflow/keras/applications/resnet50/__init__.py bazel-out/host/genfiles/tensorflow/keras/applications/vgg16/__init__.py bazel-out/host/genfiles/tensorflow/keras/applications/vgg19/__init__.py bazel-out/host/genfiles/tensorflow/keras/applications/xception/__init__.py bazel-out/host/genfiles/tensorflow/keras/backend/__init__.py bazel-out/host/genfiles/tensorflow/keras/callbacks/__init__.py bazel-out/host/genfiles/tensorflow/keras/constraints/__init__.py bazel-out/host/genfiles/tensorflow/keras/datasets/__init__.py bazel-out/host/genfiles/tensorflow/keras/datasets/boston_housing/__init__.py bazel-out/host/genfiles/tensorflow/keras/datasets/cifar10/__init__.py bazel-out/host/genfiles/tensorflow/keras/datasets/cifar100/__init__.py bazel-out/host/genfiles/tensorflow/keras/datasets/fashion_mnist/__init__.py bazel-out/host/genfiles/tensorflow/keras/datasets/imdb/__init__.py bazel-out/host/genfiles/tensorflow/keras/datasets/mnist/__init__.py bazel-out/host/genfiles/tensorflow/keras/datasets/reuters/__init__.py bazel-out/host/genfiles/tensorflow/keras/estimator/__init__.py bazel-out/host/genfiles/tensorflow/keras/initializers/__init__.py bazel-out/host/genfiles/tensorflow/keras/layers/__init__.py bazel-out/host/genfiles/tensorflow/keras/losses/__init__.py bazel-out/host/genfiles/tensorflow/keras/metrics/__init__.py bazel-out/host/genfiles/tensorflow/keras/models/__init__.py bazel-out/host/genfiles/tensorflow/keras/optimizers/__init__.py bazel-out/host/genfiles/tensorflow/keras/preprocessing/__init__.py bazel-out/host/genfiles/tensorflow/keras/preprocessing/image/__init__.py bazel-out/host/genfiles/tensorflow/keras/preprocessing/sequence/__init__.py bazel-out/host/genfiles/tensorflow/keras/preprocessing/text/__init__.py bazel-out/host/genfiles/tensorflow/keras/regularizers/__init__.py bazel-out/host/genfiles/tensorflow/keras/utils/__init__.py bazel-out/host/genfiles/tensorflow/keras/wrappers/__init__.py bazel-out/host/genfiles/tensorflow/keras/wrappers/scikit_learn/__init__.py bazel-out/host/genfiles/tensorflow/layers/__init__.py bazel-out/host/genfiles/tensorflow/linalg/__init__.py bazel-out/host/genfiles/tensorflow/logging/__init__.py bazel-out/host/genfiles/tensorflow/losses/__init__.py bazel-out/host/genfiles/tensorflow/manip/__init__.py bazel-out/host/genfiles/tensorflow/math/__init__.py bazel-out/host/genfiles/tensorflow/metrics/__init__.py bazel-out/host/genfiles/tensorflow/nn/__init__.py bazel-out/host/genfiles/tensorflow/nn/rnn_cell/__init__.py bazel-out/host/genfiles/tensorflow/profiler/__init__.py bazel-out/host/genfiles/tensorflow/python_io/__init__.py bazel-out/host/genfiles/tensorflow/quantization/__init__.py bazel-out/host/genfiles/tensorflow/resource_loader/__init__.py bazel-out/host/genfiles/tensorflow/strings/__init__.py bazel-out/host/genfiles/tensorflow/saved_model/__init__.py bazel-out/host/genfiles/tensorflow/saved_model/builder/__init__.py bazel-out/host/genfiles/tensorflow/saved_model/constants/__init__.py bazel-out/host/genfiles/tensorflow/saved_model/loader/__init__.py bazel-out/host/genfiles/tensorflow/saved_model/main_op/__init__.py bazel-out/host/genfiles/tensorflow/saved_model/signature_constants/__init__.py bazel-out/host/genfiles/tensorflow/saved_model/signature_def_utils/__init__.py bazel-out/host/genfiles/tensorflow/saved_model/tag_constants/__init__.py bazel-out/host/genfiles/tensorflow/saved_model/utils/__init__.py bazel-out/host/genfiles/tensorflow/sets/__init__.py bazel-out/host/genfiles/tensorflow/sparse/__init__.py bazel-out/host/genfiles/tensorflow/spectral/__init__.py bazel-out/host/genfiles/tensorflow/summary/__init__.py bazel-out/host/genfiles/tensorflow/sysconfig/__init__.py bazel-out/host/genfiles/tensorflow/test/__init__.py bazel-out/host/genfiles/tensorflow/train/__init__.py bazel-out/host/genfiles/tensorflow/train/queue_runner/__init__.py bazel-out/host/genfiles/tensorflow/user_ops/__init__.py')\r\nTraceback (most recent call last):\r\n  File \"/ibm/gpfs-dataP/hpc_modules/rhel7-P9-2018-09-14/at10.0-based/deeplearning/tensorflow/tensorflow-v1.11.0_openmpi-3.1.2/bazel_tmp/_bazel_acm/89da28a486992b186bd01e39111a422f/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py\", line 27, in <module>\r\n    from tensorflow.python.tools.api.generator import doc_srcs\r\n  File \"/ibm/gpfs-dataP/hpc_modules/rhel7-P9-2018-09-14/at10.0-based/deeplearning/tensorflow/tensorflow-v1.11.0_openmpi-3.1.2/bazel_tmp/_bazel_acm/89da28a486992b186bd01e39111a422f/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api.runfiles/org_tensorflow/tensorflow/python/__init__.py\", line 47, in <module>\r\n    import numpy as np\r\nImportError: No module named 'numpy'```", "comments": ["I think there was another similar issue @annarev and @meteorcloudy was commenting on?", "@gunan Do you have any update on the above issue? If that has been solved in a master commit, could you please point me to the hash? Thank you", "This hasn't been resolved yet. See https://github.com/tensorflow/tensorflow/issues/22395\r\nCurrent workaround is to use --distinct_host_configuration=false. Sorry about the issue!", "When I used ` --distinct_host_configuration=false`, somehow another error like this appeared from keras_preprocessing:\r\n```\r\nexecroot/org_tensorflow/bazel-out/k8-o\r\npt/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/keras/preprocess\r\ning/__init__.py\", line 21, in <module>\r\n    import keras_preprocessing\r\nImportError: No module named keras_preprocessing\r\n```\r\nI guess another workaround would be to change the code and add the user site in the code:\r\n```\r\nimport site\r\nimport os\r\n# path to the user site packages\r\nUSER_SITE = os.path.join(os.environ[\"HOME\"], '.local/lib/python2.7/site-packages')\r\nsite.addsitedir(USER_SITE)\r\n```", "Hi @cristianomalossi !\r\nWe are checking to see if you still need help on this issue. We recommend that you upgrade to 2.6 which is latest stable version of TF and let us know if the issue still persists in newer versions. Thanks!", "We can close, it is a very old one, I am not looking at that anymore.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/22814\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/22814\">No</a>\n"]}, {"number": 22813, "title": "The model is killing Automatically after 3 epochs", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["I apologize, but I am having a hard time understanding what the problem is, where the problem is, and what version it affects. Please resubmit and pay attention to the issue template (https://github.com/tensorflow/tensorflow/issues/new). Please provide all the information it asks. Thank you.\r\n"]}, {"number": 22812, "title": "Windows 10 c++, bazel build successfully\uff0c where is the .lib file\uff1f", "body": "I have build both TensorFlow1.11 and 1.10 's libtensorflow_cc.so file successfully, but where is the .lib file for Visual Studio ?", "comments": ["Hi Did you get the answer?\r\nI have built tensorflow for c++ with bazel on windows and need .lib and .dll. Can you share what you did to include tensorflow in visual studio project?"]}, {"number": 22811, "title": "centos6 compile source code error", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  centos6.4\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: r1.9\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**: 0.16.1\r\n- **GCC/Compiler version (if compiling from source)**: 2.12\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**: \r\n\r\n### Describe the problem\r\nCompile tensorflow with source code, but get some erros.\r\ncommand : \r\nbazel build --config=opt --conlyopt=-std=c99  --verbose_failures //tensorflow/tools/pip_package:build_pip_package\r\n\r\n### Source code / logs\r\nStarting local Bazel server and connecting to it...\r\n... still trying to connect to local Bazel server after 10 seconds ...\r\n... still trying to connect to local Bazel server after 20 seconds ...\r\nWARNING: /home/rcdev/.cache/bazel/_bazel_rcdev/0bbd005cd428560db8b92113dbd10a39/external/grpc/BUILD:1960:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_common.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /home/rcdev/.cache/bazel/_bazel_rcdev/0bbd005cd428560db8b92113dbd10a39/external/grpc/bazel/grpc_build_system.bzl:172:12\r\nWARNING: /home/rcdev/.cache/bazel/_bazel_rcdev/0bbd005cd428560db8b92113dbd10a39/external/grpc/BUILD:1960:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_decode.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /home/rcdev/.cache/bazel/_bazel_rcdev/0bbd005cd428560db8b92113dbd10a39/external/grpc/bazel/grpc_build_system.bzl:172:12\r\nWARNING: /home/rcdev/.cache/bazel/_bazel_rcdev/0bbd005cd428560db8b92113dbd10a39/external/grpc/BUILD:1960:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_encode.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /home/rcdev/.cache/bazel/_bazel_rcdev/0bbd005cd428560db8b92113dbd10a39/external/grpc/bazel/grpc_build_system.bzl:172:12\r\nWARNING: /home/rcdev/soft/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.\r\nWARNING: /home/rcdev/soft/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.\r\nINFO: Analysed target //tensorflow/tools/pip_package:build_pip_package (287 packages loaded).\r\nINFO: Found 1 target...\r\nINFO: From Compiling external/nsync/internal/counter.c:\r\ncc1plus: warning: command line option '-std=c99' is valid for C/ObjC but not for C++\r\nINFO: From Compiling tensorflow/contrib/lite/kernels/internal/tensor_utils.cc:\r\nIn file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:0,\r\n                 from tensorflow/contrib/lite/kernels/internal/tensor_utils.cc:16:\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h: In function 'void vst1q_lane_f32(float32_t*, float32x4_t, int)':\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:9673:31: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n     *(ptr) =  *((float*)&ilane);\r\n                               ^\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h: In function 'float32_t vgetq_lane_f32(float32x4_t, int)':\r\nexternal/arm_neon_2_x86_sse/NEON_2_SSE.h:11912:22: warning: dereferencing type-punned pointer will break strict-aliasing rules [-Wstrict-aliasing]\r\n     return *(float*)&ilane;\r\n                      ^\r\nERROR: /home/rcdev/.cache/bazel/_bazel_rcdev/0bbd005cd428560db8b92113dbd10a39/external/gif_archive/BUILD.bazel:8:1: C++ compilation of rule '@gif_archive//:gif' failed (Exit 1): gcc failed: error executing command \r\n  (cd /home/rcdev/.cache/bazel/_bazel_rcdev/0bbd005cd428560db8b92113dbd10a39/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/home/rcdev/soft/binutils/lib/:/home/rcdev/soft/gcc-4.9/lib/:/home/rcdev/soft/gcc-4.9/lib64/:/usr/local/CDH5/hadoop/lib/native/:/usr/local/lib: \\\r\n    PATH=/home/rcdev/soft/python3/bin:/home/rcdev/soft/bazel-0.16.1/output:/usr/local/java/jdk1.8.0/bin:/home/rcdev/soft/binutils/bin:/home/rcdev/soft/python2.7/bin:/home/rcdev/soft/gcc-4.9/bin:/home/rcdev/soft/python3/bin:/usr/local/CDH5/hadoop/bin:/usr/local/ruby/bin:/usr/local/CDH5/hive/bin:/usr/local/jdk1.7.0/bin:/usr/local/jdk1.7.0/jre/bin:/bin:/usr/local/jdk1.7.0/bin:/usr/local/apache-maven-3.0.4/bin:/usr/local/mysql/bin:/usr/local/jdk1.7.0/bin:/usr/local/jdk1.7.0/jre/bin:/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/usr/local/apache-flume/bin:/bin:/usr/local/R-3.1/bin:/usr/local/apache-flume/bin:/usr/local/CDH5/hadoop/bin:/usr/local/apache-maven-3.0.4/bin:/usr/local/CDH5/hbase/bin:/usr/local/CDH5/pig/bin:/usr/local/CDH5/zookeeper-3.4.5-cdh5.0.1/bin:/usr/local/scala-2.10.3/bin:/home/rcdev/bin:/home/rcdev/storm/bin:/home/rcdev/.local/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/home/rcdev/soft/python2.7/bin/python \\\r\n    PYTHON_LIB_PATH=/home/rcdev/soft/python2.7/lib/python2.7/site-packages \\\r\n    TF_DOWNLOAD_CLANG=0 \\\r\n    TF_NEED_CUDA=0 \\\r\n    TF_NEED_OPENCL_SYCL=0 \\\r\n  /home/rcdev/soft/gcc-4.9/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/home/rcdev/soft/gcc-4.9/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -MD -MF bazel-out/k8-opt/bin/external/gif_archive/_objs/gif/egif_lib.pic.d -fPIC -iquote external/gif_archive -iquote bazel-out/k8-opt/genfiles/external/gif_archive -iquote bazel-out/k8-opt/bin/external/gif_archive -iquote external/bazel_tools -iquote bazel-out/k8-opt/genfiles/external/bazel_tools -iquote bazel-out/k8-opt/bin/external/bazel_tools -isystem external/gif_archive/lib -isystem bazel-out/k8-opt/genfiles/external/gif_archive/lib -isystem bazel-out/k8-opt/bin/external/gif_archive/lib '-march=native' '-std=c99' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c external/gif_archive/lib/egif_lib.c -o bazel-out/k8-opt/bin/external/gif_archive/_objs/gif/egif_lib.pic.o)\r\nexternal/gif_archive/lib/egif_lib.c: In function 'EGifOpenFileName':\r\nexternal/gif_archive/lib/egif_lib.c:62:6: error: 'S_IREAD' undeclared (first use in this function)\r\n      S_IREAD | S_IWRITE);\r\n      ^\r\nexternal/gif_archive/lib/egif_lib.c:62:6: note: each undeclared identifier is reported only once for each function it appears in\r\nexternal/gif_archive/lib/egif_lib.c:62:16: error: 'S_IWRITE' undeclared (first use in this function)\r\n      S_IREAD | S_IWRITE);\r\n                ^\r\nexternal/gif_archive/lib/egif_lib.c: In function 'EGifOpenFileHandle':\r\nexternal/gif_archive/lib/egif_lib.c:119:5: warning: implicit declaration of function 'fdopen' [-Wimplicit-function-declaration]\r\n     f = fdopen(FileHandle, \"wb\");    /* Make it into a stream: */\r\n     ^\r\nexternal/gif_archive/lib/egif_lib.c:119:7: warning: assignment makes pointer from integer without a cast\r\n     f = fdopen(FileHandle, \"wb\");    /* Make it into a stream: */\r\n       ^\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 46.012s, Critical Path: 14.30s\r\nINFO: 327 processes: 327 local.\r\nFAILED: Build did NOT complete successfully\r\nYou have mail in /var/spool/mail/rcdev\r\n\r\n", "comments": ["The error is likely due to your GCC/Compiler version. Please take a look at this link [Building TensorFlow for CentOS 6.](https://blog.abysm.org/2016/06/building-tensorflow-centos-6/). It mentions about the modifications that are necessary to build. ", "> \r\n> \r\n> The error is likely due to your GCC/Compiler version. Please take a look at this link [Building TensorFlow for CentOS 6.](https://blog.abysm.org/2016/06/building-tensorflow-centos-6/). It mentions about the modifications that are necessary to build.\r\n@ymodak  thank you\r\n", "@zdx Were you able to solve your issue?", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)"]}, {"number": 22809, "title": "The virtual env install and verification fails", "body": "On Mac OS X latest and following the exact steps on Tensorflow install page using the virtual env and it fails with weird error... any ideas?\r\n\r\npip3 --version\r\npip 18.1\r\n\r\npython --version\r\nPython 3.7.0\r\n\r\nFollowing all steps exactly here....\r\nhttps://www.tensorflow.org/install/pip\r\n\r\nTo validate at end it is failing....\r\n\r\npython -c \"import tensorflow as tf; print(tf.__version__)\"\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/__init__.py\", line 22, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 114\r\n    def TFE_ContextOptionsSetAsync(arg1, async):", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "From the documentation link, I suspect that python version 3.7 is not fully supported yet. Can you please try the same for python version 3.6 and post your findings?", "Yes thank you, was very hard to figure this out without lots of googling.  Tensor flow doesn't mention this anywhere in setup guide and brew install on Mac defaults to python 3.7, seems weird it wouldn't support.  I'm new to python world, but would only expect major release version 4.x to break anything.  Also finding how u can get 3.6 with brew is also more googling.  Finally, what's up with Pip?!  I'd expect an error explaining this not something cryptic.  Anyway that's my little rant on python dependency management as a first impression.  Am up and running now .", "You are welcome. Yes, A warning message for python versions can be convenient. Pip is a tool that installs python packages but fails to provide informative message in some cases. The easy way to validate TF installation is to import TF module in Python.", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)"]}, {"number": 22808, "title": "[Documentation] Format example list.", "body": "Signed-off-by: Marcela Morales Quispe <marcela.morales.quispe@gmail.com>", "comments": ["For future reference: this is just adding periods (dots) to the end of code-of-conduct lines."]}, {"number": 22807, "title": "[Documentation] Format code block.", "body": "Signed-off-by: Marcela Morales Quispe <marcela.morales.quispe@gmail.com>", "comments": []}, {"number": 22806, "title": "tfp.bijectors.BatchNormalization ask for shape of tensor at graph construction", "body": "i am building a customized bijector with tfp.bijectors.BatchNormalization. when i construct the graph, the dimension of input tensor for forward function cannot be possibly fully defined, because of the unknown batch size. But bijector BatchNormalization keeps raising error message that input must have shape known at graph construction. The code is [here](https://github.com/breadbread1984/glow-flow/blob/3c5645b1fa25e03110ec6d6553cb793eaf758b3f/GlowStep.py#L18). is it a bug or i am using it wrong?\r\n\r\ncall stack when error occurs\r\n>  File \"C:\\Users\\yi.xie\\Documents\\glow-flow\\GlowStep.py\", line 28, in _forward\r\n    return self.flow.forward(x);\r\n  File \"C:\\Users\\yi.xie\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\distributions\\bijector_impl.py\", line 764, in forward\r\n    return self._call_forward(x, name)\r\n  File \"C:\\Users\\yi.xie\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\distributions\\bijector_impl.py\", line 745, in _call_forward\r\n    mapping = mapping.merge(y=self._forward(x, **kwargs))\r\n  File \"C:\\Users\\yi.xie\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_probability\\python\\bijectors\\chain.py\", line 263, in _forward\r\n    x = b.forward(x, **kwargs.get(b.name, {}))\r\n  File \"C:\\Users\\yi.xie\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\distributions\\bijector_impl.py\", line 764, in forward\r\n    return self._call_forward(x, name)\r\n  File \"C:\\Users\\yi.xie\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\distributions\\bijector_impl.py\", line 745, in _call_forward\r\n    mapping = mapping.merge(y=self._forward(x, **kwargs))\r\n  File \"C:\\Users\\yi.xie\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_probability\\python\\bijectors\\batch_normalization.py\", line 223, in _forward\r\n    return self._de_normalize(x)\r\n  File \"C:\\Users\\yi.xie\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_probability\\python\\bijectors\\batch_normalization.py\", line 214, in _de_normalize\r\n    broadcast_fn = self._get_broadcast_fn(x)\r\n  File \"C:\\Users\\yi.xie\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_probability\\python\\bijectors\\batch_normalization.py\", line 188, in _get_broadcast_fn\r\n    raise ValueError(\"Input must have shape known at graph construction.\")\r\nValueError: Input must have shape known at graph construction.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:windows 10\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:n/a\r\n- **TensorFlow installed from (source or binary)**:binary\r\n- **TensorFlow version (use command below)**:1.11\r\n- **Python version**:3.6\r\n- **Bazel version (if compiling from source)**:n/a\r\n- **GCC/Compiler version (if compiling from source)**:n/a\r\n- **CUDA/cuDNN version**:n/a\r\n- **GPU model and memory**:n/a\r\n- **Exact command to reproduce**:n/a\r\n\r\n", "comments": ["can I build a graph with bijector? it seems the bijectors can't accept tensors with unknown dimensions. shall I use it only in eager execution mode?", "@breadbread1984 You should be able to use bijector to build a graph. I ran above code snippet in your environment without running errors. ", "I updated tensorflow_probability library and the problem is gone. thx", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)"]}, {"number": 22805, "title": "InternalError: Failed to create session.", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nno\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 10\r\n- **TensorFlow installed from (source or binary)**:\r\nsource (conda install tensorflow)\r\n- **TensorFlow version (use command below)**:\r\n1.10.0\r\n- **Python version**:\r\n3.6.5\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\nNO CUDA\r\n- **GPU model and memory**:\r\nNO GPU\r\n\r\n### Describe the problem\r\nTraceback (most recent call last):\r\n\r\n  File \"<ipython-input-4-e4380738388e>\", line 11, in <module>\r\n    model.fit(x_train, y_train, epochs=5)\r\n\r\n  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1363, in fit\r\n    validation_steps=validation_steps)\r\n\r\n  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\", line 264, in fit_loop\r\n    outs = f(ins_batch)\r\n\r\n  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 2876, in __call__\r\n    session = get_session()\r\n\r\n  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 440, in get_session\r\n    _SESSION = session_module.Session(config=config)\r\n\r\n  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1494, in __init__\r\n    super(Session, self).__init__(target, graph, config=config)\r\n\r\n  File \"C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 626, in __init__\r\n    self._session = tf_session.TF_NewSession(self._graph._c_graph, opts)\r\n\r\nInternalError: Failed to create session.\r\n\r\n### Source code / logs\r\nimport tensorflow as tf\r\nmnist = tf.keras.datasets.mnist\r\n\r\n(x_train, y_train),(x_test, y_test) = mnist.load_data()\r\nx_train, x_test = x_train / 255.0, x_test / 255.0\r\n\r\nmodel = tf.keras.models.Sequential([\r\n  tf.keras.layers.Flatten(),\r\n  tf.keras.layers.Dense(512, activation=tf.nn.relu),\r\n  tf.keras.layers.Dropout(0.2),\r\n  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\r\n])\r\nmodel.compile(optimizer='adam',\r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\nmodel.fit(x_train, y_train, epochs=5)\r\nmodel.evaluate(x_test, y_test)\r\n", "comments": ["I was able to run your code snippet successfully using system config identical to your's:\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\nTensorFlow installed from (source or binary): source (conda install tensorflow)\r\nTensorFlow version (use command below): 1.10.0\r\nPython version:3.6.5\r\n\r\nDo you have  a separate Tensorflow session running in another terminal when you execute the script?", "No, I don't have any session running besides this one\n\nOn Sun, 7 Oct, 2018, 23:05 ymodak, <notifications@github.com> wrote:\n\n> I was able to run your code snippet successfully using system config\n> identical to your's:\n> OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\n> TensorFlow installed from (source or binary): source (conda install\n> tensorflow)\n> TensorFlow version (use command below): 1.10.0\n> Python version:3.6.5\n>\n> Do you have a separate Tensorflow session running in another terminal when\n> you execute the script?\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/22805#issuecomment-427670771>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AVYJOkgylkXJRLYdMlMjgEQtdyZNVhnrks5uijtvgaJpZM4XL3A_>\n> .\n>\n", "I updated my tensorflow version to 1.11.0 and then restarted the system, now its working fine.\r\n\r\n Thank you @ymodak ", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)"]}, {"number": 22804, "title": "timeout in //tensorflow/python/keras:data_utils_test when building from source", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n```\r\n$ uname -a\r\nLinux precision 4.15.0-34-generic #37~16.04.1-Ubuntu SMP Tue Aug 28 10:44:06 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n$ cat /etc/lsb-release\r\nDISTRIB_ID=LinuxMint\r\nDISTRIB_RELEASE=18.2\r\nDISTRIB_CODENAME=sonya\r\nDISTRIB_DESCRIPTION=\"Linux Mint 18.2 Sonya\"\r\n```\r\n\r\nCPU: Intel(R) Xeon(R) CPU E3-1505M v6 @ 3.00GHz\r\nMem: 32GB\r\nStorage: 500GB\r\n\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\nNo\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\nBuilding from source\r\n\r\n- **TensorFlow version (use command below)**:\r\n\r\n    Issue occurs on both the latest 1.11.0 release branch and on latest master (573985c currently)\r\n\r\n- **Python version**:\r\n```\r\n$ /usr/bin/python3 -V\r\nPython 3.5.2\r\n```\r\n\r\n- **Bazel version (if compiling from source)**:\r\n```\r\n$ bazel version\r\nBuild label: 0.17.2\r\nBuild target: bazel-out/k8-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Fri Sep 21 10:31:42 2018 (1537525902)\r\nBuild timestamp: 1537525902\r\nBuild timestamp as int: 1537525902\r\n```\r\n\r\n- **GCC/Compiler version (if compiling from source)**:\r\n```\r\n$ gcc -v\r\nUsing built-in specs.\r\nCOLLECT_GCC=gcc\r\nCOLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/5/lto-wrapper\r\nTarget: x86_64-linux-gnu\r\nConfigured with: ../src/configure -v --with-pkgversion='Ubuntu 5.4.0-6ubuntu1~16.04.10' --with-bugurl=file:///usr/share/doc/gcc-5/README.Bugs --enable-languages=c,ada,c++,java,go,d,fortran,objc,obj-c++ --prefix=/usr --program-suffix=-5 --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --with-sysroot=/ --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-vtable-verify --enable-libmpx --enable-plugin --with-system-zlib --disable-browser-plugin --enable-java-awt=gtk --enable-gtk-cairo --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-5-amd64/jre --enable-java-home --with-jvm-root-dir=/usr/lib/jvm/java-1.5.0-gcj-5-amd64 --with-jvm-jar-dir=/usr/lib/jvm-exports/java-1.5.0-gcj-5-amd64 --with-arch-directory=amd64 --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --enable-objc-gc --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu\r\nThread model: posix\r\ngcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.10)\r\n```\r\n\r\n- **CUDA/cuDNN version**:\r\nN/A\r\n\r\n- **GPU model and memory**:\r\n```\r\n# Quadro M1200, 4GB (3D acceleration)\r\n# Intel HD Graphics 630 (primary vga)\r\nlspci | grep -iP '(vga|3d)'\r\n00:02.0 VGA compatible controller: Intel Corporation Device 591d (rev 04)\r\n01:00.0 3D controller: NVIDIA Corporation Device 13b6 (rev a2)\r\n```\r\n\r\n- **Exact command to reproduce**:\r\n\r\n`bazel test -c opt --action_env PATH=\"$PATH\" -- //tensorflow/... -//tensorflow/compiler/... -//tensorflow/contrib/lite/...`\r\n\r\nor\r\n\r\n`bazel test --test_verbose_timeout_warnings -c opt --action_env PATH=\"$PATH\" -- //tensorflow/python/keras:data_utils_test`\r\n\r\n(I added --action_env because I was having some issues getting bazel to find my installed python3)\r\n\r\n### Describe the problem\r\n\r\nThis is the only test that fails for me when building from source.  It seems timeouts in this test have been a problem before, per a commit by @jlebar: https://github.com/tensorflow/tensorflow/commit/7a60167ba7718c23b0ed70d079bbb446f63a4fd9\r\n\r\n### Source code / logs\r\n\r\n```\r\n$ bazel test --test_verbose_timeout_warnings -c opt --action_env PATH=\"$PATH\" -- //tensorflow/python/keras:data_utils_test\r\n\r\n...\r\n\r\nTIMEOUT: //tensorflow/python/keras:data_utils_test (Summary)\r\n      /home/calid/.cache/bazel/_bazel_calid/d95f42fa008125d605be7949a2399f3e/execroot/org_tensorflow/bazel-out/k8-opt/testlogs/tensorflow/python/keras/data_utils_test/test.log\r\n[1 / 2] 1 / 1 tests, 1 failed;  1 action; last test: .../python/keras:data_utils_test\r\nTarget //tensorflow/python/keras:data_utils_test up-to-date:\r\n[2 / 2] 1 / 1 tests, 1 failed; no action; last  bazel-bin/tensorflow/python/keras/data_utils_test\r\n[2 / 2] 1 / 1 tests, 1 failed; no action; lastINFO: Elapsed time: 915.423s, Critical Path: 915.01s\r\n[2 / 2] 1 / 1 tests, 1 failed; no action; lastINFO: 1 process: 1 local.\r\n[2 / 2] 1 / 1 tests, 1 failed; no action; lastINFO: Build completed, 1 test FAILED, 2 total actions\r\n//tensorflow/python/keras:data_utils_test                               TIMEOUT in 915.0s\r\n  /home/calid/.cache/bazel/_bazel_calid/d95f42fa008125d605be7949a2399f3e/execroot/org_tensorflow/bazel-out/k8-opt/testlogs/tensorflow/python/keras/data_utils_test/test.log\r\n\r\nINFO: Build completed, 1 test FAILED, 2 total actions\r\n\r\n$ cat /home/calid/.cache/bazel/_bazel_calid/d95f42fa008125d605be7949a2399f3e/execroot/org_tensorflow/bazel-out/k8-opt/testlogs/tensorflow/python/keras/data_utils_test/test.log\r\nexec ${PAGER:-/usr/bin/less} \"$0\" || exit 1\r\nExecuting tests from //tensorflow/python/keras:data_utils_test\r\n-----------------------------------------------------------------------------\r\nTerminated\r\n```\r\n", "comments": ["same issue here.", "After digging into this further the specific issue seems to be with using multiprocessing.  Every test that has `use_multiprocessing=True` hangs for me.  For example `test_ordered_enqueuer_processes`: https://github.com/tensorflow/tensorflow/blob/c19e29306ce1777456b2dbb3a14f511edf7883a8/tensorflow/python/keras/utils/data_utils_test.py#L215-L224\r\n\r\nSpecifically, it hangs on `queue.get()` in `data_utils.py`: https://github.com/tensorflow/tensorflow/blob/c19e29306ce1777456b2dbb3a14f511edf7883a8/tensorflow/python/keras/utils/data_utils.py#L605-L613", "I think I isolated the problem:  It looks like the `use_multiprocessing=True` branch of code is not actually handling the multiprocessing use case correctly, in that it isn't using the appropriate multiprocessing constructs (`multiprocessing.Queue`, `multiprocessing.Event`...).  \r\n\r\nWhat's interesting is that in the `1.11.0` version `GeneratorEnqueuer` and `OrderedEnqueuer` handle multiprocessing differently, with `GeneratorEnqueuer` handling it correctly: \r\n\r\n`GeneratorEnqueuer.start (on 1.11.0)`:\r\nhttps://github.com/tensorflow/tensorflow/blob/c19e29306ce1777456b2dbb3a14f511edf7883a8/tensorflow/python/keras/utils/data_utils.py#L733-L743\r\n\r\nvs `OrderedEnqueuer` which does not:\r\n\r\n`OrderedEnqueuer.start (on 1.11.0)`:\r\nhttps://github.com/tensorflow/tensorflow/blob/c19e29306ce1777456b2dbb3a14f511edf7883a8/tensorflow/python/keras/utils/data_utils.py#L549-L560\r\n\r\nand sure enough on `1.11.0` only the OrderedEnqueuer tests hang, GeneratorEnqueuer tests do not.\r\n\r\nOn master it looks like there was an effort to coalesce the code and eliminate duplication by moving common logic into the SequenceEnqueuer base class.  Unfortunately it looks like the incorrect OrderedEnqueuer version of the code was used, and so now all the multiprocessing tests hang on master.\r\n\r\n`SequenceEnqueuer.start (on master)`:\r\nhttps://github.com/tensorflow/tensorflow/blob/573985cacba7ba36032fe3ac55f4ca9b52e08033/tensorflow/python/keras/utils/data_utils.py#L511-L521\r\n\r\n\r\nI'm going to work on putting together a PR to use the correct multiprocessing constructs when `use_multiprocessing=True` (basically to just use the GeneratorEnqueuer version of the multiprocessing  logic).  Let me know if I'm on the right track with this or if I've misinterpreted things.", "@XuesongYang I've opened a PR to fix the issue: https://github.com/tensorflow/tensorflow/pull/23011.   If you have time want to give my branch a try and let me know if it fixes things for you too?", "Nagging Assignee @fchollet: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Closing as the PR has moved to keras (which I'm still working on)"]}]