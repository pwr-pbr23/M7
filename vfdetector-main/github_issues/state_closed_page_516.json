[{"number": 38264, "title": "Train a Simple Audio Recognition Model", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): \r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: \r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below): \r\n- Python version: - Bazel\r\nversion (if compiling from source):\r\n- GCC/Compiler version (if compiling from\r\nsource): \r\n- CUDA/cuDNN version: - GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38264\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38264\">No</a>\n"]}, {"number": 38262, "title": "Import Error", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):windows 10\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version: 2.1\r\n- Python version: 3.7.7\r\n- Installed using virtualenv? pip? conda?:pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nImportError: Could not find the DLL(s) 'msvcp140.dll or msvcp140_1.dll'. TensorFlow requires that these DLLs be installed in a directory that is named in your %PATH% environment variable. You may install these DLLs by downloading \"Microsoft C++ Redistributable for Visual Studio 2015, 2017 and 2019\" for your platform from this URL: https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nInstalled python 3.7.7 from python.org\r\ninstalled Microsoft C++ Redistributable for Visual Studio 2015, 2017 and 2019 from the said platform.\r\nInstalled Tensorflow using powershell command \"pip install tensorflow \" .\r\nRan Powershell Command python -c \"import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))\" to check if the installation was successfull.\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@Nipsa24,\r\nCould you please verify if you have installed the [vc_redist.x64.exe](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads) file?\r\n\r\nAlso, please check [this comment](https://github.com/tensorflow/tensorflow/issues/27816#issuecomment-609096989) from a similar issue and let us know it is helps. Thanks!", "The error you have gives exactly the solution\r\n\r\n```\r\nImportError: Could not find the DLL(s) 'msvcp140.dll or msvcp140_1.dll'. TensorFlow requires that these DLLs be installed in a directory that is named in your %PATH% environment variable. You may install these DLLs by downloading \"Microsoft C++ Redistributable for Visual Studio 2015, 2017 and 2019\" for your platform from this URL: https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads\r\n```\r\n\r\nYou need to download the MSVC redistributable and place it in a directory that is within the directories contained in `%PATH%`. \r\n\r\nAs this is not a TF issue and is already duplicated in many places, closing.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38262\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38262\">No</a>\n"]}, {"number": 38261, "title": "estimator.train_and_evaluate() sometimes throws errors during training ", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow):  Yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04):  Linux \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: \r\n- TensorFlow installed from (source or\r\nbinary): pip - TensorFlow version (use command below): 2\r\n- Python version: 3 \r\n\r\n**Describe the current behavior**\r\nI am trying to run several ML model training in a python script using tensorflow 2. To do this I dockerize my script and setup a tfjob on Kubeflow. For some models the training goes to completion but for others the training fails and I get different kinds of errors somewhere along the training:\r\n\r\n`: Unable to connect to endpoint\r\n[[node save/SaveV2_1 (defined at usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/keras.py:334) ]]\r\n\r\nErrors may have originated from an input operation.\r\nInput Source operations connected to node save/SaveV2_1:\r\nConst (defined at usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/keras.py:333) ()`\r\n\r\n\r\n`Read less bytes than requested [[node save/RestoreV2 (defined at usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/keras.py:334) ]] ()`\r\n\r\n`XAmzContentSHA256Mismatch: Unable to parse ExceptionName: XAmzContentSHA256Mismatch Message: The provided 'x-amz-content-sha256' header does not match what was computed. [[node SaveV2_1 (defined at usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/keras.py:403) ]] ()`\r\n\r\n`There was no new checkpoint after the training. Eval status: no new checkpoint ('There was no new checkpoint after the training. Eval status: no new checkpoint',)`\r\n\r\n**Describe the expected behavior**\r\nI expect the s3 connection errors to be handled by tensorflow so that it doesn't error out when it can't connect to the endpoint during checkpoint saving.\r\n\r\n", "comments": ["@plaffitte, Could you share the code snippet to reproduce the issue. Thanks!", "@gadagashwini thanks for your reply. I can't share my code but I have reproduced the error by adding a for loop in the mnist tutorial code. Here's the python script that's run by the docker container:\r\n\r\n`from __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport argparse\r\nimport json\r\nimport os\r\nimport sys\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom datetime import datetime\r\n\r\nN_DIGITS = 10  # Number of digits.\r\nX_FEATURE = 'x'  # Name of the input feature.\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\r\nos.environ['AWS_LOG_LEVEL'] = '0'\r\n\r\n\r\ndef parse_arguments():\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument('--tf-data-dir',\r\n                        type=str,\r\n                        default='/tmp/data/',\r\n                        help='GCS path or local path of training data.')\r\n    parser.add_argument('--tf-model-dir',\r\n                        type=str,\r\n                        help='GCS path or local directory.')\r\n    parser.add_argument('--tf-export-dir',\r\n                        type=str,\r\n                        default='mnist/',\r\n                        help='GCS path or local directory to export model')\r\n    parser.add_argument('--tf-model-type',\r\n                        type=str,\r\n                        default='CNN',\r\n                        help='Tensorflow model type for training.')\r\n    parser.add_argument('--tf-train-steps',\r\n                        type=int,\r\n                        default=200,\r\n                        help='The number of training steps to perform.')\r\n    parser.add_argument('--tf-batch-size',\r\n                        type=int,\r\n                        default=100,\r\n                        help='The number of batch size during training')\r\n    parser.add_argument('--tf-learning-rate',\r\n                        type=float,\r\n                        default=0.01,\r\n                        help='Learning rate for training.')\r\n\r\n    args = parser.parse_known_args()[0]\r\n    return args\r\n\r\n\r\ndef conv_model(features, labels, mode, params):\r\n    \"\"\"2-layer convolution model.\"\"\"\r\n    # Reshape feature to 4d tensor with 2nd and 3rd dimensions being\r\n    # image width and height final dimension being the number of color channels.\r\n    feature = tf.reshape(features[X_FEATURE], [-1, 28, 28, 1])\r\n\r\n    # First conv layer will compute 32 features for each 5x5 patch\r\n    with tf.variable_scope('conv_layer1'):\r\n        h_conv1 = tf.layers.conv2d(\r\n            feature,\r\n            filters=32,\r\n            kernel_size=[5, 5],\r\n            padding='same',\r\n            activation=tf.nn.relu)\r\n        h_pool1 = tf.layers.max_pooling2d(\r\n            h_conv1, pool_size=2, strides=2, padding='same')\r\n\r\n    # Second conv layer will compute 64 features for each 5x5 patch.\r\n    with tf.variable_scope('conv_layer2'):\r\n        h_conv2 = tf.layers.conv2d(\r\n            h_pool1,\r\n            filters=64,\r\n            kernel_size=[5, 5],\r\n            padding='same',\r\n            activation=tf.nn.relu)\r\n        h_pool2 = tf.layers.max_pooling2d(\r\n            h_conv2, pool_size=2, strides=2, padding='same')\r\n        # reshape tensor into a batch of vectors\r\n        h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\r\n\r\n    # Densely connected layer with 1024 neurons.\r\n    h_fc1 = tf.layers.dense(h_pool2_flat, 1024, activation=tf.nn.relu)\r\n    h_fc1 = tf.layers.dropout(\r\n        h_fc1,\r\n        rate=0.5,\r\n        training=(mode == tf.estimator.ModeKeys.TRAIN))\r\n\r\n    # Compute logits (1 per class) and compute loss.\r\n    logits = tf.layers.dense(h_fc1, N_DIGITS, activation=None)\r\n    predict = tf.nn.softmax(logits)\r\n    classes = tf.cast(tf.argmax(predict, 1), tf.uint8)\r\n\r\n    # Compute predictions.\r\n    predicted_classes = tf.argmax(logits, 1)\r\n    if mode == tf.estimator.ModeKeys.PREDICT:\r\n        predictions = {\r\n            'class': predicted_classes,\r\n            'prob': tf.nn.softmax(logits)\r\n        }\r\n        return tf.estimator.EstimatorSpec(mode, predictions=predictions,\r\n                                          export_outputs={'classes':\r\n                                                              tf.estimator.export.PredictOutput({\"predictions\": predict,\r\n                                                                                                 \"classes\": classes})})\r\n\r\n    # Compute loss.\r\n    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\r\n\r\n    # Create training op.\r\n    if mode == tf.estimator.ModeKeys.TRAIN:\r\n        optimizer = tf.train.GradientDescentOptimizer(\r\n            learning_rate=params[\"learning_rate\"])\r\n        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\r\n        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\r\n\r\n    # Compute evaluation metrics.\r\n    eval_metric_ops = {\r\n        'accuracy': tf.metrics.accuracy(\r\n            labels=labels, predictions=predicted_classes)\r\n    }\r\n    return tf.estimator.EstimatorSpec(\r\n        mode, loss=loss, eval_metric_ops=eval_metric_ops)\r\n\r\n\r\ndef cnn_serving_input_receiver_fn():\r\n    inputs = {X_FEATURE: tf.placeholder(tf.float32, [None, 28, 28])}\r\n    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\r\n\r\n\r\ndef linear_serving_input_receiver_fn():\r\n    inputs = {X_FEATURE: tf.placeholder(tf.float32, (784,))}\r\n    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\r\n\r\n\r\ndef main(_):\r\n\r\n    args = parse_arguments()\r\n\r\n    for i in range(30):\r\n        try:\r\n            feature_name = str(i)\r\n            tf.logging.set_verbosity(tf.logging.INFO)\r\n            tf_config = os.environ.get('TF_CONFIG', '{}')\r\n            tf.logging.info(\"TF_CONFIG %s\", tf_config)\r\n            tf_config_json = json.loads(tf_config)\r\n            cluster = tf_config_json.get('cluster')\r\n            job_name = tf_config_json.get('task', {}).get('type')\r\n            task_index = tf_config_json.get('task', {}).get('index')\r\n            tf.logging.info(\"cluster=%s job_name=%s task_index=%s\", cluster, job_name,\r\n                            task_index)\r\n\r\n            is_chief = False\r\n            if not job_name or job_name.lower() in [\"chief\", \"master\"]:\r\n                is_chief = True\r\n                tf.logging.info(\"Will export model\")\r\n            else:\r\n                tf.logging.info(\"Will not export model\")\r\n\r\n            # Download and load MNIST dataset.\r\n            mnist = tf.contrib.learn.datasets.DATASETS['mnist'](args.tf_data_dir)\r\n            train_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n                x={X_FEATURE: mnist.train.images},\r\n                y=mnist.train.labels.astype(np.int32),\r\n                batch_size=args.tf_batch_size,\r\n                num_epochs=None,\r\n                shuffle=True)\r\n            test_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n                x={X_FEATURE: mnist.train.images},\r\n                y=mnist.train.labels.astype(np.int32),\r\n                num_epochs=1,\r\n                shuffle=False)\r\n\r\n            training_config = tf.estimator.RunConfig(\r\n                model_dir=args.tf_model_dir+\"/\"+feature_name, save_summary_steps=100, save_checkpoints_steps=1000)\r\n\r\n            if args.tf_model_type == \"LINEAR\":\r\n                # Linear classifier.\r\n                feature_columns = [\r\n                    tf.feature_column.numeric_column(\r\n                        X_FEATURE, shape=mnist.train.images.shape[1:])]\r\n                classifier = tf.estimator.LinearClassifier(\r\n                    feature_columns=feature_columns, n_classes=N_DIGITS,\r\n                    model_dir=args.tf_model_dir+\"/\"+feature_name, config=training_config)\r\n                # TODO(jlewi): Should it be linear_serving_input_receiver_fn here?\r\n                serving_fn = cnn_serving_input_receiver_fn\r\n                export_final = tf.estimator.FinalExporter(\r\n                    args.tf_export_dir+\"/feature_name\", serving_input_receiver_fn=cnn_serving_input_receiver_fn)\r\n\r\n            elif args.tf_model_type == \"CNN\":\r\n                # Convolutional network\r\n                model_params = {\"learning_rate\": args.tf_learning_rate}\r\n                classifier = tf.estimator.Estimator(\r\n                    model_fn=conv_model, model_dir=args.tf_model_dir+\"/\"+feature_name,\r\n                    config=training_config, params=model_params)\r\n                serving_fn = cnn_serving_input_receiver_fn\r\n                export_final = tf.estimator.FinalExporter(\r\n                    args.tf_export_dir+\"/feature_name\", serving_input_receiver_fn=cnn_serving_input_receiver_fn)\r\n            else:\r\n                print(\"No such model type: %s\" % args.tf_model_type)\r\n                sys.exit(1)\r\n\r\n            train_spec = tf.estimator.TrainSpec(\r\n                input_fn=train_input_fn, max_steps=args.tf_train_steps)\r\n            eval_spec = tf.estimator.EvalSpec(input_fn=test_input_fn,\r\n                                              steps=1,\r\n                                              exporters=export_final,\r\n                                              throttle_secs=1,\r\n                                              start_delay_secs=1)\r\n            print(\"Train and evaluate\")\r\n            tf.estimator.train_and_evaluate(classifier, train_spec, eval_spec)\r\n            print(\"Training done\")\r\n\r\n            if is_chief:\r\n                print(\"Export saved model\")\r\n                classifier.export_savedmodel(args.tf_export_dir+\"/feature_name\", serving_input_receiver_fn=serving_fn)\r\n                print(\"Done exporting the model\")\r\n\r\n\r\n        except Exception as e:\r\n            print(\"\\n Error during training on feature {} \\n\".format(feature_name), file=sys.stderr)\r\n            print(e.message, e.args, file=sys.stderr)\r\n            print(\"--------------------\", file=sys.stderr)\r\n\r\n            continue\r\n\r\n\r\nif __name__ == '__main__':\r\n    tf.app.run()\r\n`", "@plaffitte, I tried reproducing the issue with above code but code is not properly intended , please take a look at [gist](https://colab.sandbox.google.com/gist/gadagashwini/2ce9d58b6da0ebae4ce7dd61fe731a20/untitled505.ipynb) and provide more information. Thanks", "@gadagashwini I'm sorry the formatting messed it up a bit... I have modified it so it runs, should I share the corresponding dockerfile with you?", "I just ran again the code I pasted in the link you provided, by means of a tfjob on kubeflow, and this is what I get after epoch 12 of the second for loop iteration:\r\n\r\n`WARNING:tensorflow:No new checkpoint ready for evaluation. Skip the current evaluation pass as evaluation results are expected to be same for the same checkpoint.`\r\n\r\nThe first iteration had gone just fine, I don't understand why it just fails sometimes to write the checkpoint to S3. ", "@plaffitte,\r\nWith TensorFlow 2.x, I'm facing an error stating `AttributeError: module 'tensorflow' has no attribute 'app'`.\r\n\r\nHowever, I was able to run the code without any issues with TF 1.15.2, please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/288ba5a7b41348edbcd822b387b83a5d/38261.ipynb). Thanks!", "@amahendrakar Thanks for your feedback. The code running in colab uses local storage to store the checkpoints and the models, am I right?\r\nI believe the issue in my case stems from the communication with S3 because I use S3 as the folder for all model and checkpoint saving. I'm not sure how to reproduce that in your case, you would need to create a dockerfile and run a tfjob on Kubeflow I guess?  ", "@plaffitte,\r\nThank you for the update. Yes, Colab uses local storage to store the files.", "We have been able to reproduce this issue sporadically as well \r\n\r\n ```py\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\nimport numpy as np\r\nimport os\r\nfrom tensorflow import keras\r\nfrom tensorflow.python.lib.io import file_io\r\n\r\n# os.environ['AWS_ACCESS_KEY_ID'] = \"Q3AM3UQ867SPQQA43P2F\"\r\n# os.environ['AWS_SECRET_ACCESS_KEY'] = \"zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\"\r\n# os.environ['AWS_REGION'] = \"us-east-1\"\r\n# os.environ['S3_ENDPOINT'] = \"play.min.io\"\r\n# os.environ['S3_USE_HTTPS'] = \"1\"\r\n# os.environ['S3_VERIFY_SSL'] = \"1\"\r\n\r\nos.environ['AWS_ACCESS_KEY_ID'] = \"minio\"\r\nos.environ['AWS_SECRET_ACCESS_KEY'] = \"minio123\"\r\nos.environ['AWS_REGION'] = \"us-east-1\"\r\nos.environ['S3_ENDPOINT'] = \"localhost:9000\"\r\nos.environ['S3_USE_HTTPS'] = \"0\"\r\nos.environ['S3_VERIFY_SSL'] = \"0\"\r\n\r\nprint(file_io.stat('s3://tfbuck6'))\r\n\r\ndef get_model():\r\n  # Create a simple model.\r\n  inputs = keras.Input(shape=(32,))\r\n  outputs = keras.layers.Dense(1)(inputs)\r\n  model = keras.Model(inputs, outputs)\r\n  model.compile(optimizer='adam', loss='mean_squared_error')\r\n  return model\r\n\r\ntfmodel = get_model()\r\nkeras.experimental.export_saved_model(tfmodel, \"s3://tfbuck6\", serving_only=True)\r\n```", "@plaffitte ,\r\nIs this still an issue?\r\nCould you please update TensorFlow to the latest stable version v.2.7 and let us know if you are facing the same error. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38261\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38261\">No</a>\n"]}, {"number": 38260, "title": "Failed to find bogomips warning", "body": "Hi,\r\nTensorflow fails to find the bogomips because the word \"bogomips\" is in uper-case in my OS:\r\n\"\"\"\r\nprocessor       : 1\r\nBogoMIPS        : 100.00\r\n\"\"\"\r\ntensorflow/core/platform/profile_utils/cpu_utils.cc:106] Failed to find bogomips or clock in /proc/cpuinfo; cannot determine CPU frequency\r\n", "comments": ["@LeeJH \r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "I am running tensorflow on CentOS Linux release 7.6.1810 (AltArch) with aarch64 architecture.  I compile the tensorflow(version 2.2.0-rc2 ) from source code using command: bazel build --config=v2 --config=monolithic --config noaws --linkopt=\"-Wl,-rpath=/usr/local/lib64\" //tensorflow/tools/pip_package:build_pip_package \r\n\r\nI was simply runnig:\r\n>>> import tensorflow as tf\r\n>>> tf.add(1,2).numpy()", "@ymodak Why is this assigned to me?", "I am seeing a similar issue with Armbian 20.11.6 Focal (20.04.1 LTS) on an ODROID C4 aarch64 and TensorFlow v2.3.2.\r\n\r\nThis is the command I am using referenced from:\r\n[https://community.arm.com/developer/ip-products/processors/b/ml-ip-blog/posts/building-bazel-and-tensorflow-2-x-on-aarch64](url)\r\n\r\n> date; bazel build //tensorflow/tools/pip_package:build_pip_package --config noaws --config=monolithic --local_cpu_resources=4 --verbose_failures; date\r\n\r\nError seem:\r\n **python3 -c \"import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\r\n2021-01-22 07:30:42.449646: W tensorflow/core/platform/profile_utils/cpu_utils.cc:108] Failed to find bogomips or clock in /proc/cpuinfo; cannot determine CPU frequency\r\n2021-01-22 07:30:42.450324: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5cd92b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2021-01-22 07:30:42.450427: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\ntf.Tensor(-733.9271, shape=(), dtype=float32**\r\n\r\nThe bogomips are listed as such in cpuinfo:\r\n$ cat /proc/cpuinfo |grep -i mips\r\n\r\n> BogoMIPS\t: 48.00\r\n> BogoMIPS\t: 48.00\r\n> BogoMIPS\t: 48.00\r\n> BogoMIPS\t: 48.00\r\n\r\n", "Hi, I'm seeing the same error with tfjs-node v3.8.0\r\n\r\nRunning\r\nRPi 4\r\nLinux raspberrypi 5.10.17-v7l+ #1421 SMP Thu May 27 14:00:13 BST 2021 armv7l GNU/Linux\r\n\r\nran npm rebuild @tensorflow/tfjs-node --build-from-source\r\n\r\ntfnode.node.loadSavedModel(modelPath) \r\nthrows these errors\r\n\r\n```\r\n2021-07-17 12:56:29.018525: I tensorflow/cc/saved_model/reader.cc:38] Reading SavedModel from: ./model\r\n2021-07-17 12:56:30.135299: I tensorflow/cc/saved_model/reader.cc:90] Reading meta graph with tags { serve }\r\n2021-07-17 12:56:30.135460: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: ./model\r\n2021-07-17 12:56:34.195171: I tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.\r\n2021-07-17 12:56:34.802232: W tensorflow/core/platform/profile_utils/cpu_utils.cc:118] Failed to find bogomips or clock in /proc/cpuinfo; cannot determine CPU frequency\r\n2021-07-17 12:56:40.596275: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 153600 exceeds 10% of free system memory.\r\n2021-07-17 12:56:40.598185: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 153600 exceeds 10% of free system memory.\r\n2021-07-17 12:56:40.599316: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 153600 exceeds 10% of free system memory.\r\n2021-07-17 12:56:40.608802: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 153600 exceeds 10% of free system memory.\r\n2021-07-17 12:56:40.615196: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 153600 exceeds 10% of free system memory.\r\n2021-07-17 12:56:40.974294: I tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: ./model\r\n2021-07-17 12:56:44.061544: I tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 15043034 microseconds.\r\n\r\n```\r\n\r\n\r\n", "@LeeJH  It looks like you are using an older Version of Tensorflow. Many bugs have been fixed in the latest version. Could you please execute your code using Latest Version 2.5 and let us know if the issue still persists? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38260\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38260\">No</a>\n"]}, {"number": 38259, "title": "[INTEL_MKL] Boiler plate code for dnnl threadpool and mkl_conv_ops.cc", "body": "", "comments": ["In case there is a misunderstanding, just wanted to clarify that I think this PR is ready, i.e., doesn't need much work. I'd just like one last minor change (merging two defines together in a few places) for better readability. ", "Thanks @penpornk. Have made the changes. Also had a quick question about build. should i enable a new --config=mkl_threadpool or repurpose one of the mkl_open_source_only options?", "@penpornk , Do you have any updates regarding build option? This is mainly to enable easy benchmarking from your side. ", "@Srini511  Sorry for the delay! Following up on this soon.", "@Srini511 Got the green light for a new build config. Either options (`--config=mkl_threadpool` vs repurposing `--config=mkl_open_source_only`) or some other new name is fine with me. Your pick. :)", "Thanks @penpornk. "]}, {"number": 38258, "title": "Add float16 to _TENSOR_CONTENT_TYPES in tf.make_tensor_proto", "body": "## Overview\r\n\r\nRecently I was doing model serving using tf serving. And my model(which is also the official model provided by tensorflow, [LINK](https://github.com/tensorflow/models/tree/master/official/r1/resnet#pre-trained-model)) takes `float16` as input data type. And I found great sterilization overhead using input tensor with such data types. And I found that in `tensorflow/src/python/framework/tensor_util.py`, the `make_tensor_proto` didn't store the `float16` data in `tensor_content`, but in `repeated` fashion. Hence, I wonder if we should allow `float16` data type to be included in `_TENSOR_CONTENT_TYPES` of `tf.make_tensor_proto`(which is an API that most users are using for networking transmission) for the performance of such scenarios.\r\n\r\n## Performance\r\n\r\nUsing the default `tf.make_tensor_proto`, sending a [16, 224, 224, 3] tensor costs 280 ms(75% time used in serialization and memory copy).\r\n\r\n![fp16_](https://user-images.githubusercontent.com/38074777/78525507-ee85b400-7809-11ea-8655-4aa64aa9917b.png)\r\n\r\nAfter manually set the input data into `tensor_content`, a huge performance boost occurred. It only takes 60 ms and the overhead proportion of serialization is less than 2%.\r\n\r\n![after](https://user-images.githubusercontent.com/38074777/78525589-2d1b6e80-780a-11ea-8563-89bc4c8020ac.png)\r\n", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F38258) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it.", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F38258) for more info**.\n\n<!-- ok -->"]}, {"number": 38257, "title": "[TF2.1][TPU] Connection reset by peer during training", "body": "**System information** \r\n- TensorFlow version: 2.1\r\n- Python version: 3.6.9\r\n- TPU version: - 2.0\r\n\r\n**Describe the current behavior**\r\nI'm using TPU to train a model for Named Entity Disambiguation task using a BERT model from the huggingface. During training I randomly get this error saying the connection is reset by peer.\r\n\r\n**Standalone code to reproduce the issue** \r\nTraining code: \r\n```\r\nwith strategy.scope():\r\n    model, ent_model, comp_model = distilbert_ned(seq_len_1 = entity_text_len,\r\n                                                  seq_len_2 = company_text_len,\r\n                                                  num_finetune_bert_layers=0)\r\n    adam = tf.keras.optimizers.Adam(clipnorm=.5, lr=lr)\r\n    model.compile(optimizer=adam,\r\n                  loss=triplet_loss,\r\n                  )\r\n    if cuda_dev == 'tpu':\r\n        cb = ACC_Callback(comp_model, ent_model, model, val_set, unique_entities, best_model_dir='gs://{}/ned/out/'.format(cloud_bucket,))\r\n    else:\r\n        cb = ACC_Callback(comp_model, ent_model, model, val_set, unique_entities, best_model_dir='./')\r\n    ds_train, ds_val = get_tfrecord_dataset(batch_size)\r\n    model.fit(ds_train,\r\n          validation_data=ds_val,\r\n          epochs=8, verbose=1,\r\n          callbacks=[cb],\r\n    )\r\n```\r\n\r\nWhat the callback does is it calls `comp_model.predict()` and `ent_model.predict` to make predictions and calculate the accuracy on the validation set.\r\n\r\n**Other info / logs**:\r\n```\r\n2020-04-05 06:25:27.447473: E tensorflow/core/common_runtime/eager/context.cc:459] Failed to register function remotely due to Connection reset by peer\r\nThis shouldn't happen, please file a bug to tensorflow team.\r\n2020-04-05 06:25:41.771929: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:79] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find a context_id matching the specified one (4329004720033007128). Perhaps the worker was restarted, or the context was GC'd?\r\nAdditional GRPC error information:\r\n{\"created\":\"@1586067941.771818685\",\"description\":\"Error received from peer\",\"file\":\"external/grpc/src/core/lib/surface/call.cc\",\"file_line\":1039,\"grpc_message\":\"Unable to find a context_id matching the specified one (4329004720033007128). Perhaps the worker was restarted, or the context was GC'd?\",\"grpc_status\":3}\r\nTraceback (most recent call last):\r\n  File \"train_ned.py\", line 696, in <module>\r\n    model.save_weights('last_ned.tf')\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\", line 1123, in save_weights\r\n    self._trackable_saver.save(filepath, session=session)\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/util.py\", line 1168, in save\r\n    file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/util.py\", line 1108, in _save_cached_when_graph_building\r\n    object_graph_tensor=object_graph_tensor)\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/util.py\", line 1076, in _gather_saveables\r\n    feed_additions) = self._graph_view.serialize_object_graph()\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/graph_view.py\", line 381, in serialize_object_graph\r\n    trackable_objects, path_to_root)\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/graph_view.py\", line 344, in _serialize_gathered_objects\r\n    object_names=object_names)\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/graph_view.py\", line 96, in _serialize_slot_variables\r\n    or hasattr(trackable, \"_create_or_restore_slot_variable\")):\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/distribute/values.py\", line 830, in __getattr__\r\n    return super(TPUVariableMixin, self).__getattr__(name)\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/distribute/values.py\", line 392, in __getattr__\r\nException ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7fd3173f00b8>>\r\nTraceback (most recent call last):\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\", line 537, in __del__\r\n    handle=self._handle, deleter=self._deleter)\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py\", line 1148, in delete_iterator\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 6606, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.UnavailableError: Connection reset by peer [Op:DeleteIterator]\r\nException ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7fd3173e6c18>>\r\nTraceback (most recent call last):\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\", line 537, in __del__\r\n    handle=self._handle, deleter=self._deleter)\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py\", line 1148, in delete_iterator\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 6606, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.UnavailableError: Connection reset by peer [Op:DeleteIterator]\r\nException ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7fd3173e67b8>>\r\nTraceback (most recent call last):\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\", line 537, in __del__\r\n    handle=self._handle, deleter=self._deleter)\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py\", line 1148, in delete_iterator\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 6606, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.UnavailableError: Connection reset by peer [Op:DeleteIterator]\r\nException ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7fd3173e6358>>\r\nTraceback (most recent call last):\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\", line 537, in __del__\r\n    handle=self._handle, deleter=self._deleter)\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py\", line 1148, in delete_iterator\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 6606, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.UnavailableError: Connection reset by peer [Op:DeleteIterator]\r\nException ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7fd31735aeb8>>\r\nTraceback (most recent call last):\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\", line 537, in __del__\r\n    handle=self._handle, deleter=self._deleter)\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py\", line 1148, in delete_iterator\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 6606, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.UnavailableError: Connection reset by peer [Op:DeleteIterator]\r\nException ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7fd31735a4e0>>\r\nTraceback (most recent call last):\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\", line 537, in __del__\r\n    handle=self._handle, deleter=self._deleter)\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py\", line 1148, in delete_iterator\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"train_ned.py\", line 685, in <module>\r\n    if False:\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\", line 819, in fit\r\n2020-04-06 01:31:10.561321: E tensorflow/core/common_runtime/eager/context.cc:459] Failed to register function remotely due to Unable to find a context_id matching the specified one (10922957604321251792). Perhaps the worker was restarted, or the context was GC'd?\r\nThis shouldn't happen, please file a bug to tensorflow team.\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 397, in fit\r\n    prefix='val_')\r\n  File \"/usr/lib/python3.6/contextlib.py\", line 88, in __exit__\r\n    next(self.gen)\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 771, in on_epoch\r\n    self.callbacks.on_epoch_end(epoch, epoch_logs)\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/callbacks.py\", line 302, in on_epoch_end\r\n    callback.on_epoch_end(epoch, logs)\r\n  File \"train_ned.py\", line 619, in on_epoch_end\r\n\r\n  File \"train_ned.py\", line 636, in get_company_embeddings\r\n    return entity_embd\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\", line 1013, in predict\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 498, in predict\r\n    workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 475, in _model_iteration\r\n    total_epochs=1)\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 128, in run_one_epoch\r\n    batch_outs = execution_function(iterator)\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 98, in execution_function\r\n    distributed_function(input_fn))\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/util/nest.py\", line 568, in map_structure\r\n    structure[0], [func(*x) for x in entries],\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/util/nest.py\", line 568, in <listcomp>\r\n    structure[0], [func(*x) for x in entries],\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 130, in _non_none_constant_value\r\n    constant_value = tensor_util.constant_value(v)\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_util.py\", line 822, in constant_value\r\n    return tensor.numpy()\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 942, in numpy\r\n    maybe_arr = self._numpy()  # pylint: disable=protected-access\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 910, in _numpy\r\n    six.raise_from(core._status_to_exception(e.code, e.message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.AbortedError: RecvTensor expects a different device incarnation: 15132506705170928619 vs. 17767066468299283119. Your worker job (\"/job:tpu_worker/replica:0/task:0\") was probably restarted. Check your worker job for the reason why it was restarted.\r\nAdditional GRPC error information:\r\n{\"created\":\"@1586136670.549528961\",\"description\":\"Error received from peer\",\"file\":\"external/grpc/src/core/lib/surface/call.cc\",\"file_line\":1039,\"grpc_message\":\"RecvTensor expects a different device incarnation: 15132506705170928619 vs. 17767066468299283119. Your worker job (\"/job:tpu_worker/replica:0/task:0\") was probably restarted. Check your worker job for the reason why it was restarted.\",\"grpc_status\":10}\r\n2020-04-06 01:31:11.529445: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:79] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find a context_id matching the specified one (10922957604321251792). Perhaps the worker was restarted, or the context was GC'd?\r\nAdditional GRPC error information:\r\n{\"created\":\"@1586136671.529360273\",\"description\":\"Error received from peer\",\"file\":\"external/grpc/src/core/lib/surface/call.cc\",\"file_line\":1039,\"grpc_message\":\"Unable to find a context_id matching the specified one (10922957604321251792). Perhaps the worker was restarted, or the context was GC'd?\",\"grpc_status\":3}\r\nException ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7fc6e47cdef0>>\r\nTraceback (most recent call last):\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\", line 537, in __del__\r\n    handle=self._handle, deleter=self._deleter)\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py\", line 1148, in delete_iterator\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 6606, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Unable to find a context_id matching the specified one (10922957604321251792). Perhaps the worker was restarted, or the context was GC'd? [Op:DeleteIterator]\r\nException ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7fc700031c18>>\r\nTraceback (most recent call last):\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\", line 537, in __del__\r\n    handle=self._handle, deleter=self._deleter)\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py\", line 1148, in delete_iterator\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/home/ethan/SEER/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 6606, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Unable to find a context_id matching the specified one (10922957604321251792). Perhaps the worker was restarted, or the context was GC'd? [Op:DeleteIterator]\r\n```", "comments": ["@EthanPhan,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here. Thanks!", "@amahendrakar I can give you the code but not the data. Here's the link to my repo: https://github.com/EthanPhan/nlp.git\r\nThe file you should looking for is `train_ned.py`\r\nI'm sorry I don't know what is the best way to give you the code. If you need anything else, pls let me know\r\n", "@EthanPhan,\r\nI tried to reproduce the issue, but I'm facing an error stating `NoSectionError: No section: 'IOB-format'`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/dad3df4c05cfa3b874e8a14dadbdefd5/38257.ipynb).\r\n\r\nIs it possible for you to provide a minimal reproducible code with a sample dataset? Thanks!", "> @EthanPhan,\r\n> I tried to reproduce the issue, but I'm facing an error stating `NoSectionError: No section: 'IOB-format'`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/dad3df4c05cfa3b874e8a14dadbdefd5/38257.ipynb).\r\n> \r\n> Is it possible for you to provide a minimal reproducible code with a sample dataset? Thanks!\r\n\r\nAny updates regarding this issue? Thanks!\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38257\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38257\">No</a>\n"]}, {"number": 38256, "title": "NFC change to test presubmits", "body": "", "comments": ["Can you please submit a change to tensorflow:master ?", "This was just a test PR to test LLVM integrate cherry-pick, sorry about lack of documentation here.\r\n\r\nMehdi, if this is no longer needed, can we close it?"]}, {"number": 38255, "title": "tensorflow issue", "body": "Hey, I can't install tensorflow\r\nIf I write pip install tensorflow the error message is \r\nERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\r\nERROR: No matching distribution found for tensorflow\r\n please help\r\nthank you ", "comments": ["Closing as no issue template being filled and as there are 2 other similar issues opened by the same user in the same time interval. Deduplicating to #38252", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38255\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38255\">No</a>\n"]}, {"number": 38254, "title": "tensorflow build from source issue on Window 10 (Taking too much time)", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Window 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.1\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source): 0.27.2\r\n- GCC/Compiler version (if compiling from source): VS2017\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\nI am trying to build tensorflow from source on Window 10. I override the eigen strong inline to reduce the compile time. The build is stuck at:\r\n[4,915 / 4,918] Compiling tensorflow/core/kernels/mkl_cwise_ops_common.cc; 72789s local\r\n\r\nAny ideas why it is taking long time to compile this file?\r\n\r\nI used the following command to start the build process:\r\nbazel build --config=mkl -c opt --copt=/arch:AVX --copt=/arch:AVX2 --copt=/std:c++17 --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" --define=override_eigen_strong_inline=true //tensorflow:tensorflow.dll\r\n", "comments": ["The build unfortunately takes a long time. Furthermore, if the RAM usage is bigger than RAM available the build will crawl even slower as it needs to use swap.", "Is it normal to have one file taking that much long time to compile? It is still compiling and I don't see issue with the RAM usage.\r\n\r\n[4,915 / 4,918] Compiling tensorflow/core/kernels/mkl_cwise_ops_common.cc; 176224s local\r\n\r\nIf I don't use MKL flag, the build compiles fine. ", "Template expansion takes a lot of time during compiling, especially on Windows. If you want, you can open a bug against Visual Studio about this", "@kumaradi08, Please update for the @mihaimaruseac's comment. ", "@mihaimaruseac, Okay I will follow up with them. As of now I will wait for it to get compiled as it is. Thanks.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38254\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38254\">No</a>\n", "How much RAM does is require? I have 32GB of RAM, this file compiles for 3 hours already. The usage by CL doesn't exceed 6 GB. System has 14 GB free.", "I have 48 Gb RAM and I have to wait ~50 hours to get that one file compile.", "finally it was compiled, but has failed at linkage with concerns of multiple symbols definitions", "Hi, I'm suffering from that turbulence as well as I'm trying to release TensorFlow for Java, it's been compiling for 4 hours now and reading this thread made my want to cry. Is there any trick that can speed that up?", "I wonder if it's related to issue #10521. Maybe `sed s/inline//g tensorflow/core/util/mkl_util.h` could work around this?", "Well I have some good new about this, after talking with SIG Build folks, it happens that with VS16.4+, you can add this option and it will drastically decrease the compile time of these functions: `--copt=/d2ReducedOptimizeHugeFunctions --host_copt=/d2ReducedOptimizeHugeFunctions`. ", "Maybe the build can succeed even with GitHub Actions now?", "@saudet : yes, I want to try this right after this release, let's hope!", "> Well I have some good new about this, after talking with SIG Build folks, it happens that with VS16.4+, you can add this option and it will drastically decrease the compile time of these functions: `--copt=/d2ReducedOptimizeHugeFunctions --host_copt=/d2ReducedOptimizeHugeFunctions`.\r\n\r\nPerhaps we should add this to building from source on Windows page?", "@mihaimaruseac : These options [have been added](https://github.com/tensorflow/tensorflow/blob/3cbb50768909c585d33e99ba10172d1c44c04d6f/configure.py#L1205) in TensorFlow's configure script 11 months ago, I think standard users probably already saw the improvements without doing anything. It is just that in the case of TensorFlow for Java, we build TF with our own configuration in a CI workflow and this new flag was missing. Still, it might be worth mentioning that this makes a huge difference in case somebody else is trying to configure a CI build for TF.\r\n\r\nLooking at the mention though, it says that this flag is not integral part of the `.bazelrc` because VS16.4 was not out at that time. Now that it is, I think it can safely be added in it without any condition."]}, {"number": 38253, "title": "Import error in tensorflow_datasets", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): NO\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): MAC OS Catalina\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: NA\r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below): pip install tensorflow\r\n\r\n\r\n**Describe the current behavior**\r\n\r\n> ModuleNotFoundError: No module named 'tensorflow.compat'\r\n\r\nI encountered this error after trying to import tensorflow datasets\r\n\r\n\r\n\r\n**Describe the expected behavior**\r\nNo import error\r\n\r\n**Standalone code to reproduce the issue** \r\n> import tensorflow_datasets as tfds\r\n\r\n**Other info / logs** \r\n\r\n<img width=\"550\" alt=\"Screen Shot 2020-04-05 at 17 55 04\" src=\"https://user-images.githubusercontent.com/32034407/78510896-96e23c80-7766-11ea-8402-17708436becd.png\">\r\n", "comments": ["@AarshApple \r\nCould you please let us know the tensorflow version on which error is faced, share a simple stand alone code before which this error was faced for us to replicate it.\r\n\r\nas per the error shared please refer to [this link](https://github.com/tensorflow/tensorflow/issues/26546) and let us know if that helps.\r\n#106 [link](https://stackoverflow.com/questions/56920995/not-able-to-import-tensorflow-datasets-module-in-jupyter-notebook), [link2](https://www.heatonresearch.com/2019/09/03/tf-no-module-jupyter.html)", "@AarshApple\r\nCould you please update as per above comment", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38253\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38253\">No</a>\n"]}, {"number": 38252, "title": "problem of compling tensorflow due to installation", "body": "I have a problem with compling with tensorflow in jupyternotebook. This is the error message\r\nTraceback (most recent call last):\r\n\r\n```\r\nFile \"c:\\users\\home\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\r\nexec(code_obj, self.user_global_ns, self.user_ns)\r\n\r\nFile \"\", line 1, in\r\nimport tensorflow as tf\r\n\r\nFile \"c:\\users\\home\\miniconda3\\lib\\site-packages\\tensorflow_init_.py\", line 22, in\r\nfrom tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import\r\n\r\nFile \"c:\\users\\home\\miniconda3\\lib\\site-packages\\tensorflow\\python_init_.py\", line 49, in\r\nfrom tensorflow.python import pywrap_tensorflow\r\n\r\nFile \"c:\\users\\home\\miniconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in\r\nfrom tensorflow.python.pywrap_tensorflow_internal import *\r\n\r\nFile \"c:\\users\\home\\miniconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 114\r\ndef TFE_ContextOptionsSetAsync(arg1, async):\r\n^\r\nSyntaxError: invalid syntax\r\n```\r\n\r\njust to make it clearer, maybe it is an installation problem.\r\nwell pip install tensorflow didn't work at first, I had this messag error\r\n\r\n```\r\nERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\r\nERROR: No matching distribution found for tensorflow\r\n```\r\n\r\nso I used this line that I found somewhere to install tensorflow\r\n\r\n```\r\npip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.0.0-py3-none-any.whl\r\n```\r\n\r\nand then I needed the version 1.10.0 of tensorflow so I wrote the same line above but with the different version\r\n\r\n```\r\npip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.10.0-py3-none-any.whl\r\n```\r\n\r\nthat's it, then I tried to compile in jupyternotebook with tensorflow and it didn't work :(", "comments": ["Please fill in issue template", "@fatmafarah \r\nplease let us know the tensorflow version on which error is faced.\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n\r\nAs per error please refer to below issue if it helps\r\n#31058", "@fatmafarah\r\nplease update as per above comment", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38252\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38252\">No</a>\n"]}, {"number": 38251, "title": "Error Loading Weights with `by_name=True`", "body": "Here is a short Colab notebook with this error\r\n\r\nhttps://colab.research.google.com/drive/1Z9RoOtyPw-MXnDgPK5irbuZ9I6tpz-zM\r\n\r\n**Describe the current behavior**\r\nError message complains that I must have `TensorFlow-formatted weights` however when I am saving weights I am saving this as TensorFlow formatted weights, using the below code:\r\n\r\n```py\r\nmodel.save_weights('model_weights', save_format='tf')`\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\n\r\n**Standalone code to reproduce the issue** \r\n\r\nhttps://colab.research.google.com/drive/1Z9RoOtyPw-MXnDgPK5irbuZ9I6tpz-zM\r\n\r\n\r\n", "comments": ["While loading your weights set **by_name=False** :\r\n`new_model.load_weights('model_weights', by_name=False)`", "@aniketmaurya  what if I want to load the weights by name?  I want to make sure that I only load weights where the layer names match.  Thanks for your help!", "Was able to reproduce the issue with [TF v2.2.0rc2](https://colab.research.google.com/gist/amahendrakar/b13ea01f9d05c2d4150b00d8255697ce/38251-2-2.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/7a6e5b16aaacf0d457acf62559df8879/38251-tf-nightly.ipynb). Please find the attached gist. Thanks!", "@hamelsmu \r\nTL/DR: So if you want to load a model saved in *.tf format, then select `by_name=False`. If you want to load a model saved in *.h5 format, then select `by_name=True`. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/c0c9808471249fb63298d9273b827f1e/38251-tf-nightly.ipynb).\r\n\r\nThere is small difference between loading a saved model when the model was saved in *.tf format (tensorflow format) or in *.h5 format. The following error clearly shows what we need to do when we load a tensorflow-formatted weights (it need by_name =False). \r\n\r\n`NotImplementedError: Weights may only be loaded based on topology into Models when loading TensorFlow-formatted weights (got by_name=True to load_weights).`\r\n\r\nCheck the description of `load_weights` on [TF website](https://www.tensorflow.org/api_docs/python/tf/keras/Model?version=nightly#load_weights). \r\n\r\n`Only topological loading (by_name=False) is supported when loading weights from the TensorFlow format. Note that topological loading differs slightly between TensorFlow and HDF5 formats for user-defined classes inheriting from tf.keras.Model: HDF5 loads based on a flattened list of weights, while the TensorFlow format loads based on the object-local names of attributes to which layers are assigned in the Model's constructor. `\r\n\r\nHope this helps. Thanks! \r\n\r\nPlease close the issue if this was resolved for you. Thanks!", "~@jvishnuvardhan I am loading weights from the TF format, so shouldn't `by_name=True` work?~\r\n\r\nOops, read it again, let me try this real quick sorry", "Closing this issue, thanks for the clarification.  I clearly missed the error message.\r\n\r\nThank you so much for your help."]}, {"number": 38250, "title": "Incompatible shapes when loading model with TextVectorization and Embedding + Conv1D", "body": "There is **ValueError: Shapes incompatible** when trying to load_model with **TextVectorization** and **Embedding** + **Conv1D** (or **LSTM** or **GRU**).\r\n\r\nIt can be easily replicated using _TextVectorization layer examples_ from TF documentation. You just need to add _model save & load_ to _Using the TextVectorization layer in an Embedding + Conv1D model_ sample.\r\nI created [copy of TextVectorization layer examples colab with these errors](https://colab.research.google.com/drive/1MavOxANGMkDGo8Ob4Lm3H43CY41dON7t). Code added to original example:\r\n```python\r\nmodel.save('my_model')\r\nloaded_model = tf.keras.models.load_model('my_model')\r\n```\r\nError from load_model execution:\r\n```python\r\nWARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. \r\nEither the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\r\n\r\nTwo checkpoint references resolved to different objects (<tensorflow.python.keras.layers.embeddings.Embedding object at 0x7f31fe4d8320> and <tensorflow.python.keras.saving.saved_model.load.TextVectorization object at 0x7f31fe4d8b70>).\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py in assert_is_compatible_with(self, other)\r\n   1115     \"\"\"\r\n   1116     if not self.is_compatible_with(other):\r\n-> 1117       raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\r\n   1118 \r\n   1119   def most_specific_compatible_shape(self, other):\r\n\r\nValueError: Shapes (128, 128) and (7, 128, 128) are incompatible\r\n```\r\nThis error do NOT occur when trying to do _save & load_ in example: [_Using the TextVectorization layer in a bigram TF-IDF densely-connected model_](https://colab.research.google.com/drive/1RvCnR7h0_l4Ekn5vINWToI9TNJdpUZB3). This example contains only Dense and Dropout layers and do not contain Embedding and Conv1D.\r\n\r\nI also found same problem for my custom models using LSTM and GRU.\r\n\r\nProblem occurred for nightly TF version `2.2.0-dev20200405`", "comments": ["Was able to reproduce the issue with Tf == 2.2.0-dev20200406,\r\nPlease find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/854c310a2ebd436813b2fc61a112aef8/untitled489.ipynb). Thanks!", "> Was able to reproduce the issue with Tf == 2.2.0-dev20200406,\r\n> Please find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/854c310a2ebd436813b2fc61a112aef8/untitled489.ipynb). Thanks!\r\n\r\nHi @swierchola\r\n\r\nI have loaded the model commented by @gadagashwini using tf-nightly==2.3.0-dev20200611, and it works without prompting any errors. The inference also works well. It would be great to know if you get the same results so that this issue can be closed.", "@imartinezl I confirm that problem is solved in latest tf-nightly. Probably commit [Fix dimensionality handling issues in TextVectorization](https://github.com/tensorflow/tensorflow/commit/a92ff929b818c7dbca2d0c2648ae17e8d6ae3a40#diff-14a0a5dcf758d55726b80920a2896a21) fixed it. Thanks.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38250\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38250\">No</a>\n", "In the latest nightly, please make sure that TextVectorization and the custom standardization function are registered when loading. \r\n```\r\nloaded_model = tf.keras.models.load_model(\r\n    'my_model', \r\n    custom_objects={'TextVectorization':TextVectorization, \r\n                    'custom_standardization':custom_standardization})\r\n```"]}, {"number": 38249, "title": "problem of compling with tensorflow ", "body": "I have a problem with compling with tensorflow in jupyternotebook. This is the error message\r\nTraceback (most recent call last):\r\n\r\nFile \"c:\\users\\home\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\r\nexec(code_obj, self.user_global_ns, self.user_ns)\r\n\r\nFile \"\", line 1, in\r\nimport tensorflow as tf\r\n\r\nFile \"c:\\users\\home\\miniconda3\\lib\\site-packages\\tensorflow_init_.py\", line 22, in\r\nfrom tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import\r\n\r\nFile \"c:\\users\\home\\miniconda3\\lib\\site-packages\\tensorflow\\python_init_.py\", line 49, in\r\nfrom tensorflow.python import pywrap_tensorflow\r\n\r\nFile \"c:\\users\\home\\miniconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in\r\nfrom tensorflow.python.pywrap_tensorflow_internal import *\r\n\r\nFile \"c:\\users\\home\\miniconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 114\r\ndef TFE_ContextOptionsSetAsync(arg1, async):\r\n^\r\nSyntaxError: invalid syntax\r\n\r\nHelp please <3", "comments": ["just to make it clearer, maybe it is an installation problem.\r\nwell pip install tensorflow didn't work at first, I had this messag error\r\n\"\r\nERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\r\nERROR: No matching distribution found for tensorflow \"\r\n\r\nso I used this line that I found somewhere to install tensorflow\r\npip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.0.0-py3-none-any.whl\r\n\r\nand then I needed the version 1.10.0 of tensorflow so I wrote the same line above but with the different version\r\npip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.10.0-py3-none-any.whl\r\n\r\nthat's it, then I tried to compile in jupyternotebook with tensorflow and it didn't work :( \r\n", "Duplicated to #38252.\r\n\r\nPlease fill in issue template", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38249\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38249\">No</a>\n"]}, {"number": 38248, "title": "in nmt_with_attention, the gru in decoder is not connected, last step state is not passed to this step", "body": "https://www.tensorflow.org/tutorials/text/nmt_with_attention\r\n\r\nthe decoder is trained step by step, and it's not passing last step state to this step\r\n\r\n```\r\n# passing the concatenated vector to the GRU\r\noutput, state = self.gru(x)\r\n```\r\n\r\nis this a feature or a bug? I checked a lot of NMT with attention paper, unlike the document those decoder are connected.\r\n\r\nthanks in advance!", "comments": ["Hello, I'd like to work on this issue. Can you plz give me some pointers on where I should start?", "I think you're right.\r\n\r\n@ManishAradwad if you want to take a shot at a fix, I think all it needs is a `output, state = self.gru(x, initial_state=hidden)`", "Be careful with that. The last time I did that, the attention plots didn't come out right. So please test and see if the attention plots remain similar to what they are now.\r\n\r\nThe `x` is being created from the hidden_state. See the attention equations in the code.", "@MarkDaoust  \r\nI agree with @yashk2810\r\nI did exact the same with `initial_state=hidden` and the attention is strange, the train loss is not converging after 100 epochs (it goes down at first then goes up, ended at 0.2)\r\n", "Thanks for taking a look @hihell  \r\n\r\n> the attention is strange\r\n\r\nCan you be more specific?\r\n\r\nI'll dive in and try to figure out what's wrong.", "I tried re-running the notebook with `initial_state=hidden`, the loss after 10 epochs is 0.076(Previously it was 0.0958). The attention plots are not exactly same but the translations are more or less similar.  \r\nFor ex. Previously `try to find out` is now `try to figure it out`\r\nAre these significant differences?", "@MarkDaoust \r\nto show strange attention the experiment use 60k samples, 10 epochs \r\n\r\n`gru(x)` train loss 0.08\r\n![attention_1586504203_60k_10_tloss_0 08_stateless](https://user-images.githubusercontent.com/1401509/78972967-86084100-7b41-11ea-9a07-897ce314b3e3.png)\r\n\r\n`gru(x, initial_state=hidden)` train loss 0.09\r\n![bHJwxUMy3rQM8ikM__thumbnail](https://user-images.githubusercontent.com/1401509/78972975-8accf500-7b41-11ea-9da4-0cc9631856f4.png)\r\n", "@MarkDaoust \r\nhi, this there any update?", "I'm working on this now.", "Fixed in [9e18593](https://github.com/tensorflow/docs/commit/9e18593b7ee19058b651626d0e96a552ac7b4733)"]}, {"number": 38247, "title": "gpu-jupyter.Dockerfile has bugs - docker build fails.", "body": "After yesterday's edit, few bugs surfaced in gpu-jupyter.Dockerfile\r\nfile url tensorflow/tools/dockerfiles/dockerfiles/gpu-jupyter.Dockerfile\r\n\r\n1) line #81 should have \\ \r\npython3 \\\r\n2) line #100 should be \r\nRUN python3 -m pip  install --no-cache-dir ${TF_PACKAGE}${TF_PACKAGE_VERSION:+==${TF_PACKAGE_VERSION}} \r\n\r\nwithout these changes, docker build fails.\r\n", "comments": ["I think the file that needs to be changed is\r\ntensorflow/tensorflow/tools/dockerfiles/partials/ubuntu/python.partial.Dockerfile", "Thanks! I'm working on some changes to fix this right now.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38247\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38247\">No</a>\n"]}, {"number": 38246, "title": "Train a Simple Audio Recognition model for microcontroller use build issue", "body": "I'm not able to install dependencies in Colab in this Train a Simple Audio Recognition model for microcontroller model.\r\nError shows:\r\n1. Could not find a version that satisfies the requirement tf-nightly-gpu==1.15.0.dev20190729\r\n2. No matching distribution found for tf-nightly-gpu==1.15.0.dev20190729\r\n\r\nCan someone guide how to resolve it?", "comments": ["@ms-ims, Currently, Tf-nightly-gpu version is 2.2.0.dev20200405, For more read [here](https://pypi.org/project/tf-nightly-gpu/). To install tf 1.15.\r\nTry, pip install tensorflow==1.15. Thanks ", "@gadagashwini , Hi, I understood that current version of Tf-nightly-gpu version is 2.2.0.dev20200405 but if I install Tf-nightly-gpu version is 2.2.0.dev20200405 version the code present on colab for this model still create issue while building further.", "@ms-ims, Can you share the error log that you are facing. Thanks", "Hi @gadagashwini Thanks for your support. That issue is resolved, script is updated by that content provider. So now its building properly.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38246\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38246\">No</a>\n"]}, {"number": 38244, "title": "How to deal with variable length weight category features in tensorflow?", "body": "How to deal with variable length weight category features in tensorflow?\r\n\r\nFor example:\r\n\r\n `vocabulary_list=['A','B','C']`\r\n\r\nThe original feature format is as follows:\r\n\r\n`    [\r\n    'A:1.5,B:0.3,C:0.8',\r\n    'D:0.9,B:1.8',\r\n    'A:1.2,B:3.2,E:1.5'\r\n    ]`\r\n\r\nAfter treatment, the results are as follows:\r\n\r\n`    [\r\n    [1.5,0.3,0.8,0.0],\r\n    [0.0,1.8,0.0,0.9],\r\n    [1.2,3.2,0.0,1.5]\r\n    ]`\r\n\r\nPlease help me~~~\r\n\r\nThank you very much~~~", "comments": ["@mrchor Could  you please share a simple standalone code and Tensor Flow version with us to reproduce the issue?Thanks!", "Sorry, this is not a tensorflow issue. I need a tensorflow code to solve the problem of handling the above features. To be honest, I don't know how to do the above feature processing now. Can you provide such a code? Thank you very much~", "That is to say, I need a code like the above feature handling process.", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\nThanks!\r\n", "\u3002\u3002\u3002"]}, {"number": 38243, "title": "r1.14: Specify bazel version", "body": "https://github.com/openai/baselines is still using bazel 1.14 .  Support for 2.0 is in development.\r\n\r\nI was thinking it would be nice to add a .bazelversion file to 1.14, to ease building from source.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F38243) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F38243) for more info**.\n\n<!-- ok -->", "That won't be enough, we need to build the code again in all platform and fix `BUILD` files accordingly.\r\n\r\nHowever, since this is on 1.14, we cannot take it in. Since we no longer release patches for 1.14, the `r1.14` branch is frozen."]}, {"number": 38241, "title": "TensorFlow Lite image_segmentation example for iOS doesn't build", "body": "## URL(s) with the issue:\r\nhttps://github.com/tensorflow/examples/tree/master/lite/examples/image_segmentation/ios\r\n## Description of issue (what needs changing):\r\n\r\nThe README must be provided with an explanation of how to change the settings of the project. At the moment I have problems adjusting the development team (\"**Signing**\").\r\nError message: No profile for team 'Rob De Putter (Personal Team)' matching 'Wildcard' found: Xcode couldn't find any provisioning profiles matching 'GPC87JXMXD/Wildcard'. Install the profile (by dragging and dropping it onto Xcode's dock item) or select a different one in the Signing & Capabilities tab of the target editor.\r\n\r\n<img width=\"1421\" alt=\"Schermafbeelding 2020-04-05 om 14 54 09\" src=\"https://user-images.githubusercontent.com/36565271/78500273-4f9b8200-774d-11ea-8b6a-4f214fa2fe81.png\">\r\n<img width=\"1154\" alt=\"Schermafbeelding 2020-04-05 om 14 54 37\" src=\"https://user-images.githubusercontent.com/36565271/78500283-6641d900-774d-11ea-9bca-6aec48736816.png\">\r\n<img width=\"1152\" alt=\"Schermafbeelding 2020-04-05 om 14 54 30\" src=\"https://user-images.githubusercontent.com/36565271/78500289-6cd05080-774d-11ea-984b-d6f3710d8f08.png\">\r\n\r\n", "comments": ["Could you check if the `Wildcard` provisioning profile that you're using contains your Development Team identity correctly? This article might help:\r\nhttps://medium.com/ios-os-x-development/ios-code-signing-provisioning-in-a-nutshell-d5b247760bef", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 38240, "title": "Encountered error while reading extension file 'swift/repositories.bzl': no such package '@build_bazel_rules_swift//swift'", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 18.04 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version:1.14.0(CPU)\r\n- Python version: 3.6.9\r\n- Installed using virtualenv? pip? conda?:sudo pip3 tensorflow==1.14.0\r\n- Bazel version (if compiling from source):0.24.1\r\n- GCC/Compiler version (if compiling from source):NA\r\n- CUDA/cuDNN version: 0\r\n- GPU model and memory:GTX1660ti 6G\r\n\r\n\r\n\r\n**Describe the problem**\r\nI am follwing this [instruction](https://programmer.ink/think/tensorflow-android-side-compile-procedure-record.html#1Bazel_0241_18) to build so and jar file, but i got following error:\r\n![Snipaste_2020-04-05_21-46-33](https://user-images.githubusercontent.com/43233772/78500087-1a138a80-7787-11ea-85be-64240302a05c.png)\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nAs shown in above image\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@wadewangpower \r\nis there any particular reason to be using 1.14 version, do you want to try on any later version?\r\n\r\nplease refer to this [link](https://www.tensorflow.org/install/source#setup_for_linux_and_macos)\r\nplease refer to these links and let us know if they help\r\n#26553 #27352 #30111 #25644 #25747 ", "> @wadewangpower\r\n> is there any particular reason to be using 1.14 version, do you want to try on any later version?\r\n> \r\n> please refer to this [link](https://www.tensorflow.org/install/source#setup_for_linux_and_macos)\r\n> please refer to these links and let us know if they help\r\n> #26553 #27352 #30111 #25644 #25747\r\n\r\nThere is no particular reason that i have to use 1.14 version, just because i saw this [instruction](https://programmer.ink/think/tensorflow-android-side-compile-procedure-record.html#1Bazel_0241_18) which provides all other matched versions, so i followed  it. If i don't use tf1.14, which version do you recommend ? and is there any successful case with newer tf version ? Thanks !", "@wadewangpower \r\nplease  follow the link https://www.tensorflow.org/install/source and select the release branch 2.1\r\n", "> @wadewangpower\r\n> please follow the link https://www.tensorflow.org/install/source and select the release branch 2.1\r\n\r\nAfterwards, i found i temporarily don't need to build this .so file. If in the future i still need to build file with bazel in ubuntu os, i will try your advice~", "@wadewangpower\r\nin that case please confirm if we may move this issue to closed status", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38240\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38240\">No</a>\n"]}, {"number": 38239, "title": "Adding shape to _tensor_array_scatter", "body": "How can I add shape to tensor_array_scatter? \r\nI have tried with the following code but this doesn't work \r\n![Screenshot from 2020-04-05 15-43-33](https://user-images.githubusercontent.com/41699212/78499993-4530b680-7754-11ea-9fc0-88f3c1f5274d.png)\r\nis there another way to add shapes for graph", "comments": ["@OriAlpha, Please provide the complete standalone code replicate the issue and share the Tensorflow version that you are using. Thanks!", "Here you can find the details about the script and model in following [google_drive](https://drive.google.com/drive/folders/1aVAva4Q5bFGafpKBbvuBcFz0yaaW7jNB?usp=sharing)\r\npython file is for reading graph and pb file is the model.\r\nI am using tf1.14", "The final output of the script is at variable graph_def but this doesn't have a shape for the nodes in it, example **tensor_array_scatter node** doesn't have  a shape ", "@OriAlpha, Please take a look at the colab [gist](https://colab.sandbox.google.com/gist/gadagashwini/2f24faa8095ab8ff630ec76dabb6651c/untitled497.ipynb) and confirm the issue reproduced or not. Thanks", "No this not the issue it seems to work fine for me. The bug Is tensor_array_scatter doesn't get a shape ", "@OriAlpha, Can you share the colab gist or complete code to analyze issue.Thanks", "i think found the issue, thanks ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38239\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38239\">No</a>\n"]}, {"number": 38238, "title": " Floating point calculation error", "body": "tensorflow2.0 and python3.7 \r\nwhen i wanto calculate 165 * 3.1 or 165 * 2.1, i got a fake answer.\r\nLike this:\r\ntf.cast(165, tf.float32) * 2.1\r\nOut: <tf.Tensor: id=43186, shape=(), dtype=float32, numpy=346.49997>\r\ntf.cast(165, tf.float32) * 3.1\r\nOut: <tf.Tensor: id=43261, shape=(), dtype=float32, numpy=511.49997>\r\n\r\ni make sure its a error, but i wanto know why.\r\n", "comments": ["Hey, @JanMCHEN  you're getting this type of answer because you're multiplying a tensor with the floating number.\r\nplease see the gist for doing this: https://colab.research.google.com/drive/1HD7ScmyvOSuoXz7z7iGW7fLk-S95itGe#scrollTo=GkHs7h9l32un\r\nAnd If it doesn't solve your query, then feel free to reach out to us.", "> Hey, @JanMCHEN you're getting this type of answer because you're multiplying a tensor with the floating number.\r\n> please see the gist for doing this: https://colab.research.google.com/drive/1HD7ScmyvOSuoXz7z7iGW7fLk-S95itGe#scrollTo=GkHs7h9l32un\r\n> And If it doesn't solve your query, then feel free to reach out to us.\r\n\r\nThanks, i just hope to get a correct answer when i calculated 165 * 2.1,it should be 346.5. I solved it through 165 * 2 * 2.1 / 2, it worked but it is means that i will get a wrong answer sometimes when i calculated the float number as a common way.\r\n\u6211\u6bcd\u8bed\u662f\u6c49\u8bed\uff0c\u53ef\u80fd\u8868\u793a\u7684\u4e0d\u662f\u5f88\u6e05\u695a\uff0c\u6211\u60f3\u8bf4\u7684\u662f\u8fd9\u662f\u4e0d\u662f\u610f\u5473\u7740\u6211\u7528tensorflow\u505a\u6d6e\u70b9\u8fd0\u7b97\u65f6\u6211\u5e94\u8be5\u65f6\u523b\u6ce8\u610f\u5b83\u7684\u8f93\u51fa\uff0c\u56e0\u4e3a\u5176\u6709\u53ef\u80fd\u4e0d\u662f\u6b63\u786e\u7684\u7b54\u6848\uff0c\u6216\u8005\u8fd9\u80cc\u540e\u6d89\u53ca\u5230\u6570\u636e\u7c7b\u578b\u8f6c\u6362\uff0c\u6211\u5bf9C Language \u4e86\u89e3\u4e00\u70b9\uff0c\u4f46\u8fd8\u662f\u4e0d\u660e\u767d\u8fd9\u4e2a\u6d6e\u70b9\u8fd0\u7b97\u4e3a\u4ec0\u4e48\u4f1a\u51fa\u9519\u3002\u8c22\u8c22\u89e3\u7b54", "@abhinavsp0730 You multiplyied the tensor with the tensor, but it still not the right answer of calculating the two floating numbers.\r\n", "> @abhinavsp0730 You multiplyied the tensor with the tensor, but it still not the right answer of calculating the two floating numbers.\r\n\r\nWould you please be more specific what you're referring for the right answer? \r\nI don't used tf.math.multiply because, i think you're dealing with scalar. ", "@abhinavsp0730 When i wanto get a images'shape, it is expressed in tensors.Now i want to calculate its shape after expanding scale times.Usually i can get the shape by calulating \"img.shape * scale\", but you see when the shape is like(165,    ),scale equals to 2.1, i will get a confused anwser. \r\n   165 times to 2.1 should be 346.5 but i got 346.4999,then i fall into a bug. I'm training a \r\nSuper resolution network with a floating times\uff0c and i can't calulate it through scalar.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38238\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38238\">No</a>\n"]}, {"number": 38237, "title": "[Mismatch of Codes] built libtensorflow_cc.so does not match the interface of Eigen ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.2.0\r\n- Python version: python3.6 \uff08maintained by conda\uff09\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source): 0.29.1 (according to requirements of tensorflow 2.2.0)\r\n- GCC/Compiler version (if compiling from source): 7.5.0\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: ON 7 GB\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nI built tensorflow from sources and exported both dependancies of files and the shared library to /usr/local/include/tensorflow, /usr/local/lib (soft link to /usr/lib/ ...)\r\n\r\nNow I am building a cmake projects using tensorflow. Here is a cmake snopshot:\r\n\r\n```txt\r\n cmake ..\r\n[Semantic_Relocalization] Build type: Release\r\n[Semantic_Relocalization] Install path: /usr/local\r\n-- Using libstdc++(gcc). You can change the tool chain with clang/clang++ in Ubuntu/CentOS/MacOS\r\n-- Could NOT find GTest (missing: GTEST_LIBRARY GTEST_MAIN_LIBRARY)\r\n-- Found gflags (include: /usr/include, library: /usr/lib/x86_64-linux-gnu/libgflags.so)\r\n-- GFLAGS_INCLUDE_DIRS: /usr/include/gflags\r\n-- GFLAGS_LIBRARIES: /usr/lib/x86_64-linux-gnu/libgflags.so\r\n-- Found glog (include: /usr/include, library: /usr/lib/x86_64-linux-gnu/libglog.so)\r\n-- GLOG_INCLUDE_DIRS: /usr/include/glog\r\n-- GLOG_LIBRARIES: /usr/lib/x86_64-linux-gnu/libglog.so\r\n-- Home directory : /home/yiakwy\r\nCMake Warning at cmake/Relies.cmake:17 (message):\r\n  System variable EXTERNAL_DIR is nonexist, using\r\n  /home/yiakwy/mapping_external instead.\r\nCall Stack (most recent call first):\r\n  CMakeLists.txt:123 (include)\r\n\r\n\r\n-- EXTERNAL_LIBS_DIR : /home/yiakwy/mapping_external/linux\r\n-- Find Opencv (ver.) (include: /usr/local/include/opencv4, library: opencv_calib3d\r\n-- opencv_core\r\n-- opencv_dnn\r\n-- opencv_features2d\r\n-- opencv_flann\r\n-- opencv_gapi\r\n-- opencv_highgui\r\n-- opencv_imgcodecs\r\n-- opencv_imgproc\r\n-- opencv_ml\r\n-- opencv_objdetect\r\n-- opencv_photo\r\n-- opencv_stitching\r\n-- opencv_video\r\n-- opencv_videoio\r\n-- opencv_aruco\r\n-- opencv_bgsegm\r\n-- opencv_bioinspired\r\n-- opencv_ccalib)\r\nCMake Warning at /usr/local/share/cmake-3.9/Modules/FindBoost.cmake:769 (message):\r\n  Imported targets not available for Boost version 106501\r\nCall Stack (most recent call first):\r\n  /usr/local/share/cmake-3.9/Modules/FindBoost.cmake:873 (_Boost_COMPONENT_DEPENDENCIES)\r\n  /usr/local/share/cmake-3.9/Modules/FindBoost.cmake:1501 (_Boost_MISSING_DEPENDENCIES)\r\n  cmake/Relies.cmake:58 (find_package)\r\n  CMakeLists.txt:123 (include)\r\n\r\n\r\nCMake Warning at /usr/local/share/cmake-3.9/Modules/FindBoost.cmake:769 (message):\r\n  Imported targets not available for Boost version 106501\r\nCall Stack (most recent call first):\r\n  /usr/local/share/cmake-3.9/Modules/FindBoost.cmake:873 (_Boost_COMPONENT_DEPENDENCIES)\r\n  /usr/local/share/cmake-3.9/Modules/FindBoost.cmake:1501 (_Boost_MISSING_DEPENDENCIES)\r\n  cmake/Relies.cmake:58 (find_package)\r\n  CMakeLists.txt:123 (include)\r\n\r\n\r\n-- Boost version: 1.65.1\r\n-- Found the following Boost libraries:\r\n--   system\r\n--   filesystem\r\n-- EIGEN3_VERSION: 3.3.90\r\n-- Eigen3_DIR: /usr/local/share/eigen3/cmake\r\n-- Found Eigen3, inc: /usr/local/include/eigen3\r\n-- Found Eigen3: inc /usr/local/include/eigen3 (ver: 3.3.90)\r\n-- Protobuf compiler version: libprotoc 3.8.0\r\n\r\n-- Found Protobuf: /usr/local/lib/libprotobuf.so;-lpthread (found version \"3.8.0\")\r\n-- Protobuf compiler version: libprotoc 3.8.0\r\n\r\n-- Found Protobuf: /usr/local/lib/libprotobuf.so;-lpthread;-lpthread (found version \"3.8.0\")\r\n-- Using protobuf 3.8.0\r\n-- Protobuf_PROTOC_EXECUTABLE: /usr/local/bin/protoc\r\n-- Found Tensorflow, inc: /usr/local/include/google/tensorflow, lib: /usr/local/lib/libtensorflow_all.so\r\n-- PROTO_FILES: /home/yiakwy/WorkSpace/Github/SEMANTIC_SLAM/proto/runtime_block.proto\r\n-- hw_proto_srcs: /home/yiakwy/WorkSpace/Github/SEMANTIC_SLAM/build/proto_codec/runtime_block.pb.cc\r\n-- hw_proto_hdrs: /home/yiakwy/WorkSpace/Github/SEMANTIC_SLAM/build/proto_codec/runtime_block.pb.h\r\n-- PROTOBUF_INCLUDE_DIRS: /usr/local/include\r\n-- PROTOBUF_LIBRARIES: /usr/local/lib/libprotobuf.so\r\n-- -lpthread\r\n-- -lpthread\r\n-- models PYTHON_INCLUDE_DIR: /home/yiakwy/anaconda3/envs/py36/include/python3.6m\r\n-- models PYTHON_LIBRARY: /home/yiakwy/anaconda3/envs/py36/lib/libpython3.6m.so.1.0\r\n-- PYTHONHOME: /home/yiakwy/anaconda3/envs/py36\r\n-- Configuring done\r\n-- Generating done\r\n-- Build files have been written to: /home/yiakwy/WorkSpace/Github/SEMANTIC_SLAM/build\r\n\r\n```\r\n\r\nHowever when I try to make it, something goes wrong with Eigen interface:\r\n\r\n```text\r\n\u25b6 make\r\n[ 50%] Built target base\r\n[ 62%] Building CXX object modules/models/CMakeFiles/models.dir/main.cpp.o\r\nIn file included from /usr/local/include/google/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:42:0,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/numeric_types.h:24,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/allocator.h:26,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/tensor.h:22,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/public/session.h:24,\r\n                 from /home/yiakwy/WorkSpace/Github/SEMANTIC_SLAM/modules/models/main.cpp:6:\r\n/usr/local/include/google/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/MatMatProductAVX2.h:49:76: error: wrong number of template arguments (5, should be at least 3)\r\n class TensorContractionBlocking<QInt16, QInt16, QInt16, Index, ShardingType> {\r\n                                                                            ^\r\nIn file included from /usr/include/eigen3/unsupported/Eigen/CXX11/Tensor:112:0,\r\n                 from /usr/local/include/google/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/tensor.h:21,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/public/session.h:24,\r\n                 from /home/yiakwy/WorkSpace/Github/SEMANTIC_SLAM/modules/models/main.cpp:6:\r\n/usr/include/eigen3/unsupported/Eigen/CXX11/src/Tensor/TensorContractionBlocking.h:25:7: note: provided for \u2018template<class LhsMapper, class RhsMapper, class Index, int ShardingType> class Eigen::internal::TensorContractionBlocking\u2019\r\n class TensorContractionBlocking {\r\n       ^~~~~~~~~~~~~~~~~~~~~~~~~\r\nIn file included from /usr/local/include/google/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:42:0,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/numeric_types.h:24,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/allocator.h:26,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/tensor.h:22,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/public/session.h:24,\r\n                 from /home/yiakwy/WorkSpace/Github/SEMANTIC_SLAM/modules/models/main.cpp:6:\r\n/usr/local/include/google/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/MatMatProductAVX2.h:151:42: error: wrong number of template arguments (9, should be at least 6)\r\n                      Conjugate, PanelMode> {\r\n                                          ^\r\nIn file included from /usr/include/eigen3/unsupported/Eigen/CXX11/../../../Eigen/Core:429:0,\r\n                 from /usr/include/eigen3/unsupported/Eigen/CXX11/Tensor:14,\r\n                 from /usr/local/include/google/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/tensor.h:21,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/public/session.h:24,\r\n                 from /home/yiakwy/WorkSpace/Github/SEMANTIC_SLAM/modules/models/main.cpp:6:\r\n/usr/include/eigen3/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/BlasUtil.h:28:8: note: provided for \u2018template<class Scalar, class Index, class DataMapper, int Pack1, int Pack2, int StorageOrder, bool Conjugate, bool PanelMode> struct Eigen::internal::gemm_pack_lhs\u2019\r\n struct gemm_pack_lhs;\r\n        ^~~~~~~~~~~~~\r\nIn file included from /usr/local/include/google/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:42:0,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/numeric_types.h:24,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/allocator.h:26,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/tensor.h:22,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/public/session.h:24,\r\n                 from /home/yiakwy/WorkSpace/Github/SEMANTIC_SLAM/modules/models/main.cpp:6:\r\n/usr/local/include/google/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/MatMatProductAVX2.h:160:76: error: wrong number of template arguments (9, should be at least 6)\r\n                                      QInt16, ColMajor, Conjugate, PanelMode>::\r\n                                                                            ^\r\nIn file included from /usr/include/eigen3/unsupported/Eigen/CXX11/../../../Eigen/Core:429:0,\r\n                 from /usr/include/eigen3/unsupported/Eigen/CXX11/Tensor:14,\r\n                 from /usr/local/include/google/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/tensor.h:21,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/public/session.h:24,\r\n                 from /home/yiakwy/WorkSpace/Github/SEMANTIC_SLAM/modules/models/main.cpp:6:\r\n/usr/include/eigen3/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/BlasUtil.h:28:8: note: provided for \u2018template<class Scalar, class Index, class DataMapper, int Pack1, int Pack2, int StorageOrder, bool Conjugate, bool PanelMode> struct Eigen::internal::gemm_pack_lhs\u2019\r\n struct gemm_pack_lhs;\r\n        ^~~~~~~~~~~~~\r\nIn file included from /usr/local/include/google/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:42:0,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/numeric_types.h:24,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/allocator.h:26,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/tensor.h:22,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/public/session.h:24,\r\n                 from /home/yiakwy/WorkSpace/Github/SEMANTIC_SLAM/modules/models/main.cpp:6:\r\n/usr/local/include/google/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/MatMatProductAVX2.h:162:38: error: \u2018void Eigen::internal::operator()(Eigen::QInt16*, const DataMapper&, Index, Index, Index, Index)\u2019 must be a nonstatic member function\r\n            Index stride, Index offset) {\r\n                                      ^\r\n/usr/local/include/google/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/MatMatProductAVX2.h:549:24: error: wrong number of template arguments (5, should be at least 3)\r\n     Index, ShardingType> {\r\n                        ^\r\nIn file included from /usr/include/eigen3/unsupported/Eigen/CXX11/Tensor:112:0,\r\n                 from /usr/local/include/google/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/tensor.h:21,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/public/session.h:24,\r\n                 from /home/yiakwy/WorkSpace/Github/SEMANTIC_SLAM/modules/models/main.cpp:6:\r\n/usr/include/eigen3/unsupported/Eigen/CXX11/src/Tensor/TensorContractionBlocking.h:25:7: note: provided for \u2018template<class LhsMapper, class RhsMapper, class Index, int ShardingType> class Eigen::internal::TensorContractionBlocking\u2019\r\n class TensorContractionBlocking {\r\n       ^~~~~~~~~~~~~~~~~~~~~~~~~\r\nIn file included from /usr/local/include/google/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:42:0,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/numeric_types.h:24,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/allocator.h:26,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/tensor.h:22,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/public/session.h:24,\r\n                 from /home/yiakwy/WorkSpace/Github/SEMANTIC_SLAM/modules/models/main.cpp:6:\r\n/usr/local/include/google/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/MatMatProductAVX2.h:1793:42: error: wrong number of template arguments (9, should be at least 6)\r\n                      Conjugate, PanelMode> {\r\n                                          ^\r\nIn file included from /usr/include/eigen3/unsupported/Eigen/CXX11/../../../Eigen/Core:429:0,\r\n                 from /usr/include/eigen3/unsupported/Eigen/CXX11/Tensor:14,\r\n                 from /usr/local/include/google/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/tensor.h:21,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/public/session.h:24,\r\n                 from /home/yiakwy/WorkSpace/Github/SEMANTIC_SLAM/modules/models/main.cpp:6:\r\n/usr/include/eigen3/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/BlasUtil.h:28:8: note: provided for \u2018template<class Scalar, class Index, class DataMapper, int Pack1, int Pack2, int StorageOrder, bool Conjugate, bool PanelMode> struct Eigen::internal::gemm_pack_lhs\u2019\r\n struct gemm_pack_lhs;\r\n        ^~~~~~~~~~~~~\r\nIn file included from /usr/local/include/google/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:42:0,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/numeric_types.h:24,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/allocator.h:26,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/tensor.h:22,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/public/session.h:24,\r\n                 from /home/yiakwy/WorkSpace/Github/SEMANTIC_SLAM/modules/models/main.cpp:6:\r\n/usr/local/include/google/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/MatMatProductAVX2.h:1802:75: error: wrong number of template arguments (9, should be at least 6)\r\n                                      QInt8, ColMajor, Conjugate, PanelMode>::\r\n                                                                           ^\r\nIn file included from /usr/include/eigen3/unsupported/Eigen/CXX11/../../../Eigen/Core:429:0,\r\n                 from /usr/include/eigen3/unsupported/Eigen/CXX11/Tensor:14,\r\n                 from /usr/local/include/google/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/tensor.h:21,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/public/session.h:24,\r\n                 from /home/yiakwy/WorkSpace/Github/SEMANTIC_SLAM/modules/models/main.cpp:6:\r\n/usr/include/eigen3/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/BlasUtil.h:28:8: note: provided for \u2018template<class Scalar, class Index, class DataMapper, int Pack1, int Pack2, int StorageOrder, bool Conjugate, bool PanelMode> struct Eigen::internal::gemm_pack_lhs\u2019\r\n struct gemm_pack_lhs;\r\n        ^~~~~~~~~~~~~\r\nIn file included from /usr/local/include/google/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:42:0,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/numeric_types.h:24,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/allocator.h:26,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/tensor.h:22,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/public/session.h:24,\r\n                 from /home/yiakwy/WorkSpace/Github/SEMANTIC_SLAM/modules/models/main.cpp:6:\r\n/usr/local/include/google/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/MatMatProductAVX2.h:1804:38: error: \u2018void Eigen::internal::operator()(Eigen::QInt8*, const DataMapper&, Index, Index, Index, Index)\u2019 must be a nonstatic member function\r\n            Index stride, Index offset) {\r\n                                      ^\r\nIn file included from /usr/include/eigen3/unsupported/Eigen/CXX11/Tensor:105:0,\r\n                 from /usr/local/include/google/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/tensor.h:21,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/public/session.h:24,\r\n                 from /home/yiakwy/WorkSpace/Github/SEMANTIC_SLAM/modules/models/main.cpp:6:\r\n/usr/include/eigen3/unsupported/Eigen/CXX11/src/Tensor/TensorEvaluator.h: In instantiation of \u2018struct Eigen::TensorEvaluator<const Eigen::TensorMap<Eigen::TensorFixedSize<float, Eigen::Sizes<>, 1, long int>, 16, Eigen::MakePointer>, Eigen::DefaultDevice>\u2019:\r\n/usr/include/eigen3/unsupported/Eigen/CXX11/src/Tensor/TensorForcedEval.h:96:65:   required from \u2018struct Eigen::TensorEvaluator<const Eigen::TensorForcedEvalOp<const Eigen::TensorMap<Eigen::TensorFixedSize<float, Eigen::Sizes<>, 1, long int>, 16, Eigen::MakePointer>, Eigen::MakePointer>, Eigen::DefaultDevice>\u2019\r\n/usr/include/eigen3/unsupported/Eigen/CXX11/src/Tensor/TensorIO.h:61:42:   required from \u2018std::ostream& Eigen::operator<<(std::ostream&, const Eigen::TensorBase<Derived, 0>&) [with T = Eigen::TensorMap<Eigen::TensorFixedSize<float, Eigen::Sizes<>, 1, long int>, 16, Eigen::MakePointer>; std::ostream = std::basic_ostream<char>]\u2019\r\n/home/yiakwy/WorkSpace/Github/SEMANTIC_SLAM/modules/models/main.cpp:48:54:   required from here\r\n/usr/include/eigen3/unsupported/Eigen/CXX11/src/Tensor/TensorEvaluator.h:162:71: warning: ignoring attributes on template argument \u2018Eigen::PacketType<float, Eigen::DefaultDevice>::type {aka __vector(8) float}\u2019 [-Wignored-attributes]\r\n     PacketAccess = (internal::unpacket_traits<PacketReturnType>::size > 1),\r\n                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~\r\nIn file included from /usr/include/eigen3/unsupported/Eigen/CXX11/Tensor:133:0,\r\n                 from /usr/local/include/google/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/tensor.h:21,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/public/session.h:24,\r\n                 from /home/yiakwy/WorkSpace/Github/SEMANTIC_SLAM/modules/models/main.cpp:6:\r\n/usr/include/eigen3/unsupported/Eigen/CXX11/src/Tensor/TensorForcedEval.h: In instantiation of \u2018const int Eigen::TensorEvaluator<const Eigen::TensorForcedEvalOp<const Eigen::TensorMap<Eigen::TensorFixedSize<float, Eigen::Sizes<>, 1, long int>, 16, Eigen::MakePointer>, Eigen::MakePointer>, Eigen::DefaultDevice>::PacketSize\u2019:\r\n/usr/include/eigen3/unsupported/Eigen/CXX11/src/Tensor/TensorForcedEval.h:104:32:   required from \u2018struct Eigen::TensorEvaluator<const Eigen::TensorForcedEvalOp<const Eigen::TensorMap<Eigen::TensorFixedSize<float, Eigen::Sizes<>, 1, long int>, 16, Eigen::MakePointer>, Eigen::MakePointer>, Eigen::DefaultDevice>\u2019\r\n/usr/include/eigen3/unsupported/Eigen/CXX11/src/Tensor/TensorIO.h:61:42:   required from \u2018std::ostream& Eigen::operator<<(std::ostream&, const Eigen::TensorBase<Derived, 0>&) [with T = Eigen::TensorMap<Eigen::TensorFixedSize<float, Eigen::Sizes<>, 1, long int>, 16, Eigen::MakePointer>; std::ostream = std::basic_ostream<char>]\u2019\r\n/home/yiakwy/WorkSpace/Github/SEMANTIC_SLAM/modules/models/main.cpp:48:54:   required from here\r\n/usr/include/eigen3/unsupported/Eigen/CXX11/src/Tensor/TensorForcedEval.h:100:20: warning: ignoring attributes on template argument \u2018Eigen::PacketType<float, Eigen::DefaultDevice>::type {aka __vector(8) float}\u2019 [-Wignored-attributes]\r\n   static const int PacketSize = internal::unpacket_traits<PacketReturnType>::size;\r\n                    ^~~~~~~~~~\r\nIn file included from /usr/include/eigen3/unsupported/Eigen/CXX11/Tensor:139:0,\r\n                 from /usr/local/include/google/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/framework/tensor.h:21,\r\n                 from /usr/local/include/google/tensorflow/tensorflow/core/public/session.h:24,\r\n                 from /home/yiakwy/WorkSpace/Github/SEMANTIC_SLAM/modules/models/main.cpp:6:\r\n/usr/include/eigen3/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h: In instantiation of \u2018static void Eigen::internal::TensorExecutor<Expression, Eigen::DefaultDevice, true>::run(const Expression&, const Eigen::DefaultDevice&) [with Expression = const Eigen::TensorEvalToOp<const Eigen::TensorMap<Eigen::TensorFixedSize<float, Eigen::Sizes<>, 1, long int>, 16, Eigen::MakePointer>, Eigen::MakePointer>]\u2019:\r\n/usr/include/eigen3/unsupported/Eigen/CXX11/src/Tensor/TensorForcedEval.h:128:109:   required from \u2018bool Eigen::TensorEvaluator<const Eigen::TensorForcedEvalOp<ArgType, MakePointer_>, Device>::evalSubExprsIfNeeded(Eigen::TensorEvaluator<const Eigen::TensorForcedEvalOp<ArgType, MakePointer_>, Device>::CoeffReturnType*) [with ArgType = const Eigen::TensorMap<Eigen::TensorFixedSize<float, Eigen::Sizes<>, 1, long int>, 16, Eigen::MakePointer>; Device = Eigen::DefaultDevice; MakePointer_ = Eigen::MakePointer; Eigen::TensorEvaluator<const Eigen::TensorForcedEvalOp<ArgType, MakePointer_>, Device>::CoeffReturnType = float]\u2019\r\n/usr/include/eigen3/unsupported/Eigen/CXX11/src/Tensor/TensorIO.h:66:3:   required from \u2018std::ostream& Eigen::operator<<(std::ostream&, const Eigen::TensorBase<Derived, 0>&) [with T = Eigen::TensorMap<Eigen::TensorFixedSize<float, Eigen::Sizes<>, 1, long int>, 16, Eigen::MakePointer>; std::ostream = std::basic_ostream<char>]\u2019\r\n/home/yiakwy/WorkSpace/Github/SEMANTIC_SLAM/modules/models/main.cpp:48:54:   required from here\r\n/usr/include/eigen3/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h:61:17: warning: ignoring attributes on template argument \u2018Eigen::TensorEvaluator<const Eigen::TensorEvalToOp<const Eigen::TensorMap<Eigen::TensorFixedSize<float, Eigen::Sizes<>, 1, long int>, 16, Eigen::MakePointer>, Eigen::MakePointer>, Eigen::DefaultDevice>::PacketReturnType {aka __vector(8) float}\u2019 [-Wignored-attributes]\r\n       const int PacketSize = unpacket_traits<typename TensorEvaluator<Expression, DefaultDevice>::PacketReturnType>::size;\r\n                 ^~~~~~~~~~\r\ncc1plus: warning: unrecognized command line option \u2018-Wno-deprecated-declaration\u2019\r\nmodules/models/CMakeFiles/models.dir/build.make:62: recipe for target 'modules/models/CMakeFiles/models.dir/main.cpp.o' failed\r\nmake[2]: *** [modules/models/CMakeFiles/models.dir/main.cpp.o] Error 1\r\nCMakeFiles/Makefile2:1163: recipe for target 'modules/models/CMakeFiles/models.dir/all' failed\r\nmake[1]: *** [modules/models/CMakeFiles/models.dir/all] Error 2\r\nMakefile:140: recipe for target 'all' failed\r\nmake: *** [all] Error 2\r\n\r\n```\r\n\r\nI have already downloaded and installed Eigen specified in `tensorlfow/workspace.bzl` (3.9.0, I have printed the version I extracted from \"Eigen/src/Core/util/Macros.h\")\r\n\r\nHowever after searching a while, only to find some interfaces like \"TensorContractionBlocking\" defined in installed eigen3 (/usr/include/eigen3/unsupported/Eigen/CXX11/src/Tensor/TensorContractionBlocking.h) was different from the google version (/usr/local/include/google/tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/MatMatProductAVX2.h)\r\n\r\nHere is the captured snapshot from screen:\r\n\r\n![Screenshot 2020-04-05 at 6 03 36 PM](https://user-images.githubusercontent.com/61530411/78472569-8fbe2d00-776c-11ea-890c-fbdde9569b42.png)\r\n\r\n\r\n**Any other info / logs**\r\nSee above\r\n\r\n**Conclution**\r\n\r\nSince the source codes are incorrect, It is impossible to compile it in my cmake project. Any help ?\r\n", "comments": ["@gadagashwini \r\nI have resolved the problem by manually adding the following path to my FindEigen3.cmake module:\r\n\r\n```txt\r\n~  44 # set EIGEN3_INCLUDE_DIR\r\n~  45 # this is where I installed bazel eigen refered by tensorflow 2.2.0rc\r\n~  46 unset(EIGEN3_FOUND)\r\n~  47 # /usr/include/eigen3, ceres depended eigen\r\n~  48 # /usr/local/include/eigen3/, extracted from bazel archive\r\n~  49 # set(EIGEN3_INCLUDE_DIR \"/usr/local/include/eigen3\")\r\n~  50 set (EIGEN3_INCLUDE_DIR \"/home/yiakwy/.cache/bazel/_bazel_yiakwy/729cb3000927cd0e322e439998a82145/external/eigen_archive\")\r\n~  51 _eigen3_check_version()\r\n~  52 set(EIGEN3_FOUND ${EIGEN3_VERSION_OK})\r\n```\r\n\r\nIt seems that the released cmake-3.3.9 used by tensorflow-2.2.0-rc is patched. Only the correct version does not help. Hence I dig into the bazel building system and find the relevant eigen3 files used by tensorflow, it shows that they share template with same number of 5 arguments.\r\n\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38237\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38237\">No</a>\n", "@yiakwy-enterprise-roborock, Glad it worked. ", "@yiakwy-enterprise-roborock\r\nHi, I encounter exactly the same issue with what you described. Can you tell me how you you solve this problem in details. I didn't catch your points clearly. Thanks.\r\n> @gadagashwini\r\n> I have resolved the problem by manually adding the following path to my FindEigen3.cmake module:\r\n> \r\n> ```\r\n> ~  44 # set EIGEN3_INCLUDE_DIR\r\n> ~  45 # this is where I installed bazel eigen refered by tensorflow 2.2.0rc\r\n> ~  46 unset(EIGEN3_FOUND)\r\n> ~  47 # /usr/include/eigen3, ceres depended eigen\r\n> ~  48 # /usr/local/include/eigen3/, extracted from bazel archive\r\n> ~  49 # set(EIGEN3_INCLUDE_DIR \"/usr/local/include/eigen3\")\r\n> ~  50 set (EIGEN3_INCLUDE_DIR \"/home/yiakwy/.cache/bazel/_bazel_yiakwy/729cb3000927cd0e322e439998a82145/external/eigen_archive\")\r\n> ~  51 _eigen3_check_version()\r\n> ~  52 set(EIGEN3_FOUND ${EIGEN3_VERSION_OK})\r\n> ```\r\n> \r\n> It seems that the released cmake-3.3.9 used by tensorflow-2.2.0-rc is patched. Only the correct version does not help. Hence I dig into the bazel building system and find the relevant eigen3 files used by tensorflow, it shows that they share template with same number of 5 arguments.\r\n\r\n"]}, {"number": 38236, "title": "very slow training if recurrent_dropout above 0.0 in LSTM keras using GPU", "body": "**System information** \r\n- Have I written custom code: yes\r\n- OS Platform and Distribution: Linux Mint 19\r\n- TensorFlow installed from: pip ( `pip install tensorflow-gpu` )\r\n- TensorFlow version: 2.1.0 (same issue in 2.0.0 though)\r\n\r\n- CUDA/cuDNN version: 10.2\r\n- GPU model and memory: RTX 2080 8GB (same issue on RTX 2080Ti 11GB )\r\n\r\n\r\nHi!\r\n\r\nWhen I use LSTM `recurrent_dropout` not set to 0.0, training time is very long (~25 times longer compared to `recurrent_dropout` 0.0). I suppose it shouldn't slow down the training that much I have the same issue on two separate machines\r\n\r\nFor example\r\n\r\n`model.add(layers.LSTM(128, recurrent_dropout=0.0))` training time ~40 sec\r\n`model.add(layers.LSTM(128, recurrent_dropout=0.1))` training time is above ~17 min.\r\n\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers\r\nimport tensorflow\r\nimport os\r\nos.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"\r\n\r\n\r\nmodel = tf.keras.Sequential()\r\nmodel.add(layers.Embedding(input_dim=1000, output_dim=64))\r\nmodel.add(layers.LSTM(128, recurrent_dropout=0.1))\r\nmodel.add(layers.Dense(1))\r\n\r\nmodel.compile('sgd', 'mse')\r\nmodel.summary()\r\n\r\nx = np.random.rand(100000, 1000)\r\ny = np.random.randint(1, size = (100000,1))\r\nmodel.fit(x,y,10)\r\n```\r\n", "comments": ["i have replicated the above mentioned issue, please find the gist here for [recurrent_dropout=0.0](https://colab.sandbox.google.com/gist/Saduf2019/901bc99480dfde6ac22aa608cf407a6d/untitled127.ipynb) and [recurrent_dropout=0.1](https://colab.sandbox.google.com/gist/Saduf2019/e5a231833e080661b48e11d83593336c/untitled126.ipynb)", "This is expected since recurrent_dropout will force the LSTM to use generic kernel, rather than the performant cudnn kernel on GPU.\r\n\r\nPlease see the section of LSTM docstring about the restriction of cudnn kernel usage in https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM"]}, {"number": 38235, "title": "Tensorflow and Pip Error", "body": "**System information**\r\n- Windows 10 Basic Updated \r\n- TensorFlow installed from (source or binary): Anaconda 4.8.2\r\n- TensorFlow version: 2.1\r\n- Python version: 3.5\r\n- Installed using Pip\r\n\r\n```\r\n(tensorflow1) c:\\>pip install --ignore-installed --upgrade tensorflow\r\nCollecting tensorflow\r\n  Downloading tensorflow-2.1.0-cp35-cp35m-win_amd64.whl (355.8 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588                          | 67.7 MB 62 kB/s eta 1:16:58ERROR: Exception:\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\acer\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 425, in _error_catcher\r\n    yield\r\n  File \"c:\\users\\acer\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 507, in read\r\n    data = self._fp.read(amt) if not fp_closed else b\"\"\r\n  File \"c:\\users\\acer\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 62, in read\r\n    data = self.__fp.read(amt)\r\n  File \"c:\\users\\acer\\anaconda3\\envs\\tensorflow1\\lib\\http\\client.py\", line 448, in read\r\n    n = self.readinto(b)\r\n  File \"c:\\users\\acer\\anaconda3\\envs\\tensorflow1\\lib\\http\\client.py\", line 488, in readinto\r\n    n = self.fp.readinto(b)\r\n  File \"c:\\users\\acer\\anaconda3\\envs\\tensorflow1\\lib\\socket.py\", line 576, in readinto\r\n    return self._sock.recv_into(b)\r\n  File \"c:\\users\\acer\\anaconda3\\envs\\tensorflow1\\lib\\ssl.py\", line 937, in recv_into\r\n    return self.read(nbytes, buffer)\r\n  File \"c:\\users\\acer\\anaconda3\\envs\\tensorflow1\\lib\\ssl.py\", line 799, in read\r\n    return self._sslobj.read(len, buffer)\r\n  File \"c:\\users\\acer\\anaconda3\\envs\\tensorflow1\\lib\\ssl.py\", line 583, in read\r\n    v = self._sslobj.read(len, buffer)\r\nsocket.timeout: The read operation timed out\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\acer\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 186, in _main\r\n    status = self.run(options, args)\r\n  File \"c:\\users\\acer\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 331, in run\r\n    resolver.resolve(requirement_set)\r\n  File \"c:\\users\\acer\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\pip\\_internal\\legacy_resolve.py\", line 177, in resolve\r\n    discovered_reqs.extend(self._resolve_one(requirement_set, req))\r\n  File \"c:\\users\\acer\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\pip\\_internal\\legacy_resolve.py\", line 333, in _resolve_one\r\n    abstract_dist = self._get_abstract_dist_for(req_to_install)\r\n  File \"c:\\users\\acer\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\pip\\_internal\\legacy_resolve.py\", line 282, in _get_abstract_dist_for\r\n    abstract_dist = self.preparer.prepare_linked_requirement(req)\r\n  File \"c:\\users\\acer\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 482, in prepare_linked_requirement\r\n    hashes=hashes,\r\n  File \"c:\\users\\acer\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 287, in unpack_url\r\n    hashes=hashes,\r\n  File \"c:\\users\\acer\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 159, in unpack_http_url\r\n    link, downloader, temp_dir.path, hashes\r\n  File \"c:\\users\\acer\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 303, in _download_http_url\r\n    for chunk in download.chunks:\r\n  File \"c:\\users\\acer\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\pip\\_internal\\utils\\ui.py\", line 160, in iter\r\n    for x in it:\r\n  File \"c:\\users\\acer\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 39, in response_chunks\r\n    decode_content=False,\r\n  File \"c:\\users\\acer\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 564, in stream\r\n    data = self.read(amt=amt, decode_content=decode_content)\r\n  File \"c:\\users\\acer\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 529, in read\r\n    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\r\n  File \"c:\\users\\acer\\anaconda3\\envs\\tensorflow1\\lib\\contextlib.py\", line 77, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"c:\\users\\acer\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 430, in _error_catcher\r\n    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\r\npip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\r\n```\r\n\r\nNew Conda Environment\r\n\r\n```\r\n(base) c:\\>conda create -n tensorflow1 pip python=3.5\r\nCollecting package metadata (current_repodata.json): done\r\nSolving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\r\nCollecting package metadata (repodata.json): done\r\nSolving environment: done\r\n\r\n  added / updated specs:\r\n    - pip\r\n    - python=3.5\r\n\r\nThe following NEW packages will be INSTALLED:\r\n\r\n  certifi            pkgs/main/win-64::certifi-2018.8.24-py35_1\r\n  pip                pkgs/main/win-64::pip-10.0.1-py35_0\r\n  python             pkgs/main/win-64::python-3.5.6-he025d50_0\r\n  setuptools         pkgs/main/win-64::setuptools-40.2.0-py35_0\r\n  vc                 pkgs/main/win-64::vc-14.1-h0510ff6_4\r\n  vs2015_runtime     pkgs/main/win-64::vs2015_runtime-14.16.27012-hf0eaf9b_1\r\n  wheel              pkgs/main/win-64::wheel-0.31.1-py35_0\r\n  wincertstore       pkgs/main/win-64::wincertstore-0.2-py35hfebbdb8_0\r\n\r\n(base) c:\\>activate tensorflow1\r\n```\r\n", "comments": ["This is not a coding issue. It is caused by your network connectivity getting interrupted during a large download. The only option is to retry or download from a different network connection.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38235\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38235\">No</a>\n"]}, {"number": 38234, "title": "ctc_loss compilation failure on TPU", "body": "Hello! I'm trying to compile my simple model with custom loss that uses tf.nn.ctc_loss and get the following error:\r\n```\r\nUnimplementedError: {{function_node __inference_train_function_34365}} Compilation failure: Dynamic input dimension to reshape that is both splitted and combined is not supported: output: f32[1186,36,0], input: f32[1186,<=36,0], input_dim: 1\r\n\t [[{{node gradient_tape/ctc/ctc_loss_dense/strided_slice_2/StridedSliceGrad}}]]\r\n\tTPU compilation failed\r\n\t [[tpu_compile_succeeded_assert/_8793276995691903576/_5]]\r\n```\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): Yes\r\n- OS Platform and Distribution: Colaboratory on *TPU*\r\n- TensorFlow installed from (source or\r\nbinary): binary\r\n- TensorFlow version:  2.2.0-rc2\r\n\r\n\r\n**Loss**:\r\n```\r\nclass CTCLoss(tf.keras.losses.Loss):\r\n    def __init__(self, logits_time_major=False, reduction=tf.keras.losses.Reduction.SUM, name='ctc'):\r\n        super().__init__(reduction=reduction, name=name)\r\n        self.logits_time_major = logits_time_major\r\n\r\n    def call(self, y_true, y_pred):\r\n        y_true = tf.cast(y_true, tf.int32)\r\n        logit_length = tf.fill([tf.shape(y_pred)[0]], tf.shape(y_pred)[1])\r\n        label_length = tf.fill([tf.shape(y_true)[0]], tf.shape(y_true)[1])\r\n        loss = tf.nn.ctc_loss((\r\n            labels=y_true,\r\n            logits=y_pred,\r\n            label_length=label_length,\r\n            logit_length=logit_length,\r\n            logits_time_major=self.logits_time_major,\r\n            blank_index=-1)\r\n        return tf.reduce_mean(loss)\r\n```\r\n\r\n**Model**:\r\n```\r\nclass TestNN(tf.keras.Model):\r\n  def __init__(self):\r\n    super(TestNN, self).__init__()\r\n    self.seq = Sequential()\r\n    self.b_lstm1 = Bidirectional(LSTM(128, return_sequences=True, implementation=2), input_shape=(None, 13))\r\n    self.b_lstm2 = Bidirectional(LSTM(128, return_sequences=True, implementation=2))\r\n    self.tmd = TimeDistributed(Dense(len(inv_mapping) + 2))\r\n  \r\n  def call(self, x):\r\n    x = self.seq(x)\r\n    x = self.b_lstm1(x)\r\n    x = self.b_lstm2(x)\r\n    x = self.tmd(x)\r\n    return x\r\n```\r\n\r\n**Compilation model**:\r\n```\r\nstrategy = tf.distribute.experimental.TPUStrategy(resolver)\r\nwith strategy.scope():\r\n  model = TestNN()\r\n  model.compile(optimizer=tf.optimizers.Adam(1e-2), loss=CTCLoss())\r\n```\r\n\r\n**I got the error when running**:\r\n```\r\nmodel.fit(input_tensor, label_tensor, batch_size=36*8, epochs=1)\r\n```\r\n- input_tensor is  tf.Tensor with **shape**=(2241, 1186, 13), **dtype**=float32\r\n- label_tensor is tf.Tensor with **shape**=(2241, 59), **dtype**=int32\r\n\r\nIt's a bug, or I'm doing something wrong?", "comments": ["Sorry. It's my mistake. Now I use tf.data, and it seems OK.\r\nThis [post](https://blog.tensorflow.org/2019/01/keras-on-tpus-in-colab.html) is helpful to me.\r\n\r\nIf you want to use TPU, then you must prepare your data correctly. It is an important thing.\r\n\r\nData preparation:\r\n```\r\nds = tf.data.Dataset.from_tensor_slices((input_tensor, label_tensor))\r\ntest_dataset = ds.batch(256*8, drop_remainder=True)\r\n```\r\n\r\nModel training:\r\n```\r\nhistory = model.fit(test_dataset, batch_size=128 * strategy.num_replicas_in_sync, epochs=128)\r\n```", "> Sorry. It's my mistake. Now I use tf.data, and it seems OK.\r\n> This [post](https://blog.tensorflow.org/2019/01/keras-on-tpus-in-colab.html) is helpful to me.\r\n\r\n@haroldpnn,\r\nIs this still an issue? Please feel free to close the issue if resolved. Thanks!"]}, {"number": 38233, "title": "ValueError: No gradients provided for any variable: ['conv2d/kernel:0', 'conv2d/bias:0',", "body": "**System information** \r\nColab tensorflow 2.2.0\r\n\r\n**Describe the current behavior**:\r\nI faced this error when i tried   to solve my own data issues, which is multiple label semantic segmentations. When I ran on Jupiter notebook on my local Mac Book with Keras installation (not tf.keras but keras only), model could train normally as expected as below. \r\n\r\n![image](https://user-images.githubusercontent.com/43133053/78468464-fdf1f800-774a-11ea-9dc3-315a49fc430e.png)\r\n \r\nHowever, I stopped training the whole model on local Mac Book due to its limited memory and capability and I switched to Colab, **Tensorflow version:  2.2.0-rc2** and faced this error:\r\n`    ValueError: No gradients provided for any variable: ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'conv2d_3/kernel:0', 'conv2d_3/bias:0', 'conv2d_4/kernel:0', 'conv2d_4/bias:0', 'conv2d_5/kernel:0', 'conv2d_5/bias:0', 'conv2d_6/kernel:0', 'conv2d_6/bias:0', 'conv2d_7/kernel:0', 'conv2d_7/bias:0', 'conv2d_8/kernel:0', 'conv2d_8/bias:0', 'conv2d_9/kernel:0', 'conv2d_9/bias:0', 'conv2d_transpose/kernel:0', 'conv2d_transpose/bias:0', 'conv2d_10/kernel:0', 'conv2d_10/bias:0', 'conv2d_11/kernel:0', 'conv2d_11/bias:0', 'conv2d_transpose_1/kernel:0', 'conv2d_transpose_1/bias:0', 'conv2d_12/kernel:0', 'conv2d_12/bias:0', 'conv2d_13/kernel:0', 'conv2d_13/bias:0', 'conv2d_transpose_2/kernel:0', 'conv2d_transpose_2/bias:0', 'conv2d_14/kernel:0', 'conv2d_14/bias:0', 'conv2d_15/kernel:0', 'conv2d_15/bias:0', 'conv2d_transpose_3/kernel:0', 'conv2d_transpose_3/bias:0', 'conv2d_16/kernel:0', 'conv2d_16/bias:0', 'conv2d_17/kernel:0', 'conv2d_17/bias:0', 'conv2d_18/kernel:0', 'conv2d_18/bias:0'].`\r\n\r\n**Full error:**\r\n\r\nEpoch 1/40\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-27-f05367a1db71> in <module>()\r\n      5     callbacks=callbacks,\r\n      6     validation_data=valid_dataloader,\r\n----> 7     validation_steps=(no_of_validation_images//1),verbose=1\r\n      8 )\r\n\r\n10 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)\r\n     64   def _method_wrapper(self, *args, **kwargs):\r\n     65     if not self._in_multi_worker_mode():  # pylint: disable=protected-access\r\n---> 66       return method(self, *args, **kwargs)\r\n     67 \r\n     68     # Running inside `run_distribute_coordinator` already.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    783                 batch_size=batch_size):\r\n    784               callbacks.on_train_batch_begin(step)\r\n--> 785               tmp_logs = train_function(iterator)\r\n    786               # Catch OutOfRangeError for Datasets of unknown size.\r\n    787               # This blocks until the batch has finished executing.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    578         xla_context.Exit()\r\n    579     else:\r\n--> 580       result = self._call(*args, **kwds)\r\n    581 \r\n    582     if tracing_count == self._get_tracing_count():\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    625       # This is the first call of __call__, so we have to initialize.\r\n    626       initializers = []\r\n--> 627       self._initialize(args, kwds, add_initializers_to=initializers)\r\n    628     finally:\r\n    629       # At this point we know that the initialization is complete (or less\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)\r\n    504     self._concrete_stateful_fn = (\r\n    505         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n--> 506             *args, **kwds))\r\n    507 \r\n    508     def invalid_creator_scope(*unused_args, **unused_kwds):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n   2444       args, kwargs = None, None\r\n   2445     with self._lock:\r\n-> 2446       graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n   2447     return graph_function\r\n   2448 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   2775 \r\n   2776       self._function_cache.missed.add(call_context_key)\r\n-> 2777       graph_function = self._create_graph_function(args, kwargs)\r\n   2778       self._function_cache.primary[cache_key] = graph_function\r\n   2779       return graph_function, args, kwargs\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   2665             arg_names=arg_names,\r\n   2666             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 2667             capture_by_value=self._capture_by_value),\r\n   2668         self._function_attributes,\r\n   2669         # Tell the ConcreteFunction to clean up its graph once it goes out of\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    979         _, original_func = tf_decorator.unwrap(python_func)\r\n    980 \r\n--> 981       func_outputs = python_func(*func_args, **func_kwargs)\r\n    982 \r\n    983       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)\r\n    439         # __wrapped__ allows AutoGraph to swap in a converted function. We give\r\n    440         # the function a weak reference to itself to avoid a reference cycle.\r\n--> 441         return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    442     weak_wrapped_fn = weakref.ref(wrapped_fn)\r\n    443 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    966           except Exception as e:  # pylint:disable=broad-except\r\n    967             if hasattr(e, \"ag_error_metadata\"):\r\n--> 968               raise e.ag_error_metadata.to_exception(e)\r\n    969             else:\r\n    970               raise\r\n\r\nValueError: in user code:\r\n\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:505 train_function  *\r\n        outputs = self.distribute_strategy.run(\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\r\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\r\n        return self._call_for_each_replica(fn, args, kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\r\n        return fn(*args, **kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:475 train_step  **\r\n        self.trainable_variables)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1741 _minimize\r\n        trainable_variables))\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:525 _aggregate_gradients\r\n        filtered_grads_and_vars = _filter_grads(grads_and_vars)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:1203 _filter_grads\r\n        ([v.name for _, v in grads_and_vars],))\r\n\r\n    ValueError: No gradients provided for any variable: ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'conv2d_3/kernel:0', 'conv2d_3/bias:0', 'conv2d_4/kernel:0', 'conv2d_4/bias:0', 'conv2d_5/kernel:0', 'conv2d_5/bias:0', 'conv2d_6/kernel:0', 'conv2d_6/bias:0', 'conv2d_7/kernel:0', 'conv2d_7/bias:0', 'conv2d_8/kernel:0', 'conv2d_8/bias:0', 'conv2d_9/kernel:0', 'conv2d_9/bias:0', 'conv2d_transpose/kernel:0', 'conv2d_transpose/bias:0', 'conv2d_10/kernel:0', 'conv2d_10/bias:0', 'conv2d_11/kernel:0', 'conv2d_11/bias:0', 'conv2d_transpose_1/kernel:0', 'conv2d_transpose_1/bias:0', 'conv2d_12/kernel:0', 'conv2d_12/bias:0', 'conv2d_13/kernel:0', 'conv2d_13/bias:0', 'conv2d_transpose_2/kernel:0', 'conv2d_transpose_2/bias:0', 'conv2d_14/kernel:0', 'conv2d_14/bias:0', 'conv2d_15/kernel:0', 'conv2d_15/bias:0', 'conv2d_transpose_3/kernel:0', 'conv2d_transpose_3/bias:0', 'conv2d_16/kernel:0', 'conv2d_16/bias:0', 'conv2d_17/kernel:0', 'conv2d_17/bias:0', 'conv2d_18/kernel:0', 'conv2d_18/bias:0'].\r\n\r\n\r\n**Describe the expected behavior**:\r\nCould train model\r\n\r\n**Standalone code to reproduce the issue** \r\n\r\n\r\nThank you for looking into this", "comments": ["@phuongchi911, Thanks for reporting this issue. \r\nCan you provide the access to the dataset. Thanks", "> @phuongchi911, Thanks for reporting this issue.\r\n> Can you provide the access to the dataset. Thanks\r\n\r\n@gadagashwini thanks so much for fast response. Please kindly refer to this link for the dataset \r\n\r\nI am looking forward to your advice. ", "@phuongchi911, I tried to replicate the issue but getting different error. \r\nPLease take a look at the [gist](https://colab.sandbox.google.com/gist/gadagashwini/3e94edfb9e87d78e7165272011bab509/untitled498.ipynb) and confirm the issue. Thanks", "\r\n\r\n> @phuongchi911, I tried to replicate the issue but getting different error.\r\n> PLease take a look at the [gist](https://colab.sandbox.google.com/gist/gadagashwini/3e94edfb9e87d78e7165272011bab509/untitled498.ipynb) and confirm the issue. Thanks\r\n\r\n@gadagashwini may you confirm if this is the error u see? If yes, please help to restart the runtime and run all over again after u installed the segmentation model above. Error will dissappear. \r\n\r\n![image](https://user-images.githubusercontent.com/43133053/78866603-4a527600-7a72-11ea-92b5-7e883945c6fb.png)\r\n\r\n\r\nThe error I am facing is when I was trying to run this block of code below to train my model which I mentioned in my first post. \r\n\r\n\r\n![image](https://user-images.githubusercontent.com/43133053/78866702-7c63d800-7a72-11ea-9424-c1b3316b9eb2.png)\r\n\r\nI did not face this error if I use keras only on jupyter notebook on my local Macbook. But since my Mac is not strong enough to train the whole model, so  i stopped and swtiched to Colab and face the error. Thank you very much for looking into this\r\n\r\n\r\n\r\n\r\n", "@phuongchi911, After installing segmentation-models still it is giving `no module named 'segmentation_models'`. Please take a look at [gist](https://colab.sandbox.google.com/gist/gadagashwini/3e94edfb9e87d78e7165272011bab509/untitled498.ipynb). Thanks", "> @phuongchi911, After installing segmentation-models still it is giving `no module named 'segmentation_models'`. Please take a look at [gist](https://colab.sandbox.google.com/gist/gadagashwini/3e94edfb9e87d78e7165272011bab509/untitled498.ipynb). Thanks\r\n\r\n@gadagashwini  yes what i did to avoid that error was\r\n\r\n1/after first installation when u ran this line of code `import segmentation_models as sm` there would prompt error below\r\n\r\n![image](https://user-images.githubusercontent.com/43133053/79226050-508c8c00-7e90-11ea-931e-cd4f9f809db4.png)\r\n2/ So I restarted the run time, run again without doing the installation the model. Then there was no error\r\n\r\n![image](https://user-images.githubusercontent.com/43133053/79226157-7c0f7680-7e90-11ea-8485-cba2521b4a07.png)\r\n\r\nAnd the only error i encountered was when i tried to run the training code block as below\r\n\r\n![image](https://user-images.githubusercontent.com/43133053/79226225-99444500-7e90-11ea-92a6-6902ecf8a543.png)\r\n\r\n\r\nMay you kindly see the [gist](https://colab.research.google.com/gist/phuongchi911/e1728367ab59ae941b0dc343bbc74306/untitled498.ipynb)\r\n. I ran it directly on the gist u shared.\r\n\r\nThank you very much\r\n", "Hi, I am also experiencing this issue. I could not find any reason why this is happening. ", "Also here with Transformer model using fit().\r\n\r\nI saw this [code](https://github.com/tensorflow/tensorflow/issues/28836):\r\n`with tf.GradientTape() as tape`\r\n\r\nto apply apply_gradients.. inside a train_step function.\r\nBut using fit(), I don't know how", "I have not tried it yet, but TF 2.2 has a new api to overwrite the training step which contains the `tf.GradientTape()`. Accessing the gradients there would be possible.\r\n\r\nfrom https://github.com/tensorflow/tensorflow/releases:\r\n\r\n    You can now use custom training logic with Model.fit by overriding Model.train_step.", "Yes i have been trying to figure out how to \r\n\r\n> Also here with Transformer model using fit().\r\n> \r\n> I saw this [code](https://github.com/tensorflow/tensorflow/issues/28836):\r\n> `with tf.GradientTape() as tape`\r\n> \r\n> to apply apply_gradients.. inside a train_step function.\r\n> But using fit(), I don't know how\r\n\r\nYes I also came across with that code but still not clear how to apply it to my problem. From my understanding it is maybe due to the dead gradients. \r\n\r\nNot sure if the tensorflow support person will have any advise on this problem as I am stuck for a month", "Hi All I fixed my problem. It is not because of tensorflow itself, the issue is in the dataloader block code. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38233\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38233\">No</a>\n", "@phuongchi911, Can you describe in more details the solution ? ", "> @phuongchi911, Can you describe in more details the solution ? \n\nHi as I mentioned it is about my own data generator coding issue. Not in Tensorflow. It should return a tuple in the dataloader. But i am not sure if this will apply to your dataset. ", "> > @phuongchi911, Can you describe in more details the solution ?\r\n> \r\n> Hi as I mentioned it is about my own data generator coding issue. Not in Tensorflow. It should return a tuple in the dataloader. But i am not sure if this will apply to your dataset.\r\n\r\nGod! This worked here too, it was not returning a tuple. Thank you very much!\r\nInteresting that in previous versions it worked (even with this error)", "    ValueError: No gradients provided for any variable: ['conv2d_1/kernel:0', 'conv2d_1/bias:0'].", "https://colab.research.google.com/drive/1Okqfq5UXFttj_atsmVqwooDwVibLtriq?usp=sharing\r\ni am getting same issue while running the fit the model", "> https://colab.research.google.com/drive/1Okqfq5UXFttj_atsmVqwooDwVibLtriq?usp=sharing\r\n> i am getting same issue while running the fit the model\r\n\r\nchange input type to tuple instead of list for model input.", "can you explain how to change from list to tuple?"]}, {"number": 38232, "title": "AttributeError: 'TFLiteConverterV2' object has no attribute 'experimental_new_quantizer' due to TensorFlow 2.2.0rc2  in colab.research.google.com ", "body": "**Describe the problem**\r\nIn colab, the default TF version is not a stable version (2.2.0rc2)\r\nYou can check this by opening a new notebook in [colab.research.google.com](colab.research.google.com) and running:\r\n\r\n```\r\npip list | grep tensorflow\r\n\r\ntensorflow               2.2.0rc2    \r\n.\r\n.\r\n   \r\n```\r\n\r\n**Solution: **\r\nChange the tensorflow version from the unstable 2.2.0rc2 to stable 2.2.0\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nAs a result of the default unstable version, if I try to convert a model to a full-integer quantized model it fails due to this error:\r\n```\r\n# Convert the model to the TensorFlow Lite format with quantization\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ndef representative_dataset():\r\n  for i in range(500):\r\n    yield([x_train[i].reshape(1,1)])\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT] \r\nconverter.representative_dataset = representative_dataset\r\nconverter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nmodel_tflite = converter.convert()\r\n\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-22-f5d45cb6910e> in <module>()\r\n     12 converter.representative_dataset = representative_dataset\r\n     13 converter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\n---> 14 model_tflite = converter.convert()\r\n     15 \r\n     16 # Save the model to disk\r\n\r\n1 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py in _calibrate_quantize_model(self, result, inference_input_type, inference_output_type)\r\n    265       return calibrate_quantize.calibrate_and_quantize(\r\n    266           self.representative_dataset.input_gen, inference_input_type,\r\n--> 267           inference_output_type, allow_float, self.experimental_new_quantizer)\r\n    268 \r\n    269   def _is_unknown_shapes_allowed(self):\r\n\r\nAttributeError: 'TFLiteConverterV2' object has no attribute 'experimental_new_quantizer'\r\n```\r\n\r\nRemoving the `converter.representative_dataset = representative_dataset` line, seems to work fine but is not a valid workflow for my use case.\r\n\r\n\r\n**Current workaround**\r\nIf I uninstall `tensorflow==2.2.0rc2` and  instead install `tensorflow==2.2.0`, it seems to work as well. I simply run the following, at the beginning of my colab:\r\n\r\n`pip install tensorflow==2.2.0`\r\n\r\nThis seems to resolve the issue.\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@MeghnaNatraj Thanks for the issue. We haven't released TF 2.2.0 final version yet.\r\nWe have 2.2.0rc0, 2.2.0rc1, 2.2.0rc2 packages. \r\nAs of today 2.2.0rc2 is latest package, Colab will be updated once we have stable 2.2.0 released shortly.", "Is it possible to instead have a stable version on Colab at all times? eg: TF 2.1? ", "So, this problem is going to persist until unless the final version is released?  Also, does not work on TensorFlow 2.1?", "@sayakpaul Could you link your github issue here? Or post more details as a comment? Ideally, this should not occur for any stable version of TensorFlow.", "I just replied via the Google Group discussion.\n\nSayak Paul | sayak.dev\n\nOn Fri, 17 Apr 2020, 00:13 Meghna Natraj, <notifications@github.com> wrote:\n\n> @sayakpaul <https://github.com/sayakpaul> Could you link your github\n> issue here? Or post more details as a comment? Ideally, this should not\n> occur for any stable version of TensorFlow.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/38232#issuecomment-614829650>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AFPE2TDF7DHHCDEBJOUED5DRM5GW5ANCNFSM4MAHD2BQ>\n> .\n>\n", "Closing this issue now that colab hosts stable version. Also opened an [issue](https://github.com/googlecolab/colabtools/issues/1132) on google colab repo to address such issue in future. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38232\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38232\">No</a>\n"]}]