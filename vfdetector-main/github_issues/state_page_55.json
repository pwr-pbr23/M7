[{"number": 40965, "title": "End2end Transformer Training by Using Ragged Tensor ", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (tf nightly):\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI'd like to write a [transformer model](https://www.tensorflow.org/tutorials/text/transformer) by end2end using Ragged Tensor to speed up training. However, I found that there're some ops that Ragged Tensor could not support, ex. `matmul`, `relu`.  Do you have plan to support the other tf ops for Ragged Tensor?\r\n\r\nIn general, there are two kinds of ops to support:\r\n1. Ragged Tensor op could reuse the kernel written for regular tensor. ex. `relu`\r\n2. Ragged Tensor op could not reuse the kernel written for regular tensor. ex. `logits = tf.einsum(\"BTNH,BFNH->BNFT\", key, query)`, where dimension `F` and `T` are ragged.\r\n\r\n**Will this change the current api? How?** No.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nThose models with batches of variable-length sequential inputs, ex. Transformer.\r\n\r\n**Any Other info.**\r\n", "comments": ["Additionally, there is a ragged op that is needed to do positional encoding and does't exist. \r\nBasically what I'm looking for is the option to chop a dense tensor to the shape of a ragged one and apply an op such as '+'.\r\nExample:\r\n```\r\ntext: \"Google is nice\"\r\nembedded_text: [[1.1,2.2],[3.3,4.4],[5.5,6.6]] #ragged tensor after text embedding, <hidden_size=2, text_length=3>\r\npositional_encoding_matrix: [[0.0,1.0],[0.1,0.2],[0.5,0.6],[0.8,0.2],[0.4,0.9]]] #<hidden_size=2, max_text_length=5>\r\nwanted_function(embedded_text,positional_encoding_matrix,'+'): \r\n  step1: chops the second input to the shape of the ragged tensor, [[0.0,1.0],[0.1,0.2],[0.5,0.6],[0.8,0.2],[0.4,0.9]]]=>[[0.0,1.0],[0.1,0.2],[0.5,0.6]]\r\n  step2: apply the '+' op on the equally shaped ragged tensors and return the result\r\n```\r\nThis would enable us to use the Transformer model without adding padding vectors (and the attention masks that come with it).\r\n\r\nI'm starting to work on a version of a ragged transformer now but I still don't see a way to write the above function efficiently without help from the TF team.\r\n", "@yaochengji For elementwise functions such as `relu`, you can just use `tf.ragged.map_flat_values`.  E.g.:\r\n\r\n```\r\nx = tf.ragged.constant([[-3.0, 2.0], [3.0]])\r\ntf.ragged.map_flat_values(tf.nn.relu, x)\r\n```\r\n\r\nAdding ragged support to `tf.einsum` would be more complicated; any contributions are welcome. \r\n\r\n@ARozental You can chop a dense tensor to the shape of a ragged one with something like this:\r\n\r\n```\r\ndef chop_dense_to_ragged(dense, ragged):\r\n  mask = ragged.with_flat_values(tf.ones([tf.shape(ragged.flat_values)[0]], tf.bool))\r\n  mask = mask.to_tensor(shape=tf.shape(dense)[:tf.rank(mask)])\r\n  return tf.ragged.boolean_mask(dense, mask)\r\n\r\nd = tf.reshape(tf.range(12), [3, 4])\r\nr = tf.ragged.constant([[1, 2], [3], [4, 5, 6]])\r\nprint(chop_dense_to_ragged(d, r))\r\n# prints <tf.RaggedTensor [[0, 1], [4], [8, 9, 10]]>\r\nprint(r + chop_dense_to_ragged(d, r))\r\n# prints <tf.RaggedTensor [[1, 3], [7], [12, 14, 16]]>\r\n```\r\n"]}, {"number": 40905, "title": "Process killed on tf.dynamic_partition", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0\r\n- Python version: 3.7.6\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\n**Describe the current behavior**\r\ntf.dynamic_partition with a large `num_partitions` hangs while consuming lots of memory  and the process is killed after a while. \r\n\r\n**Describe the expected behavior**\r\nI would expect a memory allocation warning message rather than a hang followed by the killed process.  \r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n```python\r\nimport tensorflow as tf\r\n\r\npartitions = [0, 0, 1, 1, 0]\r\nnum_partitions = 100000000 \r\ndata = [10, 20, 30, 40, 50]\r\n\r\noutput = tf.dynamic_partition(data, partitions, num_partitions)\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n```\r\nKilled\r\n```\r\n", "comments": ["I am able to replicate the issue reported, cloab crashes after we run the code shared.", "Could reproduce the **crash** of **`Google Colab`** with **`Tensorflow Version 2.5`** and **`TF Nightly`**. Thanks!"]}, {"number": 40836, "title": "[TF 2.3.0] [Intel MKL] OMP Threads are created with variable number when we compile with XLA flag ON", "body": "Attn: @penpornk \r\n### **Issue:**\r\n**_The number of OMP thread created varies for the same model across multiple runs._**\r\n\r\n**_This also causes varied performance across multiple runs for the same model on same platform with same setting/tuning parameters._**\r\n\r\n### **Issue Detailed:**\r\nWith options: **_--data-num-inter-threads=1 --data-num-intra-threads=28 --socket-id=0_**\r\nWhen running benchmarks for RN50 inference on master branch(HEAD) with OMP_NUM_THREADS set to 28:  \r\n\r\nWe notice threads being created to be - 156 threads . **_(Incorrect)_**\r\nUsing May 24th commit sha: (fbc4da8201f5c3acecb998854d087c663f1f5cd8) - 28 threads are created **_(correct)_**\r\n\r\n### **Observation:**\r\n**_Disabling the XLA compile flag_** by setting TF_ENABLE_XLA=0 **_creates the proper number of 28 threads_** in current master (HEAD). **_(Correct)_**\r\n\r\n### **_How to Reproduce:_**\r\nRun resnet_50_v1.5 inference with XLA on the latest master\r\nhttps://github.com/IntelAI/models/blob/master/benchmarks/image_recognition/tensorflow/resnet50v1_5/README.md#fp32-inference-instructions\r\n", "comments": ["@nammbash Thank you for reporting! I've tagged this for 2.3.0.", "> @nammbash Thank you for reporting! I've tagged this for 2.3.0.\r\n\r\nDo we need the Comp:MKl label?", "@nammbash Yes, we do. Thank you for bringing it up!", "What is the status of this?"]}, {"number": 40817, "title": "tf.function ensures type annotations and input_signature match", "body": "The `input_signature` argument of `tf.function` allows users to specify the input dtypes of function arguments. \r\nPython type annotations for Tensors will contain the dtype of the Tensor.\r\n\r\nThese changes will allow `tf.function` to ensure that type annotations and `input_signature` match. When there is a mismatch, an error will be thrown. \r\n\r\nThis is of particular importance to ensure forward compatibility, so that in the future we can switch from `input_signature` to type annotations without breaking existing code.\r\n\r\n### Example\r\n```python\r\n@tf.function(input_signature=[tf.TensorSpec(None, dtype=tf.int32)])\r\ndef f(x: tf.Tensor[dtypes.Int32]):\r\n  return x\r\n\r\n@tf.function(input_signature=[tf.TensorSpec(None, dtype=tf.int32)])\r\ndef f(x: tf.Tensor[dtypes.String]): # Error! Type annotation does not match input_signature.\r\n  return x\r\n\r\n```", "comments": ["This is not ready to be merged until TensorFlow dtypes have Python dtype class types #40696 and the Tensor class is defined as a Generic class #40921.", "@rahul-kamat  Can you please resolve conflicts? Thanks!", "The PR is still valid, but we've been delayed on the integration."]}, {"number": 40801, "title": "tf.io.gfile.GFile truncates gzipped files loaded from Google Cloud buckets", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.15.5\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): `v2.2.0-rc4-8-g2b96f3662b 2.2.0`\r\n- Python version: 3.6.2\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\n\r\nLoading a CSV file with `tf.io.gfile.GFile(\"gs://my-bucket/my-file.csv\")` from a Google Cloud bucket is truncating the results for gzipped files.\r\n\r\nE.g. one test file is stored with gzip compression & has a compressed filesize of 45kb, but an uncompressed size of 170kb. Reading from the file via `GFile.read()` only outputs 45kb of (uncompressed) data, then the file closes. Checking the size of the file with `GFile.size()` reports 45kb.\r\n\r\nThere don't appear to be any options available regarding compression, and the data is correctly uncompressed, but truncated\r\n\r\n**Describe the expected behavior**\r\n\r\nThe entire file is returned, and `GFile.size()` returns the uncompressed filesize.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nhttps://colab.research.google.com/drive/15xXT8nXAr0cqjmvV1-JMu3es4e9a34xL?usp=sharing\r\n", "comments": ["Was able to reproduce the issue with TF v2.2 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/ae4de5593b1d31db7ee78fa5149fbb51/40801-tf-nightly.ipynb). Thanks!", "Was able to reproduce the issue in TF 2.7.0. Please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/23833552c3386ac36133b350c975a96b/untitled85.ipynb).Thanks!"]}, {"number": 40797, "title": "Cannot test op using mutlithreading", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): master\r\n- Python version: 3.6.0\r\n- Bazel version (if compiling from source): 3.1.0\r\n- GCC/Compiler version (if compiling from source): Apple clang version 11.0.0 (clang-1100.0.33.12)\r\n- CUDA/cuDNN version: None\r\n- GPU model and memory: None\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nStill only single thread is being used even if I uncommented https://github.com/petewarden/tensorflow_makefile/blob/master/tensorflow/python/kernel_tests/sparse_tensor_dense_matmul_op_test.py#L168.\r\n\r\nHere is how I tested it:\r\nVLOG(0) << worker_threads.num_threads;\r\n\r\nOutput:\r\n1\r\n\r\n**Describe the expected behavior**\r\nVLOG(0) << worker_threads.num_threads;\r\n\r\nExpected Output:\r\n100\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nUncomment:\r\nhttps://github.com/petewarden/tensorflow_makefile/blob/master/tensorflow/python/kernel_tests/sparse_tensor_dense_matmul_op_test.py#L168.\r\n\r\nbazel build -c opt --copt=-mavx --copt=-msse4.2 --copt=-O3 tensorflow/python/kernel_tests:sparse_tensor_dense_matmul_op_test\r\n\r\n./bazel-bin/tensorflow/python/kernel_tests/sparse_tensor_dense_matmul_op_test --benchmarks\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Could you point to where you added the logging? ", "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/sparse_tensor_dense_matmul_op.cc#L47\r\n\r\nAdded:\r\n```\r\nauto worker_threads = ctx->device()->tensorflow_cpu_worker_threads();\r\nconst int num_threads = worker_threads->num_threads;\r\nVLOG(0) << num_threads;\r\n```\r\n\r\n"]}, {"number": 40793, "title": "Question: fake-quantize layers are also called from TF-Lite", "body": "Hi TensorFlow developers. \r\n\r\nI'm facing a behavior with TensorFlow lite quantized models that I can't figure out.\r\n\r\nI published a question in StackOverflow but didn't get a helpful response for now: https://stackoverflow.com/questions/62433410/tensorflow-fake-quantize-layers-are-also-called-from-tf-lite/62524147.\r\n\r\nI think that what I'm actually looking for, is how do I force the C++ code to run only with integer ops (for example, the minimal.cc sample).\r\n\r\n**\r\nNote 1:\r\nWhen I'm training without quantization aware and then post-quantize the model, I see what I expect to see when running the C++ code. Only integer ops are running (except gemlowp) and I can understand exactly what the code is doing and which quantization parameters are used and how they are used.\r\n\r\nNote 2:\r\nMy main goal is to simulate HW int8 arithmetic in Python based on TF Lite quantized models. So I understand how to do it for post-quantized models. My issues are with quantized-aware models.\r\n**\r\n\r\nThanks in advance for any advice...", "comments": []}, {"number": 40784, "title": "Jetson Nano build fails with missing \"cudnn_version\" string (default=7)", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution: Ubuntu 16.04 for Nvidia Jetson Nano (Tegra ARM64)\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.1.1\r\n- Python version: 2.7.17 and 3.6.9 (issue occurs with both)\r\n- Installed using virtualenv? pip? conda?: no\r\n- Bazel version (if compiling from source): 0.29.1\r\n- GCC/Compiler version (if compiling from source): 7.5.0\r\n- CUDA/cuDNN version: CUDA 10.2 cuDNN 8.0.0\r\n- GPU model and memory: Nvidia Maxwell 4GB LPDDR4\r\n\r\n**Describe the problem**\r\nBuild halts due to missing tuple entry (instead of blank string) for option 9: cudnn_version\r\nThe default as set in \"configure.py\" is cuDNN 7, but this is not reflected in the dictionary.\r\nI have cuDNN version 8 installed but it has not been detected by the build script.\r\nEverything else has been detected fine before this point (line 1318 in \"configure.py\").\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\"sudo ./configure\" and say \"Y/y\" all dependencies (including python, computecpp, CUDA etc.)\r\n\r\n**Any other info / logs**\r\n![tensorflow2-debug](https://user-images.githubusercontent.com/8195854/85642678-16a6e580-b68a-11ea-8c51-7c6282261786.png)\r\n\r\n", "comments": ["@TheMindVirus \r\n\r\nCan you try with [tested build configuration](https://www.tensorflow.org/install/source#gpu) for TF 2.1 and see whether the problem still persists?.Thanks!", "Even if I try one of the default configurations I\u2019m not likely to get the same performance out of the board. The library versions have been compiled especially to support this board and others. Changing the environment will likely cause damage to my system and other applications.", "I am proceeding to following the build instructions here: https://www.tensorflow.org/install/source_rpi\r\nThese instructions are for the Raspberry Pi which the Jetson Nano is based around and is also ARM64.\r\nI will let you know if this builds correctly. It is currently taking a long time to build numpy on 1 core.", "When trying to build from the docker image I get errors while building SciPy such as the following:\r\nhttps://github.com/scipy/scipy/issues/9005\r\nThis is even the case on a Raspberry Pi 4. Any fixes have to be made to the docker container.\r\nThe system has the libraries required but they are not being used.", "Hi @TheMindVirus!\r\nWe are checking to see whether you still need help in this issue . Have you checked this [thread](https://towardsdatascience.com/getting-started-with-nvidia-jetson-nano-and-installing-tensorflow-gpu-ad4a3da8ed26) yet? Thanks!", "A few 404 Errors while building from source with bazel and CUDA support:\r\nhttps://storage.googleapis.com/mirror.tensorflow.org/github.com/llvm/llvm-project/archive/bcad20bc6591c8b503923402038c735a77373f99.tar.gz\r\nhttp://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/03b3c4c9baa9b99b2073a4f342b810e8843e43c2.tar.gz\r\nhttps://storage.googleapis.com/mirror.tensorflow.org/github.com/NVIDIA/cudnn-frontend/archive/73210a930333eaf66b42b01693bce7b70719c354.zip\r\nbut it is currently still building. I will give you an update when it finishes.", "The build has failed with more 404 Errors and some Internal Compiler Errors.\r\nThere are even more possible combinations than are shown in the documentation you linked, many projects look like version hell at the moment.\r\n![Screenshot from 2021-11-03 16-51-16](https://user-images.githubusercontent.com/8195854/140107898-3e0595c9-7696-4d7b-a6e3-35337464f9c0.png)\r\n", "Ok @TheMindVirus!  Could you check out this [thread](https://github.com/PINTO0309/Tensorflow-bin#usage) then ?  Thank you!", "The Jetson Nano terminal repeatedly grinds to a halt when \"Installing backend dependencies\" of h5py 3.1.0 required for building for Python.\n\nPython is definitely the way to go for Tensorflow as it's the only thing that ever needs to be built with C in the modern era.\n\nAs for the version control, the old habit of removing the old system before replacing it with the new potentially broken one is frowned upon.\n\nThere is a prebuilt binary which may work but cannot reliably be rebuilt later with exactly the same source code.\n\nCutting down on dependency libraries and just using raw Python would make it much simpler to use and also to port to e.g MicroPython and CircuitPython for use in projects."]}, {"number": 40727, "title": "tf.nn.ctc_beam_search_decoder does not pick path with highest probability at next time step", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nColab Env (Linux Ubuntu 18.04)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nN/A\r\n- TensorFlow installed from (source or binary):\r\nBinary (I think)\r\n- TensorFlow version (use command below):\r\nv2.2.0-0-g2b96f3662b 2.2.0\r\n- Python version:\r\n3.6.9\r\n- Bazel version (if compiling from source):\r\nN/A\r\n- GCC/Compiler version (if compiling from source):\r\nN/A\r\n- CUDA/cuDNN version:\r\nN/A\r\n- GPU model and memory:\r\nNone\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nThe built-in CTC beam search decoder sometimes chooses a less probable path to keep in the beam by default than it could've when expanding a given step. In the Colab example provided below, I give a concrete example of when the path (0,) is retained in the beam instead of (0, 1, 0) despite the latter having a greater log-probability.\r\n\r\n**Describe the expected behavior**\r\n\r\n(0, 1, 0) should remain in the beam; (0,) should not.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nhttps://colab.research.google.com/drive/1i9gvj0VN2gMNloohbHW6ad3Ti7eiQQCM?usp=sharing\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nWhen I was comparing against a simple python version [based off this Medium article](https://towardsdatascience.com/beam-search-decoding-in-ctc-trained-neural-networks-5a889a3d85a7), I noticed that whenever the results diverged, the root problem was always that a path that should've been kept in the beam wasn't. I suspect top-k sorting might be mucking up somewhere.\r\n\r\nThanks,\r\nSean\r\n", "comments": ["Was able to reproduce the issue with TF v2.2 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/26897d798c5f763191014d5a558564e3/40727.ipynb). Thanks!", "Hello,\r\n\r\nWhile I can appreciate that you lot are very busy, it's been a month since I opened this issue and I'm afraid it's going to fall through the cracks. I would like to stress the importance of this issue.\r\n\r\nI'm not sure why @amahendrakar removed the \"bug\" label and replaced it with \"support.\" However, I would stress that (I believe) this is a mistake in the Tensorflow codebase, rather than something specific to my code, since i was able to reproduce it in a very  minimal gist. If I'm correct, the impact of this error is that all code using the built-in CTC beam search will output paths that are not as probable as they could be, potentially decreasing the overall accuracy reported in all sorts of research papers (including Google ones).\r\n\r\nI originally stumbled on this when testing TF r1.15, which suggests that this is probably some logic error that has been around for some time in the code base. Either that, or I am fundamentally misunderstanding an aspect of this variety of search (AFAICT Graves did not publish a canon procedure for CTC beam search, leaving us to guess at appropriate rules).\r\n\r\nThank you for your time,\r\nSean", "> Hello,\r\n> \r\n> While I can appreciate that you lot are very busy, it's been a month since I opened this issue and I'm afraid it's going to fall through the cracks. I would like to stress the importance of this issue.\r\n> \r\n> I'm not sure why @amahendrakar removed the \"bug\" label and replaced it with \"support.\" However, I would stress that (I believe) this is a mistake in the Tensorflow codebase, rather than something specific to my code, since i was able to reproduce it in a very minimal gist. If I'm correct, the impact of this error is that all code using the built-in CTC beam search will output paths that are not as probable as they could be, potentially decreasing the overall accuracy reported in all sorts of research papers (including Google ones).\r\n> \r\n> I originally stumbled on this when testing TF r1.15, which suggests that this is probably some logic error that has been around for some time in the code base. Either that, or I am fundamentally misunderstanding an aspect of this variety of search (AFAICT Graves did not publish a canon procedure for CTC beam search, leaving us to guess at appropriate rules).\r\n> \r\n> Thank you for your time,\r\n> Sean\r\n\r\nDid you consider the prefix? It seems that the function will merge the probability if two beam have the same prfix, and finally obtain the highest merged probability path.", "Hi @yjiangling,\r\n\r\nI'm fairly certain that I haven't left out any probability mass because I'm relying on the op itself to calculate the probability of all but the pruned path. The way I calculate the pruned path, `[0, 1, 0]` at step t=3, given that `[0, 1]` and `[0]` are in the beam at step t=2, is to sum the total log-probability of the prefix `[0, 1]` (approx `-1.1840693`) with the log-probability of token `0` at t=3 (approx `-0.16818666458129883`) to get approximately `-1.352256`. There's no need to separate the probability of `[0, 1]` into blank-ending and non-blank ending because `0` does not match the immediately preceding token `1`. This number is greater than the _reported_ probability of prefix `[0]` at t=3, `-1.8781054`. If there's a problem with the scores reported by Tensorflow before this point, well, I guess that'd be the bug :/.\r\n\r\nBy the way, this collab assumes the blank label is still `num_classes - 1` as per #42993. As soon as [this RTF](https://github.com/tensorflow/community/pull/295) merges, the collab will have to be revisited to get the indices right.", "> Hi @yjiangling,\r\n> \r\n> I'm fairly certain that I haven't left out any probability mass because I'm relying on the op itself to calculate the probability of all but the pruned path. The way I calculate the pruned path, `[0, 1, 0]` at step t=3, given that `[0, 1]` and `[0]` are in the beam at step t=2, is to sum the total log-probability of the prefix `[0, 1]` (approx `-1.1840693`) with the log-probability of token `0` at t=3 (approx `-0.16818666458129883`) to get approximately `-1.352256`. There's no need to separate the probability of `[0, 1]` into blank-ending and non-blank ending because `0` does not match the immediately preceding token `1`. This number is greater than the _reported_ probability of prefix `[0]` at t=3, `-1.8781054`. If there's a problem with the scores reported by Tensorflow before this point, well, I guess that'd be the bug :/.\r\n> \r\n> By the way, this collab assumes the blank label is still `num_classes - 1` as per #42993. As soon as [this RTF](https://github.com/tensorflow/community/pull/295) merges, the collab will have to be revisited to get the indices right.\r\n\r\nYes\uff0cthe CTC Loss in tensorflow 2.X the indices 0 is set to be blank as default\uff0cbut the decode function greedy_decode and beam_search_decode is still set num_classes-1 as blank and have no option to set it.", "I think there really needs to be a bug in the decoder. If you run the original Colab with beam size `K=3`, the `[0, 1, 0]` is returned with logprob `-1.352256`, which is larger than the logprob of `[0]` at timestep `t=3`; and the `[0, 1, 0]` cannot use the additional element `[1]` in the beam at timestep `t=2`.\r\n\r\nWould it be possible to update the labels to include `bug` and also include `TF-2.4`?"]}, {"number": 40721, "title": "Import .tflite model into Tensorflow graph", "body": "**System information**\r\n- TensorFlow version (you are using): 2.2.0\r\n- Are you willing to contribute it (Yes/No): No (Don't have expertise to do it..)\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI'd like to be able to import a .tflite model as a 'node' within a tensorflow graph. This would allow people to download published .tflite models, add pre/post processing nodes to the graph, then re-export the graph to .tflite again. This should allow the user to adapt published models to their use case, moving certain common pre/post processing actions on-GPU or other compute device.\r\n\r\nTo my knowledge, it is not currently possible to 're-import' a .tflite model into a tensorflow graph.\r\n\r\n**Will this change the current api? How?**\r\nYes, a function will need to be added to tf.Graph to support importation of .tflite files. I could also see a function taking a tf.lite.Interpreter object which has the .tflite model in question loaded.\r\n\r\nConcrete suggestions:\r\n* `tf.graph_util.import_tflite(model_path=None)`\r\n* `tf.graph_util.import_tflite(interpreter=None)`\r\n\r\n**Who will benefit with this feature?**\r\nAll tensorflow-lite users will likely benefit. Folks publishing models will find their models will be easier to use and so more folks will download them. Folks trying to use published models will find they can add additional pre/post processing on-GPU or other compute device, making the published models more easily accessible. In some cases, this can skip re-training complex networks when versions which already work well have been published, but with perhaps not the right expected input dimensions, or not the right output format.\r\n\r\n**Any Other info.**\r\nNone at this time.", "comments": []}, {"number": 40708, "title": "looping over tf.range in tf.function is slower than looping over range", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\ncolab tensorflow 2\r\n\r\n\r\n`v2.2.0-0-g2b96f3662b 2.2.0`\r\ntested on both CPU and GPU (GPU is much worse!)\r\n\r\n**Describe the current behavior**\r\n\r\nwhen timing a simple tf.function that uses a loop, `tf.range` is much slower than using `range`.\r\nBUT `tf.range` is recommended in the docs, moreover is says that looping over non-tensor will be rolled during tracing (which does not happen. normal `range` is being traced as a loop)\r\n\r\n```\r\n@tf.function(input_signature=[tf.TensorSpec(shape=[None], dtype=tf.float32)])\r\ndef test(x):\r\n  for i in tf.range(100):\r\n    x = x * tf.constant(1.1)\r\n  return x\r\n```\r\n\r\n```\r\n%%timeit\r\ntest(tf.range(1000, dtype='float32'))\r\n```\r\nprints `100 loops, best of 3: 2.12 ms per loop`\r\nprints `10 loops, best of 3: 70.2 ms per loop` on GPU!\r\nwhile using `range` or `np.arange` is about 300 micro seconds in both CPU and GPU\r\n\r\n**Describe the expected behavior**\r\n\r\n1 there is a documentation issue where it currently always recommends `tf.range`.\r\n2 the documentation should specify when python loops are not rolled\r\n3 tf.range performance should be the same as range when used in a traced loop\r\n(also note the `np.arange` is faster than `tf.range` and comparable to `range`)", "comments": ["@amitport,\r\nI was able to reproduce the issue with TF v2.2, however I see significant improvement with TF-nightly. Please check the below gist for reference. \r\n\r\n- TF v2.2 with [CPU](https://colab.research.google.com/gist/amahendrakar/05c67191e500e8ead961f721586ca9d4/40708-cpu.ipynb), TF v2.2 with [GPU](https://colab.research.google.com/gist/amahendrakar/82bed13091464f020491b09382600bc5/40708-gpu.ipynb)\r\n\r\n- TF-nightly with [CPU](https://colab.research.google.com/gist/amahendrakar/e0962ea3f751c38cd7a19566dd056aa0/40708-cpu-tf-nightly.ipynb), TF-nightly with [GPU](https://colab.research.google.com/gist/amahendrakar/a7164d22b652dbdddfc9cc2b8052c811/40708-gpu-tf-nightly.ipynb)\r\n\r\nThanks!", "@amahendrakar thanks for looking at it\r\nstill an issue though\r\ngpu tf.range:\r\n 31.9 ms \r\ncpu tf.range:\r\n ~2ms\r\n\r\nwhile np.arange and range around 496 \u00b5s\r\n\r\nadditionally, there is a documentation issue with range not being rolled\r\n", "Hi @amitport, can you link to the docs issue you're referring to?", "https://www.tensorflow.org/guide/function#looping_over_python_data", "I tried calling the timeit function directly (on CPU), instead of using the magic function, I'm seeing very little difference for a small number of runs.\r\n\r\n`timeit.timeit(lambda: test(tf.range(1000, dtype='float32')), number=10)`\r\n`## 0.20558238199964762`\r\n\r\n`timeit.timeit(lambda: test2(tf.range(1000, dtype='float32')), number=10)`\r\n`## 0.22194579899996825`\r\n\r\nIf you increase the number to 100, then there is a notable difference. I'm wondering if python is doing some caching that is speeding range up in the long run.", "A few notes below. In summary:\r\n * `for i in range(100)` is unrolled, and that will influence measurement results\r\n * `for i in tf.range(100)` is currently slightly slower and `while i < tf.constant(100)` - we're working on workarounds\r\n * `tf.while_loop` is significantly slower on GPU than it is on CPU - that is likely because GPUs are not optimized for scalar computation, but worth investigating\r\n * using `tf.function(experimental_compile=True)` improves the performance and is recommended\r\n\r\n### Unrolling of `for i in range(n)`\r\nA for loop over a non-Tensor is being unrolled, that is, it's equivalent to writing:\r\n\r\n```\r\nx = x * tf.constant(1.1)\r\nx = x * tf.constant(1.1)\r\n... 98 more times ...\r\n```\r\n\r\nNormally, these multiplications by a constant will be further folded away, so in the end you benchmark `x = x * tf.constant(1.1 ** 100)`. So the results will not be apples-to-apples.\r\n\r\n### Performance of `for i in tf.range(n)`\r\nEspecially on GPU, this is slower than an equivalent `tf.while_loop`. This is tracked in #40517, and will be partially fixed in TF 2.3 and fully fixed in 2.4. Expect this to be in nightly soon.\r\n\r\n### Performance of `tf.while_loop` on GPU\r\nIt appears that `tf.while_loop` is about 10x slower on GPU than CPU, and that is worth having a closer look. It's very likely that the multiplication is just too small to run efficiently on GPU:\r\n\r\n```\r\n@tf.function\r\ndef test(x):\r\n  i = 0\r\n  while i < tf.constant(100):\r\n    x = x * tf.constant(1.1)\r\n    i += 1\r\n  return x\r\n```\r\n\r\n```\r\n%%timeit\r\ntest(tf.range(1000.0))\r\n# 100 loops, best of 3: 11.6 ms per loop\r\n```\r\n\r\nAnd when pinned to the CPU:\r\n\r\n```\r\n@tf.function\r\ndef test(x):\r\n  with tf.device('cpu'):\r\n    i = 0\r\n    while i < tf.constant(100):\r\n      x = x * tf.constant(1.1)\r\n      i += 1\r\n    return x\r\n```\r\n\r\n```\r\n%%timeit\r\nwith tf.device('cpu'):\r\n  test(tf.range(1000.0))\r\n# 1000 loops, best of 3: 852 \u00b5s per loop\r\n```\r\n\r\n### `experimental_compile=True` improves performance in all cases\r\n\r\nThe slowdown is mitigated when using `experimental_compile=True`, which is a good idea to apply in all cases if possible. Although some CPU-GPU differences remain:\r\n\r\n```\r\n@tf.function(experimental_compile=True)\r\ndef test(x):\r\n  for i in tf.range(100):\r\n    x = x * tf.constant(1.1)\r\n  return x\r\n```\r\n\r\n```\r\n%%timeit\r\ntest(tf.range(1000.0))\r\n# 100 loops, best of 3: 2.1 ms per loop\r\n```\r\n\r\n```\r\n@tf.function(experimental_compile=True)\r\ndef test(x):\r\n  with tf.device('cpu'):\r\n    for i in tf.range(100):\r\n      x = x * tf.constant(1.1)\r\n    return x\r\n```\r\n\r\n```\r\n%%timeit\r\nwith tf.device('cpu'):\r\n  test(tf.range(1000.0))\r\n# 1000 loops, best of 3: 432 \u00b5s per loop\r\n```", "Thanks @mdanatg your response explains a lot. as far as I'm concerned this issue can be closed though there is definitely a lot of room for improvement in tf.function documentation.\r\n\r\nA lot of information is spread throughout the documentation site, but I think it is very hard to find and the API pages themselves (mainly https://www.tensorflow.org/api_docs/python/tf/function) are currently missing many crucial things. Also IMO, the response type of tf.function should have its own detailed API page presenting things like `get_concrete_function` and how to view the generated graph inherently. (right now, without looking at tutorials, it's not clear if things like `input_signature` are a public API or not)", "Could reproduce the issue with **`Tensorflow Version 2.5`**. Please find the Gist of [CPU](https://colab.research.google.com/gist/rmothukuru/59edbb4b907a5c9806214c39a5f820d7/40708-cpu.ipynb) and [GPU](https://colab.research.google.com/gist/amahendrakar/82bed13091464f020491b09382600bc5/40708-gpu.ipynb).", "@amitport Could you please try on the latest stable TensorFlow Version 2.7.0 and let us know if it helps?Thanks!", "@sushreebarsa This is still an issue with 2.7, you can just run the Gists from the previous comment (https://github.com/tensorflow/tensorflow/issues/40708#issuecomment-853726914)"]}, {"number": 40659, "title": "[TF 2.2] Elapsed time of ConcreteFunction becomes shorter when printing loss", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n    - Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n    - Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n    - No\r\n- TensorFlow installed from (source or binary):\r\n    - Source\r\n- TensorFlow version (use command below):\r\n    - v2.2.0-0-g2b96f3662b (2.2.0)\r\n- Python version:\r\n    - 3.8.3\r\n- Bazel version (if compiling from source):\r\n    - 2.0.0\r\n- GCC/Compiler version (if compiling from source):\r\n    - 7.5.0\r\n- CUDA/cuDNN version:\r\n    - 10.0 / 7.6\r\n- GPU model and memory:\r\n    - NVIDIA Titan XP (11.9GB)\r\n\r\n**Describe the current behavior**\r\n\r\nI want to measure forward computation + backward computation time in `tf.function`\r\nwith a custom training loop.\r\nThus I wrapped `tf.function` scope to contain\r\n- model forward\r\n- tape.gradient\r\n\r\n(I know that it is much more efficient if I include `apply_gradient` into `tf.function` scope,\r\nbut I didn't for my estimation).\r\nIf I print loss right after the function call, the estimated time becomes significantly different\r\n(much shorter when w/ print loss, much longer when w/o print loss)\r\n\r\n**Describe the expected behavior**\r\n\r\nelapsed time should not be shorter when we print loss\r\n(longer could be ok if `tf.function` runs asynchronously. printing loss will synchronize device execution)\r\n(I think it runs asynchronously because if I print loss before applying gradients, throughput goes down and profiled trace shows that `ResourceApplyMomentum` operations are not overlapped with backpropagation)\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nSimplest version to reproduce\r\n```\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport os\r\nimport time\r\nimport numpy as np\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.python import keras\r\nfrom tensorflow.python.eager import def_function\r\nfrom tensorflow.python.keras import applications\r\nfrom tensorflow.python.framework import dtypes\r\nfrom tensorflow.python.framework import random_seed\r\nfrom tensorflow.python.ops import random_ops\r\nfrom tensorflow.python.ops import losses\r\nfrom tensorflow.python.eager.backprop import GradientTape\r\n\r\ndef main():\r\n  model = applications.resnet.ResNet50(True, None)\r\n  bs = 64\r\n\r\n  @def_function.function\r\n  def tf_function_scope(x, y_):\r\n    with GradientTape() as tape:\r\n      y = model(x)\r\n      loss = losses.losses_impl.sparse_softmax_cross_entropy(y_, logits=y)\r\n    grads = tape.gradient(loss, model.trainable_variables)\r\n    return loss, grads\r\n\r\n  # Train\r\n  optimizer = keras.optimizer_v2.gradient_descent.SGD(0.01)\r\n  for step in range(20):\r\n    fake_x = random_ops.random_uniform([bs, 224, 224, 3], dtype=dtypes.float32)\r\n    fake_y = random_ops.random_uniform([bs,],\r\n                                       minval=0,\r\n                                       maxval=1000,\r\n                                       dtype=dtypes.int64)\r\n    start = time.time()\r\n\r\n    loss, grads = tf_function_scope(fake_x, fake_y)\r\n    tf_func_end = time.time()\r\n\r\n    print(loss)  # on / off makes different (tf_func_end - start) result\r\n    print((tf_func_end - start) * 1000)\r\n\r\n    optimizer.apply_gradients(zip(grads, model.trainable_variables))\r\n    end = time.time()\r\n\r\n    print('step %d, took %.3f ms (before apply_gradients: %f), throghput: %f' % \\\r\n          (step, (end-start)*1000, (tf_func_end - start)*1000, bs / (end - start)))\r\n\r\nif __name__ == '__main__':\r\n  os.environ['CUDA_VISIBLE_DEVICES'] = '0'\r\n  main()\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n1. Without print loss\r\n```\r\n2020-06-22 08:42:40.022588: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-06-22 08:42:40.123857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\npciBusID: 0000:05:00.0 name: TITAN Xp computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\r\n2020-06-22 08:42:40.124190: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2020-06-22 08:42:40.126113: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2020-06-22 08:42:40.127874: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\r\n2020-06-22 08:42:40.128249: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\r\n2020-06-22 08:42:40.130484: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\r\n2020-06-22 08:42:40.132267: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\r\n2020-06-22 08:42:40.137410: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-06-22 08:42:40.148777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-06-22 08:42:40.190909: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2099905000 Hz\r\n2020-06-22 08:42:40.197116: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b7233c1450 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-06-22 08:42:40.197192: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-06-22 08:42:40.393986: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b72342ab40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-06-22 08:42:40.394053: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1\r\n2020-06-22 08:42:40.397195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\npciBusID: 0000:05:00.0 name: TITAN Xp computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\r\n2020-06-22 08:42:40.397284: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2020-06-22 08:42:40.397334: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2020-06-22 08:42:40.397374: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\r\n2020-06-22 08:42:40.397414: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\r\n2020-06-22 08:42:40.397443: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\r\n2020-06-22 08:42:40.397472: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\r\n2020-06-22 08:42:40.397502: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-06-22 08:42:40.402115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-06-22 08:42:40.402174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2020-06-22 08:42:40.405355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-06-22 08:42:40.405380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \r\n2020-06-22 08:42:40.405407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \r\n2020-06-22 08:42:40.412971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11318 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:05:00.0, compute capability: 6.1)\r\n2020-06-22 08:42:46.001636: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2020-06-22 08:42:46.209792: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\ntf function time: 4361.180067062378\r\nstep 0, took 4409.801 ms (before apply_gradients: 4361.180067), throghput: 14.513127\r\ntf function time: 122.9701042175293\r\nstep 1, took 160.225 ms (before apply_gradients: 122.970104), throghput: 399.438503\r\ntf function time: 292.9036617279053\r\nstep 2, took 329.290 ms (before apply_gradients: 292.903662), throghput: 194.357749\r\ntf function time: 293.7884330749512\r\nstep 3, took 329.407 ms (before apply_gradients: 293.788433), throghput: 194.288679\r\ntf function time: 296.1745262145996\r\nstep 4, took 331.075 ms (before apply_gradients: 296.174526), throghput: 193.309700\r\ntf function time: 295.7441806793213\r\nstep 5, took 328.914 ms (before apply_gradients: 295.744181), throghput: 194.579640\r\ntf function time: 297.3062992095947\r\nstep 6, took 328.839 ms (before apply_gradients: 297.306299), throghput: 194.624079\r\ntf function time: 300.38952827453613\r\nstep 7, took 336.697 ms (before apply_gradients: 300.389528), throghput: 190.081826\r\ntf function time: 295.8531379699707\r\nstep 8, took 333.771 ms (before apply_gradients: 295.853138), throghput: 191.748377\r\ntf function time: 293.9162254333496\r\nstep 9, took 330.256 ms (before apply_gradients: 293.916225), throghput: 193.788929\r\ntf function time: 295.107364654541\r\nstep 10, took 328.889 ms (before apply_gradients: 295.107365), throghput: 194.594592\r\ntf function time: 296.8401908874512\r\nstep 11, took 328.850 ms (before apply_gradients: 296.840191), throghput: 194.617871\r\ntf function time: 298.9656925201416\r\nstep 12, took 330.844 ms (before apply_gradients: 298.965693), throghput: 193.444828\r\ntf function time: 300.534725189209\r\nstep 13, took 337.954 ms (before apply_gradients: 300.534725), throghput: 189.374994\r\ntf function time: 295.2277660369873\r\nstep 14, took 335.415 ms (before apply_gradients: 295.227766), throghput: 190.808195\r\ntf function time: 291.32676124572754\r\nstep 15, took 334.997 ms (before apply_gradients: 291.326761), throghput: 191.046658\r\ntf function time: 287.0829105377197\r\nstep 16, took 333.483 ms (before apply_gradients: 287.082911), throghput: 191.914116\r\ntf function time: 284.6190929412842\r\nstep 17, took 327.860 ms (before apply_gradients: 284.619093), throghput: 195.205059\r\ntf function time: 288.6462211608887\r\nstep 18, took 329.876 ms (before apply_gradients: 288.646221), throghput: 194.012187\r\ntf function time: 291.00489616394043\r\nstep 19, took 328.769 ms (before apply_gradients: 291.004896), throghput: 194.665292\r\n\r\n```\r\n\r\n2. with print loss\r\n\r\n```\r\n2020-06-22 08:43:03.438864: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-06-22 08:43:03.560570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\npciBusID: 0000:05:00.0 name: TITAN Xp computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\r\n2020-06-22 08:43:03.561008: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2020-06-22 08:43:03.563477: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2020-06-22 08:43:03.565449: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\r\n2020-06-22 08:43:03.565884: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\r\n2020-06-22 08:43:03.568719: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\r\n2020-06-22 08:43:03.570816: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\r\n2020-06-22 08:43:03.575264: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-06-22 08:43:03.588127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-06-22 08:43:03.622770: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2099905000 Hz\r\n2020-06-22 08:43:03.628790: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5632029c85b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-06-22 08:43:03.628829: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-06-22 08:43:03.814060: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563202a31ca0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-06-22 08:43:03.814126: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1\r\n2020-06-22 08:43:03.822679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\npciBusID: 0000:05:00.0 name: TITAN Xp computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\r\n2020-06-22 08:43:03.822786: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2020-06-22 08:43:03.822813: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2020-06-22 08:43:03.822833: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\r\n2020-06-22 08:43:03.822864: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\r\n2020-06-22 08:43:03.822883: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\r\n2020-06-22 08:43:03.822903: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\r\n2020-06-22 08:43:03.822934: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-06-22 08:43:03.826928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-06-22 08:43:03.826991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2020-06-22 08:43:03.830583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-06-22 08:43:03.830633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \r\n2020-06-22 08:43:03.830665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \r\n2020-06-22 08:43:03.835490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11318 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:05:00.0, compute capability: 6.1)\r\n2020-06-22 08:43:09.605652: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2020-06-22 08:43:09.814419: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\nloss: tf.Tensor(6.9077563, shape=(), dtype=float32)\r\ntf function time: 4659.780740737915\r\nstep 0, took 4717.544 ms (before apply_gradients: 4659.780741), throghput: 13.566382\r\nloss: tf.Tensor(6.907754, shape=(), dtype=float32)\r\ntf function time: 123.58546257019043\r\nstep 1, took 376.163 ms (before apply_gradients: 123.585463), throghput: 170.138898\r\nloss: tf.Tensor(6.9077573, shape=(), dtype=float32)\r\ntf function time: 123.61717224121094\r\nstep 2, took 368.745 ms (before apply_gradients: 123.617172), throghput: 173.561522\r\nloss: tf.Tensor(6.9077635, shape=(), dtype=float32)\r\ntf function time: 123.36468696594238\r\nstep 3, took 367.381 ms (before apply_gradients: 123.364687), throghput: 174.205911\r\nloss: tf.Tensor(6.907756, shape=(), dtype=float32)\r\ntf function time: 122.72977828979492\r\nstep 4, took 375.007 ms (before apply_gradients: 122.729778), throghput: 170.663412\r\nloss: tf.Tensor(6.9077506, shape=(), dtype=float32)\r\ntf function time: 123.32725524902344\r\nstep 5, took 377.959 ms (before apply_gradients: 123.327255), throghput: 169.330637\r\nloss: tf.Tensor(6.907758, shape=(), dtype=float32)\r\ntf function time: 123.4426498413086\r\nstep 6, took 377.844 ms (before apply_gradients: 123.442650), throghput: 169.382137\r\nloss: tf.Tensor(6.907757, shape=(), dtype=float32)\r\ntf function time: 126.03235244750977\r\nstep 7, took 374.068 ms (before apply_gradients: 126.032352), throghput: 171.091986\r\nloss: tf.Tensor(6.9077587, shape=(), dtype=float32)\r\ntf function time: 130.0036907196045\r\nstep 8, took 373.924 ms (before apply_gradients: 130.003691), throghput: 171.157768\r\nloss: tf.Tensor(6.907766, shape=(), dtype=float32)\r\ntf function time: 122.81250953674316\r\nstep 9, took 367.702 ms (before apply_gradients: 122.812510), throghput: 174.053986\r\nloss: tf.Tensor(6.907754, shape=(), dtype=float32)\r\ntf function time: 122.46370315551758\r\nstep 10, took 367.749 ms (before apply_gradients: 122.463703), throghput: 174.031643\r\nloss: tf.Tensor(6.9077454, shape=(), dtype=float32)\r\ntf function time: 123.29578399658203\r\nstep 11, took 366.575 ms (before apply_gradients: 123.295784), throghput: 174.589101\r\nloss: tf.Tensor(6.9077616, shape=(), dtype=float32)\r\ntf function time: 123.33488464355469\r\nstep 12, took 366.533 ms (before apply_gradients: 123.334885), throghput: 174.609088\r\nloss: tf.Tensor(6.9077625, shape=(), dtype=float32)\r\ntf function time: 123.26574325561523\r\nstep 13, took 368.901 ms (before apply_gradients: 123.265743), throghput: 173.488161\r\nloss: tf.Tensor(6.907754, shape=(), dtype=float32)\r\ntf function time: 123.28004837036133\r\nstep 14, took 378.585 ms (before apply_gradients: 123.280048), throghput: 169.050499\r\nloss: tf.Tensor(6.9077578, shape=(), dtype=float32)\r\ntf function time: 123.01921844482422\r\nstep 15, took 367.751 ms (before apply_gradients: 123.019218), throghput: 174.030853\r\nloss: tf.Tensor(6.907749, shape=(), dtype=float32)\r\ntf function time: 122.85351753234863\r\nstep 16, took 370.019 ms (before apply_gradients: 122.853518), throghput: 172.964222\r\nloss: tf.Tensor(6.9077587, shape=(), dtype=float32)\r\ntf function time: 123.2306957244873\r\nstep 17, took 367.553 ms (before apply_gradients: 123.230696), throghput: 174.124776\r\nloss: tf.Tensor(6.9077473, shape=(), dtype=float32)\r\ntf function time: 122.7264404296875\r\nstep 18, took 369.329 ms (before apply_gradients: 122.726440), throghput: 173.287243\r\nloss: tf.Tensor(6.9077606, shape=(), dtype=float32)\r\ntf function time: 123.77810478210449\r\nstep 19, took 370.604 ms (before apply_gradients: 123.778105), throghput: 172.691160\r\n\r\n```\r\n\r\n3. hybrid (print loss when step >= 10)\r\n\r\n```\r\n2020-06-22 08:45:28.959617: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-06-22 08:45:29.091472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\npciBusID: 0000:05:00.0 name: TITAN Xp computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\r\n2020-06-22 08:45:29.091790: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2020-06-22 08:45:29.093565: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2020-06-22 08:45:29.095172: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\r\n2020-06-22 08:45:29.095532: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\r\n2020-06-22 08:45:29.097694: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\r\n2020-06-22 08:45:29.099348: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\r\n2020-06-22 08:45:29.104566: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-06-22 08:45:29.111665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-06-22 08:45:29.150924: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2099905000 Hz\r\n2020-06-22 08:45:29.157422: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559b110449d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-06-22 08:45:29.157478: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-06-22 08:45:29.406413: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559b110ae0b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-06-22 08:45:29.406485: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1\r\n2020-06-22 08:45:29.413518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\npciBusID: 0000:05:00.0 name: TITAN Xp computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\r\n2020-06-22 08:45:29.413695: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2020-06-22 08:45:29.413772: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2020-06-22 08:45:29.413815: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\r\n2020-06-22 08:45:29.413858: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\r\n2020-06-22 08:45:29.413901: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\r\n2020-06-22 08:45:29.413944: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\r\n2020-06-22 08:45:29.413988: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-06-22 08:45:29.421650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-06-22 08:45:29.421769: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2020-06-22 08:45:29.424724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-06-22 08:45:29.424749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \r\n2020-06-22 08:45:29.424774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \r\n2020-06-22 08:45:29.428730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11318 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:05:00.0, compute capability: 6.1)\r\n2020-06-22 08:45:34.957824: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2020-06-22 08:45:35.250004: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\ntf function time: 4716.739177703857\r\nstep 0, took 4782.601 ms (before apply_gradients: 4716.739178), throghput: 13.381840\r\ntf function time: 120.75352668762207\r\nstep 1, took 162.472 ms (before apply_gradients: 120.753527), throghput: 393.912849\r\ntf function time: 288.3281707763672\r\nstep 2, took 331.619 ms (before apply_gradients: 288.328171), throghput: 192.992408\r\ntf function time: 286.7617607116699\r\nstep 3, took 327.575 ms (before apply_gradients: 286.761761), throghput: 195.374982\r\ntf function time: 288.7263298034668\r\nstep 4, took 332.976 ms (before apply_gradients: 288.726330), throghput: 192.206123\r\ntf function time: 285.6485843658447\r\nstep 5, took 330.235 ms (before apply_gradients: 285.648584), throghput: 193.801241\r\ntf function time: 285.5794429779053\r\nstep 6, took 328.592 ms (before apply_gradients: 285.579443), throghput: 194.770378\r\ntf function time: 286.8924140930176\r\nstep 7, took 330.659 ms (before apply_gradients: 286.892414), throghput: 193.552647\r\ntf function time: 287.52660751342773\r\nstep 8, took 333.751 ms (before apply_gradients: 287.526608), throghput: 191.759609\r\ntf function time: 282.52458572387695\r\nstep 9, took 325.800 ms (before apply_gradients: 282.524586), throghput: 196.439568\r\nloss: tf.Tensor(6.907755, shape=(), dtype=float32)\r\ntf function time: 286.6995334625244\r\nstep 10, took 533.805 ms (before apply_gradients: 286.699533), throghput: 119.893993\r\nloss: tf.Tensor(6.9077554, shape=(), dtype=float32)\r\ntf function time: 120.00322341918945\r\nstep 11, took 362.584 ms (before apply_gradients: 120.003223), throghput: 176.510883\r\nloss: tf.Tensor(6.907754, shape=(), dtype=float32)\r\ntf function time: 120.20373344421387\r\nstep 12, took 364.925 ms (before apply_gradients: 120.203733), throghput: 175.378661\r\nloss: tf.Tensor(6.90776, shape=(), dtype=float32)\r\ntf function time: 120.89180946350098\r\nstep 13, took 367.710 ms (before apply_gradients: 120.891809), throghput: 174.050262\r\nloss: tf.Tensor(6.907758, shape=(), dtype=float32)\r\ntf function time: 121.07729911804199\r\nstep 14, took 375.999 ms (before apply_gradients: 121.077299), throghput: 170.213015\r\nloss: tf.Tensor(6.907757, shape=(), dtype=float32)\r\ntf function time: 121.16265296936035\r\nstep 15, took 371.518 ms (before apply_gradients: 121.162653), throghput: 172.266043\r\nloss: tf.Tensor(6.907759, shape=(), dtype=float32)\r\ntf function time: 121.36077880859375\r\nstep 16, took 371.042 ms (before apply_gradients: 121.360779), throghput: 172.487427\r\nloss: tf.Tensor(6.9077525, shape=(), dtype=float32)\r\ntf function time: 120.78547477722168\r\nstep 17, took 364.453 ms (before apply_gradients: 120.785475), throghput: 175.605711\r\nloss: tf.Tensor(6.907755, shape=(), dtype=float32)\r\ntf function time: 120.941162109375\r\nstep 18, took 375.551 ms (before apply_gradients: 120.941162), throghput: 170.416059\r\nloss: tf.Tensor(6.9077535, shape=(), dtype=float32)\r\ntf function time: 120.76926231384277\r\nstep 19, took 362.911 ms (before apply_gradients: 120.769262), throghput: 176.351553\r\n```", "comments": ["@ktaebum,\r\nCorrect me if I'm wrong, but I did not find much difference in the `throghput` time on running the code with print loss and without printing loss. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/c83da47d9449d85d41a7bc1bb644ff89/40659.ipynb#scrollTo=xr382M0ATTsf). \r\n\r\nAlso, could you please provide the code to reproduce the `hybrid` scenario. Thanks!", "@amahendrakar \r\nThanks for your response!\r\nUnfortunately, my major curiosity is not `throughput` but elapsed time of `tf_function_scope` (printed as `before apply_gradients`).\r\nIn the [gist](https://colab.research.google.com/gist/amahendrakar/c83da47d9449d85d41a7bc1bb644ff89/40659.ipynb#scrollTo=xr382M0ATTsf), elapsed time of `tf_function_scope` is\r\n- 237 ~ 238 ms when print loss before print time\r\n- 556 ~ 558 ms when not print loss before print time\r\n\r\nIs there any particular reason why the results are different?\r\nHow could I know which elapsed time is correct?\r\n\r\nFor `hybrid` scenario, I just changed the code line that prints loss as\r\n```\r\nif step >= 10:\r\n  print(loss)\r\n```", "Was able to reproduce the issue with [TF v2.2](https://colab.research.google.com/gist/amahendrakar/c510e4213adf18fe63e3ae566c43388b/40659.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/46959205cd89e9211e0d95f215469d1a/40659-tf-nightly.ipynb). Please find the attached gist. Thanks!", "Could reproduce the issue with **`Tensorflow Version 2.5`**. Please find [the Gist](https://colab.research.google.com/gist/rmothukuru/444a308c6689841258e172ec03411b0c/40659.ipynb). Thanks!"]}, {"number": 40614, "title": "If TMP is not set, then the build system defaults to the wrong path", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS Linux release 7.3.1611 (Core)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: v2.2.0\r\n- Python version: 3.5.1\r\n- Installed using virtualenv? pip? conda?: no, compiling from source\r\n- Bazel version (if compiling from source): 2.0.0 (it claimed that Tensorflow did not support anything higher)\r\n- GCC/Compiler version (if compiling from source): 8.2.0\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: Tesla P100, 16280MiB\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nWhen building Tensorflow from source when the `TMP` environment variable is not set, then following warning is shown:\r\n\r\n```\r\nAuto-Configuration Warning: 'TMP' environment variable is not set, using 'C:\\Windows\\Temp' as default\r\n```\r\n\r\nNaturally, I would expect it to default to something. However, I'm on a _Linux_ computer, not a _Windows_ computer. On Linux, it should default to something sensible (e.g. `/tmp`, or the current directory), instead of `C:\\Windows\\Temp` - which clearly isn't going to work - as on Linux this is not a valid file/directory path.\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\nAuto-Configuration Warning: 'TMP' environment variable is not set, using 'C:\\Windows\\Temp' as default\r\n```", "comments": ["What is the commit hash you are building from?\r\n\r\nThis seems weird, it looks as if Windows defines are present. Can you share the exact sequence of commands you are running from cloning the repo until the error? With full output, please.", "@sbrl \r\nPlease update as per above comment.", "Hello! Sorry for not updating sooner, I've been a bit busy. Here's what I did:\r\n\r\n```bash\r\n# Download bazel\r\ncurl -o bazel -L https://github.com/bazelbuild/bazel/releases/download/2.0.0/bazel-2.0.0-linux-x86_64\r\nchmod +x bazel\r\n# Set the PATH\r\nexport PATH=\"${PWD}:${PATH}\";\r\n\r\n# Load the appropriate modules (I am on an academic HPC)\r\nmodule load gcc/8.2.0;\r\nmodule load python/3.5.1;\r\nmodule load utilities/multi;\r\nmodule load cuda/10.1.168;\r\n\r\n# Clone tensorflow\r\ngit clone \"https://github.com/tensorflow/tensorflow.git\" \"tensorflow\";\r\ncd tensorflow;\r\ngit checkout v2.2.0;\r\n\r\n# Configure the build\r\n./configure\r\n\r\n# Interactive answers:\r\n# python location: /trinity/clustervision/CentOS/7/apps/python/3.5.1/bin/python3\r\n# Please input the desired Python library path to use\t(left as default)\r\n# OpenCL SYCL support?\tn\r\n# ROCm support? n (unless we're on a machine with an AMD GPU)\r\n# CUDA support? y\r\n# TensorRT support? n\r\n\r\n\r\n# Then it fails to locate the CUDA header files:\r\n# \"Could not find any cudnn.h, cudnn_version.h matching version '' in any subdirectory\"\r\n\r\n# Do this to locate them:\r\n# module show cuda/10.1.168\r\n# \r\n# CUDA SDK version: 10.1\r\n# cuDNN version: (left as default)\r\n# NCCL version: (left as default - seems like it'll download & build that too)\r\n# comma-separated list of base paths to look for CUDA libraries and headers:\r\n#\t/home/ViperAppsFiles/cuda/10.1.168/,/home/ViperAppsFiles/cuda/10.1.168/bin,/home/ViperAppsFiles/cuda/10.1.168/lib,/home/ViperAppsFiles/cuda/10.1.168/lib64,/home/ViperAppsFiles/cuda/10.1.168/extras/Debugger/include,/home/ViperAppsFiles/cuda/10.1.168/extras/Debugger/lib64,/home/ViperAppsFiles/cuda/10.1.168/include,/home/ViperAppsFiles/cuda/10.1.168/sdk/10.1.168/common/inc,/home/ViperAppsFiles/cuda/10.1.168/open64/bin,/home/ViperAppsFiles/cuda/10.1.168/open64/lib,/home/ViperAppsFiles/cuda/10.1.168/extras/CUPTI/include,/home/ViperAppsFiles/cuda/10.1.168/extras/CUPTI/lib64,/home/ViperAppsFiles/cuda/10.1.168/extras/Debugger/include,/home/ViperAppsFiles/cuda/10.1.168/targets/x86_64-linux/include\r\n# \r\n\r\n# Actually do the build:\r\nbazel build --config=opt --config=monolithic //tensorflow/tools/lib_package:libtensorflow\r\n# I also tried for an unrelated (much nastier and problematic) issue:\r\nbazel build --config=opt --config=cuda --config=monolithic //tensorflow/tools/lib_package:libtensorflow\r\n```\r\n\r\n/cc @mihaimaruseac, @Saduf2019 ", "Hmm, still missing the full output of the build command. Can you run the following commands please?\r\n\r\n```\r\nbazel clean --expunge\r\nyes \"\" | python configure.py\r\nbazel build --config=opt --config=monolithic //tensorflow/tools/lib_package:libtensorflow &> log.txt\r\n```\r\n\r\nand then **attach** `log.txt` in a reply?", "@sbrl\r\nPlease update as per above comment.", "Oops! I must have missed that. Attached is the log file requested.\r\n\r\nUnfortunately though, I think that `yes \"\" | python configure.py` might have wiped the custom settings from my build. I needed those because I'm in a HPC environment, and things are in weird places. Now I'll have to reset them all over again......\r\n\r\n[log.txt](https://github.com/tensorflow/tensorflow/files/4838332/log.txt)\r\n\r\n", "Ok, so I've re-run the build with the settings described above, and here's the log.txt file:\r\n\r\n[log.txt](https://github.com/tensorflow/tensorflow/files/4838575/log.txt)\r\n\r\n(this is with cache, as I accidentally ran `bazel build --config=opt --config=monolithic //tensorflow/tools/lib_package:libtensorflow | tee ../log.txt` with a missing `2>&1` there)", "This seems to be a successful build", "```\r\nDEBUG: /home/486016/.cache/bazel/_bazel_486016/c4c32abef1f212ffa655889aa665a066/external/bazel_tools/tools/cpp/lib_cc_configure.bzl:118:5: \r\nAuto-Configuration Warning: 'TMP' environment variable is not set, using 'C:\\Windows\\Temp' as default\r\n```\r\n\r\nThis seems to be bazel printing a wrong debug message. Don't think this is an issue for TF, but can you open an issue to Bazel instead?", "Oh, ok. I've opened https://github.com/bazelbuild/bazel/issues/11650.\r\n\r\nFair warning: I've never used Bazel before, so I'm seriously out of my depth with that bug report I've made against Bazel itself.", "Update, @mihaimaruseac @Saduf2019:\r\n\r\nThe people over at Bazel in the issue referenced above say it's _not_ a bug in `bazel`. Here's a quote:\r\n\r\n> This is not a bug in Bazel.\r\n> The warning was thrown because TensorFlow was trying to generate a C++ cuda toolchain for Windows on Linux.\r\n> See [here](https://github.com/tensorflow/tensorflow/blob/62b6c316d2a9a1fb06aefb086856e76241280c08/third_party/gpus/cuda_configure.bzl#L165)\r\n> \r\n> The Windows C++ cuda toolchain is not actually used on Linux, but TF implemented the auto configuration in a way that will run on all platform.\r\n> That's why you still got a successful build with this warning.\r\n\r\nLink to comment: https://github.com/bazelbuild/bazel/issues/11650#issuecomment-652856805\r\n\r\nSo I guess this issue being opened is still relevant.", "It's interesting that the `if not is_windows(...)` lines above that check don't get triggered.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/62b6c316d2a9a1fb06aefb086856e76241280c08/third_party/gpus/cuda_configure.bzl#L140-L150\r\n\r\nI'll have to debug. You are able to get a successful build, despite this warning, right?", "@sbrl \r\nPlease update as per above comment.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Hey there, @mihaimaruseac! I can get a successful build if I specify the `TMP` environment variable, but I haven't tried to see what happens if I leave it blank.\r\n\r\nSorry about taking so long to reply again..... these times are very busy :confused: ", "I thought the log form https://github.com/tensorflow/tensorflow/issues/40614#issuecomment-650320848 was a successful build without having the `TMP` variable be set", "Ah, of course! I forgot about that. Indeed, you do get a successful build when `TMP` is not set. I just thought I'd  report it here because it looked like a bug.", "Agree it is a bug We will investigate and try to fix, but was assessing impact of bug to know how to prioritize. thank you", "Ah, I see. Thanks, @mihaimaruseac :smiley_cat: ", "> It's interesting that the `if not is_windows(...)` lines above that check don't get triggered.\r\n> \r\n> https://github.com/tensorflow/tensorflow/blob/62b6c316d2a9a1fb06aefb086856e76241280c08/third_party/gpus/cuda_configure.bzl#L140-L150\r\n> \r\n> I'll have to debug. You are able to get a successful build, despite this warning, right?\r\n\r\nI am facing the same problem, I got a successful build but could not find my .whl file in /tmp directory of ubuntu", "`blaze build //.../build_pip_package` only builds a binary that will then be used to build the actual wheel. This is WAI.", "@mihaimaruseac what does `WAI` stand for? I'm very confused.", "@sbrl \r\nIs this still an issue", "@sbrl WAI = working as intended\r\n\r\nFor context: There was a comment that is now deleted where the author was only using `bazel build //.../build_pip_package` and was expecting that to generate the pip wheel.", "@sbrl \r\nPlease move the issue to closed status if resolved.", "It's not resolved, there is only a workaround.", "I'm still seeing this. I'm confused though. @mihaimaruseac says it's working as intended, but it's also a workaround? It's confusing for people building tensorflow, so I thought I'd report it just in case. If everyone thinks this should be closed then I'll close it, but I'm not so sure it's working as intended if it it's a misleading log message that confuses people.", "@sbrl sorry, the WAI comment was for a(n offtopic) comment that got deleted, not for the entire issue", "Ah, no worries. In that case I'll leave this open.", "Failing to build TF@2.1 with spack build. Looks like failing due to same reason as above. Just wanted to know where can I set the TMP variable? and how to set it? I have tried setting it on the command line but it is ignoring it.", "@samcom12 note that this issue only results in a warning, the build succeeds. So it is likely your issue is different.\r\n\r\nTo set the environment variable you have to use `export` or similar constructs for your shell."]}, {"number": 40605, "title": "Dynamical Tensor (and EagerTensor) slice assignment", "body": "**System information**\r\n- TensorFlow version (you are using): 2.2\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nI would like to have slice assignment for Tensor objects in TensorFlow.\r\nThe code I would like to write is:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\na = tf.constant([1, 2, 4, 5, 7, 3, 2, 6,])\r\nindices = tf.constant([3, 4], dtype=tf.int32)\r\n\r\na[indices] += 1\r\n```\r\n\r\nOf course it's a simplistic example and doesn't cover everything I want to do (I would use it in more complex functions not with constants), and I am happy to make it more complex if necessary.\r\n\r\nCurrently this code gives the error:\r\n```\r\nTypeError: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got <tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 4], dtype=int32)>\r\n```\r\n\r\n**Will this change the current api? How?**\r\n\r\nI guess this is a change of API since it introduces a new functionality.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nA lot of people have been asking for this feature for example in this GitHub issues:\r\n- https://github.com/tensorflow/tensorflow/issues/14132#issuecomment-483002522\r\n- https://github.com/tensorflow/tensorflow/issues/33131\r\n\r\nThese issues have unfortunately been closed because some workarounds for specific use-cases have been found (ones where the slicing is fixed and you can use [masking](https://github.com/tensorflow/tensorflow/issues/14132#issuecomment-483002522) or [TensorArrays](https://github.com/tensorflow/tensorflow/issues/14132#issuecomment-487643287)).\r\nSome other issues deal with `Variable`s which is not what I am talking about here. [Some workarounds do exist](https://stackoverflow.com/a/62202181/4332585) involving `Variable` but they seem hacky.\r\n\r\nI will personally benefit from it, in the multiple places where I now use `tensor_scatter_nd_add` or `tensor_scatter_nd_update`, which is solution that always works but is very difficult to write and very slow:\r\n\r\n- [for a wavelet-based neural network, called MWCNN](https://github.com/zaccharieramzi/tf-mwcnn/blob/master/mwcnn.py#L106-L110);\r\n- [for non-uniform fast fourier transform](https://github.com/zaccharieramzi/tfkbnufft/blob/master/tfkbnufft/nufft/interp_functions.py#L151);\r\n- [for sensitivity map extraction when doing MRI reconstruction with TensorFlow neural networks](https://github.com/zaccharieramzi/fastmri-reproducible-benchmark/blob/master/fastmri_recon/data/utils/multicoil/smap_extract.py#L27-L35).\r\n\r\n**Any Other info.**\r\n\r\nThe `tensor_scatter_nd_*` alternative might seem like a viable solution, but it suffers from 2 drawbacks that I consider huge:\r\n- It is very difficult to write. It is actually so difficult, I decided to make a package that would alleviate this difficulty by having the different slicing possibilities unit tested: [tf-slice-assign](https://github.com/zaccharieramzi/tf-slice-assign).\r\n- It is very slow. I made a [benchmark notebook](https://colab.research.google.com/drive/1gEjha7h1mhQkFwULS9MAU0bWQfzfEALY?usp=sharing) vs `pytorch` for slice assignment add. You can see that on GPU, using `tensor_scatter_nd_add` is 10 times slower than slice assignment in `pytorch` and 20 times slower on CPU. For a practical example, it means that my `tfkbnufft` (for non-uniform fast fourier transform) package is 30 times slower than its [torch counterpart](https://github.com/mmuckley/torchkbnufft#computation-speed) which I translated. This currently removes the possibility of training neural networks using the non-uniform fourier transform in TensorFlow.", "comments": ["Current solutions exist but are inefficient and not \"pythonic\":\r\n\r\n1. Create a mask as it says this [comment](https://github.com/tensorflow/tensorflow/issues/14132#issuecomment-483002522) and this [post](https://towardsdatascience.com/how-to-replace-values-by-index-in-a-tensor-with-tensorflow-2-0-510994fe6c5f).\r\n\r\n1. (Haven't tested it yet) but apparently you could also use [tf.tensor_scatter_nd_update](https://www.tensorflow.org/api_docs/python/tf/tensor_scatter_nd_update). This [question](https://stackoverflow.com/questions/62092147/how-to-efficiently-assign-to-a-slice-of-a-tensor-in-tensorflow) also talks about it.\r\n\r\nI also would like this to be possible. It will solve my problem.", "@ymodak any update ? "]}, {"number": 40594, "title": "tf.signal.irfft(2d/3d) documentation refers `input` and `Treal` as arguments.", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/signal/irfft\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/signal/irfft2d\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/signal/irfft3d\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nIn the `Args` section, there are inputs `input` and `Treal`. `Treal` no longer exist, and `input` should be `input_tensor`.\r\n\r\nRunning code:\r\n\r\n~~~python\r\ntf.signal.irfft(1, Treal=tf.float32) \r\n~~~\r\n\r\ngot exception:\r\n\r\n~~~python\r\nTypeError: _irfft() got an unexpected keyword argument 'Treal'\r\n~~~\r\n\r\nAnd if run code:\r\n\r\n~~~python\r\ntf.signal.irfft(input=1)\r\n~~~\r\n\r\ngot exception:\r\n\r\n~~~python\r\nTypeError: _irfft() got an unexpected keyword argument 'input'\r\n~~~\r\n\r\n### Parameters defined\r\n\r\nYes\r\n\r\n### Returns defined\r\n\r\nYes\r\n\r\n### Raises listed and defined\r\n\r\nNo\r\n\r\n## System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Mojave 10.14\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 2.2.0-rc3\r\n- **Python version**: 3.8.2\r\n", "comments": []}, {"number": 40576, "title": "Trying to dynamically change weighted connections between training examples", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.0\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI would like to be able to change the routing of the weighted connections between training examples. I have developed the theory for a type of neural network that takes in as input a random vector of ints between 0 and 10 (and maps it to an image). then takes these ints and after adding 200 multiples of 10 for each dimension, i use this result as the index in tf.gather with the default weight matrix which is of shape (10,200). The reason we add multiples of 200 is because the first hidden layer will have 200 neurons and we want each possible number in the input to come with its own weighted connections. So between examples we will be loading different weighted connections into the weight matrix of the layer dependant on the input.\r\n\r\nif two dimesnions happen to have the same numebr they will both load in the same connections in their respective dimensions. On top of this, to make each entry in the dimension unique we employ a circulant routing where the first neuron enters its entries in root position, while the next one rotates them by one, then the next one rotates them by 2 and so on. So a 2 in the nth position will have a different effect on the next layer from a 2 in the nth +1 position.\r\n\r\nAdditionally, Once the input layer is arranged dynamically we mirror the form within other layers that inherit from the input layer. So if there is a 3 in the nth position of the first layer. The next layer will have \"3\" weighted connections in its nth position. Note that these are not the same weighted connections that the first layer had , but a corresponding vector of weighted connections that go with it , but for the next layer. (we could not use the input into that layer to order its connections because tf._gather requires indices that are ints).\r\n\r\ni would also like to somehow do this for convolutional layers too if the logic permits.\r\n\r\nHere is some code that attempted to do all of this and a link to a colab file.\r\n\r\n\r\n**Will this change the current api? How?**\r\nI am not sure if it will because i have been trying to do it with no success\r\n\r\n**Who will benefit with this feature?**\r\n\r\nthis is a new generative algorithm that will benefit the AI community in general.\r\n\r\n**Any Other info.**\r\nhttps://colab.research.google.com/drive/1mWAQH1jJMFJ0NTKrqLxzet47aUXm9wWz?usp=sharing", "comments": []}, {"number": 40555, "title": "TFLite General OpenGL delegate ", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.2/master on Ubuntu 18.04\r\n- Are you willing to contribute it (Yes/No): Yes, I have a working version on TF 2.2.\r\n\r\n**Describe the feature and the current behavior/state.**\r\nDeprecated GL delegate runs in the GL context attached to the calling thread, instead of initializing an EGL/GLES context upon preparation.           \r\n\r\n**Will this change the current api? How?**\r\nThis change would allow builds to macro out all references to EGL/GLES in the deprecated gl_delegate package.  A build target ~\"libgeneral_opengl.so\" would be added to the lite/delegates/gpu BUILD file.  Users would provide paths to the relevant OpenGL headers (glew, glad, gl3w...) and link flags in the BUILD file.  The GL context would be initialized outside of the TFLite API. \r\n\r\n**Who will benefit with this feature?**\r\nAnyone looking to integrate TFLite into their OpenGL render pipeline, without having to deal with GLES/Android dependencies.  Particularly useful for Linux users looking to build plugins for other engines e.g. Unreal or Unity.  \r\n\r\n**Any Other info.**\r\nPerfectly understandable if this change is undesired, since simple GPU acceleration for Android is the only reason the GL delegate exists.  Asking here before PRing so I don't waste time merging into master from my 2.2 based branch.   ", "comments": ["\"Anyone looking to integrate TFLite into their OpenGL render pipeline, without having to deal with GLES/Android. Particularly useful for Linux users looking to build plugins for other engines e.g. Unreal or Unity.\"\r\n\r\nThis sounds interesting. Adding people who know more about this.", "Also, I'm not sure how deprecation works at the scale of a project like TF.  Either, \r\n\r\n1.   you don't people adding to a deprecated feature, because it will soon be removed entirely, \r\n2.  you don't want additions because that will result in support requests for something the TF team would rather ignore, or\r\n3.  adding to deprecated features is fine, because they're deprecated and thus nobody is obligated to support them.\r\n\r\nI tested this idea with the deprecated GL delegate for simplicity's sake.  If it's on the chopping block I'll refocus to making the gl package changes work with the V2 multi-backend delegate. \r\n\r\nI figured this change would hold similar status to the [MacOS Metal delegate changes](https://github.com/tensorflow/tensorflow/pull/34522). Documentation would be provided through comments.  Support would just be \"best effort.\"", "@impjdi  Hi, just checking in to see if anyone has an update on this.  I was also wondering if anyone plans on upgrading the GL delegate's [mean kernel](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/gpu/gl/kernels/mean.cc) from the current naive implementation.\r\n\r\nI was testing my real time style transfer demo with a 1660ti and the mean kernel was a staggering bottleneck.  For now I just approximate the mean by increasing the loop's increment to 8 and multiplying the result by 64 (12 -> 76 fps boost).  Unless someone plans on parallelizing it across more workgroups soon I might take a whack at it.  Diving through the TFL compiler structure should be a windy rabbit hole \ud83d\ude0a  ", "Sorry for the late response; I somehow failed to prioritize certain github issues and just read this.\r\n\r\nDue to the small team size, it's impossible for us to accommodate non-Android use cases.  We know that with a small change, things can run on Linux desktops using Mesa, but hey, it didn't run on my desktop, so we're not even trying to sell that it works on Linux desktops.  If you're trying to employ the OpenGL ES backend for some other platform, you're unfortunately on your own and we won't be able to help.\r\n\r\nre: the deprecated delegate, we will just remove it from the repository.  In fact, it hasn't been updated for quite some time unlike the new v2 delegate, so I suggest that you switch over.\r\n\r\nre: `MEAN`, you may want to check the OpenCL kernels.  That may have better kernel implementations.", "@impjdi Thanks for the update!  My apologies for the lag in this response.  Just to be clear, the ```gl_delegate.cc/.h``` files will be removed, but most/all files in ```delegates/gpu/gl/``` will stay for use in the v2 delegate?  I ask because developed a new ```MEAN``` GLSL kernel that runs fast enough for real-time style transfer, and I don't want dig into the official testing process if _all_ OpenGL delegation will be removed/replaced by OpenCL. ", "That is correct.  We probably can't remove OpenGL in favor of OpenCL, because OpenCL is not available on all Android devices."]}, {"number": 40539, "title": "Feature request: facemesh example for tensorflow lite", "body": " Facemesh example for tensorflow lite\r\n\r\nTo get the result of facemesh we need first to detect face using blazeface\u3002But how to use the result of blazeface estimation as the input of facemesh model, it is not very clear.\r\nCan we have a facemesh example for tensorflow lite ?", "comments": ["Hi guys, @ymodak @xunkai55.\r\nDo we have an example using facemesh on tensorflow lite now? ", "Thank you for the feature request! \r\n\r\nI think you are asking some sample code from MediaPipe: https://google.github.io/mediapipe/solutions/face_mesh.html, an application framework that uses TFLite.", "I would love to get sample code to (in normal form, can't open the bazel one)"]}, {"number": 40538, "title": "[TF2.2] Build libtensorflow_cc.so for C++ APIs", "body": "**System information**:\r\n- OS Platform and Distribution: Linux Ubuntu 18.04\r\n- TensorFlow installed source: source\r\n- TensorFlow version: 2.2.0 stable\r\n- Python version: python3\r\n- Bazel version: using Bazelisk with Bazel 2.0.0 version as required from tf-2.2.0\r\n- GCC/Compiler version (if compiling from source): GCC-8\r\n- CUDA/cuDNN version: No CUDA (for the moment)\r\n\r\n**What I have done**:\r\n- Got tensorflow from github:\r\n```\r\ngit clone --recurse-submodules https://github.com/tensorflow/tensorflow.git\r\ncd tensorflow\r\ngit checkout v2.2.0\r\n```\r\n\r\n- Installed and setted up Bazelisk:\r\n( Using this guide: https://gist.github.com/philwo/f3a8144e46168f23e40f291ffe92e63c )\r\n```\r\n$ sudo curl -Lo /usr/local/bin/bazel https://github.com/bazelbuild/bazelisk/releases/download/v1.1.0/bazelisk-linux-amd64\r\n$ sudo chmod +x /usr/local/bin/bazel\r\n```\r\n\r\n`$ grep -r _TF_MAX_BAZEL_VERSION .`\r\n`./configure.py:_TF_MAX_BAZEL_VERSION = '2.0.0'`\r\n\r\n```\r\n$ echo '2.0.0' > .bazelversion\r\n$ bazel version\r\n```\r\n\r\n- Start building tensorflow with Bazel:\r\n```\r\n$ ./configure\r\n\r\nsudo bazel --host_jvm_args=-Xmx28G build --jobs=8 --config=monolithic --config=v2 --config=opt --verbose_failures //tensorflow:libtensorflow_cc.so\r\n\r\nsudo bazel --host_jvm_args=-Xmx28G build --jobs=8 --config=monolithic --config=v2 --config=opt --verbose_failures //tensorflow:libtensorflow_framework.so\r\n```\r\n\r\nAs mentioned here: https://itnext.io/how-to-use-your-c-muscle-using-tensorflow-2-0-and-xcode-without-using-bazel-builds-9dc82d5e7f80 I looked for `tensorflow/contrib/makefile/download_dependencies.sh` but there is no tensorflow/contrib, since v2.1.0.\r\n\r\n- Copied libraries and headers:\r\n```\r\n# cp -rfvdp tensorflow/bazel-bin/tensorflow/*.so* /opt/tensorflow/lib\r\n# sudo find . -name \"*.h*\" | sudo cpio -updm /opt/tpt/tensorflow/include/tensorflow\r\n```\r\n- Created first dummy example:\r\n```\r\n#include <stdlib.h>\r\n#include <stdio.h>\r\n#include \"tensorflow/c/c_api.h\"\r\n\r\n#include <tensorflow/core/platform/env.h>\r\n#include <tensorflow/core/public/session.h>\r\n#include <iostream>\r\nusing namespace std;\r\nusing namespace tensorflow;\r\n\r\nint main() {return 0;}\r\n```\r\n\r\n- Trying to compile:\r\n`gcc -O3 -o test -I /opt/tensorflow/include main.cpp -L /opt/tensorflow/lib -l tensorflow_cc`\r\n\r\n- Error:\r\n```\r\nIn file included from /opt/tpt/tensorflow_cpp/include/tensorflow/core/platform/types.h:22,\r\n                 from /opt/tpt/tensorflow_cpp/include/tensorflow/core/platform/env_time.h:20,\r\n                 from /opt/tpt/tensorflow_cpp/include/tensorflow/core/platform/env.h:26,\r\n                 from main.cpp:5:\r\n/opt/tpt/tensorflow_cpp/include/tensorflow/core/platform/tstring.h:29:10: fatal error: absl/strings/string_view.h: No such file or directory\r\n #include \"absl/strings/string_view.h\"\r\n          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\ncompilation terminated.\r\n```", "comments": ["@kinos9,\r\nPlease check [this comment](https://github.com/tensorflow/tensorflow/issues/22240#issuecomment-420782646) from a similar issue and let us know if it works. Thanks!", "> @kinos9,\r\n> Please check [this comment](https://github.com/tensorflow/tensorflow/issues/22240#issuecomment-420782646) from a similar issue and let us know if it works. Thanks!\r\n\r\nThanks, that not works because contrib is not present since tf-2.1.0. However I found those headers in include/tensorflow/src.\r\n\r\nNow I'm trying to compile a first simple program:\r\n\r\n```\r\n#include <stdlib.h>\r\n\r\n#include <fstream>\r\n#include <iostream>\r\n#include <string>\r\n#include <vector>\r\n\r\n#include \"class_name.h\"\r\n#include \"tensorflow/cc/ops/const_op.h\"\r\n#include \"tensorflow/cc/ops/standard_ops.h\"\r\n#include \"tensorflow/core/framework/tensor.h\"\r\n#include \"tensorflow/core/graph/default_device.h\"\r\n#include \"tensorflow/core/graph/graph_def_builder.h\"\r\n#include \"tensorflow/core/lib/core/errors.h\"\r\n#include \"tensorflow/core/lib/core/stringpiece.h\"\r\n#include \"tensorflow/core/lib/core/threadpool.h\"\r\n#include \"tensorflow/core/lib/io/path.h\"\r\n#include \"tensorflow/core/lib/strings/stringprintf.h\"\r\n#include \"tensorflow/core/platform/env.h\"\r\n#include \"tensorflow/core/platform/init_main.h\"\r\n#include \"tensorflow/core/platform/logging.h\"\r\n#include \"tensorflow/core/platform/types.h\"\r\n#include \"tensorflow/core/public/session.h\"\r\n#include \"tensorflow/core/util/command_line_flags.h\"\r\n\r\nusing namespace tensorflow;\r\nusing tensorflow::Flag;\r\nusing tensorflow::Status;\r\nusing tensorflow::string;\r\nusing tensorflow::Tensor;\r\n\r\n//Read the image file, apply appropriate decoding depending on type of image\r\nint TensorFromFile(string filename, const int i_height, const int i_width, std::vector<Tensor>* o_tensors) {\r\n  tensorflow::Status status;\r\n  auto root = tensorflow::Scope::NewRootScope();\r\n  using namespace ::tensorflow::ops;\r\n  std::unique_ptr<tensorflow::Session> session(tensorflow::NewSession({}));\r\n  tensorflow::GraphDef graph;\r\n\r\n  auto reader = tensorflow::ops::ReadFile(root.WithOpName(\"img_reader\"), filename);\r\n  const int channels = 1;\r\n  tensorflow::Output imgreader;\r\n\r\n  if (tensorflow::str_util::EndsWith(filename, \".png\")) {\r\n    imgreader = DecodePng(root.WithOpName(\"png_reader\"), reader, DecodePng::Channels(channels));\r\n  } else if (tensorflow::str_util::EndsWith(filename, \".gif\")) {\r\n    imgreader = DecodeGif(root.WithOpName(\"gif_reader\"), reader);\r\n  } else {\r\n    imgreader = DecodeJpeg(root.WithOpName(\"jpeg_reader\"), reader, DecodeJpeg::Channels(channels));\r\n  }\r\n\r\n  auto f_caster = Cast(root.WithOpName(\"float_caster\"), imgreader, tensorflow::DT_FLOAT);\r\n  ExpandDims(root.WithOpName(\"output\"), f_caster, 0);\r\n\r\n  status = root.ToGraphDef(&graph);\r\n  if (!status.ok()) {\r\n    LOG(ERROR) << status.ToString();\r\n    return -1;\r\n  }\r\n\r\n  status = session->Create(graph);\r\n  if (!status.ok()) {\r\n    LOG(ERROR) << status.ToString();\r\n    return -1;\r\n  }\r\n\r\n  status = session->Run({}, {\"output\"}, {}, o_tensors);\r\n  if (!status.ok()) {\r\n    LOG(ERROR) << status.ToString();\r\n    return -1;\r\n  }\r\n\r\n  return 0;\r\n}\r\n\r\nint main(int argc, char* argv[]) {\r\n  using namespace ::tensorflow::ops;\r\n  tensorflow::Status status;\r\n\r\n  std::string delimiter = \".\";\r\n  std::string ofilename;\r\n  std::vector<Tensor> inputs;\r\n  std::vector<Tensor> outputs;\r\n\r\n  std::string graph_path = \"../../graphs/test0/\";\r\n  std::string image_path = \"../../graphs/test0.png\";\r\n\r\n  std::string mdlpath(graph_path);\r\n  std::string imgpath(image_path);\r\n  int32 inputdim = 32;\r\n\r\n  std::unique_ptr<tensorflow::Session> session(tensorflow::NewSession({}));\r\n  tensorflow::GraphDef graph;\r\n\r\n  //read model file\r\n  status = ReadBinaryProto(Env::Default(), mdlpath, &graph);\r\n  if (!status.ok()) {\r\n    std::cout << status.ToString() << \"\\n\";\r\n    return -1;\r\n  }\r\n\r\n  //add graph to scope\r\n  status = session->Create(graph);\r\n  if (!status.ok()) {\r\n    std::cout << status.ToString() << \"\\n\";\r\n    return -1;\r\n  }\r\n\r\n  //Read input image, assuming to be a sqaure image\r\n  if (TensorFromFile(imgpath, inputdim, inputdim, &inputs)) {\r\n    LOG(ERROR) << \"Image reading failed\"\r\n               << \"\\n\";\r\n    return -1;\r\n  }\r\n\r\n  LOG(INFO) << \"OK\";\r\n\r\n  std::cout << \"input dimension of the image: \" << inputs[0].DebugString() << std::endl;\r\n\r\n  //get the appropriate input and out layer names from the graph/mode to execute\r\n  auto inputlayer = graph.node(0).name();\r\n  auto outputlayer = graph.node(graph.node_size() - 1).name();\r\n\r\n  status = session->Run({{inputlayer, inputs[0]}}, {outputlayer}, {}, &outputs);\r\n  if (!status.ok()) {\r\n    LOG(ERROR) << status.ToString();\r\n    return -1;\r\n  }\r\n\r\n  std::cout << \"Output dimension of the image\" << outputs[0].DebugString() << std::endl;\r\n\r\n  //create filename\r\n  ofilename.append(imgpath.substr(0, imgpath.find(delimiter)));\r\n  ofilename.append(\"_mask.png\");\r\n\r\n  std::cout << \"output filename: \" << ofilename << std::endl;\r\n\r\n  //Now write this to a image file\r\n  //if (TensorToFile(ofilename, outputs, threshold)) return -1;\r\n\r\n  session->Close();\r\n\r\n  return 0;\r\n}\r\n```\r\nif I use theese flags:\r\n`g++ -O3 -m64 -o test -I /opt/tpt/tensorflow_cpp_scratch/include/tensorflow/bazel-bin main.cpp -L /opt/tpt/tensorflow_cpp_scratch/lib -l tensorflow_cc`\r\n\r\nI get this error:\r\n```\r\n/tmp/cc4xzZGr.o: In function `google::protobuf::RepeatedPtrField<tensorflow::NodeDef>::TypeHandler::WeakType const& google::protobuf::internal::RepeatedPtrFieldBase::Get<google::protobuf::RepeatedPtrField<tensorflow::NodeDef>::TypeHandler>(int) const':\r\nmain.cpp:(.text._ZNK6google8protobuf8internal20RepeatedPtrFieldBase3GetINS0_16RepeatedPtrFieldIN10tensorflow7NodeDefEE11TypeHandlerEEERKNT_8WeakTypeEi[_ZNK6google8protobuf8internal20RepeatedPtrFieldBase3GetINS0_16RepeatedPtrFieldIN10tensorflow7NodeDefEE11TypeHandlerEEERKNT_8WeakTypeEi]+0x6a): undefined reference to `google::protobuf::internal::LogMessage::LogMessage(google::protobuf::LogLevel, char const*, int)'\r\nmain.cpp:(.text._ZNK6google8protobuf8internal20RepeatedPtrFieldBase3GetINS0_16RepeatedPtrFieldIN10tensorflow7NodeDefEE11TypeHandlerEEERKNT_8WeakTypeEi[_ZNK6google8protobuf8internal20RepeatedPtrFieldBase3GetINS0_16RepeatedPtrFieldIN10tensorflow7NodeDefEE11TypeHandlerEEERKNT_8WeakTypeEi]+0x79): undefined reference to `google::protobuf::internal::LogMessage::operator<<(char const*)'\r\nmain.cpp:(.text._ZNK6google8protobuf8internal20RepeatedPtrFieldBase3GetINS0_16RepeatedPtrFieldIN10tensorflow7NodeDefEE11TypeHandlerEEERKNT_8WeakTypeEi[_ZNK6google8protobuf8internal20RepeatedPtrFieldBase3GetINS0_16RepeatedPtrFieldIN10tensorflow7NodeDefEE11TypeHandlerEEERKNT_8WeakTypeEi]+0x86): undefined reference to `google::protobuf::internal::LogFinisher::operator=(google::protobuf::internal::LogMessage&)'\r\nmain.cpp:(.text._ZNK6google8protobuf8internal20RepeatedPtrFieldBase3GetINS0_16RepeatedPtrFieldIN10tensorflow7NodeDefEE11TypeHandlerEEERKNT_8WeakTypeEi[_ZNK6google8protobuf8internal20RepeatedPtrFieldBase3GetINS0_16RepeatedPtrFieldIN10tensorflow7NodeDefEE11TypeHandlerEEERKNT_8WeakTypeEi]+0x8e): undefined reference to `google::protobuf::internal::LogMessage::~LogMessage()'\r\nmain.cpp:(.text._ZNK6google8protobuf8internal20RepeatedPtrFieldBase3GetINS0_16RepeatedPtrFieldIN10tensorflow7NodeDefEE11TypeHandlerEEERKNT_8WeakTypeEi[_ZNK6google8protobuf8internal20RepeatedPtrFieldBase3GetINS0_16RepeatedPtrFieldIN10tensorflow7NodeDefEE11TypeHandlerEEERKNT_8WeakTypeEi]+0xb2): undefined reference to `google::protobuf::internal::LogMessage::LogMessage(google::protobuf::LogLevel, char const*, int)'\r\nmain.cpp:(.text._ZNK6google8protobuf8internal20RepeatedPtrFieldBase3GetINS0_16RepeatedPtrFieldIN10tensorflow7NodeDefEE11TypeHandlerEEERKNT_8WeakTypeEi[_ZNK6google8protobuf8internal20RepeatedPtrFieldBase3GetINS0_16RepeatedPtrFieldIN10tensorflow7NodeDefEE11TypeHandlerEEERKNT_8WeakTypeEi]+0xc1): undefined reference to `google::protobuf::internal::LogMessage::operator<<(char const*)'\r\nmain.cpp:(.text._ZNK6google8protobuf8internal20RepeatedPtrFieldBase3GetINS0_16RepeatedPtrFieldIN10tensorflow7NodeDefEE11TypeHandlerEEERKNT_8WeakTypeEi[_ZNK6google8protobuf8internal20RepeatedPtrFieldBase3GetINS0_16RepeatedPtrFieldIN10tensorflow7NodeDefEE11TypeHandlerEEERKNT_8WeakTypeEi]+0xce): undefined reference to `google::protobuf::internal::LogFinisher::operator=(google::protobuf::internal::LogMessage&)'\r\nmain.cpp:(.text._ZNK6google8protobuf8internal20RepeatedPtrFieldBase3GetINS0_16RepeatedPtrFieldIN10tensorflow7NodeDefEE11TypeHandlerEEERKNT_8WeakTypeEi[_ZNK6google8protobuf8internal20RepeatedPtrFieldBase3GetINS0_16RepeatedPtrFieldIN10tensorflow7NodeDefEE11TypeHandlerEEERKNT_8WeakTypeEi]+0xd6): undefined reference to `google::protobuf::internal::LogMessage::~LogMessage()'\r\nmain.cpp:(.text._ZNK6google8protobuf8internal20RepeatedPtrFieldBase3GetINS0_16RepeatedPtrFieldIN10tensorflow7NodeDefEE11TypeHandlerEEERKNT_8WeakTypeEi[_ZNK6google8protobuf8internal20RepeatedPtrFieldBase3GetINS0_16RepeatedPtrFieldIN10tensorflow7NodeDefEE11TypeHandlerEEERKNT_8WeakTypeEi]+0xf5): undefined reference to `google::protobuf::internal::LogMessage::~LogMessage()'\r\ncollect2: error: ld returned 1 exit status\r\n```\r\n\r\nIt seems that protobuf lib is missing. So I added also `-ltensorflow_framework`\r\nIt compile without errors, BUT i get this error:\r\n\r\n```\r\n[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:118] File already exists in database: google/protobuf/any.proto\r\n[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1367] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): \r\nterminate called after throwing an instance of 'google::protobuf::FatalException'\r\n  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): \r\nAborted (core dumped)\r\n```\r\n\r\nWhy I'm getting those errors?\r\n\r\nI already read this:\r\nhttps://github.com/tensorflow/tensorflow/issues/14632\r\nand this:\r\nhttps://github.com/tensorflow/tensorflow/issues/40004\r\nbut I wasn't able to fix it.\r\n\r\nThx", "Now it seems to work:\r\nI compiled with\r\n`bazel --host_jvm_args=-Xmx30G build --jobs=8 --config=v2 --config=opt --copt=-O3 --copt=-m64 --copt=-march=native --verbose_failures //tensorflow:install_headers //tensorflow:tensorflow  //tensorflow:tensorflow_cc //tensorflow:tensorflow_framework  //tensorflow/tools/lib_package:libtensorflow`\r\n\r\nwithout `--config=monolithic` parameter.\r\n\r\nWhat `--config=monolithic` exactly do?", "> What `--config=monolithic` exactly do?\r\n\r\n@kinos9,\r\nAs per the [.bazelrc](https://github.com/tensorflow/tensorflow/blob/080851ad09152127ec7664c626b30c71268009fb/.bazelrc#L31) file, monolithic compiler option builds all TF C++ code into a single shared object. Also, please take a look at [this](https://stackoverflow.com/a/56576464) similar StackOverflow query. \r\nPlease feel free to close the issue if resolved. Thanks!", "> > What `--config=monolithic` exactly do?\r\n> \r\n> @kinos9,\r\n> As per the [.bazelrc](https://github.com/tensorflow/tensorflow/blob/080851ad09152127ec7664c626b30c71268009fb/.bazelrc#L31) file, monolithic compiler option builds all TF C++ code into a single shared object. Also, please take a look at [this](https://stackoverflow.com/a/56576464) similar StackOverflow query.\r\n> Please feel free to close the issue if resolved. Thanks!\r\n\r\nOk thanks, I know that, but why it gives to me errors mentioned above?"]}, {"number": 40498, "title": "tf.GatherV2 is always not support ", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):18.04\r\n- TensorFlow installed from (source or binary):pip\r\n- TensorFlow version (or github SHA if from source):\r\n2.2\r\n\r\n**Provide the text output from tflite_convert**\r\ntflite_convert   --from_keras_model\r\n```\r\n# Copy and paste here\r\n```\r\n\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\n**Any other info / logs**\r\ntf.gatherV2 op is neither a custom op nor a flex op\r\nInclude any logs or source code that would be helpful to diagnose the problem.\r\nIf including tracebacks, please include the full traceback. Large logs and files\r\nshould be attached.\r\n\r\nmy use case is  tf.gather(params.index,batch_dims=1)", "comments": ["@sunzhe09 could you try the conversion with flex?\r\nhttps://www.tensorflow.org/lite/guide/ops_select", "@abattery I want to run on android,the   flexop is not support (I test it with benchmark)", "@sunzhe09 Actually you can run with `org.tensorflow:tensorflow-lite-select-tf-ops:0.0.0-nightly` aar. If you have concern about the binary size requirement, @thaink can help you in that area.", "@abattery thx! besides, if I want to post train quant my model ,what should I do? @thaink  can you help me?", "For the post-quantization training, you can just use the following option during conversion.\r\nFYI, https://www.tensorflow.org/lite/performance/post_training_quantization#dynamic_range_quantization\r\n\r\n```\r\nimport tensorflow as tf\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\ntflite_quant_model = converter.convert()\r\n```", "in fact\uff0cmy use case  is full quant :\r\nimport tensorflow as tf\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\ndef representative_dataset_gen():\r\n  for _ in range(num_calibration_steps):\r\n    # Get sample input data as a numpy array in a method of your choosing.\r\n    yield [input]\r\nconverter.representative_dataset = representative_dataset_gen\r\ntflite_quant_model = converter.convert()\r\nis this mode support with flexop ?", "As far as I know, the mode will be supported with the flex op. If you have any issues with it, please let us know.", "We haven't have an official guide to do the selective build to save binary size yet. But if you want to do that, please let me know.", "@abattery I found it can't  use with tf.lite.OpsSet.TFLITE_BUILTINS_INT8 and tf.lite.OpsSet.SELECT_TF_OPS  ,it  will  get  an error  with \"tf.GatherV2 op is neither a custom op nor a flex op\"   ,but with  tf.lite.OpsSet.TFLITE_BUILTIN and tf.lite.OpsSet.SELECT_TF_OPS   it will   pass", "I see. Thanks for reporting the issue. Will take a look at the issue."]}, {"number": 40487, "title": "tfcompile for non-x86-64 CPU", "body": "Are there possibilities to cross-compile with `tfcompile` for other architectures (aarch64, CortexM, etc..)?", "comments": []}, {"number": 40486, "title": "tfcompile AOT with quantization", "body": "Does the `tfcompile` have capability of quantization?\r\nIs `tfcompile` able to process on input the quantized models?", "comments": ["@peter197321 \r\n\r\nCan you please refer this[ link ](https://www.tensorflow.org/xla/tfcompile )and see if it helps you.\r\n\r\nThis question is better asked on StackOverflow since it is not a bug or feature request. There is also a larger community that reads questions there and provide better and faster support for such issues. Thanks!", "I think the link provided does not help since AOT compilation works  for x86-64 CPU only as indicated in [AOT (Ahead-of-time) compilation for CPU with tfcompile](https://www.tensorflow.org/xla#aot_ahead-of-time_compilation_for_cpu_with_tfcompile) \r\n\r\nThis is not a question but a feature request:\r\n\r\nAdd additional targets in `XLA/tfcomplie` for other platforms other than x86-64 CPU e.g. Cortex-A, Cortex-M (ARM-based devices).\r\n\r\n"]}, {"number": 40482, "title": "Support for use of tensorflow_probability.distributions.Distribution instances in model.fit(...)", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.1.0\r\n- Are you willing to contribute it (Yes/No): No (have yet to work out the best way to implement)\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nI have a model that I would like to train using the KL divergence between the model output and a tfp.distributions.Distribution instance. (Note: this model is using tensorflow_probability's probabilistic layers). As of right now, Distributions cannot be plumbed through the model.fit(...) pipeline due to incompatibilities with the DataAdapter classes, as:\r\n\r\n1) They are not recognised by TensorLikeDataAdapter as a Tensor-like object (i.e. they fail the _is_tensor() check).\r\n\r\n2) tf.keras.utils.Sequence instances that return distributions fail in convert_for_inspection (calling np.array(distribution,dtype='float64') fails as np sees distributions as sequences).\r\n\r\n**Will this change the current api? How?**\r\nChange to support this should have no effect on the API, but would expand functionality to users of tf and tfp.\r\n\r\n**Who will benefit with this feature?**\r\nUsers who use both tf and tfp, and need to use distributions to train models.\r\n\r\n**Any Other info.**\r\n", "comments": []}, {"number": 40468, "title": "Gradient compression", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.2\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nFeature: Gradient compression\r\nDescription: In distributed deep learning, communication of gradients often become a bottleneck. Gradient compression allows the gradients to be compressed so that the cost of communication is reduced. [Horovod](https://github.com/horovod/horovod) has a compression scheme built-in [here](https://github.com/horovod/horovod/blob/master/horovod/tensorflow/compression.py). The compression can speed up the distributed training (proved by various research). Building such a feature to Tensorflow would facilitate research as well as development.\r\n\r\n**Will this change the current api? How?**\r\n\r\n\r\n**Who will benefit with this feature?**\r\nPeople who are interested in large scale distributed training. \r\n\r\n**Any Other info.**\r\n", "comments": ["Pytorch is working on something similar [here](https://github.com/pytorch/pytorch/issues/39272).\r\n\r\nNormally in a single worker system we can obtain the gradients using `compute_gradients()` function,  and make modifications to it, and then apply the gradients using `apply_gradients()` function. \r\n\r\nHow does this change in the distributed setting? More specifically how can we access the gradients before and after the aggregation (or all_reduce)?"]}, {"number": 40465, "title": "Tensorflow Java API reliability/stability guaranties", "body": "Hello everyone\r\n\r\nI want to use the TensorFlow Java API ( https://www.tensorflow.org/install/lang_java )\r\n\r\nOn the official page provided above it is stated that \"Caution: The TensorFlow Java API is not covered by the TensorFlow API stability guarantees.\"\r\n\r\nI have read the \"TensorFlow API stability guarantees\", googled little and still have the following questions:\r\n\r\n1. If I will load the trained model with \"TensorFlow Java API\"  and it will not complain, can I be sure that the inferred output is correct, meaning that I would get the same output if I would load the model in python?\r\n2. When the 2.3 release expected to happen so TensorFlow Java API will support tensorflow 2?\r\n\r\nThanks\r\nHarut", "comments": []}, {"number": 40436, "title": "On the endianness of TensorProto::tensor_content", "body": "This is a re-post from [tensorflow forums](https://groups.google.com/a/tensorflow.org/forum/?utm_medium=email&utm_source=footer#!topic/discuss/6ZaRNUF_--g).\r\n\r\nI looked into the implementation of conversion from/to the protobuf type TensorProto, and feel confused on the endianness of the underlying storage.\r\n\r\nIn my understanding of the decoding process, it checks if TensorProto::tensor_content is empty ([code](https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/core/framework/tensor.cc#L928-L931)). If not, it calls the template function Helper::Decode ([code](https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/core/framework/tensor.cc#L169-L183)), and calls `base()` to cast the bytes data to desired type ([code](https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/core/framework/tensor.cc#L176)).\r\n\r\nI searched around the definition of `base()` and found that it simply calls `reinterpret_cast` ([code](https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/core/framework/tensor.h#L86-L89)). The endianness of `reinterpret_cast` depends on the system architecture. So does tensorflow goes as it is, or did I miss anything?\r\n\r\n**TL;DR** What is the endianness of the protobuf type `TensorProto::tensor_content`?", "comments": ["You shouldn't care about the endianness of a proto, the library [takes care of it](https://stackoverflow.com/questions/28905274/endianness-of-protocol-buffer-message)", "I agree. I think it is not the case because the tensor data is serialized *before* protobuf serialization if I understand it correctly.\r\n\r\nTo be precise, `Tensor::tensor_content` is defined as repeated uint8 in protobuf ([code](https://github.com/tensorflow/tensorflow/blob/a975ef0f5c81d913d7bb1a3a2a2e84fe1f255a71/tensorflow/core/framework/tensor.proto#L38)). By putting the tensor buffer, which is contiguous floats or integers, it's reinterpreted into contiguous uint8 (in C++) in anticipation. That's the place the endianness could go wrong.", "If the tensor contains an array of floats then the repeated `float_val` (https://github.com/tensorflow/tensorflow/blob/a975ef0f5c81d913d7bb1a3a2a2e84fe1f255a71/tensorflow/core/framework/tensor.proto#L50) gets used, not `tensor_content`", "@mihaimaruseac yes, and it's partially true. The [decoding code](https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/core/framework/tensor.cc#L928-L931) shows it decides on whether `tensor_content` is empty or not to decode `tensor_content` or `*_val` fields. On the other hand, you can grep over the repo and find many places encode the tensor by [AsProtoTensorContent](https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/core/framework/tensor.cc#L960-L968), and it has the chance to encode and fill the float/integer/etc buffer into `tensor_content`. (It's called `Variant` in the [code](https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/core/framework/tensor.cc#L270-L274)).\r\n\r\nSo, I think there are chances that our issue occurs. The distinction of `tensor_content` and `*_val` may depend on versions or other factors."]}, {"number": 40421, "title": "MirroredStrategy preventing use of cuDNN GRU implementation", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab (18.04.3 LTS (Bionic Beaver))\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary (Python wheel)\r\n- TensorFlow version (use command below): **2.2.0 and tf-nightly-gpu**\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: CUDA 10.1 / cuDNN 7\r\n- GPU model and memory: Tesla T4 (15079MiB)\r\n\r\n**Describe the current behavior**\r\n\r\nThe cuDNN implementation of GRU is not being used when the model is built and compiled within `tf.distribute.MirroredStrategy`. The same model built without a strategy does use the cuDNN GRU implementation.\r\n\r\n**Describe the expected behavior**\r\n\r\nI expect a GRU model built within a `tf.distribute.MirroredStrategy` scope to use the cuDNN GRU implementation, as it does when built without a strategy.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nPlease see this [Google Colab notebook](https://colab.research.google.com/gist/kaczmarj/ecda57beb73afb7e894193e541e6489a#file-mirroredstrategy_cudnn_gru-ipynb=). Please use the GPU runtime.\r\n\r\nHere is the code that is in the notebook:\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ntfk = tf.keras\r\ntfkl = tfk.layers\r\n\r\n# The message that the cuDNN GRU implementation is used is printed at the debug level.\r\ntf.get_logger().setLevel(\"DEBUG\")\r\n\r\n# Generate data.\r\nx = np.random.rand(5000, 200, 750).astype(np.float32)\r\nx += 0.01\r\nx.clip(min=0, max=1, out=x)\r\ny = np.random.randint(2, size=(5000, 1), dtype=np.int32)\r\n\r\ndef gru_cudnn(input_shape=(200, 750), dropout_rate=0.5):\r\n    model = tfk.Sequential()\r\n    model.add(tfkl.InputLayer(input_shape))\r\n    model.add(tfkl.Masking(mask_value=0.0))\r\n    model.add(tfkl.GRU(128))\r\n    model.add(tfkl.Dropout(dropout_rate))\r\n    model.add(tfkl.Dense(1))\r\n    return model\r\n\r\n# Train model (uses cuDNN implementation).\r\nmodel = gru_cudnn()\r\nmodel.compile(\r\n    optimizer=tfk.optimizers.Adam(1e-3), \r\n    loss=tfk.losses.BinaryCrossentropy(from_logits=True))\r\n# DEBUG:tensorflow:Layer gru will use cuDNN kernel when run on GPU.\r\nmodel.fit(x, y)\r\n# 157/157 [==============================] - 3s 20ms/step - loss: 0.8034\r\n\r\n# Train using mirrored strategy, but using only one GPU.\r\nstrategy = tf.distribute.MirroredStrategy(devices=[\"GPU:0\"])\r\nwith strategy.scope():\r\n    model = gru_cudnn()\r\n    model.compile(\r\n        optimizer=tfk.optimizers.Adam(1e-3), \r\n        loss=tfk.losses.BinaryCrossentropy(from_logits=True))\r\n# DEBUG:tensorflow:Layer gru_1 will use cuDNN kernel when run on GPU.\r\nmodel.fit(x, y)\r\n# INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n# INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n# INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n# INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n# 157/157 [==============================] - 44s 279ms/step - loss: 0.8120\r\n```", "comments": ["I am able to replicate this issue, please find the [gist here.](https://colab.research.google.com/gist/Saduf2019/b2689006afb295639a07780b739cb345/untitled230.ipynb)", "Hi @kaczmarj, I'm looking at the [source code for tf.keras.layers.GRU](https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/layers/recurrent_v2.py#L392) and I found this comment, which might explain what's happening:\r\n\r\n`# Non-resource variables, such as DistributedVariables and`\r\n`# AutoCastVariables, do not work properly with the implementation`\r\n`# selector, which is used when cuDNN is used. However, by chance, such`\r\n`# variables happen to work in LSTM, so this check is only needed for GRU.`\r\n`# TODO(b/136512020): Make non-resource variables work with the`\r\n`# implementation selector.`\r\n\r\nAlso as the above comment suggests cuDNN is used with LSTM, I tried running the colab but with LSTM instead of GRU, and the time for a training step was almost identical in both cases (unlike with the GRU).", "Thanks, @nikitamaia and @Saduf2019. Is there anything that could be done to make MirroredStrategy work with cuDNN's GRU implementation?", "GRU disables cuDNN with MirroredStrategy, so unfortunately nothing can be done at this point. But I can update this thread if that changes.", "Closing issue for now since this is expected behavior and not a bug.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40421\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40421\">No</a>\n", "Reopening this issue as a feature request", "@nikitamaia Any progress on this feature request? I would appreciate this functionality. ", "It would at least be useful to log a message so the user is aware that the CuDNN GRU is not being used in this case"]}, {"number": 40383, "title": "Feature Request: API to access peak memory usage of a function call that uses TF", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): TF 2.0, 2.1, 2.2\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nIn TF 1 it was possible to retrieve the peak memory usage via:\r\n`tensorflow.contrib.memory_stats.python.ops.memory_stats_ops import MaxBytesInUse`\r\n\r\nThis does not seem to be possible anymore in TF 2.0+\r\n\r\n**Will this change the current api? How?**\r\n\r\nIt should not change the current api, it should something like `tf.profiler.memory_stats_ops` to the API\r\n\r\n**Who will benefit with this feature?**\r\n\r\nEverybody, that wants to benchmark deep learning models in TF 2.0\r\n\r\n**Any Other info.**\r\n\r\nThe function could behave similarly to the corresponding pytorch function: \r\ntensorflow.contrib.memory_stats.python.ops.memory_stats_ops import MaxBytesInUse\r\n", "comments": ["With TF 1.x 's contrib sunset, there seems no way to access memory stats during training/inference.\r\nThis makes it very hard to measure memory footprint improvements between different implementations."]}, {"number": 40313, "title": "Can I inference models with XNNPACK backend through tensorflow lite Python APIs?", "body": "One of my areas is model compression for deployment. Previously, I worked on QNNPACK and its performance was amazing. I knew that the main author of QNNPACK went to Google from FB, and he continues his work based on QNNPACK. A new library named XNNPACK was created. I am very excited to see the Sparse ConvNets feature of XNNPACK. XNNPACK suggests the TensorFlow lite in its readme. However, I did not find a specific doc or APIs for this feature. **So, can you provide some examples of the usage of XNNAPCK?**\r\n\r\n**Specifically, I want to inference the models with XNNPACK backend on CPU no matter what platform I am. Like QNNPACK, I can do some experiments on x86, while I can run on Arm (such as NVIDIA Xavier, TX2, etc) when I want to deploy models.**\r\n\r\n**For your reference**, you may learn something from PyTorch quantization feature, by which I can use same APIs to invoke QNNPACK backend on different platforms (x86 or Arm). ", "comments": ["This isn't yet possible, but we plan on enabling XNNPACK by default in the near future, so you shouldn't need to do anything explicitly on your end.", "@jdduke Is there a way to invoke xnnpack through load_delegate()? Namely, what shared lib should be pointed to and how do we build it, if required. I'd built from master with the tflite_with_xnnpack flag. ", "If you build with the `--define tflite_with_xnnpack=true` flag, then you shouldn't have to do anything manually. The delegate should be applied by default.", "@jdduke, hey, it\u2019s been a year \u2014\u00a0what\u2019s the current status of the delegate? Is it enabled by default or still requires building? \r\n\r\nAlso \u2014\u00a0is it possible to see TF logs while executing a TF Lite model via the Python API? I see a silent output while executing so I\u2019m not sure what\u2019s going on under the hood.", "I'll let @srjoglekar246 and @multiverse-tf provide an update.", "Just checked, it still requires building from src to enable XNNPACK"]}, {"number": 40298, "title": "Decoding output of object detection mobile_ssd_v2_float_coco.tflite ", "body": "The official documentation suggests mobile_ssd_v2_float_coco.tflite model for enabling GPU delegate, but after analyzing the Model with Netron, ( visualization tool to help identify how the output tensors differ.)\r\nmobile_ssd_v2_float_coco.tflite\r\nOUTPUT:\r\nraw_outputs/box_encodings\r\nid: raw_outputs/box_encodings\r\ntype: float32[1,2034,4]\r\nraw_outputs/class_predictions\r\nid: raw_outputs/class_predictions\r\ntype: float32[1,2034,91]\r\n\r\nWhereas the default model detect.tflite used in the demo has 4 different parameters.\r\nOUTPUT:\r\nTFLite_Detection_PostProcess\r\nid: TFLite_Detection_PostProcess\r\ntype: float32\r\nTFLite_Detection_PostProcess:1\r\nid: TFLite_Detection_PostProcess:1\r\ntype: float32\r\nTFLite_Detection_PostProcess:2\r\nid: TFLite_Detection_PostProcess:2\r\ntype: float32\r\nTFLite_Detection_PostProcess:3\r\nid: TFLite_Detection_PostProcess:3\r\ntype: float32\r\nie for Location, Classes, Scores, Number and detections\r\n\r\nHow can we use mobile_ssd_v2_float_coco.tfliteor any model to get enable GPU with Object Detection, Please suggest?", "comments": ["any updates on this?", "As I can see, if when we use outputs provided by this model, we are getting float32[1,2034,91] for class_predictions. \r\nAs far as I understand, it stands for 2034 as number of recognitions, followed by 91 coco classes (with 0 corresponding to background class).\r\nAny chance we can use another model with GPU , preferably one that uses hot-encoding, meaning just shows you recognition class, confidence and location box?", "@sumeshpandit Could you please let us know if this is still an issue ? Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "> @sumeshpandit Could you please let us know if this is still an issue ? Thank you!\r\n\r\nyes", "Hello, is there any update on this issue? I have the same question. How to get prediction bounding box, classes and score from 'raw_outputs/box_encodings' and 'raw_outputs/class_predictions'? ", "Hi @sumeshpandit ! you can use [visualization_utils](https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/tf2_object_detection.ipynb#scrollTo=IZ5VYaBoeeFM&line=4&uniqifier=1)  from object_detection.utils to visualize the identified objects in the image based on boundary boxes and key-points detected from the output of the model . To  enable GPU delegate , You can refer to this [codelab](https://developer.android.com/codelabs/recognize-flowers-with-tensorflow-on-android#8) .Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n"]}]