[{"number": 55694, "title": "[oneDNN] Upgrade oneDNN to v2.6", "body": "This PR updates oneDNN from v2.6-rc to v2.6.", "comments": []}, {"number": 55691, "title": "r2.9 cherry-pick: Fix crash in TF Lite Java API on Android API <= 19", "body": "Work around crash in dlsym when trying to check for the presence of a XNNPACK\r\ndelegate symbols on Android API <= 19 by detecting the respective Android\r\nversions and opting out of XNNPack inference.\r\n\r\nPiperOrigin-RevId: 441825578", "comments": []}, {"number": 55688, "title": "tf.quantization.fake_quant_with_min_max_vars crashes", "body": "<details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nBug\n\n### Source\n\nsource\n\n### Tensorflow Version\n\ntf 2.8\n\n### Custom Code\n\nYes\n\n### OS Platform and Distribution\n\nLinux Ubuntu 20.04\n\n### Mobile device\n\nn/a\n\n### Python version\n\n3.9\n\n### Bazel version\n\nn/a\n\n### GCC/Compiler version\n\nn/a\n\n### CUDA/cuDNN version\n\nn/a\n\n### GPU model and memory\n\nn/a\n\n### Current Behaviour?\n\n```shell\nSession crashes when run the code below.\r\nThe code is buggy in that the argument `min_value` and `max_value` of `tf.quantization.fake_quant_with_min_max_vars` should be scalars instead of tensors of shape `(2,)`.\r\nHowever, we expect the buggy code to be handled with `Exception` instead of just crashes.\n```\n\n\n### Standlone code to reproduce the issue\n\n```shell\nimport tensorflow as tf\r\nimport numpy as np\r\ninput_data = np.random.rand(1,3,3,2).astype(np.float32)\r\nmin_value = tf.constant([0.0, -1.0], dtype=tf.float32)\r\nmax_value = tf.constant([1.0, 0.0], dtype=tf.float32)\r\ninput_tensor = tf.constant(input_data)\r\noutput = tf.quantization.fake_quant_with_min_max_vars(input_tensor, min_value, max_value)\n```\n\n\n### Relevant log output\n\n```shell\nabort (core dumped)\n```\n</details>", "comments": ["Hello @MThalberg ,\r\nI request you please take a look at this issue #46910 where a similar issue has been raised and it is still open. Can you please follow that issue, since it is already being tracked there? Thanks!\r\n", "Thank for pointing to the other issue and indeed it is the same bug. I will close this issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55688\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55688\">No</a>\n"]}, {"number": 55684, "title": "[oneDNN] Fix Windows MSVC compiler errors", "body": "This PR fixes a Windows build break. See the CI logs here: https://tensorflow-ci.intel.com/job/tf-test-win2/49/artifact/test_run.log/*view*/", "comments": ["Tagging @learning-to-play and @mihaimaruseac for this PR.", "closing due to the reverting of the contributing commit", "Oh, apologies, I didn't notice this in time"]}, {"number": 55683, "title": "Update version numbers for TensorFlow 2.9.0-rc1", "body": "Before merging this PR, please double check that it has correctly updated\n`core/public/version.h`, `tools/pip_package/setup.py`, and\n`tensorflow/tensorflow.bzl`. Also review the execution notes below:\n\n```\nMajor: 2 -> 2\nMinor: 9 -> 9\nPatch: 0 -> 0\n\nNo lingering old version strings \"2.9.0-rc0\" found in source directory \n\"tensorflow/\". Good.\nWARNING: Below are potentially instances of lingering old version string \n\"2.9.0rc0\" in source directory \"tensorflow/\" that are not updated by this \nscript. Please check them manually!\ntensorflow/tools/pip_package/setup.py:109:2.9.0rc0\ntensorflow/tools/pip_package/setup.py:111:2.9.0rc0\n```", "comments": []}, {"number": 55671, "title": "r2.9 cherry-pick: 6b5c0f09eed \"Add missing doc strings for 4 methods under layout.py.\"", "body": "Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/6b5c0f09eedf2a840cef7e7de73b7a6d5e3ee6cb", "comments": []}, {"number": 55667, "title": "Update LATEST_BAZEL_VERSION from 5.1.0 to 5.1.1", "body": ".bazelversion was updated but LATEST_BAZEL_VERSION was not.", "comments": ["@mihaimaruseac FYI", "CC @learning-to-play "]}, {"number": 55663, "title": "tf.GradientTape.gradients()", "body": null, "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55663\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55663\">No</a>\n"]}, {"number": 55662, "title": "build tensorflow2.8 failed ", "body": "<details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nBuild/Install\n\n### Source\n\nsource\n\n### Tensorflow Version\n\ntf2.8\n\n### Custom Code\n\nYes\n\n### OS Platform and Distribution\n\ncentos7.6\n\n### Mobile device\n\n_No response_\n\n### Python version\n\n3.7.12\n\n### Bazel version\n\n4.2.2\n\n### GCC/Compiler version\n\n7.3.1\n\n### CUDA/cuDNN version\n\nrocm5.0.2\n\n### GPU model and memory\n\n_No response_\n\n### Current Behaviour?\n\n```shell\nbuild failed\r\nERROR: /root/.cache/bazel/_bazel_root/7e60a61be90f35a88e89e062446eed75/external/llvm-project/mlir/BUILD.bazel:5763:10: Linking external/llvm-project/mlir/mlir-tblgen failed: (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command\r\n  (cd /root/.cache/bazel/_bazel_root/7e60a61be90f35a88e89e062446eed75/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/opt/dtk-22.04/hip/lib:/opt/dtk-22.04/llvm/lib:/opt/dtk-22.04/lib:/opt/dtk-22.04/lib64:/opt/dtk-22.04/hip/lib:/opt/dtk-22.04/llvm/lib:/opt/dtk-22.04/lib:/opt/dtk-22.04/lib64:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/rh/devtoolset-7/root/usr/lib64/dyninst:/opt/rh/devtoolset-7/root/usr/lib/dyninst:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib \\\r\n    PATH=/opt/dtk-22.04/bin:/opt/dtk-22.04/llvm/bin:/opt/dtk-22.04/hip/bin:/opt/dtk-22.04/bin:/opt/dtk-22.04/llvm/bin:/opt/dtk-22.04/hip/bin:/home/tensorflow-2.8.0/Depend/bin:/home/tensorflow/Depend/bin:/opt/git-2.30.0/bin:/opt/cmake-3.19.3-Linux-x86_64/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \\\r\n    PWD=/proc/self/cwd \\\r\n  external/local_config_rocm/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc @bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/mlir/mlir-tblgen-2.params)\r\nExecution platform: @local_execution_config_platform//:platform\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/mlir/_objs/mlir-tblgen/AttrOrTypeDefGen.o:AttrOrTypeDefGen.cpp:function llvm::detail::provider_format_adapter<llvm::StringRef&>::~provider_format_adapter(): error: undefined reference to 'operator delete(void*, unsigned long)'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/mlir/_objs/mlir-tblgen/AttrOrTypeDefGen.o:AttrOrTypeDefGen.cpp:function llvm::detail::provider_format_adapter<llvm::StringRef>::~provider_format_adapter(): error: undefined reference to 'operator delete(void*, unsigned long)'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/mlir/_objs/mlir-tblgen/AttrOrTypeDefGen.o:AttrOrTypeDefGen.cpp:function llvm::detail::provider_format_adapter<char const*>::~provider_format_adapter(): error: undefined reference to 'operator delete(void*, unsigned long)'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/mlir/_objs/mlir-tblgen/AttrOrTypeDefGen.o:AttrOrTypeDefGen.cpp:function llvm::detail::provider_format_adapter<std::string&>::~provider_format_adapter(): error: undefined reference to 'operator delete(void*, unsigned long)'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/TableGen/Main.o:Main.cpp:function llvm::TableGenMain(char const*, bool (*)(llvm::raw_ostream&, llvm::RecordKeeper&)): error: undefined reference to 'std::_V2::system_category()'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/TableGen/Main.o:Main.cpp:function llvm::TableGenMain(char const*, bool (*)(llvm::raw_ostream&, llvm::RecordKeeper&)): error: undefined reference to 'std::_V2::system_category()'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/CommandLine.o:CommandLine.cpp:function ExpandResponseFile(llvm::StringRef, llvm::StringSaver&, void (*)(llvm::StringRef, llvm::StringSaver&, llvm::SmallVectorImpl<char const*>&, bool), llvm::SmallVectorImpl<char const*>&, bool, bool, llvm::vfs::FileSystem&): error: undefined reference to 'std::_V2::generic_category()'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/ConvertUTFWrapper.o:ConvertUTFWrapper.cpp:function llvm::convertUTF16ToUTF8String(llvm::ArrayRef<char>, std::string&): error: undefined reference to 'std::__throw_out_of_range_fmt(char const*, ...)'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:function (anonymous namespace)::ErrorErrorCategory::~ErrorErrorCategory(): error: undefined reference to 'std::_V2::error_category::~error_category()'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:function (anonymous namespace)::ErrorErrorCategory::~ErrorErrorCategory(): error: undefined reference to 'std::_V2::error_category::~error_category()'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:function llvm::object_deleter<(anonymous namespace)::ErrorErrorCategory>::call(void*): error: undefined reference to 'std::_V2::error_category::~error_category()'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:function llvm::errorToErrorCode(llvm::Error): error: undefined reference to 'std::_V2::system_category()'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:typeinfo for (anonymous namespace)::ErrorErrorCategory: error: undefined reference to 'typeinfo for std::_V2::error_category'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:vtable for (anonymous namespace)::ErrorErrorCategory: error: undefined reference to 'std::_V2::error_category::_M_message(int) const'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:vtable for (anonymous namespace)::ErrorErrorCategory: error: undefined reference to 'std::_V2::error_category::default_error_condition(int) const'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:vtable for (anonymous namespace)::ErrorErrorCategory: error: undefined reference to 'std::_V2::error_category::equivalent(int, std::error_condition const&) const'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:vtable for (anonymous namespace)::ErrorErrorCategory: error: undefined reference to 'std::_V2::error_category::equivalent(std::error_code const&, int) const'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/raw_ostream.o:raw_ostream.cpp:function llvm::raw_fd_ostream::write_impl(char const*, unsigned long): error: undefined reference to 'std::_V2::generic_category()'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/raw_ostream.o:raw_ostream.cpp:function getFD(llvm::StringRef, std::error_code&, llvm::sys::fs::CreationDisposition, llvm::sys::fs::FileAccess, llvm::sys::fs::OpenFlags): error: undefined reference to 'std::_V2::system_category()'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/raw_ostream.o:raw_ostream.cpp:function llvm::raw_fd_ostream::seek(unsigned long): error: undefined reference to 'std::_V2::generic_category()'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/raw_ostream.o:raw_ostream.cpp:function llvm::raw_fd_stream::raw_fd_stream(llvm::StringRef, std::error_code&): error: undefined reference to 'std::_V2::generic_category()'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/StringRef.o:StringRef.cpp:function llvm::APFloat::Storage::~Storage(): error: undefined reference to 'operator delete[](void*, unsigned long)'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/StringRef.o:StringRef.cpp:function llvm::APFloat::Storage::~Storage(): error: undefined reference to 'operator delete[](void*, unsigned long)'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/StringRef.o:StringRef.cpp:function llvm::APFloat::Storage::~Storage(): error: undefined reference to 'operator delete[](void*, unsigned long)'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/StringRef.o:StringRef.cpp:function llvm::APFloat::Storage::~Storage(): error: undefined reference to 'operator delete[](void*, unsigned long)'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/StringRef.o:StringRef.cpp:function unsigned int llvm::ComputeEditDistance<char>(llvm::ArrayRef<char>, llvm::ArrayRef<char>, bool, unsigned int): error: undefined reference to '__cxa_throw_bad_array_new_length'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/SourceMgr.o:SourceMgr.cpp:function llvm::SMDiagnostic::print(char const*, llvm::raw_ostream&, bool, bool) const: error: undefined reference to 'std::__throw_out_of_range_fmt(char const*, ...)'\r\ncollect2: error: ld returned 1 exit status\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 24.185s, Critical Path: 15.00s\r\nINFO: 1352 processes: 67 internal, 1285 local.\r\nFAILED: Build did NOT complete successfully\n```\n\n\n### Standlone code to reproduce the issue\n\n```shell\nbazel build -c opt  --config=rocm //tensorflow/tools/pip_package:build_pip_package --verbose_failures\n```\n\n\n### Relevant log output\n\n```shell\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=229\r\nINFO: Reading rc options for 'build' from /home/tensorflow-2.8.0/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /home/tensorflow-2.8.0/.bazelrc:\r\n  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library\r\nINFO: Reading rc options for 'build' from /home/tensorflow-2.8.0/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/local/python3.7.12/lib/python3.7/site-packages --python_path=/usr/bin/python3 --config=rocm --action_env LD_LIBRARY_PATH=/opt/dtk-22.04/hip/lib:/opt/dtk-22.04/llvm/lib:/opt/dtk-22.04/lib:/opt/dtk-22.04/lib64:/opt/dtk-22.04/hip/lib:/opt/dtk-22.04/llvm/lib:/opt/dtk-22.04/lib:/opt/dtk-22.04/lib64:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/rh/devtoolset-7/root/usr/lib64/dyninst:/opt/rh/devtoolset-7/root/usr/lib/dyninst:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib --action_env ROCM_PATH=/opt/dtk-22.04 --action_env ROCBLAS_TENSILE_LIBPATH=/opt/dtk-22.04/lib/library\r\nINFO: Reading rc options for 'build' from /home/tensorflow-2.8.0/.bazelrc:\r\n  'build' options: --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/fallback,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils\r\nINFO: Found applicable config definition build:short_logs in file /home/tensorflow-2.8.0/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /home/tensorflow-2.8.0/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:rocm in file /home/tensorflow-2.8.0/.bazelrc: --crosstool_top=@local_config_rocm//crosstool:toolchain --define=using_rocm_hipcc=true --repo_env TF_NEED_ROCM=1\r\nINFO: Found applicable config definition build:rocm in file /home/tensorflow-2.8.0/.bazelrc: --crosstool_top=@local_config_rocm//crosstool:toolchain --define=using_rocm_hipcc=true --repo_env TF_NEED_ROCM=1\r\nINFO: Found applicable config definition build:linux in file /home/tensorflow-2.8.0/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes\r\nINFO: Found applicable config definition build:dynamic_kernels in file /home/tensorflow-2.8.0/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS\r\nINFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded, 0 targets configured).\r\nINFO: Found 1 target...\r\nERROR: /root/.cache/bazel/_bazel_root/7e60a61be90f35a88e89e062446eed75/external/llvm-project/mlir/BUILD.bazel:5763:10: Linking external/llvm-project/mlir/mlir-tblgen failed: (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command\r\n  (cd /root/.cache/bazel/_bazel_root/7e60a61be90f35a88e89e062446eed75/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/opt/dtk-22.04/hip/lib:/opt/dtk-22.04/llvm/lib:/opt/dtk-22.04/lib:/opt/dtk-22.04/lib64:/opt/dtk-22.04/hip/lib:/opt/dtk-22.04/llvm/lib:/opt/dtk-22.04/lib:/opt/dtk-22.04/lib64:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/rh/devtoolset-7/root/usr/lib64/dyninst:/opt/rh/devtoolset-7/root/usr/lib/dyninst:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib \\\r\n    PATH=/opt/dtk-22.04/bin:/opt/dtk-22.04/llvm/bin:/opt/dtk-22.04/hip/bin:/opt/dtk-22.04/bin:/opt/dtk-22.04/llvm/bin:/opt/dtk-22.04/hip/bin:/home/tensorflow-2.8.0/Depend/bin:/home/tensorflow/Depend/bin:/opt/git-2.30.0/bin:/opt/cmake-3.19.3-Linux-x86_64/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \\\r\n    PWD=/proc/self/cwd \\\r\n  external/local_config_rocm/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc @bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/mlir/mlir-tblgen-2.params)\r\nExecution platform: @local_execution_config_platform//:platform\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/mlir/_objs/mlir-tblgen/AttrOrTypeDefGen.o:AttrOrTypeDefGen.cpp:function llvm::detail::provider_format_adapter<llvm::StringRef&>::~provider_format_adapter(): error: undefined reference to 'operator delete(void*, unsigned long)'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/mlir/_objs/mlir-tblgen/AttrOrTypeDefGen.o:AttrOrTypeDefGen.cpp:function llvm::detail::provider_format_adapter<llvm::StringRef>::~provider_format_adapter(): error: undefined reference to 'operator delete(void*, unsigned long)'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/mlir/_objs/mlir-tblgen/AttrOrTypeDefGen.o:AttrOrTypeDefGen.cpp:function llvm::detail::provider_format_adapter<char const*>::~provider_format_adapter(): error: undefined reference to 'operator delete(void*, unsigned long)'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/mlir/_objs/mlir-tblgen/AttrOrTypeDefGen.o:AttrOrTypeDefGen.cpp:function llvm::detail::provider_format_adapter<std::string&>::~provider_format_adapter(): error: undefined reference to 'operator delete(void*, unsigned long)'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/TableGen/Main.o:Main.cpp:function llvm::TableGenMain(char const*, bool (*)(llvm::raw_ostream&, llvm::RecordKeeper&)): error: undefined reference to 'std::_V2::system_category()'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/TableGen/Main.o:Main.cpp:function llvm::TableGenMain(char const*, bool (*)(llvm::raw_ostream&, llvm::RecordKeeper&)): error: undefined reference to 'std::_V2::system_category()'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/CommandLine.o:CommandLine.cpp:function ExpandResponseFile(llvm::StringRef, llvm::StringSaver&, void (*)(llvm::StringRef, llvm::StringSaver&, llvm::SmallVectorImpl<char const*>&, bool), llvm::SmallVectorImpl<char const*>&, bool, bool, llvm::vfs::FileSystem&): error: undefined reference to 'std::_V2::generic_category()'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/ConvertUTFWrapper.o:ConvertUTFWrapper.cpp:function llvm::convertUTF16ToUTF8String(llvm::ArrayRef<char>, std::string&): error: undefined reference to 'std::__throw_out_of_range_fmt(char const*, ...)'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:function (anonymous namespace)::ErrorErrorCategory::~ErrorErrorCategory(): error: undefined reference to 'std::_V2::error_category::~error_category()'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:function (anonymous namespace)::ErrorErrorCategory::~ErrorErrorCategory(): error: undefined reference to 'std::_V2::error_category::~error_category()'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:function llvm::object_deleter<(anonymous namespace)::ErrorErrorCategory>::call(void*): error: undefined reference to 'std::_V2::error_category::~error_category()'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:function llvm::errorToErrorCode(llvm::Error): error: undefined reference to 'std::_V2::system_category()'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:typeinfo for (anonymous namespace)::ErrorErrorCategory: error: undefined reference to 'typeinfo for std::_V2::error_category'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:vtable for (anonymous namespace)::ErrorErrorCategory: error: undefined reference to 'std::_V2::error_category::_M_message(int) const'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:vtable for (anonymous namespace)::ErrorErrorCategory: error: undefined reference to 'std::_V2::error_category::default_error_condition(int) const'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:vtable for (anonymous namespace)::ErrorErrorCategory: error: undefined reference to 'std::_V2::error_category::equivalent(int, std::error_condition const&) const'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:vtable for (anonymous namespace)::ErrorErrorCategory: error: undefined reference to 'std::_V2::error_category::equivalent(std::error_code const&, int) const'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/raw_ostream.o:raw_ostream.cpp:function llvm::raw_fd_ostream::write_impl(char const*, unsigned long): error: undefined reference to 'std::_V2::generic_category()'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/raw_ostream.o:raw_ostream.cpp:function getFD(llvm::StringRef, std::error_code&, llvm::sys::fs::CreationDisposition, llvm::sys::fs::FileAccess, llvm::sys::fs::OpenFlags): error: undefined reference to 'std::_V2::system_category()'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/raw_ostream.o:raw_ostream.cpp:function llvm::raw_fd_ostream::seek(unsigned long): error: undefined reference to 'std::_V2::generic_category()'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/raw_ostream.o:raw_ostream.cpp:function llvm::raw_fd_stream::raw_fd_stream(llvm::StringRef, std::error_code&): error: undefined reference to 'std::_V2::generic_category()'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/StringRef.o:StringRef.cpp:function llvm::APFloat::Storage::~Storage(): error: undefined reference to 'operator delete[](void*, unsigned long)'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/StringRef.o:StringRef.cpp:function llvm::APFloat::Storage::~Storage(): error: undefined reference to 'operator delete[](void*, unsigned long)'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/StringRef.o:StringRef.cpp:function llvm::APFloat::Storage::~Storage(): error: undefined reference to 'operator delete[](void*, unsigned long)'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/StringRef.o:StringRef.cpp:function llvm::APFloat::Storage::~Storage(): error: undefined reference to 'operator delete[](void*, unsigned long)'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/StringRef.o:StringRef.cpp:function unsigned int llvm::ComputeEditDistance<char>(llvm::ArrayRef<char>, llvm::ArrayRef<char>, bool, unsigned int): error: undefined reference to '__cxa_throw_bad_array_new_length'\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/SourceMgr.o:SourceMgr.cpp:function llvm::SMDiagnostic::print(char const*, llvm::raw_ostream&, bool, bool) const: error: undefined reference to 'std::__throw_out_of_range_fmt(char const*, ...)'\r\ncollect2: error: ld returned 1 exit status\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 24.185s, Critical Path: 15.00s\r\nINFO: 1352 processes: 67 internal, 1285 local.\r\nFAILED: Build did NOT complete successfully\n```\n</details>", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55662\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55662\">No</a>\n"]}, {"number": 55656, "title": "test", "body": "<details><summary>Click to expand!</summary> \n \n ### Issue Type\n\nBug\n\n### Source\n\nsource\n\n### Tensorflow Version\n\n2.6\n\n### Custom Code\n\nYes\n\n### OS Platform and Distribution\n\n_No response_\n\n### Mobile device\n\n_No response_\n\n### Python version\n\n_No response_\n\n### Bazel version\n\n_No response_\n\n### GCC/Compiler version\n\n_No response_\n\n### CUDA/cuDNN version\n\n_No response_\n\n### GPU model and memory\n\n_No response_\n\n### Current Behaviour?\n\n```shell\nA bug happened!\n```\n\n\n### Standlone code to reproduce the issue\n\n```shell\ntest\n```\n\n\n### Relevant log output\n\n_No response_</details>", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55656\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55656\">No</a>\n"]}, {"number": 55654, "title": "Google Colab ValueError: faster_rcnn_inception_v2 is not supported for tf version 2. See `model_builder.py` for features extractors compatible with different versions of Tensorflow", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab (Default)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Google Colab (Default)\r\n- TensorFlow version: 2.8.0\r\n- Python version: 3.7.13\r\n- Installed using virtualenv? pip? conda?: Google Colab (so pip)\r\n- Bazel version (if compiling from source):  Google Colab (Default)\r\n- GCC/Compiler version (if compiling from source):  (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\n- CUDA/cuDNN version:  V11.1.105\r\n- GPU model and memory:  Google Colab (Default)\r\n\r\n**Describe the problem**\r\nDon't know why faster_rcnn_inception_v2 is not supported checked the `model_builder_tf2_test.py` inside builder, can't seem to figure out what is wronf\r\n\r\nRan the blocks one after other\r\n\r\n```\r\nfrom google.colab import drive\r\ndrive.mount('/content/drive/')\r\n```\r\n\r\n```\r\nimport os \r\nos.chdir(\"/content/drive/MyDrive/Tensorflow/models/research\")\r\n```\r\n\r\n```\r\n!protoc object_detection/protos/*.proto --python_out=.\r\n```\r\n\r\n```\r\nimport pycocotools\r\n```\r\n\r\n```\r\n!cp /content/drive/MyDrive/Tensorflow/models/research/object_detection/packages/tf2/setup.py .\r\n!python -m pip install .\r\n```\r\n> Output\r\n```\r\nProcessing /content/drive/MyDrive/Tensorflow/models/research\r\n  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\r\n   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\r\n...\r\nSuccessfully built object-detection\r\nInstalling collected packages: requests, cloudpickle, object-detection\r\n  Attempting uninstall: requests\r\n    Found existing installation: requests 2.23.0\r\n    Uninstalling requests-2.23.0:\r\n      Successfully uninstalled requests-2.23.0\r\n  Attempting uninstall: cloudpickle\r\n    Found existing installation: cloudpickle 1.6.0\r\n    Uninstalling cloudpickle-1.6.0:\r\n      Successfully uninstalled cloudpickle-1.6.0\r\n  Attempting uninstall: object-detection\r\n    Found existing installation: object-detection 0.1\r\n    Uninstalling object-detection-0.1:\r\n      Successfully uninstalled object-detection-0.1\r\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\ngym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\r\ngoogle-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\r\nSuccessfully installed cloudpickle-2.0.0 object-detection-0.1 requests-2.27.1\r\n```\r\n\r\n\r\n```\r\n!python /content/drive/MyDrive/Tensorflow/models/research/object_detection/builders/model_builder_tf2_test.py\r\n```\r\n> Ouput\r\n```\r\nRunning tests under Python 3.7.13: /usr/bin/python3\r\n[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\r\n2022-04-18 17:22:34.522498: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\r\nW0418 17:22:34.835057 140651717425024 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.37s\r\nI0418 17:22:35.309757 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.37s\r\n[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\r\n[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.7s\r\nI0418 17:22:36.007474 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.7s\r\n[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\r\n[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.35s\r\nI0418 17:22:36.355132 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.35s\r\n[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\r\n[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.32s\r\nI0418 17:22:36.673634 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.32s\r\n[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\r\n[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.25s\r\nI0418 17:22:38.921587 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.25s\r\n[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\r\n[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\r\nI0418 17:22:38.922625 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\r\n[       OK ] ModelBuilderTF2Test.test_create_experimental_model\r\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\r\nI0418 17:22:38.949134 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\r\n[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\r\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\r\nI0418 17:22:38.972606 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\r\n[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\r\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\r\nI0418 17:22:38.995841 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\r\n[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\r\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.12s\r\nI0418 17:22:39.120243 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.12s\r\n[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\r\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.12s\r\nI0418 17:22:39.241493 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.12s\r\n[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\r\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.13s\r\nI0418 17:22:39.367335 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.13s\r\n[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\r\n[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.13s\r\nI0418 17:22:39.499283 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.13s\r\n[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\r\n[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.12s\r\nI0418 17:22:39.622432 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.12s\r\n[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\r\n[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\r\nI0418 17:22:39.655929 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\r\n[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\r\n[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\r\nI0418 17:22:39.881075 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\r\nI0418 17:22:39.881299 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\r\nI0418 17:22:39.881403 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\r\nI0418 17:22:39.884063 140651717425024 efficientnet_model.py:144] round_filter input=32 output=32\r\nI0418 17:22:39.909026 140651717425024 efficientnet_model.py:144] round_filter input=32 output=32\r\nI0418 17:22:39.909201 140651717425024 efficientnet_model.py:144] round_filter input=16 output=16\r\nI0418 17:22:39.982957 140651717425024 efficientnet_model.py:144] round_filter input=16 output=16\r\nI0418 17:22:39.983191 140651717425024 efficientnet_model.py:144] round_filter input=24 output=24\r\nI0418 17:22:40.185760 140651717425024 efficientnet_model.py:144] round_filter input=24 output=24\r\nI0418 17:22:40.185985 140651717425024 efficientnet_model.py:144] round_filter input=40 output=40\r\nI0418 17:22:40.383517 140651717425024 efficientnet_model.py:144] round_filter input=40 output=40\r\nI0418 17:22:40.383721 140651717425024 efficientnet_model.py:144] round_filter input=80 output=80\r\nI0418 17:22:40.676204 140651717425024 efficientnet_model.py:144] round_filter input=80 output=80\r\nI0418 17:22:40.676435 140651717425024 efficientnet_model.py:144] round_filter input=112 output=112\r\nI0418 17:22:40.967956 140651717425024 efficientnet_model.py:144] round_filter input=112 output=112\r\nI0418 17:22:40.968163 140651717425024 efficientnet_model.py:144] round_filter input=192 output=192\r\nI0418 17:22:41.539747 140651717425024 efficientnet_model.py:144] round_filter input=192 output=192\r\nI0418 17:22:41.539965 140651717425024 efficientnet_model.py:144] round_filter input=320 output=320\r\nI0418 17:22:41.629632 140651717425024 efficientnet_model.py:144] round_filter input=1280 output=1280\r\nI0418 17:22:41.666049 140651717425024 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\r\nI0418 17:22:41.727125 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\r\nI0418 17:22:41.727278 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\r\nI0418 17:22:41.727388 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\r\nI0418 17:22:41.729334 140651717425024 efficientnet_model.py:144] round_filter input=32 output=32\r\nI0418 17:22:41.748022 140651717425024 efficientnet_model.py:144] round_filter input=32 output=32\r\nI0418 17:22:41.748164 140651717425024 efficientnet_model.py:144] round_filter input=16 output=16\r\nI0418 17:22:41.909050 140651717425024 efficientnet_model.py:144] round_filter input=16 output=16\r\nI0418 17:22:41.909280 140651717425024 efficientnet_model.py:144] round_filter input=24 output=24\r\nI0418 17:22:42.199975 140651717425024 efficientnet_model.py:144] round_filter input=24 output=24\r\nI0418 17:22:42.200182 140651717425024 efficientnet_model.py:144] round_filter input=40 output=40\r\nI0418 17:22:42.490325 140651717425024 efficientnet_model.py:144] round_filter input=40 output=40\r\nI0418 17:22:42.490564 140651717425024 efficientnet_model.py:144] round_filter input=80 output=80\r\nI0418 17:22:42.882098 140651717425024 efficientnet_model.py:144] round_filter input=80 output=80\r\nI0418 17:22:42.882309 140651717425024 efficientnet_model.py:144] round_filter input=112 output=112\r\nI0418 17:22:43.272372 140651717425024 efficientnet_model.py:144] round_filter input=112 output=112\r\nI0418 17:22:43.272558 140651717425024 efficientnet_model.py:144] round_filter input=192 output=192\r\nI0418 17:22:43.749095 140651717425024 efficientnet_model.py:144] round_filter input=192 output=192\r\nI0418 17:22:43.749329 140651717425024 efficientnet_model.py:144] round_filter input=320 output=320\r\nI0418 17:22:43.950352 140651717425024 efficientnet_model.py:144] round_filter input=1280 output=1280\r\nI0418 17:22:43.988394 140651717425024 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\r\nI0418 17:22:44.066077 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\r\nI0418 17:22:44.066259 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\r\nI0418 17:22:44.066420 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\r\nI0418 17:22:44.068452 140651717425024 efficientnet_model.py:144] round_filter input=32 output=32\r\nI0418 17:22:44.097079 140651717425024 efficientnet_model.py:144] round_filter input=32 output=32\r\nI0418 17:22:44.097218 140651717425024 efficientnet_model.py:144] round_filter input=16 output=16\r\nI0418 17:22:44.254661 140651717425024 efficientnet_model.py:144] round_filter input=16 output=16\r\nI0418 17:22:44.254885 140651717425024 efficientnet_model.py:144] round_filter input=24 output=24\r\nI0418 17:22:44.559297 140651717425024 efficientnet_model.py:144] round_filter input=24 output=24\r\nI0418 17:22:44.559684 140651717425024 efficientnet_model.py:144] round_filter input=40 output=48\r\nI0418 17:22:44.873531 140651717425024 efficientnet_model.py:144] round_filter input=40 output=48\r\nI0418 17:22:44.873750 140651717425024 efficientnet_model.py:144] round_filter input=80 output=88\r\nI0418 17:22:45.300951 140651717425024 efficientnet_model.py:144] round_filter input=80 output=88\r\nI0418 17:22:45.301170 140651717425024 efficientnet_model.py:144] round_filter input=112 output=120\r\nI0418 17:22:45.704520 140651717425024 efficientnet_model.py:144] round_filter input=112 output=120\r\nI0418 17:22:45.704799 140651717425024 efficientnet_model.py:144] round_filter input=192 output=208\r\nI0418 17:22:46.203318 140651717425024 efficientnet_model.py:144] round_filter input=192 output=208\r\nI0418 17:22:46.203543 140651717425024 efficientnet_model.py:144] round_filter input=320 output=352\r\nI0418 17:22:46.401460 140651717425024 efficientnet_model.py:144] round_filter input=1280 output=1408\r\nI0418 17:22:46.447006 140651717425024 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\r\nI0418 17:22:46.522991 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\r\nI0418 17:22:46.523183 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\r\nI0418 17:22:46.523305 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\r\nI0418 17:22:46.525346 140651717425024 efficientnet_model.py:144] round_filter input=32 output=40\r\nI0418 17:22:46.545359 140651717425024 efficientnet_model.py:144] round_filter input=32 output=40\r\nI0418 17:22:46.545502 140651717425024 efficientnet_model.py:144] round_filter input=16 output=24\r\nI0418 17:22:46.945021 140651717425024 efficientnet_model.py:144] round_filter input=16 output=24\r\nI0418 17:22:46.945224 140651717425024 efficientnet_model.py:144] round_filter input=24 output=32\r\nI0418 17:22:47.246878 140651717425024 efficientnet_model.py:144] round_filter input=24 output=32\r\nI0418 17:22:47.247097 140651717425024 efficientnet_model.py:144] round_filter input=40 output=48\r\nI0418 17:22:47.545889 140651717425024 efficientnet_model.py:144] round_filter input=40 output=48\r\nI0418 17:22:47.546088 140651717425024 efficientnet_model.py:144] round_filter input=80 output=96\r\nI0418 17:22:48.029253 140651717425024 efficientnet_model.py:144] round_filter input=80 output=96\r\nI0418 17:22:48.029495 140651717425024 efficientnet_model.py:144] round_filter input=112 output=136\r\nI0418 17:22:48.550718 140651717425024 efficientnet_model.py:144] round_filter input=112 output=136\r\nI0418 17:22:48.550914 140651717425024 efficientnet_model.py:144] round_filter input=192 output=232\r\nI0418 17:22:49.137728 140651717425024 efficientnet_model.py:144] round_filter input=192 output=232\r\nI0418 17:22:49.137917 140651717425024 efficientnet_model.py:144] round_filter input=320 output=384\r\nI0418 17:22:49.339728 140651717425024 efficientnet_model.py:144] round_filter input=1280 output=1536\r\nI0418 17:22:49.376200 140651717425024 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\r\nI0418 17:22:49.457432 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\r\nI0418 17:22:49.457614 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\r\nI0418 17:22:49.457733 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\r\nI0418 17:22:49.459825 140651717425024 efficientnet_model.py:144] round_filter input=32 output=48\r\nI0418 17:22:49.480137 140651717425024 efficientnet_model.py:144] round_filter input=32 output=48\r\nI0418 17:22:49.480267 140651717425024 efficientnet_model.py:144] round_filter input=16 output=24\r\nI0418 17:22:49.626461 140651717425024 efficientnet_model.py:144] round_filter input=16 output=24\r\nI0418 17:22:49.626665 140651717425024 efficientnet_model.py:144] round_filter input=24 output=32\r\nI0418 17:22:50.004109 140651717425024 efficientnet_model.py:144] round_filter input=24 output=32\r\nI0418 17:22:50.004311 140651717425024 efficientnet_model.py:144] round_filter input=40 output=56\r\nI0418 17:22:50.396405 140651717425024 efficientnet_model.py:144] round_filter input=40 output=56\r\nI0418 17:22:50.396666 140651717425024 efficientnet_model.py:144] round_filter input=80 output=112\r\nI0418 17:22:51.007864 140651717425024 efficientnet_model.py:144] round_filter input=80 output=112\r\nI0418 17:22:51.008074 140651717425024 efficientnet_model.py:144] round_filter input=112 output=160\r\nI0418 17:22:51.602847 140651717425024 efficientnet_model.py:144] round_filter input=112 output=160\r\nI0418 17:22:51.603067 140651717425024 efficientnet_model.py:144] round_filter input=192 output=272\r\nI0418 17:22:52.382356 140651717425024 efficientnet_model.py:144] round_filter input=192 output=272\r\nI0418 17:22:52.382547 140651717425024 efficientnet_model.py:144] round_filter input=320 output=448\r\nI0418 17:22:52.584087 140651717425024 efficientnet_model.py:144] round_filter input=1280 output=1792\r\nI0418 17:22:52.621994 140651717425024 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\r\nI0418 17:22:52.946643 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\r\nI0418 17:22:52.946854 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\r\nI0418 17:22:52.946960 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\r\nI0418 17:22:52.949278 140651717425024 efficientnet_model.py:144] round_filter input=32 output=48\r\nI0418 17:22:52.968531 140651717425024 efficientnet_model.py:144] round_filter input=32 output=48\r\nI0418 17:22:52.968678 140651717425024 efficientnet_model.py:144] round_filter input=16 output=24\r\nI0418 17:22:53.208381 140651717425024 efficientnet_model.py:144] round_filter input=16 output=24\r\nI0418 17:22:53.208580 140651717425024 efficientnet_model.py:144] round_filter input=24 output=40\r\nI0418 17:22:53.705475 140651717425024 efficientnet_model.py:144] round_filter input=24 output=40\r\nI0418 17:22:53.705704 140651717425024 efficientnet_model.py:144] round_filter input=40 output=64\r\nI0418 17:22:54.200186 140651717425024 efficientnet_model.py:144] round_filter input=40 output=64\r\nI0418 17:22:54.200397 140651717425024 efficientnet_model.py:144] round_filter input=80 output=128\r\nI0418 17:22:54.891355 140651717425024 efficientnet_model.py:144] round_filter input=80 output=128\r\nI0418 17:22:54.891623 140651717425024 efficientnet_model.py:144] round_filter input=112 output=176\r\nI0418 17:22:55.574701 140651717425024 efficientnet_model.py:144] round_filter input=112 output=176\r\nI0418 17:22:55.574891 140651717425024 efficientnet_model.py:144] round_filter input=192 output=304\r\nI0418 17:22:56.476717 140651717425024 efficientnet_model.py:144] round_filter input=192 output=304\r\nI0418 17:22:56.476914 140651717425024 efficientnet_model.py:144] round_filter input=320 output=512\r\nI0418 17:22:56.763684 140651717425024 efficientnet_model.py:144] round_filter input=1280 output=2048\r\nI0418 17:22:56.816832 140651717425024 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\r\nI0418 17:22:56.921765 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\r\nI0418 17:22:56.921953 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\r\nI0418 17:22:56.922078 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\r\nI0418 17:22:56.924120 140651717425024 efficientnet_model.py:144] round_filter input=32 output=56\r\nI0418 17:22:56.943723 140651717425024 efficientnet_model.py:144] round_filter input=32 output=56\r\nI0418 17:22:56.943849 140651717425024 efficientnet_model.py:144] round_filter input=16 output=32\r\nI0418 17:22:57.174894 140651717425024 efficientnet_model.py:144] round_filter input=16 output=32\r\nI0418 17:22:57.175107 140651717425024 efficientnet_model.py:144] round_filter input=24 output=40\r\nI0418 17:22:57.765460 140651717425024 efficientnet_model.py:144] round_filter input=24 output=40\r\nI0418 17:22:57.765691 140651717425024 efficientnet_model.py:144] round_filter input=40 output=72\r\nI0418 17:22:58.367207 140651717425024 efficientnet_model.py:144] round_filter input=40 output=72\r\nI0418 17:22:58.367408 140651717425024 efficientnet_model.py:144] round_filter input=80 output=144\r\nI0418 17:22:59.146869 140651717425024 efficientnet_model.py:144] round_filter input=80 output=144\r\nI0418 17:22:59.147065 140651717425024 efficientnet_model.py:144] round_filter input=112 output=200\r\nI0418 17:23:00.243004 140651717425024 efficientnet_model.py:144] round_filter input=112 output=200\r\nI0418 17:23:00.243216 140651717425024 efficientnet_model.py:144] round_filter input=192 output=344\r\nI0418 17:23:01.329543 140651717425024 efficientnet_model.py:144] round_filter input=192 output=344\r\nI0418 17:23:01.329753 140651717425024 efficientnet_model.py:144] round_filter input=320 output=576\r\nI0418 17:23:01.632538 140651717425024 efficientnet_model.py:144] round_filter input=1280 output=2304\r\nI0418 17:23:01.667076 140651717425024 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\r\nI0418 17:23:01.783803 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\r\nI0418 17:23:01.783980 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\r\nI0418 17:23:01.784088 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\r\nI0418 17:23:01.786011 140651717425024 efficientnet_model.py:144] round_filter input=32 output=64\r\nI0418 17:23:01.804804 140651717425024 efficientnet_model.py:144] round_filter input=32 output=64\r\nI0418 17:23:01.804945 140651717425024 efficientnet_model.py:144] round_filter input=16 output=32\r\nI0418 17:23:02.119777 140651717425024 efficientnet_model.py:144] round_filter input=16 output=32\r\nI0418 17:23:02.120019 140651717425024 efficientnet_model.py:144] round_filter input=24 output=48\r\nI0418 17:23:02.801890 140651717425024 efficientnet_model.py:144] round_filter input=24 output=48\r\nI0418 17:23:02.802091 140651717425024 efficientnet_model.py:144] round_filter input=40 output=80\r\nI0418 17:23:03.464561 140651717425024 efficientnet_model.py:144] round_filter input=40 output=80\r\nI0418 17:23:03.464781 140651717425024 efficientnet_model.py:144] round_filter input=80 output=160\r\nI0418 17:23:04.441631 140651717425024 efficientnet_model.py:144] round_filter input=80 output=160\r\nI0418 17:23:04.441842 140651717425024 efficientnet_model.py:144] round_filter input=112 output=224\r\nI0418 17:23:05.429579 140651717425024 efficientnet_model.py:144] round_filter input=112 output=224\r\nI0418 17:23:05.429809 140651717425024 efficientnet_model.py:144] round_filter input=192 output=384\r\nI0418 17:23:06.740693 140651717425024 efficientnet_model.py:144] round_filter input=192 output=384\r\nI0418 17:23:06.740902 140651717425024 efficientnet_model.py:144] round_filter input=320 output=640\r\nI0418 17:23:07.480772 140651717425024 efficientnet_model.py:144] round_filter input=1280 output=2560\r\nI0418 17:23:07.517922 140651717425024 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 28.01s\r\nI0418 17:23:07.669898 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 28.01s\r\n[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\r\n[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\r\nI0418 17:23:07.677198 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\r\n[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\r\n[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\r\nI0418 17:23:07.679375 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\r\n[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\r\n[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\r\nI0418 17:23:07.680015 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\r\n[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\r\n[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\r\nI0418 17:23:07.681699 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\r\n[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\r\n[ RUN      ] ModelBuilderTF2Test.test_session\r\n[  SKIPPED ] ModelBuilderTF2Test.test_session\r\n[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\r\nI0418 17:23:07.683473 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\r\n[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\r\n[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\r\nI0418 17:23:07.684104 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\r\n[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\r\n[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\r\nINFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\r\nI0418 17:23:07.685307 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\r\n[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\r\n----------------------------------------------------------------------\r\nRan 24 tests in 33.750s\r\n\r\nOK (skipped=1)\r\n```\r\n\r\n```\r\n!pip install opencv-python-headless==4.1.2.30\r\n```\r\n\r\n```\r\nimport tensorflow.compat.v2 as tf\r\nfrom object_detection import model_lib_v2\r\n\r\ntf.config.set_soft_device_placement(True)\r\n\r\nmodel_dir = \"/content/drive/MyDrive/Tensorflow/models/research/faster_rcnn_inception_v2_coco_2018_01_28/model_dir\"\r\n\r\nconfig = tf_estimator.RunConfig(model_dir=model_dir)\r\n\r\npipeline_config_path= \"/content/drive/MyDrive/Tensorflow/models/research/faster_rcnn_inception_v2_coco_2018_01_28/pipeline.config\"\r\n\r\nnum_train_steps=100\r\nsample_1_of_n_eval_examples=1\r\nsample_1_of_n_eval_on_train_examples=5\r\nmodel_lib_v2.eval_continuously(\r\n    pipeline_config_path=pipeline_config_path,\r\n    model_dir=model_dir,\r\n    train_steps=num_train_steps,\r\n    sample_1_of_n_eval_examples=sample_1_of_n_eval_examples,\r\n    sample_1_of_n_eval_on_train_examples=(sample_1_of_n_eval_on_train_examples),\r\n    wait_interval=300, timeout=3600)\r\n```\r\n> Output\r\n```\r\nWARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\r\n[04/18 17:33:47] tensorflow WARNING: Forced number of epochs for all eval validations to be 1.\r\nINFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\r\n[04/18 17:33:47] tensorflow INFO: Maybe overwriting sample_1_of_n_eval_examples: 1\r\nINFO:tensorflow:Maybe overwriting use_bfloat16: False\r\n[04/18 17:33:47] tensorflow INFO: Maybe overwriting use_bfloat16: False\r\nINFO:tensorflow:Maybe overwriting train_steps: 100\r\n[04/18 17:33:47] tensorflow INFO: Maybe overwriting train_steps: 100\r\nINFO:tensorflow:Maybe overwriting eval_num_epochs: 1\r\n[04/18 17:33:47] tensorflow INFO: Maybe overwriting eval_num_epochs: 1\r\nWARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\r\n[04/18 17:33:47] tensorflow WARNING: Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n[<ipython-input-24-432f892b36ea>](https://localhost:8080/#) in <module>()\r\n     19     sample_1_of_n_eval_examples=sample_1_of_n_eval_examples,\r\n     20     sample_1_of_n_eval_on_train_examples=(sample_1_of_n_eval_on_train_examples),\r\n---> 21     wait_interval=300, timeout=3600)\r\n     22 \r\n\r\n3 frames\r\n[/content/drive/MyDrive/Tensorflow/models/research/object_detection/builders/model_builder.py](https://localhost:8080/#) in _check_feature_extractor_exists(feature_extractor_type)\r\n    268         '{} is not supported for tf version {}. See `model_builder.py` for '\r\n    269         'features extractors compatible with different versions of '\r\n--> 270         'Tensorflow'.format(feature_extractor_type, tf_version_str))\r\n    271 \r\n    272 \r\n\r\nValueError: faster_rcnn_inception_v2 is not supported for tf version 2. See `model_builder.py` for features extractors compatible with different versions of Tensorflow\r\n```", "comments": ["Hello @santhoshnumberone ,\r\n\r\nI request you,please download the models from the below link and let us know if the issue still persists.\r\nhttps://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\r\nAlso i request to look at this reference  [thread1](https://github.com/tensorflow/models/issues/3250) and [thread2](https://github.com/tensorflow/models/issues/4056) with the similar issue.Thanks!\r\n", "@santhoshnumberone ,\r\nThanks for opening this issue.This issue is more suitable for TensorFlow Models repo. I request you,please post it on Tensorflow Models repo from [here](https://github.com/tensorflow/models/issues/new/choose). Thanks!", "> Hello @santhoshnumberone ,\r\n> \r\n> I request you,please download the models from the below link and let us know if the issue still persists. https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md Also i request to look at this reference [thread1](https://github.com/tensorflow/models/issues/3250) and [thread2](https://github.com/tensorflow/models/issues/4056) with the similar issue.Thanks!\r\n\r\n@tilakrayal Thank you, will try your suggestions then raise the issue again if I encounter and more issues under [Tensorflow Models](https://github.com/tensorflow/models/issues/new/choose)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55654\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55654\">No</a>\n"]}, {"number": 55653, "title": "Always do safe parsing", "body": "PiperOrigin-RevId: 433016287", "comments": []}, {"number": 55640, "title": "Add TF_AssignRefVariable", "body": "The [Kernel Extension for Variable Operations API](https://github.com/tensorflow/community/blob/master/rfcs/20210504-kernel-extension-variable-ops.md) added pluggable device support for resource variables and incomplete support for ref variables (TF_OpKernelContext_ForwardRefInputToRefOutput), but it misses one endpoint to make ref variables usable: TF_AssignRefVariable.\r\n\r\nThis change attempts to fill the gaps in the RFC by adding TF_AssignRefVariable, which is analogous to TF_AssignVariable but for ref variables instead of resource variables. It uses the same semantics where the user has to pass a copy function to be called when copying the value tensor to the ref tensor.\r\n\r\n**Note: This is a remake of a [previous PR that got reverted](https://github.com/tensorflow/tensorflow/pull/55379), with a fix for the `DCHECK` on line 77 in ref_var.cc that should have been a `CHECK`.**", "comments": []}, {"number": 55638, "title": "Title", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), []()we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\n\n**System information**\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\n- TensorFlow installed from (source or binary):\n- TensorFlow version:\n- Python version:\n- Installed using virtualenv? pip? conda?:\n- Bazel version (if compiling from source):\n- GCC/Compiler version (if compiling from source):\n- CUDA/cuDNN version:\n- GPU model and memory:\n\n\n\n**Describe the problem**\n\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\n\n\n**Any other info / logs**\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.", "comments": ["Hello @abuoeissa9 ,\r\nI request you please follow the instructions mentioned in installation [document](https://www.tensorflow.org/install) for installing the latest tensorflow  \r\nversion 2.8.Thanks!"]}, {"number": 55637, "title": "r2.9 cherry-pick: Disable oneDNN by default on Windows", "body": "We would like to perform a thorough performance testing on Windows first.\r\n\r\nPiperOrigin-RevId: 438869077", "comments": []}, {"number": 55636, "title": "Added Conv2DGRU layer", "body": "Implementation of ConvGRU2D layer in tensorflow keras. \r\n\r\nExample:\r\n```python\r\nimport tensorflow as tf\r\n\r\nsteps = 10\r\nheight = 32\r\nwidth = 32\r\ninput_channels = 3\r\noutput_channels = 6\r\n\r\ninputs = tf.keras.Input(shape=(steps, height, width, input_channels))\r\nlayer = tf.keras.layers.ConvGRU2D(filters=output_channels, kernel_size=3)\r\noutputs = layer(inputs)\r\n\r\n\r\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"convgru_model\")\r\nmodel.summary()\r\n```\r\n", "comments": ["Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nFor more information, open the [CLA check for this pull request](https://github.com/tensorflow/tensorflow/pull/55636/checks?check_run_id=6038511083).", "It looks like your PR relates to the Keras component. Please submit it to the github.com/keras-team/keras repository instead. Thankyou.\r\n@fchollet, @qlzh727\r\n"]}, {"number": 55632, "title": "r2.8 cherry-pick: 70b7ef24ee8 \"Bump zlib to 1.2.12.\"", "body": "Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/70b7ef24ee8ea830d93f8ce8a38e6f34ad0257be", "comments": []}, {"number": 55631, "title": "r2.6 cherry-pick: a989426ee13 \"Improve to cover scale value greater than one\"", "body": "Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/a989426ee1346693cc015792f11d715f6944f2b8", "comments": []}, {"number": 55630, "title": "r2.7 cherry-pick: a989426ee13 \"Improve to cover scale value greater than one\"", "body": "Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/a989426ee1346693cc015792f11d715f6944f2b8", "comments": []}, {"number": 55629, "title": "r2.8 cherry-pick: a989426ee13 \"Improve to cover scale value greater than one\"", "body": "Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/a989426ee1346693cc015792f11d715f6944f2b8", "comments": []}, {"number": 55626, "title": "NotImplementedError: Cannot convert a symbolic Tensor (cond_2/strided_slice:0) to a numpy array.", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Google Colab\r\n- TensorFlow installed from (source or binary): Google Colab (default)\r\n- TensorFlow version: 1.15.2\r\n- Python version: 3.7.13\r\n- Installed using virtualenv? pip? conda?: Google Colab (no env)\r\n- Bazel version (if compiling from source): Google Colab (default)\r\n- GCC/Compiler version (if compiling from source): Google Colab (default)\r\n- CUDA/cuDNN version: Google Colab (default)\r\n- GPU model and memory: Google Colab (default)\r\n\r\n\r\n\r\n**Describe the problem**\r\nTrying to train custom object detector referring blog [Custom object detection in the browser using TensorFlow.js](https://blog.tensorflow.org/2021/01/custom-object-detection-in-browser.html)\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nRan these blocks one after other inside Google colab\r\n\r\n```\r\nfrom google.colab import drive\r\ndrive.mount('/content/drive/')\r\n```\r\n\r\n```\r\n%cd /content/drive/MyDrive/Tensorflow/models/research/\r\n```\r\n\r\n```\r\n!git clone https://github.com/tensorflow/models.git\r\n```\r\n\r\n```\r\n%tensorflow_version 1.x\r\n```\r\n\r\n```\r\n!protoc object_detection/protos/*.proto --python_out=.\r\n# Install TensorFlow Object Detection API.\r\n!cp object_detection/packages/tf1/setup.py .\r\n!python -m pip install .\r\n```\r\n\r\n```\r\n!python /content/drive/MyDrive/Tensorflow/models/research/object_detection/builders/model_builder_tf1_test.py\r\n```\r\n\r\n```\r\nnum_classes = 1\r\nbatch_size = 96\r\nnum_steps = 7500\r\nnum_eval_steps = 1000\r\n\r\ntrain_record_path = '/content/drive/MyDrive/Tensorflow/dataset/train.record'\r\ntest_record_path = '/content/drive/MyDrive/Tensorflow/dataset/test.record'\r\nmodel_dir = '/content/training/'\r\nlabelmap_path = '/content/drive/MyDrive/Tensorflow/dataset/labelmap.pbtxt'\r\n\r\npipeline_config_path = '/content/drive/MyDrive/Tensorflow/models/research/faster_rcnn_inception_v2_coco_2018_01_28/pipeline.config'\r\nfine_tune_checkpoint = '/content/drive/MyDrive/Tensorflow/models/research/faster_rcnn_inception_v2_coco_2018_01_28_training/faster_rcnn_inception_training.ckpt-1'\r\n```\r\n\r\n```\r\n!python /content/drive/MyDrive/Tensorflow/models/research/object_detection/model_main.py \\\r\n    --pipeline_config_path={pipeline_config_path} \\\r\n    --model_dir={model_dir} \\\r\n    --alsologtostderr \\\r\n    --num_train_steps={num_steps} \\\r\n    --sample_1_of_n_eval_examples=1 \\\r\n    --num_eval_steps={num_eval_steps}\r\n```\r\n\r\nError I get\r\n```\r\nreturn input_fn(**kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/inputs.py\", line 770, in _train_input_fn\r\n    params=params)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/inputs.py\", line 913, in train_input\r\n    reduce_to_frame_fn=reduce_to_frame_fn)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py\", line 251, in build\r\n    input_reader_config)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py\", line 236, in dataset_map_fn\r\n    fn_to_map, num_parallel_calls=num_parallel_calls)\r\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/data/ops/dataset_ops.py\", line 1950, in map_with_legacy_function\r\n    use_legacy_function=True))\r\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/data/ops/dataset_ops.py\", line 3472, in __init__\r\n    use_legacy_function=use_legacy_function)\r\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/data/ops/dataset_ops.py\", line 2689, in __init__\r\n    self._function.add_to_graph(ops.get_default_graph())\r\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/function.py\", line 545, in add_to_graph\r\n    self._create_definition_if_needed()\r\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/function.py\", line 377, in _create_definition_if_needed\r\n    self._create_definition_if_needed_impl()\r\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/function.py\", line 408, in _create_definition_if_needed_impl\r\n    capture_resource_var_by_value=self._capture_resource_var_by_value)\r\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/function.py\", line 944, in func_graph_from_py_func\r\n    outputs = func(*func_graph.inputs)\r\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/data/ops/dataset_ops.py\", line 2681, in wrapper_fn\r\n    ret = _wrapper_helper(*args)\r\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/data/ops/dataset_ops.py\", line 2652, in _wrapper_helper\r\n    ret = autograph.tf_convert(func, ag_ctx)(*nested_args)\r\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/autograph/impl/api.py\", line 237, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nNotImplementedError: in converted code:\r\n\r\n    /usr/local/lib/python3.7/dist-packages/object_detection/data_decoders/tf_example_decoder.py:580 decode\r\n        default_groundtruth_weights)\r\n    /tensorflow-1.15.2/python3.7/tensorflow_core/python/util/deprecation.py:507 new_func\r\n        return func(*args, **kwargs)\r\n    /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/control_flow_ops.py:1235 cond\r\n        orig_res_f, res_f = context_f.BuildCondBranch(false_fn)\r\n    /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/control_flow_ops.py:1061 BuildCondBranch\r\n        original_result = fn()\r\n    /usr/local/lib/python3.7/dist-packages/object_detection/data_decoders/tf_example_decoder.py:573 default_groundtruth_weights\r\n        dtype=tf.float32)\r\n    /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/array_ops.py:2560 ones\r\n        output = _constant_if_small(one, shape, dtype, name)\r\n    /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/array_ops.py:2295 _constant_if_small\r\n        if np.prod(shape) < 1000:\r\n    <__array_function__ internals>:6 prod\r\n        \r\n    /usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3052 prod\r\n        keepdims=keepdims, initial=initial, where=where)\r\n    /usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:86 _wrapreduction\r\n        return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\r\n    /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py:736 __array__\r\n        \" array.\".format(self.name))\r\n\r\n    NotImplementedError: Cannot convert a symbolic Tensor (cond_2/strided_slice:0) to a numpy array.\r\n```\r\n\r\nIf I run this\r\n```\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom absl import flags\r\nimport tensorflow as tf\r\nfrom object_detection import model_hparams\r\nfrom object_detection import model_lib\r\n\r\nmodel_dir = \"/content/drive/MyDrive/Tensorflow/models/research/faster_rcnn_inception_v2_coco_2018_01_28_training/\"\r\n\r\n\r\n\r\nconfig = tf.estimator.RunConfig(model_dir=model_dir)\r\npipeline_config_path= \"/content/drive/MyDrive/Tensorflow/models/research/faster_rcnn_inception_v2_coco_2018_01_28/pipeline.config\"\r\nnum_train_steps=100\r\n\r\n\r\ntrain_and_eval_dict = model_lib.create_estimator_and_inputs(\r\n                        run_config=config,\r\n                        hparams=model_hparams.create_hparams(None),\r\n                        pipeline_config_path = pipeline_config_path,\r\n                        train_steps =num_train_steps,\r\n                        sample_1_of_n_eval_examples = 1)\r\n\r\nestimator = train_and_eval_dict['estimator']\r\ntrain_input_fn = train_and_eval_dict['train_input_fn']\r\neval_input_fns = train_and_eval_dict['eval_input_fns']\r\neval_on_train_input_fn = train_and_eval_dict['eval_on_train_input_fn']\r\npredict_input_fn = train_and_eval_dict['predict_input_fn']\r\ntrain_steps = train_and_eval_dict['train_steps']\r\n\r\ntrain_spec, eval_specs = model_lib.create_train_and_eval_specs(\r\n        train_input_fn,\r\n        eval_input_fns,\r\n        eval_on_train_input_fn,\r\n        predict_input_fn,\r\n        train_steps,\r\n        eval_on_train_data=False)\r\ntf.estimator.train_and_evaluate(estimator,train_spec,eval_specs[0])\r\n```\r\n\r\nError I get\r\n```\r\nUsing TensorFlow backend.\r\nWARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\r\n[04/14 16:53:43] tensorflow WARNING: Forced number of epochs for all eval validations to be 1.\r\nINFO:tensorflow:Maybe overwriting train_steps: 100\r\n[04/14 16:53:43] tensorflow INFO: Maybe overwriting train_steps: 100\r\nINFO:tensorflow:Maybe overwriting use_bfloat16: False\r\n[04/14 16:53:43] tensorflow INFO: Maybe overwriting use_bfloat16: False\r\nINFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\r\n[04/14 16:53:43] tensorflow INFO: Maybe overwriting sample_1_of_n_eval_examples: 1\r\nINFO:tensorflow:Maybe overwriting eval_num_epochs: 1\r\n[04/14 16:53:43] tensorflow INFO: Maybe overwriting eval_num_epochs: 1\r\nINFO:tensorflow:Maybe overwriting load_pretrained: True\r\n[04/14 16:53:43] tensorflow INFO: Maybe overwriting load_pretrained: True\r\nINFO:tensorflow:Ignoring config override key: load_pretrained\r\n[04/14 16:53:43] tensorflow INFO: Ignoring config override key: load_pretrained\r\nWARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\r\n[04/14 16:53:43] tensorflow WARNING: Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\r\nINFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\r\n[04/14 16:53:43] tensorflow INFO: create_estimator_and_inputs: use_tpu False, export_to_tpu False\r\nINFO:tensorflow:Using config: {'_model_dir': '/content/drive/MyDrive/Tensorflow/models/research/faster_rcnn_inception_v2_coco_2018_01_28_training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\r\ngraph_options {\r\n  rewrite_options {\r\n    meta_optimizer_iterations: ONE\r\n  }\r\n}\r\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6e89f30590>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\r\n[04/14 16:53:43] tensorflow INFO: Using config: {'_model_dir': '/content/drive/MyDrive/Tensorflow/models/research/faster_rcnn_inception_v2_coco_2018_01_28_training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\r\ngraph_options {\r\n  rewrite_options {\r\n    meta_optimizer_iterations: ONE\r\n  }\r\n}\r\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6e89f30590>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\r\nWARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f6e89f2f050>) includes params argument, but params are not passed to Estimator.\r\n[04/14 16:53:43] tensorflow WARNING: Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f6e89f2f050>) includes params argument, but params are not passed to Estimator.\r\nINFO:tensorflow:Not using Distribute Coordinator.\r\n[04/14 16:53:43] tensorflow INFO: Not using Distribute Coordinator.\r\nINFO:tensorflow:Running training and evaluation locally (non-distributed).\r\n[04/14 16:53:43] tensorflow INFO: Running training and evaluation locally (non-distributed).\r\nINFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\r\n[04/14 16:53:43] tensorflow INFO: Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\r\nWARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\r\n[04/14 16:53:43] tensorflow WARNING: From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\r\nINFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/Tensorflow/dataset/train.record']\r\n[04/14 16:53:43] tensorflow INFO: Reading unweighted datasets: ['/content/drive/MyDrive/Tensorflow/dataset/train.record']\r\nINFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/Tensorflow/dataset/train.record']\r\n[04/14 16:53:43] tensorflow INFO: Reading record datasets for input file: ['/content/drive/MyDrive/Tensorflow/dataset/train.record']\r\nINFO:tensorflow:Number of filenames to read: 1\r\n[04/14 16:53:43] tensorflow INFO: Number of filenames to read: 1\r\nWARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\r\n[04/14 16:53:43] tensorflow WARNING: num_readers has been reduced to 1 to match input file shards.\r\nWARNING:tensorflow:From /content/drive/MyDrive/Tensorflow/models/research/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\r\n[04/14 16:53:43] tensorflow WARNING: From /content/drive/MyDrive/Tensorflow/models/research/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\r\nWARNING:tensorflow:From /content/drive/MyDrive/Tensorflow/models/research/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.map()\r\n[04/14 16:53:43] tensorflow WARNING: From /content/drive/MyDrive/Tensorflow/models/research/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.map()\r\nWARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f6e89f3fc10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\r\n[04/14 16:53:43] tensorflow WARNING: Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f6e89f3fc10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\r\nWARNING: Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f6e89f3fc10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\r\n---------------------------------------------------------------------------\r\nNotImplementedError                       Traceback (most recent call last)\r\n[<ipython-input-11-ab0734737a9e>](https://localhost:8080/#) in <module>()\r\n     39         train_steps,\r\n     40         eval_on_train_data=False)\r\n---> 41 tf.estimator.train_and_evaluate(estimator,train_spec,eval_specs[0])\r\n\r\n22 frames\r\n[/tensorflow-1.15.2/python3.7/tensorflow_core/python/autograph/impl/api.py](https://localhost:8080/#) in wrapper(*args, **kwargs)\r\n    235       except Exception as e:  # pylint:disable=broad-except\r\n    236         if hasattr(e, 'ag_error_metadata'):\r\n--> 237           raise e.ag_error_metadata.to_exception(e)\r\n    238         else:\r\n    239           raise\r\n\r\nNotImplementedError: in converted code:\r\n\r\n    /content/drive/MyDrive/Tensorflow/models/research/object_detection/data_decoders/tf_example_decoder.py:580 decode\r\n        default_groundtruth_weights)\r\n    /tensorflow-1.15.2/python3.7/tensorflow_core/python/util/deprecation.py:507 new_func\r\n        return func(*args, **kwargs)\r\n    /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/control_flow_ops.py:1235 cond\r\n        orig_res_f, res_f = context_f.BuildCondBranch(false_fn)\r\n    /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/control_flow_ops.py:1061 BuildCondBranch\r\n        original_result = fn()\r\n    /content/drive/MyDrive/Tensorflow/models/research/object_detection/data_decoders/tf_example_decoder.py:573 default_groundtruth_weights\r\n        dtype=tf.float32)\r\n    /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/array_ops.py:2560 ones\r\n        output = _constant_if_small(one, shape, dtype, name)\r\n    /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/array_ops.py:2295 _constant_if_small\r\n        if np.prod(shape) < 1000:\r\n    <__array_function__ internals>:6 prod\r\n        \r\n    /usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3052 prod\r\n        keepdims=keepdims, initial=initial, where=where)\r\n    /usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:86 _wrapreduction\r\n        return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\r\n    /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py:736 __array__\r\n        \" array.\".format(self.name))\r\n\r\n    NotImplementedError: Cannot convert a symbolic Tensor (cond_2/strided_slice:0) to a numpy array.\r\n```\r\n What is wrong here?\r\n", "comments": ["@santhoshnumberone We  see that you are using older version of TF (v1.15) which is not actively supported so we recommend you to kindly upgrade  to the latest TF versions(2.4 or later) and let us know if it is still an issue ?Please refer [this ](https://www.tensorflow.org/guide/migrate)link for migration \r\nfrom TF v1.x to 2.x .\r\nThanks!", "> @santhoshnumberone We see that you are using older version of TF (v1.15) which is not actively supported so we recommend you to kindly upgrade to the latest TF versions(2.4 or later) and let us know if it is still an issue ?Please refer [this ](https://www.tensorflow.org/guide/migrate)link for migration from TF v1.x to 2.x . Thanks!\r\n\r\nThank you for your response, I have raised the same here [Google Colab ValueError: faster_rcnn_inception_v2 is not supported for tf version 2. See model_builder.py for features extractors compatible with different versions of Tensorflow](https://github.com/tensorflow/tensorflow/issues/55654)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55626\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55626\">No</a>\n"]}, {"number": 55625, "title": "Delete 60-tflite-converter-issue.md", "body": null, "comments": []}, {"number": 55612, "title": "[oneDNN] Fix for some unit test failures", "body": "This PR fixes some unit test failures\r\n\r\n//tensorflow/python/client:timeline_test_cpu,\r\n\r\n//tensorflow/c/eager:c_api_distributed_test_cpu,\r\n\r\n//tensorflow/python/eager:context_test_cpu,\r\n\r\n//tensorflow/python/framework:config_test_cpu,\r\n\r\n//tensorflow/python/framework:config_test_tpu,\r\n\r\n//tensorflow/python/framework:node_file_writer_test_cpu\r\n\r\nThis fix makes sure that python code can query correctly if oneDNN is enabled or not", "comments": ["temporary closing this PR in order to refine code change", "This PR fixes some unit test failures\r\n\r\n//tensorflow/python/client:timeline_test_cpu,\r\n\r\n//tensorflow/c/eager:c_api_distributed_test_cpu,\r\n\r\n//tensorflow/python/eager:context_test_cpu,\r\n\r\n//tensorflow/python/framework:config_test_cpu,\r\n\r\n//tensorflow/python/framework:config_test_tpu,\r\n\r\n//tensorflow/python/framework:node_file_writer_test_cpu\r\n\r\nThis fix makes sure that python code can query correctly if oneDNN is enabled or not", "Reopening this PR which makes sure that python code can query correctly if oneDNN is enabled or not, this PR is necessary to fix some python unit test failures"]}, {"number": 55611, "title": "Avoid redundant PTX generation during nvcc compilation", "body": "In nvcc, we currently use the following two options to specify we want to store both PTX and cubin for arch xy in the resulting binary. This will cause PTX to be generated twice; first to store the PTX directly in the binary (backend = compute_xy) and then second to be compiled to cubin (backend = sm_xy). \r\n\r\n```\r\n-gencode=arch=compute_xy,code=compute_xy\r\n-gencode=arch=compute_xy,code=sm_xy\r\n```\r\n\r\nInstead, we can use the following which combines both steps, so that the PTX is only generated once.\r\n\r\n```\r\n-gencode=arch=compute_xy,code=\\\"compute_xy,sm_xy\\\"\r\n```\r\n\r\nThis change should reduce compilation time.", "comments": ["Nice, thanks for that improvement!"]}, {"number": 55607, "title": "k", "body": null, "comments": []}, {"number": 55603, "title": "Add reference to ResourceVariables", "body": "Added Reference to resource variable.\r\nFixes: https://github.com/tensorflow/tensorflow/issues/49614", "comments": []}, {"number": 55598, "title": "In tensorflow 2.8.0 multi input / multi output keras model not working", "body": "**System information**\r\n- tensorflow 2.8.0\r\n- python 3.8.12\r\n- Windows 10 Home 21H2 (19044.1586)\r\n- CPU : AMD Ryzen 9 3900XT 12-Core Processor 3.80 GHz\r\n- RAM : 64.0GB\r\n- GPU : NVIDIA GeForce GRX 1660 SUPER\r\n- NVIDIA-SMI 496.13 / Driver Version: 496.13 / CUDA Version: 11.5 / cuDNN version 8302\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n```import numpy as np\r\nimport tensorflow as tf\r\ni1 = tf.keras.layers.Input(shape=(10, 1))\r\ni2 = tf.keras.layers.Input(shape=(20, 1))\r\ni3 = tf.keras.layers.Input(shape=(40, 10))\r\nh1 = tf.keras.layers.Conv1D(32, 10, name='o1')(i1)\r\nh2 = tf.keras.layers.Conv1D(32, 20, name='o2')(i2)\r\nh3 = tf.keras.layers.Conv1D(32, 40, name='o3')(i3)\r\nm = tf.keras.Model(inputs=[i1,i2,i3], outputs=[h1,h2,h3])\r\ndef loss(y_true,y_pred):\r\n    return tf.losses.mean_absolute_error(y_true, y_pred) + tf.losses.mean_squared_error(y_true, y_pred)\r\nm.compile(optimizer='adam', loss={'o1': 'mse', 'o2':\"mae\", 'o3': loss})\r\nm.fit([np.random.normal(size=(10,10,1)), np.random.normal(size=(10,20,1)), np.random.normal(size=(10,40,10))], [np.random.normal(size=(10,1,32)),np.random.normal(size=(10,1,32)),np.random.normal(size=(10,1,32))])\r\nm.predict([np.random.normal(size=(10,10,1)), np.random.normal(size=(10,20,1)), np.random.normal(size=(10,40,10))])\r\n```\r\n- OUTPUT : \r\n```2022-04-13 09:27:20.307913: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2022-04-13 09:27:20.725606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3995 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:26:00.0, compute capability: 7.5\r\n2022-04-13 09:27:22.135084: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8302\r\n\r\nProcess finished with exit code -1073740791 (0xC0000409)\r\n```\r\n\r\n**Describe the expected behavior**\r\nIn Previous version tensorflow, work done same code, but in later 2.7.1 occur, error and can't running same code\r\n\r\n\r\n- Do you want to contribute a PR? (yes/no): may be can't\r\n- Briefly describe your candidate solution(if contributing):\r\n", "comments": ["@shinel94,\r\n\r\nI am successfully able to run using Colab `TF2.8`. Please find [the](https://colab.research.google.com/gist/chunduriv/474bba9885746fbea4b4643f68b877d2/55598.ipynb) gist for reference.\r\n\r\n>CUDA Version: 11.5 / cuDNN version 8302\r\n\r\nCould you please try with `CUDA 11.2` and `cuDNN 8.1` for `TF2.8`. Please refer tested build configuration [here](https://www.tensorflow.org/install/source_windows#gpu).\r\n\r\nTo limit memory usage on the GPU, you can always set the memory growth at the start of your code like mentioned [here](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth). Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55598\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55598\">No</a>\n"]}, {"number": 55597, "title": "Mention DTensor in 2.9 release notes", "body": null, "comments": []}, {"number": 55596, "title": "r2.9 cherry-pick: 755d37a53d8 \"Update documentation for `Mesh` and `Layout`.\"", "body": "Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/755d37a53d89d7f080a8c8129e8e2251e70324f3", "comments": []}, {"number": 55595, "title": "Possible shuffling issue with using `tf.data.Dataset.list_files`?", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 22.04 (Tried colab as well)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): pip wheel\r\n- TensorFlow version (use command below): 2.8.0 `v2.8.0-rc1-32-g3f878cff5b6 2.8.0`\r\n- Python version: 3.8.6\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: 11.2\r\n- GPU model and memory: RTX 3090 (24GB)\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nI'm having some weird behavior where I'm enumerating files in a directory, then generating the corresponding labels by using the map of the first dataset. However the order isn't being preserved when I zip them together. I've tried zipping a dataset generated from tensor slices and that seems to work. I've also tested this on Colab and get the same issue.\r\n\r\nEDIT: I checked the documentation and understand there's a shuffle parameter in list files which defaults to True, but I was expecting that if I'm zipping the same object with itself I should get matching pairs. Let me know if this is the intended behavior\r\n\r\n**Describe the expected behavior**\r\n\r\nI expect that if I zip a dataset with itself I should get pairs of matching items when I iterate over it.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\nimport os\r\nimport tensorflow as tf\r\n\r\ntf.random.set_seed(42)\r\n\r\nfrom tempfile import TemporaryDirectory\r\n\r\nwith TemporaryDirectory() as temp_dir:\r\n    for i in range(10):\r\n        os.mknod(os.path.join(temp_dir, f\"{i}.txt\"))\r\n\r\n    inputs = tf.data.Dataset.list_files(f\"{temp_dir}/*\")\r\n    ds = tf.data.Dataset.zip((inputs, inputs))\r\n\r\n    for x, y in ds:\r\n        print(f\"Input: {str(x)}, Output: {str(y)}\")\r\n```\r\n\r\nGives me:\r\n```\r\nInput: tf.Tensor(b'/tmp/tmpxcqf5sg_/5.txt', shape=(), dtype=string), Output: tf.Tensor(b'/tmp/tmpxcqf5sg_/8.txt', shape=(), dtype=string)\r\nInput: tf.Tensor(b'/tmp/tmpxcqf5sg_/8.txt', shape=(), dtype=string), Output: tf.Tensor(b'/tmp/tmpxcqf5sg_/0.txt', shape=(), dtype=string)\r\nInput: tf.Tensor(b'/tmp/tmpxcqf5sg_/2.txt', shape=(), dtype=string), Output: tf.Tensor(b'/tmp/tmpxcqf5sg_/4.txt', shape=(), dtype=string)\r\nInput: tf.Tensor(b'/tmp/tmpxcqf5sg_/0.txt', shape=(), dtype=string), Output: tf.Tensor(b'/tmp/tmpxcqf5sg_/1.txt', shape=(), dtype=string)\r\nInput: tf.Tensor(b'/tmp/tmpxcqf5sg_/4.txt', shape=(), dtype=string), Output: tf.Tensor(b'/tmp/tmpxcqf5sg_/2.txt', shape=(), dtype=string)\r\nInput: tf.Tensor(b'/tmp/tmpxcqf5sg_/7.txt', shape=(), dtype=string), Output: tf.Tensor(b'/tmp/tmpxcqf5sg_/7.txt', shape=(), dtype=string)\r\nInput: tf.Tensor(b'/tmp/tmpxcqf5sg_/1.txt', shape=(), dtype=string), Output: tf.Tensor(b'/tmp/tmpxcqf5sg_/3.txt', shape=(), dtype=string)\r\nInput: tf.Tensor(b'/tmp/tmpxcqf5sg_/3.txt', shape=(), dtype=string), Output: tf.Tensor(b'/tmp/tmpxcqf5sg_/9.txt', shape=(), dtype=string)\r\nInput: tf.Tensor(b'/tmp/tmpxcqf5sg_/9.txt', shape=(), dtype=string), Output: tf.Tensor(b'/tmp/tmpxcqf5sg_/6.txt', shape=(), dtype=string)\r\nInput: tf.Tensor(b'/tmp/tmpxcqf5sg_/6.txt', shape=(), dtype=string), Output: tf.Tensor(b'/tmp/tmpxcqf5sg_/5.txt', shape=(), dtype=string)\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@dogeplusplus - As you specified, if we pass with Shuffle=False, we get the desired result - \r\n```\r\nimport os\r\nimport tensorflow as tf\r\n\r\ntf.random.set_seed(42)\r\n\r\nfrom tempfile import TemporaryDirectory\r\n\r\nwith TemporaryDirectory() as temp_dir:\r\n    for i in range(10):\r\n        with open(os.path.join(temp_dir, f\"{i}.txt\"), 'a'):\r\n            pass\r\n\r\n    inputs = tf.data.Dataset.list_files(f\"{temp_dir}/*\", shuffle=False)\r\n    ds = tf.data.Dataset.zip((inputs, inputs))\r\n\r\n    for x, y in ds:\r\n        print(f\"Input: {str(x)}, Output: {str(y)}\")\r\n\r\nInput: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmpyf723czy/0.txt', shape=(), dtype=string), Output: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmpyf723czy/0.txt', shape=(), dtype=string)\r\nInput: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmpyf723czy/1.txt', shape=(), dtype=string), Output: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmpyf723czy/1.txt', shape=(), dtype=string)\r\nInput: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmpyf723czy/2.txt', shape=(), dtype=string), Output: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmpyf723czy/2.txt', shape=(), dtype=string)\r\nInput: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmpyf723czy/3.txt', shape=(), dtype=string), Output: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmpyf723czy/3.txt', shape=(), dtype=string)\r\nInput: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmpyf723czy/4.txt', shape=(), dtype=string), Output: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmpyf723czy/4.txt', shape=(), dtype=string)\r\nInput: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmpyf723czy/5.txt', shape=(), dtype=string), Output: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmpyf723czy/5.txt', shape=(), dtype=string)\r\nInput: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmpyf723czy/6.txt', shape=(), dtype=string), Output: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmpyf723czy/6.txt', shape=(), dtype=string)\r\nInput: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmpyf723czy/7.txt', shape=(), dtype=string), Output: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmpyf723czy/7.txt', shape=(), dtype=string)\r\nInput: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmpyf723czy/8.txt', shape=(), dtype=string), Output: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmpyf723czy/8.txt', shape=(), dtype=string)\r\nInput: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmpyf723czy/9.txt', shape=(), dtype=string), Output: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmpyf723czy/9.txt', shape=(), dtype=string)\r\n```\r\n\r\nAs for the question on why `tf.data.Dataset.zip((inputs, inputs))` not picking the same values, it selects from the datasets and each time it selects an item, it will get different results.  For example, if we iterate on the dataset as - \r\n\r\n```\r\nfor item in inputs:\r\n    print(item)\r\n```\r\nYou will get non-deterministic results, unless you set shuffle=False or set a seed as per the docs of `tf.data.Dataset.list_files` and its the intended behavior.  Even though we use the same dataset name twice in `tf.data.Dataset.zip((inputs, inputs))`, its actually independently iterating and selecting values from them.\r\n\r\nI don't see this as a bug or issue to be fixed.  If you want to shuffle the file lists, you could explicitly add a shuffle step as below - \r\n\r\n```\r\nimport os\r\nimport tensorflow as tf\r\n\r\ntf.random.set_seed(42)\r\n\r\nfrom tempfile import TemporaryDirectory\r\n\r\nwith TemporaryDirectory() as temp_dir:\r\n    for i in range(10):\r\n        with open(os.path.join(temp_dir, f\"{i}.txt\"), 'a'):\r\n            pass\r\n\r\n    inputs = tf.data.Dataset.list_files(f\"{temp_dir}/*\", shuffle=False)\r\n    ds = tf.data.Dataset.zip((inputs, inputs)).shuffle(10) # change the buffer size\r\n\r\n    for x, y in ds:\r\n        print(f\"Input: {str(x)}, Output: {str(y)}\")\r\n```\r\nWhich yields the expected result:\r\n```\r\nInput: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmp1bjzqvm9/5.txt', shape=(), dtype=string), Output: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmp1bjzqvm9/5.txt', shape=(), dtype=string)\r\nInput: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmp1bjzqvm9/8.txt', shape=(), dtype=string), Output: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmp1bjzqvm9/8.txt', shape=(), dtype=string)\r\nInput: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmp1bjzqvm9/2.txt', shape=(), dtype=string), Output: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmp1bjzqvm9/2.txt', shape=(), dtype=string)\r\nInput: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmp1bjzqvm9/0.txt', shape=(), dtype=string), Output: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmp1bjzqvm9/0.txt', shape=(), dtype=string)\r\nInput: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmp1bjzqvm9/4.txt', shape=(), dtype=string), Output: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmp1bjzqvm9/4.txt', shape=(), dtype=string)\r\nInput: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmp1bjzqvm9/7.txt', shape=(), dtype=string), Output: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmp1bjzqvm9/7.txt', shape=(), dtype=string)\r\nInput: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmp1bjzqvm9/1.txt', shape=(), dtype=string), Output: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmp1bjzqvm9/1.txt', shape=(), dtype=string)\r\nInput: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmp1bjzqvm9/3.txt', shape=(), dtype=string), Output: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmp1bjzqvm9/3.txt', shape=(), dtype=string)\r\nInput: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmp1bjzqvm9/9.txt', shape=(), dtype=string), Output: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmp1bjzqvm9/9.txt', shape=(), dtype=string)\r\nInput: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmp1bjzqvm9/6.txt', shape=(), dtype=string), Output: tf.Tensor(b'/var/folders/_z/pqb4w9_10yv7c7_7vw6dh5k800vh8l/T/tmp1bjzqvm9/6.txt', shape=(), dtype=string)\r\n```", "Ok fair enough. I knew the fix afterwards was to turn off the shuffle, but wasn't sure if this was the desired behavior when shuffling.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55595\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55595\">No</a>\n"]}]