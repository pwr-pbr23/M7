[{"number": 13686, "title": "Documentation truncated_normal does not match implementation", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Nope\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux CentOS 7.3\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.3.0-rc2-20-g0787eee 1.3.0\r\n- **Python version**: Python 3.6.1\r\n- **Bazel version (if compiling from source)**: N.A.\r\n- **CUDA/cuDNN version**: 8.0 / 6.0\r\n- **GPU model and memory**: Nvidia Tesla 12 GB\r\n- **Exact command to reproduce**: ?\r\n\r\n### Describe the problem\r\nThe documentation of `tf.truncated_normal`[https://www.tensorflow.org/api_docs/python/tf/truncated_normal] contains the following line for its parameter `stddev`: \r\n\r\n> The standard deviation of the truncated normal distribution.\r\n\r\nHowever, the example below shows that the truncated normal does not have the given standard deviation. This means that the documentation would be correct if it said\r\n\r\n> The standard deviation of the normal distribution, before truncation.\r\n\r\nor if the standard deviation of the samples would be indeed the given standard deviation.\r\n\r\n### Source code / logs\r\n\r\n    import numpy as np\r\n    import tensorflow as tf\r\n\r\n    # standard deviation not 1\r\n    with tf.Session():\r\n        print(np.std(tf.truncated_normal([10000, ], stddev=1).eval()))\r\n\r\n    # compared to scipy\r\n    from scipy.stats import truncnorm\r\n    print(truncnorm(-2, 2, loc=0, scale=1).std())\r\n", "comments": ["I'd be delighted if you fixed this in the python docstring and sent a pull request :)", "@dr4b That would require me to sign legal documents and I am not quite sure whether I am ready for that sort of commitment. That's one of the reasons why I did not directly issue a pull request.", "Ok. I'll make the change (though I'm going to do it in the Google side of the codebase so it won't propagate out for a few days).", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly."]}, {"number": 13685, "title": "Linux compile v1.1.0 failed", "body": "> ERROR: /home/fesun/.cache/bazel/_bazel_fesun/c44abb322eef8ca1d3dd1c34fcda8c3a/external/io_bazel_rules_closure/closure/private/defs.bzl:27:16: The `set` constructor for depsets is deprecated and will be removed. Please use the `depset` constructor instead. You can temporarily enable the deprecated `set` constructor by passing the flag --incompatible_disallow_set_constructor=false\r\n> ERROR: error loading package '': Extension file 'closure/private/defs.bzl' has errors\r\n> ERROR: error loading package '': Extension file 'closure/private/defs.bzl' has errors\r\n\r\nI added the flag --incompatible_disallow_set_constructor=false for all bazel command call, then:\r\n\r\n> DEBUG: /home/fesun/.cache/bazel/_bazel_fesun/c44abb322eef8ca1d3dd1c34fcda8c3a/external/bazel_tools/tools/build_defs/pkg/pkg.bzl:197:9: @//tensorflow/tools/lib_package:libtensorflow_jni: you provided a non dictionary to the pkg_tar `files` attribute. This attribute was renamed to `srcs`. Consider renaming it in your BUILD file.\r\n> DEBUG: /home/fesun/.cache/bazel/_bazel_fesun/c44abb322eef8ca1d3dd1c34fcda8c3a/external/bazel_tools/tools/build_defs/pkg/pkg.bzl:197:9: @//tensorflow/tools/lib_package:cheaders: you provided a non dictionary to the pkg_tar `files` attribute. This attribute was renamed to `srcs`. Consider renaming it in your BUILD file.\r\n> DEBUG: /home/fesun/.cache/bazel/_bazel_fesun/c44abb322eef8ca1d3dd1c34fcda8c3a/external/bazel_tools/tools/build_defs/pkg/pkg.bzl:197:9: @//tensorflow/tools/lib_package:clib: you provided a non dictionary to the pkg_tar `files` attribute. This attribute was renamed to `srcs`. Consider renaming it in your BUILD file.\r\n> DEBUG: /home/fesun/.cache/bazel/_bazel_fesun/c44abb322eef8ca1d3dd1c34fcda8c3a/external/bazel_tools/tools/build_defs/pkg/pkg.bzl:197:9: @//tensorflow/tools/lib_package:clicenses: you provided a non dictionary to the pkg_tar `files` attribute. This attribute was renamed to `srcs`. Consider renaming it in your BUILD file.\r\n> ERROR: /home/fesun/tensorflow/tensorflow/core/kernels/BUILD:59:14: Traceback (most recent call last):\r\n>         File \"/home/fesun/tensorflow/tensorflow/core/kernels/BUILD\", line 54\r\n>                 config_setting(name = \"xsmm_backward\", values = {...\"})\r\n>         File \"/home/fesun/tensorflow/tensorflow/core/kernels/BUILD\", line 59, in config_setting\r\n>                 {\"define\": \"tensorflow_xsmm=1\", \"define\": \"tensorflow_xsmm_backward=1\"}\r\n> Duplicated key \"define\" when creating dictionary\r\n> ERROR: package contains errors: tensorflow/core/kernels\r\n> ERROR: error loading package 'tensorflow/core/kernels': Package 'tensorflow/core/kernels' contains errors\r\n> \r\n\r\nAny solution for this?\r\n", "comments": ["Try using the latest version of TensorFlow (1.3 or master) and Bazel.", "Bazel had quite a few backwards incompatible changes this year, so the error is definitely due to using an incompatible bazel version. You have two options:\r\n- Use a new branch as @reedwm suggested\r\n- Or use the appropriate bazel version, as listed at the bottom of this page: \r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/install/install_sources.md"]}, {"number": 13684, "title": "Fix deadlocks in Staging Areas.", "body": "Previously, `notify_one` was used to notify inserters and removers waiting to insert and remove elements into the Staging Areas. This could result in deadlock when  many removers where waiting for\r\ndifferent keys in the case of the MapStagingArea, or were waiting on either peeks or get operations in the StagingArea.\r\n\r\nFor example, if two removers were waiting for keys 2 and 3 in a MapStaging Area respectively, and 2 was inserted but only 3's remover was notified, it is possible that 2's remover would never be notified resulting in deadlock. Thus, both should be notified.\r\n\r\nSimilarly in the case of the StagingArea with a remover and a peeker wanting to remove the last element and peek at a specific element respectively, it is not clear which one should be notified due to\r\nan insert. Thus, both should be notified.\r\n\r\nAdditionally, all inserters are now notified when an element is removed. Consider the case where two inserters are waiting to small elements into the Staging Area and a remover removes a single large element. As there may be space for both insertion elements, both inserters should be notified.", "comments": ["Can one of the admins verify this patch?", "With reference to https://github.com/tensorflow/tensorflow/pull/9686 and https://github.com/tensorflow/tensorflow/pull/10528\r\n", "cc @ekelsen", "@ekelsen, can you take a look at this PR?", "@tensorflow-jenkins test this please"]}, {"number": 13683, "title": "How to feed SparseTensor in C++ API?", "body": "I trained model via python. After training done, I want to load the model and its checkpoint for prediction via C++. But I can't find any solutions about how to feed SparseTensor or Example in C++ API.\r\n\r\npython train code:\r\n```python\r\nwith tf.name_scope('input'):\r\n    filename_queue = tf.train.string_input_producer(\r\n    tf.train.match_filenames_once(file_name), num_epochs=max_epoch)\r\n    serialized_example = self.Decode(filename_queue)\r\n    capacity = thread_num * batch_size + min_after_dequeue\r\n    batch_serialized_example = tf.train.shuffle_batch(\r\n                                    [serialized_example],\r\n                                    batch_size=batch_size,\r\n                                    num_threads=thread_num,\r\n                                    capacity=capacity,\r\n                                    min_after_dequeue=min_after_dequeue)\r\n    features = {}\r\n    features['label'] = tf.FixedLenFeature([], tf.float32)\r\n    features['continuous_feature'] = tf.FixedLenFeature([], tf.float32)\r\n    features['sparse_id'] = tf.VarLenFeature(tf.int64)\r\n    features['sparse_val'] = tf.VarLenFeature(tf.float32)\r\n    instance = tf.parse_example(batch_serialized_example, features)\r\n\r\n    label_tensor = instance['label']\r\n    continuous_feature_tensor = instance['continuous_val']\r\n    sparse_id_tensor = instance['sparse_id']\r\n    sparse_val_tensor = instance['sparse_val']\r\n\r\nwith tf.variable_scope(\"emb\") as scope:\r\n    embedding_variable = tf.Variable(tf.truncated_normal([1000000, 50], stddev=0.05), name='emb_matrix')\r\n    embedding = tf.nn.embedding_lookup_sparse(embedding_variable, sparse_id_tensor, sparse_val_tensor, \"mod\", combiner=\"sum\")\r\nnet = tf.concat([embedding, continuous_feature_tensor], 1, name='concat')\r\ndim = net.get_shape().as_list()[1]\r\nweight = tf.Variable(tf.truncated_normal([dim, 100], stddev=0.05), name='fully_weight')\r\nbias = tf.Variable(tf.truncated_normal([100], stddev=0.05), name='fully_bias')\r\nnet = tf.matmul(net, weight) + bias\r\ncross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=net, labels=label_tensor, name='cross_entropy')\r\n```\r\n\r\nIn C++, all solutions I have found is to feed `vector<pair<string, Tensor>>` into `session.Run()`. However, in my model, I don't know which function in C++ I should use. \r\n\r\nThanks.\r\n\r\n@martinwicke ", "comments": ["This seems similar to #12264. /CC @skye ", "@formath hi,how do you use spasetensor in c++ at last", "> @formath hi,how do you use spasetensor in c++ at last\r\n\r\nsparseTensor is composed by three tensors: indice, value, shape. I feed those tensors", "which c++ interface do you use to feed sparseTensor?", "> which c++ interface do you use to feed sparseTensor?\r\n\r\nwhen i save model i use placeholder,and use tfserving for predict.In the client,I use the tfserving grpc c++ client,the predictRequest's inputs is map of <string,tensorproto>", "@formath Do you mind to share the code for running such model in C++? The `Session::Run()` function accepts a vector of <string, Tensor> pairs, but I don't know how to create a Tensor object for sparseTensor ([SparseTensor](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/util/sparse/sparse_tensor.h) is not a subclass of Tensor...)", "@GuanLuo  https://mathmach.com/6d246b32/ and https://mathmach.com/f42d3a88/ show examples of `Session::Run(tensors)` and `SparseTensor` usage."]}, {"number": 13682, "title": "can any one reproduce this problew with tf.gather?", "body": "x = tf.constant([[0.22, 0.3,0.1,0.11],[0.4,0.5, 0.6,0.99],[0.8, 0.9,0.43,0.21]])\r\nindices = tf.constant([[1,2],[0,1],[2,3]])\r\nb=tf.gather_nd(x, indices\uff09\r\nsess = tf.InteractiveSession()\r\ncc=sess.run([b], feed_dict={})\r\nprint cc\r\n\r\nwith tensorflow 1.0.1 it gets [array([ 0., 0., 0.], dtype=float32)]\r\nis it a bug in 1.0.1, but with higher version,it gets right", "comments": ["Thanks for the report. But as you reported, this issue seems to be resolved with newer TF versions.\r\nAs 1.0 is now older than 7 months, we will not patch the release to fix this bug in 1.0.\r\n\r\nThank you very much for your report, and please let us know if you see this error in1.4 release"]}, {"number": 13681, "title": "type error in tensorflow document API r1.3 ( tf.truncatediv )", "body": "Cause this issue is not about tensorflow itself, please, excuse my ignoring some conventions. Plus, as you know, the postage can cost more than the goods once I try to contribute to documentation via committing so as to correct a tiny error. Please, let me use this channel to comment.\r\n\r\n\"\"\"problematic document\r\nTruncation designates that negative numbers will round fractional quantities toward zero. **I.e. -7 / 5 = 1**. This matches C semantics but it is different than Python semantics. See FloorDiv for a division function that matches Python Semantics.\r\n\"\"\" \r\n**I.e. -7 / 5 = 1** should be **I.e -7 / 5 = -1**\r\n\r\n\r\n\r\n", "comments": ["Nice catch! The documentation is generated from [math_ops.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/math_ops.cc#L626). You should submit a pull request to fix the issue. We appreciate minor fixes, so do not worry about wasting our time with documentation fixes.", "I've just requested a pull. Thank you.", "Fixed with #13712"]}, {"number": 13680, "title": "Feature request: Profiling with multiple workers in distributed settings and visualizing them individually", "body": "Hi,\r\nI am running Tensorflow in distributed settings only using CPUs with multiple workers and parameter servers. I would like to find a way to generate timeline information of individual workers/parameter servers and visualize them together to check on potential scaling issues. \r\nCurrently, I can generate timeline traces containing the profiles of all the parameter servers and a single worker.  But, visualizing all the workers in the same timeline trace would be beneficial. \r\n\r\nThank you.", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 13679, "title": "Branch 172057283", "body": "", "comments": ["Cbuild is failing, and it also reflects the same result here in the pull request tests.\r\nWill abandon this push and start a new one tomorrow."]}, {"number": 13678, "title": "Merge pull request #1 from tensorflow/master", "body": "Updated on 2017/10/13", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->"]}, {"number": 13677, "title": "Branch 172045110", "body": "", "comments": ["@tensorflow-jenkins test this please"]}, {"number": 13676, "title": "Fix cuDNN version string in CUDA9 cuDNN7 docker image.", "body": "", "comments": []}, {"number": 13675, "title": "Import Error on Windows 10: No module named '_pywrap_tensorflow_internal'", "body": "**System information**\r\nOS: Windows 10 64\r\nTensorflow version 1.3 GPU version\r\nPython 3.5.4\r\nCUDA 8.0 -> cudart64_80.dll\r\nCUDNN 6.0 -> cudnn64_6.dll\r\nGPU: GeForce GTX 1070\r\n\r\n**Installation Process & Issue:**\r\nI followed the guide provided on https://www.tensorflow.org/install/install_windows for the installation via Anaconda. The installation seems to be successful, but upon running the following command in the console:\r\n\r\n>>> import tensorflow as tf\r\n\r\nI am getting the following error:\r\n\r\n#BEGIN ERROR MESSAGE\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Eric\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\Eric\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 985, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 968, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 957, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 938, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Eric\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Eric\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Eric\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 23, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\Eric\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\Eric\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Users\\Eric\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Eric\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 52, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Eric\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\Eric\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 985, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 968, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 957, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 938, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Eric\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Eric\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Eric\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 23, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\Eric\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\n#END ERROR MESSAGE\r\n\r\n**Attempted Fixes:**\r\nEnsuring that cudart64_80.dll and cudnn64_6.dll locations are appended into %PATH%.\r\nAppending .DLL to %PATHEXT%.\r\nEnsuring that the following dependencies are available and their location in %PATH%. This list is sourced from user mrry's reply in https://github.com/tensorflow/tensorflow/issues/5949.\r\nKERNEL32.dll\r\nWSOCK32.dll\r\nWS2_32.dll\r\nSHLWAPI.dll\r\npython35.dll\r\nMSVCP140.dll\r\nVCRUNTIME140.dll\r\napi-ms-win-crt-runtime-l1-1-0.dll\r\napi-ms-win-crt-heap-l1-1-0.dll\r\napi-ms-win-crt-utility-l1-1-0.dll\r\napi-ms-win-crt-stdio-l1-1-0.dll\r\napi-ms-win-crt-string-l1-1-0.dll\r\napi-ms-win-crt-math-l1-1-0.dll\r\napi-ms-win-crt-convert-l1-1-0.dll\r\napi-ms-win-crt-environment-l1-1-0.dll\r\napi-ms-win-crt-filesystem-l1-1-0.dll\r\napi-ms-win-crt-time-l1-1-0.dll\r\n\r\nAny help would be greatly appreciated!\r\n", "comments": ["Try following the advice given in https://github.com/tensorflow/tensorflow/issues/9469 and https://stackoverflow.com/questions/43577923/cannot-import-tensorflow-for-gpu-on-windows-10 and https://github.com/tensorflow/tensorflow/issues/11571.", "Below are my results from reviewing/following the advice of the links:\r\n\r\nhttps://stackoverflow.com/questions/43577923/cannot-import-tensorflow-for-gpu-on-windows-10\r\nRecommended changing CUDNN filename from cudnn64_6.dll to cudnn64_5.dll. Same error occurs.\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/9469 OP said the issue was caused by his visual studio and his intel graphics card. My MSVCP140.dll location is in %PATH% so I doubt it is the first cause. I also have intel integrated graphics, but I am not sure how this will impact my issue. It would seem to me that the issue is regarding dependency and I am not sure how disabling integrated graphics on boot will resolve this. If anyone has knowledge otherwise please let me know!\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/11571 OP resolved issue by adding location of Visual Studio directories into %PATH% and reinstalling tensorflow. All the dll files that I have listed above already have their location in %PATH%. Unless there is a dependency that is not provided on download and not listed above, then their locations are all in my %PATH%. Not too sure about the reinstalling part. Would that be necessary? I am not sure how logically it will resolve the issue.\r\n\r\nI have also downloaded and ran mrry's debugger. It seems to be able to find all my DLLs. Output below: \r\n\r\nERROR: Failed to import the TensorFlow module.\r\n\r\n- Python version is 3.5.\r\n\r\n- TensorFlow is installed at: C:\\Users\\Eric\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\r\n\r\n- All required DLLs appear to be present. Please open an issue on the\r\n  TensorFlow GitHub page: https://github.com/tensorflow/tensorflow/issues\r\n\r\nEDITS: Reworded some sentences so its more readable.", "Look like the TensorFlow has stated using cuDNN 6.x in the past couple of days (from 5.1).\r\n(cuDNN=NVIDIA CUDA Deep Neural Network library )\r\nhttps://www.tensorflow.org/install/install_windows#CommonInstallationProblems\r\nThe problem on my computer got solved after I upgrading cuDNN 6.x (TF will not work with cuDNN 7 yet)\r\nhttps://developer.nvidia.com/cudnn\r\n\r\nMy configuration is\r\nWindows 10 x64, with GPU GTX 1080 ti\r\nAnaconda 5.0.0 (with Python 3.6)\r\nCUDA Toolkit 8.0\r\ncuDNN v6.0\r\n", "I have somewhat the same issue\r\nI also run win 10 64-bit\r\npython 3.6.2\r\nmost recent tensorflow (so I assume 1.3?)\r\nbut in the cpu-only version\r\n\r\nI installed tensorflow using pip, not anaconda though\r\n\r\n#My Console Output#\r\n\r\nPython 3.6.2 (v3.6.2:5fd33b5, Jul  8 2017, 04:57:36) [MSC v.1900 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n\\>\\>\\> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\user_name\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_inte\r\nrnal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\user_name\\AppData\\Local\\Programs\\Python\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 978, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 961, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 950, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 648, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 560, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 205, in _call_with_frames_removed\r\nImportError: DLL load failed: Das angegebene Modul wurde nicht gefunden.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\user_name\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\",\r\n line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\user_name\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_inte\r\nrnal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\user_name\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_inte\r\nrnal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\user_name\\AppData\\Local\\Programs\\Python\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\user_name\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <mo\r\ndule>\r\n    from tensorflow.python import *\r\n  File \"C:\\Users\\user_name\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49,\r\n in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\user_name\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\",\r\n line 52, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\user_name\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_inte\r\nrnal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\user_name\\AppData\\Local\\Programs\\Python\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 978, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 961, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 950, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 648, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 560, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 205, in _call_with_frames_removed\r\nImportError: DLL load failed: Das angegebene Modul wurde nicht gefunden.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\user_name\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\",\r\n line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\user_name\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_inte\r\nrnal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\user_name\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_inte\r\nrnal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\user_name\\AppData\\Local\\Programs\\Python\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\\>\\>\\>", "@BotLivesMatter Can you please try running Dependency Walker on `C:\\Users\\Eric\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\_pywrap_tensorflow_internal.pyd` and let us know if it detects any missing DLLs?\r\n\r\n@Saltzmann Since you are running the CPU version, the most likely problem is a missing `MSVCP140.DLL`. You can install it from https://www.microsoft.com/en-us/download/details.aspx?id=48145", "Running Dependency Walker outputs the following list of files with the message \"Error opening file. The system cannot find the file specified(2).\"\r\n\r\nAPI-MS-WIN-CORE-APIQUERY-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-APPCOMPAT-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-APPINIT-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-ATOMS-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-COMM-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-CONSOLE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-CONSOLE-L2-1-0.DLL\r\nAPI-MS-WIN-CORE-CONSOLE-L3-1-0.DLL\r\nAPI-MS-WIN-CORE-CRT-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-CRT-L2-1-0.DLL\r\nAPI-MS-WIN-CORE-DATETIME-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-DATETIME-L1-1-2.DLL\r\nAPI-MS-WIN-CORE-DEBUG-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-DELAYLOAD-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-ENCLAVE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-ERRORHANDLING-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-ERRORHANDLING-L1-1-3.DLL\r\nAPI-MS-WIN-CORE-FIBERS-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-FIBERS-L2-1-1.DLL\r\nAPI-MS-WIN-CORE-FILE-L1-2-1.DLL\r\nAPI-MS-WIN-CORE-FILE-L1-2-2.DLL\r\nAPI-MS-WIN-CORE-FILE-L2-1-1.DLL\r\nAPI-MS-WIN-CORE-FILE-L2-1-2.DLL\r\nAPI-MS-WIN-CORE-HANDLE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-HEAP-L1-2-0.DLL\r\nAPI-MS-WIN-CORE-HEAP-L2-1-0.DLL\r\nAPI-MS-WIN-CORE-HEAP-OBSOLETE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-INTERLOCKED-L1-2-0.DLL\r\nAPI-MS-WIN-CORE-IO-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-JOB-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-JOB-L2-1-0.DLL\r\nAPI-MS-WIN-CORE-KERNEL32-LEGACY-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-KERNEL32-LEGACY-L1-1-5.DLL\r\nAPI-MS-WIN-CORE-KERNEL32-PRIVATE-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-KERNEL32-PRIVATE-L1-1-2.DLL\r\nAPI-MS-WIN-CORE-LARGEINTEGER-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-LIBRARYLOADER-L1-2-0.DLL\r\nAPI-MS-WIN-CORE-LIBRARYLOADER-L1-2-2.DLL\r\nAPI-MS-WIN-CORE-LIBRARYLOADER-L2-1-0.DLL\r\nAPI-MS-WIN-CORE-LOCALIZATION-L1-2-1.DLL\r\nAPI-MS-WIN-CORE-LOCALIZATION-L1-2-2.DLL\r\nAPI-MS-WIN-CORE-LOCALIZATION-L2-1-0.DLL\r\nAPI-MS-WIN-CORE-LOCALIZATION-OBSOLETE-L1-3-0.DLL\r\nAPI-MS-WIN-CORE-LOCALIZATION-PRIVATE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-MEMORY-L1-1-2.DLL\r\nAPI-MS-WIN-CORE-MEMORY-L1-1-5.DLL\r\nAPI-MS-WIN-CORE-MISC-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-NAMEDPIPE-L1-2-0.DLL\r\nAPI-MS-WIN-CORE-NAMEDPIPE-L1-2-2.DLL\r\nAPI-MS-WIN-CORE-NAMESPACE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-NORMALIZATION-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-PATH-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-PERFCOUNTERS-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-PRIVATEPROFILE-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-PROCESSENVIRONMENT-L1-2-0.DLL\r\nAPI-MS-WIN-CORE-PROCESSSNAPSHOT-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-PROCESSTHREADS-L1-1-2.DLL\r\nAPI-MS-WIN-CORE-PROCESSTHREADS-L1-1-3.DLL\r\nAPI-MS-WIN-CORE-PROCESSTOPOLOGY-L1-2-0.DLL\r\nAPI-MS-WIN-CORE-PROFILE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-PSAPI-ANSI-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-PSAPI-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-QUIRKS-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-REALTIME-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-REGISTRY-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-REGISTRY-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-REGISTRYUSERSPECIFIC-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-RTLSUPPORT-L1-2-0.DLL\r\nAPI-MS-WIN-CORE-SHLWAPI-LEGACY-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-SHLWAPI-OBSOLETE-L1-2-0.DLL\r\nAPI-MS-WIN-CORE-SIDEBYSIDE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-STRING-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-STRING-L2-1-0.DLL\r\nAPI-MS-WIN-CORE-STRING-L2-1-1.DLL\r\nAPI-MS-WIN-CORE-STRING-OBSOLETE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-STRINGANSI-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-SYNCH-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-SYNCH-L1-2-0.DLL\r\nAPI-MS-WIN-CORE-SYNCH-L1-2-1.DLL\r\nAPI-MS-WIN-CORE-SYSINFO-L1-2-1.DLL\r\nAPI-MS-WIN-CORE-SYSINFO-L1-2-3.DLL\r\nAPI-MS-WIN-CORE-SYSTEMTOPOLOGY-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-SYSTEMTOPOLOGY-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-THREADPOOL-L1-2-0.DLL\r\nAPI-MS-WIN-CORE-THREADPOOL-LEGACY-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-THREADPOOL-PRIVATE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-TIMEZONE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-URL-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-UTIL-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-VERSION-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-VERSION-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-VERSION-PRIVATE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-VERSIONANSI-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-VERSIONANSI-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-WINDOWSERRORREPORTING-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-WINDOWSERRORREPORTING-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-WINRT-ERROR-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-WOW64-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-WOW64-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-XSTATE-L2-1-0.DLL\r\nAPI-MS-WIN-CRT-CONVERT-L1-1-0.DLL\r\nAPI-MS-WIN-CRT-ENVIRONMENT-L1-1-0.DLL\r\nAPI-MS-WIN-CRT-FILESYSTEM-L1-1-0.DLL\r\nAPI-MS-WIN-CRT-HEAP-L1-1-0.DLL\r\nAPI-MS-WIN-CRT-LOCALE-L1-1-0.DLL\r\nAPI-MS-WIN-CRT-MATH-L1-1-0.DLL\r\nAPI-MS-WIN-CRT-MULTIBYTE-L1-1-0.DLL\r\nAPI-MS-WIN-CRT-PRIVATE-L1-1-0.DLL\r\nAPI-MS-WIN-CRT-RUNTIME-L1-1-0.DLL\r\nAPI-MS-WIN-CRT-STDIO-L1-1-0.DLL\r\nAPI-MS-WIN-CRT-STRING-L1-1-0.DLL\r\nAPI-MS-WIN-CRT-TIME-L1-1-0.DLL\r\nAPI-MS-WIN-CRT-UTILITY-L1-1-0.DLL\r\nAPI-MS-WIN-DEVICES-CONFIG-L1-1-1.DLL\r\nAPI-MS-WIN-EVENTING-CLASSICPROVIDER-L1-1-0.DLL\r\nAPI-MS-WIN-EVENTING-CONSUMER-L1-1-0.DLL\r\nAPI-MS-WIN-EVENTING-CONTROLLER-L1-1-0.DLL\r\nAPI-MS-WIN-EVENTING-OBSOLETE-L1-1-0.DLL\r\nAPI-MS-WIN-EVENTING-PROVIDER-L1-1-0.DLL\r\nAPI-MS-WIN-GDI-INTERNAL-UAP-L1-1-0.DLL\r\nAPI-MS-WIN-SECURITY-APPCONTAINER-L1-1-0.DLL\r\nAPI-MS-WIN-SECURITY-AUDIT-L1-1-1.DLL\r\nAPI-MS-WIN-SECURITY-BASE-L1-2-0.DLL\r\nAPI-MS-WIN-SECURITY-BASE-PRIVATE-L1-1-1.DLL\r\nAPI-MS-WIN-SECURITY-CAPABILITY-L1-1-0.DLL\r\nAPI-MS-WIN-SERVICE-CORE-L1-1-1.DLL\r\nAPI-MS-WIN-SERVICE-CORE-L1-1-2.DLL\r\nAPI-MS-WIN-SERVICE-MANAGEMENT-L1-1-0.DLL\r\nAPI-MS-WIN-SERVICE-MANAGEMENT-L2-1-0.DLL\r\nAPI-MS-WIN-SERVICE-PRIVATE-L1-1-0\r\nAPI-MS-WIN-SERVICE-PRIVATE-L1-1-1.DLL\r\nAPI-MS-WIN-SERVICE-PRIVATE-L1-1-3.DLL\r\nAPI-MS-WIN-SERVICE-WINSVC-L1-2-0.DLL\r\nAPI-MS-WIN-SHCORE-PATH-L1-1-0.DLL\r\nAPI-MS-WIN-SHELL-SHELLCOM-L1-1-0.DLL\r\nAPI-MS-WIN-SHELL-SHELLFOLDERS-L1-1-0.DLL\r\nAPI-MS-WIN-STORAGE-EXPORTS-EXTERNAL-L1-1-0.DLL\r\nAPI-MS-WIN-STORAGE-EXPORTS-INTERNAL-L1-1-0.DLL\r\nCUBLAS64_80.DLL\r\nCUDNN64_6.DLL\r\nCUFFT64_80.DLL\r\nCURAND64_80.DLL\r\nCUSOLVER64_80.DLL\r\nPYTHON35.DLL\r\nAPI-MS-ONECOREUAP-SETTINGSYNC-STATUS-L1-1-0.DLL\r\nAPI-MS-WIN-APPMODEL-IDENTITY-L1-2-0.DLL\r\nAPI-MS-WIN-APPMODEL-RUNTIME-INTERNAL-L1-1-0.DLL\r\nAPI-MS-WIN-APPMODEL-RUNTIME-INTERNAL-L1-1-4.DLL\r\nAPI-MS-WIN-APPMODEL-RUNTIME-L1-1-0.DLL\r\nAPI-MS-WIN-APPMODEL-RUNTIME-L1-1-1.DLL\r\nAPI-MS-WIN-APPMODEL-RUNTIME-L1-1-2.DLL\r\nAPI-MS-WIN-APPMODEL-STATE-L1-2-0.DLL\r\nAPI-MS-WIN-APPMODEL-UNLOCK-L1-1-0.DLL\r\nAPI-MS-WIN-BASE-UTIL-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-CALENDAR-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-COM-L1-1-0\r\nAPI-MS-WIN-CORE-COM-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-COM-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-COM-L1-1-2.DLL\r\nAPI-MS-WIN-CORE-COM-L2-1-1.DLL\r\nAPI-MS-WIN-CORE-COM-MIDLPROXYSTUB-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-COM-PRIVATE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-COM-PRIVATE-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-DATETIME-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-DEBUG-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-DELAYLOAD-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-ERRORHANDLING-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-FILE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-FILE-L1-2-0.DLL\r\nAPI-MS-WIN-CORE-FILE-L2-1-0.DLL\r\nAPI-MS-WIN-CORE-FIRMWARE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-HEAP-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-INTERLOCKED-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-IO-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-KERNEL32-LEGACY-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-LIBRARYLOADER-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-LOCALIZATION-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-LOCALIZATION-L1-2-0.DLL\r\nAPI-MS-WIN-CORE-LOCALIZATION-OBSOLETE-L1-2-0.DLL\r\nAPI-MS-WIN-CORE-LOCALREGISTRY-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-MARSHAL-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-MEMORY-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-MEMORY-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-PRIVATEPROFILE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-PROCESSENVIRONMENT-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-PROCESSTHREADS-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-PROCESSTHREADS-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-PROCESSTOPOLOGY-OBSOLETE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-PSM-APP-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-PSM-APPNOTIFY-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-PSM-KEY-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-REALTIME-L1-1-2.DLL\r\nAPI-MS-WIN-CORE-REGISTRY-L2-2-0.DLL\r\nAPI-MS-WIN-CORE-REGISTRY-PRIVATE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-RTLSUPPORT-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-SHLWAPI-OBSOLETE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-SHUTDOWN-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-SYSINFO-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-SYSINFO-L1-2-0.DLL\r\nAPI-MS-WIN-CORE-TOOLHELP-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-WINRT-ERRORPRIVATE-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-WINRT-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-WINRT-PROPERTYSETPRIVATE-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-WINRT-PROPERTYSETPRIVATE-L1-1-1.DLL\r\nAPI-MS-WIN-CORE-WINRT-REGISTRATION-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-WINRT-ROBUFFER-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-WINRT-STRING-L1-1-0.DLL\r\nAPI-MS-WIN-CORE-WINRT-STRING-L1-1-1.DLL\r\nAPI-MS-WIN-COREUI-SECRUNTIME-L1-1-0.DLL\r\nAPI-MS-WIN-CRT-PROCESS-L1-1-0.DLL\r\nAPI-MS-WIN-DEVICES-QUERY-L1-1-1.DLL\r\nAPI-MS-WIN-DOWNLEVEL-ADVAPI32-L1-1-0.DLL\r\nAPI-MS-WIN-DOWNLEVEL-ADVAPI32-L2-1-0.DLL\r\nAPI-MS-WIN-DOWNLEVEL-KERNEL32-L2-1-0.DLL\r\nAPI-MS-WIN-DOWNLEVEL-NORMALIZ-L1-1-0.DLL\r\nAPI-MS-WIN-DOWNLEVEL-OLE32-L1-1-0.DLL\r\nAPI-MS-WIN-DOWNLEVEL-SHELL32-L1-1-0.DLL\r\nAPI-MS-WIN-DOWNLEVEL-SHLWAPI-L1-1-0.DLL\r\nAPI-MS-WIN-DOWNLEVEL-SHLWAPI-L2-1-0.DLL\r\nAPI-MS-WIN-DOWNLEVEL-USER32-L1-1-0.DLL\r\nAPI-MS-WIN-DOWNLEVEL-VERSION-L1-1-0.DLL\r\nAPI-MS-WIN-DWMAPI-L1-1-0.DLL\r\nAPI-MS-WIN-DX-D3DKMT-L1-1-0.DLL\r\nAPI-MS-WIN-DX-D3DKMT-L1-1-3.DLL\r\nAPI-MS-WIN-EVENTING-LEGACY-L1-1-0.DLL\r\nAPI-MS-WIN-EVENTING-TDH-L1-1-0.DLL\r\nAPI-MS-WIN-EVENTLOG-LEGACY-L1-1-0.DLL\r\nAPI-MS-WIN-GDI-DPIINFO-L1-1-0.DLL\r\nAPI-MS-WIN-HTTP-TIME-L1-1-0.DLL\r\nAPI-MS-WIN-MM-JOYSTICK-L1-1-0.DLL\r\nAPI-MS-WIN-MM-MISC-L1-1-1.DLL\r\nAPI-MS-WIN-MM-MISC-L2-1-0.DLL\r\nAPI-MS-WIN-MM-MME-L1-1-0.DLL\r\nAPI-MS-WIN-MM-TIME-L1-1-0.DLL\r\nAPI-MS-WIN-NETWORKING-INTERFACECONTEXTS-L1-1-0.DLL\r\nAPI-MS-WIN-NTUSER-RECTANGLE-L1-1-0.DLL\r\nAPI-MS-WIN-NTUSER-SYSPARAMS-L1-1-0.DLL\r\nAPI-MS-WIN-OLE32-IE-L1-1-0.DLL\r\nAPI-MS-WIN-OOBE-NOTIFICATION-L1-1-0.DLL\r\nAPI-MS-WIN-POWER-BASE-L1-1-0.DLL\r\nAPI-MS-WIN-POWER-SETTING-L1-1-0.DLL\r\nAPI-MS-WIN-RO-TYPERESOLUTION-L1-1-0.DLL\r\nAPI-MS-WIN-RTCORE-NTUSER-CLIPBOARD-L1-1-0.DLL\r\nAPI-MS-WIN-RTCORE-NTUSER-PRIVATE-L1-1-0.DLL\r\nAPI-MS-WIN-RTCORE-NTUSER-PRIVATE-L1-1-5.DLL\r\nAPI-MS-WIN-RTCORE-NTUSER-SHELL-L1-1-0.DLL\r\nAPI-MS-WIN-RTCORE-NTUSER-SYNCH-L1-1-0.DLL\r\nAPI-MS-WIN-RTCORE-NTUSER-WINDOW-L1-1-0.DLL\r\nAPI-MS-WIN-RTCORE-NTUSER-WINEVENT-L1-1-0.DLL\r\nAPI-MS-WIN-SECURITY-ACCESSHLPR-L1-1-0.DLL\r\nAPI-MS-WIN-SECURITY-ACTIVEDIRECTORYCLIENT-L1-1-0.DLL\r\nAPI-MS-WIN-SECURITY-ACTIVEDIRECTORYCLIENT-L1-1-1.DLL\r\nAPI-MS-WIN-SECURITY-BASE-L1-1-0.DLL\r\nAPI-MS-WIN-SECURITY-CREDENTIALS-L1-1-0.DLL\r\nAPI-MS-WIN-SECURITY-CREDENTIALS-L2-1-0.DLL\r\nAPI-MS-WIN-SECURITY-CRYPTOAPI-L1-1-0.DLL\r\nAPI-MS-WIN-SECURITY-GROUPPOLICY-L1-1-0.DLL\r\nAPI-MS-WIN-SECURITY-LSALOOKUP-ANSI-L2-1-0.DLL\r\nAPI-MS-WIN-SECURITY-LSALOOKUP-L1-1-1.DLL\r\nAPI-MS-WIN-SECURITY-LSALOOKUP-L1-1-2.DLL\r\nAPI-MS-WIN-SECURITY-LSALOOKUP-L2-1-1.DLL\r\nAPI-MS-WIN-SECURITY-LSAPOLICY-L1-1-0.DLL\r\nAPI-MS-WIN-SECURITY-PROVIDER-L1-1-0.DLL\r\nAPI-MS-WIN-SECURITY-SDDL-L1-1-0.DLL\r\nAPI-MS-WIN-SECURITY-SDDLPARSECOND-L1-1-0.DLL\r\nAPI-MS-WIN-SECURITY-SYSTEMFUNCTIONS-L1-1-0.DLL\r\nAPI-MS-WIN-SERVICE-WINSVC-L1-1-0.DLL\r\nAPI-MS-WIN-SHCORE-COMHELPERS-L1-1-0.DLL\r\nAPI-MS-WIN-SHCORE-OBSOLETE-L1-1-0.DLL\r\nAPI-MS-WIN-SHCORE-REGISTRY-L1-1-1.DLL\r\nAPI-MS-WIN-SHCORE-SCALING-L1-1-1.DLL\r\nAPI-MS-WIN-SHCORE-STREAM-L1-1-0.DLL\r\nAPI-MS-WIN-SHCORE-STREAM-WINRT-L1-1-0.DLL\r\nAPI-MS-WIN-SHCORE-SYSINFO-L1-1-0.DLL\r\nAPI-MS-WIN-SHCORE-THREAD-L1-1-0.DLL\r\nAPI-MS-WIN-SHCORE-UNICODEANSI-L1-1-0.DLL\r\nAPI-MS-WIN-SHELL-CHANGENOTIFY-L1-1-0.DLL\r\nAPI-MS-WIN-SHELL-NAMESPACE-L1-1-0.DLL\r\nAPI-MS-WIN-SHELL-SHDIRECTORY-L1-1-0.DLL\r\nAPI-MS-WIN-SHLWAPI-IE-L1-1-0.DLL\r\nAPI-MS-WIN-SHLWAPI-WINRT-STORAGE-L1-1-1.DLL\r\nDEVICELOCKHELPERS.DLL\r\nEMCLIENT.DLL\r\nEXT-MS-MF-PAL-L2-1-0.DLL\r\nEXT-MS-ONECORE-APPCHROMEAPI-L1-1-0.DLL\r\nEXT-MS-ONECORE-APPDEFAULTS-L1-1-0.DLL\r\nEXT-MS-ONECORE-APPMODEL-EMCLIENT-L1-1-0.DLL\r\nEXT-MS-ONECORE-APPMODEL-STATEREPOSITORY-INTERNAL-L1-1-1.DLL\r\nEXT-MS-ONECORE-DCOMP-L1-1-0.DLL\r\nEXT-MS-ONECORE-HLINK-L1-1-0.DLL\r\nEXT-MS-ONECORE-ORIENTATION-L1-1-0.DLL\r\nEXT-MS-ONECORE-PHONEINFO-L1-1-0.DLL\r\nEXT-MS-ONECORE-SHELLCHROMEAPI-L1-1-2.DLL\r\nEXT-MS-WIN-ADVAPI32-MSI-L1-1-0.DLL\r\nEXT-MS-WIN-ADVAPI32-NPUSERNAME-L1-1-0.DLL\r\nEXT-MS-WIN-ADVAPI32-NTMARTA-L1-1-0.DLL\r\nEXT-MS-WIN-ADVAPI32-PSM-APP-L1-1-0.DLL\r\nEXT-MS-WIN-ADVAPI32-REGISTRY-L1-1-0.DLL\r\nEXT-MS-WIN-ADVAPI32-SAFER-L1-1-0.DLL\r\nEXT-MS-WIN-APPCOMPAT-AEPIC-L1-1-0.DLL\r\nEXT-MS-WIN-APPCOMPAT-APPHELP-L1-1-0.DLL\r\nEXT-MS-WIN-APPMODEL-DAXCORE-L1-1-1.DLL\r\nEXT-MS-WIN-APPMODEL-DEPLOYMENT-L1-1-1.DLL\r\nEXT-MS-WIN-APPMODEL-RESTRICTEDAPPCONTAINER-INTERNAL-L1-1-0.DLL\r\nEXT-MS-WIN-APPMODEL-STATE-EXT-L1-2-0.DLL\r\nEXT-MS-WIN-APPMODEL-USERCONTEXT-L1-1-0.DLL\r\nEXT-MS-WIN-APPMODEL-VIEWSCALEFACTOR-L1-1-0.DLL\r\nEXT-MS-WIN-APPXDEPLOYMENTCLIENT-APPXDEPLOY-L1-1-0.DLL\r\nEXT-MS-WIN-APPXDEPLOYMENTCLIENT-APPXDEPLOYONECORE-L1-1-0.DLL\r\nEXT-MS-WIN-AUDIOCORE-PAL-L1-2-0.DLL\r\nEXT-MS-WIN-AUTHZ-CONTEXT-L1-1-0.DLL\r\nEXT-MS-WIN-AUTHZ-REMOTE-L1-1-0.DLL\r\nEXT-MS-WIN-COM-CLBCATQ-L1-1-0.DLL\r\nEXT-MS-WIN-COM-COML2-L1-1-1.DLL\r\nEXT-MS-WIN-COM-OLE32-L1-1-1.DLL\r\nEXT-MS-WIN-COM-OLE32-L1-1-5.DLL\r\nEXT-MS-WIN-COM-PSMREGISTER-L1-2-2.DLL\r\nEXT-MS-WIN-COM-SUSPENDRESILIENCY-L1-1-0.DLL\r\nEXT-MS-WIN-CORE-IURI-L1-1-0.DLL\r\nEXT-MS-WIN-CORE-WINRT-REMOTE-L1-1-0.DLL\r\nEXT-MS-WIN-DESKTOPAPPX-L1-1-1.DLL\r\nEXT-MS-WIN-DEVMGMT-DM-L1-1-1.DLL\r\nEXT-MS-WIN-DEVMGMT-POLICY-L1-1-1.DLL\r\nEXT-MS-WIN-DIRECT2D-DESKTOP-L1-1-0.DLL\r\nEXT-MS-WIN-DOMAINJOIN-NETJOIN-L1-1-0.DLL\r\nEXT-MS-WIN-DWMAPI-EXT-L1-1-0.DLL\r\nEXT-MS-WIN-DWMAPIDXGI-EXT-L1-1-0.DLL\r\nEXT-MS-WIN-EDPUTIL-POLICY-L1-1-1.DLL\r\nEXT-MS-WIN-ELS-ELSCORE-L1-1-0.DLL\r\nEXT-MS-WIN-EVENTING-RUNDOWN-L1-1-0.DLL\r\nEXT-MS-WIN-FAMILYSAFETY-CHILDACCOUNT-L1-1-0.DLL\r\nEXT-MS-WIN-FECLIENT-ENCRYPTEDFILE-L1-1-0.DLL\r\nEXT-MS-WIN-FECLIENT-ENCRYPTEDFILE-L1-1-1.DLL\r\nEXT-MS-WIN-FIREWALLAPI-WEBPROXY-L1-1-0.DLL\r\nEXT-MS-WIN-GDI-CLIPPING-L1-1-0.DLL\r\nEXT-MS-WIN-GDI-DC-CREATE-L1-1-1.DLL\r\nEXT-MS-WIN-GDI-DC-L1-2-0.DLL\r\nEXT-MS-WIN-GDI-DC-L1-2-1.DLL\r\nEXT-MS-WIN-GDI-DEVCAPS-L1-1-0.DLL\r\nEXT-MS-WIN-GDI-DRAW-L1-1-1.DLL\r\nEXT-MS-WIN-GDI-DRAW-L1-1-3.DLL\r\nEXT-MS-WIN-GDI-FONT-L1-1-1.DLL\r\nEXT-MS-WIN-GDI-FONT-L1-1-3.DLL\r\nEXT-MS-WIN-GDI-GDIPLUS-L1-1-0.DLL\r\nEXT-MS-WIN-GDI-INTERNAL-DESKTOP-L1-1-1.DLL\r\nEXT-MS-WIN-GDI-METAFILE-L1-1-1.DLL\r\nEXT-MS-WIN-GDI-METAFILE-L1-1-2.DLL\r\nEXT-MS-WIN-GDI-PATH-L1-1-0.DLL\r\nEXT-MS-WIN-GDI-PRINT-L1-1-0.DLL\r\nEXT-MS-WIN-GDI-PRIVATE-L1-1-0.DLL\r\nEXT-MS-WIN-GDI-RENDER-L1-1-0.DLL\r\nEXT-MS-WIN-GDI-WCS-L1-1-0.DLL\r\nEXT-MS-WIN-GPAPI-GROUPPOLICY-L1-1-0.DLL\r\nEXT-MS-WIN-GUI-DUI70-L1-1-0.DLL\r\nEXT-MS-WIN-IMM-L1-1-1.DLL\r\nEXT-MS-WIN-KERNEL32-APPCOMPAT-L1-1-0.DLL\r\nEXT-MS-WIN-KERNEL32-DATETIME-L1-1-0.DLL\r\nEXT-MS-WIN-KERNEL32-ERRORHANDLING-L1-1-0.DLL\r\nEXT-MS-WIN-KERNEL32-FILE-L1-1-0.DLL\r\nEXT-MS-WIN-KERNEL32-LOCALIZATION-L1-1-0.DLL\r\nEXT-MS-WIN-KERNEL32-PACKAGE-CURRENT-L1-1-0.DLL\r\nEXT-MS-WIN-KERNEL32-PACKAGE-L1-1-1.DLL\r\nEXT-MS-WIN-KERNEL32-QUIRKS-L1-1-0.DLL\r\nEXT-MS-WIN-KERNEL32-QUIRKS-L1-1-1.DLL\r\nEXT-MS-WIN-KERNEL32-REGISTRY-L1-1-0.DLL\r\nEXT-MS-WIN-KERNEL32-SIDEBYSIDE-L1-1-0.DLL\r\nEXT-MS-WIN-KERNELBASE-PROCESSTHREAD-L1-1-0.DLL\r\nEXT-MS-WIN-MININPUT-INPUTHOST-L1-1-0.DLL\r\nEXT-MS-WIN-MPR-MULTIPLEPROVIDERROUTER-L1-1-0.DLL\r\nEXT-MS-WIN-MRMCORER-ENVIRONMENT-L1-1-0.DLL\r\nEXT-MS-WIN-MRMCORER-RESMANAGER-L1-1-0.DLL\r\nEXT-MS-WIN-NETWORKING-WLANSTORAGE-L1-1-0.DLL\r\nEXT-MS-WIN-NTDSAPI-ACTIVEDIRECTORYCLIENT-L1-1-0.DLL\r\nEXT-MS-WIN-NTDSAPI-ACTIVEDIRECTORYCLIENT-L1-1-1.DLL\r\nEXT-MS-WIN-NTUSER-DC-ACCESS-EXT-L1-1-0.DLL\r\nEXT-MS-WIN-NTUSER-DIALOGBOX-L1-1-1.DLL\r\nEXT-MS-WIN-NTUSER-DRAW-L1-1-1.DLL\r\nEXT-MS-WIN-NTUSER-DRAW-L1-1-2.DLL\r\nEXT-MS-WIN-NTUSER-GUI-L1-3-1.DLL\r\nEXT-MS-WIN-NTUSER-KEYBOARD-L1-3-0.DLL\r\nEXT-MS-WIN-NTUSER-MENU-L1-1-3.DLL\r\nEXT-MS-WIN-NTUSER-MESSAGE-L1-1-1.DLL\r\nEXT-MS-WIN-NTUSER-MESSAGE-L1-1-3.DLL\r\nEXT-MS-WIN-NTUSER-MISC-L1-5-1.DLL\r\nEXT-MS-WIN-NTUSER-MIT-L1-1-0.DLL\r\nEXT-MS-WIN-NTUSER-MOUSE-L1-1-0.DLL\r\nEXT-MS-WIN-NTUSER-PRIVATE-L1-3-2.DLL\r\nEXT-MS-WIN-NTUSER-RECTANGLE-EXT-L1-1-0.DLL\r\nEXT-MS-WIN-NTUSER-ROTATIONMANAGER-L1-1-0.DLL\r\nEXT-MS-WIN-NTUSER-SERVER-L1-1-0.DLL\r\nEXT-MS-WIN-NTUSER-STRING-L1-1-0.DLL\r\nEXT-MS-WIN-NTUSER-SYNCH-L1-1-0.DLL\r\nEXT-MS-WIN-NTUSER-UICONTEXT-EXT-L1-1-0.DLL\r\nEXT-MS-WIN-NTUSER-WINDOW-L1-1-1.DLL\r\nEXT-MS-WIN-NTUSER-WINDOW-L1-1-4.DLL\r\nEXT-MS-WIN-NTUSER-WINDOWCLASS-L1-1-1.DLL\r\nEXT-MS-WIN-NTUSER-WINDOWSTATION-L1-1-1.DLL\r\nEXT-MS-WIN-ODBC-ODBC32-L1-1-0.DLL\r\nEXT-MS-WIN-OLE32-BINDCTX-L1-1-0.DLL\r\nEXT-MS-WIN-OLE32-IE-EXT-L1-1-0.DLL\r\nEXT-MS-WIN-OLE32-OLEAUTOMATION-L1-1-0.DLL\r\nEXT-MS-WIN-OLEACC-L1-1-2.DLL\r\nEXT-MS-WIN-PRINTER-PRNTVPT-L1-1-1.DLL\r\nEXT-MS-WIN-PROFILE-EXTENDER-L1-1-0.DLL\r\nEXT-MS-WIN-PROFILE-LOAD-L1-1-0.DLL\r\nEXT-MS-WIN-PROFILE-USERENV-L1-1-0.DLL\r\nEXT-MS-WIN-PROFILE-USERENV-L1-1-1.DLL\r\nEXT-MS-WIN-RAS-RASAPI32-L1-1-0.DLL\r\nEXT-MS-WIN-RAS-TAPI32-L1-1-1.DLL\r\nEXT-MS-WIN-RDR-DAVHLPR-L1-1-0.DLL\r\nEXT-MS-WIN-RESOURCES-DEPLOYMENT-L1-1-0.DLL\r\nEXT-MS-WIN-RO-TYPERESOLUTION-L1-1-0.DLL\r\nEXT-MS-WIN-RPC-SSL-L1-1-0.DLL\r\nEXT-MS-WIN-RTCORE-GDI-DEVCAPS-L1-1-0.DLL\r\nEXT-MS-WIN-RTCORE-GDI-OBJECT-L1-1-0.DLL\r\nEXT-MS-WIN-RTCORE-GDI-RGN-L1-1-0.DLL\r\nEXT-MS-WIN-RTCORE-GDI-RGN-L1-1-1.DLL\r\nEXT-MS-WIN-RTCORE-MINUSER-INPUT-L1-1-2.DLL\r\nEXT-MS-WIN-RTCORE-MINUSER-PRIVATE-EXT-L1-1-0.DLL\r\nEXT-MS-WIN-RTCORE-NTUSER-CURSOR-L1-1-1.DLL\r\nEXT-MS-WIN-RTCORE-NTUSER-DC-ACCESS-L1-1-0.DLL\r\nEXT-MS-WIN-RTCORE-NTUSER-DPI-L1-2-0.DLL\r\nEXT-MS-WIN-RTCORE-NTUSER-IAM-L1-1-1.DLL\r\nEXT-MS-WIN-RTCORE-NTUSER-INTEGRATION-L1-1-0.DLL\r\nEXT-MS-WIN-RTCORE-NTUSER-SYNCH-EXT-L1-1-0.DLL\r\nEXT-MS-WIN-RTCORE-NTUSER-SYSCOLORS-L1-1-0.DLL\r\nEXT-MS-WIN-RTCORE-NTUSER-SYSPARAMS-L1-1-0.DLL\r\nEXT-MS-WIN-RTCORE-NTUSER-WINDOW-EXT-L1-1-0.DLL\r\nEXT-MS-WIN-SECUR32-TRANSLATENAME-L1-1-0.DLL\r\nEXT-MS-WIN-SECURITY-CAPAUTHZ-L1-1-1.DLL\r\nEXT-MS-WIN-SECURITY-CHAMBERS-L1-1-0.DLL\r\nEXT-MS-WIN-SECURITY-CHAMBERS-L1-1-1.DLL\r\nEXT-MS-WIN-SECURITY-CREDUI-INTERNAL-L1-1-0.DLL\r\nEXT-MS-WIN-SECURITY-CREDUI-L1-1-0.DLL\r\nEXT-MS-WIN-SECURITY-CRYPTUI-L1-1-0.DLL\r\nEXT-MS-WIN-SECURITY-CRYPTUI-L1-1-1.DLL\r\nEXT-MS-WIN-SECURITY-EFS-L1-1-1.DLL\r\nEXT-MS-WIN-SECURITY-EFSWRT-L1-1-1.DLL\r\nEXT-MS-WIN-SECURITY-WINSCARD-L1-1-0.DLL\r\nEXT-MS-WIN-SESSION-USERMGR-L1-1-0.DLL\r\nEXT-MS-WIN-SESSION-USERMGR-L1-2-0.DLL\r\nEXT-MS-WIN-SESSION-USERTOKEN-L1-1-0.DLL\r\nEXT-MS-WIN-SESSION-WINSTA-L1-1-0.DLL\r\nEXT-MS-WIN-SESSION-WTSAPI32-L1-1-0.DLL\r\nEXT-MS-WIN-SETUPAPI-INF-L1-1-0.DLL\r\nEXT-MS-WIN-SETUPAPI-INF-L1-1-1.DLL\r\nEXT-MS-WIN-SHELL-DIRECTORY-L1-1-0.DLL\r\nEXT-MS-WIN-SHELL-EMBEDDEDMODE-L1-1-0.DLL\r\nEXT-MS-WIN-SHELL-SHELL32-L1-2-0.DLL\r\nEXT-MS-WIN-SHELL-SHLWAPI-L1-2-0.DLL\r\nEXT-MS-WIN-SHELL32-SHELLCOM-L1-1-0.DLL\r\nEXT-MS-WIN-SHELL32-SHELLFOLDERS-L1-2-0.DLL\r\nEXT-MS-WIN-SMBSHARE-BROWSERCLIENT-L1-1-0.DLL\r\nEXT-MS-WIN-STORAGE-SENSE-L1-2-0.DLL\r\nEXT-MS-WIN-SXS-OLEAUTOMATION-L1-1-0.DLL\r\nEXT-MS-WIN-TSF-MSCTF-L1-1-2.DLL\r\nEXT-MS-WIN-UI-VIEWMANAGEMENT-L1-1-0.DLL\r\nEXT-MS-WIN-USP10-L1-1-0.DLL\r\nEXT-MS-WIN-WER-UI-L1-1-0.DLL\r\nEXT-MS-WIN-WER-XBOX-L1-1-0.DLL\r\nEXT-MS-WIN-WINRT-STORAGE-L1-1-0.DLL\r\nEXT-MS-WIN-WLAN-ONEXUI-L1-1-0.DLL\r\nEXT-MS-WIN-WLAN-SCARD-L1-1-0.DLL\r\nIESHIMS.DLL\r\n\r\nStrangely enough, some files I know for sure I have such as PYTHON35.DLL, CUDNN64_6.DLL and their locations are in %PATH% that I defined in the tensorflow environment that I activated using the conda console. Perhaps it is using the default %PATH% when running? I know the default value will not have the location of those files.\r\n\r\nThat being said, some of these files I do not see when querying them such as API-MS-WIN-CORE-ATOMS-L1-1-0.DLL. Are these files required? If so is there a package to cover these? ", "The `API-MS-WIN-*.DLL` messages are false negatives. (This is apparently a [known issue](https://stackoverflow.com/q/36240215/3574081) in Dependency Walker, but unfortunately it's the best tool we have!) I believe the same is true for the `EXT-MS-WIN-*.DLL` ones as well. \r\n\r\nAre you running Dependency Walker from a command prompt in the same Conda environment in which you installed TensorFlow?", "In my first comment I ran it when it was just in the C drive not via cmd prompt. Literally just via file explorer.\r\n\r\nI have tried running it again but this time I placed the exe file into the tensorflow environment and ran it via cmd(Please let me know if I am running it wrong):\r\nTensorflow is located at(this displays when launching the python console): C:\\Users\\Eric\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\r\nI moved depends.exe into C:\\Users\\Eric\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\\r\n\r\nI am getting the following errors(unfortunately they do not seem to specify where they are all occurring):\r\nError: At least one required implicit or forwarded dependency was not found.\r\nError: At least one module has an unresolved import due to a missing export function in an implicitly dependent module.\r\nError: Modules with different CPU types were found.\r\nError: A circular dependency was detected.\r\nWarning: At least one delay-load dependency module was not found.\r\nWarning: At least one module has an unresolved import due to a missing export function in a delay-load dependent module.\r\n\r\nFiles with the error \"Error opening file. The system cannot find file specified(2)\". I removed all files from this list that started with API-MS or EXT-MS, let me know if you want me to post the whole thing:\r\nCUBLAS64_80.DLL\r\nCUFFT64_80.DLL\r\nCURAND64_80.DLL\r\nCUSOLVER64_80.DLL\r\nDEVICELOCKHELPERS.DLL\r\nEMCLIENT.DLL\r\nIESHIMS.DLL\r\n\r\nI guess the good news is that it is finding CUDNN and Python now. So the results seems to be much more accurate. I ran a query and none of the files above are installed except for IESHIMS.DLL, but that one's location is not in %PATH%.\r\n\r\nPlease advise on how to proceed.", "The following DLLs are typically part of a CUDA Toolkit installation:\r\n\r\n* `CUBLAS64_80.DLL`\r\n* `CUFFT64_80.DLL`\r\n* `CURAND64_80.DLL`\r\n* `CUSOLVER64_80.DLL`\r\n\r\nPerhaps you need to reinstall CUDA 8.0 to get these DLLs? (I believe the other three are false negatives.)", "Good news! After reinstalling CUDA 8, I am no longer getting the error. It seems that I was missing some of the files. Thank you for your help.\r\n\r\nI do notice that I am getting the following messages, should I be concerned about them? They do not seem critical:\r\n2017-10-13 18:23:28.501415: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\35\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-10-13 18:23:28.502420: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\35\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.", "Great! It's safe to ignore those warnings.", "@mrry thanks downloading the file worked for me as well.\r\n(just stating that here - if someone else runs across the same problem)", "The TensorFlow GPU worked after uninstalling Tensowflow CPU\r\n![image](https://user-images.githubusercontent.com/22581263/34695875-a83ed278-f4b3-11e7-9f7d-fb784126a6a8.png)\r\n"]}, {"number": 13674, "title": "Configurable upper bound for MKL allocator", "body": "Multiple ways to configure upper bound on the MKL cpu allocator\r\n\r\n- Default is 64 GB\r\n- Overridden by DRAM capacity, if available\r\n- Overridden by user configured limit if set through an environment variable.\r\n\r\nNew PR to get around CLA issues with previous PR\r\n\r\n", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "@tensorflow-jenkins test this please"]}, {"number": 13673, "title": "Add a new MKL build script for linux.", "body": "", "comments": []}, {"number": 13672, "title": "Fix discrepancy between doc and impl for `tf.reverse`", "body": "This fix tries to address the discrepancy between doc and implementations for `tf.reverse`. In the documentation, both int32 and int64 could be used for axis.\r\n\r\nHowever, the actual implementation of the `tf.reverse` does not support int64 and caused missing kernel error:\r\n```python\r\nubuntu@ubuntu:~$ python\r\nPython 2.7.12 (default, Nov 19 2016, 06:48:10)\r\n[GCC 5.4.0 20160609] on linux2\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> v = tf.reverse_v2([1, 2, 3], tf.constant([0], tf.int64))\r\n>>> sess = tf.Session()\r\n>>> sess.run(v)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 889, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1120, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1317, in _do_run\r\n    options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1336, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ReverseV2' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  device='CPU'; T in [DT_STRING]; Tidx in [DT_INT32]\r\n  device='CPU'; T in [DT_BOOL]; Tidx in [DT_INT32]\r\n  device='CPU'; T in [DT_COMPLEX128]; Tidx in [DT_INT32]\r\n  device='CPU'; T in [DT_COMPLEX64]; Tidx in [DT_INT32]\r\n  device='CPU'; T in [DT_DOUBLE]; Tidx in [DT_INT32]\r\n  device='CPU'; T in [DT_FLOAT]; Tidx in [DT_INT32]\r\n  device='CPU'; T in [DT_HALF]; Tidx in [DT_INT32]\r\n  device='CPU'; T in [DT_INT8]; Tidx in [DT_INT32]\r\n  device='CPU'; T in [DT_UINT8]; Tidx in [DT_INT32]\r\n  device='CPU'; T in [DT_INT16]; Tidx in [DT_INT32]\r\n  device='CPU'; T in [DT_UINT16]; Tidx in [DT_INT32]\r\n  device='CPU'; T in [DT_INT32]; Tidx in [DT_INT32]\r\n  device='CPU'; T in [DT_INT64]; Tidx in [DT_INT32]\r\n\r\n         [[Node: ReverseV2 = ReverseV2[T=DT_INT32, Tidx=DT_INT64](ReverseV2/tensor, Const)]]\r\n\r\n```\r\nThis fix addresses this issue and added the int64 support for axis in `tf.reverse`.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "ping @aselle "]}, {"number": 13671, "title": "Cherry-pick \"Fix for a regression in graph rewrite pass (MKL)\" into 1.4 branch.", "body": "", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this State. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Cherrypick PR, CLA ok."]}, {"number": 13670, "title": "Merge changes from 1.4-rc0 back into master", "body": "These contains mostly release note additions and some version string updates.", "comments": ["Did we want to bring the ghost batch norm revert back into master jhseu?", "I think we need to remove @jhseu's change from this. Master is correct, we just didn't want that in 1.4. \r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/13670/commits/4ac3cfecf470136723bb860c2363de50c176dcb7", "Yep, don't bring in my changes.", "Ok, I backed out the batch norm revert changes from the merge."]}, {"number": 13669, "title": "monotonic attention is buggy", "body": "### System information\r\n- **Have I written custom code **: Yes\r\n- **OS Platform and Distribution**: Manjaro Linux, kernel 4.13.5\r\n- **TensorFlow installed from **: binary\r\n- **TensorFlow version (use command below)**: 1.3, 1.4 nightly (11 oct)\r\n- **Python version**:  3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: cuda8, cudnn 7 & 6\r\n- **GPU model and memory**: gtx 1080\r\n\r\n### the problem\r\n\r\nThe two monotonic attention mechanisms, LuongMonotonicAttention and BahdanauMonotonicAttention, do not seem to work as expected on my task.\r\n\r\nIn the case of LuongMonotonicAttention, the alignment that I obtain looks like a horizontal line drawn on the first row of the image. However, the alignment has a diagonal shape using BahdanauAttention or LuongAttention, and I am instantiating these classes with the same parameters.\r\n\r\nIn the case of BahdanauMonotonicAttention, I simply receive an error message:\r\nhttps://pastebin.com/raw/mPPWnEH5\r\n\r\nIs there any preprocessing I should do in addition to the non-monotonic case ?", "comments": ["/CC @ebrevdo", "Hi, monotonic attention won't always work right out of the box when you swap softmax attention out for it.  Please see the practitioner's guide at the end of [the paper](https://arxiv.org/abs/1704.00784).  If the attention is always attending to the first encoder timestep for all decoder timesteps, you probably should try setting `score_bias_init` to a negative value.  You also will almost certainly get better results if you set `scale=True`.  If you post images of your softmax attention and the produced monotonic attention alignments, I can probably help debug further.\r\n\r\nFor the BahdanauMonotonicAttention shape error, that seems more like it may be a bug.  Can you post a full code snippet to reproduce this error?", "Here are the obtained alignments after a few iterations: [imgur link](https://imgur.com/a/R0fMe)\r\nscore_bias_init was 0 this time, just launched a new experiment with a negative value (-1)\r\n\r\nSnippet coming soon, have to flatten the code a bit", "> Here are the obtained alignments after a few iterations: imgur link\r\n\r\nWhat are the axes?  Is decoder step vertical or horizontal?  And where is the origin?\r\n\r\n> score_bias_init was 0 this time, just launched a new experiment with a negative value (-1)\r\n\r\nCool.  You may need to try progressively more negative values, and also I do recommend you try setting `scale=True`.", "Hi Colin,\r\nThe vertical axis is for the speech input, and the horizontal one for the labels. The original shapes are ~[150, 45], but I resize the images to (512,512). The origin should be the top-left corner, but I am unsure. The code is quite similar to the one in the nmt tutorial:\r\n\r\n```\r\noutputs, states, lengths = seq2seq.dynamic_decode(\r\n            self._decoder_inference,\r\n            impute_finished=True,\r\n            swap_memory=False,\r\n            maximum_iterations=self._hparams.max_label_length)\r\n\r\nattention_alignment = states.alignment_history.stack()\r\nattention_images = tf.expand_dims(tf.transpose(attention_alignment, [1, 2, 0]), -1)\r\nattention_summary = tf.summary.image(\"attention_images\", attention_images)\r\n```", "Ok, in that case monotonic attention should work - wanted to make sure you weren't reversing the input sequence, as people sometimes do in MT.  Let's get Bahdanau monotonic attention working for you since that's what I had worked with for speech.", "Turns out I had a typo in the monotonic bahdanau call, pasted the scalar `num_units` for the `memory` field too.\r\nIndeed, the alignment images look quite different for several values of `score_bias_init` and `sigmoid_noise`, will have to search for the optimal values.\r\nWould -1.0 and 0.5 (0.0 in test) respectively be a good starting point ? Cannot tell what would be an appropriate range right now.", "Typically I try [-4, -3, -2, -1] for `score_bias_init`.  I have never needed to use anything other than `sigmoid_noise=1`.  Again, I recommend using `scale=True` and `BahdanauMonotonicAttention`.", "Hi Colin @craffel ,\r\nI generated some alignments using `LuongMonotonicAttention` with `mode='hard'`\r\nhttps://i.imgur.com/O7PJkmp.png\r\nThe output does not look like a binary image, is this the expected behaviour ?\r\nSame code as above to obtain the alignment images, without any resizing", "That does not look correct for `mode='hard'`.  I'm traveling this week so will not have a chance to look at it.  Please double check that you're actually passing `mode='hard'` and then maybe post a short code snippet with how you are calling `LuongMonotonicAttention` (a minimal example showing this behavior would be most helpful).  In the meantime @ebrevdo maybe you can help debug?", "Hi George,\nAre you able to provide a minimal code example that we can use to replicate\nthe issue?\n\nOn Mon, Oct 30, 2017 at 5:57 AM, Colin Raffel <notifications@github.com>\nwrote:\n\n> That does not look correct for mode='hard'. I'm traveling this week so\n> will not have a chance to look at it. Please double check that you're\n> actually passing mode='hard' and then maybe post a short code snippet\n> with how you are calling LuongMonotonicAttention (a minimal example\n> showing this behavior would be most helpful). In the meantime @ebrevdo\n> <https://github.com/ebrevdo> maybe you can help debug?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/13669#issuecomment-340435738>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtimxRNkyag762Fb9LUqoyKr7hB_fQLks5sxcfPgaJpZM4P3nxw>\n> .\n>\n", "Thanks for the confirmation, there is probably something wrong with my code. I am also traveling tomorrow, but will check everything on Wednesday and come back with a snippet if the problem persists.\n\n\nFrom: ebrevdo\nSent: Monday 30 October 2017 15:33\nTo: tensorflow/tensorflow\nCc: George Sterpu; State change\nSubject: Re: [tensorflow/tensorflow] monotonic attention is buggy (#13669)\n\nHi George,\nAre you able to provide a minimal code example that we can use to replicate\nthe issue?\n\nOn Mon, Oct 30, 2017 at 5:57 AM, Colin Raffel <notifications@github.com>\nwrote:\n\n> That does not look correct for mode='hard'. I'm traveling this week so\n> will not have a chance to look at it. Please double check that you're\n> actually passing mode='hard' and then maybe post a short code snippet\n> with how you are calling LuongMonotonicAttention (a minimal example\n> showing this behavior would be most helpful). In the meantime @ebrevdo\n> <https://github.com/ebrevdo> maybe you can help debug?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/13669#issuecomment-340435738>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtimxRNkyag762Fb9LUqoyKr7hB_fQLks5sxcfPgaJpZM4P3nxw>\n> .\n>\n\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n"]}, {"number": 13668, "title": "ValueError: Cannot feed value of shape (128,) for Tensor 'Placeholder_142:0', which has shape '(?, 3433)", "body": "Hello... after several unsuccesfull tries, I would like to ask your help in solving this error.\r\nI am trying to train a deep autoencoder network, by using a local csv file that is then transformed (by the csv and the numpy libraries) into a numpy array. But this data is never feeding into my placeholder's tensor.\r\n\r\nHere's an abstract of the deep autoencoder:\r\n\r\n`\r\nclass Deep_Autoencoder:\r\n    \r\n    def __init__(self, input_dim, n_nodes_hl = (32, 16, 1), \r\n                 epochs = 400, batch_size = 128, learning_rate = 0.02, n_examples = 10):\r\n        \r\n        # Hyperparameters\r\n        self.input_dim = input_dim\r\n        self.epochs = epochs\r\n        self.batch_size = batch_size\r\n        self.learning_rate = learning_rate\r\n        self.n_examples = n_examples\r\n        \r\n        # Input and target placeholders\r\n        X = tf.placeholder('float', [None, self.input_dim])\r\n        Y = tf.placeholder('float', [None, self.input_dim])\r\n\t\t...\r\n\t\t\r\n\t\tself.X = X\r\n        print(\"self.X : \", self.X)\r\n        self.Y = Y\r\n        print(\"self.Y : \", self.Y)\r\n\t\t...\r\n\t        \r\n    def train_neural_network(self, data, targets):\r\n        \r\n        with tf.Session() as sess:\r\n            sess.run(tf.global_variables_initializer())\r\n            for epoch in range(self.epochs):\r\n                epoch_loss = 0\r\n                i = 0\r\n\r\n                # Let's train it in batch-mode\r\n                while i < len(data):\r\n                    start = i\r\n                    end = i + self.batch_size\r\n                    \r\n                    batch_x = np.array(data[start:end])\r\n                    print(\"type batch_x :\", type(batch_x))\r\n                    print(\"len batch_x :\", len(batch_x))\r\n                    batch_y = np.array(targets[start:end])\r\n                    print(\"type batch_y :\", type(batch_y))\r\n                    print(\"len batch_y :\", len(batch_y))\r\n                    \r\n                    hidden, _, c = sess.run([self.encoded, self.optimizer, self.cost], \r\n                                            feed_dict={self.X: batch_x, self.Y: batch_y})\r\n                    epoch_loss +=c\r\n                    i += self.batch_size\r\n\r\n            self.saver.save(sess, 'selfautoencoder.ckpt')\r\n            print('Accuracy', self.accuracy.eval({self.X: data, self.Y: targets}))`\r\n\r\nHere I create the input data and below you can see that I'll printout their main features for your info (note that I am actually interested on column 3 only):\r\n\r\n`\tfeatures_DeepAE = create_feature_sets(filename)\r\n\r\n\tTrain_x = np.array(features_DeepAE[0])\r\n\tTrain_y = np.array(features_DeepAE[1])\r\n\r\n\tprint(\"type Train_x : \", type(Train_x))\r\n\tprint(\"type Train_x.T[3] : \", type(Train_x.T[3]))\r\n\tprint(\"len Train_x : \", len(Train_x))\r\n\tprint(\"len Train_x.T[3] : \", len(Train_x.T[3]))\r\n\tprint(\"shape Train_x : \", Train_x.shape)\r\n\tprint(\"type Train_y : \", type(Train_y))\r\n\tprint(\"type Train_y.T[3] : \", type(Train_y.T[3]))\r\n\tprint(\"len Train_y : \", len(Train_y))\r\n\tprint(\"len Train_y.T[3] : \", len(Train_y.T[3]))\r\n\tprint(\"shape Train_y : \", Train_y.shape)`\r\n\r\nAnd here I run the code:\r\n\r\n`\tDAE = Deep_Autoencoder(input_dim = len(Train_x))\r\n\tDAE.train_neural_network(Train_x.T[3], Train_y.T[3])\r\n`\r\n\r\n------\r\n\r\nThese are the printouts, fyi:\r\n\r\n\ttype Train_x :  <class 'numpy.ndarray'>\r\n\ttype Train_x.T[3] :  <class 'numpy.ndarray'>\r\n\tlen Train_x :  3433\r\n\tlen Train_x.T[3] :  3433\r\n\tshape Train_x :  (3433, 5)\r\n\ttype Train_y :  <class 'numpy.ndarray'>\r\n\ttype Train_y.T[3] :  <class 'numpy.ndarray'>\r\n\tlen Train_y :  3433\r\n\tlen Train_y.T[3] :  3433\r\n\tshape Train_y :  (3433, 5)\r\n\tself.X :  Tensor(\"Placeholder_142:0\", shape=(?, 3433), dtype=float32)\r\n\tself.Y :  Tensor(\"Placeholder_143:0\", shape=(?, 3433), dtype=float32)\r\n\ttype batch_x : <class 'numpy.ndarray'>\r\n\tlen batch_x : 128\r\n\ttype batch_y : <class 'numpy.ndarray'>\r\n\tlen batch_y : 128\r\n\r\n\r\n\r\n\r\n------\r\nAnd finally the error:\r\n**ValueError: Cannot feed value of shape (128,) for Tensor 'Placeholder_142:0', which has shape '(?, 3433)'**\r\n\r\nand yes... I'm at placeholder # 143... that meas a lot of failures (reshaping the batch and/or the tensor, transposing one and/or the other, looking for workarounds on internet..) ! \r\nDo not hesitate to ask for more info if needed.", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 13667, "title": "configure.py: Disable AWS support on Windows by default", "body": "This is a follow up to https://github.com/tensorflow/tensorflow/pull/13662\r\n@gunan ", "comments": []}, {"number": 13666, "title": "Add GPU support and improve performance for tf.diag and tf.diag_part", "body": "This PR tries to settle the issue [#13491](https://github.com/tensorflow/tensorflow/issues/13491) and makes some contribution for tf.diag and tf.diag_part:\r\n- Add GPU support.\r\n- Using a simple transfer trick makes code clear and easy to be parallel.\r\n- Rewrite the CPU code using the recent rewrite of matrix_band_part as a template, which getting rid of the Eigen generator mechanism, remove the restriction which the input rank is at most 3.\r\n\r\nImplementation of transfer trick can be described as follows.\r\n\r\nAccording to the [tf.diag](https://www.tensorflow.org/versions/master/api_docs/python/tf/diag) op definition, `output[i1,..., ik, i1,..., ik] = input[i1,..., ik]`.\r\n\r\nLet the rank of input is `[s1,..., sk]`, then any offset of input's pointer can be represented by coordinate `[i1,..., ik]`, where `index = i1*(s2*...*sk) + i2*(s3*...*sk) +... + ik`.\r\n\r\nLet new_index is the offset of output's pointer with coordinate `[i1,..., ik, i1,..., ik]`, then we have\r\n```\r\nnew_index = i1*(s2*...sk*s1*...*sk) + i2*(s3*...*sk*s1*...*sk) +... + \\\r\n            ik*(s1*...*sk) + i1*(s2*...*sk) + i2*(s3*...*sk) +... + ik\r\n          = (i1*(s2*...*sk) + i2*(s3*...*sk) +... + ik) * (1 + s1*...*sk)\r\n          = index * (1 + s1*...*sk)\r\n```\r\n\r\nLet `size = s1*...*sk`, we finally have `new_index = index * (1 + size)`, which is the transfer function we use below.\r\n\r\nThis trick make our implementations clear and easy to be parallel.\r\n\r\nIf there is anything I need to modify, please let me know. Thank you for your review.", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "@cwhipkey \r\nI guess I could optimize it by multi-thread shard, should I do it for in this PR?\r\nAnd I am not sure whether I need to modify the BUILD script, because I add two files namely diag_op.h and diag_op_gpu.cu.cc. \r\n\r\nThank you very much.", "@cwhipkey \r\nIs that good to go? Thank you very much~", "Sorry for the delay, I'll review it in detail today.\r\n\r\nOne question - do you have benchmarks that show the difference in performance of old vs new on CPU?  (there are some other micro-benchmark examples, like in core/kernels/matmul_op_test.cc - with the microbenchmarks, you then build the binary and run the test binary with args like   --benchmarks=all --benchmark_min_time=20 or something).", "Can one of the admins verify this patch?", "Sorry for that I just close this PR accidentally...", "@cwhipkey Thank you for your reviews.\r\n\r\n- I've made changes according to your comments.\r\n- I've add shard function for CPU version in this PR, which gets rid of trouble of a new PR.\r\n- I've add the benchmark in `core/kernel/diag_op_test.cc`, and compare with the old in performance.\r\n\r\nIn general, current version in CPU can speed 10 times, and version in GPU can speed more than 100 times for length or 512.\r\nHere are the results:\r\n\r\n#### Old Version in CPU (96f334b0d6ec61f5037b8ddd1860a9aa7874efef)\r\n```\r\n$bazel test :diag_op_test --test_arg=--benchmarks=all --test_output=all\r\n...\r\n==================== Test output for //tensorflow/core/kernels:diag_op_test:\r\n2017-10-18 07:12:01.963569: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\nRunning main() from test_main.cc\r\nBenchmark                      Time(ns) Iterations\r\n--------------------------------------------------\r\nBM_Diag_16_DT_INT32_cpu           25606      28894       0.6M items/s\r\nBM_Diag_16_DT_FLOAT_cpu           23701      29621       0.7M items/s\r\nBM_Diag_16_DT_COMPLEX64_cpu       22794      30482       0.7M items/s\r\nBM_Diag_128_DT_INT32_cpu         236919       3006       0.5M items/s\r\nBM_Diag_128_DT_FLOAT_cpu         225901       3035       0.6M items/s\r\nBM_Diag_128_DT_COMPLEX64_cpu     248124       2874       0.5M items/s\r\nBM_Diag_512_DT_INT32_cpu        3368587        208       0.2M items/s\r\nBM_Diag_512_DT_FLOAT_cpu        3242726        215       0.2M items/s\r\nBM_Diag_512_DT_COMPLEX64_cpu    3517025        199       0.1M items/s\r\n================================================================================\r\n//tensorflow/core/kernels:diag_op_test                                   PASSED in 9.3s\r\n\r\nExecuted 1 out of 1 test: 1 test passes.\r\n```\r\n#### Current Version in CPU&GPU (36e9764583f856a00fb3573daaea74812c8edf47)\r\n```\r\nRunning main() from test_main.cc\r\nBenchmark                      Time(ns) Iterations\r\n--------------------------------------------------\r\nBM_Diag_16_DT_INT32_cpu           18760      34370       0.9M items/s\r\nBM_Diag_16_DT_FLOAT_cpu           19241      34903       0.8M items/s\r\nBM_Diag_16_DT_COMPLEX64_cpu       19791      33423       0.8M items/s\r\nBM_Diag_16_DT_INT32_gpu           34986      20144       0.5M items/s\r\nBM_Diag_16_DT_FLOAT_gpu           37343      19353       0.4M items/s\r\nBM_Diag_16_DT_COMPLEX64_gpu       35488      19930       0.5M items/s\r\nBM_Diag_128_DT_INT32_cpu          22539      29165       5.7M items/s\r\nBM_Diag_128_DT_FLOAT_cpu          26046      31457       4.9M items/s\r\nBM_Diag_128_DT_COMPLEX64_cpu      29816      20297       4.3M items/s\r\nBM_Diag_128_DT_INT32_gpu          36148      19113       3.5M items/s\r\nBM_Diag_128_DT_FLOAT_gpu          34664      19109       3.7M items/s\r\nBM_Diag_128_DT_COMPLEX64_gpu      35264      19279       3.6M items/s\r\nBM_Diag_512_DT_INT32_cpu          74927       9439       6.8M items/s\r\nBM_Diag_512_DT_FLOAT_cpu          73087       9120       7.0M items/s\r\nBM_Diag_512_DT_COMPLEX64_cpu      86292       7751       5.9M items/s\r\nBM_Diag_512_DT_INT32_gpu          35550      17597       14.4M items/s\r\nBM_Diag_512_DT_FLOAT_gpu          34587      19479       14.8M items/s\r\nBM_Diag_512_DT_COMPLEX64_gpu      37200      19071       13.8M items/s\r\n================================================================================\r\n//tensorflow/core/kernels:diag_op_test                          (cached) PASSED in 20.7s\r\n\r\nExecuted 0 out of 1 test: 1 test passes.\r\n```\r\n#### System information of test environment \r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04):** Linux Server release 7.2 (RedHat)\r\n- **TensorFlow installed from (source or binary):** source\r\n- **TensorFlow version (use command below):** 1.3.0\r\n- **Python version:** Python 3.6.1 :: Anaconda 4.4.0 (64-bit)\r\n- **Bazel version (if compiling from source):** 0.6.1\r\n- **CUDA/cuDNN version:** 8.0/5.1.3\r\n- **GPU model and memory:** Tesla M40/12G\r\n- **Exact command to reproduce:**", "(note for mergers - there are a couple small items to be changed before merging.  I may have picked the wrong 'approval' option in the review dialog, I'm not positive).", "Thanks @cwhipkey for the review. This PR has been updated according to your comments. Please take a look.", "jenkins, test this please", "@cwhipkey Seems that the Ubuntu CC test is stalling?", "jenkins, test this please", "@cwhipkey \r\nSeems that the `Ubuntu CC` is still not running. Is there something wrong with the check program?", "@cwhipkey @vrv Thank you for your attention. \r\nThe test failure of `Ubuntu contrib` seems not be related with this PR according to the log. So is there anything I can do to avoid it like merging latest master branch?\r\nHere is the tail part of the log:\r\n```\r\n//tensorflow/contrib/data/python/kernel_tests:sloppy_transformation_dataset_op_test TIMEOUT in 352.5s\r\n  /tmpfs/tmp/bazel/execroot/org_tensorflow/bazel-out/linux_gnu_x86-py3-opt/testlogs/tensorflow/contrib/data/python/kernel_tests/sloppy_transformation_dataset_op_test/test.log\r\n\r\nExecuted 399 out of 399 tests: 398 tests pass and 1 fails locally.\r\nThere were tests whose specified size is too big. Use the --test_verbose_timeout_warnings command line option to see which ones these are.\r\n```", "@jinze1994 thanks for adding this. It's nice to see that most of our diagonal / band matrix handling is in better shape now, especially on GPU.", "It's my pleasure to make some contributions for tf~"]}, {"number": 13665, "title": "Improve CRF documentation.", "body": "This PR aims to improve documentation of CRF decoding introduced in https://github.com/tensorflow/tensorflow/pull/12056 .", "comments": ["Can one of the admins verify this patch?"]}, {"number": 13664, "title": "MaxPoolingOp only supports NHWC. ERROR in my benchmark we would use NCHW dataformat", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 17.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.4.0-rc0\r\n- **Python version**: 2.7.13\r\n- **Bazel version (if compiling from source)**: 0.6.1\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n**numactl -m 1 python ./tensorflow/models/image/convnet-benchmark-alexnet/benchmark_alexnet_MKL.py --batch_size 256 --num_batches 100 -forward_backward_only --cpu knl 2>&1|tee tensorflow_alexnet_mkl.txt**\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nI have compiled tensorflow with bazel 0.6.1 and install it on my xeon phi TM platform.\r\nMeanwhile I have got a benchmark related with alexnet.\r\n\r\nWhen I run the benchmark I got the error:\r\n_2017-10-12 09:38:14.503463: E tensorflow/core/common_runtime/executor.cc:643] Executor failed to create kernel. Invalid argument: Default MaxPoolingOp only supports NHWC.\r\n         [[Node: pool1 = MaxPool[T=DT_FLOAT, data_format=\"NCHW\", ksize=[1, 1, 3, 3], padding=\"VALID\", strides=[1, 1, 2, 2], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv1)]]_\r\n\r\nAlso I find that in the benchmark, it has take both **\"NCHW\"** and **\"NHWC\"** data format into consideration. So the benchmark should support both data format.\r\nI couldn't figure out why,  is this error relates with out compile process, or might I need to add some other option into the compile process.\r\nHere is my compile command:\r\n\r\n_bazel build --config=mkl --copt=\"-g\" --copt=\"-DEIGEN_USE_VML\" --copt=\"-mavx2\" --copt=\"-mfma\" --copt=\"-O3\" --verbose_failures  --copt=\"-L/opt/intel/gcc/lib64\" -s -c opt //tensorflow/tools/pip_package:build_pip_package_\r\n\r\nanyone could help!\r\n\r\n\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["I want to change Default MaxPoolingOp only supports NHWC into NCHW. Is it possible?", "I'm having the same issue with TF 1.3 and 1.4. This seems to be an issue with MKL linking during \"./configure\" since MKL is what is responsible for interpreting the NCHW data format.  This link may be of interest: https://github.com/tensorflow/tensorflow/issues/12849.\r\n\r\nThe last version that worked for me out of the box was TF 1.2.1 so I would recommend rebuilding or trying this [whl](https://anaconda.org/intel/tensorflow/1.2.1/download/tensorflow-1.2.1-cp27-cp27mu-linux_x86_64.whl).", "@andydavis1 might have some clues about MKL related issues", "Hi, krak3nnn, thanks for your help. \r\nToday, I have got a compiled version of tensorflow1.3, which could run the benchmark with NHWC data format. So I think during the \"./configure\" step, could we add some options to solve this probem?\r\n", "@vivek-rane Can you comment on the data layout for MKL Max Pooling op here?", "This error was fixed in master branch, see #13562 . We are trying to get this fix into r1.4.", "Thanks for the info @mahmoud-abuzaina!\r\n\r\nIn the meantime, the workarounds are to:\r\n1. Build from sources including #13562, or\r\n2. Use a nightly that includes this fix, or\r\n3. Use r1.4rc1 when it is available, or the actual r1.4 release when it is available.", "Thanks a lot for your information @mahmoud-abuzaina @tatatodd , I would try the new version.", "Hi, @mahmoud-abuzaina @tatatodd  I have try build the TF in the master branch:commit 7cdd26f606b39e3e487ec15dfa6eb5c6cf63ef84 with bazel 0.6.1\r\nOS: redhat 7.4\r\nThe build command is:\r\n**bazel build --config=mkl --copt=\"-g\" --copt=\"-DEIGEN_USE_VML\" --copt=\"-mavx2\" --copt=\"-mfma\" --copt=\"-O3\" --verbose_failures --copt=\"-L/opt/intel/gcc/lib64\" -s -c opt //tensorflow/tools/pip_package:build_pip_package**\r\nIt failed with the error:\r\n_ERROR: /root/tensorflow/tensorflow/python/BUILD:1373:1: Linking of rule '//tensorflow/python:gen_string_ops_py_wrappers_cc' failed (Exit 1): gcc failed: error executing command\r\nbazel-out/host/bin/_solib_k8/_U_S_Stensorflow_Spython_Cgen_Ustring_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: error: undefined reference to 'tensorflow::MklCPUAllocator::kName'\r\nbazel-out/host/bin/_solib_k8/_U_S_Stensorflow_Spython_Cgen_Ustring_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: error: undefined reference to 'tensorflow::MklCPUAllocator::kMaxLimitStr'_\r\n\r\nDo you have any idea?\r\n\r\n\u300a====================\u300b\r\nuodated 2017-10-14\r\nsame environment build with TF-1.4.0-rc0 success\r\nand confirm run the benchmark with TF-1.4.0-rc0 would encounter the  \"MaxPoolingOp only supports NHWC\" sighting.\r\n", "@Leslie-Fang this is a more recent issue and should be fixed when #13697 is merged. ", "I meet this issue also with tf-1.8 and P100 when I do distributed train via benchmark, even while I have set num_gpus to 2 but it seems using cpu both nodes without control, which makes me confused at all... @Leslie-Fang @mahmoud-abuzaina \r\nThis is the command I execute\r\n\r\n> CUDA_VISIBLE_DEVICES='' python3.4 tf_cnn_benchmarks.py --local_parameter_device=cpu --num_gpus=2 --batch_size=128 --model=resnet50 --variable_update=distributed_replicated --job_name=ps --ps_hosts=10.10.1.71:50071,10.10.1.20:50020 --worker_hosts=10.10.1.71:40071,10.10.1.20:40020 --task_index=0 --server_protocol='grpc+verbs' --all_reduce_spec='nccl/xring'\r\n>CUDA_VISIBLE_DEVICES='' python3.4 tf_cnn_benchmarks.py --local_parameter_device=cpu --num_gpus=2 --batch_size=128 --model=resnet50 --variable_update=distributed_replicated --job_name=worker --ps_hosts=10.10.1.71:50071,10.10.1.20:50020 --worker_hosts=10.10.1.71:40071,10.10.1.20:40020 --task_index=0 --server_protocol='grpc+verbs' --all_reduce_spec='nccl/xring'\r\n\r\nThis is a part of output\r\n> I0711 13:18:38.419439 140188219279168 tf_logging.py:116] Running local_init_op.\r\nI0711 13:18:41.063343 140188219279168 tf_logging.py:116] Done running local_init_op.\r\nRunning warm up\r\n2018-07-11 13:18:45.151136: E tensorflow/core/common_runtime/executor.cc:660] Executor failed to create kernel. Invalid argument: Default MaxPoolingOp only supports NHWC on device type CPU\r\n         [[Node: v0/tower_0/cg/mpool0/MaxPool = MaxPool[T=DT_FLOAT, data_format=\"NCHW\", ksize=[1, 1, 3, 3], padding=\"SAME\", strides=[1, 1, 2, 2], _device=\"/job:worker/replica:0/task:1/device:CPU:0\"](v0/tower_0/cg/conv0/Relu)]]\r\nI0711 13:18:45.186572 140188219279168 tf_logging.py:116] Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Default MaxPoolingOp only supports NHWC on device type CPU\r\n         [[Node: v0/tower_0/cg/mpool0/MaxPool = MaxPool[T=DT_FLOAT, data_format=\"NCHW\", ksize=[1, 1, 3, 3], padding=\"SAME\", strides=[1, 1, 2, 2], _device=\"/job:worker/replica:0/task:1/device:CPU:0\"](v0/tower_0/cg/conv0/Relu)]]\r\n", "This error maybe due to inappropriately installation of cuda. tensorflow-gpu have no access to GPU devices. Try to reinstall cuda and include cudnn and check if tensorflow can use GPUs by running:\r\n\r\n`sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))`"]}, {"number": 13663, "title": "Failed to run TensorFlow inference with inputs:[image_tensor], outputs:[detection_boxes, detection_scores, detection_classes, num_detections]", "body": "Facing this issue when running TFDetect app. Even the app is crashing.\r\nThis issue i'm facing is when i'm running the example tensorflow android app.", "comments": ["Please provide details about what platform you are using  (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?  Make sure you also include the exact command if possible to produce  the output included in your test case. If you are unclear what to include  see the issue template displayed in  [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\n We ask for this in the issue submission template, because    it is really difficult to help without that information. Thanks!", "@reedwm Hi Reed, I'm on Android 5.1.1 (OS : Mac, Architecture : None). The TensorFlow version i'm using is the 1.4.0-rc0. I have complied it form source.", "I am also getting same error . So please Update us on how to fix this issue ", "/CC @petewarden @andrewharp can you take a look?", "@vamshikhoslalabs @zubairbaqai: can you please post a complete logcat from starting the app up until you see the error message? Do any of the other samples work?\r\n\r\nI just tried the [official 1.4.0-rc0 APK](https://ci.tensorflow.org/view/Release/job/release-matrix-android/lastBuild/TF_BUILD_CONTAINER_TYPE=ANDROID_FULL,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=NO_PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=cpu-slave/artifact/out/tensorflow_demo.apk) build, and it works fine for me.", "Closing this as I'm assuming it was due to the temporary jcenter  issue we had where the wrong version of the TF AAR was downloaded. If it's still occurring please open a new issue with more details."]}, {"number": 13662, "title": "Add missing default config setting in aws.BUILD", "body": "Fix http://ci.tensorflow.org/job/tf-master-win-bzl/1714/console", "comments": ["Testing at http://ci.tensorflow.org/job/tensorflow-pr-win-bazel/45/console", "@case540 FYI", "@gunan Thanks for merging it so fast! But I just realized we need to disable building with AWS support, please see https://github.com/tensorflow/tensorflow/pull/13667"]}, {"number": 13661, "title": "Docker \"MAINTAINER\" instruction is deprecated", "body": "https://docs.docker.com/engine/reference/builder/#maintainer-deprecated\r\n\r\nWe should use \"LABEL maintainer\" instead.\r\n", "comments": ["Can one of the admins verify this patch?"]}, {"number": 13660, "title": "add code sample on inspect checkpoint variables", "body": "Tested in Jupyter Notebook.", "comments": ["Can one of the admins verify this patch?"]}, {"number": 13659, "title": "Enable vectorization on z13", "body": "Enable vectorization on z13 to improve performance.", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please"]}, {"number": 13658, "title": "tensorflow 1.3.0 build with bazel failed on redhat7.4BU1", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: redhat 7.4BU1\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**: 1.3.0\r\n- **Python version**: Python 2.7.5\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\nbuild tensorflow with bazel failed:\r\n**bazel build --config=mkl --copt=\"-g\" --copt=\"-DEIGEN_USE_VML\" --copt=\"-mavx2\" --copt=\"-mfma\" --copt=\"-O3\" --verbose_failures --copt=\"-Ofast\" --copt=\"-L/opt/intel/gcc/lib64\" -s -c opt //tensorflow/tools/pip_package:build_pip_package**\r\n\r\nfailed message:\r\n_WARNING: ignoring http_proxy in environment.\r\nERROR: /root/.cache/bazel/_bazel_root/6093305914d4a581ed00c0f6c06f975b/external/io_bazel_rules_closure/closure/private/defs.bzl:27:16: The `set` constructor for depsets is deprecated and will be removed. Please use the `depset` constructor instead. You can temporarily enable the deprecated `set` constructor by passing the flag --incompatible_disallow_set_constructor=false.\r\nERROR: error loading package '': Extension file 'closure/private/defs.bzl' has errors._\r\n\r\n\r\nwhat's more see the bazel info:\r\n_[root@unassigned-hostname tensorflow-1.3.0]# bazel info\r\nWARNING: ignoring http_proxy in environment.\r\nExtracting Bazel installation...\r\n..........................................\r\nERROR: /root/.cache/bazel/_bazel_root/6093305914d4a581ed00c0f6c06f975b/external/io_bazel_rules_closure/closure/private/defs.bzl:27:16: The `set` constructor for depsets is deprecated and will be removed. Please use the `depset` constructor instead. You can temporarily enable the deprecated `set` constructor by passing the flag --incompatible_disallow_set_constructor=false.\r\nERROR: error loading package '': Extension file 'closure/private/defs.bzl' has errors._\r\n\r\n\r\nhow did I install bazel on redhat:\r\nhttps://docs.bazel.build/versions/master/install-redhat.html\r\n\r\nadd the bazel repo\r\nthen yum install bazel\r\n\r\nIs something wrong with the bazel?\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["It's the bazel version problem.\r\nDegrade bazel to 0.5.4 or use tensorflow 1.4.0.\r\nThis problem would disappear."]}, {"number": 13657, "title": "tf.train.import_meta_graph() works strangely compared to restored session with tf.train.Supervisor", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: v1.1.0-13-g8ddd727 1.1.0\r\n- **Python version**: Python 3.4.3 \r\n- **CUDA/cuDNN version**: CUDA\r\n- **GPU model and memory**: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate (GHz) 1.076\r\npciBusID 0000:02:00.0\r\nTotal memory: 11.92GiB\r\n\r\n### Describe the problem\r\n\r\nWorking on GANs in tensorflow.\r\n\r\nI would like to load a generator from a different saved session and graph, in order to do some new ops on this part of the graph that has been trained. I use tf.train.import_meta_graph() but it works strangely compared to restored session with tf.train.Supervisor.\r\nIt seems like the tf.train.Supervisor reassigns the tensors in a better way. I would have guessed that the generator would have been successfully loaded or not, but not in such a strange way. \r\nI don't know if it is a bug.\r\n\r\n### Source code / logs\r\n\r\nWhen I use tf.train.import_meta_graph():\r\n```\r\ntrain_dir = \"./train_logs/mnist/0\" \r\nckpt = tf.train.latest_checkpoint(train_dir)\r\nfilename = \".\".join([ckpt, 'meta'])\r\nsaver = tf.train.import_meta_graph(filename)\r\n\r\nz_optim = tf.get_variable(name='z_optim', shape= [number_ini_z * batch_imgs_number, 100], initializer=tf.truncated_normal_initializer())\r\ngen_z = dcgan.generator(z_optim, is_training=False, reuse=False, name='generator_z')\r\n```\r\nThen I create basic image summary:\r\n```\r\nimage_test = tf.cast(((gen_z / 2.0) + 0.5) * 255.0, tf.uint8)\r\ns_test = tf.summary.image('reconstructed_image', image_test, max_outputs=3)\r\n```\r\nIn order to reassign all the trained values to the new generator created from scratch, I collect all the variables that were in the scope of the \"generator\" and then create my own list of initializers:\r\n```\r\ngen_variables_to_initialize = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='generator_z')\r\n\r\ngen_tensors_to_restore = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='generator')\r\n\r\nlist_assign_op = []\r\n\r\nfor variables, tensors in zip(gen_variables_to_initialize, gen_tensors_to_restore):\r\n    list_assign_op.append(tf.assign(variables, tensors))\r\n\r\n```\r\nI have to explicitly create another list of variables that have to be initialized:\r\n```\r\nvariables_initializer_except_for_generator = []\r\n\r\nvariables_to_initialize = gen_variables_to_initialize + dis_variables_to_initialize \r\n\r\nfor variable in tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES):\r\n        if variable not in variables_to_initialize:\r\n            variables_initializer_except_for_generator.append(variable.initializer)\r\n```\r\n so I run the session:\r\n```\r\nwith tf.Session() as sess:\r\n    logwriter = tf.summary.FileWriter('./logs', sess.graph)\r\n    saver.restore(sess, ckpt)\r\n    sess.run((list_assign_op, variables_initializer_except_for_generator))\r\n    s = sess.run(s_test)\r\n    logwriter.add_summary(s)\r\n```\r\nThis code gives me such digits on tensorboard: \r\n![yo](https://user-images.githubusercontent.com/23338676/31488738-4d73e66c-af71-11e7-94a2-161745e052d0.jpg)\r\n\r\nAnd then I remembered I used tf.train.Supervisor during the training, At the beginning I thought my GAN was not trained enough, but I instead ran:\r\n```\r\nlogdir = \"./train_logs/mnist/0\"\r\nsv = tf.train.Supervisor(logdir=logdir,\r\n                           save_summaries_secs=None, save_model_secs=120)\r\n\r\nwith sv.managed_session() as sess:\r\n    logwriter = tf.summary.FileWriter('./logs2', sess.graph)\r\n    s = sess.run(s_test)\r\n    logwriter.add_summary(s)\r\n```\r\nI had this on tensorboard:\r\n\r\n![yo2](https://user-images.githubusercontent.com/23338676/31488901-bf877566-af71-11e7-9f22-419a7b0f425b.jpg)\r\n\r\nIt seems like the tf.train.Supervisor reassigns the tensors in a better way. I would have guessed that the generator would have been successfully loaded or not, but not in such a strange way.\r\n\r\nThe problem is that I can't use the second method if I want to do some new stuffs with the generator (such as inverting it through another training, but his time on z_optim) because it does not want to add new nodes to the graph when it has not found it in previous training checkpoint. (Btw I had to change z_optim in tf.random_normal([number_ini_z * batch_imgs_number, 100], mean=0.0, stddev=1.0,name='random_z') for that same reason.\r\n\r\nDo you have an any idea of why such a thing occurs? Or any other suggestion in loading the generator?", "comments": ["/CC @martinwicke", "Hi, finally I managed to find the issue. \r\nBy doing \r\n\r\n sess.run((list_assign_op, variables_initializer_except_for_generator))\r\n\r\nThe variables of the generator are initialized at the same time as those who are not from the generator, but since the order is not defined as the computations can be parallelized, the values are not all assigned properly.\r\n\r\nTherefore, I have to run those commands in the specific order: first the generator and then the remaining variables, and in two separate lines.\r\nIt now seems to work.\r\n\r\nI close this issue but please don't hesitate to give me extra details or tell me if I misunderstood something.\r\nCheers"]}]