[{"number": 45533, "title": "TypeError: 'NoneType' object is not subscriptable when training with tf.dataset", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.4.0-rc3\r\n- Python version: 3.8.5\r\n- Bazel version (if compiling from source): 3.1.0\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.1, 8\r\n- GPU model and memory: RTX 3080 10GB\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-18-4f2f618e8fe2> in <module>\r\n----> 1 model.fit(train_tiles, epochs = 2, validation_data = val_tiles)\r\n\r\n~\\anaconda3\\envs\\hk4\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n   1098                 _r=1):\r\n   1099               callbacks.on_train_batch_begin(step)\r\n-> 1100               tmp_logs = self.train_function(iterator)\r\n   1101               if data_handler.should_sync:\r\n   1102                 context.async_wait()\r\n\r\n~\\anaconda3\\envs\\hk4\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py in __call__(self, *args, **kwds)\r\n    826     tracing_count = self.experimental_get_tracing_count()\r\n    827     with trace.Trace(self._name) as tm:\r\n--> 828       result = self._call(*args, **kwds)\r\n    829       compiler = \"xla\" if self._experimental_compile else \"nonXla\"\r\n    830       new_tracing_count = self.experimental_get_tracing_count()\r\n\r\n~\\anaconda3\\envs\\hk4\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py in _call(self, *args, **kwds)\r\n    869       # This is the first call of __call__, so we have to initialize.\r\n    870       initializers = []\r\n--> 871       self._initialize(args, kwds, add_initializers_to=initializers)\r\n    872     finally:\r\n    873       # At this point we know that the initialization is complete (or less\r\n\r\n~\\anaconda3\\envs\\hk4\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py in _initialize(self, args, kwds, add_initializers_to)\r\n    723     self._graph_deleter = FunctionDeleter(self._lifted_initializer_graph)\r\n    724     self._concrete_stateful_fn = (\r\n--> 725         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n    726             *args, **kwds))\r\n    727 \r\n\r\n~\\anaconda3\\envs\\hk4\\lib\\site-packages\\tensorflow\\python\\eager\\function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n   2967       args, kwargs = None, None\r\n   2968     with self._lock:\r\n-> 2969       graph_function, _ = self._maybe_define_function(args, kwargs)\r\n   2970     return graph_function\r\n   2971 \r\n\r\n~\\anaconda3\\envs\\hk4\\lib\\site-packages\\tensorflow\\python\\eager\\function.py in _maybe_define_function(self, args, kwargs)\r\n   3359 \r\n   3360           self._function_cache.missed.add(call_context_key)\r\n-> 3361           graph_function = self._create_graph_function(args, kwargs)\r\n   3362           self._function_cache.primary[cache_key] = graph_function\r\n   3363 \r\n\r\n~\\anaconda3\\envs\\hk4\\lib\\site-packages\\tensorflow\\python\\eager\\function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   3194     arg_names = base_arg_names + missing_arg_names\r\n   3195     graph_function = ConcreteFunction(\r\n-> 3196         func_graph_module.func_graph_from_py_func(\r\n   3197             self._name,\r\n   3198             self._python_function,\r\n\r\n~\\anaconda3\\envs\\hk4\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    988         _, original_func = tf_decorator.unwrap(python_func)\r\n    989 \r\n--> 990       func_outputs = python_func(*func_args, **func_kwargs)\r\n    991 \r\n    992       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n~\\anaconda3\\envs\\hk4\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py in wrapped_fn(*args, **kwds)\r\n    632             xla_context.Exit()\r\n    633         else:\r\n--> 634           out = weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    635         return out\r\n    636 \r\n\r\n~\\anaconda3\\envs\\hk4\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py in wrapper(*args, **kwargs)\r\n    975           except Exception as e:  # pylint:disable=broad-except\r\n    976             if hasattr(e, \"ag_error_metadata\"):\r\n--> 977               raise e.ag_error_metadata.to_exception(e)\r\n    978             else:\r\n    979               raise\r\n\r\nTypeError: in user code:\r\n\r\n    C:\\Users\\eck\\anaconda3\\envs\\hk4\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:805 train_function  *\r\n        return step_function(self, iterator)\r\n    D:\\Workspace\\CustomModules\\crispy\\core\\ecdl.py:293 call  *\r\n        Zo = self.conv1(Z)\r\n    C:\\Users\\eck\\anaconda3\\envs\\hk4\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1008 __call__  **\r\n        self._maybe_build(inputs)\r\n    C:\\Users\\eck\\anaconda3\\envs\\hk4\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:2710 _maybe_build\r\n        self.build(input_shapes)  # pylint:disable=not-callable\r\n    C:\\Users\\eck\\anaconda3\\envs\\hk4\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py:188 build\r\n        input_channel = self._get_input_channel(input_shape)\r\n    C:\\Users\\eck\\anaconda3\\envs\\hk4\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py:359 _get_input_channel\r\n        if input_shape.dims[channel_axis].value is None:\r\n\r\n    TypeError: 'NoneType' object is not subscriptable\r\n```\r\n\r\n\r\n- Model : Keras subclass model\r\n- Data : tf.dataset\r\n\r\n**Colab code** : [https://colab.research.google.com/drive/1bRpTcelfKHNK1SphTmvTo6qbxaYY9Ovl?usp=sharing][1]\r\n\r\n**What I've done:**\r\n1) Dummy dataset with `tf.random.normal` + the subclass model : worked\r\n2) tf.dataset + a dummy model(functional API) : worked\r\n3) `run_eagerly = True` when compiling the subclass model : worked, but don't want to use it for performance.\r\n4) Iterate over tf.dataset(train and validation) : didn't raise any error, I could see the tensor value.\r\n\r\n\r\n\r\n  [1]: https://colab.research.google.com/drive/1bRpTcelfKHNK1SphTmvTo6qbxaYY9Ovl?usp=sharing", "comments": ["@Crispy13 \r\n\r\nCan you please share the supporting file to reproduce the issue in our environment. I am seeing the error message `NameError: name 'train_tiles' is not defined`.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/26cffc6155b86ee20f1ed7f42aed63c5/untitled570.ipynb).Thanks!", "Solved it through inserting `model.build(batch_input_shape)` in the code.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45533\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45533\">No</a>\n", "Hey, I've got the same issue and `model.build()` did not solve my issue as it throws another error.\r\n\r\nI also use `tf.data.Dataset` with `model.fit`. I've already written a custom training loop which worked, however i want to save some programming time with `model.fit` and multiple gpus\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.5.0-rc3-213-ga4dfb8d1a71 2.5.0\r\n- Python version: 3.9.1\r\n- CUDA/cuDNN version: 8.1\r\n- GPU model and memory: RTX3070\r\n\r\n**Stack trace**\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/benjs/python/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"/home/benjs/python/lib/python3.9/runpy.py\", line 87, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/benjs/Documents/projects/hpe/hourglass/training.py\", line 119, in <module>\r\n    train_newell(model, batch_size=30, val_batch_size=20, epochs=300, annotation_dir=mp_dir,\r\n  File \"/home/benjs/Documents/projects/hpe/hourglass/training.py\", line 92, in train_newell\r\n    model.fit(x=train_ds, epochs=epochs)\r\n  File \"/home/benjs/Documents/projects/hpe/venv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\", line 1183, in fit\r\n    tmp_logs = self.train_function(iterator)\r\n  File \"/home/benjs/Documents/projects/hpe/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\", line 889, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/home/benjs/Documents/projects/hpe/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\", line 933, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializers)\r\n  File \"/home/benjs/Documents/projects/hpe/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\", line 763, in _initialize\r\n    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n  File \"/home/benjs/Documents/projects/hpe/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3050, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/home/benjs/Documents/projects/hpe/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3444, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/home/benjs/Documents/projects/hpe/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3279, in _create_graph_function\r\n    func_graph_module.func_graph_from_py_func(\r\n  File \"/home/benjs/Documents/projects/hpe/venv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 999, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/home/benjs/Documents/projects/hpe/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\", line 672, in wrapped_fn\r\n    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/home/benjs/Documents/projects/hpe/venv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 986, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nTypeError: in user code:\r\n\r\n    /home/benjs/Documents/projects/hpe/venv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\r\n        return step_function(self, iterator)\r\n    /home/benjs/Documents/projects/hpe/hourglass/models.py:88 call  *\r\n        out = layer(out)\r\n    /home/benjs/Documents/projects/hpe/venv/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1023 __call__  **\r\n        self._maybe_build(inputs)\r\n    /home/benjs/Documents/projects/hpe/venv/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:2625 _maybe_build\r\n        self.build(input_shapes)  # pylint:disable=not-callable\r\n    /home/benjs/Documents/projects/hpe/venv/lib/python3.9/site-packages/tensorflow/python/keras/layers/convolutional.py:187 build\r\n        input_channel = self._get_input_channel(input_shape)\r\n    /home/benjs/Documents/projects/hpe/venv/lib/python3.9/site-packages/tensorflow/python/keras/layers/convolutional.py:365 _get_input_channel\r\n        if input_shape.dims[channel_axis].value is None:\r\n\r\n    TypeError: 'NoneType' object is not subscriptable\r\n```\r\n**Code**\r\nThis works for me:\r\n```\r\n    for epoch in range(epochs):\r\n        for step, (x, y) in enumerate(train_ds):\r\n            with tf.GradientTape() as tape:\r\n                heatmap_predictions = model(x, training=True)\r\n                loss_value = loss_fn(y, heatmap_predictions)\r\n\r\n            grads = tape.gradient(loss_value, model.trainable_weights)\r\n            optimizer.apply_gradients(zip(grads, model.trainable_weights))\r\n\r\n            print(f\"\\rEpoch {epoch+1}/{epochs}, Step {step}, Loss {float(loss_value)}\", end='',\r\n                  flush=True)\r\n```\r\n\r\nThis throws the error above:\r\n```\r\nmodel.compile(optimizer=optimizer, loss=loss_fn)\r\nmodel.fit(x=train_ds, epochs=epochs)\r\n```"]}, {"number": 45532, "title": "report error \"tensorflow.python.framework.errors_impl.InvalidArgumentError \"when visit dataset", "body": "version: 2.3.0\r\nOS\uff1amac\r\n### report error \"tensorflow.python.framework.errors_impl.InvalidArgumentError \"when visit dataset\r\n### script\uff1a\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\nimport tensorflow as tf\r\n\r\nimport IPython.display as display\r\nfrom PIL import Image\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport pathlib\r\n\r\n\r\nAUTOTUNE = tf.data.experimental.AUTOTUNE\r\n\r\ndata_dir = tf.keras.utils.get_file(origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\r\n                                         fname='flower_photos', untar=True)\r\n\r\ndata_dir = pathlib.Path(data_dir)\r\nprint(\"data_dir:\",data_dir)\r\n\r\nimage_list = list(data_dir.glob('*/*.jpg'))\r\nimage_count = len(image_list)\r\nprint(\"image_count:\",image_count)\r\n\r\n\r\nCLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"])\r\nprint(\"CLASS_NAMES:\",CLASS_NAMES)\r\n\r\n\r\n\r\n\r\nimage_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\r\n\r\nBATCH_SIZE = 32\r\nIMG_HEIGHT = 224\r\nIMG_WIDTH = 224\r\nSTEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)\r\n\r\n\r\ntrain_data_gen = image_generator.flow_from_directory(directory=str(data_dir),\r\n                                                     batch_size=BATCH_SIZE,\r\n                                                     shuffle=True,\r\n                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\r\n                                                     classes = list(CLASS_NAMES))\r\n\r\n\r\nlist_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'))\r\n\r\ndef get_label(file_path):\r\n    # convert the path to a list of path components\r\n    parts = tf.strings.split(file_path, '\\\\')\r\n    print(\"+++++\",parts)\r\n    # The second to last is the class-directory\r\n    return parts[-2] == CLASS_NAMES\r\n\r\n\r\ndef decode_img(img):\r\n    # convert the compressed string to a 3D uint8 tensor\r\n    img = tf.image.decode_jpeg(img, channels=3)\r\n    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\r\n    img = tf.image.convert_image_dtype(img, tf.float32)\r\n    # resize the image to the desired size.\r\n    return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\r\n\r\n\r\ndef process_path(file_path):\r\n    label = get_label(file_path)\r\n    # load the raw data from the file as a string\r\n    img = tf.io.read_file(file_path)\r\n    img = decode_img(img)\r\n    return img, label\r\n\r\n\r\nlabeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\r\n\r\nprint(labeled_ds)\r\n\r\nfor image, label in labeled_ds:\r\n    print(\"Image shape: \", image.numpy().shape)\r\n    print(\"Label: \", label.numpy())\r\n\r\n### Full error message\uff1a\r\n<ParallelMapDataset shapes: ((224, 224, 3), (5,)), types: (tf.float32, tf.bool)>\r\n2020-12-09 10:57:39.973749: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index -1 of dimension 0 out of bounds.\r\n2020-12-09 10:57:39.973883: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index -1 of dimension 0 out of bounds.\r\n2020-12-09 10:57:39.973962: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index -1 of dimension 0 out of bounds.\r\n2020-12-09 10:57:39.974040: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index -1 of dimension 0 out of bounds.\r\n2020-12-09 10:57:39.974411: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index -1 of dimension 0 out of bounds.\r\nTraceback (most recent call last):\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/context.py\", line 2102, in execution_mode\r\n    yield\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 758, in _next_internal\r\n    output_shapes=self._flat_output_shapes)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 2610, in iterator_get_next\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 6843, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: slice index -1 of dimension 0 out of bounds.\r\n         [[{{node strided_slice}}]] [Op:IteratorGetNext]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/dingjiawei/Desktop/daily_demo/load_image_data/tensorflow2.0_load_data.py\", line 85, in <module>\r\n    for image, label in labeled_ds:\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 736, in __next__\r\n    return self.next()\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 772, in next\r\n    return self._next_internal()\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 764, in _next_internal\r\n    return structure.from_compatible_tensor_list(self._element_spec, ret)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py\", line 130, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/context.py\", line 2105, in execution_mode\r\n    executor_new.wait()\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/executor.py\", line 67, in wait\r\n    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: slice index -1 of dimension 0 out of bounds.\r\n         [[{{node strided_slice}}]]\r\n\r\nI don't know what this error mean, and how to sovle it. please help me to check it. thank you ~", "comments": ["@dingjiaweiww,\r\nOn changing the line `parts = tf.strings.split(file_path, '\\\\')` to `parts = tf.strings.split(file_path,sep=\"/\")` in the `get_label` method, I was able to run the code without any issues.\r\n\r\nPlease find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/11f168001c0a9eb45175b2cba92e4cc7/45532-v2.ipynb). Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45532\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45532\">No</a>\n"]}, {"number": 45531, "title": "Don\u2019t try to build compiled metrics, when loading the model", "body": "Currently, the user can pass the strings to the metrics argument in `Model.compile` function, and convert it to one of `tf.keras.metrics` classes based on y_true shape and y_pred shape(In function `MetricsContainer._get_metric_object`). \r\n\r\nThis feature brings us convenience, but when the user saves the model and loads it, the model is compiled by default, and at the same time, it tries to build the compiled metrics. But when the compiled metrics are built, only the output shape of the model is used to guess which metric class the user wants to use, which brings surprises. The current examples are sparse categorical accuracy and sparse categorical cross-entropy. \r\n\r\nHere is the small demo to reproduce the problem. I have encountered this problem. I always thought that the performance of the model was not good, but I did not expect the metric class to be wrong.\r\n\r\n```python\r\n# TensorFlow and tf.keras\r\nimport tensorflow as tf\r\n\r\n# Helper libraries\r\nimport numpy as np\r\n\r\nprint(tf.__version__)\r\n\r\nfashion_mnist = tf.keras.datasets.fashion_mnist\r\n\r\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\r\n\r\nmodel = tf.keras.Sequential([\r\n    tf.keras.layers.Flatten(input_shape=(28, 28)),\r\n    tf.keras.layers.Dense(128, activation='relu'),\r\n    tf.keras.layers.Dense(10)\r\n])\r\n\r\nmodel.compile(optimizer='adam',\r\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n              metrics=['accuracy'])\r\n\r\nmodel.fit(train_images, train_labels, epochs=1)\r\n\r\ntest_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\r\n\r\nmodel.save('model.h5')\r\n\r\nmodel = tf.keras.models.load_model('model.h5')\r\n\r\ntest_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\r\n\r\nmodel = tf.keras.models.load_model('model.h5', compile=False)\r\n\r\nmodel.compile(optimizer='adam',\r\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n              metrics=['accuracy'])\r\n\r\ntest_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\r\n```\r\n```\r\n1875/1875 [==============================] - 2s 1ms/step - loss: 3.1409 - accuracy: 0.6773\r\n313/313 - 0s - loss: 0.8313 - accuracy: 0.7169\r\n313/313 - 0s - loss: 0.8313 - accuracy: 0.1098\r\n313/313 - 0s - loss: 0.8313 - accuracy: 0.7169\r\n```\r\n\r\nI also found that some users have encountered this \"surprise\" #43230", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F45531) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "The most direct way is to comment `model.compile metrics.build(model.outputs, model.outputs)`. I didn\u2019t go deep into why it needs to try to build at this time, so I just deleted them.", "Thanks for the PR, although this bug has been fixed in the latest release of TensorFlow: 5adacc88077ef82f6c4a7f9bb65f9ed89f9d8947\r\n"]}, {"number": 45530, "title": "Prevent unitialized memory access in `GraphConstructor::MakeEdge`", "body": "The `MakeEdge` implementation assumes that there exists an output at `output_index` of `src` node and an input at `input_index` of `dst` node. However, if this is not the case this results in accessing data out of bounds. Because we are accessing an array that is a private member of a class and only in read only mode, this usually results only in unitialized memory access. However, it is reasonable to think that malicious users could manipulate these indexes to actually read data outside the class, thus resulting in information leakage and further exploits.\r\n\r\nPiperOrigin-RevId: 346343288\r\nChange-Id: I2127da27c2023d27f26efd39afa6c853385cab6f", "comments": []}, {"number": 45529, "title": "Prevent CHECK-fail in LSTM/GRU with zero-length input.", "body": "PiperOrigin-RevId: 346239181\r\nChange-Id: I5f233dbc076aab7bb4e31ba24f5abd4eaf99ea4f", "comments": []}, {"number": 45528, "title": "Mark `MemmappedTensorAllocator` as returning opaque handle.", "body": "This allocator is used for `ImmutableConstantOp` and it returns a handle to the contents of a memory mapped file which is supposed to represent a tensor.\r\n\r\nFor tensors of complex types (resources, variables and strings), allocators which are not marked as returning opaque handles will call placement new to initialize each element. This means writing to the buffer. However, in our case, the buffer is immutable and already contains the tensor data. Hence, writing to it is both destructive and causes a crash.\r\n\r\nPiperOrigin-RevId: 345786451\r\nChange-Id: I46369c50fa60b3431709ffe068a728d3061f49c4", "comments": []}, {"number": 45527, "title": "Validate that `DataFormat*` attributes form a permutation.", "body": "The `src_format` and `dst_format` attributes for the `DataFormatDimMap` and `DataFormatVecPermute` raw ops are supposed to determine a permutation. However, this was not validated and could result in unitialized memory accesses as well as writes outside of bounds and potential crashes.\r\n\r\nWhile here, we also test that the format attributes have the needed length, add tests for all validation failure cases, remove unnecessary calls to `strings::StrCat`, and fix a few grammar errors.\r\n\r\nThis will be cherry-picked on the supported release branches.\r\n\r\nPiperOrigin-RevId: 346135579\r\nChange-Id: I1c76392382c89ad8f072d5bc93d70669851eb404", "comments": []}, {"number": 45526, "title": "Default initialize fixed point Eigen types.", "body": "In certain cases, tensors are filled with default values of the type. But, for these fixed point types, these values were uninitialized. Thus, we would have uninitialized memory access bugs, some of which were caught by MSAN.\r\n\r\nPiperOrigin-RevId: 344101137\r\nChange-Id: I14555fda74dca3b5f1582da9008901937e3f14e2", "comments": []}, {"number": 45525, "title": "Prevent unitialized memory access in `GraphConstructor::MakeEdge`", "body": "The `MakeEdge` implementation assumes that there exists an output at `output_index` of `src` node and an input at `input_index` of `dst` node. However, if this is not the case this results in accessing data out of bounds. Because we are accessing an array that is a private member of a class and only in read only mode, this usually results only in unitialized memory access. However, it is reasonable to think that malicious users could manipulate these indexes to actually read data outside the class, thus resulting in information leakage and further exploits.\r\n\r\nPiperOrigin-RevId: 346343288\r\nChange-Id: I2127da27c2023d27f26efd39afa6c853385cab6f", "comments": []}, {"number": 45524, "title": "Prevent CHECK-fail in LSTM/GRU with zero-length input.", "body": "PiperOrigin-RevId: 346239181\r\nChange-Id: I5f233dbc076aab7bb4e31ba24f5abd4eaf99ea4f", "comments": []}, {"number": 45523, "title": "Mark `MemmappedTensorAllocator` as returning opaque handle.", "body": "This allocator is used for `ImmutableConstantOp` and it returns a handle to the contents of a memory mapped file which is supposed to represent a tensor.\r\n\r\nFor tensors of complex types (resources, variables and strings), allocators which are not marked as returning opaque handles will call placement new to initialize each element. This means writing to the buffer. However, in our case, the buffer is immutable and already contains the tensor data. Hence, writing to it is both destructive and causes a crash.\r\n\r\nPiperOrigin-RevId: 345786451\r\nChange-Id: I46369c50fa60b3431709ffe068a728d3061f49c4", "comments": []}, {"number": 45522, "title": "Validate that `DataFormat*` attributes form a permutation.", "body": "The `src_format` and `dst_format` attributes for the `DataFormatDimMap` and `DataFormatVecPermute` raw ops are supposed to determine a permutation. However, this was not validated and could result in unitialized memory accesses as well as writes outside of bounds and potential crashes.\r\n\r\nWhile here, we also test that the format attributes have the needed length, add tests for all validation failure cases, remove unnecessary calls to `strings::StrCat`, and fix a few grammar errors.\r\n\r\nThis will be cherry-picked on the supported release branches.\r\n\r\nPiperOrigin-RevId: 346135579\r\nChange-Id: I1c76392382c89ad8f072d5bc93d70669851eb404", "comments": []}, {"number": 45521, "title": "Default initialize fixed point Eigen types.", "body": "In certain cases, tensors are filled with default values of the type. But, for these fixed point types, these values were uninitialized. Thus, we would have uninitialized memory access bugs, some of which were caught by MSAN.\r\n\r\nPiperOrigin-RevId: 344101137\r\nChange-Id: I14555fda74dca3b5f1582da9008901937e3f14e2", "comments": []}, {"number": 45520, "title": "Prevent unitialized memory access in `GraphConstructor::MakeEdge`", "body": "The `MakeEdge` implementation assumes that there exists an output at `output_index` of `src` node and an input at `input_index` of `dst` node. However, if this is not the case this results in accessing data out of bounds. Because we are accessing an array that is a private member of a class and only in read only mode, this usually results only in unitialized memory access. However, it is reasonable to think that malicious users could manipulate these indexes to actually read data outside the class, thus resulting in information leakage and further exploits.\r\n\r\nPiperOrigin-RevId: 346343288\r\nChange-Id: I2127da27c2023d27f26efd39afa6c853385cab6f", "comments": []}, {"number": 45519, "title": "Prevent CHECK-fail in LSTM/GRU with zero-length input.", "body": "PiperOrigin-RevId: 346239181\r\nChange-Id: I5f233dbc076aab7bb4e31ba24f5abd4eaf99ea4f", "comments": []}, {"number": 45518, "title": "Mark `MemmappedTensorAllocator` as returning opaque handle.", "body": "This allocator is used for `ImmutableConstantOp` and it returns a handle to the contents of a memory mapped file which is supposed to represent a tensor.\r\n\r\nFor tensors of complex types (resources, variables and strings), allocators which are not marked as returning opaque handles will call placement new to initialize each element. This means writing to the buffer. However, in our case, the buffer is immutable and already contains the tensor data. Hence, writing to it is both destructive and causes a crash.\r\n\r\nPiperOrigin-RevId: 345786451\r\nChange-Id: I46369c50fa60b3431709ffe068a728d3061f49c4", "comments": []}, {"number": 45517, "title": "Validate that `DataFormat*` attributes form a permutation.", "body": "The `src_format` and `dst_format` attributes for the `DataFormatDimMap` and `DataFormatVecPermute` raw ops are supposed to determine a permutation. However, this was not validated and could result in unitialized memory accesses as well as writes outside of bounds and potential crashes.\r\n\r\nWhile here, we also test that the format attributes have the needed length, add tests for all validation failure cases, remove unnecessary calls to `strings::StrCat`, and fix a few grammar errors.\r\n\r\nThis will be cherry-picked on the supported release branches.\r\n\r\nPiperOrigin-RevId: 346135579\r\nChange-Id: I1c76392382c89ad8f072d5bc93d70669851eb404", "comments": []}, {"number": 45516, "title": "Default initialize fixed point Eigen types.", "body": "In certain cases, tensors are filled with default values of the type. But, for these fixed point types, these values were uninitialized. Thus, we would have uninitialized memory access bugs, some of which were caught by MSAN.\r\n\r\nPiperOrigin-RevId: 344101137\r\nChange-Id: I14555fda74dca3b5f1582da9008901937e3f14e2", "comments": []}, {"number": 45515, "title": "Prevent unitialized memory access in `GraphConstructor::MakeEdge`", "body": "The `MakeEdge` implementation assumes that there exists an output at `output_index` of `src` node and an input at `input_index` of `dst` node. However, if this is not the case this results in accessing data out of bounds. Because we are accessing an array that is a private member of a class and only in read only mode, this usually results only in unitialized memory access. However, it is reasonable to think that malicious users could manipulate these indexes to actually read data outside the class, thus resulting in information leakage and further exploits.\r\n\r\nPiperOrigin-RevId: 346343288\r\nChange-Id: I2127da27c2023d27f26efd39afa6c853385cab6f", "comments": []}, {"number": 45514, "title": "Prevent CHECK-fail in LSTM/GRU with zero-length input.", "body": "PiperOrigin-RevId: 346239181\r\nChange-Id: I5f233dbc076aab7bb4e31ba24f5abd4eaf99ea4f", "comments": []}, {"number": 45513, "title": "Mark `MemmappedTensorAllocator` as returning opaque handle.", "body": "This allocator is used for `ImmutableConstantOp` and it returns a handle to the contents of a memory mapped file which is supposed to represent a tensor.\r\n\r\nFor tensors of complex types (resources, variables and strings), allocators which are not marked as returning opaque handles will call placement new to initialize each element. This means writing to the buffer. However, in our case, the buffer is immutable and already contains the tensor data. Hence, writing to it is both destructive and causes a crash.\r\n\r\nPiperOrigin-RevId: 345786451\r\nChange-Id: I46369c50fa60b3431709ffe068a728d3061f49c4", "comments": []}, {"number": 45512, "title": "Validate that `DataFormat*` attributes form a permutation.", "body": "The `src_format` and `dst_format` attributes for the `DataFormatDimMap` and `DataFormatVecPermute` raw ops are supposed to determine a permutation. However, this was not validated and could result in unitialized memory accesses as well as writes outside of bounds and potential crashes.\r\n\r\nWhile here, we also test that the format attributes have the needed length, add tests for all validation failure cases, remove unnecessary calls to `strings::StrCat`, and fix a few grammar errors.\r\n\r\nThis will be cherry-picked on the supported release branches.\r\n\r\nPiperOrigin-RevId: 346135579\r\nChange-Id: I1c76392382c89ad8f072d5bc93d70669851eb404", "comments": []}, {"number": 45511, "title": "Default initialize fixed point Eigen types.", "body": "In certain cases, tensors are filled with default values of the type. But, for these fixed point types, these values were uninitialized. Thus, we would have uninitialized memory access bugs, some of which were caught by MSAN.\r\n\r\nPiperOrigin-RevId: 344101137\r\nChange-Id: I14555fda74dca3b5f1582da9008901937e3f14e2", "comments": []}, {"number": 45510, "title": "When installed by pip, dependencies' versions are not fixed.", "body": "**System information**\r\n- OS Platform and Distribution: window & linux\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: 1.13, 1.14\r\n- Python version: 3.6.8\r\n- Installed using virtualenv? pip? conda?: pip\r\n\r\n**Describe the problem**\r\ngrpcio>=1.8.6 has been installed, which is always the newest one: eg. 1.34.0; however grpcio~=1.32.0 is expected\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\npip install tensorflow-gpu", "comments": ["@luciencho \r\nPlease verify your pip version if it is the latest.\r\nThere is no support for 1.x, please upgrade to 2.x and share the complete error log in case you face issues with 2.x.\r\nyou may refer to [pip install tensorflow gpu](https://github.com/tensorflow/tensorflow/issues/42367) similar issue.", "It is a tf 1.x problem.\r\nAfter updating pip, the problem remains unsolved. I was just wondering why grpcio>=1.8.6 has been installed. [code](https://github.com/tensorflow/tensorflow/blob/r1.14/tensorflow/tools/ci_build/install/install_python3.6_pip_packages.sh) does not make sense to me. ", "@luciencho\r\nThere is no support for 1.x, please upgrade to 2.x and share the complete error log in case you face issues with 2.x.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45510\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45510\">No</a>\n"]}, {"number": 45509, "title": "Prevent unitialized memory access in `GraphConstructor::MakeEdge`", "body": "The `MakeEdge` implementation assumes that there exists an output at `output_index` of `src` node and an input at `input_index` of `dst` node. However, if this is not the case this results in accessing data out of bounds. Because we are accessing an array that is a private member of a class and only in read only mode, this usually results only in unitialized memory access. However, it is reasonable to think that malicious users could manipulate these indexes to actually read data outside the class, thus resulting in information leakage and further exploits.\r\n\r\nPiperOrigin-RevId: 346343288\r\nChange-Id: I2127da27c2023d27f26efd39afa6c853385cab6f", "comments": []}, {"number": 45508, "title": "Prevent CHECK-fail in LSTM/GRU with zero-length input.", "body": "PiperOrigin-RevId: 346239181\r\nChange-Id: I5f233dbc076aab7bb4e31ba24f5abd4eaf99ea4f", "comments": []}, {"number": 45507, "title": "Mark `MemmappedTensorAllocator` as returning opaque handle.", "body": "This allocator is used for `ImmutableConstantOp` and it returns a handle to the contents of a memory mapped file which is supposed to represent a tensor.\r\n\r\nFor tensors of complex types (resources, variables and strings), allocators which are not marked as returning opaque handles will call placement new to initialize each element. This means writing to the buffer. However, in our case, the buffer is immutable and already contains the tensor data. Hence, writing to it is both destructive and causes a crash.\r\n\r\nPiperOrigin-RevId: 345786451\r\nChange-Id: I46369c50fa60b3431709ffe068a728d3061f49c4", "comments": []}, {"number": 45506, "title": "Validate that `DataFormat*` attributes form a permutation.", "body": "The `src_format` and `dst_format` attributes for the `DataFormatDimMap` and `DataFormatVecPermute` raw ops are supposed to determine a permutation. However, this was not validated and could result in unitialized memory accesses as well as writes outside of bounds and potential crashes.\r\n\r\nWhile here, we also test that the format attributes have the needed length, add tests for all validation failure cases, remove unnecessary calls to `strings::StrCat`, and fix a few grammar errors.\r\n\r\nThis will be cherry-picked on the supported release branches.\r\n\r\nPiperOrigin-RevId: 346135579\r\nChange-Id: I1c76392382c89ad8f072d5bc93d70669851eb404", "comments": []}, {"number": 45505, "title": "Default initialize fixed point Eigen types.", "body": "In certain cases, tensors are filled with default values of the type. But, for these fixed point types, these values were uninitialized. Thus, we would have uninitialized memory access bugs, some of which were caught by MSAN.\r\n\r\nPiperOrigin-RevId: 344101137\r\nChange-Id: I14555fda74dca3b5f1582da9008901937e3f14e2", "comments": []}, {"number": 45504, "title": "Bus error when load the tflite model", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): N/A\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux 4.14.119\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): Installed tflite runtime from source code.\r\n- TensorFlow version (use command below): 2.3.0\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): 3.1.0\r\n- GCC/Compiler version (if compiling from source): 8.3\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\nI have enable the FlexDelegate and compiled the tflite runtime code by using the below command for ARM 32bit machine, the wheel file is created and I have installed it in my machine. But when I load the .tflite model, I am getting the Bus error. But, I didn't got this \"Bus error\" when I use the same wheel file in Raspberry Pi, it is working fine in the Raspberry Pi(ARM 32bit).\r\n\r\nBefore enable the FlexDelegate I didn't got this Bus error while load the tflite model, but that time I got the below RuntimeError.\r\nRuntimeError: Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.Node number 16 (FlexMul) failed to prepare.\r\n\r\nNote: Actually my machine is the aarm64 64bit machine, but due to some build restrictions I am using the 32bit applications in my machine.\r\n\r\n**Command used for compilation:**\r\nCI_DOCKER_EXTRA_PARAMS=\"-e CUSTOM_BAZEL_FLAGS=--define=tflite_pip_with_flex=true -e CI_BUILD_PYTHON=python3 -e CROSSTOOL_PYTHON_INCLUDE_PATH=/usr/include/python3.7\" tensorflow/tools/ci_build/ci_build.sh PI-PYTHON37 tensorflow/lite/tools/pip_package/build_pip_package_with_bazel.sh armhf\r\n\r\n**Other info / logs**\r\nI ran the code by using gdb and got the below back trace.\r\n\r\nINFO: Created TensorFlow Lite delegate for select TF ops.\r\n[New Thread 0xebc59460 (LWP 1157)]\r\n[New Thread 0xeb458460 (LWP 1158)]\r\n[New Thread 0xeaa57460 (LWP 1159)]\r\n[New Thread 0xea0ff460 (LWP 1160)]\r\n[New Thread 0xe94ff460 (LWP 1161)]\r\n\r\nThread 2 \"python3\" received signal SIGBUS, Bus error.\r\n[Switching to Thread 0xebc59460 (LWP 1157)]\r\n0xf642d574 in std::condition_variable::condition_variable (this=0xea10075c)\r\n    at /tmp/dgboter/bbs/rhev-vm8--rhe6x86_64/buildbot/rhe6x86_64--arm-linux-gnueabihf/build/build-arm-linux-gnueabihf/obj/gcc3/arm-linux-gnueabihf/libstdc++-v3/include/condition_variable:65\r\n65\t/tmp/dgboter/bbs/rhev-vm8--rhe6x86_64/buildbot/rhe6x86_64--arm-linux-gnueabihf/build/build-arm-linux-gnueabihf/obj/gcc3/arm-linux-gnueabihf/libstdc++-v3/include/condition_variable: No such file or directory.\r\n(gdb) bt\r\n#0  0xf642d574 in std::condition_variable::condition_variable (this=0xea10075c)\r\n    at /tmp/dgboter/bbs/rhev-vm8--rhe6x86_64/buildbot/rhe6x86_64--arm-linux-gnueabihf/build/build-arm-linux-gnueabihf/obj/gcc3/arm-linux-gnueabihf/libstdc++-v3/include/condition_variable:65\r\n#1  0xf4df5a24 in nsync::nsync_mu_semaphore_init(nsync::nsync_semaphore_s_*) ()\r\n   from /usr/lib/python3.7/site-packages/tflite_runtime/_pywrap_tensorflow_interpreter_wrapper.so\r\nBacktrace stopped: previous frame identical to this frame (corrupt stack?)\r\n(gdb) ", "comments": ["What's the target OS? Is it Raspberry Pi OS?\r\nIf it's your custom HW, I think there is an ABI compatibility issue. You can check flags of /proc/cpuinfo.\r\nFYI, we only have tested ARM with Raspberry Pi OS, Ubuntu Server for ARM, Coral.", "Target OS: Linux 4.14.119\r\n\r\nroot@as371:~$cat /proc/cpuinfo\r\nprocessor\t: 0\r\nBogoMIPS\t: 50.00\r\nFeatures\t: fp asimd aes pmull sha1 sha2 crc32 cpuid\r\nCPU implementer\t: 0x41\r\nCPU architecture: 8\r\nCPU variant\t: 0x0\r\nCPU part\t: 0xd03\r\nCPU revision\t: 4\r\n\r\nprocessor\t: 1\r\nBogoMIPS\t: 50.00\r\nFeatures\t: fp asimd aes pmull sha1 sha2 crc32 cpuid\r\nCPU implementer\t: 0x41\r\nCPU architecture: 8\r\nCPU variant\t: 0x0\r\nCPU part\t: 0xd03\r\nCPU revision\t: 4\r\n\r\nprocessor\t: 2\r\nBogoMIPS\t: 50.00\r\nFeatures\t: fp asimd aes pmull sha1 sha2 crc32 cpuid\r\nCPU implementer\t: 0x41\r\nCPU architecture: 8\r\nCPU variant\t: 0x0\r\nCPU part\t: 0xd03\r\nCPU revision\t: 4\r\n\r\nprocessor\t: 3\r\nBogoMIPS\t: 50.00\r\nFeatures\t: fp asimd aes pmull sha1 sha2 crc32 cpuid\r\nCPU implementer\t: 0x41\r\nCPU architecture: 8\r\nCPU variant\t: 0x0\r\nCPU part\t: 0xd03\r\nCPU revision\t: 4\r\n\r\nroot@as371:~$\r\n", "Hi, how to check the flags of /proc/cpuinfo to find is it really ABI compatibility issue or not? If it is an ABI compatibility issue, how to fix this ?", "TF's armhf toolchain compiles ARMv7 binary with NEON and VFP supports which are missing from yours.\r\n\r\nFYI, this is RPI3's.\r\n```\r\nprocessor\t: 0\r\nmodel name\t: ARMv7 Processor rev 4 (v7l)\r\nBogoMIPS\t: 38.40\r\nFeatures\t: half thumb fastmult vfp edsp neon vfpv3 tls vfpv4 idiva idivt vfpd32 lpae evtstrm crc32 \r\nCPU implementer\t: 0x41\r\nCPU architecture: 7\r\nCPU variant\t: 0x0\r\nCPU part\t: 0xd03\r\nCPU revision\t: 4\r\n```\r\n\r\nAlso you can check ABI of binary with readelf.\r\n```\r\n$ readelf -A benchmark_model\r\nAttribute Section: aeabi\r\nFile Attributes\r\n  Tag_CPU_name: \"7-A\"\r\n  Tag_CPU_arch: v7\r\n  Tag_CPU_arch_profile: Application\r\n  Tag_ARM_ISA_use: Yes\r\n  Tag_THUMB_ISA_use: Thumb-2\r\n  Tag_FP_arch: VFPv3\r\n  Tag_Advanced_SIMD_arch: NEONv1\r\n  Tag_ABI_PCS_wchar_t: 4\r\n  Tag_ABI_FP_rounding: Needed\r\n  Tag_ABI_FP_denormal: Needed\r\n  Tag_ABI_FP_exceptions: Needed\r\n  Tag_ABI_FP_number_model: IEEE 754\r\n  Tag_ABI_align_needed: 8-byte\r\n  Tag_ABI_enum_size: int\r\n  Tag_ABI_VFP_args: VFP registers\r\n  Tag_CPU_unaligned_access: v6\r\n```\r\nYou can compare it with yours.\r\n\r\nYou might want to add some GCC options to CUSTOM_BAZEL_FLAGS to make it compatible with your target hw.\r\nhttps://gcc.gnu.org/onlinedocs/gcc/ARM-Options.html\r\n\r\n", "Hi, I got the below information in my benchmark_model and tflite runtime .so file, this looks similar to yours. \r\n\r\nI saw the \"--define=raspberry_pi_with_neon=true\" in BAZEL_FLAGS, what is the use of this flag? Is this enabling something specific to Raspberry Pi? Are we also need to enable something like that?\r\n\r\nWe are using cortex-A53 ARM64 machine, but we are using 32bit applications because of some build restrictions. In our /proc/cpuinfo we have the \"asimd\", \"asimd\" is the \"neon\" equivalent in ARM Cortex A53.\r\n\r\n$ readelf -A benchmark_model \r\nAttribute Section: aeabi\r\nFile Attributes\r\n  Tag_CPU_name: \"7-A\"\r\n  Tag_CPU_arch: v7\r\n  Tag_CPU_arch_profile: Application\r\n  Tag_ARM_ISA_use: Yes\r\n  Tag_THUMB_ISA_use: Thumb-2\r\n  Tag_FP_arch: VFPv3\r\n  Tag_Advanced_SIMD_arch: NEONv1\r\n  Tag_ABI_PCS_wchar_t: 4\r\n  Tag_ABI_FP_rounding: Needed\r\n  Tag_ABI_FP_denormal: Needed\r\n  Tag_ABI_FP_exceptions: Needed\r\n  Tag_ABI_FP_number_model: IEEE 754\r\n  Tag_ABI_align_needed: 8-byte\r\n  Tag_ABI_align_preserved: 8-byte, except leaf SP\r\n  Tag_ABI_enum_size: int\r\n  Tag_ABI_VFP_args: VFP registers\r\n  Tag_CPU_unaligned_access: v6\r\n\r\n\r\n$ readelf -A _pywrap_tensorflow_interpreter_wrapper.so \r\nAttribute Section: aeabi\r\nFile Attributes\r\n  Tag_CPU_name: \"7-A\"\r\n  Tag_CPU_arch: v7\r\n  Tag_CPU_arch_profile: Application\r\n  Tag_ARM_ISA_use: Yes\r\n  Tag_THUMB_ISA_use: Thumb-2\r\n  Tag_FP_arch: VFPv4\r\n  Tag_Advanced_SIMD_arch: NEONv1 with Fused-MAC\r\n  Tag_ABI_PCS_wchar_t: 4\r\n  Tag_ABI_FP_rounding: Needed\r\n  Tag_ABI_FP_denormal: Needed\r\n  Tag_ABI_FP_exceptions: Needed\r\n  Tag_ABI_FP_number_model: IEEE 754\r\n  Tag_ABI_align_needed: 8-byte\r\n  Tag_ABI_align_preserved: 8-byte, except leaf SP\r\n  Tag_ABI_enum_size: int\r\n  Tag_ABI_VFP_args: VFP registers\r\n  Tag_CPU_unaligned_access: v6", "Hi, initially I got the below RuntimeError when load the tflite model, so I have enabled the FlexDelegate. Is the below \"FlexMul\" feature requires VFP (or) NEON support? And Is it possible to compile the tflite runtime only with the below \"FlexMul\" Flex delegate feature?\r\n\r\n\r\nRuntimeError: Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.Node number 16 (FlexMul) failed to prepare\r\n", "https://www.tensorflow.org/lite/guide/reduce_binary_size may be helpful.", "I am still getting the bus error. I am trying to run a .tflite model for ASR which I got from another company on Synaptics based Arm platform. It is Cortex A53 but we are using armv7a ISA and building 32-bit binaries. \r\n\r\nThe ASR code requires tflite_runtime to be enabled with \"flex delegate\" which causes the crash on my embedded target but it works on Raspberry PI board. When the tflite_runtime is built with \"flex delegate\" option for PI, I saw the \"--define=raspberry_pi_with_neon=true\" in BAZEL_FLAGS. I tried enabling and disabling this flag while building for my target board, but it still crashes. I am wondering what else can be tried out. Could you please suggest?\r\n ", "Using Flex op requires to build TF op kernels which is difficult to support various targets.\r\nIf the required Flex op is only FlexMul, I think you might be able to create Flex-free ASR model with some refactoring.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45504\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45504\">No</a>\n"]}]