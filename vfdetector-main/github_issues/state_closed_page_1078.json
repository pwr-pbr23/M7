[{"number": 20934, "title": "Add additional shape validation for QuantizedAdd", "body": "This fix add additional shape validation for QuantizedAdd\r\nwith min_x, min_y, max_x, max_y.\r\n\r\nAdditional unit tests have been added in math_ops_test.cc.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 20933, "title": "Update install_pip_packages.sh", "body": "Install h5py to fix a mac release build issue.", "comments": []}, {"number": 20932, "title": "Remove usage of remove_undocumented from core parallel_for.", "body": "remove_undocumented is causing issues with our pip tests.\r\nremove_undocumented is not used anywhere else in core TF code\r\nand we have a new mechanism for annotating the public TF API.", "comments": ["This needs to be cherry-picked to 1.10 after making it into master.", "drpngx, gunan mentioned you have some more context about what exactly remove_undocumented is? I assume this is safe to remove, but please tell me if otherwise. Thanks!", "I think we completely got rid of it.", "As long as you have the `@tf.export{'foo'}` you should be fine."]}, {"number": 20931, "title": "Fix tf_trt_integration_test in py3", "body": "", "comments": ["@yifeif it seems the approval doesn't take effect."]}, {"number": 20930, "title": "Reinitializable iterator doesn't use cached dataset upon reinitializing", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, written custom code\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 8.1\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.8.0\r\n- **Python version**: 3.6.5\r\n- **Bazel version**: N/A\r\n- **CUDA/cuDNN version**: CUDA 9.0, cuDNN v7.0\r\n- **GPU model and memory**: NVIDIA GeForce GTX 960 (faced the same problem with 1080 Ti)\r\n- **Exact command to reproduce**: see below\r\n\r\n### Describe the problem\r\nFound a likely bug when using a reinitialiable iterator with a cached dataset. Upon reinitializing the iterator, the iterator does not use the cached dataset. This can be verified using the sample code below.\r\n\r\n### Source code\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport time\r\n\r\nLENGTH = 3\r\nCACHE = True\r\nVERBOSE = True\r\nSHAPE = (1,)\r\n\r\ndef data_generator():    \r\n    for n in range(LENGTH):\r\n        data = np.random.rand(*SHAPE)\r\n        yield data\r\n\r\ndef get_dataset():\r\n    train_data = tf.data.Dataset.from_generator(data_generator, output_types=tf.float32)\r\n    if CACHE:\r\n        train_data = train_data.cache()\r\n    return train_data\r\n\r\ndef get_dataset_repeat():\r\n    train_data = tf.data.Dataset.from_generator(data_generator, output_types=tf.float32)\r\n    if CACHE:\r\n        train_data = train_data.cache()\r\n    train_data = train_data.repeat()\r\n    return train_data\r\n\r\ndata = get_dataset()\r\ndata_repeat = get_dataset_repeat()\r\n\r\niterator = tf.data.Iterator.from_structure(data.output_types, data.output_shapes)\r\nnext_element = iterator.get_next()\r\n\r\ndata_init = iterator.make_initializer(data)\r\ndata_init_repeat = iterator.make_initializer(data_repeat)\r\n\r\nsess = tf.Session()\r\n\r\nprint('Reading values from iterator by reinitializing')\r\nepoch = 1\r\n\r\nfor _ in range(5):\r\n    start = time.time()\r\n    sess.run(data_init)\r\n    print('Epoch %d:' % epoch, end=' ')\r\n    for _ in range(LENGTH):\r\n        output = sess.run(next_element)\r\n        \r\n        if VERBOSE:\r\n            print(output, end=' ')\r\n        \r\n    end = time.time()\r\n    print(\"Time taken: %f\" % (end - start))\r\n\r\n    epoch += 1\r\n\r\nprint('Reading values from iterator using repeat')\r\nepoch = 1\r\nsess.run(data_init_repeat)\r\n\r\nfor _ in range(5):\r\n    start = time.time()\r\n    print('Epoch %d:' % epoch, end=' ')\r\n    for _ in range(LENGTH):\r\n        output = sess.run(next_element)\r\n        \r\n        if VERBOSE:\r\n            print(output, end=' ')\r\n\r\n    end = time.time()\r\n    print(\"Time taken: %f\" % (end - start))\r\n    \r\n    epoch += 1\r\n```\r\n\r\nThis code gives the following output:\r\n\r\n> Reading values from iterator by reinitializing\r\n> Epoch 1: [0.00544547] [0.19976228] [0.5371114] Time taken: 0.017011\r\n> Epoch 2: [0.97181207] [0.35276905] [0.69020385] Time taken: 0.003002\r\n> Epoch 3: [0.19892913] [0.2760849] [0.8980513] Time taken: 0.003003\r\n> Epoch 4: [0.92679894] [0.5854017] [0.6552748] Time taken: 0.003002\r\n> Epoch 5: [0.38050508] [0.7676437] [0.41214108] Time taken: 0.003002\r\n> Reading values from iterator using repeat\r\n> Epoch 1: [0.28107443] [0.8882484] [0.59744525] Time taken: 0.003003\r\n> Epoch 2: [0.28107443] [0.8882484] [0.59744525] Time taken: 0.003002\r\n> Epoch 3: [0.28107443] [0.8882484] [0.59744525] Time taken: 0.000000\r\n> Epoch 4: [0.28107443] [0.8882484] [0.59744525] Time taken: 0.001001\r\n> Epoch 5: [0.28107443] [0.8882484] [0.59744525] Time taken: 0.001000\r\n\r\nIn the second case, the same values are printed at every epoch because the iterator uses the cached data. However, in the first case, different values are printed at every epoch - indicating that the iterator does not use the cached values. This can be further verified by looking at the time taken (which will be more prominent with larger data). So in the above code, if I set `LENGTH = 100`, `VERBOSE = False` and `SHAPE = (500, 1000, 3)`, I get the following output:\r\n\r\n> Reading values from iterator by reinitializing\r\n> Epoch 1: Time taken: 2.228584\r\n> Epoch 2: Time taken: 2.182549\r\n> Epoch 3: Time taken: 2.175545\r\n> Epoch 4: Time taken: 2.185551\r\n> Epoch 5: Time taken: 2.161536\r\n> Reading values from iterator using repeat\r\n> Epoch 1: Time taken: 2.147525\r\n> Epoch 2: Time taken: 0.263195\r\n> Epoch 3: Time taken: 0.259186\r\n> Epoch 4: Time taken: 0.266189\r\n> Epoch 5: Time taken: 0.268181\r\n\r\nIn the second case, the first epoch takes considerably longer than the subsequent epochs - understandably, since the further epochs just reuse the cached data. However, in the first case, all the epochs take a long time.\r\n\r\nThis seems like a bug to me because the reinitializable iterator has [been advocated](https://www.tensorflow.org/guide/datasets#creating_an_iterator) as being useful in precisely such kind of situations - when you have 2 different datasets (say training and validation) and you simply reinitialize the iterator to use any one of the two at a time. However, it seems that if I reinitialize the iterator with a cached dataset, I lose the entire advantage of caching. If I set `CACHE = False` with the large shape mentioned above, I get the following output as expected:\r\n\r\n> Reading values from iterator by reinitializing\r\n> Epoch 1: Time taken: 2.317660\r\n> Epoch 2: Time taken: 2.251585\r\n> Epoch 3: Time taken: 2.209581\r\n> Epoch 4: Time taken: 2.151515\r\n> Epoch 5: Time taken: 2.156546\r\n> Reading values from iterator using repeat\r\n> Epoch 1: Time taken: 2.182563\r\n> Epoch 2: Time taken: 2.207575\r\n> Epoch 3: Time taken: 2.205560\r\n> Epoch 4: Time taken: 2.139524\r\n> Epoch 5: Time taken: 2.198561\r\n\r\nThat is, each epoch takes the same time with either method since we don't cache the dataset.", "comments": ["Assigning this one to @saeta, since he is working on a replacement for `Dataset.cache()` that probably ought to support this (especially in eager mode!).", "Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version", "I have updated the description, I'm not sure how to trigger the bot. @shivaniag can you assign the relevant person again - I think it is @saeta as @mrry mentioned. TIA.", "@saeta do you have an update on this?", "@saeta  still no update on this ? \r\n@shivaniag any solution ?", "I am facing the same issue... I want to cache a dataset X which is generates a training set Y with a reinitializable iterator going through X. Every time I reinitialize X iterator, even though I cache X, it iterates X as if there was no caching.\r\n\r\nI have noticed that this issue only occurs while caching in memory! When cache(filename) is applied, it does not occur.", "@saeta @mrry Any solution to this? I am also facing a similar issue.", "In TF 1.X, the state of the cache is tied to the state of the iterator and re-initializing the iterator will recreate the state of the iterator (including the cache state). We do not plan to change the semantics of \"reinitialize\" w.r.t. to the state of the iterator.\r\n\r\nHaving said that, I am planning to shortly submit a PR that, in TF 2.0, will decouple the cache state from the iterator state. In TF 2.0, instead of re-initializing an iterator you simply create multiple Python iterators (either implicitly via `for elem in dataset:` or explicitly via `iter(dataset)`. Once the aforementioned PR is submitted, the different iterators will share the same cache.\r\n"]}, {"number": 20929, "title": "cannot fit training data to TensorForestEstimator", "body": "Currently I am trying to to implement a random forest regression using Tensorflow's `TensorForestEstimator`. I have successfully done using scikit-learn's `RandomForestRegressor` and wants to replicate the same result using Tensorflow.\r\n\r\nI uploaded the data using pandas and I split the training and test set using scikit-learn's `train_test_split`. It contains 4 features (all numerical).\r\n\r\n```\r\n>>> X_train.shape\r\n(2711, 4)\r\n>>> y_train.shape\r\n(2711,)\r\n```\r\nI set the parameters of the for the tree\r\n\r\n```\r\nnum_features = int(np.log2(len(clean_data.columns)))\r\n\r\nparams = ForestHParams(num_classes=1, num_features=num_features,\r\n                       regression=True,num_trees=447, max_nodes=1000)\r\n\r\nregressor = TensorForestEstimator(params)\r\n```\r\nAbove i set the features as `int(np.log2(len(clean_data.columns)))` because i used `log2` for the `max_features` parameter in my original scikit-learn implementation.\r\n\r\nHowever, when tried to fit the training data, i receive and error like such\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n~/Desktop/88sparses/recommendation/recom/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)\r\n    509                 as_ref=input_arg.is_ref,\r\n--> 510                 preferred_dtype=default_dtype)\r\n    511           except TypeError as err:\r\n\r\n~/Desktop/88sparses/recommendation/recom/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx)\r\n   1108     if ret is None:\r\n-> 1109       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n   1110 \r\n\r\n~/Desktop/88sparses/recommendation/recom/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in _TensorTensorConversionFunction(t, dtype, name, as_ref)\r\n    945         \"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\" %\r\n--> 946         (dtype.name, t.dtype.name, str(t)))\r\n    947   return t\r\n\r\nValueError: Tensor conversion requested dtype float32 for Tensor with dtype float64: 'Tensor(\"concat:0\", shape=(?, 4), dtype=float64)'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-18-79323408f7f7> in <module>()\r\n      1 # from tensorflow import cast, float32\r\n      2 # X_train_cast = cast(X_train, float32)\r\n----> 3 regressor.fit(x=X_train, y=y_train)\r\n      4 \r\n      5 #regressor.score()\r\n\r\n~/Desktop/88sparses/recommendation/recom/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\r\n    430                 'in a future version' if date is None else ('after %s' % date),\r\n    431                 instructions)\r\n--> 432       return func(*args, **kwargs)\r\n    433     return tf_decorator.make_decorator(func, new_func, 'deprecated',\r\n    434                                        _add_deprecated_arg_notice_to_docstring(\r\n\r\n~/Desktop/88sparses/recommendation/recom/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py in fit(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\r\n    506     _verify_input_args(x, y, input_fn, None, batch_size)\r\n    507     if x is not None:\r\n--> 508       SKCompat(self).fit(x, y, batch_size, steps, max_steps, monitors)\r\n    509       return self\r\n    510 \r\n\r\n~/Desktop/88sparses/recommendation/recom/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py in fit(self, x, y, batch_size, steps, max_steps, monitors)\r\n   1525         steps=steps,\r\n   1526         max_steps=max_steps,\r\n-> 1527         monitors=all_monitors)\r\n   1528     return self\r\n   1529 \r\n\r\n~/Desktop/88sparses/recommendation/recom/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\r\n    430                 'in a future version' if date is None else ('after %s' % date),\r\n    431                 instructions)\r\n--> 432       return func(*args, **kwargs)\r\n    433     return tf_decorator.make_decorator(func, new_func, 'deprecated',\r\n    434                                        _add_deprecated_arg_notice_to_docstring(\r\n\r\n~/Desktop/88sparses/recommendation/recom/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py in fit(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\r\n    522       hooks.append(basic_session_run_hooks.StopAtStepHook(steps, max_steps))\r\n    523 \r\n--> 524     loss = self._train_model(input_fn=input_fn, hooks=hooks)\r\n    525     logging.info('Loss for final step: %s.', loss)\r\n    526     return self\r\n\r\n~/Desktop/88sparses/recommendation/recom/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py in _train_model(self, input_fn, hooks)\r\n   1039       self._check_inputs(features, labels)\r\n   1040       training_util._get_or_create_global_step_read()  # pylint: disable=protected-access\r\n-> 1041       model_fn_ops = self._get_train_ops(features, labels)\r\n   1042       ops.add_to_collection(ops.GraphKeys.LOSSES, model_fn_ops.loss)\r\n   1043       all_hooks.extend(hooks)\r\n\r\n~/Desktop/88sparses/recommendation/recom/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py in _get_train_ops(self, features, labels)\r\n   1262       `ModelFnOps` object.\r\n   1263     \"\"\"\r\n-> 1264     return self._call_model_fn(features, labels, model_fn_lib.ModeKeys.TRAIN)\r\n   1265 \r\n   1266   def _get_eval_ops(self, features, labels, metrics):\r\n\r\n~/Desktop/88sparses/recommendation/recom/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py in _call_model_fn(self, features, labels, mode, metrics, config)\r\n   1225     if 'model_dir' in model_fn_args:\r\n   1226       kwargs['model_dir'] = self.model_dir\r\n-> 1227     model_fn_results = self._model_fn(features, labels, **kwargs)\r\n   1228 \r\n   1229     if isinstance(model_fn_results, model_fn_lib.ModelFnOps):\r\n\r\n~/Desktop/88sparses/recommendation/recom/lib/python3.6/site-packages/tensorflow/contrib/tensor_forest/client/random_forest.py in _model_fn(features, labels, mode)\r\n    169 \r\n    170     logits, tree_paths, regression_variance = graph_builder.inference_graph(\r\n--> 171         features)\r\n    172 \r\n    173     summary.scalar('average_tree_size', graph_builder.average_size())\r\n\r\n~/Desktop/88sparses/recommendation/recom/lib/python3.6/site-packages/tensorflow/contrib/tensor_forest/python/tensor_forest.py in inference_graph(self, input_data, **inference_args)\r\n    512             data_spec,\r\n    513             sparse_features=processed_sparse_features,\r\n--> 514             **inference_args)\r\n    515         probabilities.append(probs)\r\n    516         paths.append(path)\r\n\r\n~/Desktop/88sparses/recommendation/recom/lib/python3.6/site-packages/tensorflow/contrib/tensor_forest/python/tensor_forest.py in inference_graph(self, input_data, data_spec, sparse_features)\r\n    686         sparse_shape,\r\n    687         input_spec=data_spec.SerializeToString(),\r\n--> 688         params=self.params.serialized_params_proto)\r\n    689 \r\n    690   def size(self):\r\n\r\n~/Desktop/88sparses/recommendation/recom/lib/python3.6/site-packages/tensorflow/contrib/tensor_forest/python/ops/gen_model_ops.py in tree_predictions_v4(tree_handle, input_data, sparse_input_indices, sparse_input_values, sparse_input_shape, input_spec, params, name)\r\n    467         sparse_input_values=sparse_input_values,\r\n    468         sparse_input_shape=sparse_input_shape, input_spec=input_spec,\r\n--> 469         params=params, name=name)\r\n    470     _result = _op.outputs[:]\r\n    471     _inputs_flat = _op.inputs\r\n\r\n~/Desktop/88sparses/recommendation/recom/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)\r\n    531             if input_arg.type != types_pb2.DT_INVALID:\r\n    532               raise TypeError(\"%s expected type of %s.\" %\r\n--> 533                               (prefix, dtypes.as_dtype(input_arg.type).name))\r\n    534             else:\r\n    535               # Update the maps with the default, if needed.\r\n\r\nTypeError: Input 'input_data' of 'TreePredictionsV4' Op has type float64 that does not match expected type of float32.\r\n```\r\nMy assumption was that i have to set the number of features to the number of all the features (i.e. using all features instead of a subset of the features). But i still get the same error as above.\r\n\r\nI tried to look at the source code directly but could not really understood where was the issue. A similar issue is being discuss on github here.\r\n\r\nAnother attempt was converting the input into float32.\r\n\r\n`regressor.fit(x=X_train.astype(\"float32\"), y=y_train.astype(\"float32\"))`\r\n\r\nHowever, i still got the same error as above. Then i tried using `tf.cast`\r\n\r\n```\r\nX_train_cast = cast(X_train, float32)\r\ny_train_cast = cast(y_train, float32)\r\nregressor.fit(x=X_train_cast, y=y_train_cast)\r\n```\r\nBut i got a different error saying\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-19-89e4fa057afb> in <module>()\r\n      2 X_train_cast = cast(X_train, float32)\r\n      3 y_train_cast = cast(y_train, float32)\r\n----> 4 regressor.fit(x=X_train_cast, y=y_train_cast)\r\n      5 \r\n      6 #regressor.score()\r\n\r\n~/Desktop/88sparses/recommendation/recom/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\r\n    430                 'in a future version' if date is None else ('after %s' % date),\r\n    431                 instructions)\r\n--> 432       return func(*args, **kwargs)\r\n    433     return tf_decorator.make_decorator(func, new_func, 'deprecated',\r\n    434                                        _add_deprecated_arg_notice_to_docstring(\r\n\r\n~/Desktop/88sparses/recommendation/recom/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py in fit(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\r\n    504     if (steps is not None) and (max_steps is not None):\r\n    505       raise ValueError('Can not provide both steps and max_steps.')\r\n--> 506     _verify_input_args(x, y, input_fn, None, batch_size)\r\n    507     if x is not None:\r\n    508       SKCompat(self).fit(x, y, batch_size, steps, max_steps, monitors)\r\n\r\n~/Desktop/88sparses/recommendation/recom/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py in _verify_input_args(x, y, input_fn, feed_fn, batch_size)\r\n    102 \r\n    103     if tensor_util.is_tensor(x) or y is not None and tensor_util.is_tensor(y):\r\n--> 104       raise ValueError('Inputs cannot be tensors. Please provide input_fn.')\r\n    105 \r\n    106     if feed_fn is not None:\r\n\r\nValueError: Inputs cannot be tensors. Please provide input_fn.\r\n```\r\nI was wondering if there was something missing in my implementation? Thanks in advance.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "@tensorflowbutler I was able to solve the issue, thank you very much!"]}, {"number": 20928, "title": "Add gradient for tensorflow::ops::Fill", "body": "See https://github.com/tensorflow/tensorflow/issues/20926\r\n\r\nAlso tested for any flakes with this:\r\n```\r\nbazel test --runs_per_test=100 tensorflow/cc:gradients_array_grad_test\r\n...\r\n//tensorflow/cc:gradients_array_grad_test                                PASSED in 0.8s\r\n  Stats over 100 runs: max = 0.8s, min = 0.5s, avg = 0.6s, dev = 0.0s\r\n```\r\n\r\n", "comments": ["Nagging Assignee @rmlarsen: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@yifeif It looks like the corresponding CL was submitted. How come the PR is still open?", "I dont think the CL was submitted. Let me trigger the import again."]}, {"number": 20927, "title": "Recommend the user site, no sudo", "body": "Using sudo to upgrade a pip which was installed by apt-get messes up the system environment and causes [issues](https://stackoverflow.com/q/51404984/674039).  Recommend to use the user site for installing tensor flow.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "@wimglenn thanks! Please sign the CLA.", "@rmlarsen   done\r\n", "CLAs look good, thanks!\n\n<!-- ok -->", "Hi @rmlarsen / @MarkDaoust , I thought this merge would update the guide [here](https://www.tensorflow.org/install/install_linux#InstallingNativePip), but it hasn't.  Is there a separate release process for that?"]}, {"number": 20926, "title": "C++: Add gradient for Fill operator", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n- **TensorFlow version (use command below)**:\r\nv1.4.0-19-ga52c8d9 1.4.1\r\n- **Python version**:\r\n3.5.2 (default, Nov 23 2017, 16:37:01) \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nFeature request: Add gradient support for the Fill operator in the C++ API.\r\n", "comments": ["We currently don't have anybody working on this. It would be great if you could help us by working on this and submitting a PR. Let us know if you need further clarification. Thanks!\r\n", "Thanks Yanping! PR https://github.com/tensorflow/tensorflow/pull/20928 is currently approved - if you can help with the process, can close this issue when it gets merged.", "Thank you very much for your contributions!\r\n", "Thanks all for the help getting the PR merged, fixed via https://github.com/tensorflow/tensorflow/commit/b462815ccc279c79a5592a0a2d4492718da02c5d"]}, {"number": 20925, "title": "Use InlinedVector for ShapeIndex breaks tensorflow build from source using bazel 0.14.0 inside docker ", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: latest\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**:0.14.0\r\n- **GCC/Compiler version (if compiling from source)**:gcc (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\n\r\n- **CUDA/cuDNN version**:9.0/7.1\r\n- **GPU model and memory**:Nvidia GeForce 1080 Ti\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nWhile building the tensorflow from source inside docker  using above configuration i encountered following errors.\r\n\r\n### Source code / logs\r\nERROR: /root/tensorflow/tensorflow/compiler/xla/BUILD:216:1: C++ compilation of rule '//tensorflow/compiler/xla:shape_util' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command \r\n  (cd /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    CUDA_TOOLKIT_PATH=/usr/local/cuda \\\r\n    CUDNN_INSTALL_PATH=/usr/local/cuda-9.0 \\\r\n    GCC_HOST_COMPILER_PATH=/usr/bin/gcc \\\r\n    LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \\\r\n    NCCL_INSTALL_PATH=/usr/local/cuda-9.0 \\\r\n    PATH=/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/opt/conda/bin/python3.6 \\\r\n    PYTHON_LIB_PATH=/opt/conda/lib/python3.6 \\\r\n    TF_CUDA_CLANG=0 \\\r\n    TF_CUDA_COMPUTE_CAPABILITIES=6.1 \\\r\n    TF_CUDA_VERSION=9.0 \\\r\n    TF_CUDNN_VERSION=7 \\\r\n    TF_NCCL_VERSION=2 \\\r\n    TF_NEED_CUDA=1 \\\r\n    TF_NEED_OPENCL_SYCL=0 \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/k8-opt/bin/tensorflow/compiler/xla/_objs/shape_util/tensorflow/compiler/xla/index_util.d '-frandom-seed=bazel-out/k8-opt/bin/tensorflow/compiler/xla/_objs/shape_util/tensorflow/compiler/xla/index_util.o' -D__CLANG_SUPPORT_DYN_ANNOTATION__ -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' -DTENSORFLOW_USE_JEMALLOC -DTENSORFLOW_USE_ABSL -DTF_USE_SNAPPY -iquote . -iquote bazel-out/k8-opt/genfiles -iquote external/com_google_absl -iquote bazel-out/k8-opt/genfiles/external/com_google_absl -iquote external/bazel_tools -iquote bazel-out/k8-opt/genfiles/external/bazel_tools -iquote external/nsync -iquote bazel-out/k8-opt/genfiles/external/nsync -iquote external/jemalloc -iquote bazel-out/k8-opt/genfiles/external/jemalloc -iquote external/eigen_archive -iquote bazel-out/k8-opt/genfiles/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/k8-opt/genfiles/external/local_config_sycl -iquote external/gif_archive -iquote bazel-out/k8-opt/genfiles/external/gif_archive -iquote external/jpeg -iquote bazel-out/k8-opt/genfiles/external/jpeg -iquote external/protobuf_archive -iquote bazel-out/k8-opt/genfiles/external/protobuf_archive -iquote external/com_googlesource_code_re2 -iquote bazel-out/k8-opt/genfiles/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/k8-opt/genfiles/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/k8-opt/genfiles/external/fft2d -iquote external/highwayhash -iquote bazel-out/k8-opt/genfiles/external/highwayhash -iquote external/zlib_archive -iquote bazel-out/k8-opt/genfiles/external/zlib_archive -iquote external/local_config_cuda -iquote bazel-out/k8-opt/genfiles/external/local_config_cuda -isystem external/nsync/public -isystem bazel-out/k8-opt/genfiles/external/nsync/public -isystem bazel-out/k8-opt/bin/external/nsync/public -isystem external/jemalloc/include -isystem bazel-out/k8-opt/genfiles/external/jemalloc/include -isystem bazel-out/k8-opt/bin/external/jemalloc/include -isystem external/eigen_archive -isystem bazel-out/k8-opt/genfiles/external/eigen_archive -isystem bazel-out/k8-opt/bin/external/eigen_archive -isystem external/gif_archive/lib -isystem bazel-out/k8-opt/genfiles/external/gif_archive/lib -isystem bazel-out/k8-opt/bin/external/gif_archive/lib -isystem external/protobuf_archive/src -isystem bazel-out/k8-opt/genfiles/external/protobuf_archive/src -isystem bazel-out/k8-opt/bin/external/protobuf_archive/src -isystem external/farmhash_archive/src -isystem bazel-out/k8-opt/genfiles/external/farmhash_archive/src -isystem bazel-out/k8-opt/bin/external/farmhash_archive/src -isystem external/zlib_archive -isystem bazel-out/k8-opt/genfiles/external/zlib_archive -isystem bazel-out/k8-opt/bin/external/zlib_archive -isystem external/local_config_cuda/cuda -isystem bazel-out/k8-opt/genfiles/external/local_config_cuda/cuda -isystem bazel-out/k8-opt/bin/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/cuda/include -isystem bazel-out/k8-opt/genfiles/external/local_config_cuda/cuda/cuda/include -isystem bazel-out/k8-opt/bin/external/local_config_cuda/cuda/cuda/include -isystem external/local_config_cuda/cuda/cuda/include/crt -isystem bazel-out/k8-opt/genfiles/external/local_config_cuda/cuda/cuda/include/crt -isystem bazel-out/k8-opt/bin/external/local_config_cuda/cuda/cuda/include/crt '-std=c++11' -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fPIE -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -fno-omit-frame-pointer -no-canonical-prefixes -DNDEBUG -g0 -O2 -ffunction-sections -fdata-sections '-D_GLIBCXX_USE_CXX11_ABI=0' -c tensorflow/compiler/xla/index_util.cc -o bazel-out/k8-opt/bin/tensorflow/compiler/xla/_objs/shape_util/tensorflow/compiler/xla/index_util.o)\r\nIn file included from tensorflow/compiler/xla/index_util.cc:21:0:\r\n./tensorflow/compiler/xla/shape_util.h:77:26: error: 'gtl' does not name a type\r\n   using container_type = gtl::InlinedVector<int64, 2>;\r\n                          ^\r\n./tensorflow/compiler/xla/shape_util.h:79:3: error: 'container_type' does not name a type\r\n   container_type::const_iterator begin() const { return indices_.begin(); }\r\n   ^\r\n./tensorflow/compiler/xla/shape_util.h:80:3: error: 'container_type' does not name a type\r\n   container_type::const_iterator end() const { return indices_.end(); }\r\n   ^\r\n./tensorflow/compiler/xla/shape_util.h:81:3: error: 'container_type' does not name a type\r\n   container_type::iterator begin() { return indices_.begin(); }\r\n   ^\r\n./tensorflow/compiler/xla/shape_util.h:82:3: error: 'container_type' does not name a type\r\n   container_type::iterator end() { return indices_.end(); }\r\n   ^\r\n./tensorflow/compiler/xla/shape_util.h:103:3: error: 'container_type' does not name a type\r\n   container_type indices_;\r\n   ^\r\n./tensorflow/compiler/xla/shape_util.h: In constructor 'xla::ShapeIndex::ShapeIndex(std::initializer_list<long long int>)':\r\n./tensorflow/compiler/xla/shape_util.h:65:51: error: class 'xla::ShapeIndex' does not have any field named 'indices_'\r\n   ShapeIndex(std::initializer_list<int64> init) : indices_(init) {}\r\n                                                   ^\r\n./tensorflow/compiler/xla/shape_util.h: In constructor 'xla::ShapeIndex::ShapeIndex(InputIt, InputIt)':\r\n./tensorflow/compiler/xla/shape_util.h:67:44: error: class 'xla::ShapeIndex' does not have any field named 'indices_'\r\n   ShapeIndex(InputIt start, InputIt end) : indices_(start, end) {}\r\n                                            ^\r\n./tensorflow/compiler/xla/shape_util.h: In member function 'bool xla::ShapeIndex::empty() const':\r\n./tensorflow/compiler/xla/shape_util.h:69:31: error: 'indices_' was not declared in this scope\r\n   bool empty() const { return indices_.empty(); }\r\n                               ^\r\n./tensorflow/compiler/xla/shape_util.h: In member function 'size_t xla::ShapeIndex::size() const':\r\n./tensorflow/compiler/xla/shape_util.h:70:32: error: 'indices_' was not declared in this scope\r\n   size_t size() const { return indices_.size(); }\r\n                                ^\r\n./tensorflow/compiler/xla/shape_util.h: In member function 'void xla::ShapeIndex::push_back(tensorflow::int64)':\r\n./tensorflow/compiler/xla/shape_util.h:71:33: error: 'indices_' was not declared in this scope\r\n   void push_back(int64 value) { indices_.push_back(value); }\r\n                                 ^\r\n./tensorflow/compiler/xla/shape_util.h: In member function 'void xla::ShapeIndex::pop_back()':\r\n./tensorflow/compiler/xla/shape_util.h:72:21: error: 'indices_' was not declared in this scope\r\n   void pop_back() { indices_.pop_back(); }\r\n                     ^\r\n./tensorflow/compiler/xla/shape_util.h: In member function 'void xla::ShapeIndex::push_front(tensorflow::int64)':\r\n./tensorflow/compiler/xla/shape_util.h:75:34: error: 'indices_' was not declared in this scope\r\n   void push_front(int64 value) { indices_.insert(indices_.begin(), value); }\r\n                                  ^\r\n./tensorflow/compiler/xla/shape_util.h: In member function 'const int64* xla::ShapeIndex::data() const':\r\n./tensorflow/compiler/xla/shape_util.h:84:38: error: 'indices_' was not declared in this scope\r\n   const int64* data() const { return indices_.data(); }\r\n                                      ^\r\n./tensorflow/compiler/xla/shape_util.h: In member function 'tensorflow::int64 xla::ShapeIndex::back() const':\r\n./tensorflow/compiler/xla/shape_util.h:86:31: error: 'indices_' was not declared in this scope\r\n   int64 back() const { return indices_.back(); }\r\n                               ^\r\n./tensorflow/compiler/xla/shape_util.h: In member function 'tensorflow::int64& xla::ShapeIndex::back()':\r\n./tensorflow/compiler/xla/shape_util.h:87:26: error: 'indices_' was not declared in this scope\r\n   int64& back() { return indices_.back(); }\r\n                          ^\r\n./tensorflow/compiler/xla/shape_util.h: In member function 'const int64& xla::ShapeIndex::operator[](size_t) const':\r\n./tensorflow/compiler/xla/shape_util.h:89:52: error: 'indices_' was not declared in this scope\r\n   const int64& operator[](size_t i) const { return indices_[i]; }\r\n                                                    ^\r\n./tensorflow/compiler/xla/shape_util.h: In member function 'tensorflow::int64& xla::ShapeIndex::operator[](size_t)':\r\n./tensorflow/compiler/xla/shape_util.h:90:40: error: 'indices_' was not declared in this scope\r\n   int64& operator[](size_t i) { return indices_[i]; }\r\n                                        ^\r\n./tensorflow/compiler/xla/shape_util.h: In member function 'bool xla::ShapeIndex::operator==(const xla::ShapeIndex&) const':\r\n./tensorflow/compiler/xla/shape_util.h:93:12: error: 'indices_' was not declared in this scope\r\n     return indices_ == other.indices_;\r\n            ^\r\n./tensorflow/compiler/xla/shape_util.h:93:30: error: 'const class xla::ShapeIndex' has no member named 'indices_'\r\n     return indices_ == other.indices_;\r\n                              ^\r\n./tensorflow/compiler/xla/shape_util.h: In member function 'bool xla::ShapeIndex::operator<(const xla::ShapeIndex&) const':\r\n./tensorflow/compiler/xla/shape_util.h:97:12: error: 'indices_' was not declared in this scope\r\n     return indices_ < other.indices_;\r\n            ^\r\n./tensorflow/compiler/xla/shape_util.h:97:29: error: 'const class xla::ShapeIndex' has no member named 'indices_'\r\n     return indices_ < other.indices_;\r\n                             ^\r\ntensorflow/compiler/xla/index_util.cc: In static member function 'static bool xla::IndexUtil::IndexInBounds(const xla::Shape&, tensorflow::gtl::ArraySlice<long long int>)':\r\ntensorflow/compiler/xla/index_util.cc:155:12: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   if (rank != index.size()) {\r\n            ^\r\nIn file included from ./tensorflow/core/platform/default/logging.h:24:0,\r\n                 from ./tensorflow/core/platform/logging.h:25,\r\n                 from ./tensorflow/core/lib/gtl/array_slice_internal.h:32,\r\n                 from ./tensorflow/core/lib/gtl/array_slice.h:101,\r\n                 from ./tensorflow/compiler/xla/index_util.h:25,\r\n                 from tensorflow/compiler/xla/index_util.cc:16:\r\n./tensorflow/core/platform/default/logging.h: In instantiation of 'std::string* tensorflow::internal::Check_LEImpl(const T1&, const T2&, const char*) [with T1 = long long int; T2 = long unsigned int; std::string = std::basic_string<char>]':\r\n./tensorflow/compiler/xla/shape_util.h:117:5:   required from here\r\n./tensorflow/core/platform/default/logging.h:232:35: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n TF_DEFINE_CHECK_OP_IMPL(Check_LE, <=)\r\n                                   ^\r\n./tensorflow/core/platform/macros.h:88:49: note: in definition of macro 'TF_PREDICT_TRUE'\r\n #define TF_PREDICT_TRUE(x) (__builtin_expect(!!(x), 1))\r\n                                                 ^\r\n./tensorflow/core/platform/default/logging.h:232:1: note: in expansion of macro 'TF_DEFINE_CHECK_OP_IMPL'\r\n TF_DEFINE_CHECK_OP_IMPL(Check_LE, <=)\r\n ^\r\n./tensorflow/core/platform/default/logging.h: In instantiation of 'std::string* tensorflow::internal::Check_EQImpl(const T1&, const T2&, const char*) [with T1 = long unsigned int; T2 = long long int; std::string = std::basic_string<char>]':\r\ntensorflow/compiler/xla/index_util.cc:170:3:   required from here\r\n./tensorflow/core/platform/default/logging.h:230:25: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n                         ==)  // Compilation error with CHECK_EQ(NULL, x)?\r\n                         ^\r\n./tensorflow/core/platform/macros.h:88:49: note: in definition of macro 'TF_PREDICT_TRUE'\r\n #define TF_PREDICT_TRUE(x) (__builtin_expect(!!(x), 1))\r\n                                                 ^\r\n./tensorflow/core/platform/default/logging.h:229:1: note: in expansion of macro 'TF_DEFINE_CHECK_OP_IMPL'\r\n TF_DEFINE_CHECK_OP_IMPL(Check_EQ,\r\n", "comments": ["I have faced the same issue for the latest TF1.9 build.", "Looks like the namespace tensorflow is missing in ./tensorflow/compiler/xla/shape_util.h:77 for gtl::InlinedVector<> usage. We need to change this line to tensorflow::gtl::InlinedVector<>. It builds cleanly now :-) ", "02725138f41befb78573e6abc177baed06cc1b3f fixed this"]}, {"number": 20924, "title": "Not able to build tensorflow lite iOS library", "body": "\r\n### System information\r\n\r\nTrying to follow steps from this https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/ios.md\r\n\r\nOS: Mac 10.13.4\r\nXCode: 9.4.1\r\nCommand Line Tools: 9.4.1\r\nBranch: master\r\nSHA: ff791a7fde3605493bef70de8a9c9779541daf66\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh (Throws error)\r\n\r\n### Describe the problem\r\n\r\nerror: invalid argument '--std=c++11' not allowed with 'C'\r\n\r\nI get this when i try to build. if i change CC in makefile to 'g++' then other errors pop up. i think this script is broken. \r\n\r\n### Source code / logs\r\n[build_ios_universal_lib.log](https://github.com/tensorflow/tensorflow/files/2206029/build_ios_universal_lib.log)\r\n", "comments": ["This is tracked by issue #20900 , closing this updates will be on the other issue."]}, {"number": 20923, "title": "Floating point type issue when computing extract images patches gradient", "body": "I was using `tf.extract_image_patches` when I ran into this issue. \r\n\r\nIt seems `sp_mat` here becomes a 32 bit floating point number as the sparse tensor inherits the floating point type from the values argument. If one is using float64 and the gradient is float64 computing the jacobian on the next line will result in the error \"TypeError: Input 'b' of 'SparseTensorDenseMatMul' Op has type float64 that does not match type float32 of argument 'a_values'\".\r\n\r\nInheriting the floating point type from the gradient should fix the issue.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed the license agreement @googlebot ", "CLAs look good, thanks!\n\n<!-- ok -->", "@kekeblom thank you for the fix!"]}, {"number": 20922, "title": "Decoding 16bit PNG bug", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nI have written a test that (IMHO) should not fail, but it fails.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Mint 18\r\n- **TensorFlow installed from (source or binary)**:\r\n`pip install tensorflow==1.8` in a clean environment\r\n- **TensorFlow version (use command below)**:\r\n1.8\r\n- **Python version**: \r\n3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\nPlease run \r\n```\r\n# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\r\n#\r\n# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n#\r\n#     http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n# ==============================================================================\r\n\"\"\"Tests for slim.data.tfexample_decoder.\"\"\"\r\n\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport numpy as np\r\n\r\nfrom tensorflow.contrib.slim.python.slim.data import tfexample_decoder\r\nfrom tensorflow.core.example import example_pb2\r\nfrom tensorflow.core.example import feature_pb2\r\nfrom tensorflow.python.framework import constant_op\r\nfrom tensorflow.python.framework import dtypes\r\nfrom tensorflow.python.ops import array_ops\r\nfrom tensorflow.python.ops import control_flow_ops\r\nfrom tensorflow.python.ops import image_ops\r\nfrom tensorflow.python.ops import lookup_ops\r\nfrom tensorflow.python.ops import math_ops\r\nfrom tensorflow.python.ops import parsing_ops\r\nfrom tensorflow.python.platform import test\r\n\r\n\r\nclass TFExampleDecoderTest(test.TestCase):\r\n\r\n    def _EncodedFloatFeature(self, ndarray):\r\n        return feature_pb2.Feature(float_list=feature_pb2.FloatList(\r\n            value=ndarray.flatten().tolist()))\r\n\r\n    def _EncodedInt64Feature(self, ndarray):\r\n        return feature_pb2.Feature(int64_list=feature_pb2.Int64List(\r\n            value=ndarray.flatten().tolist()))\r\n\r\n    def _EncodedBytesFeature(self, tf_encoded):\r\n        with self.test_session():\r\n            encoded = tf_encoded.eval()\r\n\r\n        def BytesList(value):\r\n            return feature_pb2.BytesList(value=[value])\r\n\r\n        return feature_pb2.Feature(bytes_list=BytesList(encoded))\r\n\r\n    def _BytesFeature(self, ndarray):\r\n        values = ndarray.flatten().tolist()\r\n        for i in range(len(values)):\r\n            values[i] = values[i].encode('utf-8')\r\n        return feature_pb2.Feature(bytes_list=feature_pb2.BytesList(value=values))\r\n\r\n    def _StringFeature(self, value):\r\n        value = value.encode('utf-8')\r\n        return feature_pb2.Feature(bytes_list=feature_pb2.BytesList(value=[value]))\r\n\r\n    def _Encoder(self, image, image_format):\r\n        assert image_format in ['jpeg', 'JPEG', 'png', 'PNG', 'raw', 'RAW']\r\n        if image_format in ['jpeg', 'JPEG']:\r\n            tf_image = constant_op.constant(image, dtype=dtypes.uint8)\r\n            return image_ops.encode_jpeg(tf_image)\r\n        if image_format in ['png', 'PNG']:\r\n            tf_image = constant_op.constant(image, dtype=dtypes.uint8)\r\n            return image_ops.encode_png(tf_image)\r\n        if image_format in ['raw', 'RAW']:\r\n            return constant_op.constant(image.tostring(), dtype=dtypes.string)\r\n\r\n    def GenerateImage(self, image_format, image_shape):\r\n        \"\"\"Generates an image and an example containing the encoded image.\r\n\r\n        Args:\r\n          image_format: the encoding format of the image.\r\n          image_shape: the shape of the image to generate.\r\n\r\n        Returns:\r\n          image: the generated image.\r\n          example: a TF-example with a feature key 'image/encoded' set to the\r\n            serialized image and a feature key 'image/format' set to the image\r\n            encoding format ['jpeg', 'JPEG', 'png', 'PNG', 'raw'].\r\n        \"\"\"\r\n        num_pixels = image_shape[0] * image_shape[1] * image_shape[2]\r\n        image = np.linspace(\r\n            0, num_pixels - 1, num=num_pixels).reshape(image_shape).astype(np.uint8)\r\n        tf_encoded = self._Encoder(image, image_format)\r\n        example = example_pb2.Example(features=feature_pb2.Features(feature={\r\n            'image/encoded': self._EncodedBytesFeature(tf_encoded),\r\n            'image/format': self._StringFeature(image_format)\r\n        }))\r\n\r\n        return image, example.SerializeToString()\r\n\r\n    def DecodeExample(self, serialized_example, item_handler, image_format):\r\n        \"\"\"Decodes the given serialized example with the specified item handler.\r\n\r\n        Args:\r\n          serialized_example: a serialized TF example string.\r\n          item_handler: the item handler used to decode the image.\r\n          image_format: the image format being decoded.\r\n\r\n        Returns:\r\n          the decoded image found in the serialized Example.\r\n        \"\"\"\r\n        serialized_example = array_ops.reshape(serialized_example, shape=[])\r\n        decoder = tfexample_decoder.TFExampleDecoder(\r\n            keys_to_features={\r\n                'image/encoded':\r\n                    parsing_ops.FixedLenFeature(\r\n                        (), dtypes.string, default_value=''),\r\n                'image/format':\r\n                    parsing_ops.FixedLenFeature(\r\n                        (), dtypes.string, default_value=image_format),\r\n            },\r\n            items_to_handlers={'image': item_handler})\r\n        [tf_image] = decoder.decode(serialized_example, ['image'])\r\n        return tf_image\r\n\r\n    def RunDecodeExample(self, serialized_example, item_handler, image_format):\r\n        tf_image = self.DecodeExample(serialized_example, item_handler,\r\n                                      image_format)\r\n\r\n        with self.test_session():\r\n            decoded_image = tf_image.eval()\r\n\r\n            # We need to recast them here to avoid some issues with uint8.\r\n            return decoded_image.astype(np.float32)\r\n\r\n    def testDecodeExampleWithPngEncodingAt16Bit(self):\r\n        image_shape = (2, 3, 3)\r\n        unused_image, serialized_example = self.GenerateImage(\r\n            image_format='png', image_shape=image_shape)\r\n        unused_decoded_image = self.RunDecodeExample(\r\n            serialized_example,\r\n            tfexample_decoder.Image(dtype=dtypes.uint16),\r\n            image_format='png')\r\n        self.assertAllClose(unused_image, unused_decoded_image)\r\n\r\n\r\nif __name__ == '__main__':\r\n    test.main()\r\n```\r\nIt is a modified https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/data/tfexample_decoder_test.py\r\n\r\n### Describe the problem\r\nI would like to decode and encode a single channel 16bit (uint16) PNG and it is not possible. I have modified the tests also to create a np.uint16 image, then trying to decode it, but it does not work.\r\n\r\n```\r\n  def testDecodeExampleWithPngEncodingAt16Bit(self):\r\n    image_shape = (2, 3, 3)\r\n    unused_image, serialized_example = self.GenerateImage(\r\n        image_format='png', image_shape=image_shape, dtype=np.uint16)\r\n    unused_decoded_image = self.RunDecodeExample(\r\n          serialized_example,\r\n          tfexample_decoder.Image(dtype=dtypes.uint16),\r\n          image_format='png')\r\n    self.assertAllClose(unused_image, unused_decoded_image)\r\n```\r\n(modifying the `GenerateImage` method accordingly).\r\n\r\nI understand that it should be possible since decode_png function allows uint16 as an output type: https://www.tensorflow.org/api_docs/python/tf/image/decode_png \r\n\r\nThe test fails because the program raises\r\n```\r\nValueError: Outputs of true_fn and false_fn must have the same type: uint16, uint8\r\n```\r\nI understand that it is due to the fact that `tf.cond` needs the same output types from branches.\r\n", "comments": ["Added stacktrace.\r\n```\r\n\u279c  python tfexample_decoder_test.py\r\n2018-07-18 13:50:30.281800: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n/home/apis/miniconda3/envs/testt/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:55: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\r\n  if d.decorator_argspec is not None), _inspect.getargspec(target))\r\nE.\r\n======================================================================\r\nERROR: testDecodeExampleWithPngEncodingAt16Bit (__main__.TFExampleDecoderTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"tfexample_decoder_test.py\", line 143, in testDecodeExampleWithPngEncodingAt16Bit\r\n    image_format='png')\r\n  File \"tfexample_decoder_test.py\", line 128, in RunDecodeExample\r\n    image_format)\r\n  File \"tfexample_decoder_test.py\", line 123, in DecodeExample\r\n    [tf_image] = decoder.decode(serialized_example, ['image'])\r\n  File \"/home/apis/miniconda3/envs/testt/lib/python3.6/site-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 520, in decode\r\n    outputs.append(handler.tensors_to_item(keys_to_tensors))\r\n  File \"/home/apis/miniconda3/envs/testt/lib/python3.6/site-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 401, in tensors_to_item\r\n    return self._decode(image_buffer, image_format)\r\n  File \"/home/apis/miniconda3/envs/testt/lib/python3.6/site-packages/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py\", line 446, in _decode\r\n    pred_fn_pairs, default=check_jpeg, exclusive=True)\r\n  File \"/home/apis/miniconda3/envs/testt/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3698, in case\r\n    allow_python_preds=False, strict=strict)\r\n  File \"/home/apis/miniconda3/envs/testt/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3602, in _case_helper\r\n    return fn()\r\n  File \"/home/apis/miniconda3/envs/testt/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 432, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/apis/miniconda3/envs/testt/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2110, in cond\r\n    (val_x.dtype.name, val_y.dtype.name))\r\nValueError: Outputs of true_fn and false_fn must have the same type: uint16, uint8\r\n\r\n----------------------------------------------------------------------\r\nRan 2 tests in 0.064s\r\n\r\nFAILED (errors=1)\r\n```\r\n", "It seems that you would need to make a change [here](https://github.com/tensorflow/tensorflow/blob/5e855c56c2657128ff793b83442edc9886808922/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py#L394)     \r\n    `return self._decode(image_buffer, image_format)`\r\nto \r\n      `return self._decode(image_buffer, image_format, self._dtype)`", "Could you elaborate more? As I understand the only place that `dtype` is used is `decode_raw`, but `self._dtype` is used here already.\r\n\r\nAlso I point to the https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py while you have pointed to older code and it have changed since that time.", "Same issue here. https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/data/tfexample_decoder.py L435 reports an error if the decoded format is not tf.uint8. In this case, decode_jpeg returns tf.uint8 while decode_image could return tf.uint16 for example if I decode uint16 PNG, and tf.cond does not different dtype of true_fn and false_fn.", "Nagging Assignee @sguada: It has been 44 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I think it was resolved. Closing due to lack of recent activity. Please reopen new ticket if the issue arises. Thanks!"]}, {"number": 20921, "title": " ValueError: Cannot feed value of shape (5, 100, 100, 3) for Tensor 'X:0', which has shape '(?, 100, 100)'", "body": "I'm very new to Tensorflow. And it hurts. A lot.\r\n \r\n# coding: utf-8\r\n\r\n# # Training a DCGAN to draw fake and real images\r\n\r\n# In[1]:\r\n\r\n\r\ndirectory = \"../Data/image_files/\"\r\nnew_dir = \"../Data/image_files/cropped\"\r\nimport urllib\r\nimport urllib.request\r\nimport tarfile\r\nimport os\r\nimport tarfile\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nfrom matplotlib.image import imread\r\nfrom scipy.misc import imresize, imsave\r\nimport tensorflow as tf\r\nimport imageio\r\nimport skimage\r\nget_ipython().run_line_magic('matplotlib', 'inline')\r\n\r\n\r\n# ## Modifying the images (reducing their size)\r\n\r\n# In[2]:\r\n\r\n\r\nheight_width = 100\r\n\r\nfilepaths = []\r\nfor dir_, _, files in os.walk(directory):\r\n    for fileName in files:\r\n        relDir = os.path.relpath(dir_, directory)\r\n        relFile = os.path.join(relDir, fileName)\r\n        filepaths.append(directory + \"/\" + relFile)\r\nfail_count = 0         \r\nfor i, fp in enumerate(filepaths):\r\n    try: \r\n        img = imread(fp, 0) #/ 255.0\r\n        img = skimage.transform.resize(img, (height_width, height_width))\r\n        imageio.imwrite(new_dir + \"/\" + str(i) + \".png\", img)        \r\n    except:\r\n        fail_count += 1\r\n        img = imread(\"../Data/white_square.png\", 0) #/ 100 width square\r\n        imageio.imwrite(new_dir + \"/\" + str(i) + \".png\", img) \r\n        with open(\"../Data/fail_log.text\", \"a+\") as f:\r\n            f.write(fp)\r\nprint(fail_count)\r\n\r\n\r\n# Load the file names of files into a list\r\n\r\n# In[3]:\r\n\r\n\r\nfilepaths_new = []\r\nfor dir_, _, files in os.walk(new_dir):\r\n    for fileName in files:\r\n        if not fileName.endswith(\".png\"):\r\n            continue\r\n        relDir = os.path.relpath(dir_, directory)\r\n        relFile = os.path.join(relDir, fileName)\r\n        filepaths_new.append(directory + \"/\" + relFile)\r\n\r\n\r\n# ## Define next batch\r\n\r\n# In[4]:\r\n\r\n\r\ndef next_batch(num=64, data=filepaths_new):\r\n    idx = np.arange(0 , len(data))\r\n    np.random.shuffle(idx)\r\n    idx = idx[:num]\r\n    print(idx)\r\n    data_shuffle = [imread(data[i]) for i in idx]\r\n\r\n    shuffled = np.asarray(data_shuffle)\r\n    print(\"shuffled:\", shuffled.shape)\r\n    return np.asarray(data_shuffle)\r\n\r\n\r\n# ## Code for creating montages (by Parag Mital)\r\n\r\n# In[5]:\r\n\r\n\r\n# Code by Parag Mital (https://github.com/pkmital/CADL/)\r\ndef montage(images):    \r\n    if isinstance(images, list):\r\n        images = np.array(images)\r\n    img_h = images.shape[1]\r\n    img_w = images.shape[2]\r\n    n_plots = int(np.ceil(np.sqrt(images.shape[0])))\r\n    if len(images.shape) == 4 and images.shape[3] == 3:\r\n        m = np.ones(\r\n            (images.shape[1] * n_plots + n_plots + 1,\r\n             images.shape[2] * n_plots + n_plots + 1, 3)) * 0.5\r\n    elif len(images.shape) == 4 and images.shape[3] == 1:\r\n        m = np.ones(\r\n            (images.shape[1] * n_plots + n_plots + 1,\r\n             images.shape[2] * n_plots + n_plots + 1, 1)) * 0.5\r\n    elif len(images.shape) == 3:\r\n        m = np.ones(\r\n            (images.shape[1] * n_plots + n_plots + 1,\r\n             images.shape[2] * n_plots + n_plots + 1)) * 0.5\r\n    else:\r\n        raise ValueError('Could not parse image shape of {}'.format(\r\n            images.shape))\r\n    for i in range(n_plots):\r\n        for j in range(n_plots):\r\n            this_filter = i * n_plots + j\r\n            if this_filter < images.shape[0]:\r\n                this_img = images[this_filter]\r\n                m[1 + i + i * img_h:1 + i + (i + 1) * img_h,\r\n                  1 + j + j * img_w:1 + j + (j + 1) * img_w] = this_img\r\n    return m\r\n\r\n\r\n# ## Definition of the neural network\r\n\r\n# In[6]:\r\n\r\n\r\ntf.reset_default_graph()\r\nbatch_size = 5\r\nn_noise = 28\r\n\r\n#config = tf.ConfigProto()\r\n#config.gpu_options.allocator_type ='BFC'\r\n#config.gpu_options.per_process_gpu_memory_fraction = 0.90\r\n\r\nX_in = tf.placeholder(dtype=tf.float32, shape=[None, height_width, height_width], name='X')\r\nnoise = tf.placeholder(dtype=tf.float32, shape=[None, n_noise])\r\n\r\nkeep_prob = tf.placeholder(dtype=tf.float32, name='keep_prob')\r\nis_training = tf.placeholder(dtype=tf.bool, name='is_training')\r\n\r\ndef lrelu(x):\r\n    return tf.maximum(x, tf.multiply(x, 0.2))\r\n\r\ndef binary_cross_entropy(x, z):\r\n    eps = 1e-12\r\n    return (-(x * tf.log(z + eps) + (1. - x) * tf.log(1. - z + eps)))\r\n\r\ndef discriminator(img_in, reuse=None, keep_prob=keep_prob):\r\n    activation = lrelu\r\n    with tf.variable_scope(\"discriminator\", reuse=reuse):\r\n        x = tf.reshape(img_in, shape=[-1, height_width, height_width, 3])\r\n        x = tf.layers.conv2d(x, kernel_size=5, filters=256, strides=2, padding='same', activation=activation)\r\n        x = tf.layers.dropout(x, keep_prob)\r\n        x = tf.layers.conv2d(x, kernel_size=5, filters=128, strides=1, padding='same', activation=activation)\r\n        x = tf.layers.dropout(x, keep_prob)\r\n        x = tf.layers.conv2d(x, kernel_size=5, filters=64, strides=1, padding='same', activation=activation)\r\n        x = tf.layers.dropout(x, keep_prob)\r\n        x = tf.contrib.layers.flatten(x)\r\n        x = tf.layers.dense(x, units=128, activation=activation)\r\n        x = tf.layers.dense(x, units=1, activation=tf.nn.sigmoid)\r\n        return x\r\n    \r\ndef generator(z, keep_prob=keep_prob, is_training=is_training):\r\n    activation = lrelu\r\n    momentum = 0.9\r\n    with tf.variable_scope(\"generator\", reuse=None):\r\n        x = z\r\n        \r\n        d1 = 4#3\r\n        d2 = 3\r\n        \r\n        x = tf.layers.dense(x, units=d1 * d1 * d2, activation=activation)\r\n        x = tf.layers.dropout(x, keep_prob)      \r\n        x = tf.contrib.layers.batch_norm(x, is_training=is_training, decay=momentum)  \r\n        \r\n        x = tf.reshape(x, shape=[-1, d1, d1, d2])\r\n        x = tf.image.resize_images(x, size=[50, 50])\r\n        \r\n        \r\n        \r\n        x = tf.layers.conv2d_transpose(x, kernel_size=5, filters=256, strides=2, padding='same', activation=activation)\r\n        x = tf.layers.dropout(x, keep_prob)\r\n        x = tf.contrib.layers.batch_norm(x, is_training=is_training, decay=momentum)\r\n        x = tf.layers.conv2d_transpose(x, kernel_size=5, filters=128, strides=2, padding='same', activation=activation)\r\n        x = tf.layers.dropout(x, keep_prob)\r\n        x = tf.contrib.layers.batch_norm(x, is_training=is_training, decay=momentum)\r\n        x = tf.layers.conv2d_transpose(x, kernel_size=5, filters=64, strides=1, padding='same', activation=activation)\r\n        x = tf.layers.dropout(x, keep_prob)\r\n        x = tf.contrib.layers.batch_norm(x, is_training=is_training, decay=momentum)\r\n        x = tf.layers.conv2d_transpose(x, kernel_size=5, filters=3, strides=1, padding='same', activation=tf.nn.sigmoid)\r\n        return x    \r\n\r\n\r\n# In[ ]:\r\n\r\n\r\n\r\n\r\n\r\n# ## Losses and optimizers\r\n\r\n# In[7]:\r\n\r\n\r\n\r\n\r\ng = generator(noise, keep_prob, is_training)\r\nprint(g)\r\nd_real = discriminator(X_in)\r\nd_fake = discriminator(g, reuse=True)\r\n\r\nvars_g = [var for var in tf.trainable_variables() if var.name.startswith(\"generator\")]\r\nvars_d = [var for var in tf.trainable_variables() if var.name.startswith(\"discriminator\")]\r\n\r\n\r\nd_reg = tf.contrib.layers.apply_regularization(tf.contrib.layers.l2_regularizer(1e-6), vars_d)\r\ng_reg = tf.contrib.layers.apply_regularization(tf.contrib.layers.l2_regularizer(1e-6), vars_g)\r\n\r\nloss_d_real = binary_cross_entropy(tf.ones_like(d_real), d_real)\r\nloss_d_fake = binary_cross_entropy(tf.zeros_like(d_fake), d_fake)\r\nloss_g = tf.reduce_mean(binary_cross_entropy(tf.ones_like(d_fake), d_fake))\r\n\r\nloss_d = tf.reduce_mean(0.5 * (loss_d_real + loss_d_fake))\r\n\r\nupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\nwith tf.control_dependencies(update_ops):\r\n    optimizer_d = tf.train.RMSPropOptimizer(learning_rate=0.0001).minimize(loss_d + d_reg, var_list=vars_d)\r\n    optimizer_g = tf.train.RMSPropOptimizer(learning_rate=0.0002).minimize(loss_g + g_reg, var_list=vars_g)\r\nsess = tf.Session()\r\nsess.run(tf.global_variables_initializer())\r\n\r\n\r\n# ## Training the network\r\n\r\n# In[8]:\r\n\r\n\r\nfor i in range(60000):\r\n    train_d = True\r\n    train_g = True\r\n    keep_prob_train = 0.6 # 0.5\r\n    \r\n    \r\n    n = np.random.uniform(0.0, 1.0, [batch_size, n_noise]).astype(np.float32)   \r\n    batch = [b for b in next_batch(num=batch_size)]  \r\n    \r\n    d_real_ls, d_fake_ls, g_ls, d_ls = sess.run([loss_d_real, loss_d_fake, loss_g, loss_d], feed_dict={X_in: batch, noise: n, keep_prob: keep_prob_train, is_training:True})\r\n    \r\n    d_fake_ls_init = d_fake_ls\r\n    \r\n    d_real_ls = np.mean(d_real_ls)\r\n    d_fake_ls = np.mean(d_fake_ls)\r\n    g_ls = g_ls\r\n    d_ls = d_ls\r\n        \r\n    if g_ls * 1.35 < d_ls:\r\n        train_g = False\r\n        pass\r\n    if d_ls * 1.35 < g_ls:\r\n        train_d = False\r\n        pass\r\n    \r\n    if train_d:\r\n        sess.run(optimizer_d, feed_dict={noise: n, X_in: batch, keep_prob: keep_prob_train, is_training:True})\r\n        \r\n        \r\n    if train_g:\r\n        sess.run(optimizer_g, feed_dict={noise: n, keep_prob: keep_prob_train, is_training:True})\r\n        \r\n        \r\n    if not i % 10:\r\n        print (i, d_ls, g_ls)\r\n        if not train_g:\r\n            print(\"not training generator\")\r\n        if not train_d:\r\n            print(\"not training discriminator\")\r\n        gen_imgs = sess.run(g, feed_dict = {noise: n, keep_prob: 1.0, is_training:False})\r\n        imgs = [img[:,:,:] for img in gen_imgs]\r\n        m = montage(imgs)\r\n        #m = imgs[0]\r\n        plt.axis('off')\r\n        plt.imshow(m, cmap='gray')\r\n        plt.show()\r\n\r\nGenerates this error.\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-8-3639a81d708d> in <module>()\r\n      8     batch = [b for b in next_batch(num=batch_size)]\r\n      9 \r\n---> 10     d_real_ls, d_fake_ls, g_ls, d_ls = sess.run([loss_d_real, loss_d_fake, loss_g, loss_d], feed_dict={X_in: batch, noise: n, keep_prob: keep_prob_train, is_training:True})\r\n     11 \r\n     12     d_fake_ls_init = d_fake_ls\r\n\r\n~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    898     try:\r\n    899       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 900                          run_metadata_ptr)\r\n    901       if run_metadata:\r\n    902         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1109                              'which has shape %r' %\r\n   1110                              (np_val.shape, subfeed_t.name,\r\n-> 1111                               str(subfeed_t.get_shape())))\r\n   1112           if not self.graph.is_feedable(subfeed_t):\r\n   1113             raise ValueError('Tensor %s may not be fed.' % subfeed_t)\r\n\r\nValueError: Cannot feed value of shape (5, 100, 100, 3) for Tensor 'X:0', which has shape '(?, 100, 100)'\r\n\r\n\r\nNo idea how to debug this. Need a bit of help.", "comments": ["X_in = tf.placeholder(dtype=tf.float32, shape=[None, height_width, height_width], name='X') here you set that the input images should be grayscale, ie num_images x width x height. But in imread function, you read color images, so you have num_images x width x height x 3. If you don't know what you are doing, change the imread to read grayscale images.", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 20920, "title": "[ Interpreter.runForMultipleInputsOutputs ] Error When running  SSD-Mobilenet-v1 model in tensorflow-lite. ", "body": "@andrewharp I tried your cutosm inference class TFLiteObjectDetectionAPIModel.java in [tensorflow/contrib/lite/examples/android](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite/examples/android) , and i use it with your ssd mobilenet v1 tflite mobilenet_ssd_tflite_v1.zip but it seems i have a problem when i call tfLite.runForMultipleInputsOutputs(inputArray, outputMap); ( in function recognizeImage(final Bitmap bitmap) ) . it throws this exception\r\n\r\n```\r\n07-18 10:37:02.416 19957-19996/com.app.cerist.realtimeobjectdetectionapi E/AndroidRuntime: FATAL EXCEPTION: Camera\r\n    Process: com.app.cerist.realtimeobjectdetectionapi, PID: 19957\r\n    java.lang.IllegalArgumentException: Output error: Outputs do not match with model outputs.\r\n        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:170)\r\n        at com.app.cerist.realtimeobjectdetectionapi.ImageClassifierTFLiteAPI.recognizeImage(ImageClassifierTFLiteAPI.java:207)\r\n        at com.app.cerist.realtimeobjectdetectionapi.MainActivity.classifyFrame(MainActivity.java:421)\r\n        at com.app.cerist.realtimeobjectdetectionapi.MainActivity.access$1000(MainActivity.java:48)\r\n        at com.app.cerist.realtimeobjectdetectionapi.MainActivity$4.run(MainActivity.java:455)\r\n        at android.os.Handler.handleCallback(Handler.java:739)\r\n        at android.os.Handler.dispatchMessage(Handler.java:95)\r\n        at android.os.Looper.loop(Looper.java:159)\r\n        at android.os.HandlerThread.run(HandlerThread.java:61)\r\n07-18 10:37:02.436 19957-19996/com.app.cerist.realtimeobjectdetectionapi V/Process: killProcess [19957] Callers=com.android.internal.os.RuntimeInit$UncaughtHandler.uncaughtException:99 java.lang.ThreadGroup.uncaughtException:693 java.lang.ThreadGroup.uncaughtException:690 <bottom of call stack> \r\n07-18 10:37:02.436 19957-19996/com.app.cerist.realtimeobjectdetectionapi I/Process: Sending signal. PID: 19957 SIG: 9\r\n```\r\n\r\nthe error said that the length of outputs array is bigger than the length of inputs array\r\nin this condition line in the Interpreter.java\r\n\r\n``` \r\npublic void runForMultipleInputsOutputs(Object[] inputs, @NonNull Map<Integer, Object> outputs) {\r\n        if (this.wrapper == null) {\r\n            throw new IllegalStateException(\"Internal error: The Interpreter has already been closed.\");\r\n        } else {\r\n            Tensor[] tensors = this.wrapper.run(inputs);\r\n            if (outputs != null && tensors != null && outputs.size() <= tensors.length) {\r\n                int size = tensors.length;\r\n                //...\r\n            }} else {\r\n                throw new IllegalArgumentException(\"Output error: Outputs do not match with model outputs.\");\r\n}\r\n```\r\nThis is my inputs array : \r\n\r\n```\r\nd.imgData = ByteBuffer.allocateDirect(1 * d.inputSize * d.inputSize * 3 * numBytesPerChannel);\r\nd.imgData.order(ByteOrder.nativeOrder());\r\n//...\r\n imgData.rewind();\r\n        for (int i = 0; i < inputSize; ++i) {\r\n            for (int j = 0; j < inputSize; ++j) {\r\n                int pixelValue = intValues[i * inputSize + j];\r\n                if (isModelQuantized) {\r\n                    // Quantized model\r\n                    imgData.put((byte) ((pixelValue >> 16) & 0xFF));\r\n                    imgData.put((byte) ((pixelValue >> 8) & 0xFF));\r\n                    imgData.put((byte) (pixelValue & 0xFF));\r\n                } else { // Float model\r\n                    imgData.putFloat((((pixelValue >> 16) & 0xFF) - IMAGE_MEAN) / IMAGE_STD);\r\n                    imgData.putFloat((((pixelValue >> 8) & 0xFF) - IMAGE_MEAN) / IMAGE_STD);\r\n                    imgData.putFloat(((pixelValue & 0xFF) - IMAGE_MEAN) / IMAGE_STD);\r\n} \r\n\r\n```\r\n\r\n```\r\nObject[] inputArray = {imgData};\r\n```\r\n\r\nAnd this  the outputs arrays :\r\n\r\n```\r\n// Copy the input data into TensorFlow.\r\n        Trace.beginSection(\"feed\");\r\n        outputLocations = new float[1][NUM_DETECTIONS][4];\r\n        outputClasses = new float[1][NUM_DETECTIONS];\r\n        outputScores = new float[1][NUM_DETECTIONS];\r\n        numDetections = new float[1];\r\n//...\r\n        Map<Integer, Object> outputMap = new HashMap<>();\r\n        outputMap.put(0, outputLocations);\r\n        outputMap.put(1, outputScores);\r\n        outputMap.put(2, numDetections);\r\n        outputMap.put(3, outputClasses);\r\n        Trace.endSection();\r\n```\r\n\r\nAnd the Inference :\r\n```\r\n// Run the inference call.\r\n        Trace.beginSection(\"run\");\r\n        Log.d(\"TAG_INPUT\",\"\"+String.valueOf(inputArray.length)); // inputArray has length of 1\r\n        Log.d(\"TAG_OUTPUT\",\"\"+String.valueOf(outputMap.size())); // outputMap has length of 4\r\n\r\n        tfLite.runForMultipleInputsOutputs(inputArray, outputMap);\r\n        Trace.endSection();\r\n```\r\n\r\nI didn't understand the meaning of this Error cuz i did exactly the same as your TFLiteObjectDetectionAPIModel.java class .\r\nthank you for Help\r\n", "comments": ["TFLiteObjectDetectionAPIModel was recently modified to use a different model, which as additional outputs (see this [commit](https://github.com/tensorflow/tensorflow/commit/f3785197b4de9466b48462f4f93b455c88dd622b#diff-c748d758eb53ac58d70a13e07e02c6db)). If you want to continue using mobilenet_v1, pattern your code after the code before that commit. In particular, mobilenet_v1 only has outputLocations and outputClass. It does not have outputScores or numDetections.", "@jdduke Thank you so much for your help That works  for Me , I reviewed the old version of this class and i fixe the issue. \r\nBut somthing it wasn't clear for me, what is the purpose of the box_priors.txt file and why he used it ? is it important to use it ?  \r\nThank you for your replay", "Hi @AbdelfettahBentaleb, @achowdhery can better respond to your latest question."]}, {"number": 20919, "title": "bazel build failure, error occur no such package @androidndk", "body": "### System information\r\n- **OS Platform and Distribution **: Ubuntu 16.04\r\n- **TensorFlow install **: installed from source\r\n- **TensorFlow version **: r1.9\r\n- **Python version **: pyenv + virtualenv to support python 3.6.6\r\n- **Bazel version **: 0.14.1 compiling from source\r\n- **GCC/Compiler version  **: gcc 4.9\r\n- **CUDA, cuDNN version**: CUDA 9.0, cuDNN 7.1\r\n- **GPU  **: NVIDIA Titan X 12GB\r\n- ** no custom code **: source compile from released r1.9 source\r\n\r\n### Describe the problem\r\nWhen compile tensor flow r1.9 from released source code, Bazel occur error message.\r\nI try to compile r1.8 as same build env. there is no error occurred. \r\n \r\n### Source code / logs\r\n- build env. setting \r\n\r\n```\r\ncd /tmp/tensorflow-r${TF_VERSION} \\\r\n    && PYTHON_BIN_PATH=/usr/local/bin/python \\\r\n        PYTHON_LIB_PATH=/usr/local/lib/python3.6/site-packages \\\r\n        GCC_HOST_COMPILER_PATH=/usr/bin/gcc \\\r\n        CC_OPT_FLAGS=\"-march=x86-64 -mavx -mavx2 -mfma -mfpmath=both -msse4.1 -msse4.2\" \\\r\n        TF_NEED_JEMALLOC=1 \\\r\n        TF_NEED_GCP=1 \\\r\n        TF_NEED_HDFS=1 \\\r\n        TF_ENABLE_XLA=1 \\\r\n        TF_NEED_VERBS=0 \\\r\n        TF_NEED_OPENCL=0 \\\r\n        TF_NEED_OPENCL_SYCL=0 \\\r\n        TF_NEED_CUDA=1 \\\r\n        TF_CUDA_CLANG=0 \\\r\n        TF_DOWNLOAD_CLANG=0 \\\r\n        TF_NEED_TENSORRT=0 \\\r\n        TF_NEED_MPI=0 \\\r\n        TF_NEED_GDR=0 \\\r\n        TF_NEED_S3=1 \\\r\n        TF_NEED_KAFKA=0 \\\r\n        TF_SET_ANDROID_WORKSPACE=0 \\\r\n        TF_CUDA_VERSION=9.0 \\\r\n        TF_CUDNN_VERSION=7 \\\r\n        TF_NCCL_VERSION=2 \\\r\n        TF_CUDA_COMPUTE_CAPABILITIES=3.5,3.7,5.2,6.0,6.1,7.0 \\\r\n        CUDA_TOOLKIT_PATH=/usr/local/cuda \\\r\n        CUDNN_INSTALL_PATH=/usr/local/cuda \\\r\n        NCCL_INSTALL_PATH=/usr \\\r\n        bash configure \\\r\n   && bazel build \\\r\n        --config=opt --config=cuda \\\r\n        --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" \\\r\n        //tensorflow/tools/pip_package:build_pip_package \\\r\n     && ./bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\r\n\r\n```\r\n\r\n```\r\nStarting local Bazel server and connecting to it...\r\n...............\r\nBuilding: no action\r\nBuilding: no action\r\nBuilding: no action\r\nERROR: /tmp/tensorflow-r1.9/tensorflow/contrib/lite/kernels/internal/BUILD:529:1: no such package '@androidndk//': The repository could not be resolved and referenced by '//tensorflow/contrib/lite/kernels/internal:cpu_check'\r\nERROR: Evaluation of query \"deps(//tensorflow/tools/pip_package:build_pip_package)\" failed: errors were encountered while computing transitive closure\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "I've update filled out following filed in the issue\r\n - Have I written custom code: no custom code\r\n - CUDA/cuDNN version: CUDA 9.0, cuDNN 7.1\r\n - GPU model and memory: NVIDIA GTX Titan X 12GB\r\n - Exact command to reproduce: update build env. setting", "@hephaex : You need to configure AndroidNDK by running ./configure and update the path to NDK.", "@shashishekhar : Thanks you kind comment. In my develop env. , I don't need to AndroidNDK. \r\nThe Tensorflow r1.8 is successful build from released source as same as same build pipeline, but the TensorFlow r1.9 is not successful build. Why it happen stop during bazel compile sequence. I try to review bazel's configuration. ", "doesn't work for me too", "@hephaex  can you attach your tensorflow/.tf_configure.bazelrc?  ", "@shashishekhar \r\nhere is my tensorflow/.tfl_configure.bazelrc\r\n\r\n```\r\nbuild --action_env PYTHON_BIN_PATH=\"/usr/local/bin/python\"\r\nbuild --action_env PYTHON_LIB_PATH=\"/usr/local/lib/python3.6/site-packages\"\r\nbuild --python_path=\"/usr/local/bin/python\"\r\nbuild --define with_jemalloc=true\r\nbuild --define with_gcp_support=true\r\nbuild --define with_hdfs_support=true\r\nbuild --define with_s3_support=true\r\nbuild:kafka --define with_kafka_support=true\r\nbuild --define with_xla_support=true\r\nbuild:gdr --define with_gdr_support=true\r\nbuild:verbs --define with_verbs_support=true\r\nbuild --action_env TF_NEED_OPENCL_SYCL=\"0\"\r\nbuild --action_env TF_NEED_CUDA=\"1\"\r\nbuild --action_env CUDA_TOOLKIT_PATH=\"/usr/local/cuda\"\r\nbuild --action_env TF_CUDA_VERSION=\"9.0\"\r\nbuild --action_env CUDNN_INSTALL_PATH=\"/usr/lib/x86_64-linux-gnu\"\r\nbuild --action_env TF_CUDNN_VERSION=\"7\"\r\nbuild --action_env TF_NCCL_VERSION=\"1\"\r\nbuild --action_env TF_CUDA_COMPUTE_CAPABILITIES=\"3.5,3.7,5.2,6.0,6.1,7.0\"\r\nbuild --action_env LD_LIBRARY_PATH=\"/usr/local/nvidia/lib:/usr/local/nvidia/lib64\"\r\nbuild --action_env TF_CUDA_CLANG=\"0\"\r\nbuild --action_env GCC_HOST_COMPILER_PATH=\"/usr/bin/gcc\"\r\nbuild --config=cuda\r\ntest --config=cuda\r\nbuild --define grpc_no_ares=true\r\nbuild:opt --copt=-march=x86-64\r\nbuild:opt --copt=-mavx\r\nbuild:opt --copt=-mavx2\r\nbuild:opt --copt=-mfma\r\nbuild:opt --copt=-mfpmath=both\r\nbuild:opt --copt=-msse4.1\r\nbuild:opt --copt=-msse4.2\r\nbuild:opt --host_copt=-march=native\r\nbuild:opt --define with_default_optimizations=true\r\nbuild --strip=always\r\n```\r\n", "My suspicion was correct, you don't have NDK configured, try running ./configure again make sure to configure for Android which will ask you about SDK and NDK. Once you have run configuration correctly your tensorflow/.tfl_configure.bazelrc should contain Android SDK and NDK path.\r\n\r\n@hephaex : let me know if that doesn't work.", "Sure, I don't use \"Android NDK\" in tensorflow 1.9. \r\nI try running ./configure again , and then choose ./WORKSPACE for Android builds.\r\n\r\n```\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: N\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See tools/bazel.rc for more details.\r\n\t--config=mkl         \t# Build with MKL support.\r\n\t--config=monolithic  \t# Config for mostly static monolithic build.\r\nConfiguration finished\r\n```\r\n\r\n It is same the result of bazel fetch, please refer to below build sequence,\r\n\r\n```\r\nroot@e5f744e97dce:/tmp/tensorflow-r1.9# cd .;PYTHON_BIN_PATH=/usr/local/bin/python PYTHON_LIB_PATH=/usr/local/lib/python3.6/site-packages \\\r\n> bazel fetch //tensorflow/tools/pip_package:build_pip_package \r\nStarting local Bazel server and connecting to it...\r\n..................\r\nERROR: /tmp/tensorflow-r1.9/tensorflow/contrib/lite/kernels/internal/BUILD:529:1: no such package '@androidndk//': The repository could not be resolved and referenced by '//tensorflow/contrib/lite/kernels/internal:cpu_check'\r\nERROR: Evaluation of query \"deps(//tensorflow/tools/pip_package:build_pip_package)\" failed: errors were encountered while computing transitive closure\r\nBuilding: no action\r\n```\r\n", "Sorry, I misread it to being related to APK.\r\n@gargn Looks like it is coming from //tensorflow/contrib/lite/toco/python:toco_from_protos \r\nand easy way to check it by running the following query:\r\nbazel query \"deps(//tensorflow/tools/pip_package:build_pip_package)\"", "After running \r\n```bazel query \"deps(//tensorflow/tools/pip_package:build_pip_package)\"```\r\n\r\nGetting the following, Please advise how to configure the paths, I am new to android\r\n```\r\nsathish@sathish-linux-deep:~/gitRepos/tensorflow/tensorflow$ bazel query \"deps(//tensorflow/tools/pip_package:build_pip_package)\"\r\nStarting local Bazel server and connecting to it...\r\nERROR: /home/sathish/gitRepos/tensorflow/tensorflow/tensorflow/contrib/lite/kernels/internal/BUILD:613:1: no such package '@androidndk//': The repository could not be resolved and referenced by '//tensorflow/contrib/lite/kernels/internal:cpu_check'\r\nERROR: /home/sathish/gitRepos/tensorflow/tensorflow/tensorflow/contrib/lite/kernels/internal/BUILD:613:1: no such package '@androidndk//': The repository could not be resolved and referenced by '//tensorflow/contrib/lite/kernels/internal:cpu_check'\r\nERROR: Evaluation of query \"deps(//tensorflow/tools/pip_package:build_pip_package)\" failed: errors were encountered while computing transitive closure\r\nsathish@sathish-linux-deep:~/gitRepos/tensorflow/tensorflow$\r\n```", "@Giribushan :  In my case, I don't need to Android NDK but it occurs failure when \"TF_SET_WORKSPACE =1 & T_CUFA=1\".  Temporary way, I install Android NDK to make Tensorflow wheels. I wish you solve error , please refer to my build configuration.\r\n\r\n```bash\r\nPYTHON_BIN_PATH=/usr/local/bin/python \\\r\nPYTHON_LIB_PATH=/usr/local/lib/python3.6/site-packages \\\r\nGCC_HOST_COMPILER_PATH=/usr/bin/gcc \\\r\nCC_OPT_FLAGS=\"-march=x86-64 -mavx -mavx2 -mfma -mfpmath=both -msse4.1 -msse4.2\" \\\r\nTF_NEED_JEMALLOC=1 \\\r\nTF_NEED_GCP=1 \\\r\nTF_NEED_HDFS=1 \\\r\nTF_ENABLE_XLA=1 \\\r\nTF_NEED_VERBS=0 \\\r\nTF_NEED_OPENCL_SYCL=0 \\\r\nTF_NEED_CUDA=1 \\\r\nTF_CUDA_CLANG=0 \\\r\nTF_NEED_TENSORRT=0 \\\r\nTF_NEED_MPI=0 \\\r\nTF_NEED_GDR=0 \\\r\nTF_NEED_S3=1 \\\r\nTF_NEED_KAFKA=0 \\\r\nTF_SET_ANDROID_WORKSPACE=1 \\\r\nTF_CUDA_VERSION=9.0 \\\r\nTF_CUDNN_VERSION=7.1 \\\r\nTF_NCCL_VERSION=2.2 \\\r\nTF_CUDA_COMPUTE_CAPABILITIES=3.5,3.7,5.2,6.0,6.1,7.0 \\\r\nCUDA_TOOLKIT_PATH=/usr/local/cuda \\\r\nCUDNN_INSTALL_PATH=/usr/local/cuda \\\r\nNCCL_INSTALL_PATH=/usr/lib/nccl \\\r\nMPI_HOME=/usr/lib/openmpi \\\r\nANDROID_SDK_HOME=/root/Android \\\r\nANDROID_NDK_HOME=/root/Android/android-ndk \\\r\nbash configure\r\n```", "@case540 : Mike do you know how one can avoid the Android ndk rule dependency, without Android NDK being configured.", "This is still an issue.", "Sorry, was on vacation. This is on my radar and I'll try to look into it sometime this week. Thanks for reporting it!", "Adding @angersson, he might have just fixed this issue (or at least a very similar one)", "This is still an issue.", "I don't think I fixed this, unfortunately.\r\n\r\nAs a fast workaround for `bazel query` halting, you can use `bazel query --keep_going`, which ignores those errors.", "Maybe the newest bazel has fixed this?", "As far as I understand, in the configure.py the ANDROID_SDK_HOME and ANDROID_NDK_HOME should be passed into the Bazel's .bazelrc file into [--action_env command line option](https://bazel.build/designs/2016/06/21/environment.html).\r\nFor this, in the script it should be something like here: https://github.com/tensorflow/tensorflow/blob/d8b89170d98d200d3538a6435159f561aa888015/configure.py#L236\r\n\r\nHope that helps. I just run into the same problem with my use case (not TF-related), so decided to reach out.\r\n/cc @case540 ", "The configure script does add those --action_env args. Is this still an issue or obsolete?\r\n\r\nAs far as I know, if you run configure properly, and set the correct ANDROID SDK/NDK paths, everything should work.", "So there is still no solution for people trying to build without any Android SDK or NDK? In my case, //tensorflow/contrib/lite/kernels/internal:cpu_check is referencing it even though I'm setting TF_SET_ANDROID_WORKSPACE=0", "Any update how to disable this...?", "As a temporary hack (if you don't want the android ndk) you can just remove it:\r\n\r\n```bash\r\nsed -i '/androidndk/d' tensorflow/lite/kernels/internal/BUILD\r\n```", "Not sure how I unassigned anything, I shouldn't even have permission for that.", "comment code @ andoridndk//:cpufeatures in tensorflow/contrib/lite/kernels/internal/BUILD", "Marking issue as resolved. Feel free to re-open this if it's unresolved or file a [new issue](https://github.com/tensorflow/tensorflow/issues/new/choose)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/20919\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/20919\">No</a>\n"]}, {"number": 20918, "title": "Resilient Backpropagation Optimizer", "body": "Rprop was originally proposed by Riedmiller and Braun in the paper [A direct adaptive method for faster backpropagation learning: the RPROP algorithm](https://doi.org/10.1109/ICNN.1993.298623)\r\n\r\nThere are two variants implemented in this contribution:\r\n\r\n1. iRprop+ which is described in the article\r\n  [Empirical evaluation of the improved Rprop learning algorithms](https://doi.org/10.1016/S0925-2312(01)00700-7)\r\n\r\n2. Rprop-  which is described in Riedmiller's article\r\n  [Advanced supervised learning in multi-layer perceptrons \u2014 From backpropagation to adaptive learning algorithms](https://doi.org/10.1016/0920-5489(94)90017-5), and is referred to as Rprop- (Rprop without weight-backtracking) in the\r\n  article [Empirical evaluation of the improved Rprop learning algorithms](https://doi.org/10.1016/S0925-2312(01)00700-7).\r\n\r\n\r\n\r\n\r\nThe TensorFlow implementation is described in the article\r\n  [Resilient Backpropagation (Rprop) for Batch-learning in TensorFlow](https://openreview.net/forum?id=r1R0o7yDz)\r\n", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "I confirm that I am OK with the pull request and with my commits being contributed to this project.\r\nCheers,\r\nChristian", "@ciprianflow Please sign the CLA.", "@googlebot rescan", "I signed it!", "@ciprianflow is it possible that you signed it with a different email than the one(s) used to commit the code in the PR? The CLA bot seems to indicate that.", "Thank you for the feedback @alextp\r\nI have responded and pushed the changes.\r\n\r\n@rmlarsen I think we both signed the agreements. I've checked the email used for the commits and it is the same. Trying again..\r\n@googlebot rescan\r\n", "Sorry if I wasn't clear. Passing a non-scalar loss to tf.gradients will\nimplicitly reduce it to a scalar (though the scalar is never actually\ncomputed). Since your code doesn't seem to use the non-scalar loss in any\nway other than to pass it to tf.gradients I believe you do not need to\nreduce it.\n\nOn Mon, Sep 17, 2018 at 5:15 PM Ciprian F. <notifications@github.com> wrote:\n\n> *@ciprianflow* commented on this pull request.\n> ------------------------------\n>\n> In tensorflow/contrib/opt/python/training/irprop_plus.py\n> <https://github.com/tensorflow/tensorflow/pull/20918#discussion_r218266054>\n> :\n>\n> > +    @compatibility(eager)\n> +    When eager execution is enabled, `loss` should be a Python function that\n> +    takes elements of `var_list` as arguments and computes the value to be\n> +    minimized. If `var_list` is `None`, `loss` should take no arguments.\n> +    Minimization (and gradient computation) is done with respect to the\n> +    elements of `var_list` if not `None`, else with respect to any trainable\n> +    variables created during the execution of the `loss` function.\n> +    `gate_gradients`, `aggregation_method`, `colocate_gradients_with_ops` and\n> +    `grad_loss` are ignored when eager execution is enabled.\n> +    @end_compatibility\n> +    \"\"\"\n> +    # Override method from base class, the loss is required to be scalar\n> +\n> +    # Error E(t)\n> +    if not self._is_scalar(loss):\n> +      raise ValueError(\"'loss' (%s) must be a 0-D tensor.\" % loss)\n>\n> @alextp <https://github.com/alextp> It does not reduce the loss to a\n> scalar for me (tested in OptimizerV2), unless the weights are scalars. For\n> example, after running the code below, the cost is a vector which needs to\n> be reduced to a scalar in order to feed the error to IRprop+. Am I missing\n> something? some help would be much appreciated. Thank you.\n>\n> import tensorflow as tf\n>\n> x1 = tf.Variable([1.0, 2.0])\n> x2 = tf.Variable([2.0, 3.0])\n> loss = 2*x1**2 + 3*x2\n>\n> grad = tf.gradients(loss, [x1, x2])\n>\n> init = tf.global_variables_initializer()\n>\n> with tf.Session() as sess:\n> sess.run(init)\n> grad_value = sess.run(grad)\n> print(sess.run(loss))\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/20918#discussion_r218266054>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxcPk9s1sDpUbJw3vebngZzbv14qqks5ucDsogaJpZM4VUV9I>\n> .\n>\n\n\n-- \n - Alex\n", "@ciprianflow Could you please rebase you PR to resolve merge conflicts?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "> It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.\r\n\r\nYes, the PR is still valid. Sorry for the long silence, we will work on it asap.", "It has been 28 days that this pull-request has stalled. Please create a new pull-request with the requested changes."]}, {"number": 20917, "title": "pull", "body": "", "comments": ["Mistakenly created PR"]}, {"number": 20916, "title": "tf.contrib.graph_editor.graph_replace is broken for while loops", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: \r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.9\r\n- **Python version**: 2.7.13\r\n\r\n### Describe the problem\r\ntf.contrib.graph_editor.graph_replace is broken for Graphs containing while-loops.\r\n\r\n### Source code / logs\r\nI've created a commit (1b9f2a5) which adds a simple test in tensorflow/contrib/graph_editor/tests/transform_test.py, which creates a graph with a while loop and replaces one of the variables therein:\r\n\r\n```python\r\n  def test_graph_replace_while_loop(self):\r\n    ops.reset_default_graph()\r\n    a = constant_op.constant(1, name=\"a\")\r\n    max_index = constant_op.constant(10)\r\n    index_start = constant_op.constant(1)\r\n    sum_start = constant_op.constant(0)\r\n    _, result = control_flow_ops.while_loop(\r\n        cond=lambda i, unused_s: i <= max_index,\r\n        body=lambda i, s: (i + 1, s + a),\r\n        loop_vars=[index_start, sum_start])\r\n    a_new = constant_op.constant(2, name=\"a_new\")\r\n    result_new = ge.graph_replace(result, {a: a_new})\r\n    with session.Session() as sess:\r\n      sess.run(variables.global_variables_initializer())\r\n      result_val, result_new_val = sess.run([result, result_new])\r\n    self.assertEqual(result_val, 10, ERROR_TOLERANCE)\r\n    self.assertEqual(result_new_val, 20, ERROR_TOLERANCE)\r\n```\r\n\r\nThe test fails as follows:\r\n\r\n```python\r\n........I0718 03:06:24.128054    6838 control_flow_util.py:313] Cannot use 'while/LessEqual/Enter' as input to 'while/LessEqual_1' because 'while/LessEqual/Enter' is in a while loop.\r\n\r\nwhile/LessEqual_1 while context: None\r\nwhile/LessEqual/Enter while context: while/while_context\r\n```\r\n\r\n", "comments": ["@purpledog, any insights on which might be going on here?", "Contrib will be deprecated. It's better to contact original contributor on this issue.\r\n", "This is still an issue. I've been in touch with the original author, and am trying to fix it myself but lack spare cycles at the moment.", "Please do upgrade to a latest `Tensorflow` version.\r\nSince `contrib` has been depreciated in `Tensorflow 2.x` and `graph_editor` is no longer available in `Tensorflow 2.x`.\r\nYou can refer [this](https://www.tensorflow.org/guide/effective_tf2#no_more_globals) document for more details on the dynamics of `TF 2`.\r\n"]}, {"number": 20915, "title": "Heavily increased memory consumption for optimizing batch_norm in tf versions > 1.3.0 ", "body": "- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n\r\n    I attach a code example that is intended to profile memory consumption for different layers of a network under different tensorflow versions. This should in principle work out of the box.\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n\r\n    VERSION=\"16.04.3 LTS (Xenial Xerus)\"\r\n    VERSION_ID=\"16.04\"\r\n    VERSION_CODENAME=xenial\r\n\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\n\r\n    pip install tensorflow-gpu==1.3.0\r\n    and\r\n    pip install tensorflow-gpu==1.5.0\r\n    and\r\n    pip install tensorflow-gpu==1.8.0\r\n    and\r\n    pip install tensorflow-gpu==1.9.0\r\n\r\n- **TensorFlow version (use command below)**:\r\nThe following tf versions were used to recreate the issue\r\n    tf.GIT_VERSION = b'unknown' \r\n    tf.VERSION = 1.3.0\r\n    and\r\n    tf.GIT_VERSION = v1.5.0-0-g37aa430d84\r\n    tf.VERSION = 1.5.0\r\n    and\r\n    tf.GIT_VERSION = v1.8.0-0-g93bc2e2072 \r\n    tf.VERSION = 1.8.0\r\n    and\r\n    tf.GIT_VERSION = v1.9.0-0-g25c197e023\r\n    tf.VERSION = 1.9.0\r\n  \r\n- **Python version**:\r\nPython 3.5.5 :: Anaconda, Inc.\r\n- **CUDA/cuDNN version**:\r\n    For tf 1.3.0:\r\n    nvcc: NVIDIA (R) Cuda compiler driver\r\n    Copyright (c) 2005-2016 NVIDIA Corporation\r\n    Built on Tue_Jan_10_13:22:03_CST_2017\r\n    Cuda compilation tools, release 8.0, V8.0.61\r\n    \r\n    For tf 1.5.0, 1.8.0, 1.9.0\r\n    nvcc: NVIDIA (R) Cuda compiler driver\r\n    Copyright (c) 2005-2017 NVIDIA Corporation\r\n    Built on Fri_Sep__1_21:08:03_CDT_2017\r\n    Cuda compilation tools, release 9.0, V9.0.176\r\n- **Bazel version (if compiling from source)**:\r\n    N/A\r\n- **GPU model and memory**:\r\n    GeForce GTX 1080 Ti\r\n    total memory shown as 10.91GiB\r\n- **Exact command to reproduce**:\r\n    python 'script shown below'\r\n\r\n### Describe the problem\r\nWhen trying to update from tensorflow 1.3.0 to a newer version, we noticed that memory consumption increased significantly for our networks.  \r\nWe tried to find out what was causing this issue and realized that there is a large discrepancy for memory consumption in our batch normalization layers when optimizing the network in training.\r\nI attach the code necessary to reproduce the results. \r\nIn the code the following happens:\r\n   First, a rather useless network of 10 batch normalization layers is created. In the examples shown below, this network expects 1D input of width 500 with 32 channels and a batch size of 16. \r\n   Second, a GPU profiler is started, repeatedly calling nvidia-smi to check the current memory consumption. While the memory usage is measured, the network is evaluated 2500 times, under many different conditions. Lastly, the timings and the memory consumption over time are saved and plotted for comparison of the tf versions. \r\n\r\n### What is the problem? \r\n\r\nThe results from running the code under 4 different conditions is shown in the plots below.\r\n1. Fused batch norm is used if possible, *with gradient update*, version specific batch norm\r\n2. Fused batch norm is used if possible, *without gradient update*, version specific batch norm\r\n3. No fused batch norm, *without gradient update*, all use batch normalization as in \r\nhttps://raw.githubusercontent.com/tensorflow/tensorflow/r1.3/tensorflow/python/layers/normalization.py\r\n4. No fused batch norm,*with gradient update*, all use batch normalization as in \r\nhttps://raw.githubusercontent.com/tensorflow/tensorflow/r1.3/tensorflow/python/layers/normalization.py\r\n\r\nFor 3 and 4, we still run the different tf versions, but we copied the mentioned file directly to our repo and call the batch_normalization from that file.\r\n\r\nFurthermore, currently the layout optimizer in the session config is turned off, but we also tried this with the layout optimizer turned on and this has no effect on this issue.\r\n\r\n#### 1.\r\n[batch_norm_fused_optimizing_step.pdf](https://github.com/tensorflow/tensorflow/files/2205279/batch_norm_fused_optimizing_step.pdf)\r\n#### 2.\r\n[batch_norm_fused_without_optimizing_step.pdf](https://github.com/tensorflow/tensorflow/files/2205281/batch_norm_fused_without_optimizing_step.pdf)\r\n#### 3.\r\n[batch_norm_unfused_1.3_implementaion.pdf](https://github.com/tensorflow/tensorflow/files/2205284/batch_norm_unfused_1.3_implementaion.pdf)\r\n#### 4.\r\n[batch_norm_unfused_1.3_implementaion_with_update.pdf](https://github.com/tensorflow/tensorflow/files/2205285/batch_norm_unfused_1.3_implementaion_with_update.pdf)\r\n\r\nFrom these plots, it seems that versions > 1.3.0 need a significant amount of extra memory when doing a gradient update step. For example, memory requirements for Batch norm in 1.9 increased by 50% compared to 1.3. Why is that?\r\n\r\n### Request\r\nIs there a way to circumvent the increased memory consumption? I assume some optimizing is happening in the background in newer versions, which leads to an increase in memory requirements. Can this be turned off?\r\n\r\n\r\n### Source code / logs\r\nSource code necessary to reproduce the problem is attached below.\r\n\r\nIn principle, however, I repeatedly run nvidia-smi for memory profiling and measure timing and memory for the following \r\n```\r\nfor i in range(self.steps):\r\n    start = time.time()\r\n    sess.run([net, train_op])\r\n    durations[i] = time.time() - start\r\n```\r\n[code.zip](https://github.com/tensorflow/tensorflow/files/2205292/code.zip)\r\n", "comments": ["@asimshankar would you PTAL? ", "There might be an issue with the provided code, there is an import missing. I'm attaching a new code.zip that fixes this issue.\r\n[code.zip](https://github.com/tensorflow/tensorflow/files/2263210/code.zip)\r\n", "I haven't had a chance to look into this yet, CCing @chsigg @reedwm @tfboyd in case they have some ideas. ", "The graphs measure time spent per step, and GPU utilization. But you are talking about memory consumption in the issue. Are you concerned about step time/utilization, or memory consumption?\r\n\r\nAlso, a smaller example that reproduces the issue would be helpful.", "GPU utilisation in the graph refers to percent of GPU memory being used, sorry for the ambiguity.\r\n\r\nThe example in itself is as small as I could get it. The reason the code has so many lines is mainly to allow for measuring the GPU memory consumption automatically when starting the sess.run.\r\nBut as I said earlier, at the end all that I do is run the following for different configurations\r\n```\r\nfor i in range(self.steps):\r\n    start = time.time()\r\n    sess.run([net, train_op])\r\n    durations[i] = time.time() - start\r\n```\r\n", "Briefly skimming your code, I noticed you ran \r\n```\r\nnvidia-smi --query-gpu=utilization.memory --format=csv\r\n```\r\nThe name \"utilization.memory\" is very confusing. According to `nvidia-smi --help-query-gpu`, `utilization.memory` is the \"Percent of time over the past sample period during which global (device) memory was being read or written.\" This is not the amount of memory used.\r\n\r\nThe best way to check for memory regression is to use binary search to find the largest batch size you can run with. If the largest batch size decreases, there is a regression. Alternatively, you can run with a fixed batch size and check memory usage with the [`tf.contrib.memory_stats.MaxBytesInUse`](https://www.tensorflow.org/api_docs/python/tf/contrib/memory_stats/MaxBytesInUse) op", "Yes, this is still an issue.\r\nNewer versions of tensorflow force us to use dramatically less batch_norm layers or reduce our batch size in almost half. ", "@paulomarciano : Did you see @reedwm 's https://github.com/tensorflow/tensorflow/issues/20915#issuecomment-416685756 ?\r\n\r\nCould you elaborate on the mechanism used to measure memory utilization? If you run with the same batch size in a newer version - does the process crash (because it runs out of memory)?\r\n ", "Yes, this is how we found the issue ", "To make it easier to replicate the problem, I submit here a very simple piece of code that builds a network and tries different batch sizes succesively. On a GTX 1080 TI, tensorflow 1.10 goes up to 150 batch size, while 1.3 goes up to 180. \r\n[example_net.zip](https://github.com/tensorflow/tensorflow/files/2386736/example_net.zip)\r\n\r\n", "Just letting you know that this is still an issue. I would like to update to newer tensorflow versions, but the memory restrictions this imposes make it unsavory.", "Indeed, it is a significant issue. The error is easily reproducible with the 36 line script that @paulomarciano uploaded. \r\n\r\n@tensorflow-team can you reproduce it? If so, do you have any idea why the memory consumption is increasing?", "I also encounter heavily increased memory consumption when using batchnorm, but when I use a boolean placeholder to control \"training\" or not. If I use a plain python boolean, then my memory consumption is much much lower. but my pipeline makes it necessary for me to switch between \"training\" modes on the fly. For all my experiments, I'm using \"trainable=True\", and TF1.9", "Thank you for the suggestion @extragoya. However, we are using a normal boolean (see provided code) and still experience the issue.\r\nWere you able to reproduce the issue @reedwm?", "Has any progress been made on this? It would really be helpful to know at least the cause of this behavior.", "Could you share the TensorFlow graph with TF 1.3 and the next version that shows regression? You can refer to this answer for instructions to dump the default TensorFlow graph.\r\nhttps://stackoverflow.com/a/34440319/9501553\r\n\r\nThis will help check if the regression is happening because use of different ops or some change in the op implementation. I couldn't find a way to dump the optimized graph after transformation but the above should still be useful.", "Sure. Here's a zip file with an example of the graph for 1.3, one for 1.12, and the code used to generate it.\r\n[example_net.zip](https://github.com/tensorflow/tensorflow/files/2991674/example_net.zip)\r\n", "I have the same problem currently.  I ran into training vs. evaluation issues when using a model where I manually created trainable variables and used tf.nn.batch_normalization.  It seemed there was some modifications to the update ops that I should have been doing (per https://github.com/tensorflow/tensorflow/issues/16455) to fix the evaluation performance.  Instead of doing this I tried using the tf.layers.batch_normalization and tf.keras.layers.BatchNormalization and ran into memory issues -- batch size of 64 worked using the tf.nn.batch_normalization() function while it failed with the *.layers.* implementations but worked with batch size of 50.  \r\n\r\nEdit: also wanted to confirm that the exact same number of parameters and data input was used in each case.", "I am also having this issue when I try to use tf.keras.layers.BatchNormalization within a custom estimator. I have followed the solution from https://github.com/tensorflow/tensorflow/issues/16455 but I am getting significant memory leak that disappears if I take out the BatchNormalization (+ the steps taken to pass the update ops) -- the only way I can keep the model from going OOM is to set the \"save-checkpoint-steps\" and \"save-summary-steps\" flags to be less frequent.\r\n\r\n@spencerfrei did you ever find a resolution to the memory issues?", "@moboehle \r\nIt looks like you are using an older Version of Tensorflow (1.x) which is out of support window. Many bugs have been fixed in the latest version. Can you please execute your code using Latest Version (2.6.0) and let us know if the issue still persists? Please refer to the[ link1,](https://www.tensorflow.org/guide/data_performance) [link2](https://www.tensorflow.org/api_docs/python/tf/compat/v1/layers/batch_normalization) and let us know if it helps? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/20915\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/20915\">No</a>\n"]}, {"number": 20914, "title": "ResourceVariable save will lead to OOM in distributed mode", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.4\r\n- **Python version**: 2.7.5\r\n- **Bazel version (if compiling from source)**: 0.9\r\n- **GCC/Compiler version (if compiling from source)**: 4.8.5\r\n- **CUDA/cuDNN version**: 7.5\r\n- **GPU model and memory**: None\r\n- **Exact command to reproduce**: save ResourceVariable in a distributed mode\r\n\r\n\r\n### Describe the problem\r\nMy model is more than 200GB so I run it in distributed mode on CPU, including 1000 workers and 100 ps. All the variables of my model are ResourceVariable partitioned by size,  and these variables are placed by the default tf.replica_device_setter. The model is triggered by a MonitoredTrainingSession. \r\n\r\nProblem happens when it begins to save model. The memory of ps0 rises to 200GB rapidly and then OOM.  I open the log placement and find that all variables are identity to ps0 when running save_op.\r\nIn ResourceVariableSaveable, line 182 reset the device, which leads to all save_ops are placed on ps0. I remove this line and re-run, it works correctly.\r\n\r\n```\r\n 168   class ResourceVariableSaveable(SaveableObject):\r\n 169     \"\"\"SaveableObject implementation that handles ResourceVariables.\"\"\"\r\n 170\r\n 171     def __init__(self, var, slice_spec, name):\r\n 172       self._var_device = var.device\r\n 173       if isinstance(var, ops.Tensor):\r\n 174         self.handle_op = var.op.inputs[0]\r\n 175         tensor = var\r\n 176       elif isinstance(var, resource_variable_ops.ResourceVariable):\r\n 177\r\n 178         def _read_variable_closure(v):\r\n 179           def f():\r\n 180             with ops.device(v.device):\r\n 181               x = v.read_value()\r\n 182             with ops.device(\"/device:CPU:0\"):\r\n 183               return array_ops.identity(x)\r\n 184           return f\r\n 185\r\n 186         self.handle_op = var.handle\r\n 187         tensor = _read_variable_closure(var)\r\n 188       else:\r\n 189         raise ValueError(\r\n 190             \"Saveable is neither a resource variable nor a read operation.\"\r\n 191             \" Got: %s\" % repr(var))\r\n 192       spec = BaseSaverBuilder.SaveSpec(tensor, slice_spec, name)\r\n 193       super(BaseSaverBuilder.ResourceVariableSaveable, self).__init__(\r\n 194           var, [spec], name)\r\n```\r\n\r\n### Source code / logs\r\nOpen the log placement to see all save_ops are placed on ps0. So many such logs\r\n```\r\n [2018-07-18 16:02:41.883522] [INFO] [31791] [tensorflow/core/common_runtime/placer.cc:698] Ignoring device specification /device:CPU:0 for node 'save_2/AssignVariableOp_176' because the input edge from 'Optimize/OptimizeLoss/CTR-PositionNetwork/position_hiddenlayer_1/weights/part_7/AdagradDecay_1'       is a reference connection and already has a device field set to /job:ps/task:16\r\n```\r\n\r\n[log.txt](https://github.com/tensorflow/tensorflow/files/2205249/log.txt)\r\n\r\n", "comments": ["Thanks for tracking this down. @agarwal-ashish it looks as if you put in this device assignment would you take a look thanks.", "@agarwal-ashish \r\nwhen I use partitioned ResourceVariable, it will be go to Line176. Line181 'x' is already an tf.identity with \"v.device\", Line183 changes the device placement using another tf.identity. It makes the Identity OP placement with \"/device:CPU:0\", after build graph in python, TF will get the candidate Devices for Identity OP in c++, finally select the default device \"/job:ps/replica:0/task:0/device:CPU:0\" (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/placer.cc#L861), the same process happen in SaveV2 OP. It results OP placement imbalance.\r\nOnly job:ps/task:0 has a SaveV2 OP, though I use the API `tf.train.Saver(sharded=True)`.\r\nThe API `tf.train.Saver(sharded=True)` works well with Variable and non-partitioned ResourceVariable.\r\nIs it by design?", "This intention here is to handle checkpointing of Variables placed on GPU when running with explicit device placement policy in Eager mode. I am submitting a fix that copies it to the CPU on the same machine instead of overriding the device to \"/device:CPU:0\" which might place it on a different job.", "@agarwal-ashish thanks for reply. I make a change in my local repo. It works well and looks simple. Here is the PR https://github.com/tensorflow/tensorflow/pull/20985. Maybe you can check whether it is helpful.", "Did you test if the code after commit# 8f130ff5b021efb94946ed9deb1341890763fd3f  work for you ? \r\n ", "@agarwal-ashish No, I just test my fix, the indent one. I will test it later.", "@agarwal-ashish The two fixes both work correctly. The only difference is you parse the device info manually and I utilize the context.", "Thanks for the fix!"]}, {"number": 20913, "title": "Keras guide webpage: tf.keras.version links to a dead webpage.", "body": "## System Information\r\n**Have I written custom code:** No\r\n**OS Platform and Distribution:** Windows 10 Pro\r\n**TensorFlow installed from:** source\r\n**TensorFlow version:** N/A\r\n**Bazel version:** N/A\r\n**CUDA/cuDNN version:** N/A\r\n**GPU model and memory:** Nvidia GeForce GTX 950m 4GB\r\n**Exact command to reproduce:** N/A\r\n\r\n## Describe the problem\r\n- On [this](https://www.tensorflow.org/guide/keras) TensorFlow guide website, I found that it mentions using `tf.keras.version` to check the keras version. However, it should be `tf.keras.__version__` instead of `tf.keras.version`. \r\n\r\n- Also, it links to a [webpage](https://www.tensorflow.org/api_docs/python/tf/keras/__version__) which throws `404` error.\r\n\r\n![tf keras issue](https://user-images.githubusercontent.com/29359259/42868356-bb35fbf0-8a8f-11e8-81e5-50b537942d62.PNG)\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Fixed it.", "Thanks!", "I'm sorry for the confusion, but I said 'fixed it' to tell that I fixed the thing that the bot was talking about regarding the template. Not because the issue was fixed @drpngx ", "I think that makes sense. Please send a PR.", "I can't find the website code in tensorflow/tensorflow repository. Can you point me to it?", "It's probably [here](https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/guide/keras.md#L36).", "I checked that file already. There's no issue in the file, it's all correct. But the webpage is different (as shown in the screenshot above) than this Keras.md file that you shared. The **webpage** documentation has the issue.\r\n\r\nJust like there's a tfjs-website repository for tensorflow.js website, I want to know how I can fix the issue on tensorflow.org website.\r\n\r\nI hope this makes it clear.", "The file seems to say `tf.keras.__version__` at line 35, right?", "For the website, probably @MarkDaoust can fix it directly.", "Yes. Thanks.\r\n\r\nWe're working on breaking the website out of the main repo so that we're not tied to release branches, as we currently are.\r\n\r\nThat will let us fix things like this more easily.\r\n\r\nThe 404 ... probably needs a fix to the api-reference generator. simple constants don't have api pages. That will take some work.", "Nagging Assignee @MarkDaoust: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 20912, "title": "android how to get time consuming ,node type and other information", "body": "![20170623201903623](https://user-images.githubusercontent.com/11265867/42868674-7c9973c0-8aa5-11e8-9558-4ae018dd96bd.png)\r\n I find a tensorflow lite app\u2018s screenshot \uff0chow to do it like that?\r\n ", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Have I written custom code N/A\r\nOS Platform and Distribution N/A\r\nTensorFlow installed from N/A\r\nTensorFlow version N/A\r\nBazel version N/A\r\nCUDA/cuDNN version N/A\r\nGPU model and memory N/A\r\nExact command to reproduce N/A", "@298068845 I apologize but I have hard time understanding what kind of help you need. Could you please clarify?\r\n", "@298068845 : You can try using https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite/tools/benchmark for per node statistics. We don't expose this in the Java API yet, if the original image is using TFLite example, it maybe generated by making changes to the example code.", "@298068845 : Please reopen if you still need help."]}, {"number": 20911, "title": "Edit  a link to notebooks directory", "body": "Bottom of this document, a link to **notebooks directory** who has tutorial misslinked.\r\nNeed to change from `..` to `../notebooks`.", "comments": []}, {"number": 20910, "title": "move_binary_operator_before_reshape.cc:76] Check failed: binary_op->inputs.size() == 2 (1 vs. 2)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Y\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux  4.17.5-1-ARCH\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: b'v1.9.0-rc2-623-geb04124bb7' 1.9.0-rc0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: 0.14.1- (@non-git)\r\n- **GCC/Compiler version (if compiling from source)**: gcc-7.1\r\n- **CUDA/cuDNN version**: cuda-9.2 cudnn-7.1\r\n- **GPU model and memory**: 16G\r\n- **Exact command to reproduce**:\r\n\r\nI use `models/research/object_detection/export_tflite_ssd_graph.py` to export the tflite_graph.pb and it's fine. Then use this command to convert it to tflite model:\r\n`\r\nbazel run -c opt tensorflow/contrib/lite/toco:toco -- \\\r\n      --input_file=$OUTPUT_DIR/tflite_graph.pb \\\r\n      --output_file=$OUTPUT_DIR/detect.tflite \\\r\n      --input_shapes=1,360,480,3 \\\r\n      --input_arrays=normalized_input_image_tensor \\\r\n      --output_arrays='raw_outputs/box_encodings','raw_outputs/class_predictions'  \\\r\n      --inference_type=QUANTIZED_UINT8 \\\r\n      --mean_values=128 \\\r\n      --std_values=128 \\\r\n      --change_concat_input_ranges=false \\\r\n      --allow_custom_ops\r\n`\r\n**It worked fine either yesterday but now when I ran  `git pull` on master branch** with newest commit id  81161f9d9987a8eb70793d95048c20be34292859 it crashed like this:\r\n`\r\ntensorflow/contrib/lite/toco/graph_transformations/move_binary_operator_before_reshape.cc:76] Check failed: binary_op->inputs.size() == 2 (1 vs. 2) Aborted\r\n`\r\nCan you take a look at it ?", "comments": ["It's ok now with today's `git pull`."]}, {"number": 20909, "title": "Tflite_convert error", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:  No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: pip install\r\n- **TensorFlow version (use command below)**: tensorflow 1.9\r\n- **Python version**: Python 2.7\r\n\r\n### Describe the problem\r\nI have written a script to convert my frozen file(.pb) into a quantized tflite (quant.lite). I keep getting the error shown below. Anyone can help me? \r\n\r\ntflite_convert: error: --default_ranges_min and --default_ranges_max must be used together\r\n\r\n### Source code / logs\r\n`INPUT=INPUT\r\nOUTPUT=output_node0\r\nINFILE=./mobilenet_v1_0.25_32_2class_batchsize1_eyes.h5.pb\r\nTYPE=QUANTIZED_UINT8\r\nOUTFILE=./mobilenet_v1_0.25_32_2class_batchsize1_eyes.quant.tflite\r\nIMAGE_SIZE=32\r\nMEAN=128 \r\nSTD=128\r\nMIN=0\r\nMAX=6'\r\ntflite_convert \\\r\n  --graph_def_file=$INFILE \\\r\n  --output_file=$OUTFILE \\\r\n  --output_format=TFLITE \\\r\n  --inference_type=$TYPE \\\r\n  --input_arrays=$INPUT \\\r\n  --output_arrays=$OUTPUT \\\r\n  --mean_values=${MEAN} \\\r\n  --std_dev_values=${STD} \\\r\n  --default_ranges_min=${MIN} \\\r\n  --default_ranges_max=${MAX} \\\r\n  --input_shapes=1,${IMAGE_SIZE},${IMAGE_SIZE},3`\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Bazel version: Not installed\r\nCUDA/cuDNN version: release 9.0, V9.0.176\r\nGPU model and memory:  GeFroce GTX 1080 8GB\r\nExact command to reproduce: No error. Quantized Tflite model produced\r\n", "Looks like you are hitting this:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/python/tflite_convert.py#L203\r\n\r\ndo you have '\\' at the end of line between default_ranges_min/max lines.", "No, this is how i type for the tflite_convert command. \r\n\r\n`tflite_convert \\\r\n--graph_def_file=$INFILE \\\r\n--output_file=$OUTFILE \\\r\n--output_format=TFLITE \\\r\n--inference_type=$TYPE \\\r\n--input_arrays=$INPUT \\\r\n--output_arrays=$OUTPUT \\\r\n--mean_values=${MEAN}  \\\r\n--std_dev_values=${STD} \\\r\n--default_ranges_min=${MIN} \\\r\n--default_ranges_max=${MAX} \\\r\n--input_shapes=1,${IMAGE_SIZE},${IMAGE_SIZE},3` ", "@savageyusuff : Can you attach the original graph which you are trying to convert.", "[graphfile.zip](https://github.com/tensorflow/tensorflow/files/2217607/graphfile.zip)\r\n\r\n\r\n\r\n\r\n", "Thanks @savageyusuff I can reproduce the error with tflite_convert in Tensorflow 1.9, but when I build from master I see a different error.\r\n@gargn : Any ideas about this error.", "This [bug fix](https://github.com/tensorflow/tensorflow/commit/b5fa781337ad8becaab893d001b04f2b995575b5#diff-89aadee1025f2c5098d86824417059c1)  wasn't included in 1.9. Please use the nightly build. You can do that by either using \"pip install --upgrade tf_nightly\" or follow the instructions [here](https://www.tensorflow.org/install/install_sources).\r\n\r\nDoing this, results in another error (in the form of a suggestion to use a flag that is no longer supported). I will work on adding a fix for it in the coming days.", "The error regarding the unsupported flag mentioned in the previous comment has been fixed in the repository. Your model should convert successfully via `tflite_convert` after today's nightly build. Please reopen this bug if you encounter anymore errors using `tflite_convert` to convert this model."]}, {"number": 20908, "title": "tf.nn.conv2d() inconsistent dilation rate at runtime", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04 LTS\r\n- **TensorFlow installed from (source or binary)**: binary (pip install)\r\n- **TensorFlow version (use command below)**: ('v1.7.0-3-g024aecf414', '1.7.0')\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 9.0/7.0.5\r\n- **GPU model and memory**: GTX1080, 8GB\r\n- **Exact command to reproduce**: shown below\r\n\r\n### Describe the problem\r\nDilated convolution via tf.nn.conv2d() with data_format='NHWC' gets corrupted to 'NCHW' during sess.run(). Since the data_format alone is corrupted and the dilation rate is unchanged, the code fails with an error message indicating that it does not support dilation along the depth dimension (dilation rate of [1, 2, 2, 1] is valid for 'NHWC' format but not for 'NCHW' format).\r\n\r\nIt seems that this is a CUDA problem, since if I disable the GPU using os.environ['CUDA_VISIBLE_DEVICES'] = '' line, the code does not error out. \r\nWeirdly enough, if I don't do anything to the output of tf.nn.conv2d(), the code does not error out either (corresponds to setting use_reduce_mean=False in the below example).\r\nAlso, if the dilation rate is set as [1, 1, 2, 2], the code does not error out, although this goes against the [documentation](https://www.tensorflow.org/versions/r1.7/api_docs/python/tf/nn/conv2d), which says that `The dimension order is determined by the value of data_format`\r\n\r\n### Source code / logs\r\n\r\nsource code to reproduce the bug\r\n```\r\nimport os\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n# os.environ['CUDA_VISIBLE_DEVICES'] = ''\r\n\r\n\r\ndef bug():\r\n    use_reduce_mean = True\r\n    dilation_rate = 2\r\n\r\n    # bug # 1: conv2d changes from NHWC to NCHW\r\n    input_shape = [1, 32, 32, 1]\r\n    in_place = tf.placeholder(dtype=tf.float32, shape=input_shape)\r\n    filter_tensor = tf.Variable(tf.random_normal(\r\n        [3, 3, 1, 1], dtype=tf.float32, stddev=0.1), trainable=True)\r\n\r\n    out_tensor = tf.nn.conv2d(\r\n        in_place, filter=filter_tensor, strides=(1, 1, 1, 1),\r\n        padding='SAME', dilations=(1, dilation_rate, dilation_rate, 1),\r\n        data_format='NHWC')\r\n\r\n    if use_reduce_mean:\r\n        out_tensor = tf.reduce_mean(out_tensor)\r\n    \r\n    with tf.Session() as sess:\r\n        init_op = tf.global_variables_initializer()\r\n        init_op.run()\r\n    \r\n        f_dict = {in_place: np.zeros(input_shape)}\r\n        sess_out = sess.run(out_tensor, feed_dict=f_dict)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    bug()\r\n```\r\n\r\nerror message:\r\n```\r\n Executor failed to create kernel. Invalid argument: Current implementation does not yet support dilations in the batch and depth dimensions.\r\n         [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 2, 2, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, Variable/read)]]\r\nTraceback (most recent call last):\r\n  File \"tmp.py\", line 48, in <module>\r\n    bug()\r\n  File \"tmp.py\", line 44, in bug\r\n    sess_out = sess.run(out_tensor, feed_dict=f_dict)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 905, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1140, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1321, in _do_run\r\n    run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1340, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Current implementation does not yet support dilations in the batch and depth dimensions.\r\n         [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 2, 2, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, Variable/read)]]\r\n\r\nCaused by op u'Conv2D', defined at:\r\n  File \"tmp.py\", line 48, in <module>\r\n    bug()\r\n  File \"tmp.py\", line 27, in bug\r\n    data_format='NHWC')\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 953, in conv2d\r\n    data_format=data_format, dilations=dilations, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): Current implementation does not yet support dilations in the batch and depth dimensions.\r\n         [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 2, 2, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, Variable/read)]]\r\n```", "comments": ["@zheng-xq this looks like a real bug, can you take a look or reassign to someone else who can?", "Looks like it's been fixed in 1.10+.\r\n\r\nCommit that fix this: https://github.com/tensorflow/tensorflow/commit/032f804a2feca8995185a5fbb9dbc62d5d8df48e", "Nagging Assignee @zheng-xq: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Sorry for the late response but @stegben I think you are right, I updated the tensorflow version to 1.10 and the above code runs without any error, thanks!", "I am using 1.7 and facing the same issue. Is there any fix other than updating tensorflow version?"]}, {"number": 20907, "title": "Update keras.md", "body": "tf.keras.models should load model configuration with `model_from_json` or `model_from_yaml`, not `from_json` or `from_yaml`", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "@cheerss Can you submit this to the master branch instead?", "of course, I'll submit a new merge request", "@cheerss Thanks!"]}, {"number": 20906, "title": "failed to load keras model with tensorflow r1.9", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: from binary(pip install)\r\n- **TensorFlow version (use command below)**:1.9.0\r\n- **Python version**: 3.6.4\r\n- **Bazel version (if compiling from source)**: None\r\n- **GCC/Compiler version (if compiling from source)**: None\r\n- **CUDA/cuDNN version**:  CUDA-8.0\r\n- **GPU model and memory**: GTX1080Ti, 12G\r\n- **Exact command to reproduce**: just as the code below\r\n\r\n### Describe the problem\r\nAs the official document [here](https://www.tensorflow.org/guide/keras), tf.keras.models could be saved with `model.save('my_model.h5')`, namely, \"The entire model can be saved to a file that contains the weight values, the model's configuration, and even the optimizer's configuration\". However, when I load the model with `model = tf.keras.models.load_model('lenet_mnist.h5')`, it throws an error: **\"You are trying to load a weight file containing 5 layers into a model with 0 layers.\"**\r\n\r\n### Source code / logs\r\n#### source code(lenet_mnist.py)\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\ndef train_test_data():\r\n    (x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\r\n    x_train, x_test = x_train / 255.0, x_test / 255.0\r\n    x_train = np.expand_dims(x_train, -1)\r\n    x_test = np.expand_dims(x_test, -1)\r\n    return x_train, y_train, x_test, y_test\r\n\r\ndef train_fn():\r\n    x_train, y_train, x_test, y_test = train_test_data()\r\n    model = tf.keras.models.Sequential([\r\n        tf.keras.layers.Conv2D(6, [5, 5], strides=1, padding=\"same\", use_bias=True),\r\n        tf.keras.layers.AvgPool2D([2, 2], 2, padding=\"valid\"),   \r\n        tf.keras.layers.LeakyReLU(0),\r\n        tf.keras.layers.Conv2D(16, [5, 5], strides=1, padding=\"valid\", use_bias=True),\r\n        tf.keras.layers.AvgPool2D([2, 2], 2, padding=\"valid\"),\r\n        tf.keras.layers.LeakyReLU(0),\r\n        tf.keras.layers.Conv2D(120, [5, 5], strides=1, padding=\"valid\", use_bias=True),\r\n        tf.keras.layers.Flatten(),\r\n        tf.keras.layers.Dense(84, activation=tf.nn.relu),\r\n        tf.keras.layers.Dense(10, activation=tf.nn.softmax),\r\n    ])\r\n    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\r\n    model.fit(x_train, y_train, epochs=5, batch_size=300)\r\n    loss, test_acc = model.evaluate(x_test, y_test, verbose=1)\r\n    print(\"test_acc: \" + str(test_acc))\r\n    model.save('lenet_mnist.h5')\r\n\r\ndef test_fn():\r\n    x_train, y_train, x_test, y_test = train_test_data()\r\n    model = tf.keras.models.load_model('lenet_mnist.h5')\r\n    loss, test_acc = model.evaluate(x_test, y_test, verbose=1)\r\n    print(\"test_acc: \" + str(test_acc))\r\n\r\ndef main(unused):\r\n    train_fn()\r\n    test_fn()\r\n\r\nif __name__ == '__main__':\r\n    tf.app.run()\r\n```\r\n\r\n#### log\r\n```\r\nTraceback (most recent call last):\r\n  File \"lenet_mnist.py\", line 60, in <module>\r\n    tf.app.run()\r\n  File \"/home/wangwenxiao/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"lenet_mnist.py\", line 57, in main\r\n    test_fn()\r\n  File \"lenet_mnist.py\", line 49, in test_fn\r\n    model = tf.keras.models.load_model('lenet_mnist.h5')\r\n  File \"/home/wangwenxiao/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py\", line 232, in load_model\r\n    load_weights_from_hdf5_group(f['model_weights'], model.layers)\r\n  File \"/home/wangwenxiao/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py\", line 732, in load_weights_from_hdf5_group\r\n    ' layers.')\r\nValueError: You are trying to load a weight file containing 5 layers into a model with 0 layers.\r\n```\r\n", "comments": ["Looks like a duplicate of https://github.com/tensorflow/tensorflow/issues/20073\r\nFeel free to reopen if you think it's not."]}, {"number": 20905, "title": "Supporting a TF lite shared library target", "body": "### Describe the problem\r\nWould the TF project be open to supporting a TF lite shared library target (as is done already with `libtensorflow.so` and `libtensorflow_cc.so`)?\r\n\r\nI believe many people would benefit from this, based on recent related issues:\r\nhttps://github.com/tensorflow/tensorflow/issues/18060\r\nhttps://github.com/tensorflow/tensorflow/issues/17826\r\nhttps://github.com/tensorflow/tensorflow/issues/16219\r\n\r\nI am happy to do the upfront work, but I would require assistance from TF devs for e.g. correct build configuration and on-going support.\r\n\r\n### Source code / logs\r\n\r\nWe could add a `tf_cc_shared_object` target to `tensorflow/contrib/lite/BUILD`:\r\n```\r\ntf_cc_shared_object(\r\n    name = \"libtensorflow_lite.so\",\r\n    framework_so = [],\r\n    linkopts = tflite_linkopts() + [\"-s\"],  # Strip library.\r\n    visibility = [\"//visibility:public\"],\r\n    deps = [\r\n        \":framework\",\r\n        \"//tensorflow/contrib/lite/kernels:builtin_ops\",\r\n    ]\r\n)\r\n```\r\n\r\nWe could also add a header-only target to define the headers for use with `libtensorflow_lite.so` (although this won't be useful until [issue 5192](https://github.com/bazelbuild/bazel/issues/5192) has been resolved).\r\n\r\nAs mentioned above, I'd need some input to decide the correct build config (e.g. `linkopts`, use of `framework_so`).", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "These fields are not applicable, as this is a feature request. I might have used the wrong template.", "Making the shared library target is easy, but we probably want to be careful about which symbols should be exposed.", "Hi @martis-chromium, we're actively working to publish a fully functional, pure C API, and as part of this will support a proper shared library target and various language bindings for that API. We don't have an exact ETA, but expect some related activity in the coming weeks.", "Ok, good to know - thank you.", "In the meantime, I'd like to (locally) produce a TF lite shared library and limit its size somewhat.\r\n\r\nIs using a linker version script to only expose symbols containing the substring \"tflite\" an acceptable (broad-stroke) solution?\r\n\r\nI am able to compile and run the demos using this approach, but I wanted to double-check that I'm not suppressing some symbols I'll need later.", "You can certainly try that, though you may get mixed results. One example of a stripped binary for TFLite is the JNI library @ https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/java/BUILD#L172. That build rule is even more aggressive about stripping.", "A preview of what the shared library looks like is the new [:litbensorflowlite_c.so](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/experimental/c/BUILD#L13) target. We'll be adding an analogous target with C++ bindings in the near future.", "@martis-chromium how do you build the demo? I am having exactly the same problem as #18060", "Are you waiting on a response from me? I'm not really in a position to help @tensorbuffer with their problem.", "Despite statements from @shashishekhar like \"Making the shared library target is easy\", noone has actually specified how to build a shared library. Googling around returns different results. Could someone please clarify this?", "@Nimitz14 here's how I did it after reading a couple of issues around here\r\n```\r\ndiff --git a/tensorflow/lite/BUILD b/tensorflow/lite/BUILD\r\nindex be84fc5db1..fadf4069e7 100644\r\n--- a/tensorflow/lite/BUILD\r\n+++ b/tensorflow/lite/BUILD\r\n@@ -342,6 +342,21 @@ cc_test(\r\n     ],\r\n )\r\n \r\n+cc_binary(\r\n+    name = \"libtflite.so\",\r\n+    deps = [\r\n+        \"//tensorflow/lite/kernels:builtin_ops\",\r\n+        \"//tensorflow/lite:builtin_op_data\",\r\n+        \"//tensorflow/lite:framework\",\r\n+        \"//tensorflow/lite:schema_fbs_version\",\r\n+        \"//tensorflow/lite:string\",\r\n+        \"//tensorflow/lite:string_util\",\r\n+        \"//tensorflow/lite/schema:schema_fbs\",\r\n+\r\n+    ],\r\n+    linkshared=1\r\n+)\r\n+\r\n # Test the serialization of a model with optional tensors.\r\n \r\n # Model tests\r\n```\r\nYou can certainly get away with less entries in `deps`.\r\n\r\nThis issue along with #22643 make the development on Android a big headache. ", "Here's mine:\r\n```\r\ndiff --git a/tensorflow/lite/BUILD b/tensorflow/lite/BUILD\r\nindex f8bb719..7fe6227 100644\r\n--- a/tensorflow/lite/BUILD\r\n+++ b/tensorflow/lite/BUILD\r\n@@ -340,6 +340,20 @@ cc_test(\r\n     ],\r\n )\r\n \r\n+cc_binary(\r\n+    name = \"libtensorflowlite.so\",\r\n+    linkopts=[\r\n+        \"-shared\",\r\n+        \"-Wl,-soname=libtensorflowlite.so\",\r\n+    ],\r\n+    linkshared = 1,\r\n+    copts = tflite_copts(),\r\n+    deps = [\r\n+        \":framework\",\r\n+        \"//tensorflow/lite/kernels:builtin_ops\",\r\n+    ],\r\n+)\r\n+\r\n```", "Hi, TF developers\r\nI also find that it will be super convenient if there is a bazel target for C library. Looking forward to that!\r\n@Nimitz14, for now I find a makefile under tensorflow/lite/tools/make. And if we make it under tensorflow root path, like: make -f tensorflow/lite/tools/make/Makefile TARGET=android TARGET_ARCH=armv7 TARGET_TOOLCHAIN_PREFIX=/ndk_standalone_tc/p19/arm/bin/arm-linux-androideabi- all -j6.\r\nIt should generate a static library under tensorflow/lite/tools/make/gen/android_armv7/lib/ named libtensorflow-lite.a .\r\nThanks again :+1:  ", "@martis-chromium @Nimitz14  I have build the .so and used it in android project. But the .so size is 3.7M and it is so big with  it is reported with hundreds of KB , can you help me\uff1f", "Hey all, a new shared library target that has both C and C++ bindings is [now available](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/BUILD#L407).\r\n\r\nYou can build this (for Android) as follows:\r\n```\r\nbazel build //tensorflow/lite:libtensorflowlite.so \\\r\n    --config=android_arm --cxxopt='--std=c++11' -c opt\r\n```\r\n\r\nThis should have a smaller binary size as it strips most unnecessary symbols. Sadly, `bazel` doesn't have very good support for generating monolithic static (.a) libraries unless you use a custom build rule that manually assembles the objects via `ar`.\r\n", "> bazel build //tensorflow/lite:libtensorflow.so \\\r\n>     --config=android_arm --cxxopt='--std=c++11' -c opt\r\n\r\nbazel build //tensorflow/lite:libtensorflowlite.so \\\r\n    --config=android_arm --cxxopt='--std=c++11' -c opt", "Ah, good catch, updated!", "> bazel build //tensorflow/lite:libtensorflowlite.so \r\n> --config=android_arm --cxxopt='--std=c++11' -c opt\r\n\r\nWhat does it take to make this work for the x86/x86_64 configurations? --config=android_x86 is rejected as invalid by bazel.", "> > bazel build //tensorflow/lite:libtensorflowlite.so\r\n> > --config=android_arm --cxxopt='--std=c++11' -c opt\r\n> \r\n> What does it take to make this work for the x86/x86_64 configurations? --config=android_x86 is rejected as invalid by bazel.\r\n\r\nYou can use `bazel build //tensorflow/lite:libtensorflowlite.so \r\n--config=android --cpu=x86 --cxxopt='--std=c++11' -c opt`", "The size of these shared libraries is ~50MB. Contrary to what @jdduke talked about [here](https://github.com/tensorflow/tensorflow/issues/25278), saying it would 1-1.5MB. Is there something extra one has to do for that to happen?", "@RuABraun can you provide the exact build command you used to generate the library? Using `bazel build //tensorflow/lite:libtensorflowlite.so --config=android_arm64 --cxxopt='--std=c++11' -c opt` I'm getting < 2MB.", "~~I'm using the same. Afterwards:~~\r\n```\r\n~/git/tensorflow-android$ ll -h bazel-out/arm64-v8a-opt/bin/tensorflow/lite/libtensorflowLite.so\r\n-r-xr-xr-x 1 rab rab 53M May 28 14:51 bazel-out/arm64-v8a-opt/bin/tensorflow/lite/libtensorflowLite.so*\r\n```\r\n~~During `configure` I said no to everything except the android stuff, I'm not using clang. This is on the latest commit of master (last commit from 5 hours ago). Struggling to see where things could have diverged (unless I should be using clang?).~~\r\n\r\nEDIT: nevermind! much smaller now. dunno what happened. Thank you for making me rerun it :D\r\n\r\nEDIT2: Only difference I can spot now is that I was specifying cpu like `--cpu=armeabi-v8a`.\r\noh and I was target lite with a capital `L`", "> Hey all, a new shared library target that has both C and C++ bindings is [now available](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/BUILD#L407).\r\n> \r\n> You can build this (for Android) as follows:\r\n> \r\n> ```\r\n> bazel build //tensorflow/lite:libtensorflowlite.so \\\r\n>     --config=android_arm --cxxopt='--std=c++11' -c opt\r\n> ```\r\n> \r\n> This should have a smaller binary size as it strips most unnecessary symbols. Sadly, `bazel` doesn't have very good support for generating monolithic static (.a) libraries unless you use a custom build rule that manually assembles the objects via `ar`.\r\n\r\nIf it helps, here is a shell script that will compile the android distribution, and then make static libraries from the `.a` files in the build.\r\n\r\n```sh\r\n#!/bin/sh\r\n\r\n# Script to make a tensorflowlite static library from the generated archives\r\n\r\n# Run it from your local tensorflow directory\r\n\r\nconfigs=(android_arm android_arm64)\r\n\r\nfor config in \"${configs[@]}\"\r\ndo\r\n  bazel build --cxxopt='--std=c++11' -c opt --config=$config //tensorflow/lite/java:tensorflow-lite\r\ndone\r\n\r\n# See: How to build tensorflowlite as a shared library\r\n#   https://github.com/tensorflow/tensorflow/issues/20905#issuecomment-468756051\r\n# See: How to combine libraries using ELF AR\r\n#   https://stackoverflow.com/a/23621751/45114\r\n\r\n# Step 1. Edit this to point to an 'ar' command in your Android toolchain that can\r\n# handle the output archive files. I'm running on a mac so I use darwin\r\nAR=\"${ARG_NDK_PATH}/toolchains/x86_64-4.9/prebuilt/darwin-x86_64/x86_64-linux-android/bin/ar\"\r\n\r\n# This is a function that outputs an \"MRI\" script as commands to the 'ar'\r\n# command that can build the resulting library\r\nwrite_mri() {\r\n\r\n  # See: How to combine libraries using ELF AR\r\n  #   https://stackoverflow.com/a/23621751/45114\r\n\r\n  echo \"create ${result}\"\r\n\r\n  for line in $(find $dir -type f -name \\*.a)\r\n  do\r\n    echo \"addlib ${line}\"\r\n  done\r\n\r\n  echo \"save\"\r\n  echo \"end\"\r\n}\r\n\r\nfor dir in bazel-out/android-*\r\ndo\r\n  mkdir -p \"${dir}/lib\"\r\n  result=\"${dir}/lib/libtensorflowlite.a\"\r\n  rm -f $result\r\n  write_mri | $AR -M\r\n  echo \"made: ${result}\"\r\ndone\r\n```", "@michaeljbishop this very helpful however when I try to link against the generated libraries I the following errors:\r\n\r\n```\r\n/Users/xxx/Library/Android/sdk/ndk-bundle/toolchains/llvm/prebuilt/darwin-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: error: /Users/xxx/Github/tensorflow/tensorflow/lite/tools/make/gen/ANDROID_arm64/lib/libtensorflow-lite.a: no archive symbol table (run ranlib)\r\n```\r\n\r\nAny ideas?", "@jdduke \r\nI am on Ubuntu 16.04.6 LTS\r\n\r\nI launched docker with:\r\n'sudo docker run -it --rm tensorflow/tensorflow:devel bash'\r\n\r\nThen './configure' in tensorflow_src (with defaults)\r\n\r\nAnd then use the command:\r\nbazel build //tensorflow/lite:libtensorflowlite.so \\\r\n    --config=android_arm --cxxopt='--std=c++11' -c opt\r\n\r\nBut I get the error:\r\nERROR: /tensorflow_src/tensorflow/lite/kernels/internal/BUILD:615:1: C++ compilation of rule '//tensorflow/lite/kernels/internal:audio_utils' failed (Exit 1)\r\nTarget //tensorflow/lite:libtensorflowlite.so failed to build\r\n\r\nFurthermore when I rerun it I get:\r\nERROR: /tensorflow_src/tensorflow/lite/experimental/resource_variable/BUILD:6:1: C++ compilation of rule '//tensorflow/lite/experimental/resource_variable:resource_variable' failed (Exit 1)\r\nTarget //tensorflow/lite:libtensorflowlite.so failed to build\r\n\r\nAnd I will get different fails almost arbitrarily. \r\n\r\n\r\n", "@amitDaMan when you say you used the defaults, did you at least point it to your Android SDK/NDK install location? That is a required part of the configure script if you're building with `--config=android_arm`.", "@jdduke  That solved it, thank you for your speed-y assistance", "Hi @jdduke, I followed your instruction and successfully built  //tensorflow/lite:libtensorflowlite.so with size < 2M. However, when I link it with my executable and run on android, my tflite model loaded fine but I got \"segmentation fault\" when executing builder(&interpreter). I am using tensorflow 1.15.0 and flatbuffer 1.10. Any ideas ? ", "@zhaojiaTech were you using the same compiler and STL version for both the libtensorflowlite.so library and your own C++ code? If not, that might cause issues, and you may be better off using the [C API](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/c/BUILD#L21) which avoids these kinds of ABI incompatibilities. \r\n\r\nI should note, we're hoping to introduce a helper build script which will also package all the necessary C++/C headers to make the shared libraries easier to use.", "@jdduke hey. I am trying to run the c++ lib on iOS. Not using the C API/Swift/ObjC. Do you have any tips on how to do this? Building the c++ lib and linking it seems straightforward. But I am wondering how to setup the c++ lib to use the metal delegate? ", "@scm-ns this thread is quite long already, can you file a separate bug if you're having trouble with iOS + C++ + Metal?\r\n", "hi, what if i what to build a lib for arm v6 linux? ", "Hi @jdduke , \r\n I followed your instruction and successfully built //tensorflow/lite:libtensorflowlite.so with size < 2M. However, when I run on android with 64-bit Architecture, my tflite model is allegendly terminated succesfully but with 0 [ms] runtimes and no output. When I used a different platform with 32-bit ARM based architecture everything works fine. I am uses tensorflow 1.14.0 and flatbuffer 2.0. Any idea what can be the problem?", "How did you build the 64-bit library? With `--config=android_arm64`?", "@michaeljbishop Thanks for the script building a static build of tflite. However I keep getting undefined reference error, it seems that the static build does not include all needed implementations?\r\n\r\n```\r\nCMakeFiles/bokehapi.dir/src/main/cpp/BokehAPI.cpp.o: In function `std::__ndk1::default_delete<tflite::Interpreter>::operator()(tflite::Interpreter*) const':\r\n/home/andrey/Android/Sdk/ndk/android-ndk-r17c/sources/cxx-stl/llvm-libc++/include/memory:2233: undefined reference to `tflite::Interpreter::~Interpreter()'\r\nCMakeFiles/bokehapi.dir/src/main/cpp/BokehAPI.cpp.o: In function `std::__ndk1::default_delete<tflite::FlatBufferModel>::operator()(tflite::FlatBufferModel*) const':\r\n/home/andrey/Android/Sdk/ndk/android-ndk-r17c/sources/cxx-stl/llvm-libc++/include/memory:2233: undefined reference to `tflite::FlatBufferModel::~FlatBufferModel()'\r\nCMakeFiles/bokehapi.dir/src/main/cpp/BokehAPI.cpp.o: In function `BokehAPI::loadModel(std::__ndk1::basic_string<char, std::__ndk1::char_traits<char>, std::__ndk1::allocator<char> > const&)':\r\n/home/andrey/data/bokeh/code/bokeh_android_tmp/app/src/main/cpp/BokehAPI.cpp:22: undefined reference to `tflite::DefaultErrorReporter()'\r\n/home/andrey/data/bokeh/code/bokeh_android_tmp/app/src/main/cpp/BokehAPI.cpp:22: undefined reference to `tflite::FlatBufferModel::BuildFromFile(char const*, tflite::ErrorReporter*)'\r\nCMakeFiles/bokehapi.dir/src/main/cpp/BokehAPI.cpp.o: In function `std::__ndk1::default_delete<tflite::FlatBufferModel>::operator()(tflite::FlatBufferModel*) const':\r\n/home/andrey/Android/Sdk/ndk/android-ndk-r17c/sources/cxx-stl/llvm-libc++/include/memory:2233: undefined reference to `tflite::FlatBufferModel::~FlatBufferModel()'\r\n/home/andrey/Android/Sdk/ndk/android-ndk-r17c/sources/cxx-stl/llvm-libc++/include/memory:2233: undefined reference to `tflite::FlatBufferModel::~FlatBufferModel()'\r\nCMakeFiles/bokehapi.dir/src/main/cpp/BokehAPI.cpp.o: In function `BokehAPI::loadModel(std::__ndk1::basic_string<char, std::__ndk1::char_traits<char>, std::__ndk1::allocator<char> > const&)':\r\n/home/andrey/data/bokeh/code/bokeh_android_tmp/app/src/main/cpp/BokehAPI.cpp:31: undefined reference to `tflite::ops::builtin::BuiltinOpResolver::BuiltinOpResolver()'\r\n/home/andrey/data/bokeh/code/bokeh_android_tmp/app/src/main/cpp/BokehAPI.cpp:32: undefined reference to `tflite::InterpreterBuilder::InterpreterBuilder(tflite::FlatBufferModel const&, tflite::OpResolver const&)'\r\n/home/andrey/data/bokeh/code/bokeh_android_tmp/app/src/main/cpp/BokehAPI.cpp:32: undefined reference to `tflite::InterpreterBuilder::operator()(std::__ndk1::unique_ptr<tflite::Interpreter, std::__ndk1::default_delete<tflite::Interpreter> >*)'\r\n/home/andrey/data/bokeh/code/bokeh_android_tmp/app/src/main/cpp/BokehAPI.cpp:32: undefined reference to `tflite::InterpreterBuilder::~InterpreterBuilder()'\r\n/home/andrey/data/bokeh/code/bokeh_android_tmp/app/src/main/cpp/BokehAPI.cpp:32: undefined reference to `tflite::InterpreterBuilder::~InterpreterBuilder()'\r\nCMakeFiles/bokehapi.dir/src/main/cpp/BokehAPI.cpp.o: In function `BokehAPI::runBokeh(unsigned char const*, int*)':\r\n/home/andrey/data/bokeh/code/bokeh_android_tmp/app/src/main/cpp/BokehAPI.cpp:36: undefined reference to `tflite::Interpreter::AllocateTensors()'\r\n/home/andrey/data/bokeh/code/bokeh_android_tmp/app/src/main/cpp/BokehAPI.cpp:61: undefined reference to `tflite::Interpreter::Invoke()'\r\nCMakeFiles/bokehapi.dir/src/main/cpp/BokehAPI.cpp.o: In function `~MutableOpResolver':\r\n/home/andrey/data/bokeh/code/bokeh_android_tmp/app/.cxx/cmake/debug/arm64-v8a/../../../../src/main/cpp/include/tensorflow/lite/mutable_op_resolver.h:57: undefined reference to `vtable for tflite::MutableOpResolver'\r\n/home/andrey/data/bokeh/code/bokeh_android_tmp/app/.cxx/cmake/debug/arm64-v8a/../../../../src/main/cpp/include/tensorflow/lite/mutable_op_resolver.h:57: undefined reference to `vtable for tflite::MutableOpResolver'\r\n```\r\n\r\nOn the other hand, I was able to get shared library of TFLite works. However, we still need to be able to build the static version of TFLite.", "@andreydung can you talk more about your static lib needs? Is there a reason the shared library is insufficient (assuming this is for Android)?", "@jdduke I would assume that the need for a static library here is the same basic reason for needing any static library: speed and size optimization. I only want what I absolutely need and I don't want the overhead of dynamic lookups.", "> I would assume that the need for a static library here is the same basic reason for needing any static library: speed and size optimization. I only want what I absolutely need and I don't want the overhead of dynamic lookups.\r\n\r\nThe overhead of calls to the shared library should be minimal relative to the cost of running inference (i.e., any marginal overhead in non-inlined calls will be dominated by the cost of executing the model), so I don't think you'd see any observable performance impact between static or shared library usage of TensorFlow Lite (unless you were to use different compiler optimization flags in your library vs the shared library).", "> > I would assume that the need for a static library here is the same basic reason for needing any static library: speed and size optimization. I only want what I absolutely need and I don't want the overhead of dynamic lookups.\r\n> \r\n> The overhead of calls to the shared library should be minimal relative to the cost of running inference (i.e., any marginal overhead in non-inlined calls will be dominated by the cost of executing the model), so I don't think you'd see any observable performance impact between static or shared library usage of TensorFlow Lite (unless you were to use different compiler optimization flags in your library vs the shared library).\r\n\r\nI appreciate that the cost is negligible compared to the cost of inference. My point is that it's an unnecessary cost regardless.", "> @jdduke I would assume that the need for a static library here is the same basic reason for needing any static library: speed and size optimization. I only want what I absolutely need and I don't want the overhead of dynamic lookups.\r\n\r\nAnother use case is creating one's own shared library which embeds tensowflow inside."]}]