[{"number": 17486, "title": "Fix minor typos for programer guide documents", "body": "Described as PR title.", "comments": ["It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "Is there any admin help review this patch?"]}, {"number": 17485, "title": "tf.contrib.image.transform crashes under Windows when CUDA is enabled", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes. A minimal example reproducing the bug is provided below.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 10 (x64)\r\n- **TensorFlow installed from (source or binary)**: \r\nBinary installed using `pip install tensorflow-gpu`\r\n- **TensorFlow version (use command below)**: \r\nb'unknown' 1.6.0 (also tested on b'unknown' 1.4.0)\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**:  \r\n  CUDA 9.0.176 / cuDNN 7.0.5\r\n  CUDA 8.0.61 / cuDNN 6.14.11\r\n- **GPU model and memory**:\r\n(device: 0, name: GeForce GTX 970M, pci bus id: 0000:01:00.0, compute capability: 5.2, memory: 3.00GiB)\r\n(device: 0, name: Quadro M1200, pci bus id: 0000:01:00.0, compute capability: 5.0, memory: 4.00GiB)\r\n- **Exact command to reproduce**: python example.py (see below)\r\n\r\n\r\n### Describe the problem\r\nThe function tf.contrib.image.transform crashes when CUDA is enabled under Windows. It produces the following errors: `CUDA_ERROR_ILLEGAL_INSTRUCTION` on tensorflow 1.6 or `CUDA_ERROR_LAUNCH_FAILED` on tensorflow 1.4.\r\nHowever, it functions correctly when CUDA is disabled (by setting _CUDA_VISIBLE_DEVICES_ to -1). \r\n\r\nI tested a variation of different parameters (such as varying the batch size, image sizes, and number of channels), but the behavior stays the same. In addition I reproduced the same error on a different machine with an older tensorflow version.\r\n\r\n### Source code / logs\r\n- **Code**:\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nbatch_size, image_size, channels = 1, 32, 1\r\n\r\ndata = np.zeros(\r\n    shape=(batch_size, image_size, image_size, channels), \r\n    dtype=np.float32)\r\n\r\ndata_node = tf.placeholder(\r\n    shape=(batch_size, image_size, image_size, channels),\r\n    dtype=tf.float32)\r\n\r\nidentity = tf.constant([1, 0, 0, 0, 1, 0, 0, 0], dtype=tf.float32)\r\ntransform = tf.tile(tf.expand_dims(identity, 0), [batch_size, 1])\r\ndata_node_transformed = tf.contrib.image.transform(data_node, transform)\r\n\r\ndata_t = tf.Session().run([data_node_transformed], feed_dict={data_node: data})\r\n```\r\n- **Console Output**:\r\n\r\n  Output with tensorflow 1.6 (with GeForce GTX 970M,) :\r\n\r\n```\r\n2018-03-06 15:42:21.578078: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1212] Found device 0 with properties:\r\nname: GeForce GTX 970M major: 5 minor: 2 memoryClockRate(GHz): 1.038\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 3.00GiB freeMemory: 2.48GiB\r\n2018-03-06 15:42:21.578310: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1312] Adding visible gpu devices: 0\r\n2018-03-06 15:42:21.890290: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2192 MB memory) -> physical GPU (device: 0, name: GeForce GTX 970M, pci bus id: 0000:01:00.0, compute capability: 5.2)\r\n2018-03-06 15:42:22.101031: E C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_INSTRUCTION\r\n2018-03-06 15:42:22.101032: E C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:1110] could not synchronize on CUDA context: CUDA_ERROR_ILLEGAL_INSTRUCTION ::\r\n2018-03-06 15:42:22.101185: F C:\\tf_jenkins\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_event_mgr.cc:203] Unexpected Event status: 1\r\n```\r\n\r\n  Output with tensorflow 1.4 (with Quadro M1200):\r\n\r\n```\r\n2018-03-06 15:31:17.800588: I C:\\tf_jenkins\\home\\workspace\\rel\u2011win\\M\\windows\u2011gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1030] Found device 0 with properties: \r\nname: Quadro M1200 major: 5 minor: 0 memoryClockRate(GHz): 1.148\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 4.00GiB freeMemory: 3.35GiB\r\n2018-03-06 15:31:17.803815: I C:\\tf_jenkins\\home\\workspace\\rel\u2011win\\M\\windows\u2011gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) \u2011> (device: 0, name: Quadro M1200, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\n2018-03-06 15:31:18.731252: E C:\\tf_jenkins\\home\\workspace\\rel\u2011win\\M\\windows\u2011gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:1110] could not synchronize on CUDA context: CUDA_ERROR_LAUNCH_FAILED :: No stack trace available\r\n2018-03-06 15:31:18.731258: E C:\\tf_jenkins\\home\\workspace\\rel\u2011win\\M\\windows\u2011gpu\\PY\\36\\tensorflow\\stream_executor\\cuda\\cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED\r\n2018-03-06 15:31:18.733458: F C:\\tf_jenkins\\home\\workspace\\rel\u2011win\\M\\windows\u2011gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_event_mgr.cc:203] Unexpected Event status: 1\r\n```", "comments": ["@gunan Can you take a look?", "I am not familiar with this code.\r\n@mrry @zheng-xq  have you seen the above error message before?", "Assuming the example is minimal, it looks like the failing code is (probably) in one of these files:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/60a21e25b0261369a15ca1d17505d7c3c82be967/tensorflow/contrib/image/kernels/image_ops.h\r\nhttps://github.com/tensorflow/tensorflow/blob/60a21e25b0261369a15ca1d17505d7c3c82be967/tensorflow/contrib/image/kernels/image_ops.cc\r\nhttps://github.com/tensorflow/tensorflow/blob/60a21e25b0261369a15ca1d17505d7c3c82be967/tensorflow/contrib/image/kernels/image_ops_gpu.cu.cc\r\n\r\nI don't know what could be causing the problem. @ringw contributed that code, and might have some ideas.", "Sorry, I don't have access to a Windows machine and am not familiar with the Windows development environment, let alone debugging CUDA. I don't think I can feasibly look into this issue in the near future. If anyone manages to narrow down the error on Windows, I can at least answer any questions about the code.", "The same issue on GTX970 and TF 1.5.0 and 1.6.0 when using tf.contrib.image.transform method.\r\nWindows 10.\r\nPython 3.6.4\r\nCuda 9\r\ncuDNN 7\r\n", "Nagging Assignee @shivaniag: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I had the same issue with tf.contrib.image.translate on TF 1.7.0\r\n\r\nWindows 10\r\nPython 3.6.4\r\nCuda 9\r\ncuDNN 7", "I have the same issue with tf.contrib.image.rotate on TF 1.7.0\r\nWindows 10\r\nPython 3.6\r\nCuda 9\r\ncuDNN 7\r\n", "I have the same issue with tf.contrib.image.rotate on TF 1.7.0\r\nWindows 10\r\nPython 3.6\r\nCuda 9\r\ncuDNN 7\r\n\r\nFor pre-processing, wrapping it with tf.data.Dataset it works, presumably because it is on the CPU?\r\n\r\n    import numpy as np\r\n    import tensorflow as tf\r\n    \r\n    batch_size, image_size, channels = 1, 32, 1\r\n    \r\n    data = np.zeros(\r\n        shape=(batch_size, image_size, image_size, channels),\r\n        dtype=np.float32)\r\n    \r\n    data_node = tf.placeholder(\r\n        shape=(batch_size, image_size, image_size, channels),\r\n        dtype=tf.float32)\r\n    \r\n    identity = tf.constant([1, 0, 0, 0, 1, 0, 0, 0], dtype=tf.float32)\r\n    transform = tf.tile(tf.expand_dims(identity, 0), [batch_size, 1])\r\n    # data_node_transformed = tf.contrib.image.transform(data_node, transform)\r\n    \r\n    data = tf.data.Dataset.from_tensor_slices(data)\r\n    data = data.map(lambda x: tf.contrib.image.transform(x, transform))\r\n    data = data.batch(1)\r\n    iterator = data.make_one_shot_iterator()\r\n    next_element = iterator.get_next()\r\n    \r\n    with tf.Session() as session:\r\n        data_t = session.run(next_element)\r\n\r\n", "Mine only crashes on the GPU aswell, Wrapping it with Dataset doesn't really solve the issue since it just forces it to run on the CPU : https://github.com/tensorflow/tensorflow/issues/13610", "@micoene Ahhh yes, you are correct, just putting it on CPU works. It is a workaround for now...\r\n\r\n    with tf.device('/cpu:0'):\r\n        data_node_transformed = tf.contrib.image.transform(data_node, transform)", "Nagging Assignee @shivaniag: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Same issues Geforce 1060, Windows 10, Python 3,6, Cuda 9, cuDNN 7.04", "I have the same issue with tf.contrib.image.rotate on TF 1.4 on GPU (GTX 980M)\r\nWindows 10\r\nPython 3.5\r\nCuda 8.0\r\ncuDNN 6.1", "Same on win10, py36, cuda9.0, cudnn7, tf1.8, gtx1080", "Nagging Assignee @shivaniag: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Similair issue:\r\n\r\nWindows 10\r\nPython 3.6\r\nCuda 9.0\r\ncuDNN 7.1.4", "@Aliyss I recreated a fresh conda env with cdnn, tensorflow gpu1.8, and keras gpu 2.1 installed from anaconda. Before that I downgraded my cuda from 9.2 to 9.0. That solved the issue for me.", "Similair issue:\r\nTensoflow-gpu 1.8\r\nWindows 10\r\nPython 3.6\r\nCuda 9.0\r\ncuDNN 7.1.4\r\n\r\nI knew that I would not upgrade. I still can\u2019t solve it now.\r\n-----------------------------------------------------------------------------------------------------------\r\nok\uff0cI think I have solved this problem. I change Tensoflow-gpu 1.8 to Tensoflow 1.8.  Well Done\uff01", "@jijingtaifeng I tried running it from the python console instead of Visual Studio or similair. try that. maybe it works.\r\n", "Same issue on this configuration:\r\nTensoflow-gpu 1.8\r\nWindows 10 x64\r\nPython 3.6.2\r\nCuda 9.0\r\ncuDNN 7\r\n\r\nIsn't there any response ? or something like that, issue is open by months....", "Similair issue:\r\n\r\nWindows 10\r\nPython 3.6\r\nTensoflow-gpu 1.8\r\nCuda 9.0\r\ncuDNN 7.1.4\r\nGPU (GeForce GTX 1050)\r\n", "Similar issue:\r\n\r\nWindows 10\r\nPython 3.6\r\nTensorflow 1.9, 1.8, 1.7, **1.4**\r\nCUDA 9.0, **8**\r\ncuDNN 7.1, **6, 7**\r\nGPU GeForce GTX 1070", "Since this is under contrib, and looking at the history, I am marking this contributions welcome as it looks like we wont be able to get to this.", "Closing out this issue, as `tf.contrib.image` has been deprecated as part of TensorFlow 2.0. If you run into similar snags with `tf.image.*` ops when using Windows with CUDA enabled, please feel free to open a new ticket. Thanks! \ud83d\ude42 ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/17485\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/17485\">No</a>\n"]}, {"number": 17484, "title": "contrib.boosted_trees.estimator_batch modules are not available in 1.6.0", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:macOS Sierra\r\n- **TensorFlow installed from (source or binary)**:source\r\n- **TensorFlow version (use command below)**:1.6.0\r\n- **Python version**:2.7\r\n- **Bazel version (if compiling from source)**:0.11.0\r\n- **CUDA/cuDNN version**:not relevant\r\n- **GPU model and memory**:not relevant\r\n- **Exact command to reproduce**:\r\n\r\ntrying to run the example in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/boosted_trees/examples/mnist.py\r\n\r\nbut get an error:\r\nModuleNotFoundError: No module named 'tensorflow.contrib.boosted_trees.estimator_batch.estimator'\r\n\r\ntried to install the latest version with pip and from source on python2.7 and python3.6 but still end up with the same error.\r\n\r\nthis is the content of the boosted_trees/estimator_batch folder in my installation:\r\n\r\ncustom_export_strategy.pyc\r\ndnn_tree_combined_estimator.py\r\n__init__.py\r\ndnn_tree_combined_estimator.pyc\r\n__init__.pyc\r\ntrainer_hooks.py\r\ncustom_export_strategy.py\r\ntrainer_hooks.pyc\r\n\r\n", "comments": ["I can reproduce this issue. Soroush (@sshrdp). Can you take a look at it?", "I got the same error:\r\n\r\n```\r\nfrom tensorflow.contrib.boosted_trees.estimator_batch.estimator import GradientBoostedDecisionTreeClassifier\r\nModuleNotFoundError: No module named 'tensorflow.contrib.boosted_trees.estimator_batch.estimator'\r\n```", "This should be fixed in the more recent releases of tensorflow.", "Nagging Assignee @rohan100jain: It has been 136 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I just confirmed that as of tf 1.11 this works now. Closing issue."]}, {"number": 17483, "title": "Less information for debugging sess.run() when fitting an image into a tensor", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: ('v1.5.0-0-g37aa430d84', '1.5.0')\r\n- **Python version**: anaconda 2.7\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: Cuda compilation tools, release 8.0, V8.0.61\r\n- **GPU model and memory**:  Quadro K4000 \r\n- **Exact command to reproduce**:  act = sess.run(op_tensor, feed_dict = feed_dict)\r\n\r\n### Describe the problem\r\nSo I am visualizing the activation map by fitting an example image into each convnet layer using **sess.run(op_tensor, feed_dict = feed_dic)**, \r\nwhere:\r\n **op_tensor: Tensor(\"conv2_1/Relu:0\", shape=(?, 112, 112, 64), dtype=float32)**;\r\n**feed_dic: {<tf.Tensor 'Placeholder:0' shape=(?, 224, 224, 3) dtype=float32>: array([[[[ 77.,  84.,  76.],\r\n         .,  74.],\r\n         ...,\r\n         [138., 122., 113.],\r\n         [136., 122., 115.],\r\n         [128., 118., 112.]]]], dtype=float32)}**\r\n\r\nHowever, I got the error here: \r\n\r\n`InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_2' with dtype float`, I did not where **Placeholder:2** comes from. So I debug into this function, I fund the error is from here: \r\n**return fn(*args)** from **tensorflow/python/client/session.py**, \r\n\r\nHere are the parameters for args:\r\n\r\n** type 'tuple': (<Swig Object of type 'TF_DeprecatedSession *' at 0x7f7dd98a9270>, {'Placeholder:0': array([[[[ 77.,  84.,  76.],\r\n         [ 77.,  84.,  76.],\r\n         [ 75.,  84.,  76.],\r\n         .......\r\n         [128., 118., 112.]]]], dtype=float32)}, ['conv2_1/Relu:0'], [], None, None** \r\n\r\nMore precisely, the error is caused by this:\r\n**if c_api.TF_GetCode(self.status.status) != 0:**, where **c_api.TF_GetCode(self.status.status)** return 3.\r\n\r\nI did whatever I can, but I can not understand your source code with too much documentation. \r\n\r\nFor the input of **sess.run()**, I did not see any inappropriate settting, Can you help me clarify this issue? I was stuck here for several days...\r\n\r\nBTW, I saved my CNN (**Conv1_1+relu+conv1_2+relu+pool1+conv2_1+relu+conv2_2+relu+pool2+fc1**) model with **tf.train.Saver()** , here is the files:\r\n\r\n```\r\n--checkpoint\r\n--tmp-model.data-00000-of-00001\r\n--tmp-model.index\r\n--tmp-model.meta\r\n```\r\n\r\nThanks in advance\r\n\r\nHao\r\n\r\n\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "@bignamehyp  I do not understand what is a bug or feature request for you??? ", "Nagging Assignee @bignamehyp: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @bignamehyp: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @bignamehyp: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @bignamehyp: It has been 34 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @bignamehyp: It has been 49 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Please keep in mind that the TensorFlow GitHub Issues page is for tracking bugs and feature requests. It is not a way to escalate a Stack Overflow support question that is not getting enough attention. Thanks!\r\n"]}, {"number": 17482, "title": "The \"multiply\" operator of type Dimension has a bug.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Custom code\r\n- **OS**: Win10 64bit \r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.5.0\r\n- **Python version**: 3.6.2\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 9.0\r\n- **GPU model and memory**: GTX 1080Ti\r\n- **Exact command to reproduce**: See codes below\r\n\r\n### Describe the problem\r\nSuppose `A` is a tensor, `L = A.shape[0]`. I found that `L*3` works while `3*L` lead to a **TypeError**. Can someone fix this?\r\n\r\n### Source code / logs\r\n```\r\nimport tensorflow as tf\r\nA = tf.placeholder( tf.float32, shape = [3, 4, 5] )\r\nL = A.shape[0]\r\nprint( type(L) )\r\nprint( L*3 )\r\nprint( 3*L )\r\n```\r\nOutput is:\r\n![image](https://user-images.githubusercontent.com/8580553/37040371-a1b8e12e-2194-11e8-8d23-b317458b2382.png)\r\n", "comments": ["It seems that this problem exists for all operators like `//`, `-`, `+`, `%` etc...", "It appears that Dimension needs special methods defined for reflexive methods, e.g., `__rmul__`.", "5fd341d has fixed the problem, I think we can close the issue now.", "Thanks a lot!"]}, {"number": 17481, "title": "Update wide.md", "body": "Alphabetized races: standard procedure in documentation.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to `go/cla#troubleshoot`.\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "Signed it.", "CLAs look good, thanks!\n\n<!-- ok -->"]}, {"number": 17480, "title": "add assert_element_shape method for tf.contrib.data", "body": "fix #16052. \r\n\r\n```python\r\nshapes = [tf.TensorShape([16, 256]), tf.TensorShape(None)]\r\nresult = dataset.apply(tf.contrib.data.assert_element_shape(shapes))\r\nprint(result.output_shapes)  # ==> \"((16, 256), <unknown>)\"\r\n```", "comments": ["@frankchn Thanks, I have fixed the code style. Could you help restart all tests?", "@mrry Hi, the behavior required has been added, and now `assert_element_shape` will raise an error if the assertion didn't not hold. Could you take a look again? ", "@mrry Thanks for your approval. My bad, I have fixed the code style, and could you help restart all tests?", "Thanks. All tests pass.", "Thanks again!", "Is there any equivalent to this in TensorFlow 2? Even the 1.15 docs seem to indicate that we are not supposed to use it.  It is actually useful.", "@dhdaines Hi, David, would you please file a new issue for it? Thanks :-)"]}, {"number": 17479, "title": "compile tensorflow1.6.0 source failed", "body": "Error Occured:\r\nbazel-out/host/bin/external/swig/swig -c++ -python -module tensorflow_wrap_toco -o bazel-out/k8-py3-opt/bin/tensorflow/contrib/lite/toco/python/tensorflow_wrap_toco.cc -outdir bazel-out/k8-py3-opt/bin/tensorflow/contrib/lite/toco/python -Iexternal/eigen_archive -Ibazel-out/k8-py3-opt/genfiles -Iexternal/protobuf_archive -Iexternal/swig -Ibazel-out/k8-py3-opt/genfiles/external/local_config_python -Iexternal/nsync -Iexternal/com_google_absl -Iexternal/gemmlowp -Iexternal/jpeg -Iexternal/com_googlesource_code_re2 -Iexternal/zlib_archive -Iexternal/flatbuffers -Iexternal/highwayhash -Iexternal/gif_archive -Ibazel-out/k8-py3-opt/genfiles/external/jpeg -Iexternal/png_archive -Iexternal/arm_neon_2_x86_sse -Iexternal/farmhash_archive -Iexternal/swig/Lib -Iexternal/swig/Lib/cffi -Iexternal/swig/Lib/python -Iexternal/swig/Lib/std -Iexternal/swig/Lib/typemaps tensorflow/contrib/lite/toco/python/toco.i\r\n:1: Error: Unable to find 'swig.swg'\r\n:3: Error: Unable to find 'python.swg'\r\ntensorflow/contrib/lite/toco/python/toco.i:16: Error: Unable to find \u2018std_string.i'\r\n\r\nuse bazel compile tensorflow\r\n\r\nPlease go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["Please provide details about what platform you are using  (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?  Make sure you also include the exact command if possible to produce  the output included in your test case. If you are unclear what to include  see the issue template displayed in  [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\n We ask for this in the issue submission template, because    it is really difficult to help without that information. Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing for lack of response; please reopen if you can fill in the platform information. ", "I've been suffering the same error while compiling tensorflow to run in a pretty outdated cluster machine. I've been able to fix it with the patch proposed in https://github.com/bazelbuild/bazel/issues/4053#issuecomment-343134886\r\nI'm using self compiled versions of gcc and bazel. My enviornment:\r\n\r\n\r\n== cat /etc/issue ===============================================\r\nLinux pgpu01 2.6.32-696.1.1.el6.x86_64 #1 SMP Tue Mar 21 12:19:18 EDT 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (GCC) 6.4.0\r\nCopyright (C) 2017 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux pgpu01 2.6.32-696.1.1.el6.x86_64 #1 SMP Tue Mar 21 12:19:18 EDT 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.12.0)\r\nprotobuf (3.2.0)\r\n\r\n== check for virtualenv =========================================\r\nTrue\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.8.0-rc1\r\ntf.GIT_VERSION = b'v1.8.0-rc1-1380-g17d877b'\r\ntf.COMPILER_VERSION = b'v1.8.0-rc1-1380-g17d877b'\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /opt/shared/cudatoolkit/9.0/lib64:/opt/shared/cudatoolkit/9.0/lib:/opt/shared/cudatoolkit/9.0/samples/common/lib/linux/x86_64:/opt/shared/cudnn/7.1_cuda-9.0/lib64:/opt/shared/python/3.6.0/lib:/cluster/home/rcilla01/lib64:\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nSat May  5 09:57:24 2018       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 384.66                 Driver Version: 384.66                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla P100-PCIE...  Off  | 00000000:08:00.0 Off |                    0 |\r\n| N/A   29C    P0    29W / 250W |      0MiB / 16276MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla P100-PCIE...  Off  | 00000000:09:00.0 Off |                    0 |\r\n| N/A   32C    P0    27W / 250W |      0MiB / 16276MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================", "I am having this issue as well.", "The patch fixes it for me too"]}, {"number": 17478, "title": "Update replicate_model_fn.py", "body": "Added a name attribute to _PerGraphState. Using the TowerOptimizer throws this warning without it:\r\n\r\n```\r\nWARNING:tensorflow:Error encountered when serializing replicate_model_fn_graph_states.\r\nType is unsupported, or the types of the items don't match field type in CollectionDef.\r\n'_PerGraphState' object has no attribute 'name'\r\n```", "comments": ["Apparently, importing the meta_graph causes problems when the name attribute is provided:\r\n\r\n```\r\nFile \"...\", line 80, in freeze #my module\r\n    saver = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices=True)\r\n  File \"...\\tensorflow\\python\\training\\saver.py\", line 1909, in import_meta_graph\r\n    **kwargs)\r\n  File \"...\\tensorflow\\python\\framework\\meta_graph.py\", line 770, in import_scoped_meta_graph\r\n    ops.prepend_name_scope(value, scope_to_prepend_to_names))\r\n  File \"...\\tensorflow\\python\\framework\\ops.py\", line 3459, in as_graph_element\r\n    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\r\n  File \"...\\tensorflow\\python\\framework\\ops.py\", line 3519, in _as_graph_element_locked\r\n    \"graph.\" % repr(name))\r\nKeyError: \"The name 'graph_reduction' refers to an Operation not in the graph.\"\r\n```\r\n\r\nIs there a way to address this?", "The warning is logged when _PerGraphState is being serialized.  This happens if it's left as part of the graph collection.  That shouldn't happen due to the `TowerOptimizer._clear_graph_state()` call.  There is some unit-test coverage of this behavior.  Are you doing something unusual with the graph, the collections or not using TowerOptimizer?", "I just use it like this:\r\n\r\n```\r\noptimizer = tf.train.MomentumOptimizer(learning_rate,\r\n                                          momentum=0.9,\r\n                                          use_nesterov=True)\r\noptimizer = TowerOptimizer(optimizer)\r\nreturn slim.learning.create_train_op(loss, optimizer, global_step=tf.train.get_or_create_global_step())\r\n```", "Nagging Reviewer @isaprykin: It has been 14 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "Nagging Reviewer @isaprykin: It has been 36 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "Nagging Reviewer @isaprykin: It has been 51 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "Nagging Reviewer @isaprykin: It has been 66 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "`replicate_model_fn` is being removed in favor of `DistributionStrategy`, in particular, `MirroredStrategy`. I will close this PR. \r\n\r\n@josh11b FYI."]}, {"number": 17477, "title": "Update replicate_model_fn.py", "body": "Added a name attribute to _PerGraphState. Using the TowerOptimizer throws this warning without it:\r\n\r\n```\r\nWARNING:tensorflow:Error encountered when serializing replicate_model_fn_graph_states.\r\nType is unsupported, or the types of the items don't match field type in CollectionDef.\r\n'_PerGraphState' object has no attribute 'name'\r\n```", "comments": ["I think contrib.estimator is deprecated in favor of tensorflow.estimator?\r\nIn any case, 1.6 release is closed, and this looks like a small fix to contrib. I will reject this PR.\r\nWe will move forward with the PR to master."]}, {"number": 17476, "title": "SVD gradient is unstable for non-unique singular values", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: ('v1.5.0-10-g5b10b34', '1.5.0')\r\n- **Python version**: Python 2.7.6\r\n- **Bazel version (if compiling from source)**: 0.11.0\r\n- **GCC/Compiler version (if compiling from source)**: 4.8.5\r\n- **CUDA/cuDNN version**: 8.0 / 6.0\r\n- **GPU model and memory**: GeForce GTX 970 4GB\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nThe gradient of SVD becomes `nan` when singular values are not unique.\r\n\r\nFrom the code\r\nhttps://github.com/tensorflow/tensorflow/blob/c6a12c77a50778e28de3590f4618bc2b62f3ecab/tensorflow/python/ops/linalg_grad.py#L332-L342\r\nit is clearly visible that `f` becomes `inf` for equal singular values.\r\n\r\nI briefly skimmed through the paper https://arxiv.org/abs/1509.07838 but couldn't find an explanation for this behaviour. Can someone give an intuitive example why the gradient for similar singular values should not be defined?\r\n\r\nSimilar singular values commonly appear for estimation of rotation matrices (all singular values become 1). At the moment it is impossible to use SVD for such a case.\r\n\r\nAlternative implementations of the SVD gradients based on the same paper are:\r\n- https://github.com/InhaDeeplearningGroup/Academic_research/blob/master/LSH/tensorflow_slim/svdGradients.py\r\n- https://gist.github.com/psycharo/60f58d5435281bdea8b9d4ee4f6e895b\r\n\r\nwhich circumvent this problem by simply replacing the `nan`s or effectively setting them to 0.\r\n\r\nCould this be used alternatively to the current implementation that just divides by 0? Or alternatively just add a small epsilon to the difference of singular values.\r\n\r\nBtw, I think that no gradient computation in TensorFlow should ever return faulty gradients but raise an error message to simplify debugging. I don't see the point of using `nan` or `inf` gradients.", "comments": ["Consider an identity matrix where SVD reduces to eigendecomposition. Every vector is an eigenvector. You have to pick a single output vector in order to be able to backprop through it, but because all choices are equally valid, the backprop is not defined.", "> which circumvent this problem by simply replacing the nans or effectively setting them to 0.\r\n\r\nThis at best patching over the problem. I don't think it would actually solve the problem for training deep learning models. You will still have very large gradients that lead to numerical stability problems when there are nearly degenerate singular values.", "> Similar singular values commonly appear for estimation of rotation matrices (all singular values become 1). At the moment it is impossible to use SVD for such a case.\r\n\r\nRotation matrices also suffer from gimbal lock (which I think may be related to this issue of degenerate singular values). You probably want to use [quaternions for spatial rotation](https://en.wikipedia.org/wiki/Quaternions_and_spatial_rotation) instead.", "Thanks for you explanation.\r\nIf a gradient is not defined, wouldn't it be better to provide no parameter updates at all (i.e. return a gradient of 0)? At the moment, the gradient becomes undefined at some circumstances (non-unique singular values) and propagates further, which breaks the whole training process without further warnings.", "It's a similar to having gradients of 1/x or sqrt(x). If x gets close to 0, it breaks your training. Traditionally it's been up to the user to make sure that doesn't happen.", "I am mostly concerned with the application of rotation estimation via SVD. After reading through https://arxiv.org/pdf/0904.1613.pdf I recognised that the underlying problem is the uniqueness of the SVD solution for the optimal R. I think the gimbal lock problem is related to Euler angles, not rotation matrices. E.g. rotation estimation via quaternions involves choosing the eigenvector with the largest eigenvalue which also becomes non-unique when all eigenvalues are equal."]}, {"number": 17475, "title": "CNN with complex valued filters", "body": "I was trying to implement a CNN with complex valued filters for an image processing task. Here is the [gist](https://gist.github.com/gautamsreekumar/81bf1ad1037ccfc5dfa8da1be28f2216l).\r\nI tried feeding in image with `float64` dtype and I got the error `Value passed to parameter 'input' has DataType complex64 not in list of allowed values: float16, float32`. So, I changed the first layer to real-valued and cast that output of this layer to complex type. Then, I got the same error for the next layer, but only this time, `float64` is not in the list of allowed values which has only complex types. Then I added line 31 in the gist. Now, I am getting this error saying `complex128` not in the allowed values list, which now shows float types. Anyone knows how to fix this?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", " Sorry. Here are the details. I am running it on a remote system. So, I don't know details regarding its installation. Please let me know if you need any more information.\r\n-----------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n\r\nYes. I was trying to implement a CNN with complex valued weights.\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n\r\nLinux Ubuntu 14.04.5\r\n- **TensorFlow installed from (source or binary)**:\r\nDon't know\r\n- **TensorFlow version (use command below)**:\r\nTensorFlow 1.2.0\r\n- **Python version**: \r\nPython 2.7 Anaconda custom (64 bit)\r\n- **Bazel version (if compiling from source)**:\r\nDon't know\r\n- **GCC/Compiler version (if compiling from source)**:\r\nN/A\r\n- **CUDA/cuDNN version**:\r\nDon't know\r\n- **GPU model and memory**:\r\nNVIDIA TITAN X 12GB\r\n- **Exact command to reproduce**:\r\nGist attached\r\n", "@gautamsreekumar Your gist is not publicly viewable.", "https://gist.github.com/gautamsreekumar/81bf1ad1037ccfc5dfa8da1be28f2216\r\n\r\nHere is the link. I have made it public (it was already public if I am right. Don't know what happened)", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "Hello \r\nI have a CNN in which the input is the Complexed-valued and the labels are double and it is for the regression task. I've implemented it using Tensorflow. But it does not work. Here, I read other people's notes. and I saw the https://gist.github.com/gautamsreekumar/81bf1ad1037ccfc5dfa8da1be28f2216 . I wonder is it enough for implementing such a network. I mean how should I define the optimizer and the cost or other related parts? just as the same as the conventional CNN which implements on a normal domain like tf.float32?\r\nThanks "]}, {"number": 17474, "title": "Windows: Use cc_import to import python lib properly", "body": "Previously, we put python.lib in data attribute of a cc_library and\r\nmanually added the link option. That caused the build to be\r\nnon-hermetic. This change fixed the problem.\r\n\r\n@gunan @mrry ", "comments": []}, {"number": 17473, "title": "[XLA] Allow for devices which have F16, no F64, no Complex", "body": "There has been an introduction of flags for support of various types in the XLA_TYPED_TEST macro.\r\n\r\nThis set of flags supports hardware which has FP16, FP32 but no FP64 or COMPLEX.\r\n\r\n", "comments": ["i don't think that the CI system error is related to my changes.", "hi - could we get this merged before merge conflicts cause a problem?  cheers."]}, {"number": 17472, "title": "Tensorflow lite: crash when use the op tf.gather() ", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: \r\n No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X 10.12.6\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.6.0\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: 0.11.0\r\n- **GCC/Compiler version (if compiling from source)**: 4.2\r\n- **CUDA/cuDNN version**: no\r\n- **GPU model and memory**: no\r\n- **Exact command to reproduce**: \r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nI build the tensorflow lite demo in Android Studio using TensorFlow Lite AAR from JCenter. It works perfect on ARM v7a devices. Then I put my model to the tflitecamerademo projects, but I encounter a crash issue. The crash stack is: \r\n`\r\nE/AndroidRuntime: FATAL EXCEPTION: CameraBackground\r\n                  Process: android.example.com.tflitecamerademo, PID: 23731\r\n                  java.lang.IllegalArgumentException: Invalid handle to Interpreter.\r\n                      at org.tensorflow.lite.NativeInterpreterWrapper.getInputDims(Native Method)\r\n                      at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:85)\r\n                      at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:118)\r\n                      at org.tensorflow.lite.Interpreter.run(Interpreter.java:96)\r\n                      at com.example.android.tflitecamerademo.ImageClassifierFloatInception.runInference(ImageClassifierFloatInception.java:104)\r\n                      at com.example.android.tflitecamerademo.ImageClassifier.classifyFrame(ImageClassifier.java:110)\r\n                      at com.example.android.tflitecamerademo.Camera2BasicFragment.classifyFrame(Camera2BasicFragment.java:664)\r\n                      at com.example.android.tflitecamerademo.Camera2BasicFragment.access$900(Camera2BasicFragment.java:69)\r\n                      at com.example.android.tflitecamerademo.Camera2BasicFragment$5.run(Camera2BasicFragment.java:560)\r\n                      at android.os.Handler.handleCallback(Handler.java:743)\r\n                      at android.os.Handler.dispatchMessage(Handler.java:95)\r\n                      at android.os.Looper.loop(Looper.java:150)\r\n                      at android.os.HandlerThread.run(HandlerThread.java:61)\r\n`\r\n\r\nThe crash occurred only at the time I used tf.gather() or tf.nn.embedding_lookup(). **The tflite model conversion seems to be completed without any errors.** I visualize the model.tflite by running: \r\n` bazel run tensorflow/contrib/lite/tools:visualize -- model.tflite model_viz.html  `\r\nthe result show that tf.gather() use builtin code. \r\n![1520329163312](https://user-images.githubusercontent.com/12081085/37024964-5e1eda10-2165-11e8-9b6e-d83f345ab8d2.jpg)\r\nI see the similar issue in https://github.com/tensorflow/tensorflow/issues/16308, but no solution.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nThe tensorflow code:\r\n\r\nimport tensorflow as tf\r\nimport pdb\r\nimport tempfile\r\nimport subprocess\r\nimport numpy as np\r\ntf.contrib.lite.tempfile = tempfile\r\ntf.contrib.lite.subprocess = subprocess\r\n\r\nimg = tf.placeholder(name=\"img\", dtype=tf.float32, shape=(1, 299, 299, 3))\r\nwith tf.name_scope(\"MobileNet\"):\r\n  \r\n  temp = tf.constant( 1, shape=[299*3], dtype=tf.int32 )\r\n  embs = tf.get_variable( 'embs', shape=(10, 299) )\r\n  emb = tf.nn.embedding_lookup(embs, temp)   ### this line leads to crash ###\r\n  img = img * 0  + tf.reshape(emb, [1, 299, 299, 3])\r\n\r\n  out = tf.nn.avg_pool(img, [1, 1, 1, 1], [1, 299, 299, 1], 'VALID')\r\n  \r\n  out = tf.layers.conv2d(\r\n        inputs=out,\r\n        filters=1001,\r\n        kernel_size=[5, 5],\r\n        padding=\"same\",\r\n        activation=tf.nn.relu)\r\n\r\n  out = tf.squeeze(out, [0, 1])\r\n  out = tf.contrib.layers.softmax(out, scope='Predictions')\r\n\r\nsaver = tf.train.Saver(tf.all_variables())\r\nwith tf.Session() as sess:\r\n   tf.global_variables_initializer().run()\r\n   saver.save(sess, \"model/model.ckpt\")\r\n   tf.train.write_graph(sess.graph_def, 'model', 'train.pb', as_text=False)", "comments": ["Nagging Assignee @aselle: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @aselle: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @aselle: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Could you try again with a recent version of TF Lite?", "Nagging Assignee @aselle: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @aselle: It has been 30 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @aselle: It has been 45 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 17471, "title": "Feature request: tf.data.Dataset.unordered_merge()", "body": "We're dealing with sequence models and we are bucketing training data by using\r\n`tf.contrib.data.group_by_window.`\r\nHowever, it's sequential by nature and too slow. \r\nSo we want to call it in parallel giving up completeness of shuffle. The `tf.data.Dataset` API has\r\n`shard` operation, however, it doesn't have `unordered_merge.` The `zip` operation waits all coming datasets and so isn't useful for this purpose. unordered_merge takes data from any comming dataset ready. It can be used to parallelize data flows.\r\n\r\n\r\nFollowing is only for satisfying the format; This request is independent of the System Information.\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: YES\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: source, HEAD of master 20180226\r\n- **TensorFlow version (use command below)**:source, HEAD of master 20180226\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**: 0.10.0; installed by bazel-0.10.0-installer-linux-x86_64.sh\r\n- **GCC/Compiler version (if compiling from source)**:4.8.5\r\n- **CUDA/cuDNN version**:V9.1.85\r\n- **GPU model and memory**:Tesla V100/16GB\r\n- **Exact command to reproduce**:N/A\r\n\r\n", "comments": ["I'd welcome this as a contribution in `tf.contrib.data`.", "I would like to work on this issue. @deasuke, Can you clarify a bit more about your use case and unordered_merge? ", "Thank you!  @toshirin is working on it and achieved x8 throughput on 10 parallel dataset merge.\r\nhttps://github.com/toshirin/tensorflow   (see unordered_merge branch)\r\n\r\nHave to add I/F, unit tests and documents.", "I submitted a pull request.\r\nWould you review it?", "@mrry \r\nWould you show me how to add  my confirm to the pull request by @toshirin ?\r\nWill I got a mail or message on Github from Googlebot?\r\n\r\n\r\nI think I already signed the CLA.\r\n> The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so. Everything is all good there.\r\n\r\nHowever, the Googlebot reports this error.\r\n> The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter. We need to confirm that all authors are ok with their commits being contributed to this project. Please have them confirm that here in the pull request.", "As contrib folder is deprecated , this feature request is not relevant , so closing this issue. Than you "]}, {"number": 17470, "title": "how to get tuple for tensorflow in c++", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:win10\r\n- **TensorFlow installed from (source or binary)**:source\r\n- **TensorFlow version (use command below)**:rc1.5\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:8.0/7.1\r\n- **GPU model and memory**:Nvidia GT\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nRewrite tracking code from python to c++.\r\nI don't know how to get tuple in c++.\r\nThe python and c++ code as following:\r\n\r\n\r\n### Source code / logs\r\npython code:\r\nlstm2_outputs, state2 = tf.nn.dynamic_rnn(lstm2, lstm2_inputs, initial_state=state2, swap_memory=swap_memory)\r\n\r\nstate2 is a tuple,state2[0] has shape(1,1024),state2[1] has shape(1,1024).\r\n\r\nc++ code:\r\nStatus run_status = session->Run({ { \"Placeholder\",place_ } ,{ \"Placeholder_1\",place1_ } ,{ \"Placeholder_2\",place2_ } ,{ \"Placeholder_3\",place3_ }  ,{ \"Placeholder_4\",place4_ }, { \"Placeholder_5\",place5_ } },output_tensor_names, {}, { &outputs });\r\n\r\noutput_tensor_names:re3/lstm1/rnn/transpose_1,re3/lstm2/rnn/transpose_1,\r\nwhy outputs[0]'s shape is(1,1,1024),outputs[1]'s shape is(1,1,1024),I think they should be (2,1,1024) according the output of python.\r\nThe python is the original code which is absolutely,i think my c++ code goes wrong!\r\n\r\nin python code:\r\n        feed_dict = {\r\n                self.imagePlaceholder : [croppedInput0, croppedInput1],\r\n                self.prevLstmState : lstmState,\r\n                self.batch_size : 1,\r\n                }\r\nin c++ code ,i write it like this:\r\nStatus run_status = session->Run({ { \"Placeholder\",place_ } ,{ \"Placeholder_1\",place1_ } ,{ \"Placeholder_2\",place2_ } ,{ \"Placeholder_3\",place3_ }  ,{ \"Placeholder_4\",place4_ }, { \"Placeholder_5\",place5_ } },output_tensor_names, {}, { &outputs });\r\nthe shape is: place_ (2,227,227,3),place1_~place_4(1,1024),does the problem from here?\r\n\r\nmy model node is like \uff1a\r\nnode {\r\n  name: \"Placeholder\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_UINT8\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: -1\r\n        }\r\n        dim {\r\n          size: 227\r\n        }\r\n        dim {\r\n          size: 227\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Placeholder_1\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: -1\r\n        }\r\n        dim {\r\n          size: 1024\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nnode {\r\n  name: \"Placeholder_2\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: -1\r\n        }\r\n        dim {\r\n          size: 1024\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\n\r\nsome body know why?Give my great appreciation to you! \r\n\r\n\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 17469, "title": "ValueError: No attr named '_XlaCompile' in name: \"Tile_1\"\uff0cplease help me", "body": "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\r\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 348, in _MaybeCompile\r\n    xla_compile = op.get_attr(\"_XlaCompile\")\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2003, in get_attr\r\n    raise ValueError(\"No attr named '\" + name + \"' in \" + str(self._node_def))\r\nValueError: No attr named '_XlaCompile' in name: \"Tile_1\"\r\nop: \"Tile\"\r\ninput: \"Const_1\"\r\ninput: \"Tile_1/multiples\"\r\nattr {\r\n  key: \"T\"\r\n  value {\r\n    type: DT_FLOAT\r\n  }\r\n}\r\nattr {\r\n  key: \"Tmultiples\"\r\n  value {\r\n    type: DT_INT32\r\n  }\r\n}\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/lx/PycharmProjects/chinese/img/model/tfDect_tiny.py\", line 342, in <module>\r\n    tfd = TFDect(logdir=\".\")\r\n  File \"/home/lx/PycharmProjects/chinese/img/model/tfDect_tiny.py\", line 293, in __init__\r\n    global_step=self.global_step)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/optimizer.py\", line 343, in minimize\r\n    grad_loss=grad_loss)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/optimizer.py\", line 414, in compute_gradients\r\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 581, in gradients\r\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 353, in _MaybeCompile\r\n    return grad_fn()  # Exit early\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 581, in <lambda>\r\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_grad.py\", line 523, in _TileGrad\r\n    assert isinstance(grad, ops.Tensor)\r\nAssertionError", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "@lxwithgod , @GoyalShreya , Did you solve the problem? I am having an extremely similar issue."]}, {"number": 17468, "title": "DeepLab v3+ Not Supported", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary: by \"pip3 install --upgrade tensorflow-gpu\"\r\n- **TensorFlow version (use command below)**:\r\ntensorflow-gpu (1.6.0)\r\n- **Python version**: \r\nPython 3.5.2 \r\n- **Bazel version (if compiling from source)**:  0.11.0\r\n- **GCC/Compiler version (if compiling from source)**:\r\ngcc (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609\r\n- **CUDA/cuDNN version**:\r\nCUDA 9.0 cuDNN 7\r\n- **GPU model and memory**: Null\r\n- **Exact command to reproduce**:\r\n> ~/tensorflow/bazel-bin/tensorflow/contrib/lite/toco/toco \\\r\n--input_file=./RD_Net/RD_Net_opt.pb \\\r\n--output_file=./RD_Net.tflite \\\r\n--input_format=TENSORFLOW_GRAPHDEF \\\r\n--output_format=TFLITE \\\r\n--inference_type=FLOAT \\\r\n--input_data_types=FLOAT \\\r\n--input_arrays=Placeholder \\\r\n--output_arrays=seq_4/Conv/BiasAdd \\\r\n--input_shapes=1,240,320,3\r\n\r\n### Describe the problem\r\nI save my pre-trained model into .pb file according to [freeze_graph.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py) and [optimize_for_inference.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/optimize_for_inference.py)\r\n\r\nmy input/out node in .pbtxt\r\n\r\n> node {\r\n  name: \"Placeholder\"\r\n  op: \"Placeholder\"\r\n  attr {\r\n    key: \"dtype\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"shape\"\r\n    value {\r\n      shape {\r\n        dim {\r\n          size: 1\r\n        }\r\n        dim {\r\n          size: 240\r\n        }\r\n        dim {\r\n          size: 320\r\n        }\r\n        dim {\r\n          size: 3\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\n\r\n> node {\r\n  name: \"seq_4/Conv/BiasAdd\"\r\n  op: \"BiasAdd\"\r\n  input: \"seq_4/Conv/Conv2D\"\r\n  input: \"seq_4/Conv/biases\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"data_format\"\r\n    value {\r\n      s: \"NHWC\"\r\n    }\r\n  }\r\n}\r\n\r\nI use the .pb to test prediction and it work fine. (the in/out node name and size are checked)\r\nbut fail in .tflite converting flow...  any suggestion?\r\n\r\nMy step:\r\n1. clone last tensorflow (commit 72239e9b0432a26feadc2412abf89a8fb92828f0)\r\n\r\n2. build the toco:\r\n> bazel build tensorflow/contrib/lite/toco:toco\r\n\r\n3. and convert my .pb into .tflite:\r\n> ~/tensorflow/bazel-bin/tensorflow/contrib/lite/toco/toco \\\r\n--input_file=./RD_Net/RD_Net_opt.pb \\\r\n--output_file=./RD_Net.tflite \\\r\n--input_format=TENSORFLOW_GRAPHDEF \\\r\n--output_format=TFLITE \\\r\n--inference_type=FLOAT \\\r\n--input_data_types=FLOAT \\\r\n--input_arrays=Placeholder \\\r\n--output_arrays=seq_4/Conv/BiasAdd \\\r\n--input_shapes=1,240,320,3\r\n\r\nthe error msg:\r\n\r\n> 2018-03-06 15:39:30.859538: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1365 operators, 2579 arrays (0 quantized)\r\n2018-03-06 15:39:30.910650: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1365 operators, 2579 arrays (0 quantized)\r\n2018-03-06 15:39:30.967113: F tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:764] Check failed: output_size_shape.dimensions_count() == 1 (2 vs. 1)\r\nAborted (core dumped)\r\n\r\n\r\n", "comments": ["@andrehentz Can you take a look at this or recommend someone who works on this?", "It looks like you have a resize_bilinear operations where the 'shape' is 2D but TOCO expects it to be 1D (which seems to match the documentation at https://www.tensorflow.org/api_docs/python/tf/image/resize_bilinear)", "Hi @andrehentz  how do you known have a resize_bilinear operations? the error msg doesn't show the key word. \r\nI do have resize_bilinear for upsample.\r\nit is weird that if I use  graph_transforms tools by myself with cmd line after \"optimize_for_inference.py\", the converter work fine to get .tflite but fail at android app like #17501.\r\n\r\nTherefore, I finally change \"resize_bilinear\"  into \"TransposeConv\" but fail with #17501 \r\n\r\nAny suggestion? Thanks~~~", "I looke at tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:764 which is handling resize bilinear. Why is the shape of your resize_bilinear 2D? Is that something that TF supports but TF Lite doesn't?", "Nagging Assignee @andrehentz: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Hi, I'm having the same issue. I'm using the frozen DeepLab v3+ model from [here](https://github.com/tensorflow/models/tree/master/research/deeplab) ([xception_coco_voc_trainaug](https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md)).\r\n\r\nI printed out the shapes of all `ResizeBilinear/size` tensors, as well as the shapes of the inputs to all of the `ResizeBilinear` tensors, and it seems that they are all 1D and have two elements:\r\n\r\n```\r\nIn [59]: print([(n.name, n.outputs[0].get_shape(), tf.contrib.util.constant_value(n.outputs[0])) for n in tf.get_default_graph().get_operations() if 'Bilinear' in n.name and '/size' in n.name])\r\n\r\n[('import/ResizeBilinear_1/size', TensorShape([Dimension(2)]), array([65, 65], dtype=int32)), ('import/decoder/ResizeBilinear/size', TensorShape([Dimension(2)]), array([129, 129], dtype=int32)), ('import/decoder/ResizeBilinear_1/size', TensorShape([Dimension(2)]), array([129, 129], dtype=int32)), ('import/ResizeBilinear_2/size', TensorShape([Dimension(2)]), array([129, 129], dtype=int32))]\r\n```\r\n\r\n```\r\nIn [60]: print([(n.name, n.inputs[1].name, n.inputs[1].shape, tf.contrib.util.constant_value(n.inputs[1])) for n in tf.get_default_graph().get_operations() if 'Bilinear' in n.name and '/size' not in n.name])\r\n\r\n[('import/ResizeBilinear', 'import/ToInt32:0', TensorShape([Dimension(2)]), None), ('import/ResizeBilinear_1', 'import/ResizeBilinear_1/size:0', TensorShape([Dimension(2)]), array([65, 65], dtype=int32)), ('import/decoder/ResizeBilinear', 'import/decoder/ResizeBilinear/size:0', TensorShape([Dimension(2)]), array([129, 129], dtype=int32)), ('import/decoder/ResizeBilinear_1', 'import/decoder/ResizeBilinear_1/size:0', TensorShape([Dimension(2)]), array([129, 129], dtype=int32)), ('import/ResizeBilinear_2', 'import/ResizeBilinear_2/size:0', TensorShape([Dimension(2)]), array([129, 129], dtype=int32)), ('import/ResizeBilinear_3', 'import/strided_slice_7:0', TensorShape([Dimension(2)]), None)]\r\n```\r\n\r\nHowever, when I add the following code to `ProcessResizeBilinearOperator`,\r\n\r\n```\r\n  std::cout << \"Output size shape for \" << output_size_name << \": \";\r\n  for(auto dim : output_size_shape.dims()) {\r\n    std::cout << dim << \", \";\r\n  }\r\n  std::cout << std::endl;\r\n  // CHECK_EQ(output_size_shape.dimensions_count(), 1);\r\n```\r\n\r\nI get the output:\r\n\r\n```\r\n2018-03-27 16:44:23.330779: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1236] Converting unsupported operation: Equal\r\n2018-03-27 16:44:23.330937: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1236] Converting unsupported operation: LogicalAnd\r\n2018-03-27 16:44:23.453760: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1895 operators, 3070 arrays (0 quantized)\r\n2018-03-27 16:44:23.504983: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 1885 operators, 3051 arrays (0 quantized)\r\n2018-03-27 16:44:23.573858: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1885 operators, 3051 arrays (0 quantized)\r\nOutput size shape for ToInt32: 2, 1, \r\n2018-03-27 16:44:23.803197: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 460 operators, 1136 arrays (0 quantized)\r\nOutput size shape for ToInt32: 2, 1, \r\n2018-03-27 16:44:23.817572: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 460 operators, 1136 arrays (0 quantized)\r\n2018-03-27 16:44:23.827669: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:311] Total transient array allocated size: 7105728 bytes, theoretical optimal value: 6316160 bytes.\r\n2018-03-27 16:44:23.830342: F tensorflow/contrib/lite/toco/tooling_util.cc:1818] Check failed: array.final_data_type == array.data_type Array \"ImageTensor\" has mis-matching actual and final data types (4,2).\r\n./convert.sh: line 10: 30075 Aborted                 (core dumped) bazel-bin/tensorflow/contrib/lite/toco/toco --input_file=../deeplabv3/deeplabv3_pascal_train_aug/frozen_inference_graph.pb --input_format=TENSORF\r\nLOW_GRAPHDEF --output_format=TFLITE --output_file=../deeplabv3/deeplabv3_pascal_train_aug/deeplabv3.tflite --inference_type=FLOAT --input_type=FLOAT --input_arrays=ImageTensor --output_arrays=SemanticPredictions \r\n--input_shapes=1,513,513,3\r\n\r\n```\r\n\r\nDoes this information help?\r\n\r\nEDIT: removing the `--input_type` and `--inference_type` flags from the call gets rid of the mis-match error (converting the model does not work though since it is TFLite is missing some operations).", "I'm facing the same issue with mobilenet v2 downloaded from [mobilenetv2_coco_voc_trainaug](http://download.tensorflow.org/models/deeplabv3_mnv2_pascal_train_aug_2018_01_29.tar.gz).\r\n\r\nThe command to generate tlite file\r\n\r\n```\r\nbazel-bin/tensorflow/contrib/lite/toco/toco \\\r\n> --input_file=frozen_inference_graph.pb \\\r\n> --input_format=TENSORFLOW_GRAPHDEF \\\r\n> --output_format=TFLITE \\\r\n> --output_file=frozen_inference_graph.lite \\\r\n> --inference_type=FLOAT \\\r\n> --input_type=FLOAT \\\r\n> --input_arrays=ImageTensor \\\r\n> --output_arrays=SemanticPredictions \\\r\n> --input_shapes=1,513,342,3\r\n\r\n```\r\nThe log of the error.\r\n```\r\n2018-04-01 15:57:00.360279: W tensorflow/contrib/lite/toco/toco_cmdline_flags.cc:178] --input_type is deprecated. It was an ambiguous flag that set both --input_data_types and --inference_input_type. If you are trying to complement the input file with information about the type of input arrays, use --input_data_type. If you are trying to control the quantization/dequantization of real-numbers input arrays in the output file, use --inference_input_type.\r\n2018-04-01 15:57:00.389245: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1172] Converting unsupported operation: Equal\r\n2018-04-01 15:57:00.389504: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1172] Converting unsupported operation: LogicalAnd\r\n2018-04-01 15:57:00.406372: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 812 operators, 1241 arrays (0 quantized)\r\n2018-04-01 15:57:00.434485: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 802 operators, 1222 arrays (0 quantized)\r\n2018-04-01 15:57:00.465611: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 802 operators, 1222 arrays (0 quantized)\r\n2018-04-01 15:57:00.465869: F tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:737] Check failed: output_size_shape.dimensions_count() == 1 (2 vs. 1)\r\nAborted (core dumped)\r\n```\r\n", "Nagging Assignee @andrehentz: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @andrehentz: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "same error as @calicratis19 ", "same error as @calicratis19", "same error as @calicratis19", "I had similar issues when converting a ResNet variant with TOCO from v1.8.0. It seems that this has been fixed by now. Checking out the latest master branch allows me to convert my model successfully.", "same error as @calicratis19 ", "same error as @calicratis19 ", "same error as @calicratis19", "I get this error:\r\nF tensorflow/contrib/lite/toco/tooling_util.cc:822] Check failed: d >= 1 (0 vs. 1)", "This error converting my LSTM graph:\r\n[https://stackoverflow.com/questions/51275360/convert-lstm-graph-with-tflite-fails](https://stackoverflow.com/questions/51275360/convert-lstm-graph-with-tflite-fails)", "During inference, batch size = 1, 10 inputs, each input is of length 2560", "Looks like DeepLab is converted successfully. For other issues please open separate bugs with additional information to help us debug this better."]}, {"number": 17467, "title": "Feature request: implement Rayleigh random sampling op", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.6.0\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: -\r\n- **GCC/Compiler version (if compiling from source)**: -\r\n- **CUDA/cuDNN version**: 9.0\r\n- **GPU model and memory**: 1080\r\n- **Exact command to reproduce**: -\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nTensorFlow does not currently offer `tf.random_rayleigh`, similar to `np.random.rayleigh`. What would be the simplest way to add this op?\r\n\r\nThe distribution is:\r\n\r\n![1c179e259da5763ce4e5dd125cd5f80e1361eb2c](https://user-images.githubusercontent.com/3104289/37019516-ca059586-2118-11e8-81ec-472bb0a7d6fa.png)\r\n", "comments": ["You can sample from a Rayleigh distribution using the [uniform sampler](https://en.wikipedia.org/wiki/Rayleigh_distribution#Generating_random_variates).  Use `tf.random_uniform` and then pass it through\r\n\r\n```python\r\nx = sigma * tf.sqrt(-2/np.log(2) * tf.log(u))\r\n```\r\n\r\n@jvdillon we can add this as a distribution pretty easily.", "Ive added this request to our internal feature request tracker. Thanks!", "Nagging Assignee @jvdillon: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @jvdillon: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @jvdillon: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @jvdillon: It has been 16 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @jvdillon: It has been 79 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @jvdillon: It has been 94 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @jvdillon: It has been 109 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I'll created and will soon submit `tfp.math.random_rayleigh` in \r\nhttps://github.com/tensorflow/probability"]}, {"number": 17466, "title": "fix typo", "body": "espected -> expected", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to `go/cla#troubleshoot`.\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->"]}, {"number": 17465, "title": "Accepts `PathLike` objects for dataset readers", "body": "* Dataset operations convert `PathLike` objects to string\r\n* `compat.path_to_str` now accepts one or more objects to convert\r\n\r\nFurther work to #15784 to allow `PathLike` objects to be passed to Dataset readers as well. ", "comments": ["It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "@mrry Added some tests, but I get the error of `ImportError: cannot import name c_api_util` when running them. \r\n\r\nCopied the configuration from another test target in tensorflow/python/BUILD. Are you able to provide any assistance to what might be wrong?", "Can you post a complete stack trace? I don't see any uses of `c_api_util` in your code, so it's possible there's a missing dependency in some other module.", "@mrry this was the log from the test run of `bazel test //tensorflow/python:compat_test` defined as [compat_test](https://github.com/damienpontifex/tensorflow/blob/15784-PathLike/tensorflow/python/BUILD#L3184-L3199)\r\n\r\nI had also tried having \"//tensorflow:tensorflow_py\" in the deps with no effect.\r\n\r\n```\r\nexec ${PAGER:-/usr/bin/less} \"$0\" || exit 1\r\nExecuting tests from //tensorflow/python:compat_test\r\n-----------------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/private/var/tmp/_bazel_ponti/1bf50702e52e66a9548714e0ff46eaaa/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/python/compat_test.runfiles/org_tensorflow/tensorflow/python/util/compat_test.py\", line 34, in <module>\r\n    from tensorflow.python.platform import test\r\n  File \"/private/var/tmp/_bazel_ponti/1bf50702e52e66a9548714e0ff46eaaa/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/python/compat_test.runfiles/org_tensorflow/tensorflow/python/platform/test.py\", line 30, in <module>\r\n    from tensorflow.python.framework import test_util as _test_util\r\n  File \"/private/var/tmp/_bazel_ponti/1bf50702e52e66a9548714e0ff46eaaa/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/python/compat_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 50, in <module>\r\n    from tensorflow.python.client import session\r\n  File \"/private/var/tmp/_bazel_ponti/1bf50702e52e66a9548714e0ff46eaaa/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/python/compat_test.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 31, in <module>\r\n    from tensorflow.python.framework import errors\r\n  File \"/private/var/tmp/_bazel_ponti/1bf50702e52e66a9548714e0ff46eaaa/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/python/compat_test.runfiles/org_tensorflow/tensorflow/python/framework/errors.py\", line 22, in <module>\r\n    from tensorflow.python.framework import errors_impl as _impl\r\n  File \"/private/var/tmp/_bazel_ponti/1bf50702e52e66a9548714e0ff46eaaa/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/python/compat_test.runfiles/org_tensorflow/tensorflow/python/framework/errors_impl.py\", line 26, in <module>\r\n    from tensorflow.python.framework import c_api_util\r\n  File \"/private/var/tmp/_bazel_ponti/1bf50702e52e66a9548714e0ff46eaaa/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/python/compat_test.runfiles/org_tensorflow/tensorflow/python/framework/c_api_util.py\", line 25, in <module>\r\n    from tensorflow.python.util import compat\r\n  File \"/private/var/tmp/_bazel_ponti/1bf50702e52e66a9548714e0ff46eaaa/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/python/compat_test.runfiles/org_tensorflow/tensorflow/python/util/compat.py\", line 44, in <module>\r\n    from tensorflow.python.framework import ops\r\n  File \"/private/var/tmp/_bazel_ponti/1bf50702e52e66a9548714e0ff46eaaa/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/python/compat_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py\", line 41, in <module>\r\n    from tensorflow.python.eager import context\r\n  File \"/private/var/tmp/_bazel_ponti/1bf50702e52e66a9548714e0ff46eaaa/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/python/compat_test.runfiles/org_tensorflow/tensorflow/python/eager/context.py\", line 29, in <module>\r\n    from tensorflow.python.framework import c_api_util\r\nImportError: cannot import name c_api_util\r\n```", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I'll close this PR. @damienpontifex please reopen if you address the comments. Thanks!", "@martinwicke @mrry I managed to resolve the raised issues and tests now pass successfully. Are we able to reopen this so my latest changes on this branch of mine can be updated here and see what we think?", "Hm... I cannot reopen the PR (\"branch was force-pushed or recreated\") can you make a new one?", "Thanks, yeh I rebased from master to get this branch up to date. I will recreate. Thanks", "@martinwicke created at #22368"]}, {"number": 17464, "title": "train priblem", "body": "\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Distributor ID: \r\nCentOS\r\nDescription:    CentOS Linux release 7.2.1511 (Core) \r\nRelease:        7.2.1511\r\n- **TensorFlow installed from (source or binary)**:pip\r\n- **TensorFlow version (use command below)**:1.5.0\r\n- **Python version**: Python 2.7.5\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:no\r\n- **GPU model and memory**:no\r\n- **Exact command to reproduce**:\r\n\r\nps\r\n```\r\n2018-03-06 11:13:09.816655: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:2222\r\n2018-03-06 11:14:56.902071: W tensorflow/core/framework/op_kernel.cc:1198] Not found: checkpoint/model.ckpt-1_temp_9e8396c2f6d04e91ad3c3fbc194a9f70; No such file or directory\r\n2018-03-06 11:14:56.902071: W tensorflow/core/framework/op_kernel.cc:1198] Not found: checkpoint/model.ckpt-1_temp_9e8396c2f6d04e91ad3c3fbc194a9f70; No such file or directory\r\n```\r\n\r\nwork:\r\n```\r\n2018-03-06 11:10:24.342583: I tensorflow/core/distributed_runtime/master_session.cc:1017] Start master session 592fd1b6a4409f07 with config: gpu_options { allow_growth: true } allow_soft_placement: true\r\nException in thread QueueRunnerThread-dummy_queue-sync_token_q_EnqueueMany:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib64/python2.7/threading.py\", line 812, in __bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib64/python2.7/threading.py\", line 765, in run\r\n    self.__target(*self.__args, **self.__kwargs)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 266, in _run\r\n    coord.request_stop(e)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py\", line 211, in request_stop\r\n    six.reraise(*sys.exc_info())\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 250, in _run\r\n    enqueue_callable()\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1251, in _single_operation_run\r\n    self._session, None, {}, [], target_list, status, None)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py\", line 473, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\nCancelledError: Step was cancelled by an explicit call to `Session::Close()`.\r\n\r\nTraceback (most recent call last):\r\n  File \"leave.py\", line 204, in <module>\r\n    tf.app.run()\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 124, in run\r\n    _sys.exit(main(argv))\r\n  File \"leave.py\", line 195, in main\r\n    rnn_model.global_step], feed_dict={keep_prob: FLAGS.dropout_keep_prob})\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 539, in run\r\n    run_metadata=run_metadata)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1013, in run\r\n    run_metadata=run_metadata)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1104, in run\r\n    raise six.reraise(*original_exc_info)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1089, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1169, in run\r\n    run_metadata=run_metadata))\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 452, in after_run\r\n    self._save(run_context.session, global_step)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 468, in _save\r\n    self._get_saver().save(session, self._save_path, global_step=step)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1614, in save\r\n    raise exc\r\ntensorflow.python.framework.errors_impl.NotFoundError: checkpoint/model.ckpt-1_temp_5d8d532077d241a38f2d79ac2ffeb9a7; No such file or directory\r\n         [[Node: save/SaveV2 = SaveV2[dtypes=[DT_INT64], _device=\"/job:ps/replica:0/task:0/device:CPU:0\"](save/ShardedFilename, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, global_step)]]\r\n         [[Node: save/Identity_S445 = _HostRecv[client_terminated=false, recv_device=\"/job:worker/replica:0/task:0/device:CPU:0\", send_device=\"/job:ps/replica:0/task:0/device:CPU:0\", send_device_incarnation=-8763115780137487660, tensor_name=\"edge_111_save/Identity\", tensor_type=DT_STRING, _device=\"/job:worker/replica:0/task:0/device:CPU:0\"]()]]\r\n\r\nCaused by op u'save/SaveV2', defined at:\r\n  File \"leave.py\", line 204, in <module>\r\n    tf.app.run()\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 124, in run\r\n    _sys.exit(main(argv))\r\n  File \"leave.py\", line 184, in main\r\n    config=set_config_proto()) as mon_sess:\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 380, in MonitoredTrainingSession\r\n    stop_grace_period_secs=stop_grace_period_secs)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 787, in __init__\r\n    stop_grace_period_secs=stop_grace_period_secs)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 511, in __init__\r\n    self._sess = _RecoverableSession(self._coordinated_creator)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 972, in __init__\r\n    _WrappedSession.__init__(self, self._create_session())\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 977, in _create_session\r\n    return self._sess_creator.create_session()\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 668, in create_session\r\n    self.tf_sess = self._session_creator.create_session()\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 431, in create_session\r\n    self._scaffold.finalize()\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 210, in finalize\r\n    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 821, in _get_saver_or_default\r\n    saver = Saver(sharded=True, allow_empty=True)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1239, in __init__\r\n    self.build()\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1248, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1284, in _build\r\n    build_save=build_save, build_restore=build_restore)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 756, in _build_internal\r\n    save_tensor = self._AddShardedSaveOps(filename_tensor, per_device)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 382, in _AddShardedSaveOps\r\n    return self._AddShardedSaveOpsForV2(filename_tensor, per_device)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 356, in _AddShardedSaveOpsForV2\r\n    sharded_saves.append(self._AddSaveOps(sharded_filename, saveables))\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 297, in _AddSaveOps\r\n    save = self.save_op(filename_tensor, saveables)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 240, in save_op\r\n    tensors)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1174, in save_v2\r\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nNotFoundError (see above for traceback): checkpoint/model.ckpt-1_temp_5d8d532077d241a38f2d79ac2ffeb9a7; No such file or directory\r\n         [[Node: save/SaveV2 = SaveV2[dtypes=[DT_INT64], _device=\"/job:ps/replica:0/task:0/device:CPU:0\"](save/ShardedFilename, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, global_step)]]\r\n         [[Node: save/Identity_S445 = _HostRecv[client_terminated=false, recv_device=\"/job:worker/replica:0/task:0/device:CPU:0\", send_device=\"/job:ps/replica:0/task:0/device:CPU:0\", send_device_incarnation=-8763115780137487660, tensor_name=\"edge_111_save/Identity\", tensor_type=DT_STRING, _device=\"/job:worker/replica:0/task:0/device:CPU:0\"]()]]\r\n```\r\n\r\n", "comments": ["```\r\n   with tf.train.MonitoredTrainingSession(master=server.target,\r\n                                                   is_chief=is_chief,\r\n                                                   checkpoint_dir=\"checkpoint/\",\r\n                                                   hooks=hooks,\r\n                                                   save_checkpoint_secs=60,\r\n                                                   config=set_config_proto()) as mon_sess:\r\n```", "The development environment for the MAC can run. On the server, if the amount of data is relatively small, it can run, and the data volume is too large to fail.", "\r\nEven if all the data is cleared, the rerun is a failure.", "have you solved this problem? @cyqluowang ", "From the error message `NotFoundError (see above for traceback): checkpoint/model.ckpt-1_temp_5d8d532077d241a38f2d79ac2ffeb9a7; No such file or directory` it seems that the workers are having trouble writing to the `checkpoint` directory.\r\n\r\nIt is possible that the parent directory where checkpoints are to be written is either not accessible or is being removed while the training is in process? ", "ok , thank you", "Closing since I interpreted your last comment to imply that my hunch was correct. Please feel free to reopen if I was mistaken. Thanks.", " i got a same error when doing sync training in distribution environment.\r\nSys: Linux Ubuntu 14.04\r\nTF I install from: pip\r\nTF version: 1.6.0\r\npython version: 2.7.14\r\n\r\n\r\n          Exception in thread QueueRunnerThread-dummy_queue-sync_token_q_EnqueueMany:\r\n          Traceback (most recent call last):\r\n            File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\r\n              self.run()\r\n            File \"/usr/lib/python2.7/threading.py\", line 754, in run\r\n              self.__target(*self.__args, **self.__kwargs)\r\n            File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 268, in _run\r\n              coord.request_stop(e)\r\n            File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py\", line 213, in request_stop\r\n              six.reraise(*sys.exc_info())\r\n            File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 252, in _run\r\n              enqueue_callable()\r\n            File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1259, in _single_operation_run\r\n              None)\r\n           File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 516, in \r\n          __exit__\r\n            c_api.TF_GetCode(self.status.status))\r\n          CancelledError: Step was cancelled by an explicit call to Session::Close().\r\n\r\n\r\n**and part of my codes is:**\r\n\r\n          class _LoggerHook(tf.train.SessionRunHook):\r\n                def begin(self):\r\n                    self._step = 0\r\n                    self._start_time = time.time()\r\n                    self._total_loss = 0\r\n            \r\n                def before_run(self, run_context):\r\n                    self._step += 1\r\n                    return tf.train.SessionRunArgs(loss)\r\n            \r\n                def after_run(self, run_context, run_values):\r\n                    loss_value = run_values.results\r\n                    self._total_loss += loss_value\r\n                    if self._step % FLAGS.log_frequency == 0:\r\n                        current_time = time.time()\r\n                        duration = current_time - self._start_time\r\n                        self._start_time = current_time\r\n                        if self._step==0:\r\n                            avg_loss = loss_value\r\n                        else:\r\n                            avg_loss = self._total_loss/self._step\r\n                        eg_per_sec = FLAGS.log_frequency * FLAGS.batch_size / duration\r\n                        sec_per_batch = float(duration / FLAGS.log_frequency)\r\n                        print('%s: training step %d cur loss = %.4f avg loss = %.4f (%.1f images/sec %.3f sec/batch)'\r\n                              % (datetime.now(), self._step, loss_value, avg_loss, eg_per_sec, sec_per_batch))\r\n            \r\n            all_hooks=[tf.train.NanTensorHook(loss), tf.train.StopAtStepHook(last_step=FLAGS.max_steps), _LoggerHook()]\r\n            if FLAGS.issync:\r\n                all_hooks.append(sync_replicas_hook)\r\n            if FLAGS.debug:\r\n                all_hooks.append(tfdbg.LocalCLIDebugHook(ui_type='curses'))\r\n            if FLAGS.finetune:\r\n                print('Finetune from %s'%FLAGS.finetune)\r\n                saver = tf.train.Saver()\r\n            config = tf.ConfigProto(log_device_placement=FLAGS.log_device_placement)\r\n            config.gpu_options.allow_growth=True\r\n            with tf.train.MonitoredTrainingSession(\r\n                    master=server.target,\r\n                    is_chief=(FLAGS.task_index == 0),\r\n                    checkpoint_dir=FLAGS.model_dir,\r\n                    hooks=all_hooks,\r\n                    config=config,\r\n                    save_summaries_steps=100,\r\n                    save_summaries_secs=None,\r\n                    log_step_count_steps=None) as sess:\r\n                if FLAGS.finetune:\r\n                    print('Load Pretrained model')\r\n                    ckpt = tf.train.get_checkpoint_state(FLAGS.finetune)\r\n                    if ckpt and ckpt.model_checkpoint_path:\r\n                        saver.restore(sess, ckpt.model_checkpoint_path)\r\n                    print('-------------------------')\r\n                while not sess.should_stop():\r\n                    sess.run(train_op)", "Got the same error log of @HandsomeHans  in `TensorFlow 1.8.0`."]}, {"number": 17463, "title": "Could the periodic resample operation be accelerated?", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:  No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.10\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: ('v1.5.0-0-g37aa430d84', '1.5.0')\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 9.0/7.0\r\n- **GPU model and memory**: NVIDIA GeForce GTX 1080, 8 GB\r\n- **Exact command to reproduce**: python periodic_resample.py\r\n\r\n### Describe the problem\r\nThe [periodic resample](https://www.tensorflow.org/api_docs/python/tf/contrib/periodic_resample/periodic_resample) operation costs about 700ms when tansforming a tensor from 1x360x640x27 to 1x1080x1920x3. Could it be accelerated by GPU in the future or did I miss something?\r\n\r\n### Source code / logs\r\n```python\r\nimport tensorflow as tf\r\nimport time\r\n\r\na = tf.Variable(tf.random_normal([1, 360, 640, 27], stddev=0.3))\r\nb = tf.contrib.periodic_resample.periodic_resample(a, [1, 1080, 1920, None])\r\n\r\nwith tf.Session() as sess:\r\n    tf.global_variables_initializer().run()\r\n    start = time.time()\r\n    _ = sess.run(b)\r\n    print 'time: %f'%(time.time() - start)\r\n```\r\n```\r\n2018-03-06 10:13:31.817568: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n2018-03-06 10:13:31.949888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-03-06 10:13:31.950167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: \r\nname: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.873\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 7.92GiB freeMemory: 6.50GiB\r\n2018-03-06 10:13:31.950194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\ntime: 0.798653\r\n```\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version\nExact command to reproduce", "Sorry for missing them. I have updated accordingly.", "Hi I'm interested in this operation as well. Can I ask you how to use it with a variable batch size tensor (batch size being known only at run-time) ? I have no idea how to configure the operation that way.", "@hengchuan We see that you are using old version of tensorflow 1.x which is not actively supported, We recommend that you upgrade to 2.4 or later version.Please have a look at the [migration](https://www.tensorflow.org/guide/migrate) guide for reference to migrate from TensorFlow 1.x to TensorFlow 2.Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/17463\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/17463\">No</a>\n"]}, {"number": 17462, "title": "Added replicate_model_fn to contrib.estimator.", "body": "I noticed that multi-gpu training (in a tower-like fashin) in r1.4 is not supported. So I copied the replicate_model_fn from r1.5 and applied the needed changes:\r\n\r\n-adding another key in ops.GraphKeys \"METRIC_VARIABLES\"\r\n-imported replicate_model_fn in contrib.estimator __init__.py ", "comments": ["TensorFlow development is on `master` rather than any of the release branches, and once there is a release branch, we only accept bugfixes for that branch, so we can't accept this right now."]}, {"number": 17461, "title": "Operators not supported: ExpandDims, Prod, Slice.", "body": "**System information**\r\n\r\nOS Platform and Distribution (Linux Ubuntu 14.04):\r\nTensorFlow installed from (build from source):\r\nTensorFlow version (1.5):\r\nBazel version(0.8.1)\r\nCPU mode\r\n\r\n**Describe the problem**\r\ni use an concat operator when i am training my own model, but when i convert it to .tflite by using toco tools, i got this error:\r\nF tensorflow/contrib/lite/toco/tflite/export.cc:303] Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops. Here is a list of operators for which you will need custom implementations: ExpandDims, Prod, Slice.\r\nAborted (core dumped)\r\ni do not use the operators it lists.\r\n[models.zip](https://github.com/tensorflow/tensorflow/files/1783288/models.zip)\r\n\r\nthere are three models definition in the zip file, the model2 adn model3 works, but model1 does not. The only difference between them is model1 use: \r\n```\r\nfeature = tf.concat([flat1,flat2], 1)\r\n```\r\n\r\nto make it more clear, i quote the code block:\r\n```\r\nwith tf.variable_scope(scope, 'lite_v1', [images, num_classes]):\r\n\r\n    images_input = tf.placeholder_with_default(images, shape=[None, 35, 35, 1], name='InputPlaceholder')\r\n\r\n    net = slim.conv2d(images_input, 12, [4, 4], padding='VALID', scope='conv1')\r\n    end_points['conv1'] = net\r\n\r\n    net = slim.max_pool2d(net, [2, 2], 2, scope='pool4')\r\n    end_points['pool4'] = net\r\n    \r\n    flat2 = slim.flatten(net)\r\n\r\n    net = slim.conv2d(net, 64, [2, 2], padding='VALID', scope='conv5')\r\n    end_points['conv5'] = net\r\n    print(\"conv5\")\r\n    print(net)\r\n    flat1 = slim.flatten(net)\r\n\r\n    feature = flat2\r\n    # feature = tf.concat([flat1,flat2], 1)\r\n\r\n    with tf.variable_scope('Logits'):\r\n\r\n      net = slim.fully_connected(feature, 100, scope='fc3')\r\n      \r\n      logits = slim.fully_connected(net, num_classes,\r\n                                  biases_initializer=tf.zeros_initializer(),\r\n                                  weights_regularizer=None,\r\n                                  activation_fn=None,\r\n                                  scope='logits')\r\n      end_points['Logits'] = logits\r\n    output = tf.multiply(logits, 1, name=\"Output\")\r\n    end_points['Output'] = output\r\n\r\n  return logits, end_points\r\nlite_v1.default_image_size = 35\r\n```\r\n\r\n\r\n\r\n", "comments": ["BTW, the concat operator is ok when i use it in other position, only when i want to concat flat1 and flat2 after slim.flatten operator, i got this error.", "i update the models.zip file. \r\nthere are three model definition in the zip file.\r\nthe difference is:\r\nmodel3.py use flat1 as the input of the fully connect layer\r\nmodel2.py use flat2 as the input of the fully connect layer\r\nboth model2 and model3 works with toco.\r\nmodel1.py use tf.concat([flat1, flat2], 1) as the input of the fully connect layer, and model1 does not work and got the error.", "Nagging Assignee @jart: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Hopefully Prod and Slice will be supported later this year. (ExpandDims will go away when those are supported)", "Punting to @aselle for tf-lite.", "Nagging Assignee @aselle: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @aselle: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @aselle: It has been 44 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @aselle: It has been 59 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @aselle: It has been 74 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "These ops should be supported now, please retry", "I just got this error `Tensorflow Op is not supported: Prod` and `Tensorflow Op is not supported: FloorMod` on `tfjs@0.12.4`", "And earlier today trying to convert other model i got this error \r\n`ValueError: Unsupported Ops in the model before optimization\r\nBatchMatMul, FloorMod`"]}, {"number": 17460, "title": "Precision in tf.gradients changed in 1.6 vs. <1.6", "body": "### System information\r\nTry the following code using different values for the infinitesimal 1e-15: \r\n\r\n```python\r\ndef TFDistance(A):\r\n\t\"\"\"\r\n\tCompute a distance matrix of A, a coordinate matrix\r\n\tUsing the factorization:\r\n\tDij = <i|i> - 2<i|j> + <j,j>\r\n\tArgs:\r\n\t\tA: a Nx3 matrix\r\n\tReturns:\r\n\t\tD: a NxN matrix\r\n\t\"\"\"\r\n\tr = tf.reduce_sum(A*A, 1)\r\n\tr = tf.reshape(r, [-1, 1]) \r\n\t# Tensorflow can only reverse mode grad the sqrt if all these elements\r\n\t# are nonzero so add a small infinitesimal \r\n\tD = r - 2*tf.matmul(A, tf.transpose(A)) + tf.transpose(r) + 1e-15\r\n\treturn tf.sqrt(D)\r\nxyzs = tf.random_uniform([2,3],dtype=tf.float64)*10.0\r\nsess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\r\ninit = tf.global_variables_initializer()\r\nsess.run(init)\r\nsess.run([TFDistance(xyzs),tf.gradients(TFDistance(xyzs),xyzs)],feed_dict={x:0.2})\r\n```\r\nThe issue is that in tf < 1.6 a small infinitesimal  (< 1e-15) was enough to avoid nan in tf.gradients due to 1/sqrt(0.0). For some reason in tf 1.6 this is returning a nan for anything less than 1e-13, which produces an unacceptable error in the result. \r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nOSX, pip and pip3 tf 1.6\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n- **TensorFlow version (use command below)**:\r\n'v1.6.0-0-gd2e24b6039', '1.6.0')\r\n- **Python version**: \r\n2.7 and 3.3\r\n- **CUDA/cuDNN version**:\r\nCPU \r\n- **Exact command to reproduce**:\r\n(See script above) \r\n### Describe the problem\r\nIn versions of tensorflow previous to 1.6 this code would not issue a nan gradient for reasonable infinitesimals (<1e-26). Suddenly the way numerical precision is handled in the gradient computation has obviously changed, and changed in a way which is clipping things near zero and doing so differently depending on if colocation of gradients is requested....   \r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nBazel version\nGPU model and memory", "1.6 changed to AVX enabled build which probably affects numerics. You could try if building without AVX to see if precision comes back", "Yaroslavv- \r\n    Thanks for the rapid response and the phenomenal worldly good you're doing with TF. \r\nI have found that a workaround is to use tf.clip_by_value(): \r\n\r\n```python\r\ndef TFDistance(A):\r\n\t\"\"\"\r\n\tCompute a distance matrix of A, a coordinate matrix\r\n\tUsing the factorization:\r\n\tDij = <i|i> - 2<i|j> + <j,j>\r\n\tArgs:\r\n\t\tA: a Nx3 matrix\r\n\tReturns:\r\n\t\tD: a NxN matrix\r\n\t\"\"\"\r\n\tr = tf.reduce_sum(A*A, 1)\r\n\tr = tf.reshape(r, [-1, 1]) # For the later broadcast.\r\n\t# Tensorflow can only reverse mode grad the sqrt if all these elements\r\n\t# are nonzero\r\n\tD = r - 2*tf.matmul(A, tf.transpose(A)) + tf.transpose(r)\r\n\treturn tf.sqrt(tf.clip_by_value(D,1e-36,1e36))\r\nxyzs = tf.random_uniform([2,3],dtype=tf.float64)*10.0\r\nsess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\r\ninit = tf.global_variables_initializer()\r\nsess.run(init)\r\nsess.run([TFDistance(xyzs),tf.gradients(TFDistance(xyzs),xyzs)],feed_dict={x:0.2})\r\n```\r\nStill this change is mildly disturbing because I worry some lower precision math is now implicated in the calculation, and I feel like some unit-test should have caught this. I'm sure anyone whose code computes d(sqrt()) or similar unstable functions is having similar issues. "]}, {"number": 17459, "title": "add a simple tensorflow model safety-check tool", "body": "Check whether a TensorFlow model contains security sensitive ops, Output related info.\r\n\r\nThis script is designed to take a checkpoint or SavedModel model file,\r\nand detect whether it contains security ops, and output the check result.\r\n\r\nTraditionally, a TensorFlow model is considered as data files, this\r\nleads people to ignore the fact that the TensorFlow model/graph\r\nis actual program/code which contains kinds of ops and runs under the\r\nTensorFlow runtime. Therefore, it is possibile to use legitimate ops\r\nto do some malicious things in a model file. This script just checks\r\nsome predefined sensitive ops, do not rely on its result completely.\r\n\r\nFor security risks of TensorFlow model, your can refer to this: \r\nhttps://github.com/tensorflow/tensorflow/blob/master/SECURITY.md", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->", "I signed it", "Can you check that the email on your commits matches the email you use in your github account? Otherwise out CLA checker gets confused.", "Yes, the email is  zhangbo5891001@gmail.com in my github account,  and I have signed CLA.\r\nI don't know why CLA check failed...\r\nAny suggestions? Thanks!", "CLAs look good, thanks!\n\n<!-- ok -->", "Looks like CLABot caught up. Thank you!\r\n\r\n@zhangbo5891001, we were internally discussion whether this would make most sense as a `--security-scan` option to `saved_model_cli`. What do you think? Then all the tools are in one place.\r\n\r\n@yifeif was looking into this.", "I have a pending change internally on saved_model_cli that does something similar. I can convert it into a PR if that makes it easier.", "Yeah, then we can compare. @zhangbo5891001 I think the big question is whether a separate command is preferable for some reason. We were leaning towards something integrated into saved_model_cli to be able to share a bunch of code.", "@martinwicke It seems that the saved_model_cli is a tool for only 'SavedModel' file. Therefore I make a seperate tool both for checkpoint and SavedModel and mainly for security.\r\nWe can add more security checks to this tool if any other security risks found  in the subsequent tensorflow versions.", "I added the saved_model_cli version at #17529. It doesn't check for checkpoint though as @zhangbo5891001 pointed out, and I would prefer to not add checkpoint check to saved_model_cli to keep it clean. @martinwicke what do you think is the best way to proceed here?", "@yifeif I agree we should keep raw checkpoints out of saved_model_cli. We are actively encouraging saving models as SavedModels. \r\n\r\n@zhangbo5891001 users would have to write their own code to interpret a checkpoint + metagraph. There isn't enough information in the metagraph to simply run it. What is the threat model here? I can see a situation where someone writes a graph execution tool and then runs untrusted graphs which happen to conform to an interface that make them work with this custom tool. \r\n\r\nThe way to formally specify the interface (and therefore make this something you can actually share) would be to produce a SavedModel. I would be in favor of adding functionality to saved_model_cli to allows converting a graph + (optionally) a checkpoint + (optionally) inputs and outputs to a SavedModel. Checking that for vulnerabilities (see #17529) makes a lot of sense.", "@martinwicke @yifeif Yes, I agree that keep saved_model_cli clean. That's why I make a separate tool.\r\n\r\nThe real threat of TensorFlow model is the ops in GraphDef of metagraph or SavedModel. Given a metagraph + checkpoint, one can run the graph(load metagraph then run session). Although TensorFlow encourages using SavedModel, many users still use checkpoint + metagraph as the serialization of models.\r\n\r\nIf we want to keep saved_model_cli clean and consider the threat of checkpoint + metagrap, maybe the way @martinwicke mentioned is a good choice.\r\n\r\n> adding functionality to saved_model_cli to allows converting a graph + (optionally) a checkpoint + (optionally) inputs and outputs to a SavedModel. Checking that for vulnerabilities", "@martinwicke Do we still need this open?", "No, I think we should add the ability to assemble a `SavedModel` from a checkpoint to `saved_model_cli` instead."]}, {"number": 17458, "title": "Segmentation fault or no convergence when using XLA_CPU with distributed TensorFlow", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: I have modified tensorflow/examples/tutorials/mnist/mnist_softmax_xla.py to use MonitoredTrainingSession and PS/worker hosts.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version**: 1.6.0\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: 0.11.0\r\n- **GCC/Compiler version (if compiling from source)**: 5.4.0\r\n- **CUDA/cuDNN version**: n/a\r\n- **GPU model and memory**: n/a\r\n- **Exact command to reproduce**: run with a local PS and a local worker\r\n\r\n### Describe the problem\r\nI'm seeing segmentation fault or no convergence when using mnist_softmax_xla.py in a distributed environment (one PS and one worker, both local) and `train_step` placed on XLA_CPU.\r\n\r\n```\r\nwith tf.device('/device:XLA_CPU:0'):\r\n  train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\r\n```\r\n\r\nIs this the expected behavior? What is the recommended way of using XLA_CPU in distributed training? \r\n", "comments": ["Segmentation faults are rarely expected behavior :)\r\nCan you share code to reproduce the problem? Ideally, as small a code snippet as possible that reproduces it.\r\n\r\nMore information would also be helpful, such as:\r\n- Details of the segmentation fault (do you have a stack trace for example?)\r\n- Where is the segmentation fault occurring - on all workers? on the PS? etc.\r\n\r\n(CC @tatianashp )\r\n", "The behavior is inconsistent. What I observed:\r\n- segmentation fault on worker side (the number of steps where segmentation fault occurs is inconsistent), or\r\n- no segmentation fault, but accuracy < 0.1\r\n\r\nThe same script runs fine (i.e. no segmentation fault or convergence problem) if `with tf.device('/device:CPU:0')` is used. \r\n\r\n```\r\ndef main(_):\r\n  ps_hosts = FLAGS.ps_hosts.split(\",\")\r\n  worker_hosts = FLAGS.worker_hosts.split(\",\")\r\n\r\n  cluster = tf.train.ClusterSpec({\"ps\": ps_hosts, \"worker\": worker_hosts})\r\n\r\n  server = tf.train.Server(cluster,\r\n                           job_name=FLAGS.job_name,\r\n                           task_index=FLAGS.task_index)\r\n\r\n\r\n  if FLAGS.job_name == \"ps\":\r\n    server.join()\r\n  elif FLAGS.job_name == \"worker\":\r\n    global_step = tf.train.get_or_create_global_step()\r\n    \r\n    hooks=[tf.train.StopAtStepHook(num_steps=10)]\r\n\r\n    mnist = input_data.read_data_sets(FLAGS.data_dir)\r\n\r\n    with tf.device(tf.train.replica_device_setter(cluster=cluster)):\r\n      # Create the model\r\n      x = tf.placeholder(tf.float32, [None, 784])\r\n      w = tf.Variable(tf.zeros([784, 10]))\r\n      b = tf.Variable(tf.zeros([10]))\r\n      y = tf.matmul(x, w) + b\r\n\r\n      # Define loss and optimizer\r\n      y_ = tf.placeholder(tf.float32, [None, 10])\r\n\r\n      # The raw formulation of cross-entropy,\r\n      #\r\n      #   tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.nn.softmax(y)),\r\n      #                                 reduction_indices=[1]))\r\n      #\r\n      # can be numerically unstable.\r\n      #\r\n      # So here we use tf.nn.softmax_cross_entropy_with_logits on the raw\r\n      # outputs of 'y', and then average across the batch.\r\n      cross_entropy = tf.reduce_mean(\r\n        tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\r\n\r\n      with tf.device('/device:XLA_CPU:0'):\r\n        train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\r\n\r\n      correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\r\n      accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\r\n\r\n    config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)\r\n    jit_level = 0\r\n    if FLAGS.xla:\r\n      # Turns on XLA JIT compilation.\r\n      jit_level = tf.OptimizerOptions.ON_1\r\n\r\n    config.graph_options.optimizer_options.global_jit_level = jit_level\r\n\r\n    with tf.train.MonitoredTrainingSession(master=server.target,\r\n                                           is_chief=(FLAGS.task_index==0),\r\n                                           hooks=hooks,\r\n                                           config=config) as sess:\r\n\r\n      train_loops = FLAGS.train_loop_count\r\n      start = time.time()\r\n      for i in range(train_loops):\r\n        batch_xs, batch_ys = mnist.train.next_batch(100)\r\n        (_, loss) = sess.run(\r\n          [train_step, cross_entropy], feed_dict={\r\n              x: batch_xs,\r\n              y_: batch_ys\r\n          })\r\n        print(\"step = %d, loss = %f\" % (i, loss))\r\n      end = time.time()\r\n      elapsed = (end - start)\r\n      print(\"Time elapsed: \", elapsed, \" seconds\" )\r\n\r\n      # Test trained model\r\n      if i == train_loops-1:\r\n        print(\"Accuracy: \", sess.run(\r\n          accuracy, feed_dict={\r\n            x: mnist.test.images,\r\n            y_: mnist.test.labels\r\n          }))\r\n```", "'device:XLA_CPU:0' is used primarily for testing. Please take a look at https://www.tensorflow.org/performance/xla/jit for instructions on other ways to invoke XLA. \r\n\r\n", "Could you elaborate on _`device:XLA_CPU:0\u2019 is used primarily for testing?_ Using it in a non-distributed environment does not cause segmentation fault or non-convergence. Does it result in undefined behavior in distributed runtime? \r\n\r\nSetting config or scope to invoke XLA (as mentioned in https://www.tensorflow.org/performance/xla/jit) does not place ops on XLA_CPU device. The logs show all ops are either on `/job:worker/replica:0/task:0/device:CPU:0` or `/job:ps/replica:0/task:0/device:CPU:0`. \r\n\r\nAlso, using `worker_device=device:XLA_CPU` in tf.train.replica_device_setter causes segmentation fault or NaN values.\r\n\r\nWhat is the recommended way of using XLA_CPU in a distributed environment?", "@andydavis1 Could you comment on using XLA_CPU in a distributed environment?", "You should configure XLA using the pointers that tatianashp@ sent you (i.e. do not use XLA_CPU device). Configured with sesion config or jit_scope,, there is no XLA_CPU device, but XLA CPU backend will be enabled on the host (i.e. CPU:0 not XLA_CPU:0).  ", "How do I verify if XLA is invoked or see which ops are compiled via XLA? I only see `LaunchOpHasKernelForDevice kernel_class_name: XlaLocalLaunchOp` in the log.\r\n\r\nAlso, I was expecting to see send/recv ops between `/job:ps/replica:0/task:0/device:CPU:0` and `/job:worker/replica:0/task:0/device:XLA_CPU:0`, but that's not the case.", "There are timeline and graphviz instructions here: https://www.tensorflow.org/performance/xla/jit\r\nXLA CPU does not currently support send/recv instructions.", "> XLA CPU does not currently support send/recv instructions\r\n\r\nCould you elaborate on that? I see XLA send/recv in tensorflow/compiler/tf2xla/ops/sendrecv_ops.cc. Is cross-device XLA send/recv not supported? If so, when is it planned to be supported?\r\n", "Send/Recv instructions are not currently implemented on the XLA CPU backend. If you want to do distributed training and use XLA CPU, you can have TF do the send/recv between machines and pass these tensors to the TF sub-graph that you want to compile for XLA CPU. So you would just want to JIT compile the sub-set of the TF graph that runs on each machine, and use TF to do the send/recv between machines.", "Nagging Assignee @asimshankar: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@sfvaroglu Please reopen if you have further concerns. "]}, {"number": 17457, "title": "realtime bounding box ", "body": "i use tensorflow project for android\r\n\r\nI trained my custom datsets by yolo and then i made pb file.\r\n\r\nThis detected bounding box where i used picture not realtime\r\n\r\nBut when i put yolo file  in the android project, this cannot detect.\r\n\r\nSo i screenshot the scene of android project and i trained this screenshot in pc by darkflow.\r\n\r\nIt detected well. I don't know why. I think option value is correct. plz help me T.T\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "I'm not clear what you're asking. Is this question about tracking or YOLO?\r\n\r\nThe realtime tracking is provided by libtensorflow_demo.so. You can double-check that it's packaged in the APK with `unzip -v tensorflow_demo.apk`. If it's not there, you'll just see stationary boxes for detections. Bazel builds of the demo will include it, but if you use the \"none\" buildType in build.gradle then you won't get it.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "is it possible to include the libtensorflow_demo.so manually and avoid building with bazel ? i downloaded the file from [here](http://ci.tensorflow.org/view/Nightly/job/nightly-android/lastStableBuild/) created a jniLibs in my project but still the ObjectTracker can't find the library. Any solutions ?"]}]