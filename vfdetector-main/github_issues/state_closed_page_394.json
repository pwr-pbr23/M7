[{"number": 42141, "title": "TensorMap: Add Erase Gradient and Gradient Tests", "body": "Update gradients and gradient tests for the TensorMap feature to be more comprehensive.\r\n\r\nAdd gradient for the erase op.\r\nImplement ZerosLike and BinaryAdd kernels, which will be used in certain gradients.\r\nAdd gradient tests to cover more cases, including gradients for more function combinations, replace, erase, and non-scalar values.\r\n@mdanatg @saxenasaurabh @dynamicwebpaige", "comments": []}, {"number": 42140, "title": "blank_index in tf.nn.ctc_loss and tf.nn.ctc_beam_search_decoder has different default value", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.3.0\r\n- Python version: 3.7\r\n\r\n**Describe the current behavior**\r\n\r\nCurrently https://www.tensorflow.org/api_docs/python/tf/nn/ctc_loss and https://www.tensorflow.org/api_docs/python/tf/nn/ctc_beam_search_decoder has different default blank index.\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/nn/ctc_loss sets default blank index to be 0.\r\n\r\nWhreas https://www.tensorflow.org/api_docs/python/tf/nn/ctc_beam_search_decoder doesn't have an API for setting blank index, and it assumes to be `num_category - 1` (see https://github.com/tensorflow/tensorflow/blob/cd7da16dd6c17df428dc9ec105c0c8f11e5fd4f5/tensorflow/core/kernels/ctc_decoder_ops.cc#L331)\r\n\r\n**Describe the expected behavior**\r\n\r\nThis is very unexpected - I would assume they have the same default value since they both work with CTC. Or at least both should provide API to change the blank index. \r\n", "comments": ["@lriuui0x0 \r\nPlease provide with simple stand alone code or colab gist witht issue faced.", "@Saduf2019 There's no standalone code - it's a complain about the unintuitive and misleading API.", "This is a duplicate of https://github.com/tensorflow/tensorflow/issues/42993. An RFC is open here: https://github.com/tensorflow/community/pull/295", "@lriuui0x0,\r\nCan you please confirm if we can close this issue as as RFC has been created as mentioned in the [above comment](https://github.com/tensorflow/tensorflow/issues/42140#issuecomment-759074051)? Thanks! ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 42139, "title": "tf.keras.callbacks.TensorBoard does not save batch - level statistics when profiling is disabled completely", "body": "During profile setup, _should_trace is set to false.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/b36436b087bd8e8701ef51718179037cccdfc26e/tensorflow/python/keras/callbacks.py#L2137\r\n\r\nHowever, during the batch begin, this is also used:\r\nhttps://github.com/tensorflow/tensorflow/blob/b36436b087bd8e8701ef51718179037cccdfc26e/tensorflow/python/keras/callbacks.py#L2160\r\n\r\nThus, disabling profiling ALSO disables batch level outputs.", "comments": ["@Zahlii Can you please share a simple standalone code to reproduce the issue? Thanks!", "Hi @Zahlii, do you have a reproducible example you can share? This helps us to debug. Thanks!", "I wasn't able to reproduce the issue with the latest tensorflow version. I think this can be closed.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42139\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42139\">No</a>\n"]}, {"number": 42137, "title": "Fix a logic issue of layout optimizer", "body": "The previous PR https://github.com/tensorflow/tensorflow/pull/40961 added the conv3d support. However, we noticed that the logic of this `!conv2d or !conv3d` should be `!(conv2d or conv3d)` or `!conv2d and !conv3d`. \r\n\r\nfyi @nluehr @ezhulenev ", "comments": []}, {"number": 42136, "title": "Gcs Filesystem refactor part 1", "body": "@mihaimaruseac \r\nThis PR is a part of work to refactor gcs to mimic the `core` implementation", "comments": []}, {"number": 42135, "title": "[TF:MLIR] Improve parallelism of tf.AddN", "body": "", "comments": ["/cc @smit-hinsu for visibility."]}, {"number": 42134, "title": "[TFLite] Fix potential overflow in 64-bit MultiplyByQuantizedMultiplier function", "body": "Hi,\r\n\r\nThis PR fixes potential overflows than can happen in the 64-bit version of `MultiplyByQuantizedMultiplier`.\r\n\r\nOverflow example:\r\n```c++\r\nint32_t quantized_multiplier;\r\nint shift;\r\ndouble scale = 0.00097656;\r\nQuantizeMultiplier(scale, &quantized_multiplier, &shift);\r\n\r\nconst int64_t x = 10000;\r\nstd::cout << x*scale << std::endl;\r\nstd::cout << MultiplyByQuantizedMultiplier(x, quantized_multiplier, shift) << std::endl;\r\n```\r\nOutput:\r\n```\r\n9.7656\r\n-10 // Should be 10\r\n```\r\n\r\nThanks,\r\nThibaut", "comments": ["Hi @suharshs, could you take a look to the PR? Thanks.", "Apologies for the delay. If @suharshs can take a look, that would be great.\r\n\r\nI would usually ask for a test that currently fails but passes with the change but I don't see any existing tests for MultiplyByQuantizedMultipler so I'll defer to @suharshs on this as well.", "@jianlijianli, @daverim  Can you please take a look on this PR ? Thanks!", "Thank you, I hesitated as there was no existing tests for any of the `MultiplyByQuantizedMultiplier` versions. I will check to add some tests as these are quite central functions. ", "@talumbau I added some tests for the int32 and int64 versions of the `MultiplyByQuantizedMultiplier` function.\r\n\r\nI had to modify a bit the BUILD file to link `libm` as I had some `undefined reference to symbol 'round@@GLIBC_2.2.5` error when compiling the `quantization_util_test`.", "@talumbau  Can you please take a look on the above comment from @Tessil. Thanks!", "@talumbau I realized I used `int32` and `int64` instead of `int32_t` and `int64_t` in two places which created a compilation error in the MacOS CPU test. The PR will need re-approval, sorry.", "Hi,\r\n\r\nI am seeing test failures in `quantization_util_test`. Can you confirm you get errors like this:\r\n\r\n```\r\nbazel build --compilation_mode=opt //third_party/tensorflow/lite/kernels/internal:quantization_util_test\r\n```\r\n\r\n```\r\nthird_party/tensorflow/lite/kernels/internal/quantization_util_test.cc:434:32: error: implicit conversion from 'double' to 'int32_t' (aka 'int') changes value from 0.1 to 0 [-Werror,-Wliteral-conversion]\r\n  EXPECT_EQ(quant_and_multiply(0.1, 0), 0);\r\n            ~~~~~~~~~~~~~~~~~~ ^~~\r\n```\r\n\r\n\r\nThanks!", "Effectively a `double` was used instead of an `int` but surprisingly I didn't have any warning or error using `bazel test //tensorflow/lite/kernels/internal:quantization_util_test` and it slipped by. I fixed the test.", "thanks very much. Just approved again.", "Hi Thibaut,\r\n\r\nI looked at the Windows Bazel GPU CI build failure, as well as the Intel oneDNN build failure. They look spurious to me and not related to this change. Can you attempt to rebase and invoke the submit process again? I believe that change in 0cead48 should be good.", "I merged the latest changes, thanks.", "Looks like there are some builds with additional warnings\r\n\r\n```\r\nthird_party/tensorflow/lite/kernels/internal/quantization_util_test.cc:453:49: error: operator '<<' has lower precedence than '-'; '-' will be evaluated first [-Werror,-Wshift-op-parentheses]\r\n                  static_cast<double>(1ll << 31 - (-3)));\r\n                                          ~~ ~~~^~~~~~\r\nthird_party/tensorflow/lite/kernels/internal/quantization_util_test.cc:453:49: note: place parentheses around the '-' expression to silence this warning\r\n                  static_cast<double>(1ll << 31 - (-3)));\r\n                                                ^\r\n```\r\n\r\nCan you fix please?", "Thank you, I fixed the warning. \r\n\r\nIs there a reason to not enable these warnings and `-Werror` in the GitHub CI build? I have to see if we can modify a bit our internal CI to more closely match the warnings you use.", "That's a good idea. I have filed this issue internally. Thanks for your patience.", "Looks like the Github CI needs significant improvement. I see a failure with this command:\r\n\r\n```\r\nbazel --blazerc=/dev/null test --compilation_mode=opt --copt=-UNDEBUG tensorflow/lite/kernels/internal:quantization_util_test\r\n```\r\n\r\nit fails on the assert here:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/internal/common.h#L179\r\n\r\nCan you reproduce?", "Thank you, the 64-bit `MultiplyByQuantizedMultiplier` effectively doesn't support negative multipliers. From what I gather it's an intentional behaviour and some HW implementations rely on the fact that the multiplier is >= 0. The TOSA spec also has an `assert(multiplier >= 0);`  in `apply_scale_32`.\r\n\r\nI removed the tests with negative multipliers for the 64-bit version but left them for the 32-bit version as some kernels use negative multipliers (notably the SUB operator to reuse the ADD kernel)."]}, {"number": 42132, "title": "[Keras Applications] WideResNet(s)", "body": "WideResNet(s) <sup>[1]</sup> are residual network structures that are aimed at improving classification performance by decreasing the depth and increasing the width of residual networks. Many SOTA paper(s) make use of WRN implementations in some form or the other (eg. <sup>[2], [3], [4]</sup>). It'd be useful to have WRN implemented in `tf.keras.applications` itself.\r\n\r\nIn case, WideResNet-28-10 and similar architectures can be added to `tf.keras.applications` we can look into the following:\r\n1. Pre-trained weights for resized ImageNet  <sup>[5]</sup> (32 x 32) on WRN-28-10\r\n2. Pre-trained weights for resized ImageNet <sup>[5]</sup> (64 x 64) on WRN-36-5 (https://patrykchrabaszcz.github.io/Imagenet32/#validation-performance)\r\n3. Pre-trained weights for CIFAR-10 / SVHN? (although, keras_applications is tightly coupled with ImageNet related implementations)\r\n4. Bottleneck ResNet-50-2 architecture with larger image sizes (eg. 224x224 / 299x299)\r\n\r\n<sup>[1]</sup> [Wide Residual Networks](https://arxiv.org/abs/1605.07146)\r\n<sup>[2]</sup> [SGDR: Stochastic Gradient Descent with Warm Restarts](https://arxiv.org/abs/1608.03983)\r\n<sup>[3]</sup> [AutoAugment: Learning Augmentation Strategies From Data](https://arxiv.org/abs/1805.09501)\r\n<sup>[4]</sup> [RandAugment: Practical automated data augmentation with a reduced search space](https://arxiv.org/abs/1909.13719)\r\n<sup>[5]</sup> [A Downsampled Variant of ImageNet as an Alternative to the CIFAR datasets](https://arxiv.org/abs/1707.08819)\r\n\r\n/cc: @tanzhenyu, @fchollet", "comments": ["Gentle ping.\r\n/cc: @fchollet, any thoughts on this?", "We currently don't have the bandwidth to support this model. Closing it."]}, {"number": 42131, "title": "cannot able to train keras fashion_mnist model in tensorflow cpu", "body": "E:\\pythonProject\\image cliassifir>python imageclif.py\r\n2020-08-07 20:54:14.852315: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\r\n2020-08-07 20:54:14.857148: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n2020-08-07 20:54:17.258338: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found\r\n2020-08-07 20:54:17.273874: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\r\n2020-08-07 20:54:17.288006: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: DESKTOP-7LER57Q\r\n2020-08-07 20:54:17.293339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: DESKTOP-7LER57Q\r\n2020-08-07 20:54:17.296868: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-08-07 20:54:17.322399: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x20589d863f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-08-07 20:54:17.327558: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nEpoch 1/10\r\nTraceback (most recent call last):\r\n  File \"imageclif.py\", line 46, in <module>\r\n    model.fit(train_images,train_labels,epochs=10)\r\n  File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1098, in fit\r\n    tmp_logs = train_function(iterator)\r\n  File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 780, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 823, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializers)\r\n  File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 697, in _initialize\r\n    *args, **kwds))\r\n  File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2855, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3213, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3075, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 986, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 600, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 973, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nValueError: in user code:\r\n\r\n    C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\r\n        return step_function(self, iterator)\r\n    C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\r\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n    C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\r\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\r\n        return self._call_for_each_replica(fn, args, kwargs)\r\n    C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\r\n        return fn(*args, **kwargs)\r\n    C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\r\n        outputs = model.train_step(data)\r\n    C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:749 train_step\r\n        y, y_pred, sample_weight, regularization_losses=self.losses)\r\n    C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:187 __call__\r\n        self.build(y_pred)\r\n    C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:140 build\r\n        self._losses = nest.map_structure(self._get_loss_object, self._losses)\r\n    C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\nest.py:635 map_structure\r\n        structure[0], [func(*x) for x in entries],\r\n    C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\nest.py:635 <listcomp>\r\n        structure[0], [func(*x) for x in entries],\r\n    C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:263 _get_loss_object\r\n        loss = losses_mod.get(loss)\r\n    C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\losses.py:1895 get\r\n        return deserialize(identifier)\r\n    C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\losses.py:1854 deserialize\r\n        printable_module_name='loss function')\r\n    C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:378 deserialize_keras_object\r\n        'Unknown ' + printable_module_name + ': ' + object_name)\r\n\r\n    ValueError: Unknown loss function: spare_categorical_crossentropy", "comments": ["you wrote spare_categorical_crossentropy, it should be sparse_categorical_crossentropy. if you fix it it will work", "thanks man \ud83d\udc4d ", "@Akshay0701 \r\nPlease move this issue to closed status if resolved."]}, {"number": 42130, "title": "Add benchmark for custom training loop.", "body": "Provide a benchmark example that uses the custom training loop.", "comments": ["@gbaned These failed checks didn't cause by my code."]}, {"number": 42129, "title": "segfault in `tf.image.crop_and_resize` when `boxes` contains large value", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\n\r\n\r\n**Describe the current behavior**\r\n`tf.image.crop_and_resize` segfault when there is a very large value in `boxes`. Can also be reproduced in nightly version\r\n\r\n**Describe the expected behavior**\r\nExpect no segfault\r\n**Standalone code to reproduce the issue**\r\n\r\n\r\n~~~python\r\nimport tensorflow as tf\r\ntf.image.crop_and_resize(image=tf.zeros((2,1,1,1)), boxes=[[1.0e+40, 0,0,0]], box_indices=[1], crop_size=[1,1])\r\n~~~\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n~~~python\r\nSegmentation fault (core dumped)\r\n~~~", "comments": ["Added a PR #42143 for the fix.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42129\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42129\">No</a>\n", "Does this issue affect the 1.15.5 version?\r\nCorresponding CVE Vulnerability CVE-2020-15266", "Yes, but being low severity and given that patching 1.15 and 2.0 is extremely expensive we no longer patched it.\r\n\r\nRecommendation is to update past 2.1", "Hello, is there any chance that vulnerability fix will be applied in versions like 2.3.4?", "Hi. Not in 2.3.4, as the 2.3.x has reached end of life.\r\n\r\nIt is already included in 2.4.0 and later", "@mihaimaruseac noted on this, thank you for the feedback."]}, {"number": 42126, "title": "Tensorflow getting stuck when running forward pass for a tf hub module", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Catalina 10.15.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): pip install tensorflow\r\n- TensorFlow version (use command below): v2.3.0-rc2-23-gb36436b087 2.3.0\r\n- Python version: 3.6.4\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: using on CPU\r\n- GPU model and memory: using on CPU\r\n\r\n**Describe the current behavior**\r\nTensorflow get stuck, it hangs suddenly and intermittently\r\n\r\n**Describe the expected behavior**\r\nTensorflow not getting stuck\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow_hub as hub\r\nimport tensorflow_text\r\n\r\nmodule = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-qa/3\")\r\nfor i in range(50):\r\n    response_embeddings = module.signatures['response_encoder'](\r\n        input=tf.constant([\"I am happy\", \"I am not happy\"]),\r\n        context=tf.constant([\"I am happy\", \"I am not happy\"]))\r\n    t = response_embeddings[\"outputs\"].numpy()\r\n    print(t.shape)\r\n```\r\nIf you repeat that last loop of 50 iterations like 3 times or something it will just get stuck and hang.\r\n\r\n", "comments": ["@perone \r\n\r\nI have tried in colab with TF version 2.3 and i am not seeing any issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/e563938fdcc37b888f45e4eb16b7273b/untitled.ipynb).Thanks!", "If it is working on Colab, it looks that it might be something related to environment or resources, since it is a big model, it might be memory management, are there any debugging flags I can enable to get more verbose info on what is going on ? I understand it doesn't reproduce on Colab, but that is like \"works on my computer\". \r\n\r\nThis is the log I get on the first run of the loop:\r\n\r\n```\r\n2020-08-12 16:03:37.207634: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-08-12 16:03:37.262803: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f854448af90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-08-12 16:03:37.262836: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n```\r\n\r\nit allocates 922MB of memory, and then the process just get stuck (no CPU usage).", "@perone \r\n\r\nIssues related to TensorFlow Hub are handled in the Hub repo. Please submit a new issue using [this link](https://github.com/tensorflow/hub/issues/new) and fill in the template, so that we can track it there. Thanks!\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42126\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42126\">No</a>\n"]}, {"number": 42125, "title": "using tf.compat.v1.ragged.placeholder", "body": "Hello , \r\n\r\nI'm facing some issue with tf.compat.v1.ragged.placeholder. I would appreciate your help on how to fix this. I'm not sure if this is a bug or lack of documentation especially that the official website does not provide any examples on how to use such placeholders. \r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): '2.3.0'\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: RTX 2080 TI\r\n\r\n\r\n**Describe the current behavior**\r\nI'm trying to pass a simple ragged array to tf.compat.v1.ragged.placeholder but Tensorflow throws the below error :\r\n                               `AttributeError: 'list' object has no attribute 'nested_row_splits'` \r\na similar code works fine on ragged.constant\r\n\r\n**Describe the expected behavior**\r\nI have tried to run the same code using ragged.constantand it works fine. I believe that tf.compat.v1.ragged.placeholder should work exactly like ragged.constant in terms of user interface without any code modification from the user. of course the internal handling could be different but this is abstracted from the user.  IF this is not possible I would appreciate your help on how to use ragged.Placeholders \r\nbelow is a code using constants and is working fine : \r\n```\r\nrt = tf.ragged.constant([[[1, 2 ] ,  [4, 5]] , [[6, 7] ,  [8, 9] , [10, 11]]] , ragged_rank=1 )\r\nrt= tf.Print(rt.values , [rt.values] , \"This is a constat\")\r\nwith tf.Session() as sess : \r\n    re    = sess.run([rt  ])\r\n\r\n\r\noutput : \r\n    This is a constat[[1 2][4...]...] \r\n```\r\n\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\nimport tensorflow.compat.v1 as tf\r\ntf.compat.v1.disable_eager_execution()\r\ntf.disable_v2_behavior()\r\nvals = [[[1, 2 ] ,  [4, 5]] , [[6, 7] ,  [8, 9] , [10, 11]]]\r\n\r\nmyTensor = tf.compat.v1.ragged.placeholder(dtype=tf.int32 , ragged_rank=1)\r\nrt= tf.Print(myTensor.values , [myTensor.values] , \"This is a placeholder\")\r\nwith tf.Session() as sess : \r\n    re    = sess.run([rt  ],feed_dict={myTensor:vals})\r\n\r\n```\r\n\r\nthis throws the below exception : \r\n```\r\n<ipython-input-27-5c8fe49f6984> in <module>\r\n      6 rt= tf.Print(myTensor.values , [myTensor.values] , \"This is a placeholder\")\r\n      7 with tf.Session() as sess :\r\n----> 8     re    = sess.run([rt  ],feed_dict={myTensor:vals})\r\n\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\client\\session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    956     try:\r\n    957       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 958                          run_metadata_ptr)\r\n    959       if run_metadata:\r\n    960         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\client\\session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1116       feed_dict = nest.flatten_dict_items(feed_dict)\r\n   1117       for feed, feed_val in feed_dict.items():\r\n-> 1118         for subfeed, subfeed_val in _feed_fn(feed, feed_val):\r\n   1119           try:\r\n   1120             subfeed_t = self.graph.as_graph_element(\r\n\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\client\\session.py in _feed_fn(feed, feed_val)\r\n   1096       for tensor_type, _, feed_fn, _ in _REGISTERED_EXPANSIONS:\r\n   1097         if isinstance(feed, tensor_type):\r\n-> 1098           return feed_fn(feed, feed_val)\r\n   1099       raise TypeError('Feed argument %r has invalid type %r' %\r\n   1100                       (feed, type(feed)))\r\n\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\ops\\ragged\\ragged_tensor.py in _ragged_tensor_session_feed(feed_key, feed_val)\r\n   2366 def _ragged_tensor_session_feed(feed_key, feed_val):\r\n   2367   key_components = feed_key.nested_row_splits + (feed_key.flat_values,)\r\n-> 2368   val_components = feed_val.nested_row_splits + (feed_val.flat_values,)\r\n   2369   return zip(key_components, val_components)\r\n   2370 \r\n\r\nAttributeError: 'list' object has no attribute 'nested_row_splits'\r\n```", "comments": ["Was able to reproduce the issue with TF v2.3. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/c90e5ac43269dfd2b6e2eea8a9f36fa6/42125.ipynb). Thanks!", "I have an update . I have finally figured a way to make the tf.ragged.placeholder work. However I would like your help to confirm that this is the correct way to do it. the solution is inspired by a comment I found in tensorflow/python/client/session.py  source code as shown below https://github.com/tensorflow/tensorflow/blob/2f93ec916b844309b3544e278995fd57a1e049be/tensorflow/python/client/session.py#L114-L115\r\n\r\nSimilarly I have tried to feed tf.ragged.placeholder with RaggedTensorValues and it appears to be working fine.  my new code looks like this : \r\n\r\n```\r\nmyTensor = tf.ragged.placeholder(dtype=tf.int32 , ragged_rank=1)\r\n\r\nrt= tf.Print(myTensor.values , [myTensor.values] , \"This is a placeholder\")\r\nwith tf.Session() as sess : \r\n    vals =tf.ragged.RaggedTensorValue(np.array([[1, 2 ]  , [4, 5]  , [6, 7] ,  [8, 9] , [10, 11]]) , np.array([0, 2, 5]))\r\n    re    = sess.run([rt  ],feed_dict={myTensor:vals})\r\n\r\noutput : \r\nThis is a placeholder[[1 2][4...]...]\r\n```\r\n\r\nCan you please confirm that this is the right way to feed a tf.ragged.placeholder ? I'm afraid that this would add unnecessary nodes to the graph every time I try to feed the placeholder with new values.  ", "@gowthamkpr @amahendrakar did you get a chance to look at this ? \r\n\r\nThe update I provided works fine on Ragged placeholders with rank 1 , but does not work on ragged placeholders of rank 2 \r\n\r\nbelow is the code for rank 2 ragged tensors  and the error thrown : \r\n```\r\n\r\nimport tensorflow.compat.v1 as tf\r\ntf.compat.v1.disable_eager_execution()\r\ntf.disable_v2_behavior()\r\nimport numpy as np \r\n\r\nmyTensor = tf.ragged.placeholder(dtype=tf.float32 , ragged_rank=2)\r\n\r\nprint(myTensor)\r\nnew_f = tf.print( \"These are the values : \", myTensor.values)\r\n\r\nsess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True)))\r\nva1 = tf.ragged.RaggedTensorValue(np.array([1.0, 2.2  , 1.1 , 4.0, 5.0 , 1.1 , 6.0, 7.0 , 1.1 , 8.0, 9.0 , 1.1 ,8.0, 9.0 , 1.1 ]) , np.array([0,3,6,9,12,15]))\r\nvals =tf.ragged.RaggedTensorValue(va1 , np.array([0, 2, 4  ]))\r\ng     = sess.run([ new_f   ] , feed_dict={myTensor:vals} )\r\nprint(g)\r\n\r\n```\r\n\r\n\r\nError trace : \r\n```\r\n\r\ntf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"RaggedPlaceholder_54/flat_values:0\", dtype=float32), row_splits=Tensor(\"RaggedPlaceholder_54/RaggedFromRowSplits/control_dependency:0\", shape=(?,), dtype=int64)), row_splits=Tensor(\"RaggedPlaceholder_54/RaggedFromRowSplits_1/control_dependency:0\", shape=(?,), dtype=int64))\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast)\r\n    547     try:\r\n--> 548       str_values = [compat.as_bytes(x) for x in proto_values]\r\n    549     except TypeError:\r\n\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py in <listcomp>(.0)\r\n    547     try:\r\n--> 548       str_values = [compat.as_bytes(x) for x in proto_values]\r\n    549     except TypeError:\r\n\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\util\\compat.py in as_bytes(bytes_or_text, encoding)\r\n     86     raise TypeError('Expected binary or unicode string, got %r' %\r\n---> 87                     (bytes_or_text,))\r\n     88 \r\n\r\nTypeError: Expected binary or unicode string, got tf.RaggedTensor(values=Tensor(\"RaggedPlaceholder_54/flat_values:0\", dtype=float32), row_splits=Tensor(\"RaggedPlaceholder_54/RaggedFromRowSplits/control_dependency:0\", shape=(?,), dtype=int64))\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py in _apply_op_helper(op_type_name, name, **keywords)\r\n    413               preferred_dtype=default_dtype,\r\n--> 414               as_ref=input_arg.is_ref)\r\n    415           if input_arg.number_attr and len(\r\n\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py in internal_convert_n_to_tensor(values, dtype, name, as_ref, preferred_dtype, ctx)\r\n   1566             preferred_dtype=preferred_dtype,\r\n-> 1567             ctx=ctx))\r\n   1568   return ret\r\n\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\r\n   1498     if ret is None:\r\n-> 1499       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n   1500 \r\n\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)\r\n    337   _ = as_ref\r\n--> 338   return constant(v, dtype=dtype, name=name)\r\n    339 \r\n\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py in constant(value, dtype, shape, name)\r\n    263   return _constant_impl(value, dtype, shape, name, verify_shape=False,\r\n--> 264                         allow_broadcast=True)\r\n    265 \r\n\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)\r\n    281           value, dtype=dtype, shape=shape, verify_shape=verify_shape,\r\n--> 282           allow_broadcast=allow_broadcast))\r\n    283   dtype_value = attr_value_pb2.AttrValue(type=tensor_value.tensor.dtype)\r\n\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast)\r\n    551                       \"Contents: %s. Consider casting elements to a \"\r\n--> 552                       \"supported type.\" % (type(values), values))\r\n    553     tensor_proto.string_val.extend(str_values)\r\n\r\nTypeError: Failed to convert object of type <class 'tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor'> to Tensor. Contents: tf.RaggedTensor(values=Tensor(\"RaggedPlaceholder_54/flat_values:0\", dtype=float32), row_splits=Tensor(\"RaggedPlaceholder_54/RaggedFromRowSplits/control_dependency:0\", shape=(?,), dtype=int64)). Consider casting elements to a supported type.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py in wrapper(*args, **kwargs)\r\n    200     try:\r\n--> 201       return target(*args, **kwargs)\r\n    202     except (TypeError, ValueError):\r\n\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\ops\\string_ops.py in string_format(template, inputs, placeholder, summarize, name)\r\n    174                                       summarize=summarize,\r\n--> 175                                       name=name)\r\n    176 \r\n\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\ops\\gen_string_ops.py in string_format(inputs, template, placeholder, summarize, name)\r\n    780                         placeholder=placeholder, summarize=summarize,\r\n--> 781                         name=name)\r\n    782   _result = _outputs[:]\r\n\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py in _apply_op_helper(op_type_name, name, **keywords)\r\n    444             raise TypeError(\r\n--> 445                 \"%s that are invalid. Tensors: %s\" % (prefix, values))\r\n    446 \r\n\r\nTypeError: Tensors in list passed to 'inputs' of 'StringFormat' Op have types [<NOT CONVERTIBLE TO TENSOR>] that are invalid. Tensors: [tf.RaggedTensor(values=Tensor(\"RaggedPlaceholder_54/flat_values:0\", dtype=float32), row_splits=Tensor(\"RaggedPlaceholder_54/RaggedFromRowSplits/control_dependency:0\", shape=(?,), dtype=int64))]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-76-624322bbdb97> in <module>\r\n      7 \r\n      8 print(myTensor)\r\n----> 9 new_f = tf.print( \"These are the values : \", myTensor.values)\r\n     10 \r\n     11 sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True)))\r\n\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py in wrapper(*args, **kwargs)\r\n    199     \"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\r\n    200     try:\r\n--> 201       return target(*args, **kwargs)\r\n    202     except (TypeError, ValueError):\r\n    203       # Note: convert_to_eager_tensor currently raises a ValueError, not a\r\n\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\ops\\logging_ops.py in print_v2(*inputs, **kwargs)\r\n    374         placeholder=placeholder,\r\n    375         summarize=summarize,\r\n--> 376         name=format_name)\r\n    377 \r\n    378   return gen_logging_ops.print_v2(\r\n\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py in wrapper(*args, **kwargs)\r\n    203       # Note: convert_to_eager_tensor currently raises a ValueError, not a\r\n    204       # TypeError, when given unexpected types.  So we need to catch both.\r\n--> 205       result = dispatch(wrapper, args, kwargs)\r\n    206       if result is not OpDispatcher.NOT_SUPPORTED:\r\n    207         return result\r\n\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py in dispatch(op, args, kwargs)\r\n    116   \"\"\"\r\n    117   for dispatcher in getattr(op, DISPATCH_ATTR):\r\n--> 118     result = dispatcher.handle(args, kwargs)\r\n    119     if result is not OpDispatcher.NOT_SUPPORTED:\r\n    120       return result\r\n\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\ops\\ragged\\ragged_dispatch.py in handle(self, args, kwargs)\r\n    257   def handle(self, args, kwargs):\r\n    258     if self.is_supported(args, kwargs):\r\n--> 259       return self._ragged_op(*args, **kwargs)\r\n    260     else:\r\n    261       return self.NOT_SUPPORTED\r\n\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\ops\\ragged\\ragged_string_ops.py in string_format(template, inputs, placeholder, summarize, name)\r\n    838     for i, input in enumerate(inputs):\r\n    839       if ragged_tensor.is_ragged(input):\r\n--> 840         output_pieces.append(ragged_tensor_to_string(input, summarize))\r\n    841       else:\r\n    842         output_pieces.append(string_ops.string_format(\r\n\r\nC:\\ProgramData\\Anaconda3\\envs\\AutoEncoder\\lib\\site-packages\\tensorflow\\python\\ops\\ragged\\ragged_string_ops.py in ragged_tensor_to_string(rt, summarize)\r\n    882     rt = ragged_tensor.convert_to_tensor_or_ragged_tensor(rt)\r\n    883     if rt.shape.rank is None:\r\n--> 884       raise ValueError(\"RaggedTensor to_string requires that rt.shape.rank \"\r\n    885                        \"is not None.\")\r\n    886     # Convert all elements of `rt` to strings.\r\n\r\nValueError: RaggedTensor to_string requires that rt.shape.rank is not None.\r\n\r\n```", "1. Yes, the appropriate value to feed for ragged tensor placeholders is a `tf.compat.v1.ragged.RaggedTensorValue` object.  Or if you prefer, you can feed each of the tensors that comprises the ragged tensor.  E.g., something like: `feed_dict={myTensor.row_splits: my_outer_row_splits, myTensor.values.row_splits: my_inner_row_splits, myTensor.values.values: my_flat_values}`.  (Both of these options will construct and run identical graphs.)\r\n\r\n2. Printing a ragged tensor with `tf.print` currently requires that the ragged tensor have a statically known rank.  The rank of a ragged tensor depends on the `ragged_rank` (~= the number of ragged dimensions), as well as the rank of the individual values.  You can fix your example by specifying `value_shape` when constructing the ragged placeholder.  I.e., change your code to:\r\n\r\n```python\r\nmyTensor = tf.ragged.placeholder(dtype=tf.float32, ragged_rank=2, value_shape=[])\r\n```\r\n\r\nThe `values_shape` arg specifies the shape of a single element in the innermost `values` tensor.  In your case, the innermost `values` tensor is a vector, so the shape of a single element is `[]`.  If you had e.g. a ragged tensor of embeddings, with an embedding dimension size of 32, then your innermost values tensor would have shape `[num_values, 32]`, and you'd need to set `value_shape=[32]` when building the placeholder.\r\n\r\nClosing this issue, but please feel free to re-open it if I haven't addressed all your questions."]}, {"number": 42124, "title": "Added thickness parameter for drawing bounding boxes", "body": "Added a `thickness` parameter for the `DrawBoundingBoxesV2` op after the `color` parameter.\r\n\r\nPreviously, there were two kernel ops, `DrawBoundingBoxes` and `DrawBoundingBoxesV2`, but both of them referenced the [same function](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/draw_bounding_box_op.cc#L58). Still haven't completely understood this design choice, but it would be nice if that could be simplified.\r\n\r\nAlso not sure where to add tests for the same, if any. Would appreciate assistance on the testing front, if it is required.", "comments": ["We can't add new inputs to existing operations, since they get serialized in SavedModels having only the original number of inputs.\r\n\r\nThat's why we have V2 of the op, and it's why we'd need V3 to add this new input.\r\n\r\nHow were you planning to expose this to users?\r\n\r\nAdding @tanzhenyu who has worked on image ops before.", ">We can't add new inputs to existing operations, since they get serialized in SavedModels having only the original number of inputs. That's why we have V2 of the op, and it's why we'd need V3 to add this new input.\r\n\r\nAh okay, did not know that. If that is going to be the case, I was actually thinking of adding a dash-interval functionality too(for making a dashed-line), should probably add that before finalizing a V3\r\n\r\n>How were you planning to expose this to users?\r\n\r\nI thought this might make a good addition to the existing [`draw_bounding_boxes`](https://www.tensorflow.org/api_docs/python/tf/image/draw_bounding_boxes) functionality. However, I'm not sure where the [`gen_image_ops`](https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/image_ops_impl.py#L4945) gets generated from/find the file. Do you have any recommendations/thoughts?", "> > We can't add new inputs to existing operations, since they get serialized in SavedModels having only the original number of inputs. That's why we have V2 of the op, and it's why we'd need V3 to add this new input.\r\n> \r\n> Ah okay, did not know that. If that is going to be the case, I was actually thinking of adding a dash-interval functionality too(for making a dashed-line), should probably add that before finalizing a V3\r\n> \r\n> > How were you planning to expose this to users?\r\n> \r\n> I thought this might make a good addition to the existing [`draw_bounding_boxes`](https://www.tensorflow.org/api_docs/python/tf/image/draw_bounding_boxes) functionality. However, I'm not sure where the [`gen_image_ops`](https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/image_ops_impl.py#L4945) gets generated from/find the file. Do you have any recommendations/thoughts?\r\n\r\nIf you add a V3 version of the op, it'll have its own binding generated automatically. You could just switch the Python to calling _v3.\r\n\r\nI would suggest adding to the Python API and adding some tests if the op is changing. But I have very little background on image ops, so I'm not a great person to decide on whether it's a good idea to add these / if there are existing alternatives / if this could be expressed as a composition of smaller ops. Maybe Zhenyu can chime in there, and eventually it'll need an [API review](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/api/tests/README.txt) anyway.", "@rsnk96  Can you please check @allenlavoie's comments and keep us posted ? Thanks!", "Which paper is this to support?", "> You could just switch the Python to calling _v3\r\n\r\nI'm trying to find where the Python --> C kernel binding is being defined, but am unable to find it. Could someone please assist with this?\r\n\r\n\r\n> Which paper is this to support?\r\n\r\nThis isn't to support a paper, this is just a functionality to make the draw box function more usable. In cases where the image is too big, a 1-pixel-width line is not too visible. So what I'm hoping thru this PR is to add a thickness parameter (and soon also a [dashed-configuration](https://stackoverflow.com/questions/26690932/opencv-rectangle-with-dotted-or-dashed-lines) for the rectangle). Any comments/recommendations?", "> > You could just switch the Python to calling _v3\r\n> \r\n> I'm trying to find where the Python --> C kernel binding is being defined, but am unable to find it. Could someone please assist with this?\r\n\r\nThese rules: https://github.com/tensorflow/tensorflow/blob/131a9225ed292e762e668cca72bb1ebe3625904c/tensorflow/python/BUILD#L2844\r\n\r\nYou can follow it to the .bzl file it's defined in, and you'll find some C++ that generates some Python for the gen_*.py file. That communicates with the runtime via string op names at the moment. Not sure how useful that is for adding a new op; I'd just do what the other ops are doing.", "@rsnk96  Can you please check @allenlavoie's comments and resolve conflicts?. Thanks!", "@allenlavoie can you review the changes now? I've shifted it to happen via a V3 of the function\r\n\r\n\r\nAdditionally, I've shifted the `@tf_export` and `@dispatch.add_dispatch_support` decorators from the V2 function to the V3 function, I hope that changes the Python binding to the C++ V3 op automatically. (Ref: decorators removed from [V2 function](https://github.com/tensorflow/tensorflow/pull/42124/files#diff-70c103f055e332fe570ec9cfd87120a4L5417))", "@rsnk96  Can you please check @allenlavoie's comments and keep us posted ? Thanks!", "> For a new op there is a three-week forward compatibility window to allow serving binaries to be updated, see https://www.tensorflow.org/api_docs/python/tf/compat/forward_compatible\r\n\r\nIncluded the forward compatibility check now @allenlavoie ", "Looks like there's also a relevant compile failure (you may have to specify int32/int64 in the REGISTER_OP call):\r\n\r\n> 2020-09-01 20:09:12.927904: F tensorflow/core/framework/op.cc:214] Non-OK-status: RegisterAlreadyLocked(deferred_[i]) status: Invalid argument: Reference to unknown attr 'int' from Input(\"thickness: int\") for Op DrawBoundingBoxesV3", "> Looks like there's also a relevant compile failure (you may have to specify int32/int64 in the REGISTER_OP call):\r\n> \r\n> > 2020-09-01 20:09:12.927904: F tensorflow/core/framework/op.cc:214] Non-OK-status: RegisterAlreadyLocked(deferred_[i]) status: Invalid argument: Reference to unknown attr 'int' from Input(\"thickness: int\") for Op DrawBoundingBoxesV3\r\n\r\n@rsnk96 Can you please check @allenlavoie's comments and keep us posted ? Thanks!\r\n\r\n", "@rsnk96  Any update on this PR? Please. Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "@rsnk96 Any update on this PR? Please. Thanks!", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 42123, "title": "No documentation on how to profile the memory usage for TF", "body": "Hello,\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/guide/profiler#memory_profile_tool\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nTF profiler only outputs the CPU information with the default configuration, but I was not able to find neither in the documentation nor on the StackOverflow etc. how to set it up for monitoring the memory usage.\r\n\r\nI get only this message on the \"memory_profile\" tools page:\r\n\"There is no memory profile to display because there were no memory activity data in the captured duration. \"\r\n\r\nTF and tensorboard versions are both 2.3.0.\r\nProfiling is run on the machine without GPU, under the non-root user, in Jupyter Notebook.\r\n\r\n### Usage example\r\n\r\nNo code example for the memory profiling is provided, hence it is not clear whether some setting should be provided to the profiler.", "comments": ["Experiencing same issue on CPU. With GPU it does show the \"summary information\" correctly, but the memory breakdown table doesn't contain meaningful entries.\r\n<img width=\"1161\" alt=\"Screenshot 2020-08-07 at 14 55 25\" src=\"https://user-images.githubusercontent.com/2892585/89647615-1f601d80-d8be-11ea-83a6-1f305c29fa48.png\">\r\n", "@anirudh161 you've been working on docs for these, any ideas?", "This tool reports memory consumption on the device (i.e. GPU or TPU); not on the host (CPU).\r\n\r\nFor the GPU issue (no breakdown to TF Ops), this is a bug that we found and fixed after TF 2.3 release. You will need to get the latest TF (https://pypi.org/project/tf-nightly/). You don't need a newer profiler plugin (i.e. the TF 2.3 release is okay).", "> This tool reports memory consumption on the device (i.e. GPU or TPU); not on the host (CPU).\r\n> \r\n> For the GPU issue (no breakdown to TF Ops), this is a bug that we found and fixed after TF 2.3 release. You will need to get the latest TF (https://pypi.org/project/tf-nightly/). You don't need a newer profiler plugin (i.e. the TF 2.3 release is okay).\r\n\r\nThanks a lot for clarifying this!"]}, {"number": 42122, "title": "tflite runtime package compatibility for Raspeberry Pi", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Raspbian GNU/Linux 10(buster)\r\n- TensorFlow installed from (source or binary):\r\n- Tensorflow version (commit SHA if source):\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): Raspberry Pi Model B Rev 2\r\n\r\n**Describe the problem**\r\nI have an old Raspberry Pi, probably one of the first model they released. It as an ARMv6-compatible processor rev 7, BCM2835. It is RPi Model B Rev 2\r\n\r\nI get the error : **tflite_runtime-2.1.0.post1-cp37-cp37m-linux_armv7l.whl is not a supported wheel on this platform**\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n\r\n1. Installed latest version of python, pip-20.2.1 wheel-0.34.2, Python3.7\r\n2. Installed OpenCV\r\n`sudo apt-get -y install libjpeg-dev libtiff5-dev libjasper-dev libpng12-dev\r\nsudo apt-get -y install libavcodec-dev libavformat-dev libswscale-dev libv4l-dev\r\nsudo apt-get -y install libxvidcore-dev libx264-dev\r\nsudo apt-get -y install qt4-dev-tools libatlas-base-dev\r\npip3 install opencv-python==3.4.6.27`\r\n\r\n3. Tried installing https://dl.google.com/coral/python/tflite_runtime-2.1.0.post1-cp37-cp37m-linux_armv7l.whl and https://dl.google.com/coral/python/tflite_runtime-2.1.0.post1-cp37-cp37m-linux_aarch64.whl (as given in https://www.tensorflow.org/lite/guide/python) gives the same error **_*.whl is not a supported wheel on this platform_**\r\n![image](https://user-images.githubusercontent.com/64406245/89629896-d8166480-d89e-11ea-9735-53e8fa80ccf6.png)\r\n\r\nPlease let me know if TF Lite runtime package is supported on this platform.\r\n", "comments": ["Perhaps you can try [Building TensorFlow Lite Standalone Pip](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/pip_package#building-tensorflow-lite-standalone-pip).", "Trying the first method in the link, build in progress - `tensorflow/lite/tools/pip_package/build_pip_package.sh`. It is taking more time than I thought, probably since the RPi processor is slow.\r\n\r\nIn the process of getting this script to build, realized, I was missing another wheel related tool, had to do `pip3 install wheel`. May be it will help the initial pip3 install of the .whl file I was trying. Not sure, need to check.\r\n \r\nHope to update soon on the Standalone Pip", "Build is stuck (Raspberrypi hangs), with the first method, tried it a couple of times. It is as shown in the image below from past 4 hours. \r\n![image](https://user-images.githubusercontent.com/64406245/90140355-eb7f6f00-dd79-11ea-8e23-68ae2dfdfcd4.png)\r\n\r\nDo you suggest any other method?\r\n", "Hi, I have the same problematic\r\n\r\nDid you manage to solve? \r\n\r\nThe fact the RPi get stuck in building is likely because it runs out of RAM, once it starts swapping is already unrecoverable \r\n\r\n\r\nThanks", "You'd better cross build TFLite PIP since it requires more RAM than you have.\r\nRegarding RPI Zero (or armv6 support), we don't have PIP supports yet.\r\nBut you can build the static library https://www.tensorflow.org/lite/guide/build_rpi#step_4b_to_build_armv6_binary_for_raspberry_pi_zero", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 42121, "title": "keras.models.load_model fails after tf.reset_default_graph OR tf.keras.backend.clear_session", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v1.15.0-rc3-22-g590d6eef7e 1.15.0\r\n- Python version: Python 3.6.2 |Anaconda custom (64-bit)| (default, Sep 19 2017, 08:03:39) [MSC v.1900 64 bit (AMD64)] on win32\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.1.243/6.14.11.10010\r\n- GPU model and memory: GeForce GTX 960M 3040 MB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nThe second load_model fails with error \"Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Placeholder:0\", shape=(40, 80), dtype=float32) is not an element of this graph.\"\r\n\r\n**Describe the expected behavior**\r\nI expect the model to be loaded, exactly like in the first call \r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n    import tensorflow as tf\r\n    from keras.models import load_model\r\n\r\n    model = load_model(\"model.h5\")\r\n    model.summary()\r\n\r\n    # tf.reset_default_graph() OR\r\n    tf.keras.backend.clear_session()\r\n\r\n    model = load_model(\"model.h5\")\r\n    model.summary()\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@mkravchik,\r\nPlease take a look at [this](https://stackoverflow.com/a/47162390) StackOverflow comment from a similar issue and let us know if it helps. Thanks!", "Well, not exactly.\r\nDebugging revealed that the problem is that Keras uses the default session if it exists, and if some initialization was done on this session resetting the graph causes the Keras's confusion  because it is expecting that the session state will not change and the session's graph will not be reset. I haven't seen neither of this in the documentation and it caused me to spend a few hours on this issue. \r\nSo if I want to load the model and then use it multiple times with calls to reset_default_graph in between, I need to keep the session with the graph around like this:\r\n```\r\ndef load():\r\n    with tf.Graph().as_default() as g:\r\n        config = tf.ConfigProto(log_device_placement=False)\r\n        config.gpu_options.allow_growth = True\r\n        sess = tf.Session(graph=g, config=config)\r\n        with sess.as_default():\r\n            model = load_model(\"model.h5\")\r\n            model.summary()\r\n            X = np.random.normal(0, 1, (20,2))\r\n            pred = model.predict(X[np.newaxis])\r\n            print(pred)\r\n\r\n            return model, sess\r\n\r\nmodel, sess = load()\r\n\r\nwith sess.as_default():\r\n    X = np.random.normal(0, 1, (20, 2))\r\n    pred = model.predict(X[np.newaxis])\r\n    print(pred)\r\n```\r\n\r\nI still think this is not how I expect Keras's load_model to behave", "@mkravchik,\r\nI was able to run the given code snippet with a sample `.h5` file, without any issues. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/75e3f3c27c6f90b91a18b84ec8fd7b1e/42121.ipynb). Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 42118, "title": "keras meet a problem with sync bn in multi worker", "body": "```strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(communication=getattr(tf.distribute.experimental.CollectiveCommunication,'NCCL'))  #RING WORK\r\nwith strategy.scope():\r\n    \r\n    inputs = keras.Input(shape=(256,256,3), name='digits')\r\n    output1=applications.ResNet50()(inputs)\r\n    # ,normalizer=\"l2\",normalize_args={'axis':1})\r\n    outputs = layers.Dense(1, activation='relu', name='dense_1')(output1)\r\n    model = keras.Model(inputs=inputs, outputs=outputs)\r\n    # inputs = keras.Input(shape=(784,), name='digits')\r\n    # num_units = 4096\r\n    # dense1 = layers.Dense(num_units, activation='relu', name='dense_1')\r\n    # x = dense1(inputs)\r\n    # x=tf.keras.layers.experimental.SyncBatchNormalization()(x)\r\n    # dense2 = layers.Dense(num_units, activation='relu', name='dense_2')\r\n    # x = dense2(x)\r\n    # outputs = layers.Dense(10, activation='softmax', name='predictions')(x)\r\n    # model = keras.Model(inputs=inputs, outputs=outputs)\r\n    model.compile(loss='sparse_categorical_crossentropy',\r\n                optimizer=keras.optimizers.RMSprop(),\r\n                metrics=['accuracy'])\r\n(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\r\nx_train=np.zeros((2048,64,64,3),dtype=np.float32)\r\nx_test = x_train[:2048]\r\ny_train=y_train[:2048]\r\ny_test=y_test[:2048]\r\nhistory = model.fit(x_train, y_train,\r\n                    batch_size=1024,\r\n                    epochs=5,\r\n                    validation_split=0.2)\r\ntest_scores = model.evaluate(x_test, y_test, verbose=1)\r\nprint('Test loss:', test_scores[0])\r\nprint('Test accuracy:', test_scores[1])\r\n```\r\n\r\nthe training code\r\n\r\nhere is the custom resnet:\r\n\r\n```# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\r\n#\r\n# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n#\r\n#     http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n# ==============================================================================\r\n# pylint: disable=invalid-name\r\n\"\"\"ResNet models for Keras.\r\n\r\nReference:\r\n  - [Deep Residual Learning for Image Recognition](\r\n      https://arxiv.org/abs/1512.03385) (CVPR 2015)\r\n\"\"\"\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nfrom tensorflow.python.keras import backend\r\nfrom tensorflow.python.keras.applications import imagenet_utils\r\nfrom tensorflow.python.keras.engine import training\r\nfrom tensorflow.python.keras.layers import VersionAwareLayers\r\nfrom tensorflow.python.keras.utils import data_utils\r\nfrom tensorflow.python.keras.utils import layer_utils\r\nfrom tensorflow.python.lib.io import file_io\r\nfrom tensorflow.python.util.tf_export import keras_export\r\nfrom tensorflow.keras.layers.experimental import SyncBatchNormalization as BatchNormalization\r\n\r\nBASE_WEIGHTS_PATH = (\r\n    'https://storage.googleapis.com/tensorflow/keras-applications/resnet/')\r\nWEIGHTS_HASHES = {\r\n    'resnet50': ('2cb95161c43110f7111970584f804107',\r\n                 '4d473c1dd8becc155b73f8504c6f6626'),\r\n    'resnet101': ('f1aeb4b969a6efcfb50fad2f0c20cfc5',\r\n                  '88cf7a10940856eca736dc7b7e228a21'),\r\n    'resnet152': ('100835be76be38e30d865e96f2aaae62',\r\n                  'ee4c566cf9a93f14d82f913c2dc6dd0c'),\r\n    'resnet50v2': ('3ef43a0b657b3be2300d5770ece849e0',\r\n                   'fac2f116257151a9d068a22e544a4917'),\r\n    'resnet101v2': ('6343647c601c52e1368623803854d971',\r\n                    'c0ed64b8031c3730f411d2eb4eea35b5'),\r\n    'resnet152v2': ('a49b44d1979771252814e80f8ec446f9',\r\n                    'ed17cf2e0169df9d443503ef94b23b33'),\r\n    'resnext50': ('67a5b30d522ed92f75a1f16eef299d1a',\r\n                  '62527c363bdd9ec598bed41947b379fc'),\r\n    'resnext101':\r\n        ('34fb605428fcc7aa4d62f44404c11509', '0f678c91647380debd923963594981b3')\r\n}\r\n\r\nlayers = None\r\n\r\n\r\ndef ResNet(stack_fn,\r\n           preact,\r\n           use_bias,\r\n           model_name='resnet',\r\n           include_top=True,\r\n           weights='imagenet',\r\n           input_tensor=None,\r\n           input_shape=None,\r\n           pooling=None,\r\n           classes=1000,\r\n           classifier_activation='softmax',\r\n           **kwargs):\r\n  \"\"\"Instantiates the ResNet, ResNetV2, and ResNeXt architecture.\r\n\r\n  Reference:\r\n  - [Deep Residual Learning for Image Recognition](\r\n      https://arxiv.org/abs/1512.03385) (CVPR 2015)\r\n\r\n  Optionally loads weights pre-trained on ImageNet.\r\n  Note that the data format convention used by the model is\r\n  the one specified in your Keras config at `~/.keras/keras.json`.\r\n\r\n  Caution: Be sure to properly pre-process your inputs to the application.\r\n  Please see `applications.resnet.preprocess_input` for an example.\r\n\r\n  Arguments:\r\n    stack_fn: a function that returns output tensor for the\r\n      stacked residual blocks.\r\n    preact: whether to use pre-activation or not\r\n      (True for ResNetV2, False for ResNet and ResNeXt).\r\n    use_bias: whether to use biases for convolutional layers or not\r\n      (True for ResNet and ResNetV2, False for ResNeXt).\r\n    model_name: string, model name.\r\n    include_top: whether to include the fully-connected\r\n      layer at the top of the network.\r\n    weights: one of `None` (random initialization),\r\n      'imagenet' (pre-training on ImageNet),\r\n      or the path to the weights file to be loaded.\r\n    input_tensor: optional Keras tensor\r\n      (i.e. output of `layers.Input()`)\r\n      to use as image input for the model.\r\n    input_shape: optional shape tuple, only to be specified\r\n      if `include_top` is False (otherwise the input shape\r\n      has to be `(224, 224, 3)` (with `channels_last` data format)\r\n      or `(3, 224, 224)` (with `channels_first` data format).\r\n      It should have exactly 3 inputs channels.\r\n    pooling: optional pooling mode for feature extraction\r\n      when `include_top` is `False`.\r\n      - `None` means that the output of the model will be\r\n          the 4D tensor output of the\r\n          last convolutional layer.\r\n      - `avg` means that global average pooling\r\n          will be applied to the output of the\r\n          last convolutional layer, and thus\r\n          the output of the model will be a 2D tensor.\r\n      - `max` means that global max pooling will\r\n          be applied.\r\n    classes: optional number of classes to classify images\r\n      into, only to be specified if `include_top` is True, and\r\n      if no `weights` argument is specified.\r\n    classifier_activation: A `str` or callable. The activation function to use\r\n      on the \"top\" layer. Ignored unless `include_top=True`. Set\r\n      `classifier_activation=None` to return the logits of the \"top\" layer.\r\n    **kwargs: For backwards compatibility only.\r\n  Returns:\r\n    A `keras.Model` instance.\r\n\r\n  Raises:\r\n    ValueError: in case of invalid argument for `weights`,\r\n      or invalid input shape.\r\n    ValueError: if `classifier_activation` is not `softmax` or `None` when\r\n      using a pretrained top layer.\r\n  \"\"\"\r\n  global layers\r\n  if 'layers' in kwargs:\r\n    layers = kwargs.pop('layers')\r\n  else:\r\n    layers = VersionAwareLayers()\r\n  if kwargs:\r\n    raise ValueError('Unknown argument(s): %s' % (kwargs,))\r\n  if not (weights in {'imagenet', None} or file_io.file_exists(weights)):\r\n    raise ValueError('The `weights` argument should be either '\r\n                     '`None` (random initialization), `imagenet` '\r\n                     '(pre-training on ImageNet), '\r\n                     'or the path to the weights file to be loaded.')\r\n\r\n  if weights == 'imagenet' and include_top and classes != 1000:\r\n    raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\r\n                     ' as true, `classes` should be 1000')\r\n\r\n  # Determine proper input shape\r\n  input_shape = imagenet_utils.obtain_input_shape(\r\n      input_shape,\r\n      default_size=224,\r\n      min_size=32,\r\n      data_format=backend.image_data_format(),\r\n      require_flatten=include_top,\r\n      weights=weights)\r\n\r\n  if input_tensor is None:\r\n    img_input = layers.Input(shape=input_shape)\r\n  else:\r\n    if not backend.is_keras_tensor(input_tensor):\r\n      img_input = layers.Input(tensor=input_tensor, shape=input_shape)\r\n    else:\r\n      img_input = input_tensor\r\n\r\n  bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1\r\n\r\n  x = layers.ZeroPadding2D(\r\n      padding=((3, 3), (3, 3)), name='conv1_pad')(img_input)\r\n  x = layers.Conv2D(64, 7, strides=2, use_bias=use_bias, name='conv1_conv')(x)\r\n\r\n  if not preact:\r\n    x = BatchNormalization(\r\n        axis=bn_axis, epsilon=1.001e-5, name='conv1_bn')(x)\r\n    x = layers.Activation('relu', name='conv1_relu')(x)\r\n\r\n  x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name='pool1_pad')(x)\r\n  x = layers.MaxPooling2D(3, strides=2, name='pool1_pool')(x)\r\n\r\n  x = stack_fn(x)\r\n\r\n  if preact:\r\n    x = BatchNormalization(\r\n        axis=bn_axis, epsilon=1.001e-5, name='post_bn')(x)\r\n    x = layers.Activation('relu', name='post_relu')(x)\r\n\r\n  if include_top:\r\n    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\r\n    imagenet_utils.validate_activation(classifier_activation, weights)\r\n    x = layers.Dense(classes, activation=classifier_activation,\r\n                     name='predictions')(x)\r\n  else:\r\n    if pooling == 'avg':\r\n      x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\r\n    elif pooling == 'max':\r\n      x = layers.GlobalMaxPooling2D(name='max_pool')(x)\r\n\r\n  # Ensure that the model takes into account\r\n  # any potential predecessors of `input_tensor`.\r\n  if input_tensor is not None:\r\n    inputs = layer_utils.get_source_inputs(input_tensor)\r\n  else:\r\n    inputs = img_input\r\n\r\n  # Create model.\r\n  model = training.Model(inputs, x, name=model_name)\r\n\r\n  # Load weights.\r\n  if (weights == 'imagenet') and (model_name in WEIGHTS_HASHES):\r\n    if include_top:\r\n      file_name = model_name + '_weights_tf_dim_ordering_tf_kernels.h5'\r\n      file_hash = WEIGHTS_HASHES[model_name][0]\r\n    else:\r\n      file_name = model_name + '_weights_tf_dim_ordering_tf_kernels_notop.h5'\r\n      file_hash = WEIGHTS_HASHES[model_name][1]\r\n    weights_path = data_utils.get_file(\r\n        file_name,\r\n        BASE_WEIGHTS_PATH + file_name,\r\n        cache_subdir='models',\r\n        file_hash=file_hash)\r\n    model.load_weights(weights_path)\r\n  elif weights is not None:\r\n    model.load_weights(weights)\r\n\r\n  return model\r\n\r\n\r\ndef block1(x, filters, kernel_size=3, stride=1, conv_shortcut=True, name=None):\r\n  \"\"\"A residual block.\r\n\r\n  Arguments:\r\n    x: input tensor.\r\n    filters: integer, filters of the bottleneck layer.\r\n    kernel_size: default 3, kernel size of the bottleneck layer.\r\n    stride: default 1, stride of the first layer.\r\n    conv_shortcut: default True, use convolution shortcut if True,\r\n        otherwise identity shortcut.\r\n    name: string, block label.\r\n\r\n  Returns:\r\n    Output tensor for the residual block.\r\n  \"\"\"\r\n  bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1\r\n\r\n  if conv_shortcut:\r\n    shortcut = layers.Conv2D(\r\n        4 * filters, 1, strides=stride, name=name + '_0_conv')(x)\r\n    shortcut = BatchNormalization(\r\n        axis=bn_axis, epsilon=1.001e-5, name=name + '_0_bn')(shortcut)\r\n  else:\r\n    shortcut = x\r\n\r\n  x = layers.Conv2D(filters, 1, strides=stride, name=name + '_1_conv')(x)\r\n  x = BatchNormalization(\r\n      axis=bn_axis, epsilon=1.001e-5, name=name + '_1_bn')(x)\r\n  x = layers.Activation('relu', name=name + '_1_relu')(x)\r\n\r\n  x = layers.Conv2D(\r\n      filters, kernel_size, padding='SAME', name=name + '_2_conv')(x)\r\n  x = BatchNormalization(\r\n      axis=bn_axis, epsilon=1.001e-5, name=name + '_2_bn')(x)\r\n  x = layers.Activation('relu', name=name + '_2_relu')(x)\r\n\r\n  x = layers.Conv2D(4 * filters, 1, name=name + '_3_conv')(x)\r\n  x = BatchNormalization(\r\n      axis=bn_axis, epsilon=1.001e-5, name=name + '_3_bn')(x)\r\n\r\n  x = layers.Add(name=name + '_add')([shortcut, x])\r\n  x = layers.Activation('relu', name=name + '_out')(x)\r\n  return x\r\n\r\n\r\ndef stack1(x, filters, blocks, stride1=2, name=None):\r\n  \"\"\"A set of stacked residual blocks.\r\n\r\n  Arguments:\r\n    x: input tensor.\r\n    filters: integer, filters of the bottleneck layer in a block.\r\n    blocks: integer, blocks in the stacked blocks.\r\n    stride1: default 2, stride of the first layer in the first block.\r\n    name: string, stack label.\r\n\r\n  Returns:\r\n    Output tensor for the stacked blocks.\r\n  \"\"\"\r\n  x = block1(x, filters, stride=stride1, name=name + '_block1')\r\n  for i in range(2, blocks + 1):\r\n    x = block1(x, filters, conv_shortcut=False, name=name + '_block' + str(i))\r\n  return x\r\n\r\n\r\ndef block2(x, filters, kernel_size=3, stride=1, conv_shortcut=False, name=None):\r\n  \"\"\"A residual block.\r\n\r\n  Arguments:\r\n      x: input tensor.\r\n      filters: integer, filters of the bottleneck layer.\r\n      kernel_size: default 3, kernel size of the bottleneck layer.\r\n      stride: default 1, stride of the first layer.\r\n      conv_shortcut: default False, use convolution shortcut if True,\r\n        otherwise identity shortcut.\r\n      name: string, block label.\r\n\r\n  Returns:\r\n    Output tensor for the residual block.\r\n  \"\"\"\r\n  bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1\r\n\r\n  preact = BatchNormalization(\r\n      axis=bn_axis, epsilon=1.001e-5, name=name + '_preact_bn')(x)\r\n  preact = layers.Activation('relu', name=name + '_preact_relu')(preact)\r\n\r\n  if conv_shortcut:\r\n    shortcut = layers.Conv2D(\r\n        4 * filters, 1, strides=stride, name=name + '_0_conv')(preact)\r\n  else:\r\n    shortcut = layers.MaxPooling2D(1, strides=stride)(x) if stride > 1 else x\r\n\r\n  x = layers.Conv2D(\r\n      filters, 1, strides=1, use_bias=False, name=name + '_1_conv')(preact)\r\n  x = BatchNormalization(\r\n      axis=bn_axis, epsilon=1.001e-5, name=name + '_1_bn')(x)\r\n  x = layers.Activation('relu', name=name + '_1_relu')(x)\r\n\r\n  x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name=name + '_2_pad')(x)\r\n  x = layers.Conv2D(\r\n      filters,\r\n      kernel_size,\r\n      strides=stride,\r\n      use_bias=False,\r\n      name=name + '_2_conv')(x)\r\n  x = BatchNormalization(\r\n      axis=bn_axis, epsilon=1.001e-5, name=name + '_2_bn')(x)\r\n  x = layers.Activation('relu', name=name + '_2_relu')(x)\r\n\r\n  x = layers.Conv2D(4 * filters, 1, name=name + '_3_conv')(x)\r\n  x = layers.Add(name=name + '_out')([shortcut, x])\r\n  return x\r\n\r\n\r\ndef stack2(x, filters, blocks, stride1=2, name=None):\r\n  \"\"\"A set of stacked residual blocks.\r\n\r\n  Arguments:\r\n      x: input tensor.\r\n      filters: integer, filters of the bottleneck layer in a block.\r\n      blocks: integer, blocks in the stacked blocks.\r\n      stride1: default 2, stride of the first layer in the first block.\r\n      name: string, stack label.\r\n\r\n  Returns:\r\n      Output tensor for the stacked blocks.\r\n  \"\"\"\r\n  x = block2(x, filters, conv_shortcut=True, name=name + '_block1')\r\n  for i in range(2, blocks):\r\n    x = block2(x, filters, name=name + '_block' + str(i))\r\n  x = block2(x, filters, stride=stride1, name=name + '_block' + str(blocks))\r\n  return x\r\n\r\n\r\ndef block3(x,\r\n           filters,\r\n           kernel_size=3,\r\n           stride=1,\r\n           groups=32,\r\n           conv_shortcut=True,\r\n           name=None):\r\n  \"\"\"A residual block.\r\n\r\n  Arguments:\r\n    x: input tensor.\r\n    filters: integer, filters of the bottleneck layer.\r\n    kernel_size: default 3, kernel size of the bottleneck layer.\r\n    stride: default 1, stride of the first layer.\r\n    groups: default 32, group size for grouped convolution.\r\n    conv_shortcut: default True, use convolution shortcut if True,\r\n        otherwise identity shortcut.\r\n    name: string, block label.\r\n\r\n  Returns:\r\n    Output tensor for the residual block.\r\n  \"\"\"\r\n  bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1\r\n\r\n  if conv_shortcut:\r\n    shortcut = layers.Conv2D(\r\n        (64 // groups) * filters,\r\n        1,\r\n        strides=stride,\r\n        use_bias=False,\r\n        name=name + '_0_conv')(x)\r\n    shortcut = BatchNormalization(\r\n        axis=bn_axis, epsilon=1.001e-5, name=name + '_0_bn')(shortcut)\r\n  else:\r\n    shortcut = x\r\n\r\n  x = layers.Conv2D(filters, 1, use_bias=False, name=name + '_1_conv')(x)\r\n  x = BatchNormalization(\r\n      axis=bn_axis, epsilon=1.001e-5, name=name + '_1_bn')(x)\r\n  x = layers.Activation('relu', name=name + '_1_relu')(x)\r\n\r\n  c = filters // groups\r\n  x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name=name + '_2_pad')(x)\r\n  x = layers.DepthwiseConv2D(\r\n      kernel_size,\r\n      strides=stride,\r\n      depth_multiplier=c,\r\n      use_bias=False,\r\n      name=name + '_2_conv')(x)\r\n  x_shape = backend.int_shape(x)[1:-1]\r\n  x = layers.Reshape(x_shape + (groups, c, c))(x)\r\n  x = layers.Lambda(\r\n      lambda x: sum(x[:, :, :, :, i] for i in range(c)),\r\n      name=name + '_2_reduce')(x)\r\n  x = layers.Reshape(x_shape + (filters,))(x)\r\n  x = BatchNormalization(\r\n      axis=bn_axis, epsilon=1.001e-5, name=name + '_2_bn')(x)\r\n  x = layers.Activation('relu', name=name + '_2_relu')(x)\r\n\r\n  x = layers.Conv2D(\r\n      (64 // groups) * filters, 1, use_bias=False, name=name + '_3_conv')(x)\r\n  x = BatchNormalization(\r\n      axis=bn_axis, epsilon=1.001e-5, name=name + '_3_bn')(x)\r\n\r\n  x = layers.Add(name=name + '_add')([shortcut, x])\r\n  x = layers.Activation('relu', name=name + '_out')(x)\r\n  return x\r\n\r\n\r\ndef stack3(x, filters, blocks, stride1=2, groups=32, name=None):\r\n  \"\"\"A set of stacked residual blocks.\r\n\r\n  Arguments:\r\n    x: input tensor.\r\n    filters: integer, filters of the bottleneck layer in a block.\r\n    blocks: integer, blocks in the stacked blocks.\r\n    stride1: default 2, stride of the first layer in the first block.\r\n    groups: default 32, group size for grouped convolution.\r\n    name: string, stack label.\r\n\r\n  Returns:\r\n    Output tensor for the stacked blocks.\r\n  \"\"\"\r\n  x = block3(x, filters, stride=stride1, groups=groups, name=name + '_block1')\r\n  for i in range(2, blocks + 1):\r\n    x = block3(\r\n        x,\r\n        filters,\r\n        groups=groups,\r\n        conv_shortcut=False,\r\n        name=name + '_block' + str(i))\r\n  return x\r\n\r\n\r\n@keras_export('keras.applications.resnet50.ResNet50',\r\n              'keras.applications.resnet.ResNet50',\r\n              'keras.applications.ResNet50')\r\ndef ResNet50(include_top=True,\r\n             weights='imagenet',\r\n             input_tensor=None,\r\n             input_shape=None,\r\n             pooling=None,\r\n             classes=1000,\r\n             **kwargs):\r\n  \"\"\"Instantiates the ResNet50 architecture.\"\"\"\r\n\r\n  def stack_fn(x):\r\n    x = stack1(x, 64, 3, stride1=1, name='conv2')\r\n    x = stack1(x, 128, 4, name='conv3')\r\n    x = stack1(x, 256, 6, name='conv4')\r\n    return stack1(x, 512, 3, name='conv5')\r\n\r\n  return ResNet(stack_fn, False, True, 'resnet50', include_top, weights,\r\n                input_tensor, input_shape, pooling, classes, **kwargs)\r\n\r\n\r\n@keras_export('keras.applications.resnet.ResNet101',\r\n              'keras.applications.ResNet101')\r\ndef ResNet101(include_top=True,\r\n              weights='imagenet',\r\n              input_tensor=None,\r\n              input_shape=None,\r\n              pooling=None,\r\n              classes=1000,\r\n              **kwargs):\r\n  \"\"\"Instantiates the ResNet101 architecture.\"\"\"\r\n\r\n  def stack_fn(x):\r\n    x = stack1(x, 64, 3, stride1=1, name='conv2')\r\n    x = stack1(x, 128, 4, name='conv3')\r\n    x = stack1(x, 256, 23, name='conv4')\r\n    return stack1(x, 512, 3, name='conv5')\r\n\r\n  return ResNet(stack_fn, False, True, 'resnet101', include_top, weights,\r\n                input_tensor, input_shape, pooling, classes, **kwargs)\r\n\r\n\r\n@keras_export('keras.applications.resnet.ResNet152',\r\n              'keras.applications.ResNet152')\r\ndef ResNet152(include_top=True,\r\n              weights='imagenet',\r\n              input_tensor=None,\r\n              input_shape=None,\r\n              pooling=None,\r\n              classes=1000,\r\n              **kwargs):\r\n  \"\"\"Instantiates the ResNet152 architecture.\"\"\"\r\n\r\n  def stack_fn(x):\r\n    x = stack1(x, 64, 3, stride1=1, name='conv2')\r\n    x = stack1(x, 128, 8, name='conv3')\r\n    x = stack1(x, 256, 36, name='conv4')\r\n    return stack1(x, 512, 3, name='conv5')\r\n\r\n  return ResNet(stack_fn, False, True, 'resnet152', include_top, weights,\r\n                input_tensor, input_shape, pooling, classes, **kwargs)\r\n\r\n\r\n@keras_export('keras.applications.resnet50.preprocess_input',\r\n              'keras.applications.resnet.preprocess_input')\r\ndef preprocess_input(x, data_format=None):\r\n  return imagenet_utils.preprocess_input(\r\n      x, data_format=data_format, mode='caffe')\r\n\r\n\r\n@keras_export('keras.applications.resnet50.decode_predictions',\r\n              'keras.applications.resnet.decode_predictions')\r\ndef decode_predictions(preds, top=5):\r\n  return imagenet_utils.decode_predictions(preds, top=top)\r\n\r\n\r\npreprocess_input.__doc__ = imagenet_utils.PREPROCESS_INPUT_DOC.format(\r\n    mode='',\r\n    ret=imagenet_utils.PREPROCESS_INPUT_RET_DOC_CAFFE,\r\n    error=imagenet_utils.PREPROCESS_INPUT_ERROR_DOC)\r\ndecode_predictions.__doc__ = imagenet_utils.decode_predictions.__doc__\r\n\r\nDOC = \"\"\"\r\n\r\n  Reference paper:\r\n  - [Deep Residual Learning for Image Recognition]\r\n  (https://arxiv.org/abs/1512.03385) (CVPR 2015)\r\n\r\n  Optionally loads weights pre-trained on ImageNet.\r\n  Note that the data format convention used by the model is\r\n  the one specified in your Keras config at `~/.keras/keras.json`.\r\n\r\n  Arguments:\r\n    include_top: whether to include the fully-connected\r\n      layer at the top of the network.\r\n    weights: one of `None` (random initialization),\r\n      'imagenet' (pre-training on ImageNet),\r\n      or the path to the weights file to be loaded.\r\n    input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\r\n      to use as image input for the model.\r\n    input_shape: optional shape tuple, only to be specified\r\n      if `include_top` is False (otherwise the input shape\r\n      has to be `(224, 224, 3)` (with `'channels_last'` data format)\r\n      or `(3, 224, 224)` (with `'channels_first'` data format).\r\n      It should have exactly 3 inputs channels,\r\n      and width and height should be no smaller than 32.\r\n      E.g. `(200, 200, 3)` would be one valid value.\r\n    pooling: Optional pooling mode for feature extraction\r\n      when `include_top` is `False`.\r\n      - `None` means that the output of the model will be\r\n          the 4D tensor output of the\r\n          last convolutional block.\r\n      - `avg` means that global average pooling\r\n          will be applied to the output of the\r\n          last convolutional block, and thus\r\n          the output of the model will be a 2D tensor.\r\n      - `max` means that global max pooling will\r\n          be applied.\r\n    classes: optional number of classes to classify images\r\n      into, only to be specified if `include_top` is True, and\r\n      if no `weights` argument is specified.\r\n\r\n  Returns:\r\n    A Keras model instance.\r\n\"\"\"\r\n\r\nsetattr(ResNet50, '__doc__', ResNet50.__doc__ + DOC)\r\nsetattr(ResNet101, '__doc__', ResNet101.__doc__ + DOC)\r\nsetattr(ResNet152, '__doc__', ResNet152.__doc__ + DOC)\r\n```\r\n\r\n_Originally posted by @ImMrMa in https://github.com/tensorflow/tensorflow/issues/42051#issuecomment-670379919_", "comments": ["@ImMrMa,\r\nThe original issue you have submitted has been reopened. \r\n\r\nCan we close this issue since it is already being tracked there? Thanks!", "fine, thank you"]}, {"number": 42117, "title": "Why the performance slowly by double 1080ti than single 1080ti?", "body": "I write a code for double 1080ti , I find the speed not reduce than single 1080ti, but I check the information by nvidia-smi the double 1080ti is working, I don't understand why the double 1080ti almost same speed than single 1080ti ?\r\n\r\nI use the tensorboard to watch the profile:\r\n![image](https://user-images.githubusercontent.com/10364552/89617865-8a5d2480-d8bd-11ea-8b98-e52d95f8cadc.png)\r\nIt is looks input waste lots of time , how to fix this problem?\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nThe full code:\r\nDouble 1080ti:\r\n```\r\n#!/usr/bin/env python\r\n# coding: utf-8\r\n\r\n# In[1]:\r\n\r\nimport sys\r\nimport os\r\nfrom datetime import datetime\r\n#from packaging import version\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\r\nbatch_size = 128\r\nepochs = 500\r\nIMG_HEIGHT = 224\r\nIMG_WIDTH = 224\r\nNUM_WORKERS = 4\r\n\r\nPATH = os.path.abspath(os.path.dirname(__file__))\r\n\r\ntrain_dir = os.path.join(PATH, 'train')\r\nvalidation_dir = os.path.join(PATH, 'valid')\r\n\r\ntrain_close_dir = os.path.join(train_dir, 'close')  # directory with our training cat pictures\r\ntrain_open_dir = os.path.join(train_dir, 'open')  # directory with our training dog pictures\r\nvalidation_close_dir = os.path.join(validation_dir, 'close')  # directory with our validation cat pictures\r\nvalidation_open_dir = os.path.join(validation_dir, 'open')  # directory with our validation dog pictures\r\n\r\n\r\nimport tensorflow as tf\r\n\r\nprint (tf.__version__)\r\n\r\n\r\n# In[2]:\r\n\r\n\r\nprint(\"Version: \", tf.__version__)\r\nprint(\"Eager mode: \", tf.executing_eagerly())\r\nprint(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")\r\n\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\nfor g in gpus:\r\n    tf.config.experimental.set_virtual_device_configuration(g, [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7000)])\r\n\r\n\r\n# In[3]:\r\n\r\n\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\r\nimport numpy as np\r\nimport random\r\n\r\nimport matplotlib.pyplot as plt\r\n\r\n# In[4]:\r\n#mirrored_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\r\nmirrored_strategy = tf.distribute.MirroredStrategy()\r\n\r\nnum_close_tr = len(os.listdir(train_close_dir))\r\nnum_open_tr = len(os.listdir(train_open_dir))\r\n\r\nnum_close_val = len(os.listdir(validation_close_dir))\r\nnum_open_val = len(os.listdir(validation_open_dir))\r\n\r\ntotal_train = num_close_tr + num_open_tr\r\ntotal_val = num_close_val + num_open_val\r\n\r\nprint('total training close images:', num_close_tr)\r\nprint('total training open images:', num_open_tr)\r\nprint('total validation close images:', num_close_val)\r\nprint('total validation open images:', num_open_val)\r\nprint(\"--\")\r\nprint(\"Total training images:\", total_train)\r\nprint(\"Total validation images:\", total_val)\r\n\r\n\r\nif len(sys.argv) > 1:\r\n    batch_size = int(sys.argv[1])\r\n\r\nif len(sys.argv) > 2:\r\n    epochs = int(sys.argv[2])\r\n\r\ndef preprocess_image(image):\r\n    image = tf.image.decode_jpeg(image, channels=3)\r\n    image = tf.image.resize(image, [image_size, image_size])\r\n    image /= 255.0\r\n    return image\r\n\r\ndef load_and_preprocess_image(path):\r\n    image = tf.io.read_file(path)\r\n    return preprocess_image(image)\r\n\r\n\r\ntrain_image_generator = ImageDataGenerator(rescale=1./255, horizontal_flip=True, zoom_range=0.1, rotation_range=45) # Generator for our training data\r\nvalidation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data\r\n\r\ntrain_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\r\n                                                           directory=train_dir,\r\n                                                           shuffle=True,\r\n                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\r\n                                                           class_mode='binary')\r\n\r\nval_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\r\n                                                              directory=validation_dir,\r\n                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\r\n                                                              class_mode='binary')\r\n\r\nsample_training_images, _ = next(train_data_gen)\r\n\r\n\r\n# In[5]:\r\n\r\n\r\ndef plotImages(images_arr):\r\n    fig, axes = plt.subplots(1, 5, figsize=(20, 20))\r\n    axes = axes.flatten()\r\n    for img, ax in zip( images_arr, axes):\r\n        ax.imshow(img)\r\n        ax.axis('off')\r\n    plt.tight_layout()\r\n    plt.show()\r\n\r\nplotImages(sample_training_images[:5])\r\n\r\n\r\n\r\n# In[6]:\r\n\r\n\r\n\r\n\r\n# In[7]:\r\n\r\n\r\nwith mirrored_strategy.scope():\r\n    tinydarknet = keras.Sequential([\r\n        keras.layers.Conv2D(16, (3, 3), strides=[1, 1], padding=\"same\", input_shape=(IMG_HEIGHT,IMG_WIDTH, 3)),\r\n        keras.layers.BatchNormalization(),\r\n        keras.layers.LeakyReLU(alpha=0.1),\r\n        keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\r\n        keras.layers.Conv2D(32, (3, 3), strides=[1, 1], padding=\"same\"),\r\n        keras.layers.BatchNormalization(),\r\n        keras.layers.LeakyReLU(alpha=0.1),\r\n        keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\r\n        keras.layers.Conv2D(16, (1, 1), strides=[1, 1], padding=\"same\"),\r\n        keras.layers.BatchNormalization(),\r\n        keras.layers.LeakyReLU(alpha=0.1),\r\n        keras.layers.Conv2D(128, (3, 3), strides=[1, 1], padding=\"same\"),\r\n        keras.layers.BatchNormalization(),\r\n        keras.layers.LeakyReLU(alpha=0.1),\r\n        keras.layers.Conv2D(16, (1, 1), strides=[1, 1], padding=\"same\"),\r\n        keras.layers.BatchNormalization(),\r\n        keras.layers.LeakyReLU(alpha=0.1),\r\n        keras.layers.Conv2D(128, (3, 3), strides=[1, 1], padding=\"same\"),\r\n        keras.layers.BatchNormalization(),\r\n        keras.layers.LeakyReLU(alpha=0.1),\r\n        keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\r\n        keras.layers.Conv2D(32, (1, 1), strides=[1, 1], padding=\"same\"),\r\n        keras.layers.BatchNormalization(),\r\n        keras.layers.LeakyReLU(alpha=0.1),\r\n        keras.layers.Conv2D(256, (3, 3), strides=[1, 1], padding=\"same\"),\r\n        keras.layers.BatchNormalization(),\r\n        keras.layers.LeakyReLU(alpha=0.1),\r\n        keras.layers.Conv2D(32, (1, 1), strides=[1, 1], padding=\"same\"),\r\n        keras.layers.BatchNormalization(),\r\n        keras.layers.LeakyReLU(alpha=0.1),\r\n        keras.layers.Conv2D(256, (3, 3), strides=[1, 1], padding=\"same\"),\r\n        keras.layers.BatchNormalization(),\r\n        keras.layers.LeakyReLU(alpha=0.1),\r\n        keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\r\n        keras.layers.Conv2D(64, (1, 1), strides=[1, 1], padding=\"same\"),\r\n        keras.layers.BatchNormalization(),\r\n        keras.layers.LeakyReLU(alpha=0.1),\r\n        keras.layers.Conv2D(512, (3, 3), strides=[1, 1], padding=\"same\"),\r\n        keras.layers.BatchNormalization(),\r\n        keras.layers.LeakyReLU(alpha=0.1),\r\n        keras.layers.Conv2D(64, (1, 1), strides=[1, 1], padding=\"same\"),\r\n        keras.layers.BatchNormalization(),\r\n        keras.layers.LeakyReLU(alpha=0.1),\r\n        keras.layers.Conv2D(512, (3, 3), strides=[1, 1], padding=\"same\"),\r\n        keras.layers.BatchNormalization(),\r\n        keras.layers.LeakyReLU(alpha=0.1),\r\n        keras.layers.Conv2D(128, (1, 1), strides=[1, 1], padding=\"same\"),\r\n        keras.layers.BatchNormalization(),\r\n        keras.layers.LeakyReLU(alpha=0.1),\r\n        keras.layers.Conv2D(1000, (1, 1)),\r\n        keras.layers.BatchNormalization(),\r\n        keras.layers.AveragePooling2D(),\r\n        keras.layers.Flatten(),\r\n        keras.layers.Dense(1)\r\n    ])\r\n\r\n\r\n    # In[8]:\r\n\r\n\r\n    tinydarknet.compile(optimizer=\"adam\",\r\n                 loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\r\n                 metrics=[\"accuracy\"])\r\n\r\n\r\n# In[9]:\r\nlogs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\ntboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\r\n                                                 histogram_freq = 1,\r\n                                                 profile_batch = '500,520')\r\n\r\n\r\nhistory = tinydarknet.fit(#_generator(\r\n    train_data_gen,\r\n    steps_per_epoch=total_train // batch_size,\r\n    epochs=epochs,\r\n    validation_data=val_data_gen,\r\n    validation_steps=total_val // batch_size,\r\n    workers=NUM_WORKERS,\r\n    callbacks = [tboard_callback]\r\n)\r\n\r\n\r\n# In[10]:\r\n\r\n\r\nacc = history.history['accuracy']\r\nval_acc = history.history['val_accuracy']\r\n\r\nloss=history.history['loss']\r\nval_loss=history.history['val_loss']\r\n\r\nepochs_range = range(epochs)\r\n\r\n\r\ntinydarknet.save(\"keras_model\")\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_model = converter.convert()\r\n\r\nwith open(\"tinydarknet.tflite\", \"w+b\") as fp:\r\n    fp.write(tflite_model)\r\n    fp.flush()\r\n\r\n```\r\n\r\nThe single 1080ti code:\r\n```\r\n#!/usr/bin/env python\r\n# coding: utf-8\r\n\r\n# In[1]:\r\n\r\nimport sys\r\nimport os\r\n\r\nbatch_size = 128\r\nepochs = 500\r\nIMG_HEIGHT = 224\r\nIMG_WIDTH = 224\r\nNUM_WORKERS = 4\r\n\r\nPATH = os.path.abspath(os.path.dirname(__file__))\r\n\r\ntrain_dir = os.path.join(PATH, 'train')\r\nvalidation_dir = os.path.join(PATH, 'valid')\r\n\r\ntrain_close_dir = os.path.join(train_dir, 'close')  # directory with our training cat pictures\r\ntrain_open_dir = os.path.join(train_dir, 'open')  # directory with our training dog pictures\r\nvalidation_close_dir = os.path.join(validation_dir, 'close')  # directory with our validation cat pictures\r\nvalidation_open_dir = os.path.join(validation_dir, 'open')  # directory with our validation dog pictures\r\n\r\n\r\nimport tensorflow as tf\r\n\r\nprint (tf.__version__)\r\n\r\n\r\n# In[2]:\r\n\r\n\r\nprint(\"Version: \", tf.__version__)\r\nprint(\"Eager mode: \", tf.executing_eagerly())\r\nprint(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")\r\n\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\ntf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=6000)])\r\n\r\n\r\n# In[3]:\r\n\r\n\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\r\nimport numpy as np\r\nimport random\r\n\r\nimport matplotlib.pyplot as plt\r\n\r\n# In[4]:\r\n\r\n\r\nnum_close_tr = len(os.listdir(train_close_dir))\r\nnum_open_tr = len(os.listdir(train_open_dir))\r\n\r\nnum_close_val = len(os.listdir(validation_close_dir))\r\nnum_open_val = len(os.listdir(validation_open_dir))\r\n\r\ntotal_train = num_close_tr + num_open_tr\r\ntotal_val = num_close_val + num_open_val\r\n\r\nprint('total training close images:', num_close_tr)\r\nprint('total training open images:', num_open_tr)\r\nprint('total validation close images:', num_close_val)\r\nprint('total validation open images:', num_open_val)\r\nprint(\"--\")\r\nprint(\"Total training images:\", total_train)\r\nprint(\"Total validation images:\", total_val)\r\n\r\n\r\nif len(sys.argv) > 1:\r\n    batch_size = int(sys.argv[1])\r\n\r\nif len(sys.argv) > 2:\r\n    epochs = int(sys.argv[2])\r\n\r\ndef preprocess_image(image):\r\n    image = tf.image.decode_jpeg(image, channels=3)\r\n    image = tf.image.resize(image, [image_size, image_size])\r\n    image /= 255.0\r\n    return image\r\n\r\ndef load_and_preprocess_image(path):\r\n    image = tf.io.read_file(path)\r\n    return preprocess_image(image)\r\n\r\n\r\ntrain_image_generator = ImageDataGenerator(rescale=1./255, horizontal_flip=True, zoom_range=0.1, rotation_range=45) # Generator for our training data\r\nvalidation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data\r\n\r\ntrain_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\r\n                                                           directory=train_dir,\r\n                                                           shuffle=True,\r\n                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\r\n                                                           class_mode='binary')\r\n\r\nval_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\r\n                                                              directory=validation_dir,\r\n                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\r\n                                                              class_mode='binary')\r\n\r\nsample_training_images, _ = next(train_data_gen)\r\n\r\n\r\n# In[5]:\r\n\r\n\r\ndef plotImages(images_arr):\r\n    fig, axes = plt.subplots(1, 5, figsize=(20, 20))\r\n    axes = axes.flatten()\r\n    for img, ax in zip( images_arr, axes):\r\n        ax.imshow(img)\r\n        ax.axis('off')\r\n    plt.tight_layout()\r\n    plt.show()\r\n\r\nplotImages(sample_training_images[:5])\r\n\r\n\r\n\r\n# In[6]:\r\n\r\n\r\n\r\n\r\n# In[7]:\r\n\r\n\r\n\r\ntinydarknet = keras.Sequential([\r\n    keras.layers.Conv2D(16, (3, 3), strides=[1, 1], padding=\"same\", input_shape=(IMG_HEIGHT,IMG_WIDTH, 3)),\r\n    keras.layers.BatchNormalization(),\r\n    keras.layers.LeakyReLU(alpha=0.1),\r\n    keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\r\n    keras.layers.Conv2D(32, (3, 3), strides=[1, 1], padding=\"same\"),\r\n    keras.layers.BatchNormalization(),\r\n    keras.layers.LeakyReLU(alpha=0.1),\r\n    keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\r\n    keras.layers.Conv2D(16, (1, 1), strides=[1, 1], padding=\"same\"),\r\n    keras.layers.BatchNormalization(),\r\n    keras.layers.LeakyReLU(alpha=0.1),\r\n    keras.layers.Conv2D(128, (3, 3), strides=[1, 1], padding=\"same\"),\r\n    keras.layers.BatchNormalization(),\r\n    keras.layers.LeakyReLU(alpha=0.1),\r\n    keras.layers.Conv2D(16, (1, 1), strides=[1, 1], padding=\"same\"),\r\n    keras.layers.BatchNormalization(),\r\n    keras.layers.LeakyReLU(alpha=0.1),\r\n    keras.layers.Conv2D(128, (3, 3), strides=[1, 1], padding=\"same\"),\r\n    keras.layers.BatchNormalization(),\r\n    keras.layers.LeakyReLU(alpha=0.1),\r\n    keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\r\n    keras.layers.Conv2D(32, (1, 1), strides=[1, 1], padding=\"same\"),\r\n    keras.layers.BatchNormalization(),\r\n    keras.layers.LeakyReLU(alpha=0.1),\r\n    keras.layers.Conv2D(256, (3, 3), strides=[1, 1], padding=\"same\"),\r\n    keras.layers.BatchNormalization(),\r\n    keras.layers.LeakyReLU(alpha=0.1),\r\n    keras.layers.Conv2D(32, (1, 1), strides=[1, 1], padding=\"same\"),\r\n    keras.layers.BatchNormalization(),\r\n    keras.layers.LeakyReLU(alpha=0.1),\r\n    keras.layers.Conv2D(256, (3, 3), strides=[1, 1], padding=\"same\"),\r\n    keras.layers.BatchNormalization(),\r\n    keras.layers.LeakyReLU(alpha=0.1),\r\n    keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\r\n    keras.layers.Conv2D(64, (1, 1), strides=[1, 1], padding=\"same\"),\r\n    keras.layers.BatchNormalization(),\r\n    keras.layers.LeakyReLU(alpha=0.1),\r\n    keras.layers.Conv2D(512, (3, 3), strides=[1, 1], padding=\"same\"),\r\n    keras.layers.BatchNormalization(),\r\n    keras.layers.LeakyReLU(alpha=0.1),\r\n    keras.layers.Conv2D(64, (1, 1), strides=[1, 1], padding=\"same\"),\r\n    keras.layers.BatchNormalization(),\r\n    keras.layers.LeakyReLU(alpha=0.1),\r\n    keras.layers.Conv2D(512, (3, 3), strides=[1, 1], padding=\"same\"),\r\n    keras.layers.BatchNormalization(),\r\n    keras.layers.LeakyReLU(alpha=0.1),\r\n    keras.layers.Conv2D(128, (1, 1), strides=[1, 1], padding=\"same\"),\r\n    keras.layers.BatchNormalization(),\r\n    keras.layers.LeakyReLU(alpha=0.1),\r\n    keras.layers.Conv2D(1000, (1, 1)),\r\n    keras.layers.BatchNormalization(),\r\n    keras.layers.AveragePooling2D(),\r\n    keras.layers.Flatten(),\r\n    keras.layers.Dense(1)\r\n])\r\n\r\n\r\n# In[8]:\r\n\r\n\r\ntinydarknet.compile(optimizer=\"adam\",\r\n             loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\r\n             metrics=[\"accuracy\"])\r\n\r\n\r\n# In[9]:\r\n\r\nhistory = tinydarknet.fit(#_generator(\r\n    train_data_gen,\r\n    steps_per_epoch=total_train // batch_size,\r\n    epochs=epochs,\r\n    validation_data=val_data_gen,\r\n    validation_steps=total_val // batch_size,\r\n    workers=NUM_WORKERS\r\n)\r\n\r\n\r\n# In[10]:\r\n\r\n\r\nacc = history.history['accuracy']\r\nval_acc = history.history['val_accuracy']\r\n\r\nloss=history.history['loss']\r\nval_loss=history.history['val_loss']\r\n\r\nepochs_range = range(epochs)\r\n\r\n\r\ntinydarknet.save(\"keras_model\")\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(tinydarknet)\r\ntflite_model = converter.convert()\r\n\r\nwith open(\"tinydarknet.tflite\", \"w+b\") as fp:\r\n    fp.write(tflite_model)\r\n    fp.flush()\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary):binary by pip\r\n- TensorFlow version (use command below): 2.3.0\r\n- Python version:Python 3.7.7\r\n- CUDA/cuDNN version:10.2\r\n- GPU model and memory: 1080ti  \r\n\r\n\r\n\r\n", "comments": ["Hi @smallworld-network-wupeng, can you start by sharing profiling information for your single GPU model? When trying to debug performance issues it's often helpful to start with the simplest case and make sure that you aren't input bound with one GPU as well. That could indicate either a bottleneck from the transformation or extraction of your data.\r\n\r\nI also noticed that in your multi-GPU case you were using callbacks to log histograms on each epoch, but there are no callbacks for the single-GPU case. It's worth comparing the results with the same callbacks and frequency, since logging this information can also slow down the training process. These ops are executed eagerly and don\u2019t have as good a performance as the ops inside a TF graph.\r\n\r\nLastly, what did you use as your batch size? Typically, you want to increase your batch size as you add more accelerators so as to make effective use of the extra computing power.\r\nIf single GPU case you have `BATCH_SIZE = 8`\r\nFor the multi GPU case you'll want to set your batch size to be `BATCH_SIZE = 8 * mirrored_strategy.num_replicas_in_sync`'", "> Hi @smallworld-network-wupeng, can you start by sharing profiling information for your single GPU model? When trying to debug performance issues it's often helpful to start with the simplest case and make sure that you aren't input bound with one GPU as well. That could indicate either a bottleneck from the transformation or extraction of your data.\r\n> \r\n> I also noticed that in your multi-GPU case you were using callbacks to log histograms on each epoch, but there are no callbacks for the single-GPU case. It's worth comparing the results with the same callbacks and frequency, since logging this information can also slow down the training process. These ops are executed eagerly and don\u2019t have as good a performance as the ops inside a TF graph.\r\n> \r\n> Lastly, what did you use as your batch size? Typically, you want to increase your batch size as you add more accelerators so as to make effective use of the extra computing power.\r\n> If single GPU case you have `BATCH_SIZE = 8`\r\n> For the multi GPU case you'll want to set your batch size to be `BATCH_SIZE = 8 * mirrored_strategy.num_replicas_in_sync`'\r\n\r\nThe single gpu profile:\r\n![image](https://user-images.githubusercontent.com/10364552/89698959-9812b880-d956-11ea-9a96-3fc40ef68c65.png)\r\n\r\nI modify the code :\r\n```\r\ntrain_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size* mirrored_strategy.num_replicas_in_sync,\r\n                                                           directory=train_dir,\r\n                                                           shuffle=True,\r\n                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\r\n                                                           class_mode='binary')\r\n\r\nval_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size* mirrored_strategy.num_replicas_in_sync,\r\n                                                              directory=validation_dir,\r\n                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\r\n                                                              class_mode='binary')\r\n```\r\nBut it's looks slower (1s/step) than before . ", "Looks like your program is still input bound in the single GPU case. You'll want to first work on that first before trying to scale to two GPUs, as adding more GPUs will likely only exacerbate the bottleneck. \r\n\r\nFirstly, you should try tuning the batch size in the single GPU case. If your batch size is too small then your GPU might be waiting around for the CPU to process and prepare the data for the next step of training. \r\n\r\nThe TF guides have a lot of suggestions on how to improve your input pipeline when using `tf.data.Dataset` which is recommended when doing distributed training. I think you should be able to wrap your `ImageDataGenerator` in the `from_generator` [method](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator) and get the benefits of using `tf.data`. There is an example of this [here in the Consuming Python generators section](https://www.tensorflow.org/guide/data#consuming_python_generators) of the `tf.data` guide.\r\n\r\nPlease see the [performance optimization guide for tf.data](https://www.tensorflow.org/guide/data_performance_analysis) and this [Tensorboard Profiler tutorial](https://www.tensorflow.org/guide/data_performance_analysis) for more suggestions on how to debug bottlenecks in your input data pipeline. I think [this video](https://www.youtube.com/watch?v=ZnukSLKEw34&list=PLQY2H8rRoyvzIuB8rZXs7pfyjiSUs8Vza&index=4&t=1s) is also very helpful in understanding the different ways your input pipeline can be a bottleneck.\r\n\r\nHope these resources help you make your program less input bound!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "> Looks like your program is still input bound in the single GPU case. You'll want to first work on that first before trying to scale to two GPUs, as adding more GPUs will likely only exacerbate the bottleneck.\r\n> \r\n> Firstly, you should try tuning the batch size in the single GPU case. If your batch size is too small then your GPU might be waiting around for the CPU to process and prepare the data for the next step of training.\r\n> \r\n> The TF guides have a lot of suggestions on how to improve your input pipeline when using `tf.data.Dataset` which is recommended when doing distributed training. I think you should be able to wrap your `ImageDataGenerator` in the `from_generator` [method](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator) and get the benefits of using `tf.data`. There is an example of this [here in the Consuming Python generators section](https://www.tensorflow.org/guide/data#consuming_python_generators) of the `tf.data` guide.\r\n> \r\n> Please see the [performance optimization guide for tf.data](https://www.tensorflow.org/guide/data_performance_analysis) and this [Tensorboard Profiler tutorial](https://www.tensorflow.org/guide/data_performance_analysis) for more suggestions on how to debug bottlenecks in your input data pipeline. I think [this video](https://www.youtube.com/watch?v=ZnukSLKEw34&list=PLQY2H8rRoyvzIuB8rZXs7pfyjiSUs8Vza&index=4&t=1s) is also very helpful in understanding the different ways your input pipeline can be a bottleneck.\r\n> \r\n> Hope these resources help you make your program less input bound!\r\n\r\nThe ImageDataGenerator waste a lot of time ,but My dataset not enough to train ,so I want to use ImageDataGenerator to increase the dataset . But it is look ImageDataGenerator performance not good . Do you have any idea ?", "Yes, it seems that the ImageDataGenerator is what is causing your input bottleneck. Did you try wrapping it in the `from_generator` method as I mentioned above? (see [example in docs here](https://www.tensorflow.org/guide/data#consuming_python_generators)). Another option (although more work) is to use tf.data and the tf.image library to do the augmentation. [This tutorial might help](https://www.tensorflow.org/tutorials/images/data_augmentation), specifically the Using tf.image section.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 42116, "title": "tf.cond  make me confused if use constant it does not work, but if convert it to tensor it works ", "body": "`\r\nimport tensorflow as tf\r\n\r\n\r\na = tf.constant([[[1,2,3,4],[5,6,7,8]], [[1,2,3,4],[5,6,7,8]]], name='a')\r\nb = tf.constant([[1,0,1,1,1,1,1,1,1], [0,1,1,1,1,0,0,0,0]], name='b')\r\n\r\ng = tf.slice(a, [0,0,0], [-1, 1, -1])\r\n\"\"\"\r\n if use  \r\n   xax_len = 7 \r\n   seq_length = 9\r\n then tensorflow raise a error\r\nelif use\r\n   xax_len = tf.convert_to_tensor(7) \r\n   seq_length = tf.convert_to_tensor(9) \r\nthen it works\r\n\"\"\" \r\nxax_len = tf.convert_to_tensor(7) \r\nseq_length = tf.convert_to_tensor(9) \r\ninput_x = tf.cond(tf.greater(xax_len,seq_length),\r\n                  lambda : tf.pad(tensor=b, paddings=[[0, 0], [0, xax_len-seq_length]], constant_values=0),\r\n                  lambda : tf.slice(b, [0,0], [-1, xax_len]))\r\nprint(input_x)\r\n`", "comments": ["@gavincaoyuji \r\n\r\nI have tried in colab with TF version 2.3 and i am not seeing any error if i use constant or if i convert it to tensor.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/c4f2b5ca5cfe9b576bd9c634dbefc290/untitled226.ipynb).Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 42115, "title": "Why does the input_layer sort the columns? ", "body": "https://github.com/tensorflow/tensorflow/blob/05ab6a2afa2959410d48aab2336cea9dc1e2c13e/tensorflow/python/feature_column/feature_column.py#L199", "comments": ["@alansplaza We are just sorting so that all the columns are sorted in alphabetical order. Apart from that it doesn't mean much.", "@alansplaza  For the columns to be in a ordered way (Alphabetical Order) it has to be sorted !\r\nThis is the reason for sorting of columns by input_layer", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 42114, "title": "Input size of converted lite model doesn't match the original model input size", "body": "**System information**\r\n- COLAB:\r\n- TensorFlow version 2.4.0-dev20200805:\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nthis [Link](https://colab.research.google.com/gist/jvishnuvardhan/23066f1a722fc566b437a5210d1b97b0/ssd_saved_model_tflite_conversion.ipynb#scrollTo=X5s5D5ufCcKb) for code I used in converting the saved model to TensorFlow lite\r\n\r\n```\r\n!pip install tf-nightly\r\nmodel_dir=saved_model'\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(model_dir,signature_keys=['serving_default'],)\r\n\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.experimental_new_converter = True\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\n\r\ntflite_model = converter.convert()\r\n\r\n#open(\"saved_model/converted_model.tflite\", \"wb\").write(tflite_model)\r\nopen('tflite_model.tflite','wb').write(tflite_model)\r\n```\r\n\r\n**The output from the converter invocation**\r\n- successfully generate the model.tflite\r\n- But When I checked the input for both the original and converted model, I found the following mismatching:\r\n- -  checked the input for the model I got it as [1,1,1,3] instead of [1,300,300,3]\r\n-- in my config file to train the object detection model, I have the following image resize:\r\n```\r\nimage_resizer {\r\n      fixed_shape_resizer {\r\n        height: 300\r\n        width: 300\r\n      }\r\n    }\r\n```\r\n\r\n\r\n**The original model I used is saved model,  It is the same as all models in the [model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md).**\r\n\r\n\r\n**I was training the object detection API and run it successfully with original .pb saved model ([using this backbone model](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz))**\r\n\r\n\r\n\r\nAny recommendations here? Thanks.", "comments": ["I was able to get this working by running the following code:\r\n\r\n```\r\n!pip install tf-nightly\r\nimport tensorflow as tf\r\n\r\n## TFLite Conversion\r\n# Before conversion, fix the model input size\r\nmodel = tf.saved_model.load(\"saved_model\")\r\nmodel.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY].inputs[0].set_shape([1, 300, 300, 3])\r\ntf.saved_model.save(model, \"saved_model_updated\", signatures=model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY])\r\n# Convert\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir='saved_model_updated', signature_keys=['serving_default'])\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\ntflite_model = converter.convert()\r\n\r\n## TFLite Interpreter to check input shape\r\ninterpreter = tf.lite.Interpreter(model_content=tflite_model)\r\ninterpreter.allocate_tensors()\r\n\r\n# Get input and output tensors.\r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\n\r\n# Test the model on random input data.\r\ninput_shape = input_details[0]['shape']\r\nprint(input_shape)\r\n```\r\n\r\n```\r\n[  1 300 300   3]\r\n```\r\n\r\n\r\nFeel free to re-open this if you still face an issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42114\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42114\">No</a>\n", "@MeghnaNatraj  Thank you so much :) \r\nI really appreciate it. it works now \ud83d\udc6f ", "Try this: \r\n`model = tf.saved_model.load(\"dir/to/model\")\r\nconcrete_func = model.signatures[\r\n  tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\r\nconcrete_func.inputs[0].set_shape([None, 224, 224, 3]) #your input size\r\nconverter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\r\ntflite_model = converter.convert()\r\nwith open('model.tflite', 'wb') as f:\r\n  f.write(tflite_model)`\r\n"]}, {"number": 42113, "title": "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot convert a Tensor of dtype resource to a NumPy array.", "body": "**System information**\r\n- OS Platform and Distribution :CentOS Linux release 7.7.1908\r\n- TensorFlow version:2.1.0\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\n```\r\nconverter = tf.lite.TFLiteConverter.from_concrete_functions([train_step.get_concrete_function(tf.TensorSpec(shape=(64, 64, 2048),dtype=tf.dtypes.float32),tf.TensorSpec(shape=(64, 50),dtype=tf.dtypes.int32))])\r\ntflite_model = converter.convert()\r\n```\r\n# Copy and paste here the exact command\r\n`tflite_model = converter.convert()`\r\n**The output from the converter invocation**\r\n```\r\n2020-08-07 09:40:27.848678: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize\r\n2020-08-07 09:40:27.848903: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: Graph size after: 16782 nodes (0), 22769 edges (0), time = 401.073ms.\r\n2020-08-07 09:40:27.848929: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: Graph size after: 16782 nodes (0), 22769 edges (0), time = 457.052ms.\r\n2020-08-07 09:40:27.848987: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_7_body_33225_grad_59089\r\n2020-08-07 09:40:27.849000: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.003ms.\r\n2020-08-07 09:40:27.849053: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.849064: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_31_body_39513_rewritten\r\n2020-08-07 09:40:27.849075: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.849084: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.849092: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_47_body_43705_grad_45308\r\n2020-08-07 09:40:27.849108: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.849121: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.849131: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_21_cond_36892_grad_54630\r\n2020-08-07 09:40:27.849143: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.849157: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.849165: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_15_body_35321_rewritten\r\n2020-08-07 09:40:27.849174: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.849183: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.849192: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_11_body_34273_rewritten\r\n2020-08-07 09:40:27.849201: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.849212: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.849220: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_15_body_35321_grad_56441\r\n2020-08-07 09:40:27.849230: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.849239: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.849250: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_38_body_41347_grad_48826\r\n2020-08-07 09:40:27.849280: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.849298: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.849309: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_21_body_36893_rewritten\r\n2020-08-07 09:40:27.849323: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.849340: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.849358: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_19_body_36369_grad_55116\r\n2020-08-07 09:40:27.849422: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.849432: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.849442: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_12_body_34535_rewritten\r\n2020-08-07 09:40:27.849453: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.849462: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.849471: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_13_cond_34796_rewritten\r\n2020-08-07 09:40:27.849481: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.849491: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.849500: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_20_body_36631_grad_54785\r\n2020-08-07 09:40:27.849509: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.849517: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.849526: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_23_body_37417_rewritten\r\n2020-08-07 09:40:27.849534: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.849543: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.849551: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_37_body_41085_rewritten\r\n2020-08-07 09:40:27.849560: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.849570: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.849580: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_18_body_36107_rewritten\r\n2020-08-07 09:40:27.849590: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.849599: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.849607: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_28_body_38727_rewritten\r\n2020-08-07 09:40:27.849616: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.849624: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.849636: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_2_body_31915_grad_60746\r\n2020-08-07 09:40:27.849646: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.849656: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.849664: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_4_cond_32438_grad_60260\r\n2020-08-07 09:40:27.849675: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.849684: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.849693: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_32_body_39775_rewritten\r\n2020-08-07 09:40:27.849702: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.849711: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.849721: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_24_body_37679_grad_53461\r\n2020-08-07 09:40:27.849732: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.849742: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.849751: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_8_body_33487_rewritten\r\n2020-08-07 09:40:27.849761: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.849771: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.849782: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_6_body_32963_rewritten\r\n2020-08-07 09:40:27.849790: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.849799: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.849808: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_21_cond_36892_rewritten\r\n2020-08-07 09:40:27.849816: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.849827: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.849838: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_11_cond_34272_rewritten\r\n2020-08-07 09:40:27.849846: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.849855: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.849863: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_40_body_41871_grad_48164\r\n2020-08-07 09:40:27.849872: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.849881: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.849890: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_17_cond_35844_grad_55954\r\n2020-08-07 09:40:27.849901: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.849911: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.849920: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_1_cond_31652_grad_61253\r\n2020-08-07 09:40:27.849929: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.849939: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.849947: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_25_cond_37940_rewritten\r\n2020-08-07 09:40:27.849957: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.849967: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.849978: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_8_cond_33486_rewritten\r\n2020-08-07 09:40:27.849988: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.850000: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.850010: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_3_body_32177_grad_60415\r\n2020-08-07 09:40:27.850020: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.850030: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.850041: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_11_cond_34272_grad_57941\r\n2020-08-07 09:40:27.850049: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.850058: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.850068: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_10_body_34011_grad_58096\r\n2020-08-07 09:40:27.850077: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.850085: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.850094: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_14_cond_35058_grad_56948\r\n2020-08-07 09:40:27.850109: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.850120: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.850130: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_35_cond_40560_rewritten\r\n2020-08-07 09:40:27.850139: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.850148: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.850160: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_31_cond_39512_rewritten\r\n2020-08-07 09:40:27.850170: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.850181: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.850192: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_14_body_35059_rewritten\r\n2020-08-07 09:40:27.850202: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.850214: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.850223: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_17_body_35845_grad_55778\r\n2020-08-07 09:40:27.850232: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.850242: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.850251: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_28_cond_38726_grad_52313\r\n2020-08-07 09:40:27.850261: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.850269: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.850278: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_31_cond_39512_grad_51320\r\n2020-08-07 09:40:27.850288: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.01ms.\r\n2020-08-07 09:40:27.850296: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.850306: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_45_body_43181_grad_46509\r\n2020-08-07 09:40:27.850315: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.850326: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.850335: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_15_cond_35320_grad_56617\r\n2020-08-07 09:40:27.850345: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.850353: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.850362: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_36_body_40823_grad_49488\r\n2020-08-07 09:40:27.850371: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.850382: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.850390: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_44_body_42919_rewritten\r\n2020-08-07 09:40:27.850399: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.850408: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.850417: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_48_body_43967_grad_44362\r\n2020-08-07 09:40:27.850430: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.850439: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.850449: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_42_cond_42394_rewritten\r\n2020-08-07 09:40:27.850458: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.850466: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.850475: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_38_cond_41346_rewritten\r\n2020-08-07 09:40:27.850484: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.850494: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.850504: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_47_body_43705_rewritten\r\n2020-08-07 09:40:27.850512: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.850523: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.850545: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_44_cond_42918_grad_47016\r\n2020-08-07 09:40:27.850558: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.850633: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.850670: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_13_body_34797_grad_57103\r\n2020-08-07 09:40:27.850701: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.850715: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.850731: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_10_cond_34010_grad_58272\r\n2020-08-07 09:40:27.850750: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.850760: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.850796: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_1_body_31653_rewritten\r\n2020-08-07 09:40:27.850812: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.850833: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.850850: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_27_body_38465_rewritten\r\n2020-08-07 09:40:27.850862: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.850879: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.850891: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_32_cond_39774_rewritten\r\n2020-08-07 09:40:27.850902: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.850918: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.850927: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_6_body_32963_grad_59420\r\n2020-08-07 09:40:27.850939: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.850950: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.850962: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_4_cond_32438_rewritten\r\n2020-08-07 09:40:27.850971: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.850982: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.851007: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_9_body_33749_rewritten\r\n2020-08-07 09:40:27.851017: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.851040: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.851065: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_25_cond_37940_grad_53306\r\n2020-08-07 09:40:27.851076: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.851091: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.851108: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_9_body_33749_grad_58427\r\n2020-08-07 09:40:27.851129: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.003ms.\r\n2020-08-07 09:40:27.851141: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.851159: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_33_body_40037_grad_50481\r\n2020-08-07 09:40:27.851171: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.003ms.\r\n2020-08-07 09:40:27.851181: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.851193: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_5_body_32701_grad_59753\r\n2020-08-07 09:40:27.851205: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.851218: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.851237: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_48_cond_43966_rewritten\r\n2020-08-07 09:40:27.851248: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.851270: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.851280: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_30_body_39251_grad_51475\r\n2020-08-07 09:40:27.851294: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.003ms.\r\n2020-08-07 09:40:27.851312: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.851330: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_34_cond_40298_rewritten\r\n2020-08-07 09:40:27.851407: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.851440: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.851475: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_33_cond_40036_grad_50657\r\n2020-08-07 09:40:27.851498: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.851508: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.851528: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_2_cond_31914_grad_60922\r\n2020-08-07 09:40:27.851547: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.851564: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.851577: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_16_body_35583_rewritten\r\n2020-08-07 09:40:27.851605: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.851616: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.851656: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_24_cond_37678_grad_53637\r\n2020-08-07 09:40:27.851666: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.851675: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.851684: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_25_body_37941_grad_53130\r\n2020-08-07 09:40:27.851693: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.851701: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.851710: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_17_cond_35844_rewritten\r\n2020-08-07 09:40:27.851719: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.851728: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.851736: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_2_cond_31914_rewritten\r\n2020-08-07 09:40:27.851745: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.003ms.\r\n2020-08-07 09:40:27.851753: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.851762: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_33_body_40037_rewritten\r\n2020-08-07 09:40:27.851773: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.851783: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.851794: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_36_cond_40822_rewritten\r\n2020-08-07 09:40:27.851805: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.851816: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.851825: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_23_cond_37416_rewritten\r\n2020-08-07 09:40:27.851834: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.851844: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.851854: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_17_body_35845_rewritten\r\n2020-08-07 09:40:27.851864: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.851875: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.851883: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_32_cond_39774_grad_50988\r\n2020-08-07 09:40:27.851892: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.851900: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.851909: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_35_body_40561_rewritten\r\n2020-08-07 09:40:27.851920: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.851931: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.851941: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_6_cond_32962_rewritten\r\n2020-08-07 09:40:27.851951: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.851960: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.851970: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_35_cond_40560_grad_49995\r\n2020-08-07 09:40:27.851980: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.851991: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.852001: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_37_cond_41084_grad_49333\r\n2020-08-07 09:40:27.852010: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.852018: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852027: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_7_body_33225_rewritten\r\n2020-08-07 09:40:27.852035: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.852046: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.852056: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_45_body_43181_rewritten\r\n2020-08-07 09:40:27.852066: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852076: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.852086: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_24_body_37679_rewritten\r\n2020-08-07 09:40:27.852101: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852112: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852123: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_43_body_42657_rewritten\r\n2020-08-07 09:40:27.852133: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852144: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.852154: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_48_body_43967_rewritten\r\n2020-08-07 09:40:27.852164: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.852175: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.852185: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_25_body_37941_rewritten\r\n2020-08-07 09:40:27.852196: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852205: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.852213: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_46_cond_43442_grad_46324\r\n2020-08-07 09:40:27.852224: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852233: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.852241: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_cond_31385_grad_61584\r\n2020-08-07 09:40:27.852250: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852258: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.852267: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_8_body_33487_grad_58758\r\n2020-08-07 09:40:27.852276: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.852286: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.852294: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_28_body_38727_grad_52137\r\n2020-08-07 09:40:27.852304: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852313: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852321: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_21_body_36893_grad_54454\r\n2020-08-07 09:40:27.852330: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.852340: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.852348: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_cond_31385_rewritten\r\n2020-08-07 09:40:27.852359: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852370: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.852380: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_1_body_31653_grad_61077\r\n2020-08-07 09:40:27.852389: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852397: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.852406: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_12_cond_34534_rewritten\r\n2020-08-07 09:40:27.852414: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852423: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852431: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_32_body_39775_grad_50812\r\n2020-08-07 09:40:27.852440: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852450: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.852459: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_46_body_43443_grad_46148\r\n2020-08-07 09:40:27.852469: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852478: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.852486: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_7_cond_33224_rewritten\r\n2020-08-07 09:40:27.852497: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.852505: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.852514: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_body_31386_grad_61408\r\n2020-08-07 09:40:27.852523: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852531: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.852541: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_29_body_38989_grad_51806\r\n2020-08-07 09:40:27.852550: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852559: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.852567: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_44_cond_42918_rewritten\r\n2020-08-07 09:40:27.852579: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.852589: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.852599: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_19_body_36369_rewritten\r\n2020-08-07 09:40:27.852610: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.852619: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.852627: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_20_cond_36630_grad_54961\r\n2020-08-07 09:40:27.852637: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852645: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852654: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_29_cond_38988_rewritten\r\n2020-08-07 09:40:27.852663: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852672: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.852680: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_27_body_38465_grad_52468\r\n2020-08-07 09:40:27.852689: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852701: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.852710: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_26_body_38203_grad_52799\r\n2020-08-07 09:40:27.852719: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852727: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852736: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_1_cond_31652_rewritten\r\n2020-08-07 09:40:27.852744: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852753: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852763: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_35_body_40561_grad_49819\r\n2020-08-07 09:40:27.852772: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852782: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852791: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_10_cond_34010_rewritten\r\n2020-08-07 09:40:27.852801: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852811: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.852819: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_16_cond_35582_grad_56285\r\n2020-08-07 09:40:27.852828: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852837: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.852847: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_22_cond_37154_grad_54299\r\n2020-08-07 09:40:27.852856: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852866: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.852876: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_14_body_35059_grad_56772\r\n2020-08-07 09:40:27.852886: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852896: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.852904: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_8_cond_33486_grad_58934\r\n2020-08-07 09:40:27.852914: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.852922: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.852932: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_2_body_31915_rewritten\r\n2020-08-07 09:40:27.852941: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852952: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.852960: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_3_cond_32176_grad_60591\r\n2020-08-07 09:40:27.852969: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.852979: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.852988: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_23_body_37417_grad_53792\r\n2020-08-07 09:40:27.852997: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853007: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.853016: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_26_body_38203_rewritten\r\n2020-08-07 09:40:27.853025: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853034: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853042: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_16_body_35583_grad_56109\r\n2020-08-07 09:40:27.853053: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.853064: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.853074: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_16_cond_35582_rewritten\r\n2020-08-07 09:40:27.853083: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853091: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.853106: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_18_cond_36106_grad_55623\r\n2020-08-07 09:40:27.853116: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853127: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.853137: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_10_body_34011_rewritten\r\n2020-08-07 09:40:27.853148: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853156: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.853165: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_body_31386_rewritten\r\n2020-08-07 09:40:27.853173: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.853182: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853193: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_26_cond_38202_rewritten\r\n2020-08-07 09:40:27.853204: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853214: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.853223: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_30_cond_39250_grad_51651\r\n2020-08-07 09:40:27.853234: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.853243: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.853254: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_30_cond_39250_rewritten\r\n2020-08-07 09:40:27.853265: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853274: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.853283: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_12_cond_34534_grad_57610\r\n2020-08-07 09:40:27.853292: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853301: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853310: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_44_body_42919_grad_46840\r\n2020-08-07 09:40:27.853318: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853327: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.853335: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_24_cond_37678_rewritten\r\n2020-08-07 09:40:27.853344: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853353: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853361: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_38_cond_41346_grad_49002\r\n2020-08-07 09:40:27.853370: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853378: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.853386: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_18_cond_36106_rewritten\r\n2020-08-07 09:40:27.853395: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853404: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.853412: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_27_cond_38464_grad_52644\r\n2020-08-07 09:40:27.853421: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853429: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.853438: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_4_body_32439_rewritten\r\n2020-08-07 09:40:27.853446: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.853455: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853466: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_39_body_41609_rewritten\r\n2020-08-07 09:40:27.853475: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853483: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.853492: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_19_cond_36368_rewritten\r\n2020-08-07 09:40:27.853500: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853509: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853519: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_42_cond_42394_grad_47678\r\n2020-08-07 09:40:27.853528: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853536: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.853546: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_38_body_41347_rewritten\r\n2020-08-07 09:40:27.853554: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.853564: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.853573: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_7_cond_33224_grad_59265\r\n2020-08-07 09:40:27.853584: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853594: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.853603: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_27_cond_38464_rewritten\r\n2020-08-07 09:40:27.853613: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853621: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.853631: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_11_body_34273_grad_57765\r\n2020-08-07 09:40:27.853639: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853649: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.853658: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_13_body_34797_rewritten\r\n2020-08-07 09:40:27.853667: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853676: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853685: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_28_cond_38726_rewritten\r\n2020-08-07 09:40:27.853694: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853704: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.853715: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_41_body_42133_grad_47833\r\n2020-08-07 09:40:27.853725: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853736: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.853747: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_39_cond_41608_rewritten\r\n2020-08-07 09:40:27.853755: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.853765: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.853774: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_33_cond_40036_rewritten\r\n2020-08-07 09:40:27.853786: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853796: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.853807: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_46_body_43443_rewritten\r\n2020-08-07 09:40:27.853818: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853829: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.853839: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_18_body_36107_grad_55447\r\n2020-08-07 09:40:27.853850: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853860: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.853869: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_14_cond_35058_rewritten\r\n2020-08-07 09:40:27.853878: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853887: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.853896: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_29_body_38989_rewritten\r\n2020-08-07 09:40:27.853905: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.853915: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.853926: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_30_body_39251_rewritten\r\n2020-08-07 09:40:27.853936: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.853944: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.853955: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_39_cond_41608_grad_48671\r\n2020-08-07 09:40:27.853965: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.853976: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.853984: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_42_body_42395_grad_47502\r\n2020-08-07 09:40:27.853996: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854007: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.854017: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_23_cond_37416_grad_53968\r\n2020-08-07 09:40:27.854026: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.854034: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.854044: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_40_cond_41870_rewritten\r\n2020-08-07 09:40:27.854055: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854065: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.854075: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_5_cond_32700_grad_59929\r\n2020-08-07 09:40:27.854084: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854093: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854104: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_47_cond_43704_grad_45484\r\n2020-08-07 09:40:27.854115: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854125: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854135: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_41_cond_42132_grad_48009\r\n2020-08-07 09:40:27.854145: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.854154: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854163: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_45_cond_43180_rewritten\r\n2020-08-07 09:40:27.854172: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854181: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.854191: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_34_cond_40298_grad_50326\r\n2020-08-07 09:40:27.854200: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854209: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.854220: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_45_cond_43180_grad_46685\r\n2020-08-07 09:40:27.854230: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854240: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854250: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_31_body_39513_grad_51144\r\n2020-08-07 09:40:27.854259: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854269: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.854277: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_6_cond_32962_grad_59596\r\n2020-08-07 09:40:27.854287: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854296: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.854307: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_9_cond_33748_grad_58603\r\n2020-08-07 09:40:27.854315: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854331: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.854342: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_12_body_34535_grad_57434\r\n2020-08-07 09:40:27.854355: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854364: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.854374: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_22_cond_37154_rewritten\r\n2020-08-07 09:40:27.854384: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854393: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854402: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_22_body_37155_rewritten\r\n2020-08-07 09:40:27.854411: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854420: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.854430: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_13_cond_34796_grad_57279\r\n2020-08-07 09:40:27.854438: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854448: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.854457: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_26_cond_38202_grad_52975\r\n2020-08-07 09:40:27.854467: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854476: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.854486: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_3_body_32177_rewritten\r\n2020-08-07 09:40:27.854494: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854504: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854513: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_39_body_41609_grad_48495\r\n2020-08-07 09:40:27.854522: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854530: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.854540: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_43_body_42657_grad_47171\r\n2020-08-07 09:40:27.854549: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854559: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.854568: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_37_body_41085_grad_49157\r\n2020-08-07 09:40:27.854578: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854588: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.854597: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_40_cond_41870_grad_48340\r\n2020-08-07 09:40:27.854605: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854614: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.854623: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_46_cond_43442_rewritten\r\n2020-08-07 09:40:27.854634: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.854642: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854651: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_5_body_32701_rewritten\r\n2020-08-07 09:40:27.854660: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854668: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854679: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_34_body_40299_rewritten\r\n2020-08-07 09:40:27.854689: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854699: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854715: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_36_body_40823_rewritten\r\n2020-08-07 09:40:27.854725: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854734: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.854742: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_4_body_32439_grad_60084\r\n2020-08-07 09:40:27.854752: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.854761: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854769: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_48_cond_43966_grad_44538\r\n2020-08-07 09:40:27.854778: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854789: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.854799: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_47_cond_43704_rewritten\r\n2020-08-07 09:40:27.854808: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854821: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.854831: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_43_cond_42656_grad_47347\r\n2020-08-07 09:40:27.854841: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854854: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854864: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_20_body_36631_rewritten\r\n2020-08-07 09:40:27.854873: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854881: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854890: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_34_body_40299_grad_50150\r\n2020-08-07 09:40:27.854899: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.854907: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.854916: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_43_cond_42656_rewritten\r\n2020-08-07 09:40:27.854928: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854940: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.854949: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_5_cond_32700_rewritten\r\n2020-08-07 09:40:27.854959: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.854971: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.854982: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_41_body_42133_rewritten\r\n2020-08-07 09:40:27.854992: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.855000: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.855009: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_19_cond_36368_grad_55292\r\n2020-08-07 09:40:27.855018: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.855026: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.855035: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_37_cond_41084_rewritten\r\n2020-08-07 09:40:27.855047: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.855056: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.855083: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_40_body_41871_rewritten\r\n2020-08-07 09:40:27.855094: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.855110: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.855121: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_22_body_37155_grad_54123\r\n2020-08-07 09:40:27.855132: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.855147: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.855159: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_20_cond_36630_rewritten\r\n2020-08-07 09:40:27.855170: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.855181: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.855192: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_29_cond_38988_grad_51982\r\n2020-08-07 09:40:27.855203: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.855213: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.855224: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_15_cond_35320_rewritten\r\n2020-08-07 09:40:27.855235: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.855244: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.855252: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_9_cond_33748_rewritten\r\n2020-08-07 09:40:27.855262: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.855271: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.855281: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_36_cond_40822_grad_49664\r\n2020-08-07 09:40:27.855289: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.855298: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.855307: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_41_cond_42132_rewritten\r\n2020-08-07 09:40:27.855318: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.855329: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.855340: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_42_body_42395_rewritten\r\n2020-08-07 09:40:27.855351: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-08-07 09:40:27.855362: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-07 09:40:27.855371: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: rnn__decoder_gru_while_3_cond_32176_rewritten\r\n2020-08-07 09:40:27.855379: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-07 09:40:27.855389: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\nTraceback (most recent call last):\r\n  File \"convert2savedmodel.py\", line 280, in <module>\r\n    tflite_model = converter.convert()\r\n  File \"/share/nishome/19930072_0/miniconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\", line 1076, in convert\r\n    return super(TFLiteConverterV2, self).convert()\r\n  File \"/share/nishome/19930072_0/miniconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\", line 878, in convert\r\n    self._funcs[0], lower_control_flow=False))\r\n  File \"/share/nishome/19930072_0/miniconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow/python/framework/convert_to_constants.py\", line 1103, in convert_variables_to_constants_v2_as_graph\r\n    aggressive_inlining=aggressive_inlining)\r\n  File \"/share/nishome/19930072_0/miniconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow/python/framework/convert_to_constants.py\", line 804, in __init__\r\n    self._build_tensor_data()\r\n  File \"/share/nishome/19930072_0/miniconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow/python/framework/convert_to_constants.py\", line 823, in _build_tensor_data\r\n    data = val_tensor.numpy()\r\n  File \"/share/nishome/19930072_0/miniconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1063, in numpy\r\n    maybe_arr = self._numpy()  # pylint: disable=protected-access\r\n  File \"/share/nishome/19930072_0/miniconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1031, in _numpy\r\n    six.raise_from(core._status_to_exception(e.code, e.message), None)  # pylint: disable=protected-access\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot convert a Tensor of dtype resource to a NumPy array.\r\n```\r\n\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n```\r\n@tf.function\r\ndef train_step(img_tensor, target):\r\n    loss = 0\r\n\r\n    #\u521d\u59cb\u5316\u6bcf\u4e2a\u6279\u6b21\u7684\u9690\u85cf\u72b6\u6001\u56e0\u4e3a\u56fe\u50cf\u4e0e\u56fe\u50cf\u7684\u5b57\u5e55\u4e4b\u95f4\u6ca1\u6709\u5173\u7cfb\r\n    hidden = decoder.reset_states(batch_size=target.shape[0])\r\n\r\n    dec_input = tf.expand_dims([tokenizer.word_index['<start>']] * target.shape[0], 1)\r\n\r\n    with tf.GradientTape() as tape:\r\n        features = encoder(img_tensor)\r\n\r\n        for i in  range(1, target.shape[1]):\r\n            #\u901a\u8fc7\u89e3\u7801\u5668\u4f20\u9012\u7279\u5f81\r\n            predictions, hidden, _ = decoder(dec_input, features, hidden)\r\n\r\n            loss += loss_function(target[:, i], predictions)\r\n\r\n            # \u4f7f\u7528 teacher forcing\r\n            dec_input = tf.expand_dims(target[:, i], 1)\r\n\r\n    total_loss = (loss / int(target.shape[1]))\r\n\r\n    trainable_variables = encoder.trainable_variables + decoder.trainable_variables\r\n\r\n    gradients = tape.gradient(loss, trainable_variables)\r\n\r\n    optimizer.apply_gradients(zip(gradients, trainable_variables))\r\n\r\n    return loss, total_loss\r\n```\r\n\r\n\r\n**full code**\r\n\r\n```\r\nclass BahdanauAttention(tf.keras.Model):\r\n    def __init__(self, utils):\r\n        super(BahdanauAttention, self).__init__()\r\n        self.W1 = tf.keras.layers.Dense(utils)\r\n        self.W2 = tf.keras.layers.Dense(utils)\r\n        self.V = tf.keras.layers.Dense(1)\r\n\r\n    def call(self, features, hidden):\r\n        # features(CNN_encoder output) shape == (batch_size, 64, embedding_dim)\r\n\r\n        # hidden shape == (batch_size, hidden_size)\r\n        # hidden_with_time_axis shape == (batch_size, 1, hidden_size)\r\n        hidden_with_time_axis_shape = tf.expand_dims(hidden, 1)\r\n\r\n        # score shape == (batch_size, 64, hidden_size)\r\n        score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis_shape))\r\n\r\n        # attention_weights shape == (batch_size, 64, 1)\r\n        # you get 1 at the last axis because you are applying score to self.V\r\n        attention_weights = tf.nn.softmax(self.V(score), axis=1)\r\n\r\n        # context_vector shape after sum == (batch_size, hidden_size)\r\n        context_vector = attention_weights * features\r\n        context_vector = tf.reduce_sum(context_vector, axis=1)\r\n\r\n        return context_vector, attention_weights\r\n\r\nclass CNN_Encoder(tf.keras.Model):\r\n    #\u7531\u4e8e\u60a8\u5df2\u7ecf\u63d0\u53d6\u4e86\u7279\u5f81\u5e76\u4f7f\u7528pickle\u8fdb\u884c\u4e86\u8f6c\u50a8\r\n    #\u8be5\u7f16\u7801\u5668\u901a\u8fc7\u5b8c\u5168\u8fde\u63a5\u7684\u5c42\u4f20\u9012\u8fd9\u4e9b\u7279\u5f81\r\n    def __init__(self, embedding):\r\n        super(CNN_Encoder, self).__init__()\r\n        # shape after fc == (batch_size, 64, embedding_dim)\r\n        self.fc = tf.keras.layers.Dense(embedding_dim)\r\n\r\n    def call(self, x):\r\n        x = self.fc(x)\r\n        x = tf.nn.relu(x)\r\n        return x\r\n\r\nclass RNN_Decoder(tf.keras.Model):\r\n    def __init__(self, embedding_dim, units, vocab_size):\r\n        super(RNN_Decoder, self).__init__()\r\n        self.units = units\r\n\r\n        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\r\n        self.gru = tf.keras.layers.GRU(self.units,\r\n                                       return_sequences=True,\r\n                                       return_state=True,\r\n                                       recurrent_initializer='glorot_uniform')\r\n        self.fc1 = tf.keras.layers.Dense(self.units)\r\n        self.fc2 = tf.keras.layers.Dense(vocab_size)\r\n\r\n        self.attention = BahdanauAttention(self.units)\r\n\r\n    def call(self, x , features, hidden):\r\n        #\u5c06\u6ce8\u610f\u529b\u5b9a\u4e49\u4e3a\u4e00\u4e2a\u5355\u72ec\u7684\u6a21\u578b\r\n        context_vector, attention_weights = self.attention(features, hidden)\r\n\r\n        #x shape after passing through embedding == (batch_size, 1, embedding_dim)\r\n        x = self.embedding(x)\r\n\r\n        #x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\r\n        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\r\n\r\n        #\u5c06concated\u540e\u7684\u7684\u5411\u91cf\u4f20\u9012\u7ed9GRU\r\n        output, state = self.gru(x)\r\n\r\n        #shape == (batch_size, max_length, hidden_size)\r\n        x = self.fc1(output)\r\n\r\n        #x shape == (batch_size, max_length, hidden_size)\r\n        x = tf.reshape(x, (-1, x.shape[2]))\r\n\r\n        # output shape == (batch_size * max_length, vocab)\r\n        x = self.fc2(x)\r\n\r\n        return x, state, attention_weights\r\n\r\n    def reset_states(self, batch_size):\r\n        return tf.zeros((batch_size, self.units))\r\n\r\nencoder = CNN_Encoder(embedding_dim)\r\ndecoder = RNN_Decoder(embedding_dim, units, vocab_size)\r\n\r\noptimizer = tf.keras.optimizers.Adam()\r\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy(\r\n    from_logits=True, reduction='none'\r\n)\r\ndef loss_function(real, pred):\r\n    mask = tf.math.logical_not(tf.math.equal(real, 0))\r\n    loss_ = loss_object(real, pred)\r\n\r\n    mask = tf.cast(mask, dtype=loss_.dtype)\r\n    loss_ *= mask\r\n\r\n    return tf.reduce_mean(loss_)\r\n\r\n#CheckPoint\r\n\r\ncheckpoint_path = './checkpoints/train'\r\nckpt = tf.train.Checkpoint(encoder=encoder,\r\n                           decoder=decoder,\r\n                           optimizer = optimizer)\r\nckpt_manage = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\r\n\r\nstart_epoch = 0\r\nif ckpt_manage.latest_checkpoint:\r\n    start_epoch = int(ckpt_manage.latest_checkpoint.split('-')[-1])\r\n    print(start_epoch)\r\n    #\u6062\u590dcheckpoint_path\u4e2d\u7684\u6700\u65b0\u68c0\u67e5\u70b9\r\n    ckpt.restore(ckpt_manage.latest_checkpoint)\r\nBATCH_SIZE = 128\r\nBUFFER_SIZE = 1000\r\nembedding_dim = 256\r\nunits = 512\r\nvocab_size = top_k + 1\r\nnum_steps = len(img_name_train) // BATCH_SIZE\r\n# \u4eceInceptionV3\u63d0\u53d6\u7684\u5411\u91cf\u7684\u5f62\u72b6\u4e3a(64\uff0c2048)\r\n# \u8fd9\u4e24\u4e2a\u53d8\u91cf\u8868\u793a\u77e2\u91cf\u5f62\u72b6\r\nfeatures_shape = 2048\r\nattention_features_shape = 64\r\n\r\n```\r\n\r\n\r\n\r\n", "comments": ["For reference, you can look into these links for possible solutions:\r\n1. https://github.com/tensorflow/tensorflow/issues/37441\r\n2. https://github.com/tensorflow/tensorflow/issues/42113,\r\n3. https://stackoverflow.com/a/62161525/2352424", "@DavidInWuhanChina \r\n\r\nIs this still an issue?\r\nPlease, close this thread if your issue was resolved. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 42112, "title": "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot convert a Tensor of dtype resource to a NumPy array.", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (or github SHA if from source):\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\n# Copy and paste here the exact command\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\n# Copy and paste the output here.\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\n# Put link here or attach to the issue.\r\n```\r\n\r\n**Failure details**\r\nIf the conversion is successful, but the generated model is wrong,\r\nstate what is wrong:\r\n- Producing wrong results and/or decrease in accuracy\r\n- Producing correct results, but the model is slower than expected (model generated from old converter)\r\n\r\n\r\n**RNN conversion support**\r\nIf converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": []}, {"number": 42111, "title": "TensorFlow hangs forever in multinode training with NCCL and certain model (with SyncBatchNorm layers)", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 14.04 running in Docker container (host is 18.04)\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): 0.29.1-1.0\r\n- GCC/Compiler version (if compiling from source): 4.8.5\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: Various, e.g. Nvidia RTX 2080 Ti\r\n\r\n**Describe the current behavior**\r\nIn certain circumstances, TensorFlow appears to hang forever before starting training:\r\n- Multinode training using `MultiWorkerMirroredStrategy` (the bug does not appear when using one worker with multiple GPUs, or with one GPU).\r\n- `NCCL` communication (not 100% sure on this)\r\n- A specific model, which seems to require SyncBatchNorm layers interleaved with Conv2D layers\r\n\r\nThis seems to happen both on the Estimator and Keras frameworks - the output is slightly different but my guess is that it's the same bug.\r\n\r\nI've tried to test with tf-nightly, but unfortunately I've had difficulty getting the correct CUDA libraries for our particular setup and haven't been able to verify whether it is reproducible on tf-nightly. However, if you e.g. are unable to reproduce and would like me to take another look, please let me know.\r\n\r\n**Describe the expected behavior**\r\nTensorFlow should not hang forever. This toy model in particular finishes training in seconds, but when the bug is triggered, hangs for hours with no output.\r\n\r\n**Standalone code to reproduce the issue**\r\nPlease note that this code must be run with multiple workers to reproduce the issue, and the `TF_CONFIG` environment variable should be set correspondingly according to your specific setup.\r\n\r\nAs far as I can see, on Colab it is possible to have multiple _GPUs_ on one worker, but I'm not sure how to set it up with multiple _workers_ (with one GPU per worker). So I'm not sure if this problem can be reproduced on Colab. But if there is a way to use multiple workers, please point me at a guide and I can try to reproduce on Colab.\r\n\r\nEstimator code:\r\n```\r\nimport logging\r\nimport os\r\nimport shutil\r\nimport sys\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ndef setup_multi_node_training():\r\n    # IMPORTANT: SET UP TF_CONFIG FOR MULTINODE TRAINING HERE\r\n    os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\r\n    tf.config.set_soft_device_placement(True)\r\n    mirrored_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(tf.distribute.experimental.CollectiveCommunication.NCCL)\r\n    # Constructs the configuration\r\n    run_config = tf.estimator.RunConfig(\r\n        train_distribute=mirrored_strategy,\r\n    )\r\n    return run_config\r\n\r\ndef input_fn():\r\n    dataset = tf.data.Dataset.from_tensors([tf.random.normal(shape=[496, 496, 64])] * 3)\r\n    dataset = dataset.repeat()\r\n    return dataset\r\n\r\ndef batch_norm(x, is_training):\r\n    layer = tf.keras.layers.experimental.SyncBatchNormalization(axis=-1)\r\n    x_norm = layer(x, is_training)\r\n    with tf.control_dependencies(layer.get_updates_for(x)):\r\n        x_norm = tf.identity(x_norm)\r\n    return x_norm\r\n\r\ndef inference(features, is_training):\r\n    conv1 = tf.keras.layers.Conv2D(32, 3, padding=\"SAME\")(features)\r\n    conv1bn = batch_norm(conv1, is_training)\r\n    deconv1bn = batch_norm(conv1bn, is_training)\r\n    conv2 = tf.keras.layers.Conv2D(32, 3, padding=\"SAME\")(conv1bn)\r\n    conv2bn = batch_norm(conv2, is_training)\r\n    return tf.keras.layers.Concatenate()([conv1bn, deconv1bn, conv2bn])\r\n\r\ndef compute_loss(predictions, labels, is_training):\r\n    return tf.reduce_mean(predictions)\r\n\r\ndef model_fn(features, labels, mode):\r\n    global_step = tf.compat.v1.train.get_global_step()\r\n    is_training = mode == tf.estimator.ModeKeys.TRAIN\r\n\r\n    predictions = inference(features, is_training)\r\n    loss = compute_loss(predictions, labels, is_training)\r\n\r\n    optimizer = tf.compat.v1.train.GradientDescentOptimizer(1e-5)\r\n    train_op = optimizer.minimize(loss, global_step=global_step)\r\n\r\n    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\r\n\r\ndef main():\r\n    model_dir = \"/tmp/output\"\r\n    run_config_params = {\r\n        \"save_checkpoints_steps\": 100,\r\n        \"save_summary_steps\": 100,\r\n        \"log_step_count_steps\": 100,\r\n        \"tf_random_seed\": 0,\r\n        \"keep_checkpoint_max\": 1,\r\n        \"model_dir\": model_dir,\r\n    }\r\n    run_config = setup_multi_node_training().replace(**run_config_params)\r\n    estimator = tf.estimator.Estimator(model_fn=model_fn, config=run_config)\r\n\r\n    train_spec = tf.estimator.TrainSpec(input_fn=input_fn, max_steps=1000)\r\n\r\n    eval_spec = tf.estimator.EvalSpec(\r\n        input_fn=input_fn, steps=100, throttle_secs=0, start_delay_secs=0\r\n    )\r\n\r\n    print(\"Training and evaluating model...\")\r\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\nKeras code:\r\n```\r\nimport os\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\nclass MyModel(keras.Model):\r\n    def __init__(self, **kwargs):\r\n        super().__init__(name=\"my_model\", **kwargs)\r\n        self.conv1 = keras.layers.Conv2D(16, 3, padding=\"SAME\")\r\n        self.sbn1 = keras.layers.experimental.SyncBatchNormalization()\r\n        self.sbn2 = keras.layers.experimental.SyncBatchNormalization()\r\n        self.conv2 = keras.layers.Conv2D(32, 3, padding=\"SAME\")\r\n        self.sbn3 = keras.layers.experimental.SyncBatchNormalization()\r\n        self.concat = keras.layers.Concatenate()\r\n\r\n    def call(self, inputs, training=False):\r\n        conv1 = self.conv1(inputs)\r\n        conv1bn = self.sbn1(conv1, training)\r\n        conv1bn2 = self.sbn2(conv1bn, training)\r\n        conv2 = self.conv2(conv1bn)\r\n        conv2bn = self.sbn3(conv2, training)\r\n        return self.concat([conv1bn, conv1bn2, conv2bn])\r\n\r\ndef get_dataset():\r\n    dataset = tf.data.Dataset.from_tensors(\r\n        [tf.random.normal(shape=[496, 496, 64])] * 3\r\n    )\r\n    dataset = dataset.repeat()\r\n    dataset = tf.data.Dataset.zip((dataset, dataset))\r\n    return dataset\r\n\r\ndef main():\r\n    model_dir = \"/tmp/keras_example\"\r\n\r\n    # IMPORTANT: SET UP TF_CONFIG FOR MULTINODE TRAINING HERE\r\n    os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\r\n    tf.config.set_soft_device_placement(True)\r\n    mirrored_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(tf.distribute.experimental.CollectiveCommunication.NCCL)\r\n\r\n    # Create dataset\r\n    train_dataset = get_dataset()\r\n\r\n    with strategy.scope():\r\n        model = MyModel()\r\n\r\n        model.compile(\r\n            optimizer=keras.optimizers.Adam(),\r\n            loss=keras.losses.MeanSquaredError(),\r\n        )\r\n\r\n    model.fit(x=train_dataset, steps_per_epoch=100, epochs=1)\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\n**Other info / logs**\r\nThere are three log files: [Estimator log](https://github.com/tensorflow/tensorflow/files/5038681/estimator_log_1.txt), [Estimator log with more debug output](https://drive.google.com/file/d/1-4abJDs1QWlHgFkFzbW6PGjZ4hXoLbpf/view?usp=sharing) (`TF_CPP_MIN_LOG_LEVEL=0` and `TF_CPP_MIN_VLOG_LEVEL=2`) (note this is a Google Drive link as the file is >20 MB), [Keras log](https://github.com/tensorflow/tensorflow/files/5038696/keras_log_1.txt). I had trouble getting the Keras log with debug output so I haven't included that but will update if I can get it.\r\n\r\nNote that the second Estimator log is gigantic, but most of the log is output in about a minute, and then the last hundred lines or so seem to be of the job actually hanging until it is killed after about 15 minutes, with this output repeated:\r\n```\r\n0: 2020-08-06 00:22:30.510236: I external/org_tensorflow/tensorflow/core/framework/model.cc:892] Starting optimization of tunable parameters with HillClimb\r\n0: 2020-08-06 00:22:30.510355: I external/org_tensorflow/tensorflow/core/framework/model.cc:943] Number of tunable parameters: 0\r\n0: 2020-08-06 00:22:30.510377: I external/org_tensorflow/tensorflow/core/kernels/data/model_dataset_op.cc:191] Waiting for 60000 ms.\r\n```\r\nIt seems somewhat bizarre that if there are 0 parameters to tune, TensorFlow should still try to repeatedly optimize the nonexistent tunable parameters. I wonder if there's some issue with the `model.cc` code not properly signaling that it has finished, if there are no tunable parameters? I see that in line 1485-1487 of `core/framework/model.cc`, there is some code that seems to be doing something with the mutex and notifying, but this block would be entirely skipped if there are no tunable parameters, and that might contribute to the infinite loop here.\r\n\r\nThanks so much!", "comments": ["I have same problem with you", "Hi @MinasTyuru, confirming that I was able to reproduce this behavior with the Keras example in TF2.2. I ran some other experiments to sanity check, and the following completed training successfully:\r\nMWMS, one machine,`CollectiveCommunication.AUTO`.\r\nMWMS, one machine,`CollectiveCommunication.NCCL` \r\nMWMS, two machines,`CollectiveCommunication.AUTO` \r\n\r\nI tried in nightly as well, and the training started and it seemed promising. But then froze at 3 steps.\r\n", "Thanks Nikita! One minor note, I was never able to get the logs for the Keras version to work. For some reason turning on verbose logging causes it to segfault. I didn't submit a separate issue as I thought maybe it was related to this issue. But the Estimator version should work if the Keras version doesn't.", "@nikitamaia Hi Nikita, just wanted to check if there's been any movement on this and if there's anything I can do to help? This would unblock substantial performance improvements for us.\r\n\r\nAlso wanted to say thank you again for all your work on the various issues I've submitted - they would have been very difficult to resolve by ourselves and it unblocked a lot of work. We really appreciate it.", "Absolutely! Very happy to help. And thank you for always submitting issues with reproducible code, logs, and other important info : )\r\n\r\nThanks for the reminder, this issue is currently being investigated and the sync batch norm layers do seem to be the culprit. I will update this thread with some more information shortly.", "@nikitamaia Were you able to get any more information on this? We may be able to do some investigation on our end if we have an idea of e.g. which part of the code is hanging.", "Hi @MinasTyuru, we were able to identify the root cause as the SyncBatchNorm layers that don't have control dependencies. The SyncBatchNorm layer launches NCCLAllRecduce in every step, so it is possible the two layers launch NCCLAllReduce on different machines in different order, leading to the program hanging. So far it seems like adding in the control deps is the best option but we're still considering the effects that might have on other use cases.\r\n\r\n", "@nikitamaia Oh, fantastic! For the time being, I think adding control dependencies is a totally fine workaround for us.\r\n\r\nJust to be clear, the issue here is that there are three SyncBatchNorm operations, whose outputs are then concatenated into a big tensor, but they can be executed in any order, is that correct? So therefore to resolve this, we would force an ordering something like this:\r\n\r\n```\r\ndef inference(features, is_training):\r\n    conv1 = tf.keras.layers.Conv2D(32, 3, padding=\"SAME\")(features)\r\n    conv1bn = batch_norm(conv1, is_training)\r\n    with tf.control_dependencies([conv1bn]):\r\n        deconv1bn = batch_norm(conv1bn, is_training)\r\n    conv2 = tf.keras.layers.Conv2D(32, 3, padding=\"SAME\")(conv1bn)\r\n    with tf.control_dependencies([deconv1bn]):\r\n        conv2bn = batch_norm(conv2, is_training)\r\n    return tf.keras.layers.Concatenate()([conv1bn, deconv1bn, conv2bn]) # must execute in this order\r\n```\r\n\r\nIs that right?", "@MinasTyuru unfortunately I think that was the first thing we tried, but it still didn't solve the problem. It seems that only adds the control deps on the forward pass, and then out of order NCCL launches happen on the backward pass and the program hangs. Let me know if you see otherwise, but this is why we were looking into a more longterm fix.", "I'm currently trying to reproduce on our end - I had a few issues so might take a little longer than expected. I did see jobs that seem to start training but have NaN loss, but I think that might be expected since the input is all-ones - I'll try changing it to random.\r\n\r\nI was thinking that something like this might work for the dependencies. Assuming Grappler doesn't just prune this operation out, it should theoretically force an ordering on both the forward and backward pass, because `x` actually depends on `y` numerically and therefore the gradient of `y` should wait for the gradient of `x` to be calculated.\r\n\r\n```\r\ndef dependency(x, y):\r\n    \"\"\"Returns an instance of x that nominally depends on y (but in reality\r\n    is identical to x).\r\n    \"\"\"\r\n    return x + 0 * tf.reduce_mean(y)\r\n\r\ndef inference(features, is_training):\r\n    conv1 = tf.keras.layers.Conv2D(32, 3, padding=\"SAME\")(features)\r\n    conv1bn = batch_norm(conv1, is_training)\r\n    deconv1bn = batch_norm(conv1bn, is_training)\r\n    # Create fake dependency on deconv1bn to enforce ordering\r\n    conv1bn = dependency(conv1bn, deconv1bn)\r\n    conv2 = tf.keras.layers.Conv2D(32, 3, padding=\"SAME\")(conv1bn)\r\n    conv2bn = batch_norm(conv2, is_training)\r\n    return tf.keras.layers.Concatenate()([conv1bn, deconv1bn, conv2bn])\r\n```", "@nikitamaia The workaround you suggested, i.e.:\r\n```\r\ndef inference(features, is_training):\r\n    conv1 = tf.keras.layers.Conv2D(32, 3, padding=\"SAME\")(features)\r\n    conv1bn = batch_norm(conv1, is_training)\r\n    deconv1bn = batch_norm(conv1bn, is_training)\r\n    with tf.control_dependencies([deconv1bn]):\r\n        conv2 = tf.keras.layers.Conv2D(32, 3, padding=\"SAME\")(conv1bn)\r\n    conv2bn = batch_norm(conv2, is_training)\r\n    return tf.keras.layers.Concatenate()([conv1bn, deconv1bn, conv2bn])\r\n```\r\n\r\nseems to work on my end - training completes without any issues. And the one in the comment above also works. I also verified that without the workaround, training still hangs. Thanks!", "We're also working on a workaround in SyncBatchNorm layer, which should be included in 2.4. Meanwhile, a complete fix is on track too.", "A workaround is submitted and will be included in 2.4.", "@crccw Thanks so much, Ran!", "@ MinasTyuru  Closing the issue since it is working with workaround mentioned above. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42111\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42111\">No</a>\n", "> deconv1bn\r\n\r\nIs tf.control_dependencies with tf.function really make backward with tape.gradient() use the same order that is expected? sorry to bother, but i'm face the same but more complexed situation."]}, {"number": 42110, "title": "Fix a conv3d dgrad type issue", "body": "This PR is to fix a conv3d dgrad type issue.\r\n\r\nBefore this PR, we use the `context->input(0).dtype()` to infer the dtype of the dgrad conv (mainly for creating the param key for autotuning). This is fine for the Conv3DBackpropInput, which has `Input(\"input: T\")` as input(0). However, for the Conv3DBackpropInputV2, the input(0) turns to be `Input(\"input_sizes: Tshape\")`. So, to fix this, we use `context->input(2).dtype()`, which is `Input(\"out_backprop: T\")` and is shared by Conv3DBackpropInput and Conv3DBackpropInputV2.\r\n\r\nfyi @nluehr ", "comments": ["Not sure if there is a simple way to add a test for this. But I think the bug is clear and only affect the perf (I guess that is why it was not captured before).\r\nBasically, this bug affects the autotuning process of conv3d dgrad. If we check nn_ops.cc, we can see that:\r\n```c++\r\nREGISTER_OP(\"Conv3DBackpropInput\")\r\n    .Input(\"input: T\")\r\n    .Input(\"filter: T\")\r\n    .Input(\"out_backprop: T\")\r\n    .Output(\"output: T\")\r\n    .Attr(\"T: {half, float, double}\")\r\n    .Attr(\"strides: list(int) >= 5\")\r\n    .Attr(GetPaddingAttrString())\r\n    .Deprecated(10, \"Use Conv3DBackpropInputV2\")\r\n    .Attr(\"dilations: list(int) = [1, 1, 1, 1, 1]\")\r\n    .SetShapeFn([](InferenceContext* c) {\r\n      return UnchangedShapeWithRank(c, 5);\r\n    });\r\n...\r\nREGISTER_OP(\"Conv3DBackpropInputV2\")\r\n    .Input(\"input_sizes: Tshape\")\r\n    .Input(\"filter: T\")\r\n    .Input(\"out_backprop: T\")\r\n    .Output(\"output: T\")\r\n    .Attr(\"T: {half, bfloat16, float, double}\")\r\n    .Attr(\"strides: list(int) >= 5\")\r\n    .Attr(GetPaddingAttrString())\r\n    .Attr(GetConvnet3dDataFormatAttrString())\r\n    .Attr(\"dilations: list(int) = [1, 1, 1, 1, 1]\")\r\n    .Attr(\"Tshape: {int32, int64} = DT_INT32\")\r\n    .SetShapeFn([](InferenceContext* c) {\r\n      ShapeHandle s;\r\n      TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(0, &s));\r\n      TF_RETURN_IF_ERROR(c->WithRank(s, 5, &s));\r\n      c->set_output(0, s);\r\n      return Status::OK();\r\n    });\r\n```\r\nFor V2, the input(0) no longer means the input itself but just its shape and therefore the input(0).T is no longer input type T but Tshape which is int32/int64. This will map the conv3d dgrad nodes with different Ts to the same cached algorithm. Any suggestion? @sanjoy "]}, {"number": 42109, "title": "Check input and axis param in quantize and dequantize", "body": "Try to fix https://github.com/tensorflow/tensorflow/issues/42105", "comments": ["Unfortunately internal tests rolled this back. Monday I'll try to get access to the failing test and try merging this again. Apologies for the delay"]}, {"number": 42108, "title": "[ROCm] Updates to dynamically load the ROCm \"hipsparse\" library", "body": "/cc @chsigg @cheshire @nvining-work ", "comments": ["@chsigg @cheshire gentle ping", "Nothing is changing functionally.\r\n\r\nAll other ROCm libraries are dynamically \"loaded\" by TF (as opposed to dynamically \"linked\"). \r\nThis PR changes the `hipsparse` library from being dynamically \"linked\" (current behaviour) to being dynamically \"loaded\"\r\n\r\nThe `wrap::` namespace is just a mechanism that is used to implement this dynamic \"loading\" functionality.\r\nThe same is done for all the other ROCm libraries, for example https://github.com/tensorflow/tensorflow/blob/master/tensorflow/stream_executor/rocm/rocm_driver_wrapper.h\r\n\r\n\r\n\r\n\r\n"]}, {"number": 42107, "title": ".", "body": "the issue has been solved", "comments": ["@alirezaghader \r\n\r\nRequest you to fill [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n Also include your TensorFlow version.Thanks!"]}, {"number": 42105, "title": "Segmentation fault in tf.quantization.quantize_and_dequantize", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0\r\n- Python version: 3.7.6\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\n`tf.quantization.quantize_and_dequantize` produces a segfault  when `input` is a tensor in any shape of `float32` or `float64` and `axis` is specified to a large number. \r\n\r\n**Describe the expected behavior**\r\nNo segfault\r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\ntf.quantization.quantize_and_dequantize(input=[2.5, 2.5], input_min=[0,0], input_max=[1,1], axis=10)\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n`Segmentation fault (core dumped)`\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42105\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42105\">No</a>\n", "Reopening since #42109 seems to not be solving this issue (this op is V2, the PR fixes on V1)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42105\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42105\">No</a>\n", "Does the CVE-2020-15265 Vulnerability Affect 1.15.5?", "Yes, but we no longer patch 1.15. Please update post 2.1", "Hello, is there any chance that vulnerability fix will be applied in versions like 2.3.4? ", "Hi. Not in 2.3.4, as the 2.3.x has reached end of life.\r\n\r\nIt is already included in 2.4.0 and later", "@mihaimaruseac noted on this, thank you for the feedback."]}]