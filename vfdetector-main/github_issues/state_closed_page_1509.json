[{"number": 7661, "title": "any pretrained models for tensorflow 1.0?", "body": "Now that TF has been updated to 1.0 with all the high-level apis, are there any supported pretrained models that are compatible with the new interfaces?", "comments": ["The previous trained models should actually work. The GraphDefs produced previous to 1.0 should be still loadable by 1.0 since none of the deprecated ops actually have been removed.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 7660, "title": "Failed to build with optimization flag AVX2", "body": "**OS : Ubuntu 16.041\r\nCPU : Intel i7 6700k**\r\n\r\nWhich supports avx2.0.\r\n\r\nI am trying to install Tensorflow from sources. \r\nWhat I am doing\r\n`./configure\r\nPlease specify the location of python. [Default is /usr/bin/python]: \r\nPlease specify optimization flags to use during compilation [Default is -march=native]: AVX2\r\nDo you wish to use jemalloc as the malloc implementation? (Linux only) [Y/n] y\r\njemalloc enabled on Linux\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] n\r\nNo Google Cloud Platform support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with Hadoop File System support? [y/N] n\r\nNo Hadoop File System support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] n\r\nNo XLA JIT support will be enabled for TensorFlow\r\nFound possible Python library paths:\r\n  /usr/local/lib/python2.7/dist-packages\r\n  /usr/lib/python2.7/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]\r\n\r\nUsing python library path: /usr/local/lib/python2.7/dist-packages\r\nDo you wish to build TensorFlow with OpenCL support? [y/N] n\r\nNo OpenCL support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with CUDA support? [y/N] y\r\nCUDA support will be enabled for TensorFlow\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0\r\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\nPlease specify the Cudnn version you want to use. [Leave empty to use system default]: 5.1.5\r\nPlease specify the location where cuDNN 5.1.5 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size.\r\n[Default is: \"3.5,5.2\"]: 6.1\r\nExtracting Bazel installation...\r\n.....\r\nINFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.\r\n.....\r\nINFO: All external dependencies fetched successfully.\r\nConfiguration finished\r\n`\r\n\r\nNow when I try to build got error,\r\n\r\n`bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package \r\nINFO: Found 1 target...\r\nERROR: /home/hannan/.cache/bazel/_bazel_hannan/45070a52d8b4aeac18b16b18e9aeca76/external/nanopb_git/BUILD.bazel:8:1: C++ compilation of rule '@nanopb_git//:nanopb' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter ... (remaining 36 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\ngcc: error: AVX2: No such file or directory\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 5.002s, Critical Path: 2.46s\r\n`\r\n\r\nIf I go with out providing optimization flag its work fine. \r\n\r\n\r\n", "comments": ["AVX2 is not an optimization flag. Use `-mavx2`", "MAVX2 is not an optimization flag. You need to make sure what you are passing there works on your compiler. Try `man gcc` to see valid flags. For MAVX2 you need `-mavx2`. Thanks!", "Thanks, solved the problem. Can you confirm for multiple flags parameters should be `-mavx2, -mavx, msse4.1`", "I believe you only need -mavx2 to get all previous sse extensions (check the man page or gcc documentation for more details). If you really want to use multiple, you'd probably just separate them with spaces i.e. \"-mavx2 -msse4.2\" etc.\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "i think when you keep the default \"-march=native\"-flag it will detect all your available hardware instructions.", "@n1kt0 I left this default, cause no issue but when I am working it gives me a warning. When I tried to configure it ran into issues.", "@codeloverr gives it you a warning that it wasn't compiled with the flags set?"]}, {"number": 7659, "title": "'NoneType' object has no attribute 'keys' in version 1.0", "body": "I was trying to run tensorflow in docker. The command was this:\r\n\r\n```\r\npython tensorflow/examples/image_retraining/retrain.py \\\r\n--bottleneck_dir=/tf_files/bottlenecks \\\r\n--how_many_training_steps 500 \\\r\n--model_dir=/tf_files/inception \\\r\n--output_graph=/tf_files/retrained_graph.pb \\\r\n--output_labels=/tf_files/retrained_labels.txt \\\r\n--image_dir /tf_files/flower_photos\r\n```\r\n\r\nI put the error I got in the log  \r\n\r\n### Environment info\r\nOperating System: OS X\r\n\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`. \r\nversion 1.0\r\n\r\n### Logs or other output that would be helpful\r\n```\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\nImage directory '/tf_files/flower_photos' not found.\r\nTraceback (most recent call last):\r\n  File \"tensorflow/examples/image_retraining/retrain.py\", line 1052, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"tensorflow/examples/image_retraining/retrain.py\", line 775, in main\r\n    class_count = len(image_lists.keys())\r\nAttributeError: 'NoneType' object has no attribute 'keys'\r\n```\r\n", "comments": ["`Image directory '/tf_files/flower_photos' not found.`\r\nYou don't have the flower_photos directory. Therefore images cannot be loaded resulting in a NoneType.\r\nYou can download the images from http://download.tensorflow.org/example_images/flower_photos.tgz ", "@essank, let us know if @microtony's suggestion worked. Thanks @microtony!", "yes the problem was here \r\n``` Image directory '/tf_files/flower_photos' not found ```\r\nI tried to do this:\r\n```\r\nmkdir tf_files\r\ncd tf_files\r\ncurl -O http://download.tensorflow.org/example_images/flower_photos.tgz\r\ntar xzf flower_photos.tgz\r\n```\r\nit's working!\r\n\r\n@microtony @aselle thanks guys! ", "not working for me ", "python retrain.py --image_dir flower_photos"]}, {"number": 7658, "title": "Optimizer var_list does not have effect on the excluded variable!", "body": "I have written piece of TensorFlow code which has two optimizers and I would like to exclude specific variables from being updated while calling \"run\" on any of these optimizers. As suggested by the TensorFlow documentation, I have specifically generated a list of variables to be updated for each optimizer, like below:\r\n\r\n    ```\r\nmentor_training_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"mentor\")\r\n    train_op_mentor = mnist.training(loss_mentor, FLAGS.learning_rate, mentor_training_vars)\r\n    mentee_training_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"mentee\")\r\n    train_op_mentee = mnist.training(loss_mentee, FLAGS.learning_rate, mentee_training_vars)\r\n    mentee_indep_training_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"mentee_indep\")\r\n    train_op_mentee_indep = mnist.training(loss_mentee_indep, FLAGS.learning_rate, mentee_indep_training_vars)\r\n```\r\n\r\nThe training functions in the mnist object is defined as:L\r\n\r\ndef training(loss, learning_rate, var_list):\r\n  # Add a scalar summary for the snapshot loss.\r\n  tf.summary.scalar('loss', loss)\r\n  # Create the gradient descent optimizer with the given learning rate.\r\n  optimizer = tf.train.GradientDescentOptimizer(learning_rate)\r\n  # Create a variable to track the global step.\r\n  global_step = tf.Variable(0, name='global_step', trainable=False)\r\n  # Use the optimizer to apply the gradients that minimize the loss\r\n  # (and also increment the global step counter) as a single training step.\r\n  train_op = optimizer.minimize(loss, global_step=global_step, var_list=var_list)\r\n  return train_op\r\n\r\n\r\n```\r\n\r\nAs it's clear in the above code, I have three namescopes, where each has their own variables.\r\n\r\nNow, let's say I only want to train the mentor variables. When I put a breakpoint after running session on the mentor optimizer, I can see that the mentee variables content is being changed after each run. Now I'm wondering whether I'm using this feature correctly, or there is something wrong with this API?", "comments": ["My reading of the documentation says that var_list takes actual lists of variables and not collection objects. Could you try just sending python lists of variables and see if your example works. Thanks! In general this kind of question about usage is best asked on StackOverflow. Thanks!\r\n", "Thanks much for the help. The reason I've posted the issue here is, because I haven't got any response on stackoverflow, so I thought it maybe an issue with TensorFlow.\r\n\r\nI have tried what you've advised and unfortunately I get a weird error as:\r\n\r\n`NotImplementedError: ('Trying to optimize unsupported type ', <tf.Tensor 'mentor/weights_mentor_l1:0' shape=(784, 1200) dtype=float32_ref>)`\r\n\r\nHere is the code I've developed to create a list instead of collection, as you've suggested:\r\n\r\n```\r\nmentor_training_vars = []\r\n\r\nmentor_training_vars.append(tf.get_default_graph().get_tensor_by_name(\"mentor/weights_mentor_l1:0\"))\r\nmentor_training_vars.append(tf.get_default_graph().get_tensor_by_name(\"mentor/biases_mentor_l1:0\"))\r\nmentor_training_vars.append(tf.get_default_graph().get_tensor_by_name(\"mentor/weights_mentor_l2:0\"))\r\nmentor_training_vars.append(tf.get_default_graph().get_tensor_by_name(\"mentor/biases_mentor_l2:0\"))\r\nmentor_training_vars.append(tf.get_default_graph().get_tensor_by_name(\"mentor/weights_mentor_l3:0\"))\r\nmentor_training_vars.append(tf.get_default_graph().get_tensor_by_name(\"mentor/biases_mentor_l3:0\"))\r\nmentor_training_vars.append(tf.get_default_graph().get_tensor_by_name(\"mentor/weights_mentor_l4:0\"))\r\nmentor_training_vars.append(tf.get_default_graph().get_tensor_by_name(\"mentor/biases_mentor_l4:0\"))\r\nmentor_training_vars.append(tf.get_default_graph().get_tensor_by_name(\"mentor_embed/weights_mentor_embed:0\"))\r\nmentor_training_vars.append(tf.get_default_graph().get_tensor_by_name(\"mentor_embed/biases_mentor_embed:0\"))\r\n\r\n# mentor_training_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"mentor\")\r\ntrain_op_mentor = mnist.training(loss_mentor, FLAGS.learning_rate, mentor_training_vars)\r\nmentee_training_vars = []\r\nmentee_training_vars.append(tf.get_default_graph().get_tensor_by_name(\"mentee/weights_mentee_l1:0\"))\r\nmentee_training_vars.append(tf.get_default_graph().get_tensor_by_name(\"mentee/biases_mentee_l1:0\"))\r\nmentee_training_vars.append(tf.get_default_graph().get_tensor_by_name(\"mentee/weights_mentee_l2:0\"))\r\nmentee_training_vars.append(tf.get_default_graph().get_tensor_by_name(\"mentee/biases_mentee_l2:0\"))\r\nmentee_training_vars.append(tf.get_default_graph().get_tensor_by_name(\"mentee/weights_mentee_l3:0\"))\r\nmentee_training_vars.append(tf.get_default_graph().get_tensor_by_name(\"mentee/biases_mentee_l3:0\"))\r\nmentee_training_vars.append(tf.get_default_graph().get_tensor_by_name(\"mentee_embed/weights_mentee_embed:0\"))\r\nmentee_training_vars.append(tf.get_default_graph().get_tensor_by_name(\"mentee_embed/biases_mentee_embed:0\"))\r\n\r\n#mentee_training_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"mentee\")\r\ntrain_op_mentee = mnist.training(loss_mentee, FLAGS.learning_rate, mentee_training_vars)\r\nmentee_indep_training_vars = []\r\nmentee_indep_training_vars.append(tf.get_default_graph().get_tensor_by_name(\"mentee_indep/weights_mentee_indep_l1:0\"))\r\nmentee_indep_training_vars.append(tf.get_default_graph().get_tensor_by_name(\"mentee_indep/biases_mentee_indep_l1:0\"))\r\nmentee_indep_training_vars.append(tf.get_default_graph().get_tensor_by_name(\"mentee_indep/weights_mentee_indep_l2:0\"))\r\nmentee_indep_training_vars.append(tf.get_default_graph().get_tensor_by_name(\"mentee_indep/biases_mentee_indep_l2:0\"))\r\nmentee_indep_training_vars.append(tf.get_default_graph().get_tensor_by_name(\"mentee_indep/weights_mentee_indep_l3:0\"))\r\nmentee_indep_training_vars.append(tf.get_default_graph().get_tensor_by_name(\"mentee_indep/biases_mentee_indep_l3:0\"))\r\n\r\n#mentee_indep_training_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"mentee_indep\"\r\ntrain_op_mentee_indep = mnist.training(loss_mentee_indep, FLAGS.learning_rate, mentee_indep_training_vars)\r\n```\r\n", "Automatically closing due to lack of recent activity. Since this issue is old at this point, please reopen the issue if it still occurs when tried with the latest version of Tensorflow. Thank you."]}, {"number": 7657, "title": "is_jpeg function only detects JFIF and not EXIF jpeg images in decode_image()", "body": "I am using tf.image.decode_image() function to dynamically decode jpeg, png or gif on the fly. However inside decode_image(), it checks if passed tensor if jpeg image using this condition:\r\n\r\n`is_jpeg = math_ops.equal(substr, b'\\xff\\xd8\\xff\\xe0', name='is_jpeg')`\r\n\r\nEXIF files have a marker of 0xff*e1*, JFIF files have a marker of 0xff*e0*. So all code that relies on 0xffe0 to detect a JPEG file will miss all EXIF files.\r\n\r\nWhen I patched it to only match first 3 bytes, its working fine.", "comments": ["Good catch. Could you submit a PR that replaces the check as\r\n```\r\nis_jpeg = math_ops.or(math_ops.equal(substr, b'\\xff\\xd8\\xff\\xe0', name='is_jfif'), math_ops.equal(substr, b'\\xff\\xd8\\xff\\xe1', name='is_exif'), name='is_jpeg')\r\n```\r\n(that's a little more conservative than your 3 byte check, but it is in the same spirit.) Thanks so much!\r\n\r\n", "Ok sure. Have never contributed to open source project till now. Any guides out there?", "@prats226 Thanks for catching this bug, and offering to fix it!  There info on contributing to TensorFlow here:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md\r\n\r\nThat links to the following documentation about creating pull requests (PRs):\r\nhttps://help.github.com/articles/about-pull-requests/", "Closing due to lack of activity.  Please reopen if necessary."]}, {"number": 7656, "title": "tf.sparse_placeholder does not accept fully specified shapes", "body": "When I try to construct `tf.sparse_placeholder` with fully specified shape, like this\r\n```\r\ntf.sparse_placeholder(tf.float32, shape=(10000, 10000))\r\n```\r\nI get\r\n\r\n```\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-15-977303dad90f> in <module>()\r\n----> 1 tf.sparse_placeholder(tf.float32, shape=(10000, 10000))\r\n\r\n/Users/astepanov/.virtualenvs/py_asr/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py in sparse_placeholder(dtype, shape, name)\r\n   1584           dtypes.int64, shape=[None, None],\r\n   1585           name=(name + \"/indices\") if name is not None else None),\r\n-> 1586       dense_shape=shape)\r\n   1587 # pylint: enable=redefined-outer-name\r\n   1588 \r\n\r\n/Users/astepanov/.virtualenvs/py_asr/lib/python3.6/site-packages/tensorflow/python/framework/sparse_tensor.py in __init__(self, indices, values, dense_shape)\r\n    134           values, name=\"values\", as_ref=True)\r\n    135       dense_shape = ops.convert_to_tensor(\r\n--> 136           dense_shape, name=\"dense_shape\", dtype=dtypes.int64)\r\n    137     self._indices = indices\r\n    138     self._values = values\r\n\r\n/Users/astepanov/.virtualenvs/py_asr/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, preferred_dtype)\r\n    649       name=name,\r\n    650       preferred_dtype=preferred_dtype,\r\n--> 651       as_ref=False)\r\n    652 \r\n    653 \r\n\r\n/Users/astepanov/.virtualenvs/py_asr/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype)\r\n    714 \r\n    715         if ret is None:\r\n--> 716           ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n    717 \r\n    718         if ret is NotImplemented:\r\n\r\n/Users/astepanov/.virtualenvs/py_asr/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in _TensorTensorConversionFunction(t, dtype, name, as_ref)\r\n    587     raise ValueError(\r\n    588         \"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\r\n--> 589         % (dtype.name, t.dtype.name, str(t)))\r\n    590   return t\r\n    591 \r\n\r\nValueError: Tensor conversion requested dtype int64 for Tensor with dtype int32: 'Tensor(\"Const_5:0\", shape=(2,), dtype=int32)'\r\n```\r\n\r\nBut when the shape is not fully specified, it is doing OK\r\n\r\n```\r\nIn [16]: tf.sparse_placeholder(tf.float32, shape=(10000, None))\r\nOut[16]: <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x112a7ff60>\r\n```\r\n\r\nI don't think that's the desired behaviour here. As a workaround for now I dropped the shape altogether in my code, but this way I cannot ensure runtime correctness of values being fed in feed_dict.\r\n\r\n### Environment info\r\nOperating System: MacOS Sierra\r\n\r\nInstalled version of CUDA and cuDNN: none\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed: `pip install tensorflow==1.0.0`\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`: 1.0.0\r\n\r\n", "comments": ["@concretevitamin, could you comment on this issue please?\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "I'm also interested in the answer. It seems to me that it would be good to allow specifying full shape, especially if partial shapes are allowed. I'm adding a small demonstration below (using version 1.5.0).\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nm = 1000000\r\nn = 1000000\r\n\r\nx = tf.placeholder(tf.float32, shape=(n, 1))\r\nx_val = np.arange(n)[:, None]\r\nW = tf.sparse_placeholder(tf.float32, shape=(m, n))        # Fails\r\n# W = tf.sparse_placeholder(tf.float32, shape=(m, None))     # Runs\r\n# W = tf.sparse_placeholder(tf.float32, shape=(None, n))     # Runs\r\n# W = tf.sparse_placeholder(tf.float32, shape=(None, None))  # Runs\r\n# W = tf.sparse_placeholder(tf.float32)                      # Runs\r\ny = tf.sparse_tensor_dense_matmul(W, x)\r\n\r\nindices = np.array([[0, 0], [1, 1], [1, 2]], dtype=np.int64)\r\nvalues = np.array([1.0, 1.0, 1.0], dtype=np.float32)\r\nshape = np.array([m, n], dtype=np.int64)\r\n\r\nwith tf.Session() as sess:\r\n    print(sess.run(y, feed_dict={x: x_val, W: (indices, values, shape)}))\r\n```"]}, {"number": 7655, "title": "Remove outdated link to nightly-matrix-android builds", "body": "This has already been replaced with the nightly-android links.", "comments": ["in reference to #7638"]}, {"number": 7654, "title": "Feature: Tensorboard Starts with all Runs Toggled Off Initially", "body": "Currently the initial load /  full page refresh of tensorboard starts on the scalars tab with all runs toggled on for rendering. If there are a lot of runs in the logdir, the browser hangs for a noticeable period of time while all of the charts for the runs are rendered. I suggest making the initial load have runs off and letting the user opt in / turn on the desired set of runs.", "comments": ["@dandelionmane, please consider this feature request.\r\n", "Or maybe default to showing the latest run?", "The concept of \"latest\" run seems somewhat loosely defined to me (ie most recent updated, started? run in parallel?).", "Having it always start with all runs disabled would be confusing to first-time TensorBoard users who haven't yet learned what the run selector is.\r\n\r\nHowever, we could make it start with all runs toggled off if you have, say, >20 runs. That should solve this performance issue.\r\n\r\nWhat do you think?", "Anyway the 20 could be a CLI option? It could be defaulted to 20, but it could also be set to 0, etc by users.", "@dandelionmane that's a good fix IMHO.\r\n\r\n@cancan101, or just keep view related options controllable in the GUI instead, no? On a similar note it would be nice if GUI controls were kept after browser tab refreshing but that might be a tall order (setting the GET object or fragment identifier like Gmail). At my work we have issues with different users having different preferences, but we look and discuss the same runs.", "How are the values in:\r\n![image](https://cloud.githubusercontent.com/assets/51059/23240002/afa75df4-f938-11e6-9879-0751b4a7a173.png)\r\npersisted? Perhaps that can be used.\r\n\r\nand re saving changes, it would be _amazing_ if a refresh did not cause by selected runs to be lost.", "Related issue, it seems that as new runs are started, they are added to the list toggled _on_.", "There's something broken in the opensource version of TensorBoard that's causing state not to get persisted in the url bar. Internally, we get really long URLs like:\r\n\r\nhttp://localhost:6006/#scalars&runsDisabled=eyI1L2xyXzFFLTA1LGNvbnY9MixmYz0yIjp0cnVlLCI1L2xyXzFFLTA0LGNvbnY9MSxmYz0yIjp0cnVlLCI1L2xyXzFFLTA0LGNvbnY9MixmYz0yIjp0cnVlfQ%3D%3D\r\n\r\nwhich include the list of selected runs. So a refresh does not lose that info. \r\n\r\nI don't want to add new command line flags for GUI settings. that will be a mess to maintain. \r\n\r\nThe values in settings are persisted via localStorage, so we could put more stuff there. It doesn't work super well for Googlers, since the TensorBoard moves around different machines and the local storage cache would be lost since it is (afaik) url specific. But for open-source use cases it should be fine. ", "Okay, yes, would be great to have setting for min number of runs to auto select or just a flag whether to auto select.", "I have a CL right now that hardcodes the number to auto-enable at 15.\r\nHow important is it to you that you be able to change that value?", "As a user, seems odd to me to have the selection behavior determined based on the number of files in the directory. Even having the > 15 is a big improvement from what I have now.", "I changed it to 10. CL will likely land in GitHub shortly (although it will be longer before it is packaged in a TensorBoard)\r\n\r\nWhy does it seem odd to have the selection behavior default to showing just the first ten runs?", "The idea have having any runs selected initially might be great for discoverability for new users. After that fact, it's just this annoying change point where I have to click an extra untoggle depending on whether I have < 10 or >= 10 runs in a directory.", "I see. How about I make it so that the first toggle click will go to all-runs-off, regardless of the number of runs present?", "What do you mean \"first toggle click\" ?", "There is a \"toggle all runs\" button.\r\nI'll make it so that regardless of how many runs your TensorBoard has, when you click \"toggle all runs\" for the first time, it will turn all runs off. So if that's the clean state you want, you can always get it in one click, rather than depending on how many runs there were.", "ok", "I just merged a change internally that will change the default again:\r\n\r\nIf there are more than 40 runs, everything is toggled off by default\r\nIf there are 40 or fewer, then everything is toggled on by default.\r\n\r\nThis way we avoid overloading the browser when there are lots of runs, but for simple cases (and new users) there is no added complexity. I got feedback that turning on only the first 10 was more confusing for everyone, since people mght not realize they are in an intermediate state.\r\n\r\n@cancan101  I'm open to changing the constant from 40 to something lower if that would be better for you.", "Yes I agree intermediate state is odd. 40 seems like a lot. Just think of seeing 40 lines all on one graph. Perhaps something like 10 or 15?", "@dandelionmane After testing the 1.1rc1, I agree that having just the \"first\" 10 selected if very weird.  Even the definition of first is somewhat arbitrary (arguably you would want the most recent 10 and not the oldest 10). I would personally love see some way to select all or nothing, presumably based on some threshold like 10 or 15 files in the directory (ideally this threshold is configurable on CLI, but I understand this may not be practical).", "> This way we avoid overloading the browser when there are lots of runs, but for simple cases (and new users) there is no added complexity. I got feedback that turning on only the first 10 was more confusing for everyone, since people mght not realize they are in an intermediate state.\r\n\r\nMakes sense.\r\n\r\n> @cancan101 I'm open to changing the constant from 40 to something lower if that would be better for you\r\n\r\nHow many different colors are there for the scalar plots? The default should not exceed that IMO."]}, {"number": 7653, "title": "failed call to cuInit: CUDA_ERROR_UNKNOWN", "body": "when i run tensorflow gpu my gpy is gt 620m \r\nlinux mint 18.1\r\n```\r\nE tensorflow/stream_executor/cuda/cuda_driver.cc:509] failed call to cuInit: CUDA_ERROR_UNKNOWN\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: essam-goda\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: essam-goda\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: 340.101.0\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:363] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  340.101  Thu Dec  1 15:52:31 PST 2016\r\nGCC version:  gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.4) \r\n\"\"\"\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 340.101.0\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:300] kernel version seems to match DSO: 340.101.0\r\n```\r\n", "comments": ["Could you google search this error and try to follow some of the advice. For example, this error appears here\r\nhttps://github.com/tensorflow/tensorflow/issues/2882\r\n1. One thing is you could have no permissions to run on the GPU as a user (you could try sudo)\r\n2. Make sure nvidia-smi works\r\n3. try some of the  cuda demos and make sure they work to narrow it down from being just a GPU install/configure problem\r\n\r\nGood Luck!\r\n", "I am having the same exact issue since upgrading to Tensorflow 1.0 \r\n\r\n\r\n`E tensorflow/stream_executor/cuda/cuda_driver.cc:509] failed call to cuInit: CUDA_ERROR_UNKNOWN\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: gangadhar-All-Series\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: gangadhar-All-Series\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: 367.57.0\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:363] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  367.57  Mon Oct  `\r\n\r\n```\r\n\r\nimport tensorflow as tf\r\n# Creates a graph.\r\na = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\r\nb = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\r\nc = tf.matmul(a, b)\r\n# Creates a session with log_device_placement set to True.\r\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\r\n# Runs the op.\r\nprint sess.run(c)\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\nE tensorflow/stream_executor/cuda/cuda_driver.cc:509] failed call to cuInit: CUDA_ERROR_UNKNOWN\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: gangadhar-All-Series\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: gangadhar-All-Series\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: 367.57.0\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:363] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  367.57  Mon Oct  3 20:37:01 PDT 2016\r\nGCC version:  gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04.3) \r\n\"\"\"\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 367.57.0\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:300] kernel version seems to match DSO: 367.57.0\r\nI tensorflow/core/common_runtime/direct_session.cc:257] Device mapping:\r\nI tensorflow/core/common_runtime/simple_placer.cc:841] MatMul: (MatMul)/job:localhost/replica:0/task:0/cpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:841] b: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:841] a: (Const)/job:localhost/replica:0/task:0/cpu:0\r\nDevice mapping: no known devices.\r\nMatMul: (MatMul): /job:localhost/replica:0/task:0/cpu:0\r\nb: (Const): /job:localhost/replica:0/task:0/cpu:0\r\na: (Const): /job:localhost/replica:0/task:0/cpu:0\r\n[[ 22.  28.]\r\n [ 49.  64.]]\r\n\r\n```", "Issue resolved after Ubuntu restart. I installed updates and was pending a restart, after the restart GPU was detected. ", "@aselle \r\nwhen run nvidia-smi result is \r\n \r\n```\r\nNVIDIA-SMI couldn't find libnvidia-ml.so library in your system. Please make sure that the NVIDIA Display Driver is properly installed and present in your system.\r\nPlease also try adding directory that contains libnvidia-ml.so to your system PATH.\r\n```", "@essamgoda that sounds like cuda isn't installed quite right. Try doing what it says, otherwise searching for methods of reinstalling nvidia drivers (sometimes you have to work pretty hard to remove remaining parts of cuda if you have used a mix of manual and automatic methods).", "@aselle   i uninstall nvidia driver and cuda and tensorflow-gpu (via pip) and install again\r\n\r\ntry to install from source code (to write GPU card with CUDA Compute Capability of my driver) show error in build\r\n\r\nwhen i run \r\n```\r\n\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: GeForce GT 620M\r\nmajor: 2 minor: 1 memoryClockRate (GHz) 1.25\r\npciBusID 0000:01:00.0\r\nTotal memory: 964.44MiB\r\nFree memory: 756.19MiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:948] Ignoring visible gpu device (device: 0, name: GeForce GT 620M, pci bus id: 0000:01:00.0) with Cuda compute capability 2.1. The minimum required Cuda capability is 3.0.\r\n```\r\n\r\ncan i change configuration to 2.1 ? or my drive will not work ever ? ", "You could try compiling from source with compute capability 2.1 specified as the required version. However, I believe from this stackoverflow post, you need at least compute capability 3.0 to use cudnn.\r\nhttp://stackoverflow.com/questions/33760192/how-to-know-which-cudnn-version-one-should-use\r\n@zheng-xq, can you verify that tensorflow requires at least 3.0?\r\n", "Yes. The minimum version that is officially supported is 3.0. ", "Thanks @zheng-xq. Closing the issue since this won't be something that can work.", "@aselle Hi, is there any alternative to make it work without running it as root?\r\n\r\n```\r\nnvidia-smi\r\nMon Aug 14 07:26:58 2017\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 375.82                 Driver Version: 375.82                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Quadro P400         Off  | 0000:01:00.0      On |                  N/A |\r\n| 34%   46C    P8    12W /  N/A |    116MiB /  1990MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla K40c          Off  | 0000:03:00.0     Off |                    0 |\r\n| 27%   50C    P8    21W / 235W |      0MiB / 11439MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  Tesla K40c          Off  | 0000:04:00.0     Off |                    0 |\r\n| 28%   55C    P8    30W / 235W |      0MiB / 11439MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|    0      2165    G   /usr/lib/xorg/Xorg                              60MiB |\r\n|    0      2271    G   gnome-shell                                     54MiB |\r\n+-----------------------------------------------------------------------------+\r\n```\r\n\r\nWithout sudo:\r\nPlease note:`\r\n2017-08-14 07:28:29.379866: E tensorflow/stream_executor/cuda/cuda_driver.cc:406] failed call to cuInit: CUDA_ERROR_NO_DEVICE`\r\n```\r\npython simple_mlp_tensorflow.py\r\n2017-08-14 07:28:29.374191: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-08-14 07:28:29.374211: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-08-14 07:28:29.374216: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-08-14 07:28:29.374219: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-08-14 07:28:29.374222: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-08-14 07:28:29.379866: E tensorflow/stream_executor/cuda/cuda_driver.cc:406] failed call to cuInit: CUDA_ERROR_NO_DEVICE\r\n2017-08-14 07:28:29.379893: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: gonzo\r\n2017-08-14 07:28:29.379898: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: gonzo\r\n2017-08-14 07:28:29.379919: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: 375.82.0\r\n2017-08-14 07:28:29.379936: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:369] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  375.82  Wed Jul 19 21:16:49 PDT 2017\r\nGCC version:  gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.4)\r\n\"\"\"\r\n2017-08-14 07:28:29.379948: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 375.82.0\r\n2017-08-14 07:28:29.379953: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:300] kernel version seems to match DSO: 375.82.0\r\n\r\n```\r\nAs root with sudo:\r\n```\r\nsudo /nohome/jaan/abhishek/anaconda3/bin/python simple_mlp_tensorflow.py\r\n2017-08-14 07:27:35.067365: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-08-14 07:27:35.067388: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-08-14 07:27:35.067392: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-08-14 07:27:35.067395: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-08-14 07:27:35.067398: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-08-14 07:27:35.294553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties:\r\nname: Tesla K40c\r\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.745\r\npciBusID 0000:03:00.0\r\nTotal memory: 11.17GiB\r\nFree memory: 11.10GiB\r\n2017-08-14 07:27:35.479863: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x16b60d0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.\r\n2017-08-14 07:27:35.480328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 1 with properties:\r\nname: Quadro P400\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.2525\r\npciBusID 0000:01:00.0\r\nTotal memory: 1.94GiB\r\nFree memory: 1.80GiB\r\n2017-08-14 07:27:35.660972: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x130fb80 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.\r\n2017-08-14 07:27:35.661598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 2 with properties:\r\nname: Tesla K40c\r\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.745\r\npciBusID 0000:04:00.0\r\nTotal memory: 11.17GiB\r\nFree memory: 11.10GiB\r\n2017-08-14 07:27:35.661622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:832] Peer access not supported between device ordinals 0 and 1\r\n2017-08-14 07:27:35.662012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:832] Peer access not supported between device ordinals 1 and 0\r\n2017-08-14 07:27:35.662023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:832] Peer access not supported between device ordinals 1 and 2\r\n2017-08-14 07:27:35.662037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:832] Peer access not supported between device ordinals 2 and 1\r\n2017-08-14 07:27:35.662051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 1 2\r\n2017-08-14 07:27:35.662059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y N Y\r\n2017-08-14 07:27:35.662066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 1:   N Y N\r\n2017-08-14 07:27:35.662072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 2:   Y N Y\r\n2017-08-14 07:27:35.662085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0)\r\n2017-08-14 07:27:35.662094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1017] Ignoring gpu device (device: 1, name: Quadro P400, pci bus id: 0000:01:00.0) with Cuda multiprocessor count: 2. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.\r\n2017-08-14 07:27:35.662103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:1) -> (device: 2, name: Tesla K40c, pci bus id: 0000:04:00.0)\r\n```", "Possible solution: I had this issue, nvidia-smi was working fine, and it turned out I was placing my device where none existed. I have two environments. One with many GPUs one with just one. Running the code one the single GPU machine but placing the device on position '1' (or any other than '0') gave rise to this error.", "Adding following lines to .bashrc worked for me!!\r\n\r\nexport LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/usr/local/cuda-8.0/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64:/usr/local/cuda-8.0/targets/x86_64-linux/lib/\"", "If it helps when running on Google Cloud adding persistence mode `nvidia-smi -pm 1` helped/worked for me as per `https://cloud.google.com/compute/docs/gpus/add-gpus#install-driver-script`", "I met the same problem, and I find nvidia-smi not work as aselle suggest.\r\nI re install the nvdia-smi follows https://blog.csdn.net/w5688414/article/details/78287199\r\nthen reboot my computer, everything works!", "> Issue resolved after Ubuntu restart. I installed updates and was pending a restart, after the restart GPU was detected.\r\nThe same for me after creating virtual environment and installing dependencies\r\n", "> > Issue resolved after Ubuntu restart. I installed updates and was pending a restart, after the restart GPU was detected.\r\n> > The same for me after creating virtual environment and installing dependencies\r\n\r\nOn my end, reloading the conda environment used was the trick (probably similar to reboot since it has reloaded path and variable and such...)", "> when i run tensorflow gpu my gpy is gt 620m\r\n> linux mint 18.1\r\n> \r\n> ```\r\n> E tensorflow/stream_executor/cuda/cuda_driver.cc:509] failed call to cuInit: CUDA_ERROR_UNKNOWN\r\n> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: essam-goda\r\n> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: essam-goda\r\n> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: 340.101.0\r\n> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:363] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  340.101  Thu Dec  1 15:52:31 PST 2016\r\n> GCC version:  gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.4) \r\n> \"\"\"\r\n> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 340.101.0\r\n> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:300] kernel version seems to match DSO: 340.101.0\r\n> ```\r\n\r\nSometimes a simple reboot  works"]}, {"number": 7652, "title": "Provide a working way to shut up warnings", "body": "These messages appear whenever I run my program.\r\n\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\n\r\nNow, I don't care that Tensorflow wasn't compiled to use SSE3 instructions, or AVX, or whatever. I don't want to see these messages. I also don't want to recompile from source to remove the warnings, install something else, play games with stderr, or whatever. I just want a clean way to shut up the warnings.\r\n\r\nHere's my initialization code.\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.python.framework import ops\r\ntf.logging.set_verbosity(tf.logging.ERROR)\r\nsess = tf.Session(config=tf.ConfigProto(device_count = {'GPU': 0}))\r\n\r\nSee? I asked for no warnings. Yet I still get them. That's a bug. Even if it's the intended behavior, please fix this.\r\n\r\nVersion is Tensorflow 1.0 on Linux.\r\n\r\nThank you!\r\n", "comments": ["https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/default/logging.cc#L117\r\n\r\nTry setting the environment variable\r\n```\r\nTF_CPP_MIN_LOG_LEVEL=2\r\n```\r\nto filter out INFO and WARNING logs.\r\n", "As a general approach for filtering out uninteresting TensorFlow messages, it may be useful to run TF scripts as\r\n\r\n`tf.sh myscript.py`\r\n\r\nwhere `tf.sh` does\r\n\r\n```\r\n#!/bin/sh\r\n# Run python script, filtering out TensorFlow logging\r\n# https://github.com/tensorflow/tensorflow/issues/566#issuecomment-259170351\r\npython $* 3>&1 1>&2 2>&3 3>&- | grep -v \":\\ I\\ \" | grep -v \"WARNING:tensorflow\" | grep -v ^pciBusID | grep -v ^major: | grep -v ^name: |grep -v ^Total\\ memory:|grep -v ^Free\\ memory:\r\n```\r\n", "Thanks for the help. Yeah, I know I could filter out messages like this, that's what I meant by playing stderr games. But it's a pain.\r\n\r\nThe environment variable trick works. I'd suggest plugging that directly into tf.logging(), or at least documenting it somewhere, to be user-friendly. I did a search prior to reporting the problem. At least this bug will get indexed so it might help other people.\r\n\r\nFor posterity, add this to your programs to shut up the initial warnings:\r\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"2\"\r\n\r\nThanks again.", "The flip-side of this, is that if people don't see these warning, they may end up filing performance bugs. The proper way to fix them is to use TensorFlow build that uses your architecture. I get 3x speed-up on large matrix multiply when using architecture-specific TF build -- https://github.com/tensorflow/tensorflow/issues/7257#issuecomment-277456370", "I get that, but they already went out of their way by changing tf.logging.set_verbosity(tf.logging.ERROR). I'm fine with warnings by default, but there ought to be documented way to get rid of unwanted messages. Just like compiler warnings. Maybe something like tf.logging.set_perf_reports(0).\r\n", "Would https://github.com/tensorflow/tensorflow/compare/master...vrv:master make you happy?\r\n\r\n(tf.logging.set_verbosity was only ever meant to affect python logging, not C++ logging.  This is a legacy google behavior, which has different logging systems for both languages -- hopefully that explains the current situation).", "Yep!", "Naive question, since the link in @vrv 's post wasn't permanent: what's the way that made you happy, @seerdecker , please?", "I forget the exact API, it's been a while. Perhaps @vrv has the patch still? From memory, @vrv solution involved a call to disable the C++ logging.\r\n\r\nNote that currently, os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"2\" does not work when using the GPU path on my machine [tensorflow-gpu (1.0.1)].\r\n ", "Yeah, I think I was making set_verbosity set the env var for C++ logging.  Sorry for never getting around to submit that patch, I might try to get to it this week.  However, it would be moot if the environment variable no longer works... :(", "So in my case, the environment variable still works, as long as it is set\n*before* importing tensorflow for the first time. If I set it after\nimporting TF, it doesn't have any effect. Do you observe the same behaviour?\n\n>\n", "I believe it's the case the environment variable is read statically the first time logging is requested, so if importing tensorflow causes something to log (which it may have only started doing in the past few months, much to my annoyance), then it is likely the case my patch won't fix the common cause of the problem since you'd have to import tensorflow before being able to use set_verbosity. :/", "Ah, tough, but makes sense. Thanks for explanation Vijay!\n\nOn Mon, 24 Jul 2017, 08:17 Vijay Vasudevan, <notifications@github.com>\nwrote:\n\n> I believe it's the case the environment variable is read statically the\n> first time logging is requested, so if importing tensorflow causes\n> something to log (which it may have only started doing in the past few\n> months, much to my annoyance), then it is likely the case my patch won't\n> fix the common cause of the problem since you'd have to import tensorflow\n> before being able to use set_verbosity. :/\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/7652#issuecomment-317328876>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAoSRZvIoCOrYEmL698dXP05ihEgSYfJks5sRDbkgaJpZM4MFNQw>\n> .\n>\n", "Here is the solution:\r\n\r\ntf.logging.set_verbosity(tf.logging.ERROR)\r\n\r\nSource:https://stackoverflow.com/questions/48608776/how-to-suppress-tensorflow-warning-displayed-in-result", "Hi all,\r\n\r\ni don't know why i can't disable warning even after putting:\r\n\r\ntf.logging.set_verbosity(tf.logging.ERROR) \r\nand this \r\nimport os\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' also i tried to put them both together, i also put these line before importing tensorflow as tf and also tried to put it after importing tensorflow but nothing is working.\r\n\r\nAnyone have any other idea?\r\n\r\nThanks ", "This is so much annoying, nothing works using tensorflow-gpu ", "I got this to work\r\ntf.get_logger().setLevel(3)\r\n\r\nBut this still doesnt suppress the one warning message I want suppressed\r\nW tensorflow/core/grappler/utils/graph_view.cc:830] No registered 'MultiDeviceIteratorGetNextFromShard' OpKernel for GPU devices compatible with node {{node MultiDeviceIteratorGetNextFromShard}}\r\n        .  Registered:  device='CPU'\r\n\r\nI get multiple of these each epoch :(", "If you only need to **get rid of warning outputs on the screen**, you might want to **clear the console** screen right after importing the tensorflow by using this simple command:\r\n\r\nIn windows:\r\n\r\n    import os\r\n    os.system('cls')\r\n\r\nIn Linux or Mac:\r\n\r\n    import os\r\n    os.system('clear')\r\n\r\n"]}, {"number": 7651, "title": "AttributeError: 'module' object has no attribute 'Default' (revisited)", "body": "### Issue\r\n\r\n```\r\n$ python\r\nPython 2.7.6 (default, Oct 26 2016, 20:30:19) \r\n[GCC 4.8.4] on linux2\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/schidester/usr/tf/local/lib/python2.7/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"/home/schidester/usr/tf/local/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 75, in <module>\r\n    from tensorflow.core.framework.graph_pb2 import *\r\n  File \"/home/schidester/usr/tf/local/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py\", line 9, in <module>\r\n    from google.protobuf import symbol_database as _symbol_database\r\n  File \"/usr/local/lib/python2.7/dist-packages/google/protobuf/symbol_database.py\", line 165, in <module>\r\n    _DEFAULT = SymbolDatabase(pool=descriptor_pool.Default())\r\nAttributeError: 'module' object has no attribute 'Default'\r\n```\r\n\r\n### Existing issues\r\nAlready found issues: #5344 and #5319 but neither provides a solution to the problem - that I could see (perhaps I just missed it somewhere)\r\n\r\n### Environment info\r\nOperating System: Linux Mint 17.3 Rosa\r\n\r\n### Reproduction details\r\nFirst I built tensorflow from git source, branch r1.0.\r\n\r\n```\r\n$ git remote -v\r\norigin\thttps://github.com/tensorflow/tensorflow (fetch)\r\norigin\thttps://github.com/tensorflow/tensorflow (push)\r\n$ git branch\r\n  master\r\n* r1.0\r\n$ bazel version\r\nBuild label: 0.4.4\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Wed Feb 1 18:54:21 2017 (1485975261)\r\nBuild timestamp: 1485975261\r\nBuild timestamp as int: 1485975261\r\n```\r\n\r\nNo apparent problems encountered during the build.  This resulted in a .whl file in the /tmp directory and I installed it with pip:\r\n\r\n```\r\n$ sudo pip install /tmp/tensorflow_pkg/tensorflow-1.0.0-cp27-none-linux_x86_64.whl\r\n```\r\n\r\nAt this point I get the import error shown at the top of this post whenever `import tensorflow` is used in a python shell.\r\n\r\nSo I removed the locally built tensorflow with `sudo pip uninstall tensorflow` and re-installed with the pre-built .whl file:\r\n\r\n```\r\n$ sudo pip install https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.0.0-cp27-none-linux_x86_64.whl\r\n```\r\n\r\nSame import error.  Uninstalled again and tried using a virtualenv.  But I'm still getting the import errors:\r\n\r\n```\r\n$ virtualenv --system-site-packages ~/usr/tf\r\n$ source ~/usr/tf/bin/activate\r\n(tf)$ pip install https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.0.0-cp27-none-linux_x86_64.whl\r\nDownloading/unpacking https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.0.0-cp27-none-linux_x86_64.whl\r\n  Downloading tensorflow-1.0.0-cp27-none-linux_x86_64.whl (44.1MB): 44.1MB downloaded\r\nRequirement already satisfied (use --upgrade to upgrade): protobuf>=3.1.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.0.0)\r\nRequirement already satisfied (use --upgrade to upgrade): wheel in /usr/lib/python2.7/dist-packages (from tensorflow==1.0.0)\r\nRequirement already satisfied (use --upgrade to upgrade): mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.0.0)\r\nRequirement already satisfied (use --upgrade to upgrade): numpy>=1.11.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.0.0)\r\nRequirement already satisfied (use --upgrade to upgrade): six>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.0.0)\r\nInstalling collected packages: tensorflow\r\nSuccessfully installed tensorflow\r\nCleaning up...\r\n(tf)$ python\r\nPython 2.7.6 (default, Oct 26 2016, 20:30:19) \r\n[GCC 4.8.4] on linux2\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/schidester/usr/tf/local/lib/python2.7/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"/home/schidester/usr/tf/local/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 75, in <module>\r\n    from tensorflow.core.framework.graph_pb2 import *\r\n  File \"/home/schidester/usr/tf/local/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py\", line 9, in <module>\r\n    from google.protobuf import symbol_database as _symbol_database\r\n  File \"/usr/local/lib/python2.7/dist-packages/google/protobuf/symbol_database.py\", line 165, in <module>\r\n    _DEFAULT = SymbolDatabase(pool=descriptor_pool.Default())\r\nAttributeError: 'module' object has no attribute 'Default'\r\n```\r\n\r\nI've tried the following, but neither had any effect:\r\n\r\n```\r\n pip install --upgrade protobuf\r\n pip install --upgrade tensorflow\r\n```\r\n\r\nMy best guess is that the python protobuf lib version available for the older version of Linux Mint I'm using is the problem.  But I don't know how to verify that or fix it - if that is indeed the problem.", "comments": ["Did you try pip install --upgrade protobuf within the virtualenv or outsisde of it. I usually do it inside the virtualenv and that resolves that problem. Thanks", "From your Python interpreter, check the location of your google.protobuf.descriptor_pool module:\r\n$ python\r\nPython 2.7.6 (default, Oct 26 2016, 20:30:19) \r\n[GCC 4.8.4] on linux2\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> from google.protobuf import descriptor_pool\r\n>>> descriptor_pool.__file__\r\n'/usr/local/lib/python2.7/dist-packages/google/protobuf/descriptor_pool.pyc'\r\n\r\nIt's possible that you are using an earlier version of google.protobuf from a different path.\r\n\r\nI installed tensorflow by using pip, and it installs a new google.protobuf under /usr/local/lib/python2.7/dist-packages, while there is another one (don't know where it comes from) under /usr/lib/python2.7/dist-packages. Removing that one solved my problem.", "Find a better way instead of removing the old version: I am using Ubuntu and that version comes from Ubuntu package python-protobuf. I uninstalled tensorflow and the new protobuf (sudo pip uninstall protobuf) and then upgrade the existing one using \"sudo pip install --upgrade protobuf\".", "@aselle I did the `pip install --upgrade protobuf` in all variations.  Inside and outside the virtualenv, with and without sudo.  In all cases it was a no-op (no install or upgrade performed).\r\n\r\n@garyshi Thanks for the tip!  It actually shows the protobuf site-package path in the stack trace of the import error - it's using the system site-packages.  Rather than tinker with the system site-packages I tried a virtualenv *without* the `--system-site-packages` option and when I performed `pip install --upgrade protobuf` within that virtualenv it installed protobuf 3.2.0.\r\n\r\n```\r\n(tf)$ pip install --upgrade protobuf\r\nDownloading/unpacking protobuf\r\n  Downloading protobuf-3.2.0-py2.py3-none-any.whl (360kB): 360kB downloaded\r\nDownloading/unpacking six>=1.9 (from protobuf)\r\n  Downloading six-1.10.0-py2.py3-none-any.whl\r\nDownloading/unpacking setuptools from https://pypi.python.org/packages/9a/9e/7614c97ca7f88a74352c726cfae1fa3f9823701d3a8b71f8c95ea581e493/setuptools-34.2.0-py2.py3-none-any.whl#md5=3b4e37333a741b711fb10dbe1a06d528 (from protobuf)\r\n  Downloading setuptools-34.2.0-py2.py3-none-any.whl (389kB): 389kB downloaded\r\nDownloading/unpacking appdirs>=1.4.0 (from setuptools->protobuf)\r\n  Downloading appdirs-1.4.0-py2.py3-none-any.whl\r\nDownloading/unpacking packaging>=16.8 (from setuptools->protobuf)\r\n  Downloading packaging-16.8-py2.py3-none-any.whl\r\nDownloading/unpacking pyparsing (from packaging>=16.8->setuptools->protobuf)\r\n  Downloading pyparsing-2.1.10-py2.py3-none-any.whl (56kB): 56kB downloaded\r\nInstalling collected packages: protobuf, six, setuptools, appdirs, packaging, pyparsing\r\n  Found existing installation: setuptools 2.2\r\n    Uninstalling setuptools:\r\n      Successfully uninstalled setuptools\r\nSuccessfully installed protobuf six setuptools appdirs packaging pyparsing\r\nCleaning up...\r\n```\r\n\r\nThen I installed tensorflow from the pre-built .whl file and the tensorflow import worked!\r\n\r\nThanks again for the feedback!", "If the above method still does not work, try upgrading setuptools by `pip install --upgrade setuptools==39.1.0` (whichever version tensorflow supports), then reinstall protobuf to the latest version and everything should work! (at least for me)"]}, {"number": 7650, "title": "Use tensordot for broadcasting in Dense#call", "body": "I replaced reshaping the over 3-ranked input to the `Dense` layer with tensordot application.\r\nThis modification is based on theano.tensor#dot.", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "cc @fchollet "]}, {"number": 7649, "title": "cuDevicePrimaryCtxSetFlags not found", "body": "Hi all,\r\ni tried running [Darkflow ](https://github.com/thtrieu/darkflow)with following argument\r\n`python flow --model cfg/yolo.cfg --load bin/yolo.weights --demo camera --gpu 1.0`\r\n\r\ngot below output \r\n\r\n```\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:135] successfully opened CUDA library cublas64_80.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:135] successfully opened CUDA library cudnn64_5.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:135] successfully opened CUDA library cufft64_80.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:135] successfully opened CUDA library nvcuda.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:135] successfully opened CUDA library curand64_80.dll locally\r\nParsing ./cfg/yolo.cfg\r\nParsing cfg/yolo.cfg\r\nLoading bin/yolo.weights ...\r\nSuccessfully identified 269862452 bytes\r\nFinished in 0.020000934600830078s\r\n\r\nBuilding net ...\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"BestSplits\" device_type: \"CPU\"') for unknown op: Bes\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"CountExtremelyRandomStats\" device_type: \"CPU\"') for\r\nelyRandomStats\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"FinishedNodes\" device_type: \"CPU\"') for unknown op:\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"GrowTree\" device_type: \"CPU\"') for unknown op: GrowT\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"ReinterpretStringToFloat\" device_type: \"CPU\"') for u\r\ntringToFloat\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"SampleInputs\" device_type: \"CPU\"') for unknown op: S\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"ScatterAddNdim\" device_type: \"CPU\"') for unknown op:\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"TopNInsert\" device_type: \"CPU\"') for unknown op: Top\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"TopNRemove\" device_type: \"CPU\"') for unknown op: Top\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"TreePredictions\" device_type: \"CPU\"') for unknown op\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"UpdateFertileSlots\" device_type: \"CPU\"') for unknown\r\n\r\nSource | Train? | Layer description                | Output size\r\n-------+--------+----------------------------------+---------------\r\n       |        | input                            | (?, 416, 416, 3)\r\n Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 416, 416, 32)\r\n Load  |  Yep!  | maxp 2x2p0_2                     | (?, 208, 208, 32)\r\n Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 208, 208, 64)\r\n Load  |  Yep!  | maxp 2x2p0_2                     | (?, 104, 104, 64)\r\n Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 128)\r\n Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 104, 104, 64)\r\n Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 128)\r\n Load  |  Yep!  | maxp 2x2p0_2                     | (?, 52, 52, 128)\r\n Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 256)\r\n Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 52, 52, 128)\r\n Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 256)\r\n Load  |  Yep!  | maxp 2x2p0_2                     | (?, 26, 26, 256)\r\n Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\r\n Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 256)\r\n Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\r\n Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 256)\r\n Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\r\n Load  |  Yep!  | maxp 2x2p0_2                     | (?, 13, 13, 512)\r\n Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\r\n Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 13, 13, 512)\r\n Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\r\n Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 13, 13, 512)\r\n Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\r\n Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\r\n Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\r\n\r\nF c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\cuda\\cuda_driver.cc:94] Check failed: s.ok() could not find cuDevicePrimaryCtxSetFlags in libcuda DSO; dlerr\r\nor: cuDevicePrimaryCtxSetFlags not found\r\n```\r\n\r\ni'm using python 3.5, windows 7(64bit), tensorflow (v1.0 installed via pip) with gpu support, cuda v8, cudnn v5\r\ni'm having NVidia GeForce 210 video card, have installed latest graphic driver \r\n\r\nnote: \r\ni also tried cuda v5 toolkit, but somehow tensorflow is still looking for v8 cuda binaries ..\r\ni installed tensorflow cpu only version, it works. but 0.4fps\r\n\r\nThanks\r\n\r\n", "comments": ["(not an expert but...) I believe GeForce 210 is a very old graphics card. It only supports (I believe) compute version 1.2. You probably won't have any luck except compute level 3.0 and above for TensorFlow. @zheng-xq, could elaborate.\r\n\r\n", "@aselle,thanks for your reply. \r\nyeah i thought of the same. i was wondering if older version of tensorflow & cuda will do the trick? ", "No, unfortunately the CUDA functionality of that generation was very limited.\r\n", "Yes, the minimum supported Cuda compute is 3.0. You are much better off using a more recent GPU. ", "ok. Thanks for your answer.", "I have the same problem, I have NVIDIA K1100M, I am running with Python3.5.2 cuda 8 and cudann 5.1 and have the same problem.\r\nIs  this GPU enough to tensorflow -gpu\r\nPlease help"]}, {"number": 7648, "title": "GPU: no known devices, despite cuda's deviceQuery returning a \"PASS\" result", "body": "Hi guys,\r\n\r\nSorry, I know there's already been tons of GPU related issues, but I could not find any that seems to be related to my problem.\r\n\r\nThe main symptom: when running tensorflow, my gpu is not detected ([the code being run](https://gist.github.com/oelmekki/cafda411bf5c2ea695d984fa98e0995b), and [its output](https://gist.github.com/oelmekki/77235c6b0dde99b3438f190eb557f40f)).\r\n\r\nWhat differs from usual issues is that cuda seems properly installed and running `./deviceQuery` from cuda samples is successful ([output](https://gist.github.com/oelmekki/fe65a15daec45aa90ec33b10b51d3aae)).\r\n\r\nI have two graphical cards:\r\n\r\n* an old GTX 650 used for my monitors (I don't want to use that one with tensorflow)\r\n* a GTX 1060 that I want to dedicate to tensorflow\r\n\r\nI use:\r\n\r\n* [tensorflow-1.0.0](https://pypi.python.org/pypi/tensorflow)\r\n* cuda-8.0 ([ls -l /usr/local/cuda/lib64/libcud*](https://gist.github.com/oelmekki/6e5e9d7d1ea871e1d73efae307efe9ce))\r\n* cudnn-5.1.10\r\n* python-2.7.12\r\n* nvidia-drivers-375.26 (this was installed by cuda and replaced my distro driver package)\r\n\r\n\r\nI've tried:\r\n\r\n* adding `/usr/local/cuda/bin/` to `$PATH`\r\n* forcing gpu placement in tensorflow script using `with tf.device('/gpu:1'):` (and `with tf.device('/gpu:0'):` when it failed, for good measure)\r\n* whitelisting the gpu I wanted to use with `CUDA_VISIBLE_DEVICES`, in case the presence of my old unsupported card did cause problems\r\n* running the script with sudo (because why not)\r\n\r\nHere are the outputs of [nvidia-smi](https://gist.github.com/oelmekki/7bdcb5cc2f791cea561a60f8b21e87b5) and [nvidia-debugdump -l](https://gist.github.com/oelmekki/b83a5a0a72e8924aeb44b70b3598f9b4), in case it's useful.\r\n\r\nAt this point, I feel like I have followed all the breadcrumbs and have no idea what I could try else. I'm not even sure if I'm contemplating a bug or a configuration problem. Any advice about how to debug this would be greatly appreciated. Thanks!\r\n", "comments": ["As a shot in the dark, maybe try TF 1.0 and look at output of verbose logging\r\n\r\n`export TF_CPP_MIN_VLOG_LEVEL=1`\r\n\r\nThere's also `export TF_CPP_MIN_VLOG_LEVEL=2` but that can be 100's of MBs of output", "This is a question that should be posted on StackOverflow -- can you post it there and link us?", "Sure, I asked it here : http://stackoverflow.com/questions/42326748/tensorflow-on-gpu-no-known-devices-despite-cudas-devicequery-returning-a-pas", "@yaroslavvb Thanks for the tip!\r\n\r\nActually, using this does not provide any more info than not using it:\r\n\r\n```\r\n$ TF_CPP_MIN_LOG_LEVEL=1 python gpu.py\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\nDevice mapping: no known devices.\r\nMatMul: (MatMul): /job:localhost/replica:0/task:0/cpu:0\r\nb: (Const): /job:localhost/replica:0/task:0/cpu:0\r\na: (Const): /job:localhost/replica:0/task:0/cpu:0\r\n[[ 22.  28.]\r\n [ 49.  64.]]\r\n```\r\n\r\n(I've also tried to export the variable globally just in case, but it produces the same result)\r\n\r\nFunny enough, setting log_level to 2 actually produces a lesser amount of output:\r\n\r\n```\r\n$ TF_CPP_MIN_LOG_LEVEL=2 python gpu.py\r\nDevice mapping: no known devices.\r\nMatMul: (MatMul): /job:localhost/replica:0/task:0/cpu:0\r\nb: (Const): /job:localhost/replica:0/task:0/cpu:0\r\na: (Const): /job:localhost/replica:0/task:0/cpu:0\r\n[[ 22.  28.]\r\n [ 49.  64.]]\r\n```\r\n\r\nEDIT: oh, got it. Log level works as the lower the number, the more verbose (and 1 seems to be the default):\r\n\r\n```\r\n$ TF_CPP_MIN_LOG_LEVEL=0 python gpu.py\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\nDevice mapping: no known devices.\r\nI tensorflow/core/common_runtime/direct_session.cc:257] Device mapping:\r\n\r\nMatMul: (MatMul): /job:localhost/replica:0/task:0/cpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:841] MatMul: (MatMul)/job:localhost/replica:0/task:0/cpu:0\r\nb: (Const): /job:localhost/replica:0/task:0/cpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:841] b: (Const)/job:localhost/replica:0/task:0/cpu:0\r\na: (Const): /job:localhost/replica:0/task:0/cpu:0\r\nI tensorflow/core/common_runtime/simple_placer.cc:841] a: (Const)/job:localhost/replica:0/task:0/cpu:0\r\n[[ 22.  28.]\r\n [ 49.  64.]]\r\n```", "@oelmekki debug logging was added recently, can you try this with TF 1.0?", "This is already what I'm using, actually :)\r\n\r\n```\r\n$ python -c \"import tensorflow; print(tensorflow.__version__)\"\r\n1.0.0\r\n```", "Sorry, it's TF_CPP_MIN_VLOG_LEVEL not TF_CPP_MIN_LOG_LEVEL (there's also TF_CPP_MIN_LOG_LEVEL which will disable TF_CPP_MIN_VLOG_LEVEL if set)", "Great, thanks, I have a lot more of debugging info indeed :+1: \r\n\r\nSince Vijay mentioned this should be discussed on SO instead, I won't paste it here, but let me know if you want to look at it at any point.\r\n\r\nThanks for help!", "hi @oelmekki @yaroslavvb did you managed to resolve the issue?\r\nI have the same problem able to use GPU before updating tensorflow to V1.3.0. I have also upgraded my Cudnn to V6. My CUDA is v8.0 so I don't seem to understand where the problem is coming from. I can verify that my tensorflow is GPU version because I used tfBInaryUrl for Python2.7-PGU support. Aside this, I have also installed several times with 'pip install tensorflow-gpu' and I still cannot run my codes on gpu. Theano works fine and I could run code with GPU if I use theano. \r\n\r\nWhen I tried to force the computation to be run on GPU , my codes wouldn't run and now, I got this mesage \"Device mapping: no known devices.\r\n\r\nThe frustrating thing is that I was using the GPU before I upgraded to v1.3.0/\r\n\r\nI would appreciate any help as regards this problem.\r\n\"", "Hi @collawolley,\r\n\r\nIndeed, it was solved for me : the problem was that there's a different lib to install for using gpu, `tensorflow-gpu` instead of `tensorflow` ( more info here : https://stackoverflow.com/questions/42326748/tensorflow-on-gpu-no-known-devices-despite-cudas-devicequery-returning-a-pas ).\r\n\r\nThat being said, it's been a while since I haven't used tensorflow (I used it to generate word embedding, but now there are a lot already available), so I can't say for sure if this answer is still relevant.\r\n\r\nBest wishes!", "I had same issue and `pip install tensorflow-gpu` fixed it for me as well.", "pip install tensorflow-gpu wont work for me. Im doing pip install tensorflow-gpu==1.4 since when i do pip install tensorflow-gpu i get this cannot find lib cublas 9.0 error. ", "I am now having the same problem. It was working. I am not sure what broke it. I did app-get update and apt get upgrade today. There was some nvidia stuff in those upgrades. I have also been using conda environments. Now no version of tf I have, either native or conda env is able to find the GPU.\r\n\r\nI am using GTX 1070\r\nUbuntu 16.04\r\nPython 3.5\r\ntf 1.5.0\r\nCuda 9.1\r\ncudnn 7.0.5\r\n\r\nHere is the full error I am getting:\r\n2018-02-13 16:16:49.861468: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n2018-02-13 16:16:49.865479: E tensorflow/stream_executor/cuda/cuda_driver.cc:406] failed call to cuInit: CUDA_ERROR_NO_DEVICE\r\n2018-02-13 16:16:49.865571: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: teves\r\n2018-02-13 16:16:49.865599: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: teves\r\n2018-02-13 16:16:49.865685: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: 390.30.0\r\n2018-02-13 16:16:49.865740: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:369] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  390.12  Wed Dec 20 07:19:16 PST 2017\r\nGCC version:  gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.6) \r\n\"\"\"\r\n2018-02-13 16:16:49.865788: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 390.12.0\r\n2018-02-13 16:16:49.865811: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:303] kernel version 390.12.0 does not match DSO version 390.30.0 -- cannot find working devices in this configuration\r\n\r\n\r\nIf I check my nvidia driver version with: \r\ncat /proc/driver/nvidia/version\r\n\r\nI get:\r\n\r\nNVRM version: NVIDIA UNIX x86_64 Kernel Module  390.12  Wed Dec 20 07:19:16 PST 2017\r\nGCC version:  gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.6) \r\n\r\nHowever if I check the driver version in ubuntu software & updates it says 390.30 \r\n\r\nAny ideas how to fix this?", "Similar issue, tf-gpu detects properly with python 3 while python 2 tf-gpu doesn't detect GPUS.\r\n\r\nUsing TF-GPU 1.4.0 on both\r\n\r\n\r\nEDIT: Installing 1.4.1 fixed the issue, @pGit1 "]}, {"number": 7647, "title": "Error when running image retraining example (retrain.py) with --print_misclassified_test_images flag", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\n- http://stackoverflow.com/questions/17322668/typeerror-dict-keys-object-does-not-support-indexing\r\n- http://stackoverflow.com/questions/18552001/accessing-dict-keys-element-by-index-in-python3\r\n- http://stackoverflow.com/questions/26693055/dict-key-object-does-not-support-indexing-python-3\r\n\r\n### Environment info\r\nOperating System: macOS 10.12.3\r\nPython version: 3.5.2\r\n\r\nInstalled version of CUDA and cuDNN: Not using CUDA\r\n\r\n1. The commit hash (`git rev-parse HEAD`): 89059e6f0b2788b624e744afc21ba2472523a250\r\n2. The output of `bazel version`: \r\n```\r\nBuild label: 0.4.4\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Wed Feb 1 18:56:35 2017 (1485975395)\r\nBuild timestamp: 1485975395\r\nBuild timestamp as int: 1485975395\r\n```\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\nRun this command:\r\n`bazel-bin/tensorflow/examples/image_retraining/retrain --image_dir ~/flower_photos/ --print_misclassified_test_images`\r\n\r\n### What other attempted solutions have you tried?\r\nReviewed source code for retrain.py, both locally and latest version on Github. See lines 892-896 (inside main function). The code looks correct. I suspect it is an issue specific to Python 3. \r\n\r\nI have not tried to run this in Python 2 yet.\r\n\r\n### Logs or other output that would be helpful\r\nThis is what is output:\r\n```\r\n=== MISCLASSIFIED TEST IMAGES ===\r\nTraceback (most recent call last):\r\n  File \"/Users/jsawruk/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/examples/image_retraining/retrain.py\", line 1061, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/Users/jsawruk/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/python/platform/app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/Users/jsawruk/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/examples/image_retraining/retrain.py\", line 896, in main\r\n    print('%70s  %s' % (test_filename, image_lists.keys()[predictions[i]]))\r\nTypeError: 'dict_keys' object does not support indexing\r\n```\r\n\r\nIt appears the solution is to rewrite line 896 from:\r\n`print('%70s  %s' % (test_filename, image_lists.keys()[predictions[i]]))`\r\n\r\nto:\r\n\r\n`print('%70s  %s' % (test_filename, list(image_lists.keys())[predictions[i]]))`\r\n\r\nWhen I edit the code locally to the line above, I no longer get the error when I run the example.", "comments": ["@boyuzhangus: That's a separate issue. It sounds like you either a) don't have bazel installed correctly or b) you have bazel installed correctly but it's not in your path. On my computer, bazel is in $HOME/bin, so I added the following to my .profile:\r\n\r\n`export PATH=\"$PATH:$HOME/bin\"`\r\n\r\nIf you continue to have issues after you have bazel properly installed, please file a separate issue unless you are having the exact issue that I reported with this specific flag.", "@jsawruk, that is definitely a python 2 print statement. Sorry about that. Your fix changed it to the print function, which is the right thing to do. Could you please submit a pull request to fix that. Thanks so much!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Sir, I am seeing this traceback:\r\nTraceback (most recent call last):\r\n  File \".\\retrain.py\", line 1062, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"C:\\Users\\SAKSHIM\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \".\\retrain.py\", line 888, in main\r\n    ground_truth_input: test_ground_truth})\r\n  File \"C:\\Users\\SAKSHIM\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 889, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\Users\\SAKSHIM\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1096, in _run\r\n    % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\r\nValueError: Cannot feed value of shape (0,) for Tensor 'input/BottleneckInputPlaceholder:0', which has shape '(?, 2048)'\r\nMy python version:\r\nPython 3.5.4 (v3.5.4:3f56838, Aug  8 2017, 02:17:05) [MSC v.1900 64 bit (AMD64)] on win32"]}, {"number": 7646, "title": "kernel size in contrib.layers.conv2d", "body": "```conv = tf.contrib.layers.convolution2d(x, num_filters, kernel_size=[height, width])```\r\n\r\nResulting in this error:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n/usr/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/utils.py in n_positive_integers(n, value)\r\n    309   try:\r\n--> 310     value = int(value)\r\n    311   except (TypeError, ValueError):\r\n\r\nTypeError: int() argument must be a string, a bytes-like object or a number, not 'tuple'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-89-04da00716174> in <module>()\r\n      9 for height in convolved_words:\r\n     10     conv = tf.contrib.layers.convolution2d(\r\n---> 11         embed, num_filters, kernel_size=(height, embedding_size))\r\n     12     pool = tf.nn.top_k(conv, k=k_max, sorted=False).value\r\n     13     max_pooled.append(pool)\r\n\r\n/usr/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)\r\n    175       current_args = current_scope[key_func].copy()\r\n    176       current_args.update(kwargs)\r\n--> 177     return func(*args, **current_args)\r\n    178   _add_op(func)\r\n    179   setattr(func_with_args, '_key_op', _key_op(func))\r\n\r\n/usr/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/layers.py in convolution(inputs, num_outputs, kernel_size, stride, padding, data_format, rate, activation_fn, normalizer_fn, normalizer_params, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, reuse, variables_collections, outputs_collections, trainable, scope)\r\n    814                        input_rank)\r\n    815     conv_dims = input_rank - 2\r\n--> 816     kernel_size = utils.n_positive_integers(conv_dims, kernel_size)\r\n    817     stride = utils.n_positive_integers(conv_dims, stride)\r\n    818     rate = utils.n_positive_integers(conv_dims, rate)\r\n\r\n/usr/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/utils.py in n_positive_integers(n, value)\r\n    314       raise ValueError(\r\n    315           'Expected sequence of %d positive integers, but received %r' %\r\n--> 316           (n, value))\r\n    317     try:\r\n    318       values = tuple(int(x) for x in value)\r\n\r\nValueError: Expected sequence of 1 positive integers, but received (3, 128)\r\n```", "comments": ["input tensor shape is `<tf.Tensor 'Reshape_3:0' shape=(?, 10, 128) dtype=float32>`\r\n\r\nOh... I forgot that conv2d requires NHWC inputs, and forgot C=1 expansion", "I'm using \r\n`Z1 = tf.contrib.layers.conv2d(X,W1, stride=[1,1,1,1])` where X is a shape of (input_size, no.of examples) and getting the error:\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-47-31e33cc68e16> in <module>()\r\n      5     X, Y = create_placeholders(64, 64, 3, 6)\r\n      6     parameters = initialize_parameters()\r\n----> 7     Z3 = forward_propagation(X, parameters)\r\n      8     init = tf.global_variables_initializer()\r\n      9     sess.run(init)\r\n\r\n<ipython-input-46-c985a9aff991> in forward_propagation(X, parameters)\r\n     25     ### START CODE HERE ###\r\n     26     # CONV2D: stride of 1, padding 'SAME'\r\n---> 27     Z1 = tf.contrib.layers.conv2d(X,W1, stride=[1,1,1,1])\r\n     28     # RELU\r\n     29     A1 = tf.nn.relu(Z1)\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)\r\n    179       current_args = current_scope[key_func].copy()\r\n    180       current_args.update(kwargs)\r\n--> 181     return func(*args, **current_args)\r\n    182   _add_op(func)\r\n    183   setattr(func_with_args, '_key_op', _key_op(func))\r\n\r\nTypeError: convolution() missing 1 required positional argument: 'kernel_size'\r\n```\r\nCan you please tell me how to fix this ?", "Hey there, Just now I've got a solution of this.\r\nJust use `tf.nn.conv2d(inputs, num_outputs, strides, padding)` in place of `tf.contrib.layers.conv2d(inputs, num_outputs, kernel_size, stride)`\r\n\r\nThank You  : )"]}, {"number": 7645, "title": "CCI Best Practices", "body": "Google is a member of CCI. What do you think to add [CCI badge](https://bestpractices.coreinfrastructure.org) to TF repository?\r\n", "comments": ["@martinwicke, have we considered this?", "Sure. I think we're meeting these criteria, we just have to apply. ", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Assigneee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "We're not done with this, but the badge tracks progress, so closing this seems appropriate."]}, {"number": 7644, "title": "Feature request: Save the logging to a file", "body": "According to [this SO question](http://stackoverflow.com/questions/40559667/how-to-redirect-tensorflow-logging-to-a-file), saving the logger output to a file is not supported.\r\n\r\nWould be great if that would be possible.\r\n\r\nThank you\r\n\r\n\r\n", "comments": ["Could you just use unix style file redirection?\r\ni.e. \r\n```\r\ncmd > foo.txt\r\n```\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Try `cmd 1>foo.txt 2>&1`. It works for me."]}, {"number": 7643, "title": "Interaction between tf.map_fn and tf.gradients", "body": "Hi,\r\n\r\nI am using Tensorflow v0.11 and I have tried on Mac OS X and Centos 6\r\n\r\nI am running into an error when running the following code:\r\n\r\n```\r\nW = tf.get_variable('W', (5, 3))\r\n\r\nx = tf.placeholder(tf.float32, shape=(None, 5))\r\n\r\nh = tf.matmul(x, W)\r\n\r\ngrads = tf.map_fn(lambda x: tf.gradients(x, W)[0], h)\r\n```\r\n\r\nI basically want to have the following but without a fixed batch size:\r\n`grads = [tf.gradients(h[t], W)[0] for t in range(batch_size)]`\r\n\r\nMy error is:\r\n\r\n```\r\nInvalid argument: TensorArray map/TensorArray_1@map/while/gradients: Could not write to TensorArray index 3 because it has already been read.\r\n[...]\r\ntensorflow.python.framework.errors.InvalidArgumentError: TensorArray map/TensorArray_1@map/while/gradients: Could not write to TensorArray index 3 because it has already been read.\r\n\t [[Node: map/while/gradients/map/while/TensorArrayRead_grad/TensorArrayWrite = TensorArrayWrite[T=DT_FLOAT, _class=[\"loc:@map/TensorArray\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](map/while/gradients/map/while/TensorArrayRead_grad/TensorArrayGrad/TensorArrayGrad, map/while/Identity, map/while/gradients/Fill, map/while/gradients/map/while/TensorArrayRead_grad/TensorArrayGrad/gradient_flow)]]\r\n```\r\n\r\nI have tried the following workaround using `scan` instead of `map_fn` with a zero initializer but to no avail:\r\n```\r\ninitializer = np.zeros((5, 3)).astype('float32')\r\ngrads = tf.scan(\r\n\tlambda a, x: tf.gradients(x, W)[0],\r\n\th,\r\n\tinitializer)\r\n```\r\n\r\nIs this a know issue? ", "comments": ["@yuanbyu, do you have any ideas? @daniellevy , could you try 1.0, please and see if this is still a problem.", "Yes the problem still occurs with v1.0 with the same error message.", "It looks like this is a known issue and this issue is probably a duplicate of #3972. There @yuanbyu suggests using tf.while_loop instead of tf.map_fn. Give that a try and let us know if that works. Thanks!", "I think this works\r\n\r\n```\r\nmax_seq_len = 10\r\nx = tf.placeholder(tf.float32, [None, 5])\r\nW = tf.get_variable(\"W\", [5, 3])\r\nh = tf.matmul(x, W)\r\n\r\ndef body(old_g, t):\r\n    g = tf.gradients([h[t]], [W])[0]\r\n    new_g = tuple(tf.select(tf.equal(ti, t), g, old_g[ti]) for ti in range(len(old_g)))\r\n    return new_g, t + 1\r\n\r\ndef cond(_, t):\r\n    return tf.less(t, tf.shape(h)[0])\r\n\r\ngrads = tf.while_loop(cond, body, [(tf.zeros_like(W),)*max_seq_len, tf.constant(0)])\r\n\r\nwith tf.Session() as sess:\r\n    tf.global_variables_initializer().run()\r\n    grads_out = sess.run(grads, feed_dict={x: np.random.randn(2*5).reshape(2, 5)})\r\n```\r\n\r\nYou basically just build a giant empty tuple and fill it in as you go. dynmaic_rnn does something similar to this. ", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 7642, "title": "v1.0.0 on Centos 7 complie error whith cuda 8.0", "body": "build with --config=cuda get error\r\n[rnd@localhost tensorflow]$ bazel build -c opt --config=cuda tensorflow/tools/pip_package:build_pip_package --verbose_failures\r\nINFO: $TEST_TMPDIR defined: output root default is '/home/rnd/tmp'.\r\n......\r\nWARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.build/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.\r\nWARNING: /home/rnd/gits/tensorflow/tensorflow/workspace.bzl:27:5: \r\nCurrent Bazel is not a release version, cannot check for compatibility.\r\nWARNING: /home/rnd/gits/tensorflow/tensorflow/workspace.bzl:28:5: Make sure that you are running at least Bazel 0.4.2.\r\n.\r\nINFO: Found 1 target...\r\nERROR: /home/rnd/tmp/_bazel_rnd/707043e71401a80a1e11714c15a7b311/external/pcre/BUILD:5:1: undeclared inclusion(s) in rule '@pcre//:pcre':\r\nthis rule is missing dependency declarations for the following files included by 'external/pcre/pcre_globals.c':\r\n  '/lib/gcc/x86_64-redhat-linux/4.8.5/include/limits.h'\r\n  '/lib/gcc/x86_64-redhat-linux/4.8.5/include/syslimits.h'\r\n  '/lib/gcc/x86_64-redhat-linux/4.8.5/include/stddef.h'\r\n  '/lib/gcc/x86_64-redhat-linux/4.8.5/include/stdarg.h'\r\n  '/lib/gcc/x86_64-redhat-linux/4.8.5/include/stdint.h'.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 6.763s, Critical Path: 0.73s\r\n\r\n### Environment info\r\nOperating System:\r\nCentOS Linux release 7.2.1511 (Core)\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n[rnd@localhost ~]$ ls /usr/local/cuda/lib64/libcud*\r\n/usr/local/cuda/lib64/libcudadevrt.a\r\n/usr/local/cuda/lib64/libcudart.so\r\n/usr/local/cuda/lib64/libcudart.so.8.0\r\n/usr/local/cuda/lib64/libcudart.so.8.0.44\r\n/usr/local/cuda/lib64/libcudart_static.a\r\n/usr/local/cuda/lib64/libcudnn.so\r\n/usr/local/cuda/lib64/libcudnn.so.5\r\n/usr/local/cuda/lib64/libcudnn.so.5.1.5\r\n/usr/local/cuda/lib64/libcudnn_static.a\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n[rnd@localhost tensorflow]$ git rev-parse HEAD\r\n07bb8ea2379bd459832b23951fb20ec47f3fdbd4\r\n\r\n2. The output of `bazel version`\r\n[rnd@localhost bazel]$ git checkout 0.4.2\r\nHEAD is now at ba94a7b... Release 0.4.2 (2016-12-02)\r\n[rnd@localhost bazel]$ git rev-parse HEAD\r\nba94a7b93e1c95bca1928d8c51c6adc62ed864ab\r\n[rnd@localhost bazel]$ bazel version\r\nINFO: $TEST_TMPDIR defined: output root default is '/home/rnd/tmp'.\r\n......\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Thu Jan 01 00:00:00 1970 (0)\r\nBuild timestamp: Thu Jan 01 00:00:00 1970 (0)\r\nBuild timestamp as int: 0\r\n\r\n### What other attempted solutions have you tried?\r\ndelete \"--config=cuda\" will be OK, but I need cuda \r\n\r\n[rnd@localhost tensorflow]$ bazel build -c opt  tensorflow/tools/pip_package:build_pip_package --verbose_failures\r\n\r\n\r\n", "comments": ["We don't officially support CentOS. Some people have managed to get it to work with the cmake build file. Please search existing issues."]}, {"number": 7640, "title": "ImportError: No module named 'tensorflow.contrib.distributions.python.ops.bijectors'", "body": "I want to run tensorflow 1.0 RC2 on windows 10, but encounter issues #7540, #7500, then follow the suggestion to install Nightly Build version (http://ci.tensorflow.org/view/Nightly/job/nightly-win/DEVICE=cpu,OS=windows/87/artifact/cmake_build/tf_python/dist/tensorflow-1.0.0-cp35-cp35m-win_amd64.whl),  but still encounter the following issue:\r\n=================================\r\n(tensorflow_py35) C:\\Work\\tensorflow\\tensorflow\\examples\\tutorials\\mnist>python mnist_softmax.py\r\nTraceback (most recent call last):\r\n  File \"mnist_softmax.py\", line 28, in <module>\r\n    from tensorflow.examples.tutorials.mnist import input_data\r\n  File \"C:\\Miniconda3\\envs\\tensorflow_py35\\lib\\site-packages\\tensorflow\\examples\\tutorials\\mnist\\__init__.py\", line 21, in <module>\r\n    from tensorflow.examples.tutorials.mnist import input_data\r\n  File \"C:\\Miniconda3\\envs\\tensorflow_py35\\lib\\site-packages\\tensorflow\\examples\\tutorials\\mnist\\input_data.py\", line 29, in <module>\r\n    from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\r\n  File \"C:\\Miniconda3\\envs\\tensorflow_py35\\lib\\site-packages\\tensorflow\\contrib\\__init__.py\", line 22, in <module>\r\n    from tensorflow.contrib import bayesflow\r\n  File \"C:\\Miniconda3\\envs\\tensorflow_py35\\lib\\site-packages\\tensorflow\\contrib\\bayesflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.contrib.bayesflow.python.ops import entropy\r\n  File \"C:\\Miniconda3\\envs\\tensorflow_py35\\lib\\site-packages\\tensorflow\\contrib\\bayesflow\\python\\ops\\entropy.py\", line 23, in <module>\r\n    from tensorflow.contrib.bayesflow.python.ops.entropy_impl import *\r\n  File \"C:\\Miniconda3\\envs\\tensorflow_py35\\lib\\site-packages\\tensorflow\\contrib\\bayesflow\\python\\ops\\entropy_impl.py\", line 30, in <module>\r\n    from tensorflow.contrib.bayesflow.python.ops import variational_inference\r\n  File \"C:\\Miniconda3\\envs\\tensorflow_py35\\lib\\site-packages\\tensorflow\\contrib\\bayesflow\\python\\ops\\variational_inference.py\", line 26, in <module>\r\n    from tensorflow.contrib.bayesflow.python.ops.variational_inference_impl import *\r\n  File \"C:\\Miniconda3\\envs\\tensorflow_py35\\lib\\site-packages\\tensorflow\\contrib\\bayesflow\\python\\ops\\variational_inference_impl.py\", line 29, in <module>\r\n    from tensorflow.contrib.bayesflow.python.ops import stochastic_graph as sg\r\n  File \"C:\\Miniconda3\\envs\\tensorflow_py35\\lib\\site-packages\\tensorflow\\contrib\\bayesflow\\python\\ops\\stochastic_graph.py\", line 28, in <module>\r\n    from tensorflow.contrib.bayesflow.python.ops import stochastic_tensor\r\n  File \"C:\\Miniconda3\\envs\\tensorflow_py35\\lib\\site-packages\\tensorflow\\contrib\\bayesflow\\python\\ops\\stochastic_tensor.py\", line 39, in <module>\r\n    from tensorflow.contrib.distributions.python.ops import distribution\r\n  File \"C:\\Miniconda3\\envs\\tensorflow_py35\\lib\\site-packages\\tensorflow\\contrib\\distributions\\__init__.py\", line 91, in <module>\r\n    from tensorflow.contrib.distributions.python.ops.conditional_transformed_distribution import *\r\n  File \"C:\\Miniconda3\\envs\\tensorflow_py35\\lib\\site-packages\\tensorflow\\contrib\\distributions\\python\\ops\\conditional_transformed_distribution.py\", line 22, in <module>\r\n    from tensorflow.contrib.distributions.python.ops import transformed_distribution\r\n  File \"C:\\Miniconda3\\envs\\tensorflow_py35\\lib\\site-packages\\tensorflow\\contrib\\distributions\\python\\ops\\transformed_distribution.py\", line 24, in <module>\r\n    from tensorflow.contrib.distributions.python.ops.bijectors import identity as identity_lib\r\nImportError: No module named 'tensorflow.contrib.distributions.python.ops.bijectors'\r\n\r\n\r\n", "comments": ["Are these problems present if you try TensorFlow 1.0 (newer than RC2)?", "patch of #7617 fix the issue, the latest master auto-build works fine."]}, {"number": 7639, "title": "nnbnrnhnvjb", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\r\n\r\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\r\nout of scope for GitHub Issues and point people to StackOverflow.\r\n\r\nFor bugs or installation issues, please provide the following information.\r\nThe more information you provide, the more easily we will be able to offer\r\nhelp and advice.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\n### Environment info\r\nOperating System:\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n2. The output of `bazel version`\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\n\r\n### What other attempted solutions have you tried?\r\n\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n", "comments": ["Please ignore. "]}, {"number": 7638, "title": "Links to Android nightly builds on README.md are broken", "body": "Links to Android nightly builds on https://github.com/tensorflow/tensorflow/blob/master/README.md are broken.\r\n\r\n![image](https://cloud.githubusercontent.com/assets/15331/23086006/c80cc702-f538-11e6-927d-d44b1f5f80e2.png)\r\n\r\n-->\r\n![image](https://cloud.githubusercontent.com/assets/15331/23086019/d91aa082-f538-11e6-9d76-7e56cd879900.png)\r\n", "comments": ["@yifeif, @gunan, could you take a look?", "This looks like a bad merge. The nightly-matrix-android link can be deleted, and the correct links to nightly-android are found just below.", "Thanks @andrewharp for pointing to the correct link! Closing."]}, {"number": 7637, "title": "iris_monitors.py broken in release r1.0 due to inacurate MetricSpec namespace", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\r\n\r\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\r\nout of scope for GitHub Issues and point people to StackOverflow.\r\n\r\nFor bugs or installation issues, please provide the following information.\r\nThe more information you provide, the more easily we will be able to offer\r\nhelp and advice.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\n`tf.contrib.learn.metric_spec.MetricSpec` should be changed to `MetricSpec` in iris_monitors.py in release 1.0.0\r\n\r\nNo need to import MetricSpec in iris_monitors.py it's already imported on line 24 in commit [fa4ba830f437fdb9dc1085b4d68a3bab41a16e20](https://github.com/tensorflow/tensorflow/blob/fa4ba830f437fdb9dc1085b4d68a3bab41a16e20/tensorflow/examples/tutorials/monitors/iris_monitors.py):\r\n`tensorflow.contrib.learn.python.learn.metric_spec import MetricSpec`\r\n\r\n### Environment info\r\nOperating System:\r\n>tensorflow/tensorflow/examples/tutorials/monitors$ lsb_release -a\r\nNo LSB modules are available.\r\nDistributor ID:\tUbuntu\r\nDescription:\tUbuntu 16.04.1 LTS\r\nRelease:\t16.04\r\nCodename:\txenial\r\n>tensorflow/tensorflow/examples/tutorials/monitors$ uname -a\r\nLinux panchito 4.4.0-62-generic-tuxonice #83~ppa1-Ubuntu SMP Thu Feb 2 23:17:45 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n```\r\nrepositories/tensorflow/tensorflow/examples/tutorials/monitors$ python -c \"import tensorflow; print(tensorflow.__version__)\"\r\n1.0.0\r\n```\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n2. The output of `bazel version`\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\nrepositories/tensorflow/tensorflow/examples/tutorials/monitors$ python iris_monitors.py\r\nTraceback (most recent call last):\r\n  File \"iris_monitors.py\", line 116, in <module>\r\n    tf.app.run()\r\n  File \"/home/chidochipotle/anaconda3/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"iris_monitors.py\", line 42, in main\r\n    tf.contrib.learn.metric_spec.MetricSpec(\r\nAttributeError: module 'tensorflow.contrib.learn' has no attribute 'metric_spec'\r\n\r\n### What other attempted solutions have you tried?\r\n\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n", "comments": ["Needs many more changes to work, iris_monitors.py seems to be is totally broken with r1.0 or I am just too newbie to understand what's wrong ...\r\n\r\nAfter fixing a couple of more inaccurate imports I get lots of warnings when I run it:\r\n\r\n```\r\ndkor@panchito:~/repositories/tensorflow/tensorflow/examples/tutorials/monitors$ python iris_monitors.py \r\nWARNING:tensorflow:From /home/dkor/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:322: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\r\nInstructions for updating:\r\nMonitors are deprecated. Please use tf.train.SessionRunHook.\r\nWARNING:tensorflow:From /home/dkor/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:322: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\r\nInstructions for updating:\r\nMonitors are deprecated. Please use tf.train.SessionRunHook.\r\nINFO:tensorflow:Using config: {'_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdc67b414e0>, '_is_chief': True, '_tf_random_seed': None, '_task_type': None, '_keep_checkpoint_max': 5, '_master': '', '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_environment': 'local', '_save_checkpoints_secs': 1, '_num_ps_replicas': 0, '_tf_config': gpu_options {\r\n  per_process_gpu_memory_fraction: 1\r\n}\r\n, '_save_checkpoints_steps': None, '_task_id': 0, '_evaluation_master': ''}\r\n/home/dkor/anaconda3/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py:247: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\r\n  equality = a == b\r\nWARNING:tensorflow:From iris_monitors.py:104: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\r\nInstructions for updating:\r\nEstimator is decoupled from Scikit Learn interface by moving into\r\nseparate class SKCompat. Arguments x, y and batch_size are only\r\navailable in the SKCompat class, Estimator will only accept input_fn.\r\nExample conversion:\r\n  est = Estimator(...) -> est = SKCompat(Estimator(...))\r\nWARNING:tensorflow:From iris_monitors.py:104: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\r\nInstructions for updating:\r\nEstimator is decoupled from Scikit Learn interface by moving into\r\nseparate class SKCompat. Arguments x, y and batch_size are only\r\navailable in the SKCompat class, Estimator will only accept input_fn.\r\nExample conversion:\r\n  est = Estimator(...) -> est = SKCompat(Estimator(...))\r\nWARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\r\nWARNING:tensorflow:From /home/dkor/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\nINFO:tensorflow:Saving checkpoints for 851 into /tmp/iris_model/model.ckpt.\r\nINFO:tensorflow:loss = 0.0496295, step = 851\r\nWARNING:tensorflow:From /home/dkor/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:712: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\r\nInstructions for updating:\r\nEstimator is decoupled from Scikit Learn interface by moving into\r\nseparate class SKCompat. Arguments x, y and batch_size are only\r\navailable in the SKCompat class, Estimator will only accept input_fn.\r\nExample conversion:\r\n  est = Estimator(...) -> est = SKCompat(Estimator(...))\r\nWARNING:tensorflow:From /home/dkor/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:712: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\r\nInstructions for updating:\r\nEstimator is decoupled from Scikit Learn interface by moving into\r\nseparate class SKCompat. Arguments x, y and batch_size are only\r\navailable in the SKCompat class, Estimator will only accept input_fn.\r\nExample conversion:\r\n  est = Estimator(...) -> est = SKCompat(Estimator(...))\r\nWARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\r\nWARNING:tensorflow:From /home/dkor/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\nINFO:tensorflow:Starting evaluation at 2017-02-17-23:21:20\r\nINFO:tensorflow:Finished evaluation at 2017-02-17-23:21:21\r\nINFO:tensorflow:Saving dict for global step 851: accuracy = 0.966667, auc = 0.998333, global_step = 851, loss = 0.0598002, precision = 1.0, recall = 1.0\r\nWARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\r\nINFO:tensorflow:Validation (step 851): precision = 1.0, auc = 0.998333, loss = 0.0598002, recall = 1.0, accuracy = 0.966667, global_step = 851\r\nINFO:tensorflow:Saving checkpoints for 852 into /tmp/iris_model/model.ckpt.\r\nWARNING:tensorflow:From /home/dkor/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:712: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\r\nInstructions for updating:\r\nEstimator is decoupled from Scikit Learn interface by moving into\r\nseparate class SKCompat. Arguments x, y and batch_size are only\r\navailable in the SKCompat class, Estimator will only accept input_fn.\r\nExample conversion:\r\n  est = Estimator(...) -> est = SKCompat(Estimator(...))\r\nWARNING:tensorflow:From /home/dkor/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:712: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\r\nInstructions for updating:\r\nEstimator is decoupled from Scikit Learn interface by moving into\r\nseparate class SKCompat. Arguments x, y and batch_size are only\r\navailable in the SKCompat class, Estimator will only accept input_fn.\r\nExample conversion:\r\n  est = Estimator(...) -> est = SKCompat(Estimator(...))\r\nWARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\r\nWARNING:tensorflow:From /home/dkor/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\nINFO:tensorflow:Starting evaluation at 2017-02-17-23:21:23\r\nINFO:tensorflow:Finished evaluation at 2017-02-17-23:21:23\r\nINFO:tensorflow:Saving dict for global step 852: accuracy = 0.966667, auc = 0.998333, global_step = 852, loss = 0.0556784, precision = 1.0, recall = 1.0\r\nWARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\r\nINFO:tensorflow:Validation (step 901): precision = 1.0, auc = 0.998333, loss = 0.0556784, recall = 1.0, accuracy = 0.966667, global_step = 852\r\nINFO:tensorflow:Saving checkpoints for 902 into /tmp/iris_model/model.ckpt.\r\nINFO:tensorflow:global_step/sec: 23.6534\r\nINFO:tensorflow:loss = 0.0484522, step = 951\r\nWARNING:tensorflow:From /home/dkor/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:712: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\r\nInstructions for updating:\r\nEstimator is decoupled from Scikit Learn interface by moving into\r\nseparate class SKCompat. Arguments x, y and batch_size are only\r\navailable in the SKCompat class, Estimator will only accept input_fn.\r\nExample conversion:\r\n  est = Estimator(...) -> est = SKCompat(Estimator(...))\r\nWARNING:tensorflow:From /home/dkor/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:712: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\r\nInstructions for updating:\r\nEstimator is decoupled from Scikit Learn interface by moving into\r\nseparate class SKCompat. Arguments x, y and batch_size are only\r\navailable in the SKCompat class, Estimator will only accept input_fn.\r\nExample conversion:\r\n  est = Estimator(...) -> est = SKCompat(Estimator(...))\r\nWARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\r\nWARNING:tensorflow:From /home/dkor/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\nINFO:tensorflow:Starting evaluation at 2017-02-17-23:21:24\r\nINFO:tensorflow:Finished evaluation at 2017-02-17-23:21:25\r\nINFO:tensorflow:Saving dict for global step 902: accuracy = 0.966667, auc = 0.998333, global_step = 902, loss = 0.0556355, precision = 1.0, recall = 1.0\r\nWARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\r\nINFO:tensorflow:Validation (step 951): precision = 1.0, auc = 0.998333, loss = 0.0556355, recall = 1.0, accuracy = 0.966667, global_step = 902\r\nINFO:tensorflow:Saving checkpoints for 952 into /tmp/iris_model/model.ckpt.\r\nWARNING:tensorflow:From /home/dkor/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:712: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\r\nInstructions for updating:\r\nEstimator is decoupled from Scikit Learn interface by moving into\r\nseparate class SKCompat. Arguments x, y and batch_size are only\r\navailable in the SKCompat class, Estimator will only accept input_fn.\r\nExample conversion:\r\n  est = Estimator(...) -> est = SKCompat(Estimator(...))\r\nWARNING:tensorflow:From /home/dkor/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:712: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\r\nInstructions for updating:\r\nEstimator is decoupled from Scikit Learn interface by moving into\r\nseparate class SKCompat. Arguments x, y and batch_size are only\r\navailable in the SKCompat class, Estimator will only accept input_fn.\r\nExample conversion:\r\n  est = Estimator(...) -> est = SKCompat(Estimator(...))\r\nWARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\r\nWARNING:tensorflow:From /home/dkor/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\nINFO:tensorflow:Starting evaluation at 2017-02-17-23:21:26\r\nINFO:tensorflow:Finished evaluation at 2017-02-17-23:21:26\r\nINFO:tensorflow:Saving dict for global step 952: accuracy = 0.966667, auc = 0.998333, global_step = 952, loss = 0.0556713, precision = 1.0, recall = 1.0\r\nWARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\r\nINFO:tensorflow:Validation (step 1001): precision = 1.0, auc = 0.998333, loss = 0.0556713, recall = 1.0, accuracy = 0.966667, global_step = 952\r\nINFO:tensorflow:Saving checkpoints for 1002 into /tmp/iris_model/model.ckpt.\r\nINFO:tensorflow:global_step/sec: 31.7257\r\nINFO:tensorflow:loss = 0.0475382, step = 1051\r\nWARNING:tensorflow:From /home/dkor/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:712: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\r\nInstructions for updating:\r\nEstimator is decoupled from Scikit Learn interface by moving into\r\nseparate class SKCompat. Arguments x, y and batch_size are only\r\navailable in the SKCompat class, Estimator will only accept input_fn.\r\nExample conversion:\r\n  est = Estimator(...) -> est = SKCompat(Estimator(...))\r\nWARNING:tensorflow:From /home/dkor/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:712: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\r\nInstructions for updating:\r\nEstimator is decoupled from Scikit Learn interface by moving into\r\nseparate class SKCompat. Arguments x, y and batch_size are only\r\navailable in the SKCompat class, Estimator will only accept input_fn.\r\nExample conversion:\r\n  est = Estimator(...) -> est = SKCompat(Estimator(...))\r\nWARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\r\nWARNING:tensorflow:From /home/dkor/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\nINFO:tensorflow:Starting evaluation at 2017-02-17-23:21:27\r\nINFO:tensorflow:Finished evaluation at 2017-02-17-23:21:28\r\nINFO:tensorflow:Saving dict for global step 1002: accuracy = 0.966667, auc = 0.998333, global_step = 1002, loss = 0.0556784, precision = 1.0, recall = 1.0\r\nWARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\r\nINFO:tensorflow:Validation (step 1051): precision = 1.0, auc = 0.998333, loss = 0.0556784, recall = 1.0, accuracy = 0.966667, global_step = 1002\r\nINFO:tensorflow:Saving checkpoints for 1052 into /tmp/iris_model/model.ckpt.\r\nWARNING:tensorflow:From /home/dkor/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:712: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\r\nInstructions for updating:\r\nEstimator is decoupled from Scikit Learn interface by moving into\r\nseparate class SKCompat. Arguments x, y and batch_size are only\r\navailable in the SKCompat class, Estimator will only accept input_fn.\r\nExample conversion:\r\n  est = Estimator(...) -> est = SKCompat(Estimator(...))\r\nWARNING:tensorflow:From /home/dkor/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:712: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\r\nInstructions for updating:\r\nEstimator is decoupled from Scikit Learn interface by moving into\r\nseparate class SKCompat. Arguments x, y and batch_size are only\r\navailable in the SKCompat class, Estimator will only accept input_fn.\r\nExample conversion:\r\n  est = Estimator(...) -> est = SKCompat(Estimator(...))\r\nWARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\r\nWARNING:tensorflow:From /home/dkor/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\nINFO:tensorflow:Starting evaluation at 2017-02-17-23:21:29\r\nINFO:tensorflow:Finished evaluation at 2017-02-17-23:21:29\r\nINFO:tensorflow:Saving dict for global step 1052: accuracy = 0.966667, auc = 0.998333, global_step = 1052, loss = 0.0557572, precision = 1.0, recall = 1.0\r\nWARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\r\nINFO:tensorflow:Validation (step 1101): precision = 1.0, auc = 0.998333, loss = 0.0557572, recall = 1.0, accuracy = 0.966667, global_step = 1052\r\nINFO:tensorflow:Saving checkpoints for 1102 into /tmp/iris_model/model.ckpt.\r\nINFO:tensorflow:global_step/sec: 32.9999\r\nINFO:tensorflow:loss = 0.0466149, step = 1151\r\nWARNING:tensorflow:From /home/dkor/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:712: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\r\nInstructions for updating:\r\nEstimator is decoupled from Scikit Learn interface by moving into\r\nseparate class SKCompat. Arguments x, y and batch_size are only\r\navailable in the SKCompat class, Estimator will only accept input_fn.\r\nExample conversion:\r\n  est = Estimator(...) -> est = SKCompat(Estimator(...))\r\nWARNING:tensorflow:From /home/dkor/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:712: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\r\nInstructions for updating:\r\nEstimator is decoupled from Scikit Learn interface by moving into\r\nseparate class SKCompat. Arguments x, y and batch_size are only\r\navailable in the SKCompat class, Estimator will only accept input_fn.\r\nExample conversion:\r\n  est = Estimator(...) -> est = SKCompat(Estimator(...))\r\nWARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\r\nWARNING:tensorflow:From /home/dkor/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\nINFO:tensorflow:Starting evaluation at 2017-02-17-23:21:30\r\nINFO:tensorflow:Finished evaluation at 2017-02-17-23:21:31\r\nINFO:tensorflow:Saving dict for global step 1102: accuracy = 0.966667, auc = 0.998333, global_step = 1102, loss = 0.0559047, precision = 1.0, recall = 1.0\r\nWARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\r\nINFO:tensorflow:Validation (step 1151): precision = 1.0, auc = 0.998333, loss = 0.0559047, recall = 1.0, accuracy = 0.966667, global_step = 1102\r\nINFO:tensorflow:Stopping. Best step: 951 with loss = 0.05563554912805557.\r\nINFO:tensorflow:Saving checkpoints for 1151 into /tmp/iris_model/model.ckpt.\r\nINFO:tensorflow:Loss for final step: 0.0466149.\r\nWARNING:tensorflow:From iris_monitors.py:108: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\r\nInstructions for updating:\r\nEstimator is decoupled from Scikit Learn interface by moving into\r\nseparate class SKCompat. Arguments x, y and batch_size are only\r\navailable in the SKCompat class, Estimator will only accept input_fn.\r\nExample conversion:\r\n  est = Estimator(...) -> est = SKCompat(Estimator(...))\r\nWARNING:tensorflow:From iris_monitors.py:108: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\r\nInstructions for updating:\r\nEstimator is decoupled from Scikit Learn interface by moving into\r\nseparate class SKCompat. Arguments x, y and batch_size are only\r\navailable in the SKCompat class, Estimator will only accept input_fn.\r\nExample conversion:\r\n  est = Estimator(...) -> est = SKCompat(Estimator(...))\r\nWARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\r\nWARNING:tensorflow:From /home/dkor/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\nINFO:tensorflow:Starting evaluation at 2017-02-17-23:21:32\r\nINFO:tensorflow:Finished evaluation at 2017-02-17-23:21:32\r\nINFO:tensorflow:Saving dict for global step 1151: accuracy = 0.966667, auc = 0.998333, global_step = 1151, loss = 0.0619039\r\nWARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\r\nAccuracy: 0.966667\r\nWARNING:tensorflow:From /home/dkor/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:374: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\r\nInstructions for updating:\r\nEstimator is decoupled from Scikit Learn interface by moving into\r\nseparate class SKCompat. Arguments x, y and batch_size are only\r\navailable in the SKCompat class, Estimator will only accept input_fn.\r\nExample conversion:\r\n  est = Estimator(...) -> est = SKCompat(Estimator(...))\r\nWARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\r\nPredictions: [1, 2]\r\ndkor@panchito:~/repositories/tensorflow/tensorflow/examples/tutorials/monitors$ \r\n\r\n\r\n```", "I'm getting the errors using the latest nightly TF build (3/3/2017) with the Iris dataset. I see this issue as closed. So how was it fixed?\r\nIt worked fine prior to 1.0. Using python 3.5.1 on Windows, no gpu.\r\ncode is the same as the example in https://www.tensorflow.org/get_started/tflearn\r\n\r\nErrors:\r\n\r\nC:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:248: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\r\n  equality = a == b\r\nWARNING:tensorflow:From C:\\Users\\Jake\\py\\files\\Iris\\Iris_TF_example.py:34: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\r\nInstructions for updating:\r\nEstimator is decoupled from Scikit Learn interface by moving into\r\nseparate class SKCompat. Arguments x, y and batch_size are only\r\navailable in the SKCompat class, Estimator will only accept input_fn.\r\nExample conversion:\r\n  est = Estimator(...) -> est = SKCompat(Estimator(...))\r\nWARNING:tensorflow:From C:\\Users\\Jake\\py\\files\\Iris\\Iris_TF_example.py:34: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\r\nInstructions for updating:\r\nEstimator is decoupled from Scikit Learn interface by moving into\r\nseparate class SKCompat. Arguments x, y and batch_size are only\r\navailable in the SKCompat class, Estimator will only accept input_fn.\r\nExample conversion:\r\n  est = Estimator(...) -> est = SKCompat(Estimator(...))\r\nWARNING:tensorflow:From C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:527: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\n2017-03-03 09:47:24.299814: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\cpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-03-03 09:47:24.303698: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\cpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-03-03 09:47:24.305520: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\cpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-03-03 09:47:24.309054: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\cpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-03-03 09:47:24.311934: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\cpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-03-03 09:47:24.329330: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\cpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-03-03 09:47:24.330449: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\cpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-03-03 09:47:24.340085: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\cpu\\os\\windows\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-03-03 09:47:24.891764: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:1150] Not found: Key dnn/hiddenlayer_1/biases/denlayer_1/biases/part_0/Adagrad not found in checkpoint\r\n2017-03-03 09:47:24.897697: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:1150] Not found: Key dnn/hiddenlayer_0/weights/enlayer_0/weights/part_0/Adagrad not found in checkpoint\r\n2017-03-03 09:47:24.909642: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:1150] Not found: Key dnn/hiddenlayer_1/weights/enlayer_1/weights/part_0/Adagrad not found in checkpoint\r\n2017-03-03 09:47:24.912938: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:1150] Not found: Key dnn/hiddenlayer_2/biases/denlayer_2/biases/part_0/Adagrad not found in checkpoint\r\n2017-03-03 09:47:24.917436: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:1150] Not found: Key dnn/hiddenlayer_2/weights/enlayer_2/weights/part_0/Adagrad not found in checkpoint\r\n2017-03-03 09:47:24.918026: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:1150] Not found: Key dnn/hiddenlayer_0/biases/denlayer_0/biases/part_0/Adagrad not found in checkpoint\r\n2017-03-03 09:47:24.925070: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:1150] Not found: Key dnn/logits/biases/dnn/logits/biases/part_0/Adagrad not found in checkpoint\r\n2017-03-03 09:47:24.930800: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:1150] Not found: Key dnn/multi_class_head/dnn/learning_rate not found in checkpoint\r\n2017-03-03 09:47:24.931319: W c:\\tf_jenkins\\home\\workspace\\nightly-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:1150] Not found: Key dnn/logits/weights/nn/logits/weights/part_0/Adagrad not found in checkpoint\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1024, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1006, in _run_fn\r\n    status, run_metadata)\r\n  File \"C:\\Users\\Jake\\AppData\\Local\\Programs\\Python\\Python35\\lib\\contextlib.py\", line 66, in __exit__\r\n    next(self.gen)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.NotFoundError: Key dnn/hiddenlayer_1/biases/denlayer_1/biases/part_0/Adagrad not found in checkpoint\r\n         [[Node: save/RestoreV2_5 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_5/tensor_names, save/RestoreV2_5/shape_and_slices)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Jake\\py\\files\\Iris\\Iris_TF_example.py\", line 34, in <module>\r\n    steps=2000)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 281, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 402, in fit\r\n    SKCompat(self).fit(x, y, batch_size, steps, max_steps, monitors)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 1301, in fit\r\n    monitors=all_monitors)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 281, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 418, in fit\r\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 962, in _train_model\r\n    config=config_pb2.ConfigProto(allow_soft_placement=True)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 332, in MonitoredTrainingSession\r\n    stop_grace_period_secs=stop_grace_period_secs)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 626, in __init__\r\n    stop_grace_period_secs=stop_grace_period_secs)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 455, in __init__\r\n    self._sess = _RecoverableSession(self._coordinated_creator)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 799, in __init__\r\n    _WrappedSession.__init__(self, self._create_session())\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 804, in _create_session\r\n    return self._sess_creator.create_session()\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 516, in create_session\r\n    self.tf_sess = self._session_creator.create_session()\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 392, in create_session\r\n    init_fn=self._scaffold.init_fn)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\training\\session_manager.py\", line 256, in prepare_session\r\n    config=config)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\training\\session_manager.py\", line 188, in _restore_checkpoint\r\n    saver.restore(sess, ckpt.model_checkpoint_path)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1457, in restore\r\n    {self.saver_def.filename_tensor_name: save_path})\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 769, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 967, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1017, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1037, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.NotFoundError: Key dnn/hiddenlayer_1/biases/denlayer_1/biases/part_0/Adagrad not found in checkpoint\r\n         [[Node: save/RestoreV2_5 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_5/tensor_names, save/RestoreV2_5/shape_and_slices)]]\r\n\r\nCaused by op 'save/RestoreV2_5', defined at:\r\n  File \"C:\\Users\\Jake\\py\\files\\Iris\\Iris_TF_example.py\", line 34, in <module>\r\n    steps=2000)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 281, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 402, in fit\r\n    SKCompat(self).fit(x, y, batch_size, steps, max_steps, monitors)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 1301, in fit\r\n    monitors=all_monitors)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 281, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 418, in fit\r\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 962, in _train_model\r\n    config=config_pb2.ConfigProto(allow_soft_placement=True)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 332, in MonitoredTrainingSession\r\n    stop_grace_period_secs=stop_grace_period_secs)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 626, in __init__\r\n    stop_grace_period_secs=stop_grace_period_secs)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 455, in __init__\r\n    self._sess = _RecoverableSession(self._coordinated_creator)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 799, in __init__\r\n    _WrappedSession.__init__(self, self._create_session())\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 804, in _create_session\r\n    return self._sess_creator.create_session()\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 516, in create_session\r\n    self.tf_sess = self._session_creator.create_session()\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 383, in create_session\r\n    self._scaffold.finalize()\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 188, in finalize\r\n    self._saver.build()\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1086, in build\r\n    restore_sequentially=self._restore_sequentially)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 687, in build\r\n    restore_sequentially, reshape)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 450, in _AddShardedRestoreOps\r\n    name=\"restore_shard\"))\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 407, in _AddRestoreOps\r\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 247, in restore_op\r\n    [spec.tensor.dtype])[0])\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 669, in restore_v2\r\n    dtypes=dtypes, name=name)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\r\n    op_def=op_def)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2334, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"C:\\Users\\Jake\\py\\my_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1226, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nNotFoundError (see above for traceback): Key dnn/hiddenlayer_1/biases/denlayer_1/biases/part_0/Adagrad not found in checkpoint\r\n         [[Node: save/RestoreV2_5 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_5/tensor_names, save/RestoreV2_5/shape_and_slices)]]", "Use learn.MetricSpec instead", "I'm new to this and using the tensorflow site as a learning resource. If recent code changes break the learn example than for the sake of clear/concise learning it would require updating the tensorflow site with the corrected code. Specifically: https://www.tensorflow.org/get_started/tflearn \r\n"]}, {"number": 7636, "title": "Snap package for tensorflow", "body": "It would be nice to have a snap package for tensorflow. https://snapcraft.io/\r\nThe advantage is that it is easy to install and supports multiple distributions. ", "comments": ["And http://flatpak.org", "@martinwicke , do we have any plans for package distribution through other than pip means. I know ubuntu/Debian was a non-starter for various reasons. We certainly would be happy to accept contributions by the community in this area as package maintainers. ", "Community contributed packages would be great. We just started publishing to maven, and we have a tgz with .so/.h files. \r\n\r\nWe don't have the bandwidth to maintain other packages, but we'd love to have community-maintained packages.", "I will close this issue. If someone wants to take it on, I'd be excited to add a link to a community supported package to our website."]}, {"number": 7635, "title": "Inconsistent in r.12 doc", "body": "Hi, in the doc of r.12, the api for tf.split is \r\n`tf.split(split_dim, num_split, value, name='split')`\r\n\r\nyet, the real api is changed to\r\n`tf.split(value, num_split, ... )`\r\n\r\n\r\n", "comments": []}, {"number": 7634, "title": "Setting import_scope on import_meta_graph causes error for attached metagraph file", "body": "Using the attached meta file:\r\n```\r\nmodel_fn = './my-model.meta'\r\n\r\ngraph = tf.Graph()\r\nsess = tf.InteractiveSession(graph=graph)\r\n\r\nt_input = tf.placeholder(np.float32, name='images') # define the input tensor\r\nt_preprocessed = tf.expand_dims(t_input, 0)\r\n\r\nnew_saver = tf.train.import_meta_graph(model_fn, input_map={'images': t_input}, import_scope='import')\r\nnew_saver.restore(sess, './')\r\n```\r\nresults in:\r\n```\r\nKeyError: \"The name 'gradients/discriminator/minibatch/map/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/RefEnter:0' refers to a Tensor which does not exist. The operation, 'gradients/discriminator/minibatch/map/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/RefEnter', does not exist in the graph.\"\r\n```\r\nI'm trying to remap the input so I can do image space optimization with a library that assumes the network input is (width, height, channels). Loading doesn't error if I load without the input_map and import_scope keyword arguments; however, this causes problems for the library I'm interacting with. Setting import_scope alone does cause an error.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\nAsked on Stack Overflow in case this isn't a bug: http://bit.ly/2lW7lRA\r\n\r\n### Environment info\r\nOperating System:\r\n\r\nMac\r\n\r\n1. A link to the pip package you installed:\r\nhttps://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.0.0-py3-none-any.whl\r\n\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n1.0.0\r\n\r\n[my-model.meta.zip](https://github.com/tensorflow/tensorflow/files/784246/my-model.meta.zip)\r\n", "comments": ["@concretevitamin or @sherrym, can you take a  look or suggest somebody would be knowledgable about these metagraph issues? Thanks in advance.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "This issue has been resolved on StackOverflow -  http://bit.ly/2lW7lRA. "]}, {"number": 7633, "title": "file not found: -lcublas.8.0", "body": "I am trying to install tensorflow w/ GPU from Source on Mac OS X El Capitan. (CUDA 8.0 & cuDNN 5.1)\r\n\r\nAfter wrestling with LYLD_LIBRARY_PATH [#6729](https://github.com/tensorflow/tensorflow/issues/6729), I ran\r\n`bazel build --config=opt --config=cuda --action_env PATH --action_env LD_LIBRARY_PATH --action_env DYLD_LIBRARY_PATH  //tensorflow/tools/pip_package:build_pip_package`\r\n\r\nBut, it generates an error that cannot find cublas.8.0 which I have in my directory. If I try with --verbose_failures, it generate following description.\r\n\r\nLinking of rule '//tensorflow/python:_pywrap_tensorflow.so' failed: link_dynamic_library.sh failed: error executing command\r\n\r\n\r\nWhat am I missing? it should be something with path configuration. :-( ", "comments": ["I suspect you're using bazel 0.4.4. If that is true, you might have to downgrade to bazel 0.4.3.\r\nSee #7227 for details, and it seems like it will be fixed in 0.4.5\r\n\r\nLet us know if that helps.", "Yes, it helps. \r\n\r\nFinally, I could build the tensorflow r.1.0. on my mac !! Thank you so much. \r\n\r\nI had to set all the environment variables though (e.g., save in the .profile file)\r\n\r\nexport CUDA_HOME=/usr/local/cuda\r\nexport DYLD_LIBRARY_PATH=/usr/local/cuda/lib:/usr/local/cuda/extras/CUPTI/lib\r\nexport LD_LIBRARY_PATH=$DYLD_LIBRARY_PATH\r\nexport PATH=$DYLD_LIBRARY_PATH:$PATH\r\n\r\n\r\nand it won't work in the tensorflow folder for some reason :-) [#3217](https://github.com/tensorflow/tensorflow/issues/3217)\r\n", "yes, disabling SIP, setting variables as above and downgrading to bazel 0.4.3 made it possible to build pip package on El Capitan!!!", "Thanks for the hints! I also needed to apply the solution [in this SO question about libcudart.8.0.dylib not loaded](http://stackoverflow.com/questions/39865212/dyld-library-not-loaded-rpath-libcudart-8-0-dylib-while-building-tensorflow) to get to build pip package on Mac OS X El Capitan (CUDA 8.0 & cuDNN 5.1).", "Yes, that softlink needs to be created too\n\n_____________________________\nKind Regards,\nAlexey Simonov\n\n\n> On 5 Mar 2017, at 10:47, khyox <notifications@github.com> wrote:\n> \n> Thanks for the hints! I also needed to apply the solution in this SO question about libcudart.8.0.dylib not loaded to get to build pip package on Mac OS X El Capitan (CUDA 8.0 & cuDNN 5.1).\n> \n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub, or mute the thread.\n> \n"]}, {"number": 7632, "title": "max_pool3d does not support float16(half)", "body": "I'm using version 0.12.1 on Ubuntu 14.04 LTS 64 bit. Here is the minimal example I run to find the error:\r\n\r\n```\r\n    with tf.Graph().as_default():\r\n        a = tf.constant(1, shape = [1, 4, 4, 4, 1], dtype = tf.float16)\r\n        b = tf.nn.max_pool3d(a, ksize = [1, 2, 2, 2, 1], strides = [1, 2, 2, 2, 1], padding = 'SAME')\r\n\r\n        with tf.Session() as sess:\r\n            print(sess.run([a, b]))\r\n```\r\n\r\nThe I got error:\r\n\r\n```\r\n...\r\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'MaxPool3D' with these attrs.  Registered devices: [CPU,GPU], Registered kernels:\r\n  device='CPU'; T in [DT_FLOAT]\r\n  device='GPU'; T in [DT_FLOAT]\r\n```\r\n\r\nIf I use ```dtype = tf.float32```, there is no error. ```max_pool3d``` python docstring says it supports half precision, but why ```dtype = tf.float16``` does not work?\r\n\r\n\r\n", "comments": ["@martinwicke , it is confusing the doc generator gives all the possible types of tensors all the time, even when we don't have kernels registered.\r\n\r\n@weiliu620 , thanks for reporting this. We should definitely at least update the documentation. If you would like to provide float16 functionality for maxpool3d that would be great. But we are likely not to get to it anytime soon. Thanks!\r\n", "@aselle greetings, which files are relevant to add float16 support for `maxpool3d`? Is it beginner-friendly?\r\n\r\nIs it like adding\r\n\r\n    REGISTER_KERNEL_BUILDER(\r\n        Name(\"MaxPool\").Device(DEVICE_CPU).TypeConstraint<Eigen::half>(\"T\"),\r\n        MaxPoolingOp<CPUDevice, Eigen::half>);\r\n\r\nbut for `MaxPool3D` in /tensorflow/core/kernels/maxpooling_op.cc?", "It is not beginner friendly, the best way is to find a commit that added fp16 support and use that as a template. Here's a mega-commit that added fp16 to a bunch of ops, although there are probably smaller examples -- https://github.com/tensorflow/tensorflow/commit/9bedadce", "@yaroslavvb thanks, I'm planning to working on it. Here's my progress so far https://github.com/tensorflow/tensorflow/compare/master...rilut:maxpool3d-float16?expand=1", "@yaroslavvb so I compiled my fork of tensorflow (on a Ubuntu VM), and I have compilation errors. Since the error log is long, do you have any tip to debug tf compilation errors?", "We are actively working on FP16.  Assigning to myself to monitor and contributions are still very welcome.  ", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "@MarkDaoust see https://github.com/tensorflow/tensorflow/issues/7632#issuecomment-280898121. \r\n\r\nCould we fix the C++ doc generator to only produce docs for kernels that actually exist? That may not be straightforward, the information exists in different places. @josh11b FYI.", "The docs part of this problem is fixed, at some point between r1.1 and r1.2. Compare:\r\n\r\nhttps://www.tensorflow.org/versions/r1.1/api_docs/python/tf/nn/max_pool3d\r\nhttps://www.tensorflow.org/versions/r1.2/api_docs/python/tf/nn/max_pool3d\r\n\r\nI don't know the details of how that list is generated, but given that this is a generated python wrapper that the docs are generated from, I doubt it is something trivial enough that we would be able to cherry-pick back onto the old releases. \r\n\r\nIt's not a total solution to your problem, but this op did gain `bfloat16` suport in `r1.5`:\r\n\r\nhttps://www.tensorflow.org/versions/r1.5/api_docs/python/tf/nn/max_pool3d ", "The docs issue has been resolved and r1.5 has bfloat16 support.\r\n@rilut Do you still need float16 support and interested in implementing it?", "@tatianashp Hi, I don't think I really understand the underlying code, so I pass \ud83d\ude4f. Thanks for asking", "I am closing the issue then. If somebody needs fp16 for maxpool3d  and wants to implement please feel free to submit PR."]}, {"number": 7631, "title": "FEATURE: Tensorboard Scalars: Simple Way of Setting y axis to start at 0", "body": "I have a number of scalars that I plot in tensorboard that are non negative values (ie accuracy, etc). It would be cool if there was a quick way to have the y axis start at 0 rather than allocating unused space in the negative y direction.\r\n![image](https://cloud.githubusercontent.com/assets/51059/23080071/7b1aa63c-f51d-11e6-8ae0-82bbf299a01f.png)\r\n", "comments": ["If there anyone working on this issue? If there is no one, can I try this one?", "I'm migrating this to https://github.com/tensorflow/tensorboard/issues/77. @chris-chris you're welcome to contribute on this. If you're still interested, let's discuss on the new issue at tensorboard/77."]}]