[{"number": 54707, "title": "Add an option to enable parallel while op in tf_to_tfrt conversion.", "body": "Add an option to enable parallel while op in tf_to_tfrt conversion.\n\nCurrently, it is disabled by default. If turned on:\n1. parallel_iterations in tf.While will be propagated to tfrt.while, which was previously always 1.\n2. stream merging is disabled in while body for parallelizing iteration handling operations.\n\nThis is only for testing over more models currently.\n", "comments": []}, {"number": 54706, "title": "Refactor op_def_util so it can be used in multiple pybind targets.", "body": "Refactor op_def_util so it can be used in multiple pybind targets.\n", "comments": []}, {"number": 54705, "title": "change the way that eager mode op is determined: ", "body": "change the way that eager mode op is determined: \n1. if ops is run under EagerExecute,  eager_mode = !is_func of that TraceMe\n2. if ops is not run under EagerExecute, eager_mode = false. (legacy trace goes here).\n", "comments": []}, {"number": 54704, "title": "Export current optimizer to legacy namespace. ", "body": "Export current optimizer to legacy namespace. \n\nA new-version optimizer is going to be available in TF 2.9 release. Although the new optimizer is now under experimental namespace, it will in future become the default optimizer. For backward compatibility, we will continue support the current optimizer in the legacy namespace.\n", "comments": []}, {"number": 54703, "title": "Adding fingerprint field to HloModule.", "body": "Adding fingerprint field to HloModule.\nChange to reuse CompilationEvent and ProfileSource enums for ops and module-level profile.\n", "comments": []}, {"number": 54702, "title": "Update tf_generated_ops.td.", "body": "Update tf_generated_ops.td.\n", "comments": []}, {"number": 54701, "title": "[mhlo] Restrict the op-regions of reduceOp and reduceWindowOp from returning tuple-types.", "body": "[mhlo] Restrict the op-regions of reduceOp and reduceWindowOp from returning tuple-types.\n\n1. During import (from HLO) we flatten the tuple return-types of region-blocks.\n2. The verifier of the ops are made aware that tuple returns are not allowed.\n", "comments": []}, {"number": 54700, "title": "Move rest of wrapper::Enum parsing/printing from gpu_kernels to gpu_wrapper.", "body": "Move rest of wrapper::Enum parsing/printing from gpu_kernels to gpu_wrapper.\n\n- Remove `Parse` function template (they can't be partially specialized and more generally http://www.gotw.ca/publications/mill17.htm).\n- Change `operator<<` to `Print` function (because ADL may accidentally print CUDA/ROCm enums as integers).\n", "comments": []}, {"number": 54699, "title": "Entry computation's layout needs to be updated after spmd partitioning.", "body": "Entry computation's layout needs to be updated after spmd partitioning.\n", "comments": []}, {"number": 54698, "title": "Some legacy tests have inconsistencies layout when compiling the infeed", "body": "Some legacy tests have inconsistencies layout when compiling the infeed\nop and transferring infeed data. Adding this api allows the tests to\nget the layout right for transferring data.\n", "comments": []}, {"number": 54697, "title": " multi label `class_weight` ", "body": "hi \r\ni was trying to deal with multi-output classification problem on an imbalanced dataset using class_weight parameter of fit method  ; but i faced this issue; i am looking for an alternative or solution \r\n`class_weight` is only supported for Models with a single output.\r\nthanks ", "comments": ["Hi @Drlilou !\r\nCould you please update the [template](https://github.com/tensorflow/tensorflow/issues/new/choose) too as it will help us analyze the issue [tf version, steps followed before you ran into this error or stand alone code/colab gist to reproduce the issue faced].Thanks!", "tensorflow version : 2.8.0\r\nenvironnement : colab \r\nmodel.fit( x_train,[y_train1,y_train2] , batch size=128, class_weight=....) ", "you can see this documentation https://www.tensorflow.org/tutorials/structured_data/imbalanced_data .", "Hi @Drlilou ! Did  you try again after passing weights as dictionaries ? Attaching relevant threads as reference. R [1](https://datascience.stackexchange.com/questions/41698/how-to-apply-class-weight-to-a-multi-output-model), [2](https://stackoverflow.com/questions/65151225/error-using-class-weights-parameter-with-keras-in-multi-class-classification-pro) . \r\n\r\nPlease post this issue on [keras-team/keras repo](https://github.com/keras-team/keras/issues) for further assistance. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54697\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54697\">No</a>\n"]}, {"number": 54696, "title": "[XLA] Iterate over instructions, not all values, in `CalculateBufferStartEndMap`.", "body": "[XLA] Iterate over instructions, not all values, in `CalculateBufferStartEndMap`.\n\nThe existing loop is very inefficient for module with lots of small computations as most values will not correspond to the current computation.\n\nI also removed several redundant hash look-ups. I added `HloInstruction::IsRoot`, as it's a really common thing to want to know.\n", "comments": []}, {"number": 54695, "title": "Add a test for multi-device function using jit_compiled collective.", "body": "Add a test for multi-device function using jit_compiled collective.\n\nWe do raise an error now, but after the noted feature lands, this shall work.\n", "comments": []}, {"number": 54694, "title": "TypeError: can't pickle _thread.RLock objects when using KerasClassifier with Keras and RandomizedSearchCV", "body": "I created a simple neural network for binary spam/ham text classification using pretrained BERT transformer. Now I want to apply randomized search for tuning the hyperparameters. For now the only hyperparameter I would like to tune is the dropout regularization probability.\r\n\r\nI set up a sklearn pipeline with scikeras's KerasClassifier that contains my custom `build_sequential_nn()` method. When merely fitting  the pipeline, everything is fine; however, when I pass the pipeline into a sklearn `RandomizedSearchCV`, the following error message pops up:\r\n\r\n`TypeError: can't pickle _thread.RLock objects`\r\n\r\nFull error message will be detailed at the end of the post.\r\n\r\nA full reproducible code is as follows, including sample data:\r\n```\r\nimport numpy as np\r\nimport pandas as pd \r\n\r\nimport sklearn \r\nfrom sklearn.base import BaseEstimator, TransformerMixin\r\nfrom sklearn.pipeline import Pipeline\r\nfrom sklearn.model_selection import RandomizedSearchCV\r\n\r\nfrom scikeras.wrappers import KerasClassifier\r\n\r\nimport tensorflow_hub as hub \r\nimport tensorflow as tf \r\nimport tensorflow_text\r\nfrom tensorflow.keras.layers import Input, Dropout, Dense\r\n\r\n\r\nclass BertPreprocessor(TransformerMixin, BaseEstimator):\r\n    def __init__(self, preprocessor_model):\r\n        super().__init__()\r\n        self.preprocessor_model = preprocessor_model\r\n    def fit(self, X=None, y=None):\r\n        return self \r\n    def transform(self, X, y=None):\r\n        return self.preprocessor_model(X)\r\n\r\nclass BertEncoder(TransformerMixin, BaseEstimator):\r\n    def __init__(self, encoder_model):\r\n        super().__init__()\r\n        self.encoder_model = encoder_model\r\n    def fit(self, X=None, y=None):\r\n        return self\r\n    def transform(self, X, y=None):\r\n        return pd.DataFrame(self.encoder_model(X)['pooled_output'])\r\n\r\ndef build_nn_sequential(dropout_prob=0.1, epochs=10): \r\n    model = Sequential()\r\n    model.add(Input(shape=768, name='bert_pooled_output'))\r\n    model.add(Dropout(dropout_prob, name='dropout'))\r\n    model.add(Dense(1, activation='sigmoid', name='classification_output'))\r\n\r\n    metrics_list = [\r\n        tf.keras.metrics.AUC(name='auc'),\r\n        tf.keras.metrics.BinaryAccuracy(name='accuracy')\r\n    ]\r\n    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = metrics_list)\r\n    return model\r\n\r\n# Automatically fetch BERT preprocessor and encoder\r\nbert_encoder_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\"\r\nbert_preprocessor_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\r\nbert_preprocessor_model = hub.KerasLayer(bert_preprocessor_url)\r\nbert_encoder_model = hub.KerasLayer(bert_encoder_url)\r\n\r\n# Get train data \r\ndf = pd.read_json(...)   # see data also below\r\n\r\nX_train_ = df['comment_text']\r\ny_train_ = df['label']\r\n\r\npipe = Pipeline([\r\n    ('preprocess', BertPreprocessor(bert_preprocessor_model)),\r\n    ('encode', BertEncoder(bert_encoder_model)),\r\n    ('model', KerasClassifier(build_fn=build_nn_sequential)),\r\n])\r\n\r\n# pipe.fit(X_train_, y_train_)    # This evaluates fine! \r\n\r\nsearch_spaces = ({\r\n    'model__dropout_prob': np.logspace(np.log10(0.05), np.log10(0.67), 10),\r\n    'model__epochs': [10, 20, 30],\r\n})\r\n\r\nsearch = RandomizedSearchCV(\r\n    estimator=pipe,\r\n    param_distributions=search_spaces, \r\n    scoring='roc_auc',\r\n    cv=3, \r\n    verbose=0\r\n).fit(X_train_, y_train_)   # <--- row where error pops up\r\n```\r\n\r\n### Sample data:\r\n```\r\ndf = pd.read_json('{\"comment_text\":{\"0\":\"problem wanted say problem trying redirect event schedule pakistan NUMBERTAG NUMBERTAG pakistan mother fucker boy want married sister ohhhh love sister boob hmmmmm yummyy\",\"1\":\"get life fucking loser question ask ask katie goulet picture\",\"2\":\"cum drinker hey wat nigga thought u could ban took long cuz wa busy az hell recently ill keep cumming back take word cumdrinker\",\"3\":\"liar liar pant fire seriously looked contribution tennis portal page tennis page ha descussion ever please lie NUMBERTAG NUMBERTAG NUMBERTAG NUMBERTAG\",\"4\":\"stop writing p nothing discus given lack bsinc education diplomacy\",\"5\":\"wa fucking page one edit page\",\"6\":\"question mad gay\",\"7\":\"warning page nerd please leave one stay girl though pleeeeeeeeeeeeeaaaaaaaaaaaaaaaaaaaaaassssssssssssssssseeeeeeeeeeeee NUMBERTAG oneoneoneoneoneoneoneoneoneoneoenone\",\"8\":\"full shit\",\"9\":\"go fuck conrad black cheated thousand people pension anyone defends hm asshole apologist evil\",\"10\":\"list office bearer national union student australia wp userfy userfied page located\",\"11\":\"talk history scottish national party claim spying hi sentence someone belief npov claim mean someone belief npov claim\",\"12\":\"section meant vice review btw magazine website writer name attached also like richardwilson NUMBERTAG even know question ninjarobotpirate wa responding happy criticise answer \\\\u2026 \\\\u2026 btw NUMBERTAG far know none editor either albanian croatian maybe airplane vision quite good think take care\",\"13\":\"next time subtweet\",\"14\":\"physicsyo yo yo dog\",\"15\":\"self censorship tv show might might notable tv pre empted breaking news notable happens time\",\"16\":\"article contains information soursed huddersfield aa street street\",\"17\":\"utc onto something centrifugal force experienced mass exhibiting inertia result tiny little bullet hitting side ride merry go round rueda puthoff haisch described zero point field electronic lorenz equation coupling inertial frame reference give mass inertial reluctance rather resistance enable describe change velocity direction compare ac v dc tesla v edison NUMBERTAG NUMBERTAG NUMBERTAG june NUMBERTAG\",\"18\":\"meant wa meant state either unblock create new account rendering block useless simple\",\"19\":\"NUMBERTAG utc hi NUMBERTAG must mistakenly thought ian wa original member b c always viewed band definitive axeman NUMBERTAG yeah almost bought akai headrush looper year ago notorious role cab one guitarist recording settled bos loop station instead rather headrush boomerang due two reliability price issue respectively check hovercraft southpacific auburn lull kind hallucinitory guitar looping thought cab new lineup wa incredible saw NUMBERTAG skipped classic lineup NUMBERTAG compare two performance wise best NUMBERTAG NUMBERTAG NUMBERTAG may\"},\"label\":{\"0\":1,\"1\":1,\"2\":1,\"3\":1,\"4\":1,\"5\":1,\"6\":1,\"7\":1,\"8\":1,\"9\":1,\"10\":0,\"11\":0,\"12\":0,\"13\":0,\"14\":0,\"15\":0,\"16\":0,\"17\":0,\"18\":0,\"19\":0}}')\r\n```\r\n\r\n### Full error message:\r\n```\r\nTypeError                                 Traceback (most recent call last)\r\n~\\AppData\\Local\\Temp\\ipykernel_18240\\1200168424.py in <module>\r\n     63     cv=3,\r\n     64     verbose=0\r\n---> 65 ).fit(X_train_, y_train_)\r\n     66 \r\n     67 # print(f\"Best model parameters: {search.best_params_}, best score {search.best_score_}.\")\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\skopt\\searchcv.py in fit(self, X, y, groups, callback, **fit_params)\r\n    464             self.optimizer_kwargs_ = dict(self.optimizer_kwargs)\r\n    465 \r\n--> 466         super().fit(X=X, y=y, groups=groups, **fit_params)\r\n    467 \r\n    468         # BaseSearchCV never ranked train scores,\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self, X, y, groups, **fit_params)\r\n    803         n_splits = cv_orig.get_n_splits(X, y, groups)\r\n    804 \r\n--> 805         base_estimator = clone(self.estimator)\r\n    806 \r\n    807         parallel = Parallel(n_jobs=self.n_jobs, pre_dispatch=self.pre_dispatch)\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py in clone(estimator, safe)\r\n     84     new_object_params = estimator.get_params(deep=False)\r\n     85     for name, param in new_object_params.items():\r\n---> 86         new_object_params[name] = clone(param, safe=False)\r\n     87     new_object = klass(**new_object_params)\r\n     88     params_set = new_object.get_params(deep=False)\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py in clone(estimator, safe)\r\n     62     # XXX: not handling dictionaries\r\n     63     if estimator_type in (list, tuple, set, frozenset):\r\n---> 64         return estimator_type([clone(e, safe=safe) for e in estimator])\r\n     65     elif not hasattr(estimator, \"get_params\") or isinstance(estimator, type):\r\n     66         if not safe:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py in <listcomp>(.0)\r\n     62     # XXX: not handling dictionaries\r\n     63     if estimator_type in (list, tuple, set, frozenset):\r\n---> 64         return estimator_type([clone(e, safe=safe) for e in estimator])\r\n     65     elif not hasattr(estimator, \"get_params\") or isinstance(estimator, type):\r\n     66         if not safe:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py in clone(estimator, safe)\r\n     62     # XXX: not handling dictionaries\r\n     63     if estimator_type in (list, tuple, set, frozenset):\r\n---> 64         return estimator_type([clone(e, safe=safe) for e in estimator])\r\n     65     elif not hasattr(estimator, \"get_params\") or isinstance(estimator, type):\r\n     66         if not safe:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py in <listcomp>(.0)\r\n     62     # XXX: not handling dictionaries\r\n     63     if estimator_type in (list, tuple, set, frozenset):\r\n---> 64         return estimator_type([clone(e, safe=safe) for e in estimator])\r\n     65     elif not hasattr(estimator, \"get_params\") or isinstance(estimator, type):\r\n     66         if not safe:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py in clone(estimator, safe)\r\n     84     new_object_params = estimator.get_params(deep=False)\r\n     85     for name, param in new_object_params.items():\r\n---> 86         new_object_params[name] = clone(param, safe=False)\r\n     87     new_object = klass(**new_object_params)\r\n     88     params_set = new_object.get_params(deep=False)\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py in clone(estimator, safe)\r\n     65     elif not hasattr(estimator, \"get_params\") or isinstance(estimator, type):\r\n     66         if not safe:\r\n---> 67             return copy.deepcopy(estimator)\r\n     68         else:\r\n     69             if isinstance(estimator, type):\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    178                     y = x\r\n    179                 else:\r\n--> 180                     y = _reconstruct(x, memo, *rv)\r\n    181 \r\n    182     # If is its own copy, don't memoize.\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)\r\n    279     if state is not None:\r\n    280         if deep:\r\n--> 281             state = deepcopy(state, memo)\r\n    282         if hasattr(y, '__setstate__'):\r\n    283             y.__setstate__(state)\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    148     copier = _deepcopy_dispatch.get(cls)\r\n    149     if copier:\r\n--> 150         y = copier(x, memo)\r\n    151     else:\r\n    152         try:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _deepcopy_dict(x, memo, deepcopy)\r\n    239     memo[id(x)] = y\r\n    240     for key, value in x.items():\r\n--> 241         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    242     return y\r\n    243 d[dict] = _deepcopy_dict\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    178                     y = x\r\n    179                 else:\r\n--> 180                     y = _reconstruct(x, memo, *rv)\r\n    181 \r\n    182     # If is its own copy, don't memoize.\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)\r\n    279     if state is not None:\r\n    280         if deep:\r\n--> 281             state = deepcopy(state, memo)\r\n    282         if hasattr(y, '__setstate__'):\r\n    283             y.__setstate__(state)\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    148     copier = _deepcopy_dispatch.get(cls)\r\n    149     if copier:\r\n--> 150         y = copier(x, memo)\r\n    151     else:\r\n    152         try:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _deepcopy_tuple(x, memo, deepcopy)\r\n    219 \r\n    220 def _deepcopy_tuple(x, memo, deepcopy=deepcopy):\r\n--> 221     y = [deepcopy(a, memo) for a in x]\r\n    222     # We're not going to put the tuple in the memo, but it's still important we\r\n    223     # check for it, in case the tuple contains recursive mutable structures.\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in <listcomp>(.0)\r\n    219 \r\n    220 def _deepcopy_tuple(x, memo, deepcopy=deepcopy):\r\n--> 221     y = [deepcopy(a, memo) for a in x]\r\n    222     # We're not going to put the tuple in the memo, but it's still important we\r\n    223     # check for it, in case the tuple contains recursive mutable structures.\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    148     copier = _deepcopy_dispatch.get(cls)\r\n    149     if copier:\r\n--> 150         y = copier(x, memo)\r\n    151     else:\r\n    152         try:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _deepcopy_dict(x, memo, deepcopy)\r\n    239     memo[id(x)] = y\r\n    240     for key, value in x.items():\r\n--> 241         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    242     return y\r\n    243 d[dict] = _deepcopy_dict\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    148     copier = _deepcopy_dispatch.get(cls)\r\n    149     if copier:\r\n--> 150         y = copier(x, memo)\r\n    151     else:\r\n    152         try:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _deepcopy_dict(x, memo, deepcopy)\r\n    239     memo[id(x)] = y\r\n    240     for key, value in x.items():\r\n--> 241         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    242     return y\r\n    243 d[dict] = _deepcopy_dict\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    178                     y = x\r\n    179                 else:\r\n--> 180                     y = _reconstruct(x, memo, *rv)\r\n    181 \r\n    182     # If is its own copy, don't memoize.\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)\r\n    279     if state is not None:\r\n    280         if deep:\r\n--> 281             state = deepcopy(state, memo)\r\n    282         if hasattr(y, '__setstate__'):\r\n    283             y.__setstate__(state)\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    148     copier = _deepcopy_dispatch.get(cls)\r\n    149     if copier:\r\n--> 150         y = copier(x, memo)\r\n    151     else:\r\n    152         try:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _deepcopy_tuple(x, memo, deepcopy)\r\n    219 \r\n    220 def _deepcopy_tuple(x, memo, deepcopy=deepcopy):\r\n--> 221     y = [deepcopy(a, memo) for a in x]\r\n    222     # We're not going to put the tuple in the memo, but it's still important we\r\n    223     # check for it, in case the tuple contains recursive mutable structures.\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in <listcomp>(.0)\r\n    219 \r\n    220 def _deepcopy_tuple(x, memo, deepcopy=deepcopy):\r\n--> 221     y = [deepcopy(a, memo) for a in x]\r\n    222     # We're not going to put the tuple in the memo, but it's still important we\r\n    223     # check for it, in case the tuple contains recursive mutable structures.\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    148     copier = _deepcopy_dispatch.get(cls)\r\n    149     if copier:\r\n--> 150         y = copier(x, memo)\r\n    151     else:\r\n    152         try:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _deepcopy_dict(x, memo, deepcopy)\r\n    239     memo[id(x)] = y\r\n    240     for key, value in x.items():\r\n--> 241         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    242     return y\r\n    243 d[dict] = _deepcopy_dict\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    178                     y = x\r\n    179                 else:\r\n--> 180                     y = _reconstruct(x, memo, *rv)\r\n    181 \r\n    182     # If is its own copy, don't memoize.\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)\r\n    279     if state is not None:\r\n    280         if deep:\r\n--> 281             state = deepcopy(state, memo)\r\n    282         if hasattr(y, '__setstate__'):\r\n    283             y.__setstate__(state)\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    148     copier = _deepcopy_dispatch.get(cls)\r\n    149     if copier:\r\n--> 150         y = copier(x, memo)\r\n    151     else:\r\n    152         try:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _deepcopy_dict(x, memo, deepcopy)\r\n    239     memo[id(x)] = y\r\n    240     for key, value in x.items():\r\n--> 241         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    242     return y\r\n    243 d[dict] = _deepcopy_dict\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    148     copier = _deepcopy_dispatch.get(cls)\r\n    149     if copier:\r\n--> 150         y = copier(x, memo)\r\n    151     else:\r\n    152         try:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _deepcopy_list(x, memo, deepcopy)\r\n    214     append = y.append\r\n    215     for a in x:\r\n--> 216         append(deepcopy(a, memo))\r\n    217     return y\r\n    218 d[list] = _deepcopy_list\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    178                     y = x\r\n    179                 else:\r\n--> 180                     y = _reconstruct(x, memo, *rv)\r\n    181 \r\n    182     # If is its own copy, don't memoize.\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)\r\n    279     if state is not None:\r\n    280         if deep:\r\n--> 281             state = deepcopy(state, memo)\r\n    282         if hasattr(y, '__setstate__'):\r\n    283             y.__setstate__(state)\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    148     copier = _deepcopy_dispatch.get(cls)\r\n    149     if copier:\r\n--> 150         y = copier(x, memo)\r\n    151     else:\r\n    152         try:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _deepcopy_tuple(x, memo, deepcopy)\r\n    219 \r\n    220 def _deepcopy_tuple(x, memo, deepcopy=deepcopy):\r\n--> 221     y = [deepcopy(a, memo) for a in x]\r\n    222     # We're not going to put the tuple in the memo, but it's still important we\r\n    223     # check for it, in case the tuple contains recursive mutable structures.\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in <listcomp>(.0)\r\n    219 \r\n    220 def _deepcopy_tuple(x, memo, deepcopy=deepcopy):\r\n--> 221     y = [deepcopy(a, memo) for a in x]\r\n    222     # We're not going to put the tuple in the memo, but it's still important we\r\n    223     # check for it, in case the tuple contains recursive mutable structures.\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    148     copier = _deepcopy_dispatch.get(cls)\r\n    149     if copier:\r\n--> 150         y = copier(x, memo)\r\n    151     else:\r\n    152         try:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _deepcopy_dict(x, memo, deepcopy)\r\n    239     memo[id(x)] = y\r\n    240     for key, value in x.items():\r\n--> 241         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    242     return y\r\n    243 d[dict] = _deepcopy_dict\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    178                     y = x\r\n    179                 else:\r\n--> 180                     y = _reconstruct(x, memo, *rv)\r\n    181 \r\n    182     # If is its own copy, don't memoize.\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)\r\n    279     if state is not None:\r\n    280         if deep:\r\n--> 281             state = deepcopy(state, memo)\r\n    282         if hasattr(y, '__setstate__'):\r\n    283             y.__setstate__(state)\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    148     copier = _deepcopy_dispatch.get(cls)\r\n    149     if copier:\r\n--> 150         y = copier(x, memo)\r\n    151     else:\r\n    152         try:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _deepcopy_dict(x, memo, deepcopy)\r\n    239     memo[id(x)] = y\r\n    240     for key, value in x.items():\r\n--> 241         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    242     return y\r\n    243 d[dict] = _deepcopy_dict\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    148     copier = _deepcopy_dispatch.get(cls)\r\n    149     if copier:\r\n--> 150         y = copier(x, memo)\r\n    151     else:\r\n    152         try:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _deepcopy_list(x, memo, deepcopy)\r\n    214     append = y.append\r\n    215     for a in x:\r\n--> 216         append(deepcopy(a, memo))\r\n    217     return y\r\n    218 d[list] = _deepcopy_list\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    178                     y = x\r\n    179                 else:\r\n--> 180                     y = _reconstruct(x, memo, *rv)\r\n    181 \r\n    182     # If is its own copy, don't memoize.\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)\r\n    279     if state is not None:\r\n    280         if deep:\r\n--> 281             state = deepcopy(state, memo)\r\n    282         if hasattr(y, '__setstate__'):\r\n    283             y.__setstate__(state)\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    148     copier = _deepcopy_dispatch.get(cls)\r\n    149     if copier:\r\n--> 150         y = copier(x, memo)\r\n    151     else:\r\n    152         try:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _deepcopy_tuple(x, memo, deepcopy)\r\n    219 \r\n    220 def _deepcopy_tuple(x, memo, deepcopy=deepcopy):\r\n--> 221     y = [deepcopy(a, memo) for a in x]\r\n    222     # We're not going to put the tuple in the memo, but it's still important we\r\n    223     # check for it, in case the tuple contains recursive mutable structures.\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in <listcomp>(.0)\r\n    219 \r\n    220 def _deepcopy_tuple(x, memo, deepcopy=deepcopy):\r\n--> 221     y = [deepcopy(a, memo) for a in x]\r\n    222     # We're not going to put the tuple in the memo, but it's still important we\r\n    223     # check for it, in case the tuple contains recursive mutable structures.\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    148     copier = _deepcopy_dispatch.get(cls)\r\n    149     if copier:\r\n--> 150         y = copier(x, memo)\r\n    151     else:\r\n    152         try:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _deepcopy_dict(x, memo, deepcopy)\r\n    239     memo[id(x)] = y\r\n    240     for key, value in x.items():\r\n--> 241         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    242     return y\r\n    243 d[dict] = _deepcopy_dict\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    178                     y = x\r\n    179                 else:\r\n--> 180                     y = _reconstruct(x, memo, *rv)\r\n    181 \r\n    182     # If is its own copy, don't memoize.\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)\r\n    279     if state is not None:\r\n    280         if deep:\r\n--> 281             state = deepcopy(state, memo)\r\n    282         if hasattr(y, '__setstate__'):\r\n    283             y.__setstate__(state)\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    148     copier = _deepcopy_dispatch.get(cls)\r\n    149     if copier:\r\n--> 150         y = copier(x, memo)\r\n    151     else:\r\n    152         try:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _deepcopy_dict(x, memo, deepcopy)\r\n    239     memo[id(x)] = y\r\n    240     for key, value in x.items():\r\n--> 241         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    242     return y\r\n    243 d[dict] = _deepcopy_dict\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    178                     y = x\r\n    179                 else:\r\n--> 180                     y = _reconstruct(x, memo, *rv)\r\n    181 \r\n    182     # If is its own copy, don't memoize.\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)\r\n    279     if state is not None:\r\n    280         if deep:\r\n--> 281             state = deepcopy(state, memo)\r\n    282         if hasattr(y, '__setstate__'):\r\n    283             y.__setstate__(state)\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    148     copier = _deepcopy_dispatch.get(cls)\r\n    149     if copier:\r\n--> 150         y = copier(x, memo)\r\n    151     else:\r\n    152         try:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _deepcopy_dict(x, memo, deepcopy)\r\n    239     memo[id(x)] = y\r\n    240     for key, value in x.items():\r\n--> 241         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    242     return y\r\n    243 d[dict] = _deepcopy_dict\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    178                     y = x\r\n    179                 else:\r\n--> 180                     y = _reconstruct(x, memo, *rv)\r\n    181 \r\n    182     # If is its own copy, don't memoize.\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)\r\n    279     if state is not None:\r\n    280         if deep:\r\n--> 281             state = deepcopy(state, memo)\r\n    282         if hasattr(y, '__setstate__'):\r\n    283             y.__setstate__(state)\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    148     copier = _deepcopy_dispatch.get(cls)\r\n    149     if copier:\r\n--> 150         y = copier(x, memo)\r\n    151     else:\r\n    152         try:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _deepcopy_dict(x, memo, deepcopy)\r\n    239     memo[id(x)] = y\r\n    240     for key, value in x.items():\r\n--> 241         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    242     return y\r\n    243 d[dict] = _deepcopy_dict\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    178                     y = x\r\n    179                 else:\r\n--> 180                     y = _reconstruct(x, memo, *rv)\r\n    181 \r\n    182     # If is its own copy, don't memoize.\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)\r\n    279     if state is not None:\r\n    280         if deep:\r\n--> 281             state = deepcopy(state, memo)\r\n    282         if hasattr(y, '__setstate__'):\r\n    283             y.__setstate__(state)\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    148     copier = _deepcopy_dispatch.get(cls)\r\n    149     if copier:\r\n--> 150         y = copier(x, memo)\r\n    151     else:\r\n    152         try:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _deepcopy_tuple(x, memo, deepcopy)\r\n    219 \r\n    220 def _deepcopy_tuple(x, memo, deepcopy=deepcopy):\r\n--> 221     y = [deepcopy(a, memo) for a in x]\r\n    222     # We're not going to put the tuple in the memo, but it's still important we\r\n    223     # check for it, in case the tuple contains recursive mutable structures.\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in <listcomp>(.0)\r\n    219 \r\n    220 def _deepcopy_tuple(x, memo, deepcopy=deepcopy):\r\n--> 221     y = [deepcopy(a, memo) for a in x]\r\n    222     # We're not going to put the tuple in the memo, but it's still important we\r\n    223     # check for it, in case the tuple contains recursive mutable structures.\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    148     copier = _deepcopy_dispatch.get(cls)\r\n    149     if copier:\r\n--> 150         y = copier(x, memo)\r\n    151     else:\r\n    152         try:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _deepcopy_dict(x, memo, deepcopy)\r\n    239     memo[id(x)] = y\r\n    240     for key, value in x.items():\r\n--> 241         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    242     return y\r\n    243 d[dict] = _deepcopy_dict\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    178                     y = x\r\n    179                 else:\r\n--> 180                     y = _reconstruct(x, memo, *rv)\r\n    181 \r\n    182     # If is its own copy, don't memoize.\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)\r\n    305             for key, value in dictiter:\r\n    306                 key = deepcopy(key, memo)\r\n--> 307                 value = deepcopy(value, memo)\r\n    308                 y[key] = value\r\n    309         else:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    178                     y = x\r\n    179                 else:\r\n--> 180                     y = _reconstruct(x, memo, *rv)\r\n    181 \r\n    182     # If is its own copy, don't memoize.\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)\r\n    279     if state is not None:\r\n    280         if deep:\r\n--> 281             state = deepcopy(state, memo)\r\n    282         if hasattr(y, '__setstate__'):\r\n    283             y.__setstate__(state)\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    148     copier = _deepcopy_dispatch.get(cls)\r\n    149     if copier:\r\n--> 150         y = copier(x, memo)\r\n    151     else:\r\n    152         try:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _deepcopy_dict(x, memo, deepcopy)\r\n    239     memo[id(x)] = y\r\n    240     for key, value in x.items():\r\n--> 241         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    242     return y\r\n    243 d[dict] = _deepcopy_dict\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    178                     y = x\r\n    179                 else:\r\n--> 180                     y = _reconstruct(x, memo, *rv)\r\n    181 \r\n    182     # If is its own copy, don't memoize.\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)\r\n    279     if state is not None:\r\n    280         if deep:\r\n--> 281             state = deepcopy(state, memo)\r\n    282         if hasattr(y, '__setstate__'):\r\n    283             y.__setstate__(state)\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    148     copier = _deepcopy_dispatch.get(cls)\r\n    149     if copier:\r\n--> 150         y = copier(x, memo)\r\n    151     else:\r\n    152         try:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in _deepcopy_dict(x, memo, deepcopy)\r\n    239     memo[id(x)] = y\r\n    240     for key, value in x.items():\r\n--> 241         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    242     return y\r\n    243 d[dict] = _deepcopy_dict\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    167                     reductor = getattr(x, \"__reduce_ex__\", None)\r\n    168                     if reductor:\r\n--> 169                         rv = reductor(4)\r\n    170                     else:\r\n    171                         reductor = getattr(x, \"__reduce__\", None)\r\n\r\nTypeError: can't pickle _thread.RLock objects\r\n```\r\n\r\n### Versions:\r\n```\r\nnumpy 1.21.5\r\npandas 1.3.5.\r\nsklearn 1.0.2.\r\nscikeras 0.6.1.\r\ntensorflow 2.8.0.\r\ntensorflow_text 2.8.1.\r\ntensorflow_hub 0.12.0\r\n```\r\n\r\n### Note:\r\n- A [very similar issue was reported in 2020](https://github.com/tensorflow/tensorflow/issues/42641) where the issue was reproducible on TFv2.3 as mentioned [in this comment](https://github.com/tensorflow/tensorflow/issues/42641#issuecomment-684982906) in that thread. However there was no clear solution/workaround provided there, rather [this link](https://machinelearningmastery.com/use-keras-deep-learning-models-scikit-learn-python/). Having compared the code snippets provided in that blog post with my code above, I don't see any obvious inconsistencies or mistakes in my solution. Note that the linked blog post is actually only about incorporating a KerasClassifier into a grid/randomized search logic, and not about incorporating an entire sklearn pipeline. This might be important. \r\n- Another time the same error message was reported here on github was [this one](https://github.com/tensorflow/tensorflow/issues/47324). Yet, in this case the reason is seemingly unrelated. \r\n- [In this thread on StackOverflow](https://stackoverflow.com/a/48720211/5123111) Marcin Mo\u017cejko mentions that `keras` doesn't support parallelization via pickle which would be performed by default by grid/randomized search, and proposed explicitly setting `n_jobs=1` to prevent multiprocessing. Makes total sense, I tried, yet I am still getting the same error message.   \r\n- [Another bug report from 2020](https://github.com/keras-team/keras/issues/14194) also mentioned the same issue. Just like before, this was unfortunately also closed without solution. Note however, that in this case too, a pure `KerasClassifier` model was used and not a `sklearn` pipeline. Might be relevant.", "comments": ["@leweex95 \r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThank you!", "Thanks, I will do so.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54694\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54694\">No</a>\n"]}, {"number": 54693, "title": "Validation not executed", "body": "Why is the validation not executed, when the Flatten layer is used?\r\n\r\n```python \r\n model = Sequential()\r\n  for i in range(hp.Int('n_layers', 1, 6)):\r\n    model.add(Conv1D(filters=hp.Int(f'conv_{i}_filter',min_value=16,max_value=256,step=16), \r\n                     kernel_size=hp.Int(f'conv_{i}_kernel',min_value=1,max_value=20,step=1), \r\n                     activation='relu', \r\n                     input_shape=(n_steps_in, n_features)))\r\n  model.add(MaxPooling1D(pool_size=2))\r\n  model.add(Flatten())\r\n  model.add(Dense(50, activation='relu'))\r\n  model.add(Dense(n_output))\r\n  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\r\n  model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=hp_learning_rate),metrics = ['mae', 'msle'])\r\n```\r\n", "comments": [">Sorry, i did not pass data within the validation data."]}, {"number": 54692, "title": "Avoid local type inference upon node edits, and avoid running the type constructor if when adding a NodeDef that has type info already set. This increases the chance for stale type info during graph transformations, but avoids surprising behavior when the callers do supply a correct type.", "body": "Avoid local type inference upon node edits, and avoid running the type constructor if when adding a NodeDef that has type info already set. This increases the chance for stale type info during graph transformations, but avoids surprising behavior when the callers do supply a correct type.\nIt also has better support for incremental or partial type inference.\nIn general, it will be most robust to run the type inference pass before transforms which rely on it.\n", "comments": []}, {"number": 54691, "title": "Added possibility to convert Metal tensor back to descriptor.", "body": "Added possibility to convert Metal tensor back to descriptor.\n", "comments": []}, {"number": 54690, "title": "[XLA] Iterate directly over values in `HloLiveRange::NormalizeAliasedBuffers`.", "body": "[XLA] Iterate directly over values in `HloLiveRange::NormalizeAliasedBuffers`.\n\nThis is more efficient if the numbers of values in this computation is lower than the number of buffers in the alias analysis.\n", "comments": []}, {"number": 54689, "title": "Update highwayhash from fd3d9af80465e4383162e4a7c5e2f406e82dd968 to 8e7cfe476f67e865b2be62b5a60a75014a631c9a.", "body": "Update highwayhash from fd3d9af80465e4383162e4a7c5e2f406e82dd968 to 8e7cfe476f67e865b2be62b5a60a75014a631c9a.\n", "comments": []}, {"number": 54688, "title": "Update png from v1.6.37 to v1.6.35.", "body": "Update png from v1.6.37 to v1.6.35.\n", "comments": []}, {"number": 54687, "title": "After finetuning a BERT model max_position_embeddings=128, my saved model is not reflecting the smaller sequence length", "body": "I used to fine-tune BERT with tf1 with original BERT code, now that I am using tf-models-official, although I change max_position_embedding, my saved model file doesn't change. Previously when I limit max_seq_length and saved model with the associated signature (with the same max_seq_length) my saved model would be smaller. Here in tf-models-official I don't need to explicitly pass a signature, so the only place that l put limitation is in max_position_embedding. The problem is my saved model is bigger than I expected.\r\n   ", "comments": ["Hi @SohaK ! \r\nCould you please update the template too as it helps us analyse the [issue](https://github.com/tensorflow/tensorflow/issues/new/choose) [tf version, steps followed before you ran into this error or stand alone code/colab gist to reproduce the issue faced].Thanks!", "TF version: 2.7\r\n\r\nI am almost following https://www.tensorflow.org/text/tutorials/fine_tune_bert but with my own BERT model and data\r\n\r\nbert_config: {'hidden_size': 512,\r\n 'hidden_act': 'gelu',\r\n 'initializer_range': 0.02,\r\n 'vocab_size': 47644,\r\n 'hidden_dropout_prob': 0.1,\r\n 'num_attention_heads': 8,\r\n 'type_vocab_size': 2,\r\n 'max_position_embeddings': 128,\r\n 'num_hidden_layers': 12,\r\n 'intermediate_size': 2048,\r\n 'attention_probs_dropout_prob': 0.1,\r\n 'max_seq_length': 128}\r\n\r\n\r\nwith tf.saved_model.save(reloaded, export_dir=export_dir) I get the variables and pb files the variable file are 753 MB, but I expected to be 251 MB (based on older versions on TF1), the saved_model.pb is 4.65 MB while on TF1 I used to get 764kB.\r\nwith bert_classifier.save(export_dir, include_optimizer=False), I get the variables with the size I expect, and I get two pb files: saved_model.pb and keras_metadata.pb the saved_model.pb is 3.99 MB.\r\n\r\nDo these different saved models affect the runtime behavior and speed?\r\n\r\n", "Also\r\nbert_classifier = tf.saved_model.load(import_dir)\r\nbert_classifier.summary()\r\non both way of saving gives me\r\n\r\n'_UserObject' object has no attribute 'summary'\r\n", "@SohaK, When i tried to save the Fine_tune_bert model with same configuration as you mentioned, it has only one .pb file `saved_model.pb`. Size of the model ~3.4MB. \r\n\r\nUse keras load model to load your model.\r\n```\r\nfrom tensorflow import keras\r\n\r\nnew_model = keras.models.load_model(\"save_model_keras\")\r\nnew_model.summary()\r\n```", "Thank you @gadagashwini \r\n\r\nfrom tensorflow import keras\r\nimport_dir=\"AF_128_NQ_3\"\r\nreloaded = keras.models.load_model(import_dir)\r\nreloaded.summary()\r\n\r\ngives me:\r\n\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-6-8bed57a106ac> in <module>\r\n      1 from tensorflow import keras\r\n      2 import_dir=\"./AF_128_NQ_3\"\r\n----> 3 reloaded = keras.models.load_model(import_dir)\r\n      4 # reloaded = tf.saved_model.load(import_dir)\r\n      5 reloaded.summary()\r\n\r\n~/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages/keras/utils/traceback_utils.py in error_handler(*args, **kwargs)\r\n     65     except Exception as e:  # pylint: disable=broad-except\r\n     66       filtered_tb = _process_traceback_frames(e.__traceback__)\r\n---> 67       raise e.with_traceback(filtered_tb) from None\r\n     68     finally:\r\n     69       del filtered_tb\r\n\r\n~/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    528     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n    529     try:\r\n--> 530       result = method(self, *args, **kwargs)\r\n    531     finally:\r\n    532       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\nTypeError: __init__() missing 2 required positional arguments: 'inputs' and 'outputs'\r\n\r\n\r\n\r\n\r\n", "@gadagashwini I also need to be able to reload a bert classifier_model checkpoint to retrain further, but when I do:\r\n\r\nbert_classifier, bert_encoder = bert.bert_models.classifier_model(bert_config, num_labels=2)\r\ncheckpoint = tf.train.Checkpoint(model=bert_classifier)\r\ncheckpoint.read(os.path.join(path +'/model00000001.ckpt/variables/', 'variables')).assert_existing_objects_matched()\r\n\r\nI get this error:\r\n---------------------------------------------------------------------------\r\nAssertionError                            Traceback (most recent call last)\r\n<ipython-input-19-6fad2876f6ee> in <module>\r\n      1 checkpoint = tf.train.Checkpoint(model=bert_classifier)\r\n      2 checkpoint.read(\r\n----> 3     os.path.join(efs_path +\"AF2022/model00000001.ckpt/variables/\", 'variables')).assert_existing_objects_matched()\r\n\r\n~/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages/tensorflow/python/training/tracking/util.py in assert_existing_objects_matched(self)\r\n    845       num_variables_to_show = min(10, num_unused_python_objects)\r\n    846       raise AssertionError(\r\n--> 847           f\"Found {num_unused_python_objects} Python objects that were \"\r\n    848           \"not bound to checkpointed values, likely due to changes in the \"\r\n    849           f\"Python program. Showing {num_variables_to_show} of \"\r\n\r\nAssertionError: Found 201 Python objects that were not bound to checkpointed values, likely due to changes in the Python program. Showing 10 of 201 unmatched objects: [<tf.Variable 'transformer/layer_5/output/kernel:0' shape=(2048, 512) dtype=float32, numpy=...", "@SohaK, Could you share complete code to reproduce the issue. Thanks!", "@gadagashwini  This is the complete code:\r\n\r\n!pip install tensorflow==2.8\r\n!pip install -U tensorflow-text==2.8\r\n!pip install tf-models-official==2.7\r\n\r\n\r\nimport os\r\nimport json\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nfrom official.nlp import bert\r\nfrom official import nlp\r\n\r\n# Load the required submodules\r\nimport official.nlp.optimization\r\nimport official.nlp.bert.run_classifier\r\n\r\n\r\nefs_path = # a path\r\ndata_path =  efs_path + # a path\r\n\r\ngs_folder_bert = efs_path + # a path\r\ntf.io.gfile.listdir(gs_folder_bert)\r\n\r\nbert_config_file = os.path.join(gs_folder_bert, \"bert_config.json\")\r\nconfig_dict = json.loads(tf.io.gfile.GFile(bert_config_file).read())\r\n\r\nbert_config = bert.configs.BertConfig.from_dict(config_dict)\r\n\r\nbert_classifier, bert_encoder = bert.bert_models.classifier_model(\r\n    bert_config, num_labels=2)\r\n\r\ntrain_data_output_path=\"./AF_NQ_train.tf_record\"\r\neval_data_output_path=\"./AF_NQ_eval.tf_record\"\r\n\r\nmax_seq_length = 128\r\nbatch_size = 32\r\neval_batch_size = 32\r\n\r\ntraining_dataset = bert.run_classifier.get_dataset_fn(\r\n    train_data_output_path,\r\n    max_seq_length,\r\n    batch_size,\r\n    is_training=True)()\r\n\r\nevaluation_dataset = bert.run_classifier.get_dataset_fn(\r\n    eval_data_output_path,\r\n    max_seq_length,\r\n    eval_batch_size,\r\n    is_training=False)()\r\n\r\n\r\n\r\n# Set up epochs and steps\r\nepochs = 1\r\nbatch_size = 32\r\neval_batch_size = 32\r\n\r\nTRAIN_SIZE = # a number\r\ntrain_data_size = TRAIN_SIZE\r\nsteps_per_epoch = int(train_data_size / batch_size)\r\nnum_train_steps = steps_per_epoch * epochs\r\nwarmup_steps = int(epochs * train_data_size * 0.1 / batch_size)\r\n\r\n# creates an optimizer with learning rate schedule\r\noptimizer = nlp.optimization.create_optimizer(\r\n    2e-5, num_train_steps=num_train_steps, num_warmup_steps=warmup_steps)\r\n\r\n\r\n\r\ncheckpoint = tf.keras.callbacks.ModelCheckpoint('model{epoch:08d}_test.ckpt', save_freq=steps_per_epoch, save_format=\"tf\") \r\nlog = tf.keras.callbacks.TensorBoard(log_dir='./logs',update_freq=10)\r\nmetrics = [tf.keras.metrics.SparseCategoricalAccuracy('accuracy', dtype=tf.float32)]\r\nloss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\n\r\nbert_classifier.compile(\r\n    optimizer=optimizer,\r\n    loss=loss,\r\n    metrics=metrics)\r\n\r\nbert_classifier.fit(\r\n      training_dataset,\r\n      validation_data=evaluation_dataset,\r\n      batch_size=32,\r\n      steps_per_epoch=steps_per_epoch,\r\n      epochs=epochs,\r\n      callbacks=[checkpoint, log])\r\n\r\n\r\n\r\nexport_dir='./AF_128_NQ_3'\r\ntf.saved_model.save(bert_classifier, export_dir=export_dir)\r\n\r\nimport_dir=\"./AF_128_NQ_3\"\r\nbert_classifier = tf.keras.models.load_model(import_dir)\r\n\r\n\r\n---------------------------------------------------------------------------------------------------------------------------------\r\nWARNING:absl:Found untraced functions such as dropout_5_layer_call_fn, dropout_5_layer_call_and_return_conditional_losses, logits_layer_call_fn, logits_layer_call_and_return_conditional_losses, self_attention_layer_call_fn while saving (showing 5 of 364). These functions will not be directly callable after loading.\r\nINFO:tensorflow:Assets written to: ./AF_128_NQ_3/assets\r\nINFO:tensorflow:Assets written to: ./AF_128_NQ_3/assets\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n/tmp/ipykernel_1252/896310302.py in <module>\r\n      3 \r\n      4 import_dir=\"./AF_128_NQ_3\"\r\n----> 5 bert_classifier = tf.keras.models.load_model(import_dir)\r\n\r\n~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/keras/utils/traceback_utils.py in error_handler(*args, **kwargs)\r\n     65     except Exception as e:  # pylint: disable=broad-except\r\n     66       filtered_tb = _process_traceback_frames(e.__traceback__)\r\n---> 67       raise e.with_traceback(filtered_tb) from None\r\n     68     finally:\r\n     69       del filtered_tb\r\n\r\n~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    627     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n    628     try:\r\n--> 629       result = method(self, *args, **kwargs)\r\n    630     finally:\r\n    631       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\nTypeError: __init__() missing 2 required positional arguments: 'inputs' and 'outputs'\r\n", "@SohaK, Thanks for providing code to reproduce. Could you please provide the required documents like Json and dataset file. Thanks!", "As I said I am following https://www.tensorflow.org/text/tutorials/fine_tune_bert. ", "@SohaK,\r\nWhen i tried to save the [Fine_tune_bert model](https://www.tensorflow.org/text/tutorials/fine_tune_bert) with same configuration as you mentioned, it has only one .pb file saved_model.pb. Size of the model ~3.3MB.\r\nIf you are customising the model and training it again. Make sure you have the same size data set. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54687\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54687\">No</a>\n"]}, {"number": 54686, "title": "Update com_github_googlecloudplatform_google_cloud_cpp from v1.17.1 to v1.36.0.", "body": "Update com_github_googlecloudplatform_google_cloud_cpp from v1.17.1 to v1.36.0.\n", "comments": []}, {"number": 54685, "title": "Update com_github_google_crc32c from 1.0.6 to 1.1.2.", "body": "Update com_github_google_crc32c from 1.0.6 to 1.1.2.\n", "comments": []}, {"number": 54684, "title": "Also turn HLO bufferization dialect conversion patterns into rewrite patterns.", "body": "Also turn HLO bufferization dialect conversion patterns into rewrite patterns.\n", "comments": []}, {"number": 54683, "title": "Add a log message with more details when batch sizes differ.", "body": "Add a log message with more details when batch sizes differ.\n", "comments": []}, {"number": 54682, "title": "Fix bug with live range end position.", "body": "Fix bug with live range end position.\n", "comments": []}, {"number": 54680, "title": "TFlite benchmark_model tool: Don't destruct the NNAPI SL before destructing the", "body": "TFlite benchmark_model tool: Don't destruct the NNAPI SL before destructing the\ndelegate that uses it.\n", "comments": []}, {"number": 54679, "title": "[XLA:ALGEBRAIC_SIMPLIFIER] Handle Base Dilation correctly when folding a pad into a reduce window. The padding on the operand is dilated.", "body": "[XLA:ALGEBRAIC_SIMPLIFIER] Handle Base Dilation correctly when folding a pad into a reduce window. The padding on the operand is dilated.\n", "comments": []}, {"number": 54678, "title": "Update com_google_protobuf from v3.9.2 to v3.19.4.", "body": "Update com_google_protobuf from v3.9.2 to v3.19.4.\n", "comments": []}, {"number": 54677, "title": "Update png from v1.6.37 to v1.6.35.", "body": "Update png from v1.6.37 to v1.6.35.\n", "comments": []}]