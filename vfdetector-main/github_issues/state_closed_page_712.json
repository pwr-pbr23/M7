[{"number": 32220, "title": "[r2.0:Cherrypick]:Fix add_metric name ordering issue.", "body": "PiperOrigin-RevId: 267226711\r\n\r\nFixes: https://github.com/tensorflow/tensorflow/issues/32144", "comments": []}, {"number": 32219, "title": "TFP 0.8-rc0 AttributeError: 'MultivariateNormalTriL' object has no attribute 'type'", "body": "I am using TFP 0.8-rc0 with TF2.0.0-rc0 for a VAE composed with keras functional API. I am able to train the VAE however when I want to retrieve the latent code by calling the encoder only (using .predict()), it throws \r\n\r\n> AttributeError: 'MultivariateNormalTriL' object has no attribute 'type' \r\n\r\nwhich is not very informative in itself and I am not sure what it refers to. I am a bit confused why the decoder input seems to accept the output of the TFP layer without problem but can't seem to call predict on the encoder alone. Note that calling predict on encoder alone works when replacing the TFP layer with an equivalent keras sampling class. I understand that the tfp layer, when no convert_to_tensor_fn is defined, should call sample() by default so returning its output with encoder.predict(samples) should be possible.\r\n\r\nHere is a minimal reproduction code:\r\n\r\n\r\n\r\n```\r\n\r\nimport numpy as np\r\nimport os\r\nimport tensorflow_probability as tfp\r\ntfd = tfp.distributions\r\ntfpl = tfp.layers.distribution_layer\r\nimport tensorflow as tf\r\n\r\n\r\nload_model = 1\r\n\r\nlatent_dim = 8\r\nlearning_rate = 1e-4\r\n\r\nBATCH_SIZE = 100\r\nTEST_BATCH_SIZE = 10\r\n\r\n\r\ncolor_channels = 1\r\n(train_images, _), (test_images, _) = tf.keras.datasets.mnist.load_data()\r\n\r\ntrain_images = train_images[:5000,::]\r\nn_trainsamples = np.shape(train_images)[0]\r\nimsize = np.shape(train_images)[1]\r\ntrain_images = train_images.reshape(-1, imsize, imsize, 1).astype('float32')\r\ntrain_images /= 255.\r\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_images)).shuffle(n_trainsamples).repeat().batch(BATCH_SIZE)\r\n\r\nimage_input = tf.keras.Input(shape=(imsize, imsize, color_channels), name='encoder_input')\r\nx = tf.keras.layers.Flatten()(image_input)\r\nx = tf.keras.layers.Dense(500, activation='softplus', name=\"Inference-l1_Dense\")(x)\r\nx = tf.keras.layers.Dense(tfpl.MultivariateNormalTriL.params_size(latent_dim))(x)\r\nz = tfpl.MultivariateNormalTriL(latent_dim)(x)\r\nprior = tfd.Independent(tfd.Normal(loc=[0., 0], scale=1), reinterpreted_batch_ndims=1)\r\ntfpl.KLDivergenceAddLoss(prior, weight=1.0)\r\n\r\nencoder = tf.keras.Model(inputs=image_input, outputs=z, name='encoder')\r\n\r\nlatent_inputs = tf.keras.Input(shape=(latent_dim,), name='z_sampling')\r\nx = tf.keras.layers.Dense(500, activation='softplus', name=\"Generative-l1_Dense\")(latent_inputs)\r\nx = tf.keras.layers.Dense(imsize ** 2 * color_channels, activation='sigmoid', name=\"Generative-l3_Dense_out\")(x)  \r\n\r\noutput_probs = tf.keras.layers.Reshape(target_shape=(imsize, imsize, color_channels), name=\"Generative-output_probs\")(x)\r\n\r\ndecoder = tf.keras.Model(inputs=latent_inputs, outputs=output_probs, name='decoder')\r\noutput_probs = decoder(z)\r\n\r\nvae_model = tf.keras.Model(inputs=image_input, outputs=output_probs, name='vae')\r\n\r\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\r\nvae_model.compile(optimizer, tf.keras.losses.BinaryCrossentropy())\r\n\r\nvae_model.fit(train_dataset, steps_per_epoch=n_trainsamples // BATCH_SIZE, epochs=4)\r\n\r\nlatents = encoder.predict(train_images[:4,::])\r\nprint('latent shape: ' + latents.shape())\r\n\r\n\r\n```\r\n\r\n\r\n\r\nAnd the full stack with the error:\r\n\r\n> \r\n> 2019-09-04 21:56:37.276275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n> 2019-09-04 21:56:37.276332: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n> 2019-09-04 21:56:37.278632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n> 2019-09-04 21:56:37.278665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \r\n> 2019-09-04 21:56:37.278682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \r\n> 2019-09-04 21:56:37.280141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: eaaf:00:00.0, compute capability: 3.7)\r\n> Train for 50 steps\r\n> Epoch 1/4\r\n> WARNING: Logging before flag parsing goes to stderr.\r\n> W0904 21:56:38.184839 140359104337664 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/math_grad.py:1394: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Use tf.where in 2.0, which has the same broadcast rule as np.where\r\n> 2019-09-04 21:56:39.006765: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n> 50/50 [==============================] - 1s 29ms/step - loss: 0.2975\r\n> Epoch 2/4\r\n> 50/50 [==============================] - 0s 5ms/step - loss: 0.2114\r\n> Epoch 3/4\r\n> 50/50 [==============================] - 0s 5ms/step - loss: 0.1730\r\n> Epoch 4/4\r\n> 50/50 [==============================] - 0s 5ms/step - loss: 0.1590\r\n> Traceback (most recent call last):\r\n>   File \"/home/pycharm_project/VAE/save_issue_reproduction.py\", line 55, in <module>\r\n>     latents = encoder.predict(train_images[:4,::])\r\n>   File \"/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training.py\", line 915, in predict\r\n>     use_multiprocessing=use_multiprocessing)\r\n>   File \"/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\", line 722, in predict\r\n>     callbacks=callbacks)\r\n>   File \"/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\", line 189, in model_iteration\r\n>     f = _make_execution_function(model, mode)\r\n>   File \"/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\", line 565, in _make_execution_function\r\n>     return model._make_execution_function(mode)\r\n>   File \"/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training.py\", line 2155, in _make_execution_function\r\n>     self._make_predict_function()\r\n>   File \"/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training.py\", line 2145, in _make_predict_function\r\n>     **kwargs)\r\n>   File \"/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/backend.py\", line 3658, in function\r\n>     return EagerExecutionFunction(inputs, outputs, updates=updates, name=name)\r\n>   File \"/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/backend.py\", line 3555, in __init__\r\n>     base_graph=source_graph)\r\n>   File \"/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/lift_to_graph.py\", line 260, in lift_to_graph\r\n>     add_sources=add_sources))\r\n>   File \"/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/op_selector.py\", line 404, in map_subgraph\r\n>     elif op.type == \"Placeholder\":\r\n> AttributeError: 'MultivariateNormalTriL' object has no attribute 'type'\r\n", "comments": ["I have tried on colab with TF2.0.0-rc0 ,2.0 nightly version 2.0.0-dev20190903 and was able to reproduce the issue.Please, find the [gist](https://colab.sandbox.google.com/gist/ravikyram/5757e4e551b8262e9205a18f1a3637b4/untitled152.ipynb) here.Thanks!", "@reedwm any idea about this one?", "No idea, since I am unfamiliar with tensorflow probability. Maybe try filing an issue with the [tensorflow probability](https://github.com/tensorflow/probability) repo.", "Thanks for getting back to me, already done: https://github.com/tensorflow/probability/issues/544", "@reedwm the reason I asked you was the recent refactoring of dtypes in keras, though it seems the issue here is more around keras assuming all items returned by a layer are tensors or ops, whereas the distribution layers return subtypes of this class: https://github.com/tensorflow/probability/blob/master/tensorflow_probability/python/layers/internal/distribution_tensor_coercible.py#L41\r\n(note that keras is checking op.type in the stacktrace via lift_to_graph->op_selector).\r\nCould you point this to the right person in keras or TF?", "With my refactor, I was careful not to assume anything was a tensor. So this is probably caused by something else.\r\n\r\n/CC @fchollet @pavithrasv ", "So is this a tf.keras or a tfp bug then? Are there any fixes coming?", "@kristofgiber, @reedwm, @brianwa84, @ravikyram, The [original example](https://github.com/tensorflow/tensorflow/issues/32219#issue-489428442) works both with TFP 0.8 or TFP 0.9 combined with TF 2.1.  See also https://github.com/tensorflow/probability/issues/538#issuecomment-578224143, where I say that there are other examples that work with TF 2.1. \r\n\r\n**However**, I have an example where I am still getting this error `AttributeError: 'Normal' object has no attribute 'type'`, when the output of the network is a `Normal` distribution. I was trying to understand the differences between my example and the other mentioned examples, but I don't understand the differences that cause the issues.", "yes as pointed in the above comment the original example works with TF 2.1 and TFP 0.9 or 0.8\r\n\r\nI am going to mark this as fixed. \r\n@nbro can you please open a new issue with a minimal repro where it is failing for you. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32219\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32219\">No</a>\n", "@goldiegadde I have already opened the issue: https://github.com/tensorflow/tensorflow/issues/34765. And, finally, I understood the cause of the issue and I created a simple example that shows it. See https://github.com/tensorflow/tensorflow/issues/34765#issuecomment-580359337."]}, {"number": 32218, "title": "tf.signal.fft2d speed is slow and unstable in RTX2080Ti", "body": "**System information**\r\n- OS Platform: Linux Ubuntu 18.04 (server)\r\n- TensorFlow installed from: docker tensorflow/tensorflow  1.14.0-gpu-py3-jupyter \r\n- TensorFlow version: 1.14.0\r\n- Python version: 3.6.8\r\n- CUDA:  v10.0\r\n- GPU model: RTX 2080Ti \r\n\r\n**Describe the current behavior**\r\nThe speed of fft2d operation `tf.signal.fft2d` is very unstable at different iterations. Here is an example output of time every 100 iterations (code is shown below):\r\n```\r\n2019-09-04 19:03:57.731947\r\n2019-09-04 19:04:33.715335\r\n2019-09-04 19:05:10.976109\r\n2019-09-04 19:05:44.012072\r\n2019-09-04 19:06:15.616308\r\n2019-09-04 19:07:14.961716\r\n2019-09-04 19:08:12.324199\r\n2019-09-04 19:09:11.560423\r\n2019-09-04 19:10:08.877960\r\n2019-09-04 19:11:08.102977\r\n```\r\nDuring the training, there is no other programs running.\r\n\r\nBur when running the same code in my local machine (GTX 1080Ti) with the same TensorFlow docker image. The speed is fast and stable.\r\n```\r\n2019-09-04 14:12:00.387114\r\n2019-09-04 14:12:07.363174\r\n2019-09-04 14:12:14.355784\r\n2019-09-04 14:12:21.384377\r\n2019-09-04 14:12:28.378524\r\n```\r\n\r\n**Describe the expected behavior**\r\nThe speed should be always very fast (about 7s/100iterations).\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport os\r\nimport datetime\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\r\n\r\ndef main(_):\r\n    dp_train = tf.placeholder(tf.float32, shape=(41, 300, 300, 1))\r\n    dp = tf.complex(dp_train, 0.0)\r\n    dp_fft = tf.abs(tf.signal.fft2d(dp))\r\n    W = tf.get_variable('W_conv', [1, 1, 1, 1])  # not important, just want to make the training process to run.\r\n    cost_train = tf.reduce_mean(tf.nn.conv2d(dp_fft, W, strides=[1, 1, 1, 1], padding='SAME'))\r\n\r\n    opt = tf.train.AdamOptimizer(1e-4)\r\n    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n    with tf.control_dependencies(update_ops):\r\n        train_op = opt.minimize(cost_train)  # var_list=vars_digital\r\n\r\n    with tf.Session() as sess:\r\n        sess.run(tf.global_variables_initializer())\r\n        sess.run(tf.local_variables_initializer())\r\n        coord = tf.train.Coordinator()\r\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\r\n\r\n        for i in range(0, 5000):\r\n            data = np.random.rand(41,300,300,1)\r\n            sess.run(train_op, feed_dict={dp_train:data})\r\n            if i % 100 ==0:\r\n                old_time = datetime.datetime.now()\r\n                print(old_time)\r\n\r\n        coord.request_stop()\r\n        coord.join(threads)\r\n\r\nif __name__ == '__main__':\r\n    tf.app.run()\r\n\r\n```\r\n", "comments": ["I was able to reproduce the issue with Tensorflow 1.14.0. Please see the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/63fded2fb0049ecf0e1a8de505856559/untitled125.ipynb). Thanks", "Thanks for the report! Note that in your example, `tf.signal.fft2d` operates over the inner-most 2 dimensions (`[300, 1]`) so this is likely even slower than you measure.", "> I was able to reproduce the issue with Tensorflow 1.14.0. Please see the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/63fded2fb0049ecf0e1a8de505856559/untitled125.ipynb). Thanks\r\n\r\nThanks for the Colab! The CUDA device filter \r\n```python\r\nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\r\n```\r\nis causing TensorFlow to ignore its GPU, running the FFT on CPU:\r\n\r\n```python\r\ntf.config.experimental.get_visible_devices()\r\n> [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\r\n```\r\n\r\nWhen I remove the device filters I get consistent timing:\r\n```\r\n2019-09-20 06:24:40.498802\r\n2019-09-20 06:24:45.739194\r\n2019-09-20 06:24:51.046707\r\n2019-09-20 06:24:56.424465\r\n2019-09-20 06:25:01.734107\r\n2019-09-20 06:25:07.108748\r\n2019-09-20 06:25:12.504023\r\n2019-09-20 06:25:17.908167\r\n2019-09-20 06:25:23.324278\r\n2019-09-20 06:25:28.803539\r\n2019-09-20 06:25:34.155487\r\n2019-09-20 06:25:39.518539\r\n2019-09-20 06:25:44.901134\r\n2019-09-20 06:25:50.260070\r\n2019-09-20 06:25:55.723608\r\n2019-09-20 06:26:01.048212\r\n```\r\n\r\n@YichengWu are you certain your example code is actually running on GPU?", "@rryan , thank you so much for your help! Yes, my code is running on GPU. And the speed is varying from day to day even there is nothing else running on the cluster, sometimes 60s/100iter, sometimes 7s/100iter.", "> @rryan , thank you so much for your help! Yes, my code is running on GPU. And the speed is varying from day to day even there is nothing else running on the cluster, sometimes 60s/100iter, sometimes 7s/100iter.\r\n\r\nGotcha, what happens when you run this on the machine with the RTX2080Ti?\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport os\r\nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\r\ntf.config.experimental.get_visible_devices()\r\n```", "If this is a cluster, is it possible that your job is switching between multiple machines -- some of which have a PCI_BUS_ID 1 for the RTX2080Ti, some of which don't? ", "One way to make sure in the code is to add this after you set CUDA_VISIBLE_DEVICES:\r\n\r\n```python\r\n# Check there is a GPU available.\r\nassert tf.config.experimental.get_visible_devices(\"GPU\")\r\n```\r\n\r\nand then later in your code:\r\n\r\n```python\r\nwith tf.device('/gpu:0'):\r\n  dp_fft = tf.abs(tf.signal.fft2d(dp))\r\n```\r\nThat way, TensorFlow will throw an error if it can't put the FFT on a GPU.\r\n\r\nWe definitely could have a bug leading to unstable performance, but I just want to sanity check and make sure that the FFTs are definitely running on the GPU in your cluster environment.", "Hey RJ, I just checked my code and the code is running on the GPU. Just want to let you know that there were several times that the speed changed a lot for one running (without stopping the code)", "Thanks for double-checking and the additional info (the speed changes within the same training run). I don't know what could be causing this.\r\n\r\nWhen you hit a period of slowness, what happens if you kill training and re-start? Does it return to fast execution immediately or does the slowness persist?", "If I restart, the code is still slow. After a random period of time, the code becomes fast.", "This is what I saw just now, the speed changed from 40s/100iter to 6s/100iter.\r\n2019-09-30 01:50:45.808665\r\n2019-09-30 01:51:25.043709\r\n2019-09-30 01:52:04.264984\r\n2019-09-30 01:52:44.757427\r\n2019-09-30 01:53:25.178119\r\n2019-09-30 01:54:04.592331\r\n2019-09-30 01:54:44.897020\r\n2019-09-30 01:55:24.013882\r\n2019-09-30 01:56:03.740308\r\n2019-09-30 01:56:43.617144\r\n2019-09-30 01:57:23.751177\r\n2019-09-30 01:58:04.228672\r\n2019-09-30 01:58:45.134902\r\n2019-09-30 01:59:24.387479\r\n2019-09-30 01:59:57.731981\r\n2019-09-30 02:00:03.707638\r\n2019-09-30 02:00:09.638930\r\n2019-09-30 02:00:15.949742\r\n2019-09-30 02:00:22.020293\r\n2019-09-30 02:00:28.099341\r\n", "Could you please post the output of `nvidia-smi` when the issue is occurring and when the issue not occurring? I'd like to see the difference between the two.", "The  GPU-Util is very low when the code is slow. Output from `nvidia-smi`:\r\nHere is when the code is slow\r\n```\r\n|   4  GeForce RTX 208...  Off  | 00000000:88:00.0 Off |                  N/A |\r\n| 30%   40C    P2    54W / 250W |  10903MiB / 11019MiB |      0%      Default |\r\n\r\n|    4      4009      C   python                                     10893MiB |\r\n```\r\n\r\nHere is when the code is fast\r\n```\r\n|   4  GeForce RTX 208...  Off  | 00000000:3E:00.0 Off |                  N/A |\r\n| 31%   43C    P2    74W / 250W |  10942MiB / 11019MiB |      6%      Default |\r\n\r\n|    4     19222      C   python                                     10151MiB |\r\n```", "Thanks @YichengWu! \r\n\r\nCould you please instrument your code to take TensorFlow traces and save them? \r\n\r\nYou can use [tf.train.ProfilerHook](https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/train/ProfilerHook), which would require you to update your code to use `tf.train.MonitoredSession`, or you could capture a trace manually using [this approach](https://gist.githubusercontent.com/ikhlestov/80ee9abee427b13bf9d9c5103ebb2e6e/raw/c744f959769f7bde374856565922132a86991dee/01_simple_example.py\r\n).", "Ideally, please post a JSON trace file for both the slow behavior and fast behavior. ", "The files are attached.\r\n[json_files.zip](https://github.com/tensorflow/tensorflow/files/3674021/json_files.zip)\r\n", "Thanks! What the trace shows is that the actual kernel execute time (on `/device:GPU:0/stream:all`) is comparable between the two:\r\n\r\nFast (0.137 ms):\r\n<img width=\"1190\" alt=\"Screen Shot 2019-09-30 at 11 26 13 PM\" src=\"https://user-images.githubusercontent.com/26527/65939139-de63c680-e3d9-11e9-8536-a2a1f9b18e37.png\">\r\n\r\nSlow (0.143 ms):\r\n<img width=\"1315\" alt=\"Screen Shot 2019-09-30 at 11 26 44 PM\" src=\"https://user-images.githubusercontent.com/26527/65939144-e0c62080-e3d9-11e9-84ba-32a58419989c.png\">\r\n\r\nYet the FFT2D op execution itself (`/job:localhost/replica:0/task:0/device:GPU:0` [1]) takes a lot longer in the slow profile (346 ms vs. 2552 ms). \r\n\r\nSo this suggests that in periods of slowness, something about the CPU side of the FFT op is taking a lot longer. \r\n\r\nThe Conv2DBackpropFilter op has the same discrepancy in timing -- in the fast trace it takes 2002 ms, and in the slow trace it takes 24072 ms. If you look at the actual Conv2DBackpropFilter ops in `/device:GPU:0/stream:all`, they are the same speed between the two traces.\r\n\r\nThis suggests that the issue isn't related to FFT ops specifically, and it's probably not related to the GPU either since the ops appear to be executing efficiently on device.\r\n\r\nWhat's the CPU load of the machine during periods of slowness? How about RAM usage? Does the machine have virtual memory enabled and is it possible it's swapping? Just trying to think of things that could change over time that could cause the CPU to run a lot more slowly, or for TensorFlow to have reduced access to cores on the machine (higher priority processes?).\r\n\r\n[1] This is a \"logical\" GPU device, which represents the execution of the FFT from start to finish -- including CPU-based logic to prepare the GPU for the FFT, then the FFT kernel itself, and any cleanup that must be done. The `stream` GPU devices represent actual time on the device.", "@YichengWu we are discussing this internally and don't really know what could be causing it. We may have seen similar issues on V100/P100 GPUs -- in those cases, profiling suggests all the time is spent within the CUDA API (in the request to launch the kernel).\r\n\r\nOne hypothesis is that due to an architecture mismatch between the bundled kernels and your GPU, CUDA may be JIT'ing a specialized kernel on the fly. There is a cache for JIT'ed kernels, and we are wondering if something is causing CUDA to need to regularly re-compile the kernels needed for your program.\r\n\r\nThere are some configuration options for the JIT and cache here:\r\nhttps://devblogs.nvidia.com/cuda-pro-tip-understand-fat-binaries-jit-caching/\r\n\r\nIn particular, I'm wondering what happens when you set `CUDA_CACHE_DISABLE=1` and `CUDA_FORCE_PTX_JIT=1`. If that reproduces the slow behavior then we can probably conclude that something is causing your CUDA kernel cache to churn.", "@rryan I added the code as you suggested (shown below). But the speed is the same with/without the following code (both are slow or fast):\r\n```\r\nCUDA_CACHE_DISABLE=1\r\nCUDA_FORCE_PTX_JIT=1\r\n```\r\nPlease let me know if there is anything wrong in my implementation.\r\n\r\nThe completed code is here:\r\n```\r\nimport os\r\nimport datetime\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tensorflow.python.client import timeline\r\n\r\n\r\nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\r\nCUDA_CACHE_DISABLE=1\r\nCUDA_FORCE_PTX_JIT=1\r\n\r\n# Check there is a GPU available.\r\nassert tf.config.experimental.get_visible_devices(\"GPU\")\r\n\r\ndef main(_):\r\n    dp_train = tf.placeholder(tf.float32, shape=(41, 300, 300, 1))\r\n    dp = tf.complex(dp_train, 0.0)\r\n    with tf.device('/gpu:0'):\r\n      dp_fft = tf.abs(tf.signal.fft2d(dp))\r\n    W = tf.get_variable('W_conv', [1, 1, 1, 1])  # not important, just want to make the training process to run.\r\n    cost_train = tf.reduce_mean(tf.nn.conv2d(dp_fft, W, strides=[1, 1, 1, 1], padding='SAME'))\r\n\r\n    opt = tf.train.AdamOptimizer(1e-4)\r\n    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n    with tf.control_dependencies(update_ops):\r\n        train_op = opt.minimize(cost_train)  # var_list=vars_digital\r\n\r\n    with tf.Session() as sess:\r\n        options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\r\n        run_metadata = tf.RunMetadata()\r\n        sess.run(tf.global_variables_initializer())\r\n        sess.run(tf.local_variables_initializer())\r\n        coord = tf.train.Coordinator()\r\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\r\n        \r\n        for i in range(0, 1000):\r\n            data = np.random.rand(41,300,300,1)\r\n            sess.run(train_op, feed_dict={dp_train:data})\r\n\r\n            if i % 100 ==0:\r\n                old_time = datetime.datetime.now()\r\n                print(old_time)\r\n                \r\n\r\n\r\n        coord.request_stop()\r\n        coord.join(threads)\r\n\r\nif __name__ == '__main__':\r\n    tf.app.run()\r\n```", "> os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\r\n> os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\r\n> CUDA_CACHE_DISABLE=1\r\n> CUDA_FORCE_PTX_JIT=1\r\n\r\nThanks! It would need to be set as an environment variable like CUDA_DEVICE_ORDER:\r\n\r\n```python\r\nos.environ[\"CUDA_CACHE_DISABLE\"] = \"1\"\r\nos.environ[\"CUDA_FORCE_PTX_JIT\"] = \"1\"\r\n```", "I did one test several days ago. First I didn't have these two lines and the code ran fast (7s/100iter). After adding these two lines, the code loading process was really slow (took about 30mins) and the running process was slow (65s/100iter). I am not sure if it proves that cache is the reason because the code was slow (60s/iter, not the loading part) after I commented out these two lines. I can try more tests but the code is always slow for several days.\r\n\r\n```\r\n2019-10-17 18:28:39.065277: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\r\n\r\n2019-10-17 18:30:39.189080: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n\r\n2019-10-17 18:58:12.048244\r\n2019-10-17 18:59:17.135890\r\n2019-10-17 19:00:21.047744\r\n2019-10-17 19:01:26.743846\r\n```", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32218\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32218\">No</a>\n", "I have the same problem when using 3080 and tf2.5"]}, {"number": 32217, "title": "Make curl available on all tensorflow docker images", "body": "While working on some Kubeflow Pipelines automation\r\nwe noticed the gpu based tf images had curl installed\r\nwhile the non-gpu didn't which was causing some issues.\r\n\r\nThis consistently make curl available on all images.", "comments": []}, {"number": 32216, "title": "[XLA] [GPU] Support int8 in BufferComparator", "body": "\u2026llision.\r\n\r\n@cheshire I just changed the version number to 4.2 and replaced tabs with spaces.  Could you try it again?", "comments": ["@yongfeng-nv  Could you take a look at a conflict and rebase? I think an unrelated change erroneously addded some whitespace to buffer_comparator, it looks like the other changes could be discarded.", "> @yongfeng-nv Could you take a look at a conflict and rebase? I think an unrelated change erroneously addded some whitespace to buffer_comparator, it looks like the other changes could be discarded.\r\n\r\nJust merged and updated the PR."]}, {"number": 32215, "title": "Weights that are SparseTensor values do not get gradients in eager execution mode", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v1.14.0-rc1-22-gaf24dc91b5 1.14.0 also reproduces on v2.0.0-beta1-5101-gc75bb66 2.0.0-rc0\r\n- Python version: 3.6.7\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: None\r\n- GPU model and memory: None\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nWhen trying to train a subclassed Keras model that has a trainable parameter that is the values Tensor of a SparseTensor weight matrix, the training fails with an error message saying that the parameter does not have gradients. This problem reproduces only in eager mode.\r\n\r\n**Describe the expected behavior**\r\n\r\nThe values of non-zero elements in sparse weight matrices with fixed indices should be trainable.\r\n\r\n**Code to reproduce the issue**\r\n\r\nThe code for the two versions only differs in enabling eager execution and the loss function.\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n#Without this line the script works in v1.14.\r\n#comment out this line for v2.0-rc0\r\ntf.enable_eager_execution()\r\n\r\n\r\ndef matmul_dense_sparse(a, b):\r\n    ta = tf.transpose(a)\r\n    tb = tf.sparse.transpose(b)\r\n    return tf.transpose(tf.sparse.sparse_dense_matmul(tb, ta))\r\n\r\n\r\nclass SparseLayer(tf.keras.layers.Layer):\r\n    def __init__(self, indices, shape):\r\n        super().__init__()\r\n        self.indices = indices\r\n        self.shape = shape\r\n\r\n    def build(self, input_shape):\r\n        self.w = self.add_weight(name='w',\r\n                        shape=(self.indices.shape[0],),\r\n                        trainable=True)\r\n        self.sparse_mat = tf.sparse.reorder(tf.sparse.SparseTensor(self.indices, self.w, self.shape))\r\n        super().build(input_shape)\r\n\r\n    def call(self, inputs):\r\n        return matmul_dense_sparse(inputs, self.sparse_mat)\r\n\r\n\r\nclass SparseModel(tf.keras.Model):\r\n    def __init__(self, indices, shape):\r\n        super().__init__()\r\n        self.l1 = SparseLayer(indices, shape)\r\n\r\n    def call(self, inputs):\r\n        return self.l1(inputs)\r\n\r\nindices = np.array([[1, 2], [30, 1], [30, 3], [45, 2], [56, 2], [32, 4]])\r\n\r\nex_x = np.random.rand(20, 100)\r\nex_y = np.random.rand(20, 5)\r\n\r\nmodel = SparseModel(indices, (100, 5))\r\n\r\n#compile for v1.14\r\nmodel.compile(tf.keras.optimizers.SGD(), tf.losses.mean_squared_error)\r\n#compile for v2.0-rc0\r\n#model.compile(tf.keras.optimizers.SGD(), tf.losses.MeanSquaredError())\r\n\r\nmodel.fit(ex_x, ex_y)\r\n```\r\n\r\n**Other info / logs**\r\nTraceback in v1.14:\r\n```\r\nTraceback (most recent call last):\r\n  File \"bug_reprod.py\", line 43, in <module>\r\n    model.fit(ex_x, ex_y)\r\n  File \"/home/mero/.ve/tfsim-P0VFtrg_/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 780, in fit\r\n    steps_name='steps_per_epoch')\r\n  File \"/home/mero/.ve/tfsim-P0VFtrg_/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\", line 157, in model_iteration\r\n    f = _make_execution_function(model, mode)\r\n  File \"/home/mero/.ve/tfsim-P0VFtrg_/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\", line 532, in _make_execution_function\r\n    return model._make_execution_function(mode)\r\n  File \"/home/mero/.ve/tfsim-P0VFtrg_/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 2276, in _make_execution_function\r\n    self._make_train_function()\r\n  File \"/home/mero/.ve/tfsim-P0VFtrg_/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 2219, in _make_train_function\r\n    params=self._collected_trainable_weights, loss=self.total_loss)\r\n  File \"/home/mero/.ve/tfsim-P0VFtrg_/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\", line 491, in get_updates\r\n    grads = self.get_gradients(loss, params)\r\n  File \"/home/mero/.ve/tfsim-P0VFtrg_/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\", line 398, in get_gradients\r\n    \"K.argmax, K.round, K.eval.\".format(param))\r\nValueError: Variable <tf.Variable 'sparse_model/sparse_layer/w:0' shape=(6,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\r\n```\r\n\r\nTraceback in 2.0-rc0:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"bug_reprod.py\", line 42, in <module>\r\n    model.fit(ex_x, ex_y)\r\n  File \"/home/mero/.ve/tfsim-8nc9BEC-/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\", line 734, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/home/mero/.ve/tfsim-8nc9BEC-/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 324, in fit\r\n    total_epochs=epochs)\r\n  File \"/home/mero/.ve/tfsim-8nc9BEC-/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 123, in run_one_epoch\r\n    batch_outs = execution_function(iterator)\r\n  File \"/home/mero/.ve/tfsim-8nc9BEC-/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 86, in execution_function\r\n    distributed_function(input_fn))\r\n  File \"/home/mero/.ve/tfsim-8nc9BEC-/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\", line 427, in __call__\r\n    self._initialize(args, kwds, add_initializers_to=initializer_map)\r\n  File \"/home/mero/.ve/tfsim-8nc9BEC-/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\", line 370, in _initialize\r\n    *args, **kwds))\r\n  File \"/home/mero/.ve/tfsim-8nc9BEC-/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 1847, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/home/mero/.ve/tfsim-8nc9BEC-/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 2147, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/home/mero/.ve/tfsim-8nc9BEC-/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 2038, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/home/mero/.ve/tfsim-8nc9BEC-/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\", line 915, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/home/mero/.ve/tfsim-8nc9BEC-/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\", line 320, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/home/mero/.ve/tfsim-8nc9BEC-/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 73, in distributed_function\r\n    per_replica_function, args=(model, x, y, sample_weights))\r\n  File \"/home/mero/.ve/tfsim-8nc9BEC-/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 760, in experimental_run_v2\r\n    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n  File \"/home/mero/.ve/tfsim-8nc9BEC-/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 1787, in call_for_each_replica\r\n    return self._call_for_each_replica(fn, args, kwargs)\r\n  File \"/home/mero/.ve/tfsim-8nc9BEC-/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 2132, in _call_for_each_replica\r\n    return fn(*args, **kwargs)\r\n  File \"/home/mero/.ve/tfsim-8nc9BEC-/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py\", line 292, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/home/mero/.ve/tfsim-8nc9BEC-/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 264, in train_on_batch\r\n    output_loss_metrics=model._output_loss_metrics)\r\n  File \"/home/mero/.ve/tfsim-8nc9BEC-/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py\", line 311, in train_on_batch\r\n    output_loss_metrics=output_loss_metrics))\r\n  File \"/home/mero/.ve/tfsim-8nc9BEC-/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py\", line 272, in _process_single_batch\r\n    model.optimizer.apply_gradients(zip(grads, trainable_weights))\r\n  File \"/home/mero/.ve/tfsim-8nc9BEC-/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\", line 427, in apply_gradients\r\n    grads_and_vars = _filter_grads(grads_and_vars)\r\n  File \"/home/mero/.ve/tfsim-8nc9BEC-/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\", line 1025, in _filter_grads\r\n    ([v.name for _, v in grads_and_vars],))\r\nValueError: No gradients provided for any variable: ['sparse_model/sparse_layer/w:0'].\r\n```\r\n\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Passing variable as tensor and then try to get gradients is not supported. This will very likely error out even if you're using dense tensor as well. If you want to support sparse input, simply use tf.keras.layers.Dense since it already supports sparse input today (starting in TF 2.0 rc0)", "If I understand @martinwicke 's comments on the issue #6998 well this is supposed to work this way. Replacing all sparse ops with their dense equivalent makes the above code work on 2.0-rc0.", "I made a workaround for my use case with `tf.custom_gradient`. It is probably slow on the backward pass, but works. It can be found here: https://gist.github.com/laci37/b7bcb88a08ed09e298b6bf34393ad80b"]}, {"number": 32214, "title": " Error installing tensorflow centos 7", "body": "\r\nhi guys, i'm trying to install tensorflow on centos 7, i have python 3.7.4 installed.\r\n\r\nWhen trying to give the pip looks like the message:\r\nCould not find a version that satisfies the requirement tensorflow (from versions:) No matching distribution found for tensorflow\r\n\r\n\r\nCould you please help me?", "comments": ["What version of pip?", "Version 19.2.3", "Can you post the full log of `python -m pip install --upgrade pip && python -m pip install --upgrade tensorflow`?", "\r\nThis is the message that appears:\r\n\r\n![MJ9oUp1SML](https://user-images.githubusercontent.com/38332691/64284614-5ef4eb80-cf30-11e9-979f-e793b45a8d53.png)\r\n", "Add in a `-v` on the second `pip install` so we get more detailed logs.\r\n\r\nMost likely this is an issue with your environment, not a bug in TF.", "Also, try `pip install --upgrade setuptools`", "I did the procedure, and gave this message:\r\n\r\n![UPoJ9ARnws](https://user-images.githubusercontent.com/38332691/64287141-50f59980-cf35-11e9-9983-8ac523668ae3.png)\r\n\r\nI also upgraded setuptools, then tried again and presented the same message\r\n\r\nI am suspecting it to be some limitation for the centos 7 version I am using.\r\n\r\nThe version I use is Centos Linux release 7.4.1708 (AltArch)", "On windows and Ubuntu it worked normally", "Probably the c++ compiler or some standard library.\r\n\r\nPlease try with `-vvv`.\r\n\r\nAlso, it's harder to read from the images, can you copy-paste instead?", "\r\nI had to do it all over again.\r\n\r\nI had to attach the error log as it exceeded the character limit\r\n[error.txt](https://github.com/tensorflow/tensorflow/files/3580706/error.txt)\r\n", "Hello, can anyone help me?", "Can you also post the output of `pip debug --verbose`? Sorry for the delay in answering", "```\r\n(tensorflowteste01) [root@localhost ~]# pip debug --verbose\r\nWARNING: This command is only meant for debugging. Do not use this with automation for parsing and getting these details, since the output and options of this command may change without notice.\r\npip version: pip 19.2.3 from /root/.pyenv/versions/3.7.4/envs/tensorflowteste01/lib/python3.7/site-packages/pip (python 3.7)\r\nsys.version: 3.7.4 (default, Sep  5 2019, 14:57:56) \r\n[GCC 4.8.5 20150623 (Red Hat 4.8.5-36)]\r\nsys.executable: /root/.pyenv/versions/3.7.4/envs/tensorflowteste01/bin/python3.7\r\nsys.getdefaultencoding: utf-8\r\nsys.getfilesystemencoding: utf-8\r\nlocale.getpreferredencoding: UTF-8\r\nsys.platform: linux\r\nsys.implementation:\r\n  name: cpython\r\nCompatible tags: 38\r\n  cp37-cp37m-manylinux2010_i686\r\n  cp37-cp37m-manylinux1_i686\r\n  cp37-cp37m-linux_i686\r\n  cp37-abi3-manylinux2010_i686\r\n  cp37-abi3-manylinux1_i686\r\n  cp37-abi3-linux_i686\r\n  cp37-none-manylinux2010_i686\r\n  cp37-none-manylinux1_i686\r\n  cp37-none-linux_i686\r\n  cp36-abi3-manylinux2010_i686\r\n  cp36-abi3-manylinux1_i686\r\n  cp36-abi3-linux_i686\r\n  cp35-abi3-manylinux2010_i686\r\n  cp35-abi3-manylinux1_i686\r\n  cp35-abi3-linux_i686\r\n  cp34-abi3-manylinux2010_i686\r\n  cp34-abi3-manylinux1_i686\r\n  cp34-abi3-linux_i686\r\n  cp33-abi3-manylinux2010_i686\r\n  cp33-abi3-manylinux1_i686\r\n  cp33-abi3-linux_i686\r\n  cp32-abi3-manylinux2010_i686\r\n  cp32-abi3-manylinux1_i686\r\n  cp32-abi3-linux_i686\r\n  py3-none-manylinux2010_i686\r\n  py3-none-manylinux1_i686\r\n  py3-none-linux_i686\r\n  cp37-none-any\r\n  cp3-none-any\r\n  py37-none-any\r\n  py3-none-any\r\n  py36-none-any\r\n  py35-none-any\r\n  py34-none-any\r\n  py33-none-any\r\n  py32-none-any\r\n  py31-none-any\r\n  py30-none-any\r\n```", "None of those tags show up on the [released wheels page](https://pypi.org/project/tensorflow/2.0.0rc0/). Is your CPU or Python on 32 bits? Then, this is a case of #32315, we don't have support for 32 bits at the moment.", "\r\nI will change my system to 64 bits and see if it will work.\r\n\r\nThanks for your help, I will leave it open even if I encounter any difficulty.", "Any updates? Is this issue fixed?", "\r\nI am waiting for the infrastructure to change to 64 bits.\r\n\r\nFor now I will mark as solved the problem, and anything I mention again.\r\n\r\nThanks a lot for the help. Have a great day", "https://github.com/tensorflow/tensorflow/issues/32627"]}, {"number": 32213, "title": "[micro] TFLite optimization failed with TFLite micro interpreter", "body": "**System information**\r\n- custom code: Modified TFLite micro example, **hello_world**, to use MNIST.\r\n- OS Platform and Distribution: Linux Ubuntu 18.04\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: v1.12.1-3259-gf59745a381 2.0.0-beta0\r\n- Python version: 3.6.8\r\n\r\n**Describe the current behavior**\r\nWithout TFL converter optimization, prediction on **micro interpreter** works.\r\nWith any TFL converter optimization, prediction on **micro interpreter** gets wild and produce **random** values.\r\nFor example,\r\n`converter.optimizations = [tf.lite.Optimize.DEFAULT]`\r\n\r\n**Describe the expected behavior**\r\nRegardless of TFL converter optimization, prediction on **micro interpreter** should work.\r\n\r\n**Code to reproduce the issue**\r\nhttps://github.com/ehirdoy/tflm-helloworld/tree/bug\r\n\r\nNG: https://github.com/ehirdoy/tflm-helloworld/commit/13fd1c39e368729f574f44daf93299470ec1649d HEAD\r\nOK: https://github.com/ehirdoy/tflm-helloworld/commit/a025d2a5f5c2487b551b6bfd8414926ebf864bfb HEAD^\r\n\r\n> $ git checkout -f bug\r\n> $ make input_data.h\r\n> $ make\r\n> $ ./hello_world # NG\r\n> $ git checkout HEAD^\r\n> $ make\r\n> $ ./hello_world # OK\r\n\r\n**Other info / logs**\r\nLogs are in the git commit mesage in the above, {OK,NG} commits.\r\n\r\n> commit 13fd1c39e368729f574f44daf93299470ec1649d (HEAD, origin/bug, github/bug)\r\n> Author: Hiroshi Doyu <hiroshi.doyu@ericsson.com>\r\n> Date:   Wed Sep 4 14:14:33 2019 +0300\r\n> \r\n>     [BUG?] store TFLite file optimized for size\r\n> \r\n>     Without the following\r\n>       'converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]',\r\n>     MNIST prediction works OK as seen in the previous commit log.\r\n> \r\n>     With the above OPTIMIZE_FOR_SIZE inserted right before convert(),\r\n>     MNIST prediction seems to go wild with random values as seen below:\r\n> \r\n>       $ touch train-mnist-tflite.py\r\n>       $ make\r\n>       $ ./hello_world\r\n> \r\n>           ......\r\n>           ................\r\n>           ................\r\n>                ...........\r\n>                       ....\r\n>                      ....\r\n>                      ....\r\n>                     ....\r\n>                     ....\r\n>                    ....\r\n>                    ...\r\n>                   ....\r\n>                  ....\r\n>                 .....\r\n>                 ....\r\n>                .....\r\n>                ....\r\n>               .....\r\n>               .....\r\n>               ....\r\n> \r\n>     0: 0.096435\r\n>     1: 0.083848\r\n>     2: 0.109924\r\n>     3: 0.096781\r\n>     4: 0.103029\r\n>     5: 0.100698\r\n>     6: 0.095319\r\n>     7: 0.095055\r\n>     8: 0.114907\r\n>     9: 0.104004\r\n>\r\n>     0: 0.000000\r\n>     1: 0.000000\r\n>     2: 0.000000\r\n>     3: 0.000000\r\n>     4: 0.000000\r\n>     5: 0.000000\r\n>     6: 0.000000\r\n>     7: 0.000000\r\n>     8: 1.000000\r\n>     9: 0.000000\r\n> ", "comments": ["@ehirdoy Is this still an issue? Can you check with `TF2.0` and let us know whether the issue persists with latest TF version. If this was not resolved with `TF2.0` or `tf-nightly`, please update [the gist](https://colab.sandbox.google.com/gist/jvishnuvardhan/ea39638fcb8ad1294985631e25f4567e/untitled546.ipynb) and share. Thanks!", "@ehirdoy Did you had time to review my shared gist? Thanks!", "Automatically closing this out since I understand it to be resolved, but please let me know if I'm mistaken.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32213\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32213\">No</a>\n"]}, {"number": 32212, "title": "Raise undefined symbol in \"tensorflow.contrib.fused_conv.python.ops.fused_conv2d_bias_activation_op\" module", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `CentOS Linux release 7.6.1810 (Core)`\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: \r\n- TensorFlow installed from (source or binary): `source`\r\n- TensorFlow version: `1.14.0`\r\n- Python version: `3.6.5`\r\n- Installed using virtualenv? pip? conda?: `conda`\r\n- Bazel version (if compiling from source): `0.25.0`\r\n- GCC/Compiler version (if compiling from source): `4.8.5`\r\n- CUDA/cuDNN version: `CUDA==10.1 / CUDNN=7`\r\n- GPU model and memory: `GeForce GTX 1080   8119MiB`\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n```\r\n>>> from tensorflow.contrib.fused_conv.python.ops.fused_conv2d_bias_activation_op import *\r\n2019-09-04 13:57:26.493744: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0904 13:57:28.321362 140054143231808 __init__.py:308] Limited tf.compat.v2.summary API due to missing TensorBoard installation.\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/root/conda/lib/python3.6/site-packages/tensorflow/contrib/fused_conv/__init__.py\", line 22, in <module>\r\n    from tensorflow.contrib.fused_conv.python.ops.fused_conv2d_bias_activation_op import *\r\n  File \"/root/conda/lib/python3.6/site-packages/tensorflow/contrib/fused_conv/python/ops/fused_conv2d_bias_activation_op.py\", line 26, in <module>\r\n    resource_loader.get_path_to_datafile(\"_fused_conv2d_bias_activation_op.so\"))\r\n  File \"/root/conda/lib/python3.6/site-packages/tensorflow/contrib/util/loader.py\", line 56, in load_op_library\r\n    ret = load_library.load_op_library(path)\r\n  File \"/root/conda/lib/python3.6/site-packages/tensorflow/python/framework/load_library.py\", line 61, in load_op_library\r\n    lib_handle = py_tf.TF_LoadLibrary(library_filename)\r\ntensorflow.python.framework.errors_impl.NotFoundError: /root/conda/lib/python3.6/site-packages/tensorflow/contrib/fused_conv/python/ops/_fused_conv2d_bias_activation_op.so: undefined symbol: _ZN10tensorflow6Logger18singleton_factory_E\r\n>>>\r\n```\r\nI follow Anaconda compiled tensorflow conda package method(conda-build and some referenced recipes) to compile tensorflow==1.14 with tensorRT and nccl features. \r\n```\r\n[root@skyaxe-computing-1 work-dir]# curl -L -O  https://repo.anaconda.com/pkgs/main/linux-64/tensorflow-base-1.14.0-gpu_py36he45bfe2_0.tar.bz2\r\n[root@skyaxe-computing-1 work-dir]# tar jxf tensorflow-base-1.14.0-gpu_py36he45bfe2_0.tar.bz2\r\n# get recipes in info/recipe\r\n[root@skyaxe-computing-1 work-dir]# ls -d  info/recipe/\r\ninfo/recipe/\r\n```\r\n\r\nMy `build.sh`, `meta.yaml`:\r\n<details>\r\n\r\n```\r\n#!/bin/bash\r\n\r\ntensorflow_version=$(echo $TENSORFLOW_VERSION_NUMBER | tr -d \".\")\r\n\r\n# Compile tensorflow from source\r\nexport PYTHON_BIN_PATH=${PYTHON}\r\nexport PYTHON_LIB_PATH=${SP_DIR}\r\nexport CC_OPT_FLAGS=\"-march=native\"\r\n\r\n# disable jemmloc (needs MADV_HUGEPAGE macro which is not in glib <= 2.12)\r\nexport TF_NEED_JEMALLOC=1\r\nexport TF_NEED_GCP=0\r\nexport TF_NEED_HDFS=0\r\nexport TF_NEED_S3=0\r\nexport TF_ENABLE_XLA=0\r\nexport TF_NEED_OPENCL=0\r\nexport TF_NEED_OPENCL_SYCL=0\r\nexport TF_NEED_GDR=0\r\nexport TF_NEED_KAFKA=1\r\nexport TF_DOWNLOAD_CLANG=0\r\nexport TF_NEED_IGNITE=1\r\nexport TF_ENABLE_XLA=1\r\nexport TF_NEED_ROCM=0\r\n\r\nif [[ \"$CUDNN_VERSION\" -le 6 ]]; then\r\n    export TF_NEED_TENSORRT=0\r\nelse\r\n    export TF_NEED_TENSORRT=1\r\n    if [[ \"$CUDA_VERSION\" = \"9.2\" ]]; then\r\n        export TENSORRT_INSTALL_PATH=/opt/compute/TensorRT-4.0.1.6\r\n    elif [[ \"$CUDA_VERSION\" = \"10.1\" ]]; then\r\n        export TENSORRT_INSTALL_PATH=/opt/compute/TensorRT-5.1.2.2\r\n    else\r\n        export TENSORRT_INSTALL_PATH=/opt/compute/TensorRT-3.0.4    # Modify it according to your requirement.\r\n    fi\r\nfi\r\nexport TF_NCCL_VERSION=2.4  # Modify it according to your requirement, defalut value is 1.3(from GitHub)\r\nif [[ \"$CUDA_VERSION\" = \"8.0\" ]]; then\r\n    export NCCL_INSTALL_PATH=/opt/compute/nccl_2.2.13-1+cuda8.0_x86_64  # Modify it according to your requirement.\r\nelif [[ \"$CUDA_VERSION\" = \"9.0\" ]]; then\r\n    export NCCL_INSTALL_PATH=/opt/compute/nccl_2.2.13-1+cuda9.0_x86_64  # Modify it according to your requirement.\r\nelif [[ \"$CUDA_VERSION\" = \"9.2\" ]]; then\r\n    export NCCL_INSTALL_PATH=/opt/compute/nccl_2.3.7-1+cuda9.2_x86_64  # Modify it according to your requirement.\r\nelif [[ \"$CUDA_VERSION\" = \"10.1\" ]]; then\r\n    export NCCL_INSTALL_PATH=/opt/compute/nccl_2.4.8-1+cuda10.1_x86_64\r\nfi\r\n\r\n# CUDA details, these should be customized depending on the system details\r\nexport TF_NEED_CUDA=1\r\nexport TF_CUDA_VERSION=\"${CUDA_VERSION}\"\r\nexport TF_CUDNN_VERSION=\"${CUDNN_VERSION}\"\r\nexport GCC_HOST_COMPILER_PATH=\"$(which gcc)\"\r\nexport CUDA_TOOLKIT_PATH=\"/usr/local/cuda\"\r\nexport CUDNN_INSTALL_PATH=\"/usr/local/cuda\"\r\nexport TF_CUDA_CLANG=0\r\n\r\nexport TF_CUDA_COMPUTE_CAPABILITIES=\"3.0,3.5,5.2\"\r\nif [[ ${CUDA_VERSION} = \"8.0\" ]]; then\r\n    export TF_CUDA_COMPUTE_CAPABILITIES=\"3.0,3.5,5.2,6.0,6.1\"\r\nelif [[ \"$CUDA_VERSION\" = \"9.0\" ]]; then\r\n    export TF_CUDA_COMPUTE_CAPABILITIES=\"3.0,3.5,5.2,6.0,6.1,7.0\"\r\nelif [[ \"$CUDA_VERSION\" = \"9.2\" ]]; then\r\n    export TF_CUDA_COMPUTE_CAPABILITIES=\"3.0,3.5,5.2,6.0,6.1,7.0\"\r\nelif [[ \"$CUDA_VERSION\" = \"10.1\" ]]; then\r\n    export TF_CUDA_COMPUTE_CAPABILITIES=\"3.0,3.5,5.2,6.0,6.1,7.0,7.5\"\r\nfi\r\n\r\nexport TF_NEED_MPI=0\r\n# enable Intel MKL\r\nif [[ \"$tensorflow_version\" -ge 120 ]]; then\r\n    export TF_NEED_MKL=1\r\n    export TF_DOWNLOAD_MKL=1\r\nfi\r\n\r\nexport TF_NEED_VERBS=1\r\nexport TF_SET_ANDROID_WORKSPACE=0\r\n./configure\r\n\r\nbazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-msse4.2 --copt=-mfpmath=both --config=cuda --jobs=$(nproc) \\\r\n    --config=mkl --verbose_failures --color=yes //tensorflow/tools/pip_package:build_pip_package\r\n\r\n# build a whl file\r\nmkdir -p $SRC_DIR/tensorflow_pkg\r\nbazel-bin/tensorflow/tools/pip_package/build_pip_package $SRC_DIR/tensorflow_pkg\r\n\r\n# install using pip from the whl file\r\npip install --no-deps $SRC_DIR/tensorflow_pkg/*.whl\r\n\r\nrm -f ${PREFIX}/bin/tensorboard\r\n```\r\n```\r\npackage:\r\n    name: tensorflow-gpu\r\n    version: {{ version }}\r\n\r\nsource:\r\n  git_url: https://github.com/tensorflow/tensorflow.git\r\n  git_rev: v{{ version }}\r\n\r\n\r\nbuild:\r\n    entry_points:\r\n        - tensorboard = tensorflow.tensorboard.tensorboard:main\r\n    script_env:\r\n        - CUDA_VERSION\r\n        - CUDNN_VERSION\r\n        - TENSORFLOW_VERSION_NUMBER\r\n    string: py{{ CONDA_PY }}_{{ string }}\r\n\r\nrequirements:\r\n    build:\r\n        - werkzeug\r\n        - bleach\r\n        - numpy 1.15.*\r\n        - mkl\r\n        - six\r\n        - protobuf 3.6.*\r\n        - python x.x\r\n        - backports.weakref\r\n        - html5lib\r\n        - markdown\r\n        - mock\r\n        - keras-applications\r\n        - keras-preprocessing\r\n        - enum34 # [py27]\r\n    run:\r\n        - python\r\n        - werkzeug\r\n        - six\r\n        - protobuf\r\n        - numpy\r\n        - markdown\r\n        - html5lib\r\n        - bleach\r\n        - backports.weakref\r\n```\r\n</details>\r\n\r\n**Any other info / logs**\r\n* use `nvidia-docker` and `nvidia/cuda:10.1-cudnn7-devel-centos7` docker image\r\n* import tensorflow is ok and `sess = tensorflow.Session(config=tensorflow.ConfigProto(log_device_placement=True))` will display visible gpu devices and others info\r\n* similar behaviour can refer to: https://github.com/ContinuumIO/anaconda-issues/issues/11239 and https://github.com/tensorflow/tensorflow/issues?q=tensorflow.contrib.fused_conv.python.ops.fused_conv2d_bias_activation_op \r\n* pre-build wheel package will produce same error, error see https://user-images.githubusercontent.com/19144683/64264093-54077e80-cf63-11e9-9b92-83fc11a4be79.png\r\n:\r\n```\r\n[root@skyaxe-computing-1 log-2019-07]# docker run -ti --rm --network host nvidia/cuda:10.1-cudnn7-devel-centos7 /bin/bash\r\n[root@skyaxe-computing-1 /]# curl https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/Miniconda3-4.3.30-Linux-x86_64.sh -L -O\r\n... ...\r\n\r\n[root@skyaxe-computing-1 /]# /root/miniconda3/bin/pip install -i   https://mirrors.aliyun.com/pypi/simple/   tensorflow-gpu==1.14.0\r\n```\r\n", "comments": ["@memory-yancy, Thanks for reporting the issue.\r\nI could replicate the issue on Tensorflow 1.14.0.\r\nIts fixed in the latest Tf nightly version. Please see the [gist here](https://colab.sandbox.google.com/gist/gadagashwini/5290c7a10f1501e5ae0051808d9a0275/untitled124.ipynb).\r\nYou want to a give try.Thanks! ", "@gadagashwini  Thanks your reply !\r\n\r\n* `tf-nightly-gpu-1.15.0.dev20190821` will also raise similar error:\r\n```\r\n>>> tensorflow.__version__\r\n'1.15.0-dev20190821'\r\n>>> from tensorflow.contrib.fused_conv.python.ops.fused_conv2d_bias_activation_op import *\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/root/miniconda3/lib/python3.6/site-packages/tensorflow_core/contrib/fused_conv/__init__.py\", line 22, in <module>\r\n    from tensorflow.contrib.fused_conv.python.ops.fused_conv2d_bias_activation_op import *\r\n  File \"/root/miniconda3/lib/python3.6/site-packages/tensorflow_core/contrib/fused_conv/python/ops/fused_conv2d_bias_activation_op.py\", line 26, in <module>\r\n    resource_loader.get_path_to_datafile(\"_fused_conv2d_bias_activation_op.so\"))\r\n  File \"/root/miniconda3/lib/python3.6/site-packages/tensorflow_core/contrib/util/loader.py\", line 56, in load_op_library\r\n    ret = load_library.load_op_library(path)\r\n  File \"/root/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/load_library.py\", line 61, in load_op_library\r\n    lib_handle = py_tf.TF_LoadLibrary(library_filename)\r\ntensorflow.python.framework.errors_impl.NotFoundError: /root/miniconda3/lib/python3.6/site-packages/tensorflow_core/contrib/fused_conv/python/ops/_fused_conv2d_bias_activation_op.so: undefined symbol: _ZN10tensorflow7functor10NHWCToNCHWIN5Eigen9GpuDeviceEfLi4EEclERKS3_NS2_9TensorMapINS2_6TensorIKfLi4ELi1ElEELi16ENS2_11MakePointerEEENS7_INS8_IfLi4ELi1ElEELi16ESB_EE\r\n```\r\n* `tf-nightly-1.15.0.dev20190821` is OK\r\n\r\nAccording to my issues, tensorflow-gpu is my requirement. So, any update about tensorflow-gpu?\r\n\r\nAnd, `tf-nightly(-gpu)`, master branch is 1.14.0 in `tensorflow/core/public/version.h`. If I want to compile V1.15(assume related bugs have fixed), should I checkout `r1.15` branch?", "Was able to replicate the issue with Tensorflow-GPU nightly version. Please see the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/d8eb1426cb06a8ebbe3c427122414590/untitled129.ipynb). Thanks!", "Apologies for the delay in response. `contrib` module is deprecated and has moved of TF. \r\nYou may want  to raise a request on[ tf addons repo](https://github.com/tensorflow/addons) for contrib features. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32212\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32212\">No</a>\n"]}, {"number": 32211, "title": "[TF2] Nightly-20190904 broken import", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): tf-nightly-2.0-preview (maybe others)\r\n- Python version: 3.6 (probably others)\r\n\r\n**Describe the current behavior**\r\n```\r\n!pip install tf-nightly-2.0-preview\r\nimport tensorflow as tf\r\n```\r\nErrors with:\r\n```\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-2-64156d691fe5> in <module>()\r\n----> 1 import tensorflow as tf\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py in <module>()\r\n     96 \r\n     97 # We still need all the names that are toplevel on tensorflow_core\r\n---> 98 from tensorflow_core import *\r\n     99 \r\n    100 # These should not be visible in the main tf module.\r\n\r\nAttributeError: module 'tensorflow_core' has no attribute 'compiler'\r\n```", "comments": ["Maybe @goldiegadde?\r\nNightlies are very minimally tested. not even tested for imports.\r\nGoldie, are we planning any testing on nightlies?", "Looks to be the same error as https://github.com/tensorflow/tensorflow/issues/29536 so @mihaimaruseac who might know what the issue is as well.", "We really should add at least a simple import test before pushing to pypi. I know we talked about it, but nobody has time. ", "Looks as though this has been fixed. Thanks!", "Sorry for the breakage, we are in the process of adding smoke tests prior to pushing binaries. We have removed the broken binaries from pypi. Thanks for your patience!"]}, {"number": 32210, "title": "[TF 2.0.0-rc0] Keras layer dependency tracking behaviour changed in 2.0.0-rc0", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS, Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0-rc0\r\n- Python version: Python 3.6/3.7\r\n\r\nWe are developing an open source library for training binarized and other extremely quantized networks at http://larq.dev that heavily relies on `tf.keras`. For this we are adding custom layers that modify (i.e. quantize) the layers kernel (and activations) prior to the computation.\r\n\r\n## Expected Behaviour\r\n\r\nA simplified version of what we are doing is here:\r\n```python\r\nfrom tensorflow import keras\r\n\r\n# For our use case this would be a quantizer with a custom gradient\r\ndef projection(x):\r\n    return 2 * x\r\n\r\nclass CustomDense(keras.layers.Dense):\r\n    def call(self, inputs):\r\n        original_kernel = self.kernel\r\n        self.kernel = projection(self.kernel)\r\n        outputs = super().call(inputs)\r\n        self.kernel = original_kernel  # reset the original kernel to make this work in eager mode\r\n        return outputs\r\n\r\nmodel = keras.models.Sequential([CustomDense(32, input_shape=(32,))])\r\n\r\nassert model.layers[0].kernel in model.layers[0].trainable_weights\r\n```\r\n\r\nThis worked well for TensorFlow 1.13, 1.14 in graph and eager as well as for `2.0.0-beta0` and `2.0.0-beta1`.\r\n\r\n## Current Behaviour\r\n\r\nIt looks like TensorFlow `2.0.0-rc0` changed the automatic dependency tracking which makes the above code fail on the last line. The same is true for `2.0.0.dev20190904`:\r\n```python-traceback\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-1-e416b6b97b33> in <module>\r\n     40 model = keras.models.Sequential([CustomDense(32, input_shape=(32,))])\r\n     41 \r\n---> 42 assert model.layers[0].kernel in model.layers[0].trainable_weights\r\n\r\n~/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py in __bool__(self)\r\n    874 \r\n    875   def __bool__(self):\r\n--> 876     return bool(self._numpy())\r\n    877 \r\n    878   __nonzero__ = __bool__\r\n\r\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\r\n```\r\n\r\nIgnoring the automatic dependency tracking by using the following makes the above code work.\r\n```python\r\nfrom tensorflow import keras\r\nfrom tensorflow.python.training.tracking.base import (\r\n         no_automatic_dependency_tracking_scope,\r\n     )\r\n\r\ndef projection(x):\r\n    return 2 * x\r\n\r\nclass CustomDense(keras.layers.Dense):\r\n    def call(self, inputs):\r\n        original_kernel = self.kernel\r\n        with no_automatic_dependency_tracking_scope(self):\r\n            self.kernel = projection(self.kernel)\r\n        outputs = super().call(inputs)\r\n        with no_automatic_dependency_tracking_scope(self):\r\n            self.kernel = original_kernel\r\n        return outputs\r\n\r\nmodel = keras.models.Sequential([CustomDense(32, input_shape=(32,))])\r\n\r\nassert model.layers[0].kernel in model.layers[0].trainable_weights\r\n```\r\n\r\n## Questions\r\n\r\nIs this behaviour change expected or is it a bug in `2.0.0-rc0`?\r\n\r\nIs there a better way to achieve this, without needing to temporarily overwrite `layer.kernel`?\r\n\r\nIf this change is expected, is it save to use the private `no_automatic_dependency_tracking_scope` to workaround this issue?\r\n\r\n@dynamicwebpaige Is this issue better posted at the TensorFlow 2.0 testing mailing list?", "comments": ["@lgeiger: Thanks for the bug report. Recently we changed the behavior of equality in 2.0 such that Variables & Tensors are no longer hashable. As an unfortunate side-effect `model.layers[0].kernel in model.layers[0].trainable_weights` does not work as you probably intended since it is trying to do an element-wise equality comparison of `model.layers[0].kernel` with each of the trainable weights. Instead, please try changing your code to `any(model.layers[0].kernel is w for w in model.layers[0].trainable_weights)`\r\n\r\nWe'd received a couple of reports with people running into obscure errors with this change and will look into improving the communication of this change.", "@jaingaurav Thanks for the info, I agree more documentation about this change would help. \r\n\r\nDo you know why the comparison when ignoring the dependency tracking with `no_automatic_dependency_tracking_scope` works? Following your argument, I intuitively would expect it to fail as well."]}, {"number": 32209, "title": "TensorFlow Lite softmax error if dims >4  (num_dims >= 1 && num_dims <= 4)", "body": "**System information**\r\n- OS Platform and Distribution (Linux Ubuntu 16.04):\r\n- TensorFlow installed from ( binary):\r\n- TensorFlow version (1.13.1):\r\n- Python version (3.7)\r\n\r\nmy model graph contain reshape op as follows:\r\nself. pixel_link_logits = tf.reshape(self.pixel_link_logits,[shape[0], shape[1], shape[2], 16, 2])\r\nself.pixel_link_scores = tf.nn.softmax(self.pixel_link_logits)\r\n\r\n**this is my  tflite_convert code**\r\n\r\n```\r\n  6 graph_def_file = \"./model_v4.pb\"\r\n  7 input_arrays = [\"evaluation_768x768/Placeholder\"]\r\n  8 output_arrays = [\"evaluation_768x768/Squeeze\",\"evaluation_768x768/Squeeze_1\"]\r\n  9 converter = tf.lite.TFLiteConverter.from_frozen_graph(graph_def_file, input_arrays, output_arrays)\r\n 10\r\n 11 converter.post_training_quantize=True\r\n 12\r\n 13 tflite_model = converter.convert()\r\n 14 with open(\"converted_model.tflite\", \"wb\") as f:\r\n 15     f.write(tflite_model)\r\n 16 interpreter = tf.lite.Interpreter(model_path=\"converted_model.tflite\")\r\n 17 interpreter.allocate_tensors()\r\n 18 input_details = interpreter.get_input_details()\r\n 19 output_details = interpreter.get_output_details()\r\n 20 input_shape = input_details[0]['shape']\r\n 21\r\n 22 input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\r\n 23 interpreter.set_tensor(input_details[0]['index'], input_data)\r\n 24 interpreter.invoke()\r\n 25 output_data = interpreter.get_tensor(output_details[0]['index'])\r\n 26 print(output_data)\r\n```\r\n\r\nI counter the error on softmax about num_dims >= 1 && num_dims <= 4, how can I resolver it @ry ,\r\n**this is the error  logs**\r\n\r\nwhen I interpreter the tflite model, counter the dimentions error, the infor:\r\nTraceback (most recent call last):\r\n  File \"interpreter.py\", line 17, in <module>\r\n    interpreter.allocate_tensors()\r\n  File \"/home/xxx/miniconda3/lib/python3.6/site-packages/tensorflow/lite/python/interpreter.py\", line 73, in allocate_tensors\r\n    return self._interpreter.AllocateTensors()\r\n  File \"/home/dengjie/miniconda3/lib/python3.6/site-packages/tensorflow/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py\", line 106, in AllocateTensors\r\n    return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)\r\nRuntimeError: tensorflow/lite/kernels/activations.cc:216 num_dims >= 1 && num_dims <= 4 was not true.Node number 146 (SOFTMAX) failed to prepare\r\n\r\nI found the tensorflow source code about softmax  only surpport 4 dimensions:\r\nthe code: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/activations.cc\r\n![image](https://user-images.githubusercontent.com/12806623/64256590-5ca58800-cf56-11e9-8541-15446005d58a.png)\r\nhow can i solve it\uff0c who help me\uff1f", "comments": ["This is a known limitation for softmax().", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32209\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32209\">No</a>\n"]}, {"number": 32208, "title": "make_adv_reg_config not found", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\nWhile trying to run the code given on https://www.tensorflow.org/neural_structured_learning/ I ran into the following error:\r\nAttributeError: module 'neural_structured_learning.lib' has no attribute 'make_adv_reg_config'\r\nI have already installed neural_structured_learning using !pip install neural_structured_learning and I am working on TF 2.0.0-rc0 on Colab (also tried it on 1.14)\r\nI have also check the code on github and couldn't find make_adv_reg_config in neural_structured_learning/lib/*\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Seems like the method make_adv_reg_config() was moved to the configs module. The below code works:\r\n`adv_config = nsl.configs.make_adv_reg_config(multiplier=0.2, adv_step_size=0.05)`", "Thank you for your response.\nIt's working now\n\nOn Thu, 5 Sep 2019 at 08:07, Amal Vijayan <notifications@github.com> wrote:\n\n> Seems like the method make_adv_reg_config() was moved to the configs\n> module. The below code works:\n> adv_config = nsl.configs.make_adv_reg_config(multiplier=0.2,\n> adv_step_size=0.05)\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/32208?email_source=notifications&email_token=AHAKXXBY26EANMW7COBK6RDQICHYVA5CNFSM4ITRL6XKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD552NNY#issuecomment-528197303>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AHAKXXEJIXTDSLUBTE7ASJLQICHYVANCNFSM4ITRL6XA>\n> .\n>\n", "Closing this issue since it's resolved. Thanks!\r\nhttps://www.tensorflow.org/neural_structured_learning/api_docs/python/nsl/configs/make_adv_reg_config", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32208\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32208\">No</a>\n"]}, {"number": 32207, "title": "Unsupported ops", "body": "**System information**\r\n- OS Platform and Distribution: Ubuntu 18.04.3:\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: 2.0.0-rc0\r\n\r\n_Here's my code:_\r\n\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(model_dir)\r\ntflite_model = converter.convert()\r\nopen(os.path.join(model_dir, 'model.tflite'), \"wb\").write(tflite_model)\r\n\r\n_Here's the error:_\r\n\r\nHere is a list of operators for which you will need custom implementations: **Complex, Imag, Real, TensorListReserve, TensorListStack, While**\r\n\r\nHello Tensorflow team, I would love to see the ops above supported in tflite. Any chance you can \r\nshare with me your plans regarding this request?", "comments": ["We have some general guidance on unsupported operations in our FAQ [here](https://www.tensorflow.org/lite/guide/faq#why_doesnt_my_model_convert). However, for the specific ops you mentioned we are currently working on getting them working through [this](https://www.tensorflow.org/lite/guide/ops_select) path as indicated on our [roadmap](https://www.tensorflow.org/lite/guide/roadmap). Control flow is still a work in progress."]}, {"number": 32206, "title": "tflite: RandomStandardNormal not convertible with pure tensorflow, but works with keras", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): docker\r\n- TensorFlow version (use command below): 1.15.0-dev20190821\r\n- Python version: 3.6.8\r\n\r\nI have an variational autoencoder model utilizing `tf.random.normal` function. I want to convert it into a tflite model.\r\n\r\nI have written code in keras that achieves that. The conversion works and I get reasonable results. However, if I re-write the model with tensorflow-only operations (no keras so to speak), the converter claims that RandomStandardNormal is not available for tflite:\r\n```\r\n2019-09-04 12:04:12.858787: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: RandomStandardNormal\r\n2019-09-04 12:04:12.859104: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 21 operators, 32 arrays (0 quantized)\r\n2019-09-04 12:04:12.859336: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 21 operators, 32 arrays (0 quantized)\r\n2019-09-04 12:04:12.859712: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 9 operators, 21 arrays (0 quantized)\r\n2019-09-04 12:04:12.859823: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 9 operators, 21 arrays (0 quantized)\r\n2019-09-04 12:04:12.859876: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 9 operators, 21 arrays (0 quantized)\r\n2019-09-04 12:04:12.859972: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 320 bytes, theoretical optimal value: 256 bytes.\r\n2019-09-04 12:04:12.860009: I tensorflow/lite/toco/toco_tooling.cc:454] Number of parameters: 8592\r\n2019-09-04 12:04:12.860269: E tensorflow/lite/toco/toco_tooling.cc:481] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, FULLY_CONNECTED, LOGISTIC, MUL. Here is a list of operators for which you will need custom implementations: RandomStandardNormal.\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/toco_from_protos\", line 10, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 89, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 52, in execute\r\n    enable_mlir_converter)\r\nException: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, FULLY_CONNECTED, LOGISTIC, MUL. Here is a list of operators for which you will need custom implementations: RandomStandardNormal.\r\n```\r\nThis is very confusing, as the keras model used the very same function and it worked. Does keras do something under the hood?\r\n\r\n**Code to reproduce the issue**\r\nI have created a repo for this [HERE](https://github.com/DocDriven/tflite_tests). Steps to reproduce this issue:\r\n1. Execute `python keras_model.py` to train and save the keras model\r\n2. Execute `python keras_conversion.py` to create the tflite model without errors\r\n3. Execute `python tf_model.py` to train, save and freeze the pure tf model\r\n4. Execute `python tf_conversion.py` to try the conversion and get the error\r\n", "comments": ["For any TF version (1.x or 2.x), Keras conversion works (not sure why) but pure TF model conversion (with or without optimization) fails as the model uses a TF op called`RandomStandardUniform` which does not have an equivalent TFLite op implementation (i.e, the op is unsupported in TFLite). However, we can make an exception and use the TF op in the TFLite model by setting `converter.target_spec.supported_ops = {... , SELECT_TF_OPS}` during conversion (shown below). To verify, use [Netron](https://lutzroeder.github.io/netron/) to inspect the final TFLite model `model.tflite` generated below to find the TF equivalent of this op named as `FlexRandomStandardNormal`. *Note: Using TF ops can cause a large increase in the model size.*\r\n\r\n(Prerequisite: Run [tf_model.py](https://github.com/DocDriven/tflite_tests/blob/master/tf_model.py) in TF 1.x (*Use [colab](https://colab.research.google.com) and set `%tensorflow_version 1.x`*) to generate `frozen_model.pb`)\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ntf_model_path = 'frozen_model.pb'\r\ntflite_model_path = 'model.tflite'\r\ninputs = ['model/eval_inputs']\r\noutputs = ['model/y']\r\ndataset = np.random.rand(100, 90).astype(np.float32)\r\n\r\n# Convert the model.\r\nconverter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(tf_model_path, inputs, outputs)\r\n# Allow the usage of the TF op `RandomStandardUniform` in the TFLite model \r\nconverter.target_spec.supported_ops = {\r\n  tf.lite.OpsSet.TFLITE_BUILTINS, # Use TFLite ops when defined\r\n  tf.lite.OpsSet.SELECT_TF_OPS  # Fallback to TF op if the TFLite op hasn't been defined.\r\n}\r\n# (optional) Enable optimization\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\ndef representative_dataset_gen():\r\n  for i in range(100):\r\n    yield [dataset[i:i+1]]\r\nconverter.representative_dataset = representative_dataset_gen\r\ntflite_model = converter.convert()\r\nwith open(tflite_model_path, 'wb') as f:\r\n  f.write(tflite_model)\r\n\r\n# Run Inference\r\ninterpreter = tf.lite.Interpreter(model_content=tflite_model)\r\ninterpreter.allocate_tensors()\r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\ninput_shape = input_details[0]['shape']\r\ninput_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\r\ninterpreter.set_tensor(input_details[0]['index'], input_data)\r\ninterpreter.invoke()\r\noutput_data = interpreter.get_tensor(output_details[0]['index'])[0]\r\nprint(output_data)\r\n```\r\n\r\n```\r\n[ 3.5671520e-01  2.7348164e-01 .....]\r\n```\r\n\r\nCould you check it on your side?", "@DocDriven  \r\nIs this still an issue.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32206\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32206\">No</a>\n"]}, {"number": 32205, "title": "KeyError: u'BatchMatMulV2'", "body": "Trying to generate a .pb file from .meta file but encountered this error when running in tensorflow 1.13.1. \r\nWorks after changing tensorflow version to 1.14.0\r\nBut I need to generate .pb file using tensorflow 1.13.1 or below versions. \r\n\r\nHere's the code: \r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nmeta_path = 'fns.ckpt.meta' # Your .meta file\r\noutput_node_names = ['add_37']    # Output nodes\r\n\r\nwith tf.Session() as sess:\r\n\r\n    # Restore the graph\r\n    saver = tf.train.import_meta_graph(meta_path)\r\n\r\n    # Load weights\r\n    saver.restore(sess,\"checkpoints/fns.ckpt\")\r\n\r\n    # Freeze the graph\r\n    frozen_graph_def = tf.graph_util.convert_variables_to_constants(\r\n        sess,\r\n        sess.graph_def,\r\n        output_node_names)\r\n\r\n    # Save the frozen graph\r\n    with open('output_graph.pb', 'wb') as f:\r\n      f.write(frozen_graph_def.SerializeToString())\r\n```", "comments": ["@taiftahmid Sorry for the delay in my response. I think you can check the source code of 1.13.1 and 1.14 and find the file that is helping in generating a .pb file from .meta file. Once you find that file, then update your forked version of 1.13.1. Thanks!\r\n\r\nPlease close the issue.\r\nThis is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32205\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32205\">No</a>\n"]}, {"number": 32204, "title": "Coral Board Demo example fails RuntimeError: Model provided has model identifier 'CTYP', should be 'TFL3'", "body": "Traceback (most recent call last):\r\n  File \"/usr/bin/edgetpu_classify\", line 11, in <module>\r\n    load_entry_point('edgetpuvision==1.0', 'console_scripts', 'edgetpu_classify')()\r\n  File \"/usr/lib/python3/dist-packages/edgetpuvision/classify.py\", line 162, in main\r\n    run_app(add_render_gen_args, render_gen)\r\n  File \"/usr/lib/python3/dist-packages/edgetpuvision/apps.py\", line 70, in run_app\r\n    display=args.displaymode):\r\n  File \"/usr/lib/python3/dist-packages/edgetpuvision/gstreamer.py\", line 240, in run_gen\r\n    inference_size = render_overlay_gen.send(None)  # Initialize.\r\n  File \"/usr/lib/python3/dist-packages/edgetpuvision/classify.py\", line 112, in render_gen\r\n    engines, titles = utils.make_engines(args.model, ClassificationEngine)\r\n  File \"/usr/lib/python3/dist-packages/edgetpuvision/utils.py\", line 53, in make_engines\r\n    engine = engine_class(model_path)\r\n  File \"/usr/lib/python3/dist-packages/edgetpu/classification/engine.py\", line 38, in __init__\r\n    super().__init__(model_path)\r\n  File \"/usr/lib/python3/dist-packages/edgetpu/swig/edgetpu_cpp_wrapper.py\", line 300, in __init__\r\n    this = _edgetpu_cpp_wrapper.new_BasicEngine(*args)\r\nRuntimeError: Model provided has model identifier 'CTYP', should be 'TFL3'\r\n\r\nThis is the output of Coral Board with the Coral Camera example. The given tflite model produces the above output. I couldn't figure out why.\r\n\r\nThis output is from the ssh window connected to the google coral board.", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the code snippet to reproduce the issue. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32204\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32204\">No</a>\n", "same error trying to run the teachable demo on the coral board ", "I am having same problem.\r\nRPI 4 and python 3.7.3\r\n![image](https://user-images.githubusercontent.com/25264037/65900790-73a59180-e3bf-11e9-9678-47f84b8b6d03.png)\r\n\r\n\r\n", "I get complains that my model is 'ion ':\r\n\r\n`File \"/usr/local/lib/python3.7/dist-packages/edgetpu/detection/engine.py\", line 73, in __init__\r\n    super().__init__(model_path)\r\n  File \"/usr/local/lib/python3.7/dist-packages/edgetpu/basic/basic_engine.py\", line 40, in __init__\r\n    self._engine = BasicEnginePythonWrapper.CreateFromFile(model_path)\r\nRuntimeError: Model provided has model identifier 'ion ', should be 'TFL3'`\r\n\r\nI trained quantized model and used the export_tflite_ssd_graph.py and tflite_convert to get the EdgeTPU compiled model.", "My bad. Was sending model over Git LFS to RPi and forgot to do lfs sync. Also forgot to run the tflite through the edgetpu_compiler.", "@mikkleini \r\nI have similar error. \r\n ERROR: Model provided has model identifier '', should be 'TFL3' <\r\nCould you explain how to resolve this error in detail? ", "@chohk88 - basically my problem was that I provided completely wrong type of file to inference engine.  Open your file with some text or binary editor and check if it reminds tflite file or not.\r\nYou should see \"TFL3\" in ASCII at 5th byte. If not then you could have wrong file or damaged file.", "Hi @mikkleini ,\r\nI am using Git LFS as well but I am confused.\r\nWhat is git LFS sync? \r\nI thought ` git lfs track \"*.tflite\"` was enough\r\n\r\nDo I need to install git LFS on the RPI4 as well and run some command?", "@mikkleini \r\nYes running `git lfs pull` on the RPI4 solved my issue :) ", "I used to have a similar problem when downloading a `.tflite` file from github (the coral TPU detection demo). The reason was that I was not logged in on the remote device (no session creds on my RPI4) and was downloading not the buffer file but a `html` file :). As a result, I used to get `ValueError: Model provided has model identifier '<!D', should be 'TFL3'`. Please make sure the `.tflite` is holding a buffer and not something else.  \r\n", "In my case, the `.tflite` files mentioned in the `install_requirements.sh` were not present in the repository (they were renamed). For example, `mobilenet_ssd_v2_coco_quant_postprocess.tflite` was not present, instead this was present - `ssd_mobilenet_v2_coco_quant_postprocess.tflite`.\r\n\r\nBecause of this, the `curl `command in `install_requirements.sh` simply got 404 HTML page from github, and that showed up as this error later - \r\n> ValueError: Model provided has model identifier '<!D', should be 'TFL3'\r\n\r\nI changed the file names in both the installation script and the subsequent command, removed old `.tflite` file, rerun the installation script, and then it ran fine. ", "Hi,\r\n\r\nSolution: For Coral_Edge_TPU\r\n\r\nActually install_requirements file downloads file with name of \"${TEST_DATA_URL}/mobilenet_ssd_v2_coco_quant_postprocess_edgetpu.tflite\" \\\r\n     -OL \"${TEST_DATA_URL}/mobilenet_ssd_v2_coco_quant_postprocess.tflite\" \\\r\n     -OL \"${TEST_DATA_URL}/coco_labels.txt\")\r\n\r\nBut above files do not exist currently in repository.\r\n\r\nSo download from https://github.com/google-coral/edgetpu/tree/master/test_data\r\n**ssh_mobilenet v2_coco_quant_postprocess_edgetpu.tflite** and another file from the repository and replace in the model folder.\r\nRun script with changed names then it works fine.\r\n\r\n\r\n\r\n"]}, {"number": 32203, "title": "why some OPs are not shown on timeline", "body": "why some OPs are not shown on timeline, such as FlatMapDataset, PrefetchDataset and ParallelMapDataset.", "comments": ["@lxl910915,\r\nCould you elaborate the issue with context. Thanks! ", "> @lxl910915,\r\n> Could you elaborate the issue with context. Thanks!\r\n\r\nWe use tf.data.Dataset to read dataset file, and we also used map,batch,shuffle,prefetch OPs and so on. While on timeline, we can not find those OPs. We only find the get_next OP.\r\n![image](https://user-images.githubusercontent.com/8842010/64322739-bc06a500-cff5-11e9-8a84-dd2e84084195.png)\r\n\r\nCode as follows:\r\n```\r\ndataset = tf.data.Dataset.list_files(data_dir, shuffle=False)\r\ndataset = dataset.interleave(\r\n\tlambda x: tf.data.TextLineDataset(x), cycle_length=4,\r\n\tblock_length=batch_size)\r\ndataset = dataset.repeat(epochs)\r\ndataset = dataset.prefetch(batch_size * 10)\r\ndataset = dataset.shuffle(batch_size * 10)\r\ndataset = dataset.batch(batch_size)\r\ndef parse(line):\r\n\t...\r\n\treturn label, feature\r\ndataset = dataset.map(parse)\r\ndataset = dataset.prefetch(1)\r\nlabel, feature = dataset.make_one_shot_iterator().get_next()\r\n```\r\n", "@lxl910915, Will it be possible to provide minimal standalone code reproduce the reported issue. Thanks!", "@lxl910915,\r\nAny update ", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32203\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32203\">No</a>\n"]}, {"number": 32202, "title": "Check types of name parameters", "body": "In case user pass non-string as a tensor name, the code raises ValueError. One common mistake is to specify tensor object instad of its name. Unfortunately, in this case current implementation fails to produce an error message resulting in misleading errors like shown below. This PR introduce explicit type-checks of input parameters.\r\n\r\n```\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/util.py in get_tensors_from_tensor_names(graph, tensor_names)\r\n      114   if invalid_tensors:\r\n      115     raise ValueError(\"Invalid tensors '{}' were found.\".format(\r\n  --> 116         \",\".join(invalid_tensors)))\r\n      117   return tensors\r\n      118\r\n\r\n  TypeError: sequence item 0: expected str instance, Tensor found\r\n```\r\n\r\n\r\n", "comments": ["Hi. I see one failed test in an unrelated area. The error message looks like\r\n\r\n```\r\nERROR: /tmpfs/tmp/bazel/external/com_google_protobuf/BUILD:148:1: C++ compilation of rule '@com_google_protobuf//:protobuf' failed (Exit 1) gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections ... (remaining 40 argument(s) skipped)\r\nUse --sandbox_debug to see verbose messages from the sandbox\r\ngcc: error: unrecognized command line option '-std=c++14'\r\nERROR: /tmpfs/src/github/tensorflow/tensorflow/tools/proto_text/BUILD:34:1 C++ compilation of rule '@com_google_protobuf//:protobuf' failed (Exit 1) gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections ... (remaining 40 argument(s) skipped)\r\nUse --sandbox_debug to see verbose messages from the sandbox\r\nINFO: Elapsed time: 29.647s, Critical Path: 0.32s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nCould you please help me to figure out the reason? Should I rebase this topic to other base commit where the C++ issue is fixed?", "@gargn I've rebased the code in attempt to overcome mysterious error above. Could you please review again?", "@gargn can you please help merge this change internally.", "@grwlf Can you please check @rthadur's comments and keep us posted. Thanks!", "Sure, I will do it today.\n\n\u0432\u0442, 24 \u043c\u0430\u0440. 2020 \u0433. \u0432 14:16, gbaned <notifications@github.com>:\n\n> @grwlf <https://github.com/grwlf> Can you please check @rthadur\n> <https://github.com/rthadur>'s comments and keep us posted. Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/32202#issuecomment-603179706>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ABCFGIPNO7RTSGVSVRPQN73RJCJBVANCNFSM4ITPZ47A>\n> .\n>\n", "Hi @gargn, Can you please review this PR ? Thanks!", "@grwlf The current statement would not be clear if a user passes in an object. eg:\r\n\"Invalid tensor name 'tf.keras....numpy...' of type 'numpy.int64'. Expected a string.\"\r\n\r\nInstead this would be easier to debug\r\n\"Invalid type for a tensor name in the provided graph. Expected type for a tensor name is 'str', instead got type 'numpy.int64' for tensor name 'tf.keras....numpy...'\"", "@grwlf Can you please check @MeghnaNatraj's comments and keep us posted. Thanks!", "@gbaned Thank you for the reminder. @MeghnaNatraj done, please check.", "@grwlf Can you please address Ubuntu Sanity errors? Thanks!", "`FAIL: Found 1 non-whitelisted pylint errors:\r\ntensorflow/lite/python/util.py:123: [C0301(line-too-long), ] Line too long (81/80)`", "@grwlf Can you please check @rthadur's comments and keep us posted. Thanks!", "> `FAIL: Found 1 non-whitelisted pylint errors: tensorflow/lite/python/util.py:123: [C0301(line-too-long), ] Line too long (81/80)`\r\n\r\nOy vey, fixed", "@grwlf can you please check below error \r\n\r\n`tensorflow/lite/python/util.py\", line 124, in get_tensors_from_tensor_names\r\n    type(name), name))\r\nValueError: Invalid type for a tensor name in the provided graph. Expected type for a tensor name is 'str', instead got type '<type 'unicode'>' for tensor name 'input'`"]}, {"number": 32201, "title": "Bug in the Tensorflow .pb to .tflite conversion using TFLiteConverter", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.13 (CPU version)\r\n- Python version: 3.6.9\r\n\r\n\r\n**Describe the current behavior**\r\nTFLiteConverter converts the first convolutional layer of tensorflow model into depthwise convolutional layer if the input to the model has single channel (In my case grey scale images with channel =1).\r\n\r\n**Describe the expected behavior**\r\n\r\nConvolutional layer in the tensorflow model should remain the same even after TFLiteConverter.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nlink to tensorflow model: https://drive.google.com/open?id=14R84txljdYdTIZRmHAD1Rkfl-_n9fCGb\r\n\r\nlink to the generated tflite model: https://drive.google.com/open?id=1WlmWhJYjxfLIjwZcUJ9vLq8ZB5oBmaUD\r\n\r\nCode used to generate tflite file from tensorflow model:\r\n\r\n```\r\nimport tensorflow as tf\r\ngraph_def_file = \"single_layer.pb\"\r\ninput_arrays =['s']\r\noutput_arrays =['conv/Relu']\r\noutput_file = \"single_layer.tflite\"\r\n\r\nconverter = tf.lite.TFLiteConverter.from_frozen_graph(graph_def_file, input_arrays, output_arrays)\r\ntflite_model = converter.convert()\r\nopen(output_file, \"wb\").write(tflite_model)\r\n\r\n```\r\n\r\nI used netron to visualise the .pb and .tflite graph, link: https://github.com/lutzroeder/netron\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nTensorflow graph:\r\n![1](https://user-images.githubusercontent.com/32209750/64239177-0e659a00-cf00-11e9-9d99-67809d639104.PNG)\r\n\r\nTflite graph after TFLiteConverter:\r\n![image](https://user-images.githubusercontent.com/32209750/64239288-45d44680-cf00-11e9-9fb4-18eddf063b4f.png)\r\n\r\n\r\n\r\n\r\n", "comments": ["@ymodak ", "seems the bug comes from here: https://github.com/tensorflow/tensorflow/blob/04256c89d8783c5cfd7e550f9512e9478beb6454/tensorflow/lite/toco/graph_transformations/convert_pure_conv_to_depthwise.cc#L49\r\n\r\nthe if statement assumes that if a depth equals to one, it is a depthwise convolution. ", "Hi,\r\n\r\nThe convert to depthwiseconv is by design. I'm curious if this causes an issue for you (correctness/performance regression)?", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32201\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32201\">No</a>\n"]}, {"number": 32200, "title": "[tflite] how to build tflite project to library for ios  bazel, swift, pod, make?", "body": "I want to build tflite project library to shared with other projects on android & ios.\r\nIt is easy to build android project library via bazel (cc_binary) and test it via adb. \r\nHow about ios, use bazel, swift, pod, make,c++/objectc? how to test it? is there any example?", "comments": ["@laohur, Did you get a chance to look [Tensorflow official website](https://www.tensorflow.org/lite/guide/build_ios) to build Tf lite on iOS. Thanks", "> official\r\nget it! mostly unity & xcode problems.", "@laohur, Can you please let us know if you are happy to close if no issue persists. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32200\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32200\">No</a>\n"]}, {"number": 32199, "title": "_num_gpus_per_worker", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": []}, {"number": 32198, "title": "[INTEL MKL] Fix to non-native gcc build.", "body": "This PR fixes following build error when building with non-native gcc version.\r\n```ERROR: /ec/pdx/disks/aipg_lab_home_pool_01/mabuzain/code/private-tensorflow/tensorflow/compiler/tf2tensorrt/BUILD:506:1: SWIGing tensorflow/compiler/tf2tensorrt/utils/py_utils.i failed (Exit 1)\r\nbazel-out/host/bin/external/swig/swig: /lib64/libstdc++.so.6: version `CXXABI_1.3.9' not found (required by bazel-out/host/bin/external/swig/swig)\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build```", "comments": ["> This PR fixes following build error when building with non-native gcc version.\r\n> \r\n> ```\r\n> bazel-out/host/bin/external/swig/swig: /lib64/libstdc++.so.6: version `CXXABI_1.3.9' not found (required by bazel-out/host/bin/external/swig/swig)\r\n> Target //tensorflow/tools/pip_package:build_pip_package failed to build```\r\n> ```\r\n\r\nWhat part of ENV is wrong without your change? Usually the right way to fix env problems is by adding a --action_env FOO=BAR to the bazel command line.", "@mdfaijul Could you please check reviewer comments and keep us posted. Thanks!", "@r4nt @gbaned I am using `CentOS Linux release 7.5.1804`, and building with GCC 6.3.\r\n\r\nI tried with `--action_env ` to the bazel build command, but it did not work for me. Seeing same error:\r\n```ERROR: tensorflow/lite/python/optimize/BUILD:28:1: SWIGing tensorflow/lite/python/optimize/calibration_wrapper.i failed (Exit 1)```\r\n```bazel-out/host/bin/external/swig/swig: /lib64/libstdc++.so.6: version `CXXABI_1.3.9' not found (required by bazel-out/host/bin/external/swig/swig)```\r\n\r\nHere is the build command I used:\r\n```bazel --output_base=<some_dir> --action_env LD_LIBRARY_PATH=<gcc_6.3_dir>/lib64 --config=mkl --copt=\"-mfma\" --copt=\"-mavx2\" -c opt //tensorflow/tools/pip_package:build_pip_package```\r\n", "Can you show the output of \r\n$ ldd bazel-out/host/bin/external/swig/swig\r\n", "@r4nt Here is the output of $ ldd bazel-out/host/bin/external/swig\r\n```\r\nlinux-vdso.so.1 =>  (0x00007ffed8b62000)\r\n\tlibstdc++.so.6 => /opt/tensorflow/gcc6.3/lib64/libstdc++.so.6 (0x00007fa63c357000)\r\n\tlibm.so.6 => /lib64/libm.so.6 (0x00007fa63c055000)\r\n\tlibgcc_s.so.1 => /opt/tensorflow/gcc6.3/lib64/libgcc_s.so.1 (0x00007fa63be3e000)\r\n\tlibc.so.6 => /lib64/libc.so.6 (0x00007fa63ba71000)\r\n\t/lib64/ld-linux-x86-64.so.2 (0x00007fa63c6d8000)\r\n```\r\nSo ldd output is pointing to correct LD_LIBRARY_PATH setting. But I get the following error\r\n```\r\nERROR: /ec/pdx/disks/aipg_lab_home_pool_01/mdfaijul/public-tf/tensorflow/compiler/tf2tensorrt/BUILD:508:1: SWIGing tensorflow/compiler/tf2tensorrt/utils/py_utils.i failed (Exit 1)\r\nbazel-out/host/bin/external/swig/swig: /lib64/libstdc++.so.6: version `CXXABI_1.3.9' not found (required by bazel-out/host/bin/external/swig/swig)```", "Sorry for the delays. Can you run bazel with -s and paste the full command line (including where it sets all the env variables) for the failing action?", "@mdfaijul Could you please check reviewer comments and keep us posted. Thanks!", "@r4nt @gbaned Here is full command with -s option. I have put more logs here as I'm not sure what info will be useful to you.\r\n`SUBCOMMAND: # //tensorflow/python:_pywrap_py_func_version_script [action 'Executing genrule //tensorflow/python:_pywrap_py_func_version_script [for host]']\r\n(cd /localdisk/amin/deps-tf/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/opt/tensorflow/gcc6.3/lib64 \\\r\n    PATH=/usr/local/cuda/bin:/nfs/site/home/mdfaijul/.local/bin:/opt/tensorflow/gcc6.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; echo '\\''{global:\r\n init_pywrap_py_func;\r\n init__pywrap_py_func;\r\n PyInit__pywrap_py_func;\r\n local: *;};'\\'' >bazel-out/host/genfiles/tensorflow/python/_pywrap_py_func-version-script.lds')\r\nSUBCOMMAND: # //tensorflow/lite/python/interpreter_wrapper:tensorflow_wrap_interpreter_wrapper_py_wrap [action 'SWIGing tensorflow/lite/python/interpreter_wrapper/interpreter_wrapper.i [for host]']\r\n(cd /localdisk/amin/deps-tf/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n  bazel-out/host/bin/external/swig/swig -c++ -python -module tensorflow_wrap_interpreter_wrapper -o bazel-out/host/bin/tensorflow/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.cc -outdir bazel-out/host/bin/tensorflow/lite/python/interpreter_wrapper -Iexternal/eigen_archive -Iexternal/swig -Ibazel-out/host/genfiles -Ibazel-out/host/genfiles/external/local_config_python -Iexternal/com_google_absl -Iexternal/gemmlowp -Iexternal/flatbuffers -Iexternal/arm_neon_2_x86_sse -Iexternal/farmhash_archive -Iexternal/swig/Lib -Iexternal/swig/Lib/cffi -Iexternal/swig/Lib/python -Iexternal/swig/Lib/std -Iexternal/swig/Lib/typemaps tensorflow/lite/python/interpreter_wrapper/interpreter_wrapper.i)\r\nSUBCOMMAND: # //tensorflow/lite/experimental/ruy:pack_avx2 [action 'Compiling tensorflow/lite/experimental/ruy/pack_avx2.cc [for host]']\r\n(cd /localdisk/amin/deps-tf/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/opt/tensorflow/gcc6.3/lib64 \\\r\n    PATH=/usr/local/cuda/bin:/nfs/site/home/mdfaijul/.local/bin:/opt/tensorflow/gcc6.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin \\\r\n    PWD=/proc/self/cwd \\\r\n  /opt/tensorflow/gcc6.3/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/host/bin/tensorflow/lite/experimental/ruy/_objs/pack_avx2/pack_avx2.pic.d '-frandom-seed=bazel-out/host/bin/tensorflow/lite/experimental/ruy/_objs/pack_avx2/pack_avx2.pic.o' -fPIC -iquote . -iquote bazel-out/host/genfiles -iquote bazel-out/host/bin -iquote external/gemmlowp -iquote bazel-out/host/genfiles/external/gemmlowp -iquote bazel-out/host/bin/external/gemmlowp -g0 -g0 '-std=c++14' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c tensorflow/lite/experimental/ruy/pack_avx2.cc -o bazel-out/host/bin/tensorflow/lite/experimental/ruy/_objs/pack_avx2/pack_avx2.pic.o)\r\nERROR: /ec/pdx/disks/aipg_lab_home_pool_01/mdfaijul/public-tf/tensorflow/lite/python/interpreter_wrapper/BUILD:60:1: SWIGing tensorflow/lite/python/interpreter_wrapper/interpreter_wrapper.i failed (Exit 1)\r\nbazel-out/host/bin/external/swig/swig: /lib64/libstdc++.so.6: version `CXXABI_1.3.9' not found (required by bazel-out/host/bin/external/swig/swig)\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build`", "@r4nt @gbaned I see this issue on CentOS, but not on Ubuntu, BTW.", "@r4nt @gbaned any update?", "@r4nt @gbaned any update?", "Just to confirm:\r\n1. when you run bazel-out/host/bin/external/swig/swig on the command line you don't get the error?\r\n2. can you potentially edit bazel-out/host/bin/external/swig/swig and replace it with a script that just prints LD_LIBRARY_PATH?", "@mdfaijul Could you please check reviewer comments and keep us posted. Thanks!", "@gbaned @r4nt @agramesh1 I am not able to reproduce the issue with current master. Hence closing this PR.", "It happens to me on tensorflow 2.0.1 on centos using gcc-6.3.0\r\nThe change to the file in this PR fixes it. Thanks!\r\nif there's a way to achieve the same results without the change, I would be interested to know.", "SWIG has been a problematic when building on CentOS 6/7. The usual fix worked here:\r\n\r\n```\r\ndiff --git a/tensorflow/tensorflow.bzl b/tensorflow/tensorflow.bzl\r\nindex 796143a..4624e72 100644\r\n--- a/tensorflow/tensorflow.bzl\r\n+++ b/tensorflow/tensorflow.bzl\r\n@@ -1658,6 +1658,7 @@ def _py_wrap_cc_impl(ctx):\r\n         outputs = outputs,\r\n         mnemonic = \"PythonSwig\",\r\n         progress_message = \"SWIGing \" + src.path,\r\n+        use_default_shell_env = True,\r\n     )\r\n     return struct(files = depset(outputs))\r\n```\r\n\r\n"]}, {"number": 32197, "title": "Increase the clarity of reshuffle_each_iteration documentation", "body": "When `reshuffle_each_iteration` is `None`, private instance variable `_reshuffle_each_iteration` gets set to `True`, which is I think what the original docstring is alluding to.\r\n\r\nThe original docstring says that the value defaults to `True` which is slightly confusing as the default is a `None`.  I've made changes to the docstrings to attempt to increase its clarity.", "comments": ["> It is common practice for None value to indicate that the default behavior should be used\r\n\r\n\ud83d\udc4d closing this."]}, {"number": 32196, "title": "ImportError: cannot import name 'Event' from 'tensorflow_core.python' (unknown location)", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): with \"pip install tensorflow-gpu==2.0.0-rc0\"\r\n- TensorFlow version:tensorflow-gpu==2.0.0-rc0\r\n- Python version:3.7.3\r\n- Installed using virtualenv? pip? conda?:pip\r\n- Bazel version (if compiling from source):0.29.0\r\n- CUDA/cuDNN version: CUDA 10.0 and 10.1/cuDNN 10.0 and 10.1\r\n- GPU model and memory: NVIDIA GeForce GTX 1070/ 8 GB GDDR5\r\n\r\nI'm using Jupyther notebook. I've installed tensorflow with 'pip install tensorflow-gpu==2.0.0-rc0' in my environment terminal. \r\nNow in Jupyter notebook trying to import with:\r\nfrom tensorflow.keras.models import Sequential \r\nfrom tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\r\n\r\nAnd I've got this error:\r\n`ERROR:root:Internal Python error in the inspect module.\r\nBelow is the traceback from this internal error.\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3296, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-167-72e06926552d>\", line 11, in <module>\r\n    from tensorflow.keras.models import Sequential\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 45, in <module>\r\n    from tensorflow._api.v2 import compat\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\__init__.py\", line 23, in <module>\r\n    from tensorflow._api.v2.compat import v1\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\__init__.py\", line 72, in <module>\r\n    from tensorflow._api.v2.compat.v1 import summary\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\summary\\__init__.py\", line 14, in <module>\r\n    from tensorflow.python import Event\r\nImportError: cannot import name 'Event' from 'tensorflow_core.python' (unknown location)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2033, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1095, in get_records\r\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 313, in wrapped\r\n    return f(*args, **kwargs)\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 347, in _fixed_getinnerframes\r\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\r\n  File \"C:\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\r\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\r\n  File \"C:\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\r\n    filename = getsourcefile(frame) or getfile(frame)\r\n  File \"C:\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\r\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\r\n  File \"C:\\Anaconda3\\lib\\inspect.py\", line 733, in getmodule\r\n    if ismodule(module) and hasattr(module, '__file__'):\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 45, in <module>\r\n    from tensorflow._api.v2 import compat\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\__init__.py\", line 23, in <module>\r\n    from tensorflow._api.v2.compat import v1\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\__init__.py\", line 72, in <module>\r\n    from tensorflow._api.v2.compat.v1 import summary\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\summary\\__init__.py\", line 14, in <module>\r\n    from tensorflow.python import Event\r\nImportError: cannot import name 'Event' from 'tensorflow_core.python' (unknown location)\r\n\r\nWhen I was using same code with Sublime Text it was working ok.\r\n`", "comments": ["@Full4me ,\r\nWhen tried running \r\n```\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\r\n```\r\ncode,  I was able to execute without any issues.Thanks!", "@oanush \r\n\r\nreinstalled, restarted PC and now is working. \r\n\r\nThx for Your time. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32196\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32196\">No</a>\n"]}, {"number": 32195, "title": "Adjust audio_provider for the sparkfun_edge for production boards.", "body": "Temporary gain emulation to deal with too-quiet audio on prototype boards\r\ntogether with fluctuating 'zero' level offset causes oversaturation on\r\nproduction boards.\r\n\r\ncc: @petewarden ", "comments": ["Please add label comp:micro so it gets in the right queue", "ping @petewarden for review ?", "@suphoff  Can you please resolve conflicts? Thanks!", "Updated", "Thanks for your patience! We're not going to take this PR, since we're hoping the number of proto boards is pretty small now and newer generations are moving over to digital mics."]}, {"number": 32194, "title": "micro_speech preprocessing", "body": "**System information**\r\n- TensorFlow version (you are using): 1.14\r\n- Are you willing to contribute it (Yes/No): yes\r\n\r\ntensorflow/examples/speech_commands project defines 3 different preprocessing modes. It is possible to train a ML model using all of them. \r\n\r\nThen there is an experimental project which will use the ML model from the 1st project on a micro-controller: tensorflow/lite/experimental/micro/examples/micro_speech/\r\nThis project ignores the preprocessing modes from the first project. By looking at the code in the micro_speech project it assumes the preprocessing mode always to be 'micro'.  The preprocessing includes some scaling operations and it looks like those operations are done inside 'micro_features_generator.cc' \r\ntensorflow/lite/experimental/micro/examples/micro_speech/micro_features/micro_features_generator.cc\r\nThere is an comment related to this: 'These scaling values are derived from those used in input_data.py in the training pipeline.'\r\n\r\nThe problems I see at the moment:\r\n1 .It is very unclear how those magic scaling numbers in micro_features_generator.cc are derived from training pipeline. What if my pipeline parameters are not exactly the same as they were when those magic numbers where defined.   \r\n2. It is impossible to use another preprocessing mode as 'micro' because it is not implemented on micro_speech project.\r\n3. There is suspicious operation where pointer is always moved 160 steps forward. Why hardcoded 160? From where does this number come and why buffer pointer is always moved 160.  'frontend_input = input + 160; ' \r\n4. Documentation of the all preprocessing modes is lacking.\r\n\r\nSo at the moment if somebody use 'average' or 'mfcc' preprocessing mode then the input to the model is not correctly prepared in micro_speech project and it will fail to detect sounds. One should to implement all preprocessing modes in micro_features_generator.cc.\r\n\r\nI am also not sure if 'micro' works always correctly because there is that hardcoded 160 which is obviously depend on some ML model input parameters.", "comments": ["@petewarden Could you please give your input to this issue.\r\n\r\nI find it weird that ML model has a good accuracy after training but it performs badly on target micro controller HW. Preprocessing might be the reason for that. If the input to the model is not exactly similar preprocessed during training and inferencing then the model wont work good on target HW. ", "3. Pointer is always moved 160 is maybe wrong. It should be 320 because stride in the example is defined as 20ms and sampling rate 16000Hz. So if we want to go forward always 20ms then it means 320 samples.\r\n", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32194\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32194\">No</a>\n", "I have the same confusion, and after read the source code. I got the reason for \"frontend_input = input + 160; \".\r\n\r\nI think this is because we reuse 10 ms history audio data, it means 160 sample when sample rate is 16000.\r\n\r\nAt the first time WindowProcessSamples() will read the whole 480 samples (30ms),  and 320 samples following (20 ms), just the new samples. Log like below:\r\n\r\n```\r\nnum_samples_read 480, audio_samples_size 512, output_slice_size 40  \r\n\r\nnum_samples_read 320, audio_samples_size 512, output_slice_size 40  \r\n\r\nnum_samples_read 320, audio_samples_size 512, output_slice_size 40  \r\n\r\nnum_samples_read 320, audio_samples_size 512, output_slice_size 40  \r\n\r\nnum_samples_read 320, audio_samples_size 512, output_slice_size 40  \r\n```\r\nIf see the source code of WindowProcessSamples(), we can konw that windows state keeps the history 160 samples in itself buffer.\r\n```\r\n memmove(state->input, state->input + state->step,\r\n          sizeof(*state->input) * (state->size - state->step));\r\n  state->input_used -= state->step;\r\n```\r\nSo the 'frontend_input = input + 160;' is correct.\r\n\r\nI write this if it could help anyone.\r\n"]}, {"number": 32193, "title": "Inconsistent behavior of .shape when using sparse.placeholder", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nNo\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nUbuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nNo\r\n- TensorFlow installed from (source or binary):\r\nbinary\r\n- TensorFlow version (use command below):\r\n1.15.0-dev20190821\r\n- Python version:\r\n3.7.4\r\n\r\n**Describe the current behavior**\r\n\r\nsparse.placeholder does loses the shape entirely when batch is not provided. This is inconstent with how tf.placeholder behaves.\r\n**Describe the expected behavior**\r\ntf.placeholder and tf.sparse.placeholder have the same behavior.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nprint(tf.__version__)\r\n\r\nprint(\"Printing shape of sparse placeholder when using (None, 1024)\")\r\nprint(tf.compat.v1.sparse.placeholder(dtype=tf.float32, shape=(None, 1024)).shape)\r\n\r\nprint(\"Printing shape of dense placeholder when using (None, 1024)\")\r\nprint(tf.compat.v1.placeholder(dtype=tf.float32, shape=(None, 1024)).shape)\r\n\r\nprint(\"Printing shape of sparse placeholder when using (-1, 1024)\")\r\nprint(tf.compat.v1.sparse.placeholder(dtype=tf.float32, shape=(-1, 1024)).shape)\r\n\r\nprint(\"Printing shape of dense placeholder when using (-1, 1024)\")\r\nprint(tf.compat.v1.placeholder(dtype=tf.float32, shape=(-1, 1024)).shape)\r\n```\r\n\r\n**Other info / logs**\r\n\r\n```\r\n1.15.0-dev20190821\r\nPrinting shape of sparse placeholder when using (None, 1024)\r\n(?, ?)\r\nPrinting shape of dense placeholder when using (None, 1024)\r\n(?, 1024)\r\nPrinting shape of sparse placeholder when using (-1, 1024)\r\n(?, 1024)\r\nPrinting shape of dense placeholder when using (-1, 1024)\r\nTraceback (most recent call last):\r\n  File \"/home/pyalamanchili/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\", line 206, in make_shape\r\n    shape = tensor_shape.as_shape(v)\r\n  File \"/home/pyalamanchili/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py\", line 1216, in as_shape\r\n    return TensorShape(shape)\r\n  File \"/home/pyalamanchili/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py\", line 776, in __init__\r\n    self._dims = [as_dimension(d) for d in dims_iter]\r\n  File \"/home/pyalamanchili/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py\", line 776, in <listcomp>\r\n    self._dims = [as_dimension(d) for d in dims_iter]\r\n  File \"/home/pyalamanchili/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py\", line 718, in as_dimension\r\n    return Dimension(value)\r\n  File \"/home/pyalamanchili/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py\", line 198, in __init__\r\n    raise ValueError(\"Dimension %d must be >= 0\" % self._value)\r\nValueError: Dimension -1 must be >= 0\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/tmp/sparse_shape.py\", line 15, in <module>\r\n    print(tf.compat.v1.placeholder(dtype=tf.float32, shape=(-1, 1024)).shape)\r\n  File \"/home/pyalamanchili/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\", line 2619, in placeholder\r\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\r\n  File \"/home/pyalamanchili/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py\", line 6667, in placeholder\r\n    shape = _execute.make_shape(shape, \"shape\")\r\n  File \"/home/pyalamanchili/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\", line 211, in make_shape\r\n    e))\r\nValueError: Error converting shape to a TensorShape: Dimension -1 must be >= 0.\r\n\r\n```", "comments": ["This results in downstream bugs in keras. Should I create new tickets for them or should I include the bugs coming up in keras over here?", "Issue replicating for TF version-[1.15.0-dev20190821](https://colab.research.google.com/gist/oanush/379564e09facc63f335a55bcb5319bfe/32193.ipynb).\r\nThanks!", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32193\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32193\">No</a>\n"]}, {"number": 32192, "title": "JSON serializable issue at RemoteMonitor", "body": "The Tensorflow implementation of RemoteMonitor callback raises the error\r\n`Object of type float32 is not JSON serializable.`\r\n\r\nKeras own implementation works fine with the same code.\r\n\r\nI think the relevant code difference is \r\n    \r\n```\r\nfor k, v in logs.items():\r\n      send[k] = v\r\n\r\n```\r\nin the Tensorflow implementation and\r\n\r\n```\r\nfor k, v in logs.items():\r\n            if isinstance(v, (np.ndarray, np.generic)):\r\n                send[k] = v.item()\r\n            else:\r\n                send[k] = v\r\n```\r\n\r\nin the Keras implementation.\r\n", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the minimal code snippet to reproduce the issue. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "My description above was a little bit short. It was meant as a short notice that the tensorflow.keras RemoteMonitor class has a bug which the Keras RemoteMonitor class does not have. Let me explain it with a little bit more detail.\r\n\r\nI have made a quick example which shows the error.\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport tensorflow.keras as keras\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.datasets import fashion_mnist\r\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Activation, BatchNormalization, MaxPool2D\r\nfrom tensorflow.keras.optimizers import Adam, Adadelta\r\nimport tensorflow.keras.losses as losses\r\nimport tensorflow.keras.metrics as metrics\r\nfrom tensorflow.keras.callbacks import RemoteMonitor, LambdaCallback, Callback\r\n\r\n(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\r\n\r\nx_train = x_train.reshape(-1,28,28,1) / 255\r\nx_test = x_test.reshape(-1,28,28,1) / 255\r\n\r\ny_train = y_train.astype(np.int32)\r\ny_test = y_test.astype(np.int32)\r\n\r\nremote_cb = RemoteMonitor(root=\"http://localhost:9000\", path=\"/publish/epoch/end/\", send_as_json=True)\r\n\r\nmodel = Sequential()\r\nmodel.add(Conv2D(64,(3,3), activation=\"relu\", input_shape=(28,28,1)))\r\nmodel.add(MaxPool2D((2,2)))\r\nmodel.add(BatchNormalization())\r\nmodel.add(Flatten())\r\nmodel.add(Dense(256, activation=\"relu\"))\r\nmodel.add(Dense(10, activation=\"softmax\"))\r\n\r\nmodel.compile(loss=losses.sparse_categorical_crossentropy, optimizer=Adam(),\r\n              metrics = [\"accuracy\"])\r\n\r\nmodel.fit(x_train[:3000], y_train[:3000], epochs=5, batch_size=64, callbacks=[remote_cb])\r\n```\r\n\r\nThis code gives a error \r\n`Object of type float32 is not JSON serializable`.\r\n\r\nBut when delete the Tensorflow from the imports, so using the keras implementation, then the above code works fine.\r\n\r\nSo I looked at the tensorflow.keras  [RemoteMonitor class](https://github.com/tensorflow/tensorflow/blob/r1.14/tensorflow/python/keras/callbacks.py#L1264-L1316) and compared it to the [Remote Monitor class](https://github.com/keras-team/keras/blob/master/keras/callbacks.py#L847) from keras.\r\n\r\nAs stated above the relevant difference is\r\n\r\n```\r\nfor k, v in logs.items():\r\n      send[k] = v\r\n```\r\n\r\nin the Tensorflow.keras and \r\n\r\n```\r\nfor k, v in logs.items():\r\n            if isinstance(v, (np.ndarray, np.generic)):\r\n                send[k] = v.item()\r\n            else:\r\n                send[k] = v\r\n```\r\n\r\nin the keras implementation.\r\n\r\nI have also tried to replace the lines in the Tensorflow.keras callback.py file with the lines from the keras callbacks.py file and then the code works with the Tensorflow imports.", "I have tried on colab with 2.0.0-rc0 and was able to reproduce the issue.Please,find the [gist ](https://colab.sandbox.google.com/gist/ravikyram/bf10dde754b4e8d73d8c021e4e014120/untitled156.ipynb) here.Please, let us know which TensorFlow version you are using?.Thanks!", "I have used 1.14.0, but the class RemoteMonitor is in 1.14.0 and 2.0.0-rc0 identical.", "I have tried on colab with 2.0.0-rc0,1.14,TF nightly versions and was able to reproduce the issue.Please,find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/1be5308bed758dc9cedb42e2a866983b/untitled156.ipynb).Thanks!", "Hi, I would like to work on fixing this.", "As the PR has been merged, close the bug for now. Feel free to reopen it if needed.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32192\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32192\">No</a>\n", "Is this issue resolved, which build has this issue resolved?"]}, {"number": 32191, "title": "fix OSS issue with cupti tracer", "body": "PiperOrigin-RevId: 265071523", "comments": []}]