[{"number": 30335, "title": "Fixed all the warning in the flow for TC match_dilated_convolution_test", "body": "", "comments": ["Can one of the admins verify this patch?", "The change looks good to me, adding @impjdi to double check.", "@amitsrivastava78  Could you please check reviewer comments and keep us posted. Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 30334, "title": "Fixed all the warning in the flow for TC match_dilated_convolution_test", "body": "", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F30334) for more info**.\n\n<!-- need_author_cla -->"]}, {"number": 30333, "title": "Fixed all the warning in the flow for TC match_dilated_convolution_test", "body": "", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F30333) for more info**.\n\n<!-- need_author_cla -->"]}, {"number": 30332, "title": "TensofflowLite on Andoid: Didn't find op for builtin opcode 'CONV_2D' version '2'", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, I am using custom Flutter plugin for Firebase Custom model\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Samsun S10 / Emulator\r\n- TensorFlow installed from (source or binary): tf-nightly\r\n- TensorFlow version (use command below): 1.14\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nAndroid library fails to load InceptionV3 model converted to TFLite.\r\n```E/CustomCompatChecker(15099): The model is INCOMPATIBLE. It may contain unrecognized custom ops, or not FlatBuffer format: java.lang.IllegalArgumentException: Internal error: Cannot create interpreter: Didn't find op for built-in opcode 'CONV_2D' version '2'```\r\n**Describe the expected behavior**\r\nModel loaded. Simple models, or not optimized work. \r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n1. Convert TF InceptionV3 to TFLite (with optimization for size)\r\n2. Load model to Android device - fails sometimes not finding a matching model or the error above.\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["You need a newer version of TensorFlow Lite, at least 1.14.0, which was just published this past week (https://bintray.com/google/tensorflow/tensorflow-lite/1.14.0)."]}, {"number": 30331, "title": "Tensorflow2 tf.train.Checkpoint(), tf.train,CheckpointManager.save() got ValueError:substring not found", "body": "Hello.\r\nI'm the beginner using tensorflow2. So could you help me a little?\r\nCould you let me know how to save the model weight as ckpt files?\r\n\r\nI just try to save the weight like below\r\n\r\n#################################################################\r\noptimizer = tf.keras.optimizers.Adam(FLAGS.lr)\r\nloss_object =tf.losses.sparse_categorical_crossentropy\r\nckpt = tf.train.Checkpoint(step=tf.Variable(0), optimizer=optimizer, model=model)\r\nmanager = tf.train.CheckpointManager(ckpt, './tf_ckpts/', max_to_keep=3)\r\n\r\ndef train_one_step(data, label, model, optimizer):\r\n    with tf.GradientTape() as tape:\r\n        pred, end_points= model(data)\r\n        loss = loss_object\r\n        ckpt.step.assign_add(1)\r\n        if int(ckpt.step) % 10 == 0:\r\n            save_path = manager.save()\r\n            print (\"Saved checkpoint for step {}: {}\".format(int(ckpt.step), save_path))\r\n\r\nloss, pred, label = train_one_step(train_data, train_label, model, optimizer)\r\n\r\nbut I have the error like below. Do you happen to know the reason?!\r\nThank you in advance.\r\n\r\nFile \"\", line 1, in\r\nrunfile('/home/kevin/Downloads/3D/pointnet2/tf2_train.py', wdir='/home/kevin/Downloads/3D/pointnet2')\r\n\r\nFile \"/home/kevin/anaconda3/lib/python3.6/site-packages/spyder/utils/site/sitecustomize.py\", line 705, in runfile\r\nexecfile(filename, namespace)\r\n\r\nFile \"/home/kevin/anaconda3/lib/python3.6/site-packages/spyder/utils/site/sitecustomize.py\", line 102, in execfile\r\nexec(compile(f.read(), filename, 'exec'), namespace)\r\n\r\nFile \"/home/kevin/Downloads/3D/pointnet2/tf2_train.py\", line 188, in\r\ntrain(train_dataset)\r\n\r\nFile \"/home/kevin/Downloads/3D/pointnet2/tf2_train.py\", line 173, in train\r\nloss, accuracy = train_one_epoch(MODEL, optimizer, train_dataset)\r\n\r\nFile \"/home/kevin/Downloads/3D/pointnet2/tf2_train.py\", line 151, in train_one_epoch\r\nloss, pred, label = train_one_step(train_data, train_label, model, optimizer)\r\n\r\nFile \"/home/kevin/Downloads/3D/pointnet2/tf2_train.py\", line 98, in train_one_step\r\nsave_path = ckpt.save(model)\r\n\r\nFile \"/home/kevin/anaconda3/envs/tf_2/lib/python3.6/site-packages/tensorflow/python/training/tracking/util.py\", line 1840, in save\r\nfile_path = self.write(\"%s-%d\" % (file_prefix, checkpoint_number))\r\n\r\nFile \"/home/kevin/anaconda3/envs/tf_2/lib/python3.6/site-packages/tensorflow/python/training/tracking/util.py\", line 1770, in write\r\noutput = self._saver.save(file_prefix=file_prefix)\r\n\r\nFile \"/home/kevin/anaconda3/envs/tf_2/lib/python3.6/site-packages/tensorflow/python/training/tracking/util.py\", line 1106, in save\r\nfile_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)\r\n\r\nFile \"/home/kevin/anaconda3/envs/tf_2/lib/python3.6/site-packages/tensorflow/python/training/tracking/util.py\", line 1046, in _save_cached_when_graph_building\r\nobject_graph_tensor=object_graph_tensor)\r\n\r\nFile \"/home/kevin/anaconda3/envs/tf_2/lib/python3.6/site-packages/tensorflow/python/training/tracking/util.py\", line 1014, in _gather_saveables\r\nfeed_additions) = self._graph_view.serialize_object_graph()\r\n\r\nFile \"/home/kevin/anaconda3/envs/tf_2/lib/python3.6/site-packages/tensorflow/python/training/tracking/graph_view.py\", line 381, in serialize_object_graph\r\ntrackable_objects, path_to_root)\r\n\r\nFile \"/home/kevin/anaconda3/envs/tf_2/lib/python3.6/site-packages/tensorflow/python/training/tracking/graph_view.py\", line 355, in _serialize_gathered_objects\r\nobject_map=object_map))\r\n\r\nFile \"/home/kevin/anaconda3/envs/tf_2/lib/python3.6/site-packages/tensorflow/python/training/tracking/graph_view.py\", line 264, in _add_attributes_to_object_graph\r\n[maybe_saveable], convert_variable_to_tensor=False)\r\n\r\nFile \"/home/kevin/anaconda3/envs/tf_2/lib/python3.6/site-packages/tensorflow/python/training/saving/saveable_object_util.py\", line 270, in op_list_to_dict\r\nset_var = names_to_saveables.setdefault(var._shared_name, var)\r\n\r\nFile \"/home/kevin/anaconda3/envs/tf_2/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1087, in _shared_name\r\nreturn self.name[:self.name.index(\":\")]\r\n\r\nValueError: substring not found\r\n\r\n", "comments": ["I found the solution myself. \r\nIn custom model, I put the instance of tf.Variable into same instance. So it was set as 'UnreadVariable'\r\nWhat I did wrong is below.\r\n\r\nF=tf.Variable(initial_value=tf.constant_initializer(0.0))\r\nF = F.assign_add(tf.constant(1.0))\r\n\r\nS = F.assign_add(tf.constant(1.0)) \r\n\r\nThen i solved it.", "@tolry418 Closing since the issue has been resolved. Thanks!"]}, {"number": 30330, "title": "tf.keras.utils.multi_gpu_model use only one GPU when using sequential model", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using):1.14\r\n- Are you willing to contribute it (Yes/No):No\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nThe tf.keras.utils.multi_gpu_model doesn't work well with sequential model. Only one GPU is working.\r\n**Will this change the current api? How?**\r\nNo\r\n\r\n**Who will benefit with this feature?**\r\nEveryone who use keras with multi-gpu system.\r\n\r\n**Any Other info.**", "comments": ["@mungsoo ,\r\nThank you for pointing this out. Can you please provide a reproducible code snippet which helps us in identifying the location of bug exactly.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30330\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30330\">No</a>\n"]}, {"number": 30329, "title": "ImportError: /lib64/libc.so.6: version `GLIBC_2.15' not found on importing Keras", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version & Keras Version. Also, did you compile from source or install a binary?\r\nRequest you to fill the issue template  because it is really difficult to help without that information. Thanks!", "OS details :\r\nLinux rndarch45 2.6.32-696.30.1.el6.x86_64 #1 SMP Fri May 18 11:50:44 EDT 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n\r\nGLIB version= 2.12\r\nTensorflow version= 1.14.1\r\n\r\nI was using PIP install\r\n\r\n@ravikyram ", "Please, go through the [link ](https://www.tensorflow.org/guide/keras) .you can directly import keras from tensorflow. Thanks!", "@ravikyram \r\n\r\nSorry, but my importing tensorflow itself isn't working because of the GLIBC incompatibility. The error is for not proper installation of tensorflow, not keras.", "Just to verify did you get chance to follow instructions from [TensorFlow](https://www.tensorflow.org/install/pip) website .Please, let us know. Thanks!.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 30328, "title": "[ROCm] Fix for the broken `--config=rocm` build", "body": "The following commit breaks the `--config=rocm` build\r\n\r\nhttps://github.com/tensorflow/tensorflow/commit/e4a0ae3ed04d4d7f8c0381cb8a2d187f86411de8#diff-455a4c7f8e22d7c514e8c2caa27506c5\r\n\r\nThe above commit moves forward the Eigen pointer to which introduces changes (on the Eigen side) which lead to the following errors\r\n\r\n```\r\nIn file included from tensorflow/core/kernels/cross_op_gpu.cu.cc:20:\r\nIn file included from ./tensorflow/core/framework/register_types.h:20:\r\nIn file included from ./tensorflow/core/framework/numeric_types.h:20:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1:\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:140:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorChipping.h:356:37: error:  'Eigen::constCast':  no overloaded function has restriction specifiers that are compatible with the ambient context 'data'\r\n    typename Storage::Type result = constCast(m_impl.data());\r\n                                    ^\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorChipping.h:356:37: error:  'Eigen::constCast':  no overloaded function has restriction specifiers that are compatible with the ambient context 'data'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorAssign.h:148:56: note: in instantiation of member function 'Eigen::TensorEvaluator<const Eigen::TensorChippingOp<1, Eigen::TensorMap<Eigen::Tensor<int, 2, 1, long>, 16, MakePointer> >, Eigen::Gpu\\\r\nDevice>::data' requested here\r\n    return m_rightImpl.evalSubExprsIfNeeded(m_leftImpl.data());\r\n\r\n```\r\n\r\nThe fix for this is trivial and a PR for it has already been submitted to the official Eigen repo\r\n\r\nhttps://bitbucket.org/eigen/eigen/pull-requests/669/adding-the-eigen_device_func-attribute-to/diff\r\n\r\nThis PR is to update the eigen patch to apply the fix, to get the `--config=rocm` build working again\r\n\r\nThis commit can be undone once the Eigen PR is merged and the TF eigen pointer has moved forward to pick up the fix.\r\n\r\n@rmlarsen , please approve.  This is a trivial update to the eigen patch file. \r\n\r\n------------------------------------------------\r\n\r\n@tatianashp @whchung \r\n", "comments": []}, {"number": 30327, "title": "Cherry-picked from master e43b94649d3e1ac5d538e4eca9166b899511d681.", "body": "Disable caching by default unless GCS_READ_CACHE_MAX_SIZE_MB is set.\r\nAdd a buffered GCS reader ideal for sequential reads. This reader will preload up to 64MB (default GCS_READ_CACHE_BLOCK_SIZE_MB) to avoid reading small chunks of data from GCS. This buffer is per file handle and not shared with other readers of the same file. Use this new reader when caching is disabled.\r\n\r\nPiperOrigin-RevId: 255689024", "comments": []}, {"number": 30326, "title": "[XLA:GPU][ROCm] Refactor nvptx_backend_lib to support both NVPTX and AMDGPU", "body": "Notice `nvptx_backend_lib` shall better be renamed as `gpu_backend_lib` but it is\r\nskipped in this commit so minimize potential impacts to other XLA clients.\r\n\r\nSubsequent PR would rename `nvptx_backend_lib` to `gpu_backend_lib`, and introduce complete AMDGPU-specific LLVM invocation logic.\r\n\r\n- Determine platform-specific behaviors when constructing LLVM TargetMachine.\r\n\r\n- Break CompileModuleToPtx into 3 functions:\r\n  - NVPTXGetTargetMachine & GetTargetMachine : setup LLVM TargetMachine\r\n  - LinkAndOptimizeModule : NVPTX-specific logic to link with libdevice, and run LLVM optimization passes.\r\n  - EmitModuleToPTX : NVPTX-specific logic to drive LLVM NVPTX backend.\r\n\r\n- Modify LinkLibdeviceIfNecessary to use LinkWithBitcodeVector.\r\n  - LinkWithBitcodeVector would link a vector of paths to LLVM bitcode libs,\r\n    this utility routine could support both NVPTX (libdevice) and AMDGPU\r\n    (ROCm-Device-Libs).", "comments": ["The list of failures in `Linux GPU` should have no relationship with the PR.", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F30326) for more info**.\n\n<!-- need_author_consent -->", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F30326) for more info**.\n\n<!-- ok -->", "@thomasjoerg a gentle ping", "@thomasjoerg submitted a new commit per your review comments. could you help re-review and approve again? Thanks a lot.", "@thomasjoerg Many thanks for your review. I just submitted a revised version.", "@thomasjoerg since PR #30238 has been merged I've rebased this PR. Now it looks more concise. Could you help re-review again? Thanks.", "Failures in the 6 failing targets don't suggest anything to do with proposed changes introduced in this PR.", "@thomasjoerg would you mind re-approve this PR again? Thanks."]}, {"number": 30325, "title": "Consider integer division/remainder by constant scalar as cheap.", "body": "Consider integer division/remainder by constant scalar as cheap.\r\nLLVM optimize that to faster instruction.\r\n\r\n@sanjoy ", "comments": ["The CI have some failing tests. The 2 with details do not seem related to my PR. If I look at already merged commits that have CI runs, I also saw those errors. Can I do something to help this to get merged?", "I'll try merging it manually."]}, {"number": 30324, "title": "Memory leak in eager mode when creating keras model in loop", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: not tested\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v1.12.1-5259-ge703239 1.15.0-dev20190629\r\n- Python version: 3.7.3\r\n- Bazel version (if compiling from source): not compiled from source\r\n- GCC/Compiler version (if compiling from source): not compiled from source\r\n- CUDA/cuDNN version: using CPU\r\n- GPU model and memory: using CPU\r\n\r\n**Describe the current behavior**\r\n\r\nIn eager execution, when creating a `tf.keras.Sequential` model inside a loop and discarding it immediately, the memory increases over time. The following code shows this by printing the used memory at each iteration.\r\n\r\n```python\r\nimport psutil\r\nimport tensorflow as tf\r\n\r\ntf.compat.v1.enable_eager_execution()\r\n\r\nfor _ in range(100):\r\n    tf.keras.Sequential([tf.keras.layers.Dense(3000, input_dim=3000)])\r\n    print(psutil.virtual_memory().used / 2 ** 30)\r\n```\r\n\r\nOutput:\r\n\r\n```\r\n1.0170440673828125\r\n1.0506706237792969\r\n1.0841865539550781\r\n1.1179122924804688\r\n[...]\r\n4.285423278808594\r\n4.318950653076172\r\n4.35223388671875\r\n```\r\n\r\nThe same result happens when using the Functional API or Model subclassing API. Adding `tf.keras.backend.clear_session()` in the loop solves the leak in all cases like in graph mode. To see this effect better, one should additionally use `gc.collect()` in the loop.\r\n\r\n**Describe the expected behavior**\r\n\r\nWhile adding `tf.keras.backend.clear_session()` to the loop helps, this should not be necessary because in eager execution there is no graph to clear, which according to the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/backend/clear_session) seems to be the only thing this function does:\r\n\r\n> Destroys the current TF graph and creates a new one.\r\n\r\nTherefore it is also suprising that this function helps at all during eager execution. The expected behavior is that there is no memory leak even without `tf.keras.backend.clear_session()`. \r\n\r\n**Code to reproduce the issue**\r\nCode is in description above.\r\n\r\n**Other info / logs**\r\nNothing here.", "comments": ["Does \r\n\r\n`del model`\r\n\r\nHelp?", "> \r\n> \r\n> Does\r\n> \r\n> `del model`\r\n> \r\n> Help?\r\n\r\nIt doesn\u2018t work!@bionicles ", "A similar situation, if I train the model in the main thread and load the model in another thread AT THE SAME TIME. All things are in a loop. However, **if I use clear_session() method in one thread, the code in another thread won't work!!!** I test **pytorch** and **mxnet** , and **there is no any memory leak in a loop.** why??? amazing tensorflow!!! I think that clear_session shouldn't be necessary. @bionicles @tjume ", "> if I use clear_session() method in one thread, the code in another thread won't work!!!\r\n\r\nThat is purely logical. Threads share memory, thus if you call `clear_session` to swipe a model out of memory in a thread, don't expect other threads to access the now-deleted memory...\r\n\r\n---\r\n\r\nNow, I do agree (after reproducing the issue, which is all the more present in TF 2.0 with Eager execution enabled by default) that the absence of implicit garbage collection inside the loop is a bit annoying. Note that if you use `clear_session` (without `gc.collect`), the garbage collector will take out the past models from memory every few seconds (which shows if you add some `time.sleep` instruction in the loop), so I guess there are two things at stake in what you raise:\r\n* keras models created in a given scope are not swiped out when they go out of scope (causing more or less of a memory leak) - this indeed probably requires either fixing or documenting (so that users will either use `clear_session` or not need it)\r\n* the python garbage collector can take some time before deallocating the memory taken by those models once their clearing has been ordered (which I don't think tensorflow developers can do much about)\r\n\r\nMy humble opinion, however is that it really is not an amazing effort from your end as a programmer to add a couple of memory-freeing instructions now and then in your code... This is actually pretty common, in my experience, when you are creating stuff faster than the garbage collector will take care of. But that will be up to the developers/maintainers to decide!", "Maybe I didn't make it clear. I mean if I train model A in the main thread and load  model B and predict  in another thread AT THE SAME TIME. All things are in a loop. However,  if I use clear_session() method in one thread (to clear model A, e.g), BUT the model B in another thread  doesn't work(DOESN'T predict). **As you can see,  there is no any relationship between model A and model B. It seems that  clearing model A can influence model B.** why??? That isn't logical. @pandrey-fr ", "> It seems that clearing model A can influence model B\r\n\r\nOh, I see! Thanks for clarifying the issue. From my understanding (but I might be wrong - I am just a tensorflow user, not an expert, let alone a developer), `tf.keras.backend.clear_session` clears all graphs _that have not been called yet_. So, if you declare models A and B, then `clear_session` will remove all those whose `predict` (or `evaluate`, or `fit`, etc.) method has not yet been called. On the other hand, once you have called such a method, the model cannot be deleted using `clear_session`, but can be so using `del <my_instance>`. In either cases, using `gc.collect` ensures the freed memory is effectively deallocated (otherwise it will be done once the garbage collector's routine check on it).\r\n\r\nExamples:\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n# Enable Eager execution, if required (i.e. using TF 1.x).\r\nif hasattr(tf, 'enable_eager_execution'):\r\n    tf.enable_eager_execution()\r\n\r\n# Make some dummy input data.\r\ninputs = np.random.normal(size=(1, 3000))\r\n\r\n# Declare two models.\r\nmodel_a = tf.keras.Sequential([tf.keras.layers.Dense(3000, input_dim=3000)])\r\nmodel_b = tf.keras.Sequential([tf.keras.layers.Dense(3000, input_dim=3000)])\r\n\r\n# This will clear BOTH models (i.e. the underlying graph will be cleared out).\r\ntf.keras.backend.clear_session()\r\n# Both those lines are going to fail:\r\nmodel_a.predict(inputs)\r\nmodel_b.predict(inputs)\r\n\r\n\r\n# Declare two models (again).\r\nmodel_a = tf.keras.Sequential([tf.keras.layers.Dense(3000, input_dim=3000)])\r\nmodel_b = tf.keras.Sequential([tf.keras.layers.Dense(3000, input_dim=3000)])\r\n\r\n# Use model B.\r\nmodel_b.predict(inputs)\r\n# This will discard the graph underlying model A ONLY.\r\ntf.keras.backend.clear_session()\r\n# This will fail.\r\nmodel_a.predict(inputs)\r\n# This will work.\r\nmodel_b.predict(inputs)\r\n\r\n# Discard model B (now that is has been called).\r\ndel model_b\r\n\r\n# Note that using gc.collect() enforces garbage collection at wanted points.\r\n```", "That being cleared, I now agree with you that it could be useful to dispose of a generic function to clear out a specific keras model without having to worry about its having been used or not. Let's wait for somebody from the mainteance / development team to actually pick up this issue!", "OK. Thanks in advance @pandrey-fr ", "Why is this not fixed in all the github threads I\u2019ve come across? Seems pretty useless to be unable to call model.predict() in a loop without eventually maxing out your memory and dumping the whole thing \r\n\r\nLooks like I may have to switch to pytorch", "@brandonbell11 \r\n\r\n> Why is this not fixed in all the github threads I\u2019ve come across?\r\n\r\nThere has been some (great) improvement on those issues, notably in 2.0-rc0, and we can expect some more with the upcoming actual 2.0 (and 1.15) release(s). The issue arises from Eager execution triggering the creation of (sometimes usefully) redundant back-end graphs, which sometimes end up not being properly discarded. It seems to no longer happen when using tf.data.Dataset objects (which feels logical to me: Datasets ensure the homogeneity of samples' specification, hence making it safe to re-use the same back-end graph), but there still are some issues when feeding individual EagerTensors.\r\n\r\nI would hope it will be fixed at some point, but you have to understand that Eager execution is a big turn compared to how TensorFlow's back-end works, which used to be the normal way of writing TF code until not so long ago. It is therefore bound to take a little time fixing everything, and to be honest I am personally amazed by how fast it is going - when I moved to using Eager a few months ago, I felt like it was a terrible choice leading to huge performance drops and memory leaks issues, while today the former have mostly vanished and the latter are progressively solved. So, my point is, we, as users, have to show a little patience.\r\n\r\n> Seems pretty useless to be unable to call model.predict() in a loop without eventually maxing out your memory and dumping the whole thing\r\n\r\nThe problem is honestly not _that_ great, but yes, in some cases such a problematic behaviour arises. Note, however, that you can work it around, notably by using a Dataset object - and I can hear that this is an effort you would rather not have to make. You could also stick with 1.14 and Eager disabled.\r\n\r\n> Looks like I may have to switch to pytorch\r\n\r\nHonestly, I do not believe anyone \"has to\" switch to PyTorch - but nor to TensorFlow. You should pick up the framework that suits you best at a given point, and be opened to change when relevant (which is less and less hard as their high-level APIs look more and more similar). If you feel like PyTorch works better for you, switch to it, but please do not look at it as a forced thing nor as being part of a \"choose your holy side and be verbose about it\" decision. Both frameworks' devs are doing their best, they disagree on some points, and there is something of a competition for users between them, but in my humble opinion we, as users, actually tend to benefit from it. Eager is clearly a response to PyTorch having a similar behaviour, but TF devs have also shown their ability to make it great while preserving the back-end specifics of TF, and not just make it a _fa\u00e7ade_ filled with bugs (which it kind of felt like in the beginning). So, what I am saying is, if you want to move to PyTorch, do it, but please do not make it sound like TF devs are not doing there job - this is rather disrespectful, and pointless since it is easy to see that they are actually working on solving issues (and rather succeeding to do so).", "> Seems pretty useless to be unable to call model.predict() in a loop without eventually maxing out your memory and dumping the whole thing\r\n\r\nI don't follow. Creating models in a loop will increase memory; this is a known issue with the way the keras backend manages state. However I don't see any leak when calling predict in a loop: https://colab.sandbox.google.com/gist/robieta/cc5e2ccb179d97441e08fab3220ca5bf/predict_leak_test.ipynb", "@robieta When I run a similar test (on tf2.0-rc0), I can actually see (using psutils, as in the code initially provided by the person who opened the issue) a small RAM usage increase unless calling `tf.keras.backend.clear_graph()` and `gc.collect()` explicitly in the loop. I do agree that this feels like a very minor problem though, and I never run into GPU memory exhaustion (which I do in the models in-loop creation issue, which as you mentioned is a well-known one).", "@robieta \r\nApologies I should have mentioned this is specific to my use case, and perhaps should make another thread. The models I use are only loaded in and build once. \r\n\r\nIn short, I am having this issue when implementing a monte-carlo rollout policy implemented in seqGAN(https://arxiv.org/pdf/1609.05473.pdf), which requires me to complete a sentence N times, i.e. N*sentence_length calls to model.predict() to get the next word, as well as model2.predict() to get the score for that sentence. \r\n\r\nIf I have a sentence of length 30 tokens, and I want 20 example for each word, I end up having to make 9280 total calls to model.predict() to get the rewards I need. Using `tf.keras.backend.clear_session()` and `gc.collect()` at the end of each loop doesn't prevent the GPU ram from gradually being filled up. \r\n\r\nI cannot even make it through one complete iteration without everything dumping and getting an OOM error. \r\n\r\nIs the only fix for this at the moment just rolling back to TF-1.15?\r\n", "I'm using TensorFlow 2.0.0 and Keras 2.3.1 and still having the same issue.", "I'm going to close this since the original issue (growth from model creation) has been addressed as a known issue and now the thread is kind of drifting. We have also recently made a fix to the internals of TF that eliminates a leak when invoking model.predict many, many times. If you are still seeing issues with predict, feel free to open a new issue with a repro.. Thanks for all of the feedback.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30324\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30324\">No</a>\n"]}, {"number": 30323, "title": "[XLA:GPU][ROCm] Rename nvptx_constants to target_constants", "body": "- Rename nvptx_constants to target_constants\r\n- Put NVPTX-specific values under xla::gpu::nvptx namespace\r\n- Add AMDGPU-specific triple and datalayout values, under xla::gpu::amdgpu namespace\r\n\r\nSubsequent PRs would address how \"nvptx_backend_lib.cc\" invokes LLVM, and how \"nvptx_compiler.cc\" drives LLVM code emission process to support both NVPTX and AMDGPU targets.", "comments": ["@whchung FYI I'm leaving the XLA team at the end of the month.  @thomasjoerg is a good person to cc for reviews.", "The single error in `Ubuntu Sanity` has nothing to do with changes introduced in this PR."]}, {"number": 30322, "title": "[ROCm] Adding ROCm support for the batch_matmul op", "body": "This PR adds ROCm support for the batch_matmul op\r\n\r\nThe changes in this PR are trivial. please review and merge. thanks.\r\n\r\n------------------------\r\n\r\n@tatianashp @whchung @chsigg ", "comments": []}, {"number": 30321, "title": "tensorflow 2.0 keras multi_gpu_model only utilizing one GPU", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): Binary, pip install\r\n- TensorFlow version (use command below): tensorflow-gpu==2.0.0-beta1\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: cudatoolkit 10.0.130, cudnn 7.6.0\r\n- GPU model and memory: 4x NVIDIA GeForce GTX 1080 Ti\r\n\r\n**Describe the current behavior**\r\nWhen using multi_gpu_model (i.e., tf.keras.utils.multi_gpu_model) in tensorflow 2.0 to distribute a job across multiple gpus (4), only one gpu appears to be used. That is when monitoring the GPU usage only one GPU shows substantial dedicated GPU memory usage and GPU utility. \r\n\r\n**Describe the expected behavior**\r\nEach of the 4 GPUs should indicate that memory is being copied to the device and processed.\r\n\r\n**Code to reproduce the issue**\r\nWhile my issue arises with custom code using model.fit_generator, I was able to replicate the issue using model.fit with documentation code provided at https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/utils/multi_gpu_model\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras.applications import Xception\r\nfrom tensorflow.keras.utils import multi_gpu_model\r\nimport numpy as np\r\n\r\nnum_samples = 1000\r\nheight = 224\r\nwidth = 224\r\nnum_classes = 1000\r\n\r\n# Instantiate the base model (or \"template\" model).\r\n# We recommend doing this with under a CPU device scope,\r\n# so that the model's weights are hosted on CPU memory.\r\n# Otherwise they may end up hosted on a GPU, which would\r\n# complicate weight sharing.\r\nwith tf.device('/cpu:0'):\r\n    model = Xception(weights=None,\r\n                     input_shape=(height, width, 3),\r\n                     classes=num_classes)\r\n\r\n# Replicates the model on 8 GPUs.\r\n# This assumes that your machine has 8 available GPUs.\r\nparallel_model = multi_gpu_model(model, gpus=4) # gpus changed to 4\r\nparallel_model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\r\n\r\n# Generate dummy data.\r\nx = np.random.random((num_samples, height, width, 3))\r\ny = np.random.random((num_samples, num_classes))\r\n\r\nparallel_model.summary()\r\n# This `fit` call will be distributed on 8 GPUs.\r\n# Since the batch size is 256, each GPU will process 32 samples.\r\nparallel_model.fit(x, y, epochs=20, batch_size=16) #batch_sized changed to 16\r\n```\r\n\r\n", "comments": ["I have separately encountered the same issue as the OP. The load is distributed across all GPUs as expected with multi_gpu_model in TensorFlow1.13.1, but sits on 1 GPU in 2.0.\r\n\r\nBelow are screenshots of my nvidia-smi when running the above code with 1.13 and 2.0 respectively.\r\n\r\nHave I written custom code: No\r\nOS Platform and Distribution: Ubuntu 18.04\r\nTensorFlow installed from (source or binary): binary\r\nTensorFlow version (use command below): 1.13.1 and 2.0.0-beta1, both gpu\r\n            tensorflow-gpu==1.13.1\r\n            tensorflow-gpu==2.0.0-beta1\r\nPython version: 3.6\r\nCUDA/cuDNN version: CUDA: 10.0, cuDNN: 7.6\r\nGPU model and memory: 4x NVIDIA Tesla M60\r\n\r\nTensorflow 1.13.1:\r\n![tf_1](https://user-images.githubusercontent.com/35641527/60617662-cc05cc80-9d99-11e9-812b-592970181a31.png)\r\n\r\nTensorflow 2.0.0-beta1\r\n![tf_2](https://user-images.githubusercontent.com/35641527/60617668-cdcf9000-9d99-11e9-8514-8f26f546580a.png)\r\n", "Use distribute strategy for multi gpu training in tf2.0. As of now multi_gpu_model doesnot work when running in eager mode, which is default in tf2.0. Here is the code with necessary changes made\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras.applications import Xception\r\nimport numpy as np\r\n\r\nnum_samples = 1000\r\nheight = 224\r\nwidth = 224\r\nnum_classes = 1000\r\n\r\nstrategy = tf.distribute.MirroredStrategy()\r\nwith strategy.scope():\r\n    parallel_model = Xception(weights=None,\r\n                     input_shape=(height, width, 3),\r\n                     classes=num_classes)\r\n    parallel_model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\r\n\r\n# Generate dummy data.\r\nx = np.random.random((num_samples, height, width, 3))\r\ny = np.random.random((num_samples, num_classes))\r\n\r\nparallel_model.summary()\r\n# This `fit` call will be distributed on 8 GPUs.\r\n# Since the batch size is 256, each GPU will process 32 samples.\r\nparallel_model.fit(x, y, epochs=20, batch_size=16) #batch_sized changed to 16\r\n```", "Any plans or advise how to use multiple gpus with fit_generator method?\r\n\r\ntensorflow/python/keras/engine/training.py\", line 1157, in fit_generator\r\n    raise NotImplementedError('`fit_generator` is not supported for '\r\nNotImplementedError: `fit_generator` is not supported for models compiled with tf.distribute.Strategy.\r\n", "@IuriiZhakun  you can use the` tf.data.Dataset` api to create a train/validation dataset which can be used with the tf.keras.Model.fit method. `tf.data.Dataset.from_generator` is one the ways to achieve this.", "training gets stuck with multiple gpus at 100% utilization, after yielding few samples.\r\nthe same code works fine without MirroredStrategy.\r\nI guess I shall try training without keras fit method.\r\n@srihari-humbarwadi, thanks nevertheless!", "Thanks for the great suggestions! \r\n\r\nI am also using fit_generator with eager execution, though for me it was just easier to revert back to TF1.14 until multi_gpu_model gets fixed in TF2.0 eager mode", "Thanks @srihari-humbarwadi -- tf.distribute.Strategy would indeed be the recommendation. @mketcha , can you clarify what doesn't work when you try with MirrorStrategy? Do you have code to reproduce?", "Following @IuriiZhakun 's comment above:\r\n\r\n> Any plans or advise how to use multiple gpus with fit_generator method?\r\n> \r\n> tensorflow/python/keras/engine/training.py\", line 1157, in fit_generator\r\n> raise NotImplementedError('fit_generator is not supported for '\r\n> NotImplementedError: fit_generator is not supported for models compiled with tf.distribute.Strategy.\r\n\r\nI did not attempt the MirrorStrategy as I am also using fit_generator", "Thank you @srihari-humbarwadi. I was at least able to train the model, but I get an unfortunate error at the end about running out of data.\r\n\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10.0.18362 Build 18362\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0-beta1\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: 10.0/7.6.1\r\n- GPU model and memory: 2x MSI GeForce RTX 2080 Ti GAMING X TRIO (no NVlink)\r\n\r\nI used the same code that you used in your example except that I changed the batch_size to 64 and the number of epochs to 10:\r\n\r\n```\r\n# This `fit` call will be distributed on 2 GPUs.\r\n# Since the batch size is 64, each GPU will process 32 samples.\r\nparallel_model.fit(x, y, epochs=10, batch_size=64)\r\n```\r\n\r\nIt runs perfectly until the final epoch. It always ends with:\r\n\r\n```\r\nEpoch 8/10\r\n16/16 [==============================] - 5s 334ms/step - loss: 3590.6503\r\nEpoch 9/10\r\n16/16 [==============================] - 5s 332ms/step - loss: 3597.1092\r\nEpoch 10/10\r\n12/16 [=====================>........] - ETA: 1s - loss: 3603.6067\r\nW0723 14:30:47.582621   232 training_arrays.py:309] Your dataset ran out of data; \r\ninterrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` \r\nbatches (in this case, 160 batches). You may need to use the repeat() function when \r\nbuilding your dataset.\r\n12/16 [=====================>........] - ETA: 1s - loss: 3603.6067\r\n```\r\n\r\nThis is only an issue with MirroredStrategy. When I train on a single GPU, there is no issue.\r\n\r\nEdit: I'm getting this output too!\r\n\r\n```\r\n2019-07-23 16:52:04.173982: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\r\n         [[{{node IteratorGetNext_1}}]]\r\n         [[GroupCrossDeviceControlEdges_0/RMSprop/RMSprop/update_0/Const/_355]]\r\n2019-07-23 16:52:04.183310: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\r\n         [[{{node IteratorGetNext_1}}]]\r\n         [[Identity_1/_376]]\r\n2019-07-23 16:52:04.189139: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\r\n         [[{{node IteratorGetNext_1}}]]\r\n```\r\n\r\n**TEMPORARY SOLUTION:** I converted the numpy arrays to a tf Dataset and used .repeat() while providing the proper number of steps per epoch within fit:\r\n\r\n```\r\ntrain_dataset = tf.data.Dataset.from_tensor_slices((x, y))\r\n\r\nBATCH_SIZE = 64\r\nBUFFER_SIZE = 10000\r\n\r\ntrain_dataset = train_dataset.shuffle(BUFFER_SIZE).repeat().batch(BATCH_SIZE)\r\n\r\nif BUFFER_SIZE % BATCH_SIZE != 0:\r\n    parallel_steps = BUFFER_SIZE // BATCH_SIZE + 1\r\nelse:\r\n    parallel_steps = BUFFER_SIZE // BATCH_SIZE\r\n\r\n# This `fit` call will be distributed on 2 GPUs.\r\n# Since the batch size is 64, each GPU will process 32 samples.\r\nparallel_model.fit(train_dataset, epochs=10, steps_per_epoch = parallel_steps)\r\n```", "@mketcha You need to switch to ```tf.distribute.Strategy``` in this case. Closing this issue for now. Please reopen if have any further questions using ```tf.distribute.Strategy```. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30321\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30321\">No</a>\n", "> @IuriiZhakun you can use the` tf.data.Dataset` api to create a train/validation dataset which can be used with the tf.keras.Model.fit method. `tf.data.Dataset.from_generator` is one the ways to achieve this.\r\n\r\n@srihari-humbarwadi Thank you for the hint, can you provide a few lines of code, if possible connected to your previous code snippet? I am not advanced with tensorflow and can't bring fit_generator to work on distributed strategies.", "I am using TF 1.14 and my computer has two GPUs. I was reading above posts but was confused finally which of the methods should be used with all the changes mentioned above:\r\n\r\nMethod 1:\r\n```\r\nwith tf.device('/cpu:0'):\r\n    model = ...\r\nparallel_model = multi_gpu_model(model, gpus=2)\r\nparallel_model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\r\n\r\n```\r\n\r\nMethod 2:\r\n```\r\nstrategy = tf.distribute.MirroredStrategy()\r\nwith strategy.scope():\r\n    parallel_model = ...\r\n    parallel_model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\r\n\r\n```\r\n\r\n\r\n", "Using TF 2.0, one solution is to switch off eager execution, which is what prevents multi_gpu_model from working. This can be done as follows after importing tensorflow: \r\n```\r\nimport tensorflow as tf\r\ntf.compat.v1.disable_eager_execution()\r\n```", "When i use tf.distribute.MirroredStrategy() in TF2.0(stable) and there are three GPUs available(gpu_id: 1\u30012\u30013), there are four types of  GPUs utilization.\r\n\uff081\uff09\r\n![1](https://user-images.githubusercontent.com/27215307/68097274-18e8e380-fef1-11e9-8e81-fb79dd361ad7.png)\r\n\uff082\uff09\r\n![2](https://user-images.githubusercontent.com/27215307/68097281-21d9b500-fef1-11e9-91f1-878f71d28e39.png)\r\n\uff083\uff09\r\n![3](https://user-images.githubusercontent.com/27215307/68097282-2736ff80-fef1-11e9-8dc4-9f296b4e3747.png)\r\n\uff084\uff09\r\n![4](https://user-images.githubusercontent.com/27215307/68097284-2c944a00-fef1-11e9-847d-519facae5e07.png)\r\n\r\n **Is this normal?** @srihari-humbarwadi @IuriiZhakun \r\n\r\n\r\n\r\n", "Looks like your GPU's are not being kept busy by the input pipeline or the batch size is too small. Please follow this guide and go ahead and tune/ profile your data input pipeline!\nhttps://www.tensorflow.org/guide/data_performance", "As of December 2021, upgrading from tensorflow version 1.13.1 to tensorflow 2.0.0 and with reference from above mentioned solution, the following snippet change worked well.\r\n\r\n# Before\r\n\r\n```\r\navailable_gpus = len(K.tensorflow_backend._get_available_gpus())\r\n\r\nif available_gpus > 1:\r\n\tmodel_parallel = multi_gpu_model(model, gpus = available_gpus)\r\nelse:\r\n\tmodel_parallel = model\r\n```\r\n\r\n# After\r\n\r\n```\r\navailable_gpus = len(K.tensorflow_backend._get_available_gpus())\r\n\r\nif available_gpus > 1:\r\n    strategy = tf.distribute.MirroredStrategy()\r\n    with strategy.scope():\r\n        model_parallel = multi_gpu_model(model, gpus=available_gpus)\r\nelse:\r\n    model_parallel = model\r\n```", "@asifpatankar: thanks much men! I solved my problem in Tensorflow v2.0...."]}, {"number": 30320, "title": "Fix bug in GpuAtomicCasHelper", "body": "I happened to notice this as I was looking through the code. I don't think this code path is used for CUDA devices so I'm not sure how to test it, but it looks pretty clear to me that it's a bug.\r\n\r\ncc @nluehr ", "comments": []}, {"number": 30319, "title": "TensorFlow does not work without tcmalloc in some cases (boosted trees).", "body": "\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04.4\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: binary from pip\r\n- **TensorFlow version (use command below)**: v1.14.0-rc1-22-gaf24dc91b5 1.14.0\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: \r\n\r\n  1. launch jupyter notebook,\r\n  2. download tutorial from google colab (https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/estimators/boosted_trees.ipynb),\r\n  3. run the notebook.\r\n\r\n\r\n\r\n### Describe the problem\r\n\r\n\r\nHi, I'm currently learning TensorFlow from the tutorials of the TF site.\r\n\r\nBut, during exercise in the tutorial (https://www.tensorflow.org/tutorials/estimators/boosted_trees), I got a strange error.\r\n\r\nTensorFlow was constantly crashed with the code, although it was provided from official site. I tried both jupyter notebook and plain python code.\r\n\r\nSo I googled the problem a little bit, and found that there's a workaround (https://github.com/tensorflow/tensorflow/issues/6968), i.e.,\r\n\r\n```bash\r\nsudo apt install libtcmalloc-minimal4\r\nexport LD_PRELOAD=\"/usr/lib/libtcmalloc_minimal.so.4\"\r\n```\r\n\r\nAnd then the code worked flawlessly.\r\n\r\nHowever, this leaves another questions, and these are what I really wonder;\r\n\r\n1. does this problem happen to some boundary cases like mine? Perhaps I am missing some configurations. I'll be glad to let me know.\r\n\r\n2. if not, that is, `tcmalloc` is necessary for the TensorFlow, and considering that `tcmalloc` is not distributed with the every default linux (for example, ubuntu) installations, might be there a better way to evade this situation?\r\n\r\n\r\n\r\n### Source code / logs\r\n\r\n\r\nBefore applying the `tcmalloc` package, jupyter kernel died with this message,\r\n\r\n```\r\nKernel Restarting\r\n\r\nThe kernel appears to have died. It will restart automatically.\r\n```\r\n\r\nHere is some snippet of the log message.\r\n\r\n\r\n```\r\n*** Error in `/home/sungjin/.virtualenvs/boost/bin/python3': malloc(): memory corruption (fast): 0x00007fe0e804d6d0 ***\r\n======= Backtrace: =========\r\n/lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7fe1f56097e5]\r\n```\r\n\r\n\r\n\r\n", "comments": ["@daisylab Will you be able to tell us in which function this issue encountered? I tried executing and i got error in `def make_inmemory_train_input_fn` saying `InvalidArgumentError: Retval[0] does not have value`. Thanks!", "In my case that was `est.train(train_input_fn, max_steps=100)`, which caused a memory allocation error. With `tcmalloc` package installed, it does not create problem, but in vanilla Ubuntu Linux without tcmalloc, I guess you can see the error.\r\n", "@daisylab Can you please try it against TF 1.13 as mentioned in the tutorial? Thanks!", "Tried it against TF 1.13 and it seems not working, same as in TF 1.14. Here is log file. \r\n\r\n```\r\nsungjin@gtx1080:~/tmp> mkvirtualenv tf-1.13          \r\nRunning virtualenv with interpreter /usr/bin/python3\r\nAlready using interpreter /usr/bin/python3\r\nUsing base prefix '/usr'\r\nNew python executable in /home/sungjin/.virtualenvs/tf-1.13/bin/python3\r\nAlso creating executable in /home/sungjin/.virtualenvs/tf-1.13/bin/python\r\nInstalling setuptools, pip, wheel...\r\ndone.\r\nvirtualenvwrapper.user_scripts creating /home/sungjin/.virtualenvs/tf-1.13/bin/predeactivate\r\nvirtualenvwrapper.user_scripts creating /home/sungjin/.virtualenvs/tf-1.13/bin/postdeactivate\r\nvirtualenvwrapper.user_scripts creating /home/sungjin/.virtualenvs/tf-1.13/bin/preactivate\r\nvirtualenvwrapper.user_scripts creating /home/sungjin/.virtualenvs/tf-1.13/bin/postactivate\r\nvirtualenvwrapper.user_scripts creating /home/sungjin/.virtualenvs/tf-1.13/bin/get_env_details\r\n\r\n\r\n\r\n(tf-1.13) sungjin@gtx1080:~/tmp> pip install tensorflow==1.13.1 pandas matplotlib\r\nCollecting tensorflow==1.13.1\r\n  Using cached https://files.pythonhosted.org/packages/ca/f2/0931c194bb98398017d52c94ee30e5e1a4082ab6af76e204856ff1fdb33e/tensorflow-1.13.1-cp35-cp35m-manylinux1_x86_64.whl\r\nCollecting pandas\r\n  Using cached https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl\r\nCollecting matplotlib\r\n  Using cached https://files.pythonhosted.org/packages/89/61/465fb3bfba684b0f53b5c4829c3c89e86e6fe9fdcdfda93e38f1788090f0/matplotlib-3.0.3-cp35-cp35m-manylinux1_x86_64.whl\r\nCollecting tensorflow-estimator<1.14.0rc0,>=1.13.0 (from tensorflow==1.13.1)\r\n  Using cached https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl\r\nCollecting termcolor>=1.1.0 (from tensorflow==1.13.1)\r\nCollecting absl-py>=0.1.6 (from tensorflow==1.13.1)\r\nCollecting grpcio>=1.8.6 (from tensorflow==1.13.1)\r\n  Using cached https://files.pythonhosted.org/packages/7e/8e/9e446349fc449951ecf3768070483ea88e76725cdd5bbddb9bc50f6948d4/grpcio-1.22.0-cp35-cp35m-manylinux1_x86_64.whl\r\nCollecting tensorboard<1.14.0,>=1.13.0 (from tensorflow==1.13.1)\r\n  Using cached https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl\r\nCollecting gast>=0.2.0 (from tensorflow==1.13.1)\r\nCollecting astor>=0.6.0 (from tensorflow==1.13.1)\r\n  Using cached https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\r\nCollecting protobuf>=3.6.1 (from tensorflow==1.13.1)\r\n  Using cached https://files.pythonhosted.org/packages/7c/d2/581ebc3c41879aca2c4fce5c37cdb8d779c4ea79109b6da7f640735ea0a2/protobuf-3.8.0-cp35-cp35m-manylinux1_x86_64.whl\r\nCollecting keras-preprocessing>=1.0.5 (from tensorflow==1.13.1)\r\n  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\r\nCollecting numpy>=1.13.3 (from tensorflow==1.13.1)\r\n  Using cached https://files.pythonhosted.org/packages/bb/ef/d5a21cbc094d3f4d5b5336494dbcc9550b70c766a8345513c7c24ed18418/numpy-1.16.4-cp35-cp35m-manylinux1_x86_64.whl\r\nCollecting six>=1.10.0 (from tensorflow==1.13.1)\r\n  Using cached https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\r\nCollecting keras-applications>=1.0.6 (from tensorflow==1.13.1)\r\n  Using cached https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl\r\nRequirement already satisfied: wheel>=0.26 in /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages (from tensorflow==1.13.1) (0.33.4)\r\nCollecting python-dateutil>=2.5.0 (from pandas)\r\n  Using cached https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl\r\nCollecting pytz>=2011k (from pandas)\r\n  Using cached https://files.pythonhosted.org/packages/3d/73/fe30c2daaaa0713420d0382b16fbb761409f532c56bdcc514bf7b6262bb6/pytz-2019.1-py2.py3-none-any.whl\r\nCollecting cycler>=0.10 (from matplotlib)\r\n  Using cached https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\r\nCollecting kiwisolver>=1.0.1 (from matplotlib)\r\n  Using cached https://files.pythonhosted.org/packages/ee/18/4cd2e84c6aff0c6a50479118083d20b9e676e5175a913c0ea76d700fc244/kiwisolver-1.1.0-cp35-cp35m-manylinux1_x86_64.whl\r\nCollecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib)\r\n  Using cached https://files.pythonhosted.org/packages/dd/d9/3ec19e966301a6e25769976999bd7bbe552016f0d32b577dc9d63d2e0c49/pyparsing-2.4.0-py2.py3-none-any.whl\r\nCollecting mock>=2.0.0 (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1)\r\n  Using cached https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\r\nCollecting markdown>=2.6.8 (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1)\r\n  Using cached https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl\r\nCollecting werkzeug>=0.11.15 (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1)\r\n  Using cached https://files.pythonhosted.org/packages/9f/57/92a497e38161ce40606c27a86759c6b92dd34fcdb33f64171ec559257c02/Werkzeug-0.15.4-py2.py3-none-any.whl\r\nRequirement already satisfied: setuptools in /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages (from protobuf>=3.6.1->tensorflow==1.13.1) (41.0.1)\r\nCollecting h5py (from keras-applications>=1.0.6->tensorflow==1.13.1)\r\n  Using cached https://files.pythonhosted.org/packages/4c/77/c4933e12dca0f61bcdafc207c7532e1250b8d12719459fd85132f3daa9fd/h5py-2.9.0-cp35-cp35m-manylinux1_x86_64.whl\r\nInstalling collected packages: six, absl-py, numpy, mock, tensorflow-estimator, termcolor, grpcio, protobuf, markdown, werkzeug, tensorboard, gast, astor, keras-preprocessing, h5py, keras-applications, tensorflow, python-dateutil, pytz, pandas, cycler, kiwisolver, pyparsing, matplotlib\r\nSuccessfully installed absl-py-0.7.1 astor-0.8.0 cycler-0.10.0 gast-0.2.2 grpcio-1.22.0 h5py-2.9.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 kiwisolver-1.1.0 markdown-3.1.1 matplotlib-3.0.3 mock-3.0.5 numpy-1.16.4 pandas-0.24.2 protobuf-3.8.0 pyparsing-2.4.0 python-dateutil-2.8.0 pytz-2019.1 six-1.12.0 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0 termcolor-1.1.0 werkzeug-0.15.4\r\n\r\n\r\n\r\n(tf-1.13) sungjin@gtx1080:~/tmp> python boosted.py   \r\nFeature value: \"Third\"\r\n2019-07-11 20:16:32.944625: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-07-11 20:16:32.948672: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3407925000 Hz\r\n2019-07-11 20:16:32.949138: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x4c050a0 executing computations on platform Host. Devices:\r\n2019-07-11 20:16:32.949152: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\r\nOne-hot encoded\"  [[0. 0. 1.]]\r\nAccuracy :  0.78409094\r\nDummy model :  0.625\r\n*** Error in `python': corrupted size vs. prev_size: 0x00007f2890018430 ***\r\n======= Backtrace: =========\r\n/lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f29736f17e5]\r\n/lib/x86_64-linux-gnu/libc.so.6(+0x7e9dc)[0x7f29736f89dc]\r\n/lib/x86_64-linux-gnu/libc.so.6(+0x81cde)[0x7f29736fbcde]\r\n/lib/x86_64-linux-gnu/libc.so.6(+0x82c0a)[0x7f29736fcc0a]\r\n/lib/x86_64-linux-gnu/libc.so.6(posix_memalign+0x11d)[0x7f297370171d]\r\n/home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(_ZN10tensorflow4port13AlignedMallocEmi+0x24)[0x7f2949c18794]\r\n/home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(+0x42689a)[0x7f29498d389a]\r\n/home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(+0x4c2e4d)[0x7f294996fe4d]\r\n/home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(_ZN10tensorflow6TensorC2EPNS_9AllocatorENS_8DataTypeERKNS_11TensorShapeERKNS_20AllocationAttributesE+0x81b)[0x7f294998187b]\r\n/home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(_ZN10tensorflow15OpKernelContext15allocate_tensorENS_8DataTypeERKNS_11TensorShapeEPNS_6TensorENS_19AllocatorAttributesERKNS_20AllocationAttributesE+0x84)[0x7f2949954344]\r\n/home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(_ZN10tensorflow15OpKernelContext15allocate_outputEiRKNS_11TensorShapeEPPNS_6TensorENS_19AllocatorAttributesE+0x71)[0x7f2949954801]\r\n/home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(_ZN10tensorflow15OpKernelContext15allocate_outputEiRKNS_11TensorShapeEPPNS_6TensorE+0xc5)[0x7f2949954945]\r\n/home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(_ZN10tensorflow15OpKernelContext15allocate_outputEN4absl11string_viewERKNS_11TensorShapeEPPNS_6TensorE+0x9b)[0x7f2949954a0b]\r\n/home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so(_ZN10tensorflow30BoostedTreesMakeStatsSummaryOp7ComputeEPNS_15OpKernelContextE+0x555)[0x7f294cda1555]\r\n/home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(+0x6cfe02)[0x7f2949b7ce02]\r\n/home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(+0x6c2970)[0x7f2949b6f970]\r\n/home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(_ZN5Eigen15ThreadPoolTemplIN10tensorflow6thread16EigenEnvironmentEE10WorkerLoopEi+0x306)[0x7f2949bee996]\r\n/home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(_ZNSt17_Function_handlerIFvvEZN10tensorflow6thread16EigenEnvironment12CreateThreadESt8functionIS0_EEUlvE_E9_M_invokeERKSt9_Any_data+0x44)[0x7f2949bed854]\r\n/usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xb8c80)[0x7f2955dedc80]\r\n/lib/x86_64-linux-gnu/libpthread.so.0(+0x76ba)[0x7f2973a4b6ba]\r\n/lib/x86_64-linux-gnu/libc.so.6(clone+0x6d)[0x7f297378141d]\r\n======= Memory map: ========\r\n00400000-007aa000 r-xp 00000000 103:01 19267643                          /home/sungjin/.virtualenvs/tf-1.13/bin/python3\r\n009a9000-009ab000 r--p 003a9000 103:01 19267643                          /home/sungjin/.virtualenvs/tf-1.13/bin/python3\r\n009ab000-00a42000 rw-p 003ab000 103:01 19267643                          /home/sungjin/.virtualenvs/tf-1.13/bin/python3\r\n00a42000-00a73000 rw-p 00000000 00:00 0 \r\n01a3e000-066e5000 rw-p 00000000 00:00 0                                  [heap]\r\n7f2840000000-7f2840084000 rw-p 00000000 00:00 0 \r\n7f2840084000-7f2844000000 ---p 00000000 00:00 0 \r\n7f2844000000-7f2844021000 rw-p 00000000 00:00 0 \r\n7f2844021000-7f2848000000 ---p 00000000 00:00 0 \r\n7f2848000000-7f2848021000 rw-p 00000000 00:00 0 \r\n7f2848021000-7f284c000000 ---p 00000000 00:00 0 \r\n7f284c000000-7f284c021000 rw-p 00000000 00:00 0 \r\n7f284c021000-7f2850000000 ---p 00000000 00:00 0 \r\n7f2850000000-7f2850021000 rw-p 00000000 00:00 0 \r\n7f2850021000-7f2854000000 ---p 00000000 00:00 0 \r\n7f2854000000-7f2854021000 rw-p 00000000 00:00 0 \r\n7f2854021000-7f2858000000 ---p 00000000 00:00 0 \r\n7f2858000000-7f2858021000 rw-p 00000000 00:00 0 \r\n7f2858021000-7f285c000000 ---p 00000000 00:00 0 \r\n7f285c000000-7f285c021000 rw-p 00000000 00:00 0 \r\n7f285c021000-7f2860000000 ---p 00000000 00:00 0 \r\n7f2860ffa000-7f2860ffb000 ---p 00000000 00:00 0 \r\n7f2860ffb000-7f28617fb000 rw-p 00000000 00:00 0 \r\n7f2861ffc000-7f2861ffd000 ---p 00000000 00:00 0 \r\n7f2861ffd000-7f28627fd000 rw-p 00000000 00:00 0 \r\n7f2862ffe000-7f2862fff000 ---p 00000000 00:00 0 \r\n7f2862fff000-7f28637ff000 rw-p 00000000 00:00 0 \r\n7f2864000000-7f2864021000 rw-p 00000000 00:00 0 \r\n7f2864021000-7f2868000000 ---p 00000000 00:00 0 \r\n7f2868000000-7f2868021000 rw-p 00000000 00:00 0 \r\n7f2868021000-7f286c000000 ---p 00000000 00:00 0 \r\n7f286c000000-7f286c021000 rw-p 00000000 00:00 0 \r\n7f286c021000-7f2870000000 ---p 00000000 00:00 0 \r\n7f2870000000-7f2870077000 rw-p 00000000 00:00 0 \r\n7f2870077000-7f2874000000 ---p 00000000 00:00 0 \r\n7f2874000000-7f2874021000 rw-p 00000000 00:00 0 \r\n7f2874021000-7f2878000000 ---p 00000000 00:00 0 \r\n7f2879ffc000-7f2879ffd000 ---p 00000000 00:00 0 \r\n7f2879ffd000-7f287a7fd000 rw-p 00000000 00:00 0 \r\n7f287c000000-7f287c2c7000 rw-p 00000000 00:00 0 \r\n7f287c2c7000-7f2880000000 ---p 00000000 00:00 0 \r\n7f2880000000-7f28802c4000 rw-p 00000000 00:00 0 \r\n7f28802c4000-7f2884000000 ---p 00000000 00:00 0 \r\n7f2884000000-7f2884056000 rw-p 00000000 00:00 0 \r\n7f2884056000-7f2888000000 ---p 00000000 00:00 0 \r\n7f2888000000-7f2888806000 rw-p 00000000 00:00 0 \r\n7f2888806000-7f288c000000 ---p 00000000 00:00 0 \r\n7f288c000000-7f288c06a000 rw-p 00000000 00:00 0 \r\n7f288c06a000-7f2890000000 ---p 00000000 00:00 0 \r\n7f2890000000-7f2890849000 rw-p 00000000 00:00 0 \r\n7f2890849000-7f2894000000 ---p 00000000 00:00 0 \r\n7f2894000000-7f2894078000 rw-p 00000000 00:00 0 \r\n7f2894078000-7f2898000000 ---p 00000000 00:00 0 \r\n7f2898000000-7f2898806000 rw-p 00000000 00:00 0 \r\n7f2898806000-7f289c000000 ---p 00000000 00:00 0 \r\n7f289c000000-7f289c05f000 rw-p 00000000 00:00 0 \r\n7f289c05f000-7f28a0000000 ---p 00000000 00:00 0 \r\n7f28a0000000-7f28a0047000 rw-p 00000000 00:00 0 \r\n7f28a0047000-7f28a4000000 ---p 00000000 00:00 0 \r\n7f28a57fb000-7f28a57fc000 ---p 00000000 00:00 0 \r\n7f28a57fc000-7f28a5ffc000 rw-p 00000000 00:00 0 \r\n7f28a5ffc000-7f28a5ffd000 ---p 00000000 00:00 0 \r\n7f28a5ffd000-7f28a67fd000 rw-p 00000000 00:00 0 \r\n7f28a67fd000-7f28a67fe000 ---p 00000000 00:00 0 \r\n7f28a67fe000-7f28a6ffe000 rw-p 00000000 00:00 0 \r\n7f28a6ffe000-7f28a6fff000 ---p 00000000 00:00 0 \r\n7f28a6fff000-7f28a77ff000 rw-p 00000000 00:00 0 \r\n7f28a77ff000-7f28a7800000 ---p 00000000 00:00 0 \r\n7f28a7800000-7f28a8000000 rw-p 00000000 00:00 0 \r\n7f28a8000000-7f28a8021000 rw-p 00000000 00:00 0 \r\n7f28a8021000-7f28ac000000 ---p 00000000 00:00 0 \r\n7f28ac000000-7f28ac021000 rw-p 00000000 00:00 0 \r\n7f28ac021000-7f28b0000000 ---p 00000000 00:00 0 \r\n7f28b0000000-7f28b00cc000 rw-p 00000000 00:00 0 \r\n7f28b00cc000-7f28b4000000 ---p 00000000 00:00 0 \r\n7f28b47f9000-7f28b47fa000 ---p 00000000 00:00 0 \r\n7f28b47fa000-7f28b4ffa000 rw-p 00000000 00:00 0 \r\n7f28b4ffa000-7f28b4ffb000 ---p 00000000 00:00 0 \r\n7f28b4ffb000-7f28b57fb000 rw-p 00000000 00:00 0 \r\n7f28b57fb000-7f28b57fc000 ---p 00000000 00:00 0 \r\n7f28b57fc000-7f28b5ffc000 rw-p 00000000 00:00 0 \r\n7f28b5ffc000-7f28b5ffd000 ---p 00000000 00:00 0 \r\n7f28b5ffd000-7f28b67fd000 rw-p 00000000 00:00 0 \r\n7f28b67fd000-7f28b67fe000 ---p 00000000 00:00 0 \r\n7f28b67fe000-7f28b6ffe000 rw-p 00000000 00:00 0 \r\n7f28b6ffe000-7f28b6fff000 ---p 00000000 00:00 0 \r\n7f28b6fff000-7f28b77ff000 rw-p 00000000 00:00 0 \r\n7f28b77ff000-7f28b7800000 ---p 00000000 00:00 0 \r\n7f28b7800000-7f28b8000000 rw-p 00000000 00:00 0 \r\n7f28b8000000-7f28b8021000 rw-p 00000000 00:00 0 \r\n7f28b8021000-7f28bc000000 ---p 00000000 00:00 0 \r\n7f28bc000000-7f28bc115000 rw-p 00000000 00:00 0 \r\n7f28bc115000-7f28c0000000 ---p 00000000 00:00 0 \r\n7f28c0000000-7f28c0021000 rw-p 00000000 00:00 0 \r\n7f28c0021000-7f28c4000000 ---p 00000000 00:00 0 \r\n7f28c4000000-7f28c4021000 rw-p 00000000 00:00 0 \r\n7f28c4021000-7f28c8000000 ---p 00000000 00:00 0 \r\n7f28c8000000-7f28c8021000 rw-p 00000000 00:00 0 \r\n7f28c8021000-7f28cc000000 ---p 00000000 00:00 0 \r\n7f28cc000000-7f28cc021000 rw-p 00000000 00:00 0 \r\n7f28cc021000-7f28d0000000 ---p 00000000 00:00 0 \r\n7f28d0000000-7f28d0021000 rw-p 00000000 00:00 0 \r\n7f28d0021000-7f28d4000000 ---p 00000000 00:00 0 \r\n7f28d4000000-7f28d4021000 rw-p 00000000 00:00 0 \r\n7f28d4021000-7f28d8000000 ---p 00000000 00:00 0 \r\n7f28d8000000-7f28d8021000 rw-p 00000000 00:00 0 \r\n7f28d8021000-7f28dc000000 ---p 00000000 00:00 0 \r\n7f28dc000000-7f28dc021000 rw-p 00000000 00:00 0 \r\n7f28dc021000-7f28e0000000 ---p 00000000 00:00 0 \r\n7f28e0000000-7f28e0021000 rw-p 00000000 00:00 0 \r\n7f28e0021000-7f28e4000000 ---p 00000000 00:00 0 \r\n7f28e4000000-7f28e4021000 rw-p 00000000 00:00 0 \r\n7f28e4021000-7f28e8000000 ---p 00000000 00:00 0 \r\n7f28e8000000-7f28e8021000 rw-p 00000000 00:00 0 \r\n7f28e8021000-7f28ec000000 ---p 00000000 00:00 0 \r\n7f28ec000000-7f28ec021000 rw-p 00000000 00:00 0 \r\n7f28ec021000-7f28f0000000 ---p 00000000 00:00 0 \r\n7f28f0000000-7f28f0021000 rw-p 00000000 00:00 0 \r\n7f28f0021000-7f28f4000000 ---p 00000000 00:00 0 \r\n7f28f47f9000-7f28f47fa000 ---p 00000000 00:00 0 \r\n7f28f47fa000-7f28f4ffa000 rw-p 00000000 00:00 0 \r\n7f28f4ffa000-7f28f4ffb000 ---p 00000000 00:00 0 \r\n7f28f4ffb000-7f28f57fb000 rw-p 00000000 00:00 0 \r\n7f28f57fb000-7f28f57fc000 ---p 00000000 00:00 0 \r\n7f28f57fc000-7f28f5ffc000 rw-p 00000000 00:00 0 \r\n7f28f5ffc000-7f28f5ffd000 ---p 00000000 00:00 0 \r\n7f28f5ffd000-7f28f67fd000 rw-p 00000000 00:00 0 \r\n7f28f67fd000-7f28f67fe000 ---p 00000000 00:00 0 \r\n7f28f67fe000-7f28f6ffe000 rw-p 00000000 00:00 0 \r\n7f28f6ffe000-7f28f6fff000 ---p 00000000 00:00 0 \r\n7f28f6fff000-7f28f77ff000 rw-p 00000000 00:00 0 \r\n7f28f77ff000-7f28f7800000 ---p 00000000 00:00 0 \r\n7f28f7800000-7f28f8000000 rw-p 00000000 00:00 0 \r\n7f28f8000000-7f28f8021000 rw-p 00000000 00:00 0 \r\n7f28f8021000-7f28fc000000 ---p 00000000 00:00 0 \r\n7f28fc379000-7f28fc739000 rw-p 00000000 00:00 0 \r\n7f28fc7f9000-7f28fc7fa000 ---p 00000000 00:00 0 \r\n7f28fc7fa000-7f28fcffa000 rw-p 00000000 00:00 0 \r\n7f28fcffa000-7f28fcffb000 ---p 00000000 00:00 0 \r\n7f28fcffb000-7f28fd7fb000 rw-p 00000000 00:00 0 \r\n7f28fd7fb000-7f28fd7fc000 ---p 00000000 00:00 0 \r\n7f28fd7fc000-7f28fdffc000 rw-p 00000000 00:00 0 \r\n7f28fdffc000-7f28fdffd000 ---p 00000000 00:00 0 \r\n7f28fdffd000-7f28fe7fd000 rw-p 00000000 00:00 0 \r\n7f28fe7fd000-7f28fe7fe000 ---p 00000000 00:00 0 \r\n7f28fe7fe000-7f28feffe000 rw-p 00000000 00:00 0 \r\n7f28feffe000-7f28fefff000 ---p 00000000 00:00 0 \r\n7f28fefff000-7f28ff7ff000 rw-p 00000000 00:00 0 \r\n7f28ff7ff000-7f28ff800000 ---p 00000000 00:00 0 \r\n7f28ff800000-7f2900000000 rw-p 00000000 00:00 0 \r\n7f2900000000-7f2900021000 rw-p 00000000 00:00 0 \r\n7f2900021000-7f2904000000 ---p 00000000 00:00 0 \r\n7f2904000000-7f2904021000 rw-p 00000000 00:00 0 \r\n7f2904021000-7f2908000000 ---p 00000000 00:00 0 \r\n7f2908000000-7f2908021000 rw-p 00000000 00:00 0 \r\n7f2908021000-7f290c000000 ---p 00000000 00:00 0 \r\n7f290c000000-7f290c021000 rw-p 00000000 00:00 0 \r\n7f290c021000-7f2910000000 ---p 00000000 00:00 0 \r\n7f2910000000-7f2910021000 rw-p 00000000 00:00 0 \r\n7f2910021000-7f2914000000 ---p 00000000 00:00 0 \r\n7f2914000000-7f2914021000 rw-p 00000000 00:00 0 \r\n7f2914021000-7f2918000000 ---p 00000000 00:00 0 \r\n7f2918000000-7f2918021000 rw-p 00000000 00:00 0 \r\n7f2918021000-7f291c000000 ---p 00000000 00:00 0 \r\n7f291c3b9000-7f291c7f9000 rw-p 00000000 00:00 0 \r\n7f291c7f9000-7f291c7fa000 ---p 00000000 00:00 0 \r\n7f291c7fa000-7f291cffa000 rw-p 00000000 00:00 0 \r\n7f291cffa000-7f291cffb000 ---p 00000000 00:00 0 \r\n7f291cffb000-7f291d7fb000 rw-p 00000000 00:00 0 \r\n7f291d7fb000-7f291d7fc000 ---p 00000000 00:00 0 \r\n7f291d7fc000-7f291dffc000 rw-p 00000000 00:00 0 \r\n7f291dffc000-7f291dffd000 ---p 00000000 00:00 0 \r\n7f291dffd000-7f291e7fd000 rw-p 00000000 00:00 0 \r\n7f291e7fd000-7f291e7fe000 ---p 00000000 00:00 0 \r\n7f291e7fe000-7f291effe000 rw-p 00000000 00:00 0 \r\n7f291effe000-7f291efff000 ---p 00000000 00:00 0 \r\n7f291efff000-7f291f7ff000 rw-p 00000000 00:00 0 \r\n7f291f7ff000-7f291f800000 ---p 00000000 00:00 0 \r\n7f291f800000-7f2920000000 rw-p 00000000 00:00 0 \r\n7f2920000000-7f2920021000 rw-p 00000000 00:00 0 \r\n7f2920021000-7f2924000000 ---p 00000000 00:00 0 \r\n7f2924000000-7f2924021000 rw-p 00000000 00:00 0 \r\n7f2924021000-7f2928000000 ---p 00000000 00:00 0 \r\n7f2928000000-7f2928021000 rw-p 00000000 00:00 0 \r\n7f2928021000-7f292c000000 ---p 00000000 00:00 0 \r\n7f292c000000-7f292c021000 rw-p 00000000 00:00 0 \r\n7f292c021000-7f2930000000 ---p 00000000 00:00 0 \r\n7f2930000000-7f2930021000 rw-p 00000000 00:00 0 \r\n7f2930021000-7f2934000000 ---p 00000000 00:00 0 \r\n7f2934000000-7f2934021000 rw-p 00000000 00:00 0 \r\n7f2934021000-7f2938000000 ---p 00000000 00:00 0 \r\n7f2938032000-7f29381b2000 rw-p 00000000 00:00 0 \r\n7f29381f2000-7f29384f2000 rw-p 00000000 00:00 0 \r\n7f29384f2000-7f29384f3000 ---p 00000000 00:00 0 \r\n7f29384f3000-7f2938cf3000 rw-p 00000000 00:00 0 \r\n7f2938cf3000-7f2938cf4000 ---p 00000000 00:00 0 \r\n7f2938cf4000-7f29394f4000 rw-p 00000000 00:00 0 \r\n7f29394f4000-7f29394f5000 ---p 00000000 00:00 0 \r\n7f29394f5000-7f2939cf5000 rw-p 00000000 00:00 0 \r\n7f2939cf5000-7f2939cf6000 ---p 00000000 00:00 0 \r\n7f2939cf6000-7f293a4f6000 rw-p 00000000 00:00 0 \r\n7f293a4f6000-7f293a4f7000 ---p 00000000 00:00 0 \r\n7f293a4f7000-7f293acf7000 rw-p 00000000 00:00 0 \r\n7f293acf7000-7f293acf8000 ---p 00000000 00:00 0 \r\n7f293acf8000-7f293b4f8000 rw-p 00000000 00:00 0 \r\n7f293b4f8000-7f293b4f9000 ---p 00000000 00:00 0 \r\n7f293b4f9000-7f293bcf9000 rw-p 00000000 00:00 0 \r\n7f293bcf9000-7f293bcfa000 ---p 00000000 00:00 0 \r\n7f293bcfa000-7f293c5fa000 rw-p 00000000 00:00 0 \r\n7f293c5fa000-7f293e5fa000 rw-p 00000000 00:00 0 \r\n7f293e5fa000-7f293e5fb000 ---p 00000000 00:00 0 \r\n7f293e5fb000-7f293edfb000 rw-p 00000000 00:00 0 \r\n7f293edfb000-7f293edfc000 ---p 00000000 00:00 0 \r\n7f293edfc000-7f293f5fc000 rw-p 00000000 00:00 0 \r\n7f293f5fc000-7f293f5fd000 ---p 00000000 00:00 0 \r\n7f293f5fd000-7f293fe7d000 rw-p 00000000 00:00 0 \r\n7f293fe7d000-7f293fe94000 r-xp 00000000 fc:00 10616881                   /lib/x86_64-linux-gnu/libresolv-2.23.so\r\n7f293fe94000-7f2940094000 ---p 00017000 fc:00 10616881                   /lib/x86_64-linux-gnu/libresolv-2.23.so\r\n7f2940094000-7f2940095000 r--p 00017000 fc:00 10616881                   /lib/x86_64-linux-gnu/libresolv-2.23.so\r\n7f2940095000-7f2940096000 rw-p 00018000 fc:00 10616881                   /lib/x86_64-linux-gnu/libresolv-2.23.so\r\n7f2940096000-7f2940098000 rw-p 00000000 00:00 0 \r\n7f2940098000-7f294009d000 r-xp 00000000 fc:00 10616902                   /lib/x86_64-linux-gnu/libnss_dns-2.23.so\r\n7f294009d000-7f294029d000 ---p 00005000 fc:00 10616902                   /lib/x86_64-linux-gnu/libnss_dns-2.23.so\r\n7f294029d000-7f294029e000 r--p 00005000 fc:00 10616902                   /lib/x86_64-linux-gnu/libnss_dns-2.23.so\r\n7f294029e000-7f294029f000 rw-p 00006000 fc:00 10616902                   /lib/x86_64-linux-gnu/libnss_dns-2.23.so\r\n7f294029f000-7f29402a1000 r-xp 00000000 fc:00 10623753                   /lib/x86_64-linux-gnu/libnss_mdns4_minimal.so.2\r\n7f29402a1000-7f29404a0000 ---p 00002000 fc:00 10623753                   /lib/x86_64-linux-gnu/libnss_mdns4_minimal.so.2\r\n7f29404a0000-7f29404a1000 r--p 00001000 fc:00 10623753                   /lib/x86_64-linux-gnu/libnss_mdns4_minimal.so.2\r\n7f29404a1000-7f29404a2000 rw-p 00002000 fc:00 10623753                   /lib/x86_64-linux-gnu/libnss_mdns4_minimal.so.2\r\n7f29404a2000-7f29404ad000 r-xp 00000000 fc:00 10616908                   /lib/x86_64-linux-gnu/libnss_files-2.23.so\r\n7f29404ad000-7f29406ac000 ---p 0000b000 fc:00 10616908                   /lib/x86_64-linux-gnu/libnss_files-2.23.so\r\n7f29406ac000-7f29406ad000 r--p 0000a000 fc:00 10616908                   /lib/x86_64-linux-gnu/libnss_files-2.23.so\r\n7f29406ad000-7f29406ae000 rw-p 0000b000 fc:00 10616908                   /lib/x86_64-linux-gnu/libnss_files-2.23.so\r\n7f29406ae000-7f29406f4000 rw-p 00000000 00:00 0 \r\n7f29406f4000-7f29406fb000 r-xp 00000000 103:01 20846128                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/backends/_tkagg.cpython-35m-x86_64-linux-gnu.so\r\n7f29406fb000-7f29408fa000 ---p 00007000 103:01 20846128                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/backends/_tkagg.cpython-35m-x86_64-linux-gnu.so\r\n7f29408fa000-7f29408fb000 rw-p 00006000 103:01 20846128                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/backends/_tkagg.cpython-35m-x86_64-linux-gnu.so\r\n7f29408fb000-7f29408fc000 rw-p 00000000 00:00 0 \r\n7f29408fc000-7f2940920000 r-xp 00000000 fc:00 10627159                   /lib/x86_64-linux-gnu/libpng12.so.0.54.0\r\n7f2940920000-7f2940b1f000 ---p 00024000 fc:00 10627159                   /lib/x86_64-linux-gnu/libpng12.so.0.54.0\r\n7f2940b1f000-7f2940b20000 r--p 00023000 fc:00 10627159                   /lib/x86_64-linux-gnu/libpng12.so.0.54.0\r\n7f2940b20000-7f2940b21000 rw-p 00024000 fc:00 10627159                   /lib/x86_64-linux-gnu/libpng12.so.0.54.0\r\n7f2940b21000-7f2940b26000 r-xp 00000000 fc:00 2758324                    /usr/lib/x86_64-linux-gnu/libXdmcp.so.6.0.0\r\n7f2940b26000-7f2940d25000 ---p 00005000 fc:00 2758324                    /usr/lib/x86_64-linux-gnu/libXdmcp.so.6.0.0\r\n7f2940d25000-7f2940d26000 r--p 00004000 fc:00 2758324                    /usr/lib/x86_64-linux-gnu/libXdmcp.so.6.0.0\r\n7f2940d26000-7f2940d27000 rw-p 00005000 fc:00 2758324                    /usr/lib/x86_64-linux-gnu/libXdmcp.so.6.0.0\r\n7f2940d27000-7f2940d29000 r-xp 00000000 fc:00 2758322                    /usr/lib/x86_64-linux-gnu/libXau.so.6.0.0\r\n7f2940d29000-7f2940f29000 ---p 00002000 fc:00 2758322                    /usr/lib/x86_64-linux-gnu/libXau.so.6.0.0\r\n7f2940f29000-7f2940f2a000 r--p 00002000 fc:00 2758322                    /usr/lib/x86_64-linux-gnu/libXau.so.6.0.0\r\n7f2940f2a000-7f2940f2b000 rw-p 00003000 fc:00 2758322                    /usr/lib/x86_64-linux-gnu/libXau.so.6.0.0\r\n7f2940f2b000-7f2940f3c000 r-xp 00000000 fc:00 2758335                    /usr/lib/x86_64-linux-gnu/libXext.so.6.4.0\r\n7f2940f3c000-7f294113b000 ---p 00011000 fc:00 2758335                    /usr/lib/x86_64-linux-gnu/libXext.so.6.4.0\r\n7f294113b000-7f294113c000 r--p 00010000 fc:00 2758335                    /usr/lib/x86_64-linux-gnu/libXext.so.6.4.0\r\n7f294113c000-7f294113d000 rw-p 00011000 fc:00 2758335                    /usr/lib/x86_64-linux-gnu/libXext.so.6.4.0\r\n7f294113d000-7f2941146000 r-xp 00000000 fc:00 2756338                    /usr/lib/x86_64-linux-gnu/libXrender.so.1.3.0\r\n7f2941146000-7f2941345000 ---p 00009000 fc:00 2756338                    /usr/lib/x86_64-linux-gnu/libXrender.so.1.3.0\r\n7f2941345000-7f2941346000 r--p 00008000 fc:00 2756338                    /usr/lib/x86_64-linux-gnu/libXrender.so.1.3.0\r\n7f2941346000-7f2941347000 rw-p 00009000 fc:00 2756338                    /usr/lib/x86_64-linux-gnu/libXrender.so.1.3.0\r\n7f2941347000-7f29413eb000 r-xp 00000000 fc:00 2752590                    /usr/lib/x86_64-linux-gnu/libfreetype.so.6.12.1\r\n7f29413eb000-7f29415ea000 ---p 000a4000 fc:00 2752590                    /usr/lib/x86_64-linux-gnu/libfreetype.so.6.12.1\r\n7f29415ea000-7f29415f0000 r--p 000a3000 fc:00 2752590                    /usr/lib/x86_64-linux-gnu/libfreetype.so.6.12.1\r\n7f29415f0000-7f29415f1000 rw-p 000a9000 fc:00 2752590                    /usr/lib/x86_64-linux-gnu/libfreetype.so.6.12.1\r\n7f29415f1000-7f2941612000 r-xp 00000000 fc:00 2758326                    /usr/lib/x86_64-linux-gnu/libxcb.so.1.1.0\r\n7f2941612000-7f2941811000 ---p 00021000 fc:00 2758326                    /usr/lib/x86_64-linux-gnu/libxcb.so.1.1.0\r\n7f2941811000-7f2941812000 r--p 00020000 fc:00 2758326                    /usr/lib/x86_64-linux-gnu/libxcb.so.1.1.0\r\n7f2941812000-7f2941813000 rw-p 00021000 fc:00 2758326                    /usr/lib/x86_64-linux-gnu/libxcb.so.1.1.0\r\n7f2941813000-7f2941815000 r-xp 00000000 fc:00 2755469                    /usr/lib/x86_64-linux-gnu/libXss.so.1.0.0\r\n7f2941815000-7f2941a15000 ---p 00002000 fc:00 2755469                    /usr/lib/x86_64-linux-gnu/libXss.so.1.0.0\r\n7f2941a15000-7f2941a16000 r--p 00002000 fc:00 2755469                    /usr/lib/x86_64-linux-gnu/libXss.so.1.0.0\r\n7f2941a16000-7f2941a17000 rw-p 00003000 fc:00 2755469                    /usr/lib/x86_64-linux-gnu/libXss.so.1.0.0\r\n7f2941a17000-7f2941a54000 r-xp 00000000 fc:00 2756301                    /usr/lib/x86_64-linux-gnu/libfontconfig.so.1.9.0\r\n7f2941a54000-7f2941c53000 ---p 0003d000 fc:00 2756301                    /usr/lib/x86_64-linux-gnu/libfontconfig.so.1.9.0\r\n7f2941c53000-7f2941c55000 r--p 0003c000 fc:00 2756301                    /usr/lib/x86_64-linux-gnu/libfontconfig.so.1.9.0\r\n7f2941c55000-7f2941c5a000 rw-p 0003e000 fc:00 2756301                    /usr/lib/x86_64-linux-gnu/libfontconfig.so.1.9.0\r\n7f2941c5a000-7f2941c6e000 r-xp 00000000 fc:00 2768132                    /usr/lib/x86_64-linux-gnu/libXft.so.2.3.2\r\n7f2941c6e000-7f2941e6d000 ---p 00014000 fc:00 2768132                    /usr/lib/x86_64-linux-gnu/libXft.so.2.3.2\r\n7f2941e6d000-7f2941e6e000 r--p 00013000 fc:00 2768132                    /usr/lib/x86_64-linux-gnu/libXft.so.2.3.2\r\n7f2941e6e000-7f2941e6f000 rw-p 00014000 fc:00 2768132                    /usr/lib/x86_64-linux-gnu/libXft.so.2.3.2\r\n7f2941e6f000-7f2941fa4000 r-xp 00000000 fc:00 2757424                    /usr/lib/x86_64-linux-gnu/libX11.so.6.3.0\r\n7f2941fa4000-7f29421a4000 ---p 00135000 fc:00 2757424                    /usr/lib/x86_64-linux-gnu/libX11.so.6.3.0\r\n7f29421a4000-7f29421a5000 r--p 00135000 fc:00 2757424                    /usr/lib/x86_64-linux-gnu/libX11.so.6.3.0\r\n7f29421a5000-7f29421a9000 rw-p 00136000 fc:00 2757424                    /usr/lib/x86_64-linux-gnu/libX11.so.6.3.0\r\n7f29421a9000-7f2942348000 r-xp 00000000 fc:00 2755471                    /usr/lib/x86_64-linux-gnu/libtcl8.6.so\r\n7f2942348000-7f2942548000 ---p 0019f000 fc:00 2755471                    /usr/lib/x86_64-linux-gnu/libtcl8.6.so\r\n7f2942548000-7f2942556000 r--p 0019f000 fc:00 2755471                    /usr/lib/x86_64-linux-gnu/libtcl8.6.so\r\n7f2942556000-7f2942557000 rw-p 001ad000 fc:00 2755471                    /usr/lib/x86_64-linux-gnu/libtcl8.6.so\r\n7f2942557000-7f2942558000 rw-p 00000000 00:00 0 \r\n7f2942558000-7f2942697000 r-xp 00000000 fc:00 2755473                    /usr/lib/x86_64-linux-gnu/libtk8.6.so\r\n7f2942697000-7f2942897000 ---p 0013f000 fc:00 2755473                    /usr/lib/x86_64-linux-gnu/libtk8.6.so\r\n7f2942897000-7f29428ac000 r--p 0013f000 fc:00 2755473                    /usr/lib/x86_64-linux-gnu/libtk8.6.so\r\n7f29428ac000-7f29428b5000 rw-p 00154000 fc:00 2755473                    /usr/lib/x86_64-linux-gnu/libtk8.6.so\r\n7f29428b5000-7f29429fc000 r-xp 00000000 fc:00 2755477                    /usr/lib/libBLT.2.5.so.8.6\r\n7f29429fc000-7f2942bfb000 ---p 00147000 fc:00 2755477                    /usr/lib/libBLT.2.5.so.8.6\r\n7f2942bfb000-7f2942bfc000 r--p 00146000 fc:00 2755477                    /usr/lib/libBLT.2.5.so.8.6\r\n7f2942bfc000-7f2942c1d000 rw-p 00147000 fc:00 2755477                    /usr/lib/libBLT.2.5.so.8.6\r\n7f2942c1d000-7f2942c1e000 rw-p 00000000 00:00 0 \r\n7f2942c1e000-7f2942c2b000 r-xp 00000000 fc:00 2755479                    /usr/lib/python3.5/lib-dynload/_tkinter.cpython-35m-x86_64-linux-gnu.so\r\n7f2942c2b000-7f2942e2a000 ---p 0000d000 fc:00 2755479                    /usr/lib/python3.5/lib-dynload/_tkinter.cpython-35m-x86_64-linux-gnu.so\r\n7f2942e2a000-7f2942e2b000 r--p 0000c000 fc:00 2755479                    /usr/lib/python3.5/lib-dynload/_tkinter.cpython-35m-x86_64-linux-gnu.so\r\n7f2942e2b000-7f2942e2d000 rw-p 0000d000 fc:00 2755479                    /usr/lib/python3.5/lib-dynload/_tkinter.cpython-35m-x86_64-linux-gnu.so\r\n7f2942e2d000-7f2942eed000 rw-p 00000000 00:00 0 \r\n7f2942eed000-7f2942f43000 r-xp 00000000 103:01 20846118                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/backends/_backend_agg.cpython-35m-x86_64-linux-gnu.so\r\n7f2942f43000-7f2943143000 ---p 00056000 103:01 20846118                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/backends/_backend_agg.cpython-35m-x86_64-linux-gnu.so\r\n7f2943143000-7f2943144000 rw-p 00056000 103:01 20846118                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/backends/_backend_agg.cpython-35m-x86_64-linux-gnu.so\r\n7f2943144000-7f2943205000 rw-p 00000000 00:00 0 \r\n7f2943205000-7f2943261000 r-xp 00000000 103:01 20845540                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/_qhull.cpython-35m-x86_64-linux-gnu.so\r\n7f2943261000-7f2943460000 ---p 0005c000 103:01 20845540                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/_qhull.cpython-35m-x86_64-linux-gnu.so\r\n7f2943460000-7f2943462000 rw-p 0005b000 103:01 20845540                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/_qhull.cpython-35m-x86_64-linux-gnu.so\r\n7f2943462000-7f2943464000 rw-p 00000000 00:00 0 \r\n7f2943464000-7f2943482000 r-xp 00000000 103:01 20845496                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/_tri.cpython-35m-x86_64-linux-gnu.so\r\n7f2943482000-7f2943682000 ---p 0001e000 103:01 20845496                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/_tri.cpython-35m-x86_64-linux-gnu.so\r\n7f2943682000-7f2943683000 rw-p 0001e000 103:01 20845496                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/_tri.cpython-35m-x86_64-linux-gnu.so\r\n7f2943683000-7f2943784000 rw-p 00000000 00:00 0 \r\n7f2943784000-7f29437be000 r-xp 00000000 103:01 20845514                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/_image.cpython-35m-x86_64-linux-gnu.so\r\n7f29437be000-7f29439be000 ---p 0003a000 103:01 20845514                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/_image.cpython-35m-x86_64-linux-gnu.so\r\n7f29439be000-7f29439bf000 rw-p 0003a000 103:01 20845514                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/_image.cpython-35m-x86_64-linux-gnu.so\r\n7f29439bf000-7f2943a80000 rw-p 00000000 00:00 0 \r\n7f2943a80000-7f2943abc000 r-xp 00000000 103:01 19271858                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/kiwisolver.cpython-35m-x86_64-linux-gnu.so\r\n7f2943abc000-7f2943cbb000 ---p 0003c000 103:01 19271858                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/kiwisolver.cpython-35m-x86_64-linux-gnu.so\r\n7f2943cbb000-7f2943cbe000 rw-p 0003b000 103:01 19271858                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/kiwisolver.cpython-35m-x86_64-linux-gnu.so\r\n7f2943cbe000-7f2943cfe000 rw-p 00000000 00:00 0 \r\n7f2943cfe000-7f2943d3d000 r-xp 00000000 103:01 20845735                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/.libs/libpng16-cfdb1654.so.16.21.0\r\n7f2943d3d000-7f2943f3c000 ---p 0003f000 103:01 20845735                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/.libs/libpng16-cfdb1654.so.16.21.0\r\n7f2943f3c000-7f2943f3d000 rw-p 0003e000 103:01 20845735                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/.libs/libpng16-cfdb1654.so.16.21.0\r\n7f2943f3d000-7f2943f41000 rw-p 00040000 103:01 20845735                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/.libs/libpng16-cfdb1654.so.16.21.0\r\n7f2943f41000-7f2943f4a000 r-xp 00000000 103:01 20845485                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/_png.cpython-35m-x86_64-linux-gnu.so\r\n7f2943f4a000-7f2944149000 ---p 00009000 103:01 20845485                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/_png.cpython-35m-x86_64-linux-gnu.so\r\n7f2944149000-7f294414a000 rw-p 00008000 103:01 20845485                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/_png.cpython-35m-x86_64-linux-gnu.so\r\n7f294414a000-7f294414c000 rw-p 0000a000 103:01 20845485                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/_png.cpython-35m-x86_64-linux-gnu.so\r\n7f294414c000-7f294424c000 rw-p 00000000 00:00 0 \r\n7f294424c000-7f2944320000 r-xp 00000000 103:01 20845491                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/ft2font.cpython-35m-x86_64-linux-gnu.so\r\n7f2944320000-7f294451f000 ---p 000d4000 103:01 20845491                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/ft2font.cpython-35m-x86_64-linux-gnu.so\r\n7f294451f000-7f2944526000 rw-p 000d3000 103:01 20845491                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/ft2font.cpython-35m-x86_64-linux-gnu.so\r\n7f2944526000-7f2944567000 rw-p 00000000 00:00 0 \r\n7f2944567000-7f294457d000 r-xp 00000000 103:01 20845538                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/_contour.cpython-35m-x86_64-linux-gnu.so\r\n7f294457d000-7f294477d000 ---p 00016000 103:01 20845538                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/_contour.cpython-35m-x86_64-linux-gnu.so\r\n7f294477d000-7f294477e000 rw-p 00016000 103:01 20845538                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/_contour.cpython-35m-x86_64-linux-gnu.so\r\n7f294477e000-7f2944eff000 rw-p 00000000 00:00 0 \r\n7f2944eff000-7f2944f15000 r-xp 00000000 103:01 19271148                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5l.cpython-35m-x86_64-linux-gnu.so\r\n7f2944f15000-7f2945115000 ---p 00016000 103:01 19271148                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5l.cpython-35m-x86_64-linux-gnu.so\r\n7f2945115000-7f294511b000 rw-p 00016000 103:01 19271148                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5l.cpython-35m-x86_64-linux-gnu.so\r\n7f294511b000-7f2945133000 r-xp 00000000 103:01 19271133                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5o.cpython-35m-x86_64-linux-gnu.so\r\n7f2945133000-7f2945333000 ---p 00018000 103:01 19271133                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5o.cpython-35m-x86_64-linux-gnu.so\r\n7f2945333000-7f294533a000 rw-p 00018000 103:01 19271133                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5o.cpython-35m-x86_64-linux-gnu.so\r\n7f294533a000-7f2945365000 r-xp 00000000 103:01 19271135                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5fd.cpython-35m-x86_64-linux-gnu.so\r\n7f2945365000-7f2945565000 ---p 0002b000 103:01 19271135                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5fd.cpython-35m-x86_64-linux-gnu.so\r\n7f2945565000-7f2945568000 rw-p 0002b000 103:01 19271135                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5fd.cpython-35m-x86_64-linux-gnu.so\r\n7f2945568000-7f2945569000 rw-p 00000000 00:00 0 \r\n7f2945569000-7f294556c000 rw-p 0002f000 103:01 19271135                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5fd.cpython-35m-x86_64-linux-gnu.so\r\n7f294556c000-7f2945577000 r-xp 00000000 103:01 19271131                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5i.cpython-35m-x86_64-linux-gnu.so\r\n7f2945577000-7f2945776000 ---p 0000b000 103:01 19271131                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5i.cpython-35m-x86_64-linux-gnu.so\r\n7f2945776000-7f294577b000 rw-p 0000a000 103:01 19271131                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5i.cpython-35m-x86_64-linux-gnu.so\r\n7f294577b000-7f29457a0000 r-xp 00000000 103:01 19271129                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5g.cpython-35m-x86_64-linux-gnu.so\r\n7f29457a0000-7f294599f000 ---p 00025000 103:01 19271129                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5g.cpython-35m-x86_64-linux-gnu.so\r\n7f294599f000-7f29459a3000 rw-p 00024000 103:01 19271129                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5g.cpython-35m-x86_64-linux-gnu.so\r\n7f29459a3000-7f29459a4000 rw-p 00000000 00:00 0 \r\n7f29459a4000-7f29459a6000 rw-p 00029000 103:01 19271129                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5g.cpython-35m-x86_64-linux-gnu.so\r\n7f29459a6000-7f29459c0000 r-xp 00000000 103:01 19271145                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5f.cpython-35m-x86_64-linux-gnu.so\r\n7f29459c0000-7f2945bbf000 ---p 0001a000 103:01 19271145                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5f.cpython-35m-x86_64-linux-gnu.so\r\n7f2945bbf000-7f2945bc3000 rw-p 00019000 103:01 19271145                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5f.cpython-35m-x86_64-linux-gnu.so\r\n7f2945bc3000-7f2945bc4000 rw-p 00000000 00:00 0 \r\n7f2945bc4000-7f2945bc7000 rw-p 0001e000 103:01 19271145                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5f.cpython-35m-x86_64-linux-gnu.so\r\n7f2945bc7000-7f2945bd7000 r-xp 00000000 103:01 19271140                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5ds.cpython-35m-x86_64-linux-gnu.so\r\n7f2945bd7000-7f2945dd7000 ---p 00010000 103:01 19271140                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5ds.cpython-35m-x86_64-linux-gnu.so\r\n7f2945dd7000-7f2945ddc000 rw-p 00010000 103:01 19271140                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5ds.cpython-35m-x86_64-linux-gnu.so\r\n7f2945ddc000-7f2945df6000 r-xp 00000000 103:01 19271144                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5d.cpython-35m-x86_64-linux-gnu.so\r\n7f2945df6000-7f2945ff6000 ---p 0001a000 103:01 19271144                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5d.cpython-35m-x86_64-linux-gnu.so\r\n7f2945ff6000-7f2945ffd000 rw-p 0001a000 103:01 19271144                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5d.cpython-35m-x86_64-linux-gnu.so\r\n7f2945ffd000-7f2946006000 r-xp 00000000 103:01 19271137                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/_proxy.cpython-35m-x86_64-linux-gnu.so\r\n7f2946006000-7f2946206000 ---p 00009000 103:01 19271137                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/_proxy.cpython-35m-x86_64-linux-gnu.so\r\n7f2946206000-7f2946207000 rw-p 00009000 103:01 19271137                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/_proxy.cpython-35m-x86_64-linux-gnu.so\r\n7f2946207000-7f2946209000 rw-p 0000b000 103:01 19271137                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/_proxy.cpython-35m-x86_64-linux-gnu.so\r\n7f2946209000-7f2946214000 r-xp 00000000 103:01 19271146                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5ac.cpython-35m-x86_64-linux-gnu.so\r\n7f2946214000-7f2946413000 ---p 0000b000 103:01 19271146                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5ac.cpython-35m-x86_64-linux-gnu.so\r\n7f2946413000-7f2946417000 rw-p 0000a000 103:01 19271146                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5ac.cpython-35m-x86_64-linux-gnu.so\r\n7f2946417000-7f2946464000 r-xp 00000000 103:01 19271141                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5p.cpython-35m-x86_64-linux-gnu.so\r\n7f2946464000-7f2946664000 ---p 0004d000 103:01 19271141                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5p.cpython-35m-x86_64-linux-gnu.so\r\n7f2946664000-7f294666e000 rw-p 0004d000 103:01 19271141                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5p.cpython-35m-x86_64-linux-gnu.so\r\n7f294666e000-7f2946670000 rw-p 00000000 00:00 0 \r\n7f2946670000-7f2946673000 rw-p 00058000 103:01 19271141                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5p.cpython-35m-x86_64-linux-gnu.so\r\n7f2946673000-7f294668a000 r-xp 00000000 103:01 19271143                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5s.cpython-35m-x86_64-linux-gnu.so\r\n7f294668a000-7f294688a000 ---p 00017000 103:01 19271143                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5s.cpython-35m-x86_64-linux-gnu.so\r\n7f294688a000-7f294688d000 rw-p 00017000 103:01 19271143                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5s.cpython-35m-x86_64-linux-gnu.so\r\n7f294688d000-7f294688e000 rw-p 00000000 00:00 0 \r\n7f294688e000-7f2946891000 rw-p 0001b000 103:01 19271143                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5s.cpython-35m-x86_64-linux-gnu.so\r\n7f2946891000-7f29468af000 r-xp 00000000 103:01 19271153                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5a.cpython-35m-x86_64-linux-gnu.so\r\n7f29468af000-7f2946aaf000 ---p 0001e000 103:01 19271153                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5a.cpython-35m-x86_64-linux-gnu.so\r\n7f2946aaf000-7f2946ab6000 rw-p 0001e000 103:01 19271153                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5a.cpython-35m-x86_64-linux-gnu.so\r\n7f2946ab6000-7f2946abe000 r-xp 00000000 103:01 19271150                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5z.cpython-35m-x86_64-linux-gnu.so\r\n7f2946abe000-7f2946cbe000 ---p 00008000 103:01 19271150                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5z.cpython-35m-x86_64-linux-gnu.so\r\n7f2946cbe000-7f2946cc2000 rw-p 00008000 103:01 19271150                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5z.cpython-35m-x86_64-linux-gnu.so\r\n7f2946cc2000-7f2946cd8000 r-xp 00000000 103:01 19271138                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5.cpython-35m-x86_64-linux-gnu.so\r\n7f2946cd8000-7f2946ed8000 ---p 00016000 103:01 19271138                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5.cpython-35m-x86_64-linux-gnu.so\r\n7f2946ed8000-7f2946ede000 rw-p 00016000 103:01 19271138                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5.cpython-35m-x86_64-linux-gnu.so\r\n7f2946ede000-7f2946ee7000 r-xp 00000000 103:01 19271151                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/utils.cpython-35m-x86_64-linux-gnu.so\r\n7f2946ee7000-7f29470e7000 ---p 00009000 103:01 19271151                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/utils.cpython-35m-x86_64-linux-gnu.so\r\n7f29470e7000-7f29470e8000 rw-p 00009000 103:01 19271151                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/utils.cpython-35m-x86_64-linux-gnu.so\r\n7f29470e8000-7f29470eb000 rw-p 0000b000 103:01 19271151                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/utils.cpython-35m-x86_64-linux-gnu.so\r\n7f29470eb000-7f2947158000 r-xp 00000000 103:01 19271147                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5t.cpython-35m-x86_64-linux-gnu.so\r\n7f2947158000-7f2947358000 ---p 0006d000 103:01 19271147                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5t.cpython-35m-x86_64-linux-gnu.so\r\n7f2947358000-7f2947362000 rw-p 0006d000 103:01 19271147                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5t.cpython-35m-x86_64-linux-gnu.so\r\n7f2947362000-7f2947364000 rw-p 00000000 00:00 0 \r\n7f2947364000-7f2947368000 rw-p 00078000 103:01 19271147                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5t.cpython-35m-x86_64-linux-gnu.so\r\n7f2947368000-7f294739b000 r-xp 00000000 103:01 19271154                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/defs.cpython-35m-x86_64-linux-gnu.so\r\n7f294739b000-7f294759a000 ---p 00033000 103:01 19271154                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/defs.cpython-35m-x86_64-linux-gnu.so\r\n7f294759a000-7f29475a3000 rw-p 00032000 103:01 19271154                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/defs.cpython-35m-x86_64-linux-gnu.so\r\n7f29475a3000-7f29475c1000 r-xp 00000000 103:01 19271134                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/_objects.cpython-35m-x86_64-linux-gnu.so\r\n7f29475c1000-7f29477c0000 ---p 0001e000 103:01 19271134                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/_objects.cpython-35m-x86_64-linux-gnu.so\r\n7f29477c0000-7f29477c3000 rw-p 0001d000 103:01 19271134                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/_objects.cpython-35m-x86_64-linux-gnu.so\r\n7f29477c3000-7f29477c4000 rw-p 00000000 00:00 0 \r\n7f29477c4000-7f29477c7000 rw-p 00021000 103:01 19271134                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/_objects.cpython-35m-x86_64-linux-gnu.so\r\n7f29477c7000-7f29477d3000 r-xp 00000000 103:01 19271132                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5r.cpython-35m-x86_64-linux-gnu.so\r\n7f29477d3000-7f29479d2000 ---p 0000c000 103:01 19271132                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5r.cpython-35m-x86_64-linux-gnu.so\r\n7f29479d2000-7f29479d5000 rw-p 0000b000 103:01 19271132                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5r.cpython-35m-x86_64-linux-gnu.so\r\n7f29479d5000-7f29479d8000 rw-p 0000f000 103:01 19271132                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/h5r.cpython-35m-x86_64-linux-gnu.so\r\n7f29479d8000-7f29479ea000 r-xp 00000000 103:01 19271130                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/_conv.cpython-35m-x86_64-linux-gnu.so\r\n7f29479ea000-7f2947bea000 ---p 00012000 103:01 19271130                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/_conv.cpython-35m-x86_64-linux-gnu.so\r\n7f2947bea000-7f2947beb000 rw-p 00012000 103:01 19271130                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/_conv.cpython-35m-x86_64-linux-gnu.so\r\n7f2947beb000-7f2947bee000 rw-p 00014000 103:01 19271130                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/_conv.cpython-35m-x86_64-linux-gnu.so\r\n7f2947bee000-7f2947c02000 r-xp 00000000 103:01 19271233                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/.libs/libz-a147dcb0.so.1.2.3\r\n7f2947c02000-7f2947e01000 ---p 00014000 103:01 19271233                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/.libs/libz-a147dcb0.so.1.2.3\r\n7f2947e01000-7f2947e02000 rw-p 00013000 103:01 19271233                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/.libs/libz-a147dcb0.so.1.2.3\r\n7f2947e02000-7f2947e03000 rw-p 00015000 103:01 19271233                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/.libs/libz-a147dcb0.so.1.2.3\r\n7f2947e03000-7f2947e0b000 r-xp 00000000 103:01 19271234                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/.libs/libaec-2147abcd.so.0.0.4\r\n7f2947e0b000-7f294800a000 ---p 00008000 103:01 19271234                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/.libs/libaec-2147abcd.so.0.0.4\r\n7f294800a000-7f294800b000 rw-p 00007000 103:01 19271234                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/.libs/libaec-2147abcd.so.0.0.4\r\n7f294800b000-7f294800c000 rw-p 00009000 103:01 19271234                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/.libs/libaec-2147abcd.so.0.0.4\r\n7f294800c000-7f294800e000 r-xp 00000000 103:01 19271235                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/.libs/libsz-1c7dd0cf.so.2.0.1\r\n7f294800e000-7f294820d000 ---p 00002000 103:01 19271235                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/.libs/libsz-1c7dd0cf.so.2.0.1\r\n7f294820d000-7f2948210000 rw-p 00001000 103:01 19271235                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/.libs/libsz-1c7dd0cf.so.2.0.1\r\n7f2948210000-7f2948790000 rw-p 00000000 00:00 0 \r\n7f2948790000-7f2948794000 r-xp 00000000 fc:00 2761029                    /usr/lib/python3.5/lib-dynload/termios.cpython-35m-x86_64-linux-gnu.so\r\n7f2948794000-7f2948993000 ---p 00004000 fc:00 2761029                    /usr/lib/python3.5/lib-dynload/termios.cpython-35m-x86_64-linux-gnu.so\r\n7f2948993000-7f2948994000 r--p 00003000 fc:00 2761029                    /usr/lib/python3.5/lib-dynload/termios.cpython-35m-x86_64-linux-gnu.so\r\n7f2948994000-7f2948996000 rw-p 00004000 fc:00 2761029                    /usr/lib/python3.5/lib-dynload/termios.cpython-35m-x86_64-linux-gnu.so\r\n7f2948996000-7f2948ad6000 rw-p 00000000 00:00 0 \r\n7f2948ad6000-7f2948d11000 r-xp 00000000 103:01 19270257                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/google/protobuf/pyext/_message.cpython-35m-x86_64-linux-gnu.so\r\n7f2948d11000-7f2948f10000 ---p 0023b000 103:01 19270257                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/google/protobuf/pyext/_message.cpython-35m-x86_64-linux-gnu.so\r\n7f2948f10000-7f2948f22000 rw-p 0023a000 103:01 19270257                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/google/protobuf/pyext/_message.cpython-35m-x86_64-linux-gnu.so\r\n7f2948f22000-7f2948f24000 rw-p 00000000 00:00 0 \r\n7f2948f24000-7f2948f25000 r-xp 00000000 103:01 19270120                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/google/protobuf/internal/_api_implementation.cpython-35m-x86_64-linux-gnu.so\r\n7f2948f25000-7f2949124000 ---p 00001000 103:01 19270120                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/google/protobuf/internal/_api_implementation.cpython-35m-x86_64-linux-gnu.so\r\n7f2949124000-7f2949125000 rw-p 00000000 103:01 19270120                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/google/protobuf/internal/_api_implementation.cpython-35m-x86_64-linux-gnu.so\r\n7f2949125000-7f29492a5000 rw-p 00000000 00:00 0 \r\n7f29492a5000-7f29492ac000 r-xp 00000000 fc:00 10616928                   /lib/x86_64-linux-gnu/librt-2.23.so\r\n7f29492ac000-7f29494ab000 ---p 00007000 fc:00 10616928                   /lib/x86_64-linux-gnu/librt-2.23.so\r\n7f29494ab000-7f29494ac000 r--p 00006000 fc:00 10616928                   /lib/x86_64-linux-gnu/librt-2.23.so\r\n7f29494ac000-7f29494ad000 rw-p 00007000 fc:00 10616928                   /lib/x86_64-linux-gnu/librt-2.23.so\r\n7f29494ad000-7f294a295000 r-xp 00000000 103:01 19271329                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/tensorflow/libtensorflow_framework.so\r\n7f294a295000-7f294a296000 ---p 00de8000 103:01 19271329                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/tensorflow/libtensorflow_framework.so\r\n7f294a296000-7f294a2e6000 r--p 00de8000 103:01 19271329                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/tensorflow/libtensorflow_framework.so\r\n7f294a2e6000-7f294a2e9000 rw-p 00e38000 103:01 19271329                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/tensorflow/libtensorflow_framework.so\r\n7f294a2e9000-7f294a2f6000 rw-p 00000000 00:00 0 \r\n7f294a2f6000-7f2953a81000 r-xp 00000000 103:01 19530289                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n7f2953a81000-7f2953a82000 ---p 0978b000 103:01 19530289                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n7f2953a82000-7f2953e67000 r--p 0978b000 103:01 19530289                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n7f2953e67000-7f2953e87000 rw-p 09b70000 103:01 19530289                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n7f2953e87000-7f2953fe8000 rw-p 00000000 00:00 0 \r\n7f2953fe8000-7f2953ffa000 r-xp 00000000 103:01 20845064                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/testing.cpython-35m-x86_64-linux-gnu.so\r\n7f2953ffa000-7f29541f9000 ---p 00012000 103:01 20845064                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/testing.cpython-35m-x86_64-linux-gnu.so\r\n7f29541f9000-7f29541fb000 rw-p 00011000 103:01 20845064                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/testing.cpython-35m-x86_64-linux-gnu.so\r\n7f29541fb000-7f29542fb000 rw-p 00000000 00:00 0 \r\n7f29542fb000-7f2954311000 r-xp 00000000 103:01 20845125                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/io/msgpack/_unpacker.cpython-35m-x86_64-linux-gnu.so\r\n7f2954311000-7f2954510000 ---p 00016000 103:01 20845125                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/io/msgpack/_unpacker.cpython-35m-x86_64-linux-gnu.so\r\n7f2954510000-7f2954513000 rw-p 00015000 103:01 20845125                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/io/msgpack/_unpacker.cpython-35m-x86_64-linux-gnu.so\r\n7f2954513000-7f2954524000 r-xp 00000000 103:01 20845123                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/io/msgpack/_packer.cpython-35m-x86_64-linux-gnu.so\r\n7f2954524000-7f2954723000 ---p 00011000 103:01 20845123                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/io/msgpack/_packer.cpython-35m-x86_64-linux-gnu.so\r\n7f2954723000-7f2954725000 rw-p 00010000 103:01 20845123                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/io/msgpack/_packer.cpython-35m-x86_64-linux-gnu.so\r\n7f2954725000-7f2954726000 r-xp 00000000 103:01 20845201                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/util/_move.cpython-35m-x86_64-linux-gnu.so\r\n7f2954726000-7f2954926000 ---p 00001000 103:01 20845201                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/util/_move.cpython-35m-x86_64-linux-gnu.so\r\n7f2954926000-7f2954927000 rw-p 00001000 103:01 20845201                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/util/_move.cpython-35m-x86_64-linux-gnu.so\r\n7f2954927000-7f2954959000 r-xp 00000000 103:01 20845066                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/writers.cpython-35m-x86_64-linux-gnu.so\r\n7f2954959000-7f2954b59000 ---p 00032000 103:01 20845066                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/writers.cpython-35m-x86_64-linux-gnu.so\r\n7f2954b59000-7f2954b5d000 rw-p 00032000 103:01 20845066                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/writers.cpython-35m-x86_64-linux-gnu.so\r\n7f2954b5d000-7f2954b9e000 rw-p 00000000 00:00 0 \r\n7f2954b9e000-7f2954c28000 r-xp 00000000 103:01 20845057                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/parsers.cpython-35m-x86_64-linux-gnu.so\r\n7f2954c28000-7f2954e28000 ---p 0008a000 103:01 20845057                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/parsers.cpython-35m-x86_64-linux-gnu.so\r\n7f2954e28000-7f2954e2f000 rw-p 0008a000 103:01 20845057                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/parsers.cpython-35m-x86_64-linux-gnu.so\r\n7f2954e2f000-7f2954e31000 rw-p 00000000 00:00 0 \r\n7f2954e31000-7f2954e46000 r-xp 00000000 103:01 20845063                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/json.cpython-35m-x86_64-linux-gnu.so\r\n7f2954e46000-7f2955046000 ---p 00015000 103:01 20845063                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/json.cpython-35m-x86_64-linux-gnu.so\r\n7f2955046000-7f2955047000 rw-p 00015000 103:01 20845063                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/json.cpython-35m-x86_64-linux-gnu.so\r\n7f2955047000-7f2955107000 rw-p 00000000 00:00 0 \r\n7f2955107000-7f2955141000 r-xp 00000000 103:01 20845045                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/reshape.cpython-35m-x86_64-linux-gnu.so\r\n7f2955141000-7f2955340000 ---p 0003a000 103:01 20845045                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/reshape.cpython-35m-x86_64-linux-gnu.so\r\n7f2955340000-7f2955344000 rw-p 00039000 103:01 20845045                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/reshape.cpython-35m-x86_64-linux-gnu.so\r\n7f2955344000-7f2955345000 rw-p 00000000 00:00 0 \r\n7f2955345000-7f2955384000 r-xp 00000000 103:01 20845054                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/reduction.cpython-35m-x86_64-linux-gnu.so\r\n7f2955384000-7f2955584000 ---p 0003f000 103:01 20845054                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/reduction.cpython-35m-x86_64-linux-gnu.so\r\n7f2955584000-7f2955588000 rw-p 0003f000 103:01 20845054                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/reduction.cpython-35m-x86_64-linux-gnu.so\r\n7f2955588000-7f2955608000 rw-p 00000000 00:00 0 \r\n7f2955608000-7f295561b000 r-xp 00000000 103:01 20845046                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/skiplist.cpython-35m-x86_64-linux-gnu.so\r\n7f295561b000-7f295581b000 ---p 00013000 103:01 20845046                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/skiplist.cpython-35m-x86_64-linux-gnu.so\r\n7f295581b000-7f295581d000 rw-p 00013000 103:01 20845046                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/skiplist.cpython-35m-x86_64-linux-gnu.so\r\n7f295581d000-7f29558d6000 r-xp 00000000 103:01 20845049                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/window.cpython-35m-x86_64-linux-gnu.so\r\n7f29558d6000-7f2955ad6000 ---p 000b9000 103:01 20845049                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/window.cpython-35m-x86_64-linux-gnu.so\r\n7f2955ad6000-7f2955ade000 rw-p 000b9000 103:01 20845049                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/window.cpython-35m-x86_64-linux-gnu.so\r\n7f2955ade000-7f2955b1f000 rw-p 00000000 00:00 0 \r\n7f2955b1f000-7f2955b35000 r-xp 00000000 fc:00 10617367                   /lib/x86_64-linux-gnu/libgcc_s.so.1\r\n7f2955b35000-7f2955d34000 ---p 00016000 fc:00 10617367                   /lib/x86_64-linux-gnu/libgcc_s.so.1\r\n7f2955d34000-7f2955d35000 rw-p 00015000 fc:00 10617367                   /lib/x86_64-linux-gnu/libgcc_s.so.1\r\n7f2955d35000-7f2955ea7000 r-xp 00000000 fc:00 2753024                    /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21\r\n7f2955ea7000-7f29560a7000 ---p 00172000 fc:00 2753024                    /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21\r\n7f29560a7000-7f29560b1000 r--p 00172000 fc:00 2753024                    /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21\r\n7f29560b1000-7f29560b3000 rw-p 0017c000 fc:00 2753024                    /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21\r\n7f29560b3000-7f29560b7000 rw-p 00000000 00:00 0 \r\n7f29560b7000-7f29560e4000 r-xp 00000000 103:01 20845547                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/_path.cpython-35m-x86_64-linux-gnu.so\r\n7f29560e4000-7f29562e4000 ---p 0002d000 103:01 20845547                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/_path.cpython-35m-x86_64-linux-gnu.so\r\n7f29562e4000-7f29562e5000 rw-p 0002d000 103:01 20845547                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/matplotlib/_path.cpython-35m-x86_64-linux-gnu.so\r\n7f29562e5000-7f2956566000 rw-p 00000000 00:00 0 \r\n7f2956567000-7f29566e7000 rw-p 00000000 00:00 0 \r\n7f29566e7000-7f29566ec000 r-xp 00000000 fc:00 2761042                    /usr/lib/python3.5/lib-dynload/mmap.cpython-35m-x86_64-linux-gnu.so\r\n7f29566ec000-7f29568ec000 ---p 00005000 fc:00 2761042                    /usr/lib/python3.5/lib-dynload/mmap.cpython-35m-x86_64-linux-gnu.so\r\n7f29568ec000-7f29568ed000 r--p 00005000 fc:00 2761042                    /usr/lib/python3.5/lib-dynload/mmap.cpython-35m-x86_64-linux-gnu.so\r\n7f29568ed000-7f29568ee000 rw-p 00006000 fc:00 2761042                    /usr/lib/python3.5/lib-dynload/mmap.cpython-35m-x86_64-linux-gnu.so\r\n7f29568ee000-7f29568f5000 r-xp 00000000 fc:00 2761035                    /usr/lib/python3.5/lib-dynload/_csv.cpython-35m-x86_64-linux-gnu.so\r\n7f29568f5000-7f2956af5000 ---p 00007000 fc:00 2761035                    /usr/lib/python3.5/lib-dynload/_csv.cpython-35m-x86_64-linux-gnu.so\r\n7f2956af5000-7f2956af6000 r--p 00007000 fc:00 2761035                    /usr/lib/python3.5/lib-dynload/_csv.cpython-35m-x86_64-linux-gnu.so\r\n7f2956af6000-7f2956af8000 rw-p 00008000 fc:00 2761035                    /usr/lib/python3.5/lib-dynload/_csv.cpython-35m-x86_64-linux-gnu.so\r\n7f2956af8000-7f2956b78000 rw-p 00000000 00:00 0 \r\n7f2956b78000-7f2956bb8000 r-xp 00000000 103:01 20845061                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/internals.cpython-35m-x86_64-linux-gnu.so\r\n7f2956bb8000-7f2956db7000 ---p 00040000 103:01 20845061                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/internals.cpython-35m-x86_64-linux-gnu.so\r\n7f2956db7000-7f2956dbc000 rw-p 0003f000 103:01 20845061                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/internals.cpython-35m-x86_64-linux-gnu.so\r\n7f2956dbc000-7f2956dfd000 rw-p 00000000 00:00 0 \r\n7f2956dfd000-7f2956e06000 r-xp 00000000 103:01 20845052                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/indexing.cpython-35m-x86_64-linux-gnu.so\r\n7f2956e06000-7f2957005000 ---p 00009000 103:01 20845052                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/indexing.cpython-35m-x86_64-linux-gnu.so\r\n7f2957005000-7f2957006000 rw-p 00008000 103:01 20845052                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/indexing.cpython-35m-x86_64-linux-gnu.so\r\n7f2957006000-7f29570c7000 rw-p 00000000 00:00 0 \r\n7f29570c7000-7f29570d8000 r-xp 00000000 fc:00 2761049                    /usr/lib/python3.5/lib-dynload/_json.cpython-35m-x86_64-linux-gnu.so\r\n7f29570d8000-7f29572d7000 ---p 00011000 fc:00 2761049                    /usr/lib/python3.5/lib-dynload/_json.cpython-35m-x86_64-linux-gnu.so\r\n7f29572d7000-7f29572d8000 r--p 00010000 fc:00 2761049                    /usr/lib/python3.5/lib-dynload/_json.cpython-35m-x86_64-linux-gnu.so\r\n7f29572d8000-7f29572d9000 rw-p 00011000 fc:00 2761049                    /usr/lib/python3.5/lib-dynload/_json.cpython-35m-x86_64-linux-gnu.so\r\n7f29572d9000-7f2957359000 rw-p 00000000 00:00 0 \r\n7f2957359000-7f295740e000 r-xp 00000000 103:01 20845048                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/groupby.cpython-35m-x86_64-linux-gnu.so\r\n7f295740e000-7f295760e000 ---p 000b5000 103:01 20845048                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/groupby.cpython-35m-x86_64-linux-gnu.so\r\n7f295760e000-7f2957616000 rw-p 000b5000 103:01 20845048                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/groupby.cpython-35m-x86_64-linux-gnu.so\r\n7f2957616000-7f2957658000 rw-p 00000000 00:00 0 \r\n7f2957658000-7f2957736000 r-xp 00000000 103:01 20845051                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/sparse.cpython-35m-x86_64-linux-gnu.so\r\n7f2957736000-7f2957935000 ---p 000de000 103:01 20845051                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/sparse.cpython-35m-x86_64-linux-gnu.so\r\n7f2957935000-7f295793a000 rw-p 000dd000 103:01 20845051                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/sparse.cpython-35m-x86_64-linux-gnu.so\r\n7f295793a000-7f29579bb000 rw-p 00000000 00:00 0 \r\n7f29579bb000-7f2957c29000 r-xp 00000000 103:01 20845044                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/join.cpython-35m-x86_64-linux-gnu.so\r\n7f2957c29000-7f2957e29000 ---p 0026e000 103:01 20845044                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/join.cpython-35m-x86_64-linux-gnu.so\r\n7f2957e29000-7f2957e32000 rw-p 0026e000 103:01 20845044                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/join.cpython-35m-x86_64-linux-gnu.so\r\n7f2957e32000-7f2957e33000 rw-p 00000000 00:00 0 \r\n7f2957e33000-7f2957ed5000 r-xp 00000000 103:01 20845060                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/index.cpython-35m-x86_64-linux-gnu.so\r\n7f2957ed5000-7f29580d5000 ---p 000a2000 103:01 20845060                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/index.cpython-35m-x86_64-linux-gnu.so\r\n7f29580d5000-7f29580dd000 rw-p 000a2000 103:01 20845060                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/index.cpython-35m-x86_64-linux-gnu.so\r\n7f29580dd000-7f295821f000 rw-p 00000000 00:00 0 \r\n7f295821f000-7f2958252000 r-xp 00000000 103:01 20845053                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/ops.cpython-35m-x86_64-linux-gnu.so\r\n7f2958252000-7f2958452000 ---p 00033000 103:01 20845053                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/ops.cpython-35m-x86_64-linux-gnu.so\r\n7f2958452000-7f2958456000 rw-p 00033000 103:01 20845053                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/ops.cpython-35m-x86_64-linux-gnu.so\r\n7f2958456000-7f2958457000 rw-p 00000000 00:00 0 \r\n7f2958457000-7f2958481000 r-xp 00000000 103:01 20845050                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/hashing.cpython-35m-x86_64-linux-gnu.so\r\n7f2958481000-7f2958680000 ---p 0002a000 103:01 20845050                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/hashing.cpython-35m-x86_64-linux-gnu.so\r\n7f2958680000-7f2958684000 rw-p 00029000 103:01 20845050                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/hashing.cpython-35m-x86_64-linux-gnu.so\r\n7f2958684000-7f29586c4000 rw-p 00000000 00:00 0 \r\n7f29586c4000-7f29586d2000 r-xp 00000000 103:01 20845062                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/properties.cpython-35m-x86_64-linux-gnu.so\r\n7f29586d2000-7f29588d1000 ---p 0000e000 103:01 20845062                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/properties.cpython-35m-x86_64-linux-gnu.so\r\n7f29588d1000-7f29588d3000 rw-p 0000d000 103:01 20845062                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/properties.cpython-35m-x86_64-linux-gnu.so\r\n7f29588d3000-7f2958913000 rw-p 00000000 00:00 0 \r\n7f2958913000-7f2958b21000 r-xp 00000000 103:01 20845043                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/interval.cpython-35m-x86_64-linux-gnu.so\r\n7f2958b21000-7f2958d21000 ---p 0020e000 103:01 20845043                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/interval.cpython-35m-x86_64-linux-gnu.so\r\n7f2958d21000-7f2958d31000 rw-p 0020e000 103:01 20845043                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/interval.cpython-35m-x86_64-linux-gnu.so\r\n7f2958d31000-7f2958d34000 rw-p 00000000 00:00 0 \r\n7f2958d34000-7f2958eda000 r-xp 00000000 103:01 20845047                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/algos.cpython-35m-x86_64-linux-gnu.so\r\n7f2958eda000-7f29590da000 ---p 001a6000 103:01 20845047                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/algos.cpython-35m-x86_64-linux-gnu.so\r\n7f29590da000-7f29590e6000 rw-p 001a6000 103:01 20845047                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/algos.cpython-35m-x86_64-linux-gnu.so\r\n7f29590e6000-7f2959129000 rw-p 00000000 00:00 0 \r\n7f2959129000-7f2959176000 r-xp 00000000 103:01 20845058                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslib.cpython-35m-x86_64-linux-gnu.so\r\n7f2959176000-7f2959375000 ---p 0004d000 103:01 20845058                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslib.cpython-35m-x86_64-linux-gnu.so\r\n7f2959375000-7f295937a000 rw-p 0004c000 103:01 20845058                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslib.cpython-35m-x86_64-linux-gnu.so\r\n7f295937a000-7f29593bb000 rw-p 00000000 00:00 0 \r\n7f29593bb000-7f2959425000 r-xp 00000000 103:01 20845065                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/lib.cpython-35m-x86_64-linux-gnu.so\r\n7f2959425000-7f2959624000 ---p 0006a000 103:01 20845065                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/lib.cpython-35m-x86_64-linux-gnu.so\r\n7f2959624000-7f295962e000 rw-p 00069000 103:01 20845065                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/lib.cpython-35m-x86_64-linux-gnu.so\r\n7f295962e000-7f2959630000 rw-p 00000000 00:00 0 \r\n7f2959630000-7f2959642000 r-xp 00000000 103:01 20845059                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/missing.cpython-35m-x86_64-linux-gnu.so\r\n7f2959642000-7f2959842000 ---p 00012000 103:01 20845059                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/missing.cpython-35m-x86_64-linux-gnu.so\r\n7f2959842000-7f2959844000 rw-p 00012000 103:01 20845059                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/missing.cpython-35m-x86_64-linux-gnu.so\r\n7f2959844000-7f29598d1000 r-xp 00000000 103:01 20845055                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/hashtable.cpython-35m-x86_64-linux-gnu.so\r\n7f29598d1000-7f2959ad0000 ---p 0008d000 103:01 20845055                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/hashtable.cpython-35m-x86_64-linux-gnu.so\r\n7f2959ad0000-7f2959adc000 rw-p 0008c000 103:01 20845055                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/hashtable.cpython-35m-x86_64-linux-gnu.so\r\n7f2959adc000-7f2959add000 rw-p 00000000 00:00 0 \r\n7f2959add000-7f2959b1c000 r-xp 00000000 103:01 20845080                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/resolution.cpython-35m-x86_64-linux-gnu.so\r\n7f2959b1c000-7f2959d1c000 ---p 0003f000 103:01 20845080                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/resolution.cpython-35m-x86_64-linux-gnu.so\r\n7f2959d1c000-7f2959d21000 rw-p 0003f000 103:01 20845080                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/resolution.cpython-35m-x86_64-linux-gnu.so\r\n7f2959d21000-7f2959d22000 rw-p 00000000 00:00 0 \r\n7f2959d22000-7f2959d61000 r-xp 00000000 103:01 20845071                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/fields.cpython-35m-x86_64-linux-gnu.so\r\n7f2959d61000-7f2959f61000 ---p 0003f000 103:01 20845071                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/fields.cpython-35m-x86_64-linux-gnu.so\r\n7f2959f61000-7f2959f65000 rw-p 0003f000 103:01 20845071                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/fields.cpython-35m-x86_64-linux-gnu.so\r\n7f2959f65000-7f2959f66000 rw-p 00000000 00:00 0 \r\n7f2959f66000-7f2959fe0000 r-xp 00000000 103:01 20845076                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/timestamps.cpython-35m-x86_64-linux-gnu.so\r\n7f2959fe0000-7f295a1df000 ---p 0007a000 103:01 20845076                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/timestamps.cpython-35m-x86_64-linux-gnu.so\r\n7f295a1df000-7f295a1e9000 rw-p 00079000 103:01 20845076                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/timestamps.cpython-35m-x86_64-linux-gnu.so\r\n7f295a1e9000-7f295a1ec000 rw-p 00000000 00:00 0 \r\n7f295a1ec000-7f295a20b000 r-xp 00000000 103:01 20845082                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/frequencies.cpython-35m-x86_64-linux-gnu.so\r\n7f295a20b000-7f295a40a000 ---p 0001f000 103:01 20845082                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/frequencies.cpython-35m-x86_64-linux-gnu.so\r\n7f295a40a000-7f295a40e000 rw-p 0001e000 103:01 20845082                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/frequencies.cpython-35m-x86_64-linux-gnu.so\r\n7f295a40e000-7f295a47c000 r-xp 00000000 103:01 20845079                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/period.cpython-35m-x86_64-linux-gnu.so\r\n7f295a47c000-7f295a67c000 ---p 0006e000 103:01 20845079                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/period.cpython-35m-x86_64-linux-gnu.so\r\n7f295a67c000-7f295a685000 rw-p 0006e000 103:01 20845079                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/period.cpython-35m-x86_64-linux-gnu.so\r\n7f295a685000-7f295a686000 rw-p 00000000 00:00 0 \r\n7f295a686000-7f295a6df000 r-xp 00000000 103:01 20845070                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/parsing.cpython-35m-x86_64-linux-gnu.so\r\n7f295a6df000-7f295a8de000 ---p 00059000 103:01 20845070                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/parsing.cpython-35m-x86_64-linux-gnu.so\r\n7f295a8de000-7f295a8e5000 rw-p 00058000 103:01 20845070                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/parsing.cpython-35m-x86_64-linux-gnu.so\r\n7f295a8e5000-7f295a927000 rw-p 00000000 00:00 0 \r\n7f295a927000-7f295a95e000 r-xp 00000000 103:01 20845075                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/timezones.cpython-35m-x86_64-linux-gnu.so\r\n7f295a95e000-7f295ab5e000 ---p 00037000 103:01 20845075                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/timezones.cpython-35m-x86_64-linux-gnu.so\r\n7f295ab5e000-7f295ab62000 rw-p 00037000 103:01 20845075                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/timezones.cpython-35m-x86_64-linux-gnu.so\r\n7f295ab62000-7f295ab63000 rw-p 00000000 00:00 0 \r\n7f295ab63000-7f295abc8000 r-xp 00000000 103:01 20845077                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/strptime.cpython-35m-x86_64-linux-gnu.so\r\n7f295abc8000-7f295adc7000 ---p 00065000 103:01 20845077                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/strptime.cpython-35m-x86_64-linux-gnu.so\r\n7f295adc7000-7f295adce000 rw-p 00064000 103:01 20845077                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/strptime.cpython-35m-x86_64-linux-gnu.so\r\n7f295adce000-7f295add0000 rw-p 00000000 00:00 0 \r\n7f295add0000-7f295addd000 r-xp 00000000 103:01 20845072                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/ccalendar.cpython-35m-x86_64-linux-gnu.so\r\n7f295addd000-7f295afdd000 ---p 0000d000 103:01 20845072                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/ccalendar.cpython-35m-x86_64-linux-gnu.so\r\n7f295afdd000-7f295afdf000 rw-p 0000d000 103:01 20845072                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/ccalendar.cpython-35m-x86_64-linux-gnu.so\r\n7f295afdf000-7f295b044000 r-xp 00000000 103:01 20845074                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/offsets.cpython-35m-x86_64-linux-gnu.so\r\n7f295b044000-7f295b243000 ---p 00065000 103:01 20845074                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/offsets.cpython-35m-x86_64-linux-gnu.so\r\n7f295b243000-7f295b24c000 rw-p 00064000 103:01 20845074                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/offsets.cpython-35m-x86_64-linux-gnu.so\r\n7f295b24c000-7f295b24e000 rw-p 00000000 00:00 0 \r\n7f295b24e000-7f295b2c2000 r-xp 00000000 103:01 20845081                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/timedeltas.cpython-35m-x86_64-linux-gnu.so\r\n7f295b2c2000-7f295b4c1000 ---p 00074000 103:01 20845081                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/timedeltas.cpython-35m-x86_64-linux-gnu.so\r\n7f295b4c1000-7f295b4c9000 rw-p 00073000 103:01 20845081                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/timedeltas.cpython-35m-x86_64-linux-gnu.so\r\n7f295b4c9000-7f295b4cb000 rw-p 00000000 00:00 0 \r\n7f295b4cb000-7f295b4d7000 r-xp 00000000 103:01 20845084                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/np_datetime.cpython-35m-x86_64-linux-gnu.so\r\n7f295b4d7000-7f295b6d6000 ---p 0000c000 103:01 20845084                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/np_datetime.cpython-35m-x86_64-linux-gnu.so\r\n7f295b6d6000-7f295b6d7000 rw-p 0000b000 103:01 20845084                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/np_datetime.cpython-35m-x86_64-linux-gnu.so\r\n7f295b6d7000-7f295b6ff000 r-xp 00000000 103:01 20845083                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/nattype.cpython-35m-x86_64-linux-gnu.so\r\n7f295b6ff000-7f295b8fe000 ---p 00028000 103:01 20845083                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/nattype.cpython-35m-x86_64-linux-gnu.so\r\n7f295b8fe000-7f295b902000 rw-p 00027000 103:01 20845083                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/nattype.cpython-35m-x86_64-linux-gnu.so\r\n7f295b902000-7f295b903000 rw-p 00000000 00:00 0 \r\n7f295b903000-7f295b96a000 r-xp 00000000 103:01 20845073                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/conversion.cpython-35m-x86_64-linux-gnu.so\r\n7f295b96a000-7f295bb6a000 ---p 00067000 103:01 20845073                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/conversion.cpython-35m-x86_64-linux-gnu.so\r\n7f295bb6a000-7f295bb70000 rw-p 00067000 103:01 20845073                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/pandas/_libs/tslibs/conversion.cpython-35m-x86_64-linux-gnu.so\r\n7f295bb70000-7f295bbf2000 rw-p 00000000 00:00 0 \r\n7f295bbf2000-7f295bc50000 r-xp 00000000 fc:00 10617104                   /lib/x86_64-linux-gnu/libssl.so.1.0.0\r\n7f295bc50000-7f295be50000 ---p 0005e000 fc:00 10617104                   /lib/x86_64-linux-gnu/libssl.so.1.0.0\r\n7f295be50000-7f295be54000 r--p 0005e000 fc:00 10617104                   /lib/x86_64-linux-gnu/libssl.so.1.0.0\r\n7f295be54000-7f295be5b000 rw-p 00062000 fc:00 10617104                   /lib/x86_64-linux-gnu/libssl.so.1.0.0\r\n7f295be5b000-7f295be72000 r-xp 00000000 fc:00 2762676                    /usr/lib/python3.5/lib-dynload/_ssl.cpython-35m-x86_64-linux-gnu.so\r\n7f295be72000-7f295c072000 ---p 00017000 fc:00 2762676                    /usr/lib/python3.5/lib-dynload/_ssl.cpython-35m-x86_64-linux-gnu.so\r\n7f295c072000-7f295c073000 r--p 00017000 fc:00 2762676                    /usr/lib/python3.5/lib-dynload/_ssl.cpython-35m-x86_64-linux-gnu.so\r\n7f295c073000-7f295c078000 rw-p 00018000 fc:00 2762676                    /usr/lib/python3.5/lib-dynload/_ssl.cpython-35m-x86_64-linux-gnu.so\r\n7f295c078000-7f295c238000 rw-p 00000000 00:00 0 \r\n7f295c238000-7f295c239000 r-xp 00000000 fc:00 2762677                    /usr/lib/python3.5/lib-dynload/_opcode.cpython-35m-x86_64-linux-gnu.so\r\n7f295c239000-7f295c438000 ---p 00001000 fc:00 2762677                    /usr/lib/python3.5/lib-dynload/_opcode.cpython-35m-x86_64-linux-gnu.so\r\n7f295c438000-7f295c439000 r--p 00000000 fc:00 2762677                    /usr/lib/python3.5/lib-dynload/_opcode.cpython-35m-x86_64-linux-gnu.so\r\n7f295c439000-7f295c43a000 rw-p 00001000 fc:00 2762677                    /usr/lib/python3.5/lib-dynload/_opcode.cpython-35m-x86_64-linux-gnu.so\r\n7f295c43a000-7f295c47a000 rw-p 00000000 00:00 0 \r\n7f295c47a000-7f295c695000 r-xp 00000000 fc:00 10616937                   /lib/x86_64-linux-gnu/libcrypto.so.1.0.0\r\n7f295c695000-7f295c894000 ---p 0021b000 fc:00 10616937                   /lib/x86_64-linux-gnu/libcrypto.so.1.0.0\r\n7f295c894000-7f295c8b0000 r--p 0021a000 fc:00 10616937                   /lib/x86_64-linux-gnu/libcrypto.so.1.0.0\r\n7f295c8b0000-7f295c8bc000 rw-p 00236000 fc:00 10616937                   /lib/x86_64-linux-gnu/libcrypto.so.1.0.0\r\n7f295c8bc000-7f295c8bf000 rw-p 00000000 00:00 0 \r\n7f295c8bf000-7f295c8c4000 r-xp 00000000 fc:00 2762675                    /usr/lib/python3.5/lib-dynload/_hashlib.cpython-35m-x86_64-linux-gnu.so\r\n7f295c8c4000-7f295cac4000 ---p 00005000 fc:00 2762675                    /usr/lib/python3.5/lib-dynload/_hashlib.cpython-35m-x86_64-linux-gnu.so\r\n7f295cac4000-7f295cac5000 r--p 00005000 fc:00 2762675                    /usr/lib/python3.5/lib-dynload/_hashlib.cpython-35m-x86_64-linux-gnu.so\r\n7f295cac5000-7f295cac6000 rw-p 00006000 fc:00 2762675                    /usr/lib/python3.5/lib-dynload/_hashlib.cpython-35m-x86_64-linux-gnu.so\r\n7f295cac7000-7f295cc87000 rw-p 00000000 00:00 0 \r\n7f295ccb3000-7f295ccf3000 rw-p 00000000 00:00 0 \r\n7f295ccf3000-7f295cda5000 r-xp 00000000 103:01 19269176                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/numpy/random/mtrand.cpython-35m-x86_64-linux-gnu.so\r\n7f295cda5000-7f295cfa4000 ---p 000b2000 103:01 19269176                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/numpy/random/mtrand.cpython-35m-x86_64-linux-gnu.so\r\n7f295cfa4000-7f295cfc9000 rw-p 000b1000 103:01 19269176                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/numpy/random/mtrand.cpython-35m-x86_64-linux-gnu.so\r\n7f295cfc9000-7f295d04b000 rw-p 00000000 00:00 0 \r\n7f295d04b000-7f295d054000 r-xp 00000000 103:01 19269021                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/numpy/fft/fftpack_lite.cpython-35m-x86_64-linux-gnu.so\r\n7f295d054000-7f295d254000 ---p 00009000 103:01 19269021                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/numpy/fft/fftpack_lite.cpython-35m-x86_64-linux-gnu.so\r\n7f295d254000-7f295d255000 rw-p 00009000 103:01 19269021                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/numpy/fft/fftpack_lite.cpython-35m-x86_64-linux-gnu.so\r\n7f295d255000-7f295d28c000 r-xp 00000000 fc:00 2754878                    /usr/lib/x86_64-linux-gnu/libmpdec.so.2.4.2\r\n7f295d28c000-7f295d48b000 ---p 00037000 fc:00 2754878                    /usr/lib/x86_64-linux-gnu/libmpdec.so.2.4.2\r\n7f295d48b000-7f295d48c000 r--p 00036000 fc:00 2754878                    /usr/lib/x86_64-linux-gnu/libmpdec.so.2.4.2\r\n7f295d48c000-7f295d48d000 rw-p 00037000 fc:00 2754878                    /usr/lib/x86_64-linux-gnu/libmpdec.so.2.4.2\r\n7f295d48d000-7f295d4b1000 r-xp 00000000 fc:00 2761060                    /usr/lib/python3.5/lib-dynload/_decimal.cpython-35m-x86_64-linux-gnu.so\r\n7f295d4b1000-7f295d6b0000 ---p 00024000 fc:00 2761060                    /usr/lib/python3.5/lib-dynload/_decimal.cpython-35m-x86_64-linux-gnu.so\r\n7f295d6b0000-7f295d6b1000 r--p 00023000 fc:00 2761060                    /usr/lib/python3.5/lib-dynload/_decimal.cpython-35m-x86_64-linux-gnu.so\r\n7f295d6b1000-7f295d6ba000 rw-p 00024000 fc:00 2761060                    /usr/lib/python3.5/lib-dynload/_decimal.cpython-35m-x86_64-linux-gnu.so\r\n7f295d6ba000-7f295d6db000 r-xp 00000000 fc:00 10617381                   /lib/x86_64-linux-gnu/liblzma.so.5.0.0\r\n7f295d6db000-7f295d8da000 ---p 00021000 fc:00 10617381                   /lib/x86_64-linux-gnu/liblzma.so.5.0.0\r\n7f295d8da000-7f295d8db000 r--p 00020000 fc:00 10617381                   /lib/x86_64-linux-gnu/liblzma.so.5.0.0\r\n7f295d8db000-7f295d8dc000 rw-p 00021000 fc:00 10617381                   /lib/x86_64-linux-gnu/liblzma.so.5.0.0\r\n7f295d8dc000-7f295d8e3000 r-xp 00000000 fc:00 2761033                    /usr/lib/python3.5/lib-dynload/_lzma.cpython-35m-x86_64-linux-gnu.so\r\n7f295d8e3000-7f295dae2000 ---p 00007000 fc:00 2761033                    /usr/lib/python3.5/lib-dynload/_lzma.cpython-35m-x86_64-linux-gnu.so\r\n7f295dae2000-7f295dae3000 r--p 00006000 fc:00 2761033                    /usr/lib/python3.5/lib-dynload/_lzma.cpython-35m-x86_64-linux-gnu.so\r\n7f295dae3000-7f295dae5000 rw-p 00007000 fc:00 2761033                    /usr/lib/python3.5/lib-dynload/_lzma.cpython-35m-x86_64-linux-gnu.so\r\n7f295dae5000-7f295daf4000 r-xp 00000000 fc:00 10617408                   /lib/x86_64-linux-gnu/libbz2.so.1.0.4\r\n7f295daf4000-7f295dcf3000 ---p 0000f000 fc:00 10617408                   /lib/x86_64-linux-gnu/libbz2.so.1.0.4\r\n7f295dcf3000-7f295dcf4000 r--p 0000e000 fc:00 10617408                   /lib/x86_64-linux-gnu/libbz2.so.1.0.4\r\n7f295dcf4000-7f295dcf5000 rw-p 0000f000 fc:00 10617408                   /lib/x86_64-linux-gnu/libbz2.so.1.0.4\r\n7f295dcf5000-7f295dcf9000 r-xp 00000000 fc:00 2761047                    /usr/lib/python3.5/lib-dynload/_bz2.cpython-35m-x86_64-linux-gnu.so\r\n7f295dcf9000-7f295def8000 ---p 00004000 fc:00 2761047                    /usr/lib/python3.5/lib-dynload/_bz2.cpython-35m-x86_64-linux-gnu.so\r\n7f295def8000-7f295def9000 r--p 00003000 fc:00 2761047                    /usr/lib/python3.5/lib-dynload/_bz2.cpython-35m-x86_64-linux-gnu.so\r\n7f295def9000-7f295defa000 rw-p 00004000 fc:00 2761047                    /usr/lib/python3.5/lib-dynload/_bz2.cpython-35m-x86_64-linux-gnu.so\r\n7f295defa000-7f295dffa000 rw-p 00000000 00:00 0 \r\n7f295dffa000-7f295e025000 r-xp 00000000 103:01 19269068                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/numpy/linalg/_umath_linalg.cpython-35m-x86_64-linux-gnu.so\r\n7f295e025000-7f295e224000 ---p 0002b000 103:01 19269068                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/numpy/linalg/_umath_linalg.cpython-35m-x86_64-linux-gnu.so\r\n7f295e224000-7f295e226000 rw-p 0002a000 103:01 19269068                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/numpy/linalg/_umath_linalg.cpython-35m-x86_64-linux-gnu.so\r\n7f295e226000-7f295e229000 rw-p 000d3000 103:01 19269068                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/numpy/linalg/_umath_linalg.cpython-35m-x86_64-linux-gnu.so\r\n7f295e229000-7f295e22d000 r-xp 00000000 103:01 19269071                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/numpy/linalg/lapack_lite.cpython-35m-x86_64-linux-gnu.so\r\n7f295e22d000-7f295e42d000 ---p 00004000 103:01 19269071                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/numpy/linalg/lapack_lite.cpython-35m-x86_64-linux-gnu.so\r\n7f295e42d000-7f295e42e000 rw-p 00004000 103:01 19269071                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/numpy/linalg/lapack_lite.cpython-35m-x86_64-linux-gnu.so\r\n7f295e42e000-7f295e430000 rw-p 00019000 103:01 19269071                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/numpy/linalg/lapack_lite.cpython-35m-x86_64-linux-gnu.so\r\n7f295e430000-7f295e4b0000 rw-p 00000000 00:00 0 \r\n7f295e4b0000-7f295e4cf000 r-xp 00000000 103:01 19268805                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/numpy/core/_multiarray_tests.cpython-35m-x86_64-linux-gnu.so\r\n7f295e4cf000-7f295e6ce000 ---p 0001f000 103:01 19268805                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/numpy/core/_multiarray_tests.cpython-35m-x86_64-linux-gnu.so\r\n7f295e6ce000-7f295e6d0000 rw-p 0001e000 103:01 19268805                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/numpy/core/_multiarray_tests.cpython-35m-x86_64-linux-gnu.so\r\n7f295e6d0000-7f295e750000 rw-p 00000000 00:00 0 \r\n7f295e750000-7f295e772000 r-xp 00000000 fc:00 2761034                    /usr/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so\r\n7f295e772000-7f295e971000 ---p 00022000 fc:00 2761034                    /usr/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so\r\n7f295e971000-7f295e972000 r--p 00021000 fc:00 2761034                    /usr/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so\r\n7f295e972000-7f295e976000 rw-p 00022000 fc:00 2761034                    /usr/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so\r\n7f295e976000-7f295e977000 rw-p 00000000 00:00 0 \r\n7f295e998000-7f295ea18000 rw-p 00000000 00:00 0 \r\n7f295ea18000-7f2960a18000 rw-p 00000000 00:00 0 \r\n7f2960a18000-7f2960a98000 rw-p 00000000 00:00 0 \r\n7f2960a98000-7f2962a98000 rw-p 00000000 00:00 0 \r\n7f2962a98000-7f2962ad8000 rw-p 00000000 00:00 0 \r\n7f2962ad8000-7f2962ad9000 ---p 00000000 00:00 0 \r\n7f2962ad9000-7f29632d9000 rw-p 00000000 00:00 0 \r\n7f29632d9000-7f296b2d9000 rw-p 00000000 00:00 0 \r\n7f296b2d9000-7f296b2da000 ---p 00000000 00:00 0 \r\n7f296b2da000-7f296bada000 rw-p 00000000 00:00 0 \r\n7f296bada000-7f296dada000 rw-p 00000000 00:00 0 \r\n7f296dada000-7f296dadb000 ---p 00000000 00:00 0 \r\n7f296dadb000-7f296e2db000 rw-p 00000000 00:00 0 \r\n7f296e2db000-7f296e2dc000 ---p 00000000 00:00 0 \r\n7f296e2dc000-7f296eadc000 rw-p 00000000 00:00 0 \r\n7f296eaec000-7f296ebec000 rw-p 00000000 00:00 0 \r\n7f296ebec000-7f296ec0c000 r-xp 00000000 103:01 19271237                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/.libs/libhdf5_hl-db841637.so.100.1.1\r\n7f296ec0c000-7f296ee0c000 ---p 00020000 103:01 19271237                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/.libs/libhdf5_hl-db841637.so.100.1.1\r\n7f296ee0c000-7f296ee0d000 rw-p 00020000 103:01 19271237                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/.libs/libhdf5_hl-db841637.so.100.1.1\r\n7f296ee0d000-7f296ee0e000 rw-p 00000000 00:00 0 \r\n7f296ee0e000-7f296ee18000 rw-p 00022000 103:01 19271237                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/.libs/libhdf5_hl-db841637.so.100.1.1\r\n7f296ee18000-7f296f1b4000 r-xp 00000000 103:01 19271236                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/.libs/libhdf5-8c568c27.so.103.0.0\r\n7f296f1b4000-7f296f3b4000 ---p 0039c000 103:01 19271236                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/.libs/libhdf5-8c568c27.so.103.0.0\r\n7f296f3b4000-7f296f3c6000 rw-p 0039c000 103:01 19271236                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/.libs/libhdf5-8c568c27.so.103.0.0\r\n7f296f3c6000-7f296f3c8000 rw-p 00000000 00:00 0 \r\n7f296f3c8000-7f296f40a000 rw-p 003ae000 103:01 19271236                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/.libs/libhdf5-8c568c27.so.103.0.0\r\n7f296f40a000-7f296f415000 r-xp 00000000 103:01 19271149                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/_errors.cpython-35m-x86_64-linux-gnu.so\r\n7f296f415000-7f296f614000 ---p 0000b000 103:01 19271149                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/_errors.cpython-35m-x86_64-linux-gnu.so\r\n7f296f614000-7f296f615000 rw-p 0000a000 103:01 19271149                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/_errors.cpython-35m-x86_64-linux-gnu.so\r\n7f296f615000-7f296f616000 rw-p 00000000 00:00 0 \r\n7f296f616000-7f296f619000 rw-p 0000c000 103:01 19271149                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/h5py/_errors.cpython-35m-x86_64-linux-gnu.so\r\n7f296f619000-7f29700da000 rw-p 00000000 00:00 0 \r\n7f29700da000-7f29700de000 r-xp 00000000 fc:00 10617466                   /lib/x86_64-linux-gnu/libuuid.so.1.3.0\r\n7f29700de000-7f29702dd000 ---p 00004000 fc:00 10617466                   /lib/x86_64-linux-gnu/libuuid.so.1.3.0\r\n7f29702dd000-7f29702de000 r--p 00003000 fc:00 10617466                   /lib/x86_64-linux-gnu/libuuid.so.1.3.0\r\n7f29702de000-7f29702df000 rw-p 00004000 fc:00 10617466                   /lib/x86_64-linux-gnu/libuuid.so.1.3.0\r\n7f29702df000-7f29703cf000 r-xp 00000000 103:01 19268977                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/numpy/.libs/libgfortran-ed201abd.so.3.0.0\r\n7f29703cf000-7f29705ce000 ---p 000f0000 103:01 19268977                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/numpy/.libs/libgfortran-ed201abd.so.3.0.0\r\n7f29705ce000-7f29705d0000 rw-p 000ef000 103:01 19268977                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/numpy/.libs/libgfortran-ed201abd.so.3.0.0\r\n7f29705d0000-7f29705d1000 rw-p 00000000 00:00 0 \r\n7f29705d1000-7f29705d9000 rw-p 000f2000 103:01 19268977                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/numpy/.libs/libgfortran-ed201abd.so.3.0.0\r\n7f29705d9000-7f29720d4000 r-xp 00000000 103:01 19268978                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/numpy/.libs/libopenblasp-r0-2ecf47d5.3.7.dev.so\r\n7f29720d4000-7f29722d4000 ---p 01afb000 103:01 19268978                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/numpy/.libs/libopenblasp-r0-2ecf47d5.3.7.dev.so\r\n7f29722d4000-7f29722ed000 rw-p 01afb000 103:01 19268978                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/numpy/.libs/libopenblasp-r0-2ecf47d5.3.7.dev.so\r\n7f29722ed000-7f29722f8000 rw-p 00000000 00:00 0 \r\n7f29722f8000-7f2972370000 rw-p 01be7000 103:01 19268978                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/numpy/.libs/libopenblasp-r0-2ecf47d5.3.7.dev.so\r\n7f2972370000-7f29726f0000 r-xp 00000000 103:01 19268807                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/numpy/core/_multiarray_umath.cpython-35m-x86_64-linux-gnu.so\r\n7f29726f0000-7f29728f0000 ---p 00380000 103:01 19268807                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/numpy/core/_multiarray_umath.cpython-35m-x86_64-linux-gnu.so\r\n7f29728f0000-7f297290e000 rw-p 00380000 103:01 19268807                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/numpy/core/_multiarray_umath.cpython-35m-x86_64-linux-gnu.so\r\n7f297290e000-7f297292f000 rw-p 00000000 00:00 0 \r\n7f297292f000-7f2972936000 rw-p 0132a000 103:01 19268807                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/numpy/core/_multiarray_umath.cpython-35m-x86_64-linux-gnu.so\r\n7f2972936000-7f29729f6000 rw-p 00000000 00:00 0 \r\n7f2972a10000-7f2972a24000 r-xp 00000000 103:01 19531574                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/tensorflow/python/framework/fast_tensor_util.so\r\n7f2972a24000-7f2972a25000 r--p 00013000 103:01 19531574                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/tensorflow/python/framework/fast_tensor_util.so\r\n7f2972a25000-7f2972a27000 rw-p 00014000 103:01 19531574                  /home/sungjin/.virtualenvs/tf-1.13/lib/python3.5/site-packages/tensorflow/python/framework/fast_tensor_util.so\r\n7f2972a27000-7f2972b27000 rw-p 00000000 00:00 0 \r\n7f2972b27000-7f2972c2f000 r-xp 00000000 fc:00 10616856                   /lib/x86_64-linux-gnu/libm-2.23.so\r\n7f2972c2f000-7f2972e2e000 ---p 00108000 fc:00 10616856                   /lib/x86_64-linux-gnu/libm-2.23.so\r\n7f2972e2e000-7f2972e2f000 r--p 00107000 fc:00 10616856                   /lib/x86_64-linux-gnu/libm-2.23.so\r\n7f2972e2f000-7f2972e30000 rw-p 00108000 fc:00 10616856                   /lib/x86_64-linux-gnu/libm-2.23.so\r\n7f2972e30000-7f2972e49000 r-xp 00000000 fc:00 10617649                   /lib/x86_64-linux-gnu/libz.so.1.2.8\r\n7f2972e49000-7f2973048000 ---p 00019000 fc:00 10617649                   /lib/x86_64-linux-gnu/libz.so.1.2.8\r\n7f2973048000-7f2973049000 r--p 00018000 fc:00 10617649                   /lib/x86_64-linux-gnu/libz.so.1.2.8\r\n7f2973049000-7f297304a000 rw-p 00019000 fc:00 10617649                   /lib/x86_64-linux-gnu/libz.so.1.2.8\r\n7f297304a000-7f2973070000 r-xp 00000000 fc:00 10617338                   /lib/x86_64-linux-gnu/libexpat.so.1.6.0\r\n7f2973070000-7f2973270000 ---p 00026000 fc:00 10617338                   /lib/x86_64-linux-gnu/libexpat.so.1.6.0\r\n7f2973270000-7f2973272000 r--p 00026000 fc:00 10617338                   /lib/x86_64-linux-gnu/libexpat.so.1.6.0\r\n7f2973272000-7f2973273000 rw-p 00028000 fc:00 10617338                   /lib/x86_64-linux-gnu/libexpat.so.1.6.0\r\n7f2973273000-7f2973275000 r-xp 00000000 fc:00 10616899                   /lib/x86_64-linux-gnu/libutil-2.23.so\r\n7f2973275000-7f2973474000 ---p 00002000 fc:00 10616899                   /lib/x86_64-linux-gnu/libutil-2.23.so\r\n7f2973474000-7f2973475000 r--p 00001000 fc:00 10616899                   /lib/x86_64-linux-gnu/libutil-2.23.so\r\n7f2973475000-7f2973476000 rw-p 00002000 fc:00 10616899                   /lib/x86_64-linux-gnu/libutil-2.23.so\r\n7f2973476000-7f2973479000 r-xp 00000000 fc:00 10616870                   /lib/x86_64-linux-gnu/libdl-2.23.so\r\n7f2973479000-7f2973678000 ---p 00003000 fc:00 10616870                   /lib/x86_64-linux-gnu/libdl-2.23.so\r\n7f2973678000-7f2973679000 r--p 00002000 fc:00 10616870                   /lib/x86_64-linux-gnu/libdl-2.23.so\r\n7f2973679000-7f297367a000 rw-p 00003000 fc:00 10616870                   /lib/x86_64-linux-gnu/libdl-2.23.so\r\n7f297367a000-7f297383a000 r-xp 00000000 fc:00 10616866                   /lib/x86_64-linux-gnu/libc-2.23.so\r\n7f297383a000-7f2973a3a000 ---p 001c0000 fc:00 10616866                   /lib/x86_64-linux-gnu/libc-2.23.so\r\n7f2973a3a000-7f2973a3e000 r--p 001c0000 fc:00 10616866                   /lib/x86_64-linux-gnu/libc-2.23.so\r\n7f2973a3e000-7f2973a40000 rw-p 001c4000 fc:00 10616866                   /lib/x86_64-linux-gnu/libc-2.23.so\r\n7f2973a40000-7f2973a44000 rw-p 00000000 00:00 0 \r\n7f2973a44000-7f2973a5c000 r-xp 00000000 fc:00 10616864                   /lib/x86_64-linux-gnu/libpthread-2.23.so\r\n7f2973a5c000-7f2973c5b000 ---p 00018000 fc:00 10616864                   /lib/x86_64-linux-gnu/libpthread-2.23.so\r\n7f2973c5b000-7f2973c5c000 r--p 00017000 fc:00 10616864                   /lib/x86_64-linux-gnu/libpthread-2.23.so\r\n7f2973c5c000-7f2973c5d000 rw-p 00018000 fc:00 10616864                   /lib/x86_64-linux-gnu/libpthread-2.23.so\r\n7f2973c5d000-7f2973c61000 rw-p 00000000 00:00 0 \r\n7f2973c61000-7f2973c87000 r-xp 00000000 fc:00 10616863                   /lib/x86_64-linux-gnu/ld-2.23.so\r\n7f2973c8e000-7f2973cce000 rw-p 00000000 00:00 0 \r\n7f2973cce000-7f2973e66000 r--p 00000000 fc:00 2755584                    /usr/lib/locale/locale-archive\r\n7f2973e66000-7f2973e6c000 rw-p 00000000 00:00 0 \r\n7f2973e7d000-7f2973e7e000 rw-p 00000000 00:00 0 \r\n7f2973e7e000-7f2973e7f000 rwxp 00000000 00:00 0 \r\n7f2973e7f000-7f2973e86000 r--s 00000000 fc:00 2766856                    /usr/lib/x86_64-linux-gnu/gconv/gconv-modules.cache\r\n7f2973e86000-7f2973e87000 r--p 00025000 fc:00 10616863                   /lib/x86_64-linux-gnu/ld-2.23.so\r\n7f2973e87000-7f2973e88000 rw-p 00026000 fc:00 10616863                   /lib/x86_64-linux-gnu/ld-2.23.so\r\n7f2973e88000-7f2973e89000 rw-p 00000000 00:00 0 \r\n7fff363dc000-7fff3646a000 rw-p 00000000 00:00 0                          [stack]\r\n7fff365c0000-7fff365c3000 r--p 00000000 00:00 0                          [vvar]\r\n7fff365c3000-7fff365c5000 r-xp 00000000 00:00 0                          [vdso]\r\nffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0                  [vsyscall]\r\nzsh: abort (core dumped)  python boosted.py\r\n```\r\n", "Thanks for the report.\r\nSeems like a duplicate of b/132111572 (tracked internally)\r\n", "@lamberta Wanted to ask if a similar issue could be present with tensorflow lite C/C++ library?\r\nI cannot really spot anything about custom allocators aside from single printf in `python/lite.py`\r\nor is it a problem only for python bindings?", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information."]}, {"number": 30318, "title": "Refactor CacheDatasetOp and add tests", "body": "This PR refactors `CacheDatasetOp` and add the unit tests.\r\n\r\ncc: @jsimsa  ", "comments": ["@jsimsa The variable name has been updated. Please have a look at the change (https://github.com/tensorflow/tensorflow/pull/30318/commits/e6593c186bed1e740efd4e65463542a1ca3a63d2)! The sanity check failed last time. It seems to be unrelated as the log shows:\r\n```\r\nERROR: error loading package 'tensorflow/lite/delegates/gpu/metal/kernels': Unable to load package for '//java/com/google/wireless/qa/mobileharness/client/builddefs:mobile_test.bzl': BUILD file not found on package path\r\nINFO: Elapsed time: 7.246s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (53 packages loaded)\r\nFAILED: Build did NOT complete successfully (53 packages loaded)\r\n\r\nFAIL: bazel build --nobuild  -- //tensorflow/... -//tensorflow/lite/delegates/gpu/... -//tensorflow/lite/java/demo/app/... -//tensorflow/lite/schema/...\r\n  This is due to invalid BUILD files. See lines above for details.\r\n```", "@rthadur The internal checks have been pending for a while. Could you please help trigger the internal checks?", "@jsimsa The internal check and Window Bazel check failed. Could you please help check and paste the related log details here?", "The cache dataset ops tests are timing out internally. The following error is repeated in the log a lot of times:\r\n\r\n```\r\nthird_party/tensorflow/core/kernels/data/cache_dataset_ops_test.cc:172: Failure\r\nExpected equality of these values:\r\n  ::tensorflow::Status::OK()\r\n    Which is: OK\r\n  (iterator->GetNext(iterator_ctx.get(), &next, &end_of_sequence))\r\n    Which is: Permission denied: open failed for cache_data_0.lockfile: Permission denied\r\n```", "When you specify a file path for the test, you should generate it with `env::Default()->LocalTempFilename()`.", "@jsimsa Thanks for the suggestion! The `tmp_dir` is added to the specified file path. Could you have a look at the change(https://github.com/tensorflow/tensorflow/pull/30318/commits/436516cacc69f4bbc8c9f66aca742a208af3164e)?", "Close this PR as the code has been merged. @jsimsa Thanks for your help on this PR!"]}, {"number": 30317, "title": "tf.nn.depthwise_conv2d does not preserve number of channels", "body": "edit: _**you can skip reading this post, go to the next one directly**_\r\n\r\n**System information**\r\n\r\n- OS Platform and Distribution: Linux Ubuntu 18.04\r\n- TensorFlow installed from: pip\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 1.13.1\r\n- CUDA/cuDNN version: 10\r\n- GPU model and memory: RTX 2080 Ti\r\n\r\n**Describe the current behavior**\r\nif I  look at the tensor before and after the depthwise_conv2d:\r\n```\r\nic| x: <tf.Tensor 'fusion/upsample/transpose_1:0' shape=(?, 128, ?, ?) dtype=float32>\r\nic| x: <tf.Tensor 'fusion/dwconv1/BatchToSpaceND:0' shape=(?, ?, ?, ?) dtype=float32>\r\n```\r\n\r\n**Describe the expected behavior**\r\nif I  look at the tensor before and after the depthwise_conv2d the channel number should be preserved, and look something like this:\r\n```\r\nic| x: <tf.Tensor 'fusion/upsample/transpose_1:0' shape=(?, 128, ?, ?) dtype=float32>\r\nic| x: <tf.Tensor 'fusion/transpose_1:0' shape=(?, 128, ?, ?) dtype=float32>\r\n```\r\n\r\nso IMO depthwise_conv2d with dilations  and NCHW it's loosing the information about number of channels \r\n\r\n**Code to reproduce the issue**\r\n\r\nbecause tf.layers.depthwise_conv2d is not implemented, I implemented this:\r\n\r\n```\r\ndef _depthwise_conv2d(self, tensor, kernel_size, strides, rate=[1, 1], name='dwconv'):\r\n    \"\"\"Problem: doesn't support channel first + dilations\"\"\"\r\n    c = self._n_channels(tensor)\r\n    filter_shape = [kernel_size[0], kernel_size[1], c, 1]\r\n    filter = tf.get_variable(name + \"/filter\", shape=filter_shape, dtype=tf.float32)\r\n    strides = [1, 1, strides[0], strides[1]]\r\n    tensor = tf.nn.depthwise_conv2d(tensor, filter, strides, padding='SAME',\r\n                                    rate=rate, name=name, data_format='NCHW')\r\n    return tensor\r\n```\r\nthis works:\r\n```\r\nx = self._depthwise_conv2d(x, (3, 3), (1, 1), name='dwconv2')\r\n```\r\nbut this does not:\r\n(the difference is dilations or specifically dilations + NCHW data format)\r\n```\r\nx = self._depthwise_conv2d(x, (3, 3), (1, 1), [4, 4], name='dwconv1')\r\n```\r\n\r\nis gives following error on the batch_norm which follows the depthwise_conv2d\r\n```\r\n    x = tf.layers.batch_normalization(x, self.caxis, training=self.training)\r\n  File \"~/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"~/.local/lib/python3.6/site-packages/tensorflow/python/layers/normalization.py\", line 313, in batch_normalization\r\n    return layer.apply(inputs, training=training)\r\n  File \"~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1227, in apply\r\n    return self.__call__(inputs, *args, **kwargs)\r\n  File \"~/.local/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 530, in __call__\r\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\r\n  File \"~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 538, in __call__\r\n    self._maybe_build(inputs)\r\n  File \"~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1603, in _maybe_build\r\n    self.build(input_shapes)\r\n  File \"~/.local/lib/python3.6/site-packages/tensorflow/python/keras/layers/normalization.py\", line 306, in build\r\n    input_shape)\r\nValueError: ('Input has undefined `axis` dimension. Input shape: ', TensorShape([Dimension(None), Dimension(None), Dimension(None), Dimension(None)]))\r\n```\r\n\r\n\r\n\r\n", "comments": ["Looks like the code is incomplete.Can you please provide full code snippet to reproduce it on our environment.Thanks!", "ok, I came up with this minimal example:\r\n```\r\nimport tensorflow as tf\r\nfrom icecream import ic\r\n\r\nic(tf.__version__)\r\n\r\n# channel last - OK - as expected\r\nnhwc_tensor = tf.placeholder(tf.float32, (None, None, None, 3))\r\nc = nhwc_tensor.get_shape().as_list()[-1]\r\nfilter_shape = [3, 3, c, 1]\r\nfilter = tf.get_variable(\"filter\", shape=filter_shape, dtype=tf.float32)\r\nstrides = [1, 1, 1, 1]\r\nrate = 4\r\nic(nhwc_tensor)\r\nnhwc_tensor = tf.nn.depthwise_conv2d(nhwc_tensor, filter, strides, \"SAME\", [rate, rate], \"ok_dwconv\", \"NHWC\")\r\nic(nhwc_tensor)\r\nnhwc_tensor = tf.layers.batch_normalization(nhwc_tensor, name='after_ok')\r\n\r\n# channel first - BUG\r\nnchw_tensor = tf.placeholder(tf.float32, (None, 3, None, None))\r\nc = nchw_tensor.get_shape().as_list()[1]\r\nfilter_shape = [3, 3, c, 1]\r\nfilter2 = tf.get_variable(\"filter2\", shape=filter_shape, dtype=tf.float32)\r\nstrides = [1, 1, 1, 1]\r\nrate = 4\r\nic(nchw_tensor)\r\nnchw_tensor = tf.nn.depthwise_conv2d(nchw_tensor, filter2, strides, \"SAME\", [rate, rate], \"buggy_dwconv\", \"NCHW\")\r\nic(nchw_tensor)\r\nnchw_tensor = tf.layers.batch_normalization(nchw_tensor, name='after_bug')\r\n\r\n```\r\nit turns out that another necessary ingredient for the bug to occur is `None` for height and width", "output of the code above on my machine:\r\n\r\n```\r\nic| tf.__version__: '1.13.1'\r\nWARNING:tensorflow:From /data/users/adrian.staniec/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops)\r\nis deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nColocations handled automatically by placer.\r\nic| nhwc_tensor: <tf.Tensor 'Placeholder:0' shape=(?, ?, ?, 3) dtype=float32>\r\nic| nhwc_tensor: <tf.Tensor 'ok_dwconv/BatchToSpaceND:0' shape=(?, ?, ?, 3) dtype=float32>\r\nWARNING:tensorflow:From depthwise.py:16: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse keras.layers.batch_normalization instead.\r\nic| nchw_tesnor: <tf.Tensor 'Placeholder_1:0' shape=(?, 3, ?, ?) dtype=float32>\r\nic| nchw_tesnor: <tf.Tensor 'buggy_dwconv/BatchToSpaceND:0' shape=(?, ?, ?, ?) dtype=float32>\r\nTraceback (most recent call last):\r\n  File \"depthwise.py\", line 28, in <module>\r\n    nchw_tesnor = tf.layers.batch_normalization(nchw_tesnor, name='after_bug')\r\n  File \"/data/users/adrian.staniec/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/data/users/adrian.staniec/.local/lib/python3.6/site-packages/tensorflow/python/layers/normalization.py\", line 313, in batch_normalization\r\n    return layer.apply(inputs, training=training)\r\n  File \"/data/users/adrian.staniec/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1227, in apply\r\n    return self.__call__(inputs, *args, **kwargs)\r\n  File \"/data/users/adrian.staniec/.local/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 530, in __call__\r\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\r\n  File \"/data/users/adrian.staniec/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 538, in __call__\r\n    self._maybe_build(inputs)\r\n  File \"/data/users/adrian.staniec/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1603, in _maybe_build\r\n    self.build(input_shapes)\r\n  File \"/data/users/adrian.staniec/.local/lib/python3.6/site-packages/tensorflow/python/keras/layers/normalization.py\", line 306, in build\r\n    input_shape)\r\nValueError: ('Input has undefined `axis` dimension. Input shape: ', TensorShape([Dimension(None), Dimension(None), Dimension(None), Dimension(None)]))\r\n```", "I have tried on colab with TF 1.13.1-version with GPU and was able to reproduce the issue.Thanks!", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30317\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30317\">No</a>\n"]}, {"number": 30316, "title": "The docs are unscrollable with JavaScript disabled", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/stack\r\n\r\n## Description of issue (what needs changing):\r\n\r\n```css\r\nbody[pending] {\r\n\toverflow: hidden;\r\n}\r\n```\r\n\r\nshould be removed.\r\n\r\n### Clear description\r\nJS is considered harmful, so the docs should be usable without JS.\r\n\r\nThe same problem is present in Android and Fuchsia docs.\r\n", "comments": ["Thanks for the report.\r\n\r\nWe currently push old versions to GitHub and these are plain Markdown files: https://github.com/tensorflow/docs/blob/r1.10/site/en/api_docs/python/tf/stack.md\r\n\r\nBut we will also start pushing the the current version as part of the standard release. Good point.\r\n", "Thanks for the workaround, but I think that the websites should be fixed too.", "I've filed an internal ticket: b/136665885\r\nCan't promise anything and JavaScript will remain on the site\u2014but maybe we can at least get it to scroll without it :)\r\n", "Alright ... scrolling without JavaScript should be fixed in prod now.\r\nI don't have a way to test but let me know if you run into an issue. Thanks\r\n", "Works like a charm. Thanks to everyone involved in fixing it!"]}, {"number": 30315, "title": "TFlite conversion of Conv1D with dilation !=1", "body": "\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): tensorflow==2.0.0-beta1\r\n- Python version: python3\r\n\r\n\r\n**Describe the current behavior**\r\nAfter converting a Conv1D op to tensorflow lite the interpreter cannot allocate tensors:\r\n\r\n` tensorflow/lite/kernels/space_to_batch_nd.cc:96 NumDimensions(op_context.input) != kInputDimensionNum (3 != 4)Node number 0 (SPACE_TO_BATCH_ND) failed to prepare.\r\n`\r\n\r\n\r\n**Describe the expected behavior**\r\nTflite model should be able to load and execute.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```\r\n!pip install -q tensorflow==2.0.0-beta1\r\n\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras.layers import *\r\n\r\ndef get_model():\r\n  input = tf.keras.Input(shape=(10,40))\r\n  \r\n  #No error when dilation rate == 1\r\n  layer = Conv1D(32, (3),dilation_rate =2, padding='same',use_bias=False) (input)\r\n  layer = GlobalMaxPooling1D()(layer)\r\n  output = Dense(2) (layer)\r\n\r\n  model = Model(inputs=[input], outputs=[output])\r\n  return model\r\n\r\n\r\nmodel = get_model()\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n\r\ntflite_model = converter.convert()\r\nopen(\"./trained_model.tflite\", \"wb\").write(tflite_model)\r\n\r\n\r\ninterpreter = tf.lite.Interpreter(model_path=\"./trained_model.tflite\")\r\n\r\ninterpreter.allocate_tensors()\r\n```\r\n\r\n\r\n**Other info / logs**\r\nThe problem does not occur when dilation_rate ==1", "comments": ["This issue is solved with PRs #28410, #27867 & #28179.  Thanks!", "Was able to reproduce the issue with [TF v2.1](https://colab.research.google.com/gist/amahendrakar/5216cdcb0582cc62e6a6518ea5334e2e/2-1-template.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/14ab31228c0693ab78b78ed73f0145d0/tf-nightly.ipynb#scrollTo=ieAW-NK5iqpf) i.e. v2.2.0-dev20200327. Please find the attached gist. Thanks!", "@karimnosseir can you take a look?", "@amahendrakar Can you share the sample code ?\r\nThe example in the original issue works when i tried it.\r\n\r\nThanks", "@karimnosseir,\r\nSure, below are the links of the gist using\r\n- TF v2.1\r\nhttps://colab.research.google.com/gist/amahendrakar/5216cdcb0582cc62e6a6518ea5334e2e/2-1-template.ipynb\r\n\r\n- TF-nightly\r\nhttps://colab.research.google.com/gist/amahendrakar/14ab31228c0693ab78b78ed73f0145d0/tf-nightly.ipynb#scrollTo=ieAW-NK5iqpf", "@karimnosseir Hi, what tensorflow version were you using?", "Thanks @amahendrakar I can reproduce it on the 2.1 but works with nightly. Can you please retry.\r\n\r\n@suicao i was using tf-nightly\r\n", "I can confirm that this works with ```'2.2.0-dev20200414```", "@karimnosseir,\r\nWorks without any issues with the latest TF-nightly i.e. v2.2.0-dev20200415. Please find the gist [here](https://colab.research.google.com/gist/amahendrakar/67ba5ecd35433f7e61e5102f8d74611a/30315-tf-nightly.ipynb#scrollTo=ieAW-NK5iqpf). Thanks!", "Thanks for confirming. I am closing the issue. Please feel free to reopen/create a new one if you have any problems.\r\n\r\nThanks", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30315\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30315\">No</a>\n", "Issue still exists in TF 2.2 stable."]}, {"number": 30314, "title": "TensorFlow Lite Micro int8 quantization support?", "body": "\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: STM32F746G\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: '1.14.0'\r\n- **Python version**: 3.7.3\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**: \r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**: \r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\n[feature request] \r\n.tflite model exported with a tensorflow version > r.1.13 are not compatible anymore with TensorFlow Lite Micro experimental Library. \r\n\r\nKernels functions has to be updated to support asymetric per-axis quantization. \r\n\r\nIs there any release schedule on this lib?\r\n\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["Release schedule on which library? Tensorflow 1.14 is publicly available now (latest release) and any model you train (and then utilize something like post-training quantization) to produce a quantized model should be fine, according to the error message", "Production of a quantized model is fine, but the integration on an embedded device using TensorFlow lite experimental micro lib is not working. \r\nTo my mind it is due to the asymmetric per-axis quantization not supported by micro kernel. So my question was more \"is there any update of the experimental micro lib schedule?\" ", "I'm having the same issue with stm32f746 and tflite-micro.\r\nI'm running `v1.14.0-rc1-22-gaf24dc9 1.14.0` version.\r\n\r\nWhen using `OPTIMIZE_FOR_SIZE` or `QUANTIZED_UINT8` in TFLiteConverter and get the tflite flatbuffer, then when the buffer is parsed, the `tensorflow/lite/experimental/micro/simple_tensor_allocator.c:TfLiteTypeSizeOf` complains that:\r\n\r\n> Only float32, int16, int32, int64, uint8, bool, complex64 supported currently.\r\n\r\nAnd according to `c_api_internal.h` the type is set to `kTfLiteInt8`, which fails.\r\n\r\nWithout optimization, the flatbuffer is more than 3x times the size and also needs much more RAM.\r\nIs there any way to enforce kTfLiteUInt8?\r\nI thought that `tf.lite.constants.QUANTIZED_UINT8` was doing that, but for some reason it uses INT8.", "Assigning to @njeffrie since he's looking into this now.", "We are working to support signed int8 quantization on micro.  Which operators are  you using?  We tend to prioritize based on usage, so this info can help us choose which ops to prioritize.  We currently have int8 versions of fully_connected and we are close to landing int8 per-channel versions of conv2d and depthwise_conv.", "Hi @njeffrie thanks for the reply. As you already mentioned the conv2d and depthwise_conv are the most common used and also in my case I've tried to use those two.\r\n\r\nThanks!", "We have landed int8 reference kernels for conv, depthwise_conv, fully_connected and several other ops.  Thanks for your feedback and please feel free to re-open if you are still running into any issues."]}, {"number": 30313, "title": "android GpuDelegate: even the simplest tflite converted models seems to run on CPU", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): tf docker images\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: oneplus5, pixel3, galaxy s10\r\n- TensorFlow installed from (source or binary): various\r\n- TensorFlow version (use command below): 1.12.0, 1.13.1, 1.14.0, 1.15.0-dev20190628, r1.14 source build\r\n- Python version: 3.x\r\n- Bazel version (if compiling from source): 0.25.2\r\n- GCC/Compiler version (if compiling from source): 7.4.0\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\ntflite converted models seems to always run on cpu despite using gpudelegate, for example the simplest model from https://github.com/tensorflow/tensorflow/issues/30311 runs for hundreds of milliseconds per inference no matter whether cpu or gpudelegate is used, while stock mobilenet_v1 (no quantization, no manual tflite conversion, downloaded tflite model) runs ~80ms per inference on this device when using gpudelegate and 150-300ms on cpu.\r\n\r\n**Describe the expected behavior**\r\ntflite to actually use GPU when running conv2d networks\r\n\r\n**Code to reproduce the issue**\r\nattached NHW3 model (and script to generate pb and tflite with optimization options, which do not have any effect), this is basically NHW3 input, single tf.layers.conv2d() constant-initialized layer and reduce_sum() for output.\r\n\r\nAny hint on debugging this issue?\r\nI tested both jcenter downloaded (0.0.0-nightly branches) and manually built from r1.14 branch tensorflow-lite and tensorflow-lite-gpu.\r\nI used 1.12.0, 1.13.1, 1.14.0, 1.15.0-dev20190628, r1.14 source build tensorflow/tflite with different optimization options with no success.\r\n\r\nCould you please show how *exactly* you generated mobilenet_v1 tflite model found in your tutorials, since it works like a charm with gpudelegate: ~80ms per single-image inference on gpu and several hundreds seconds on cpu on sufficiently recent android. Or any hints on how to debug this gpudelegate issue.\r\n\r\n[test_model_3channels.tar.gz](https://github.com/tensorflow/tensorflow/files/3350552/test_model_3channels.tar.gz)", "comments": ["@bioothod \r\n\r\nThanks for attaching the model.\r\n\r\n> ERROR: Next operations are not supported by GPU delegate:\r\n> SUM: Operation is not supported.\r\n> First 1 operations will run on the GPU, and the remaining 1 on the CPU.\r\n\r\nWell, we don't have a SUM operation, and MobileNet v1 doesn't have a SUM at the end either.  It's not clear where the confusion is coming from.  Can you elaborate?", "@bioothod \r\n\r\nOh and a couple of things.\r\n\r\n1. By default, TFLite gpu delegate options has allow_precision_loss to 0 (false), to be on the safe side.  You may want to turn that on for speed up.\r\n2. Your network needs to be deep enough.  There is additional cost you have to eat up (memcpy, GPU/CPU sync etc.) that needs to be compensated by GPU's faster execution.  So if you have a network with just a single CONV_2D, of course it's going to be slower than on the CPU only.", "https://www.tensorflow.org/lite/guide/ops_compatibility states that tf.reduce_sum will be removed from the graph, probably will be replaced with ADD_N operation. Or does it mean it should be removed by the user? I've attached different mobilenet_v1 which doesn't work as fast as google-converted tflite either, it doesn't have SUM operator.\r\n\r\nAlso. I'm quite sure I saw gpudelegate exception about unsupported SUM operator with some other models (do not remember, what it was though), and now there are none, model just works slow.\r\n\r\nI used precision loss without any effect.\r\nThis conv2d network is slower than the whole mobilenet_v1 on cpu, well, its because of large convolutions, but still.\r\n\r\n[model.ckpt-1044627-frozen.tflite.gz](https://github.com/tensorflow/tensorflow/files/3352660/model.ckpt-1044627-frozen.tflite.gz)\r\n\r\n", "N.B. maybe not slower, after 100-400 ms variation is very high and I never measured mean and anyway it is unacceptably high for 2 operations or for the whole network like in the example above. And since there is no exception in gpudelegate log I suppose it runs on GPU and should be, well, not slower than google-converted mobilenet_v1", "More confusion.\r\n\r\nSUM operator works and produces correct results (maybe running on CPU - any chance to **know** that graph works on GPU?):\r\n```\r\nimages = tf.placeholder(tf.float32, shape=[None, 32, 32, num_channels], name='input/tensor')\r\nx = tf.layers.conv2d(images, 1, kernel_size=[3, 3], kernel_initializer=tf.ones_initializer(), use_bias=False)\r\nsum_pixels = tf.reduce_sum(x, axis=[1, 2], name='output/sum_pixels')\r\n```\r\n[test_conv2d_3channels_sum_works.tflite.gz](https://github.com/tensorflow/tensorflow/files/3356009/test_conv2d_3channels_sum_works.tflite.gz)\r\n\r\n\r\nSUM operator crashes with unsupported op exception:\r\n```\r\nimages = tf.placeholder(tf.float32, shape=[None, 32, 32, num_channels], name='input/tensor')\r\nx = tf.layers.conv2d(images, 1, kernel_size=[32, 32], kernel_initializer=tf.ones_initializer(), use_bias=False)\r\nsum_pixels = tf.reduce_sum(x, axis=[1, 2], name='output/sum_pixels')\r\n```\r\n[test_conv2d_3channels_sum_crashes.tflite.gz](https://github.com/tensorflow/tensorflow/files/3355986/test_conv2d_3channels_sum_crashes.tflite.gz)\r\n\r\n\r\nGpuDelegate crashes with:\r\n```\r\nI/Adreno: Error: Uniform offsets cannot find a suitable location/component.\r\n    Error: Linking failed.\r\nW/ImageReader_JNI: Unable to acquire a buffer item, very likely client tried to acquire more than maxImages buffers\r\nE/AndroidRuntime: FATAL EXCEPTION: inference\r\n    Process: org.tensorflow.lite.examples.classification, PID: 30676\r\n    java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: TfLiteGpuDelegate Prepare: Program is not properly linked: Error: Uniform offsets cannot find a suitable location/component.\r\n    Error: Linking failed.Node number 2 (TfLiteGpuDelegate) failed to prepare.\r\n    \r\n        at org.tensorflow.lite.NativeInterpreterWrapper.applyDelegate(Native Method)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.init(NativeInterpreterWrapper.java:83)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:60)\r\n        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:224)\r\n```\r\n```\r\nimages = tf.placeholder(tf.float32, shape=[None, 32, 32, num_channels], name='input/tensor')\r\nx = tf.layers.conv2d(images, 1, kernel_size=[32, 32], kernel_initializer=tf.ones_initializer(), use_bias=False)\r\nsum_pixels = tf.reshape(x, [1, 1], name='output/sum_pixels')\r\n```\r\n[test_conv2d_3channels_crash_uniform_offsets.tflite.gz](https://github.com/tensorflow/tensorflow/files/3356051/test_conv2d_3channels_crash_uniform_offsets.tflite.gz)\r\n", "`delegates/gpu/common/model_builder.cc` has a function called `NewOperationParser()`.  That's the set of operations supported by GPU.", "> `delegates/gpu/common/model_builder.cc` has a function called `NewOperationParser()`. That's the set of operations supported by GPU.\r\n\r\nIt is probably related to SUM operation. Well, then why does it work in the first graph? The only difference is input shape [1,1,1,1]crashes vs [1,30,30,1]works", "In all cases, SUM runs on the CPU.\r\n\r\nWhat is succeeding on the first case and failing on the second case is CONV_2D on the GPU.", "Things are getting more and more weird, isn't conv_2d supposed to always succeed, at least as it is written in documentation, or there are some constraints? Why doesn't delegate throw the same exception explaining (at least something) that this operation is not supported on gpu because of /reason/ and so on\r\n\r\nAre you on this issue and do you need any additional details from me, or you think everything is fine?\r\nI will dig into delegate code in a meantime (ouch, there are no debug helpers) and try to find out more", "Apparently, both failing models fail because GL can not compile conv_2d kernel for 32x32 reception field, which is very large for real life anyway, and for smaller kernels it silently replaces sum or squeeze wtih CPU implementations, just like you've said.\r\n\r\nStill curious how to determine which operations run on gpu, since the only way to run fast enough is not to touch any property of tflite converter, even not `setting converter.optimizations = [tf.lite.Optimize.DEFAULT]`. Model runs fast with plain\r\n```\r\nconverter = tf.lite.TFLiteConverter.from_session(sess, [images], output_nodes)\r\n#converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n#converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_LATENCY]\r\n#converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\r\nconverter = tf.lite.TFLiteConverter.from_session(sess, [images], output_nodes)\r\n```\r\n\r\nIf any optimization property has been touched to any commented above, model greatly shrinks in size, but starts executing only on CPU.", "Again... \r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/gpu/common/model_builder.cc#L1879-L1957\r\n\r\nthis is the list of supported ops on the GPU.\r\n\r\nIf it crashes, that's a bug, and we should look into it, but we cannot accommodate all hypothetical single op test cases.  After all, this is an open source project, and you can contribute by fixing bugs too ;)", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30313\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30313\">No</a>\n"]}, {"number": 30312, "title": "[ROCm] Add gfx908 into supported AMD GCN ISA version list", "body": "", "comments": []}, {"number": 30311, "title": "TFLite's DepthwiseConv2D is broken with GpuDelegate for 1-channel input", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): tf docker images\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: oneplus5, pixel3, galaxy s10\r\n- TensorFlow installed from (source or binary): various\r\n- TensorFlow version (use command below):  1.14.0, 1.15.0-dev20190628, r1.14 source build\r\n- Python version: 3.x\r\n- Bazel version (if compiling from source): 0.25.2\r\n- GCC/Compiler version (if compiling from source): 7.4.0\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nWhen using supersimple network consisting of NHWC input, single tf.layers.conv2d() layer (constant initialized) and reduce_sum output, output for C=3 is the same for CPU (host tf and tflite and android tflite) and android GpuDelegate are kind of the same (less than 2% difference). When using C=1 CPU host (tf and tflite) and android on CPU are kind of the same (less than 10% difference), but android GpuDelegate produces drastically different output.\r\n\r\n**Describe the expected behavior**\r\nproduce kind of the same results for the same models (no matter C=1 or C=3) for CPU host tf and tflite and android tflite on CPU and GpuDelegate.\r\n\r\n**Code to reproduce the issue**\r\nAttached archive with broken model generated with 1.15.0-dev20190628 tflite converted with default options (no properties changed) and script to create model and tflite file itself.\r\n\r\n**Other info / logs**\r\nI tested tflite both from nightly build from jcenter and local builds from r1.14 branch.\r\nHere are the results when providing 1.224.224.1 image filled with 0.1 value:\r\ncpu host tf: 5677536.5,\r\ncpu host tflite: 6028237.0 (6.2% difference)\r\nandroid cpu: 6028237\r\nandroid gpudelegate: 44336.1\r\n\r\n[test_model.tar.gz](https://github.com/tensorflow/tensorflow/files/3350494/test_model.tar.gz)\r\n\r\nAlso, tflite converted models seems to always run on cpu despite using gpudelegate, for example this model runs for hundreds of milliseconds no matter whether cpu or gpudelegate is used, while stock mobilenet_v1 (no quantization) runs ~80ms per inference on this device when using gpudelegate and 150-300ms on cpu.\r\nI will fill another bug report for this though", "comments": ["Attached model with pure conv2d layers and incorrect output results on cpu and gpudelegate, probably related to some fp16 overflow? I do not use precision loss option in gpudelegate, it was created with default parameters.\r\n\r\noutput node is [1][1]float at 0-th offset, input is 1.32.32.3 tensor filled with 0.1\r\nandroid cpu: 244059422720\r\nandroid gpudelegate: 1572096\r\n\r\n[test_conv2d_3channels_conv2d_possible_overflow.tflite.gz](https://github.com/tensorflow/tensorflow/files/3356153/test_conv2d_3channels_conv2d_possible_overflow.tflite.gz)\r\n", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30311\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30311\">No</a>\n"]}, {"number": 30310, "title": "[TensorFlow 2.0] Automated naming of keras metric layers is not consistent", "body": "**System information**\r\n- Have I written custom code: **yes**\r\n- OS Platform and Distribution: **Mac OS X 10.14.5**\r\n- TensorFlow installed from: **binary**\r\n- TensorFlow version: **v2.0.0-beta0-16-g1d91213fe7 2.0.0-beta1**\r\n- Python version: **3.6.8**\r\n- CUDA/cuDNN version: **don't have a GPU**\r\n- GPU model and memory: **don't have a GPU**\r\n\r\n**Describe the current behavior**\r\n\r\nThe automatic naming of Keras metric layers is not consistent.  Example, if I create two `BinaryAccuracy` metrics:\r\n\r\n```python\r\n>>> tf.keras.metrics.BinaryAccuracy().name\r\n'binary_accuracy'\r\n>>> tf.keras.metrics.BinaryAccuracy().name\r\n'binary_accuracy'\r\n```\r\n\r\nWhereas, if I create two `Recall` metrics:\r\n\r\n```python\r\n>>> tf.keras.metrics.Recall().name\r\n'recall'\r\n>>> tf.keras.metrics.Recall().name\r\n'recall_1'\r\n```\r\n\r\nAfter testing every metric class in `tf.keras.metrics`, I found that the same behavior as `Recall` is produced by the following metrics:\r\n\r\n- `AUC`\r\n- `FalseNegatives`\r\n- `FalsePositives`\r\n- `MeanIoU`\r\n- `MeanRelativeError`\r\n- `Precision`\r\n- `Recall`\r\n- `SensitivityAtSpecificity`\r\n- `SpecificityAtSensitivity`\r\n- `TrueNegatives`\r\n- `TruePositives`\r\n\r\n**Describe the expected behavior**\r\n\r\nEither all the metrics should be created with the exact same name, or they should all have an integer added to the end of the second metric with that name.\r\n\r\n**Code to reproduce the issue**\r\n\r\nHere's my code that lists all the classes in `tf.keras.metrics` that have different names when instanciated twice:\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport inspect\r\n\r\nfor name, metric in tf.keras.metrics.__dict__.items():\r\n    if inspect.isclass(metric):  # It's a metric keras layer\r\n        args = ()\r\n        if name == 'MeanIoU':\r\n            args = (2,)\r\n        elif name == 'MeanRelativeError':\r\n            args = ([1],)\r\n        elif name == 'Metric':\r\n            continue\r\n        elif name == 'SensitivityAtSpecificity':\r\n            args = (0.5,)\r\n        elif name == 'SpecificityAtSensitivity':\r\n            args = (0.5,)\r\n\r\n        layer_name_0 = metric(*args).name\r\n        layer_name_1 = metric(*args).name\r\n\r\n        if layer_name_0 != layer_name_1:  # Two same metrics don't have the same name\r\n            print('-', name)\r\n```", "comments": ["I am able to reproduce the issue on Colab with Tensorflow 2.0.0.beta1. Thanks!", "I think this is intended behavior.  Referring to says ```tf.keras.metrics.Recall``` documentation it says [Creates a Recall instance.](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Recall#__init__ )\r\nWhereas for ```tf.keras.metrics.Accuracy``` the name: Accuracy is hard coded.\r\nSame can apply to the other metrics as well.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30310\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30310\">No</a>\n"]}, {"number": 30309, "title": "tf.keras.layers.Conv1DTranspose ?", "body": "This is somewhat related to the issue #8729, which is already solved.\r\nIn the issue, tf.nn.conv1d_transpose was requested and implemented in the end.\r\n\r\nBut the corresponding function in tf.layers or tf.keras is missing.\r\nIn other words, there's no function like tf.layers.conv1d_transpose, tf.keras.layers.Conv1DTranspose.\r\n\r\nCan you please implement it?\r\nSince there's already tf.nn.conv1d_transpose, I guess it doesn't take so much time to implement it.", "comments": ["This is already implemented.\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/convolutional.py", "Thank you for your response.\r\n\r\nBut could you tell me in which branch and file we can find the function\r\ntf.keras.layers.Conv1DTranspose?\r\n\r\nI can't find it in the file you said.", "Oh it seems that we only have 2dtranspose, but not 1dtranspose.", "Any updates so far?", "Still missing in TensorFlow 2.0.\r\nSince TensorFlow already has `tf.nn.conv1d_transpose`, it should be easy to implement `tf.keras.Conv1DTranspose`.", "It is really weird not to have Conv1DTransposed in TF.\r\nI feel like I am able to turn right 90 degrees, but not left. Yes, this is not a huge problem because you can always turn right 3 times, but why?\r\n\r\nAnyway, this is what I use and I hope it'll help someone\r\n\r\n```python\r\nclass Conv1DTranspose(tf.keras.layers.Layer):\r\n    def __init__(self, filters, kernel_size, strides=1, padding='valid'):\r\n        super().__init__()\r\n        self.conv2dtranspose = tf.keras.layers.Conv2DTranspose(\r\n          filters, (kernel_size, 1), (strides, 1), padding\r\n        )\r\n\r\n    def call(self, x):\r\n        x = tf.expand_dims(x, axis=2)\r\n        x = self.conv2dtranspose(x)\r\n        x = tf.squeeze(x, axis=2)\r\n        return x\r\n```", "even just for symmetry reasons - ``Conv1DTranspose`` needs to find it's way in the Keras API.\r\n\r\nIt has been requested already (see #6724) but denied as it can be reduced to a ``Conv2DTranspose`` which is already implemented. But if we keep that reasoning, why do we need ``Conv1D``, ``Conv2D`` if all of them can be replaced with a ``Conv3D``.\r\n\r\nAnd let`s face it ``Conv1DTranspose`` is not that exotic, that everyone who needs it, should be forced to implement it's own version.\r\n\r\nCould it be, that ``Conv1DTranspose`` is not here, because it is not in the original Keras API? Should we report the issue there first, and wait until it finds it's way back to TF?\r\n", "Somehow this falls outside of my radar. I will make this done today.", "This is fixed and should be available in tf-nightly tomorrow. Closing it.", "Thank you @tanzhenyu - that was really quick!\r\n\r\nP.S. I guess it also resolves #29157", "> Thank you @tanzhenyu - that was really quick!\r\n> \r\n> P.S. I guess it also resolves #29157\r\n\r\nYeah, resolving that too. Thanks"]}, {"number": 30308, "title": "XLA Warning", "body": "<!--This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.-->\r\n\r\nI am receiving this warning,\r\n```\r\nW tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\r\n``` \r\nin one of my travic ci builds. AFAIK, XLA is going through active development and therefore I prefer not to use, `TF_XLA_FLAGS=--tf_xla_cpu_global_jit`. However, I cannot figure out how to silence this warning, permanently during future builds. If any such technique exists then I would suggest to add that to warning itself. \r\nPlease let me know, if it can be done by manipulating env variables. Thanks. \r\n", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nPlease.provide reproducible code. If you are unclear what to include see the issue template displayed in the Github new issue[ template](https://github.com/tensorflow/tensorflow/issues/new/choose)\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!", "Below is the complete `Build System Information`,\r\n```python\r\nBuild system information\r\nBuild language: python\r\nBuild group: stable\r\nBuild dist: trusty\r\nBuild id: 553259216\r\nJob id: 553259233\r\nRuntime kernel version: 4.4.0-101-generic\r\ntravis-build version: 7b7f39e22\r\nBuild image provisioning date and time\r\nTue Dec  5 19:58:13 UTC 2017\r\nOperating System Details\r\nDistributor ID:\tUbuntu\r\nDescription:\tUbuntu 14.04.5 LTS\r\nRelease:\t14.04\r\nCodename:\ttrusty\r\nCookbooks Version\r\n7c2c6a6 https://github.com/travis-ci/travis-cookbooks/tree/7c2c6a6\r\ngit version\r\ngit version 2.15.1\r\nbash version\r\nGNU bash, version 4.3.11(1)-release (x86_64-pc-linux-gnu)\r\ngcc version\r\ngcc (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4\r\nCopyright (C) 2013 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\ndocker version\r\nClient:\r\n Version:      17.09.0-ce\r\n API version:  1.32\r\n Go version:   go1.8.3\r\n Git commit:   afdb6d4\r\n Built:        Tue Sep 26 22:42:38 2017\r\n OS/Arch:      linux/amd64\r\nServer:\r\n Version:      17.09.0-ce\r\n API version:  1.32 (minimum version 1.12)\r\n Go version:   go1.8.3\r\n Git commit:   afdb6d4\r\n Built:        Tue Sep 26 22:41:20 2017\r\n OS/Arch:      linux/amd64\r\n Experimental: false\r\nclang version\r\nclang version 5.0.0 (tags/RELEASE_500/final)\r\nTarget: x86_64-unknown-linux-gnu\r\nThread model: posix\r\nInstalledDir: /usr/local/clang-5.0.0/bin\r\njq version\r\njq-1.5\r\nbats version\r\nBats 0.4.0\r\nshellcheck version\r\n0.4.6\r\nshfmt version\r\nv2.0.0\r\nccache version\r\nccache version 3.1.9\r\nCopyright (C) 2002-2007 Andrew Tridgell\r\nCopyright (C) 2009-2011 Joel Rosdahl\r\nThis program is free software; you can redistribute it and/or modify it under\r\nthe terms of the GNU General Public License as published by the Free Software\r\nFoundation; either version 3 of the License, or (at your option) any later\r\nversion.\r\ncmake version\r\ncmake version 3.9.2\r\nCMake suite maintained and supported by Kitware (kitware.com/cmake).\r\nheroku version\r\nheroku-cli/6.14.39-addc925 (linux-x64) node-v9.2.0\r\nimagemagick version\r\nVersion: ImageMagick 6.7.7-10 2017-07-31 Q16 http://www.imagemagick.org\r\nmd5deep version\r\n4.2\r\nmercurial version\r\nMercurial Distributed SCM (version 4.2.2)\r\n(see https://mercurial-scm.org for more information)\r\nCopyright (C) 2005-2017 Matt Mackall and others\r\nThis is free software; see the source for copying conditions. There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\nmysql version\r\nmysql  Ver 14.14 Distrib 5.6.33, for debian-linux-gnu (x86_64) using  EditLine wrapper\r\nopenssl version\r\nOpenSSL 1.0.1f 6 Jan 2014\r\npacker version\r\nPacker v1.0.2\r\nYour version of Packer is out of date! The latest version\r\nis 1.1.2. You can update by downloading from www.packer.io\r\npostgresql client version\r\npsql (PostgreSQL) 9.6.6\r\nragel version\r\nRagel State Machine Compiler version 6.8 Feb 2013\r\nCopyright (c) 2001-2009 by Adrian Thurston\r\nsubversion version\r\nsvn, version 1.8.8 (r1568071)\r\n   compiled Aug 10 2017, 17:20:39 on x86_64-pc-linux-gnu\r\nCopyright (C) 2013 The Apache Software Foundation.\r\nThis software consists of contributions made by many people;\r\nsee the NOTICE file for more information.\r\nSubversion is open source software, see http://subversion.apache.org/\r\nThe following repository access (RA) modules are available:\r\n* ra_svn : Module for accessing a repository using the svn network protocol.\r\n  - with Cyrus SASL authentication\r\n  - handles 'svn' scheme\r\n* ra_local : Module for accessing a repository on local disk.\r\n  - handles 'file' scheme\r\n* ra_serf : Module for accessing a repository via WebDAV protocol using serf.\r\n  - using serf 1.3.3\r\n  - handles 'http' scheme\r\n  - handles 'https' scheme\r\nsudo version\r\nSudo version 1.8.9p5\r\nConfigure options: --prefix=/usr -v --with-all-insults --with-pam --with-fqdn --with-logging=syslog --with-logfac=authpriv --with-env-editor --with-editor=/usr/bin/editor --with-timeout=15 --with-password-timeout=0 --with-passprompt=[sudo] password for %p:  --without-lecture --with-tty-tickets --disable-root-mailer --enable-admin-flag --with-sendmail=/usr/sbin/sendmail --with-timedir=/var/lib/sudo --mandir=/usr/share/man --libexecdir=/usr/lib/sudo --with-sssd --with-sssd-lib=/usr/lib/x86_64-linux-gnu --with-selinux\r\nSudoers policy plugin version 1.8.9p5\r\nSudoers file grammar version 43\r\nSudoers path: /etc/sudoers\r\nAuthentication methods: 'pam'\r\nSyslog facility if syslog is being used for logging: authpriv\r\nSyslog priority to use when user authenticates successfully: notice\r\nSyslog priority to use when user authenticates unsuccessfully: alert\r\nSend mail if the user is not in sudoers\r\nUse a separate timestamp for each user/tty combo\r\nLecture user the first time they run sudo\r\nRoot may run sudo\r\nAllow some information gathering to give useful error messages\r\nRequire fully-qualified hostnames in the sudoers file\r\nVisudo will honor the EDITOR environment variable\r\nSet the LOGNAME and USER environment variables\r\nLength at which to wrap log file lines (0 for no wrap): 80\r\nAuthentication timestamp timeout: 15.0 minutes\r\nPassword prompt timeout: 0.0 minutes\r\nNumber of tries to enter a password: 3\r\nUmask to use or 0777 to use user's: 022\r\nPath to mail program: /usr/sbin/sendmail\r\nFlags for mail program: -t\r\nAddress to send mail to: root\r\nSubject line for mail messages: *** SECURITY information for %h ***\r\nIncorrect password message: Sorry, try again.\r\nPath to authentication timestamp dir: /var/lib/sudo\r\nDefault password prompt: [sudo] password for %p: \r\nDefault user to run commands as: root\r\nValue to override user's $PATH with: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin\r\nPath to the editor for use by visudo: /usr/bin/editor\r\nWhen to require a password for 'list' pseudocommand: any\r\nWhen to require a password for 'verify' pseudocommand: all\r\nFile descriptors >= 3 will be closed before executing a command\r\nEnvironment variables to check for sanity:\r\n\tTZ\r\n\tTERM\r\n\tLINGUAS\r\n\tLC_*\r\n\tLANGUAGE\r\n\tLANG\r\n\tCOLORTERM\r\nEnvironment variables to remove:\r\n\tRUBYOPT\r\n\tRUBYLIB\r\n\tPYTHONUSERBASE\r\n\tPYTHONINSPECT\r\n\tPYTHONPATH\r\n\tPYTHONHOME\r\n\tTMPPREFIX\r\n\tZDOTDIR\r\n\tREADNULLCMD\r\n\tNULLCMD\r\n\tFPATH\r\n\tPERL5DB\r\n\tPERL5OPT\r\n\tPERL5LIB\r\n\tPERLLIB\r\n\tPERLIO_DEBUG \r\n\tJAVA_TOOL_OPTIONS\r\n\tSHELLOPTS\r\n\tGLOBIGNORE\r\n\tPS4\r\n\tBASH_ENV\r\n\tENV\r\n\tTERMCAP\r\n\tTERMPATH\r\n\tTERMINFO_DIRS\r\n\tTERMINFO\r\n\t_RLD*\r\n\tLD_*\r\n\tPATH_LOCALE\r\n\tNLSPATH\r\n\tHOSTALIASES\r\n\tRES_OPTIONS\r\n\tLOCALDOMAIN\r\n\tCDPATH\r\n\tIFS\r\nEnvironment variables to preserve:\r\n\tJAVA_HOME\r\n\tTRAVIS\r\n\tCI\r\n\tDEBIAN_FRONTEND\r\n\tXAUTHORIZATION\r\n\tXAUTHORITY\r\n\tPS2\r\n\tPS1\r\n\tPATH\r\n\tLS_COLORS\r\n\tKRB5CCNAME\r\n\tHOSTNAME\r\n\tHOME\r\n\tDISPLAY\r\n\tCOLORS\r\nLocale to use while parsing sudoers: C\r\nDirectory in which to store input/output logs: /var/log/sudo-io\r\nFile in which to store the input/output log: %{seq}\r\nAdd an entry to the utmp/utmpx file when allocating a pty\r\nPAM service name to use\r\nPAM service name to use for login shells\r\nCreate a new PAM session for the command to run in\r\nMaximum I/O log sequence number: 0\r\nLocal IP address and netmask pairs:\r\n\t10.240.0.28/255.255.255.255\r\n\t172.17.0.1/255.255.0.0\r\nSudoers I/O plugin version 1.8.9p5\r\ngzip version\r\ngzip 1.6\r\nCopyright (C) 2007, 2010, 2011 Free Software Foundation, Inc.\r\nCopyright (C) 1993 Jean-loup Gailly.\r\nThis is free software.  You may redistribute copies of it under the terms of\r\nthe GNU General Public License <http://www.gnu.org/licenses/gpl.html>.\r\nThere is NO WARRANTY, to the extent permitted by law.\r\nWritten by Jean-loup Gailly.\r\nzip version\r\nCopyright (c) 1990-2008 Info-ZIP - Type 'zip \"-L\"' for software license.\r\nThis is Zip 3.0 (July 5th 2008), by Info-ZIP.\r\nCurrently maintained by E. Gordon.  Please send bug reports to\r\nthe authors using the web page at www.info-zip.org; see README for details.\r\nLatest sources and executables are at ftp://ftp.info-zip.org/pub/infozip,\r\nas of above date; see http://www.info-zip.org/ for other sites.\r\nCompiled with gcc 4.8.2 for Unix (Linux ELF) on Oct 21 2013.\r\nZip special compilation options:\r\n\tUSE_EF_UT_TIME       (store Universal Time)\r\n\tBZIP2_SUPPORT        (bzip2 library version 1.0.6, 6-Sept-2010)\r\n\t    bzip2 code and library copyright (c) Julian R Seward\r\n\t    (See the bzip2 license for terms of use)\r\n\tSYMLINK_SUPPORT      (symbolic links supported)\r\n\tLARGE_FILE_SUPPORT   (can read and write large files on file system)\r\n\tZIP64_SUPPORT        (use Zip64 to store large files in archives)\r\n\tUNICODE_SUPPORT      (store and read UTF-8 Unicode paths)\r\n\tSTORE_UNIX_UIDs_GIDs (store UID/GID sizes/values using new extra field)\r\n\tUIDGID_NOT_16BIT     (old Unix 16-bit UID/GID extra field not used)\r\n\t[encryption, version 2.91 of 05 Jan 2007] (modified for Zip 3)\r\nEncryption notice:\r\n\tThe encryption code of this program is not copyrighted and is\r\n\tput in the public domain.  It was originally written in Europe\r\n\tand, to the best of our knowledge, can be freely distributed\r\n\tin both source and object forms from any country, including\r\n\tthe USA under License Exception TSU of the U.S. Export\r\n\tAdministration Regulations (section 740.13(e)) of 6 June 2002.\r\nZip environment options:\r\n             ZIP:  [none]\r\n          ZIPOPT:  [none]\r\nvim version\r\nVIM - Vi IMproved 7.4 (2013 Aug 10, compiled Nov 24 2016 16:43:18)\r\nIncluded patches: 1-52\r\nExtra patches: 8.0.0056\r\nModified by pkg-vim-maintainers@lists.alioth.debian.org\r\nCompiled by buildd@\r\nHuge version without GUI.  Features included (+) or not (-):\r\n+acl             +farsi           +mouse_netterm   +syntax\r\n+arabic          +file_in_path    +mouse_sgr       +tag_binary\r\n+autocmd         +find_in_path    -mouse_sysmouse  +tag_old_static\r\n-balloon_eval    +float           +mouse_urxvt     -tag_any_white\r\n-browse          +folding         +mouse_xterm     -tcl\r\n++builtin_terms  -footer          +multi_byte      +terminfo\r\n+byte_offset     +fork()          +multi_lang      +termresponse\r\n+cindent         +gettext         -mzscheme        +textobjects\r\n-clientserver    -hangul_input    +netbeans_intg   +title\r\n-clipboard       +iconv           +path_extra      -toolbar\r\n+cmdline_compl   +insert_expand   -perl            +user_commands\r\n+cmdline_hist    +jumplist        +persistent_undo +vertsplit\r\n+cmdline_info    +keymap          +postscript      +virtualedit\r\n+comments        +langmap         +printer         +visual\r\n+conceal         +libcall         +profile         +visualextra\r\n+cryptv          +linebreak       +python          +viminfo\r\n+cscope          +lispindent      -python3         +vreplace\r\n+cursorbind      +listcmds        +quickfix        +wildignore\r\n+cursorshape     +localmap        +reltime         +wildmenu\r\n+dialog_con      -lua             +rightleft       +windows\r\n+diff            +menu            -ruby            +writebackup\r\n+digraphs        +mksession       +scrollbind      -X11\r\n-dnd             +modify_fname    +signs           -xfontset\r\n-ebcdic          +mouse           +smartindent     -xim\r\n+emacs_tags      -mouseshape      -sniff           -xsmp\r\n+eval            +mouse_dec       +startuptime     -xterm_clipboard\r\n+ex_extra        +mouse_gpm       +statusline      -xterm_save\r\n+extra_search    -mouse_jsbterm   -sun_workshop    -xpm\r\n   system vimrc file: \"$VIM/vimrc\"\r\n     user vimrc file: \"$HOME/.vimrc\"\r\n 2nd user vimrc file: \"~/.vim/vimrc\"\r\n      user exrc file: \"$HOME/.exrc\"\r\n  fall-back for $VIM: \"/usr/share/vim\"\r\nCompilation: gcc -c -I. -Iproto -DHAVE_CONFIG_H     -g -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security -U_FORTIFY_SOURCE -D_FORTIFY_SOURCE=1      \r\nLinking: gcc   -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,--as-needed -o vim        -lm -ltinfo -lnsl  -lselinux  -lacl -lattr -lgpm -ldl    -L/usr/lib/python2.7/config-x86_64-linux-gnu -lpython2.7 -lpthread -ldl -lutil -lm -Xlinker -export-dynamic -Wl,-O1 -Wl,-Bsymbolic-functions      \r\niptables version\r\niptables v1.4.21\r\ncurl version\r\ncurl 7.35.0 (x86_64-pc-linux-gnu) libcurl/7.35.0 OpenSSL/1.0.1f zlib/1.2.8 libidn/1.28 librtmp/2.3\r\nwget version\r\nGNU Wget 1.15 built on linux-gnu.\r\nrsync version\r\nrsync  version 3.1.0  protocol version 31\r\ngimme version\r\nv1.2.0\r\nnvm version\r\n0.33.6\r\nperlbrew version\r\n/home/travis/perl5/perlbrew/bin/perlbrew  - App::perlbrew/0.80\r\nphpenv version\r\nrbenv 1.1.1-25-g6aa70b6\r\nrvm version\r\nrvm 1.29.3 (latest) by Michal Papis, Piotr Kuczynski, Wayne E. Seguin [https://rvm.io]\r\ndefault ruby version\r\nruby 2.4.1p111 (2017-03-22 revision 58053) [x86_64-linux]\r\nCouchDB version\r\ncouchdb 1.6.1\r\nElasticSearch version\r\n5.5.0\r\nInstalled Firefox version\r\nfirefox 56.0.2\r\nMongoDB version\r\nMongoDB 3.4.10\r\nPhantomJS version\r\n2.1.1\r\nPre-installed PostgreSQL versions\r\n9.2.24\r\n9.3.20\r\n9.4.15\r\n9.5.10\r\n9.6.6\r\nRabbitMQ Version\r\n3.6.14\r\nRedis version\r\nredis-server 4.0.6\r\nriak version\r\n2.2.3\r\nPre-installed Go versions\r\n1.7.4\r\nant version\r\nApache Ant(TM) version 1.9.3 compiled on April 8 2014\r\nmvn version\r\nApache Maven 3.5.2 (138edd61fd100ec658bfa2d307c43b76940a5d7d; 2017-10-18T07:58:13Z)\r\nMaven home: /usr/local/maven-3.5.2\r\nJava version: 1.8.0_151, vendor: Oracle Corporation\r\nJava home: /usr/lib/jvm/java-8-oracle/jre\r\nDefault locale: en_US, platform encoding: UTF-8\r\nOS name: \"linux\", version: \"4.4.0-98-generic\", arch: \"amd64\", family: \"unix\"\r\ngradle version\r\n------------------------------------------------------------\r\nGradle 4.0.1\r\n------------------------------------------------------------\r\nBuild time:   2017-07-07 14:02:41 UTC\r\nRevision:     38e5dc0f772daecca1d2681885d3d85414eb6826\r\nGroovy:       2.4.11\r\nAnt:          Apache Ant(TM) version 1.9.6 compiled on June 29 2015\r\nJVM:          1.8.0_151 (Oracle Corporation 25.151-b12)\r\nOS:           Linux 4.4.0-98-generic amd64\r\nlein version\r\nLeiningen 2.8.1 on Java 1.8.0_151 Java HotSpot(TM) 64-Bit Server VM\r\nPre-installed Node.js versions\r\nv4.8.6\r\nv6.12.0\r\nv6.12.1\r\nv8.9\r\nv8.9.1\r\nphpenv versions\r\n  system\r\n  5.6\r\n* 5.6.32 (set by /home/travis/.phpenv/version)\r\n  7.0\r\n  7.0.25\r\n  7.1\r\n  7.1.11\r\n  hhvm\r\n  hhvm-stable\r\ncomposer --version\r\nComposer version 1.5.2 2017-09-11 16:59:25\r\nPre-installed Ruby versions\r\nruby-2.2.7\r\nruby-2.3.4\r\nruby-2.4.1\r\n```\r\nAbout the tensorflow version, below snippets of logs will be relevant,\r\n**Environment Location**\r\n```\r\nenvironment location: /home/travis/miniconda/envs/test-environment\r\n```\r\n**Version**\r\n```\r\ntensorboard            1.14.0    \r\ntensorflow             1.14.0    \r\ntensorflow-estimator   1.14.0 \r\n```\r\nMost probably, installed via `conda`.\r\n**Miscellaneous Details**\r\n```\r\n2019-07-02 12:35:55.175246: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\r\nTo enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2019-07-02 12:35:55.206996: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\r\n2019-07-02 12:35:55.207182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ee8fd713e0 executing computations on platform Host. Devices:\r\n2019-07-02 12:35:55.207198: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\r\nOMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.\r\nOMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info\r\nOMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0,1\r\nOMP: Info #156: KMP_AFFINITY: 2 available OS procs\r\nOMP: Info #157: KMP_AFFINITY: Uniform topology\r\nOMP: Info #179: KMP_AFFINITY: 1 packages x 1 cores/pkg x 2 threads/core (1 total cores)\r\nOMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:\r\nOMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 thread 1 \r\nOMP: Info #250: KMP_AFFINITY: pid 24554 tid 24554 thread 0 bound to OS proc set 0\r\n2019-07-02 12:35:55.208209: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\r\n```\r\nFor details, visit, https://api.travis-ci.org/v3/job/553259233/log.txt\r\nThanks.", "@ravikyram I'm receiving the same error \r\n2019-07-03 18:02:26.272503: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set. If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU. To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\r\n\r\n following is my Docker container details\r\n ubuntu:18.10\r\n\r\nRUN apt-get update && apt-get install -y --no-install-recommends software-properties-common\r\n\r\nRUN apt-get update && apt-get install -y --no-install-recommends \\\r\n        python3.7 \\\r\n         python3-dev\r\nand following is Pipfile\r\n\r\n[[source]]\r\nname = \"pypi\"\r\nurl = \"https://pypi.org/simple\"\r\nverify_ssl = true\r\n\r\n[dev-packages]\r\n\r\n[packages]\r\nnumpy = \"*\"\r\nscikit-learn = \"*\"\r\npandas = \"*\"\r\npytest = \"*\"\r\npytest-cov = \"*\"\r\npymysql = \"*\"\r\nsqlalchemy = \"*\"\r\nalembic = \"*\"\r\nboto3 = \"*\"\r\nflask = \"*\"\r\nflask-restplus = \"*\"\r\nmoto = \"*\"\r\ntensorflow = \"*\"\r\n\r\n\r\n[requires]\r\npython_version = \"3.7\"\r\n", "@czgdp1807 @amitml Have you solved the warnings since i have the same warnings with you ?", "@tangjie77wd I haven't figured out a way yet to silence the warnings. We are planning to leave them as it is in the travis logs.", "@sanjoy @tpopp  any updates on how to silence the warning since we are not planning to use XLA for testing purposes.", "@czgdp1807  Well,the performance is poor if i do not handle with it.", "Sorry about this. The warning should not have been printed when you aren't using XLA at all. There's not any environment variable to hide this warning, but I will work on a fix in the code now.", "@tangjie77wd set `TF_XLA_FLAGS=--tf_xla_cpu_global_jit` for using XLA as far as I can figure out from the warning message. This will improve the performance.", "@tpopp Thanks, waiting for this issue to be closed via some PR. \r\n\r\nEdit - Ah! It's in master. Well, when can we expect this in the next release. I mean how much time? Can this issue be closed now?", "@czgdp1807  Thanks very much.Do you mean **export TF_XLA_FLAGS=--tf_xla_cpu_global_jit=/mytensorflowpath/tensorflow/compiler/xla:$TF_XLA_FLAGS=--tf_xla_cpu_global_jit** ?", "@tangjie77wd Yes", "> @tangjie77wd Yes\r\n\r\nHowever,the warning is still the same.", "The warning suggested `XLA_FLAGS=--xla_hlo_profile` this too. If after setting this the things don't work then please make a comment here. Probably this may need a fix. For more details read the warning message again and try the suggestions in it.\r\nPS - Did you observe any improvements after applying https://github.com/tensorflow/tensorflow/issues/30308#issuecomment-513706301?", "> The warning suggested `XLA_FLAGS=--xla_hlo_profile` this too. If after setting this the things don't work then please make a comment here. Probably this may need a fix. For more details read the warning message again and try the suggestions in it.\r\n> PS - Did you observe any improvements after applying [#30308 (comment)](https://github.com/tensorflow/tensorflow/issues/30308#issuecomment-513706301)?\r\n\r\nIs the specific path of XLA_FLAGS=--xla_hlo_profile the same with TF_XLA_FLAGS=--tf_xla_cpu_global_jit ? ", "Yes probably, this is what my intuition says. I suspect that is there any thing extra to be installed for using XLA. In fact, you can also take a look XLA usage in tensorflow guide. @tpopp any suggestions/corrections for @tangjie77wd 's situation.", "@czgdp1807 It can not be better if there is something extra to be installed for using XLA. Do i need to do something with /mytensorflowpath/tensorflow/compiler/xla/service/BUILD ?", "> Yes probably, this is what my intuition says. I suspect that is there any thing extra to be installed for using XLA. In fact, you can also take a look XLA usage in tensorflow guide. @tpopp any suggestions/corrections for @tangjie77wd 's situation.\r\n\r\n@czgdp1807 I know i can choose opening XLA and AXV and SSE during the libtensorflow_cc.so building if i uninstall my tensorflow and rebuild it.However, i really do not want to uninstall  my tensorflow now.", "> Yes probably, this is what my intuition says. I suspect that is there any thing extra to be installed for using XLA. In fact, you can also take a look XLA usage in tensorflow guide. @tpopp any suggestions/corrections for @tangjie77wd 's situation.\r\n\r\n@czgdp1807 Am i wrong ?Maybe it is TF_XLA_FLAGS=--tf_xla_cpu_global_jit=/mytensorflowpath/tensorflow/compiler/xla/...cc or TF_XLA_FLAGS=--tf_xla_cpu_global_jit=/mytensorflowpath/tensorflow/compiler/git/...cc when i look at **TF_XLA_FLAGS=--xla_generate_hlo_graph=.* python mnist_softmax_xla.py** in link here [https://stackoverflow.com/questions/45681405/tensorflow-xla-not-producing-the-dot-file](url)", "Well, https://www.tensorflow.org/xla/jit#step_3_run_with_xla should work. Have you tried it? ", "Or what about using XLA from within the code as shown in https://www.tensorflow.org/xla/tutorials/xla_compile?", "Using the environment variable should be something like this:\r\n`export TF_XLA_FLAGS=--tf_xla_cpu_global_jit`\r\n\r\nIt is a boolean flag, so setting it to some other string evaluated to false because it did not make sense relative to a boolean value. Also, setting it without enabling XLA with --tf_xla_auto_jit=2 will not affect performance. This message being printed was a bug because it was only supposed to occur when actually using XLA.\r\n\r\nThe change would be in tf-nightly after 1 day, and I'm not sure when it would end up in the general tensorflow package.", "> Or what about using XLA from within the code as shown in https://www.tensorflow.org/xla/tutorials/xla_compile?\r\n\r\nYeah,once i have tried to active XLA before main function in my c++ code like the following:\r\n**#include \"c_api_experimental.h\"**\r\n**TF_SessionOptions* options = TF_NewSessionOptions();**\r\n**TF_EnableXLACompilation(options,true);**\r\nHowever,these above make my project building failed with error **collect2: error: ld returned 1 exit status** ! I am not only able to get [https://www.tensorflow.org/install/lang_c#compile](url) to run but also [https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/multibox_detector/main.cc](url) to run successfully before i do this above.", "> Well, https://www.tensorflow.org/xla/jit#step_3_run_with_xla should work. Have you tried it?\r\n\r\nNo,i think i can not try it since i use tensorflow 2.0 c++ api with eclipse GUI on Ubuntu 16.04 .", "> Using the environment variable should be something like this:\r\n> `export TF_XLA_FLAGS=--tf_xla_cpu_global_jit`\r\n> \r\n> It is a boolean flag, so setting it to some other string evaluated to false because it did not make sense relative to a boolean value. Also, setting it without enabling XLA with --tf_xla_auto_jit=2 will not affect performance. This message being printed was a bug because it was only supposed to occur when actually using XLA.\r\n> \r\n> The change would be in tf-nightly after 1 day, and I'm not sure when it would end up in the general tensorflow package.\r\n\r\nYou mean that the warning **(One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile** has no big effect on performance but i really get very poor performance after i replace libxgboost.so with libtensorflow_cc.so. Maybe the poor performance is cause by other warnings like the warning **Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA** or the warning **Running all optimization passes in grouping 0. If you see this a lot, you might be extending the graph too many times (which means you modify the graph many times before execution). Try reducing graph modifications or using SavedModel to avoid any graph modification**, is it right ?", "> Yes probably, this is what my intuition says. I suspect that is there any thing extra to be installed for using XLA. In fact, you can also take a look XLA usage in tensorflow guide. @tpopp any suggestions/corrections for @tangjie77wd 's situation.\r\n\r\nSorry for my negligent reply . The warning **2019-07-23 10:17:57.259354: E tensorflow/core/util/command_line_flags.cc:106] Couldn't interpret value =/mytensorflowpath/tensorflow/compiler/xla:=--tf_xla_cpu_global_jit for fl_jlag tf_xla_cpu_globait.** occurs after i set environment variable **export TF_XLA_FLAGS=--tf_xla_cpu_global_jit=/mytensorflowpath/tensorflow/compiler/xla:$TF_XLA_FLAGS=--tf_xla_cpu_global_jit** . I observe it just now. I think this new warning means setting environment failed, is it right?", "AFAICT, Yes.", "> AFAICT, Yes.\r\n\r\nWell,how do you set the environment variable of XLA_FLAGS or TF_XLA_FLAGS since add **export TF_XLA_FLAGS=--tf_xla_cpu_global_jit=/mytensorflowpath/tensorflow/compiler/xla:$TF_XLA_FLAGS=--tf_xla_cpu_global_jit** to /etc/profile is wrong ? I think the correct is like TF_XLA_FLAGS=export TF_XLA_FLAGS=/mytensorflowpath/tensorflow/compiler/xla/someglobalgitpath:$TF_XLA_FLAGS but i do not know what is the specific path of tensorflow XLA cpu global git or XLA hlo profile.", "@tangjie77wd I use linux and on that probably using the suggestion in https://github.com/tensorflow/tensorflow/issues/30308#issuecomment-513985618 should work. If you are facing problems in using XLA with environment flags then I would suggest you to use `xla.compile` in your code for compiling the model. I have given the associated link in https://github.com/tensorflow/tensorflow/issues/30308#issuecomment-513751793", "> @tangjie77wd I use linux and on that probably using the suggestion in [#30308 (comment)](https://github.com/tensorflow/tensorflow/issues/30308#issuecomment-513985618) should work. If you are facing problems in using XLA with environment flags then I would suggest you to use `xla.compile` in your code for compiling the model. I have given the associated link in [#30308 (comment)](https://github.com/tensorflow/tensorflow/issues/30308#issuecomment-513751793)\r\n\r\nThanks anyway. I have looked at  [https://www.tensorflow.org/xla/tutorials/xla_compile](url)  once but it  is not suitable for me because i do prediction with C++ API not Python.", "@tpopp Is there any C++ API for XLA compile. May be if it exists then it can be added to https://www.tensorflow.org/xla/tutorials/xla_compile . Or any trick for using `xla.compile` in C++ code will be helpful. Thanks. ", "> @tpopp Is there any C++ API for XLA compile. May be if it exists then it can be added to https://www.tensorflow.org/xla/tutorials/xla_compile . Or any trick for using `xla.compile` in C++ code will be helpful. Thanks.\r\n\r\nI think sentenses below  maybe is XLA C++ API:\r\n**#include \"c_api_experimental.h\"\r\nTF_SessionOptions* options = TF_NewSessionOptions();\r\nTF_EnableXLACompilation(options,true);*\r\nIt can not be built successuffly because it need some XLA libraries .However, i do not find any .so file in /mytensorflowpath/tensorflow/compiler/xla/client/lib and there are only some c++ source file and c++ header file .", "There is not a C++ API for XLA compile. If you think there would be use in this, feel free to open another issue, and someone with more insight than me can respond.\r\n\r\nI will close this issue as the bug this was opened for is now fixed at head. \r\n\r\nRegarding the other issues for @tangjie77wd, It looks like you're still adding other information when setting the flag. It should be exactly `TF_XLA_FLAGS=--tf_xla_cpu_global_jit` while it looks like you're adding other path information leading to it being unable to parse. As you said in one issue though, you don't have Tensorflow built with XLA, so it doesn't matter anyway. The reason you are seeing this message is just because of a bug in the logging information and won't make a difference anyway.\r\n\r\nI would advise just ignoring the message for now if you can. And regarding the Tensorflow being slower than Boost for your use case, you'll probably get the best result looking for help with the stack overflow community.", "@tpopp Thank you,i have already solved the problem."]}, {"number": 30307, "title": "categorical feature columns usage together with DenseFeatures layers in Keras fails with 1.14", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **yes**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **MacOS** and **Ubuntu**\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):  1.14 and nightly. **This code works with 2.0.0b1**\r\n\r\n**Describe the current behavior**\r\n\r\n`feature_column.categorical_column_with_vocabulary_list` does not correctly works with TF 1.14 and nightly when using it together with `tf.keras.layers.DenseFeatures`.\r\n\r\nWe get the error: \r\n\r\n```Table not initialized.\r\nFailedPreconditionError: Table not initialized.\r\n\t [[{{node sequential/dense_features/x_embedding/hash_table_Lookup/LookupTableFindV2}}]]```\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nExpected to fit the model without errors.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\ntf.__version__\r\n\r\nx = np.random.choice(3, 1000)\r\nx = np.reshape(x, newshape=[1000,1])\r\n\r\ny = np.random.normal(size = 1000)\r\n\r\nfc = tf.feature_column.categorical_column_with_vocabulary_list(\"x\",vocabulary_list=[0,1,2,3])\r\nem = tf.feature_column.embedding_column(fc, dimension = 10)\r\n\r\nmodel = tf.keras.Sequential([\r\n  tf.keras.layers.DenseFeatures(feature_columns=[em]),\r\n  tf.keras.layers.Dense(units = 1)\r\n])\r\n\r\nmodel.compile(loss = \"mse\", optimizer = \"adam\")\r\n\r\nmodel.fit(x = {'x': x}, y = y)\r\n```\r\n\r\nfails with log:\r\n\r\n```\r\n2019-07-02 13:27:03.558149: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-07-02 13:27:03.575154: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8bb54f5f00 executing computations on platform Host. Devices:\r\n2019-07-02 13:27:03.575169: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-07-02 13:27:03.615659: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1558] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\r\n2019-07-02 13:27:03.763974: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at lookup_table_op.cc:809 : Failed precondition: Table not initialized.\r\nFailedPreconditionError: Table not initialized.\r\n\t [[{{node sequential/dense_features/x_embedding/hash_table_Lookup/LookupTableFindV2}}]]\r\n```\r\n", "comments": ["@dfalbel I could able to reproduce the issue with Tensorflow 1.14.0 on Colab. And it is working as expected with Tensorflow 2.0.0.beta1.  Thanks!", "In TF v1, you will need to initialize all tables (this is no longer required in v2).\r\n\r\nSee https://www.tensorflow.org/api_docs/python/tf/initialize_all_tables", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30307\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30307\">No</a>\n"]}, {"number": 30306, "title": "[tf.keras] predict_generator stuck with using use_multiprocessing=True", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Debian 9.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 1.14\r\n- Python version: 3.5\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: Tesla P100 - 16280MiB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nWhen I use `model.predict_generator` with `use_multiprocessing=True` the code gets stuck.\r\n**Describe the expected behavior**\r\nIdeally the code should not get stuck and all cores should be used for predictions.\r\n**Code to reproduce the issue**\r\n\r\n```\r\nfrom tensorflow.keras.layers import Conv3D, MaxPool3D, Flatten, Dense\r\nfrom tensorflow.keras.layers import Dropout, Input, BatchNormalization\r\nfrom tensorflow.keras.layers import AvgPool3D\r\nfrom tensorflow.keras import Model\r\nfrom tensorflow.keras.optimizers import Adam\r\nfrom tensorflow.keras.utils import Sequence\r\nfrom tensorflow.keras import callbacks\r\nfrom tensorflow.keras.layers import Concatenate, Add\r\nfrom tensorflow.keras.estimator import model_to_estimator\r\nfrom tensorflow.keras.utils import multi_gpu_model\r\nfrom tensorflow.keras.utils import Sequence\r\nimport tensorflow as tf\r\n\r\n\r\ndef build_model(input_shape=(128, 128, 50, 1), n_class=3, multilabel=False):\r\n   \r\n    def spatial_reduction_block(inputs, block_name):\r\n        filters = inputs._shape_as_list()[-1]\r\n        with tf.name_scope(block_name):\r\n            maxpool = MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='same')(inputs)\r\n            conv_a_0 = Conv3D(filters=filters//4, kernel_size=(3, 3, 3), strides=(2, 2, 2), padding='same', activation='relu')(inputs)\r\n            conv_b_0 = Conv3D(filters=filters, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same', activation='relu')(inputs)\r\n            conv_c_0 = Conv3D(filters=filters, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same', activation='relu')(inputs)\r\n\r\n            conv_b_1 = Conv3D(filters=(5*filters)//16, kernel_size=(3, 3, 3), strides=(2, 2, 2), \r\n                              padding='same', activation='relu')(conv_b_0)\r\n            conv_c_1 = Conv3D(filters=(5*filters)//16, kernel_size=(3, 3, 3), strides=(1, 1, 1), \r\n                              padding='same', activation='relu')(conv_c_0)\r\n            conv_c_2 = Conv3D(filters=(7*filters)//16, kernel_size=(3, 3, 3), strides=(2, 2, 2), \r\n                              padding='same', activation='relu')(conv_c_1)\r\n\r\n            concat_output = Concatenate()([maxpool, conv_a_0, conv_b_1, conv_c_2])\r\n\r\n        return concat_output\r\n\r\n    def residual_convolution_block(inputs, block_name):\r\n        filters = inputs._shape_as_list()[-1]\r\n        with tf.name_scope(block_name):\r\n            conv_a_0 = Conv3D(filters=filters//2, kernel_size=(3, 3, 3), strides=(1, 1, 1), padding='same', activation='relu')(inputs)\r\n            conv_b_0 = Conv3D(filters=filters//2, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same', activation='relu')(inputs)\r\n            conv_c_0 = Conv3D(filters=filters//2, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same', activation='relu')(inputs)\r\n\r\n            conv_b_1 = Conv3D(filters=filters//2, kernel_size=(3, 3, 3), strides=(1, 1, 1), padding='same', activation='relu')(conv_b_0)\r\n            conv_c_1 = Conv3D(filters=filters//2, kernel_size=(3, 3, 3), strides=(1, 1, 1), padding='same', activation='relu')(conv_c_0)\r\n            conv_c_2 = Conv3D(filters=filters//2, kernel_size=(3, 3, 3), strides=(1, 1, 1), padding='same', activation='relu')(conv_c_1)\r\n\r\n            concat_output = Concatenate()([conv_a_0, conv_b_1, conv_c_2])\r\n\r\n            conv_d_0 = Conv3D(filters=filters, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same', activation='relu')(concat_output)\r\n\r\n            add_1 = Add()([conv_d_0, inputs])\r\n\r\n        return add_1\r\n    \r\n    if not multilabel:\r\n        activation_fn = 'softmax'\r\n    else:\r\n        activation_fn = 'sigmoid'\r\n    \r\n    inputs = Input(shape=input_shape, name='inputs')\r\n    conv_1 = Conv3D(filters=64, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same', activation='relu')(inputs)\r\n    spatial_reduction_block_1 = spatial_reduction_block(conv_1, 'spatial_reduction_block_1')\r\n    residual_convolution_block_1 = residual_convolution_block(spatial_reduction_block_1, 'residual_convolution_block_1')\r\n    spatial_reduction_block_2 = spatial_reduction_block(residual_convolution_block_1, 'spatial_reduction_block_2')\r\n    residual_convolution_block_2 = residual_convolution_block(spatial_reduction_block_2, 'residual_convolution_block_2')\r\n    conv_2 = Conv3D(filters=512, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same', activation='relu')(residual_convolution_block_2)\r\n    maxpool_1 = MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid')(conv_2)\r\n    conv_3 = Conv3D(filters=1024, kernel_size=(1, 1, 1), strides=(1, 1, 1), padding='same', activation='relu')(maxpool_1)\r\n    maxpool_2 = MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid')(conv_3)\r\n    flatten = Flatten()(maxpool_2)\r\n    dropout_1 = Dropout(rate=0.2)(flatten)\r\n    dense_1 = Dense(512, activation='sigmoid')(dropout_1)\r\n    dropout_2 = Dropout(rate=0.2)(dense_1)\r\n    outputs = Dense(n_class, activation=activation_fn, name='outputs')(dropout_2)\r\n    \r\n    model = Model(inputs=inputs, outputs=outputs)\r\n    return model\r\n\r\nmodel = build_model((128,128,50, 1), 3, False)\r\n\r\nclass mygenerator(Sequence):\r\n    def __init__(self, x_set, y_set, batch_size, augment=False):\r\n        self.x, self.y = x_set, y_set\r\n        self.batch_size = batch_size\r\n        self.augment = augment\r\n    \r\n    def __len__(self):\r\n        return int(np.ceil(len(self.x) / float(self.batch_size)))\r\n    \r\n    def __getitem__(self, idx):\r\n        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\r\n        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\r\n        \r\n        x = [read_image(filename, self.augment) for filename in batch_x] # read a numpy array named filename\r\n        y = [read_label(label) for label in batch_y]\r\n        \r\n        return np.array(x), np.array(y)\r\n\r\ntest_generator = mygenerator(X_TEST, Y_TEST, eval_batch_size, augment=False)\r\n\r\npreds = model.predict_generator(test_generator, verbose=1, use_multiprocessing=True, steps=eval_steps)\r\n\r\n```\r\n**Other info / logs**\r\nNA", "comments": ["@jashshah ,\r\nWhen trying to reproduce the issue, NameError: name 'model' is not defined. Can you please share the complete reproducible code.", "@rmothukuru I have shared the code to create the model. Do you want the code used to train the model as well?", "@jashshah ,\r\nThank you for the code. When I tried executing it, I am getting the error,\r\n\r\n`---> 79 model = build_model((128,128,50), 3, False)`\r\n\r\n`ValueError: Input 0 of layer conv3d is incompatible with the layer: expected ndim=5, found ndim=4. Full shape received: [None, 128, 128, 50]`. \r\n\r\n", "@rmothukuru My apologies for the error. I have updated the code. ", "@jashshah ,\r\nCan you please confirm if you are getting below mentioned Exception when the execution is stuck.\r\n\r\n```\r\nException in thread Thread-4:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.6/threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\", line 742, in _run\r\n    sequence = list(range(len(self.sequence)))\r\n  File \"<ipython-input-1-f6db4c2102ca>\", line 93, in __len__\r\n    return int(np.ceil(len(self.x) / float(self.batch_size)))\r\nTypeError: object of type 'int' has no len()\r\n```", "@rmothukuru I am not getting any sort of error. The execution just remains stuck with 0% volatile GPU-Utilization even though the GPU memory usage is around 15GB.", "@rmothukuru is there any work around for now while the bug is fixed? I am unable to speed up inference since I cannot use multiprocessing.", "@jashshah The code snippet you provided is incomplete. Can you please update it and also as a sanity check for gpu config., Can you please try to execute your code in [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true) using gpu (clcik edit notebook settings and select gpu from the drop down). Thanks!", "@ymodak can you tell me where the code is incomplete? I believe @rmothukuru was able to reproduce the issue. The only thing that I cannot provide you with is the data since that is proprietary. ", "@ymodak ,\r\nSorry for the confusion. Reproduced the code in Google Colab with GPU as Runtime, with TF Version, 1.14 and with Dummy Data. This is the [Gist](https://colab.sandbox.google.com/drive/1BmaVlJHPX9dsJ1QNpkZKbbZkgWBvdaLR#scrollTo=VjoPXkL5SNbN).\r\n\r\nExecution was stuck as explained by @jashshah,  with the exception shown below, as I might have used X_TEST and Y_TEST as simple integers. Thanks.\r\n\r\n```\r\nException in thread Thread-4:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.6/threading.py\", line 864, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\", line 742, in _run\r\n    sequence = list(range(len(self.sequence)))\r\n  File \"<ipython-input-10-c2c93000e6bc>\", line 10, in __len__\r\n    return int(np.ceil(len(self.x) / float(self.batch_size)))\r\nTypeError: object of type 'int' has no len()\r\n```", "@jashshah Apologies for the delay in response. I believe ```use_multiprocessing``` argument is irrelevant in this case, since the code snippet fails with same error even after setting it to false.\r\nWere you able to execute it by setting it to false?", "@ymodak I am able to execute it when `use_multiprocessing` argument is set to `False`.", "My guess is that a deadlock occurred within keras.utils.OrderedEnqueuer (which is used when the generator is a sequence). Please confirm if you experience the same stall with fit_generator or evaluate_generator. Also please check if keras.experimental.terminate_keras_multiprocessing_pools returns any useful errors: https://www.tensorflow.org/api_docs/python/tf/keras/experimental/terminate_keras_multiprocessing_pools\r\n\r\nThanks!", "Closing as there isn't enough information to reproduce the issue. Feel free to re-open if you have a run-able colab.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30306\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30306\">No</a>\n", "@rmothukuru  did you solved the problem? I'm getting the same error "]}]