[{"number": 44771, "title": "[CherryPick:r2.4] Expose Logging C API in pip package", "body": "**Note: this is an r2.4 PR** /cc @mihaimaruseac It might make sense to apply a82cdca (PR #44690) to 2.4. Though I am not sure if branch 2.4 still accept cherry-picks, so please feel free to close the PR if not appropriate.\r\n\r\nWhile working on modular file systems, noticed that the logging\r\nC API headers are not included in tensorflow pip packages.\r\n\r\nThis limit the ability for plugins to add logging in the file system.\r\n\r\nThis PR adds logging C API header in pip package.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["cc @mihaimaruseac to take a look."]}, {"number": 44770, "title": "tf.keras.preprocessing.image_dataset_from_directory ignores labels passed in 'labels' argument", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nyes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\nbinary\r\n- TensorFlow version (use command below):\r\ntensorflow-gpu 2.3.0\r\n- Python version:\r\n3.8.3\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\nCUDA Version: 10.1\r\n- GPU model and memory:\r\n4 x Tesla P100 16GB\r\n\r\n\r\n**Describe the current behavior**\r\ntf.keras.preprocessing.image_dataset_from_directory creates labels based on the subdirectories despite labels being passed explicitly. Despite labels from 6 different classes being passed, only 3 are recognized (from the folder structure). The issue persists if I only have one subfolder in the directory.\r\n**Describe the expected behavior**\r\nThe expectation is for the labels not to be ignored, and to be used instead of trying to infer them from the folder structure.\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\ntrain = tf.keras.preprocessing.image_dataset_from_directory(\r\n                    '/home/jupyter/JM/images', labels=list(np.uint8(np.round(np.random.random(6613)*5))),\r\n    image_size=(1024, 1024), validation_split=0.3, subset = 'training', seed = 42, label_mode = 'categorical')\r\n\r\nfile path is irrelevant - just choose a viable file path with subdirectories and replace the 6613 with the number of files in the subdirectories\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\nFound 6613 files belonging to 3 classes.", "comments": ["I've started to fix https://github.com/tensorflow/tensorflow/issues/44752 with https://github.com/tensorflow/tensorflow/pull/44769.\r\n\r\nYour problem is  `num_classes=len(class_names)` I will try to fix after i got a feedback at https://github.com/tensorflow/tensorflow/pull/44769.", "@ravikyram is this being resolved?", "@Justus-M \r\nCould you please check with the latest tf version and update us, as the PR is merged this should be resolved,", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "I had already requested, six months ago, what is the behavior that we want to have with this API https://github.com/tensorflow/tensorflow/pull/44769#issuecomment-727277002. \r\nI think we need a description about what the team want to do in cases like this one. /cc @nikitamaia ", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44770\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44770\">No</a>\n"]}, {"number": 44769, "title": "Fix class_names in image_dataset_from_directory", "body": "Initial fix of https://github.com/tensorflow/tensorflow/issues/44752", "comments": ["@fchollet Do you want that we handle directory/subdirectory walking strategy here? What behavior do you want?\r\n\r\nAlso do you want a separate PR for https://github.com/tensorflow/tensorflow/issues/44770? \r\n\r\nCause if we want to think about a refactoring it could impact both tickets.", "@fchollet Let me know what do you want to do with the original issue at https://github.com/tensorflow/tensorflow/issues/44752"]}, {"number": 44768, "title": "tf.distribute.experimental.CommunicationOptions does not work at all", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.4-rc1\r\n- Python version: 3.7\r\n\r\n**Describe the current behavior**\r\n\r\nThe implementation of `tf.distribute.experimental.CommunicationOptions` tries to use some trickery (for unknown reason) and fails to do anything in its constructor. See https://github.com/tensorflow/tensorflow/blob/bd3a5259f5a1b07a5e899bf86a47d8a4141c2374/tensorflow/python/distribute/collective_util.py#L84 and https://github.com/tensorflow/tensorflow/blob/bd3a5259f5a1b07a5e899bf86a47d8a4141c2374/tensorflow/python/distribute/collective_util.py#L114\r\n\r\nThis makes it impossible to use the non-deprecated `tf.distribute.MultiWorkerMirroredStrategy` and specify the communication backend as that requires to create such an options instance\r\n\r\n**Describe the expected behavior**\r\n\r\nCreating an instance of that class initializes the members\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\nimport tensorflow as tf\r\ntf.distribute.experimental.CommunicationOptions(bytes_per_pack=-1) # This should fail!\r\ncommunication = tf.distribute.experimental.CommunicationImplementation.NCCL\r\no = tf.distribute.experimental.CommunicationOptions(implementation=communication)\r\nassert o.implementation == communication # Error: no attribute 'implementation'\r\n```\r\n\r\n**Other info / logs**\r\n\r\nIMO this is critical for the 2.4 release and the fix is rather simple: Don't have an extra Options class but simply put that code into `_OptionsExported` and let `Hints` derive from that. To not disturb other (internal) code renaming `_OptionsExported` to `Options` would be wise.\r\n", "comments": ["It's to separate internal APIs and external APIs (e.g. the merge() method).  A fix is in the pipeline and will be cherrypicked.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44768\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44768\">No</a>\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44768\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44768\">No</a>\n"]}, {"number": 44767, "title": "**kwargs weights - Initialization Layer", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nWhen a Layer is initialized, or a subclassed layer as Dense, with 'weights' among the **kwargs, no weights are stored apparently. I believe the bug is in line 2658 in the base_layer.py file.\r\n\r\n**Describe the expected behavior**\r\n\r\nI would expect to have weights set as per initialization, when calling Layer.get_weights()\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nimport tensorflow as tf\r\n\r\nweights = tf.random.uniform(shape = [20,10]), tf.random.uniform(shape = [10,])\r\n\r\nlayer = tf.keras.layers.Layer(weights = weights)\r\ndense = tf.keras.layers.Dense(10, weights = weights)\r\n\r\nlayer.get_weights()\r\ndense.get_weights()\r\n\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@msqueo \r\n\r\nWe see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced]\r\nI ran the code shared on tf 2.3, please refer to [this gist](https://colab.research.google.com/gist/Saduf2019/ed8b3f6db002f57cf0a4b5c7f70cd6af/untitled460.ipynb) and confirm.\r\n", "```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nweights = np.ones((10, 11))\r\ndense = tf.keras.layers.Dense(units=11, input_shape=(10,),\r\n                          weights=[weights],\r\n                          use_bias=False)\r\nmodel = tf.keras.models.Sequential()\r\nmodel.add(dense)\r\ndense_init_weights = model.layers[0].get_weights()\r\nnp.allclose(weights,dense_init_weights)\r\n```", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@Saduf2019 thanks for taking care of this issue. Yes, I am using it on TensorFlow 2.3.0.\r\n@bhack thanks for your solution. I assume that you are able to retrieve custom weights, initialized at layer inception, only if the layer is assigned to a model. Correct? ", "> thanks for your solution. I assume that you are able to retrieve custom weights, initialized at layer inception, only if the layer is assigned to a model. Correct?\r\n\r\nCheck layers methods e.g. `build` at https://keras.io/guides/making_new_layers_and_models_via_subclassing/", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44767\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44767\">No</a>\n"]}, {"number": 44766, "title": "Could not compute output tensor even when correct inputs are being passed to keras model", "body": "I was trying to create frozen graph for the below mentioned model but when I call get_concrete_function i always get assertion error:\r\n\r\n  **AssertionError: Could not compute output Tensor(\"alpha_beta/add:0\", shape=(None, 2), dtype=float32)**\r\nNot sure what am I missing here, I have verified the number of inputs are correct and model gives no errors while training with same inputs.\r\nTensorFlow version- 2.3\r\nAny help here would be much appreciated!\r\n\r\n\r\ndef get_model(features:List[F.BaseInputFeature], **kwargs) -> keras.Model:\r\n    inputs, concats = zip(*[feature.get_input() for feature in features])\r\n\r\n    def model_block(size, postfix):\r\n        \"\"\"\r\n        Helper function for creating a dense block.\r\n        Use a fully connected layer followed by Batch Norm and Dropout for \r\n        Regularization and faster training.\r\n        \"\"\"\r\n        def result(input):\r\n            model = keras.layers.Dense(size, activation=tf.nn.relu, name='inner_Dense-%s' % postfix)(input)\r\n            model = keras.layers.BatchNormalization(name='inner_BatchNorm-%s' % postfix)(model)\r\n            return keras.layers.Dropout(0.2, name='inner_Dropout-%s' % postfix)(model)\r\n        return result\r\n    print(inputs)\r\n    output = keras.layers.Concatenate(name='inner_concat')(list(concats))\r\n    for i, size in enumerate([256, 256, 256, 128, 128, 128, 64, 64, 64]):\r\n        output = model_block(size, str(i))(output)\r\n\r\n    dist = keras.layers.Dense(2, name='alpha_beta', activation=custom_activation)(output)\r\n    print('dist-', dist)\r\n    from keras.utils.generic_utils import get_custom_objects\r\n    from keras.layers import Activation\r\n    from tensorflow.python.tools import freeze_graph\r\n    from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\r\n\r\n    get_custom_objects().update({'custom_activation': Activation(custom_activation)})\r\n    model = tf.keras.Model(inputs=list(inputs), outputs=[dist])\r\n\r\n\r\n    model.compile(optimizer=keras.optimizers.Adam(lr=1e-2), loss=[loss], metrics=[metric])\r\n\r\n    # Convert Keras model to ConcreteFunction\r\n    full_model = tf.function(lambda x: model(x))\r\n    print(full_model)\r\n    full_model = full_model.get_concrete_function(\r\n        tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype))\r\n    # Get frozen ConcreteFunction\r\n    frozen_func = convert_variables_to_constants_v2(full_model)\r\n    frozen_func.graph.as_graph_def()\r\n    layers = [op.name for op in frozen_func.graph.get_operations()]\r\n    print(\"-\" * 50)\r\n    print(\"Frozen model layers: \")\r\n    for layer in layers:\r\n        print(layer)\r\n    print(\"-\" * 50)\r\n    print(\"Frozen model inputs: \")\r\n    print(frozen_func.inputs)\r\n    print(\"Frozen model outputs: \")\r\n    print(frozen_func.outputs)\r\n    # Save frozen graph from frozen ConcreteFunction to hard drive\r\n    tf.io.write_graph(graph_or_graph_def=frozen_func.graph,\r\n                      logdir=\"./frozen_models\",\r\n                      name=\"frozen_graph.pb\",\r\n                      as_text=False)\r\n\r\n    return model\r\n", "comments": ["@Pratibha2007 \r\n\r\nPlease, share colab link or simple standalone code with proper indentation and supporting files to reproduce the issue in our environment. It helps us in localizing the issue folder. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 44765, "title": "ImportError: cannot import name 'np_utils' in ImageDataGenerator", "body": "The TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#examples_2\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description: `np_utils` is no longer available. It should be replaced with `utils`. Reproducible code is mentioned in [this Colab](https://colab.research.google.com/gist/rmothukuru/ebaf4d013cfaaba3816353cb5b8e3604/bug_fix_imagedatagen_flow.ipynb).\r\n\r\nFor example, why should someone use this method? How is it useful? : Developers using `ImageDataGenerator.flow` use this code.\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct? : Yes\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly? : Yes\r\n\r\n### Returns defined\r\n\r\nAre return values defined? : Yes\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? No\r\n\r\n### Usage example\r\n\r\nIs there a usage example? : Yes\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n", "comments": ["Was able to reproduce the issue with TF v2.3 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/31e386806706356954977ff2f431015e/44765.ipynb). Thanks!"]}, {"number": 44764, "title": "Replaced np_utils with utils in image.py", "body": "Replaced np_utils with utils, as np_utils is removed in TF 2.x", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F44764) for more info**.\n\n<!-- need_author_cla -->"]}, {"number": 44763, "title": "Failed to serialize the input pipeline graph: PyFunc is stateful. [Op:DatasetToGraphV2]", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 20.04):\r\n- TensorFlow installed from (source or binary): binary build from branch `2.3.0`\r\n- TensorFlow version (use command below): 2.3.0\r\n- Python version: 3.8.5\r\n- Bazel version (if compiling from source): 3.1.0\r\n- CUDA/cuDNN version: 11.1, 8.0.4\r\n- GPU model and memory: Nvidia GeForce 1060 6Gb\r\n\r\n**Describe the current behavior**\r\nI am using a custom model that inherits from `tf.Module`. Also for some logic I am using `tf-addons==0.11.2`\r\nEverything trains ok, without problem, however when I am using `tf.saved_model.save(custom_model, path)` I get the error below in logs section.\r\nI found this issue after tensorflow update 2.1.0 source to 2.3.0 binary.\r\n\r\n**Standalone code to reproduce the issue**\r\nBelow is my train code:\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow_addons as tfa\r\n\r\nclass NERTrainer(tf.Module):\r\n    ..........\r\n    def _helpers_(self):\r\n        pass\r\n    ..........\r\n    def train(self):\r\n        ix = 0\r\n        for words, chars, labels, sentence_lengths in self._training_dataset:\r\n            with tf.GradientTape() as tape:\r\n                embeddings = self._add_embeddings_transformations(words, chars, ix)\r\n                logits = self._add_logits(embeddings, ix)\r\n                labels = tf.cast(labels, tf.int32)\r\n                sentence_lengths = tf.cast(sentence_lengths, tf.int32)\r\n\r\n                log_likelihood, transition_parameters = tfa.text.crf_log_likelihood(\r\n                    logits, labels, sentence_lengths\r\n                )\r\n                log_likelihood = tf.reduce_mean(-log_likelihood)\r\n            gradients = tape.gradient(log_likelihood, self._trainables)\r\n            self.optimizer.apply_gradients(zip(gradients, self._trainables))\r\n            ix += 1\r\n\r\n        self._transition_parameters = tf.constant(transition_parameters.numpy())\r\n        scores = self._run_evaluation(train_dataset=False)\r\n        return {'avg_f1': np.mean(scores['f1'])}\r\n\r\nif '__name__' == '__main__':\r\n    nn_trainer = NERTrainer()\r\n    num_epochs = 10\r\n    for ix in range(num_epochs):\r\n            print('Epoch #{}'.format(ix))\r\n            logger.info('Epoch #{}'.format(ix))\r\n    \r\n            nn_trainer.train()\r\n            nn_trainer.lr *= nn_trainer.lr_decay\r\n            \r\n            tf.saved_model.save(nn_trainer, target_save_path)\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\nAll logs while training:\r\n```\r\n2020-11-11 14:21:33.948277: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\r\n2020-11-11 14:21:33.948441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-11 14:21:33.948969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:0a:00.0 name: GeForce GTX 1060 6GB computeCapability: 6.1\r\ncoreClock: 1.8095GHz coreCount: 10 deviceMemorySize: 5,93GiB deviceMemoryBandwidth: 178,99GiB/s\r\n2020-11-11 14:21:33.948983: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.1\r\n2020-11-11 14:21:33.950141: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11\r\n2020-11-11 14:21:33.950597: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-11-11 14:21:33.950717: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-11-11 14:21:33.951851: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.11\r\n2020-11-11 14:21:33.952087: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11\r\n2020-11-11 14:21:33.952157: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\r\n2020-11-11 14:21:33.952243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-11 14:21:33.952820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-11 14:21:33.953190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-11-11 14:21:33.953398: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-11-11 14:21:33.980819: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 3792500000 Hz\r\n2020-11-11 14:21:33.981555: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x791e0e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-11-11 14:21:33.981578: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-11-11 14:21:34.038911: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-11 14:21:34.039310: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x78fa260 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-11-11 14:21:34.039330: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1060 6GB, Compute Capability 6.1\r\n2020-11-11 14:21:34.039561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-11 14:21:34.040024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:0a:00.0 name: GeForce GTX 1060 6GB computeCapability: 6.1\r\ncoreClock: 1.8095GHz coreCount: 10 deviceMemorySize: 5,93GiB deviceMemoryBandwidth: 178,99GiB/s\r\n2020-11-11 14:21:34.040053: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.1\r\n2020-11-11 14:21:34.040099: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11\r\n2020-11-11 14:21:34.040122: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-11-11 14:21:34.040141: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-11-11 14:21:34.040160: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.11\r\n2020-11-11 14:21:34.040178: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11\r\n2020-11-11 14:21:34.040196: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\r\n2020-11-11 14:21:34.040286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-11 14:21:34.040790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-11 14:21:34.041208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-11-11 14:21:34.041240: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.1\r\n2020-11-11 14:21:34.268942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-11-11 14:21:34.268983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \r\n2020-11-11 14:21:34.268992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \r\n2020-11-11 14:21:34.269251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-11 14:21:34.269571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-11 14:21:34.269829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5006 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:0a:00.0, compute capability: 6.1)\r\nEpoch #0\r\n2020-11-11 14:21:34.496695: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\r\n2020-11-11 14:21:34.824964: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11\r\n2020-11-11 14:22:03.651363: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\r\nTraceback (most recent call last):\r\n  File \"ner.py\", line 358, in <module>\r\n    tf.saved_model.save(nn_trainer, target_save_path)\r\n  File \"/home/kirill/.local/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py\", line 975, in save\r\n    _, exported_graph, object_saver, asset_info = _build_meta_graph(\r\n  File \"/home/kirill/.local/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py\", line 1061, in _build_meta_graph\r\n    _ = _SaveableView(checkpoint_graph_view)\r\n  File \"/home/kirill/.local/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py\", line 216, in __init__\r\n    function._list_all_concrete_functions_for_serialization())  # pylint: disable=protected-access\r\n  File \"/home/kirill/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 1030, in _list_all_concrete_functions_for_serialization\r\n    concrete_functions = self._list_all_concrete_functions()\r\n  File \"/home/kirill/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 1012, in _list_all_concrete_functions\r\n    self.get_concrete_function()\r\n  File \"/home/kirill/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 1167, in get_concrete_function\r\n    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)\r\n  File \"/home/kirill/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 1073, in _get_concrete_function_garbage_collected\r\n    self._initialize(args, kwargs, add_initializers_to=initializers)\r\n  File \"/home/kirill/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 696, in _initialize\r\n    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n  File \"/home/kirill/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 2855, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/home/kirill/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3213, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/home/kirill/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3065, in _create_graph_function\r\n    func_graph_module.func_graph_from_py_func(\r\n  File \"/home/kirill/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 986, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/home/kirill/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 600, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/home/kirill/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py\", line 262, in _creator\r\n    resource = self._create_resource()\r\n  File \"/home/kirill/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 205, in <lambda>\r\n    lambda: weak_self._trace_variant_creation()()),  # pylint: disable=unnecessary-lambda,protected-access\r\n  File \"/home/kirill/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 277, in _trace_variant_creation\r\n    self._as_serialized_graph(external_state_policy=distribute_options\r\n  File \"/home/kirill/.local/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/kirill/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 248, in _as_serialized_graph\r\n    return gen_dataset_ops.dataset_to_graph_v2(\r\n  File \"/home/kirill/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1122, in dataset_to_graph_v2\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/home/kirill/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 6843, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.FailedPreconditionError: Failed to serialize the input pipeline graph: PyFunc is stateful. [Op:DatasetToGraphV2]\r\n```\r\nI see this error the first time. Didn't find something similar.\r\nCould you help me with this issue please?\r\n", "comments": ["@Ecclesiast \r\nI ran the code shared it has syntax errors and is not indented, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/a0c28aa761df5a8df9671438fb01cff8/untitled460.ipynb). could you please share indented code such that we could replicate the issue or is possible share a colab gist with the error.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44763\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44763\">No</a>\n"]}, {"number": 44762, "title": "in nocopts attribute of cc_library rule @jpeg//:simd_none: This attribute was removed.", "body": "- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Catalina 10.15.7 (19H2)\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: r1.14\r\n- Python version: \r\npython -V\r\nPython 2.7.16\r\npython3 -V\r\nPython 3.7.7\r\n- Installed using virtualenv? pip? conda?: -\r\n- Bazel version (if compiling from source):\r\nbazel --version\r\nbazel 3.7.0-homebrew\r\n- GCC/Compiler version (if compiling from source):\r\nclang -v\r\nApple clang version 11.0.3 (clang-1103.0.32.29)\r\nTarget: x86_64-apple-darwin19.6.0\r\nThread model: posix\r\nInstalledDir: /Library/Developer/CommandLineTools/usr/bin\r\n- CUDA/cuDNN version: -\r\n- GPU model and memory: -\r\n\r\n\r\n```\r\ngit clone --single-branch --branch r1.14 git@github.com:tensorflow/tensorflow.git\r\ncd tensorflow\r\nbazel build tensorflow/tools/graph_transforms:summarize_graph\r\n```\r\n\r\n```\r\nERROR: /private/var/tmp/_bazel_my_user/839731be594c2770db7eceb921cc3596/external/jpeg/BUILD.bazel:488:11: in nocopts attribute of cc_library rule @jpeg//:simd_none: This attribute was removed. See https://github.com/bazelbuild/bazel/issues/8706 for details.\r\nERROR: /private/var/tmp/_bazel_my_user/839731be594c2770db7eceb921cc3596/external/jpeg/BUILD.bazel:488:11: in nocopts attribute of cc_library rule @jpeg//:simd_none: This attribute was removed. See https://github.com/bazelbuild/bazel/issues/8706 for details.\r\nERROR: Analysis of target '//tensorflow/tools/graph_transforms:summarize_graph' failed; build aborted: Analysis of target '@jpeg//:simd_none' failed\r\nFAILED: Build did NOT complete successfully (82 packages loaded, 2745 targets configured)\r\n```\r\n", "comments": ["@mrgloom \r\n\r\nTF 1.x is not supported..Can you try with Latest stable releases TF version 2.3 and let us know if you are facing the issue. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44762\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44762\">No</a>\n"]}, {"number": 44761, "title": "Could not load dynamic library 'libcuda.so.1'", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.3.1\r\n- Python version: 3.7.9\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: cuda 10.1 cudnn7\r\n- GPU model and memory: K80\r\n\r\n\r\n\r\n**Describe the problem**\r\n```\r\n$ python -c \"import tensorflow as tf; hello = tf.constant('hello world');\"\r\n2020-11-11 10:40:12.930534: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-11-11 10:40:14.016970: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\n2020-11-11 10:40:14.017024: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\r\n2020-11-11 10:40:14.017053: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (16c54693e7f2): /proc/driver/nvidia/version does not exist\r\n2020-11-11 10:40:14.017450: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-11-11 10:40:14.041823: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300060000 Hz\r\n2020-11-11 10:40:14.042236: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558b3bbe0d40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n```\r\n", "comments": ["```\r\n$ find /usr/ -iname 'libcuda*'\r\n/usr/local/cuda-10.1/compat/libcuda.so.1\r\n/usr/local/cuda-10.1/compat/libcuda.so\r\n/usr/local/cuda-10.1/compat/libcuda.so.418.165.02\r\n/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudart.so.10.1\r\n/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudart.so.10.1.243\r\n/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudart.so\r\n/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudadevrt.a\r\n/usr/local/cuda-10.1/targets/x86_64-linux/lib/stubs/libcuda.so\r\n/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudart_static.a\r\n/usr/local/cuda-10.1/extras/Debugger/lib64/libcudacore.a\r\n/usr/local/cuda-10.1/extras/Debugger/include/libcudacore.h\r\n```", "Setting LD_LIBRARY_PATH resolves the issue:\r\n\r\n```\r\nexport LD_LIBRARY_PATH=/usr/local/cuda-10.1/compat/:$LD_LIBRARY_PATH\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44761\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44761\">No</a>\n"]}, {"number": 44760, "title": "ERROR: /data/workspace/willy_sung/tensorflow/tensorflow/python/tools/BUILD:282:1 ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 16.04.7 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:no\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version: git checkout r2.2\r\n- Python version:3.6.12\r\n- Installed using virtualenv? pip? conda?:no\r\n- Bazel version (if compiling from source):3.1.0\r\n- GCC/Compiler version (if compiling from source): 5.4.0\r\n- CUDA/cuDNN version:V10.2.89/ 7.5.0\r\n- GPU model and memory:GeForce GTX 1080 Ti 11GB  for 4 cards\r\n\r\n\r\n\r\n**Describe the problem**\r\nI want to use tensorboard on CUDA 10.2 but I found if I want tensorflow 2.2 on CUDA 10.2 with the tensorboard version\r\nI have to build from source,so I follow the instruction from [here](https://tensorflow.google.cn/install/source)\r\nERROR: /data/workspace/willy_sung/tensorflow/tensorflow/python/tools/BUILD:282:1                                   \r\nC++ compilation of rule '//tensorflow/core/kernels:sparse_tensor_dense_matmul_op_gpu' failed (Exit 1)\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n`git checkout r.2.2`\r\n`./configures`\r\n\r\n```\r\nYou have bazel 3.1.0 installed.\r\nPlease specify the location of python. [Default is /usr/bin/python3]:\r\n\r\n\r\nFound possible Python library paths:\r\n  /usr/local/lib/python3.6/dist-packages\r\n  /usr/lib/python3/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/local/lib/python3.6/dist-packages]\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: n\r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: n\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with TensorRT support? [y/N]: n\r\nNo TensorRT support will be enabled for TensorFlow.\r\n\r\nFound CUDA 10.2 in:\r\n    /usr/local/cuda-10.2/targets/x86_64-linux/lib\r\n    /usr/local/cuda-10.2/targets/x86_64-linux/include\r\nFound cuDNN 7 in:\r\n    /usr/lib/x86_64-linux-gnu\r\n    /usr/include\r\n\r\n\r\nPlease specify a list of comma-separated CUDA compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus. Each capability can be specified as \"x.y\" or \"compute_xy\" to include both virtual and binary GPU code, or as \"sm_xy\" to only include the binary code.\r\nPlease note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 6.1,6.1,6.1,6.1]: 7.5\r\n\r\n\r\nDo you want to use clang as CUDA compiler? [y/N]: n\r\nnvcc will be used as CUDA compiler.\r\n\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]:\r\n\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]:\r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n        --config=mkl            # Build with MKL support.\r\n        --config=monolithic     # Config for mostly static monolithic build.\r\n        --config=ngraph         # Build with Intel nGraph support.\r\n        --config=numa           # Build with NUMA support.\r\n        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.\r\n        --config=v2             # Build TensorFlow 2.x instead of 1.x.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n        --config=noaws          # Disable AWS S3 filesystem support.\r\n        --config=nogcp          # Disable GCP support.\r\n        --config=nohdfs         # Disable HDFS support.\r\n        --config=nonccl         # Disable NVIDIA NCCL support.\r\nConfiguration finished\r\n\r\n```\r\nthen \r\n`bazel build //tensorflow/tools/pip_package:build_pip_package`\r\n\r\n```\r\nexternal/eigen_archive/Eigen/src/Core/Ref.h(232): warning: __host__ annotation i                                  s ignored on a function(\"Ref\") that is explicitly defaulted on its first declara                                  tion\r\n\r\nexternal/eigen_archive/Eigen/src/Core/Ref.h(232): warning: __device__ annotation                                   is ignored on a function(\"Ref\") that is explicitly defaulted on its first decla                                  ration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/Block.h(111): warning: __host__ annotation                                   is ignored on a function(\"Block\") that is explicitly defaulted on its first dec                                  laration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/Block.h(111): warning: __device__ annotati                                  on is ignored on a function(\"Block\") that is explicitly defaulted on its first d                                  eclaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/Block.h(161): warning: __host__ annotation                                   is ignored on a function(\"BlockImpl\") that is explicitly defaulted on its first                                   declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/Block.h(161): warning: __device__ annotati                                  on is ignored on a function(\"BlockImpl\") that is explicitly defaulted on its fir                                  st declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/Block.h(181): warning: __host__ annotation                                   is ignored on a function(\"BlockImpl_dense\") that is explicitly defaulted on its                                   first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/Block.h(181): warning: __device__ annotati                                  on is ignored on a function(\"BlockImpl_dense\") that is explicitly defaulted on i                                  ts first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/Block.h(341): warning: __host__ annotation                                   is ignored on a function(\"BlockImpl_dense\") that is explicitly defaulted on its                                   first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/Block.h(341): warning: __device__ annotati                                  on is ignored on a function(\"BlockImpl_dense\") that is explicitly defaulted on i                                  ts first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/IndexedView.h(114): warning: __host__ anno                                  tation is ignored on a function(\"IndexedView\") that is explicitly defaulted on i                                  ts first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/IndexedView.h(114): warning: __device__ an                                  notation is ignored on a function(\"IndexedView\") that is explicitly defaulted on                                   its first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/Reshaped.h(103): warning: __host__ annotat                                  ion is ignored on a function(\"Reshaped\") that is explicitly defaulted on its fir                                  st declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/Reshaped.h(103): warning: __device__ annot                                  ation is ignored on a function(\"Reshaped\") that is explicitly defaulted on its f                                  irst declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/Reshaped.h(137): warning: __host__ annotat                                  ion is ignored on a function(\"ReshapedImpl\") that is explicitly defaulted on its                                   first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/Reshaped.h(137): warning: __device__ annot                                  ation is ignored on a function(\"ReshapedImpl\") that is explicitly defaulted on i                                  ts first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/Reshaped.h(155): warning: __host__ annotat                                  ion is ignored on a function(\"ReshapedImpl_dense\") that is explicitly defaulted                                   on its first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/Reshaped.h(155): warning: __device__ annot                                  ation is ignored on a function(\"ReshapedImpl_dense\") that is explicitly defaulte                                  d on its first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/Reshaped.h(215): warning: __host__ annotat                                  ion is ignored on a function(\"ReshapedImpl_dense\") that is explicitly defaulted                                   on its first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/Reshaped.h(215): warning: __device__ annot                                  ation is ignored on a function(\"ReshapedImpl_dense\") that is explicitly defaulte                                  d on its first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/Transpose.h(66): warning: __host__ annotat                                  ion is ignored on a function(\"Transpose\") that is explicitly defaulted on its fi                                  rst declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/Transpose.h(66): warning: __device__ annot                                  ation is ignored on a function(\"Transpose\") that is explicitly defaulted on its                                   first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/Transpose.h(126): warning: __host__ annota                                  tion is ignored on a function(\"TransposeImpl\") that is explicitly defaulted on i                                  ts first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/Transpose.h(126): warning: __device__ anno                                  tation is ignored on a function(\"TransposeImpl\") that is explicitly defaulted on                                   its first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/Transpose.h(157): warning: __host__ annota                                  tion is ignored on a function(\"TransposeImpl\") that is explicitly defaulted on i                                  ts first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/Transpose.h(157): warning: __device__ anno                                  tation is ignored on a function(\"TransposeImpl\") that is explicitly defaulted on                                   its first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/Transpose.h(157): warning: __host__ annota                                  tion is ignored on a function(\"~TransposeImpl\") that is explicitly defaulted on                                   its first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/Transpose.h(157): warning: __device__ anno                                  tation is ignored on a function(\"~TransposeImpl\") that is explicitly defaulted o                                  n its first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/Diagonal.h(78): warning: __host__ annotati                                  on is ignored on a function(\"Diagonal\") that is explicitly defaulted on its firs                                  t declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/Diagonal.h(78): warning: __device__ annota                                  tion is ignored on a function(\"Diagonal\") that is explicitly defaulted on its fi                                  rst declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/TriangularMatrix.h(222): warning: __host__                                   annotation is ignored on a function(\"TriangularView\") that is explicitly defaul                                  ted on its first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/TriangularMatrix.h(222): warning: __device                                  __ annotation is ignored on a function(\"TriangularView\") that is explicitly defa                                  ulted on its first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/TriangularMatrix.h(559): warning: __host__                                   annotation is ignored on a function(\"TriangularViewImpl\") that is explicitly de                                  faulted on its first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/TriangularMatrix.h(559): warning: __device                                  __ annotation is ignored on a function(\"TriangularViewImpl\") that is explicitly                                   defaulted on its first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/TriangularMatrix.h(560): warning: __host__                                   annotation is ignored on a function(\"TriangularViewImpl\") that is explicitly de                                  faulted on its first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/TriangularMatrix.h(560): warning: __device                                  __ annotation is ignored on a function(\"TriangularViewImpl\") that is explicitly                                   defaulted on its first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/TriangularMatrix.h(560): warning: __host__                                   annotation is ignored on a function(\"~TriangularViewImpl\") that is explicitly d                                  efaulted on its first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/TriangularMatrix.h(560): warning: __device                                  __ annotation is ignored on a function(\"~TriangularViewImpl\") that is explicitly                                   defaulted on its first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/Reverse.h(90): warning: __host__ annotatio                                  n is ignored on a function(\"Reverse\") that is explicitly defaulted on its first                                   declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/Reverse.h(90): warning: __device__ annotat                                  ion is ignored on a function(\"Reverse\") that is explicitly defaulted on its firs                                  t declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/ArrayWrapper.h(47): warning: __host__ anno                                  tation is ignored on a function(\"ArrayWrapper\") that is explicitly defaulted on                                   its first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/ArrayWrapper.h(47): warning: __device__ an                                  notation is ignored on a function(\"ArrayWrapper\") that is explicitly defaulted o                                  n its first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/ArrayWrapper.h(145): warning: __host__ ann                                  otation is ignored on a function(\"MatrixWrapper\") that is explicitly defaulted o                                  n its first declaration\r\n\r\nexternal/eigen_archive/Eigen/src/Core/ArrayWrapper.h(145): warning: __device__ a                                  nnotation is ignored on a function(\"MatrixWrapper\") that is explicitly defaulted                                   on its first declaration\r\n\r\n./tensorflow/core/platform/env.h(368): warning: overloaded virtual function \"ten                                  sorflow::Env::RegisterFileSystem\" is only partially overridden in class \"tensorf                                  low::EnvWrapper\"\r\n\r\nexternal/com_google_absl/absl/types/optional.h(428): warning: expression has no                                   effect\r\n          detected during instantiation of \"const T &absl::lts_2020_02_25::optio                                  nal<T>::operator*() const & [with T=stream_executor::dnn::AlgorithmDesc]\"\r\n./tensorflow/stream_executor/dnn.h(804): here\r\n\r\nexternal/com_google_absl/absl/types/optional.h(428): warning: expression has no                                   effect\r\n          detected during instantiation of \"const T &absl::lts_2020_02_25::optio                                  nal<T>::operator*() const & [with T=size_t]\"\r\n./tensorflow/stream_executor/dnn.h(858): here\r\n\r\nexternal/com_google_absl/absl/time/internal/cctz/include/cctz/civil_time_detail.                                  h: In function 'constexpr absl::lts_2020_02_25::time_internal::cctz::detail::civ                                  il_day absl::lts_2020_02_25::time_internal::cctz::detail::next_weekday(absl::lts                                  _2020_02_25::time_internal::cctz::detail::civil_day, absl::lts_2020_02_25::time_                                  internal::cctz::detail::weekday)':\r\nexternal/com_google_absl/absl/time/internal/cctz/include/cctz/civil_time_detail.                                  h:567:20: error: call to non-constexpr function 'absl::lts_2020_02_25::time_inte                                  rnal::cctz::detail::civil_time<absl::lts_2020_02_25::time_internal::cctz::detail                                  ::day_tag> absl::lts_2020_02_25::time_internal::cctz::detail::operator+(absl::lt                                  s_2020_02_25::time_internal::cctz::detail::civil_time<absl::lts_2020_02_25::time                                  _internal::cctz::detail::day_tag>, absl::lts_2020_02_25::time_internal::cctz::di                                  ff_t)'\r\n           return cd + (j - i);\r\n                    ^\r\nexternal/com_google_absl/absl/time/internal/cctz/include/cctz/civil_time_detail.                                  h: In function 'constexpr absl::lts_2020_02_25::time_internal::cctz::detail::civ                                  il_day absl::lts_2020_02_25::time_internal::cctz::detail::prev_weekday(absl::lts                                  _2020_02_25::time_internal::cctz::detail::civil_day, absl::lts_2020_02_25::time_                                  internal::cctz::detail::weekday)':\r\nexternal/com_google_absl/absl/time/internal/cctz/include/cctz/civil_time_detail.                                  h:587:20: error: call to non-constexpr function 'absl::lts_2020_02_25::time_inte                                  rnal::cctz::detail::civil_time<absl::lts_2020_02_25::time_internal::cctz::detail                                  ::day_tag> absl::lts_2020_02_25::time_internal::cctz::detail::operator-(absl::lt                                  s_2020_02_25::time_internal::cctz::detail::civil_time<absl::lts_2020_02_25::time                                  _internal::cctz::detail::day_tag>, absl::lts_2020_02_25::time_internal::cctz::di                                  ff_t)'\r\n           return cd - (j - i);\r\n                    ^\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nERROR: /data/workspace/willy_sung/tensorflow/tensorflow/python/tools/BUILD:282:1                                   C++ compilation of rule '//tensorflow/core/kernels:sparse_tensor_dense_matmul_o                                  p_gpu' failed (Exit 1)\r\nINFO: Elapsed time: 804.121s, Critical Path: 101.69s\r\nINFO: 5406 processes: 5406 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["As you are on gcc5 check https://github.com/tensorflow/tensorflow/issues/34946\r\n\r\n", "> As you are on gcc5 check #34946\r\nyesgcc Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609\r\nso should I use bazel build //tensorflow/tools/pip_package:build_pip_package -D_GLIBCXX_USE_CXX11_ABI=0?\r\n", "@petewarden Do you know if It is still ok to compile with gcc 5.4 with this setup?\r\n\r\nEDIT:\r\nSorry Peter I meant @perfinion \r\n", "@lunasdejavu Could you please try on the stable TF v2.6.0 and let us know if the issue still persists ? Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44760\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44760\">No</a>\n"]}, {"number": 44759, "title": "tf.nn.depth_to_space is not support", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows10 enterprise\r\n- TensorFlow installed from (source or binary): binary (pip install tensorflow==1.14)\r\n- TensorFlow version (or github SHA if from source): 1.14\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, BATCH_TO_SPACE_ND, CONV_2D, DEPTHWISE_CONV_2D, SPACE_TO_BATCH_ND, SPACE_TO_DEPTH. Here is a list of operators for which you will need custom implementations: DEPTH_TO_SPACE.\r\n```\r\n\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\nhttps://gist.github.com/goldflower/dec52a344de461413ae10de84a555b44\r\n\r\n\r\n**Any other info / logs**\r\n\r\nThe code above create the pb file and reproduce the issue.\r\n\r\nhttps://www.tensorflow.org/mlir/tfl_ops\r\n\r\nHere says tfl.depth_to_space (TFL::DepthToSpaceOp) can be support but actually not?\r\n\r\n", "comments": ["@goldflower \r\n\r\nCan you try with TF 2.x recent stable version like 2.3 and see if the issue still persists. Thanks!", "> @goldflower\r\n> \r\n> Can you try with TF 2.x recent stable version like 2.3 and see if the issue still persists. Thanks!\r\n\r\nI can convert pb to tflite with TFLiteConverter.from_frozen_graph with TF 2.3.\r\n\r\nI also noticed that I can use tflite_convert.exe with TF1.14 to convert without any problem but TFLiteConverter.from_frozen_graph didn't work even I set target_ops both TFLITE_BUILTINS and SELECT_TF_OPS.", "@goldflower So everything is working fine with TF 2.3 but you had issues with TF 1.14 only ?\r\nWe had a lot of fixes and supported many features in new TF versions. So it is better to stick with new versions.", "@karimnosseir \r\nI can use the binary (both taco and tflite_convert under 1.14) to convert it without problem.\r\nI'll use those binaries, thanks.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44759\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44759\">No</a>\n"]}, {"number": 44758, "title": "tf.random.log_uniform_candidate_sampler gives undesired true class", "body": "From tensorflow's word2vec tutorial: https://www.tensorflow.org/tutorials/text/word2vec#define_loss_function_and_compile_model\r\n\r\nNagative sampling is conducted using `tf.random.log_uniform_candidate_sampler`. Given the context class (true class), the goal is to sample negative classes from the whole vocabulary list. To my understanding, The negative classes must differ from the given context class. However, I found that the context class may appear in the negative classes sampled by tf.random.log_uniform_candidate_sampler. Here is the code:\r\n\r\n```\r\nimport tensorflow as tf\r\nSEED = 42 \r\n\r\n# encode the words\r\nsentence = \"The wide road shimmered in the hot sun\"\r\ntokens = list(sentence.lower().split())\r\nvocab, index = {}, 1 # start indexing from 1\r\nvocab['<pad>'] = 0 # add a padding token \r\nfor token in tokens:\r\n  if token not in vocab: \r\n    vocab[token] = index\r\n    index += 1\r\nvocab_size = len(vocab)\r\nprint(vocab)\r\ninverse_vocab = {index: token for token, index in vocab.items()}\r\nprint(inverse_vocab)\r\n\r\n\r\n# make (hot, the) as a context pair\r\ntarget_word, context_word = 6, 1\r\nprint(\"target: {}, context: {}\".format(inverse_vocab[target_word], inverse_vocab[context_word]))\r\n\r\n\r\n# negative sampling\r\n# Set the number of negative samples per positive context. \r\nnum_ns = 4\r\n\r\ncontext_class = tf.reshape(tf.constant(context_word, dtype=\"int64\"), (1, 1))\r\nnegative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\r\n    true_classes=context_class, # class that should be sampled as 'positive'\r\n    num_true=1, # each positive skip-gram has 1 positive context class\r\n    num_sampled=num_ns, # number of negative context words to sample\r\n    unique=True, # all the negative samples should be unique\r\n    range_max=vocab_size, # pick index of the samples from [0, vocab_size]\r\n    seed=SEED, # seed for reproducibility\r\n    name=\"negative_sampling\" # name of this operation\r\n)\r\nprint(\"negative samples\\' index: \", negative_sampling_candidates.numpy())\r\nprint(\"negetive samples: \", [inverse_vocab[index.numpy()] for index in negative_sampling_candidates])\r\n# \"the\" will show in negative samples, if not, run it several times.\r\n```\r\nThe word \"the\" is the context class of word \"hot\", why it could show in the sampled negative classes? Moreover, the target word hot could also be sampled as negative class. Do I misunderstand something?", "comments": ["Have you already seen https://www.tensorflow.org/extras/candidate_sampling.pdf ?", "> Have you already seen https://www.tensorflow.org/extras/candidate_sampling.pdf ?\r\n\r\nI've read that. If you mean \r\n\r\n> The random choice of S_i may or may not depend on x_i and/or T_i.\r\n\r\nBut if positive sample can show in negative samples, why the function have this `true_classes` argument? And what does the comment `# class that should be sampled as 'positive'` in the word2vec tutorial mean, what's the effect of **sampled as positive**?\r\n", "Was able to reproduce the issue with TF v2.3 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/0af7d3fc721a80b2bf6e3ae809000fa7/44758.ipynb). Thanks!", "@Yu-Qing-Wang I am not deeply in this op but I think that `true_class` interpretation is in https://github.com/tensorflow/tensorflow/blob/v2.3.1/tensorflow/python/ops/candidate_sampling_ops.py#L120-L128", "Was anyone able to fix this issue? I had the same question and would appreciate an explanation of why thr `true_classes` is included in the distribution returned.\r\n\r\nThanks!", "@MarkDaoust Do you think that we could improve the documentation here?", "Facing the same issue. Does using tf.nn.fixed_unigram_candidate_sampler instead of tf.random.log_uniform_candidate_sampler for negative sampling not cause this issue of generating undesired true class also?", "> Facing the same issue. Does using tf.nn.fixed_unigram_candidate_sampler instead of tf.random.log_uniform_candidate_sampler for negative sampling not cause this issue of generating undesired true class also?\r\n\r\nFrom what I understand there's a probability attached to each label while sampling. So there is a chance that the `true_label` gets returned as a false label while generating the context classes here. I might be wrong here, but the PDFs and the code snippet referenced above point in that direction.", "- I think this is designed to be, but the line `pass the context word as true class to exclude it from being sampled` in the tutorial is really misguiding. I'm just learning this from the tutorial, so there maybe mistakes in my understanding.\r\n- In my test, `true_classes` has no effect on the sampled results, seems it's only used to calculate the second returned value `true_expected_count`:\r\n  ```py\r\n  # Do sampling 1000 times using true_classes [0, 8]\r\n  sample_func = lambda ii: tf.random.log_uniform_candidate_sampler(true_classes=[[ii]], num_true=1, num_sampled=4, unique=True, range_max=8, seed=42)\r\n  dd = {ii : np.stack([sample_func(ii)[0].numpy() for jj in range(1000)]) for ii in range(8)}\r\n  # Calculate the distribution in each true_class\r\n  for ii in dd:\r\n      print(\"true_class:\", ii, \", negative value_counts:\", pd.value_counts(dd[ii].flatten()).to_dict())\r\n  # true_class: 0 , negative value_counts: {0: 871, 1: 722, 2: 584, 3: 466, 4: 402, 5: 329, 7: 319, 6: 307}\r\n  # true_class: 1 , negative value_counts: {0: 867, 1: 695, 2: 571, 3: 485, 4: 411, 5: 380, 6: 316, 7: 275}\r\n  # true_class: 2 , negative value_counts: {0: 869, 1: 716, 2: 541, 3: 488, 4: 389, 5: 357, 6: 321, 7: 319}\r\n  # true_class: 3 , negative value_counts: {0: 877, 1: 715, 2: 582, 3: 482, 4: 394, 5: 355, 6: 318, 7: 277}\r\n  # true_class: 4 , negative value_counts: {0: 883, 1: 716, 2: 566, 3: 489, 4: 394, 5: 367, 6: 316, 7: 269}\r\n  # true_class: 5 , negative value_counts: {0: 862, 1: 717, 2: 583, 3: 496, 4: 376, 5: 357, 6: 315, 7: 294}\r\n  # true_class: 6 , negative value_counts: {0: 859, 1: 725, 2: 575, 3: 482, 4: 413, 5: 356, 6: 302, 7: 288}\r\n  # true_class: 7 , negative value_counts: {0: 880, 1: 724, 2: 555, 3: 488, 4: 425, 5: 324, 7: 302, 6: 302}\r\n  \r\n  # Result of `true_expected_count`\r\n  print({ii : np.mean([sample_func(ii)[1].numpy() for jj in range(1000)]) for ii in range(8)})\r\n  # {0: 0.99967235, 1: 0.7245632, 2: 0.5737029, 3: 0.47004792, 4: 0.3987442, 5: 0.34728608, 6: 0.3084587, 7: 0.27554017}\r\n  ```\r\n- Similar result with `tf.nn.fixed_unigram_candidate_sampler` or `tf.keras.preprocessing.sequence.skipgrams` with `negative_samples=4`:\r\n  ```py\r\n  unigrams = [0.99967235, 0.7245632, 0.5737029, 0.47004792, 0.3987442, 0.34728608, 0.3084587, 0.27554017]\r\n  sample_func = lambda ii: tf.nn.fixed_unigram_candidate_sampler(true_classes=[[ii]], num_true=1, num_sampled=4, unique=True, range_max=8, unigrams=unigrams)\r\n  dd = {ii : np.stack([sample_func(ii)[0].numpy() for jj in range(1000)]) for ii in range(8)}\r\n  print(\"true_class:\", 0, \"value_counts:\", pd.value_counts(dd[0].flatten()).to_dict())\r\n  print(\"true_class:\", 7, \", negative value_counts:\", pd.value_counts(dd[7].flatten()).to_dict())\r\n  # true_class: 0 , negative value_counts: {0: 793, 1: 666, 2: 546, 3: 475, 4: 426, 5: 382, 7: 356, 6: 356}\r\n  # true_class: 7 , negative value_counts: {0: 759, 1: 674, 2: 579, 3: 526, 4: 418, 5: 386, 6: 356, 7: 302}\r\n  ```\r\n- That means, **if `0` representing the word `the` and it's a `context_word`, which would be a high probability, it also will be selected as a `negative sample` with high probability no matter what the `context_word` is**.\r\n- But in the original [word2vec TrainModelThread](https://github.com/svn2github/word2vec/blob/99e546e27cae10aa20209dae1ed98716ac9022e9/word2vec.c#L516) I think the positive word is actually excluded in negatives if they are in a same sample. In my understanding, I think current behavior of `log_uniform_candidate_sampler` is better.\r\n- Actually in a real practice like the `shakespeare` dataset, the ratio selecting a positive as negative in the same sample is low, so this behavior may doesn't matter:\r\n  ```py\r\n  # After generated `targets, contexts, labels` following the tutorial\r\n  rr_contexts = np.array(contexts)[:, :, 0]\r\n  rr = [rr_contexts[ii][0] in rr_contexts[ii][1:] for ii in range(rr_contexts.shape[0])]\r\n  print(\"Total negatives containing positive:\", np.sum(rr), \", ratio:\", np.sum(rr) / rr_contexts.shape[0])\r\n  # Total negatives containing positive: 2226 , ratio: 0.03430843685459758\r\n  print(\"Sample:\", rr_contexts[np.array(rr)][:5].tolist())\r\n  # Sample: [[1, 3, 0, 73, 1], [1, 1, 2, 47, 625], [4, 9, 717, 11, 4], [8, 15, 37, 26, 8], [1, 97, 1, 4, 120]]\r\n  ```\r\n- Moreover, it's a high ratio that a positive pair `(target_word, context_word)` would also be a negative sample pair:\r\n  ```py\r\n  targets, contexts, labels = np.array(targets), np.array(contexts), np.array(labels)\r\n  dd = pd.DataFrame({\"targets\": targets.tolist(), \"pos\": contexts[:, 0, 0].tolist(), \"neg\": contexts[:, 1:, 0].tolist()})\r\n  cc = dd.groupby('targets').apply(lambda ii: np.sum([jj in ii['pos'].values for jj in np.concatenate(ii['neg'].values)]))\r\n  print(\"Total negative pairs containing positive pair:\", cc.sum(), \"ratio:\", cc.sum() / dd.shape[0])\r\n  # Total negative pairs containing positive pair: 38660 ratio: 0.5953095887035925\r\n  ```\r\n- So IMO, we need an update on the tutorial description, really misguiding.", "According to the big table in https://www.tensorflow.org/extras/candidate_sampling.pdf , the phrase \"negative samples\" may mean different things in different algorithms. For example, in NCE, \"negative samples\" means S_i (which is just the sampled classes) which may overlap with true classes, while in Sampled Logistic \"negative samples\" means S_i - T_i which excludes the true classes.\r\n\r\nFor `tf.random.log_uniform_candidate_sampler`, the return value `sampled_candidates` corresponds to S_i, not any specific definition of \"negative samples\" in any specific algorithm. It's the caller's responsibility to pick an algorithm and calculate the \"negative samples\" defined by that algorithm (e.g. S_i - T_i).\r\n\r\nThe `true_classes` argument is for calculating the `true_expected_count` output (as a by-product of the op's main calculation), which may be needed by some algorithms (according to https://www.tensorflow.org/extras/candidate_sampling.pdf). It's not for excluding true classes in the return value `sampled_candidates` (again that step is algorithm-specific and should be carried out by the caller).", "@Wang-Yu-Qing \r\nIs this still an issue ", "Even if Wang-Yu-Qing is fine, I think we need to update documentations to make clear the meaning of \"negative samples\".", "Agreed. We'll track the documentation update in #49490.", "In that case can this be move to closed status.", "Closing this issue and tracking the documentation update in #49490. Feel free to reopen.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44758\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44758\">No</a>\n"]}, {"number": 44757, "title": "Removed dead link", "body": "Removed dead link", "comments": ["We are closing this PR as it has been copied from PR[#44742](https://github.com/tensorflow/tensorflow/pull/44742). This behavior is unethical and runs contrary to our TensorFlow Code of Conduct.  Thank you for your interest. \r\ncc @mihaimaruseac", "I did not copy anything from any PR. Without knowing anything about someone you are not supposed to comment like that. I saw the issue I have done what I have to do that's all. Be careful next time when stating about somebody @gbaned "]}, {"number": 44756, "title": "Memory leak with keras metrics", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): tf-nightly\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nThe following test is failing, as the metric is not properly garbage collected.\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.python.framework.test_util import assert_no_garbage_created\r\n\r\nclass TestMetric(tf.test.TestCase):\r\n  @assert_no_garbage_created\r\n  def test_metric(self):\r\n    metric = tf.keras.metrics.Mean('test', dtype=tf.float32)\r\n\r\nimport unittest\r\nunittest.main(argv=['first-arg-is-ignored'], exit=False)\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nTest should pass\r\n\r\n**Standalone code to reproduce the issue**\r\nSee above.\r\n\r\n**Other info / logs** ", "comments": ["@jnd77 \r\nI ran the code shared on tf 2.3 and nightly, please let us know if this confirm your [issue](https://colab.research.google.com/gist/Saduf2019/0d4cc5e30f0dddd8efefdec172a49e96/untitled457.ipynb).", "@Saduf2019 \r\nThanks for reproducing it. It confirms the issue. ", "This is fixed with latest tf-nightly. See colab [gist](https://colab.research.google.com/gist/ymodak/13256d6196cff01519be16827b321333/untitled457.ipynb) to know more. Thanks!"]}, {"number": 44755, "title": "Cannot execute ./configure", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Not Applicable\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20 window subsystem.\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Not Applicable\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): master branch\r\n- Python version: 3.8.2\r\n- Bazel version (if compiling from source): Not Applicable\r\n- GCC/Compiler version (if compiling from source): Not Applicable\r\n- CUDA/cuDNN version: Not Applicable\r\n- GPU model and memory: Not Applicable\r\n\r\n\r\n**Describe the current behavior**\r\n\r\n./configure does not execute\r\n\r\n**Describe the expected behavior**\r\n\r\n./configure should execute\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nPlease clone and do `./configure` on ubuntu on window subsystem. It will not work!\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n```\r\n./configure: line 2: $'\\r': command not found  : invalid optione 3: set: -                                                                                             set: usage: set [-abefhkmnptuvxBCHP] [-o option-name] [--] [arg ...]   : invalid option nameset: pipefail                                                                                      ./configure: line 5: $'\\r': command not found\r\n./configure: line 16: syntax error: unexpected end of file\r\n```\r\n\r\n", "comments": ["@rxng8 \r\n\r\nProvide the exact sequence of commands / steps that you executed before running into the problem.Thanks!", "Does `python configure.py` work?\r\n\r\nIt is very likely the issue is on your system, we cannot know without additional checks.", "Yes, `python configure.py` does work, thank you!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44755\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44755\">No</a>\n", "I think we should still make a note that the command `./configure` does not work with Linux in Windows subsystem.", "I think the issue is on your system, it was looking for the wrong end of line marker (`\\r\\n` instead of `\\n`).\r\n\r\nWe are building our pip wheels on Windows using WSL, afaik"]}, {"number": 44754, "title": "Java API load model core dumped", "body": "**System information**\r\n- I written custom code:\r\n- OS Platform and Distribution : Linux Ubuntu 18.04.5\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.3.1\r\n- Python version: 3.8; Java version: 1.8.0_271\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source): 7.3.0\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nI tried to load both tf forzen and saved model with .pb files in IDEA 2017.2 with  Java 8 (Linux x64 1.8.0_271) by using JAVA API , but got a error message showing the failure.\r\nHowever, it works well on other machines and only mine fails.\r\n\r\n**Describe the expected behavior**\r\nI would like to load tf frozen and saved models with .pb file with Java API on my remote server.\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport org.apache.commons.io.IOUtils;\r\nimport org.tensorflow.Graph;\r\nimport org.tensorflow.Session;\r\nimport org.tensorflow.Tensor;\r\nimport java.util.Random;\r\n\r\nimport java.io.FileInputStream;\r\nimport java.io.IOException;\r\nimport java.nio.FloatBuffer;\r\n\r\npublic class TFTest {\r\n\r\n    public static void main(String[] args) throws IOException {\r\n\r\n        String path = \"/path/to/resnet50/frozen_inference_graph.pb\";\r\n        try (Graph graph = new Graph()) {\r\n            byte[] graphBytes = IOUtils.toByteArray(new\r\n                    FileInputStream(path));\r\n            graph.importGraphDef(graphBytes);\r\n\r\n            try(Session session = new Session(graph)){\r\n                float[][] input = new float[1][1];\r\n                input[0] = new float[]{10.0f};\r\n          \r\n                Tensor z = session.runner()\r\n                        .feed(\"x\", Tensor.create(input))\r\n                        .fetch(\"y\").run().get(0);\r\n                float[][] zz = (float[][]) z.copyTo(new float[1][1]);\r\n                System.out.println(\"y = \" + zz[0][0]);\r\n            }\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n**Other info / logs** \r\n```\r\n#\r\n# A fatal error has been detected by the Java Runtime Environment:\r\n#\r\n#  SIGILL (0x4) at pc=0x00007f3fe5154da9, pid=19433, tid=0x00007f402d3d3700\r\n#\r\n# JRE version: Java(TM) SE Runtime Environment (8.0_271-b09) (build 1.8.0_271-b09)\r\n# Java VM: Java HotSpot(TM) 64-Bit Server VM (25.271-b09 mixed mode linux-amd64 compressed oops)\r\n# Problematic frame:\r\n# C  [libtensorflow_framework.so.1+0x744da9]  _GLOBAL__sub_I_loader.cc+0x99\r\n#\r\n# Failed to write core dump. Core dumps have been disabled. To enable core dumping, try \"ulimit -c unlimited\" before starting Java again\r\n#\r\n# An error report file with more information is saved as:\r\n# /home/qihong/TEST_TF/hs_err_pid19433.log\r\n#\r\n# If you would like to submit a bug report, please visit:\r\n#   http://bugreport.java.com/bugreport/crash.jsp\r\n# The crash happened outside the Java Virtual Machine in native code.\r\n# See problematic frame for where to report the bug.\r\n#\r\n```\r\n", "comments": [">```\r\n># An error report file with more information is saved as:\r\n># /home/qihong/TEST_TF/hs_err_pid19433.log\r\n>```\r\n\r\nCould you please share the log file `hs_err_pid19433.log`, so that we can look into this? Thanks!", "here's the  log file '''hs_err_pid19433.log'''\r\n```\r\n#\r\n# A fatal error has been detected by the Java Runtime Environment:\r\n#\r\n#  SIGILL (0x4) at pc=0x00007f3fe5154da9, pid=19433, tid=0x00007f402d3d3700\r\n#\r\n# JRE version: Java(TM) SE Runtime Environment (8.0_271-b09) (build 1.8.0_271-b09)\r\n# Java VM: Java HotSpot(TM) 64-Bit Server VM (25.271-b09 mixed mode linux-amd64 compressed oops)\r\n# Problematic frame:\r\n# C  [libtensorflow_framework.so.1+0x744da9]  _GLOBAL__sub_I_loader.cc+0x99\r\n#\r\n# Failed to write core dump. Core dumps have been disabled. To enable core dumping, try \"ulimit -c unlimited\" before starting Java again\r\n#\r\n# If you would like to submit a bug report, please visit:\r\n#   http://bugreport.java.com/bugreport/crash.jsp\r\n# The crash happened outside the Java Virtual Machine in native code.\r\n# See problematic frame for where to report the bug.\r\n#\r\n\r\n---------------  T H R E A D  ---------------\r\n\r\nCurrent thread (0x00007f4024011000):  JavaThread \"main\" [_thread_in_native, id=19439, stack(0x00007f402d2d4000,0x00007f402d3d4000)]\r\n\r\nsiginfo: si_signo: 4 (SIGILL), si_code: 2 (ILL_ILLOPN), si_addr: 0x00007f3fe5154da9\r\n\r\nRegisters:\r\nRAX=0x00007f4024651410, RBX=0x00007f402d3d0860, RCX=0x0000000000000000, RDX=0x00007f40240008d0\r\nRSP=0x00007f402d3d0810, RBP=0x00007f402d3d0920, RSI=0x00007f402d3d0750, RDI=0x00007f402d3d0840\r\nR8 =0x00007f4024633e30, R9 =0x0000000000000000, R10=0x00007f40240008d0, R11=0x0000000000000001\r\nR12=0x00007ffdec87e078, R13=0x00007ffdec87e0b0, R14=0x00007f3fe636a510, R15=0x00007f402463bfc0\r\nRIP=0x00007f3fe5154da9, EFLAGS=0x0000000000010206, CSGSFS=0x002b000000000033, ERR=0x0000000000000000\r\n  TRAPNO=0x0000000000000006\r\n\r\nTop of Stack: (sp=0x00007f402d3d0810)\r\n0x00007f402d3d0810:   00007f402d3f0b60 00005573f72fbb30\r\n0x00007f402d3d0820:   7461646f722e0062 00617461642e0061\r\n0x00007f402d3d0830:   0000000000000000 0000000000011c00\r\n0x00007f402d3d0840:   000000792d533e0f 0000000000000007\r\n0x00007f402d3d0850:   0000000000000000 00007f40240096c8\r\n0x00007f402d3d0860:   0000000000011c30 ffffffffffffffb0\r\n0x00007f402d3d0870:   0000000000000470 000004a0000011c1\r\n0x00007f402d3d0880:   000000000000008e 0000000000000011\r\n0x00007f402d3d0890:   0000000000000002 000000790000007c\r\n0x00007f402d3d08a0:   000000e90000007f 00007f4024000780\r\n0x00007f402d3d08b0:   00007f402d3d0940 0000000000011c00\r\n0x00007f402d3d08c0:   00007f4024000020 00007ffdec87e078\r\n0x00007f402d3d08d0:   0000000000000000 00007f3fe5163eed\r\n0x00007f402d3d08e0:   00007f402d3d08f4 d1de7b5e4a08cd00\r\n0x00007f402d3d08f0:   bfebfbff0098e3fd 0000000000000001\r\n0x00007f402d3d0900:   00007ffdec87e078 00007ffdec87e0b0\r\n0x00007f402d3d0910:   00007f3fe636a510 00007f402463bfc0\r\n0x00007f402d3d0920:   0000000000000006 00007f402d1d98f3\r\n0x00007f402d3d0930:   00007f3fe636c018 0000000000000000\r\n0x00007f402d3d0940:   00007f402d3f1050 0000000000000000\r\n0x00007f402d3d0950:   00007f402d3d0a30 00007f402463bfc0\r\n0x00007f402d3d0960:   000000000000000a 00007f402d3d0b90\r\n0x00007f402d3d0970:   000000000000000a 00007f402d1de3bf\r\n0x00007f402d3d0980:   00007f402463bfc0 00007f402463c570\r\n0x00007f402d3d0990:   00007f402463ca90 00007f402463cf80\r\n0x00007f402d3d09a0:   00005573f72fb5d0 00007f402d1de16a\r\n0x00007f402d3d09b0:   00007f402d3d0e70 00007f402d3d0b80\r\n0x00007f402d3d09c0:   00000000000013d5 00007f402d3d0a80\r\n0x00007f402d3d09d0:   00007f4000000001 00007f402d3d09b0\r\n0x00007f402d3d09e0:   00007f402d3d0b90 00007f402d3f4140\r\n0x00007f402d3d09f0:   800000012d3d0b70 00007f3f00000001\r\n0x00007f402d3d0a00:   000000070f9740d0 0000000000000000 \r\n\r\nInstructions: (pc=0x00007f3fe5154da9)\r\n0x00007f3fe5154d89:   8d 35 a1 66 ed 00 48 8d 3d e2 66 ed 00 48 89 05\r\n0x00007f3fe5154d99:   7b 97 2a 01 e8 ee 06 f8 ff 48 8d bd 20 ff ff ff\r\n0x00007f3fe5154da9:   c5 fb 10 0d f7 c3 f0 00 c5 fb 10 05 f7 c3 f0 00\r\n0x00007f3fe5154db9:   be 21 00 00 00 48 89 05 4b 97 2a 01 e8 d6 06 f8 \r\n\r\nRegister to memory mapping:\r\n\r\nRAX=0x00007f4024651410 is an unknown value\r\nRBX=0x00007f402d3d0860 is pointing into the stack for thread: 0x00007f4024011000\r\nRCX=0x0000000000000000 is an unknown value\r\nRDX=0x00007f40240008d0 is an unknown value\r\nRSP=0x00007f402d3d0810 is pointing into the stack for thread: 0x00007f4024011000\r\nRBP=0x00007f402d3d0920 is pointing into the stack for thread: 0x00007f4024011000\r\nRSI=0x00007f402d3d0750 is pointing into the stack for thread: 0x00007f4024011000\r\nRDI=0x00007f402d3d0840 is pointing into the stack for thread: 0x00007f4024011000\r\nR8 =0x00007f4024633e30 is an unknown value\r\nR9 =0x0000000000000000 is an unknown value\r\nR10=0x00007f40240008d0 is an unknown value\r\nR11=0x0000000000000001 is an unknown value\r\nR12=0x00007ffdec87e078 is an unknown value\r\nR13=0x00007ffdec87e0b0 is an unknown value\r\nR14=0x00007f3fe636a510: <offset 0x195a510> in /tmp/tensorflow_native_libraries-1605065232619-0/libtensorflow_framework.so.1 at 0x00007f3fe4a10000\r\nR15=0x00007f402463bfc0 is an unknown value\r\n\r\n\r\nStack: [0x00007f402d2d4000,0x00007f402d3d4000],  sp=0x00007f402d3d0810,  free space=1010k\r\nNative frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code)\r\nC  [libtensorflow_framework.so.1+0x744da9]  _GLOBAL__sub_I_loader.cc+0x99\r\nC  [ld-linux-x86-64.so.2+0x108f3]\r\n\r\nJava frames: (J=compiled Java code, j=interpreted, Vv=VM code)\r\nj  java.lang.ClassLoader$NativeLibrary.load(Ljava/lang/String;Z)V+0\r\nj  java.lang.ClassLoader.loadLibrary0(Ljava/lang/Class;Ljava/io/File;)Z+328\r\nj  java.lang.ClassLoader.loadLibrary(Ljava/lang/Class;Ljava/lang/String;Z)V+48\r\nj  java.lang.Runtime.load0(Ljava/lang/Class;Ljava/lang/String;)V+57\r\nj  java.lang.System.load(Ljava/lang/String;)V+7\r\nj  org.tensorflow.NativeLibrary.load()V+212\r\nj  org.tensorflow.TensorFlow.init()V+0\r\nj  org.tensorflow.TensorFlow.<clinit>()V+0\r\nv  ~StubRoutines::call_stub\r\nj  org.tensorflow.Graph.<clinit>()V+0\r\nv  ~StubRoutines::call_stub\r\nj  XXX.TFTest.main([Ljava/lang/String;)V+3\r\nv  ~StubRoutines::call_stub\r\n\r\n---------------  P R O C E S S  ---------------\r\n\r\nJava Threads: ( => current thread )\r\n  0x00007f4024615800 JavaThread \"Service Thread\" daemon [_thread_blocked, id=19474, stack(0x00007f400d1d5000,0x00007f400d2d6000)]\r\n  0x00007f402460a800 JavaThread \"C1 CompilerThread3\" daemon [_thread_blocked, id=19473, stack(0x00007f400d4ee000,0x00007f400d5ee000)]\r\n  0x00007f4024608000 JavaThread \"C2 CompilerThread2\" daemon [_thread_blocked, id=19472, stack(0x00007f400d5ef000,0x00007f400d6ef000)]\r\n  0x00007f4024602800 JavaThread \"C2 CompilerThread1\" daemon [_thread_blocked, id=19471, stack(0x00007f400d6f0000,0x00007f400d7f0000)]\r\n  0x00007f4024601800 JavaThread \"C2 CompilerThread0\" daemon [_thread_blocked, id=19470, stack(0x00007f400d7f1000,0x00007f400d8f1000)]\r\n  0x00007f4024604800 JavaThread \"Monitor Ctrl-Break\" daemon [_thread_in_native, id=19469, stack(0x00007f400d8f1000,0x00007f400d9f2000)]\r\n  0x00007f402420e000 JavaThread \"Signal Dispatcher\" daemon [_thread_blocked, id=19468, stack(0x00007f400dc56000,0x00007f400dd57000)]\r\n  0x00007f40241dc800 JavaThread \"Finalizer\" daemon [_thread_blocked, id=19460, stack(0x00007f400e1ea000,0x00007f400e2eb000)]\r\n  0x00007f40241d8000 JavaThread \"Reference Handler\" daemon [_thread_blocked, id=19459, stack(0x00007f400e2eb000,0x00007f400e3ec000)]\r\n=>0x00007f4024011000 JavaThread \"main\" [_thread_in_native, id=19439, stack(0x00007f402d2d4000,0x00007f402d3d4000)]\r\n\r\nOther Threads:\r\n  0x00007f40241ce000 VMThread [stack: 0x00007f400e3ed000,0x00007f400e4ed000] [id=19458]\r\n  0x00007f4024618000 WatcherThread [stack: 0x00007f400d0d5000,0x00007f400d1d5000] [id=19475]\r\n\r\nVM state:not at safepoint (normal execution)\r\n\r\nVM Mutex/Monitor currently owned by a thread: None\r\n\r\nheap address: 0x0000000688200000, size: 4990 MB, Compressed Oops mode: Zero based, Oop shift amount: 3\r\nNarrow klass base: 0x0000000000000000, Narrow klass shift: 3\r\nCompressed class space size: 1073741824 Address: 0x00000007c0000000\r\n\r\nHeap:\r\n PSYoungGen      total 93184K, used 8438K [0x0000000758100000, 0x000000075e900000, 0x00000007c0000000)\r\n  eden space 79872K, 10% used [0x0000000758100000,0x000000075893d820,0x000000075cf00000)\r\n  from space 13312K, 0% used [0x000000075dc00000,0x000000075dc00000,0x000000075e900000)\r\n  to   space 13312K, 0% used [0x000000075cf00000,0x000000075cf00000,0x000000075dc00000)\r\n ParOldGen       total 212992K, used 0K [0x0000000688200000, 0x0000000695200000, 0x0000000758100000)\r\n  object space 212992K, 0% used [0x0000000688200000,0x0000000688200000,0x0000000695200000)\r\n Metaspace       used 3456K, capacity 4568K, committed 4864K, reserved 1056768K\r\n  class space    used 379K, capacity 392K, committed 512K, reserved 1048576K\r\n\r\nCard table byte_map: [0x00007f40293d9000,0x00007f4029d99000] byte_map_base: 0x00007f4025f98000\r\n\r\nMarking Bits: (ParMarkBitMap*) 0x00007f402c7800e0\r\n Begin Bits: [0x00007f3fe6410000, 0x00007f3feb208000)\r\n End Bits:   [0x00007f3feb208000, 0x00007f3ff0000000)\r\n\r\nPolling page: 0x00007f402d3ef000\r\n\r\nCodeCache: size=245760Kb used=1269Kb max_used=1284Kb free=244490Kb\r\n bounds [0x00007f4015000000, 0x00007f4015270000, 0x00007f4024000000]\r\n total_blobs=360 nmethods=100 adapters=175\r\n compilation: enabled\r\n\r\nCompilation events (10 events):\r\nEvent: 0.965 Thread 0x00007f4024601800 nmethod 97 0x00007f401513afd0 code [0x00007f401513b180, 0x00007f401513ba38]\r\nEvent: 0.972 Thread 0x00007f4024608000 nmethod 95 0x00007f401513ff50 code [0x00007f4015140180, 0x00007f4015141768]\r\nEvent: 0.974 Thread 0x00007f4024602800   99       4       java.io.FilterInputStream::read (9 bytes)\r\nEvent: 0.974 Thread 0x00007f4024601800  100       4       java.io.FilterInputStream::read (11 bytes)\r\nEvent: 0.975 Thread 0x00007f4024608000  101       4       java.io.FileOutputStream::write (12 bytes)\r\nEvent: 0.975 Thread 0x00007f4024602800 nmethod 99 0x00007f4015137850 code [0x00007f40151379c0, 0x00007f4015137ac8]\r\nEvent: 0.975 Thread 0x00007f4024601800 nmethod 100 0x00007f401513acd0 code [0x00007f401513ae20, 0x00007f401513aee8]\r\nEvent: 0.975 Thread 0x00007f4024608000 nmethod 101 0x00007f401513aa50 code [0x00007f401513aba0, 0x00007f401513ac28]\r\nEvent: 1.189 Thread 0x00007f402460a800  102       1       java.util.zip.ZipFile::access$000 (5 bytes)\r\nEvent: 1.189 Thread 0x00007f402460a800 nmethod 102 0x00007f401513a750 code [0x00007f401513a8a0, 0x00007f401513a990]\r\n\r\nGC Heap History (0 events):\r\nNo events\r\n\r\nDeoptimization events (0 events):\r\nNo events\r\n\r\nClasses redefined (0 events):\r\nNo events\r\n\r\nInternal exceptions (7 events):\r\nEvent: 0.032 Thread 0x00007f4024011000 Exception <a 'java/lang/NoSuchMethodError': Method sun.misc.Unsafe.defineClass(Ljava/lang/String;[BII)Ljava/lang/Class; name or signature does not match> (0x0000000758107cc0) thrown at [/scratch/jenkins/workspace/8-2-build-linux-amd64/jdk8u271/605/hotspot\r\nEvent: 0.032 Thread 0x00007f4024011000 Exception <a 'java/lang/NoSuchMethodError': Method sun.misc.Unsafe.prefetchRead(Ljava/lang/Object;J)V name or signature does not match> (0x0000000758107fa8) thrown at [/scratch/jenkins/workspace/8-2-build-linux-amd64/jdk8u271/605/hotspot/src/share/vm/prim\r\nEvent: 0.148 Thread 0x00007f4024011000 Exception <a 'java/lang/UnsatisfiedLinkError': org.tensorflow.TensorFlow.version()Ljava/lang/String;> (0x0000000758357ea0) thrown at [/scratch/jenkins/workspace/8-2-build-linux-amd64/jdk8u271/605/hotspot/src/share/vm/prims/nativeLookup.cpp, line 500]\r\nEvent: 0.155 Thread 0x00007f4024011000 Exception <a 'java/security/PrivilegedActionException'> (0x000000075838c238) thrown at [/scratch/jenkins/workspace/8-2-build-linux-amd64/jdk8u271/605/hotspot/src/share/vm/prims/jvm.cpp, line 1512]\r\nEvent: 0.155 Thread 0x00007f4024011000 Exception <a 'java/security/PrivilegedActionException'> (0x000000075838c448) thrown at [/scratch/jenkins/workspace/8-2-build-linux-amd64/jdk8u271/605/hotspot/src/share/vm/prims/jvm.cpp, line 1512]\r\nEvent: 0.156 Thread 0x00007f4024011000 Exception <a 'java/security/PrivilegedActionException'> (0x000000075838ea90) thrown at [/scratch/jenkins/workspace/8-2-build-linux-amd64/jdk8u271/605/hotspot/src/share/vm/prims/jvm.cpp, line 1512]\r\nEvent: 0.156 Thread 0x00007f4024011000 Exception <a 'java/security/PrivilegedActionException'> (0x000000075838eca0) thrown at [/scratch/jenkins/workspace/8-2-build-linux-amd64/jdk8u271/605/hotspot/src/share/vm/prims/jvm.cpp, line 1512]\r\n\r\nEvents (10 events):\r\nEvent: 0.161 loading class java/util/LinkedHashSet\r\nEvent: 0.161 loading class java/util/LinkedHashSet done\r\nEvent: 0.161 loading class java/io/DeleteOnExitHook$1\r\nEvent: 0.161 loading class java/io/DeleteOnExitHook$1 done\r\nEvent: 0.161 loading class java/lang/Shutdown\r\nEvent: 0.161 loading class java/lang/Shutdown done\r\nEvent: 0.161 loading class java/lang/Shutdown$Lock\r\nEvent: 0.161 loading class java/lang/Shutdown$Lock done\r\nEvent: 0.354 loading class java/io/FileOutputStream$1\r\nEvent: 0.354 loading class java/io/FileOutputStream$1 done\r\n\r\n\r\nDynamic libraries:\r\n688200000-695200000 rw-p 00000000 00:00 0 \r\n695200000-758100000 ---p 00000000 00:00 0 \r\n758100000-75e900000 rw-p 00000000 00:00 0 \r\n75e900000-7c0000000 ---p 00000000 00:00 0 \r\n7c0000000-7c0080000 rw-p 00000000 00:00 0 \r\n7c0080000-800000000 ---p 00000000 00:00 0 \r\n5573f5af3000-5573f5af4000 r-xp 00000000 08:01 10623457                   /home/qihong/java/jdk_1_8_0_271/bin/java\r\n5573f5cf3000-5573f5cf4000 r--p 00000000 08:01 10623457                   /home/qihong/java/jdk_1_8_0_271/bin/java\r\n5573f5cf4000-5573f5cf5000 rw-p 00001000 08:01 10623457                   /home/qihong/java/jdk_1_8_0_271/bin/java\r\n5573f72fb000-5573f731c000 rw-p 00000000 00:00 0                          [heap]\r\n7f3fa6c96000-7f3fafb93000 r-xp 00000000 08:01 12847970                   /tmp/tensorflow_native_libraries-1605065232619-0/libtensorflow_jni.so\r\n7f3fafb93000-7f3fafb94000 ---p 08efd000 08:01 12847970                   /tmp/tensorflow_native_libraries-1605065232619-0/libtensorflow_jni.so\r\n7f3fafb94000-7f3faff6f000 r--p 08efd000 08:01 12847970                   /tmp/tensorflow_native_libraries-1605065232619-0/libtensorflow_jni.so\r\n7f3faff6f000-7f3faff86000 rw-p 092d8000 08:01 12847970                   /tmp/tensorflow_native_libraries-1605065232619-0/libtensorflow_jni.so\r\n7f3faff86000-7f3fb0000000 rw-p 00000000 00:00 0 \r\n7f3fb0000000-7f3fb0021000 rw-p 00000000 00:00 0 \r\n7f3fb0021000-7f3fb4000000 ---p 00000000 00:00 0 \r\n7f3fb8000000-7f3fb8021000 rw-p 00000000 00:00 0 \r\n7f3fb8021000-7f3fbc000000 ---p 00000000 00:00 0 \r\n7f3fbcfff000-7f3fc0000000 rw-p 00000000 00:00 0 \r\n7f3fc0000000-7f3fc0111000 rw-p 00000000 00:00 0 \r\n7f3fc0111000-7f3fc4000000 ---p 00000000 00:00 0 \r\n7f3fc4000000-7f3fc4064000 rw-p 00000000 00:00 0 \r\n7f3fc4064000-7f3fc8000000 ---p 00000000 00:00 0 \r\n7f3fc8000000-7f3fc80f1000 rw-p 00000000 00:00 0 \r\n7f3fc80f1000-7f3fcc000000 ---p 00000000 00:00 0 \r\n7f3fcc000000-7f3fcc08c000 rw-p 00000000 00:00 0 \r\n7f3fcc08c000-7f3fd0000000 ---p 00000000 00:00 0 \r\n7f3fd0000000-7f3fd0021000 rw-p 00000000 00:00 0 \r\n7f3fd0021000-7f3fd4000000 ---p 00000000 00:00 0 \r\n7f3fd4000000-7f3fd404f000 rw-p 00000000 00:00 0 \r\n7f3fd404f000-7f3fd8000000 ---p 00000000 00:00 0 \r\n7f3fd8000000-7f3fd8021000 rw-p 00000000 00:00 0 \r\n7f3fd8021000-7f3fdc000000 ---p 00000000 00:00 0 \r\n7f3fdc000000-7f3fdc021000 rw-p 00000000 00:00 0 \r\n7f3fdc021000-7f3fe0000000 ---p 00000000 00:00 0 \r\n7f3fe0000000-7f3fe0021000 rw-p 00000000 00:00 0 \r\n7f3fe0021000-7f3fe4000000 ---p 00000000 00:00 0 \r\n7f3fe445d000-7f3fe4a10000 rw-p 00000000 00:00 0 \r\n7f3fe4a10000-7f3fe6355000 r-xp 00000000 08:01 12847969                   /tmp/tensorflow_native_libraries-1605065232619-0/libtensorflow_framework.so.1\r\n7f3fe6355000-7f3fe63fb000 r--p 01944000 08:01 12847969                   /tmp/tensorflow_native_libraries-1605065232619-0/libtensorflow_framework.so.1\r\n7f3fe63fb000-7f3fe63ff000 rw-p 019ea000 08:01 12847969                   /tmp/tensorflow_native_libraries-1605065232619-0/libtensorflow_framework.so.1\r\n7f3fe63ff000-7f3ff0000000 rw-p 00000000 00:00 0 \r\n7f3ff0000000-7f3ff0021000 rw-p 00000000 00:00 0 \r\n7f3ff0021000-7f3ff4000000 ---p 00000000 00:00 0 \r\n7f3ff4000000-7f3ff4021000 rw-p 00000000 00:00 0 \r\n7f3ff4021000-7f3ff8000000 ---p 00000000 00:00 0 \r\n7f3ff8000000-7f3ff8021000 rw-p 00000000 00:00 0 \r\n7f3ff8021000-7f3ffc000000 ---p 00000000 00:00 0 \r\n7f3ffc000000-7f3ffc021000 rw-p 00000000 00:00 0 \r\n7f3ffc021000-7f4000000000 ---p 00000000 00:00 0 \r\n7f4000000000-7f4000021000 rw-p 00000000 00:00 0 \r\n7f4000021000-7f4004000000 ---p 00000000 00:00 0 \r\n7f4004000000-7f4004021000 rw-p 00000000 00:00 0 \r\n7f4004021000-7f4008000000 ---p 00000000 00:00 0 \r\n7f4008000000-7f4008021000 rw-p 00000000 00:00 0 \r\n7f4008021000-7f400c000000 ---p 00000000 00:00 0 \r\n7f400c46f000-7f400cb19000 rw-p 00000000 00:00 0 \r\n7f400cb19000-7f400cb30000 r-xp 00000000 08:01 6029318                    /lib/x86_64-linux-gnu/libgcc_s.so.1\r\n7f400cb30000-7f400cd2f000 ---p 00017000 08:01 6029318                    /lib/x86_64-linux-gnu/libgcc_s.so.1\r\n7f400cd2f000-7f400cd30000 r--p 00016000 08:01 6029318                    /lib/x86_64-linux-gnu/libgcc_s.so.1\r\n7f400cd30000-7f400cd31000 rw-p 00017000 08:01 6029318                    /lib/x86_64-linux-gnu/libgcc_s.so.1\r\n7f400cd31000-7f400ceaa000 r-xp 00000000 08:01 21240599                   /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.25\r\n7f400ceaa000-7f400d0aa000 ---p 00179000 08:01 21240599                   /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.25\r\n7f400d0aa000-7f400d0b4000 r--p 00179000 08:01 21240599                   /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.25\r\n7f400d0b4000-7f400d0b6000 rw-p 00183000 08:01 21240599                   /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.25\r\n7f400d0b6000-7f400d0ba000 rw-p 00000000 00:00 0 \r\n7f400d0ba000-7f400d0d4000 r--p 00000000 08:01 45615941                   /etc/ld.so.cache\r\n7f400d0d4000-7f400d0d5000 ---p 00000000 00:00 0 \r\n7f400d0d5000-7f400d1d5000 rw-p 00000000 00:00 0 \r\n7f400d1d5000-7f400d1d8000 ---p 00000000 00:00 0 \r\n7f400d1d8000-7f400d2d6000 rw-p 00000000 00:00 0 \r\n7f400d2d6000-7f400d2ec000 r-xp 00000000 08:01 11935133                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libnet.so\r\n7f400d2ec000-7f400d4eb000 ---p 00016000 08:01 11935133                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libnet.so\r\n7f400d4eb000-7f400d4ec000 r--p 00015000 08:01 11935133                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libnet.so\r\n7f400d4ec000-7f400d4ed000 rw-p 00016000 08:01 11935133                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libnet.so\r\n7f400d4ed000-7f400d4ee000 ---p 00000000 00:00 0 \r\n7f400d4ee000-7f400d4f1000 ---p 00000000 00:00 0 \r\n7f400d4f1000-7f400d5ee000 rw-p 00000000 00:00 0 \r\n7f400d5ee000-7f400d5ef000 ---p 00000000 00:00 0 \r\n7f400d5ef000-7f400d5f2000 ---p 00000000 00:00 0 \r\n7f400d5f2000-7f400d6ef000 rw-p 00000000 00:00 0 \r\n7f400d6ef000-7f400d6f0000 ---p 00000000 00:00 0 \r\n7f400d6f0000-7f400d6f3000 ---p 00000000 00:00 0 \r\n7f400d6f3000-7f400d7f0000 rw-p 00000000 00:00 0 \r\n7f400d7f0000-7f400d7f1000 ---p 00000000 00:00 0 \r\n7f400d7f1000-7f400d7f4000 ---p 00000000 00:00 0 \r\n7f400d7f4000-7f400d8f1000 rw-p 00000000 00:00 0 \r\n7f400d8f1000-7f400d8f4000 ---p 00000000 00:00 0 \r\n7f400d8f4000-7f400d9f2000 rw-p 00000000 00:00 0 \r\n7f400d9f2000-7f400d9f4000 r--s 0001a000 08:01 13893744                   /home/qihong/installation/idea-IU-172.4574.19/lib/idea_rt.jar\r\n7f400d9f4000-7f400d9f6000 r--s 00009000 08:01 25957971                   /home/qihong/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.9.6/jackson-dataformat-yaml-2.9.6.jar\r\n7f400d9f6000-7f400d9fa000 r--s 0004c000 08:01 18745809                   /home/qihong/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.8/jackson-core-2.9.8.jar\r\n7f400d9fa000-7f400d9fd000 r--s 0000e000 08:01 18746625                   /home/qihong/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar\r\n7f400d9fd000-7f400da10000 r--s 00137000 08:01 25822664                   /home/qihong/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.6/jackson-databind-2.9.6.jar\r\n7f400da10000-7f400da12000 r--s 00017000 08:01 25822662                   /home/qihong/.m2/repository/org/glassfish/javax.json/1.1.2/javax.json-1.1.2.jar\r\n7f400da12000-7f400da13000 r--s 00005000 08:01 25692739                   /home/qihong/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar\r\n7f400da13000-7f400da15000 r--s 00010000 08:01 25692737                   /home/qihong/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar\r\n7f400da15000-7f400da1a000 r--s 00017000 08:01 25692735                   /home/qihong/.m2/repository/javax/enterprise/cdi-api/2.0/cdi-api-2.0.jar\r\n7f400da1a000-7f400da1c000 r--s 00006000 08:01 25562157                   /home/qihong/.m2/repository/javax/json/javax.json-api/1.1.4/javax.json-api-1.1.4.jar\r\n7f400da1c000-7f400da1e000 r--s 00004000 08:01 25562153                   /home/qihong/.m2/repository/javax/json/bind/javax.json.bind-api/1.0/javax.json.bind-api-1.0.jar\r\n7f400da1e000-7f400da26000 r--s 00041000 08:01 25431574                   /home/qihong/.m2/repository/org/eclipse/yasson/1.0.1/yasson-1.0.1.jar\r\n7f400da26000-7f400da2c000 r--s 0003c000 08:01 32244101                   /home/qihong/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.2/log4j-api-2.11.2.jar\r\n7f400da2c000-7f400da2e000 r--s 00009000 08:01 12979358                   /home/qihong/.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar\r\n7f400da2e000-7f400da2f000 r--s 00005000 08:01 32113462                   /home/qihong/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.11.2/log4j-slf4j-impl-2.11.2.jar\r\n7f400da2f000-7f400da30000 r--s 00000000 08:01 29365624                   /home/qihong/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.14/animal-sniffer-annotations-1.14.jar\r\n7f400da30000-7f400da32000 r--s 00001000 08:01 21633272                   /home/qihong/.m2/repository/com/google/j2objc/j2objc-annotations/1.1/j2objc-annotations-1.1.jar\r\n7f400da32000-7f400da34000 r--s 00006000 08:01 32637491                   /home/qihong/.m2/repository/org/checkerframework/checker-compat-qual/2.0.0/checker-compat-qual-2.0.0.jar\r\n7f400da34000-7f400da66000 r--s 0026b000 08:01 23860558                   /home/qihong/.m2/repository/com/google/guava/guava/25.0-jre/guava-25.0-jre.jar\r\n7f400da66000-7f400da68000 r--s 0000e000 08:01 16650830                   /home/qihong/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar\r\n7f400da68000-7f400da76000 r--s 00121000 08:01 32637364                   /home/qihong/.m2/repository/org/mozilla/rhino/1.7.7.2/rhino-1.7.7.2.jar\r\n7f400da76000-7f400da78000 r--s 0001c000 08:01 23467966                   /home/qihong/.m2/repository/com/google/re2j/re2j/1.3/re2j-1.3.jar\r\n7f400da78000-7f400da7d000 r--s 0001d000 08:01 22945853                   /home/qihong/.m2/repository/com/google/elemental2/elemental2-core/1.0.0-RC1/elemental2-core-1.0.0-RC1.jar\r\n7f400da7d000-7f400da7f000 r--s 00004000 08:01 22559043                   /home/qihong/.m2/repository/com/google/jsinterop/base/1.0.0/base-1.0.0.jar\r\n7f400da7f000-7f400da80000 r--s 00000000 08:01 22023255                   /home/qihong/.m2/repository/com/google/jsinterop/jsinterop-annotations/1.0.2/jsinterop-annotations-1.0.2.jar\r\n7f400da80000-7f400da82000 r--s 00003000 08:01 12716959                   /home/qihong/.m2/repository/com/google/code/findbugs/jsr305/3.0.1/jsr305-3.0.1.jar\r\n7f400da82000-7f400da87000 r--s 00036000 08:01 16388309                   /home/qihong/.m2/repository/com/google/code/gson/gson/2.8.5/gson-2.8.5.jar\r\n7f400da87000-7f400da89000 r--s 00002000 08:01 20584988                   /home/qihong/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.1/error_prone_annotations-2.3.1.jar\r\n7f400da89000-7f400da8c000 r--s 00010000 08:01 31459021                   /home/qihong/.m2/repository/args4j/args4j/2.0.26/args4j-2.0.26.jar\r\n7f400da8c000-7f400da8d000 r--s 00035000 08:01 20187693                   /home/qihong/.m2/repository/com/google/javascript/closure-compiler-externs/v20200504/closure-compiler-externs-v20200504.jar\r\n7f400da8d000-7f400dae5000 r--s 00715000 08:01 19400757                   /home/qihong/.m2/repository/com/google/javascript/closure-compiler-unshaded/v20200504/closure-compiler-unshaded-v20200504.jar\r\n7f400dae5000-7f400dae7000 r--s 0000a000 08:01 32113460                   /home/qihong/.m2/repository/org/json/json/20090211/json-20090211.jar\r\n7f400dae7000-7f400daec000 r--s 00034000 08:01 29101017                   /home/qihong/.m2/repository/commons-beanutils/commons-beanutils/1.8.3/commons-beanutils-1.8.3.jar\r\n7f400daec000-7f400daf0000 r--s 00029000 08:01 28968087                   /home/qihong/.m2/repository/commons-io/commons-io/2.3/commons-io-2.3.jar\r\n7f400daf0000-7f400db05000 r--s 0011b000 08:01 19013839                   /home/qihong/.m2/repository/com/github/sommeri/less4j/1.12.0/less4j-1.12.0.jar\r\n7f400db05000-7f400db07000 r--s 00100000 08:01 32508433                   /home/qihong/.m2/repository/org/apache/tapestry/tapestry-webresources/5.6.1/tapestry-webresources-5.6.1.jar\r\n7f400db07000-7f400db0e000 r--s 0004b000 08:01 28969535                   /home/qihong/.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar\r\n7f400db0e000-7f400db11000 r--s 00026000 08:01 13767040                   /home/qihong/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar\r\n7f400db11000-7f400db15000 r--s 00017000 08:01 32508446                   /home/qihong/.m2/repository/org/apache/tapestry/commons/5.6.1/commons-5.6.1.jar\r\n7f400db15000-7f400db19000 r--s 0001d000 08:01 32508443                   /home/qihong/.m2/repository/org/apache/tapestry/beanmodel/5.6.1/beanmodel-5.6.1.jar\r\n7f400db19000-7f400db1a000 r--s 00007000 08:01 32508441                   /home/qihong/.m2/repository/org/apache/tapestry/tapestry-json/5.6.1/tapestry-json-5.6.1.jar\r\n7f400db1a000-7f400db1b000 r--s 00000000 08:01 11010820                   /home/qihong/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar\r\n7f400db1b000-7f400db24000 r--s 00080000 08:01 32508435                   /home/qihong/.m2/repository/org/apache/tapestry/plastic/5.6.1/plastic-5.6.1.jar\r\n7f400db24000-7f400db26000 r--s 00003000 08:01 32508432                   /home/qihong/.m2/repository/org/apache/tapestry/tapestry5-annotations/5.6.1/tapestry5-annotations-5.6.1.jar\r\n7f400db26000-7f400db29000 r--s 0000e000 08:01 32508439                   /home/qihong/.m2/repository/org/apache/tapestry/tapestry-func/5.6.1/tapestry-func-5.6.1.jar\r\n7f400db29000-7f400db35000 r--s 00061000 08:01 32508431                   /home/qihong/.m2/repository/org/apache/tapestry/tapestry-ioc/5.6.1/tapestry-ioc-5.6.1.jar\r\n7f400db35000-7f400db62000 r--s 002bc000 08:01 32508430                   /home/qihong/.m2/repository/org/apache/tapestry/tapestry-core/5.6.1/tapestry-core-5.6.1.jar\r\n7f400db62000-7f400db64000 r--s 00000000 08:01 12716957                   /home/qihong/.m2/repository/org/slf4j/jul-to-slf4j/1.7.25/jul-to-slf4j-1.7.25.jar\r\n7f400db64000-7f400db65000 r--s 00005000 08:01 32508427                   /home/qihong/.m2/repository/org/apache/logging/log4j/log4j-jul/2.11.2/log4j-jul-2.11.2.jar\r\n7f400db65000-7f400db86000 r--s 0016d000 08:01 32508447                   /home/qihong/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.2/log4j-core-2.11.2.jar\r\n7f400db86000-7f400db87000 r--s 00000000 08:01 32113456                   /home/qihong/.m2/repository/org/springframework/boot/spring-boot-starter-log4j2/2.1.3.RELEASE/spring-boot-starter-log4j2-2.1.3.RELEASE.jar\r\n7f400db87000-7f400db8c000 r--s 00040000 08:01 31852524                   /home/qihong/.m2/repository/org/springframework/spring-expression/5.1.5.RELEASE/spring-expression-5.1.5.RELEASE.jar\r\n7f400db8c000-7f400db96000 r--s 00051000 08:01 31852532                   /home/qihong/.m2/repository/org/springframework/spring-aop/5.1.5.RELEASE/spring-aop-5.1.5.RELEASE.jar\r\n7f400db96000-7f400dba5000 r--s 000b5000 08:01 32113454                   /home/qihong/.m2/repository/org/springframework/spring-webmvc/5.1.5.RELEASE/spring-webmvc-5.1.5.RELEASE.jar\r\n7f400dba5000-7f400dbb2000 r--s 00098000 08:01 31852534                   /home/qihong/.m2/repository/org/springframework/spring-beans/5.1.5.RELEASE/spring-beans-5.1.5.RELEASE.jar\r\n7f400dbb2000-7f400dbce000 r--s 00136000 08:01 31852507                   /home/qihong/.m2/repository/org/springframework/spring-web/5.1.5.RELEASE/spring-web-5.1.5.RELEASE.jar\r\n7f400dbce000-7f400dbd0000 r--s 0000f000 08:01 12716955                   /home/qihong/.m2/repository/com/fasterxml/classmate/1.4.0/classmate-1.4.0.jar\r\n7f400dbd0000-7f400dbd2000 r--s 0000f000 08:01 31982385                   /home/qihong/.m2/repository/org/jboss/logging/jboss-logging/3.3.2.Final/jboss-logging-3.3.2.Final.jar\r\n7f400dbd2000-7f400dbd7000 r--s 00012000 08:01 12716953                   /home/qihong/.m2/repository/javax/validation/validation-api/2.0.1.Final/validation-api-2.0.1.Final.jar\r\n7f400dbd7000-7f400dbf4000 r--s 000fe000 08:01 31852522                   /home/qihong/.m2/repository/org/hibernate/validator/hibernate-validator/6.0.14.Final/hibernate-validator-6.0.14.Final.jar\r\n7f400dbf4000-7f400dbf9000 r--s 0003c000 08:01 31852526                   /home/qihong/.m2/repository/org/apache/tomcat/embed/tomcat-embed-websocket/9.0.16/tomcat-embed-websocket-9.0.16.jar\r\n7f400dbf9000-7f400dbfe000 r--s 00039000 08:01 31852525                   /home/qihong/.m2/repository/org/apache/tomcat/embed/tomcat-embed-el/9.0.16/tomcat-embed-el-9.0.16.jar\r\n7f400dbfe000-7f400dc28000 r--s 002f9000 08:01 31852528                   /home/qihong/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/9.0.16/tomcat-embed-core-9.0.16.jar\r\n7f400dc28000-7f400dc29000 r--s 00000000 08:01 31852520                   /home/qihong/.m2/repository/org/springframework/boot/spring-boot-starter-tomcat/2.1.3.RELEASE/spring-boot-starter-tomcat-2.1.3.RELEASE.jar\r\n7f400dc29000-7f400dc2b000 r--s 00001000 08:01 12716951                   /home/qihong/.m2/repository/com/fasterxml/jackson/module/jackson-module-parameter-names/2.9.8/jackson-module-parameter-names-2.9.8.jar\r\n7f400dc2b000-7f400dc2e000 r--s 00016000 08:01 12716949                   /home/qihong/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.9.8/jackson-datatype-jsr310-2.9.8.jar\r\n7f400dc2e000-7f400dc30000 r--s 00007000 08:01 12716947                   /home/qihong/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.9.8/jackson-datatype-jdk8-2.9.8.jar\r\n7f400dc30000-7f400dc31000 r--s 00000000 08:01 31852498                   /home/qihong/.m2/repository/org/springframework/boot/spring-boot-starter-json/2.1.3.RELEASE/spring-boot-starter-json-2.1.3.RELEASE.jar\r\n7f400dc31000-7f400dc32000 r--s 00000000 08:01 31852514                   /home/qihong/.m2/repository/org/springframework/boot/spring-boot-starter-web/2.1.3.RELEASE/spring-boot-starter-web-2.1.3.RELEASE.jar\r\n7f400dc32000-7f400dc56000 r--s 00110000 08:01 31852512                   /home/qihong/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/2.1.3.RELEASE/spring-boot-autoconfigure-2.1.3.RELEASE.jar\r\n7f400dc56000-7f400dc59000 ---p 00000000 00:00 0 \r\n7f400dc59000-7f400dd57000 rw-p 00000000 00:00 0 \r\n7f400dd57000-7f400e1ea000 r--p 00000000 08:01 21235028                   /usr/lib/locale/locale-archive\r\n7f400e1ea000-7f400e1ed000 ---p 00000000 00:00 0 \r\n7f400e1ed000-7f400e2eb000 rw-p 00000000 00:00 0 \r\n7f400e2eb000-7f400e2ee000 ---p 00000000 00:00 0 \r\n7f400e2ee000-7f400e3ec000 rw-p 00000000 00:00 0 \r\n7f400e3ec000-7f400e3ed000 ---p 00000000 00:00 0 \r\n7f400e3ed000-7f400fc40000 rw-p 00000000 00:00 0 \r\n7f400fc40000-7f4010000000 ---p 00000000 00:00 0 \r\n7f4010000000-7f4010021000 rw-p 00000000 00:00 0 \r\n7f4010021000-7f4014000000 ---p 00000000 00:00 0 \r\n7f4014000000-7f4014007000 r--s 00043000 08:01 24909458                   /home/qihong/.m2/repository/org/yaml/snakeyaml/1.23/snakeyaml-1.23.jar\r\n7f4014007000-7f4014008000 r--s 00005000 08:01 31852500                   /home/qihong/.m2/repository/org/springframework/spring-jcl/5.1.5.RELEASE/spring-jcl-5.1.5.RELEASE.jar\r\n7f4014008000-7f4014021000 r--s 00123000 08:01 31852499                   /home/qihong/.m2/repository/org/springframework/spring-core/5.1.5.RELEASE/spring-core-5.1.5.RELEASE.jar\r\n7f4014021000-7f401403b000 r--s 000f3000 08:01 31852516                   /home/qihong/.m2/repository/org/springframework/spring-context/5.1.5.RELEASE/spring-context-5.1.5.RELEASE.jar\r\n7f401403b000-7f4015000000 rw-p 00000000 00:00 0 \r\n7f4015000000-7f4015270000 rwxp 00000000 00:00 0 \r\n7f4015270000-7f4024000000 ---p 00000000 00:00 0 \r\n7f4024000000-7f40246a2000 rw-p 00000000 00:00 0 \r\n7f40246a2000-7f4028000000 ---p 00000000 00:00 0 \r\n7f4028000000-7f4028002000 r--s 00005000 08:01 12589134                   /home/qihong/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar\r\n7f4028002000-7f4028017000 r--s 000d3000 08:01 31852518                   /home/qihong/.m2/repository/org/springframework/boot/spring-boot/2.1.3.RELEASE/spring-boot-2.1.3.RELEASE.jar\r\n7f4028017000-7f4028019000 r--s 08725000 08:01 18220346                   /home/qihong/.m2/repository/org/tensorflow/libtensorflow_jni/1.15.0/libtensorflow_jni-1.15.0.jar\r\n7f4028019000-7f402804a000 r--s 001d1000 08:01 16782900                   /home/qihong/.m2/repository/org/tensorflow/libtensorflow/1.15.0/libtensorflow-1.15.0.jar\r\n7f402804a000-7f402805a000 r--s 00149000 08:01 16388315                   /home/qihong/.m2/repository/com/google/protobuf/protobuf-java/3.5.1/protobuf-java-3.5.1.jar\r\n7f402805a000-7f4028074000 r--s 002a6000 08:01 16388313                   /home/qihong/.m2/repository/org/tensorflow/proto/1.15.0/proto-1.15.0.jar\r\n7f4028074000-7f4028086000 r--s 00353000 08:01 11538539                   /home/qihong/java/jdk_1_8_0_271/jre/lib/resources.jar\r\n7f4028086000-7f4028099000 r--s 000d6000 08:01 11538543                   /home/qihong/java/jdk_1_8_0_271/jre/lib/plugin.jar\r\n7f4028099000-7f40280aa000 r--s 001c1000 08:01 11538537                   /home/qihong/java/jdk_1_8_0_271/jre/lib/jsse.jar\r\n7f40280aa000-7f40280ac000 r--s 00007000 08:01 11538545                   /home/qihong/java/jdk_1_8_0_271/jre/lib/jfxswt.jar\r\n7f40280ac000-7f40282fe000 rw-p 00000000 00:00 0 \r\n7f40282fe000-7f40284db000 r--s 03e16000 08:01 11538538                   /home/qihong/java/jdk_1_8_0_271/jre/lib/rt.jar\r\n7f40284db000-7f4028551000 rw-p 00000000 00:00 0 \r\n7f4028551000-7f4028552000 ---p 00000000 00:00 0 \r\n7f4028552000-7f4028652000 rw-p 00000000 00:00 0 \r\n7f4028652000-7f4028653000 ---p 00000000 00:00 0 \r\n7f4028653000-7f4028753000 rw-p 00000000 00:00 0 \r\n7f4028753000-7f4028754000 ---p 00000000 00:00 0 \r\n7f4028754000-7f4028854000 rw-p 00000000 00:00 0 \r\n7f4028854000-7f4028855000 ---p 00000000 00:00 0 \r\n7f4028855000-7f4028955000 rw-p 00000000 00:00 0 \r\n7f4028955000-7f4028956000 ---p 00000000 00:00 0 \r\n7f4028956000-7f4028a56000 rw-p 00000000 00:00 0 \r\n7f4028a56000-7f4028a57000 ---p 00000000 00:00 0 \r\n7f4028a57000-7f4028b57000 rw-p 00000000 00:00 0 \r\n7f4028b57000-7f4028b58000 ---p 00000000 00:00 0 \r\n7f4028b58000-7f4028c58000 rw-p 00000000 00:00 0 \r\n7f4028c58000-7f4028c59000 ---p 00000000 00:00 0 \r\n7f4028c59000-7f4028dc1000 rw-p 00000000 00:00 0 \r\n7f4028dc1000-7f40293d9000 ---p 00000000 00:00 0 \r\n7f40293d9000-7f4029441000 rw-p 00000000 00:00 0 \r\n7f4029441000-7f4029a58000 ---p 00000000 00:00 0 \r\n7f4029a58000-7f4029a8d000 rw-p 00000000 00:00 0 \r\n7f4029a8d000-7f4029d98000 ---p 00000000 00:00 0 \r\n7f4029d98000-7f4029da3000 rw-p 00000000 00:00 0 \r\n7f4029da3000-7f402a159000 ---p 00000000 00:00 0 \r\n7f402a159000-7f402a174000 r-xp 00000000 08:01 11935132                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libzip.so\r\n7f402a174000-7f402a373000 ---p 0001b000 08:01 11935132                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libzip.so\r\n7f402a373000-7f402a374000 r--p 0001a000 08:01 11935132                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libzip.so\r\n7f402a374000-7f402a375000 rw-p 0001b000 08:01 11935132                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libzip.so\r\n7f402a375000-7f402a380000 r-xp 00000000 08:01 6029600                    /lib/x86_64-linux-gnu/libnss_files-2.27.so\r\n7f402a380000-7f402a57f000 ---p 0000b000 08:01 6029600                    /lib/x86_64-linux-gnu/libnss_files-2.27.so\r\n7f402a57f000-7f402a580000 r--p 0000a000 08:01 6029600                    /lib/x86_64-linux-gnu/libnss_files-2.27.so\r\n7f402a580000-7f402a581000 rw-p 0000b000 08:01 6029600                    /lib/x86_64-linux-gnu/libnss_files-2.27.so\r\n7f402a581000-7f402a587000 rw-p 00000000 00:00 0 \r\n7f402a587000-7f402a59e000 r-xp 00000000 08:01 6029597                    /lib/x86_64-linux-gnu/libnsl-2.27.so\r\n7f402a59e000-7f402a79d000 ---p 00017000 08:01 6029597                    /lib/x86_64-linux-gnu/libnsl-2.27.so\r\n7f402a79d000-7f402a79e000 r--p 00016000 08:01 6029597                    /lib/x86_64-linux-gnu/libnsl-2.27.so\r\n7f402a79e000-7f402a79f000 rw-p 00017000 08:01 6029597                    /lib/x86_64-linux-gnu/libnsl-2.27.so\r\n7f402a79f000-7f402a7a1000 rw-p 00000000 00:00 0 \r\n7f402a7a1000-7f402a7ac000 r-xp 00000000 08:01 6029602                    /lib/x86_64-linux-gnu/libnss_nis-2.27.so\r\n7f402a7ac000-7f402a9ab000 ---p 0000b000 08:01 6029602                    /lib/x86_64-linux-gnu/libnss_nis-2.27.so\r\n7f402a9ab000-7f402a9ac000 r--p 0000a000 08:01 6029602                    /lib/x86_64-linux-gnu/libnss_nis-2.27.so\r\n7f402a9ac000-7f402a9ad000 rw-p 0000b000 08:01 6029602                    /lib/x86_64-linux-gnu/libnss_nis-2.27.so\r\n7f402a9ad000-7f402a9b5000 r-xp 00000000 08:01 6029598                    /lib/x86_64-linux-gnu/libnss_compat-2.27.so\r\n7f402a9b5000-7f402abb5000 ---p 00008000 08:01 6029598                    /lib/x86_64-linux-gnu/libnss_compat-2.27.so\r\n7f402abb5000-7f402abb6000 r--p 00008000 08:01 6029598                    /lib/x86_64-linux-gnu/libnss_compat-2.27.so\r\n7f402abb6000-7f402abb7000 rw-p 00009000 08:01 6029598                    /lib/x86_64-linux-gnu/libnss_compat-2.27.so\r\n7f402abb7000-7f402abc1000 r-xp 00000000 08:01 11935139                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libinstrument.so\r\n7f402abc1000-7f402adc0000 ---p 0000a000 08:01 11935139                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libinstrument.so\r\n7f402adc0000-7f402adc1000 r--p 00009000 08:01 11935139                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libinstrument.so\r\n7f402adc1000-7f402adc2000 rw-p 0000a000 08:01 11935139                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libinstrument.so\r\n7f402adc2000-7f402adee000 r-xp 00000000 08:01 11935130                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libjava.so\r\n7f402adee000-7f402afee000 ---p 0002c000 08:01 11935130                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libjava.so\r\n7f402afee000-7f402afef000 r--p 0002c000 08:01 11935130                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libjava.so\r\n7f402afef000-7f402aff1000 rw-p 0002d000 08:01 11935130                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libjava.so\r\n7f402aff1000-7f402affe000 r-xp 00000000 08:01 11935117                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libverify.so\r\n7f402affe000-7f402b1fd000 ---p 0000d000 08:01 11935117                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libverify.so\r\n7f402b1fd000-7f402b1ff000 r--p 0000c000 08:01 11935117                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libverify.so\r\n7f402b1ff000-7f402b200000 rw-p 0000e000 08:01 11935117                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libverify.so\r\n7f402b200000-7f402b207000 r-xp 00000000 08:01 6029607                    /lib/x86_64-linux-gnu/librt-2.27.so\r\n7f402b207000-7f402b406000 ---p 00007000 08:01 6029607                    /lib/x86_64-linux-gnu/librt-2.27.so\r\n7f402b406000-7f402b407000 r--p 00006000 08:01 6029607                    /lib/x86_64-linux-gnu/librt-2.27.so\r\n7f402b407000-7f402b408000 rw-p 00007000 08:01 6029607                    /lib/x86_64-linux-gnu/librt-2.27.so\r\n7f402b408000-7f402b5a5000 r-xp 00000000 08:01 6029594                    /lib/x86_64-linux-gnu/libm-2.27.so\r\n7f402b5a5000-7f402b7a4000 ---p 0019d000 08:01 6029594                    /lib/x86_64-linux-gnu/libm-2.27.so\r\n7f402b7a4000-7f402b7a5000 r--p 0019c000 08:01 6029594                    /lib/x86_64-linux-gnu/libm-2.27.so\r\n7f402b7a5000-7f402b7a6000 rw-p 0019d000 08:01 6029594                    /lib/x86_64-linux-gnu/libm-2.27.so\r\n7f402b7a6000-7f402c49b000 r-xp 00000000 08:01 12066242                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/server/libjvm.so\r\n7f402c49b000-7f402c69b000 ---p 00cf5000 08:01 12066242                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/server/libjvm.so\r\n7f402c69b000-7f402c731000 r--p 00cf5000 08:01 12066242                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/server/libjvm.so\r\n7f402c731000-7f402c762000 rw-p 00d8b000 08:01 12066242                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/server/libjvm.so\r\n7f402c762000-7f402c79d000 rw-p 00000000 00:00 0 \r\n7f402c79d000-7f402c984000 r-xp 00000000 08:01 6029590                    /lib/x86_64-linux-gnu/libc-2.27.so\r\n7f402c984000-7f402cb84000 ---p 001e7000 08:01 6029590                    /lib/x86_64-linux-gnu/libc-2.27.so\r\n7f402cb84000-7f402cb88000 r--p 001e7000 08:01 6029590                    /lib/x86_64-linux-gnu/libc-2.27.so\r\n7f402cb88000-7f402cb8a000 rw-p 001eb000 08:01 6029590                    /lib/x86_64-linux-gnu/libc-2.27.so\r\n7f402cb8a000-7f402cb8e000 rw-p 00000000 00:00 0 \r\n7f402cb8e000-7f402cb91000 r-xp 00000000 08:01 6029593                    /lib/x86_64-linux-gnu/libdl-2.27.so\r\n7f402cb91000-7f402cd90000 ---p 00003000 08:01 6029593                    /lib/x86_64-linux-gnu/libdl-2.27.so\r\n7f402cd90000-7f402cd91000 r--p 00002000 08:01 6029593                    /lib/x86_64-linux-gnu/libdl-2.27.so\r\n7f402cd91000-7f402cd92000 rw-p 00003000 08:01 6029593                    /lib/x86_64-linux-gnu/libdl-2.27.so\r\n7f402cd92000-7f402cda9000 r-xp 00000000 08:01 26087328                   /home/qihong/java/jdk_1_8_0_271/lib/amd64/jli/libjli.so\r\n7f402cda9000-7f402cfa8000 ---p 00017000 08:01 26087328                   /home/qihong/java/jdk_1_8_0_271/lib/amd64/jli/libjli.so\r\n7f402cfa8000-7f402cfa9000 r--p 00016000 08:01 26087328                   /home/qihong/java/jdk_1_8_0_271/lib/amd64/jli/libjli.so\r\n7f402cfa9000-7f402cfaa000 rw-p 00017000 08:01 26087328                   /home/qihong/java/jdk_1_8_0_271/lib/amd64/jli/libjli.so\r\n7f402cfaa000-7f402cfc4000 r-xp 00000000 08:01 6029605                    /lib/x86_64-linux-gnu/libpthread-2.27.so\r\n7f402cfc4000-7f402d1c3000 ---p 0001a000 08:01 6029605                    /lib/x86_64-linux-gnu/libpthread-2.27.so\r\n7f402d1c3000-7f402d1c4000 r--p 00019000 08:01 6029605                    /lib/x86_64-linux-gnu/libpthread-2.27.so\r\n7f402d1c4000-7f402d1c5000 rw-p 0001a000 08:01 6029605                    /lib/x86_64-linux-gnu/libpthread-2.27.so\r\n7f402d1c5000-7f402d1c9000 rw-p 00000000 00:00 0 \r\n7f402d1c9000-7f402d1f2000 r-xp 00000000 08:01 6029585                    /lib/x86_64-linux-gnu/ld-2.27.so\r\n7f402d1f2000-7f402d1f3000 r--s 00000000 08:01 31852510                   /home/qihong/.m2/repository/org/springframework/boot/spring-boot-starter/2.1.3.RELEASE/spring-boot-starter-2.1.3.RELEASE.jar\r\n7f402d1f3000-7f402d1f8000 r--s 00087000 08:01 11538535                   /home/qihong/java/jdk_1_8_0_271/jre/lib/jfr.jar\r\n7f402d1f8000-7f402d1fa000 r--s 0001b000 08:01 11538534                   /home/qihong/java/jdk_1_8_0_271/jre/lib/jce.jar\r\n7f402d1fa000-7f402d216000 r--s 0020c000 08:01 11538541                   /home/qihong/java/jdk_1_8_0_271/jre/lib/deploy.jar\r\n7f402d216000-7f402d2d3000 rw-p 00000000 00:00 0 \r\n7f402d2d3000-7f402d2d4000 ---p 00000000 00:00 0 \r\n7f402d2d4000-7f402d2d7000 ---p 00000000 00:00 0 \r\n7f402d2d7000-7f402d3d6000 rw-p 00000000 00:00 0 \r\n7f402d3d6000-7f402d3d7000 r--s 00000000 08:01 11538533                   /home/qihong/java/jdk_1_8_0_271/jre/lib/management-agent.jar\r\n7f402d3d7000-7f402d3e1000 r--s 0006e000 08:01 11538542                   /home/qihong/java/jdk_1_8_0_271/jre/lib/javaws.jar\r\n7f402d3e1000-7f402d3e6000 r--s 002f9000 08:01 11538532                   /home/qihong/java/jdk_1_8_0_271/jre/lib/charsets.jar\r\n7f402d3e6000-7f402d3ee000 rw-s 00000000 08:01 19799579                   /tmp/hsperfdata_qihong/19433\r\n7f402d3ee000-7f402d3ef000 rw-p 00000000 00:00 0 \r\n7f402d3ef000-7f402d3f0000 r--p 00000000 00:00 0 \r\n7f402d3f0000-7f402d3f2000 rw-p 00000000 00:00 0 \r\n7f402d3f2000-7f402d3f3000 r--p 00029000 08:01 6029585                    /lib/x86_64-linux-gnu/ld-2.27.so\r\n7f402d3f3000-7f402d3f4000 rw-p 0002a000 08:01 6029585                    /lib/x86_64-linux-gnu/ld-2.27.so\r\n7f402d3f4000-7f402d3f5000 rw-p 00000000 00:00 0 \r\n7ffdec85e000-7ffdec882000 rw-p 00000000 00:00 0                          [stack]\r\n7ffdec968000-7ffdec96b000 r--p 00000000 00:00 0                          [vvar]\r\n7ffdec96b000-7ffdec96c000 r-xp 00000000 00:00 0                          [vdso]\r\nffffffffff600000-ffffffffff601000 --xp 00000000 00:00 0                  [vsyscall]\r\n\r\nVM Arguments:\r\njvm_args: -javaagent:/home/qihong/installation/idea-IU-172.4574.19/lib/idea_rt.jar=40529:/home/qihong/installation/idea-IU-172.4574.19/bin -Dfile.encoding=UTF-8 \r\njava_command: XXX.TFTest\r\njava_class_path (initial): /home/qihong/java/jdk_1_8_0_271/jre/lib/charsets.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/deploy.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/ext/cldrdata.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/ext/dnsns.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/ext/jaccess.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/ext/jfxrt.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/ext/localedata.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/ext/nashorn.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/ext/sunec.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/ext/sunjce_provider.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/ext/sunpkcs11.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/ext/zipfs.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/javaws.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/jce.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/jfr.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/jfxswt.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/jsse.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/management-agent.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/plugin.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/resources.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/rt.jar:/home/qihong/TEST_TF/target/classes:/home/qihong/.m2/repository/org/tensorflow/proto/1.15.0/proto-1.15.0.jar:/home/qihong/.m2/repository/com/google/protobuf/protobuf-java/3.5.1/protobuf-java-3.5.1.jar:/home/qihong/.m2/repository/org/tensorflow/libtensorflow/1.15.0/libtensorflow-1.15.0.jar:/home/qihong/.m2/repository/org/tensorflow/libtensorflow_jni/1.15.0/libtensorflow_jni-1.15.0.jar:/home/qihong/.m2/repository/org/springframework/boot/spring-boot-starter/2.1.3.RELEASE/spring-boot-starter-2.1.3.RELEASE.jar:/home/qihong/.m2/repository/org/springframework/boot/spring-boot/2.1.3.RELEASE/spring-boot-2.1.3.RELEASE.jar:/home/qihong/.m2/repository/org/springframework/spring-context/5.1.5.RELEASE/spring-context-5.1.5.RELEASE.jar:/home/qihong/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/2.1.3.RELEASE/spring-boot-autoc\r\nLauncher Type: SUN_STANDARD\r\n\r\nEnvironment Variables:\r\nJAVA_HOME=/home/qihong/java/jdk_1_8_0_271\r\nJRE_HOME=/home/qihong/java/jdk_1_8_0_271/jre\r\nCLASSPATH=/home/qihong/installation/idea-IU-172.4574.19/lib/bootstrap.jar:/home/qihong/installation/idea-IU-172.4574.19/lib/extensions.jar:/home/qihong/installation/idea-IU-172.4574.19/lib/util.jar:/home/qihong/installation/idea-IU-172.4574.19/lib/jdom.jar:/home/qihong/installation/idea-IU-172.4574.19/lib/log4j.jar:/home/qihong/installation/idea-IU-172.4574.19/lib/trove4j.jar:/home/qihong/installation/idea-IU-172.4574.19/lib/jna.jar:/home/qihong/java/jdk_1_8_0_271/lib/tools.jar\r\nPATH=/home/qihong/java/jdk_1_8_0_271/bin:/home/qihong/java/jdk_11_0_9/bin:/home/qihong/anaconda3/bin:/home/qihong/anaconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\r\nLD_LIBRARY_PATH=/home/qihong/installation/idea-IU-172.4574.19/bin:\r\nSHELL=/bin/bash\r\nDISPLAY=localhost:10.0\r\n\r\nSignal Handlers:\r\nSIGSEGV: [libjvm.so+0xadf3a0], sa_mask[0]=11111111011111111101111111111110, sa_flags=SA_RESTART|SA_SIGINFO\r\nSIGBUS: [libjvm.so+0xadf3a0], sa_mask[0]=11111111011111111101111111111110, sa_flags=SA_RESTART|SA_SIGINFO\r\nSIGFPE: [libjvm.so+0x913c30], sa_mask[0]=11111111011111111101111111111110, sa_flags=SA_RESTART|SA_SIGINFO\r\nSIGPIPE: [libjvm.so+0x913c30], sa_mask[0]=11111111011111111101111111111110, sa_flags=SA_RESTART|SA_SIGINFO\r\nSIGXFSZ: [libjvm.so+0x913c30], sa_mask[0]=11111111011111111101111111111110, sa_flags=SA_RESTART|SA_SIGINFO\r\nSIGILL: [libjvm.so+0x913c30], sa_mask[0]=11111111011111111101111111111110, sa_flags=SA_RESTART|SA_SIGINFO\r\nSIGUSR1: SIG_DFL, sa_mask[0]=00000000000000000000000000000000, sa_flags=none\r\nSIGUSR2: [libjvm.so+0x913b00], sa_mask[0]=00100000000000000000000000000000, sa_flags=SA_RESTART|SA_SIGINFO\r\nSIGHUP: [libjvm.so+0x914120], sa_mask[0]=11111111011111111101111111111110, sa_flags=SA_RESTART|SA_SIGINFO\r\nSIGINT: [libjvm.so+0x914120], sa_mask[0]=11111111011111111101111111111110, sa_flags=SA_RESTART|SA_SIGINFO\r\nSIGTERM: [libjvm.so+0x914120], sa_mask[0]=11111111011111111101111111111110, sa_flags=SA_RESTART|SA_SIGINFO\r\nSIGQUIT: [libjvm.so+0x914120], sa_mask[0]=11111111011111111101111111111110, sa_flags=SA_RESTART|SA_SIGINFO\r\n\r\n\r\n---------------  S Y S T E M  ---------------\r\n\r\nOS:DISTRIB_ID=Ubuntu\r\nDISTRIB_RELEASE=18.04\r\nDISTRIB_CODENAME=bionic\r\nDISTRIB_DESCRIPTION=\"Ubuntu 18.04.5 LTS\"\r\n\r\nuname:Linux 5.3.0-28-generic #30~18.04.1-Ubuntu SMP Fri Jan 17 06:14:09 UTC 2020 x86_64\r\nlibc:glibc 2.27 NPTL 2.27 \r\nrlimit: STACK 8192k, CORE 0k, NPROC 79635, NOFILE 1048576, AS infinity\r\nload average:0.57 0.36 0.27\r\n\r\n/proc/meminfo:\r\nMemTotal:       20435540 kB\r\nMemFree:         8384596 kB\r\nMemAvailable:   17206692 kB\r\nBuffers:          567192 kB\r\nCached:          8104844 kB\r\nSwapCached:            0 kB\r\nActive:          5297996 kB\r\nInactive:        6049832 kB\r\nActive(anon):    2677028 kB\r\nInactive(anon):      600 kB\r\nActive(file):    2620968 kB\r\nInactive(file):  6049232 kB\r\nUnevictable:           0 kB\r\nMlocked:               0 kB\r\nSwapTotal:       2097148 kB\r\nSwapFree:        2097148 kB\r\nDirty:            185264 kB\r\nWriteback:             0 kB\r\nAnonPages:       2676092 kB\r\nMapped:           266832 kB\r\nShmem:              1688 kB\r\nKReclaimable:     517960 kB\r\nSlab:             564768 kB\r\nSReclaimable:     517960 kB\r\nSUnreclaim:        46808 kB\r\nKernelStack:       10880 kB\r\nPageTables:        32260 kB\r\nNFS_Unstable:          0 kB\r\nBounce:                0 kB\r\nWritebackTmp:          0 kB\r\nCommitLimit:    12314916 kB\r\nCommitted_AS:    6871444 kB\r\nVmallocTotal:   34359738367 kB\r\nVmallocUsed:       20428 kB\r\nVmallocChunk:          0 kB\r\nPercpu:             2496 kB\r\nHardwareCorrupted:     0 kB\r\nAnonHugePages:         0 kB\r\nShmemHugePages:        0 kB\r\nShmemPmdMapped:        0 kB\r\nCmaTotal:              0 kB\r\nCmaFree:               0 kB\r\nHugePages_Total:       0\r\nHugePages_Free:        0\r\nHugePages_Rsvd:        0\r\nHugePages_Surp:        0\r\nHugepagesize:       2048 kB\r\nHugetlb:               0 kB\r\nDirectMap4k:      175792 kB\r\nDirectMap2M:    20729856 kB\r\n\r\ncontainer (cgroup) information:\r\ncontainer_type: cgroupv1\r\ncpu_cpuset_cpus: 0-7\r\ncpu_memory_nodes: 0\r\nactive_processor_count: 8\r\ncpu_quota: -1\r\ncpu_period: 100000\r\ncpu_shares: -1\r\nmemory_limit_in_bytes: -1\r\nmemory_and_swap_limit_in_bytes: -2\r\nmemory_soft_limit_in_bytes: -1\r\nmemory_usage_in_bytes: 11620184064\r\nmemory_max_usage_in_bytes: 0\r\n\r\n\r\nCPU:total 8 (initial active 8) (4 cores per cpu, 2 threads per core) family 6 model 30 stepping 5, cmov, cx8, fxsr, mmx, sse, sse2, sse3, ssse3, sse4.1, sse4.2, popcnt, ht, tsc, tscinvbit\r\n\r\n/proc/cpuinfo:\r\nprocessor\t: 0\r\nvendor_id\t: GenuineIntel\r\ncpu family\t: 6\r\nmodel\t\t: 30\r\nmodel name\t: Intel(R) Core(TM) i7 CPU         860  @ 2.80GHz\r\nstepping\t: 5\r\nmicrocode\t: 0xa\r\ncpu MHz\t\t: 2964.113\r\ncache size\t: 8192 KB\r\nphysical id\t: 0\r\nsiblings\t: 8\r\ncore id\t\t: 0\r\ncpu cores\t: 4\r\napicid\t\t: 0\r\ninitial apicid\t: 0\r\nfpu\t\t: yes\r\nfpu_exception\t: yes\r\ncpuid level\t: 11\r\nwp\t\t: yes\r\nflags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d\r\nbugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit\r\nbogomips\t: 5585.88\r\nclflush size\t: 64\r\ncache_alignment\t: 64\r\naddress sizes\t: 36 bits physical, 48 bits virtual\r\npower management:\r\n\r\nprocessor\t: 1\r\nvendor_id\t: GenuineIntel\r\ncpu family\t: 6\r\nmodel\t\t: 30\r\nmodel name\t: Intel(R) Core(TM) i7 CPU         860  @ 2.80GHz\r\nstepping\t: 5\r\nmicrocode\t: 0xa\r\ncpu MHz\t\t: 2941.756\r\ncache size\t: 8192 KB\r\nphysical id\t: 0\r\nsiblings\t: 8\r\ncore id\t\t: 0\r\ncpu cores\t: 4\r\napicid\t\t: 1\r\ninitial apicid\t: 1\r\nfpu\t\t: yes\r\nfpu_exception\t: yes\r\ncpuid level\t: 11\r\nwp\t\t: yes\r\nflags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d\r\nbugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit\r\nbogomips\t: 5585.88\r\nclflush size\t: 64\r\ncache_alignment\t: 64\r\naddress sizes\t: 36 bits physical, 48 bits virtual\r\npower management:\r\n\r\nprocessor\t: 2\r\nvendor_id\t: GenuineIntel\r\ncpu family\t: 6\r\nmodel\t\t: 30\r\nmodel name\t: Intel(R) Core(TM) i7 CPU         860  @ 2.80GHz\r\nstepping\t: 5\r\nmicrocode\t: 0xa\r\ncpu MHz\t\t: 2992.502\r\ncache size\t: 8192 KB\r\nphysical id\t: 0\r\nsiblings\t: 8\r\ncore id\t\t: 3\r\ncpu cores\t: 4\r\napicid\t\t: 7\r\ninitial apicid\t: 7\r\nfpu\t\t: yes\r\nfpu_exception\t: yes\r\ncpuid level\t: 11\r\nwp\t\t: yes\r\nflags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d\r\nbugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit\r\nbogomips\t: 5585.88\r\nclflush size\t: 64\r\ncache_alignment\t: 64\r\naddress sizes\t: 36 bits physical, 48 bits virtual\r\npower management:\r\n\r\nprocessor\t: 3\r\nvendor_id\t: GenuineIntel\r\ncpu family\t: 6\r\nmodel\t\t: 30\r\nmodel name\t: Intel(R) Core(TM) i7 CPU         860  @ 2.80GHz\r\nstepping\t: 5\r\nmicrocode\t: 0xa\r\ncpu MHz\t\t: 3015.266\r\ncache size\t: 8192 KB\r\nphysical id\t: 0\r\nsiblings\t: 8\r\ncore id\t\t: 2\r\ncpu cores\t: 4\r\napicid\t\t: 4\r\ninitial apicid\t: 4\r\nfpu\t\t: yes\r\nfpu_exception\t: yes\r\ncpuid level\t: 11\r\nwp\t\t: yes\r\nflags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d\r\nbugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit\r\nbogomips\t: 5585.88\r\nclflush size\t: 64\r\ncache_alignment\t: 64\r\naddress sizes\t: 36 bits physical, 48 bits virtual\r\npower management:\r\n\r\nprocessor\t: 4\r\nvendor_id\t: GenuineIntel\r\ncpu family\t: 6\r\nmodel\t\t: 30\r\nmodel name\t: Intel(R) Core(TM) i7 CPU         860  @ 2.80GHz\r\nstepping\t: 5\r\nmicrocode\t: 0xa\r\ncpu MHz\t\t: 3034.687\r\ncache size\t: 8192 KB\r\nphysical id\t: 0\r\nsiblings\t: 8\r\ncore id\t\t: 3\r\ncpu cores\t: 4\r\napicid\t\t: 6\r\ninitial apicid\t: 6\r\nfpu\t\t: yes\r\nfpu_exception\t: yes\r\ncpuid level\t: 11\r\nwp\t\t: yes\r\nflags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d\r\nbugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit\r\nbogomips\t: 5585.88\r\nclflush size\t: 64\r\ncache_alignment\t: 64\r\naddress sizes\t: 36 bits physical, 48 bits virtual\r\npower management:\r\n\r\nprocessor\t: 5\r\nvendor_id\t: GenuineIntel\r\ncpu family\t: 6\r\nmodel\t\t: 30\r\nmodel name\t: Intel(R) Core(TM) i7 CPU         860  @ 2.80GHz\r\nstepping\t: 5\r\nmicrocode\t: 0xa\r\ncpu MHz\t\t: 2928.733\r\ncache size\t: 8192 KB\r\nphysical id\t: 0\r\nsiblings\t: 8\r\ncore id\t\t: 2\r\ncpu cores\t: 4\r\napicid\t\t: 5\r\ninitial apicid\t: 5\r\nfpu\t\t: yes\r\nfpu_exception\t: yes\r\ncpuid level\t: 11\r\nwp\t\t: yes\r\nflags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d\r\nbugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit\r\nbogomips\t: 5585.88\r\nclflush size\t: 64\r\ncache_alignment\t: 64\r\naddress sizes\t: 36 bits physical, 48 bits virtual\r\npower management:\r\n\r\nprocessor\t: 6\r\nvendor_id\t: GenuineIntel\r\ncpu family\t: 6\r\nmodel\t\t: 30\r\nmodel name\t: Intel(R) Core(TM) i7 CPU         860  @ 2.80GHz\r\nstepping\t: 5\r\nmicrocode\t: 0xa\r\ncpu MHz\t\t: 2926.159\r\ncache size\t: 8192 KB\r\nphysical id\t: 0\r\nsiblings\t: 8\r\ncore id\t\t: 1\r\ncpu cores\t: 4\r\napicid\t\t: 2\r\ninitial apicid\t: 2\r\nfpu\t\t: yes\r\nfpu_exception\t: yes\r\ncpuid level\t: 11\r\nwp\t\t: yes\r\nflags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d\r\nbugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit\r\nbogomips\t: 5585.88\r\nclflush size\t: 64\r\ncache_alignment\t: 64\r\naddress sizes\t: 36 bits physical, 48 bits virtual\r\npower management:\r\n\r\nprocessor\t: 7\r\nvendor_id\t: GenuineIntel\r\ncpu family\t: 6\r\nmodel\t\t: 30\r\nmodel name\t: Intel(R) Core(TM) i7 CPU         860  @ 2.80GHz\r\nstepping\t: 5\r\nmicrocode\t: 0xa\r\ncpu MHz\t\t: 2925.942\r\ncache size\t: 8192 KB\r\nphysical id\t: 0\r\nsiblings\t: 8\r\ncore id\t\t: 1\r\ncpu cores\t: 4\r\napicid\t\t: 3\r\ninitial apicid\t: 3\r\nfpu\t\t: yes\r\nfpu_exception\t: yes\r\ncpuid level\t: 11\r\nwp\t\t: yes\r\nflags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d\r\nbugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit\r\nbogomips\t: 5585.88\r\nclflush size\t: 64\r\ncache_alignment\t: 64\r\naddress sizes\t: 36 bits physical, 48 bits virtual\r\npower management:\r\n\r\n\r\n\r\nMemory: 4k page, physical 20435540k(8381320k free), swap 2097148k(2097148k free)\r\n\r\nvm_info: Java HotSpot(TM) 64-Bit Server VM (25.271-b09) for linux-amd64 JRE (1.8.0_271-b09), built on Sep 16 2020 17:01:41 by \"java_re\" with gcc 7.3.0\r\n\r\ntime: Wed Nov 11 11:27:13 2020\r\ntimezone: CST\r\nelapsed time: 1.258237 seconds (0d 0h 0m 1s)\r\n```", "I have the same problem , `new Graph()` this method will cause jvm crash.\r\njava Tensorflow api version is 1.15.0\r\n\r\n> \r\n     <groupId>org.tensorflow</groupId>\r\n     <artifactId>tensorflow</artifactId>\r\n     <version>1.15.0</version>\r\n        \r\n        \r\n\r\n", "> here's the log file '''hs_err_pid19433.log'''\r\n> \r\n> ```\r\n> #\r\n> # A fatal error has been detected by the Java Runtime Environment:\r\n> #\r\n> #  SIGILL (0x4) at pc=0x00007f3fe5154da9, pid=19433, tid=0x00007f402d3d3700\r\n> #\r\n> # JRE version: Java(TM) SE Runtime Environment (8.0_271-b09) (build 1.8.0_271-b09)\r\n> # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.271-b09 mixed mode linux-amd64 compressed oops)\r\n> # Problematic frame:\r\n> # C  [libtensorflow_framework.so.1+0x744da9]  _GLOBAL__sub_I_loader.cc+0x99\r\n> #\r\n> # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try \"ulimit -c unlimited\" before starting Java again\r\n> #\r\n> # If you would like to submit a bug report, please visit:\r\n> #   http://bugreport.java.com/bugreport/crash.jsp\r\n> # The crash happened outside the Java Virtual Machine in native code.\r\n> # See problematic frame for where to report the bug.\r\n> #\r\n> \r\n> ---------------  T H R E A D  ---------------\r\n> \r\n> Current thread (0x00007f4024011000):  JavaThread \"main\" [_thread_in_native, id=19439, stack(0x00007f402d2d4000,0x00007f402d3d4000)]\r\n> \r\n> siginfo: si_signo: 4 (SIGILL), si_code: 2 (ILL_ILLOPN), si_addr: 0x00007f3fe5154da9\r\n> \r\n> Registers:\r\n> RAX=0x00007f4024651410, RBX=0x00007f402d3d0860, RCX=0x0000000000000000, RDX=0x00007f40240008d0\r\n> RSP=0x00007f402d3d0810, RBP=0x00007f402d3d0920, RSI=0x00007f402d3d0750, RDI=0x00007f402d3d0840\r\n> R8 =0x00007f4024633e30, R9 =0x0000000000000000, R10=0x00007f40240008d0, R11=0x0000000000000001\r\n> R12=0x00007ffdec87e078, R13=0x00007ffdec87e0b0, R14=0x00007f3fe636a510, R15=0x00007f402463bfc0\r\n> RIP=0x00007f3fe5154da9, EFLAGS=0x0000000000010206, CSGSFS=0x002b000000000033, ERR=0x0000000000000000\r\n>   TRAPNO=0x0000000000000006\r\n> \r\n> Top of Stack: (sp=0x00007f402d3d0810)\r\n> 0x00007f402d3d0810:   00007f402d3f0b60 00005573f72fbb30\r\n> 0x00007f402d3d0820:   7461646f722e0062 00617461642e0061\r\n> 0x00007f402d3d0830:   0000000000000000 0000000000011c00\r\n> 0x00007f402d3d0840:   000000792d533e0f 0000000000000007\r\n> 0x00007f402d3d0850:   0000000000000000 00007f40240096c8\r\n> 0x00007f402d3d0860:   0000000000011c30 ffffffffffffffb0\r\n> 0x00007f402d3d0870:   0000000000000470 000004a0000011c1\r\n> 0x00007f402d3d0880:   000000000000008e 0000000000000011\r\n> 0x00007f402d3d0890:   0000000000000002 000000790000007c\r\n> 0x00007f402d3d08a0:   000000e90000007f 00007f4024000780\r\n> 0x00007f402d3d08b0:   00007f402d3d0940 0000000000011c00\r\n> 0x00007f402d3d08c0:   00007f4024000020 00007ffdec87e078\r\n> 0x00007f402d3d08d0:   0000000000000000 00007f3fe5163eed\r\n> 0x00007f402d3d08e0:   00007f402d3d08f4 d1de7b5e4a08cd00\r\n> 0x00007f402d3d08f0:   bfebfbff0098e3fd 0000000000000001\r\n> 0x00007f402d3d0900:   00007ffdec87e078 00007ffdec87e0b0\r\n> 0x00007f402d3d0910:   00007f3fe636a510 00007f402463bfc0\r\n> 0x00007f402d3d0920:   0000000000000006 00007f402d1d98f3\r\n> 0x00007f402d3d0930:   00007f3fe636c018 0000000000000000\r\n> 0x00007f402d3d0940:   00007f402d3f1050 0000000000000000\r\n> 0x00007f402d3d0950:   00007f402d3d0a30 00007f402463bfc0\r\n> 0x00007f402d3d0960:   000000000000000a 00007f402d3d0b90\r\n> 0x00007f402d3d0970:   000000000000000a 00007f402d1de3bf\r\n> 0x00007f402d3d0980:   00007f402463bfc0 00007f402463c570\r\n> 0x00007f402d3d0990:   00007f402463ca90 00007f402463cf80\r\n> 0x00007f402d3d09a0:   00005573f72fb5d0 00007f402d1de16a\r\n> 0x00007f402d3d09b0:   00007f402d3d0e70 00007f402d3d0b80\r\n> 0x00007f402d3d09c0:   00000000000013d5 00007f402d3d0a80\r\n> 0x00007f402d3d09d0:   00007f4000000001 00007f402d3d09b0\r\n> 0x00007f402d3d09e0:   00007f402d3d0b90 00007f402d3f4140\r\n> 0x00007f402d3d09f0:   800000012d3d0b70 00007f3f00000001\r\n> 0x00007f402d3d0a00:   000000070f9740d0 0000000000000000 \r\n> \r\n> Instructions: (pc=0x00007f3fe5154da9)\r\n> 0x00007f3fe5154d89:   8d 35 a1 66 ed 00 48 8d 3d e2 66 ed 00 48 89 05\r\n> 0x00007f3fe5154d99:   7b 97 2a 01 e8 ee 06 f8 ff 48 8d bd 20 ff ff ff\r\n> 0x00007f3fe5154da9:   c5 fb 10 0d f7 c3 f0 00 c5 fb 10 05 f7 c3 f0 00\r\n> 0x00007f3fe5154db9:   be 21 00 00 00 48 89 05 4b 97 2a 01 e8 d6 06 f8 \r\n> \r\n> Register to memory mapping:\r\n> \r\n> RAX=0x00007f4024651410 is an unknown value\r\n> RBX=0x00007f402d3d0860 is pointing into the stack for thread: 0x00007f4024011000\r\n> RCX=0x0000000000000000 is an unknown value\r\n> RDX=0x00007f40240008d0 is an unknown value\r\n> RSP=0x00007f402d3d0810 is pointing into the stack for thread: 0x00007f4024011000\r\n> RBP=0x00007f402d3d0920 is pointing into the stack for thread: 0x00007f4024011000\r\n> RSI=0x00007f402d3d0750 is pointing into the stack for thread: 0x00007f4024011000\r\n> RDI=0x00007f402d3d0840 is pointing into the stack for thread: 0x00007f4024011000\r\n> R8 =0x00007f4024633e30 is an unknown value\r\n> R9 =0x0000000000000000 is an unknown value\r\n> R10=0x00007f40240008d0 is an unknown value\r\n> R11=0x0000000000000001 is an unknown value\r\n> R12=0x00007ffdec87e078 is an unknown value\r\n> R13=0x00007ffdec87e0b0 is an unknown value\r\n> R14=0x00007f3fe636a510: <offset 0x195a510> in /tmp/tensorflow_native_libraries-1605065232619-0/libtensorflow_framework.so.1 at 0x00007f3fe4a10000\r\n> R15=0x00007f402463bfc0 is an unknown value\r\n> \r\n> \r\n> Stack: [0x00007f402d2d4000,0x00007f402d3d4000],  sp=0x00007f402d3d0810,  free space=1010k\r\n> Native frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code)\r\n> C  [libtensorflow_framework.so.1+0x744da9]  _GLOBAL__sub_I_loader.cc+0x99\r\n> C  [ld-linux-x86-64.so.2+0x108f3]\r\n> \r\n> Java frames: (J=compiled Java code, j=interpreted, Vv=VM code)\r\n> j  java.lang.ClassLoader$NativeLibrary.load(Ljava/lang/String;Z)V+0\r\n> j  java.lang.ClassLoader.loadLibrary0(Ljava/lang/Class;Ljava/io/File;)Z+328\r\n> j  java.lang.ClassLoader.loadLibrary(Ljava/lang/Class;Ljava/lang/String;Z)V+48\r\n> j  java.lang.Runtime.load0(Ljava/lang/Class;Ljava/lang/String;)V+57\r\n> j  java.lang.System.load(Ljava/lang/String;)V+7\r\n> j  org.tensorflow.NativeLibrary.load()V+212\r\n> j  org.tensorflow.TensorFlow.init()V+0\r\n> j  org.tensorflow.TensorFlow.<clinit>()V+0\r\n> v  ~StubRoutines::call_stub\r\n> j  org.tensorflow.Graph.<clinit>()V+0\r\n> v  ~StubRoutines::call_stub\r\n> j  XXX.TFTest.main([Ljava/lang/String;)V+3\r\n> v  ~StubRoutines::call_stub\r\n> \r\n> ---------------  P R O C E S S  ---------------\r\n> \r\n> Java Threads: ( => current thread )\r\n>   0x00007f4024615800 JavaThread \"Service Thread\" daemon [_thread_blocked, id=19474, stack(0x00007f400d1d5000,0x00007f400d2d6000)]\r\n>   0x00007f402460a800 JavaThread \"C1 CompilerThread3\" daemon [_thread_blocked, id=19473, stack(0x00007f400d4ee000,0x00007f400d5ee000)]\r\n>   0x00007f4024608000 JavaThread \"C2 CompilerThread2\" daemon [_thread_blocked, id=19472, stack(0x00007f400d5ef000,0x00007f400d6ef000)]\r\n>   0x00007f4024602800 JavaThread \"C2 CompilerThread1\" daemon [_thread_blocked, id=19471, stack(0x00007f400d6f0000,0x00007f400d7f0000)]\r\n>   0x00007f4024601800 JavaThread \"C2 CompilerThread0\" daemon [_thread_blocked, id=19470, stack(0x00007f400d7f1000,0x00007f400d8f1000)]\r\n>   0x00007f4024604800 JavaThread \"Monitor Ctrl-Break\" daemon [_thread_in_native, id=19469, stack(0x00007f400d8f1000,0x00007f400d9f2000)]\r\n>   0x00007f402420e000 JavaThread \"Signal Dispatcher\" daemon [_thread_blocked, id=19468, stack(0x00007f400dc56000,0x00007f400dd57000)]\r\n>   0x00007f40241dc800 JavaThread \"Finalizer\" daemon [_thread_blocked, id=19460, stack(0x00007f400e1ea000,0x00007f400e2eb000)]\r\n>   0x00007f40241d8000 JavaThread \"Reference Handler\" daemon [_thread_blocked, id=19459, stack(0x00007f400e2eb000,0x00007f400e3ec000)]\r\n> =>0x00007f4024011000 JavaThread \"main\" [_thread_in_native, id=19439, stack(0x00007f402d2d4000,0x00007f402d3d4000)]\r\n> \r\n> Other Threads:\r\n>   0x00007f40241ce000 VMThread [stack: 0x00007f400e3ed000,0x00007f400e4ed000] [id=19458]\r\n>   0x00007f4024618000 WatcherThread [stack: 0x00007f400d0d5000,0x00007f400d1d5000] [id=19475]\r\n> \r\n> VM state:not at safepoint (normal execution)\r\n> \r\n> VM Mutex/Monitor currently owned by a thread: None\r\n> \r\n> heap address: 0x0000000688200000, size: 4990 MB, Compressed Oops mode: Zero based, Oop shift amount: 3\r\n> Narrow klass base: 0x0000000000000000, Narrow klass shift: 3\r\n> Compressed class space size: 1073741824 Address: 0x00000007c0000000\r\n> \r\n> Heap:\r\n>  PSYoungGen      total 93184K, used 8438K [0x0000000758100000, 0x000000075e900000, 0x00000007c0000000)\r\n>   eden space 79872K, 10% used [0x0000000758100000,0x000000075893d820,0x000000075cf00000)\r\n>   from space 13312K, 0% used [0x000000075dc00000,0x000000075dc00000,0x000000075e900000)\r\n>   to   space 13312K, 0% used [0x000000075cf00000,0x000000075cf00000,0x000000075dc00000)\r\n>  ParOldGen       total 212992K, used 0K [0x0000000688200000, 0x0000000695200000, 0x0000000758100000)\r\n>   object space 212992K, 0% used [0x0000000688200000,0x0000000688200000,0x0000000695200000)\r\n>  Metaspace       used 3456K, capacity 4568K, committed 4864K, reserved 1056768K\r\n>   class space    used 379K, capacity 392K, committed 512K, reserved 1048576K\r\n> \r\n> Card table byte_map: [0x00007f40293d9000,0x00007f4029d99000] byte_map_base: 0x00007f4025f98000\r\n> \r\n> Marking Bits: (ParMarkBitMap*) 0x00007f402c7800e0\r\n>  Begin Bits: [0x00007f3fe6410000, 0x00007f3feb208000)\r\n>  End Bits:   [0x00007f3feb208000, 0x00007f3ff0000000)\r\n> \r\n> Polling page: 0x00007f402d3ef000\r\n> \r\n> CodeCache: size=245760Kb used=1269Kb max_used=1284Kb free=244490Kb\r\n>  bounds [0x00007f4015000000, 0x00007f4015270000, 0x00007f4024000000]\r\n>  total_blobs=360 nmethods=100 adapters=175\r\n>  compilation: enabled\r\n> \r\n> Compilation events (10 events):\r\n> Event: 0.965 Thread 0x00007f4024601800 nmethod 97 0x00007f401513afd0 code [0x00007f401513b180, 0x00007f401513ba38]\r\n> Event: 0.972 Thread 0x00007f4024608000 nmethod 95 0x00007f401513ff50 code [0x00007f4015140180, 0x00007f4015141768]\r\n> Event: 0.974 Thread 0x00007f4024602800   99       4       java.io.FilterInputStream::read (9 bytes)\r\n> Event: 0.974 Thread 0x00007f4024601800  100       4       java.io.FilterInputStream::read (11 bytes)\r\n> Event: 0.975 Thread 0x00007f4024608000  101       4       java.io.FileOutputStream::write (12 bytes)\r\n> Event: 0.975 Thread 0x00007f4024602800 nmethod 99 0x00007f4015137850 code [0x00007f40151379c0, 0x00007f4015137ac8]\r\n> Event: 0.975 Thread 0x00007f4024601800 nmethod 100 0x00007f401513acd0 code [0x00007f401513ae20, 0x00007f401513aee8]\r\n> Event: 0.975 Thread 0x00007f4024608000 nmethod 101 0x00007f401513aa50 code [0x00007f401513aba0, 0x00007f401513ac28]\r\n> Event: 1.189 Thread 0x00007f402460a800  102       1       java.util.zip.ZipFile::access$000 (5 bytes)\r\n> Event: 1.189 Thread 0x00007f402460a800 nmethod 102 0x00007f401513a750 code [0x00007f401513a8a0, 0x00007f401513a990]\r\n> \r\n> GC Heap History (0 events):\r\n> No events\r\n> \r\n> Deoptimization events (0 events):\r\n> No events\r\n> \r\n> Classes redefined (0 events):\r\n> No events\r\n> \r\n> Internal exceptions (7 events):\r\n> Event: 0.032 Thread 0x00007f4024011000 Exception <a 'java/lang/NoSuchMethodError': Method sun.misc.Unsafe.defineClass(Ljava/lang/String;[BII)Ljava/lang/Class; name or signature does not match> (0x0000000758107cc0) thrown at [/scratch/jenkins/workspace/8-2-build-linux-amd64/jdk8u271/605/hotspot\r\n> Event: 0.032 Thread 0x00007f4024011000 Exception <a 'java/lang/NoSuchMethodError': Method sun.misc.Unsafe.prefetchRead(Ljava/lang/Object;J)V name or signature does not match> (0x0000000758107fa8) thrown at [/scratch/jenkins/workspace/8-2-build-linux-amd64/jdk8u271/605/hotspot/src/share/vm/prim\r\n> Event: 0.148 Thread 0x00007f4024011000 Exception <a 'java/lang/UnsatisfiedLinkError': org.tensorflow.TensorFlow.version()Ljava/lang/String;> (0x0000000758357ea0) thrown at [/scratch/jenkins/workspace/8-2-build-linux-amd64/jdk8u271/605/hotspot/src/share/vm/prims/nativeLookup.cpp, line 500]\r\n> Event: 0.155 Thread 0x00007f4024011000 Exception <a 'java/security/PrivilegedActionException'> (0x000000075838c238) thrown at [/scratch/jenkins/workspace/8-2-build-linux-amd64/jdk8u271/605/hotspot/src/share/vm/prims/jvm.cpp, line 1512]\r\n> Event: 0.155 Thread 0x00007f4024011000 Exception <a 'java/security/PrivilegedActionException'> (0x000000075838c448) thrown at [/scratch/jenkins/workspace/8-2-build-linux-amd64/jdk8u271/605/hotspot/src/share/vm/prims/jvm.cpp, line 1512]\r\n> Event: 0.156 Thread 0x00007f4024011000 Exception <a 'java/security/PrivilegedActionException'> (0x000000075838ea90) thrown at [/scratch/jenkins/workspace/8-2-build-linux-amd64/jdk8u271/605/hotspot/src/share/vm/prims/jvm.cpp, line 1512]\r\n> Event: 0.156 Thread 0x00007f4024011000 Exception <a 'java/security/PrivilegedActionException'> (0x000000075838eca0) thrown at [/scratch/jenkins/workspace/8-2-build-linux-amd64/jdk8u271/605/hotspot/src/share/vm/prims/jvm.cpp, line 1512]\r\n> \r\n> Events (10 events):\r\n> Event: 0.161 loading class java/util/LinkedHashSet\r\n> Event: 0.161 loading class java/util/LinkedHashSet done\r\n> Event: 0.161 loading class java/io/DeleteOnExitHook$1\r\n> Event: 0.161 loading class java/io/DeleteOnExitHook$1 done\r\n> Event: 0.161 loading class java/lang/Shutdown\r\n> Event: 0.161 loading class java/lang/Shutdown done\r\n> Event: 0.161 loading class java/lang/Shutdown$Lock\r\n> Event: 0.161 loading class java/lang/Shutdown$Lock done\r\n> Event: 0.354 loading class java/io/FileOutputStream$1\r\n> Event: 0.354 loading class java/io/FileOutputStream$1 done\r\n> \r\n> \r\n> Dynamic libraries:\r\n> 688200000-695200000 rw-p 00000000 00:00 0 \r\n> 695200000-758100000 ---p 00000000 00:00 0 \r\n> 758100000-75e900000 rw-p 00000000 00:00 0 \r\n> 75e900000-7c0000000 ---p 00000000 00:00 0 \r\n> 7c0000000-7c0080000 rw-p 00000000 00:00 0 \r\n> 7c0080000-800000000 ---p 00000000 00:00 0 \r\n> 5573f5af3000-5573f5af4000 r-xp 00000000 08:01 10623457                   /home/qihong/java/jdk_1_8_0_271/bin/java\r\n> 5573f5cf3000-5573f5cf4000 r--p 00000000 08:01 10623457                   /home/qihong/java/jdk_1_8_0_271/bin/java\r\n> 5573f5cf4000-5573f5cf5000 rw-p 00001000 08:01 10623457                   /home/qihong/java/jdk_1_8_0_271/bin/java\r\n> 5573f72fb000-5573f731c000 rw-p 00000000 00:00 0                          [heap]\r\n> 7f3fa6c96000-7f3fafb93000 r-xp 00000000 08:01 12847970                   /tmp/tensorflow_native_libraries-1605065232619-0/libtensorflow_jni.so\r\n> 7f3fafb93000-7f3fafb94000 ---p 08efd000 08:01 12847970                   /tmp/tensorflow_native_libraries-1605065232619-0/libtensorflow_jni.so\r\n> 7f3fafb94000-7f3faff6f000 r--p 08efd000 08:01 12847970                   /tmp/tensorflow_native_libraries-1605065232619-0/libtensorflow_jni.so\r\n> 7f3faff6f000-7f3faff86000 rw-p 092d8000 08:01 12847970                   /tmp/tensorflow_native_libraries-1605065232619-0/libtensorflow_jni.so\r\n> 7f3faff86000-7f3fb0000000 rw-p 00000000 00:00 0 \r\n> 7f3fb0000000-7f3fb0021000 rw-p 00000000 00:00 0 \r\n> 7f3fb0021000-7f3fb4000000 ---p 00000000 00:00 0 \r\n> 7f3fb8000000-7f3fb8021000 rw-p 00000000 00:00 0 \r\n> 7f3fb8021000-7f3fbc000000 ---p 00000000 00:00 0 \r\n> 7f3fbcfff000-7f3fc0000000 rw-p 00000000 00:00 0 \r\n> 7f3fc0000000-7f3fc0111000 rw-p 00000000 00:00 0 \r\n> 7f3fc0111000-7f3fc4000000 ---p 00000000 00:00 0 \r\n> 7f3fc4000000-7f3fc4064000 rw-p 00000000 00:00 0 \r\n> 7f3fc4064000-7f3fc8000000 ---p 00000000 00:00 0 \r\n> 7f3fc8000000-7f3fc80f1000 rw-p 00000000 00:00 0 \r\n> 7f3fc80f1000-7f3fcc000000 ---p 00000000 00:00 0 \r\n> 7f3fcc000000-7f3fcc08c000 rw-p 00000000 00:00 0 \r\n> 7f3fcc08c000-7f3fd0000000 ---p 00000000 00:00 0 \r\n> 7f3fd0000000-7f3fd0021000 rw-p 00000000 00:00 0 \r\n> 7f3fd0021000-7f3fd4000000 ---p 00000000 00:00 0 \r\n> 7f3fd4000000-7f3fd404f000 rw-p 00000000 00:00 0 \r\n> 7f3fd404f000-7f3fd8000000 ---p 00000000 00:00 0 \r\n> 7f3fd8000000-7f3fd8021000 rw-p 00000000 00:00 0 \r\n> 7f3fd8021000-7f3fdc000000 ---p 00000000 00:00 0 \r\n> 7f3fdc000000-7f3fdc021000 rw-p 00000000 00:00 0 \r\n> 7f3fdc021000-7f3fe0000000 ---p 00000000 00:00 0 \r\n> 7f3fe0000000-7f3fe0021000 rw-p 00000000 00:00 0 \r\n> 7f3fe0021000-7f3fe4000000 ---p 00000000 00:00 0 \r\n> 7f3fe445d000-7f3fe4a10000 rw-p 00000000 00:00 0 \r\n> 7f3fe4a10000-7f3fe6355000 r-xp 00000000 08:01 12847969                   /tmp/tensorflow_native_libraries-1605065232619-0/libtensorflow_framework.so.1\r\n> 7f3fe6355000-7f3fe63fb000 r--p 01944000 08:01 12847969                   /tmp/tensorflow_native_libraries-1605065232619-0/libtensorflow_framework.so.1\r\n> 7f3fe63fb000-7f3fe63ff000 rw-p 019ea000 08:01 12847969                   /tmp/tensorflow_native_libraries-1605065232619-0/libtensorflow_framework.so.1\r\n> 7f3fe63ff000-7f3ff0000000 rw-p 00000000 00:00 0 \r\n> 7f3ff0000000-7f3ff0021000 rw-p 00000000 00:00 0 \r\n> 7f3ff0021000-7f3ff4000000 ---p 00000000 00:00 0 \r\n> 7f3ff4000000-7f3ff4021000 rw-p 00000000 00:00 0 \r\n> 7f3ff4021000-7f3ff8000000 ---p 00000000 00:00 0 \r\n> 7f3ff8000000-7f3ff8021000 rw-p 00000000 00:00 0 \r\n> 7f3ff8021000-7f3ffc000000 ---p 00000000 00:00 0 \r\n> 7f3ffc000000-7f3ffc021000 rw-p 00000000 00:00 0 \r\n> 7f3ffc021000-7f4000000000 ---p 00000000 00:00 0 \r\n> 7f4000000000-7f4000021000 rw-p 00000000 00:00 0 \r\n> 7f4000021000-7f4004000000 ---p 00000000 00:00 0 \r\n> 7f4004000000-7f4004021000 rw-p 00000000 00:00 0 \r\n> 7f4004021000-7f4008000000 ---p 00000000 00:00 0 \r\n> 7f4008000000-7f4008021000 rw-p 00000000 00:00 0 \r\n> 7f4008021000-7f400c000000 ---p 00000000 00:00 0 \r\n> 7f400c46f000-7f400cb19000 rw-p 00000000 00:00 0 \r\n> 7f400cb19000-7f400cb30000 r-xp 00000000 08:01 6029318                    /lib/x86_64-linux-gnu/libgcc_s.so.1\r\n> 7f400cb30000-7f400cd2f000 ---p 00017000 08:01 6029318                    /lib/x86_64-linux-gnu/libgcc_s.so.1\r\n> 7f400cd2f000-7f400cd30000 r--p 00016000 08:01 6029318                    /lib/x86_64-linux-gnu/libgcc_s.so.1\r\n> 7f400cd30000-7f400cd31000 rw-p 00017000 08:01 6029318                    /lib/x86_64-linux-gnu/libgcc_s.so.1\r\n> 7f400cd31000-7f400ceaa000 r-xp 00000000 08:01 21240599                   /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.25\r\n> 7f400ceaa000-7f400d0aa000 ---p 00179000 08:01 21240599                   /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.25\r\n> 7f400d0aa000-7f400d0b4000 r--p 00179000 08:01 21240599                   /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.25\r\n> 7f400d0b4000-7f400d0b6000 rw-p 00183000 08:01 21240599                   /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.25\r\n> 7f400d0b6000-7f400d0ba000 rw-p 00000000 00:00 0 \r\n> 7f400d0ba000-7f400d0d4000 r--p 00000000 08:01 45615941                   /etc/ld.so.cache\r\n> 7f400d0d4000-7f400d0d5000 ---p 00000000 00:00 0 \r\n> 7f400d0d5000-7f400d1d5000 rw-p 00000000 00:00 0 \r\n> 7f400d1d5000-7f400d1d8000 ---p 00000000 00:00 0 \r\n> 7f400d1d8000-7f400d2d6000 rw-p 00000000 00:00 0 \r\n> 7f400d2d6000-7f400d2ec000 r-xp 00000000 08:01 11935133                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libnet.so\r\n> 7f400d2ec000-7f400d4eb000 ---p 00016000 08:01 11935133                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libnet.so\r\n> 7f400d4eb000-7f400d4ec000 r--p 00015000 08:01 11935133                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libnet.so\r\n> 7f400d4ec000-7f400d4ed000 rw-p 00016000 08:01 11935133                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libnet.so\r\n> 7f400d4ed000-7f400d4ee000 ---p 00000000 00:00 0 \r\n> 7f400d4ee000-7f400d4f1000 ---p 00000000 00:00 0 \r\n> 7f400d4f1000-7f400d5ee000 rw-p 00000000 00:00 0 \r\n> 7f400d5ee000-7f400d5ef000 ---p 00000000 00:00 0 \r\n> 7f400d5ef000-7f400d5f2000 ---p 00000000 00:00 0 \r\n> 7f400d5f2000-7f400d6ef000 rw-p 00000000 00:00 0 \r\n> 7f400d6ef000-7f400d6f0000 ---p 00000000 00:00 0 \r\n> 7f400d6f0000-7f400d6f3000 ---p 00000000 00:00 0 \r\n> 7f400d6f3000-7f400d7f0000 rw-p 00000000 00:00 0 \r\n> 7f400d7f0000-7f400d7f1000 ---p 00000000 00:00 0 \r\n> 7f400d7f1000-7f400d7f4000 ---p 00000000 00:00 0 \r\n> 7f400d7f4000-7f400d8f1000 rw-p 00000000 00:00 0 \r\n> 7f400d8f1000-7f400d8f4000 ---p 00000000 00:00 0 \r\n> 7f400d8f4000-7f400d9f2000 rw-p 00000000 00:00 0 \r\n> 7f400d9f2000-7f400d9f4000 r--s 0001a000 08:01 13893744                   /home/qihong/installation/idea-IU-172.4574.19/lib/idea_rt.jar\r\n> 7f400d9f4000-7f400d9f6000 r--s 00009000 08:01 25957971                   /home/qihong/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.9.6/jackson-dataformat-yaml-2.9.6.jar\r\n> 7f400d9f6000-7f400d9fa000 r--s 0004c000 08:01 18745809                   /home/qihong/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.8/jackson-core-2.9.8.jar\r\n> 7f400d9fa000-7f400d9fd000 r--s 0000e000 08:01 18746625                   /home/qihong/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar\r\n> 7f400d9fd000-7f400da10000 r--s 00137000 08:01 25822664                   /home/qihong/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.6/jackson-databind-2.9.6.jar\r\n> 7f400da10000-7f400da12000 r--s 00017000 08:01 25822662                   /home/qihong/.m2/repository/org/glassfish/javax.json/1.1.2/javax.json-1.1.2.jar\r\n> 7f400da12000-7f400da13000 r--s 00005000 08:01 25692739                   /home/qihong/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar\r\n> 7f400da13000-7f400da15000 r--s 00010000 08:01 25692737                   /home/qihong/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar\r\n> 7f400da15000-7f400da1a000 r--s 00017000 08:01 25692735                   /home/qihong/.m2/repository/javax/enterprise/cdi-api/2.0/cdi-api-2.0.jar\r\n> 7f400da1a000-7f400da1c000 r--s 00006000 08:01 25562157                   /home/qihong/.m2/repository/javax/json/javax.json-api/1.1.4/javax.json-api-1.1.4.jar\r\n> 7f400da1c000-7f400da1e000 r--s 00004000 08:01 25562153                   /home/qihong/.m2/repository/javax/json/bind/javax.json.bind-api/1.0/javax.json.bind-api-1.0.jar\r\n> 7f400da1e000-7f400da26000 r--s 00041000 08:01 25431574                   /home/qihong/.m2/repository/org/eclipse/yasson/1.0.1/yasson-1.0.1.jar\r\n> 7f400da26000-7f400da2c000 r--s 0003c000 08:01 32244101                   /home/qihong/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.2/log4j-api-2.11.2.jar\r\n> 7f400da2c000-7f400da2e000 r--s 00009000 08:01 12979358                   /home/qihong/.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar\r\n> 7f400da2e000-7f400da2f000 r--s 00005000 08:01 32113462                   /home/qihong/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.11.2/log4j-slf4j-impl-2.11.2.jar\r\n> 7f400da2f000-7f400da30000 r--s 00000000 08:01 29365624                   /home/qihong/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.14/animal-sniffer-annotations-1.14.jar\r\n> 7f400da30000-7f400da32000 r--s 00001000 08:01 21633272                   /home/qihong/.m2/repository/com/google/j2objc/j2objc-annotations/1.1/j2objc-annotations-1.1.jar\r\n> 7f400da32000-7f400da34000 r--s 00006000 08:01 32637491                   /home/qihong/.m2/repository/org/checkerframework/checker-compat-qual/2.0.0/checker-compat-qual-2.0.0.jar\r\n> 7f400da34000-7f400da66000 r--s 0026b000 08:01 23860558                   /home/qihong/.m2/repository/com/google/guava/guava/25.0-jre/guava-25.0-jre.jar\r\n> 7f400da66000-7f400da68000 r--s 0000e000 08:01 16650830                   /home/qihong/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar\r\n> 7f400da68000-7f400da76000 r--s 00121000 08:01 32637364                   /home/qihong/.m2/repository/org/mozilla/rhino/1.7.7.2/rhino-1.7.7.2.jar\r\n> 7f400da76000-7f400da78000 r--s 0001c000 08:01 23467966                   /home/qihong/.m2/repository/com/google/re2j/re2j/1.3/re2j-1.3.jar\r\n> 7f400da78000-7f400da7d000 r--s 0001d000 08:01 22945853                   /home/qihong/.m2/repository/com/google/elemental2/elemental2-core/1.0.0-RC1/elemental2-core-1.0.0-RC1.jar\r\n> 7f400da7d000-7f400da7f000 r--s 00004000 08:01 22559043                   /home/qihong/.m2/repository/com/google/jsinterop/base/1.0.0/base-1.0.0.jar\r\n> 7f400da7f000-7f400da80000 r--s 00000000 08:01 22023255                   /home/qihong/.m2/repository/com/google/jsinterop/jsinterop-annotations/1.0.2/jsinterop-annotations-1.0.2.jar\r\n> 7f400da80000-7f400da82000 r--s 00003000 08:01 12716959                   /home/qihong/.m2/repository/com/google/code/findbugs/jsr305/3.0.1/jsr305-3.0.1.jar\r\n> 7f400da82000-7f400da87000 r--s 00036000 08:01 16388309                   /home/qihong/.m2/repository/com/google/code/gson/gson/2.8.5/gson-2.8.5.jar\r\n> 7f400da87000-7f400da89000 r--s 00002000 08:01 20584988                   /home/qihong/.m2/repository/com/google/errorprone/error_prone_annotations/2.3.1/error_prone_annotations-2.3.1.jar\r\n> 7f400da89000-7f400da8c000 r--s 00010000 08:01 31459021                   /home/qihong/.m2/repository/args4j/args4j/2.0.26/args4j-2.0.26.jar\r\n> 7f400da8c000-7f400da8d000 r--s 00035000 08:01 20187693                   /home/qihong/.m2/repository/com/google/javascript/closure-compiler-externs/v20200504/closure-compiler-externs-v20200504.jar\r\n> 7f400da8d000-7f400dae5000 r--s 00715000 08:01 19400757                   /home/qihong/.m2/repository/com/google/javascript/closure-compiler-unshaded/v20200504/closure-compiler-unshaded-v20200504.jar\r\n> 7f400dae5000-7f400dae7000 r--s 0000a000 08:01 32113460                   /home/qihong/.m2/repository/org/json/json/20090211/json-20090211.jar\r\n> 7f400dae7000-7f400daec000 r--s 00034000 08:01 29101017                   /home/qihong/.m2/repository/commons-beanutils/commons-beanutils/1.8.3/commons-beanutils-1.8.3.jar\r\n> 7f400daec000-7f400daf0000 r--s 00029000 08:01 28968087                   /home/qihong/.m2/repository/commons-io/commons-io/2.3/commons-io-2.3.jar\r\n> 7f400daf0000-7f400db05000 r--s 0011b000 08:01 19013839                   /home/qihong/.m2/repository/com/github/sommeri/less4j/1.12.0/less4j-1.12.0.jar\r\n> 7f400db05000-7f400db07000 r--s 00100000 08:01 32508433                   /home/qihong/.m2/repository/org/apache/tapestry/tapestry-webresources/5.6.1/tapestry-webresources-5.6.1.jar\r\n> 7f400db07000-7f400db0e000 r--s 0004b000 08:01 28969535                   /home/qihong/.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar\r\n> 7f400db0e000-7f400db11000 r--s 00026000 08:01 13767040                   /home/qihong/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar\r\n> 7f400db11000-7f400db15000 r--s 00017000 08:01 32508446                   /home/qihong/.m2/repository/org/apache/tapestry/commons/5.6.1/commons-5.6.1.jar\r\n> 7f400db15000-7f400db19000 r--s 0001d000 08:01 32508443                   /home/qihong/.m2/repository/org/apache/tapestry/beanmodel/5.6.1/beanmodel-5.6.1.jar\r\n> 7f400db19000-7f400db1a000 r--s 00007000 08:01 32508441                   /home/qihong/.m2/repository/org/apache/tapestry/tapestry-json/5.6.1/tapestry-json-5.6.1.jar\r\n> 7f400db1a000-7f400db1b000 r--s 00000000 08:01 11010820                   /home/qihong/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar\r\n> 7f400db1b000-7f400db24000 r--s 00080000 08:01 32508435                   /home/qihong/.m2/repository/org/apache/tapestry/plastic/5.6.1/plastic-5.6.1.jar\r\n> 7f400db24000-7f400db26000 r--s 00003000 08:01 32508432                   /home/qihong/.m2/repository/org/apache/tapestry/tapestry5-annotations/5.6.1/tapestry5-annotations-5.6.1.jar\r\n> 7f400db26000-7f400db29000 r--s 0000e000 08:01 32508439                   /home/qihong/.m2/repository/org/apache/tapestry/tapestry-func/5.6.1/tapestry-func-5.6.1.jar\r\n> 7f400db29000-7f400db35000 r--s 00061000 08:01 32508431                   /home/qihong/.m2/repository/org/apache/tapestry/tapestry-ioc/5.6.1/tapestry-ioc-5.6.1.jar\r\n> 7f400db35000-7f400db62000 r--s 002bc000 08:01 32508430                   /home/qihong/.m2/repository/org/apache/tapestry/tapestry-core/5.6.1/tapestry-core-5.6.1.jar\r\n> 7f400db62000-7f400db64000 r--s 00000000 08:01 12716957                   /home/qihong/.m2/repository/org/slf4j/jul-to-slf4j/1.7.25/jul-to-slf4j-1.7.25.jar\r\n> 7f400db64000-7f400db65000 r--s 00005000 08:01 32508427                   /home/qihong/.m2/repository/org/apache/logging/log4j/log4j-jul/2.11.2/log4j-jul-2.11.2.jar\r\n> 7f400db65000-7f400db86000 r--s 0016d000 08:01 32508447                   /home/qihong/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.2/log4j-core-2.11.2.jar\r\n> 7f400db86000-7f400db87000 r--s 00000000 08:01 32113456                   /home/qihong/.m2/repository/org/springframework/boot/spring-boot-starter-log4j2/2.1.3.RELEASE/spring-boot-starter-log4j2-2.1.3.RELEASE.jar\r\n> 7f400db87000-7f400db8c000 r--s 00040000 08:01 31852524                   /home/qihong/.m2/repository/org/springframework/spring-expression/5.1.5.RELEASE/spring-expression-5.1.5.RELEASE.jar\r\n> 7f400db8c000-7f400db96000 r--s 00051000 08:01 31852532                   /home/qihong/.m2/repository/org/springframework/spring-aop/5.1.5.RELEASE/spring-aop-5.1.5.RELEASE.jar\r\n> 7f400db96000-7f400dba5000 r--s 000b5000 08:01 32113454                   /home/qihong/.m2/repository/org/springframework/spring-webmvc/5.1.5.RELEASE/spring-webmvc-5.1.5.RELEASE.jar\r\n> 7f400dba5000-7f400dbb2000 r--s 00098000 08:01 31852534                   /home/qihong/.m2/repository/org/springframework/spring-beans/5.1.5.RELEASE/spring-beans-5.1.5.RELEASE.jar\r\n> 7f400dbb2000-7f400dbce000 r--s 00136000 08:01 31852507                   /home/qihong/.m2/repository/org/springframework/spring-web/5.1.5.RELEASE/spring-web-5.1.5.RELEASE.jar\r\n> 7f400dbce000-7f400dbd0000 r--s 0000f000 08:01 12716955                   /home/qihong/.m2/repository/com/fasterxml/classmate/1.4.0/classmate-1.4.0.jar\r\n> 7f400dbd0000-7f400dbd2000 r--s 0000f000 08:01 31982385                   /home/qihong/.m2/repository/org/jboss/logging/jboss-logging/3.3.2.Final/jboss-logging-3.3.2.Final.jar\r\n> 7f400dbd2000-7f400dbd7000 r--s 00012000 08:01 12716953                   /home/qihong/.m2/repository/javax/validation/validation-api/2.0.1.Final/validation-api-2.0.1.Final.jar\r\n> 7f400dbd7000-7f400dbf4000 r--s 000fe000 08:01 31852522                   /home/qihong/.m2/repository/org/hibernate/validator/hibernate-validator/6.0.14.Final/hibernate-validator-6.0.14.Final.jar\r\n> 7f400dbf4000-7f400dbf9000 r--s 0003c000 08:01 31852526                   /home/qihong/.m2/repository/org/apache/tomcat/embed/tomcat-embed-websocket/9.0.16/tomcat-embed-websocket-9.0.16.jar\r\n> 7f400dbf9000-7f400dbfe000 r--s 00039000 08:01 31852525                   /home/qihong/.m2/repository/org/apache/tomcat/embed/tomcat-embed-el/9.0.16/tomcat-embed-el-9.0.16.jar\r\n> 7f400dbfe000-7f400dc28000 r--s 002f9000 08:01 31852528                   /home/qihong/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/9.0.16/tomcat-embed-core-9.0.16.jar\r\n> 7f400dc28000-7f400dc29000 r--s 00000000 08:01 31852520                   /home/qihong/.m2/repository/org/springframework/boot/spring-boot-starter-tomcat/2.1.3.RELEASE/spring-boot-starter-tomcat-2.1.3.RELEASE.jar\r\n> 7f400dc29000-7f400dc2b000 r--s 00001000 08:01 12716951                   /home/qihong/.m2/repository/com/fasterxml/jackson/module/jackson-module-parameter-names/2.9.8/jackson-module-parameter-names-2.9.8.jar\r\n> 7f400dc2b000-7f400dc2e000 r--s 00016000 08:01 12716949                   /home/qihong/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.9.8/jackson-datatype-jsr310-2.9.8.jar\r\n> 7f400dc2e000-7f400dc30000 r--s 00007000 08:01 12716947                   /home/qihong/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.9.8/jackson-datatype-jdk8-2.9.8.jar\r\n> 7f400dc30000-7f400dc31000 r--s 00000000 08:01 31852498                   /home/qihong/.m2/repository/org/springframework/boot/spring-boot-starter-json/2.1.3.RELEASE/spring-boot-starter-json-2.1.3.RELEASE.jar\r\n> 7f400dc31000-7f400dc32000 r--s 00000000 08:01 31852514                   /home/qihong/.m2/repository/org/springframework/boot/spring-boot-starter-web/2.1.3.RELEASE/spring-boot-starter-web-2.1.3.RELEASE.jar\r\n> 7f400dc32000-7f400dc56000 r--s 00110000 08:01 31852512                   /home/qihong/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/2.1.3.RELEASE/spring-boot-autoconfigure-2.1.3.RELEASE.jar\r\n> 7f400dc56000-7f400dc59000 ---p 00000000 00:00 0 \r\n> 7f400dc59000-7f400dd57000 rw-p 00000000 00:00 0 \r\n> 7f400dd57000-7f400e1ea000 r--p 00000000 08:01 21235028                   /usr/lib/locale/locale-archive\r\n> 7f400e1ea000-7f400e1ed000 ---p 00000000 00:00 0 \r\n> 7f400e1ed000-7f400e2eb000 rw-p 00000000 00:00 0 \r\n> 7f400e2eb000-7f400e2ee000 ---p 00000000 00:00 0 \r\n> 7f400e2ee000-7f400e3ec000 rw-p 00000000 00:00 0 \r\n> 7f400e3ec000-7f400e3ed000 ---p 00000000 00:00 0 \r\n> 7f400e3ed000-7f400fc40000 rw-p 00000000 00:00 0 \r\n> 7f400fc40000-7f4010000000 ---p 00000000 00:00 0 \r\n> 7f4010000000-7f4010021000 rw-p 00000000 00:00 0 \r\n> 7f4010021000-7f4014000000 ---p 00000000 00:00 0 \r\n> 7f4014000000-7f4014007000 r--s 00043000 08:01 24909458                   /home/qihong/.m2/repository/org/yaml/snakeyaml/1.23/snakeyaml-1.23.jar\r\n> 7f4014007000-7f4014008000 r--s 00005000 08:01 31852500                   /home/qihong/.m2/repository/org/springframework/spring-jcl/5.1.5.RELEASE/spring-jcl-5.1.5.RELEASE.jar\r\n> 7f4014008000-7f4014021000 r--s 00123000 08:01 31852499                   /home/qihong/.m2/repository/org/springframework/spring-core/5.1.5.RELEASE/spring-core-5.1.5.RELEASE.jar\r\n> 7f4014021000-7f401403b000 r--s 000f3000 08:01 31852516                   /home/qihong/.m2/repository/org/springframework/spring-context/5.1.5.RELEASE/spring-context-5.1.5.RELEASE.jar\r\n> 7f401403b000-7f4015000000 rw-p 00000000 00:00 0 \r\n> 7f4015000000-7f4015270000 rwxp 00000000 00:00 0 \r\n> 7f4015270000-7f4024000000 ---p 00000000 00:00 0 \r\n> 7f4024000000-7f40246a2000 rw-p 00000000 00:00 0 \r\n> 7f40246a2000-7f4028000000 ---p 00000000 00:00 0 \r\n> 7f4028000000-7f4028002000 r--s 00005000 08:01 12589134                   /home/qihong/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar\r\n> 7f4028002000-7f4028017000 r--s 000d3000 08:01 31852518                   /home/qihong/.m2/repository/org/springframework/boot/spring-boot/2.1.3.RELEASE/spring-boot-2.1.3.RELEASE.jar\r\n> 7f4028017000-7f4028019000 r--s 08725000 08:01 18220346                   /home/qihong/.m2/repository/org/tensorflow/libtensorflow_jni/1.15.0/libtensorflow_jni-1.15.0.jar\r\n> 7f4028019000-7f402804a000 r--s 001d1000 08:01 16782900                   /home/qihong/.m2/repository/org/tensorflow/libtensorflow/1.15.0/libtensorflow-1.15.0.jar\r\n> 7f402804a000-7f402805a000 r--s 00149000 08:01 16388315                   /home/qihong/.m2/repository/com/google/protobuf/protobuf-java/3.5.1/protobuf-java-3.5.1.jar\r\n> 7f402805a000-7f4028074000 r--s 002a6000 08:01 16388313                   /home/qihong/.m2/repository/org/tensorflow/proto/1.15.0/proto-1.15.0.jar\r\n> 7f4028074000-7f4028086000 r--s 00353000 08:01 11538539                   /home/qihong/java/jdk_1_8_0_271/jre/lib/resources.jar\r\n> 7f4028086000-7f4028099000 r--s 000d6000 08:01 11538543                   /home/qihong/java/jdk_1_8_0_271/jre/lib/plugin.jar\r\n> 7f4028099000-7f40280aa000 r--s 001c1000 08:01 11538537                   /home/qihong/java/jdk_1_8_0_271/jre/lib/jsse.jar\r\n> 7f40280aa000-7f40280ac000 r--s 00007000 08:01 11538545                   /home/qihong/java/jdk_1_8_0_271/jre/lib/jfxswt.jar\r\n> 7f40280ac000-7f40282fe000 rw-p 00000000 00:00 0 \r\n> 7f40282fe000-7f40284db000 r--s 03e16000 08:01 11538538                   /home/qihong/java/jdk_1_8_0_271/jre/lib/rt.jar\r\n> 7f40284db000-7f4028551000 rw-p 00000000 00:00 0 \r\n> 7f4028551000-7f4028552000 ---p 00000000 00:00 0 \r\n> 7f4028552000-7f4028652000 rw-p 00000000 00:00 0 \r\n> 7f4028652000-7f4028653000 ---p 00000000 00:00 0 \r\n> 7f4028653000-7f4028753000 rw-p 00000000 00:00 0 \r\n> 7f4028753000-7f4028754000 ---p 00000000 00:00 0 \r\n> 7f4028754000-7f4028854000 rw-p 00000000 00:00 0 \r\n> 7f4028854000-7f4028855000 ---p 00000000 00:00 0 \r\n> 7f4028855000-7f4028955000 rw-p 00000000 00:00 0 \r\n> 7f4028955000-7f4028956000 ---p 00000000 00:00 0 \r\n> 7f4028956000-7f4028a56000 rw-p 00000000 00:00 0 \r\n> 7f4028a56000-7f4028a57000 ---p 00000000 00:00 0 \r\n> 7f4028a57000-7f4028b57000 rw-p 00000000 00:00 0 \r\n> 7f4028b57000-7f4028b58000 ---p 00000000 00:00 0 \r\n> 7f4028b58000-7f4028c58000 rw-p 00000000 00:00 0 \r\n> 7f4028c58000-7f4028c59000 ---p 00000000 00:00 0 \r\n> 7f4028c59000-7f4028dc1000 rw-p 00000000 00:00 0 \r\n> 7f4028dc1000-7f40293d9000 ---p 00000000 00:00 0 \r\n> 7f40293d9000-7f4029441000 rw-p 00000000 00:00 0 \r\n> 7f4029441000-7f4029a58000 ---p 00000000 00:00 0 \r\n> 7f4029a58000-7f4029a8d000 rw-p 00000000 00:00 0 \r\n> 7f4029a8d000-7f4029d98000 ---p 00000000 00:00 0 \r\n> 7f4029d98000-7f4029da3000 rw-p 00000000 00:00 0 \r\n> 7f4029da3000-7f402a159000 ---p 00000000 00:00 0 \r\n> 7f402a159000-7f402a174000 r-xp 00000000 08:01 11935132                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libzip.so\r\n> 7f402a174000-7f402a373000 ---p 0001b000 08:01 11935132                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libzip.so\r\n> 7f402a373000-7f402a374000 r--p 0001a000 08:01 11935132                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libzip.so\r\n> 7f402a374000-7f402a375000 rw-p 0001b000 08:01 11935132                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libzip.so\r\n> 7f402a375000-7f402a380000 r-xp 00000000 08:01 6029600                    /lib/x86_64-linux-gnu/libnss_files-2.27.so\r\n> 7f402a380000-7f402a57f000 ---p 0000b000 08:01 6029600                    /lib/x86_64-linux-gnu/libnss_files-2.27.so\r\n> 7f402a57f000-7f402a580000 r--p 0000a000 08:01 6029600                    /lib/x86_64-linux-gnu/libnss_files-2.27.so\r\n> 7f402a580000-7f402a581000 rw-p 0000b000 08:01 6029600                    /lib/x86_64-linux-gnu/libnss_files-2.27.so\r\n> 7f402a581000-7f402a587000 rw-p 00000000 00:00 0 \r\n> 7f402a587000-7f402a59e000 r-xp 00000000 08:01 6029597                    /lib/x86_64-linux-gnu/libnsl-2.27.so\r\n> 7f402a59e000-7f402a79d000 ---p 00017000 08:01 6029597                    /lib/x86_64-linux-gnu/libnsl-2.27.so\r\n> 7f402a79d000-7f402a79e000 r--p 00016000 08:01 6029597                    /lib/x86_64-linux-gnu/libnsl-2.27.so\r\n> 7f402a79e000-7f402a79f000 rw-p 00017000 08:01 6029597                    /lib/x86_64-linux-gnu/libnsl-2.27.so\r\n> 7f402a79f000-7f402a7a1000 rw-p 00000000 00:00 0 \r\n> 7f402a7a1000-7f402a7ac000 r-xp 00000000 08:01 6029602                    /lib/x86_64-linux-gnu/libnss_nis-2.27.so\r\n> 7f402a7ac000-7f402a9ab000 ---p 0000b000 08:01 6029602                    /lib/x86_64-linux-gnu/libnss_nis-2.27.so\r\n> 7f402a9ab000-7f402a9ac000 r--p 0000a000 08:01 6029602                    /lib/x86_64-linux-gnu/libnss_nis-2.27.so\r\n> 7f402a9ac000-7f402a9ad000 rw-p 0000b000 08:01 6029602                    /lib/x86_64-linux-gnu/libnss_nis-2.27.so\r\n> 7f402a9ad000-7f402a9b5000 r-xp 00000000 08:01 6029598                    /lib/x86_64-linux-gnu/libnss_compat-2.27.so\r\n> 7f402a9b5000-7f402abb5000 ---p 00008000 08:01 6029598                    /lib/x86_64-linux-gnu/libnss_compat-2.27.so\r\n> 7f402abb5000-7f402abb6000 r--p 00008000 08:01 6029598                    /lib/x86_64-linux-gnu/libnss_compat-2.27.so\r\n> 7f402abb6000-7f402abb7000 rw-p 00009000 08:01 6029598                    /lib/x86_64-linux-gnu/libnss_compat-2.27.so\r\n> 7f402abb7000-7f402abc1000 r-xp 00000000 08:01 11935139                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libinstrument.so\r\n> 7f402abc1000-7f402adc0000 ---p 0000a000 08:01 11935139                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libinstrument.so\r\n> 7f402adc0000-7f402adc1000 r--p 00009000 08:01 11935139                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libinstrument.so\r\n> 7f402adc1000-7f402adc2000 rw-p 0000a000 08:01 11935139                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libinstrument.so\r\n> 7f402adc2000-7f402adee000 r-xp 00000000 08:01 11935130                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libjava.so\r\n> 7f402adee000-7f402afee000 ---p 0002c000 08:01 11935130                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libjava.so\r\n> 7f402afee000-7f402afef000 r--p 0002c000 08:01 11935130                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libjava.so\r\n> 7f402afef000-7f402aff1000 rw-p 0002d000 08:01 11935130                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libjava.so\r\n> 7f402aff1000-7f402affe000 r-xp 00000000 08:01 11935117                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libverify.so\r\n> 7f402affe000-7f402b1fd000 ---p 0000d000 08:01 11935117                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libverify.so\r\n> 7f402b1fd000-7f402b1ff000 r--p 0000c000 08:01 11935117                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libverify.so\r\n> 7f402b1ff000-7f402b200000 rw-p 0000e000 08:01 11935117                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/libverify.so\r\n> 7f402b200000-7f402b207000 r-xp 00000000 08:01 6029607                    /lib/x86_64-linux-gnu/librt-2.27.so\r\n> 7f402b207000-7f402b406000 ---p 00007000 08:01 6029607                    /lib/x86_64-linux-gnu/librt-2.27.so\r\n> 7f402b406000-7f402b407000 r--p 00006000 08:01 6029607                    /lib/x86_64-linux-gnu/librt-2.27.so\r\n> 7f402b407000-7f402b408000 rw-p 00007000 08:01 6029607                    /lib/x86_64-linux-gnu/librt-2.27.so\r\n> 7f402b408000-7f402b5a5000 r-xp 00000000 08:01 6029594                    /lib/x86_64-linux-gnu/libm-2.27.so\r\n> 7f402b5a5000-7f402b7a4000 ---p 0019d000 08:01 6029594                    /lib/x86_64-linux-gnu/libm-2.27.so\r\n> 7f402b7a4000-7f402b7a5000 r--p 0019c000 08:01 6029594                    /lib/x86_64-linux-gnu/libm-2.27.so\r\n> 7f402b7a5000-7f402b7a6000 rw-p 0019d000 08:01 6029594                    /lib/x86_64-linux-gnu/libm-2.27.so\r\n> 7f402b7a6000-7f402c49b000 r-xp 00000000 08:01 12066242                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/server/libjvm.so\r\n> 7f402c49b000-7f402c69b000 ---p 00cf5000 08:01 12066242                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/server/libjvm.so\r\n> 7f402c69b000-7f402c731000 r--p 00cf5000 08:01 12066242                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/server/libjvm.so\r\n> 7f402c731000-7f402c762000 rw-p 00d8b000 08:01 12066242                   /home/qihong/java/jdk_1_8_0_271/jre/lib/amd64/server/libjvm.so\r\n> 7f402c762000-7f402c79d000 rw-p 00000000 00:00 0 \r\n> 7f402c79d000-7f402c984000 r-xp 00000000 08:01 6029590                    /lib/x86_64-linux-gnu/libc-2.27.so\r\n> 7f402c984000-7f402cb84000 ---p 001e7000 08:01 6029590                    /lib/x86_64-linux-gnu/libc-2.27.so\r\n> 7f402cb84000-7f402cb88000 r--p 001e7000 08:01 6029590                    /lib/x86_64-linux-gnu/libc-2.27.so\r\n> 7f402cb88000-7f402cb8a000 rw-p 001eb000 08:01 6029590                    /lib/x86_64-linux-gnu/libc-2.27.so\r\n> 7f402cb8a000-7f402cb8e000 rw-p 00000000 00:00 0 \r\n> 7f402cb8e000-7f402cb91000 r-xp 00000000 08:01 6029593                    /lib/x86_64-linux-gnu/libdl-2.27.so\r\n> 7f402cb91000-7f402cd90000 ---p 00003000 08:01 6029593                    /lib/x86_64-linux-gnu/libdl-2.27.so\r\n> 7f402cd90000-7f402cd91000 r--p 00002000 08:01 6029593                    /lib/x86_64-linux-gnu/libdl-2.27.so\r\n> 7f402cd91000-7f402cd92000 rw-p 00003000 08:01 6029593                    /lib/x86_64-linux-gnu/libdl-2.27.so\r\n> 7f402cd92000-7f402cda9000 r-xp 00000000 08:01 26087328                   /home/qihong/java/jdk_1_8_0_271/lib/amd64/jli/libjli.so\r\n> 7f402cda9000-7f402cfa8000 ---p 00017000 08:01 26087328                   /home/qihong/java/jdk_1_8_0_271/lib/amd64/jli/libjli.so\r\n> 7f402cfa8000-7f402cfa9000 r--p 00016000 08:01 26087328                   /home/qihong/java/jdk_1_8_0_271/lib/amd64/jli/libjli.so\r\n> 7f402cfa9000-7f402cfaa000 rw-p 00017000 08:01 26087328                   /home/qihong/java/jdk_1_8_0_271/lib/amd64/jli/libjli.so\r\n> 7f402cfaa000-7f402cfc4000 r-xp 00000000 08:01 6029605                    /lib/x86_64-linux-gnu/libpthread-2.27.so\r\n> 7f402cfc4000-7f402d1c3000 ---p 0001a000 08:01 6029605                    /lib/x86_64-linux-gnu/libpthread-2.27.so\r\n> 7f402d1c3000-7f402d1c4000 r--p 00019000 08:01 6029605                    /lib/x86_64-linux-gnu/libpthread-2.27.so\r\n> 7f402d1c4000-7f402d1c5000 rw-p 0001a000 08:01 6029605                    /lib/x86_64-linux-gnu/libpthread-2.27.so\r\n> 7f402d1c5000-7f402d1c9000 rw-p 00000000 00:00 0 \r\n> 7f402d1c9000-7f402d1f2000 r-xp 00000000 08:01 6029585                    /lib/x86_64-linux-gnu/ld-2.27.so\r\n> 7f402d1f2000-7f402d1f3000 r--s 00000000 08:01 31852510                   /home/qihong/.m2/repository/org/springframework/boot/spring-boot-starter/2.1.3.RELEASE/spring-boot-starter-2.1.3.RELEASE.jar\r\n> 7f402d1f3000-7f402d1f8000 r--s 00087000 08:01 11538535                   /home/qihong/java/jdk_1_8_0_271/jre/lib/jfr.jar\r\n> 7f402d1f8000-7f402d1fa000 r--s 0001b000 08:01 11538534                   /home/qihong/java/jdk_1_8_0_271/jre/lib/jce.jar\r\n> 7f402d1fa000-7f402d216000 r--s 0020c000 08:01 11538541                   /home/qihong/java/jdk_1_8_0_271/jre/lib/deploy.jar\r\n> 7f402d216000-7f402d2d3000 rw-p 00000000 00:00 0 \r\n> 7f402d2d3000-7f402d2d4000 ---p 00000000 00:00 0 \r\n> 7f402d2d4000-7f402d2d7000 ---p 00000000 00:00 0 \r\n> 7f402d2d7000-7f402d3d6000 rw-p 00000000 00:00 0 \r\n> 7f402d3d6000-7f402d3d7000 r--s 00000000 08:01 11538533                   /home/qihong/java/jdk_1_8_0_271/jre/lib/management-agent.jar\r\n> 7f402d3d7000-7f402d3e1000 r--s 0006e000 08:01 11538542                   /home/qihong/java/jdk_1_8_0_271/jre/lib/javaws.jar\r\n> 7f402d3e1000-7f402d3e6000 r--s 002f9000 08:01 11538532                   /home/qihong/java/jdk_1_8_0_271/jre/lib/charsets.jar\r\n> 7f402d3e6000-7f402d3ee000 rw-s 00000000 08:01 19799579                   /tmp/hsperfdata_qihong/19433\r\n> 7f402d3ee000-7f402d3ef000 rw-p 00000000 00:00 0 \r\n> 7f402d3ef000-7f402d3f0000 r--p 00000000 00:00 0 \r\n> 7f402d3f0000-7f402d3f2000 rw-p 00000000 00:00 0 \r\n> 7f402d3f2000-7f402d3f3000 r--p 00029000 08:01 6029585                    /lib/x86_64-linux-gnu/ld-2.27.so\r\n> 7f402d3f3000-7f402d3f4000 rw-p 0002a000 08:01 6029585                    /lib/x86_64-linux-gnu/ld-2.27.so\r\n> 7f402d3f4000-7f402d3f5000 rw-p 00000000 00:00 0 \r\n> 7ffdec85e000-7ffdec882000 rw-p 00000000 00:00 0                          [stack]\r\n> 7ffdec968000-7ffdec96b000 r--p 00000000 00:00 0                          [vvar]\r\n> 7ffdec96b000-7ffdec96c000 r-xp 00000000 00:00 0                          [vdso]\r\n> ffffffffff600000-ffffffffff601000 --xp 00000000 00:00 0                  [vsyscall]\r\n> \r\n> VM Arguments:\r\n> jvm_args: -javaagent:/home/qihong/installation/idea-IU-172.4574.19/lib/idea_rt.jar=40529:/home/qihong/installation/idea-IU-172.4574.19/bin -Dfile.encoding=UTF-8 \r\n> java_command: XXX.TFTest\r\n> java_class_path (initial): /home/qihong/java/jdk_1_8_0_271/jre/lib/charsets.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/deploy.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/ext/cldrdata.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/ext/dnsns.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/ext/jaccess.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/ext/jfxrt.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/ext/localedata.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/ext/nashorn.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/ext/sunec.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/ext/sunjce_provider.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/ext/sunpkcs11.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/ext/zipfs.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/javaws.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/jce.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/jfr.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/jfxswt.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/jsse.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/management-agent.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/plugin.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/resources.jar:/home/qihong/java/jdk_1_8_0_271/jre/lib/rt.jar:/home/qihong/TEST_TF/target/classes:/home/qihong/.m2/repository/org/tensorflow/proto/1.15.0/proto-1.15.0.jar:/home/qihong/.m2/repository/com/google/protobuf/protobuf-java/3.5.1/protobuf-java-3.5.1.jar:/home/qihong/.m2/repository/org/tensorflow/libtensorflow/1.15.0/libtensorflow-1.15.0.jar:/home/qihong/.m2/repository/org/tensorflow/libtensorflow_jni/1.15.0/libtensorflow_jni-1.15.0.jar:/home/qihong/.m2/repository/org/springframework/boot/spring-boot-starter/2.1.3.RELEASE/spring-boot-starter-2.1.3.RELEASE.jar:/home/qihong/.m2/repository/org/springframework/boot/spring-boot/2.1.3.RELEASE/spring-boot-2.1.3.RELEASE.jar:/home/qihong/.m2/repository/org/springframework/spring-context/5.1.5.RELEASE/spring-context-5.1.5.RELEASE.jar:/home/qihong/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/2.1.3.RELEASE/spring-boot-autoc\r\n> Launcher Type: SUN_STANDARD\r\n> \r\n> Environment Variables:\r\n> JAVA_HOME=/home/qihong/java/jdk_1_8_0_271\r\n> JRE_HOME=/home/qihong/java/jdk_1_8_0_271/jre\r\n> CLASSPATH=/home/qihong/installation/idea-IU-172.4574.19/lib/bootstrap.jar:/home/qihong/installation/idea-IU-172.4574.19/lib/extensions.jar:/home/qihong/installation/idea-IU-172.4574.19/lib/util.jar:/home/qihong/installation/idea-IU-172.4574.19/lib/jdom.jar:/home/qihong/installation/idea-IU-172.4574.19/lib/log4j.jar:/home/qihong/installation/idea-IU-172.4574.19/lib/trove4j.jar:/home/qihong/installation/idea-IU-172.4574.19/lib/jna.jar:/home/qihong/java/jdk_1_8_0_271/lib/tools.jar\r\n> PATH=/home/qihong/java/jdk_1_8_0_271/bin:/home/qihong/java/jdk_11_0_9/bin:/home/qihong/anaconda3/bin:/home/qihong/anaconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\r\n> LD_LIBRARY_PATH=/home/qihong/installation/idea-IU-172.4574.19/bin:\r\n> SHELL=/bin/bash\r\n> DISPLAY=localhost:10.0\r\n> \r\n> Signal Handlers:\r\n> SIGSEGV: [libjvm.so+0xadf3a0], sa_mask[0]=11111111011111111101111111111110, sa_flags=SA_RESTART|SA_SIGINFO\r\n> SIGBUS: [libjvm.so+0xadf3a0], sa_mask[0]=11111111011111111101111111111110, sa_flags=SA_RESTART|SA_SIGINFO\r\n> SIGFPE: [libjvm.so+0x913c30], sa_mask[0]=11111111011111111101111111111110, sa_flags=SA_RESTART|SA_SIGINFO\r\n> SIGPIPE: [libjvm.so+0x913c30], sa_mask[0]=11111111011111111101111111111110, sa_flags=SA_RESTART|SA_SIGINFO\r\n> SIGXFSZ: [libjvm.so+0x913c30], sa_mask[0]=11111111011111111101111111111110, sa_flags=SA_RESTART|SA_SIGINFO\r\n> SIGILL: [libjvm.so+0x913c30], sa_mask[0]=11111111011111111101111111111110, sa_flags=SA_RESTART|SA_SIGINFO\r\n> SIGUSR1: SIG_DFL, sa_mask[0]=00000000000000000000000000000000, sa_flags=none\r\n> SIGUSR2: [libjvm.so+0x913b00], sa_mask[0]=00100000000000000000000000000000, sa_flags=SA_RESTART|SA_SIGINFO\r\n> SIGHUP: [libjvm.so+0x914120], sa_mask[0]=11111111011111111101111111111110, sa_flags=SA_RESTART|SA_SIGINFO\r\n> SIGINT: [libjvm.so+0x914120], sa_mask[0]=11111111011111111101111111111110, sa_flags=SA_RESTART|SA_SIGINFO\r\n> SIGTERM: [libjvm.so+0x914120], sa_mask[0]=11111111011111111101111111111110, sa_flags=SA_RESTART|SA_SIGINFO\r\n> SIGQUIT: [libjvm.so+0x914120], sa_mask[0]=11111111011111111101111111111110, sa_flags=SA_RESTART|SA_SIGINFO\r\n> \r\n> \r\n> ---------------  S Y S T E M  ---------------\r\n> \r\n> OS:DISTRIB_ID=Ubuntu\r\n> DISTRIB_RELEASE=18.04\r\n> DISTRIB_CODENAME=bionic\r\n> DISTRIB_DESCRIPTION=\"Ubuntu 18.04.5 LTS\"\r\n> \r\n> uname:Linux 5.3.0-28-generic #30~18.04.1-Ubuntu SMP Fri Jan 17 06:14:09 UTC 2020 x86_64\r\n> libc:glibc 2.27 NPTL 2.27 \r\n> rlimit: STACK 8192k, CORE 0k, NPROC 79635, NOFILE 1048576, AS infinity\r\n> load average:0.57 0.36 0.27\r\n> \r\n> /proc/meminfo:\r\n> MemTotal:       20435540 kB\r\n> MemFree:         8384596 kB\r\n> MemAvailable:   17206692 kB\r\n> Buffers:          567192 kB\r\n> Cached:          8104844 kB\r\n> SwapCached:            0 kB\r\n> Active:          5297996 kB\r\n> Inactive:        6049832 kB\r\n> Active(anon):    2677028 kB\r\n> Inactive(anon):      600 kB\r\n> Active(file):    2620968 kB\r\n> Inactive(file):  6049232 kB\r\n> Unevictable:           0 kB\r\n> Mlocked:               0 kB\r\n> SwapTotal:       2097148 kB\r\n> SwapFree:        2097148 kB\r\n> Dirty:            185264 kB\r\n> Writeback:             0 kB\r\n> AnonPages:       2676092 kB\r\n> Mapped:           266832 kB\r\n> Shmem:              1688 kB\r\n> KReclaimable:     517960 kB\r\n> Slab:             564768 kB\r\n> SReclaimable:     517960 kB\r\n> SUnreclaim:        46808 kB\r\n> KernelStack:       10880 kB\r\n> PageTables:        32260 kB\r\n> NFS_Unstable:          0 kB\r\n> Bounce:                0 kB\r\n> WritebackTmp:          0 kB\r\n> CommitLimit:    12314916 kB\r\n> Committed_AS:    6871444 kB\r\n> VmallocTotal:   34359738367 kB\r\n> VmallocUsed:       20428 kB\r\n> VmallocChunk:          0 kB\r\n> Percpu:             2496 kB\r\n> HardwareCorrupted:     0 kB\r\n> AnonHugePages:         0 kB\r\n> ShmemHugePages:        0 kB\r\n> ShmemPmdMapped:        0 kB\r\n> CmaTotal:              0 kB\r\n> CmaFree:               0 kB\r\n> HugePages_Total:       0\r\n> HugePages_Free:        0\r\n> HugePages_Rsvd:        0\r\n> HugePages_Surp:        0\r\n> Hugepagesize:       2048 kB\r\n> Hugetlb:               0 kB\r\n> DirectMap4k:      175792 kB\r\n> DirectMap2M:    20729856 kB\r\n> \r\n> container (cgroup) information:\r\n> container_type: cgroupv1\r\n> cpu_cpuset_cpus: 0-7\r\n> cpu_memory_nodes: 0\r\n> active_processor_count: 8\r\n> cpu_quota: -1\r\n> cpu_period: 100000\r\n> cpu_shares: -1\r\n> memory_limit_in_bytes: -1\r\n> memory_and_swap_limit_in_bytes: -2\r\n> memory_soft_limit_in_bytes: -1\r\n> memory_usage_in_bytes: 11620184064\r\n> memory_max_usage_in_bytes: 0\r\n> \r\n> \r\n> CPU:total 8 (initial active 8) (4 cores per cpu, 2 threads per core) family 6 model 30 stepping 5, cmov, cx8, fxsr, mmx, sse, sse2, sse3, ssse3, sse4.1, sse4.2, popcnt, ht, tsc, tscinvbit\r\n> \r\n> /proc/cpuinfo:\r\n> processor\t: 0\r\n> vendor_id\t: GenuineIntel\r\n> cpu family\t: 6\r\n> model\t\t: 30\r\n> model name\t: Intel(R) Core(TM) i7 CPU         860  @ 2.80GHz\r\n> stepping\t: 5\r\n> microcode\t: 0xa\r\n> cpu MHz\t\t: 2964.113\r\n> cache size\t: 8192 KB\r\n> physical id\t: 0\r\n> siblings\t: 8\r\n> core id\t\t: 0\r\n> cpu cores\t: 4\r\n> apicid\t\t: 0\r\n> initial apicid\t: 0\r\n> fpu\t\t: yes\r\n> fpu_exception\t: yes\r\n> cpuid level\t: 11\r\n> wp\t\t: yes\r\n> flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d\r\n> bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit\r\n> bogomips\t: 5585.88\r\n> clflush size\t: 64\r\n> cache_alignment\t: 64\r\n> address sizes\t: 36 bits physical, 48 bits virtual\r\n> power management:\r\n> \r\n> processor\t: 1\r\n> vendor_id\t: GenuineIntel\r\n> cpu family\t: 6\r\n> model\t\t: 30\r\n> model name\t: Intel(R) Core(TM) i7 CPU         860  @ 2.80GHz\r\n> stepping\t: 5\r\n> microcode\t: 0xa\r\n> cpu MHz\t\t: 2941.756\r\n> cache size\t: 8192 KB\r\n> physical id\t: 0\r\n> siblings\t: 8\r\n> core id\t\t: 0\r\n> cpu cores\t: 4\r\n> apicid\t\t: 1\r\n> initial apicid\t: 1\r\n> fpu\t\t: yes\r\n> fpu_exception\t: yes\r\n> cpuid level\t: 11\r\n> wp\t\t: yes\r\n> flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d\r\n> bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit\r\n> bogomips\t: 5585.88\r\n> clflush size\t: 64\r\n> cache_alignment\t: 64\r\n> address sizes\t: 36 bits physical, 48 bits virtual\r\n> power management:\r\n> \r\n> processor\t: 2\r\n> vendor_id\t: GenuineIntel\r\n> cpu family\t: 6\r\n> model\t\t: 30\r\n> model name\t: Intel(R) Core(TM) i7 CPU         860  @ 2.80GHz\r\n> stepping\t: 5\r\n> microcode\t: 0xa\r\n> cpu MHz\t\t: 2992.502\r\n> cache size\t: 8192 KB\r\n> physical id\t: 0\r\n> siblings\t: 8\r\n> core id\t\t: 3\r\n> cpu cores\t: 4\r\n> apicid\t\t: 7\r\n> initial apicid\t: 7\r\n> fpu\t\t: yes\r\n> fpu_exception\t: yes\r\n> cpuid level\t: 11\r\n> wp\t\t: yes\r\n> flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d\r\n> bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit\r\n> bogomips\t: 5585.88\r\n> clflush size\t: 64\r\n> cache_alignment\t: 64\r\n> address sizes\t: 36 bits physical, 48 bits virtual\r\n> power management:\r\n> \r\n> processor\t: 3\r\n> vendor_id\t: GenuineIntel\r\n> cpu family\t: 6\r\n> model\t\t: 30\r\n> model name\t: Intel(R) Core(TM) i7 CPU         860  @ 2.80GHz\r\n> stepping\t: 5\r\n> microcode\t: 0xa\r\n> cpu MHz\t\t: 3015.266\r\n> cache size\t: 8192 KB\r\n> physical id\t: 0\r\n> siblings\t: 8\r\n> core id\t\t: 2\r\n> cpu cores\t: 4\r\n> apicid\t\t: 4\r\n> initial apicid\t: 4\r\n> fpu\t\t: yes\r\n> fpu_exception\t: yes\r\n> cpuid level\t: 11\r\n> wp\t\t: yes\r\n> flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d\r\n> bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit\r\n> bogomips\t: 5585.88\r\n> clflush size\t: 64\r\n> cache_alignment\t: 64\r\n> address sizes\t: 36 bits physical, 48 bits virtual\r\n> power management:\r\n> \r\n> processor\t: 4\r\n> vendor_id\t: GenuineIntel\r\n> cpu family\t: 6\r\n> model\t\t: 30\r\n> model name\t: Intel(R) Core(TM) i7 CPU         860  @ 2.80GHz\r\n> stepping\t: 5\r\n> microcode\t: 0xa\r\n> cpu MHz\t\t: 3034.687\r\n> cache size\t: 8192 KB\r\n> physical id\t: 0\r\n> siblings\t: 8\r\n> core id\t\t: 3\r\n> cpu cores\t: 4\r\n> apicid\t\t: 6\r\n> initial apicid\t: 6\r\n> fpu\t\t: yes\r\n> fpu_exception\t: yes\r\n> cpuid level\t: 11\r\n> wp\t\t: yes\r\n> flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d\r\n> bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit\r\n> bogomips\t: 5585.88\r\n> clflush size\t: 64\r\n> cache_alignment\t: 64\r\n> address sizes\t: 36 bits physical, 48 bits virtual\r\n> power management:\r\n> \r\n> processor\t: 5\r\n> vendor_id\t: GenuineIntel\r\n> cpu family\t: 6\r\n> model\t\t: 30\r\n> model name\t: Intel(R) Core(TM) i7 CPU         860  @ 2.80GHz\r\n> stepping\t: 5\r\n> microcode\t: 0xa\r\n> cpu MHz\t\t: 2928.733\r\n> cache size\t: 8192 KB\r\n> physical id\t: 0\r\n> siblings\t: 8\r\n> core id\t\t: 2\r\n> cpu cores\t: 4\r\n> apicid\t\t: 5\r\n> initial apicid\t: 5\r\n> fpu\t\t: yes\r\n> fpu_exception\t: yes\r\n> cpuid level\t: 11\r\n> wp\t\t: yes\r\n> flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d\r\n> bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit\r\n> bogomips\t: 5585.88\r\n> clflush size\t: 64\r\n> cache_alignment\t: 64\r\n> address sizes\t: 36 bits physical, 48 bits virtual\r\n> power management:\r\n> \r\n> processor\t: 6\r\n> vendor_id\t: GenuineIntel\r\n> cpu family\t: 6\r\n> model\t\t: 30\r\n> model name\t: Intel(R) Core(TM) i7 CPU         860  @ 2.80GHz\r\n> stepping\t: 5\r\n> microcode\t: 0xa\r\n> cpu MHz\t\t: 2926.159\r\n> cache size\t: 8192 KB\r\n> physical id\t: 0\r\n> siblings\t: 8\r\n> core id\t\t: 1\r\n> cpu cores\t: 4\r\n> apicid\t\t: 2\r\n> initial apicid\t: 2\r\n> fpu\t\t: yes\r\n> fpu_exception\t: yes\r\n> cpuid level\t: 11\r\n> wp\t\t: yes\r\n> flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d\r\n> bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit\r\n> bogomips\t: 5585.88\r\n> clflush size\t: 64\r\n> cache_alignment\t: 64\r\n> address sizes\t: 36 bits physical, 48 bits virtual\r\n> power management:\r\n> \r\n> processor\t: 7\r\n> vendor_id\t: GenuineIntel\r\n> cpu family\t: 6\r\n> model\t\t: 30\r\n> model name\t: Intel(R) Core(TM) i7 CPU         860  @ 2.80GHz\r\n> stepping\t: 5\r\n> microcode\t: 0xa\r\n> cpu MHz\t\t: 2925.942\r\n> cache size\t: 8192 KB\r\n> physical id\t: 0\r\n> siblings\t: 8\r\n> core id\t\t: 1\r\n> cpu cores\t: 4\r\n> apicid\t\t: 3\r\n> initial apicid\t: 3\r\n> fpu\t\t: yes\r\n> fpu_exception\t: yes\r\n> cpuid level\t: 11\r\n> wp\t\t: yes\r\n> flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d\r\n> bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit\r\n> bogomips\t: 5585.88\r\n> clflush size\t: 64\r\n> cache_alignment\t: 64\r\n> address sizes\t: 36 bits physical, 48 bits virtual\r\n> power management:\r\n> \r\n> \r\n> \r\n> Memory: 4k page, physical 20435540k(8381320k free), swap 2097148k(2097148k free)\r\n> \r\n> vm_info: Java HotSpot(TM) 64-Bit Server VM (25.271-b09) for linux-amd64 JRE (1.8.0_271-b09), built on Sep 16 2020 17:01:41 by \"java_re\" with gcc 7.3.0\r\n> \r\n> time: Wed Nov 11 11:27:13 2020\r\n> timezone: CST\r\n> elapsed time: 1.258237 seconds (0d 0h 0m 1s)\r\n> ```\r\n\r\nyour cpu not supports avx/avx2, while tensorflow being built under avx2 since version 1.4. ", "@KimiLiuQh It looks like you are using an older Version of Tensorflow . Many bugs have been fixed in the latest version. Could you please execute your code using Latest Version 2.6.0 and let us know if the issue still persists? Please refer to the similar [ issue ](https://stackoverflow.com/questions/13654449/error-segmentation-fault-core-dumped), article [link](https://blog.opstree.com/2019/04/02/resolving-segmentation-fault-core-dumped-in-ubuntu/) and let us know if it helps?Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44754\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44754\">No</a>\n"]}, {"number": 44753, "title": "Issue working with Nvidia rtx-3090", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.4.0-rc1\r\n- Python version: 3.8.5\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: Cuda-11.1 cuDNN-8.05\r\n- GPU model and memory: Nvidia rtx-3090 (24GB memory)\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nwhen listing the GPU devices using **tf.congif.list_physical_devices('GPU')**, It states that '**Could not load dynamic library 'libcusolver.so.10**''.\r\nI've got libcusolver.so.11 in the path where other successfully loaded files are located and tensorflow is searching for libcusolver.so.10 _(i've also copied the file and renamed it to libcusolver.so.10 to try my luck but, still facing the same issue)_\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n`>>> tf.config.list_physical_devices('GPU')\r\n2020-11-11 11:11:23.937512: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-11-11 11:11:23.937695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-11-11 11:11:23.938928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:2d:00.0 name: GeForce RTX 3090 computeCapability: 8.6\r\ncoreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\r\n2020-11-11 11:11:23.938959: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n2020-11-11 11:11:23.938983: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\r\n2020-11-11 11:11:23.938996: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\r\n2020-11-11 11:11:23.939009: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2020-11-11 11:11:23.939022: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2020-11-11 11:11:23.939098: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\r\n2020-11-11 11:11:23.939114: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\r\n2020-11-11 11:11:23.939127: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\r\n2020-11-11 11:11:23.939136: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\n[]\r\n`\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@JVedant \r\nCould you please refer to [this comment to use cuda 11](https://github.com/tensorflow/tensorflow/issues/43629#issuecomment-702851560).\r\nSame issue reported in #43947, [link](https://stackoverflow.com/questions/64193633/could-not-load-dynamic-library-libcublas-so-10-dlerror-libcublas-so-10-cann).", "> @JVedant\r\n> Could you please refer to [this comment to use cuda 11](https://github.com/tensorflow/tensorflow/issues/43629#issuecomment-702851560).\r\n> Same issue reported in #43947, [link](https://stackoverflow.com/questions/64193633/could-not-load-dynamic-library-libcublas-so-10-dlerror-libcublas-so-10-cann).\r\n\r\nfigured it out by checking the ticket mentioned above. \r\nThanks for the help.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44753\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44753\">No</a>\n"]}, {"number": 44751, "title": "TensorFlow support for Apple Silicon (M1 Chips)", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 2.1+ (I don't know specifics)\r\n- Are you willing to contribute it (Yes/No): No, not enough repository knowledge.\r\n\r\n**Describe the feature and the current behavior/state.**\r\nThis is not a feature per se, but a question. How soon would TensorFlow be available for the Apple Silicon macs announced today with the M1 chips?\r\n\r\n**Will this change the current api? How?**\r\nHmmm, I don't know. Probably not.\r\n\r\n**Who will benefit with this feature?**\r\nThis will benefit everybody who buys an apple silicon mac right now, and in the future. This is a big change, and no one would buy intel macs after a few years.\r\n\r\n**Any Other info.**\r\nI know python and numpy are being personally helped by apple for this transition.", "comments": ["Well from the presentation of yesterday, specially timing [33 minutes](https://www.apple.com/apple-events/november-2020/), a person speaks about tensorflow, nothing super specific but it could be. Does a TF dev. could give more informations  about support of neural engine ? \r\nFrom my experience the neural engine is totally close to dev., only native execution of coreml can use it.", "It would be really cool if TF could utilize the 16-core neural engine **and** their 8-core GPU.", "There is nothing against, what you can do at least for inference is to transform your TF model to [Coreml](https://coremltools.readme.io/docs) using Apple convertor. Then you will be able to execute your model \"efficiently\" on apple Hardware (inference only).", "Well, my main problem would be training a model, as it takes more than an hour (I think) for my current model. When I get my hands on a mac, I'll see if it runs ok on rosetta 2. \r\n\r\nI just listened to the part of the event where they mention TensorFlow:\r\n \"It also makes Mac Mini great for developers, scientists, and engineers. Utilizing deep learning technologies, like TensorFlow or Create ML, which are now accelerated by M1.\"\r\nThey say Mac Mini, but I'm sure the same thing goes for the MacBook Pro and Air.", "my 2 cents, do not train with an emulator, it is a terrible idea. And definitively a Mac is not the optimal platform for training. ", "> Well, my main problem would be training a model, as it takes more than an hour (I think) for my current model. When I get my hands on a mac, I'll see if it runs ok on rosetta 2.\r\n\r\nI dont think we will need rosetta 2, as mac OS itself is a Unix machine so all the programming language and the compilers are natively running on mac for its core system to work. if we compile the TF library once(that might be bumpy), we should be good to go. what i was wondering if we run the TF for training or inference(natively with TF not after porting to CoreML) will it utilize neural engine or the ML accelerators. maybe not, for that to work the processors needs to know that its a ML job and we are not specifically telling it that its a ML job. Not sure if it's intelligent enough to do that on its own.\r\n", "I really have no idea how python packaging works, but if something is done with Xcode, the new version should be able to compile for ARM if it's out yet. I might be wrong and maybe TF dependencies might be a problem.", "First question is if they meant TensorFlow or TensorFlow Lite or some other component of the ecosystem.\r\n\r\nTensorFlow pips are only built for x86_64 at the moment.", "Can TensorFlow pips be built for arm64  without any issue? If not, what is the main obstacle?\r\nHmmm, I'm not sure what TF component they meant. Probably TensorFlow.", "The main obstacle is: TF is build other backend (Eigen - CPU, CUDA- GPU, ...). It means you must be able to code all your layer, operators, etc  for these technologies. From my knowledge there is no TF  training for Apple chip (TF lite has something for inference Apple GPU).\r\nNow if you compile from scratch TF on your Mac - M1. You will get a CPU version ARM (because Eigen works on ARM), but with no usage of Apple GPU or Neural Engine. Make a backend is a tough work, it needs a lot of effort, time, and working hour. Apple develop their own hardware/software I am not sure they care a lot about TF.", "Hmmm. CPU training is OK for the time being, I'm not training huge models or anything. If you can, could you give me a super broad estimate of when the GPU or the neural engine could be used? Something like late 2020, mid 2021, etc. Or is this just going to come out of nowhere?", "Maybe Apple would be of help somehow. Maybe.", "There are several challenges involved with the architecture of the apple silicon M1 chip, the 4+4 cpu core architecture, the 8 GPU \"cores\" and the neural processing unit. What would be a great upside is the shared (but limited) memory.\r\n\r\nCoreML is fine for inference of converted models, but full tensorflow would require a full backend which utilizes the full backend of components and does the memory management.\r\n\r\nInspiration and guidance could come from AMDs ROCm TF port.https://github.com/ROCmSoftwarePlatform/tensorflow-upstream. The build system is described here https://github.com/ROCmSoftwarePlatform/tensorflow-upstream/blob/develop-upstream/rocm_docs/rocm-port-overview.md \r\n\r\nAnother way would be to take the route of Metal or OpenCL - still the press event did not give much insight on how to actually use it. The issue for metal support is stale for some time #11085 ", "> It would be really cool if TF could utilize the 16-core neural engine **and** their 8-core GPU.\r\n\r\nThe questions is whether ANE is even optimized for these kinds of workloads. \ud83e\udd37\u200d\u2642\ufe0f According [to documentation](https://developer.apple.com/documentation/coreml/core_ml_api/personalizing_a_model_with_on-device_updates) there is just an option to \"fine tune\" (personalize) models locally.", "I don't think we will see any new TF port for ANE, until Apple release any api thats similar to Cuda (only the API, as the implementation is Nvidia's proprietary tech), otherwise it will be very difficult to write the TF core logics to port to metal or existing ANE apis, great example is AMDs RCOM which is an api similar to CUDA. But I doubt Apple will come forward and make any effort, they will only try to push CoreML instead. And  also there are not too many people waiting for this feature (only those using macs, as most people are using linux or have a separate linux machine). so most probably it will never happen from the open source community side as well. :( ", "Note that we don't release `tensorflow-gpu` for macos anyway.", "I also wouldn't expect this to be supported out of the box quite soon.\r\nProbably when MLIR and the new runtime get upstreamed, multiple backends will have better support.\r\nAn interesting alternative could be provided by Apple when auto diff will be part of swift, but this is just speculation.", "So for now, it'll only work on the CPU. That's quite OK with me. If the CPU is better than Kaggle's, I'll be fine. I'm pretty new to deep learning, so I'm not doing heavy stuff. And maybe by the time I get farther into deep learning and ML, there might be support for the ANE and the GPU.", "I wonder why Apple \"announced\" acceleration for Tensorflow on M1 macs on the Apple event. Are they outright lying, or did they mean something else? The specialy mentioned acceleration for Tensorflow and Create ML in the same sentence. And since Create ML is used for training I assumed that they also would provide acceleration for Tensorflow training.", ">And since Create ML is used for training I assumed that they also would provide acceleration for Tensorflow training.\r\n\r\nThere are no developments going on in this repo at the moment, that would only mean apple has compiled the packages for TF to support it, which is very unlikely. Maybe they meant it is possible to do so, kind of like near future possibility.\r\n", "> \"Utilize ML frameworks like TensorFlow or Create ML, now accelerated by the M1 chip.\"  \r\n![image](https://user-images.githubusercontent.com/6539412/99003546-169d6a00-24f3-11eb-9cfe-dce890edc25f.png)\r\nfrom https://www.apple.com/newsroom/2020/11/introducing-the-next-generation-of-mac/ as of 2020-11-12\r\n\r\nMy only guess is that they are referring to Swift for Tensorflow but it would be nice to get clarification from someone who knows for sure. \r\nhttps://www.tensorflow.org/swift\r\nhttps://github.com/tensorflow/swift\r\n\r\n\r\n", "I have opened a ticket on my apple developer account, lets see :-)", "The answer from developer support to my ticket: \r\n\r\n\"Currently there is no documentation available for Tensorflow support on the M1 chip set. At the moment you can find general documentation for Apple Silicon in our documentation library.\r\n\r\nI also forwarded your request as feedback to the appropriate team.\"", "So far the only way this could work is via\r\n\r\nTensorflow -> nGraph -> PlaidML -> Metal\r\n\r\nNo-one has tried though on arm, I have never bothered on my MBP as I don't have a GPU and I am doing all my TF testing on my Linux box. When I get my new MacBook I will give it a try.", "Thanks @dani0805 for the ticket. I know apple doesn't care too much about stuff like this, but TensorFlow is huge and probably will be supported in the near future.", "According to [this](https://www.apple.com/newsroom/2020/11/introducing-the-next-generation-of-mac/\r\n) press release it's supported. --> \"Utilize ML frameworks like TensorFlow or Create ML, now accelerated by the M1 chip.\"", "Right now what we can expect is that Tensorflow will be able to run on the CPUs in the M1 chip ... \r\n\r\nThe biggest blocker to GPU acceleration is the Metal API. I've heard little to no indication that Apple rectified this issue on their end. CUDA and HIP (ROCm) support templatized kernels which are used everywhere in Tensorflow so Metal would need a similar capability to be even worth considering for porting the Eigen library. For the most part we should assume that Tensorflow won't support Apple GPUs for acceleration in the near future and likely in the distant future as well ...\r\n\r\nWith all that being said there might still be a way to optimize Tensorflow further for the M1's CPU by exploring the use of their AMX instruction set featured on some Apple processors ...", "TensorFlow on ARM is a thing. It works on NVIDIA Jetson Xaviers, which are ARM based. They use an ARM the CUDA library for GPU support. I am pretty sure Python will work on M1s which means likely TensorFlow CPU will work. I am very curious to know what \"TensorFlow or Create ML, now accelerated by the M1 chip.\" is going to mean and if this needs to be driven by the community or if Apple is going to help. ", "TF on ARM exists, but it's not part of the official releases on PyPI.", "Accelerating TensorFlow Performance on Mac:\r\nhttps://blog.tensorflow.org/2020/11/accelerating-tensorflow-performance-on-mac.html\r\n\r\n\"TensorFlow users on Intel Macs or Macs powered by Apple\u2019s new M1 chip can now take advantage of accelerated training using Apple\u2019s Mac-optimized version of TensorFlow 2.4 and the new ML Compute framework.\"", "I guess that closes the issue then", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44751\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44751\">No</a>\n", "I  am getting following error when I am importing tensor flow on MacBook Air m1\r\nzsh: illegal hardware instruction  python", "The Apple TF on M1 chips is a private fork of TF owned by Apple. We don't have access to fixing code issues there", "> Accelerating TensorFlow Performance on Mac:\n> \n> https://blog.tensorflow.org/2020/11/accelerating-tensorflow-performance-on-mac.html\n> \n> \n> \n> \"TensorFlow users on Intel Macs or Macs powered by Apple\u2019s new M1 chip can now take advantage of accelerated training using Apple\u2019s Mac-optimized version of TensorFlow 2.4 and the new ML Compute framework.\"\n\nI would not that the linked article only talks about CPU / GPU support. It doesn't mention the neural Engine. Perhaps performance is still being left on the table?\ufffc", "> > Accelerating TensorFlow Performance on Mac:\r\n> > https://blog.tensorflow.org/2020/11/accelerating-tensorflow-performance-on-mac.html\r\n> > \"TensorFlow users on Intel Macs or Macs powered by Apple\u2019s new M1 chip can now take advantage of accelerated training using Apple\u2019s Mac-optimized version of TensorFlow 2.4 and the new ML Compute framework.\"\r\n> \r\n> I would not that the linked article only talks about CPU / GPU support. It doesn't mention the neural Engine. Perhaps performance is still being left on the table?\ufffc\r\n\r\nIt should be possible to test this. I am quoting something that was written for iOS, but it should work on MacOS too https://github.com/hollance/neural-engine/blob/master/docs/is-model-using-ane.md\r\n\r\nCore ML uses three different \"engines\" that are implemented in the private Espresso framework:\r\n\r\nANE \u2014 Espresso::ANERuntimeEngine\r\nGPU \u2014 Espresso::MPSEngine and Espresso::MetalLowmemEngine\r\nCPU \u2014 Espresso::BNNSEngine\r\nIt can switch between these engines when running your model. By looking at which engine name appears in the debugger's stack trace, you can see which engine / processor is currently being used.\r\n\r\nTo find out if the model (also) runs on the GPU or CPU, you can use the following symbolic breakpoints:\r\n\r\nEspresso::MPSEngine::context::__launch_kernel\r\nEspresso::BNNSEngine::convolution_kernel::__launch\r\n\r\n", "> I am getting following error when I am importing tensor flow on MacBook Air m1\r\n> zsh: illegal hardware instruction python\r\n\r\nSame here", "While on a [spreadsheet](https://docs.google.com/spreadsheets/d/1er-NivvuIheDmIKBVRu3S_BzA_lZT5z3Z-CxQZ-uPVs/edit) that shows apps/games that have support for apple silicon (native or translated), I found this:\r\nhttps://github.com/apple/tensorflow_macos\r\nThis has been released 10 days ago, and it's by Apple, and TensorFlow would be hardware accelerated.", "Although the apple's implementation does supports arm64 hardware acceleration there is no solution for some major thirdparty packages that works along with tensorflow such as matplotlib, opencv and etc. So using x86_64 tensorflow is still a required solution for specific usecases. Is there any possible way to use x86_64 tensorflow while using x86_64 python distribution on apple silicon mac? Thanks.", "So, by now, is there any form of support for Apple Silicon?", "Is this solved yet?", "@Huibean \r\n\r\nYes. You'll need to install miniforge 3 and create a virtual env. The majority of the details are on Apple's TensorFlow fork. It's public so just type in apple TensorFlow Github.", "@TheMartian32 Thanks, just try that, but crash with another error when import TensorFlow\r\n```\r\nImportError: Traceback (most recent call last):\r\n  File \"/Users/huibean/tensorflow_macos_venv/lib/python3.8/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: dlopen(/Users/huibean/tensorflow_macos_venv/lib/python3.8/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 6): no suitable image found.  Did find:\r\n\t/Users/huibean/tensorflow_macos_venv/lib/python3.8/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so: mach-o, but wrong architecture\r\n\t/Users/huibean/tensorflow_macos_venv/lib/python3.8/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so: mach-o, but wrong architecture\r\n```\r\n", "@Huibean  Ah, sorry about that. This issue from that GitHub page seems to solve it: https://github.com/apple/tensorflow_macos/issues/3\r\n\r\nScroll down until it says Nov 18 and the comment should have ( at the time of writing this comment ) 13 likes and 5 hearts. If you encounter any other issues, feel free to tag me and I'd be happy to help.", "@TheMartian32 thx, but I am a little bit confused, this issue is created on  19 Nov 2020", "Apple's closed source fork is not a good solution. For one it's missing the libraries (libtensorflow) and only provides the frameworks (which I assume have a subset of the functionality). Essentially the apple fork is only useful for running python with tensorflow, but any attempt at using the C interface will fail", "After #45404 you should be able to compile this repository on Apple M1 chips.\r\n\r\nHowever, we still cannot provide full support as we lack devices to test on.", "@mihaimaruseac trying to build it today", "Now I can success import after build from source with master, thanks @mihaimaruseac ", "Awesome. Thank you for confirming.\r\n\r\nIf you encounter bugs, please still open them here, though we cannot provide real support as for the other platforms at the moment due to lack of hardware and head count. But we'll try to fix things as it is possible.", "@mihaimaruseac I can import the module, trying to run some basic code, but it seems like an empty module\r\n```\r\n(base) \u279c  Work ipython\r\nPython 3.8.3 (default, Jul  2 2020, 11:26:31)\r\nType 'copyright', 'credits' or 'license' for more information\r\nIPython 7.16.1 -- An enhanced Interactive Python. Type '?' for help.\r\n\r\nIn [1]: import tensorflow as tf\r\n\r\nIn [2]: tf.add(1, 2).numpy()\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-2-a78df43b9eac> in <module>\r\n----> 1 tf.add(1, 2).numpy()\r\n\r\nAttributeError: module 'tensorflow' has no attribute 'add'\r\n\r\nIn [3]: hello = tf.constant('Hello, TensorFlow!')\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-3-d3dc7fc200cc> in <module>\r\n----> 1 hello = tf.constant('Hello, TensorFlow!')\r\n\r\nAttributeError: module 'tensorflow' has no attribute 'constant'\r\n\r\nIn [4]: print(tf)\r\n<module 'tensorflow' (namespace)>\r\n\r\nIn [5]: vars(tf)\r\nOut[5]:\r\n{'__name__': 'tensorflow',\r\n '__doc__': None,\r\n '__package__': 'tensorflow',\r\n '__loader__': <_frozen_importlib_external._NamespaceLoader at 0x7fc5e000b400>,\r\n '__spec__': ModuleSpec(name='tensorflow', loader=<_frozen_importlib_external._NamespaceLoader object at 0x7fc5e000b400>, submodule_search_locations=_NamespacePath(['/Users/huibean/Work/tensorflow'])),\r\n '__file__': None,\r\n '__path__': _NamespacePath(['/Users/huibean/Work/tensorflow'])}\r\n```", "Two things:\r\n\r\n1. Make sure you do the above from a different directory than the sources of TF when compiling from source\r\n2. If the above doesn't work, can paste the output of `ls site-package/lib/tensorflow` (or where TF pip gets installed)?", "@mihaimaruseac \r\nI guess I don't have it in site-package\r\n```\r\n(base) \u279c  site-packages pwd\r\n/Users/huibean/anaconda3/lib/python3.8/site-packages\r\n(base) \u279c  site-packages ls tensor*\r\ntensorboard_plugin_wit:\r\n__init__.py          _vendor              wit_plugin_loader.py\r\n__pycache__          static\r\n_utils               wit_plugin.py\r\n\r\ntensorboard_plugin_wit-1.8.0.dist-info:\r\nINSTALLER        RECORD           entry_points.txt\r\nMETADATA         WHEEL            top_level.txt\r\n\r\ntensorflow_estimator:\r\n__init__.py __pycache__ _api        python\r\n\r\ntensorflow_estimator-2.4.0.dist-info:\r\nINSTALLER     METADATA      RECORD        WHEEL         top_level.txt\r\n(base) \u279c  site-packages\r\n```", "What is the output of `pip list`?", "@mihaimaruseac I don't have it in pip\r\n```\r\n(base) \u279c  tensorflow git:(master) pip list | grep tens\r\ntensorboard-plugin-wit             1.8.0\r\ntensorflow-estimator               2.4.0\r\ntyping-extensions                  3.7.4.2\r\nwidgetsnbextension                 3.5.1\r\n```\r\nI build the source with these steps, can't not get arm64 whl\r\n```\r\n bazel build --config=macos_arm64 tensorflow/tools/pip_package:build_pip_package\r\n./bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\r\n(base) \u279c  tensorflow git:(master) ls /tmp/tensorflow_pkg\r\ntensorflow-2.5.0-cp38-cp38-macosx_11_0_x86_64.whl\r\n(base) \u279c  tensorflow git:(master) pip install /tmp/tensorflow_pkg/tensorflow-2.5.0-cp38-cp38-macosx_11_0_x86_64.whl\r\nERROR: tensorflow-2.5.0-cp38-cp38-macosx_11_0_x86_64.whl is not a supported wheel on this platform.\r\n```", "What is the output of `pip debug verbose`?\r\n\r\n`pip list` seems to suggest the wheel was not installed, which makes sense. Now it's strange that `import tensorflow` works, but probably this is because of `tensorflow_estimator` depending on TF and faking it.", "Can that help: https://github.com/apple/tensorflow_macos ?", "any updates?\r\n", "Hi, is there any way to use the tensorflow-io in mac m1 ? Could I build the source code of tensorflow-io in the mac m1 machine ? The purpose is to use tensorflow-io with kafka in mac m1. Thanks.", "@aelmrabe , just use Apple's own distribution of TensorFlow until it's merged into the main project https://github.com/apple/tensorflow_macos"]}, {"number": 44750, "title": "Add support for CUDA 11.1 on Windows 10 for the 8.6 compute capability", "body": "**System information**\r\n- System: Windows 10\r\n- TensorFlow version (you are using): 2.5.0.dev20201108\r\n- Are you willing to contribute it (Yes/No): Yes. I can do the testing of the new build and provide any additional information.\r\n\r\n- TensorFlow version (you are using): 2.5.0.dev20201108\r\n- Python version: 3.8.6-amd64\r\n- Compiler: MSVC 2019\r\n- cuDNN: 8.0.4.30\r\n- CUDA: 11.0.3_451.82\r\n- ptxas: from CUDA 11.1\r\n- NVIDIA Drivers: 456.71\r\n\r\nHello TensorFlow team. I recently got working on my RTX 3090 on the Windows 10 machine and decided to share my investigations with you.\r\n\r\nRight now I got TensorFlow 2.5.0.dev20201108 work with CUDA 11.0 and ptxas.exe (PTX compiler) from CUDA 11.1, because ptxas from 11.1 supports 8.6 compute capability and on 11.0 - I'm getting error `ptxas fatal : Value 'sm_86' is not defined for option 'gpu-name'` - which is mean that 11.0 doesn't support 8.6 yet (at least I think so).\r\n\r\nSo, I don't know if it's planned, but would be great to add support of the CUDA 11.1 for the Win build (I don't know if people having the same issue on the Linux). Because my current solution is kind of hacky (using the compiler from a different version) and even though I don't see any errors right now, it could potentially cause some in the future.\r\n\r\nHere is also detailed info on my finding: [https://dobromyslova.medium.com/making-work-tensorflow-with-nvidia-rtx-3090-on-windows-10-7a38e8e582bf](https://dobromyslova.medium.com/making-work-tensorflow-with-nvidia-rtx-3090-on-windows-10-7a38e8e582bf)\r\n\r\nPlease feel free to contact me for any additional information.", "comments": ["@sanjoy @pkanwar23 can you take it from here?", "Been using tensorflow/tensorflow:nightly-gpu-jupyter, even the latest nightly images (2.5.0-dev20201112) have the issue still with RTX 3090. Any insights?", "> Been using tensorflow/tensorflow:nightly-gpu-jupyter, even the latest nightly images (2.5.0-dev20201112) have the issue still with RTX 3090. Any insights?\r\n\r\nI got some performance issues (too slow learning) until I applied temporary fix for the PTX compilations. You can read more in the article that I posted in the description: [https://dobromyslova.medium.com/making-work-tensorflow-with-nvidia-rtx-3090-on-windows-10-7a38e8e582bf](https://dobromyslova.medium.com/making-work-tensorflow-with-nvidia-rtx-3090-on-windows-10-7a38e8e582bf)", "@dobromyslova Thanks for the info.  Just tried with images provided by [Nvidia](https://ngc.nvidia.com/catalog/containers/nvidia:tensorflow/tags) which works with my RTX 3090, and the performance did improve.  If you used docker, definitely check it out.", "Thank you for the information, I will try this as well", "> because ptxas from 11.1 supports 8.6 compute capability and on 11.0 - I'm getting error ptxas fatal : Value 'sm_86' is not defined for option 'gpu-name' - which is mean that 11.0 doesn't support 8.6 yet (at least I think so).\r\n\r\nIs this when building TensorFlow from source?\r\n\r\nIf yes, you can try to explicitly select compute capability 8.0 (and not 8.6) when `configure` asks you about it.  TF built with CC 8.0 should work on 3090, though perhaps not with peak performance, and CUDA 11.0 supports 8.0.", ">Is this when building TensorFlow from source?\r\n\r\nNo, I used already prebuilt TensorFlow from pip, the one that currently works for me is the `2.5.0.dev20201108` one.\r\n\r\nRight now I don't have any issues with this version, but if you want I can try to build it from source with compute capability 8.0, just let me know if you want me to try.", "exactly the same issue on Linux", "the same issue", "@dobromyslova Could you please try to use TF v2.6.0 and refer to the [Build from source](https://www.tensorflow.org/install/source_windows) ? Please let us know if the issue still persists ?Thanks you!", "> @dobromyslova Could you please try to use TF v2.6.0 and refer to the [Build from source](https://www.tensorflow.org/install/source_windows) ? Please let us know if the issue still persists ?Thanks you!\r\n\r\nThank you! I will try it and let you know!", "@sushreebarsa I tried GPU build from branch v2.6.0:\r\n```\r\ngit checkout v2.6.0\r\n```\r\nAnd got the following error:\r\n```\r\nWARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/b570a1921c9e55ac53c8972bd2bfd37cd0eb510d.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nDEBUG: C:/users/workerml/_bazel_workerml/iqkt7btw/external/tf_runtime/third_party/cuda/dependencies.bzl:51:10: The following command will download NVIDIA proprietary software. By using the software you agree to comply with the terms of the license agreement that accompanies the software. If you do not agree to the terms of the license agreement, do not use the software.\r\nINFO: Repository local_config_cuda instantiated at:\r\n  C:/tf_build_test/tensorflow/WORKSPACE:15:14: in <toplevel>\r\n  C:/tf_build_test/tensorflow/tensorflow/workspace2.bzl:1088:19: in workspace\r\n  C:/tf_build_test/tensorflow/tensorflow/workspace2.bzl:90:19: in _tf_toolchains\r\nRepository rule cuda_configure defined at:\r\n  C:/tf_build_test/tensorflow/third_party/gpus/cuda_configure.bzl:1448:33: in <toplevel>\r\nERROR: An error occurred during the fetch of repository 'local_config_cuda':\r\n   Traceback (most recent call last):\r\n        File \"C:/tf_build_test/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1401, column 38, in _cuda_autoconf_impl\r\n                _create_local_cuda_repository(repository_ctx)\r\n        File \"C:/tf_build_test/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1239, column 56, in _create_local_cuda_repository\r\n                host_compiler_includes + _cuda_include_path(\r\n        File \"C:/tf_build_test/tensorflow/third_party/gpus/cuda_configure.bzl\", line 364, column 32, in _cuda_include_path\r\n                inc_entries.append(realpath(repository_ctx, cuda_config.cuda_toolkit_path + \"/include\"))\r\n        File \"C:/tf_build_test/tensorflow/third_party/remote_config/common.bzl\", line 290, column 19, in realpath\r\n                return execute(repository_ctx, [bash_bin, \"-c\", \"realpath \\\"%s\\\"\" % path]).stdout.strip()\r\n        File \"C:/tf_build_test/tensorflow/third_party/remote_config/common.bzl\", line 230, column 13, in execute\r\n                fail(\r\nError in fail: Repository command failed\r\n/usr/bin/bash: line 1: realpath: command not found\r\nINFO: Found applicable config definition build:cuda in file c:\\work\\py\\tf_build_test\\tensorflow.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda\r\nINFO: Found applicable config definition build:cuda in file c:\\work\\py\\tf_build_test\\tensorflow.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda\r\nWARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.\r\nERROR: @local_config_cuda//:enable_cuda :: Error loading option @local_config_cuda//:enable_cuda: Repository command failed\r\n/usr/bin/bash: line 1: realpath: command not found\r\n```\r\nI found that this issue may be related to this problem: https://github.com/tensorflow/tensorflow/issues/52131\r\n\r\nAlso, the CPU build works, but we want GPU anyway.\r\nPlease let me know what you think.\r\n\r\nP.S. here is my configuration:\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.6.0\r\n- Python version: 3.8.0\r\n- Installed using virtualenv? pip? conda?: pip and virtualenv\r\n- Bazel version (if compiling from source): 3.7.2\r\n- GCC/Compiler version (if compiling from source): Visual Studio 2019\r\n- CUDA/cuDNN version: 11.2 / 8.1.0\r\n- GPU model and memory: RTX3090\r\n", "@dobromyslova, This issue is fixed in latest Tensorflow version.\r\nBuild Tensorflow version with Bazel 5.0.0/4.2.1. Follow the instructions mentioned [here](https://www.tensorflow.org/install/source_windows). Thanks!", "Thank you, I will try and let you know.", "Okay, I can confirm that latest build of TensorFlow is now working without an issues on RTX 3090 (8.6 compute capability)!\r\n\r\nThank you for the hard work!\r\n\r\nHere is also some profile data from my runs:\r\n### With tf-nightly-gpu\r\nInstall TF:\r\n```commandline\r\npip install tf-nightly-gpu\r\npip install tensorflow-hub\r\npip install matplotlib\r\n```\r\n\r\nResults of run:\r\n```commandline\r\n$ python validate_build.py\r\n\r\nTensorFlow version: 2.8.0-dev20211030\r\nEager mode enabled: True\r\nGPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\r\nCUDA version: 64_112\r\ncuDNN version: 64_8\r\n\r\n2022-03-28 22:06:45.962369: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2022-03-28 22:06:46.344298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21674 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\r\n2022-03-28 22:07:00.136319: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\r\n\r\nElapsed time: 21.45432949066162 sec\r\n```\r\n\r\n### With tensorflow-gpu\r\nInstall TF:\r\n```commandline\r\npython -m pip install -U pip\r\n\r\npip install tensorflow-gpu==2.8.0\r\npip install tensorflow-hub\r\npip install matplotlib\r\n```\r\n\r\nResults of run:\r\n```commandline\r\n$ python validate_build.py\r\n\r\nTensorFlow version: 2.8.0\r\nEager mode enabled: True\r\nGPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\r\nCUDA version: 64_112\r\ncuDNN version: 64_8\r\n\r\n2022-03-28 22:17:11.289526: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2022-03-28 22:17:11.657375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21676 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\r\n2022-03-28 22:17:15.023230: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\r\n\r\nElapsed time: 6.308921813964844 sec\r\n```\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44750\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44750\">No</a>\n"]}, {"number": 44749, "title": "run out of heap space when compiling kernel bias_op.cc", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.3.1\r\n- Python version: 2.7\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source): 3.7.0\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA / 16GB\r\n\r\n**Describe the problem**\r\n### compile bias_op.cc\r\n### fatal error C1002: compiler is out of heap space in pass 2\r\n### how to adjust the compiler options?\r\n### please help!\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["sorry . the complete error message is \r\n### unsupported\\Eigen\\CXX11\\src\\Tensor\\TensorBroadcasting.h(653) : fatal error C1002: compiler is out of heap space in pass 2", "@oldoldman \r\n\r\nPlease, see tested build configuration from [here](https://www.tensorflow.org/install/source_windows#cpu). Can you try with python 3.5-3.8 and verify once. Thanks!", "> @oldoldman\r\n> \r\n> Please, see tested build configuration from [here](https://www.tensorflow.org/install/source_windows#cpu). Can you try with python 3.5-3.8 and verify once. Thanks!\r\n\r\npassed after changed compiler to clang. thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44749\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44749\">No</a>\n"]}, {"number": 44748, "title": "tf.eye is OOM when num_rows is over 10**5", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.3.0\r\n- On google colab free GPU\r\n- Are you willing to contribute it (Yes/No): I want to try.\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n```\r\nelement_count = 10**5\r\neye_tf = tf.eye(element_count, dtype=tf.float32)\r\n```\r\nThis code will be OOM. The error is here.\r\n\r\n```\r\nResourceExhaustedError: OOM when allocating tensor with shape[100000,100000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:MatrixDiagV3] name: diag\r\n```\r\n\r\n\r\n**Will this change the current api? How?**\r\nNo. \r\n\r\n**Who will benefit with this feature?**\r\nI want to calculate huge array (the num_rows is over 10**8) using tesorflow parallel processing.\r\nThis change extend the possibility of tensorflow calculation.\r\n\r\n**Any Other info.**\r\n", "comments": ["I have tried in colab with TF 2.3 , nightly version (`2.5.0-dev20201110`) and was able to reproduce the issue. Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/54e5fe7e9285bc103524e5e3958165e7/untitled512.ipynb).Thanks!", "@RyosukeMatsushima how much memory are you asking for this to Colab GPU? \r\nhttps://datascience.stackexchange.com/questions/72870/how-to-find-the-size-of-a-tensor-in-bytes", "> @RyosukeMatsushima how much memory are you asking for this to Colab GPU?\r\n> https://datascience.stackexchange.com/questions/72870/how-to-find-the-size-of-a-tensor-in-bytes\r\n\r\n@bhack sorry for the late response. Calculate according to your link, memory of eye_tf = 10^5 * 10^5 elements * 4bytes(float32) = 40GB.\r\nIs it possible for tensorflow to calculate a tensor over GPU memory size?. The size of Colab GPU memory is 12GB.\r\n```\r\n!free -h\r\n```\r\n```\r\n  total        used        free      shared  buff/cache   available\r\nMem:            12G        544M         10G        960K        1.9G         11G\r\nSwap:            0B          0B          0B\r\n```\r\nI'm so glad if tensorflow can calculate huge array over memory.", "I think you can close this and upvote/follow https://github.com/tensorflow/tensorflow/issues/29840", "Thank you!\r\nIt seems that this issue will be solved by #29840 and I close this."]}, {"number": 44747, "title": "[PluggableDevice]Add kernel and stream executor c api extension", "body": "Extend current kernel C API and refactor some stream executor C API", "comments": ["@annarev @sanjoy @penpornk This is the PR mentioned in [#43610](https://github.com/tensorflow/tensorflow/pull/43610), thanks"]}, {"number": 44746, "title": "Enable unit testing with Renode for the Bluepill target as part of CI.", "body": "With the addition of running all the unit tests on a software emulated bluepill target with Renode, we add an additional 25s (on my i7-7820HQ) to the running time for test_bluepill.sh\r\n\r\nAddresses http://b/146226672\r\n", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "@JakubJatczak and @PiotrZierhoffer: turning on Renode as part of CI for bluepill."]}, {"number": 44745, "title": "Move keras.efficientnet preprocessing layers to preprocess_input function", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.3.1\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nCurrent [preprocessing layers](https://github.com/tensorflow/tensorflow/blob/fcc4b966f1265f466e82617020af93670141b009/tensorflow/python/keras/applications/efficientnet.py#L316-L317) are a part of the main model. They are also not noted in the [TF docs](https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB0). \r\n\r\nI would propose moving these layers to the efficientnet preprocess_input function which currently does nothing. This would be consistent with the behavior of the other ready-made keras models.\r\n\r\n**Will this change the current api? How?**\r\nYes. It would move preprocessing layers into a separate function. Unfortunately this would likely lead to unexpected behavior but not errors for people currently using the built-in preprocessing layers.\r\n\r\n**Who will benefit with this feature?**\r\nNew users of the EfficientNet ready-made models. It would make the api consistent with other ready-made models. It would also separate preprocessing for edge case applications.\r\n\r\n**Any Other info.**\r\n", "comments": ["All Keras Applications going forward with do preprocessing as part of the model, so that they are able to take as input raw images (which removes the need to think about preprocessing at all). Old applications will keep using `preprocessing_input` for backwards compatibility.", "@fchollet but in the efficientnet original implementation, they use the preprocess in imagenet_utils with torch mode which have these fixed means and std for normalization\r\n` x = layers.Rescaling(1. / 255.)(x)\r\n  x = layers.Normalization(axis=bn_axis)(x)`\r\n but in the the peprocess in the efficientNet class are just:\r\n` x = layers.Rescaling(1. / 255.)(x)\r\n  x = layers.Normalization(axis=bn_axis)(x)`  \r\nThis normalization will compute mean and std depending on the input, is it possible that this may cause bad performance when the model is just used for extracting image features.", "@bayethiernodiop I was confused about the normalization layers in the loaded EfficientNet models as well. From the docs on [normalization layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Normalization#examples_2) it looks like the layer has to be called with `layer.adapt` to change the mean and std, so I think the EfficientNet's normalization layers don't change with the input data. \r\n\r\nThis seems to be case with my own experience. I was able to feed it unnormalized data with various scalings and got varying results, as you'd expect if the normalization layer was static. ", "Can't convert to tfjs model because of preprocessing layers. It's not cool", "Guys, you can use [qubvel](https://github.com/qubvel/efficientnet) implementation. The only difference is the absence of Rescale and Normalization layers exactly!", "@fchollet can you please provide more information (or a link) on what will be different for \"new\" and \"old\" applications? And from what versions of keras and TF will the change occur? (Or has it already been released?) Will all pre-trained models from that point on expect input between [0,255], as opposed to previously expecting a range of [-1,1]? Will the expected data type still be float, or will that change to uint8?\r\n\r\nI don't have a strong preference which range or datatype is chosen, the most important thing is to be consistent across all models. It was confusing for me why EfficientNet was behaving differently to other keras models. Since this is going to cause subtle breakages for many people, I hope it will be communicated clearly and well in advance.\r\n\r\nSee also issue #42506"]}, {"number": 44744, "title": "TFLu - Apollo3 - Update AmbiqSuite SDK", "body": "Addressing #44737\r\n\r\nThis PR updates the version of the AmbiqSuite SDK used in TFLu", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "closing this per discussion in #44737"]}, {"number": 44743, "title": "TensorflowLite  LSTM data input format example", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (or github SHA if from source):\r\nAndroid, Tensorflow 2.3\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n[https://github.com/grewe/UCross/blob/main/Training/LSTM_CrosswalkNavigation_Training.ipynb](https://github.com/grewe/UCross/blob/main/Training/LSTM_CrosswalkNavigation_Training.ipynb)\r\n\r\n```\r\nTraining performed using notebook at https://github.com/grewe/UCross/blob/main/Training/LSTM_CrosswalkNavigation_Training.ipynb\r\n\r\nThis has a CNN feature extractor that runs on a sequence of 40 images captured producing 40 Feature Vectors.   These are fed into an LSTM model and trained for a video activity recognition (directing users across crosswalk) application\r\n\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\nI understand will create 2 TFLite models (one for Feature Extractor CNN and the other for the LSTM model).  My question is how do I repackage the 40 Feature Vectors in my sequence as input into the TFLite model on Android.   I would like to see some examples showing this for Android (as on Android do not have access to full Tensorflow api).\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\n# Put link here or attach to the issue.\r\n```\r\n\r\n**Failure details**\r\nIf the conversion is successful, but the generated model is wrong,\r\nstate what is wrong:\r\n- Producing wrong results and/or decrease in accuracy\r\n- Producing correct results, but the model is slower than expected (model generated from old converter)\r\n\r\n\r\n**RNN conversion support**\r\nIf converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["I see you have added `TFLiteConverter` label, however I don't see TF Lite conversion code in your example. Since you are using keras to train the model you can use `tf.lite.TFLiteConverter.from_keras_model` to convert your model into TF Lite.\r\nSee https://www.tensorflow.org/lite/convert#convert_a_keras_model_", "Sorry here is the conversion code that we are using.  \r\n[https://github.com/grewe/covidID_mask/blob/master/maskDetect/MaskDetectTflite.ipynb](https://github.com/grewe/covidID_mask/blob/master/maskDetect/MaskDetectTflite.ipynb)\r\n", "As you can see it is using the TFliteConverter  (but, from a saved model)\r\n\r\n`converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir='saved_model_new', signature_keys=['serving_default'])\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\ntflite_model = converter.convert()`", "Also, what is the result of the order of the output vector indices changing in what they store is it breaks reading them in from the generated TFLite model (output of converter that is different between version prior and including  tf-nightly==2.4.0-dev20200929 require us to setup output  in via Android \r\n`        Trace.beginSection(\"feed\");\r\n        outputLocations = new float[1][NUM_DETECTIONS][4];\r\n        detectionMulticlassScores = new float[1][NUM_DETECTIONS][NUM_CLASSES];\r\n        outputScores = new float[1][NUM_DETECTIONS];\r\n        outputClasses = new float[1][NUM_DETECTIONS];\r\n        detectionAnchorIndeces = new float[1][NUM_DETECTIONS];\r\n        rawDetectionScores = new float[1][NUM_RAW_DETECTION_BOXES][NUM_CLASSES];\r\n        numDetections = new float[1];\r\n        rawDetectionBoxes = new float[1][NUM_RAW_DETECTION_BOXES][4];\r\n\r\n        Object[] inputArray = {imgData};\r\n        Map<Integer, Object> outputMap = new HashMap<>();\r\n\r\n        outputMap.put(0, outputScores);         // [1,N] - Confidence Values\r\n        outputMap.put(1, rawDetectionBoxes);    // [1,M,4] - Non-max-suppressed bounding boxes\r\n        outputMap.put(2, numDetections);        // [N] - Number of detections\r\n        outputMap.put(3, outputLocations);      // [1,N,4] - Bounding Boxes\r\n        outputMap.put(4, outputClasses);        // [1,N] - class index\r\n        outputMap.put(5, rawDetectionScores);   // [1,M,C] - raw detection scores\r\n        outputMap.put(6, detectionMulticlassScores); // [1,N,C] - detection multiclass scores\r\n        outputMap.put(7, detectionAnchorIndeces); // [1,N] detection anchor indeces\r\n\r\n        Trace.endSection();\r\n\r\n        // Run the inference call.\r\n        Trace.beginSection(\"run\");\r\n        tfLite.runForMultipleInputsOutputs(inputArray, outputMap);\r\n        Trace.endSection();`\r\n![image](https://user-images.githubusercontent.com/11790686/98877457-66b5f700-2435-11eb-91c2-269ba1337593.png)\r\n\r\n\r\n**so after this tfnighlty version (tf-nightly==2.4.0-dev20200929)  the order of the output indices and their associated meaning change  and UNFORTUNATELY there is NO documentation as to what this order is and why it changes for different tfnightly versions -- this is too fragile --instead like the python code a Dictionary type datastructure class should be used so we can index into it by names like outputLocations rather than a numeric index**\r\n", "What is the progress on this?\r\n", "@grewe We have added Signature support in TFLite interpreter, so you can use Signature input/output names instead of tensor indices.\r\nPython API support is ready and will be checked in soon.\r\nWill update the issue here when it lands.\r\n\r\nThanks", "Update:\r\nAPI for using signature names instead of tensor names are added in C++ and Python. Java API will be updated soon.\r\nYou can try the python or C++. Will update the bug once the Java ones are added too.\r\n\r\nExample,\r\nmy_signature = interpreter.get_signature_runner(\"my_method\")\r\nresults = my_signature(input_1=input_tensor_1, input_2=input_tensor_2)\r\nprint(results[\"my_output\"])\r\n\r\n\r\nThanks", "@grewe You can now use SignatureDef in TFLite in java API too. Example below\r\n\r\nFloatBuffer output = FloatBuffer.allocate(1);\r\nfloat[] inputX = {2.0f};\r\nfloat[] inputY = {4.0f};\r\nMap<String, Object> inputs = new HashMap<>();\r\ninputs.put(\"x\", inputX); // SignatureDef input is 'x'\r\ninputs.put(\"y\", inputY); // SignatureDef input is 'y'\r\nMap<String, Object> outputs = new HashMap<>();\r\noutputs.put(\"output_0\", output); // SignatureDef output is 'output_0'\r\n// runSignature takes the inputs/outputs maps \r\ninterpreter.runSignature(inputs, outputs);\r\n\r\n\r\nI am going to close the issue. Please give it a try and let us know if you have any issues by creating new issue if needed.\r\n\r\nThanks", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44743\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44743\">No</a>\n"]}, {"number": 44742, "title": "Remove link to inactive chat room on StackOverflow", "body": "This room no longer exists.\r\n\r\nFixes #44525.", "comments": ["Fixes #44525"]}, {"number": 44741, "title": "Fix wrong path separator in error message when saved model does not exist", "body": "Error message generation changed for `keras.models.load_model` (fixed bug #44739).\r\nPath separator recived from os.path.sep, and now for Windows error message looking like\r\n`OSError: SavedModel file does not exist at: C:\\IncorrectPathToSavedModel\\{saved_model.pbtxt|saved_model.pb}`\r\nfor Linux - \r\n`OSError: SavedModel file does not exist at: ~/IncorrectPathToSavedModel/{saved_model.pbtxt|saved_model.pb}`", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F44741) for more info**.\n\n<!-- need_sender_cla -->", "\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F44741) for more info**.\n\n<!-- need_sender_cla -->", "> Looks good, please add a quick unit test.\r\n\r\nYes I think that it is better to have a quick unit test if he have enough time but also it is really trivial and it will be quite hard to create a regression there after this change.", "> Looks good, please add a quick unit test.\r\n\r\nThank you!\r\nI added a test for this bug, hopefully now all right.", "/cc @rthadur Let's check if https://github.com/tensorflow/tensorflow/pull/43754#issuecomment-704407517 is still an issue if @fchollet will approve this without any extra commit request.", "@fchollet can you approve this pull request, please?\r\nI was resolve issue and add simple unit test.\r\nIt's not seriously bug, off course, but this fix make project better, imho."]}]