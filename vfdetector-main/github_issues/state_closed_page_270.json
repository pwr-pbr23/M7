[{"number": 46297, "title": "gtest headers result in conflicting clang-format requirements", "body": "@tensorflow/micro\r\n\r\nWhile porting OPs from lite to micro, one of the intermediate steps results in test code copied over from lite that has gtest headers. While this code is not (and can not) be compiled for TFLM it still trips up the formatting checks as described in https://github.com/tensorflow/tensorflow/pull/46159#discussion_r553568396.\r\n\r\nDeleting these includes (the workaround in https://github.com/tensorflow/tensorflow/pull/46159#discussion_r553568396) works just fine and it would be nice to give pull request authors this feedback directly via the TF Micro CI instead of waiting for the change to be imported internally before the error is detected.\r\n\r\nThe overarching goal is to get to a place where if a pull request passes the external CI, it also passes the internal CI (unless the code that a PR is breaking is internal-only).", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46297\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46297\">No</a>\n"]}, {"number": 46294, "title": "Linear aglebra C++ API", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): r2.1 c++ API\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nIs there any plan to extend the current c++ API to include ops such as those from tf.linalg in the python API? Atm I only see a Inv op but computes the inverse element-wise. My solution at the moment would be to write a new op that uses eigen to perform the different operations but it seems that eigen is able to run in a CUDA kernel yet. \r\n\r\n**Will this change the current api? How?**\r\n\r\nAdding a new set of OPs.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nIt would be very handy for graphs that do not only use neural networks. Use case: I'm currently implementing a sampled based controller for a robot that will run on a GPU. Hence I don't want to run the python interpreter as we will collect a lot of data from sensors and need to process everything on the fly. The controller performs a bunch of linear algebra calculation and run a NN in the middle of it, all of the operations being performed once for every sample. The high number of samples requires a GPU to be a real time controller. ", "comments": ["Never mind, found what I was looking for by looking at the ops in the include files. Maybe an update of the documentation could be useful. Closing the issue as the feature is already available. "]}, {"number": 46292, "title": "Add IRFFT operator to TF Lite", "body": "This PR adds an IRFFT operator to TF Lite. I declared it as a custom operator despite the RFFT having recently been promoted to a built-in operator as I assume that the decision whether an operator should be built-in or custom is not up to an external contributor to make. Given that the fourier transform is a very basic building block of signal processing, I'd of course welcome if this op would also become built-in :-).\r\n\r\nA few notes:\r\n- I changed the `third_party/fft2d/fft2d.h` header file as I believe the previous version was incorrect. I double-checked with the source code it is compiled against, and this should now hold the correct declarations.\r\n- The updated `third_party/fft2d/fft2d.h` header file now includes a declaration of `rdft2dsort(...)`. Using that function I simplified the implementation of `Rfft2dReorder` in `rfft2d.cc`.\r\n- The tests in `irfft2d_test.cc` were compared against the output of numpy and the regular tensorflow operators. Please see this python notebook for comparison: https://gist.github.com/tcwalther/f1f2a31a2f2fba3e8f2fa3ea99164002\r\n- I'm not sure how to update `tensorflow/compiler/mlir/lite/tests/prepare-tf.mlir`. This file seems auto-generated. The rfft op has an entry there for mapping the 1d op to the 2d op, and it seems that I need to add the irfft op there, too.", "comments": ["@tcwalther Can you please check @lu-wang-g's comments and keep us posted ? Thanks!", "@gbaned most certainly, apologies for the delay. I will address these this weekend.", "Thanks for the suggestions @thaink, I've addressed those. Could you, or one of your colleagues, reply to my question in the thread above?", "Sorry I accidentally resolved previous comments.\r\n\r\nDue to our build rule setup, I guess it's not easy to leave one op as builtin & the other as custom op in a single file.\r\n\r\nSo we either need to split the file (but to avoid code duplication, maybe have a common fft_utils library file?)\r\n\r\nOr we can add irfft to builtin op. (but I think our guideline is to have at least more than one clients using it before promoting custom op to builtin op)\r\n\r\nMaybe let's just split irfft op out of rfft2d for now?\r\n\r\nCherrs,", "@tcwalther Can you please check @renjie-liu's comments and resolve conflicts?. Thanks!", "Hi @gbaned and @renjie-liu, I replied to your comments and resolved conflicts.\r\n\r\n@renjie-liu I understand your reasoning. I personally think it would be great to have irfft be part of TF Lite, but of course I understand your policy.\r\n\r\nRealistically, right now, it is actually faster to do a DFT via matrix multiplication and use hardware acceleration on mobile than to use this FFT operator. However, I would hope that we can also write accelerated versions of these ops in the long run, in which case this would actually be faster. Of course, having CPU-based ops is a prerequisite for accelerated versions, and I thus hope that my contribution can help get us there in the long run.\r\n\r\nNote that operators such as `tf.signal.stft` use rfft/irfft, and if one replaces the FFT operator with a DFT, one also has to replace the whole stft operator in the process. Several projects have gone down that route now (most prominently, the [Google Magenta project](https://github.com/magenta/magenta/blob/41b891c137e8a51bd44322f0434ba8f3f7df0dba/magenta/models/onsets_frames_transcription/melspec_input.py)), and it would be neat if that was no longer required in the future. Of course, that is work for separate PRs, but I figured I'd mention it here for context.", "Actually, contrary to what I stated in my last comment, it seems that the rfft is actually faster than the DFT. Here are two profiles on iOS, iPhone Xs. The app runs YAMNet as well as AAC encoding on the incoming audio signal.\r\n\r\nUsing Magenta's DFT:\r\n<img width=\"674\" alt=\"Screenshot 2021-03-03 at 17 29 58\" src=\"https://user-images.githubusercontent.com/2840901/109838221-414c3380-7c46-11eb-8847-f3dd4799989e.png\">\r\n\r\nUsing RFFT (which should be 100% indicative of the IRFFT performance in this PR, too):\r\n<img width=\"673\" alt=\"Screenshot 2021-03-03 at 17 29 49\" src=\"https://user-images.githubusercontent.com/2840901/109838218-401b0680-7c46-11eb-920b-fceca758f457.png\">\r\n\r\nI don't have a DFT implementation of the IRFFT, so I can't compare it right now, but this should be very representative.\r\n\r\nNote that the DFT runs on CoreML (it's just a matrix multiplication), whereas the RFFT runs on the CPU and thus does not benefit from acceleration.\r\n\r\nTherefore, using RFFT/IRFFT is actually more convenient than the Magenta hack as one can just use Tensorflow's regular operators, and it also seems to be significantly faster in at least one case. I don't have a range of devices around for benchmarking, but given that the iPhone Xs runs the DFT on CoreML, I would only assume a bigger performance benefit for older models (and an identical one for newer models). The situation on Android is likely similar (again, cannot test, this is just a hunch).\r\n\r\n\r\n@renjie-liu what would be required in order to promote this to a built-in op? This library here would benefit from it, and it is used in various commercial projects (listed in their readme), so that may satisfy the \"more than one client\" requirement:\r\nhttps://github.com/deezer/spleeter", "Sorry for the delay, lgtm", "@tcwalther can you please check ubuntu sanity build failures ?", "Updated, should pass now.", "@renjie-liu getting back to my other question: what would it take to promote this op to a built-in op?", "One more question before merging this. In my original PR description I asked:\r\n\r\n> I'm not sure how to update tensorflow/compiler/mlir/lite/tests/prepare-tf.mlir. This file seems auto-generated. The rfft op has an entry there for mapping the 1d op to the 2d op, and it seems that I need to add the irfft op there, too.\r\n\r\nCould you please confirm that I haven't overlooked anything here? Or is there something missing?", "Hi Thomas,\r\n\r\nTo promote it to builtin ops, you can take a look at commit like this: \r\nhttps://github.com/tensorflow/tensorflow/commit/957aacafa5a17a65547d8a7a7101d88a3f47a00c\r\n\r\nAs for the `prepare-tf.mlir`, it is actually hand-crafted. For the rfft op, since we only have a `rfft2d` op there, we will transform `rfft` to `rfft2d`, so you don't need to do that in this commit. (And actually the mlir changes are only needed when you promote it to builtin op).\r\n\r\n", "Excellent, thanks. I'd still be very excited to promote it to a built-in op, but if you'd rather have this discussion separately or at a later time, then feel free to merge.", "@tcwalther Thank you for the PR! I am looking forward to having it available in nightly release. While you are discussing promotion of `IRFFT` to built-in ops,  I wanted to add that it will be helpful to think about including some of the ops that deal with complex math like\r\n```\r\ntf.Atan {device = \"\"}\r\ntf.Complex {device = \"\"}\r\ntf.Imag {device = \"\"}\r\ntf.Real {device = \"\"}\r\n``` \r\nIt will allow us to modify complex inputs to IRFFT in tensorflow and enable us to do some end-to-end audio processing using tflite models. Of course, this doesn't need to be a part of this PR. It is something I hope is considered for next batch of ops awaiting promotion to built-ins.", "Imag, Real and ComplexAbs has been added as builtin ops. You can check it as the master branch.\r\nFor Atan, it is currently being working on.", "Thanks for the update.", "@lu-wang-g @thaink looks like this is still missing your reviews before we can merge this. If you have change requests, please don't hesitate to let me know!\r\n\r\nAlso, as @avroshk also wrote, I still believe this would deserve being a built-in op. I'm happy to make the changes if I get a green light for you on that one.", "@tcwalther rdft2dsort is not defined in third_party/fft2d/fft2d.h\r\nIt is throwing an error in our internal tests now. How about just defining it in old way that rfft.cc did? ", "> @tcwalther rdft2dsort is not defined in third_party/fft2d/fft2d.h\r\n> It is throwing an error in our internal tests now.\r\n\r\nHmm, that is weird. As you can see in the PR, I explicitly added this function definition to `third_party/fft2d/fft2d.h`. Do you have a dedicated internal copy in your internal tests that doesn't use the header file in this repo?\r\n\r\n> How about just defining it in old way that rfft.cc did?\r\n\r\nIt would require me to implement this for IRFFT, which is not 100% trivial. The way you sort it has to be different for the inverse than the forward case. I also don't really see the point of writing it manually - it is part of the FFT library after all, and rewriting it seems only like an opportunity to introduce a bug. I also found it much easier to understand the code when this function is used, as the FFT library refers to it in its documentation a lot. Took me a while to figure out that the old rfft2d.cc file contained a reimplementation of it.\r\n\r\nCan you check why this fails in your internal tests? Again, this PR does add the method definition, so it should work just fine.", "Our third_party/fft2d/fft2d.h is different than that under tensorflow directory.\r\nAnyway, I'll fix that in my side and land your PR.", "@tcwalther I fixed all errors to merge this PR but found that there are cases where the results between TF and TFLite does not match.\r\nCould you check the following case:\r\n````\r\nreal = tf.range(64, delta=1, dtype=tf.float32)\r\nimag = tf.range(64, 128, delta=1, dtype=tf.float32)\r\nt = tf.reshape(tf.complex(real, imag), [8, 8])\r\nfft_length=tf.constant([4, 4], dtype=tf.int32)\r\ntf.signal.irfft2d(t, fft_length)\r\n````\r\nTF has output:\r\n```\r\n13. -39.   0.  38.   0.   4.   0.  -4.  -4.   2.   0.  -2.  -8.   0. 0.   0.\r\n```\r\nWhile TFLite output is:\r\n````\r\n13, -41, 0, 36, 0.25, -16.25, 0.25, -24.25, -4, 4, 0, 0, -8.25, 20.25, -0.25, 20.25\r\n````", "@tcwalther Any update on this PR? Please. Thanks!", "@thaink thanks so much for finding this error. I have written a test that can reproduce this, and will look into solving this bug over the weekend!", "@thaink I found the mistake.\r\n\r\nThe input source you tested with cannot be converted back to a real sequence:\r\n\r\n```\r\nIn [55]: fft.ifft2(x, fft_length)\r\nOut[55]:\r\narray([[13.5+77.5j,  0.  -1.j , -0.5 -0.5j, -1.  +0.j ],\r\n       [ 0.  -8.j ,  0.  +0.j ,  0.  +0.j ,  0.  +0.j ],\r\n       [-4.  -4.j ,  0.  +0.j ,  0.  +0.j ,  0.  +0.j ],\r\n       [-8.  +0.j ,  0.  +0.j ,  0.  +0.j ,  0.  +0.j ]], dtype=complex64)\r\n```\r\n\r\nThe RFFT/IRFFT is an optimisation technique over regular complex FFTs that exploits symmetry in the Fourier domain. However, different implementations can do so differently, and the FFT library that ships with Tensorflow Lite simply has a different behaviour than Numpy's library.\r\n\r\nWhile the behaviour is inconsistent, I'm not sure it's fair to call it a bug - after all, the behaviour of an IRFFT on broken input data is, as far as I know, mathematically undefined.\r\n\r\nI believe this PR is ready to be merged as-is.", "Sorry, I was not so familiar with IRFFT.\r\n\r\nOne small question, how do you generate the expected_result in irfft2d_test.cc? are the input datas there broken as well? As I tested those cases, the results between TF and TFLite also does not match. I don't expect it to match Numpy's behaviour but would be good to match TF.\r\n\r\n@renjie-liu @lu-wang-g WDYT? Can we submit is PR as it-is? In such case, I would need to remove the zip_test since it will not pass.", "@lu-wang-g probably can help on that?", "@thaink the numbers from the test are from the notebook I link to in the PR description: https://gist.github.com/tcwalther/f1f2a31a2f2fba3e8f2fa3ea99164002\r\n\r\nYou can see that there I also check for equivalence between Numpy and Tensorflow.", "@tcwalther Sorry. The error I got is actually related to Pad op. Just found that after doing some more investigation today.", "Thanks for merging, this is quite exciting. I believe this didn't make it into the 2.5.0 release anymore though, did it? If not, in which release do you intend to include this change?"]}, {"number": 46291, "title": "Input y of 'Greater' op has type float32 that does not match type int64 of x", "body": "I have this code below:\r\n```\r\ntf.contrib.metrics.precision_at_recall(tf.cast(tf.argmax(tf.nn.softmax(query_preds[i], dim=1), axis=1), tf.float32), tf.argmax(query_y, axis=1), target_recall=0.3)\r\n```\r\n\r\nIt keeps giving me this error. I tried casting as you can see but still not working.", "comments": ["Important to note I tried the same function with ```tf.contrib.metrics.accuracy``` but it is working fine, so something has to do with ```precision_at_recall```, as well as ```recall_at_precision```:\r\n\r\n```\r\ntf.contrib.metrics.accuracy(tf.argmax(tf.nn.softmax(query_preds[i], dim=1), axis=1), tf.argmax(query_y, axis=1))\r\n```", "@hiyamgh \r\nPlease, fill [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\nFrom the information you provided it looks like you are using TF 1.x.\r\nTensorFlow 1.x is not actively supported. Could you please update TensorFlow to the latest stable version v2.4 and check if you are facing the same issue.\r\nIn TF 2.4 you can use `tf.keras.metrics.Accuracy` instead of `tf.contrib.metrics.accuracy` as contrib functionality removed in TF 2.x\r\nIf you are still facing issue please share colab link or simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster. Thanks!\r\n`\r\n\r\n`", "Hello @ravikyram \r\n\r\nThank you for your fast response. I have upgraded to ``tf 2.4`` but now I am using this now:\r\n```\r\ntf.keras.metrics.Accuracy(tf.argmax(tf.nn.softmax(support_pred), axis=1), tf.argmax(support_y, axis=1))\r\n```\r\n\r\nand getting now another error:\r\n```\r\n    ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\r\n```", "I have dumped my sample code here on this colab notebook: [https://colab.research.google.com/drive/1brMeujSY4aSJT_CG5THEL0rfsNeXspi2?usp=sharing](https://colab.research.google.com/drive/1brMeujSY4aSJT_CG5THEL0rfsNeXspi2?usp=sharing)\r\n\r\nThank you in advance.", "@hiyamgh \r\n\r\nCan you please refer similar SO issues [link1](https://stackoverflow.com/questions/22175489/numpy-valueerror-the-truth-value-of-an-array-with-more-than-one-element-is-ambi/22175725) , [link2](https://stackoverflow.com/questions/10062954/valueerror-the-truth-value-of-an-array-with-more-than-one-element-is-ambiguous) and see if it helps you. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46291\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46291\">No</a>\n"]}, {"number": 46290, "title": "Add int8 and int16x8 support for GATHER_ND operator", "body": "", "comments": ["Merge conflict resolved!"]}, {"number": 46289, "title": "How to convert TF1.12 checkpoints to saved/keras model format.", "body": "I have a TTS model checkpoints trained on TFv1.12. For inferencing, I have used \r\n`self.session = tf.Session(config=config)\r\nself.session.run(tf.global_variables_initializer())\r\nsaver = tf.train.Saver()\r\nsaver.restore(self.session, checkpoint_path)\r\n`\r\nFor its TFlite conversion, saved/keras model is required. How do I convert this model into TFLite.", "comments": ["@nehasoni3,\r\nFor converting to `.tflite` format, please go through [this](https://www.tensorflow.org/lite/convert) official guide.\r\n\r\nAlso TensorFlow 1.x is not actively supported, hence I'd recommend updating TensorFlow to the latest stable version v2.4. Thanks!", "> @nehasoni3,\r\n> For converting to `.tflite` format, please go through [this](https://www.tensorflow.org/lite/convert) official guide.\r\n> \r\n> Also TensorFlow 1.x is not actively supported, hence I'd recommend updating TensorFlow to the latest stable version v2.4. Thanks!\r\n\r\nThanks for reply.\r\nI have model in TFv1.12. I have tried [this.](https://gist.github.com/zhanwenchen/d628ef70e9f76525fd47d6213c30730d).\r\ncheckpoints are converted into saved model but can not converted into TFlite, its do not have signature_def", "> Also TensorFlow 1.x is not actively supported, hence I'd recommend updating TensorFlow to the latest stable version v2.4. Thanks!\r\n\r\n@nehasoni3,\r\nCould you please check if you are facing the same issue with TF v2.4 as well? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46289\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46289\">No</a>\n"]}, {"number": 46288, "title": "TF2.1 .h5 file to .pb", "body": "```\r\nfrom tensorflow.python.keras.models import load_model\r\nimport tensorflow as tf\r\n\r\n\r\nH5Path = \"xxx.h5\"\r\nYoloV5s_model = load_model(H5Path, compile=False)\r\nYoloV5s_model.summary()\r\nYoloV5s_model.save(\"a.pb\")\r\n```\r\n\r\n\r\n\r\n2021-01-08 20:36:37.248006: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\r\nTraceback (most recent call last):\r\n  File \"TFLoadH5AndInfer.py\", line 18, in <module>\r\n    YoloV5s_model.save(\"Yolov5s_1.pb\")\r\n  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\", line 1008, in save\r\n    signatures, options)\r\n  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\save.py\", line 115, in save_model\r\n    signatures, options)\r\n  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\saved_model\\save.py\", line 78, in save\r\n    save_lib.save(model, filepath, signatures, options)\r\n  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\save.py\", line 899, in save\r\n    _ = _SaveableView(checkpoint_graph_view)\r\n  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\save.py\", line 165, in __init__\r\n    self.checkpoint_view.objects_ids_and_slot_variables())\r\n  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\graph_view.py\", line 415, in objects_ids_and_slot_variables\r\n    trackable_objects, path_to_root = self._breadth_first_traversal()\r\n  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\graph_view.py\", line 199, in _breadth_first_traversal\r\n    for name, dependency in self.list_dependencies(current_trackable):\r\n  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\save.py\", line 113, in list_dependencies\r\n    for name, dep in super(_AugmentedGraphView, self).list_dependencies(obj):\r\n  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\graph_view.py\", line 159, in list_dependencies\r\n    return obj._checkpoint_dependencies\r\n  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\data_structures.py\", line 744, in __getattribute__\r\n    return object.__getattribute__(self, name)\r\n  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\data_structures.py\", line 786, in _checkpoint_dependencies\r\n    \"ignored.\" % (self,))\r\nValueError: Unable to save the object {1: ListWrapper([0, 0, 0, 0]), 2: ListWrapper([0, 0, 0, 0]), 3: ListWrapper([1, 2, 2, 1])} (a dictionary wrapper constructed automatically on attribute assignment). The wrapped dictionary contains a non-string key which maps to a trackable object or mutable data structure.\r\n\r\nIf you don't need this dictionary checkpointed, wrap it in a tf.contrib.checkpoint.NoDependency object; it will be automatically un-wrapped and subsequently ignored.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["@EdwardVincentMa \r\nI ran the code shared and face different error due to dependencies not shared, please find [gist here](https://colab.research.google.com/gist/Saduf2019/88a0600859c52a5195d7b90155850013/untitled492.ipynb).", "@Saduf2019 I think @EdwardVincentMa with `xxx.h5` means its own model.\r\n\r\n@EdwardVincentMa can you share your model definition, a code snippet that we can just copy, past and run or a colab to reproduce your error?", "@bhack \r\nOur standard replies have \"request for dependencies\" which is the request for model used by user [so we could replicate the issue faced].", "> @bhack\r\n> Our standard replies have \"request for dependencies\" which is the request for model used by user [so we could replicate the issue faced].\r\n\r\nYes I understand but if the user can share a small model definition and saving code to reproduce this instead of only the saved model Is better for debugging the issue directly than make another round to request model definition.\r\n\r\nGenerally I think that if the user could minimize the code surface to reproduce the bug and not exactly share Its working example directly It Is faster to triage ISSUES.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 46287, "title": "TFLu: Update downloaded GCC version to 10", "body": "* Add new GCC download script.\r\n* Enable GCC 10 for all targets.\r\n* Update GCC flags for cortex_m_generic target.\r\n\r\nThis intends to fix: https://github.com/tensorflow/tensorflow/issues/43725 so that M55 can also be compiled with GCC.\r\nOnly targets, cortex_m_generic and stm32f4 has been tested.\r\nIt has only been tested on Linux.\r\n", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "Copybara has been unable to migrate this change 3 times now. I'm going to let it sit and try again in a bit.", "Note that the MacOS checksum may be incorrect: https://github.com/tensorflow/tensorflow/issues/46393"]}, {"number": 46286, "title": "Cannot create tf.constant inside tf.function with integer tensor.", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **yes**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Ubuntu 18.04**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **N/A**\r\n- TensorFlow installed from (source or binary): **binary (Google Colab)**\r\n- TensorFlow version (use command below): **v2.4.0-0-g582c8d236cb 2.4.0**\r\n- Python version: **Python 3.6.9**\r\n- Bazel version (if compiling from source): **N/A**\r\n- GCC/Compiler version (if compiling from source): **N/A**\r\n- CUDA/cuDNN version: **N/A**\r\n- GPU model and memory: **N/A**\r\n\r\n\r\n**Describe the current behavior**\r\nIt is impossible to create a `tf.constant` inside a function wrapped by `tf.function` if the argument to `tf.constant` is an integer Tensor.\r\n\r\n**Describe the expected behavior**\r\nIt is expected that such operations do not raise an error. For example in case of slightly more advanced postprocessing.\r\nUnless this behaviour is desired, this issue can be closed. I would however, greatly appreciate an explanation.\r\n\r\n**Standalone code to reproduce the issue**\r\nThe following snippet will work with eager execution:\r\n```python\r\ndef function():\r\n    a = int(tf.random.normal(shape=()))\r\n    tf.print(a)\r\n\r\n    constant = tf.constant([a])\r\n    tf.print(constant)\r\n```\r\nWill output:\r\n```\r\n-1\r\n[-1]\r\n```\r\n\r\nHowever, after wrapping in `tf.function` an error is raised:\r\n```python\r\nwrapped = tf.function(function)\r\nwrapped()\r\n```\r\n\r\nRaises:\r\n```\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    975           except Exception as e:  # pylint:disable=broad-except\r\n    976             if hasattr(e, \"ag_error_metadata\"):\r\n--> 977               raise e.ag_error_metadata.to_exception(e)\r\n    978             else:\r\n    979               raise\r\n\r\nTypeError: in user code:\r\n\r\n    <ipython-input-97-0acfdad4a1be>:5 function  *\r\n        constant = tf.constant([a])\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:265 constant  **\r\n        allow_broadcast=True)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:283 _constant_impl\r\n        allow_broadcast=allow_broadcast))\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py:457 make_tensor_proto\r\n        _AssertCompatible(values, dtype)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py:334 _AssertCompatible\r\n        raise TypeError(\"Expected any non-tensor type, got a tensor instead.\")\r\n\r\n    TypeError: Expected any non-tensor type, got a tensor instead.\r\n```\r\n\r\n**Other info / logs**: **N/A**\r\n", "comments": ["I have tried in colab with TF version 2.3, 2.4, nightly version(`2.5.0-dev20210108`) and was able to reproduce the issue . Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/f78f0f1fbb431efeaac88336119788d0/untitled603.ipynb). Thanks!", "It seems that in the wrapped version. The `a = int(tf.random.normal(shape=()))` is interpreted as `a = tf.cast(tf.random.normal(shape=()), tf.int32)` and a list of tensor is not good argument for `tf.constant`.\r\n\r\nI've commented the last two line of the function and changed `tf.print(a)` to `tf.print(a, type(a))` to see the above difference.", "Also, I wonder if you could use `tf.convert_to_tensor` to replace the second `tf.constant` in your more advanced case, as `tf.convert_to_tensor` can accept both Tensor type and python native types.", "> Also, I wonder if you could use `tf.convert_to_tensor` to replace the second `tf.constant` in your more advanced case, as `tf.convert_to_tensor` can accept both Tensor type and python native types.\r\n\r\nYes! It works! Thank you. My issue is resolved and if you are comfortable with it, it can be closed.", "@sebastian-sz I'm not a maintainer, so it's up to you whether to close it :stuck_out_tongue_closed_eyes:", "Understood. Thanks again for help! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46286\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46286\">No</a>\n"]}, {"number": 46285, "title": "'tf.Size' op is neither a custom op nor a flex op", "body": "### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**: No\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10.0.18363\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**: n/a\r\n-   **TensorFlow installed from (source or binary)**: binary\r\n-   **TensorFlow version (use command below)**: tensorflow-2.4.0\r\n-   **Python version**: 3.8.5\r\n-   **Bazel version (if compiling from source)**: n/a\r\n-   **GCC/Compiler version (if compiling from source)**: n/a\r\n-   **CUDA/cuDNN version**: CUDA 11.0 / CuDNN 8.0.5\r\n-   **GPU model and memory**: Quadro P2000 4GB\r\n-   **Exact command to reproduce**: Run \"Convert a SavedModel\" from https://www.tensorflow.org/lite/convert\r\n\r\n### Describe the problem\r\nFor some unknown reason (to me) I am no longer able to convert a model to TFLite for usage on a Raspberry Pi. When I run the script mentioned in the link above, the following error appears:\r\n\r\n```\r\nloc(callsite(callsite(\"Postprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/SortByField_1/Size@__inference___call___23519\" at \"StatefulPartitionedCall@__inference_signature_wrapper_25508\") at \"StatefulPartitionedCall\")): error: 'tf.Size' op is neither a custom op nor a flex op\r\nerror: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):\r\n        tf.Size {device = \"\"}\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Reno\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\", line 210, in toco_convert_protos\r\n    model_str = wrap_toco.wrapped_toco_convert(model_flags_str,\r\n  File \"C:\\Users\\Reno\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\wrap_toco.py\", line 32, in wrapped_toco_convert\r\n    return _pywrap_toco_api.TocoConvert(\r\nException: <unknown>:0: error: loc(callsite(callsite(\"Postprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/SortByField_1/Size@__inference___call___23519\" at \"StatefulPartitionedCall@__inference_signature_wrapper_25508\") at \"StatefulPartitionedCall\")): 'tf.Size' op is neither a custom op nor a flex op\r\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\r\n<unknown>:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):\r\n        tf.Size {device = \"\"}\r\n \r\n \r\nDuring handling of the above exception, another exception occurred:\r\n \r\nTraceback (most recent call last):\r\n  File \"convert_to_tflite_v2.py\", line 7, in <module>\r\n    tflite_model = converter.convert()\r\n  File \"C:\\Users\\Reno\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\", line 739, in convert\r\n    result = _convert_saved_model(**converter_kwargs)\r\n  File \"C:\\Users\\Reno\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\", line 632, in convert_saved_model\r\n    data = toco_convert_protos(\r\n  File \"C:\\Users\\Reno\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\", line 216, in toco_convert_protos\r\n    raise ConverterError(str(e))\r\ntensorflow.lite.python.convert.ConverterError: <unknown>:0: error: loc(callsite(callsite(\"Postprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/SortByField_1/Size@__inference___call___23519\" at \"StatefulPartitionedCall@__inference_signature_wrapper_25508\") at \"StatefulPartitionedCall\")): 'tf.Size' op is neither a custom op nor a flex op\r\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\r\n<unknown>:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):\r\n        tf.Size {device = \"\"}\r\n```\r\n\r\nI have read more issues regarding Flex Ops, unfortunately I haven't found a suitable solution as of now. I tried adding the following line:\r\n\r\n```\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\n```\r\n\r\nWhen this line is present, the model converts very smoothly to a TFlite model, but then the TFLite model doesn't work anymore on a Raspberry Pi, with the following error: \r\n\r\n```\r\nUnexpected failure when preparing tensor allocations: Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.\r\n```\r\n\r\nI never had this before for any other model. The model works perfectly fine with regular TensorFlow. It's just the TFlite part which causes issues for me.\r\n\r\nI am using a pre-trained model (SSD MobileNet V2 FPNLite 320x320) from the Detection Model Zoo at https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\r\n\r\n### Source code / logs\r\nI started off by installing a fresh install of Tensorflow. See:\r\n\r\n```\r\n(base) C:\\Users\\Reno>conda activate tensorflow\r\n \r\n(tensorflow) C:\\Users\\Reno>pip cache purge\r\nERROR: No matching packages\r\n \r\n(tensorflow) C:\\Users\\Reno>pip list\r\nPackage      Version\r\n------------ -------------------\r\ncertifi      2020.12.5\r\npip          20.3.3\r\nsetuptools   51.0.0.post20201207\r\nwheel        0.36.2\r\nwincertstore 0.2\r\n \r\n(tensorflow) C:\\Users\\Reno>pip install --upgrade tensorflow\r\nCollecting tensorflow\r\n  Downloading tensorflow-2.4.0-cp38-cp38-win_amd64.whl (370.7 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 370.7 MB 21 kB/s\r\nRequirement already satisfied: wheel~=0.35 in c:\\users\\reno\\.conda\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (0.36.2)\r\nCollecting gast==0.3.3\r\n  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\r\nCollecting absl-py~=0.10\r\n  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 127 kB 2.2 MB/s\r\nCollecting astunparse~=1.6.3\r\n  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\r\nCollecting flatbuffers~=1.12.0\r\n  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\r\nCollecting google-pasta~=0.2\r\n  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 57 kB 1.5 MB/s\r\nCollecting grpcio~=1.32.0\r\n  Downloading grpcio-1.32.0-cp38-cp38-win_amd64.whl (2.6 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2.6 MB 2.2 MB/s\r\nCollecting h5py~=2.10.0\r\n  Downloading h5py-2.10.0-cp38-cp38-win_amd64.whl (2.5 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2.5 MB 803 kB/s\r\nCollecting keras-preprocessing~=1.1.2\r\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 42 kB 3.2 MB/s\r\nCollecting numpy~=1.19.2\r\n  Downloading numpy-1.19.5-cp38-cp38-win_amd64.whl (13.3 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 13.3 MB 3.3 MB/s\r\nCollecting opt-einsum~=3.3.0\r\n  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 65 kB 2.2 MB/s\r\nCollecting protobuf>=3.9.2\r\n  Downloading protobuf-3.14.0-py2.py3-none-any.whl (173 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 173 kB 2.2 MB/s\r\nCollecting six~=1.15.0\r\n  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\r\nCollecting tensorboard~=2.4\r\n  Downloading tensorboard-2.4.0-py3-none-any.whl (10.6 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10.6 MB 2.2 MB/s\r\nRequirement already satisfied: setuptools>=41.0.0 in c:\\users\\reno\\.conda\\envs\\tensorflow\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (51.0.0.post20201207)\r\nCollecting google-auth<2,>=1.6.3\r\n  Downloading google_auth-1.24.0-py2.py3-none-any.whl (114 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 114 kB 2.2 MB/s\r\nCollecting cachetools<5.0,>=2.0.0\r\n  Downloading cachetools-4.2.0-py3-none-any.whl (12 kB)\r\nCollecting google-auth-oauthlib<0.5,>=0.4.1\r\n  Downloading google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\r\nCollecting markdown>=2.6.8\r\n  Downloading Markdown-3.3.3-py3-none-any.whl (96 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 96 kB 3.2 MB/s\r\nCollecting pyasn1-modules>=0.2.1\r\n  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 155 kB 2.2 MB/s\r\nCollecting pyasn1<0.5.0,>=0.4.6\r\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 77 kB 2.6 MB/s\r\nCollecting requests<3,>=2.21.0\r\n  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 61 kB 2.0 MB/s\r\nRequirement already satisfied: certifi>=2017.4.17 in c:\\users\\reno\\.conda\\envs\\tensorflow\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\r\nCollecting chardet<5,>=3.0.2\r\n  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 178 kB 2.2 MB/s\r\nCollecting idna<3,>=2.5\r\n  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 58 kB 2.0 MB/s\r\nCollecting requests-oauthlib>=0.7.0\r\n  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\r\nCollecting oauthlib>=3.0.0\r\n  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 147 kB 2.2 MB/s\r\nCollecting rsa<5,>=3.1.4\r\n  Downloading rsa-4.6-py3-none-any.whl (47 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 47 kB 3.2 MB/s\r\nCollecting tensorboard-plugin-wit>=1.6.0\r\n  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 779 kB 2.2 MB/s\r\nCollecting tensorflow-estimator<2.5.0,>=2.4.0rc0\r\n  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 462 kB 2.2 MB/s\r\nCollecting termcolor~=1.1.0\r\n  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\r\nCollecting typing-extensions~=3.7.4\r\n  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\r\nCollecting urllib3<1.27,>=1.21.1\r\n  Downloading urllib3-1.26.2-py2.py3-none-any.whl (136 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 136 kB 2.2 MB/s\r\nCollecting werkzeug>=0.11.15\r\n  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 298 kB 2.2 MB/s\r\nCollecting wrapt~=1.12.1\r\n  Downloading wrapt-1.12.1.tar.gz (27 kB)\r\nBuilding wheels for collected packages: termcolor, wrapt\r\n  Building wheel for termcolor (setup.py) ... done\r\n  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=841391132c29825394e6b0ab2a1e79ffb1f6a1867cd2a214dc65cc3c4aa5b688\r\n  Stored in directory: c:\\users\\reno\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\r\n  Building wheel for wrapt (setup.py) ... done\r\n  Created wheel for wrapt: filename=wrapt-1.12.1-cp38-cp38-win_amd64.whl size=33672 sha256=7efbaa96078fc7ecd811c170d66cc642ab8fd8f88a41af40ba118c5b7c16765f\r\n  Stored in directory: c:\\users\\reno\\appdata\\local\\pip\\cache\\wheels\\5f\\fd\\9e\\b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\r\nSuccessfully built termcolor wrapt\r\nInstalling collected packages: urllib3, pyasn1, idna, chardet, six, rsa, requests, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, protobuf, numpy, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, typing-extensions, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow\r\nSuccessfully installed absl-py-0.11.0 astunparse-1.6.3 cachetools-4.2.0 chardet-4.0.0 flatbuffers-1.12 gast-0.3.3 google-auth-1.24.0 google-auth-oauthlib-0.4.2 google-pasta-0.2.0 grpcio-1.32.0 h5py-2.10.0 idna-2.10 keras-preprocessing-1.1.2 markdown-3.3.3 numpy-1.19.5 oauthlib-3.1.0 opt-einsum-3.3.0 protobuf-3.14.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.25.1 requests-oauthlib-1.3.0 rsa-4.6 six-1.15.0 tensorboard-2.4.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.4.0 tensorflow-estimator-2.4.0 termcolor-1.1.0 typing-extensions-3.7.4.3 urllib3-1.26.2 werkzeug-1.0.1 wrapt-1.12.1\r\n\r\n(tensorflow) C:\\Users\\Reno>cd C:\\Users\\Reno\\Documents\\TensorFlow\\workspace\\training\r\n\r\n(tensorflow) C:\\Users\\Reno\\Documents\\TensorFlow\\workspace\\training>python convert_to_tflite_v2.py\r\n\r\n2021-01-08 11:30:11.595435: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2021-01-08 11:30:19.711062: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-01-08 11:30:19.715933: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll\r\n2021-01-08 11:30:20.065510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: Quadro P2000 computeCapability: 6.1\r\ncoreClock: 1.607GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 89.53GiB/s\r\n2021-01-08 11:30:20.072148: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2021-01-08 11:30:20.083133: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2021-01-08 11:30:20.088475: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2021-01-08 11:30:20.099554: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n2021-01-08 11:30:20.105734: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n2021-01-08 11:30:20.118062: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\r\n2021-01-08 11:30:20.124535: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n2021-01-08 11:30:20.130482: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2021-01-08 11:30:20.133532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2021-01-08 11:30:20.136101: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-01-08 11:30:20.144289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: Quadro P2000 computeCapability: 6.1\r\ncoreClock: 1.607GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 89.53GiB/s\r\n2021-01-08 11:30:20.152136: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2021-01-08 11:30:20.155789: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2021-01-08 11:30:20.159025: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2021-01-08 11:30:20.162087: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n2021-01-08 11:30:20.165806: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n2021-01-08 11:30:20.171067: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\r\n2021-01-08 11:30:20.174766: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n2021-01-08 11:30:20.180898: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2021-01-08 11:30:20.185452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2021-01-08 11:30:20.767230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-01-08 11:30:20.771172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0\r\n2021-01-08 11:30:20.773087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N\r\n2021-01-08 11:30:20.775197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2982 MB memory) -> physical GPU (device: 0, name: Quadro P2000, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2021-01-08 11:30:20.783136: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-01-08 11:31:15.040028: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored output_format.\r\n2021-01-08 11:31:15.046343: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:319] Ignored drop_control_dependency.\r\n2021-01-08 11:31:15.052724: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:325] Ignored change_concat_input_ranges.\r\n2021-01-08 11:31:15.059159: I tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: C:/Users/Reno/Documents/TensorFlow/workspace/training_walnoot/exported-models/walnoot_model_lite/saved_model/\r\n2021-01-08 11:31:15.152959: I tensorflow/cc/saved_model/reader.cc:55] Reading meta graph with tags { serve }\r\n2021-01-08 11:31:15.155845: I tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: C:/Users/Reno/Documents/TensorFlow/workspace/training_walnoot/exported-models/walnoot_model_lite/saved_model/\r\n2021-01-08 11:31:15.163162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-01-08 11:31:15.167694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]\r\n2021-01-08 11:31:15.170225: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-01-08 11:31:15.517776: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\r\n2021-01-08 11:31:15.565923: I tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.\r\n2021-01-08 11:31:16.326616: I tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: C:/Users/Reno/Documents/TensorFlow/workspace/training_walnoot/exported-models/walnoot_model_lite/saved_model/\r\n2021-01-08 11:31:16.703255: I tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 1644097 microseconds.\r\n2021-01-08 11:31:20.471768: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:194] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\r\n2021-01-08 11:31:21.438534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: Quadro P2000 computeCapability: 6.1\r\ncoreClock: 1.607GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 89.53GiB/s\r\n2021-01-08 11:31:21.445277: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2021-01-08 11:31:21.452203: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2021-01-08 11:31:21.456431: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2021-01-08 11:31:21.461100: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n2021-01-08 11:31:21.467734: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n2021-01-08 11:31:21.473807: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\r\n2021-01-08 11:31:21.479188: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n2021-01-08 11:31:21.485787: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2021-01-08 11:31:21.491625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2021-01-08 11:31:21.495347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-01-08 11:31:21.499727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0\r\n2021-01-08 11:31:21.502749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N\r\n2021-01-08 11:31:21.505539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2982 MB memory) -> physical GPU (device: 0, name: Quadro P2000, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2021-01-08 11:31:21.513866: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\nloc(callsite(callsite(\"Postprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/SortByField_1/Size@__inference___call___23519\" at \"StatefulPartitionedCall@__inference_signature_wrapper_25508\") at \"StatefulPartitionedCall\")): error: 'tf.Size' op is neither a custom op nor a flex op\r\nerror: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):\r\n        tf.Size {device = \"\"}\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Reno\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\", line 210, in toco_convert_protos\r\n    model_str = wrap_toco.wrapped_toco_convert(model_flags_str,\r\n  File \"C:\\Users\\Reno\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\wrap_toco.py\", line 32, in wrapped_toco_convert\r\n    return _pywrap_toco_api.TocoConvert(\r\nException: <unknown>:0: error: loc(callsite(callsite(\"Postprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/SortByField_1/Size@__inference___call___23519\" at \"StatefulPartitionedCall@__inference_signature_wrapper_25508\") at \"StatefulPartitionedCall\")): 'tf.Size' op is neither a custom op nor a flex op\r\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\r\n<unknown>:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):\r\n        tf.Size {device = \"\"}\r\n \r\n \r\nDuring handling of the above exception, another exception occurred:\r\n \r\nTraceback (most recent call last):\r\n  File \"convert_to_tflite_v2.py\", line 7, in <module>\r\n    tflite_model = converter.convert()\r\n  File \"C:\\Users\\Reno\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\", line 739, in convert\r\n    result = _convert_saved_model(**converter_kwargs)\r\n  File \"C:\\Users\\Reno\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\", line 632, in convert_saved_model\r\n    data = toco_convert_protos(\r\n  File \"C:\\Users\\Reno\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\", line 216, in toco_convert_protos\r\n    raise ConverterError(str(e))\r\ntensorflow.lite.python.convert.ConverterError: <unknown>:0: error: loc(callsite(callsite(\"Postprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/SortByField_1/Size@__inference___call___23519\" at \"StatefulPartitionedCall@__inference_signature_wrapper_25508\") at \"StatefulPartitionedCall\")): 'tf.Size' op is neither a custom op nor a flex op\r\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\r\n<unknown>:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):\r\n        tf.Size {device = \"\"}\r\n \r\n \r\n(tensorflow) C:\\Users\\Reno\\Documents\\TensorFlow\\workspace\\training>\r\n```\r\n\r\nWhy is this error appearing just now, what does it mean, and how can I convert a model to TFlite without any of these nasty errors and subsequently run it on a Raspberry Pi without any hassle.\r\n\r\nThanks in advance.", "comments": ["@RenoLooijmans,\r\n> When this line is present, the model converts very smoothly to a TFlite model\r\n\r\nAs mentioned, I was able to convert the model enabling `SELECT_TF_OPS`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/6042511a73aa403109ff22452502ffc5/46285.ipynb).\r\n\r\n> but then the TFLite model doesn't work anymore on a Raspberry Pi, with the following error:\r\n\r\nCould you please provide the exact sequence of commands/steps that you executed before running into the issue and also the complete error log, so that we can look into this. Thanks!", "Thanks for your answer. In the meanwhile I have completely reinstalled once again and tested things on a TF-nightly build. For whatever reason this seems to have worked properly! A TFLite file has been succesfully generated. During the conversion I received some informational messages but nothing out of the ordinary.\r\n\r\nNow I'm having the issue the following script does not work anymore - I am unable to get the boxes, classes, scores and count.\r\n\r\nShould I make a new ticket or can we continue in this thread?\r\n\r\nThe script I am using is the following.\r\n\r\n```\r\nimport tensorflow as tf \r\nimport matplotlib\r\nimport matplotlib.pyplot as plt\r\n\r\nimport cv2\r\nimport time\r\nimport numpy as np\r\n\r\nfrom PIL import Image\r\n\r\nIMAGE_PATH = \"C:/Users/Reno/Documents/TensorFlow/workspace/training_walnoot/evaluate/27.jpg\"\r\nMODEL_PATH = \"C:/Users/Reno/Documents/TensorFlow/workspace/training_walnoot/exported-models/walnoot_model/saved_model/saved_model.tflite\"\r\n\r\ndef set_input_tensor(interpreter, image):\r\n  \"\"\"Sets the input tensor.\"\"\"\r\n  tensor_index = interpreter.get_input_details()[0]['index']\r\n  input_tensor = interpreter.tensor(tensor_index)()[0]\r\n  input_tensor[:, :] = image\r\n\r\n\r\ndef get_output_tensor(interpreter, index):\r\n  \"\"\"Returns the output tensor at the given index.\"\"\"\r\n  output_details = interpreter.get_output_details()[index]\r\n  tensor = np.squeeze(interpreter.get_tensor(output_details['index']))\r\n  return tensor\r\n\r\n\r\ndef detect_objects(interpreter, image, threshold):\r\n  \"\"\"Returns a list of detection results, each a dictionary of object info.\"\"\"\r\n  set_input_tensor(interpreter, image)\r\n  interpreter.invoke()\r\n  \r\n  print(interpreter.get_tensor(interpreter.get_output_details()[0]['index']))\r\n\r\n  # Get all output details\r\n  boxes = get_output_tensor(interpreter, 0)\r\n  classes = get_output_tensor(interpreter, 1)\r\n  scores = get_output_tensor(interpreter, 2)\r\n  count = int(get_output_tensor(interpreter, 3))\r\n\r\n  results = []\r\n  for i in range(count):\r\n    if scores[i] >= threshold:\r\n      result = {\r\n          'bounding_box': boxes[i],\r\n          'class_id': classes[i],\r\n          'score': scores[i]\r\n      }\r\n      results.append(result)\r\n  return results\r\n  \r\ninterpreter = tf.lite.Interpreter(model_path=MODEL_PATH)\r\ninterpreter.allocate_tensors()\r\n_, IMG_HEIGHT, IMG_WIDTH, _ = interpreter.get_input_details()[0]['shape']\r\n\r\ndef preprocess_image(image_path):\r\n    img = tf.io.read_file(image_path)\r\n    img = tf.io.decode_image(img, channels=3)\r\n    img = tf.image.convert_image_dtype(img, tf.float32)\r\n    original_image = img\r\n    resized_img = tf.image.resize(img, (IMG_HEIGHT, IMG_WIDTH))\r\n    resized_img = resized_img[tf.newaxis, :]\r\n    return resized_img, original_image\r\n    \r\nLABEL_DICT = {0: 'Walnoot'\r\n}\r\n\r\nCOLORS = np.random.randint(0, 255, size=(len(LABEL_DICT), 3), dtype=\"uint8\")\r\n\r\ndef display_results(image_path, threshold=0.3):\r\n    # Load the input image and preprocess it\r\n    preprocessed_image, original_image = preprocess_image(image_path)\r\n    # print(preprocessed_image.shape, original_image.shape)\r\n\r\n    # =============Perform inference=====================\r\n    start_time = time.monotonic()\r\n    results = detect_objects(interpreter, preprocessed_image, threshold=threshold)\r\n    print(f\"Elapsed time: {(time.monotonic() - start_time)*1000} miliseconds\")\r\n\r\n    # =============Display the results====================\r\n    original_numpy = original_image.numpy()\r\n    for obj in results:\r\n        # Convert the bounding box figures from relative coordinates\r\n        # to absolute coordinates based on the original resolution\r\n        ymin, xmin, ymax, xmax = obj['bounding_box']\r\n        xmin = int(xmin * original_numpy.shape[1])\r\n        xmax = int(xmax * original_numpy.shape[1])\r\n        ymin = int(ymin * original_numpy.shape[0])\r\n        ymax = int(ymax * original_numpy.shape[0])\r\n\r\n        # Grab the class index for the current iteration\r\n        idx = int(obj['class_id'])\r\n        # Skip the background\r\n        if idx >= len(LABEL_DICT):\r\n            continue\r\n        \r\n        # draw the bounding box and label on the image\r\n        color = [int(c) for c in COLORS[idx]]\r\n        cv2.rectangle(original_numpy, (xmin, ymin), (xmax, ymax), \r\n                    color, 2)\r\n        y = ymin - 15 if ymin - 15 > 15 else ymin + 15\r\n        label = \"{}: {:.2f}%\".format(LABEL_DICT[obj['class_id']],\r\n            obj['score'] * 100)\r\n        cv2.putText(original_numpy, label, (xmin, y),\r\n            cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\r\n\r\n    # return the final ima\r\n    original_int = (original_numpy * 255).astype(np.uint8)\r\n    return original_int\r\n    \r\nresultant_image = display_results(IMAGE_PATH)\r\nimg = Image.fromarray(resultant_image)\r\n\r\nplt.figure()\r\nplt.imshow(img)\r\n\r\nmng = plt.get_current_fig_manager()\r\nmng.window.state('zoomed')\r\n\r\nplt.show()\r\n```\r\n\r\nI expected the line:\r\n\r\n```\r\nprint(interpreter.get_tensor(interpreter.get_output_details()[0]['index']))\r\n```\r\n\r\nTo output something like (the x-y coordinates of the detected objects).\r\n\r\n```\r\n[[[ 1.3571475e-01  3.7934765e-01  2.8558272e-01  4.7231331e-01]\r\n  [ 5.7490164e-01  5.1752263e-01  7.5879282e-01  5.7256919e-01]\r\n  [ 6.5346777e-01  6.6449586e-04  8.0882227e-01  2.5530253e-02]\r\n  [ 8.5825253e-01 -6.4711552e-04  9.7376263e-01  2.1930968e-03]\r\n  [ 9.4300693e-01  1.5642031e-03  9.8640281e-01  5.2240370e-03]\r\n  [ 8.3009332e-01  5.0730270e-04  9.5639700e-01  3.3790930e-03]\r\n  [ 8.0205852e-01  1.2441243e-03  9.3465418e-01  3.4776509e-03]\r\n  [ 8.4763682e-01  9.7268170e-01  1.0028182e+00  9.9840266e-01]\r\n  [ 7.7918953e-01 -3.1198433e-04  9.0533978e-01  1.6820970e-03]\r\n  [-8.9339709e-01 -2.3550144e-01  1.4566548e+00  1.0536630e+00]]]\r\n```\r\n\r\nInstead, the following is returned:\r\n\r\n```\r\n[100.]\r\n```\r\n\r\nBecause of this unexpected result the rest of the code doesn't work anymore either. What could be the reason I'm only returned a single value on the position where the XY-coordinates of the boxes should be displayed?\r\n\r\nAs mentioned, the original TF 'saved_model.pb' works very good!!", "I tracked my issue down to the shape of the input tensor not being sized correctly.\r\n\r\ninterpreter.get_input_details()[0]['shape'] gives for the WORKING model [1 320 320 3], whilst giving [1 1 1 3] for the model returning the error. I have no idea what caused the input tensor to be sized differently.\r\n\r\nEDIT: Seems to be ending up at https://github.com/tensorflow/tensorflow/issues/42153 and https://github.com/tensorflow/tensorflow/issues/42157\r\n\r\n2 Questions:\r\n- How can I set the input shape correctly during conversion?\r\n- Why happens this now, and worked it fine on my previous models? Has something changed to the way TF deals with this?", "Could you try using the new signature API? If there are multiple outputs in the model, the order of the output tensors can be changed.\r\n\r\nThe generated tflite file will have the SignatureDef details. Using Python API (as an example) you can do something like\r\n\r\nmy_signature = interpreter.get_signature_runner(\"my_method\")\r\nresults = my_signature(input_1=input_tensor_1, input_2=input_tensor_2)\r\nprint(results[\"my_output\"])\r\n\r\nSignatureDef provides meaningful/generic names for inputs/outputs which doesn't rely on specific model details. More on SignatureDefs here.\r\nIf your saved model has a defined signatureDef then it will be exported during conversion to TFLite and then you can use the Signature inputs/outputs for inference and not relying on inputs/outputs order or tensor names.", "@RenoLooijmans this is bit off topic but could you share how to install or use TFLite runtime on Raspberry Pi? You need a TFLite runtime with Flex enabled when you have the following error.\r\n\r\n```\r\nUnexpected failure when preparing tensor allocations: Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46285\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46285\">No</a>\n", "In my case, the command\r\n\r\n`toco --saved_model_dir ./exported-models/tflite/saved_model --allow_custom_ops --graph_def_file ./exported-models/tflite/saved_model/saved_model.pb --output_file ./exported-models/tflite/tflite/detect.tflite  --input_shapes 1,300,300,3 --input_arrays normalized_input_image_tensor \u2013output_arrays 'TFLite_Detection_PostProcess\u2019,\u2019TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'`\r\n\r\ngenerated the same error, which is\r\n\r\n`tensorflow.lite.python.convert.ConverterError: <unknown>:0: error: loc(callsite(callsite(\"Postprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/SortByField_1/Size@__inference___call___23519\" at \"StatefulPartitionedCall@__inference_signature_wrapper_25508\") at \"StatefulPartitionedCall\")): 'tf.Size' op is neither a custom op nor a flex op\r\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\r\n<unknown>:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):\r\n        tf.Size {device = \"\"}`\r\n\r\nEventually, I modified the command by adding \r\n`--emit-select-tf-ops true`,\r\n which is actually suggested in the error message.\r\n\r\nThe new command is:\r\n`toco --saved_model_dir ./exported-models/tflite/saved_model --emit-select-tf-ops true --allow_custom_ops --graph_def_file ./exported-models/tflite/saved_model/saved_model.pb --output_file ./exported-models/tflite/tflite/detect.tflite  --input_shapes 1,300,300,3 --input_arrays normalized_input_image_tensor \u2013output_arrays 'TFLite_Detection_PostProcess\u2019,\u2019TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'`\r\n\r\nThe detect.tflite is then successfully converted from savd_mode.pb.", "@RenoLooijmans May I ask you which TF version you are using? I am currently on TF 2.4.1 and I still have the `error: 'tf.Size' op is neither a custom op nor a flex op` when trying to convert to TFLlite the `tf.meshgrid` function", "@yann-pourcenoux I am using TF-nightly builds now as they appear to work better for me. After I trained a model I use both export_tflite_graph_tf2.py (models/research/object) and convert_to_tflite_v2.py which contains the following code below:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nsaved_model_dir = \"C:/Users/xxxxx/Documents/TensorFlow/workspace/training/exported-models/model_lite/saved_model/\"\r\n\r\n# Convert the model to TF lite\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n#converter.experimental_new_converter=True\r\ntflite_model = converter.convert()\r\n\r\n# Serialize the model\r\nopen(saved_model_dir + 'saved_model.tflite', 'wb').write(tflite_model)\r\n```\r\nGoodluck!", "@yann-pourcenoux you can enable tf.Size op through the select TF option. https://www.tensorflow.org/lite/guide/ops_select\r\n\r\nOr if you can use tf-nightly, there is possibility that the size op can be supported via builtin op."]}, {"number": 46284, "title": "TFLite: GPU delegate (OpenGL) outputs errors when different context is active.", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Samsung Galaxy\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.3\r\n- Python version: -\r\n- Bazel version (if compiling from source): 2.0.0\r\n- GCC/Compiler version (if compiling from source): \r\n- CUDA/cuDNN version: -\r\n- GPU model and memory: -\r\n\r\n**Describe the current behavior**\r\nI have a problem running TFLite's GPU delegate on a mobile device without OpenCL support (which means the delegate falls back to the OpenGL implementation obviously).\r\n```\r\nI/tflite: Initialized TensorFlow Lite runtime.\r\nI/tflite: Created TensorFlow Lite delegate for GPU.\r\nE/tflite: OpenCL library not loaded - dlopen failed: library \"libOpenCL-pixel.so\" not found\r\nE/tflite: Falling back to OpenGL\r\nE/libEGL: call to OpenGL ES API with no current context (logged once per thread)\r\n```\r\nGot error:\r\n```\r\nE/tflite: TfLiteGpuDelegate Invoke: ToTensorConverter: input data size does not match expected size.\r\nE/tflite: Node number 130 (TfLiteGpuDelegateV2) failed to invoke.\r\nE/tflite: TfLiteGpuDelegate Invoke: Write to buffer failed. Source data is larger than buffer.\r\nE/tflite: Node number 87 (TfLiteGpuDelegateV2) failed to invoke.\r\n```\r\nProblem is that my app (which is using Unity3D engine) is creating its own OpenGL context (I don't have access to rendering context, so I can not change it back to TFLite one after rendering) which is active and TFLite can not copy data to GPU.\r\nI think TFLite should activate its own context before making any operations on GPU when running OpenGL. \r\n**Describe the expected behavior**\r\nTFLite works when app changes current OpenGL context to different than the one used by TFLite.", "comments": ["@Gohan1989 \r\nplease share a simple stand alone code to replicate the issue faced.", "@Gohan1989 Instead of using TF 2.3, can you use master branch's latest snapshot and tell me how it goes?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@impjdi \r\nOn master branch I have the same behavior.", "@Gohan1989 can you attach your tflite model?  doesn't have to contain trained weights; i only need the architecture.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46284\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46284\">No</a>\n"]}, {"number": 46283, "title": "Implement support for ragged tensors in mean_squared_error loss function.", "body": "First cut at addressing Issue #45403.\r\n\r\nThis PR adds support for RaggedTensors to \"mse\" loss. Tensors with shapes of (batch, ragged_dimension) or (batch, ragged_dimension, feature dims) are handled on a per batch basis.\r\n\r\n\r\n", "comments": ["@tomerk \r\n> I think these semantics should be in model.compile\r\n\r\nCan you please clarify ?\r\nCurrently model.compile only creates the LossesContainer; from my reading of the code at this time the code doesn't know what time of tensors will be used as y_true, y_pred. The LossesContainer is only built when called with target tensors as model.fit is being used.\r\n\r\nOne potential option would be to move the RaggedTensor support from the LossFunctionWrapper class and instead into the LossesContainer; the drawback I see is that this would then no longer work for custom training loops.\r\n\r\nThe documentation of keras loss functions typically suggests creating an instance of a loss class and testing it on a tensor; for instance https://keras.io/api/losses/probabilistic_losses/#binarycrossentropy-class. From that standpoint, it seems to me that it would be preferable if the loss class itself (e.g. keras.losses.BinaryCrossentropy in our example) did support RaggedTensors when invoked.\r\n\r\nOr did you mean that the behaviour of the loss functions needs to be documented both in the description of model.compile (which is where the user specifies the loss function that ends up getting wrapped) and in the Loss base class ? I would fully agree that it would be desirable to improve the documentation; that may alleviate slightly the concern with additional complexity / magic behaviour for RaggedTensors that we are introducing; which I do agree is a valid concern.\r\n\r\nApologies in advance if I'm misinterpreting your comment.", "I just meant that it should be documented in both places, since that\u2019s where the logic for working with ragged tensors with these different shapes would be enabled. (E.g. when you make one of the built in loss classes, or when you pass in a custom loss fn. but *not* with a custom loss object you right yourself or with one of the non-object oriented loss functions directly when used outside of compile)", "@tomerk Added RaggedTensor specific info to both model.compile and losses.Loss.", "@tomerk Previous CI failed against Google internal CI. Rebased the PR.", "@tomerk previous CI run failed due to indentation issue caught by pylint. Please re-trigger CI.", "@omalleyt12 @tomerk CI instance for TF-Lite failed with error unrelated to the PR (VM install error). Please re-trigger the CI. Is there any way for me to re-trigger the CI for a PR that has been approved ? CI errors seem to be very frequent."]}, {"number": 46282, "title": "tf.io.gfile.GFile does not raise an error when given a directory", "body": "Python's `open` does not accept directories. The following results in an `IsADirectoryError`:\r\n\r\n```\r\n    with open('.', 'r') as f:\r\n        print(f.readlines())\r\n```\r\n\r\nHowever, if you use `tf.io.gfile.GFile` instead, you will get an empty list and no error:\r\n\r\n```\r\n    with tf.io.gfile.GFile('.', 'r') as f:\r\n        print(f.readlines())\r\n\r\n```\r\n\r\nNot sure if this is a feature or a bug, but it is not the behavior I would expect, given that the [documentation](https://www.tensorflow.org/api_docs/python/tf/io/gfile/GFile) says that `tf.io.gfile` is meant to provide an API close to Python's file IO objects.", "comments": ["@MiladShahidi \r\n\r\nThanks for filing the issue.\r\nPlease, fill [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\nPlease, share colab link or simple stndalone code with supporting files to reproduce the issue in our environment. It helps us in localizing the issue faster.\r\n\r\nAre you interested in submitting PR for this?\r\n\r\nThanks!\r\n", "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Mojave 10.14.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.4.0\r\n- Python version:  3.7.5\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nThe `tf.io.gfile.GFile` function does not raise an error when given a directory, whereas Python's `open` does. Given that the documentation says the role of the `gfile` module is to provide an API that's close to Python's file IO API, it would be reasonable to expect it to raise an error when the provided address points to a directory.\r\n\r\n**Describe the expected behavior**\r\nthe `GFile` method should raise an error when given a directory.\r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://colab.research.google.com/drive/1qR5b7M5SbpepOX9b9Jlru3fPOfCWqVxa?usp=sharing", "Thank you for your response @ravikyram. I'd be more than happy to submit a PR for this.", "@MiladShahidi \r\n\r\nThanks for your interest in submitting PR.\r\nI have tried in colab with TF version 2.3, 2.4 and nightly version(`2.5.0-dev20210110`) and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/70c1e8a714c17d4b288b246e04324bf0/untitled606.ipynb).\r\n\r\n Please, submit a PR .Thanks!", "Known issue, should be fixed in 2.5 with the switch to modular filesystems.", "Thanks @mihaimaruseac. So, should I still submit a PR? Or is it already taken care of?", "I think this is handled already, thank you for offering to send a PR.\r\n\r\nhttps://cs.opensource.google/tensorflow/tensorflow/+/master:tensorflow/c/experimental/filesystem/plugins/posix/posix_filesystem.cc;l=208-212;drc=f64e839687b6129dfe2a9e21ef965593c7f3a3c2", "I executed the code in Nightly 2.6 and  not getting any error message when passing directory. Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/df2a49e181a65c54af2033db56bf5084/nighly.ipynb).Thanks!", "In this case, closing as resolved. Thank you", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46282\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46282\">No</a>\n"]}, {"number": 46280, "title": "tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found", "body": "System information\uff1a\r\n\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):no\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):ubuntu 18.04\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\nTensorFlow installed from (source or binary): source\r\nTensorFlow version (use command below):1.15.0\r\nPython version:3.6\r\nCUDA/cuDNN version: 10.0\r\nGPU model and memory:7.4\r\n\r\nDescribe the current behavior\uff1a\r\nI used tensorflow1.15 to train my code\uff0cafter training 33 epochs raise \"tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found\"\r\n\r\nepoch  32 end time is : 2021-01-08 14:21:29.075227\r\ntrain files shuffled!\r\nis training ep :  33\r\ntotal train batch num: 100\r\nep 33 i 0 psemce 0.0 bbvert -0.23279694 l2 0.060497742 ce 0.26028115 siou -0.5535758 bbscore 0.0038582273 pmask 0.6467816\r\nep 33 i 0 test psem 0.0 bbvert 1.9851223 l2 0.059121773 ce 2.2534707 siou -0.3274702 bbscore 0.0048341155 pmask 3.4519947\r\ntest pred bborder [[2 1 0]]\r\nep 33 i 20 psemce 0.0 bbvert -0.44303733 l2 0.030050844 ce 0.16678412 siou -0.6398723 bbscore 0.0026201883 pmask 0.63400114\r\nep 33 i 20 test psem 0.0 bbvert -0.4450612 l2 0.04898257 ce 0.23810822 siou -0.732152 bbscore 0.0016184862 pmask 0.47476012\r\ntest pred bborder [[2 0 1]]\r\nep 33 i 40 psemce 0.0 bbvert 0.43996847 l2 0.08725857 ce 0.8109299 siou -0.45822 bbscore 0.0034747643 pmask 0.9270937\r\nep 33 i 40 test psem 0.0 bbvert -0.07955924 l2 0.040802542 ce 0.4581066 siou -0.5784684 bbscore 0.0087565 pmask 1.0110209\r\ntest pred bborder [[2 0 1]]\r\nep 33 i 60 psemce 0.0 bbvert 0.057684183 l2 0.071036406 ce 0.5709717 siou -0.58432394 bbscore 0.00046247765 pmask 0.48829234\r\nep 33 i 60 test psem 0.0 bbvert -0.3817188 l2 0.03684793 ce 0.2770622 siou -0.69562894 bbscore 0.0019779946 pmask 0.54431504\r\ntest pred bborder [[2 0 1]]\r\nep 33 i 80 psemce 0.0 bbvert 0.038050413 l2 0.034902867 ce 0.6071266 siou -0.60397905 bbscore 0.015431552 pmask 0.8978894\r\nep 33 i 80 test psem 0.0 bbvert 1.1076844 l2 0.07785928 ce 1.3761435 siou -0.34631833 bbscore 0.033992507 pmask 1.7343999\r\ntest pred bborder [[2 0 1]]\r\nmodel saved in :  ./log/train_mod/model033.cptk\r\nepoch  33 end time is : 2021-01-08 14:21:44.245053\r\ntrain files shuffled!\r\nis training ep :  34\r\ntotal train batch num: 100\r\nep 34 i 0 psemce 0.0 bbvert -0.41581324 l2 0.057975773 ce 0.28829214 siou -0.76208115 bbscore 0.0003172583 pmask 0.34254307\r\nep 34 i 0 test psem 0.0 bbvert 1.7912706 l2 0.08668331 ce 2.017744 siou -0.31315675 bbscore 0.00576146 pmask 2.1253805\r\ntest pred bborder [[0 2 1]]\r\nep 34 i 20 psemce 0.0 bbvert -0.14073128 l2 0.034625944 ce 0.4937689 siou -0.6691261 bbscore 0.0047056335 pmask 0.7088615\r\nep 34 i 20 test psem 0.0 bbvert 1.9534252 l2 0.0907397 ce 2.1705353 siou -0.3078499 bbscore 0.0019757028 pmask 2.682012\r\ntest pred bborder [[0 2 1]]\r\nep 34 i 40 psemce 0.0 bbvert 0.27091432 l2 0.053299602 ce 0.7194822 siou -0.5018675 bbscore 0.001409175 pmask 0.60204554\r\nep 34 i 40 test psem 0.0 bbvert -0.28416353 l2 0.09286666 ce 0.19349718 siou -0.5705274 bbscore 0.003192804 pmask 0.21589296\r\ntest pred bborder [[1 0 2]]\r\n2021-01-08 14:21:52.432564: W tensorflow/core/framework/op_kernel.cc:1639] Invalid argument: ValueError: matrix contains invalid numeric entries\r\nTraceback (most recent call last):\r\n\r\n  File \"/home/liu/anaconda3/envs/tf1.15/lib/python3.6/site-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\r\n    ret = func(*args)\r\n\r\n  File \"/home/liu/disk1/Life/3DBoNetPoint818a(linux)/helper_net.py\", line 115, in assign_mappings_valid_only\r\n    row_ind, col_ind = linear_sum_assignment(valid_cost)\r\n\r\n  File \"/home/liu/anaconda3/envs/tf1.15/lib/python3.6/site-packages/scipy/optimize/_hungarian.py\", line 93, in linear_sum_assignment\r\n    raise ValueError(\"matrix contains invalid numeric entries\")\r\n\r\nValueError: matrix contains invalid numeric entries\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/liu/anaconda3/envs/tf1.15/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\r\n    return fn(*args)\r\n  File \"/home/liu/anaconda3/envs/tf1.15/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\r\n    target_list, run_metadata)\r\n  File \"/home/liu/anaconda3/envs/tf1.15/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\r\n  (0) Invalid argument: ValueError: matrix contains invalid numeric entries\r\nTraceback (most recent call last):\r\n\r\n  File \"/home/liu/anaconda3/envs/tf1.15/lib/python3.6/site-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\r\n    ret = func(*args)\r\n\r\n  File \"/home/liu/disk1/Life/3DBoNetPoint818a(linux)/helper_net.py\", line 115, in assign_mappings_valid_only\r\n    row_ind, col_ind = linear_sum_assignment(valid_cost)\r\n\r\n  File \"/home/liu/anaconda3/envs/tf1.15/lib/python3.6/site-packages/scipy/optimize/_hungarian.py\", line 93, in linear_sum_assignment\r\n    raise ValueError(\"matrix contains invalid numeric entries\")\r\n\r\nValueError: matrix contains invalid numeric entries\r\n\r\n\r\n     [[{{node bbox/PyFunc}}]]\r\n     [[gradients/backbone/fa_layer1/ThreeInterpolate_grad/ThreeInterpolateGrad/_425]]\r\n  (1) Invalid argument: ValueError: matrix contains invalid numeric entries\r\nTraceback (most recent call last):\r\n\r\n  File \"/home/liu/anaconda3/envs/tf1.15/lib/python3.6/site-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\r\n    ret = func(*args)\r\n\r\n  File \"/home/liu/disk1/Life/3DBoNetPoint818a(linux)/helper_net.py\", line 115, in assign_mappings_valid_only\r\n    row_ind, col_ind = linear_sum_assignment(valid_cost)\r\n\r\n  File \"/home/liu/anaconda3/envs/tf1.15/lib/python3.6/site-packages/scipy/optimize/_hungarian.py\", line 93, in linear_sum_assignment\r\n    raise ValueError(\"matrix contains invalid numeric entries\")\r\n\r\nValueError: matrix contains invalid numeric entries", "comments": ["@lifeiwen \r\nWe see that you are using an old version of tf which is not supported now, can you please upgrade to 2.x version and let us know if there is any issue faced.\r\n\r\nAlso please share a  stand alone code or a colab gist with error reported.", "@Saduf2019 Thanks for your advice\uff0cI installed tensorflow2.5 on Nvidia 3090 and trained my code\uff0cBut I got some similar errors", "@Saduf2019 Below is my running log\uff0cI have verified that there is no problem with the data, and I really can\u2019t understand why such a problem occurs during the training process. Looking forward to your reply.\uff1a\r\nep 35 i 40 psemce 0.0 bbvert -0.26186523 l2 0.050587684 ce 0.34921426 siou -0.66166717 bbscore 0.00023075327 pmask 0.40985933\r\nep 35 i 40 test psem 0.0 bbvert -0.29428068 l2 0.10698747 ce 0.16675441 siou -0.56802255 bbscore 0.0030464008 pmask 0.43296114\r\ntest pred bborder [[0 1 2]]\r\nep 35 i 60 psemce 0.0 bbvert 1.3711776 l2 0.066582106 ce 1.7335279 siou -0.42893246 bbscore 0.0043712487 pmask 1.8511868\r\nep 35 i 60 test psem 0.0 bbvert 0.23468393 l2 0.06658577 ce 0.6473511 siou -0.47925293 bbscore 0.0020650337 pmask 0.5931383\r\ntest pred bborder [[1 0 2]]\r\nep 35 i 80 psemce 0.0 bbvert -0.18187413 l2 0.08177448 ce 0.32304624 siou -0.58669484 bbscore 0.0040581333 pmask 0.3738186\r\nep 35 i 80 test psem 0.0 bbvert 0.0770213 l2 0.0655105 ce 0.5536749 siou -0.5421641 bbscore 0.002022297 pmask 1.5775248\r\ntest pred bborder [[2 1 0]]\r\nmodel saved in :  ./log/train_mod/model035.cptk\r\nepoch  35 end time is : 2021-01-11 10:38:50.641399\r\ntrain files shuffled!\r\nis training ep :  36\r\ntotal train batch num: 100\r\nep 36 i 0 psemce 0.0 bbvert 1.249488 l2 0.091530986 ce 1.5373621 siou -0.3794051 bbscore 0.0018183877 pmask 2.2903516\r\nep 36 i 0 test psem 0.0 bbvert -0.21928397 l2 0.051158678 ce 0.38333455 siou -0.6537772 bbscore 0.0016100239 pmask 1.375641\r\ntest pred bborder [[1 2 0]]\r\n2021-01-11 10:38:53.433607: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: matrix contains invalid numeric entries\r\nTraceback (most recent call last):\r\n\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\r\n    ret = func(*args)\r\n\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 624, in wrapper\r\n    return func(*args, **kwargs)\r\n\r\n  File \"/home/liu/disk1/3DBoNetPoint818a/helper_net.py\", line 122, in assign_mappings_valid_only\r\n    row_ind, col_ind = linear_sum_assignment(valid_cost)\r\n\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/scipy/optimize/_lsap.py\", line 93, in linear_sum_assignment\r\n    raise ValueError(\"matrix contains invalid numeric entries\")\r\n\r\nValueError: matrix contains invalid numeric entries\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1375, in _do_call\r\n    return fn(*args)\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1360, in _run_fn\r\n    target_list, run_metadata)\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1453, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\r\n  (0) Invalid argument: ValueError: matrix contains invalid numeric entries\r\nTraceback (most recent call last):\r\n\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\r\n    ret = func(*args)\r\n\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 624, in wrapper\r\n    return func(*args, **kwargs)\r\n\r\n  File \"/home/liu/disk1/3DBoNetPoint818a/helper_net.py\", line 122, in assign_mappings_valid_only\r\n    row_ind, col_ind = linear_sum_assignment(valid_cost)\r\n\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/scipy/optimize/_lsap.py\", line 93, in linear_sum_assignment\r\n    raise ValueError(\"matrix contains invalid numeric entries\")\r\n\r\nValueError: matrix contains invalid numeric entries\r\n\r\n\r\n\t [[{{node bbox/PyFunc}}]]\r\n  (1) Invalid argument: ValueError: matrix contains invalid numeric entries\r\nTraceback (most recent call last):\r\n\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\r\n    ret = func(*args)\r\n\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 624, in wrapper\r\n    return func(*args, **kwargs)\r\n\r\n  File \"/home/liu/disk1/3DBoNetPoint818a/helper_net.py\", line 122, in assign_mappings_valid_only\r\n    row_ind, col_ind = linear_sum_assignment(valid_cost)\r\n\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/scipy/optimize/_lsap.py\", line 93, in linear_sum_assignment\r\n    raise ValueError(\"matrix contains invalid numeric entries\")\r\n\r\nValueError: matrix contains invalid numeric entries\r\n\r\n\r\n\t [[{{node bbox/PyFunc}}]]\r\n\t [[gradients/backbone/fa_layer1/ThreeInterpolate_grad/ThreeInterpolateGrad/_407]]\r\n0 successful operations.\r\n0 derived errors ignored.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"main_train.py\", line 78, in <module>\r\n    train(net, data,configs=configs)\r\n  File \"main_train.py\", line 33, in train\r\n    feed_dict={net.X_pc:bat_pc[:, :, 0:6], net.Y_bbvert:bat_bbvert, net.Y_pmask:bat_pmask[:,:,:], net.Y_psem:bat_psem_onehot[:,:,:], net.lr:l_rate, net.is_train:True})\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 968, in run\r\n    run_metadata_ptr)\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1191, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1369, in _do_run\r\n    run_metadata)\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1394, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\r\n  (0) Invalid argument: ValueError: matrix contains invalid numeric entries\r\nTraceback (most recent call last):\r\n\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\r\n    ret = func(*args)\r\n\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 624, in wrapper\r\n    return func(*args, **kwargs)\r\n\r\n  File \"/home/liu/disk1/3DBoNetPoint818a/helper_net.py\", line 122, in assign_mappings_valid_only\r\n    row_ind, col_ind = linear_sum_assignment(valid_cost)\r\n\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/scipy/optimize/_lsap.py\", line 93, in linear_sum_assignment\r\n    raise ValueError(\"matrix contains invalid numeric entries\")\r\n\r\nValueError: matrix contains invalid numeric entries\r\n\r\n\r\n\t [[node bbox/PyFunc (defined at /home/liu/disk1/3DBoNetPoint818a/helper_net.py:134) ]]\r\n  (1) Invalid argument: ValueError: matrix contains invalid numeric entries\r\nTraceback (most recent call last):\r\n\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\r\n    ret = func(*args)\r\n\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\", line 624, in wrapper\r\n    return func(*args, **kwargs)\r\n\r\n  File \"/home/liu/disk1/3DBoNetPoint818a/helper_net.py\", line 122, in assign_mappings_valid_only\r\n    row_ind, col_ind = linear_sum_assignment(valid_cost)\r\n\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/scipy/optimize/_lsap.py\", line 93, in linear_sum_assignment\r\n    raise ValueError(\"matrix contains invalid numeric entries\")\r\n\r\nValueError: matrix contains invalid numeric entries\r\n\r\n\r\n\t [[node bbox/PyFunc (defined at /home/liu/disk1/3DBoNetPoint818a/helper_net.py:134) ]]\r\n\t [[gradients/backbone/fa_layer1/ThreeInterpolate_grad/ThreeInterpolateGrad/_407]]\r\n0 successful operations.\r\n0 derived errors ignored.\r\n\r\nErrors may have originated from an input operation.\r\nInput Source operations connected to node bbox/PyFunc:\r\n Y_bbvert (defined at /home/liu/disk1/3DBoNetPoint818a/main_3D_BoNet.py:226)\t\r\n bbox/add_11 (defined at /home/liu/disk1/3DBoNetPoint818a/helper_net.py:190)\r\n\r\nInput Source operations connected to node bbox/PyFunc:\r\n Y_bbvert (defined at /home/liu/disk1/3DBoNetPoint818a/main_3D_BoNet.py:226)\t\r\n bbox/add_11 (defined at /home/liu/disk1/3DBoNetPoint818a/helper_net.py:190)\r\n\r\nOriginal stack trace for 'bbox/PyFunc':\r\n  File \"main_train.py\", line 72, in <module>\r\n    net.build_graph()\r\n  File \"/home/liu/disk1/3DBoNetPoint818a/main_3D_BoNet.py\", line 246, in build_graph\r\n    self.y_bbvert_pred, self.pred_bborder = Ops.bbvert_association(self.X_pc,  self.y_bbvert_pred_raw, self.Y_bbvert, label=bbox_criteria)\r\n  File \"/home/liu/disk1/3DBoNetPoint818a/helper_net.py\", line 208, in bbvert_association\r\n    pred_bborder, association_score_min = Ops.hungarian(associate_maxtrix, bb_gt=Y_bbvert)\r\n  File \"/home/liu/disk1/3DBoNetPoint818a/helper_net.py\", line 134, in hungarian\r\n    ordering, loss_total = tf.compat.v1.py_func(assign_mappings_valid_only, [loss_matrix, bb_gt], [tf.int32, tf.float32])\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 337, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\", line 206, in wrapper\r\n    return target(*args, **kwargs)\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py\", line 636, in py_func\r\n    return py_func_common(func, inp, Tout, stateful, name=name)\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py\", line 617, in py_func_common\r\n    func=func, inp=inp, Tout=Tout, stateful=stateful, eager=False, name=name)\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py\", line 352, in _internal_py_func\r\n    input=inp, token=token, Tout=Tout, name=name)\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/tensorflow/python/ops/gen_script_ops.py\", line 150, in py_func\r\n    \"PyFunc\", input=input, token=token, Tout=Tout, name=name)\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 750, in _apply_op_helper\r\n    attrs=attr_protos, op_def=op_def)\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3543, in _create_op_internal\r\n    op_def=op_def)\r\n  File \"/home/liu/anaconda3/envs/tf2.5/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2023, in __init__\r\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)", "@lifeiwen \r\nplease share stand alone code for us to replicate the issue faced with dependencies.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46280\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46280\">No</a>\n", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information."]}, {"number": 46279, "title": "delete pycharm project issue(Pycharm project deletion problem due to cache deletion)", "body": "The project was deleted while using pycharm for tensorflow developer certification. It seems that the pycharm project was deleted while deleting the Mac OS cache and junk. Developers preparing for certification should be aware of this issue.", "comments": ["@spirid0n \r\n\r\nThanks for filing the issue and share the information.\r\n\r\nCan I close the issue since it is not a bug or feature request related to Tensorflow. This is the platform to address Bugs/Feature requests related to Tensorflow. Thanks!", "Do you know why I am writing here? I have ignored my mail more than 10 times. I couldn't stand it, so I left a post here. I'll keep it elsewhere. I will close that issue", "Don't ignore it.", "cc @JosBecker "]}, {"number": 46278, "title": "TF2.4 MultiWorkerMirroredStrategy and ParameterServerStrategy training very slow for large mode and large data compared with TF1.14", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):**TF on yarn**(running machine system is CentOS 7)\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below):2.4.0\r\n- Python version:3.6\r\n- CUDA/cuDNN version: no gpu\r\n- GPU model and memory: no gpu\r\n- CPU info: please see it below\r\n- Training config: [MultiWorkerMirroredStrategy] chief/woker: 8 instances, 8 cpus per instance, 120G memory per instance; [ParameterServerStrategy] chief:  8cpus,25G memory; worker: 30 instances, 8 cpus per instance, 25G memory per instance;ps: 8 instances, 12 cpus per instance, 25G memory per instance(which is the same with training using TF1.14)\r\n\r\n**Describe the current behavior**\r\n\r\nI built a wide&deep based model  with about **1.3 billion trainable params** which is used for ranking items for industrial recommend ranking system.\r\nWhen I trained the same model using parameter server strategy on TF 1.14(asynchronous training) with about **4 billion training samples**\uff0cit only costs about 23 hours, but when I upgrade model to TF 2.4 using keras api, training becomes very slow (about 5597 hours(ETA) of MultiWorkerMirroredStrategy, at least 72 hours of ParameterServerStrategy)\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\nSorry, I can just paste model summary here because of the code complexity, you can see it beflow. I only paste wide model and input of deep model here. deep model is just a [512, 512,512, 512] sequential model. All features name are replaced for privacy so there maybe some mistake here.\r\n\r\n**Other info / logs** \r\n", "comments": ["Here is model summary: please [click](https://github.com/wuxianxingkong/tf-issue/blob/main/model_summary.txt)\r\n\r\n\r\nHere is CPU info: please [click](https://github.com/wuxianxingkong/tf-issue/blob/main/cpu_info.txt)", "MultiWorkerMirroredStrategy Performance Summary:\r\n![s1](https://user-images.githubusercontent.com/4003232/103988787-a3019b80-51c9-11eb-8913-720c7f73e350.png)\r\n\r\n", "MultiWorkerMirroredStrategy Stats:\r\n![111](https://user-images.githubusercontent.com/4003232/103992038-82881000-51ce-11eb-8ae4-064ab05d3fc3.png)\r\n", "> Sorry, I can just paste model summary here because of the code complexity, you can see it beflow. I only paste wide model and input of deep model here.\r\n\r\n@wuxianxingkong,\r\nWithout a sample code it would be difficult for us to debug the issue. Could you please provide a minimal code snippet using a dummy dataset, so that we can reproduce the issue on our end. Thanks!", "```python\r\n\r\nimport datetime\r\nimport math\r\nimport os\r\nimport time\r\n\r\nimport numpy as np\r\nimport pandas as pd\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.keras.layers.experimental import preprocessing\r\n\r\n\r\ndef parse_record_batch(message, features):\r\n  parsed_feature_dict = tf.io.parse_example(message, features)\r\n  label = parsed_feature_dict.pop('label')\r\n  weight = parsed_feature_dict.pop('weight')\r\n  # We have to padding all sparse feature with -1 in sync with recommend engine which also padding -1 before sending grpc predict request to TF serving.\r\n  for feature_name, cur_tensor in parsed_feature_dict.items():\r\n    if feature_name.startswith('sparse'):\r\n      parsed_feature_dict[feature_name] = tf.sparse.to_dense(cur_tensor, -1)\r\n\r\n  return parsed_feature_dict, label, weight\r\n\r\ndef input_fn(file_path, batch_size, num_epochs, features):\r\n  # We need to set shuffle to False because multi worker stragtegy will auto split training file, so no shuffle means split across worker is in the same certain same way\r\n  dataset = tf.data.Dataset.list_files(file_path, shuffle=False)\r\n  dataset = dataset.interleave(\r\n    lambda filename: tf.data.TFRecordDataset(filename),\r\n    cycle_length=10,\r\n    block_length=1000,\r\n    num_parallel_calls=10\r\n  )\r\n  dataset = dataset.repeat(num_epochs).shuffle(batch_size * 20, reshuffle_each_iteration=True)\r\n  dataset = dataset.batch(batch_size=batch_size)\r\n  dataset = dataset.map(lambda x: parse_record_batch(x, features), num_parallel_calls=5)\r\n  return dataset\r\n\r\ndef get_nhoursago(n, work_hour=None):\r\n  if work_hour:\r\n    date = time.strptime(work_hour, '%Y-%m-%d-%H')\r\n    day = datetime.datetime(\r\n      date[0], date[1], date[2], date[3]) - datetime.timedelta(hours=n)\r\n  else:\r\n    day = datetime.datetime.now() - datetime.timedelta(hours=n)\r\n  return day.strftime('%Y-%m-%d-%H')\r\n\r\ndef get_nhourslast(n, work_hour=None):\r\n  if work_hour:\r\n    date = time.strptime(work_hour, '%Y-%m-%d-%H')\r\n    day = datetime.datetime(\r\n      date[0], date[1], date[2], date[3]) + datetime.timedelta(hours=n)\r\n  else:\r\n    day = datetime.datetime.now() + datetime.timedelta(hours=n)\r\n  return day.strftime('%Y-%m-%d-%H')\r\n\r\n# get tfrecords from HDFS, HDFS path format is:\r\n# father_directory/2020-01-09-01/tfrecords/part-*\r\n#                            .../data_size        (file which record the tfrecords sample length)\r\ndef get_train_file_info(data_dir, biz_date, data_range):\r\n  date_list = [d.strftime(\"%Y-%m-%d-%H\") for d in\r\n               pd.date_range(get_nhoursago(data_range, biz_date), get_nhoursago(1, biz_date),\r\n                             freq='H')]\r\n  data_path = []\r\n  sample_count = 0\r\n  for cur_data in data_dir.split(','):\r\n    data_path.extend(['%s/%s/tfrecords/part-*' % (cur_data, dt) for dt in date_list])\r\n    sample_count = sample_count + sum([int(tf.io.gfile.GFile('%s/%s/data_size' % (cur_data, dt), \"r\").readline()) for dt in date_list])\r\n  return data_path, sample_count\r\n\r\n\r\ndef get_cur_time():\r\n  return datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\r\n\r\ndef get_parse_example_config(all_dict, feature_name):\r\n  if feature_name.startswith('sparse'):\r\n    all_dict[feature_name] = tf.io.VarLenFeature(tf.int64)\r\n  else:\r\n    all_dict[feature_name] = tf.io.FixedLenFeature((1), tf.float32, 0.0)\r\n\r\nclass DenseToRaggedLayer(tf.keras.layers.Layer):\r\n  def __init__(self, ignore_value=-1, **kwargs):\r\n    super(DenseToRaggedLayer, self).__init__(**kwargs)\r\n    self.ignore_value = ignore_value\r\n\r\n  def call(self, inputs):\r\n    return tf.RaggedTensor.from_tensor(inputs, padding=self.ignore_value)\r\n\r\ndef embedding_dim_fn(bucket_size):\r\n  return int(np.power(2, np.ceil(np.log(bucket_size ** 0.25)) + 3))\r\n\r\n# Default behavior: to_wide: True, to_deep: True, transform: None\r\nsimple_sparse_config = {\r\n  'sparse_feature1': {'bucket_size': 2100},\r\n  'sparse_feature2': {'bucket_size': 5000000},\r\n  'sparse_feature5': {'bucket_size': 500000},\r\n  'sparse_feature6': {'bucket_size': 800000},\r\n  'sparse_feature7': {'bucket_size': 800000},\r\n  'sparse_feature8': {'bucket_size': 30000},\r\n  'sparse_feature9': {'bucket_size': 30000},\r\n  'sparse_feature10': {'bucket_size': 23000},\r\n  'sparse_feature11': {'bucket_size': 23000},\r\n  'sparse_feature12': {'bucket_size': 800000},\r\n  'sparse_feature13': {'bucket_size': 800000},\r\n  'sparse_feature14': {'bucket_size': 80000},\r\n  'sparse_feature15': {'bucket_size': 80000},\r\n  'sparse_feature16': {'bucket_size': 30000},\r\n  'sparse_feature17': {'bucket_size': 30000},\r\n  'sparse_feature19': {'bucket_size': 100000},\r\n}\r\n\r\nshare_embedding_sparse_config = [\r\n  {'name': 'ss1',\r\n   'columns': {'sparse_feature_20': {}, 'sparse_feature_21': {}, 'sparse_feature_22': {}, 'sparse_feature_23': {}},\r\n   'bucket_size': 220000,\r\n   'embedding_size': 128},\r\n  {'name': 'ss2',\r\n   'columns': {'sparse_feature_24': {}, 'sparse_feature_25': {}, 'sparse_feature_26': {}},\r\n   'bucket_size': 260000,\r\n   'embedding_size': 128},\r\n  {'name': 'ss3',\r\n   'columns': {'sparse_feature_27': {}, 'sparse_feature_28': {}, 'sparse_feature_29': {}},\r\n   'bucket_size': 7500000,\r\n   'embedding_size': 64} # we can't set embedding_size to 128 in multi worker strategy because of protobuf object size limit:https://github.com/tensorflow/tensorflow/issues/45041\r\n]\r\n\r\nadditional_dense_feature = {'label': tf.io.FixedLenFeature((1), tf.float32, 0.0),\r\n                            'weight': tf.io.FixedLenFeature((1), tf.float32, 0.0)}\r\n\r\ndef build_model():\r\n  parse_example_config = dict()\r\n  wide_inputs = []\r\n  wide_raw_inputs = []\r\n  deep_inputs = []\r\n  deep_raw_inputs = []\r\n  print('[{}] Build simple sparse part...'.format(get_cur_time()))\r\n  for feature_name, conf in simple_sparse_config.items():\r\n    cur_input = keras.Input(shape=(None,), name=feature_name, dtype=tf.int64)\r\n    get_parse_example_config(parse_example_config, feature_name)\r\n    ragged_hashed_input = preprocessing.Hashing(num_bins=conf['bucket_size'], name=feature_name + '_hash')(DenseToRaggedLayer(name=feature_name + '_rag')(cur_input))\r\n    if conf.get('to_wide', True):\r\n      wide_raw_inputs.append(cur_input)\r\n      wide_inputs.append(preprocessing.CategoryEncoding(max_tokens=conf['bucket_size'], output_mode='binary', sparse=True, name=feature_name + '_cat')(ragged_hashed_input))\r\n    if conf.get('to_deep', True):\r\n      deep_raw_inputs.append(cur_input)\r\n      deep_inputs.append(layers.GlobalAveragePooling1D(name=feature_name + '_avg_pool')(layers.Embedding(conf['bucket_size'], embedding_dim_fn(conf['bucket_size']), name=feature_name + '_emb')(ragged_hashed_input)))\r\n      # Bug in TF:  https://github.com/tensorflow/tensorflow/issues/45041\r\n      # cur_emb.set_weights([np.random.random(size=(conf['bucket_size'], embedding_dim_fn(conf['bucket_size'])))])\r\n  print('[{}] Build share embedding part...'.format(get_cur_time()))\r\n  for conf in share_embedding_sparse_config:\r\n    shared_embedding = layers.Embedding(conf['bucket_size'], conf['embedding_size'], name=conf['name'] + '_share_emb')\r\n    # print('conf', conf)\r\n    for feature_name, inner_conf in conf['columns'].items():\r\n      cur_input = keras.Input(shape=(None,), name=feature_name, dtype=tf.int64)\r\n      get_parse_example_config(parse_example_config, feature_name)\r\n      ragged_hashed_input = preprocessing.Hashing(num_bins=conf['bucket_size'], name=feature_name + '_hash')(DenseToRaggedLayer(name=feature_name + '_rag')(cur_input))\r\n      if inner_conf.get('to_wide', True):\r\n        wide_raw_inputs.append(cur_input)\r\n        wide_inputs.append(preprocessing.CategoryEncoding(max_tokens=conf['bucket_size'], output_mode='binary', sparse=True, name=feature_name + '_cat')(ragged_hashed_input))\r\n      if inner_conf.get('to_deep', True):\r\n        deep_raw_inputs.append(cur_input)\r\n        deep_inputs.append(layers.GlobalAveragePooling1D(name=feature_name + '_avg_pool')(shared_embedding(ragged_hashed_input)))\r\n  print('[{}] Build combine part...'.format(get_cur_time()))\r\n  # BUILD MODEL\r\n  wide_output = keras.experimental.LinearModel()(wide_inputs)\r\n  deep_first = layers.Concatenate()(deep_inputs)\r\n  dnn_model_output = keras.Sequential([keras.layers.Dense(units=512),\r\n                                       keras.layers.Dense(units=512),\r\n                                       keras.layers.Dense(units=512),\r\n                                       keras.layers.Dense(units=1)])(deep_first)\r\n  wide_model = keras.Model(inputs=wide_raw_inputs, outputs=wide_output, name='wide_model')\r\n  deep_input_model = keras.Model(inputs=deep_raw_inputs, outputs=dnn_model_output, name='deep_model')\r\n  print('wide model summary:')\r\n  wide_model.summary(line_length=200)\r\n  print('deep model summary:')\r\n  deep_input_model.summary(line_length=200)\r\n\r\n  wide_deep_model = tf.keras.experimental.WideDeepModel(wide_model, deep_input_model)\r\n\r\n  parse_example_config.update(additional_dense_feature)\r\n  return wide_deep_model, parse_example_config\r\n\r\nbiz_date = '2020-01-09-00'\r\ntrain_dir = 'hdfs_train_father_directory'\r\neval_dir = 'hdfs_eval_father_directory'\r\nmodel_dir = 'hdfs_model_dir'\r\nBATCH_SIZE = 1024\r\nTRAIN_EPOCHS = 1\r\ntrain_files, train_sample_count = get_train_file_info(train_dir, biz_date, 7 * 24)\r\n\r\ncluster_resolver = tf.distribute.cluster_resolver.TFConfigClusterResolver()\r\nstrategy = tf.distribute.MultiWorkerMirroredStrategy(cluster_resolver)\r\ntask_type, task_id = (strategy.cluster_resolver.task_type,\r\n                        strategy.cluster_resolver.task_id)\r\nprint('[{}] task type: {}, task id: {}'.format(get_cur_time(), task_type, task_id))\r\nprint('[{}] Start build model...'.format(get_cur_time()))\r\nwith strategy.scope():\r\n  global_batch_size = BATCH_SIZE * strategy.num_replicas_in_sync\r\n  print('[{}] Global batch size is: {} ({} * {})'.format(get_cur_time(), global_batch_size, BATCH_SIZE, strategy.num_replicas_in_sync))\r\n  model, features = build_model()\r\n  print('[{}] Compile model...'.format(get_cur_time()))\r\n  model.compile(optimizer=[tf.keras.optimizers.Ftrl(),\r\n                           tf.keras.optimizers.Adagrad()])\r\n\r\n  print('[{}] Save model structure...'.format(get_cur_time()))\r\n  callbacks = [tf.keras.callbacks.TensorBoard(log_dir=os.path.join(model_dir, \"logs\"), update_freq=20, histogram_freq=1, profile_batch='2,4'),\r\n               tf.keras.callbacks.experimental.BackupAndRestore(os.path.join(model_dir, \"checkpoint\"))]\r\n  print('[{}] Start train...'.format(get_cur_time()))\r\n\r\n  model.fit(input_fn(train_files, global_batch_size, TRAIN_EPOCHS, features),\r\n            epochs=TRAIN_EPOCHS, callbacks=callbacks, steps_per_epoch=int(math.floor(train_sample_count * 1.0 / global_batch_size)))\r\n\r\n```", "@amahendrakar Thanks for reply. Please check code above. I tried my best to union them all but there maybe some mistakes.", "Code for ParameterServerStrategy is almost the same with the code above except that I rewrite wide&deep combined model in functional way.", "I use tf.print('position_flag_x', tf.timestamp()) to check execute time in one step(Multi worker strategy), I found that there were two place costs lots of time:\r\n\r\n1. wide model inference: cost 3 seconds\r\n2. the time between one step end and next step start: cost about 30 seconds which is almost the same as Collective OP time \r\n shown in TF Profiler. \r\n\r\nUpdate: I copy make_train_function to WideDeepModel, and add tf.print. I found that  step_function cost only abount 3s, but after step_function is called, there will be a long time doing something in tf.fucntion:\r\n```python\r\ntf.function(step_function):\r\n  step_function()\r\n  OP_Cost_30s() # TF will do something here? It costs lots of time\r\n```\r\n", "@wuxianxingkong,\r\nThank you for the update. \r\n\r\nOn running the code, I am facing an error stating `NotFoundError: hdfs_train_father_directory/2020-01-02-00/data_size; No such file or directory`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/1cd3e46545c6d64bf02e432ec3114698/46278.ipynb). \r\n\r\nCould you please share all the files necessary to run the code or update the code to use dummy/random data, so that we can reproduce the issue on our end. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 46276, "title": "Don't raise an Error on unknown kwargs", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version 2.1 - 2.3:\r\n- Are you willing to contribute it (No):\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nAlmost all Keras objects support **kwargs but raising an TypeError if a 'Keyword argument (is) not understood'. i.e.\r\n\r\n```\r\ntf.keras.layers.Dense(8, foo='bar')\r\n```\r\n\r\nI wish a more Duck Typing behavior that either ignores unknown args or raises a warning according to the debug level.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nSimplifies the parameter management for inheriting classes or adapter classes.\r\n\r\n```\r\nclass MyLayer(tf.keras.layers.Layer):\r\n   def __init__(self, units=8, dims=(0,2,1), **kwargs):\r\n      super(MyLayer, self).__init__(**kwargs)\r\n      self.layer = tf.keras.layers.Dense(units, **kwargs)\r\n      self.permute = tf.keras.layers.Permute(dims, **kwargs)\r\n      [...]\r\n```\r\n", "comments": ["> I wish a more Duck Typing behavior that either ignores unknown args or raises a warning according to the debug level.\r\n\r\nThis would be extremely dangerous, since it would mean any mistyped argument would be silently ignored instead of causing an error. For example:\r\n\r\n```python\r\ndense = Dense(32, activaton='relu')  # This silently creates a layer with *no* activation due to the typo.\r\n```"]}, {"number": 46275, "title": "Refactor ReshapeSparseTensor into a template+class", "body": "This is in preparation for adding a GPU implementation.\r\nNo functional change.\r\n\r\ncc @nluehr ", "comments": ["@allenlavoie Any idea who should review this?", "@penpornk has been working on sparse kernels I believe. Penporn, want to take a look?", "@allenlavoie @cheshire Sure, I can review this. :)", "Gentle ping."]}, {"number": 46274, "title": "tf.experimental.numpy fails with plt.hist", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): using example from TF docs\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.4.0-rc4-71-g582c8d236cb 2.4.0\r\n- Python version: 3.8.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.0 / 8.0.4\r\n- GPU model and memory: GTX 1660 Ti, 6 GB\r\n\r\n**Describe the current behavior**\r\nJust trying to plot a histogram from a random standard normal distribution array made with tf.experimental.numpy\r\nThe code is copied from here: https://www.tensorflow.org/guide/tf_numpy\r\nWhat I get is a bunch of random lines in the histogram.\r\nThe values in the random matrices AFAICT seem fine - look like a normal distribution.\r\n\r\n![bad](https://user-images.githubusercontent.com/901867/103975506-26b77b80-5129-11eb-89cd-b61bed58b5c8.png)\r\n\r\n**Describe the expected behavior**\r\nI should get the normal distribution bell curve in the histogram image.\r\n\r\n![good](https://user-images.githubusercontent.com/901867/103975532-35059780-5129-11eb-87a4-3e5b1b16f3f1.png)\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport tensorflow.experimental.numpy as tnp\r\n\r\n# bad image - see above\r\nlabels1 = 15 + 2 * tnp.random.randn(1000)\r\n_ = plt.hist(labels1)\r\n\r\n# good image - see above\r\nlabels2 = 15 + 2 * np.random.randn(1000)\r\n_ = plt.hist(labels2)\r\n\r\n```\r\nI run everything in Jupyter Notebook in Chrome.\r\n\r\nTensorflow is actually running on the GPU.", "comments": ["@FlorinAndrei,\r\nOn running the code with TF v2.4, I got the expected behavior. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/cddfa0eb488d857ceef401e41c739f48/46274.ipynb). \r\n\r\n Could you please try running the code in a new virtual environment and check if you are facing the same issue. Thanks!", "@amahendrakar  I was able to reproduce the issue(bad results) with tensorflow versions 2.3.0 and 2.4.0 in windows 10 . But the same versions produces the expected/good results when used in colab. I think this is a os specific issue. I want to contribute/help in this. Can you please giude me?", "Python, CUDA, and the Python modules - are all a fresh install. I've completely uninstalled the old Anaconda and Python bits and started from scratch with the latest versions. This was literally the TF test drive I did - and it failed.\r\n\r\nIf you need me to run it with various options, capture debug logs, etc - let me know.", "BTW, your own documentation page is now broken, it's showing the bad output:\r\n\r\nhttps://www.tensorflow.org/guide/tf_numpy#numpy_interoperability\r\n\r\n![Screen Shot 2021-01-08 at 1 53 09 PM](https://user-images.githubusercontent.com/901867/104067936-eb648d80-51b8-11eb-9bf7-ee2dbc4a1cae.png)\r\n", "@FlorinAndrei May be this was an issue with some `2.4rc3` version but not anymore with later versions like `tf-nightly` or `TF2.4`. I have checked it with colab but will check on `Windows 10` system later.\r\n\r\n[Here](https://colab.research.google.com/gist/jvishnuvardhan/2fac487cbe3609552e08ea12c91ff078/46274.ipynb) is a gist with `tf-nightly`.\r\n\r\nI agree with you that TF website shows similar histogram as you noticed. But, when you run the code in that colab, it will show as a expected histogram. [Here](https://colab.research.google.com/gist/jvishnuvardhan/f207d102f287406a98beaebd5599b189/tf_numpy.ipynb) is the gist.\r\n\r\nCan you please run the code with `tf-nightly` and `TF2.4` and let us know whether the issue persists with recent versions. Thanks!\r\n\r\n", "@jvishnuvardhan There's no need to speculate. Like I said at the very beginning in this discussion (please refer to the top comment), I'm using 2.4.0:\r\n\r\n```\r\n>python\r\nPython 3.8.7 (tags/v3.8.7:6503f05, Dec 21 2020, 17:59:51) [MSC v.1928 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n2021-01-20 18:35:42.219325: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n>>> tf.__version__\r\n'2.4.0'\r\n>>> print(tf.version.GIT_VERSION, tf.version.VERSION)\r\nv2.4.0-rc4-71-g582c8d236cb 2.4.0\r\n```\r\n\r\nThere is no more recent version of TF available with pip:\r\n\r\n```\r\npip install --user --upgrade tensorflow\r\nRequirement already up-to-date: tensorflow in c:\\users\\flori\\appdata\\roaming\\python\\python38\\site-packages (2.4.0)\r\n```\r\n\r\nI will not try tf-nightly, I don't have time for that.", "This may be a NumPy version issue. @FlorinAndrei can you tell me the NumPy and matplotlib versions when you ran into the bad image?", "The issue still occurs with the versions currently installed. I just checked moments ago. The versions are:\r\n\r\n```\r\nnp.__version__\r\n'1.19.5'\r\n\r\nmatplotlib.__version__\r\n'3.3.4'\r\n\r\ntf.__version__\r\n'2.4.1'\r\n```\r\n\r\nI don't know if this will help, but I've captured the console output from Jupyter while running the failed code. Here is the output:\r\n\r\nhttps://gist.github.com/FlorinAndrei/ef90e68bcb75d2d3cd64b12acb14667b", "Given that this is hard to reproduce, it might help to figure out if this is a matplotlib related issue or an issue with the TF kernel. @FlorinAndrei can you print the values in labels1 and inspect the distribution to see if this is producing a reasonable set of 1000 float values. The histogram seems to show a handful of values with a count of 1 which looks broken. Also check if the dtype looks correct.\r\n\r\nNote also that a recent change requires calling numpy.experimental_enable_numpy_behavior() to enable numpy style type promotion. ", "This is labels1:\r\n\r\n```\r\nndarray<<tf.Tensor: shape=(1000,), dtype=float64, numpy=\r\narray([19.78081558, 13.45904798, 14.12964647, 17.00849968, 14.41289163,\r\n       15.63509735, 11.95597987, 12.21283557, 15.73229975, 14.1320517 ,\r\n       15.71561052, 11.88870977, 13.32098549, 11.51131012, 14.31889325,\r\n       17.0135532 , 15.78388232, 16.1916691 , 14.21063682, 14.05635951,\r\n       18.04723484, 16.47800067, 18.1168248 , 17.14846506, 12.58118162,\r\n       15.45623849, 16.13998039, 15.40504702, 17.26882688, 14.50920164,\r\n       13.86580215, 13.26296502, 14.47810345, 15.4120932 , 15.85014382,\r\n       14.63866278, 14.27790941, 17.18285021, 14.01603754, 18.85048763,\r\n       16.91405978, 13.78490271, 14.91056252, 16.96977761, 15.48022693,\r\n       14.4031711 , 13.76716642, 12.47979089, 14.42517709, 19.40269905,\r\n       12.8316006 , 16.23055321, 13.11039687, 11.89935032, 14.6534007 ,\r\n       14.07146883, 17.43018337, 15.89971108, 15.17286839, 21.023557  ,\r\n       12.19444536, 15.75577225, 17.92958889, 13.42408448, 15.78275425,\r\n       16.76528553, 17.74291291, 15.2542025 , 16.24640107, 15.7568763 ,\r\n       21.10346298, 13.497665  , 17.14507284, 16.92227441, 12.012511  ,\r\n       15.52903001, 16.16173272, 16.46417017, 15.31563809, 14.80087716,\r\n       17.55761467, 12.72184078, 16.80070687, 14.53757038, 13.101123  ,\r\n       13.62243158, 12.51737987, 13.59091204, 17.0257101 , 15.92294085,\r\n       14.93044579, 15.98277135, 14.33046538, 13.27455081, 13.39695607,\r\n       10.7112541 , 14.69472743, 14.54144788, 14.33197709, 15.34974758,\r\n       14.70379807, 15.38474559, 18.04566222, 17.3847292 , 15.50944118,\r\n       13.24118371,  8.58776939, 17.42391041, 16.56052927, 11.60218659,\r\n       14.80654898, 14.02050234, 14.95662422, 13.81741732, 15.60980258,\r\n       12.12697828, 14.92582021, 17.19444591, 18.45241113, 14.43573426,\r\n       13.21627796, 17.74533862, 12.81197773, 14.34316725, 14.60278645,\r\n       15.82505158, 10.79113032, 14.85792303, 15.85981381, 11.28345473,\r\n       13.9791923 , 15.43082064, 16.44140614, 14.12900391, 11.81493743,\r\n       18.01757993, 17.37319621, 15.60328857, 15.55632445, 13.34949634,\r\n       17.40529579, 12.39889034, 14.94552816, 15.63216018, 12.61959924,\r\n       17.40868988, 14.617995  , 12.95955456, 14.95127599, 14.73346399,\r\n       16.94021008, 14.47398077, 11.09310643, 16.90784015, 18.86924114,\r\n       17.16617749, 16.211527  , 14.39512199, 12.04954448, 12.49680612,\r\n       17.22228401, 17.06475306, 20.85642706, 11.14667568, 14.65299782,\r\n       13.68104059, 15.0542971 , 18.24618877, 15.89248326, 16.20102659,\r\n       17.23121059, 12.42990416, 15.53852035, 16.41762131, 13.97969896,\r\n       16.52781467, 14.65386726, 18.75783446, 11.21682695, 14.73613683,\r\n       16.63371056, 15.93952413, 18.68291041, 12.47864196, 13.22780194,\r\n       13.81475246, 15.65067057, 18.39739662, 15.53119167, 13.64062421,\r\n       18.4479756 , 13.31348638, 14.79067543, 17.78022787, 15.34564444,\r\n       16.03125379, 14.25215226, 12.55754522, 14.3759994 , 11.27629086,\r\n       15.08147385, 17.52871212, 15.04160888, 14.84470661, 12.06503999,\r\n       15.09481134, 13.39591597, 20.91904101, 17.50547829, 15.47398302,\r\n       14.06548157, 16.05004102, 14.22998182, 15.52494125, 13.92237473,\r\n       14.89248665, 14.2383167 , 12.40792164, 12.89983641, 13.98476589,\r\n       12.72963063, 16.26937683, 15.63044265, 16.8788645 , 15.29016438,\r\n       15.02134435, 10.42836829, 18.30874604, 14.62576413, 12.63645687,\r\n       12.49073124, 13.96187322, 14.08827237, 15.66164333, 13.59893116,\r\n       17.07364423, 13.39832022, 18.33998505, 17.5511353 , 13.05765353,\r\n       15.35436653, 16.48467564, 14.02666048, 14.61085584, 12.88164587,\r\n       14.99789286, 16.31116727, 15.34193151, 14.45467409, 15.38077812,\r\n       15.98588437, 12.29475501, 12.73619531, 13.63359372, 13.09895345,\r\n       15.64993624, 14.25874793, 14.18187701, 15.53970929, 17.10404899,\r\n       13.90608135, 11.96566022, 14.14807561, 14.37142946, 14.91215035,\r\n       14.30390229, 10.44785647, 17.35283773, 15.48158863, 17.20347226,\r\n       11.18192108, 11.88326085, 19.22165301, 13.09402315, 16.77422011,\r\n       15.29806332, 14.65275828, 12.40882896, 14.68055511, 15.06264074,\r\n       12.22143187, 12.41289463, 15.90229858, 12.56505307, 15.56340245,\r\n       13.45727729, 18.79094809, 12.81723461, 15.70023918, 15.05171624,\r\n       12.18713437, 14.12130062, 13.46583241, 11.12518164, 16.33777276,\r\n       15.94900851, 17.13711618, 17.3608268 , 15.20043316, 13.3878622 ,\r\n       14.38599894, 16.90452794, 14.32555359, 13.49103515, 15.28669042,\r\n       16.39362239, 15.96173557, 17.6349929 , 13.00824058, 12.69867049,\r\n       16.69555983, 13.17586382, 16.99980257, 14.85401062, 13.70005736,\r\n       14.97746736, 11.94846454, 15.88030887, 15.25863918, 15.06490927,\r\n       16.48180943, 16.95106651, 14.96034648, 16.36021449, 16.23095385,\r\n       15.0481904 , 16.53055907, 12.971027  , 13.08125628, 15.4737926 ,\r\n       14.60394005, 13.90285642, 14.4986939 , 16.46874953, 16.80750778,\r\n       15.3097497 , 14.76292684, 15.94580957, 16.75933195, 16.30767719,\r\n       17.21259434, 16.31387626, 14.33098282, 10.37729358, 11.29514457,\r\n       17.87354002, 19.07728962, 12.88580563, 13.03892345, 17.32679135,\r\n       16.42016629, 13.29437837, 15.64310578, 11.61241735, 13.44370173,\r\n       13.14180529, 12.72338759, 15.44404221, 18.68859556, 15.94680659,\r\n       12.11255788, 14.06115415, 14.57842459, 11.78080395, 12.37700132,\r\n       13.73462768, 14.72204347, 14.8026317 , 13.66171951, 14.34311927,\r\n       14.90129794, 16.65534264, 12.10456418, 15.38434941, 10.58910506,\r\n       17.59793429, 10.94960423, 14.1081797 , 13.84641565, 15.11996885,\r\n       11.95977426, 15.42295794, 15.11125386, 14.64109771, 10.83789819,\r\n       11.49105029, 12.54881165, 15.6016665 , 15.50637143, 13.97526379,\r\n       15.77870016, 16.77736377, 15.53615953, 17.03079251, 14.67056464,\r\n       15.61964427, 11.05271492, 13.85403149, 13.63461329, 15.38101017,\r\n       14.92442349, 12.27153489, 14.26310213, 14.53824833, 15.84200138,\r\n        8.26620963, 14.35852927, 13.08323763, 14.3868915 , 15.22813244,\r\n       14.15079897, 14.24721975, 13.8714924 , 14.01594882, 13.36878728,\r\n       18.21772374, 13.33596717, 13.75859171, 16.05284402, 12.35760772,\r\n       16.35973687, 15.24493829, 19.30674146, 15.04839777, 18.48091712,\r\n       18.19251374, 15.54557225, 13.97697248, 15.35741864, 13.05364972,\r\n       16.64120127, 19.90071533, 14.10281049,  8.66563603, 16.80025148,\r\n       11.93904567, 14.77155393, 16.31777608, 16.63561782, 16.58826035,\r\n       14.71029213, 13.2117095 , 14.63494447, 14.6196565 , 15.81160148,\r\n       12.32587761, 15.98816998, 17.92979519, 17.04556897, 15.39634578,\r\n       14.28552534, 14.24901   , 17.91034972, 16.06775548, 16.13581983,\r\n       17.17990527, 15.74535913, 16.04845523, 17.67358301, 16.63467027,\r\n       17.18469302, 13.07271904, 14.88712495, 20.70219103, 16.5558376 ,\r\n       15.73111123, 15.30048251, 15.8259332 , 17.55639675, 17.38987492,\r\n       17.42462787, 17.00342801, 11.65999969, 16.02014535, 14.61395278,\r\n       14.88870954, 11.98216583, 13.69316036, 10.18911632, 13.94349657,\r\n       12.91545145, 15.783211  , 17.01759627, 17.96913532, 14.48399882,\r\n       14.8743117 , 15.74305457, 11.62807574, 13.12182756, 15.21911734,\r\n       12.26574343, 13.73981005, 16.08668315, 16.42840954, 13.70200578,\r\n       13.38597249, 14.16908174, 12.05326057, 12.82479949, 11.91415905,\r\n       17.32590789, 12.44959034, 18.022533  , 17.58638671, 14.23429377,\r\n       12.73265764, 17.63059826, 15.45182046, 14.28572055, 17.8730982 ,\r\n       15.94035606, 15.15182715, 13.64738597, 12.16499307, 13.78667608,\r\n       12.71493422, 18.47438734, 14.51175048, 14.92272154,  9.080784  ,\r\n       16.11056909, 23.13876174, 12.87011462, 12.01223677, 17.66788531,\r\n       15.19056268, 11.50571861, 11.92601923, 15.35416882, 14.6745811 ,\r\n       12.52331724, 12.53446091, 14.12910798, 13.01594528, 15.88596744,\r\n       16.68564162, 13.04189754, 12.36717723, 18.9105257 , 14.76737572,\r\n       13.0256933 , 16.16209395, 15.50748117, 15.48415749, 11.99467613,\r\n       15.04281581, 14.20291797, 16.92694259, 12.15571931, 17.5534874 ,\r\n       14.85451715, 15.99218077, 15.68418431, 11.99054986, 13.6733552 ,\r\n       13.23306151, 13.60803444, 15.29039717, 16.21322827, 14.65194217,\r\n       15.99460993, 14.83797179, 13.30002317, 16.27166286, 15.67780125,\r\n       11.62110227, 15.73292246, 15.69831678, 19.12254757, 18.04706068,\r\n       16.83690228, 14.44494179, 14.33764725, 15.32052721, 13.71510322,\r\n       16.16400659, 15.74911756, 17.385473  , 10.49827024, 14.42050802,\r\n       11.54984124, 12.85476912, 14.3673829 , 14.12618375, 13.4949065 ,\r\n       14.99684545, 14.38113996, 11.32276862, 16.5560197 , 15.97335515,\r\n       15.32753014, 11.78804922, 13.87143458, 12.8948799 , 12.38559426,\r\n       14.68202733, 13.98451323, 13.20413842, 15.27600341, 15.59971634,\r\n       12.75146941, 17.74393925, 13.3774891 , 16.08319225, 14.89804641,\r\n       14.7659616 ,  9.71831912, 18.11720418, 16.68335814,  9.12931552,\r\n       19.03936021, 13.32530069, 14.12887994, 11.21771539, 18.31085378,\r\n       16.95072189, 12.68293421, 14.86339238, 17.09849828, 14.51819293,\r\n       13.86193171, 14.31532444, 15.80980018, 14.45013394, 17.71067473,\r\n       12.75209907, 15.58264842, 14.04067229, 15.58317283, 15.76402052,\r\n       15.83589523,  8.74561161, 12.79111498, 16.76981735, 15.72248735,\r\n       18.57884946, 11.73054406, 13.04978244, 19.76464401, 13.84230477,\r\n       16.95918575, 11.71928661, 16.65118485, 16.83814051, 15.36273718,\r\n       17.07083139, 12.87757876, 18.00168298, 13.51545801, 14.15485493,\r\n       12.55495488, 11.57516398, 17.16040729, 11.19008804, 14.45851218,\r\n       12.57296995, 14.0193623 , 14.64324408, 15.14502428, 14.50291326,\r\n       17.80108358, 11.66597261, 15.95448513, 14.49254521, 17.59273465,\r\n       18.73429733, 16.47002345, 14.53632199, 12.34233807, 16.22116992,\r\n       16.49068061, 17.77796634, 15.17703844, 16.13013308, 11.56949189,\r\n       12.24811315, 14.81614282, 14.06348339, 17.88511064, 16.88180627,\r\n        9.09738296, 17.18290372, 15.384796  , 11.15193556, 13.89721148,\r\n       10.42042895, 12.29086094, 14.00746961, 13.0629025 , 13.33861029,\r\n       11.93005496, 16.08591638, 15.53840979, 17.35577037, 13.96337465,\r\n       12.71623204, 13.41119563, 17.02467414, 14.71735887, 17.49831588,\r\n       16.09269039, 13.46453217, 16.42699798, 13.00411324, 11.73578639,\r\n       11.30647474, 16.04012384, 14.18897848, 17.28148236, 14.89273978,\r\n       15.63603113, 14.14665243, 15.45316717, 15.29521062, 14.13890453,\r\n       16.30086351, 14.11330103, 15.41627038, 17.13700088, 16.17372451,\r\n       14.16387812, 13.71724839, 13.99404391, 17.33144259, 14.52474828,\r\n       15.64149386, 17.24461658, 15.21060485, 15.08298422, 14.72374732,\r\n       13.3333551 , 13.71632133, 16.84972118, 13.49333523, 14.62823408,\r\n       14.57121963, 17.10299598, 12.4146078 , 12.30861595, 14.74768112,\r\n       12.84475245,  9.67270034, 13.82030538, 16.50473866, 14.24695672,\r\n        8.22946072, 17.17453043, 13.81977619, 15.17146162, 17.33268214,\r\n       14.40827947, 13.32762346, 12.14545878, 18.3990061 , 17.05760432,\r\n       16.24450904, 13.80498922, 10.93904503, 16.1246462 , 15.22915389,\r\n       15.7379302 , 13.49327897, 15.21734234, 15.73708689, 13.96396169,\r\n       14.16793163, 11.50439819, 12.91822639, 15.46031275, 12.09028493,\r\n       19.46724809, 14.98926182, 15.88538202, 15.2647405 , 11.9825398 ,\r\n       16.13943752, 14.31981695, 15.2360176 , 12.6717067 , 14.04309543,\r\n       14.05861959, 15.09811712, 10.4193973 , 12.82987473, 14.85429928,\r\n       16.77473861, 10.72896977, 13.49407205, 14.9895753 , 14.78657337,\r\n       18.80719155, 14.93999077, 15.47104904, 12.76397927, 11.27814525,\r\n       13.26515877, 16.10061514, 13.80611977, 15.75250212, 11.30664575,\r\n       14.54358562, 16.21445568, 15.94654947, 14.89492331, 13.66421144,\r\n       17.12697398, 15.72328936, 11.99930247, 17.12355168, 19.21215004,\r\n       15.90145682, 13.18416179, 13.23541016, 15.54080209, 15.66671802,\r\n       14.88146687, 16.15453376, 14.53709173, 14.04291755, 11.73950787,\r\n       13.98503462, 14.68133477, 18.12419174, 13.19757217, 17.54248384,\r\n       14.37832165, 13.69308591, 13.49838261, 11.92207577, 19.70015188,\r\n       15.30241758, 17.03573642, 15.36934271, 17.02950571, 15.27343177,\r\n       13.2968186 , 18.30953515, 16.15656294, 13.19546833, 13.71028887,\r\n       14.25496496, 15.52669973, 15.13494324, 14.56582971, 15.76589127,\r\n       14.80801244, 16.39542466, 18.48487032, 18.3773566 , 13.2696964 ,\r\n        9.52766465, 13.30785507, 15.79124145, 13.1296365 , 17.68775463,\r\n       13.13378336, 16.80503074, 13.73848553, 13.81024933, 17.06023885,\r\n       13.55680848, 17.09089223, 12.54489918, 16.419229  , 16.88685602,\r\n       14.22914165, 16.56450917,  9.95631531, 14.56199245, 15.54258985,\r\n       14.65464392, 15.29819073, 13.62647901, 11.8174206 , 12.33550847,\r\n       12.33828805, 11.96344018, 17.54018062, 16.42540777, 16.67848988,\r\n       16.59717608, 11.43935704, 15.26917924, 13.74840307, 12.20388752,\r\n       18.30857106, 17.10554886, 15.77158824, 14.54674251, 12.94234518,\r\n       14.72858585, 16.30237468, 12.23751719, 13.59155219, 13.86407369,\r\n       14.07041852, 12.73483978, 19.2506437 , 14.49567024, 16.22668365,\r\n       13.27631806, 17.76996023, 15.27698989, 16.10621338, 17.17676248,\r\n       17.57440564, 13.375244  , 16.34533398, 16.27034808, 16.15614689,\r\n       14.08004255, 14.38577427, 13.37548875, 14.27987978, 16.08778968,\r\n       17.25000531, 12.64973908, 13.68830947, 15.96869418, 14.7370131 ,\r\n       14.76793587, 13.17241508, 17.33680329, 17.06296355, 16.53707455,\r\n       12.79403584, 13.56796708, 15.10296747, 18.39799394, 13.69668467,\r\n       14.93040557, 16.67011026, 15.96598431, 14.36194571, 14.19998614,\r\n       17.19840588, 16.76894254, 12.34764854, 14.75509042, 15.75641582,\r\n       14.18795293, 16.6837338 , 14.0266593 , 15.32813335, 14.17430556,\r\n       15.42527953, 14.53471166, 13.40098761, 13.03411731, 14.28343806,\r\n       13.76731134, 17.82636339, 15.00244367, 16.54557787, 14.98768303,\r\n       16.560411  , 11.75992017, 14.8060796 , 18.69643685, 18.15658392,\r\n       16.36322502, 13.61962577, 18.11677318, 14.97632887, 16.43333214,\r\n       15.82171311, 16.67716963, 15.20915806, 18.40582913, 17.67182976,\r\n       14.6560204 , 15.50813297, 12.25360714, 15.76040543, 13.97660268,\r\n       15.26649775, 17.36850038, 14.83754344, 13.91094662, 18.70047954,\r\n       15.3242188 , 15.07183756, 15.08157072, 13.42846604, 16.85246364,\r\n       13.36647045, 14.73494148, 10.93333153, 15.96842453, 14.71219556,\r\n       15.38798499, 11.14117028, 17.26953863, 13.92074634, 14.49445626,\r\n       15.14106664, 15.84910761, 16.36733455, 13.38051897, 17.41837255])>>\r\n```\r\n\r\nThis is labels2:\r\n\r\n```\r\narray([15.99771285, 13.84124456, 13.99605812, 16.51619841, 16.61771614,\r\n       11.51999875, 17.3290339 , 14.1233086 , 14.19479435, 17.00306462,\r\n       11.95753271, 15.24624593, 13.57253563, 17.33520155, 14.76650262,\r\n       12.37844119, 17.51498345, 16.46828016, 15.10404329, 14.93896608,\r\n       13.01971574, 12.60102303, 11.95735683, 18.14125766, 15.0987938 ,\r\n       15.91163466, 13.90660698, 16.15829679, 15.97815941, 17.20649445,\r\n       14.80400942, 14.96816242, 13.79872937, 12.07661388, 14.97375753,\r\n       14.10159763, 17.51947386, 12.55434094, 18.02881866, 15.34850177,\r\n       15.656255  , 14.63116354, 12.04417278, 15.77436262, 13.67384279,\r\n       16.12402931, 17.96570075, 13.55347534, 15.72981842, 12.54466978,\r\n       14.73163087, 15.50006349, 15.3599818 , 14.52763307, 15.4971848 ,\r\n       11.60644519, 14.16938071, 15.55519915, 15.03435341, 16.06644016,\r\n       13.30448248, 16.20720863, 17.80910635, 12.14348278, 14.60843682,\r\n       12.56439096, 16.30469966, 11.76037132, 14.08966727, 15.78669295,\r\n       13.95174585, 14.49246548, 15.8876893 , 11.57857193, 17.22463492,\r\n       14.59409332, 15.20800842, 18.08561199, 19.82300194, 12.25709368,\r\n       16.01761502, 15.75206701, 16.39504519, 13.18647877, 13.69308339,\r\n       10.93411062, 16.15393603, 16.31721064, 14.33365201, 10.97676898,\r\n       18.09800169, 15.56186152, 11.75151452, 12.69109068, 18.30172093,\r\n       19.78409443, 18.25529201, 17.96375411, 15.92196164, 15.84525366,\r\n       14.43786514, 15.55812306, 15.68854827, 16.15437206, 15.68660391,\r\n       10.82383114, 18.64135839, 16.97012498, 17.30810634, 14.94010565,\r\n       14.06775255, 12.93670774, 14.59975154, 14.11492426, 16.46953771,\r\n       16.25318982, 14.8455728 , 14.07162902, 13.40383604, 14.9002145 ,\r\n       18.25157567, 10.84481762, 16.44476125, 16.53246193, 15.68959559,\r\n       18.2558428 , 15.26072542, 16.07476176, 14.1361405 , 14.85552841,\r\n       14.54857363, 14.08044993, 13.84960138, 10.7045452 , 11.6058977 ,\r\n       14.85902756, 15.40864596, 12.77042038, 17.3928957 , 15.74798215,\r\n       12.00284511, 16.16096019, 16.74391901, 14.63777654, 16.05722727,\r\n       15.21682045, 16.70554196, 11.50627197, 15.48832742, 15.06433101,\r\n       17.04154627, 15.11247842, 12.51871023, 16.02038664, 13.83207969,\r\n       17.73368357, 19.62403578, 15.23529699, 12.63546141, 16.24654021,\r\n       16.75825681, 16.32118123, 18.62684051, 11.76180197, 11.34490455,\r\n       14.80217813, 12.67800693, 15.02644453, 15.3638301 , 15.8707838 ,\r\n       14.75676164, 12.45418939, 16.67377834, 15.45031091, 16.13181411,\r\n       19.65859348, 12.56189862, 14.48748822, 14.36950515, 14.00406022,\r\n       15.7680763 , 12.12140911, 14.16999513, 14.81308147, 16.62025218,\r\n       14.61276615, 15.82124857, 15.53835639, 15.89170274, 17.07299542,\r\n       11.62288683, 12.24800701, 15.16545142, 16.56963562, 17.36825014,\r\n       13.40816354, 16.61099935, 18.00060194, 14.03983927, 17.80612603,\r\n       14.92547713, 13.75461247, 15.06637235, 13.47583127, 20.66563191,\r\n       17.33750867, 16.28441185, 15.73287731, 13.8342392 , 17.09055979,\r\n       12.50819729, 18.43942562, 16.2807204 , 17.75667777, 13.11654566,\r\n       12.38379305, 13.36987577, 12.55463427, 13.54167366, 14.08859988,\r\n       17.19233014, 13.7403261 ,  9.90530665, 17.62212214, 13.51934352,\r\n       14.87051344, 14.39144392, 14.08807042, 16.94620876, 15.22648514,\r\n       16.78161278, 14.79608313, 17.77589596, 13.65965912, 12.24554491,\r\n       15.19553534, 16.96356652, 11.84700856, 12.50470643, 15.30882753,\r\n       16.06720343, 16.51568435, 16.17765907, 14.40748368, 15.87601098,\r\n       11.28630114, 15.18411809, 15.32185825, 14.43155539, 14.2707844 ,\r\n       16.8232202 , 16.47992568, 17.04769687, 13.46875286,  8.93651772,\r\n       11.90199959, 13.86940668, 11.17447655, 15.67627791, 14.98053069,\r\n       13.27263975, 12.18349153, 19.65056464, 14.53215688, 15.05680296,\r\n       13.05935645, 15.11217953, 13.13228039, 14.64985297, 18.01131557,\r\n       14.48046709, 14.09334879, 11.23083335, 16.04950809, 15.76018583,\r\n       15.48831567, 16.46933034, 15.40949231, 18.74426132, 15.11398437,\r\n       13.17701916, 18.55916521, 14.25246788, 16.0512772 , 15.95552987,\r\n       15.97993823, 17.34188181, 17.13878226, 10.47499718, 15.81778463,\r\n       15.90807102, 16.54180802,  9.72382843, 12.55018744, 18.66538505,\r\n       14.12218699, 16.07868894, 16.78719248, 14.62442594, 13.75282842,\r\n       14.99761168, 15.03783427, 14.27056807, 16.16210116, 13.69296913,\r\n       13.15433588, 12.10642037, 16.20606582, 14.43415043, 15.50674275,\r\n       11.78615295, 16.98255085, 12.85922062, 16.99449683, 16.04173898,\r\n       13.04526783, 15.16403697, 12.41054094, 12.31480103, 11.12920639,\r\n       11.95106865, 15.33219068, 15.29325268, 17.11912611, 16.38430841,\r\n       16.42321664, 15.59382692, 15.62483795, 16.37498146, 14.81277388,\r\n       11.41984531, 16.65281343, 16.24207472, 12.33090234, 14.04958031,\r\n       13.56046597,  9.77920134, 17.14664017, 15.30834804, 17.09730826,\r\n       17.42639913, 10.23192444, 17.83917032, 15.71656791, 17.16877889,\r\n       17.51382054, 12.5266411 , 12.42189406, 15.37242623, 12.26308884,\r\n       14.56522079, 15.50719864, 17.70016005, 14.54565711, 14.03638541,\r\n       14.40023135, 15.34168996, 14.06260426, 14.09837307, 13.55620031,\r\n       13.31561571, 11.77449685, 14.35316372, 11.68368463, 12.70896655,\r\n       16.96273263, 17.18327195, 15.31810677, 17.18160181, 17.91242176,\r\n       13.89767677, 15.99439879, 15.67874263, 15.7446655 , 16.77814507,\r\n       13.6435891 , 14.29909062, 16.02303753, 17.839913  , 14.06188348,\r\n       15.55487441, 13.68890331, 16.59235063, 18.09838247, 15.71953121,\r\n       15.25112997, 13.57896806, 15.37576086, 17.45291423, 20.11918434,\r\n       16.12731317, 15.45666257, 13.68285782, 18.64142779, 12.14268845,\r\n       16.46314095, 16.25997648, 14.66688155, 14.70714455, 14.76923382,\r\n       11.72751806, 13.68530057, 14.92277569, 11.07046149, 12.72104758,\r\n       12.98482659, 17.58429113, 15.99073978, 13.43544977, 18.69234598,\r\n       14.84336723, 15.12060768, 14.31706031, 14.58665473, 13.76512549,\r\n       15.85081985, 15.30140448, 18.04480318, 15.08925922, 17.51522465,\r\n       17.95444985, 13.41934251, 11.70880936, 13.35172043, 13.53475005,\r\n       13.56671293, 14.70737457, 12.6153039 , 15.72557143, 14.90522706,\r\n       14.21843627, 18.77903872, 12.76594785, 15.61971463, 14.6889779 ,\r\n       13.969816  , 14.5729719 , 15.46741071, 13.33188159, 14.23350787,\r\n       14.4415353 , 19.15806876, 16.90348241, 13.70313212, 15.44395014,\r\n       14.45454557, 15.19074564, 11.82453   , 14.70613513, 14.75531561,\r\n       15.72858435, 18.97298268, 13.51229612, 17.07587799, 15.93511535,\r\n       15.24722422, 15.23728718, 12.58921945, 10.85929688, 11.89640068,\r\n       14.54025533, 14.2997771 , 17.40434771, 11.96244915, 13.85945968,\r\n       17.33132999, 14.09464391, 17.1253941 , 17.52060678, 15.35108495,\r\n       19.00945147, 18.79272869, 17.72657585, 15.7887491 , 16.17519563,\r\n        9.69895932, 14.40390184, 16.76415208, 15.42754228, 14.46592858,\r\n       15.13913026, 13.91902908, 13.50909755, 19.00058762, 15.31635024,\r\n       14.41014742, 14.80363192, 14.99180588, 15.52182912, 16.56562083,\r\n       15.21607135, 16.54914833, 13.02036948, 14.78979509, 14.27107689,\r\n       12.14808518, 12.69683024, 14.24734477, 14.80439324, 14.22078229,\r\n       14.70372873, 13.3061228 , 13.58245981, 15.11597393, 19.69758376,\r\n       15.25364429, 14.92435839, 13.30903773, 16.36004287, 13.98449971,\r\n       14.64217704, 16.01202828, 15.716588  , 17.56054755, 17.55086499,\r\n       12.38190566, 13.48456052, 16.84837075, 13.62337486, 16.79015597,\r\n       15.75933199, 11.26453129, 17.52503773, 13.19424478, 12.14189765,\r\n       17.6250098 , 18.96945085, 16.05613273, 13.65344302, 13.76066149,\r\n       17.18967718, 12.71054186, 12.70117192, 12.86741486, 11.59828213,\r\n       16.70092624, 16.87376745, 15.48491628, 10.53629326, 13.52132357,\r\n       18.55053905, 14.23542848, 14.28497174, 12.77206081, 16.92931401,\r\n       12.93095286, 13.76350925, 16.08334046, 11.87303232, 17.13324662,\r\n       18.55324309, 14.70649092, 16.54581583, 15.81310011, 16.9190209 ,\r\n       12.22598561, 14.9042106 , 14.4483978 , 16.55466627, 12.18746873,\r\n       14.01478395, 15.97562161, 15.92317466, 13.38960252, 11.08887744,\r\n       18.67472721, 15.88101865, 16.48638823, 16.92333016, 18.9047692 ,\r\n       15.15011755, 16.39477291, 17.14014831, 12.24585512, 15.66324872,\r\n       16.67533613, 16.7862491 , 16.52815271, 13.46872022, 15.91976594,\r\n       16.88655378,  9.69837751, 12.40972231, 15.27992066, 17.55262583,\r\n       14.94207767, 14.39809022, 14.59303184, 17.22689031, 13.54126227,\r\n       15.98482666, 16.25097333, 16.67613843, 14.36355646, 14.17019339,\r\n       16.39811977, 14.50832586, 17.12167015, 14.78867824, 14.77225068,\r\n       15.6880378 , 14.53290849, 12.73756858, 14.11401387, 16.48663495,\r\n       16.51899378, 14.73688133, 16.86616402, 15.78347272, 14.49398257,\r\n       13.11228957, 16.62951465, 15.81885346, 20.17788222, 17.09465854,\r\n       16.19085684, 12.13291911, 16.28018772, 16.18597853, 13.14392952,\r\n       16.70778587, 14.12829523, 13.75897567, 14.20016529, 17.21667714,\r\n       14.15760673, 17.18191141, 16.20199592, 18.60126191, 16.29716804,\r\n       13.64327913, 14.58300616, 16.83138834, 15.12081844, 14.93819912,\r\n       15.99541098, 13.77019604, 16.42285947, 16.09248342, 12.16055477,\r\n       14.49072814, 15.53641245, 15.89379527, 14.98200864, 18.20027637,\r\n       16.28311681, 16.43113239, 16.09044766, 15.43505773, 13.70873429,\r\n       14.21354546, 15.10743202, 16.55608208, 10.49151039, 14.90987699,\r\n       16.09925059, 14.00013502, 15.51875486, 17.52537849, 18.21225235,\r\n       12.32415063, 15.03377047, 17.82667677, 17.07976868, 13.27822793,\r\n       17.54734795, 11.56974359, 15.02960354, 13.33524014, 17.62107537,\r\n       12.25060225, 13.13459443, 17.84187603, 17.76684755, 14.20296835,\r\n       14.7235011 , 13.32933504, 17.06180277, 13.23793474, 16.07018593,\r\n       15.123201  , 14.92971795, 18.11572738, 12.75823843, 15.3800293 ,\r\n       15.78587744, 15.00412582, 15.85211564, 12.63001816, 16.78597569,\r\n       13.96368376, 15.63022264, 16.72443285, 16.08433963, 12.94883324,\r\n       14.58714134, 11.84650257, 14.27404571, 12.70473631, 13.54122971,\r\n       19.48059579, 13.65089731, 17.01126151, 11.70451937, 14.2635545 ,\r\n       16.89572939, 13.87875793, 13.68883338, 15.20865993, 13.6374857 ,\r\n       14.20467706, 16.72863484, 14.94295007, 17.19686345, 17.80558351,\r\n       16.54686288, 16.6791424 , 15.2514436 , 11.23873965, 11.66092587,\r\n       16.07785773, 14.55141927, 16.52261467, 17.4156384 , 14.3817449 ,\r\n       10.54378907, 12.83433893, 13.69968403, 14.51577998, 14.37395008,\r\n       12.34263169, 13.80302716, 12.44750688, 14.48102078, 17.99011399,\r\n       13.63158991, 17.24020796, 13.13809227, 16.49790321, 13.45228438,\r\n       15.67591157, 12.43451515, 15.84541829, 15.89532749, 17.37208547,\r\n       16.46695306, 14.75065439, 13.91875165, 16.37252077, 12.7592184 ,\r\n       14.00468738, 16.05665208, 16.26710105, 14.00257834, 15.56162516,\r\n       19.87394657, 15.26134509, 12.84573913, 11.51137591, 12.58087094,\r\n       14.81570215, 15.40212906, 15.65569854, 18.22075744, 16.3644497 ,\r\n       11.78705423, 15.32539651, 13.48434017, 14.07938244, 17.04261085,\r\n       11.27318791, 14.97551173, 14.41943309, 15.46431837, 12.98647222,\r\n       11.97432108, 16.30395132, 12.53040865, 15.53152612, 16.67085076,\r\n       10.73892455, 17.85199976, 14.85176337, 14.6950218 , 14.91803704,\r\n       16.58238953, 16.48804959, 14.43843199, 16.78512758, 18.62138906,\r\n       16.50131195, 14.83483768, 14.57309716, 13.86762099, 11.69314217,\r\n       14.05183665, 17.58779618, 16.69561263, 12.01902672, 14.31138358,\r\n       12.31033518, 14.44584117, 13.05069615, 13.65296528, 16.93398238,\r\n       18.89836622, 15.31534966, 15.61245953, 16.41271727, 17.24444218,\r\n       12.414273  , 15.48533277, 14.94320504, 16.19782935, 15.97042862,\r\n       11.83228295, 16.52614607, 14.2188729 , 13.58019854, 11.76037103,\r\n       15.65355337, 15.59416348, 18.15903598, 14.84148331, 13.63933079,\r\n       15.18387327, 16.781849  , 17.51992647, 14.74073264, 14.44633616,\r\n       14.39539359, 13.33762793, 14.5184211 , 15.16595844, 15.56114179,\r\n       11.830351  , 15.56222157, 16.20720004, 16.47914425, 16.97565403,\r\n       14.39756557, 17.22524   , 17.1504855 , 11.01802073, 16.49238788,\r\n       12.80600889, 16.54673297, 15.77592331, 16.25665356, 15.50079692,\r\n       17.5582156 , 14.99748064, 16.26739674, 12.32531127, 13.30074347,\r\n       17.33843248, 13.7768121 , 18.05829639, 14.63179052, 14.86973022,\r\n       13.70535958, 14.36368206, 13.18351822, 12.34710333, 16.50430294,\r\n       13.86987847, 15.13857046, 19.17208749, 16.71013226, 17.09053684,\r\n       14.84015727, 17.0950148 , 14.04495617, 12.22834011, 13.98041076,\r\n       12.64856154, 13.32385834, 13.94342379, 17.11530422, 13.49626372,\r\n       11.39739413, 15.86642271, 10.96527532, 12.07081337, 17.2485325 ,\r\n       20.92811262, 17.70985998, 16.8065843 , 13.81195415, 15.93424331,\r\n       15.23681773, 14.31031454, 15.56992072, 12.04180292, 15.3697605 ,\r\n       16.86951457, 15.60902888, 16.87977582, 12.39783713, 16.38544372,\r\n       15.8139527 , 15.29619918, 14.6726904 , 13.86013021, 12.63238785,\r\n       13.73662667, 15.87213465, 13.83805107, 15.21811128, 14.90332571,\r\n       13.53701621, 14.04097312, 15.76812871, 13.83973039, 17.28521939,\r\n       13.47469674, 14.1177997 , 14.12693192, 12.9142475 , 14.27661277,\r\n       13.97385433, 13.24337892, 15.1009523 , 11.95043796, 16.52953875,\r\n       13.62532247, 15.49521364, 15.33914596, 16.38929726, 12.88793796,\r\n       11.15567302, 16.64557637, 14.68997069, 14.93505371, 16.18656473,\r\n       15.07251766, 17.61400545, 13.43287976, 17.0074887 , 13.24157433,\r\n       14.29942856, 20.53436581, 15.41770513, 17.05221906, 14.60800045,\r\n       11.74545502, 12.96711155, 17.51824785, 14.76156279, 17.41246121,\r\n       17.36742631, 14.48471052, 17.12777726, 14.58387559, 14.67958949,\r\n       14.19750572, 15.11708437, 15.93615741, 16.35904896, 13.53603631,\r\n       17.13665445, 13.55112327, 14.80753459, 15.47853327, 13.08014697,\r\n       16.87670046, 15.90665794, 12.07177624, 15.6608798 , 18.24189587,\r\n       14.02283631, 17.65780669, 14.19194595, 16.67617576, 13.85230284,\r\n       15.29371128, 12.79833536, 16.52433976, 15.52070388, 18.65442987,\r\n       13.93590127, 18.44577952, 17.30402767, 14.01493338, 14.3400785 ,\r\n       15.05897038, 15.05027946, 13.60611597, 16.56685618, 14.0832172 ,\r\n       14.34944742, 13.52417802, 15.98423919, 12.16630718, 16.1962614 ,\r\n       15.1411768 , 13.93820881, 14.33963614, 11.70182622, 17.87259152])\r\n```", "I tried that call, and with my version I get this:\r\n\r\n```\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-2-a739f37bf140> in <module>\r\n----> 1 tnp.experimental_enable_numpy_behavior()\r\n\r\nAttributeError: module 'tensorflow.experimental.numpy' has no attribute 'experimental_enable_numpy_behavior'\r\n```", "> I tried that call, and with my version I get this:\r\n> \r\n> ```\r\n> AttributeError                            Traceback (most recent call last)\r\n> <ipython-input-2-a739f37bf140> in <module>\r\n> ----> 1 tnp.experimental_enable_numpy_behavior()\r\n> \r\n> AttributeError: module 'tensorflow.experimental.numpy' has no attribute 'experimental_enable_numpy_behavior'\r\n> ```\r\n\r\n`experimental_enable_numpy_behavior` only exists and is necessary in `tf-nightly`. If you're using other versions, you can keep using `tnp` in the old way.", "Found the culprit: matplotlib 3.3.4 gives the bad image, while 3.2.2 gives the good image.", "Opened a bug report with Matplotlib:\r\n\r\nhttps://github.com/matplotlib/matplotlib/issues/19574", "Matplotlib closed the bug report, basically saying \"the TF output format is wrong, please fix it\".\r\n\r\n> please convert to a numpy array or list of lists or list of numpy arrays. Nothing else is documented or guaranteed to work. While we don't try to break things, passing other objects are not guaranteed to be stable.", "FWIW (I am not a matplotlib dev) the claim isn't that the TF output format is *wrong*, just that the TF output format isn't *numpy*, which is all they claim to support.\r\n\r\nIn debugging this I did notice one difference between the numpy objects and the TF emulation, which is part of why this doesn't work as expected in matplotlib (which thinks the 1D input it gets from TF is a collection of vectors):\r\n\r\n```\r\nfrom collections.abc import Iterable\r\nprint(isinstance(labels1[0], Iterable))\r\nprint(isinstance(labels2[0], Iterable))\r\n```\r\n\r\nI don't know how tight of an emulation of numpy TF is aiming for, but I thought I'd mention it.\r\n\r\nBTW it works fine with seaborn\r\n\r\n```python\r\nimport seaborn as sns\r\nsns.histplot(labels1)\r\n```\r\n\r\n![image](https://user-images.githubusercontent.com/315810/109227828-f0909280-778e-11eb-9ffc-7d1ca7ad0171.png)\r\n\r\n\r\nThe problem isn't any deep incompatibility with matplotlib, just a quirk of how they detect the nested dataset format that `plt.hist` can accept.", "The root cause is that `_reshape_2D` in `matplotlib` used to do an `np.asarray` on the input first but https://github.com/matplotlib/matplotlib/commit/ac018af76cae81054dd27c2d4039dfd5467a1366 removed that. Currently it still recognizes an object with a `to_numpy` method as numpy array, but not those with `__array__`, which is TF's way to emulate numpy array.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46274\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46274\">No</a>\n"]}, {"number": 46273, "title": "Are mean and standard deviation values always 127.5 and 127.5", "body": "In the example label_image.cc (under) lite/examples/label_image, we are hardcoding mean and standard deviation to 127.5f.\r\nWill these values work for any model ?\r\nCan these values obtained run time ?\r\nTo change these mean and standard deviation ? what is the place to change , training ? (or) conversion (or) Inference ?\r\n", "comments": ["@pranathibl \r\nWe see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced]", "Sure,\r\ntensor flow version 2.4.0\r\nUsing example label_image.cc in tfLite examples.", "Did you try changing the values in [label.h](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/label_image/label_image.h) and test?\r\nThis [Stack Overflow](https://stackoverflow.com/questions/57963341/why-does-the-tensorflow-lite-example-use-image-mean-and-image-std-when-adding-pi) thread may help you understand the behavior.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 46272, "title": "use of interpreter-->SetNumThreads. Do we need to invoke setNumThreads always to improve performance", "body": "In the label_image.cc example from tfLite, we are passing setNumThreads manually under the code.\r\nDoes number of threads automatically picked by tfLite (or) Is it required by user to always force SetNumThreads ?\r\n", "comments": ["Hi @pranathibl, it's determined automatically when not specified (equal to calling `setNumThreads(-1)`).\r\n\r\nFor simple questions in the future, please use stackoverflow :)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46272\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46272\">No</a>\n"]}, {"number": 46271, "title": "TFLite: iOS: Ensure we use the iOS mktemp", "body": "It's fairly common for iOS developers to have mktemp from coreutils\r\ninstalled and sitting in front of the iOS mktemp on their PATH. Since the\r\ncoreutils version has different flags, trying to build tflite from source\r\nresults in the following error:\r\n\r\n    ERROR: /Users/mgalgs/development/tensorflow/tensorflow/lite/ios/BUILD:49:28: Executing genrule //tensorflow/lite/ios:TensorFlowLiteC_framework failed (Exit 1): bash failed: error executing command /bin/bash -c ... (remaining 1 argument(s) skipped)\r\n    mktemp: too few X's in template 'framework'\r\n    Target //tensorflow/lite/ios:TensorFlowLiteC_framework failed to build\r\n\r\nFix this by using the mktemp from /usr/bin/ explicitly.", "comments": []}, {"number": 46270, "title": "Refactor case BuiltinOperator_GATHER_ND in flatbuffer_conversions", "body": "PR1 for issue #46268.", "comments": ["@rsun-bdti  Can you please resolve conflicts? Thanks!"]}, {"number": 46269, "title": "tensorrt not working with cuda 11.2", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.4.0\r\n- Python version: 3.9.1\r\n- Bazel version (if compiling from source): 3.7.2\r\n- GCC/Compiler version (if compiling from source):  7.5.0\r\n- CUDA/cuDNN version: 11.2 / 8.0.5\r\n- GPU model and memory:  GTX1080Ti 11GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\ntf workfs fine, but tftrt no\r\n\r\n**Describe the expected behavior**\r\n```\r\n2021-01-08 10:32:10.702646: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvrtc.so.11.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/usr/local/cuda/lib64:/usr/local/cuda/lib64:\r\n```\r\nafter add soft link\r\n\r\n```\r\n2021-01-08 10:41:23.887753: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libnvinfer.so.7'; dlerror: /usr/local/cuda/lib64/libnvrtc.so.11.1: version `libnvrtc.so.11.1' not found (required by /usr/lib/x86_64-linux-gnu/libnvinfer.so.7); LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/local/cuda/lib64:/usr/local/cuda/lib64:\r\n```\r\n\r\n**Standalone code to reproduce the issue**\r\nany tensorrt example code\r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@alanpurple,\r\nIn order to expedite the trouble-shooting process, could you please provide a minimal code snippet to reproduce the issue reported here along with the complete error log. \r\n\r\nAlso, please check if you are facing the same issue with **CUDA 11.0** and **cuDNN 8** as well? Thanks!", "no issue with cuda 11.1,  cudna 8.0.5 and tensorrt 7.2.2.3\r\n\r\nminimal code is \r\n\r\n```\r\nimport tensorflow.experimental.tensorrt as trt\r\nconversion_params = trt.ConversionParams(max_workspace_size_bytes=(1<<32),precision_mode=\"FP16\",maximum_cached_engines=100)\r\nconverter = trt.Converter(\r\n    input_saved_model_dir='./testmodel/1',\r\n    conversion_params=conversion_params)\r\nconverter.convert()\r\ndef my_input_fn():\r\n    for x,y in train_ds.take(1000):\r\n        yield (x,)\r\nconverter.build(input_fn=my_input_fn)\r\nconverter.save('./trt3')\r\n```\r\n\r\n\r\nsomething like this", "> no issue with cuda 11.1, cudna 8.0.5 and tensorrt 7.2.2.3\r\n\r\n@alanpurple,\r\nThank you for the update. Since TensorFlow v2.4 is built and tested against CUDA 11.0 and cuDNN 8, I'd suggest you to use CUDA 11.0 for now.\r\n\r\nSupport for CUDA 11.2 is already being tracked in issue [#46093](https://github.com/tensorflow/tensorflow/issues/46093). Please feel free to close the issue if resolved. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46269\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46269\">No</a>\n", "Drive by comment: you need to install libnvrtc.so.11.1, see https://github.com/NVIDIA/TensorRT/issues/1064"]}, {"number": 46268, "title": "Micro: port op GATHER_ND from Lite", "body": "@tensorflow/micro\r\n\r\n**System information**\r\nHost OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\nTensorFlow installed from (source or binary): source\r\nTensorflow version (commit SHA if source): master\r\nTarget platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): Sparkfun Edge\r\n\r\n**Describe the problem**\r\nI am about to port The TF Lite kernel op GATHER_ND to TF Lite Micro.\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\nPR 1: refactor flatbuffer_conversions parsing function\r\nPR 2: refactor reference implementation from lite/kernels/internal/reference/reference_ops.h into its own header without making any changes.\r\nPR 3: copy the reference kernel from lite to micro without making any changes. At this point the kernel is in micro but it is not part of the build.\r\n", "comments": ["Closing this issue. GATHER_ND has been ported into TFLM."]}, {"number": 46267, "title": "Remove unneccessary define.", "body": "@pnikam-cad confirmed that this will no longer be needed: https://github.com/tensorflow/tensorflow/pull/46238#discussion_r553364064\n", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 46265, "title": "Have artifcat directory be different for different build_types.", "body": "Fixes #46261\n", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 46264, "title": "Minor improvement in _NormalizingCombiner to use MEAN_IDX and VAR_IDX", "body": "This is a minor improvement to `_NormalizingCombiner` to use `self.MEAN_IDX` and `self.VAR_IDX` when getting items from `accumulator`.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F46264) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!"]}, {"number": 46263, "title": "Fix a minor formatting error in lite/kernels/expand_dims.cc", "body": "No related issue since it's a small cleanup.", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 46262, "title": "[tf.data service] Test split provider failures with distributed and zipped datasets", "body": "This PR extends the test cases for `data_service_ops` by adding the following tests:\r\n- Test the failing case of creating a split provider for a `ZipDataset`\r\n- Test the failing case of creating a split provider for a `DataServiceDataset`.\r\n\r\ncc: @aaudiber", "comments": ["@aaudiber I have simplified the tests as per the comments and retained only the ones where we cover the split-provider failures. Updated the description as well."]}]