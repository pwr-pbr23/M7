[{"number": 48253, "title": "fix the TFLM github CI.", "body": "Fixes #48254.", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 48252, "title": "Update runtime version to 2.5.0 for newly added kernels' versions", "body": "This is necessary to correctly reflect the minimum runtime version for these newly added features", "comments": ["Should this be a cherrypick from master? We don't want to have to change the same lines again on 2.6, right?", "This is cl is the same as cherry-picking from master.\r\nActually, I made this pr then cherry-pick to the master.", "I changed the commit message to \"Merging\" but I am also not sure if it must be fixed that way.", "The cherrypick process requires the change to be in master first so that we have time to fully test it against nightly builds before taking into the release branch, as release testing is very expensive (18 hours or more).\r\n\r\nThen, the commits on release branch have to have a reference to the original changelist as there are teams that use this in the automation for their release.\r\n\r\nAs such, let's close this PR and follow the proper procedure for cherrypicking."]}, {"number": 48251, "title": "Corstone download appears occasionally fail", "body": "\r\nHere is one CI run where the corstone download failed unexpectedly:\r\nhttps://source.cloud.google.com/results/invocations/d8f3e531-377b-4e7a-b7e6-18a039a7eedb/log\r\n\r\n```\r\ntensorflow/lite/micro/tools/make/downloads/flatbuffers already exists, skipping the download.\r\ntensorflow/lite/micro/tools/make/downloads/pigweed already exists, skipping the download.\r\n--2021-04-01 21:36:06--  https://developer.arm.com/-/media/Arm%20Developer%20Community/Downloads/OSS/FVP/Corstone-300/FVP_Corstone_SSE-300_Ethos-U55_11.12_57.tgz\r\nResolving developer.arm.com (developer.arm.com)... 23.6.139.135\r\nConnecting to developer.arm.com (developer.arm.com)|23.6.139.135|:443... connected.\r\nHTTP request sent, awaiting response... 200 OK\r\nLength: 419 [text/html]\r\nSaving to: \u2018/tmp/tmp.Q0ggPBjdiR/temp_file\u2019\r\n\r\n     0K                                                       100% 8.59M=0s\r\n\r\n2021-04-01 21:36:12 (8.59 MB/s) - \u2018/tmp/tmp.Q0ggPBjdiR/temp_file\u2019 saved [419/419]\r\n\r\ntensorflow/lite/micro/tools/make/targets/cortex_m_corstone_300_makefile.inc:7: *** Something went wrong with the Arm Corstone-300 software download: Bad checksum. Expected: 08cc89b02a41917c2224f390f3ac0b47, Got: 97e661159b989fa04a4c122a981758ef.  Stop.\r\n```\r\n", "comments": ["I am not able to reproduce this. Anyway perhaps we can add a retry loop.", "OK, thanks for looking into it.\r\n\r\nLet's keep this bug open awithout changing anything. I have only seen this issue twice and it might be worth waiting for now.", "Hi @advaitjain - have you seen this lately? How about closing it?", "I haven't seen this since. Closing."]}, {"number": 48250, "title": "Update convolutional.py", "body": "Updating `stride` argument in `SeparableConv2D` class as it currently supports  equal \r\n      length strides in the row and column dimensions.\r\n\r\nFixes the issue https://github.com/tensorflow/tensorflow/issues/45259", "comments": []}, {"number": 48249, "title": "[INTEL MKL]  Setting default value for KMP_BLOCKTIME", "body": "To improve overall user experience and performance, this PR sets KMP_BLOCKTIME to 1, if not set already by user.", "comments": ["@alenik01 This PR has changes that could affect `--config=mkl_aarch64` build. Could you please help check if things are okay on your end? (I plan to cherry-pick this into TF 2.5.)", "Good morning, @penpornk Many thanks for the heads up. Mmain problem which I encounter with this commit is that it doesn't build even with `--config=mkl`, because Bazel for some reason fails to find `external/llvm_openmp/include/omp.h`. The similar situation is also for `--config=mkl_aarch64`. Did you manage to build the master after merging this commit?\r\n\r\n>Execution platform: @local_execution_config_platform//:platform\r\n>tensorflow/core/common_runtime/threadpool_device.cc:19:10: fatal error: external/llvm_openmp/include/omp.h: No such file or directory\r\n>   19 | #include \"external/llvm_openmp/include/omp.h\"\r\n>     |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n>compilation terminated.\r\n>Target //tensorflow/tools/pip_package:build_pip_package failed to build", "Good morning, @alenik01! We decided not to cherry-pick this PR into 2.5 for now. \r\n\r\n> Did you manage to build the master after merging this commit?\r\n\r\nI didn't try building it manually, but the [oneDNN CI test for this PR was fine](https://tensorflow-ci.intel.com/job/tensorflow-mkl-linux-cpu-pr/8858/).", "Good afternoon, @penpornk \r\n\r\n>Could you please help check if things are okay on your end?\r\n\r\nI have checked `--config=mkl_aarch64` with the current TF `master` and it works correctly on AArch64 server. The only disadvantage for us is that additional `--cxxopt=\"-DDNNL_AARCH64_USE_ACL=1\"` has to be added now in the build command, _i.e._ defined globally for all the build instead of the necessary files only, I will try to find a more elegant solution."]}, {"number": 48248, "title": "[INTEL MKL] update oneDNN version in TensorFlow to v2.2 official release", "body": "", "comments": []}, {"number": 48247, "title": "[Intel MKL] added threadpool config and changed dnnl run to use the blockformat.", "body": "", "comments": ["@gbaned  this error with community build is due to branch checkout issue nothing to do with this PR. Can you please review this PR."]}, {"number": 48246, "title": "[TF:TRT] ConvertSplit for dynamic shapes.", "body": "@tfeher @bixia1 for review\r\nFix SqueezeTensor to ensure that the TRT layers generated by ConvertSplit have unique names.\r\n\r\nAdd tests for ConvertSplit dynamic shapes.  ", "comments": ["@DEKHTIARJonathan Can you please check @bixia1's comments and keep us posted ? Thanks!", "@DEKHTIARJonathan  Any update on this PR? Please. Thanks!", "Still under work, please do not close", "@DEKHTIARJonathan  Can you please resolve conflicts? Thanks!", "@bixia1 finally fixed sorry for the delay, please review and let me know if we are good to go\r\n\r\n```\r\nINFO: Build completed successfully, 2592 total actions\r\n//tensorflow/compiler/tf2tensorrt:convert_graph_test                     PASSED in 6.4s\r\n//tensorflow/compiler/tf2tensorrt:convert_graph_test_gpu                 PASSED in 6.2s\r\n//tensorflow/compiler/tf2tensorrt:convert_nodes_test                     PASSED in 153.9s\r\n//tensorflow/compiler/tf2tensorrt:convert_nodes_test_gpu                 PASSED in 168.5s\r\n//tensorflow/compiler/tf2tensorrt:segment_test                           PASSED in 0.2s\r\n//tensorflow/compiler/tf2tensorrt:segment_test_gpu                       PASSED in 0.1s\r\n//tensorflow/compiler/tf2tensorrt:tensorrt_test_cc                       PASSED in 3.9s\r\n//tensorflow/compiler/tf2tensorrt:tensorrt_test_cc_gpu                   PASSED in 3.9s\r\n//tensorflow/compiler/tf2tensorrt:trt_allocator_test                     PASSED in 0.1s\r\n//tensorflow/compiler/tf2tensorrt:trt_engine_op_test                     PASSED in 2.7s\r\n//tensorflow/compiler/tf2tensorrt:trt_engine_op_test_gpu                 PASSED in 2.4s\r\n//tensorflow/compiler/tf2tensorrt:trt_engine_resource_ops_test           PASSED in 2.4s\r\n//tensorflow/compiler/tf2tensorrt:trt_engine_resource_ops_test_gpu       PASSED in 2.2s\r\n//tensorflow/compiler/tf2tensorrt:trt_lru_cache_test                     PASSED in 0.1s\r\n//tensorflow/compiler/tf2tensorrt:trt_shape_optimization_profiles_test   PASSED in 6.9s\r\n//tensorflow/compiler/tf2tensorrt:trt_shape_optimization_profiles_test_gpu PASSED in 7.0s\r\n\r\nINFO: Build completed successfully, 9 total actions\r\n//tensorflow/python/compiler/tensorrt:trt_convert_test                   PASSED in 58.4s\r\n//tensorflow/python/compiler/tensorrt:trt_convert_test_gpu               PASSED in 58.5s\r\n```", "The PR title is : ConvertSplit for dynamic shapes.\r\nOn the other hand, this PR does NOT enable dynamic shape for ConvertSplit. Instead, it only fixes a bug that is related to the layer names generated by ConvertSplit. Am I right here?", "@DEKHTIARJonathan  Can you please check @bixia1's comments and keep us posted ? Thanks!", "@DEKHTIARJonathan  Can you please resolve conflicts? Thanks!\r\n"]}, {"number": 48245, "title": "Modify Side Input Data Types for cuDNN BatchNorm", "body": "Side inputs for cuDNN Fused BatchnormForward have been taking the incorrect data type till now. It should be the same data type as the input. This PR aims to correct that in the `stream_executor` and `core/kernels`.", "comments": ["@AyanmoI  Can you please check @sanjoy's comments and keep us posted ? Thanks!", "Hi @sanjoy, I think this is an obvious wrong use of data type of side input. As shown below, the side_input should be T but we convert it later to U:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/nn_ops.cc#L228\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/fused_batch_norm_op.cc#L913.\r\n\r\nUnfortunately or fortunately, it is hard to write a unit test case to hit it, because we've limit the U to be float, which is wider than or equal to the T (half or float). So, always using U/float for the side_input would be actually \"safe\" enough when we use the AsDeviceMemory<U> to convert a half tensor to obtain its raw pointer. However, this bug can be encountered when we want to explicitly call the `ThenBatchNormalizationForward` as shown in tensorflow/compiler/xla/service/gpu/cudnn_batchnorm_runner.cc from this PR.", "@sanjoy  Can you please assist on above comments from @kaixih. Thanks!", "@nluehr for vis."]}, {"number": 48244, "title": "[TF-TRT] Enable INT8 calibration for use_implicit_batch=false when there is no dynamic shape inputs", "body": "@tfeher @bixia1\r\nPreviously we disable INT8 calibration when use_implicit_batch=false. This PR partially enable INT8 calibration for use_implicit_batch=false, that is, when the engine has only static input shapes.", "comments": ["@DEKHTIARJonathan Can you please check @bixia1s comments and keep us posted ? Thanks!", "@DEKHTIARJonathan Any update on this PR? Please. Thanks!", "Still under work, please do not close", "@bixia1 : sorry I totally forgot to update this PR.\r\nI now applied all the changes you requested. Let me know if we need anything else"]}, {"number": 48243, "title": "[TFLM] Sub kernel refactoring", "body": "In preparation for adding support for an optimized version of SUB for CEVA-DSP cores, refactoring and separation of sub into sub.cc and sub_common.cc to allow for reference fallback from the optimized kernel.\r\n\r\nRemoved uint8 support as well.\r\n", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "With https://github.com/tensorflow/tensorflow/pull/48789, you should be able to see the cause of the TfLite Micro CI failure again.", "@yair-ehrenwald  Any update on this PR? Please. Thanks!", "With TFLM moving to its own GitHub repository, we are not going to be merging any TFLM specific pull requests in the TensorFlow repository starting today.\r\n\r\nI am closing the current PR but please feel free to open a new PR in https://github.com/tensorflow/tflite-micro/.\r\n\r\nhttps://groups.google.com/a/tensorflow.org/g/micro/c/W4DACgjPmOE\r\n"]}, {"number": 48242, "title": "Ubuntu Debbian to MacOS Terminal Prompt and TF", "body": "Hi,\r\n\r\nI have traditionally used TF 2.3.1 on an linux ubuntu debbian where I ran this project through a jupyter notebook.  No GPU was needed to run anything.  \r\n\r\nI am now working locally on my Mac OS Terminal where I believe I can only conda install TF 2.0.  When I try pip installing an upgrade, I can no longer even import tensorflow.  I get this error importing tensorflow:\r\n\r\nFile \"/Users/blah/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: dlopen(/Users/blah/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: _SecKeyCopyExternalRepresentation\r\n  Referenced from: /Users/blah/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.2.dylib\r\n  Expected in: /System/Library/Frameworks/Security.framework/Versions/A/Security\r\n in /Users/blah/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.2.dylib\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\n\"Traceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/blah/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"/Users/blah/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/__init__.py\", line 40, in <module>\r\n    from tensorflow.python.eager import context\r\n  File \"/Users/blah/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/eager/context.py\", line 35, in <module>\r\n    from tensorflow.python import pywrap_tfe\r\n  File \"/Users/blah/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/pywrap_tfe.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/Users/blah/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 83, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/Users/blah/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: dlopen(/Users/blah/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: _SecKeyCopyExternalRepresentation\r\n  Referenced from: /Users/blah/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.2.dylib\r\n  Expected in: /System/Library/Frameworks/Security.framework/Versions/A/Security\r\n in /Users/blah/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.2.dylib\"\r\n\r\n\r\nAnyways, when I run the identical code with just tensorflow 2.0 in jupyter I am getting an error in my pipeline: \r\n\r\n26     return (0.5 / float(tf.shape(x_true)[0])) * tf.square(tf.linalg.norm(x_true - x_prime))    #original\r\n     27 \r\n     28 \r\n\r\nTypeError: float() argument must be a string or a number, not 'Tensor'\r\n\r\n\r\n\r\nUnfortunately, I am not as well versed in the differences between TFs and installing various versions.  I would prefer not to go through the entire pipeline to change TF syntax but am willing to do so if that is the only work around.  Would anybody have an idea what may be wrong?  Thanks.\r\n\r\n\r\n\r\n \r\n\r\n\r\n\r\n\r\n", "comments": ["@o0stsou0o \r\nCan you please refer to this isue with same error and let us know if it helps: #36945, [link](https://github.com/tensorflow/tensorflow/issues/5141), [link](https://stackoverflow.com/questions/35989572/importerror-dlopen-symbol-not-found-pycodecinfo-getincrementaldecoder)", "Hi Saduf2019,\r\n\r\nI don't think any of the links are helpful though I did post to the first link.  I will add that the version of OSX I am using is 10.11.6 El Capitan.  Thanks.  \r\n\r\n\r\n> @o0stsou0o\r\n> Can you please refer to this isue with same error and let us know if it helps: #36945, [link](https://github.com/tensorflow/tensorflow/issues/5141), [link](https://stackoverflow.com/questions/35989572/importerror-dlopen-symbol-not-found-pycodecinfo-getincrementaldecoder)\r\n\r\n", "@o0stsou0o I am not sure what is the root-cause but the best way to resolve this kind of issue is by removing `conda` and `Tensorflow` completely and re-install TF through `pip`. Unfortunately we don't support conda builds as we don't have any control on those builds. If your error is specific to Anaconda's TF, then post it in Anaconda repo so that some conda experts will resolve your issue faster. Thanks!", "Thank you so much.  I am hoping to install tensorflow 2.3.1 or above.  I've tried with pip.  Unfortunately, if you run pip install --upgrade tensorflow or pip install tensorflow, it installs tensorflow 1.8.0.  If you conda install tensorflow, it gives you tensorflow 2.0.0.  In both cases if you try installing tensorflow==2.3.2 it gives an error upon import tensorflow.  Would you know of what may be the problem?  \r\n\r\n> @o0stsou0o I am not sure what is the root-cause but the best way to resolve this kind of issue is by removing `conda` and `Tensorflow` completely and re-install TF through `pip`. Unfortunately we don't support conda builds as we don't have any control on those builds. If your error is specific to Anaconda's TF, then post it in Anaconda repo so that some conda experts will resolve your issue faster. Thanks!\r\n\r\n", "@o0stsou0o I just tried `pip3 install tensorflow==2.4.1` on Mac OS and it correctly installed `TF2.4.1`.  If you still face it, search `tensorflow` related folders and delete all of them and restart Mac and try the above command. \r\n\r\nIt could be that when you tried `pip install tensorflow`, that `pip` might be connected to `python2.x` and tried to install `TF1.x`. We no longer support `python2.x` and `TF1.x`.\r\n\r\nPlease let me know how it progresses. Thanks!", "Thank you so much.  So I looked at the installation.  Indeed, when I do pip show tensorflow both inside and outside the conda environment, it shows version 2.4.1 in the site-packages in python 3.8.  Unfortunately, when I print the version of tensorflow in python3, I'm getting 1.8.0 (below).  Would you know why?  \r\n\r\n<img width=\"1092\" alt=\"Screen Shot 2021-04-07 at 9 26 28 PM\" src=\"https://user-images.githubusercontent.com/23566009/113954833-9a305e00-97e8-11eb-9444-8311b10955ba.png\">\r\n\r\n\r\n\r\n> @o0stsou0o I just tried `pip3 install tensorflow==2.4.1` on Mac OS and it correctly installed `TF2.4.1`. If you still face it, search `tensorflow` related folders and delete all of them and restart Mac and try the above command.\r\n> \r\n> It could be that when you tried `pip install tensorflow`, that `pip` might be connected to `python2.x` and tried to install `TF1.x`. We no longer support `python2.x` and `TF1.x`.\r\n> \r\n> Please let me know how it progresses. Thanks!\r\n\r\n", "@o0stsou0o Can you create a virtual Environment and install TF through `pip. Instructions are [here](https://www.tensorflow.org/install/pip). Thanks!", "Thank you for your continued correspondence.  So in the virtual environment (not conda), I pip installed --upgrade tensorflow.  I then went into python3 and got the following error importing tensorflow:\r\n\r\n<img width=\"1091\" alt=\"Screen Shot 2021-04-09 at 10 43 05 AM\" src=\"https://user-images.githubusercontent.com/23566009/114197629-8a1b9a00-9920-11eb-8dd2-c47090f04da2.png\">\r\n\r\nThere was a long list of things not uninstalling while pip installing tensorflow though (below):\r\n\r\n<img width=\"848\" alt=\"Screen Shot 2021-04-09 at 10 35 40 AM\" src=\"https://user-images.githubusercontent.com/23566009/114197830-bcc59280-9920-11eb-99ec-00e16cf3c042.png\">\r\n\r\nDo you have an idea what may be the issue?  \r\n\r\n\r\n> @o0stsou0o Can you create a virtual Environment and install TF through `pip. Instructions are [here](https://www.tensorflow.org/install/pip). Thanks!\r\n\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48242\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48242\">No</a>\n"]}, {"number": 48241, "title": "Fix for #48155", "body": "This PR is exactly the patch from @andrewstevens-infineon attached to #48155\r\n", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 48240, "title": "README grammar edits", "body": "A couple of grammar edits for README to improve readability.", "comments": ["We will not be encouraging one liner grammatical changes as this is expensive process, if possible please include more such changes in a single PR.Thank you\r\nCC @mihaimaruseac "]}, {"number": 48239, "title": "Autograph transformation failure with tensorflow 2.4.1", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: 3.7.10\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source): 7.3.0\r\n- CUDA/cuDNN version: 11.2\r\n- GPU model and memory: GTX1080Ti, 11 GB VRAM\r\n\r\n**Describe the current behavior**\r\n\r\ntensorflow asked me to report a bug\r\n\r\n```\r\n $ export AUTOGRAPH_VERBOSITY=10\r\n $ python repro.py\r\n2021-04-01 20:28:34.334930: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\n2021-04-01 20:28:35.704317: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-04-01 20:28:35.705182: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n2021-04-01 20:28:35.871925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:03:00.0 name: GeForce GTX 1080 computeCapability: 6.1\r\ncoreClock: 1.7715GHz coreCount: 20 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 298.32GiB/s\r\n2021-04-01 20:28:35.873276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \r\npciBusID: 0000:04:00.0 name: GeForce GTX 1080 computeCapability: 6.1\r\ncoreClock: 1.7715GHz coreCount: 20 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 298.32GiB/s\r\n2021-04-01 20:28:35.874585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \r\npciBusID: 0000:07:00.0 name: GeForce GTX 1080 computeCapability: 6.1\r\ncoreClock: 1.7715GHz coreCount: 20 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 298.32GiB/s\r\n2021-04-01 20:28:35.875977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: \r\npciBusID: 0000:08:00.0 name: GeForce GTX 1080 computeCapability: 6.1\r\ncoreClock: 1.7715GHz coreCount: 20 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 298.32GiB/s\r\n2021-04-01 20:28:35.876804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 4 with properties: \r\npciBusID: 0000:83:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\r\n2021-04-01 20:28:35.878258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 5 with properties: \r\npciBusID: 0000:84:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\r\n2021-04-01 20:28:35.879686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 6 with properties: \r\npciBusID: 0000:87:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\r\n2021-04-01 20:28:35.881117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 7 with properties: \r\npciBusID: 0000:88:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\r\n2021-04-01 20:28:35.881154: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\n2021-04-01 20:28:35.882875: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\r\n2021-04-01 20:28:35.882923: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\r\n2021-04-01 20:28:35.884498: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2021-04-01 20:28:35.884771: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2021-04-01 20:28:35.886423: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2021-04-01 20:28:35.887438: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\r\n2021-04-01 20:28:35.891003: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\r\n2021-04-01 20:28:35.910781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7\r\n2021-04-01 20:28:35.911152: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-04-01 20:28:37.137066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:03:00.0 name: GeForce GTX 1080 computeCapability: 6.1\r\ncoreClock: 1.7715GHz coreCount: 20 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 298.32GiB/s\r\n2021-04-01 20:28:37.138107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \r\npciBusID: 0000:04:00.0 name: GeForce GTX 1080 computeCapability: 6.1\r\ncoreClock: 1.7715GHz coreCount: 20 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 298.32GiB/s\r\n2021-04-01 20:28:37.139125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \r\npciBusID: 0000:07:00.0 name: GeForce GTX 1080 computeCapability: 6.1\r\ncoreClock: 1.7715GHz coreCount: 20 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 298.32GiB/s\r\n2021-04-01 20:28:37.140194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: \r\npciBusID: 0000:08:00.0 name: GeForce GTX 1080 computeCapability: 6.1\r\ncoreClock: 1.7715GHz coreCount: 20 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 298.32GiB/s\r\n2021-04-01 20:28:37.140952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 4 with properties: \r\npciBusID: 0000:83:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\r\n2021-04-01 20:28:37.142042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 5 with properties: \r\npciBusID: 0000:84:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\r\n2021-04-01 20:28:37.143120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 6 with properties: \r\npciBusID: 0000:87:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\r\n2021-04-01 20:28:37.144269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 7 with properties: \r\npciBusID: 0000:88:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\r\n2021-04-01 20:28:37.144311: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\n2021-04-01 20:28:37.144341: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\r\n2021-04-01 20:28:37.144354: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\r\n2021-04-01 20:28:37.144366: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2021-04-01 20:28:37.144377: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2021-04-01 20:28:37.144389: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2021-04-01 20:28:37.144401: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\r\n2021-04-01 20:28:37.144414: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\r\n2021-04-01 20:28:37.161814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7\r\n2021-04-01 20:28:37.161872: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\n2021-04-01 20:28:40.704083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-04-01 20:28:40.704138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 2 3 4 5 6 7 \r\n2021-04-01 20:28:40.704147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y Y Y N N N N \r\n2021-04-01 20:28:40.704152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N Y Y N N N N \r\n2021-04-01 20:28:40.704159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 2:   Y Y N Y N N N N \r\n2021-04-01 20:28:40.704164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 3:   Y Y Y N N N N N \r\n2021-04-01 20:28:40.704186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 4:   N N N N N Y Y Y \r\n2021-04-01 20:28:40.704211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 5:   N N N N Y N Y Y \r\n2021-04-01 20:28:40.704217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 6:   N N N N Y Y N Y \r\n2021-04-01 20:28:40.704223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 7:   N N N N Y Y Y N \r\n2021-04-01 20:28:40.715354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7424 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1)\r\n2021-04-01 20:28:40.718506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7424 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080, pci bus id: 0000:04:00.0, compute capability: 6.1)\r\n2021-04-01 20:28:40.726289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 7424 MB memory) -> physical GPU (device: 2, name: GeForce GTX 1080, pci bus id: 0000:07:00.0, compute capability: 6.1)\r\n2021-04-01 20:28:40.732324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 7424 MB memory) -> physical GPU (device: 3, name: GeForce GTX 1080, pci bus id: 0000:08:00.0, compute capability: 6.1)\r\n2021-04-01 20:28:40.737468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 130 MB memory) -> physical GPU (device: 4, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)\r\n2021-04-01 20:28:40.741858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:5 with 10269 MB memory) -> physical GPU (device: 5, name: GeForce GTX 1080 Ti, pci bus id: 0000:84:00.0, compute capability: 6.1)\r\n2021-04-01 20:28:40.748570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:6 with 10269 MB memory) -> physical GPU (device: 6, name: GeForce GTX 1080 Ti, pci bus id: 0000:87:00.0, compute capability: 6.1)\r\n2021-04-01 20:28:40.753390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:7 with 10269 MB memory) -> physical GPU (device: 7, name: GeForce GTX 1080 Ti, pci bus id: 0000:88:00.0, compute capability: 6.1)\r\n2021-04-01 20:28:40.754020: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\nWARNING:tensorflow:AutoGraph could not transform <bound method LIFCell.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7ff1b3f268d0>> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: module 'gast' has no attribute 'Constant'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function pre_train_step at 0x7ff1500db3b0> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function voltage_reg_loss at 0x7ff1b3f66c20> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\n2021-04-01 20:28:41.569861: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\r\n2021-04-01 20:28:41.595639: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2394455000 Hz\r\n2021-04-01 20:28:41.782810: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\r\n\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nRun code without being told to report an error. Also, the full code seems to be running a lot slower than expected, but I can't tell if this is because of this warning or some other aspect of the full project.\r\n\r\nBy the way, based on previous github issues, I insured that `gast` version `==0.2.2` is installed.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```py\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nfrom os.path import join as opj\r\n\r\nfrom collections import namedtuple\r\n\r\n\r\ndef pseudo_derivative(v_scaled, dampening_factor):\r\n    '''\r\n    Define the pseudo derivative used to derive through spikes.\r\n    :param v_scaled: scaled version of the voltage being 0 at threshold and -1 at rest\r\n    :param dampening_factor: parameter that stabilizes learning\r\n    :return:\r\n    '''\r\n    return dampening_factor*tf.maximum(1 - tf.abs(v_scaled), 0)\r\n    #return dampening_factor*tf.exp(-2.0*tf.abs(v_scaled))\r\n\r\n\r\n@tf.custom_gradient\r\ndef spike_function(v_scaled, dampening_factor):\r\n    '''\r\n    The tensorflow function which is defined as a Heaviside function (to compute the spikes),\r\n    but with a gradient defined with the pseudo derivative.\r\n    :param v_scaled: scaled version of the voltage being -1 at rest and 0 at the threshold\r\n    :param dampening_factor: parameter to stabilize learning\r\n    :param derivative_width: parameter which will rescale the width of the pseudo-derivative\r\n    :return: the spike tensor\r\n    '''\r\n    z_ = tf.greater(v_scaled, 0.)\r\n    z_ = tf.cast(z_, dtype=tf.float32)\r\n\r\n    grad = lambda dy: [dy*pseudo_derivative(v_scaled, dampening_factor), tf.zeros_like(dampening_factor)]\r\n\r\n    return tf.identity(z_, name=\"SpikeFunction\"), grad\r\n\r\n@tf.function\r\ndef voltage_reg_loss(v_scaled):\r\n\r\n    reg_thresh_pos = 0.4\r\n    reg_thresh_neg = -2.0\r\n\r\n    per_neuron_time_step = tf.nn.relu(v_scaled - 0.4)**2 + tf.nn.relu(-2.0 - v_scaled)**2\r\n\r\n    loss_volt = tf.math.reduce_mean(per_neuron_time_step)**2\r\n\r\n    return loss_volt\r\n\r\n\r\nclass LIFCell(tf.keras.layers.Layer):\r\n\r\n    def __init__(self,\r\n                 n_rec,\r\n                 tau=20.,\r\n                 thr=1.,\r\n                 dt=1,\r\n                 n_refractory=5,\r\n                 dampening_factor=.3):\r\n\r\n        super().__init__(self)\r\n\r\n        self.n_rec = n_rec\r\n\r\n        self._dt = float(dt)\r\n        self._decay = tf.exp(-dt / tau)\r\n        self._n_refractory = n_refractory\r\n\r\n\r\n        self.input_weights = None\r\n        self.bias_currents = None\r\n        self.recurrent_weights = None\r\n        self.disconnect_mask = None\r\n\r\n        self.threshold = thr\r\n        self._dampening_factor = dampening_factor\r\n\r\n    def build(self, input_shape):\r\n\r\n        initializer = tf.keras.initializers.GlorotNormal()\r\n\r\n        self.input_weights = self.add_weight(shape=(input_shape[-1], self.n_rec),\r\n                                             initializer=initializer,\r\n                                             name='input_weights')\r\n\r\n        self.disconnect_mask = tf.cast(np.diag(np.ones(self.n_rec, dtype=np.bool)), tf.bool)\r\n\r\n        self.recurrent_weights = self.add_weight(shape=(self.n_rec, self.n_rec),\r\n                                                 initializer=initializer,\r\n                                                 name='recurrent_weights')\r\n\r\n    @property\r\n    def state_size(self):\r\n        return self.n_rec, self.n_rec, self.n_rec\r\n\r\n    @property\r\n    def output_size(self):\r\n        return self.n_rec, self.n_rec, self.n_rec\r\n\r\n    def zero_state(self, batch_size, dtype=tf.float32):\r\n        v0 = tf.zeros((batch_size, self.n_rec), dtype)\r\n        r0 = tf.zeros((batch_size, self.n_rec), tf.int32)\r\n        z_buf0 = tf.zeros((batch_size, self.n_rec), tf.float32)\r\n        return v0, r0, z_buf0\r\n\r\n    def get_initial_state(self, batch_size, inputs, dtype=tf.float32):\r\n        v0 = tf.zeros((batch_size, self.n_rec), dtype)\r\n        r0 = tf.zeros((batch_size, self.n_rec), tf.int32)\r\n        z_buf0 = tf.zeros((batch_size, self.n_rec), tf.float32)\r\n        return v0, r0, z_buf0\r\n\r\n    @tf.function\r\n    def call(self, inputs, initial_state):\r\n        old_v = initial_state[0]\r\n        old_r = initial_state[1]\r\n        old_z = initial_state[2]\r\n\r\n        no_autapse_w_rec = tf.where(self.disconnect_mask, tf.zeros_like(self.recurrent_weights), self.recurrent_weights)\r\n\r\n        i_in = tf.matmul(inputs, self.input_weights)\r\n        i_rec = tf.matmul(old_z, no_autapse_w_rec)\r\n\r\n        i_reset = -self.threshold * old_z\r\n        input_current = (1.0 - self._decay)*(i_in + i_rec) + i_reset\r\n\r\n        new_v = self._decay * old_v + input_current\r\n\r\n        is_refractory = tf.greater(old_r, 0)\r\n        v_scaled = (new_v - self.threshold) / self.threshold\r\n        new_z = spike_function(v_scaled, self._dampening_factor)\r\n        new_z = tf.where(is_refractory, tf.zeros_like(new_z), new_z)\r\n        new_r = tf.clip_by_value(old_r - 1 + tf.cast(new_z * self._n_refractory, tf.int32), 0, self._n_refractory)\r\n\r\n        new_state = (new_v, new_r, new_z)\r\n        output = (new_v, new_z)\r\n\r\n        return output, new_state\r\n\r\n\r\ndef create_pretrain_model(cell, seq_len=1000, n_input=40):\r\n\r\n    inputs = tf.keras.layers.Input(shape=(seq_len, n_input))\r\n    batch_size = tf.shape(inputs)[0]\r\n\r\n    rnn = tf.keras.layers.RNN(cell, return_sequences=True)\r\n\r\n    initial_state = cell.zero_state(batch_size)\r\n    v, z = rnn(inputs, initial_state=initial_state)\r\n\r\n    return tf.keras.Model(inputs=inputs, outputs=[v, z])\r\n\r\n\r\nif __name__ == '__main__':\r\n\r\n    with tf.device('/GPU:0'):\r\n\r\n        # initialize the cell\r\n        cell = LIFCell(512)\r\n\r\n        # create the model with some inputs\r\n        model = create_pretrain_model(cell, seq_len=1000, n_input=40)\r\n\r\n        # save initial weights\r\n        model.save_weights(opj('ckpt', 'init_weights'))\r\n\r\n        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\r\n\r\n        # optimize the network simply so that \"voltages\" tend to lie within a certain range\r\n        @tf.function\r\n        def pre_train_step(samples):\r\n\r\n            with tf.GradientTape() as tape:\r\n\r\n                v, z = model(samples)\r\n\r\n                scaled_voltage = (v - 1.0)\r\n\r\n                loss = voltage_reg_loss(scaled_voltage)\r\n\r\n            gradients = tape.gradient(loss, model.trainable_variables)\r\n            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n\r\n            return v, z\r\n\r\n        # only 10 iterations\r\n        for i in range(10):\r\n\r\n            # input is irrelevant for reproducing the bug\r\n            samples = tf.random.uniform((100, 1000, 40))\r\n\r\n            # training step\r\n            v, z = pre_train_step(samples)\r\n\r\n        # save pre-trained weights\r\n        model.save_weights(opj('ckpt', 'pretrain_weights'))\r\n```\r\n", "comments": ["@Ebanflo42,\r\nLooking at the output log, seems like this is similar to issue #47802.\r\n\r\nPlease take a look at [this comment](https://github.com/tensorflow/tensorflow/issues/47802#issuecomment-799555152) and let us know if you are still facing the same issue. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48239\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48239\">No</a>\n"]}, {"number": 48238, "title": "tf.meshgrid throws exception when input tensors have different dtypes", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Reproducible on several OS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: See above\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: 3.7.10\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: Reproducible with or without GPU\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nCurrently, the way TensorFlow tests its own `meshgrid` implementation is by comparing the output to the result of NumPy's implementation ([code](https://github.com/tensorflow/tensorflow/blob/32f8688c1c108ab2df794fe4ceb9e058641359b0/tensorflow/python/kernel_tests/array_ops_test.py#L552)).\r\n\r\nIn NumPy's implementation, when you call the function with arrays of different types, the types of the input arrays are mapped to the output arrays:\r\n\r\n```python\r\nnp.meshgrid([1, 2, 3], [4.0, 5.0, 6.0])\r\n[array([[1, 2, 3],\r\n       [1, 2, 3],\r\n       [1, 2, 3]]), array([[4., 4., 4.],\r\n       [5., 5., 5.],\r\n       [6., 6., 6.]])]\r\n```\r\n\r\nNumPy's code even works with tensors:\r\n\r\n```python\r\na = tf.constant([1,2,3])\r\nb = tf.constant([4,5,6], dtype='float32')\r\nnp.meshgrid(a, b)\r\n[array([[1, 2, 3],\r\n       [1, 2, 3],\r\n       [1, 2, 3]], dtype=int32), array([[4., 4., 4.],\r\n       [5., 5., 5.],\r\n       [6., 6., 6.]], dtype=float32)]\r\n```\r\n\r\nHowever, the TensorFlow Python implementation throws an exception:\r\n\r\n```python\r\ntf.meshgrid(tf.constant([0, 1]), tf.constant([2., 3.]))\r\nInvalidArgumentError: cannot compute Mul as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:Mul]\r\n```\r\n\r\nIt seems like this is being thrown by an internal matrix multiplication operation.\r\n\r\n**Describe the expected behavior**\r\n\r\nTensorFlow's Python function to match how NumPy handles inputs with different data types.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```python\r\ntf.meshgrid(tf.constant([0, 1]), tf.constant([2., 3.]))\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nThis was discovered during [code review](https://github.com/tensorflow/tfjs/pull/4855#pullrequestreview-624437214) for implementing `tf.meshgrid` for TensorFlow.js\r\n\r\nI'd also be willing to submit a PR with a patch and an additional unit test to cover this case.\r\n", "comments": ["@ymodak,\r\nI was able to reproduce the issue with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/3643d3263bf159df41177abd2ac1aff3/48238.ipynb). Thanks!", "Thanks for reporting this! Tensorflow has different type promotion rules, and we have an experimental flag to control it.\r\n\r\n```\r\nimport tensorflow.experimental.numpy as tnp\r\nimport tensorflow.compat.v2 as tf\r\ntf.compat.v2.enable_v2_behavior()\r\n\r\ntnp.experimental_enable_numpy_behavior(prefer_float32=True)\r\ntnp.meshgrid(tf.constant([0, 1]), tf.constant([2., 3.]))\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48238\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48238\">No</a>\n", "@kkimdev thanks for the pointer. Is there is a compelling reason to keep the default behavior of throwing an exception?", "Each type promotion rule has a trade-off.  historically, TensorFlow has been conservative and arguably it can reduce unexpected type promotion bugs.  Though this decision is not necessarily final and can be revisited (and there have been some discussions).", "> Each type promotion rule has a trade-off. historically, TensorFlow has been conservative and arguably it can reduce unexpected type promotion bugs.\r\n\r\n@kkimdev that's definitely understandable, in an extreme example users might even call `tf.meshgrid` to verify that tensors have the same type (but that sounds like an anti-pattern to me...)"]}, {"number": 48237, "title": "The new Apple M1 MLcompute Tensorflow2.4 not compatible with Numpy1.20.1 or 1.18.5", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Apple Macbook M1 air):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):Apple M1 MLcompute optimized build\r\n- TensorFlow version:2.4\r\n- Python version:3.9\r\n- Installed using virtualenv? pip? conda?: conda through conda-miniforge\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nI am running the new apple native tensorflow package 2.4, and ran into a problem I did not have before. This jupyter notebook code works in old intel based environment where an older tensorflow version was used. But with M1 apple MLcompute TensorFlow2.4 it is not compatible with Numpy 1.20 or 1.18(I downgraded numpy to try). The error log:**Provide the exact sequence of commands / steps that you executed before running into the \r\n\r\nproblem**\r\nScreen catch error log:\r\n```\r\nNotImplementedError: Cannot convert a symbolic Tensor (lstm_1/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\r\n    ---------------------------------------------------------------------------\r\n    NotImplementedError                       Traceback (most recent call last)\r\n    <ipython-input-20-73358e637fe3> in <module>\r\n          4 model = Sequential()\r\n          5 model.add(Embedding(vocab_size+1, W2V_SIZE, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False))\r\n    ----> 6 model.add(LSTM(500, dropout=0.2, recurrent_dropout=0.2))\r\n          7 model.add(Dense(units = 10000, kernel_initializer = 'glorot_uniform', activation = 'relu'))\r\n          8 model.add(Dropout(0.35))\r\n    ~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n        515     self._self_setattr_tracking = False  # pylint: disable=protected-access\r\n        516     try:\r\n    --> 517       result = method(self, *args, **kwargs)\r\n        518     finally:\r\n        519       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\r\n    ~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py in add(self, layer)\r\n        221       # If the model is being built continuously on top of an input layer:\r\n        222       # refresh its output.\r\n    --> 223       output_tensor = layer(self.outputs[0])\r\n        224       if len(nest.flatten(output_tensor)) != 1:\r\n        225         raise ValueError(SINGLE_LAYER_OUTPUT_ERROR_MSG)\r\n    ~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py in __call__(self, inputs, initial_state, constants, **kwargs)\r\n        658 \r\n        659     if initial_state is None and constants is None:\r\n    --> 660       return super(RNN, self).__call__(inputs, **kwargs)\r\n        661 \r\n        662     # If any of `initial_state` or `constants` are specified and are Keras\r\n    ~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)\r\n        944     # >> model = tf.keras.Model(inputs, outputs)\r\n        945     if _in_functional_construction_mode(self, inputs, args, kwargs, input_list):\r\n    --> 946       return self._functional_construction_call(inputs, args, kwargs,\r\n        947                                                 input_list)\r\n        948 \r\n    ~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py in _functional_construction_call(self, inputs, args, kwargs, input_list)\r\n       1083           layer=self, inputs=inputs, build_graph=True, training=training_value):\r\n       1084         # Check input assumptions set after layer building, e.g. input shape.\r\n    -> 1085         outputs = self._keras_tensor_symbolic_call(\r\n       1086             inputs, input_masks, args, kwargs)\r\n       1087 \r\n    ~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py in _keras_tensor_symbolic_call(self, inputs, input_masks, args, kwargs)\r\n        815       return nest.map_structure(keras_tensor.KerasTensor, output_signature)\r\n        816     else:\r\n    --> 817       return self._infer_output_signature(inputs, args, kwargs, input_masks)\r\n        818 \r\n        819   def _infer_output_signature(self, inputs, args, kwargs, input_masks):\r\n    ~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py in _infer_output_signature(self, inputs, args, kwargs, input_masks)\r\n        856           # TODO(kaftan): do we maybe_build here, or have we already done it?\r\n        857           self._maybe_build(inputs)\r\n    --> 858           outputs = call_fn(inputs, *args, **kwargs)\r\n        859 \r\n        860         self._handle_activity_regularization(inputs, outputs)\r\n    ~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent_v2.py in call(self, inputs, mask, training, initial_state)\r\n       1161     # LSTM does not support constants. Ignore it during process.\r\n       1162     orig_initial_state = initial_state\r\n    -> 1163     inputs, initial_state, _ = self._process_inputs(inputs, initial_state, None)\r\n       1164 \r\n       1165     if isinstance(mask, list):\r\n    ~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py in _process_inputs(self, inputs, initial_state, constants)\r\n        857         initial_state = self.states\r\n        858     elif initial_state is None:\r\n    --> 859       initial_state = self.get_initial_state(inputs)\r\n        860 \r\n        861     if len(initial_state) != len(self.states):\r\n    ~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py in get_initial_state(self, inputs)\r\n        640     dtype = inputs.dtype\r\n        641     if get_initial_state_fn:\r\n    --> 642       init_state = get_initial_state_fn(\r\n        643           inputs=None, batch_size=batch_size, dtype=dtype)\r\n        644     else:\r\n    ~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py in get_initial_state(self, inputs, batch_size, dtype)\r\n       2504 \r\n       2505   def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\r\n    -> 2506     return list(_generate_zero_filled_state_for_cell(\r\n       2507         self, inputs, batch_size, dtype))\r\n       2508 \r\n    ~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py in _generate_zero_filled_state_for_cell(cell, inputs, batch_size, dtype)\r\n       2985     batch_size = array_ops.shape(inputs)[0]\r\n       2986     dtype = inputs.dtype\r\n    -> 2987   return _generate_zero_filled_state(batch_size, cell.state_size, dtype)\r\n       2988 \r\n       2989 \r\n    ~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py in _generate_zero_filled_state(batch_size_tensor, state_size, dtype)\r\n       3001 \r\n       3002   if nest.is_nested(state_size):\r\n    -> 3003     return nest.map_structure(create_zeros, state_size)\r\n       3004   else:\r\n       3005     return create_zeros(state_size)\r\n    ~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/util/nest.py in map_structure(func, *structure, **kwargs)\r\n        657 \r\n        658   return pack_sequence_as(\r\n    --> 659       structure[0], [func(*x) for x in entries],\r\n        660       expand_composites=expand_composites)\r\n        661 \r\n    ~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/util/nest.py in <listcomp>(.0)\r\n        657 \r\n        658   return pack_sequence_as(\r\n    --> 659       structure[0], [func(*x) for x in entries],\r\n        660       expand_composites=expand_composites)\r\n        661 \r\n    ~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py in create_zeros(unnested_state_size)\r\n       2998     flat_dims = tensor_shape.TensorShape(unnested_state_size).as_list()\r\n       2999     init_state_size = [batch_size_tensor] + flat_dims\r\n    -> 3000     return array_ops.zeros(init_state_size, dtype=dtype)\r\n       3001 \r\n       3002   if nest.is_nested(state_size):\r\n    ~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)\r\n        199     \"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\r\n        200     try:\r\n    --> 201       return target(*args, **kwargs)\r\n        202     except (TypeError, ValueError):\r\n        203       # Note: convert_to_eager_tensor currently raises a ValueError, not a\r\n    ~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py in wrapped(*args, **kwargs)\r\n       2817 \r\n       2818   def wrapped(*args, **kwargs):\r\n    -> 2819     tensor = fun(*args, **kwargs)\r\n       2820     tensor._is_zeros_tensor = True\r\n       2821     return tensor\r\n    ~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py in zeros(shape, dtype, name)\r\n       2866           # Create a constant if it won't be very big. Otherwise create a fill\r\n       2867           # op to prevent serialized GraphDefs from becoming too large.\r\n    -> 2868           output = _constant_if_small(zero, shape, dtype, name)\r\n       2869           if output is not None:\r\n       2870             return output\r\n    ~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py in _constant_if_small(value, shape, dtype, name)\r\n       2802 def _constant_if_small(value, shape, dtype, name):\r\n       2803   try:\r\n    -> 2804     if np.prod(shape) < 1000:\r\n       2805       return constant(value, shape=shape, dtype=dtype, name=name)\r\n       2806   except TypeError:\r\n    <__array_function__ internals> in prod(*args, **kwargs)\r\n    ~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/numpy/core/fromnumeric.py in prod(a, axis, dtype, out, keepdims, initial, where)\r\n       3028     10\r\n       3029     \"\"\"\r\n    -> 3030     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\r\n       3031                           keepdims=keepdims, initial=initial, where=where)\r\n       3032 \r\n    ~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/numpy/core/fromnumeric.py in _wrapreduction(obj, ufunc, method, axis, dtype, out, **kwargs)\r\n         85                 return reduction(axis=axis, out=out, **passkwargs)\r\n         86 \r\n    ---> 87     return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\r\n         88 \r\n         89 \r\n    ~/miniforge3/envs/tf2.4/lib/python3.8/site-packages/tensorflow/python/framework/ops.py in __array__(self)\r\n        850 \r\n        851   def __array__(self):\r\n    --> 852     raise NotImplementedError(\r\n        853         \"Cannot convert a symbolic Tensor ({}) to a numpy array.\"\r\n        854         \" This error may indicate that you're trying to pass a Tensor to\"\r\n    NotImplementedError: Cannot convert a symbolic Tensor (lstm_1/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\r\n```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@xxl4tomxu98 As you noticed this is more related to numpy version (>1.20). As mentioned [here](https://github.com/tensorflow/tensorflow/blob/r2.4/tensorflow/tools/pip_package/setup.py#L84), there is a bound on numpy versions supported by TF2.4  ( ~=1.19.2). Currently numpy version should be  >=1.19.2 and  < 1.20. \r\n\r\nDowngrading `numpy 1.2x.x` to the versions mentioned above will work without any issues. Thanks!\r\n\r\ncc @mihaimaruseac \r\n\r\nCurrently there is a feature request (https://github.com/tensorflow/tensorflow/issues/47691) opened to work on supporting `numpy1.2x.x` with TF. We can track the progress there.\r\n\r\nI am closing this issue as we can track the feature request for any progress related to supporting `numpy1.20.x` with recent TF versions. Thanks you.\r\n\r\nFeel free to reopen if I missed anything. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48237\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48237\">No</a>\n", "I uninstalled numpy 1.20.1 and 1.18.5 and tried to install numpy~=1.19.2 and got this error:\r\n```\r\nERROR: Failed building wheel for numpy\r\nFailed to build numpy\r\nERROR: Could not build wheels for numpy which use PEP 517 and cannot be installed directly\r\n```", "@xxl4tomxu98 Looks like there are some issues install TF on M1. Similar issue https://github.com/tensorflow/tensorflow/issues/45645 https://github.com/tensorflow/tensorflow/issues/45631\r\n\r\nUnfortunately this is more related to M1 repo https://github.com/apple/tensorflow_macos. Please post the issue there as there are some M1 experts  who can help you. Thank you!"]}, {"number": 48236, "title": "tensorflow.python.framework.errors_impl.InvalidArgumentError:  Specified a list with shape [32,3] from a tensor with shape [2,3] \t [[node model/lstm/TensorArrayUnstack/TensorListFromTensor (defined at /PycharmProjects/Latestcodeemma/venv/lib/python3.8/site-packages/kerashypetune/kerashypetune.py:206) ]] [Op:__inference_train_function_10478]", "body": "**We are writing a neural network for text analysis. To do this we want to perform a gridsearch for the hyperparameters. However, in our code we get the following error:**\r\n\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError:  Specified a list with shape [32,3] from a tensor with shape [2,3]\r\n\t [[node model/lstm/TensorArrayUnstack/TensorListFromTensor (defined at PycharmProjects/venv/lib/python3.8/site-packages/kerashypetune/kerashypetune.py:206) ]] [Op:__inference_train_function_10478]\r\n\r\nFunction call stack:\r\ntrain_function\r\n\r\n**This would indicate that some dimensions do not line up, however, all our dimensions of the data set are correct as we can fit the model  correctly, but the grid search does not work. \r\nThe full error is:**\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/Desktop/grid_search.py\", line 141, in <module>\r\n    kgs.search([X_pricing_train, X_reports_train], Y_train, validation_data=([X_pricing_test, X_reports_test], Y_test), callbacks=callback)\r\n  File \"/Users/PycharmProjects/venv/lib/python3.8/site-packages/kerashypetune/kerashypetune.py\", line 206, in search\r\n    model.fit(x = x, \r\n  File \"/Users/PycharmProjects/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 1100, in fit\r\n    tmp_logs = self.train_function(iterator)\r\n  File \"/Users/PycharmProjects/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 828, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/Users/PycharmProjects/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 855, in _call\r\n    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n  File \"/Users/PycharmProjects/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 2942, in __call__\r\n    return graph_function._call_flat(\r\n  File \"/Users/PycharmProjects/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 1918, in _call_flat\r\n    return self._build_call_outputs(self._inference_function.call(\r\n  File \"/Users/PycharmProjects//venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 555, in call\r\n    outputs = execute.execute(\r\n  File \"/Users/PycharmProjects/venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError:  Specified a list with shape [32,3] from a tensor with shape [2,3]\r\n\t [[node model/lstm/TensorArrayUnstack/TensorListFromTensor (defined at /PycharmProjects/venv/lib/python3.8/site-packages/kerashypetune/kerashypetune.py:206) ]] [Op:__inference_train_function_10478]\r\n\r\nFunction call stack:\r\ntrain_function\r\n\r\n\r\n**Does someone know how to solve this error or where it could potentially go wrong? In the form of what kind of dimensions might not line up?**\r\n\r\n**The way we defined our grid search is the following:**\r\n\r\nkerasgridsearch = KerasGridSearch(hypermodel, param_grid, monitor = 'val_loss', greater_is_better=False, tuner_verbose=1)\r\ncallback = K.callbacks.EarlyStopping(monitor=monitor)\r\nkerasgridsearcg.search([X_1_train, X_2_train], Y_train, validation_data=([X_1_test, X_2_test], Y_test), callbacks=callback)\r\n", "comments": ["please check for a similar issue [here](https://stackoverflow.com/questions/64309194/invalidargumenterror-specified-a-list-with-shape-60-9-from-a-tensor-with-shap) , thank you ", "@thomultee \r\nYou may also refer to similar issues and let us know: [link](https://stackoverflow.com/questions/66298721/tensorflow-python-framework-errors-impl-invalidargumenterror-specified-a-list-w),[link1](https://github.com/keras-team/keras/issues/11749), [link2](https://stackoverflow.com/questions/56000401/tensorflow-invalid-shape-invalidargumenterror)", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 48235, "title": "Error when loading trained model with tf.keras.models.load_model", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: 3.8.0\r\n- CUDA/cuDNN version: 11.0.221 / 8.0.4 \r\n- GPU model and memory: RTX 3090 24GB\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nWhen loading a model with `tf.keras.models.load_model` that has been saved with `model.save` the following error occurs:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"loading_minimal_example.py\", line 29, in <module>\r\n    model = tf.keras.models.load_model(\r\n  File \"/home/bjkomer/anaconda3/envs/myenv/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py\", line 212, in load_model\r\n    return saved_model_load.load(filepath, compile, options)\r\n  File \"/home/bjkomer/anaconda3/envs/myenv/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/load.py\", line 138, in load\r\n    keras_loader.load_layers(compile=compile)\r\n  File \"/home/bjkomer/anaconda3/envs/myenv/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/load.py\", line 380, in load_layers\r\n    self.loaded_nodes[node_metadata.node_id] = self._load_layer(\r\n  File \"/home/bjkomer/anaconda3/envs/myenv/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/load.py\", line 417, in _load_layer\r\n    obj, setter = self._revive_from_config(identifier, metadata, node_id)\r\n  File \"/home/bjkomer/anaconda3/envs/myenv/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/load.py\", line 431, in _revive_from_config\r\n    obj = self._revive_metric_from_config(metadata)\r\n  File \"/home/bjkomer/anaconda3/envs/myenv/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/load.py\", line 540, in _revive_metric_from_config\r\n    obj = metrics.deserialize(\r\n  File \"/home/bjkomer/anaconda3/envs/myenv/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py\", line 3446, in deserialize\r\n    return deserialize_keras_object(\r\n  File \"/home/bjkomer/anaconda3/envs/myenv/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py\", line 346, in deserialize_keras_object\r\n    (cls, cls_config) = class_and_config_for_serialized_keras_object(\r\n  File \"/home/bjkomer/anaconda3/envs/myenv/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py\", line 311, in class_and_config_for_serialized_keras_object\r\n    deserialized_objects[key] = deserialize_keras_object(\r\n  File \"/home/bjkomer/anaconda3/envs/myenv/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py\", line 360, in deserialize_keras_object\r\n    return cls.from_config(cls_config)\r\n  File \"/home/bjkomer/anaconda3/envs/myenv/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py\", line 642, in from_config\r\n    return super(MeanMetricWrapper, cls).from_config(config)\r\n  File \"/home/bjkomer/anaconda3/envs/myenv/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 720, in from_config\r\n    return cls(**config)\r\nTypeError: __init__() got an unexpected keyword argument 'reduction'\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nThe model will be loaded without errors.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tensorflow.keras.layers import Input\r\nfrom tensorflow.keras.models import Model\r\n\r\ninp = Input(shape=(None, 10))\r\n\r\nout = tf.keras.layers.LSTM(50)(inp)\r\n\r\nmodel = Model(inputs=inp, outputs=out)\r\n  \r\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\r\nloss = tf.keras.losses.BinaryCrossentropy()\r\n\r\nmodel.compile(\r\n    optimizer=optimizer,\r\n    loss=loss,\r\n    metrics=loss,\r\n)\r\n\r\n\r\nhistory = model.fit(\r\n    np.zeros((32, 16, 10)),\r\n    np.zeros((32, 50)),\r\n    steps_per_epoch=1,\r\n    epochs=2,\r\n) \r\n\r\nmodel.save(\"my_model\")\r\n\r\ndel model\r\n  \r\nmodel = tf.keras.models.load_model(\r\n    \"my_model\", compile=False\r\n)\r\n```\r\n\r\nNote that if `model.fit` is not called, the model will be loaded fine. Also, if metrics are not given to `model.compile` it will also be loaded fine. This error only occurs if the model has been trained while reporting metrics.\r\nEdit: the model doesn't need to be recurrent, the issue also happens with a single dense layer\r\n", "comments": ["@bjkomer,\r\nLooks like the error was caused because of using the same loss function `loss = tf.keras.losses.BinaryCrossentropy()` for both `loss` and `metrics`.\r\n\r\nOn adding the metric function `metric = tf.keras.metrics.BinaryCrossentropy()`, I was able to run the code without any issues. \r\n\r\nPlease find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/226883d6d57c84caf98c7df91d60bf66/48235.ipynb#scrollTo=mY_NlmWsXrWw). Thanks!", "Thanks! Using that separate metric function made it work for me as well.\r\n\r\nInterestingly I also noticed it seems to run fine using the same loss function for both `loss` and `metrics` if it is a custom loss function. For example:\r\n\r\n```python\r\n# ...\r\nloss = tf.keras.losses.BinaryCrossentropy()\r\n\r\ndef custom_loss(y_true, y_pred):\r\n    return loss(y_true, y_pred)\r\n\r\nmodel.compile(\r\n    optimizer=optimizer,\r\n    loss=custom_loss,\r\n    metrics=custom_loss,\r\n)\r\n# ...\r\nmodel = tf.keras.models.load_model(\r\n    \"my_model\", compile=False,\r\n    custom_objects={\"custom_loss\": custom_loss},\r\n)\r\n```", "> Thanks! Using that separate metric function made it work for me as well.\r\n\r\n@bjkomer,\r\nThank you for the update. \r\n\r\nIs this still an issue? Please feel free to close the issue if it is resolved.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "For my specific case this has been resolved. There is still the related issue of the error message not being very helpful and inconsistent behaviour of the original model and restored model when `model.fit` is called. That could be treated as a separate issue though.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48235\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48235\">No</a>\n", "@bjkomer: you need to use `tf.keras.losses.BinaryCrossentropy` for loss and `tf.keras.metrics.BinaryCrossentropy` for metrics."]}, {"number": 48234, "title": "Broken syntax highlighting on docs that render python notebooks.", "body": "tensorflow/docs related.\r\n\r\n## URL(s) with the issue:\r\n\r\nCode example for `MultiHeadAttention` at:\r\n\r\nhttps://www.tensorflow.org/tutorials/text/transformer?hl=en#multi-head_attention\r\n\r\nand code example at:\r\n\r\nhttps://www.tensorflow.org/tutorials/text/image_captioning?hl=en#create_a_tfdata_dataset_for_training\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nI actually wasted some amount of time for my own stupidity, but there seems to be a glitch in the syntax highlighting system for notebooks rendered on the docs.\r\n\r\nIt seems that the syntax highlighter parses `//` as comments in python code blocks, not [`floordiv`](https://docs.python.org/3/library/operator.html#operator.floordiv), which it actually means.\r\n\r\nThis actually may cause some amount of confusion, especially for people coming from c++ world like myself \r\nwho tend to eye-parse away the `//` as comments and the broken syntax highlighter is encouraging this (+ it looks so natural!).\r\n\r\n### Request visuals, if applicable\r\n\r\n![image](https://user-images.githubusercontent.com/14329563/113301809-5f3ab000-933a-11eb-82e9-251e0f514af1.png)\r\n\r\n![image](https://user-images.githubusercontent.com/14329563/113301852-6a8ddb80-933a-11eb-80a7-1edf624f5047.png)\r\n\r\nAlso in dark mode:\r\n\r\n![image](https://user-images.githubusercontent.com/14329563/113302147-bc366600-933a-11eb-8569-f61efa84de73.png)\r\n", "comments": ["When the Jupyter notebooks are rendered as HTML, for python code, `lang-python` CSS class is used for the `<pre>` block instead of `lang-py`. The `prettify` library used at https://www.tensorflow.org/tutorials understands python code as `lang-py` (https://github.com/tensorflow/docs/blob/master/tools/tensorflow_docs/api_generator/parser.py#L503 - `lang-py` is used correctly when generating API documentation). When `prettify` doesn't recognize the language identifier, it falls back to `default-code` lexer which ends up being used when `lang-python` is specified (floor division operator is probably being interpreted as a _C style comment_).\r\n\r\nWhen the underlying JavaScript function is invoked from the Google Chrome Developer Console with the correct language identifier, the generated output is correct as shown by the following snippet.\r\n```\r\n> window.prettyPrintOne('self.depth = d_model // self.num_heads', 'python')\r\n\"<span class=\"kwd\">self</span><span class=\"pun\">.</span><span class=\"pln\">depth </span><span class=\"pun\">=</span><span class=\"pln\"> d_model </span><span class=\"com\">// self.num_heads</span>\"\r\n\r\n> window.prettyPrintOne('self.depth = d_model // self.num_heads', 'py')\r\n\"<span class=\"pln\">self</span><span class=\"pun\">.</span><span class=\"pln\">depth </span><span class=\"pun\">=</span><span class=\"pln\"> d_model </span><span class=\"pun\">//</span><span class=\"pln\"> self</span><span class=\"pun\">.</span><span class=\"pln\">num_heads</span>\"\r\n```\r\n\r\nI could not find any information on how this repo is converted to the full fledged site at https://www.tensorflow.org/tutorials or how the Jupyter notebooks are converted to HTML. This change probably needs to happen in that converter.", "Unfortunately, tensorflow.org (and others) use a version of [code-prettify](https://github.com/googlearchive/code-prettify) and that project is now archived. There are no plans to upgrade, at this time. Sorry"]}, {"number": 48233, "title": "Map XLA opaque type to a scalar TensorShape in XLAShapeToTensorShape.", "body": "The `variant` type is (by convention) given a scalar shape in op definitions.\r\nThe `variant` type maps to the `opaque` type in TF2XLA.\r\nSo It appears reasonable to return a scalar `TensorShape` when an opaque typed shape is given to `XLAShapeToTensorShape`.\r\n\r\nThis allows an XLA backend to return TF variant tensors for opaque backend-specific values.", "comments": ["Hi @jakeh-gc,\r\n\r\n> This allows an XLA backend to return TF variant tensors for opaque backend-specific values.\r\n\r\nCan you share a bit more context on this?  Do you have something working end to end that represents TF variants as opaque values in XLA?\r\n\r\nThanks!\r\n\r\nCC @jpienaar @yunxing ", "Hi @sanjoy,\r\n\r\nThanks for taking a look!\r\n\r\n> Can you share a bit more context on this?\r\n\r\nSure.\r\n\r\nI have a custom-call. This custom-call produces some additional attributes during lowering. To minimise memory consumption and maximise throughput, we need to attach this information to the corresponding gradient instruction.\r\n\r\nFor regular attributes we would simply do the following:\r\n```\r\nret = gen_my_ops.my_op(x, attr=attr)\r\n...\r\n@ops.RegisterGradient(\"MyOp\")\r\ndef _my_op_grad(op, *grads):\r\n  return [\r\n   gen_my_ops.my_grad_op(grads[0], attr=op.get_attr(\"attr\"))\r\n  ]\r\n```\r\nSadly, our extra attribute is only knowable during lowering of the forward custom-call instruction. For this reason, the solution I've come up with is to return the attributes in an opaque tensor. This is internally implemented as an `absl::any`.\r\n\r\nThis creates an opaque data dependency between the instructions, and means we can now use the custom-call and gradient like this:\r\n```\r\nret, opaque_attr = gen_my_ops.my_op(x)\r\n...\r\n@ops.RegisterGradient(\"MyOp\")\r\ndef _my_op_grad(op, *grads):\r\n  return [\r\n   gen_my_ops.my_grad_op(grads[0], op.output[1])\r\n  ]\r\n```\r\nWhere the `REGISTER_OP` has changed from having an attribute to a variant input and output.\r\n\r\nThis works as-is in most cases, except when we call `control_flow_util_v2.create_new_tf_function` on a graph that outputs an `opaque` tensor. This causes `BuildComputation` to fail in `retval.GetShape`, which calls `XLAShapeToTensorShape`.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/425b7e924b180b9979457ab7f36c78f306a5eef8/tensorflow/compiler/tf2xla/xla_compiler.cc#L220-L224\r\n\r\nWe need this information to be returned and passed to the gradient of the tf function to reach the grad op.\r\n\r\n> Do you have something working end to end that represents TF variants as opaque values in XLA?\r\n\r\nSort of. We only support it inside our backend and on these computation boundaries. For example, we don't allow them on the entry computation parameters or root instruction result.\r\n\r\ntl;dr\r\nBeing able to handle this shape conversion, allows us to support custom-calls that have attributes/data produced during lowering that can be shared with other instructions.\r\n", "@sanjoy  Any update on this PR? Please. Thanks!", "Sorry for the delay.\r\n\r\nThe PR looks fine to me, but please add a unit test.\r\n\r\nCC @smit-hinsu in case I'm missing something.", "@jakeh-gc  Can you please check @sanjoy's comments and keep us posted ? Thanks!", "@sanjoy @gbaned Sure, I'll pick this up again shortly.", "@jakeh-gc  Any update on this PR? Please. Thanks!", "Unfortunately I haven't had time to revisit this. I'll reopen when I get the time.\r\nThanks."]}, {"number": 48231, "title": "Added Type Hint", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F48231) for more info**.\n\n<!-- need_sender_cla -->"]}, {"number": 48230, "title": "Reset/Reinitialize model weights/parameters", "body": "Motivated by [this](https://github.com/keras-team/keras/issues/341) post, I would like to ask for a method like `model.reset_weights()` to get the reset and init the weights again.", "comments": ["Hi there,\r\n\r\nYou can straightforwardly roll out your own function. Like this:\r\n\r\n```python\r\ndef reinitialize_model(model):\r\n  weights = []\r\n  initializers = []\r\n  for layer in model.layers:\r\n    if isinstance(layer, (keras.layers.Dense, keras.layers.Conv2D)):\r\n      weights += [layer.kernel, layer.bias]\r\n      initializers += [layer.kernel_initializer, layer.bias_initializer]\r\n    elif isinstance(layer, keras.layers.BatchNormalization):\r\n      weights += [layer.gamma, layer.beta, layer.moving_mean, layer.moving_variance]\r\n      initializers += [layer.gamma_initializer,\r\n                       layer.beta_initializer,\r\n                       layer.moving_mean_initializer,\r\n                       layer.moving_variance_initializer]\r\n  for w, init in zip(weights, initializers):\r\n    w.assign(init(w.shape, dtype=w.dtype))\r\n\r\nreinitialize_model(model)\r\n```\r\n\r\nYou will need to add coverage for all the layers (with weights) you use in your model.", "Merci", "Not so straightforward", "What do you mean by \"add coverage for all layers\"? @fchollet \r\n", "I was also confused by what exactly @fchollet meant by \"add coverage for all layers\", but I believe the following is an example (which worked for my model):\r\n```\r\ndef reinitialize_model(model):\r\n    weights = []\r\n    initializers = []\r\n    for layer in model.layers:\r\n        if isinstance(layer, (keras.layers.Dense, keras.layers.Conv2D)):\r\n            weights += [layer.kernel, layer.bias]\r\n            initializers += [layer.kernel_initializer, layer.bias_initializer]\r\n        elif isinstance(layer, keras.layers.BatchNormalization):\r\n            weights += [layer.gamma, layer.beta, layer.moving_mean, layer.moving_variance]\r\n            initializers += [layer.gamma_initializer,\r\n                            layer.beta_initializer,\r\n                            layer.moving_mean_initializer,\r\n                            layer.moving_variance_initializer]\r\n        elif isinstance(layer, keras.layers.embeddings.Embedding):\r\n            weights += [layer.embeddings]\r\n            initializers += [layer.embeddings_initializer]\r\n        elif isinstance(layer, (keras.engine.input_layer.InputLayer,\r\n                                            keras.layers.core.Reshape,\r\n                                            keras.layers.merge.Concatenate,\r\n                               )):\r\n            # These layers don't need initialization\r\n            continue\r\n        else:\r\n            raise ValueError('Unhandled layer type: %s' % (type(layer)))\r\n    for w, init in zip(weights, initializers):\r\n        w.assign(init(w.shape, dtype=w.dtype))\r\n```", "Does this solved by anyone?\r\nI have Bi-LSTM in my model, so every time I construct a new instance(but the old one's gpu memory can not be released)"]}, {"number": 48229, "title": "Multiple retracing when shapes changes ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: na\r\n- TensorFlow installed from (source or binary): binay pypy\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\n\r\n```\r\nimport tensorflow as tf\r\n@tf.function()  # Setting experimental relax shapes does not change the result\r\ndef unique_numpy(arr):\r\n    unique_val, unique_inverse = tf.unique(arr)\r\n    return unique_val\r\n# We trace two functions.\r\nunique_numpy.get_concrete_function(tf.TensorSpec(shape=(None,), dtype=tf.int32))\r\nunique_numpy.get_concrete_function(tf.TensorSpec(shape=(None,), dtype=tf.int64))\r\nprint(unique_numpy.pretty_printed_concrete_signatures()) # 2 signatures available \r\nunique_numpy(tf.constant([0, 2], dtype=tf.int32)) \r\nprint(' New')\r\nprint(unique_numpy.pretty_printed_concrete_signatures()) # 3 signatures while it should have re used the tf.TensorSpec(shape=(None,), dtype=tf.int32) trace\r\n```\r\n\r\n**Describe the expected behavior**\r\nSince `tf.constant([0, 2], dtype=tf.int32)`respects the signature `tf.TensorSpec(shape=(None,), dtype=tf.int32)`I would have thought that TF would reuse that trace and not trace again the function.\r\n\r\nI would like to do that to create a function with the same name that could support the same shape but multiple dtypes.\r\n \r\n**Standalone code to reproduce the issue**\r\nDone above\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\n\r\n", "comments": ["I am able to replicate the issue reported, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/c8bf4652ba79f99a8e8d34497e815ce7/untitled581.ipynb)", "This is a bug, indeed. Here's a temporary workaround in case you're blocked by it:\r\n\r\n```\r\ncf = unique_numpy.get_concrete_function(tf.TensorSpec(shape=(None,), dtype=tf.int64))\r\ncf(tf.constant([0, 2], dtype=tf.int32))  # guaranteed not to retrace\r\n```", "Now it is using 2 signatures instead of 3 at the end, here is the [gist](https://colab.research.google.com/gist/sachinprasadhs/871fcd3cdf05c903952cffcc9e493fe7/untitled581.ipynb) for reference. Thanks!", "This should now be fixed at head, and should land in the next version.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48229\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48229\">No</a>\n"]}, {"number": 48228, "title": "Centernet Mobilenet Keypoint Model Training on custom datasets issue in Keypoints Scores", "body": "Hi,\r\n\r\nTensorFlow : 2.2.0\r\nPython : 3.6\r\nModel: centernet_mobilenet_kpt_fpn\r\n\r\nI am trying to train centernet keypoint model on custom datasets. But its keypoints score is very less, if box score, i am getting as 70% then keypoints score i am getting 3%. \r\nCan anyone tell me why it is happening?", "comments": ["@sandhyacs \r\n\r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in the [Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!", "hi @Saduf2019 \r\nOS: Ubuntu 20.04\r\nRAM:16 Gb\r\nTensorflow Version: 2.2.0 (CPU)\r\nInstall: pip install tensorflow\r\n\r\nCommand to get saved_model:\r\n\r\npython object_detection/export_tflite_model_tf2.py \\\r\n    --pipeline_config_path path/to/ssd_model/pipeline.config \\\r\n    --trained_checkpoint_dir path/to/ssd_model/checkpoint \\\r\n    --output_directory path/to/exported_model_directory \\\r\n    --keypoint_label_map_path path/to/label_map.txt \\\r\n    --max_detections 10 \\\r\n    --centernet_include_keypoints true \\\r\n    --config_override \" \\\r\n            model{ \\\r\n              center_net { \\\r\n                image_resizer { \\\r\n                  fixed_shape_resizer { \\\r\n                    height: 320 \\\r\n                    width: 320 \\\r\n                  } \\\r\n                } \\\r\n              } \\\r\n            }\" \\\r\n", "@sandhyacs \r\nPlease share code such that we can replicate your issue as requested before or a colab gist with the issue reported.", "@Saduf2019 \r\nhere is the code :\r\n\r\nimport os\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\r\nimport pathlib\r\nimport tensorflow as tf\r\nimport cv2\r\nimport numpy as np\r\nfrom PIL import Image\r\nimport time\r\nfrom object_detection.utils import label_map_util\r\nimport vis_utils as viz_utils\r\nimport matplotlib.pyplot as plt\r\nimport warnings\r\n\r\n\r\nwarnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\r\n\r\ntf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)\r\n\r\n# Enable GPU dynamic memory allocation\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\nfor gpu in gpus:\r\n    tf.config.experimental.set_memory_growth(gpu, True)\r\n\r\n\r\nIMAGE_PATHS =['./images/image.jpg']\r\nPATH_TO_LABELS = './Annotation/label.pbtxt'\r\n\r\nPATH_TO_SAVED_MODEL = './centernet_training/exported_tfjs130/saved_model'\r\n\r\n\r\nprint('Loading model...', end='')\r\nstart_time = time.time()\r\n\r\n# Load saved model and build the detection function\r\ndetect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\r\n\r\nend_time = time.time()\r\nelapsed_time = end_time - start_time\r\nprint('Done! Took {} seconds'.format(elapsed_time))\r\n\r\ncategory_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\r\n                                                                    use_display_name=True)\r\n\r\ndef load_image_into_numpy_array(path):\r\n    \"\"\"Load an image from file into a numpy array.\r\n\r\n    Puts image into numpy array to feed into tensorflow graph.\r\n    Note that by convention we put it into a numpy array with shape\r\n    (height, width, channels), where channels=3 for RGB.\r\n\r\n    Args:\r\n      path: the file path to the image\r\n\r\n    Returns:\r\n      uint8 numpy array with shape (img_height, img_width, 3)\r\n    \"\"\"\r\n    return np.array(Image.open(path))\r\n\r\n\r\nfor image_path in IMAGE_PATHS:\r\n\r\n    print('Running inference for {}... '.format(image_path), end='')\r\n\r\n    image_np = load_image_into_numpy_array(image_path)\r\n\r\n    # Things to try:\r\n    # Flip horizontally\r\n    # image_np = np.fliplr(image_np).copy()\r\n\r\n    # Convert image to grayscale\r\n    # image_np = np.tile(\r\n    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\r\n\r\n    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\r\n    input_tensor = tf.convert_to_tensor(image_np)\r\n    # The model expects a batch of images, so add an axis with `tf.newaxis`.\r\n    input_tensor = input_tensor[tf.newaxis, ...]\r\n\r\n    # input_tensor = np.expand_dims(image_np, 0)\r\n    detections = detect_fn(input_tensor)\r\n    print(detections)\r\n\r\n    # All outputs are batches tensors.\r\n    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\r\n    # We're only interested in the first num_detections.\r\n    num_detections = int(detections.pop('num_detections'))\r\n    detections = {key: value[0, :num_detections].numpy()\r\n                   for key, value in detections.items()}\r\n    detections['num_detections'] = num_detections\r\n\r\n    # detection_classes should be ints.\r\n    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\r\n    image_np_with_detections = image_np.copy()\r\n    keypoints_edge = [(0,1),(1,2),(0,4),(1,2),(2,3),(3,4),(0,5),(5,6),(0,7),(7,8),(0,9),(9,10),(0,11),(11,12),(0,13),(13,14)]\r\n    # keypoints_edge=[(0),(2,3),(4,0),(5,6),(7,8),(9,10),(11,12),(13,14)]\r\n    keypoints, keypoint_scores = None, None\r\n    if 'detection_keypoints' in detections:\r\n        keypoints = detections['detection_keypoints'][0]\r\n        keypoint_scores = detections['detection_keypoint_scores'][0]\r\n        # print(keypoint_scores)\r\n    \r\n\r\n    viz_utils.visualize_boxes_and_labels_on_image_array(\r\n          image_np_with_detections,\r\n          detections['detection_boxes'],\r\n          detections['detection_classes'],\r\n          detections['detection_scores'],\r\n          category_index,\r\n          detections['detection_keypoints'],\r\n          detections['detection_keypoint_scores'],\r\n          keypoints_edge,\r\n          use_normalized_coordinates=True,\r\n          max_boxes_to_draw=100,\r\n          min_score_thresh=.012,\r\n          agnostic_mode=False)\r\n    # cv2.imshow(\"image\", image_np_with_detections)\r\n    # cv2.waitKey(0)\r\n    cv2.imwrite(\"image1.jpg\", image_np_with_detections)\r\n\r\n\r\n\r\ndetection output value:::::::::\r\n\r\n\r\n{'detection_scores': <tf.Tensor: shape=(1, 20), dtype=float32, numpy=\r\narray([[0.06789026, 0.01249853, 0.01208547, 0.01185322, 0.01181099,\r\n        0.01155534, 0.01140523, 0.01130983, 0.01103154, 0.01071545,\r\n        0.01061767, 0.01051009, 0.01013181, 0.01008138, 0.00993431,\r\n        0.00976467, 0.00943464, 0.00935957, 0.00887686, 0.00885502]],\r\n      dtype=float32)>, 'detection_boxes': <tf.Tensor: shape=(1, 20, 4), dtype=float32, numpy=\r\narray([[[0.13730091, 0.32741907, 0.7452771 , 1.        ],\r\n        [0.1164946 , 0.40842503, 0.5942084 , 0.94309825],\r\n        [0.31554076, 0.4400742 , 0.8326622 , 0.8645741 ],\r\n        [0.15150423, 0.4066526 , 0.5591988 , 1.        ],\r\n        [0.3664359 , 0.46189266, 0.85989213, 0.8583806 ],\r\n        [0.35931483, 0.43022317, 1.        , 0.8588001 ],\r\n        [0.10772906, 0.39031708, 0.57172394, 0.9455812 ],\r\n        [0.3973289 , 0.5177271 , 0.8446241 , 0.8650462 ],\r\n        [0.3918531 , 0.49185765, 0.8500999 , 0.85966563],\r\n        [0.25776097, 0.4039864 , 0.765442  , 0.8850369 ],\r\n        [0.34294412, 0.47849476, 0.85213387, 0.8730285 ],\r\n        [0.2584469 , 0.42615962, 0.8116311 , 0.86286366],\r\n        [0.14577265, 0.41487572, 0.6118054 , 1.        ],\r\n        [0.09863588, 0.40075323, 0.5495671 , 0.91952   ],\r\n        [0.26192006, 0.4451055 , 0.7769079 , 0.8751678 ],\r\n        [0.24351698, 0.5555348 , 0.57656103, 0.9834885 ],\r\n        [0.32030442, 0.39564145, 0.8591486 , 0.83088183],\r\n        [0.13802098, 0.41636357, 0.619557  , 0.9976597 ],\r\n        [0.2914784 , 0.53250486, 0.7629746 , 0.9908934 ],\r\n        [0.21742396, 0.50269926, 0.57140404, 1.        ]]], dtype=float32)>, 'detection_multiclass_scores': <tf.Tensor: shape=(1, 20, 1), dtype=float32, numpy=\r\narray([[[0.06789026],\r\n        [0.01249853],\r\n        [0.01208547],\r\n        [0.01185322],\r\n        [0.01181099],\r\n        [0.01155534],\r\n        [0.01140523],\r\n        [0.01130983],\r\n        [0.01103154],\r\n        [0.01071545],\r\n        [0.01061767],\r\n        [0.01051009],\r\n        [0.01013181],\r\n        [0.01008138],\r\n        [0.00993431],\r\n        [0.00976467],\r\n        [0.00943464],\r\n        [0.00935957],\r\n        [0.00887686],\r\n        [0.00885502]]], dtype=float32)>, 'detection_classes': <tf.Tensor: shape=(1, 20), dtype=float32, numpy=\r\narray([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\r\n        1., 1., 1., 1.]], dtype=float32)>, 'detection_keypoints': <tf.Tensor: shape=(1, 20, 15, 2), dtype=float32, numpy=\r\narray([[[[0.47890738, 0.4956637 ],\r\n         [0.604445  , 0.47518045],\r\n         [0.6040884 , 0.45681825],\r\n         [0.60456514, 0.45788175],\r\n         [0.60448736, 0.45661062],\r\n         [0.29398328, 0.7235079 ],\r\n         [0.26798505, 0.66134644],\r\n         [0.3100821 , 0.7425556 ],\r\n         [0.29321608, 0.8148615 ],\r\n         [0.35619816, 0.752157  ],\r\n         [0.29423812, 0.8149114 ],\r\n         [0.40581948, 0.7547023 ],\r\n         [0.52508235, 0.79987055],\r\n         [0.4773598 , 0.7170463 ],\r\n         [0.52794045, 0.73719734]],\r\n\r\n        [[0.3644668 , 0.54298186],\r\n         [0.35875103, 0.512097  ],\r\n         [0.33526656, 0.47394824],\r\n         [0.28252384, 0.43885103],\r\n         [0.408202  , 0.4700727 ],\r\n         [0.29398328, 0.7235079 ],\r\n         [0.38075683, 0.709367  ],\r\n         [0.3473508 , 0.7755918 ],\r\n         [0.29321608, 0.8148615 ],\r\n         [0.32592568, 0.7873942 ],\r\n         [0.29423812, 0.8149114 ],\r\n         [0.30695957, 0.7828873 ],\r\n         [0.28823513, 0.8627173 ],\r\n         [0.29511344, 0.7533645 ],\r\n         [0.2813087 , 0.8128631 ]],\r\n\r\n        [[0.5737297 , 0.55923986],\r\n         [0.604445  , 0.47518045],\r\n         [0.6040884 , 0.45681825],\r\n         [0.60547525, 0.47872588],\r\n         [0.6055099 , 0.47589344],\r\n         [0.6288579 , 0.6571531 ],\r\n         [0.62544477, 0.6766425 ],\r\n         [0.59381074, 0.72051156],\r\n         [0.5244929 , 0.79978716],\r\n         [0.5750875 , 0.7275822 ],\r\n         [0.528823  , 0.79956514],\r\n         [0.55358243, 0.72690505],\r\n         [0.52508235, 0.79987055],\r\n         [0.532687  , 0.7024399 ],\r\n         [0.52794045, 0.73719734]],\r\n\r\n        [[0.33759624, 0.5458373 ],\r\n         [0.32039917, 0.52165973],\r\n         [0.28425926, 0.47349527],\r\n         [0.28252384, 0.43885103],\r\n         [0.36973333, 0.47776094],\r\n         [0.29398328, 0.7235079 ],\r\n         [0.39235133, 0.7445855 ],\r\n         [0.36878225, 0.8069528 ],\r\n         [0.397098  , 0.82431906],\r\n         [0.34812513, 0.82203794],\r\n         [0.3972052 , 0.82524353],\r\n         [0.32671085, 0.8122454 ],\r\n         [0.32038793, 0.9030313 ],\r\n         [0.3073508 , 0.7744105 ],\r\n         [0.30358037, 0.8395443 ]],\r\n\r\n        [[0.67727774, 0.5731032 ],\r\n         [0.604445  , 0.47518045],\r\n         [0.6040884 , 0.45681825],\r\n         [0.60547525, 0.47872588],\r\n         [0.6055099 , 0.47589344],\r\n         [0.6288579 , 0.6571531 ],\r\n         [0.55405444, 0.6771843 ],\r\n         [0.56617767, 0.7073975 ],\r\n         [0.5244929 , 0.79978716],\r\n         [0.5778203 , 0.70877033],\r\n         [0.528823  , 0.79956514],\r\n         [0.5795676 , 0.7119748 ],\r\n         [0.52508235, 0.79987055],\r\n         [0.5992406 , 0.6974476 ],\r\n         [0.52794045, 0.73719734]],\r\n\r\n        [[0.64919394, 0.34873497],\r\n         [0.60300636, 0.45638075],\r\n         [0.6040884 , 0.45681825],\r\n         [0.60456514, 0.45788175],\r\n         [0.60448736, 0.45661062],\r\n         [0.6288579 , 0.6571531 ],\r\n         [0.63155496, 0.47045422],\r\n         [0.5000547 , 0.47567326],\r\n         [0.43452063, 0.52550834],\r\n         [0.46169335, 0.4743933 ],\r\n         [0.37936884, 0.5267217 ],\r\n         [0.42808613, 0.44198835],\r\n         [0.3632677 , 0.47759998],\r\n         [0.44534302, 0.39364856],\r\n         [0.39086136, 0.4087515 ]],\r\n\r\n        [[0.3756039 , 0.55538726],\r\n         [0.37826186, 0.51396346],\r\n         [0.37501225, 0.46211007],\r\n         [0.28252384, 0.43885103],\r\n         [0.6055099 , 0.47589344],\r\n         [0.29398328, 0.7235079 ],\r\n         [0.34266025, 0.72792244],\r\n         [0.29708663, 0.79973954],\r\n         [0.29321608, 0.8148615 ],\r\n         [0.28047925, 0.8064877 ],\r\n         [0.29423812, 0.8149114 ],\r\n         [0.26641446, 0.79738647],\r\n         [0.23364958, 0.88340795],\r\n         [0.2639025 , 0.76453286],\r\n         [0.23920643, 0.8330481 ]],\r\n\r\n        [[0.74005115, 0.66380185],\r\n         [0.78694725, 0.67055815],\r\n         [0.7794554 , 0.6454843 ],\r\n         [0.80117875, 0.6450816 ],\r\n         [0.78455764, 0.6551838 ],\r\n         [0.6288579 , 0.6571531 ],\r\n         [0.6007164 , 0.6735719 ],\r\n         [0.58458513, 0.6930307 ],\r\n         [0.5244929 , 0.79978716],\r\n         [0.5845144 , 0.7025396 ],\r\n         [0.528823  , 0.79956514],\r\n         [0.58732283, 0.7150524 ],\r\n         [0.52508235, 0.79987055],\r\n         [0.61805904, 0.7156404 ],\r\n         [0.52794045, 0.73719734]],\r\n\r\n        [[0.7265505 , 0.61455077],\r\n         [0.786642  , 0.60635376],\r\n         [0.74477047, 0.5765604 ],\r\n         [0.7981317 , 0.5730776 ],\r\n         [0.7604938 , 0.5981266 ],\r\n         [0.6288579 , 0.6571531 ],\r\n         [0.5759923 , 0.6830944 ],\r\n         [0.5781771 , 0.7051288 ],\r\n         [0.5244929 , 0.79978716],\r\n         [0.58744633, 0.7065285 ],\r\n         [0.528823  , 0.79956514],\r\n         [0.59480053, 0.7128585 ],\r\n         [0.52508235, 0.79987055],\r\n         [0.6257969 , 0.7001342 ],\r\n         [0.52794045, 0.73719734]],\r\n\r\n        [[0.51014066, 0.52347255],\r\n         [0.604445  , 0.47518045],\r\n         [0.6040884 , 0.45681825],\r\n         [0.60456514, 0.45788175],\r\n         [0.60448736, 0.45661062],\r\n         [0.6288579 , 0.6571531 ],\r\n         [0.51639456, 0.68472147],\r\n         [0.4941185 , 0.7497692 ],\r\n         [0.5244929 , 0.79978716],\r\n         [0.47804537, 0.7629774 ],\r\n         [0.3972052 , 0.82524353],\r\n         [0.4582998 , 0.75073284],\r\n         [0.52508235, 0.79987055],\r\n         [0.44801313, 0.718298  ],\r\n         [0.52794045, 0.73719734]],\r\n\r\n        [[0.61422706, 0.5891655 ],\r\n         [0.604445  , 0.47518045],\r\n         [0.6040884 , 0.45681825],\r\n         [0.60547525, 0.47872588],\r\n         [0.6055099 , 0.47589344],\r\n         [0.6288579 , 0.6571531 ],\r\n         [0.6427414 , 0.6764668 ],\r\n         [0.59507555, 0.7170955 ],\r\n         [0.5244929 , 0.79978716],\r\n         [0.5748372 , 0.7282665 ],\r\n         [0.528823  , 0.79956514],\r\n         [0.55471   , 0.7284547 ],\r\n         [0.52508235, 0.79987055],\r\n         [0.5491802 , 0.7092719 ],\r\n         [0.52794045, 0.73719734]],\r\n\r\n        [[0.56038225, 0.53521466],\r\n         [0.604445  , 0.47518045],\r\n         [0.6040884 , 0.45681825],\r\n         [0.60456514, 0.45788175],\r\n         [0.6055099 , 0.47589344],\r\n         [0.6288579 , 0.6571531 ],\r\n         [0.55406773, 0.674914  ],\r\n         [0.50474775, 0.7358842 ],\r\n         [0.5244929 , 0.79978716],\r\n         [0.483381  , 0.7466792 ],\r\n         [0.3972052 , 0.82524353],\r\n         [0.45996374, 0.7432082 ],\r\n         [0.52508235, 0.79987055],\r\n         [0.4554515 , 0.71910596],\r\n         [0.52794045, 0.73719734]],\r\n\r\n        [[0.34941322, 0.55156964],\r\n         [0.31089208, 0.5395539 ],\r\n         [0.2936744 , 0.4904794 ],\r\n         [0.28252384, 0.43885103],\r\n         [0.6055099 , 0.47589344],\r\n         [0.29398328, 0.7235079 ],\r\n         [0.44609734, 0.73029524],\r\n         [0.40401098, 0.7969795 ],\r\n         [0.397098  , 0.82431906],\r\n         [0.37132704, 0.81395245],\r\n         [0.3972052 , 0.82524353],\r\n         [0.33378425, 0.8112062 ],\r\n         [0.52508235, 0.79987055],\r\n         [0.3029934 , 0.78133947],\r\n         [0.29948622, 0.8394797 ]],\r\n\r\n        [[0.36984634, 0.5653872 ],\r\n         [0.3657679 , 0.5256569 ],\r\n         [0.3748841 , 0.48051786],\r\n         [0.4476639 , 0.45645258],\r\n         [0.43370137, 0.4969873 ],\r\n         [0.29398328, 0.7235079 ],\r\n         [0.32953447, 0.7179423 ],\r\n         [0.27249736, 0.77907646],\r\n         [0.29321608, 0.8148615 ],\r\n         [0.25270638, 0.7821395 ],\r\n         [0.29423812, 0.8149114 ],\r\n         [0.23665777, 0.76938576],\r\n         [0.20068347, 0.8482231 ],\r\n         [0.23694263, 0.7415011 ],\r\n         [0.20771639, 0.80277675]],\r\n\r\n        [[0.5290936 , 0.53745484],\r\n         [0.604445  , 0.47518045],\r\n         [0.6040884 , 0.45681825],\r\n         [0.60456514, 0.45788175],\r\n         [0.6055099 , 0.47589344],\r\n         [0.6288579 , 0.6571531 ],\r\n         [0.53730047, 0.6750348 ],\r\n         [0.4976544 , 0.7344142 ],\r\n         [0.5244929 , 0.79978716],\r\n         [0.4791696 , 0.748458  ],\r\n         [0.3972052 , 0.82524353],\r\n         [0.45707178, 0.74433625],\r\n         [0.52508235, 0.79987055],\r\n         [0.45038375, 0.7188722 ],\r\n         [0.52794045, 0.73719734]],\r\n\r\n        [[0.43501914, 0.73749906],\r\n         [0.4396471 , 0.72368205],\r\n         [0.44231653, 0.7256803 ],\r\n         [0.4614204 , 0.70369434],\r\n         [0.4628053 , 0.72096616],\r\n         [0.29398328, 0.7235079 ],\r\n         [0.43079743, 0.7832277 ],\r\n         [0.40102842, 0.7928725 ],\r\n         [0.397098  , 0.82431906],\r\n         [0.39040852, 0.78771836],\r\n         [0.3972052 , 0.82524353],\r\n         [0.38554347, 0.7840663 ],\r\n         [0.52508235, 0.79987055],\r\n         [0.38241804, 0.77676153],\r\n         [0.37242296, 0.79121965]],\r\n\r\n        [[0.6067067 , 0.51246816],\r\n         [0.604445  , 0.47518045],\r\n         [0.6040884 , 0.45681825],\r\n         [0.60456514, 0.45788175],\r\n         [0.60448736, 0.45661062],\r\n         [0.6288579 , 0.6571531 ],\r\n         [0.57455   , 0.643717  ],\r\n         [0.56492656, 0.6898281 ],\r\n         [0.5244929 , 0.79978716],\r\n         [0.56143755, 0.6956403 ],\r\n         [0.528823  , 0.79956514],\r\n         [0.55096656, 0.6942273 ],\r\n         [0.52508235, 0.79987055],\r\n         [0.5506239 , 0.6697188 ],\r\n         [0.52794045, 0.73719734]],\r\n\r\n        [[0.35450375, 0.55349195],\r\n         [0.3238949 , 0.5412891 ],\r\n         [0.30903348, 0.49576336],\r\n         [0.28252384, 0.43885103],\r\n         [0.3937085 , 0.48578176],\r\n         [0.29398328, 0.7235079 ],\r\n         [0.43840906, 0.71565336],\r\n         [0.39827722, 0.7784594 ],\r\n         [0.397098  , 0.82431906],\r\n         [0.36905855, 0.79452544],\r\n         [0.3972052 , 0.82524353],\r\n         [0.33669162, 0.79291904],\r\n         [0.52508235, 0.79987055],\r\n         [0.31099853, 0.7654623 ],\r\n         [0.30647355, 0.82049537]],\r\n\r\n        [[0.55811995, 0.67598945],\r\n         [0.5500795 , 0.6560347 ],\r\n         [0.5590832 , 0.6449093 ],\r\n         [0.6089583 , 0.6288593 ],\r\n         [0.60763925, 0.6394795 ],\r\n         [0.6288579 , 0.6571531 ],\r\n         [0.55899954, 0.7706226 ],\r\n         [0.5092303 , 0.7980016 ],\r\n         [0.5244929 , 0.79978716],\r\n         [0.49098682, 0.79826486],\r\n         [0.3972052 , 0.82524353],\r\n         [0.47440633, 0.79767   ],\r\n         [0.52508235, 0.79987055],\r\n         [0.46942082, 0.77804655],\r\n         [0.52794045, 0.73719734]],\r\n\r\n        [[0.40308282, 0.6487758 ],\r\n         [0.3959494 , 0.63385785],\r\n         [0.3744034 , 0.5984824 ],\r\n         [0.43764818, 0.5747856 ],\r\n         [0.43746307, 0.590709  ],\r\n         [0.29398328, 0.7235079 ],\r\n         [0.41585344, 0.77181846],\r\n         [0.3956966 , 0.81848097],\r\n         [0.397098  , 0.82431906],\r\n         [0.379707  , 0.82387304],\r\n         [0.3972052 , 0.82524353],\r\n         [0.3575333 , 0.8247968 ],\r\n         [0.34257853, 0.8899466 ],\r\n         [0.34386703, 0.80989957],\r\n         [0.33288535, 0.8473333 ]]]], dtype=float32)>, 'detection_keypoint_scores': <tf.Tensor: shape=(1, 20, 15), dtype=float32, numpy=\r\narray([[[0.1       , 0.12789923, 0.15232775, 0.13707036, 0.1593894 ,\r\n         0.14675722, 0.1       , 0.1       , 0.11026657, 0.1       ,\r\n         0.10526174, 0.1       , 0.12228966, 0.1       , 0.10547316],\r\n        [0.1       , 0.1       , 0.1       , 0.1085431 , 0.1       ,\r\n         0.14675722, 0.1       , 0.1       , 0.11026657, 0.1       ,\r\n         0.10526174, 0.1       , 0.1       , 0.1       , 0.1       ],\r\n        [0.1       , 0.12789923, 0.15232775, 0.12119687, 0.12422892,\r\n         0.10038066, 0.1       , 0.1       , 0.18725973, 0.1       ,\r\n         0.11328223, 0.1       , 0.12228966, 0.1       , 0.10547316],\r\n        [0.1       , 0.1       , 0.1       , 0.1085431 , 0.1       ,\r\n         0.14675722, 0.1       , 0.1       , 0.13080952, 0.1       ,\r\n         0.10276383, 0.1       , 0.1       , 0.1       , 0.1       ],\r\n        [0.1       , 0.12789923, 0.15232775, 0.12119687, 0.12422892,\r\n         0.10038066, 0.1       , 0.1       , 0.18725973, 0.1       ,\r\n         0.11328223, 0.1       , 0.12228966, 0.1       , 0.10547316],\r\n        [0.1       , 0.1451081 , 0.15232775, 0.13707036, 0.1593894 ,\r\n         0.10038066, 0.1       , 0.1       , 0.1       , 0.1       ,\r\n         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\r\n        [0.1       , 0.1       , 0.1       , 0.1085431 , 0.12422892,\r\n         0.14675722, 0.1       , 0.1       , 0.11026657, 0.1       ,\r\n         0.10526174, 0.1       , 0.1       , 0.1       , 0.1       ],\r\n        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\r\n         0.10038066, 0.1       , 0.1       , 0.18725973, 0.1       ,\r\n         0.11328223, 0.1       , 0.12228966, 0.1       , 0.10547316],\r\n        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\r\n         0.10038066, 0.1       , 0.1       , 0.18725973, 0.1       ,\r\n         0.11328223, 0.1       , 0.12228966, 0.1       , 0.10547316],\r\n        [0.1       , 0.12789923, 0.15232775, 0.13707036, 0.1593894 ,\r\n         0.10038066, 0.1       , 0.1       , 0.18725973, 0.1       ,\r\n         0.10276383, 0.1       , 0.12228966, 0.1       , 0.10547316],\r\n        [0.1       , 0.12789923, 0.15232775, 0.12119687, 0.12422892,\r\n         0.10038066, 0.1       , 0.1       , 0.18725973, 0.1       ,\r\n         0.11328223, 0.1       , 0.12228966, 0.1       , 0.10547316],\r\n        [0.1       , 0.12789923, 0.15232775, 0.13707036, 0.12422892,\r\n         0.10038066, 0.1       , 0.1       , 0.18725973, 0.1       ,\r\n         0.10276383, 0.1       , 0.12228966, 0.1       , 0.10547316],\r\n        [0.1       , 0.1       , 0.1       , 0.1085431 , 0.12422892,\r\n         0.14675722, 0.1       , 0.1       , 0.13080952, 0.1       ,\r\n         0.10276383, 0.1       , 0.12228966, 0.1       , 0.1       ],\r\n        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\r\n         0.14675722, 0.1       , 0.1       , 0.11026657, 0.1       ,\r\n         0.10526174, 0.1       , 0.1       , 0.1       , 0.1       ],\r\n        [0.1       , 0.12789923, 0.15232775, 0.13707036, 0.12422892,\r\n         0.10038066, 0.1       , 0.1       , 0.18725973, 0.1       ,\r\n         0.10276383, 0.1       , 0.12228966, 0.1       , 0.10547316],\r\n        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\r\n         0.14675722, 0.1       , 0.1       , 0.13080952, 0.1       ,\r\n         0.10276383, 0.1       , 0.12228966, 0.1       , 0.1       ],\r\n        [0.1       , 0.12789923, 0.15232775, 0.13707036, 0.1593894 ,\r\n         0.10038066, 0.1       , 0.1       , 0.18725973, 0.1       ,\r\n         0.11328223, 0.1       , 0.12228966, 0.1       , 0.10547316],\r\n        [0.1       , 0.1       , 0.1       , 0.1085431 , 0.1       ,\r\n         0.14675722, 0.1       , 0.1       , 0.13080952, 0.1       ,\r\n         0.10276383, 0.1       , 0.12228966, 0.1       , 0.1       ],\r\n        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\r\n         0.10038066, 0.1       , 0.1       , 0.18725973, 0.1       ,\r\n         0.10276383, 0.1       , 0.12228966, 0.1       , 0.10547316],\r\n        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\r\n         0.14675722, 0.1       , 0.1       , 0.13080952, 0.1       ,\r\n         0.10276383, 0.1       , 0.1       , 0.1       , 0.1       ]]],\r\n      dtype=float32)>, 'num_detections': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([20.], dtype=float32)>, 'detection_boxes_strided': <tf.Tensor: shape=(1, 20, 4), dtype=float32, numpy=\r\narray([[[ 17.574516,  41.90964 ,  95.39547 , 129.08534 ],\r\n        [ 14.911308,  52.278404,  76.05868 , 120.716576],\r\n        [ 40.389217,  56.3295  , 106.580765, 110.66548 ],\r\n        [ 19.392542,  52.051533,  71.577446, 130.94345 ],\r\n        [ 46.903793,  59.12226 , 110.06619 , 109.87272 ],\r\n        [ 45.9923  ,  55.068565, 130.97769 , 109.926414],\r\n        [ 13.78932 ,  49.960587,  73.180664, 121.03439 ],\r\n        [ 50.8581  ,  66.269066, 108.111885, 110.725914],\r\n        [ 50.157196,  62.95778 , 108.81279 , 110.0372  ],\r\n        [ 32.993404,  51.71026 ,  97.97658 , 113.28472 ],\r\n        [ 43.896847,  61.24733 , 109.073135, 111.74765 ],\r\n        [ 33.081203,  54.54843 , 103.88878 , 110.44655 ],\r\n        [ 18.6589  ,  53.10409 ,  78.31109 , 131.89088 ],\r\n        [ 12.625393,  51.296413,  70.34459 , 117.69856 ],\r\n        [ 33.52577 ,  56.973503,  99.444214, 112.02148 ],\r\n        [ 31.170174,  71.10845 ,  73.79981 , 125.88653 ],\r\n        [ 40.998966,  50.642105, 109.97102 , 106.352875],\r\n        [ 17.666685,  53.294537,  79.3033  , 127.70044 ],\r\n        [ 37.309235,  68.16062 ,  97.66075 , 126.83436 ],\r\n        [ 27.830267,  64.345505,  73.13972 , 128.64948 ]]], dtype=float32)>}\r\n", "@sandhyacs \r\nPlease share a colab gist with the error reported, i ran the code shared above but face indentation error.", "hi  @Saduf2019 \r\n\r\nhttps://drive.google.com/file/d/1fA_zG8rzNIUkJSCPa4I0KO-NnQ19YcZW/view?usp=sharing \r\nhere is the drive link of model and attached python script.\r\n\r\nhttps://drive.google.com/file/d/1Y6_WhZ5fx00MQHdwDJ5BD3mYhMXye0yB/view?usp=sharing\r\n\r\n\r\n", "hi @Saduf2019 \r\n\r\nAny update?\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@sandhyacs \r\nI tried running the code shared but face dependencies issues, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/072424147caf4c0e1b851ee8631fdf7e/untitled597.ipynb), please share a colab gist if possible with the error reported.", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 48227, "title": "Tensorflow-lite: unresolved dependencies during linking", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): arm 64 \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 85c8b2a817f95a3e979ecd1ed95bff1dc1335cff\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source): 7.4.0\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nUnresolved dependencies during linking.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nI'm creating a very easy model via following python code:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tensorflow import keras\r\n\r\nmodel = keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\r\nmodel.compile(optimizer='sgd', loss='mean_squared_error')\r\n\r\nxs = np.array([ -1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\r\nys = np.array([ -3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)\r\n\r\nmodel.fit(xs, ys, epochs=500)\r\n\r\nprint(model.predict([10.0]))\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_model = converter.convert()\r\nopen('linear.tflite', 'wb').write(tflite_model)\r\n```\r\n\r\n\r\nAfterwards I'm trying to create a simple C++ program to load and evaluate the model. But with following code which just creates the model. I'm already getting linker errors:\r\n\r\n```\r\n#include <tensorflow/lite/interpreter.h>\r\n#include <tensorflow/lite/kernels/register.h>\r\n#include <tensorflow/lite/model.h>\r\n#include <tensorflow/lite/tools/gen_op_registration.h>\r\n\r\nstd::unique_ptr<tflite::FlatBufferModel> model = tflite::FlatBufferModel::BuildFromFile(\"linear.tflite\");\r\n\r\nif(!model){\r\n    printf(\"Failed to mmap model\\n\");\r\n    exit(0);\r\n}\r\n```\r\n\r\nI observe following linker problems:\r\n\r\nlibtensorflow-lite.so: undefined reference to 'TfLiteXNNPackDelegateOptionsDefault'\r\nlibtensorflow-lite.so: undefined reference to 'TfLiteXNNPackDelegateDelete'\r\nlibtensorflow-lite.so: undefined reference to 'tflite::tools::ToolParams::Merge(tflite::tools::ToolParams const&, bool)'\r\nlibtensorflow-lite.so: undefined reference to 'TfLiteXNNPackDelegateCreate'\r\nlibtensorflow-lite.so: undefined reference to 'tflite::Flags::Parse(int*, char const**, std::vector<tflite::Flag, std::allocator<tflite::Flag> > const&)'\r\n\r\nNote that I'm building with TFLITE_ENABLE_XNNPACK=OFF. I'm using CMake for the compilation.\r\n\r\nCould anybody suggest on what's going wrong?\r\n\r\nKind regards,\r\n\r\nWannes", "comments": ["@multiverse-tf could you take a look?", "@WannesBouwen could you share the CMakeLists.txt you created for your simple C++ program? In case you are not aware of this, we have some recent updates on the cmake build guide: https://www.tensorflow.org/lite/guide/build_cmake\r\n\r\nAlso, does this issue happen w/ the HEAD? We have had multiple CMake-related changes since the commit [85c8b2a](https://github.com/tensorflow/tensorflow/commit/85c8b2a817f95a3e979ecd1ed95bff1dc1335cff).", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48227\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48227\">No</a>\n", "Hello,\r\n\r\nSorry for the late response. I've updated to the latest available changeset and the problem is not seen anymore. Thank you for the help.\r\n\r\nKind regards,\r\n\r\nWannes"]}, {"number": 48226, "title": "Mobilenet v3 keras model lack a 7x7 avgpool and cannot get reported performance", "body": "Mobilenetv3 keras model is reported as converted from its ckpt model. As I observed its structure, they are inconsistent, as keras model **lacks a 'Avgpool' layer before conv_2 layer**. As a consequence, the released mobilenetv3_large_1.0 model can only achieve top1: 72.7%, 3% lower than ckpt model.\r\n", "comments": ["@Kewenjing1020 \r\nCan you please share the code in support of the issue reported, also if possible share a colab gist with the issue reported.", "Hi @Saduf2019 , I observed the model structure via netron.app.  ", "@Kewenjing1020 \r\nPlease share simple stand alone code such that we can replicate the issue or a colab gist with the issue reported.", "@Saduf2019 please look at  #48504", "@i-bat \r\nis this a duplicate of #48504, if yes please move this to closed status as its already tracked.", "Thanks for reporting the issue. Please https://github.com/tensorflow/tensorflow/pull/48542#issuecomment-824258134 for more updates. #48542 should fix the issue."]}, {"number": 48225, "title": "how to obtain the location of input/output when create a new Op?", "body": "Hi, I am following the [doc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/pad_op.cc#L372) to implement a new tensorflow Op. For REGISTER_KERNEL_BUILDER, \r\n`REGISTER_KERNEL_BUILDER(Name(\"PadV2\")\r\n                            .Device(DEVICE_GPU)\r\n                            .TypeConstraint<int32>(\"T\")\r\n                            .TypeConstraint<int32>(\"Tpaddings\")\r\n                            .HostMemory(\"input\")\r\n                            .HostMemory(\"paddings\")\r\n                            .HostMemory(\"constant_values\")\r\n                            .HostMemory(\"output\"),\r\n                        PadOp<CPUDevice, int32, int32>);`\r\n\r\nFor my case, I need to know where the tensor is allocated. For example, for `PadV1`, the `input` might be on the gpu while for `PadV2` the `input` might be on the host memory. How can I obtain those info?\r\n", "comments": ["this issue has been resolved. We can obtain this info using `context->input_memory_type(0)`."]}, {"number": 48224, "title": "How can I find the type of quantization?", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n\r\nHow can I find out the quantization type (e.g. float16 or int8) of the tflite file after loading the .tflite file in a Python environment and creating an Interpreter through tf.lite.Interpreter?\r\n", "comments": ["@xhae could you triage this issue?", "You may use [netron app](https://github.com/lutzroeder/netron) to load your tflite file and inspect the node properties.", "> You may use [netron app](https://github.com/lutzroeder/netron) to load your tflite file and inspect the node properties.\r\n\r\nThank you, but I have to find out through code execution in Python..", "AFAIK there's no such metadata that you can read and get the quantization type directly, instead you can navigate the weights and observe the data types. Does this make sense to you?", "> AFAIK there's no such metadata that you can read and get the quantization type directly, instead you can navigate the weights and observe the data types. Does this make sense to you?\r\n\r\nYes, I was wondering if there was any other way than the way you told me. Thank you!", "\ud83d\udc4d  sorry for the inconvenience."]}, {"number": 48222, "title": "Fix GCS filesystem", "body": "This cherrypicks two changelists.", "comments": []}]