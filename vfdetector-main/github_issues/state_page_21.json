[{"number": 51643, "title": "tf.math.xdivy decorated with @tf.function returns 0 when the input is large", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.6.0\r\n- Python version: 3.7.11\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: running on CPU\r\n- GPU model and memory: running on CPU\r\n\r\n**Describe the current behavior**\r\nWhen we feed large inputs to tf.math.xdivy decorated with @tf.function, we get outputs of 0, which is wrong.\r\n\r\n**Describe the expected behavior**\r\nThe function returns correct results, just like what it does in eager mode.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n    import pickle\r\n    import tensorflow as tf\r\n    \r\n    input_path = \"tf_math_xdivy_inputs.p\"\r\n    data = pickle.load(open(input_path, 'rb'))\r\n    \r\n    fun = tf.math.xdivy\r\n    \r\n    output1 = fun(**data) \r\n    print(output1)  # the results in eager mode is correct\r\n    \r\n    @tf.function\r\n    def fun_wrapper(data):\r\n        return fun(**data)\r\n    \r\n    output2 = fun_wrapper(data)\r\n    print(output2)  # the results of tf function is wrong\r\n\r\nThe inputs are {'x': array([-3.0127542e+38+0.j], dtype=complex64), 'y': (2.0609168319398798e+37-2.2877970645017637e+38j)}.\r\n\r\nOutput1 is tf.Tensor([-0.11767363-1.3062797j], shape=(1,), dtype=complex64).\r\n\r\nOutput2 is tf.Tensor([-0.+0.j], shape=(1,), dtype=complex64).\r\n\r\nThis is the input for reproduction. Please decompress it before use.\r\n[tf_math_xdivy_inputs.p.zip](https://github.com/tensorflow/tensorflow/files/7034126/tf_math_xdivy_inputs.p.zip)\r\n\r\nWe also detect similar issues with other apis. They are: tf.nn.compute_average_loss, tf.realdiv, tf.math.sign. We can provide corresponding inputs if necessary.\r\n\r\n\r\n\r\n", "comments": ["@jiannanWang Could you please have a look at the[ link](https://www.tensorflow.org/guide/function), [link1](https://www.tensorflow.org/api_docs/python/tf/math/xdivy) and let us know if it helps? Thanks!", "Thank you for your quick response! I have read the two links you provided, but I'm afraid they don't help. I think it's a correctness issue rather than a performance issue. Can you please be clearer and maybe provide more information? Because I don't understand why these two links might be helpful.", "@sanatmpa1 Was able to replicate the issue on colab using 2.5, 2.6 and tf-nightly,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/b1bc00df59ef75d376701bd93029f4fd/untitled407.ipynb#scrollTo=sJ0t_IhtGLP9) for reference.Thank you!", "I simplified the code to reproduce and now you don't need to download the input file.\r\n\r\n    import tensorflow as tf\r\n    import numpy as np\r\n    \r\n    x = np.array([-3.e+38+0.j], dtype='complex64')\r\n    y = (2.e+37-2.e+38j)\r\n    \r\n    output1 = tf.math.xdivy(x, y)\r\n    print(output1)  # the results in eager mode is correct\r\n    \r\n    @tf.function\r\n    def fun_wrapper(x, y):\r\n        return tf.math.xdivy(x, y)\r\n    \r\n    output2 = fun_wrapper(x, y)\r\n    print(output2)  # the results of tf function is wrong\r\n\r\nIt seems to me this bug is caused by overflow or type conversion. I hope this can help you localize the bug. Thank you!", "@jiannanWang I can reproduce the issue. [Here](https://colab.research.google.com/gist/jvishnuvardhan/498379c3bd9ad6df2675ea405b7df307/untitled.ipynb) is a gist with `tf-nightly` for our reference. Thanks!", "Yes, this looks like an XLA overflow issue for complex division.  It's probably using the native complex division algorithm."]}, {"number": 51642, "title": "How to wrap a CuPy function inside a function decorated by tf.function", "body": "I have a CuPy function tweaking TF tensor as follows:\r\nTF tensor => dlpack => CuPy device array => apply some CuPy functions => CuPy device array => dlpack => TF tensor.\r\n\r\nThe code will work in eager mode, but once I decorate the function with tf.function, it won't work.\r\n\r\n```\r\ndlcapsule = tf.experimental.dlpack.to_dlpack(x)\r\nInvalidArgumentError: The argument to `to_dlpack` must be a TF tensor, not Python object\r\n```\r\n\r\nI believe the general question should be: how to wrap up a python function calling TF tensor and also returning TF tensor in graph mode? Thanks.", "comments": ["@llodds ,\r\nIn order to expedite the trouble-shooting process, could you please provide a complete code and tensorflow you are using.Thanks!", "@tilakrayal \r\n\r\nAs requested:\r\n\r\n```python\r\nimport os\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # suppress tf messages\r\nos.environ['TF_GPU_THREAD_MODE'] = 'gpu_private' # GPU has dedicated CPU threads\r\n\r\nimport tensorflow as tf\r\n# so we know exactly the GPU memory usage\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\nfor gpu in gpus:\r\n    tf.config.experimental.set_memory_growth(gpu, True)\r\n    \r\nimport cupy as cp\r\n# conversion functions between tensorflow and cupy\r\ndef tf2cp(x):\r\n    dlcapsule = tf.experimental.dlpack.to_dlpack(x)\r\n    return cp.fromDlpack(dlcapsule)\r\ndef cp2tf(x):\r\n    dlcapsule = x.toDlpack()\r\n    return tf.experimental.dlpack.from_dlpack(dlcapsule)\r\n\r\n# now, test how to use cupy with distributed TF\r\nimport numpy as np\r\nX = np.random.random_sample((100, 128, 128, 128))\r\nY = np.random.random_sample((100, 128, 128, 128))\r\ndataset = tf.data.Dataset.from_tensor_slices((X, Y))\r\ndataset = dataset.shuffle(50, reshuffle_each_iteration=True)\r\ndataset = dataset.batch(10, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\r\nstrategy = tf.distribute.MirroredStrategy()\r\ndataset_dist = strategy.experimental_distribute_dataset(dataset)\r\n\r\n\r\ndef simple_cupy_op(X, Y):\r\n    X_cp = tf2cp(X)\r\n    Y_cp = tf2cp(Y)\r\n    Y_cp = X_cp + Y_cp\r\n    X = cp2tf(X_cp)\r\n    Y = cp2tf(Y_cp)\r\n    \r\n@tf.function\r\ndef simple_cupy_op_dist(X, Y):\r\n    strategy.run(simple_cupy_op, args = (X, Y))\r\n    \r\nfor X, Y in dataset_dist:\r\n    simple_cupy_op_dist(X, Y)\r\n```\r\n\r\nError message:\r\n```\r\n    ./test_cupy_with_dist_TF.py:41 simple_cupy_op_dist  *\r\n        strategy.run(simple_cupy_op, args = (X, Y))\r\n    ./test_cupy_with_dist_TF.py:33 simple_cupy_op  *\r\n        X_cp = tf2cp(X)\r\n    ./test_cupy_with_dist_TF.py:15 tf2cp  *\r\n        dlcapsule = tf.experimental.dlpack.to_dlpack(x)\r\n    /hpc/apps/pyhpc/dist/conda/x86_64/envs/cuda-11.0/lib/python3.8/site-packages/tensorflow/python/dlpack/dlpack.py:45 to_dlpack  **\r\n        return pywrap_tfe.TFE_ToDlpackCapsule(tf_tensor)\r\n\r\n    InvalidArgumentError: The argument to `to_dlpack` must be a TF tensor, not Python object\r\n```\r\n\r\nThanks!", "@Saduf2019  ,\r\nI was able to reproduce the issue in tf v2.5,v2.6 and nightly.Please find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/a1725f8d416325727c9dd09d57490b2b/untitled64.ipynb).", "CuPy, like NumPy, is dependent on a Python runtime to run. When executing a tf.function, there is no such Python runtime - all ops are compiled into a graph that is executed inside the TF executor, which isolated from Python.\r\n\r\nTo mix such Python-reliant ops into the TF graph, you can use [py_function](https://www.tensorflow.org/api_docs/python/tf/py_function):\r\n\r\n```\r\n@tf.function\r\ndef simple_cupy_op(X, Y):\r\n    tf.py_function(simple_cupy_op, ...)\r\n```\r\n\r\ncc @yuefengz \r\n\r\nNote however that `py_function` code is not portable, and I don't think it will work well with tf.distribute. For use with tf.function / tf.distribute, my advice would be to rewrite the CuPy code into TF ops. Fundamentally, they should be similar - in both cases you'd run GPU kernels.", "@mdanatg Looks like I have to build a C++ wrapper for CuPy, and then convert it to TF ops, is that right? Can I write TF op directly from python? tf.py_function indeed doesn't work well with tf.distribute. ", "@mdanatg Is there a way/function to extract tensor from distributed replica and then gather them to produce a distributed replica? I am thinking an alternative way to use multiprocessing module to apply CuPy op on tensor directly. ", "@yuefengz would know more about the last question.\r\n\r\nFor building a wrapper over CuPy, that might be tricky, though it might work. Replacing all `cp.*` / `np.*` calls with corresponding `tf.*` might be a lot more straightforward, unless you have very large programs.", "@mdanatg @yuefengz I am using CuPy to write a customized 3D augmentation layer for device tensors. TF currently doesn't provide 3D random transformation APIs. This CuPy-based layer currently work in eager mode with strategy.run(), but nsys results show poor-overlapping among augmentation operations across multiple-GPUs, so I am thinking about either wrapping it as TF ops so it can work in graph mode or doing it outside of TF (extracting tensors from replicas and then wrapping CuPy inside multiprocessing.Process()). Now I don't know the right TF API to extract from or gather to a distributed replica. "]}, {"number": 51629, "title": "tf.image.non_max_suppression does not return a dynamic valid detection number after converting to TFLite models", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installation (pip package or built from source): pip\r\n- TensorFlow library (version, if pip package or github SHA, if built from source): 2.4.1/2.5.0/2.6.0\r\n\r\n### 2. Code\r\nhttps://colab.research.google.com/drive/1F4L9cdlhkxKHe70_5_H2SOAlH9Zl-jn-?usp=sharing\r\n\r\n### 3. Failure after conversion\r\nIf the conversion is successful, but the generated model is wrong, then state what is wrong:\r\n\r\nIn eager mode, after NMS, the valid detection number is zero. \r\nAfter conversion to the TFLite model, the shape of the `valid_detection` is always `100`.\r\nAnd I checked that `tf.shape` works flawlessly after converting to TFLite models in https://colab.research.google.com/drive/1dFeffpoi3Cd3ua6x6ny4k_-foPC8_mOe?usp=sharing\r\n\r\n### 4. (optional) RNN conversion support\r\nIf converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.\r\n\r\n### 5. (optional) Any other info / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nI check that `tf.image.non_max_suppression_padded` could output the correct valid detection number.\r\n", "comments": ["In the second colab, print(keras_model(inp)) also gave the same result with the TFLite interpreter's result.", "@srjoglekar246 could you take a look at the nms issue?", "@zldrobit To help me debug can you share the model (with NMS) here? I can take a look at the ops & help debug.", "@srjoglekar246 Of course. [The model](https://drive.google.com/file/d/131FsXY7SmDgy1-SMucm4-0cNS2gds9c7/view?usp=sharing) is an object detection model with `tf.image.non_max_suppression` op.\r\nI extract the number of valid detections by `tf.shape(selected_indices)[0]` returned from the NMS https://github.com/zldrobit/yolov5/blob/fa277e5a54ecc572bfcff1b88808ce85de5bfede/models/tf.py#L409-L410.\r\n\r\n\r\nI also add [the colab notebook](https://colab.research.google.com/drive/1MbP1jFogryuQIY581cPWNLa1wTTOXFIX?usp=sharing) to reproduce this model.", "Hi @zldrobit @ymodak  was able to replicate this issue in TF [2.6](https://colab.research.google.com/gist/mohantym/2a8cc0bc6c5aeadda3308e8bee77705c/tflite_nms_valid_det_nr.ipynb#scrollTo=oxhGNjJVDJ7m) and [2.5](https://colab.research.google.com/gist/mohantym/06a9b93aa041aa48b8fbd08376f55428/tflite_nms_valid_det_nr.ipynb#scrollTo=6NBf9_I--rHf) , got different error in TF [nightly](https://colab.research.google.com/gist/mohantym/1db4d79abb164577b91b19c98dcee1e0/tflite_nms_valid_det_nr.ipynb#scrollTo=6NBf9_I--rHf) .", "@zldrobit You are right, I played around with your script & the padded version of NMS performs correctly. This might be because we map the TF implementation of padded NMS to TFLite's custom NMS op. This essentially 'fuses' the whole NMS procedure into a single op - this does not happen for `tf.image.non_max_suppression`, which results in a big graph that is kinda buggy.\r\n\r\nThe following code snippet seems to work:\r\n\r\n```\r\ndef agnostic_nms(x):                                                                                                  \r\n    boxes, classes, scores = x                                                                                        \r\n    class_inds = tf.cast(tf.argmax(classes, axis=-1), tf.float32)                                                     \r\n    scores_inp = tf.reduce_max(scores, -1)                                                                            \r\n    selected_indices_padded, num_valid = tf.image.non_max_suppression_padded(                                                                     \r\n        boxes, scores_inp, max_output_size=100, iou_threshold=0.45, score_threshold=0.25,\r\n        pad_to_max_output_size=True)\r\n    selected_inds = tf.slice(selected_indices_padded, tf.constant([0]), tf.reshape(num_valid, [1]))\r\n    selected_boxes = tf.gather(boxes, selected_inds)                                                                  \r\n    padded_boxes = tf.pad(selected_boxes,                                                                             \r\n                          paddings=[[0, 100 - tf.shape(selected_boxes)[0]], [0, 0]],                         \r\n                          mode=\"CONSTANT\", constant_values=0.0)                                                       \r\n    selected_scores = tf.gather(scores_inp, selected_inds)                                                            \r\n    padded_scores = tf.pad(selected_scores,                                                                           \r\n                           paddings=[[0, 100 - tf.shape(selected_boxes)[0]]],                                \r\n                           mode=\"CONSTANT\", constant_values=-1.0)                                                     \r\n    selected_classes = tf.gather(class_inds, selected_inds)                                                           \r\n    padded_classes = tf.pad(selected_classes,                                                                         \r\n                            paddings=[[0, 100 - tf.shape(selected_boxes)[0]]],                               \r\n                            mode=\"CONSTANT\", constant_values=-1.0)                                                                                                                       \r\n    return padded_boxes, padded_scores, padded_classes, num_valid\r\n```\r\n\r\nJust be mindful that the output order is changed, so you will have to look at the output details to confirm.\r\n\r\nI will check if we can prioritize doing what we did for NMS padded for normal NMS as well (essentially the whole procedure of converting TF function to TFLite's fused NMS op), but we probably won't get to it this quarter.\r\n\r\nDoes using padded NMS atleast unblock your use-case?", "@srjoglekar246 Thanks for your detailed explanation. I could use padded NMS in my use case, though it will break some backward compatibility in the project.\r\n\r\nEDIT: I found that `non_max_suppression_padded` gives wrong results after converting to tfjs models. I have to use\r\n```\r\nvalid_detections = tf.reduce_sum(tf.where(selected_scores >= opt.score_thres, x=1, y=0))\r\n```\r\nwith plain `tf.image.non_max_suppression` to work with both TFLite and tfjs models.", "@srjoglekar246 I tried your code snippet that uses `tf.image.non_max_suppression_padded` and was able to get the correct # of detections. However I'm unable to run this toy model on the TFlite GPU delegate:\r\n```\r\n./android_aarch64_benchmark_model --use_gpu=true --graph=nms.tflite                                                                                          \r\nSTARTING!\r\nLog parameter values verbosely: [0]\r\nGraph: [nms.tflite]\r\nUse gpu: [1]\r\nLoaded model nms.tflite\r\nINFO: Initialized TensorFlow Lite runtime.\r\nINFO: Created TensorFlow Lite delegate for GPU.\r\nERROR: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.\r\nFailed to apply GPU delegate.\r\n```\r\nI was under the impression that `tf.image.non_max_suppression_padded` was intended to specifically address the dynamic-sized tensor issue. @zldrobit you mentioned you were having luck w/ this operation for TFlite \u2013\u00a0have you run into this issue?\r\n\r\nInspecting the model, I do notice a `While` operation. Could that be the culprit?\r\n![image](https://user-images.githubusercontent.com/20094729/136872431-e8e49a15-2740-47a6-b6ab-c31cdbe60aa7.png)\r\n\r\nModel:\r\n[nms.tflite.zip](https://github.com/tensorflow/tensorflow/files/7326062/nms.tflite.zip)\r\n\r\nTo reproduce:\r\nhttps://colab.research.google.com/drive/1F4L9cdlhkxKHe70_5_H2SOAlH9Zl-jn-?usp=sharing", "@alexdwu13 I only tested NMS with padded on CPU and didn't test it on GPU delegate.\r\nI also tested combined NMS in various situations, though some tests are not conducted. You could find the test results at https://github.com/ultralytics/yolov5/discussions/2095#discussioncomment-326401.", "@srjoglekar246 @zldrobit I just opened an issue. Feel free to follow: https://github.com/tensorflow/tensorflow/issues/52388"]}, {"number": 51622, "title": "ValueError: `tape` is required when a `Tensor` loss is passed.", "body": "**tensorflow 2.5 python 3.7**\r\n\r\nAs said in https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Optimizer?hl=en#minimize,  the first parameter of minmize should satisfy the requirement,\r\n\r\n_Tensor\u00a0or callable. If a callable,\u00a0loss\u00a0should take no arguments and return the value to minimize. If a\u00a0Tensor, the\u00a0tape\u00a0argument must be passed._\r\n\r\nThe first piece of code takes tensor as the input of minimize(), and it requires the gradient tape, but I don't know how.\r\nThe second piece of code takes callable function as the input of minimize(), which is easy \r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\nx_train = [1, 2, 3]\r\ny_train = [1, 2, 3]\r\n\r\nW = tf.Variable(tf.random.normal([1]), name='weight')\r\nb = tf.Variable(tf.random.normal([1]), name='bias')\r\nhypothesis = W * x_train + b\r\n\r\n\r\n@tf.function\r\ndef cost():\r\n    y_model = W * x_train + b\r\n    error = tf.reduce_mean(tf.square(y_train - y_model))\r\n    return error\r\n\r\n\r\noptimizer = tf.optimizers.SGD(learning_rate=0.01)\r\n\r\ncost_value = cost()\r\ntrain = tf.keras.optimizers.Adam().minimize(cost_value, var_list=[W, b])\r\n\r\ntf.print(W)\r\ntf.print(b)\r\n```\r\nHow to add the gradient tape, I know the following code certainly works.\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\nx_train = [1, 2, 3]\r\ny_train = [1, 2, 3]\r\n\r\nW = tf.Variable(tf.random.normal([1]), name='weight')\r\nb = tf.Variable(tf.random.normal([1]), name='bias')\r\nhypothesis = W * x_train + b\r\n\r\n\r\n@tf.function\r\ndef cost():\r\n    y_model = W * x_train + b\r\n    error = tf.reduce_mean(tf.square(y_train - y_model))\r\n    return error\r\n\r\n\r\noptimizer = tf.optimizers.SGD(learning_rate=0.01)\r\n\r\ncost_value = cost()\r\ntrain = tf.keras.optimizers.Adam().minimize(cost, var_list=[W, b])\r\n\r\ntf.print(W)\r\ntf.print(b)\r\n```\r\nPlease help me revise the first piece of code and let it run, thanks!\r\n", "comments": ["Hi @sjtusmartboy , was able to replicate and resolve in TF2.6 by replacing `cost = cost()`  with` cost = lambda: cost()` , providing [gist ](https://colab.research.google.com/gist/mohantym/6e008dd557ebee5d20bbd8e32c34d705/github_51622.ipynb)for reference.please look at this [documentation ](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam)for further details", "@mohantym Thanks for your code. If cost function has a 'step' parameter that I want to record, then how to pass that variable into the cost()?\r\n\r\nIn addition, cost = lambda: cost() is the lambda function, it can certainly be passed as the parameter of minimize(). Is there a way to pass the tensor as the parameter of minimize()?", "Hi @sanatmpa1 ,could you please look into this issue."]}, {"number": 51619, "title": "tensorflow-gpu Docker Image - Python TensorRT Import Fails", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1.  It must be a bug, a feature request, or a significant problem with the\r\n    documentation (for small docs fixes please send a PR instead).\r\n2.  The form below must be filled out.\r\n3.  It shouldn't be a TensorBoard issue. Those go\r\n    [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**: no\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: `tensorflow/tensorflow:2.5.1-gpu` Docker image\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**: N/A\r\n-   **TensorFlow installed from (source or binary)**: N/A\r\n-   **TensorFlow version (use command below)**: N/A\r\n-   **Python version**: N/A\r\n-   **Bazel version (if compiling from source)**: N/A\r\n-   **GCC/Compiler version (if compiling from source)**: N/A\r\n-   **CUDA/cuDNN version**: N/A\r\n-   **GPU model and memory**: N/A\r\n-   **Exact command to reproduce**: `docker run -it --rm tensorflow/tensorflow:2.5.1-gpu python`, then `import tensorrt`\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nUnable to import tensorrt in `tensorflow/tensorflow:2.5.1-gpu`,  `tensorflow/tensorflow:2.5.0-gpu`, and `tensorflow/tensorflow:2.6.0-gpu`. No modifications to images -- straight pull from Dockerhub. Have attempted first importing tensorflow, then tensorrt, but tensorrt import still fails. Below error:\r\n\r\n```\r\n>>> import tensorrt\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nModuleNotFoundError: No module named 'tensorrt'\r\n```\r\n\r\n### Source code / logs\r\nN/A\r\n", "comments": ["Hi @Saduf2019 ,Could you please look into this issue!", "@thenadz \r\nCan you please verify if the tensorrt path is correct,you may refer to [this link](make sure that your TensorRT is added do your path (LD_LIBRARY_PATH)).\r\nSimilar issues : [link](https://github.com/NVIDIA-AI-IOT/torch2trt/issues/152), [link1](https://forums.developer.nvidia.com/t/importerror-no-module-named-tensorrt-parsers/65765).\r\n\r\nIn case you still face issues: \r\nyou may also try \"pip install tensorrt\" and We need to add the path to TensorRT package to PYTHONPATH in virtual environment:\r\n\r\n(tensorflow-demo) nvidia@nvidia-nano:/usr/src/tensorrt/samples/python$ export PYTHONPATH=/usr/lib/python3.6/dist-packages:$PYTHONPATH as per [link](https://www.bojankomazec.com/2019/12/how-to-install-tensorrt-python-package.html)", "@Saduf2019 As noted in the initial question, this is within the context of the official TensorFlow GPU docker image which comes with pre-installed TensorRT and which I would expect to be setup such that TensorRT is usable out of the box. This image has no `PYTHONPATH` initialized when launching and manually setting `PYTHONPATH` equal to `/usr/local/lib/python3.6/dist-packages` does not resolve the issue. ", "And to be clear, TensorRT is already in the docker image under the above-referenced dist-pacakges path so seems clear it's *supposed* to work OOTB..."]}, {"number": 51617, "title": "XLA extension: expose output operand aliasing in ops.CustomCall python api", "body": "**System information**\r\n- TensorFlow version (you are using): latest/nightly\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nCurrently, the `output_operand_aliasing` is only exposed to CustomCallWithAliasing, which calls CustomCallWithLayout:\r\nhttps://github.com/tensorflow/tensorflow/blob/0fb82942a0b9d734f066575eeb38963de1d7d1c9/tensorflow/compiler/xla/python/ops.cc#L172-L182\r\nActually the `output_operand_aliasing` is supported without specifying operands layout. But in `CustomCall` python api it is assigned as empty:\r\nhttps://github.com/tensorflow/tensorflow/blob/0fb82942a0b9d734f066575eeb38963de1d7d1c9/tensorflow/compiler/xla/python/ops.cc#L137-L147\r\nWhy not expose the `output_operand_aliasing` in `CustomCall` python api? It will be convenient in use as users do not wanna consider layout custom calls e.g. elementwise ones or custom reduce. \r\n\r\n**Will this change the current api? How?**\r\n\r\nAs discussed above, `output_operand_aliasing` will be a args in `CustomCall` python api with default value `{}` as before. \r\n\r\n**Who will benefit with this feature?**\r\n\r\nAs discussed above. \r\n\r\n**Any Other info.**\r\n", "comments": []}, {"number": 51603, "title": "Android audio classification example does not work on a Pixel with Android 10", "body": "## URL(s) with the issue:\r\nhttps://github.com/tensorflow/examples/tree/master/lite/examples/sound_classification/android\r\n\r\n## Description of issue (what needs changing):\r\nPerhaps indicate that although hardware may support Android 6+, it may not be capable enough to run the example.\r\n\r\n### Clear description\r\nThe README.md file indicates that any device supporting Android 6+ with audio support is sufficient. While the example worked fine on my Pixel 4 XL (Android 11), it would not on my Pixel (Android 10). The screen controls are displayed, but it only displays \"Silence\" as the classification, and does not update the bar to the right as it does on my 4 XL. The slider control is also extremely slow to respond, somewhere on the order of 3/4 of a second to a second. I think the hardware just isn't capable enough to run TensorFlow even though it does support Android 10.", "comments": ["@wangtz could you take a look?"]}, {"number": 51599, "title": "`third_party/py/BUILD.tpl`: add `stub_shebang` for `py_runtime`", "body": "Bazel 4.2.0 by default uses `#!/usr/bin/env python` for all python\r\nscripts, and breaks build on systems that lack a `python` executable.\r\n\r\nThis commit adds a stub_shebang that points to the python binary\r\nspecified by ./configure.py script, the same as the interpreter_path.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F51599) for more info**.\n\n<!-- need_sender_cla -->", "@jxy  Can you please sign CLA. Thanks!", "\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F51599) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "@jxy  Can you please address Ubuntu Sanity errors? Thanks!", "`stub_shebang` is introduced to `py_runtime` only since Bazel version 4.2.0.  This change is not compatible with Bazel < 4.2.0.", "Oh, so we have to wait on this until we can upgrade to Bazel 4.2.\r\n\r\nThank you for the context.", "@mihaimaruseac Any update on this PR? Please. Thanks!", "@mihaimaruseac Any update on this PR? Please. Thanks!"]}, {"number": 51591, "title": "Tf lite model fails to provide inference - Output tensor at index 0 is expected to have 3 dimensions, found 2", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n- TensorFlow installation (pip package or built from source): 2.6.0\r\n- TensorFlow library (version, if pip package or github SHA, if built from source):  all other libraries cloned from https://github.com/tensorflow/examples/tensorflow_examples/lite/model_maker/pip_package\r\n\r\n### 2. Code\r\nTrained a model using tf lite model maker. Attaching the colab with output but without input dataset below:\r\nhttps://colab.research.google.com/drive/1RVa019JFQmODFQNPrfmpOTaSi_GMwtlE?usp=sharing\r\n\r\nConvert to tflite using model maker's **model.export()**\r\n\r\n### 3. Failure after conversion\r\nEvaluates successfully with model maker's **model.evaluate_tflite**\r\nBut fails to run inference on colab as well as with tf object detection android demo app https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android\r\n\r\nPython inference on colab:\r\n```\r\n#@title Load the trained TFLite model and define some visualization functions\r\n\r\nimport cv2\r\n\r\nfrom PIL import Image\r\n\r\nmodel_path = 'model.tflite'\r\n\r\n# Load the labels into a list\r\nclasses = ['???'] * model.model_spec.config.num_classes\r\nlabel_map = model.model_spec.config.label_map\r\nfor label_id, label_name in label_map.as_dict().items():\r\n  classes[label_id-1] = label_name\r\n\r\n# Define a list of colors for visualization\r\nCOLORS = np.random.randint(0, 255, size=(len(classes), 3), dtype=np.uint8)\r\n\r\ndef preprocess_image(image_path, input_size):\r\n  \"\"\"Preprocess the input image to feed to the TFLite model\"\"\"\r\n  img = tf.io.read_file(image_path)\r\n  img = tf.io.decode_image(img, channels=3)\r\n  img = tf.image.convert_image_dtype(img, tf.uint8)\r\n  original_image = img\r\n  resized_img = tf.image.resize(img, input_size)\r\n  resized_img = resized_img[tf.newaxis, :]\r\n  return resized_img, original_image\r\n\r\n\r\ndef set_input_tensor(interpreter, image):\r\n  \"\"\"Set the input tensor.\"\"\"\r\n  tensor_index = interpreter.get_input_details()[0]['index']\r\n  input_tensor = interpreter.tensor(tensor_index)()[0]\r\n  input_tensor[:, :] = image\r\n\r\n\r\ndef get_output_tensor(interpreter, index):\r\n  \"\"\"Retur the output tensor at the given index.\"\"\"\r\n  output_details = interpreter.get_output_details()[index]\r\n  tensor = np.squeeze(interpreter.get_tensor(output_details['index']))\r\n  return tensor\r\n\r\n\r\ndef detect_objects(interpreter, image, threshold):\r\n  \"\"\"Returns a list of detection results, each a dictionary of object info.\"\"\"\r\n  # Feed the input image to the model\r\n  set_input_tensor(interpreter, image)\r\n  interpreter.invoke()\r\n\r\n  # Get all outputs from the model\r\n  boxes = get_output_tensor(interpreter, 0)\r\n  classes = get_output_tensor(interpreter, 1)\r\n  scores = get_output_tensor(interpreter, 2)\r\n  count = int(get_output_tensor(interpreter, 3))\r\n\r\n  results = []\r\n  for i in range(count):\r\n    if scores[i] >= threshold:\r\n      result = {\r\n        'bounding_box': boxes[i],\r\n        'class_id': classes[i],\r\n        'score': scores[i]\r\n      }\r\n      results.append(result)\r\n  return results\r\n\r\n\r\ndef run_odt_and_draw_results(image_path, interpreter, threshold=0.5):\r\n  \"\"\"Run object detection on the input image and draw the detection results\"\"\"\r\n  # Load the input shape required by the model\r\n  _, input_height, input_width, _ = interpreter.get_input_details()[0]['shape']\r\n\r\n  # Load the input image and preprocess it\r\n  preprocessed_image, original_image = preprocess_image(\r\n      image_path,\r\n      (input_height, input_width)\r\n    )\r\n\r\n  # Run object detection on the input image\r\n  results = detect_objects(interpreter, preprocessed_image, threshold=threshold)\r\n\r\n  # Plot the detection results on the input image\r\n  original_image_np = original_image.numpy().astype(np.uint8)\r\n  for obj in results:\r\n    # Convert the object bounding box from relative coordinates to absolute\r\n    # coordinates based on the original image resolution\r\n    ymin, xmin, ymax, xmax = obj['bounding_box']\r\n    xmin = int(xmin * original_image_np.shape[1])\r\n    xmax = int(xmax * original_image_np.shape[1])\r\n    ymin = int(ymin * original_image_np.shape[0])\r\n    ymax = int(ymax * original_image_np.shape[0])\r\n\r\n    # Find the class index of the current object\r\n    class_id = int(obj['class_id'])\r\n\r\n    # Draw the bounding box and label on the image\r\n    color = [int(c) for c in COLORS[class_id]]\r\n    cv2.rectangle(original_image_np, (xmin, ymin), (xmax, ymax), color, 2)\r\n    # Make adjustments to make the label visible for all objects\r\n    y = ymin - 15 if ymin - 15 > 15 else ymin + 15\r\n    label = \"{}: {:.0f}%\".format(classes[class_id], obj['score'] * 100)\r\n    cv2.putText(original_image_np, label, (xmin, y),\r\n        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\r\n\r\n  # Return the final image\r\n  original_uint8 = original_image_np.astype(np.uint8)\r\n  return original_uint8\r\n```\r\n```\r\n#@title Run object detection and show the detection results\r\n\r\nINPUT_IMAGE_URL = \"https://storage.googleapis.com/cloud-ml-data/img/openimage/3/2520/3916261642_0a504acd60_o.jpg\" #@param {type:\"string\"}\r\nDETECTION_THRESHOLD = 0.3 #@param {type:\"number\"}\r\n\r\nTEMP_FILE = '/tmp/image.png'\r\n\r\n!wget -q -O $TEMP_FILE $INPUT_IMAGE_URL\r\nim = Image.open(TEMP_FILE)\r\nim.thumbnail((512, 512), Image.ANTIALIAS)\r\nim.save(TEMP_FILE, 'PNG')\r\n\r\n# Load the TFLite model\r\ninterpreter = tf.lite.Interpreter(model_path=model_path)\r\ninterpreter.allocate_tensors()\r\n\r\n# Run inference and draw detection result on the local copy of the original file\r\ndetection_result_image = run_odt_and_draw_results(\r\n    TEMP_FILE,\r\n    interpreter,\r\n    threshold=DETECTION_THRESHOLD\r\n)\r\n\r\n# Show the detection result\r\nImage.fromarray(detection_result_image)\r\n```\r\nError:\r\n\r\n> ---------------------------------------------------------------------------\r\n> TypeError                                 Traceback (most recent call last)\r\n> <ipython-input-19-2bfddfa5022e> in <module>()\r\n>      19     TEMP_FILE,\r\n>      20     interpreter,\r\n> ---> 21     threshold=DETECTION_THRESHOLD\r\n>      22 )\r\n>      23 \r\n> \r\n> 1 frames\r\n> <ipython-input-18-568dde2e930c> in run_odt_and_draw_results(image_path, interpreter, threshold)\r\n>      77 \r\n>      78   # Run object detection on the input image\r\n> ---> 79   results = detect_objects(interpreter, preprocessed_image, threshold=threshold)\r\n>      80 \r\n>      81   # Plot the detection results on the input image\r\n> \r\n> <ipython-input-18-568dde2e930c> in detect_objects(interpreter, image, threshold)\r\n>      51   classes = get_output_tensor(interpreter, 1)\r\n>      52   scores = get_output_tensor(interpreter, 2)\r\n> ---> 53   count = int(get_output_tensor(interpreter, 3))\r\n>      54 \r\n>      55   results = []\r\n> \r\n> TypeError: only size-1 arrays can be converted to Python scalars\r\n\r\nAndroid studio fatal exception:\r\n\r\n> E/AndroidRuntime: FATAL EXCEPTION: main\r\n>     Process: org.tensorflow.lite.examples.detection, PID: 27414\r\n>     java.lang.AssertionError: Error occurred when initializing ObjectDetector: Output tensor at index 0 is expected to have 3 dimensions, found 2.\r\n>         at org.tensorflow.lite.task.vision.detector.ObjectDetector.initJniWithByteBuffer(Native Method)\r\n>         at org.tensorflow.lite.task.vision.detector.ObjectDetector.access$100(ObjectDetector.java:86)\r\n>         at org.tensorflow.lite.task.vision.detector.ObjectDetector$3.createHandle(ObjectDetector.java:211)\r\n>         at org.tensorflow.lite.task.core.TaskJniUtils.createHandleFromLibrary(TaskJniUtils.java:91)\r\n>         at org.tensorflow.lite.task.vision.detector.ObjectDetector.createFromBufferAndOptions(ObjectDetector.java:207)\r\n>         at org.tensorflow.lite.examples.detection.tflite.TFLiteObjectDetectionAPIModel.<init>(TFLiteObjectDetectionAPIModel.java:87)\r\n>         at org.tensorflow.lite.examples.detection.tflite.TFLiteObjectDetectionAPIModel.create(TFLiteObjectDetectionAPIModel.java:81)\r\n>         at org.tensorflow.lite.examples.detection.DetectorActivity.onPreviewSizeChosen(DetectorActivity.java:99)\r\n>         at org.tensorflow.lite.examples.detection.CameraActivity$7.onPreviewSizeChosen(CameraActivity.java:446)\r\n>         at org.tensorflow.lite.examples.detection.CameraConnectionFragment.setUpCameraOutputs(CameraConnectionFragment.java:357)\r\n>         at org.tensorflow.lite.examples.detection.CameraConnectionFragment.openCamera(CameraConnectionFragment.java:362)\r\n>         at org.tensorflow.lite.examples.detection.CameraConnectionFragment.access$300(CameraConnectionFragment.java:66)\r\n>         at org.tensorflow.lite.examples.detection.CameraConnectionFragment$3.onSurfaceTextureAvailable(CameraConnectionFragment.java:171)\r\n>         at android.view.TextureView.getTextureLayer(TextureView.java:415)\r\n>         at android.view.TextureView.draw(TextureView.java:360)\r\n>         at android.view.View.updateDisplayListIfDirty(View.java:21389)\r\n>         at android.view.View.draw(View.java:22254)\r\n>         at android.view.ViewGroup.drawChild(ViewGroup.java:4541)\r\n>         at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4302)\r\n>         at android.view.View.updateDisplayListIfDirty(View.java:21380)\r\n>         at android.view.View.draw(View.java:22254)\r\n>         at android.view.ViewGroup.drawChild(ViewGroup.java:4541)\r\n>         at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4302)\r\n>         at android.view.View.updateDisplayListIfDirty(View.java:21380)\r\n>         at android.view.View.draw(View.java:22254)\r\n>         at android.view.ViewGroup.drawChild(ViewGroup.java:4541)\r\n>         at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4302)\r\n>         at android.view.View.draw(View.java:22538)\r\n>         at android.view.View.updateDisplayListIfDirty(View.java:21389)\r\n>         at android.view.View.draw(View.java:22254)\r\n>         at android.view.ViewGroup.drawChild(ViewGroup.java:4541)\r\n>         at androidx.coordinatorlayout.widget.CoordinatorLayout.drawChild(CoordinatorLayout.java:1246)\r\n>         at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4302)\r\n>         at android.view.View.draw(View.java:22538)\r\n>         at android.view.View.updateDisplayListIfDirty(View.java:21389)\r\n>         at android.view.View.draw(View.java:22254)\r\n>         at android.view.ViewGroup.drawChild(ViewGroup.java:4541)\r\n>         at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4302)\r\n>         at android.view.View.updateDisplayListIfDirty(View.java:21380)\r\n>         at android.view.View.draw(View.java:22254)\r\n>         at android.view.ViewGroup.drawChild(ViewGroup.java:4541)\r\n>         at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4302)\r\n>         at android.view.View.updateDisplayListIfDirty(View.java:21380)\r\n>         at android.view.View.draw(View.java:22254)\r\n>         at android.view.ViewGroup.drawChild(ViewGroup.java:4541)\r\n>         at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4302)\r\n>         at android.view.View.updateDisplayListIfDirty(View.java:21380)\r\n>         at android.view.View.draw(View.java:22254)\r\n>         at android.view.ViewGroup.drawChild(ViewGroup.java:4541)\r\n>         at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4302)\r\n>         at android.view.View.updateDisplayListIfDirty(View.java:21380)\r\n>         at android.view.View.draw(View.java:22254)\r\n>         at android.view.ViewGroup.drawChild(ViewGroup.java:4541)\r\n>         at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4302)\r\n> E/AndroidRuntime:     at android.view.View.draw(View.java:22538)\r\n>         at com.android.internal.policy.DecorView.draw(DecorView.java:848)\r\n>         at android.view.View.updateDisplayListIfDirty(View.java:21389)\r\n>         at android.view.ThreadedRenderer.updateViewTreeDisplayList(ThreadedRenderer.java:559)\r\n>         at android.view.ThreadedRenderer.updateRootDisplayList(ThreadedRenderer.java:565)\r\n>         at android.view.ThreadedRenderer.draw(ThreadedRenderer.java:647)\r\n>         at android.view.ViewRootImpl.draw(ViewRootImpl.java:4417)\r\n>         at android.view.ViewRootImpl.performDraw(ViewRootImpl.java:4144)\r\n>         at android.view.ViewRootImpl.performTraversals(ViewRootImpl.java:3391)\r\n>         at android.view.ViewRootImpl.doTraversal(ViewRootImpl.java:2182)\r\n>         at android.view.ViewRootImpl$TraversalRunnable.run(ViewRootImpl.java:8730)\r\n>         at android.view.Choreographer$CallbackRecord.run(Choreographer.java:1352)\r\n>         at android.view.Choreographer.doCallbacks(Choreographer.java:1149)\r\n>         at android.view.Choreographer.doFrame(Choreographer.java:1049)\r\n>         at android.view.Choreographer$FrameHandler.handleMessage(Choreographer.java:1275)\r\n>         at android.os.Handler.dispatchMessage(Handler.java:106)\r\n>         at android.os.Looper.loop(Looper.java:233)\r\n>         at android.app.ActivityThread.main(ActivityThread.java:8010)\r\n>         at java.lang.reflect.Method.invoke(Native Method)\r\n>         at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:631)\r\n>         at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:978)\r\n\r\nThis is a new issue that has cropped up since tf version upgrade to 2.6.0 and model maker to 0.3.3\r\nI have older models trained the same way that work perfectly fine on both colab and with the demo app.\r\nIs there something else that needs to be added while exporting the tflite model or is there some version conflict that is causing this.  Does anybody have any clue about this error?", "comments": ["@ziyeqinghan could you take a look?\r\n", "Hi @craditya @ziyeqinghan , I was getting error in this line    \r\n`model = object_detector.create(train_data, model_spec=spec, batch_size=4, epochs = 30, train_whole_model=True, validation_data=validation_data)`\r\nin TF [2.5](https://colab.research.google.com/gist/mohantym/b1a48789106bca188e34c3b367629c4d/copy-of-model-maker-object-detection-tutorial.ipynb#scrollTo=kwlYdTcg63xy) , [2..6 ,](https://colab.research.google.com/gist/mohantym/b1a48789106bca188e34c3b367629c4d/copy-of-model-maker-object-detection-tutorial.ipynb#scrollTo=kwlYdTcg63xy) [2.7](https://colab.research.google.com/gist/mohantym/7765d1cf7d4ac4eeeceecce8b7ac2e1f/copy-of-model-maker-object-detection-tutorial.ipynb#scrollTo=kwlYdTcg63xy).", "Hi @mohantym, if you followed my colab, you need to upload some data as train_data, test_data and validation_data.\r\nOr you could use the default example data provided in the example code, which can be loaded by:\r\n`train_data, validation_data, test_data = object_detector.DataLoader.from_csv('gs://cloud-ml-data/img/openimage/csv/salads_ml_use.csv')`\r\nAfter this try running \r\n`model = object_detector.create(train_data, model_spec=spec, batch_size=4, epochs = 30, train_whole_model=True, validation_data=validation_data)`\r\n\r\nOr was it some other error completely?", "I have the same error trying to infer on Android. Also opened a question on stackoverflow: https://stackoverflow.com/questions/68908871/output-tensor-size-mismatch-with-ssd-fpn-models-on-mobile", "so that means this issue is not just limited to tflite model maker library, but more so because of tf lite converter \r\n@abattery @mohantym ", "Hi @ymodak  ,Could you please look into this issue!", "I'm Having the same issue. I hope they can figure it out ASAP :)", "By adding some `print` statements in `detect_objects` and eyeballing the data, it looks rather like the order of the output tensors has changed.\r\n\r\nI can make the thing run to completion by swapping around the indices in the middle section of `detect_objects` as follows:\r\n\r\n```python\r\n  # Get all outputs from the model\r\n  boxes = get_output_tensor(interpreter, 1)\r\n  classes = get_output_tensor(interpreter, 3)\r\n  scores = get_output_tensor(interpreter, 0)\r\n  count = int(get_output_tensor(interpreter, 2))\r\n```\r\n\r\n~That said, I'm getting utterly useless detection results out of this from my own model, and I haven't yet figured out why, so there may be deeper problems.~\r\n\r\nEDIT: The useless detection results I was getting turned out to be down to a silly mistake elsewhere. So this fix seems to be working well for me.", "> I'm Having the same issue. I hope they can figure it out ASAP :)\r\n\r\nSo i have used model maker 0.32 and tensorflow 2.5.0 and my model is now working fine", "@jawj I would try the same and provide an update. Thanks for figuring out a resolution.", "> > I'm Having the same issue. I hope they can figure it out ASAP :)\r\n> \r\n> So i have used model maker 0.32 and tensorflow 2.5.0 and my model is now working fine\r\n\r\n@hallowcard13 Yes, I had mentioned above that I have been facing this issue with the new version and not with the old ones, for both model maker and tf.", "> \r\n> \r\n> > > I'm Having the same issue. I hope they can figure it out ASAP :)\r\n> > \r\n> > \r\n> > So i have used model maker 0.32 and tensorflow 2.5.0 and my model is now working fine\r\n> \r\n> @hallowcard13 Yes, I had mentioned above that I have been facing this issue with the new version and not with the old ones, for both model maker and tf.\r\n\r\nPlz, I have the same problem but I don't get what I should do to solve it. Can u help me?", "> \r\n> \r\n> By adding some `print` statements in `detect_objects` and eyeballing the data, it looks rather like the order of the output tensors has changed.\r\n> \r\n> I can make the thing run to completion by swapping around the indices in the middle section of `detect_objects` as follows:\r\n> \r\n> ```python\r\n>   # Get all outputs from the model\r\n>   boxes = get_output_tensor(interpreter, 1)\r\n>   classes = get_output_tensor(interpreter, 3)\r\n>   scores = get_output_tensor(interpreter, 0)\r\n>   count = int(get_output_tensor(interpreter, 2))\r\n> ```\r\n> \r\n> ~That said, I'm getting utterly useless detection results out of this from my own model, and I haven't yet figured out why, so there may be deeper problems.~\r\n> \r\n> EDIT: The useless detection results I was getting turned out to be down to a silly mistake elsewhere. So this fix seems to be working well for me.\r\nI tried your solution and it is working with me. but, I get very bad result detection. can you tell me what you do to fix it\r\n", "How on earth can this problem be solved?", "Swapping the indices seems to be working.\r\nSame can be done for the android app as well with lib interpreter. Refer below link.\r\n[https://discuss.tensorflow.org/t/object-detection-android-app-creates-error-with-model-from-tflite-model-maker-it-had-worked-for-many-weeks-a-until-a-few-weeks-ago/4015/9](url)\r\nThe official fix from forums is to use tf 2.5 till they fix the issue. Refer below link.\r\n[https://discuss.tensorflow.org/t/invalidargumenterror-required-broadcastable-shapes-op-mul/3824](url)", "> How on earth can this problem be solved?\r\n\r\n- If you are running inference in just python and not using online editors that provide accelerators like colab, you can just use tf 2.5\r\n- If you are running inference in just python and using online editors that provide accelerators like colab, downgrading to tf 2.5 doesn't seem to work for me. Anyway, colab warns against pip installing tensorflow, stating that it might not work. Instead you can try swapping the indices as mentioned in above solutions to get inference. And if `model.evaluate_tflite('model.tflite', test_data)` doesn't work you can install model-maker-nightly for that.\r\n- If you running inference in the android app, change the build variant to lib interpreter instead of lib task api, and swap the indices in the code for lib interpreter as mentioned in my previous comment.\r\n", "Can you please reassign this thread to the right people, as I can see from the forums Khanh LeViet and Yuqi Li have said to be fixing this issue @abattery "]}, {"number": 51585, "title": "For loop in \"call\" function not working with Autograph/tf.range", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code : Yes\r\n- OS Platform and Distribution : Windows 10\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 2.3.0\r\n- Python version: 3.8.8\r\n- CUDA/cuDNN version: N/A (testing on CPU)\r\n- GPU model and memory: N/A (see above)\r\n\r\nI am training a set of models in parallel as part of a more elaborate training procedure so as a result I am trying to implement a call function like the following one:\r\n\r\n    class multi_model_test(tf.keras.Model):\r\n        def __init__(self, num_models,width,depth):\r\n            super(multi_model_test, self).__init__()\r\n\r\n            self.n_traces = num_models\r\n            self.net_list = []\r\n            for i in range(self.n_traces):\r\n                net = tf.keras.models.Sequential()\r\n                net.add(tf.keras.Input(shape = (1,)))\r\n                for i in range(depth):\r\n                    net.add(tf.keras.layers.Dense(width,activation = 'swish'))\r\n                net.add(tf.keras.layers.Dense(1))\r\n                self.net_list.append(net)\r\n\r\n\r\n        def call(self,ipts):\r\n            outlist = []\r\n            for i in tf.range(self.n_traces):\r\n                outlist.append(self.net_list[i](ipts))\r\n            out = tf.stack(outlist,-1)\r\n            return out\r\n\r\nWhen I build this as follows:\r\n```\r\nmodel = multi_model_test(10,50,10)\r\nmodel.build((None,1))\r\n```\r\nI get the following error:\r\n\r\n``ValueError: You cannot build your model by calling `build` if your layers do not support float type inputs. Instead, in order to instantiate and build your model, `call` your model on real tensor data (of the correct dtype).``\r\n\r\nThis appears to be a bug since the error here clearly does not affect the input, and this model can take float inputs. If I exchange the `tf.range` for simply `range` in the for loop in the call function I don't have an issue but then this doesn't work with Autograph and training takes a very long time.\r\n\r\n\r\n\r\n", "comments": ["Hi @adgolden1 @sanatmpa1 , I was able to replicate this issue in TF[ 2.2](https://colab.research.google.com/gist/mohantym/204f53b156323fd57010066f61a4ef50/github_51585_2-2.ipynb) ,[ 2.3](https://colab.research.google.com/gist/mohantym/0dedb74f823767975328fab3cf96a2e9/github_51585_2-3.ipynb) ,[2.4 ](https://colab.research.google.com/gist/mohantym/d6b8d58e5c766a45913548e1df2e71f2/github_51585_2-4.ipynb) and TF [2.6](https://colab.research.google.com/gist/mohantym/4b3c942a0c6abe2780452fcb204719d1/github_51585_2-6.ipynb) , issue does not persist when only used only range in call method instead of tf.range", "That's true but if only `range` is used then Autograph cannot process the model and I have found that to slow down the training substantially.", "@tomerk can probably tell more, but the error message seems wrong.\r\n\r\nLooking at the code, using `tf.range` would index a Python list (`self.net_list`) using a Tensor (`i` is a Tensor when the loop is over `tf.range`), which isn't supported. The same happens for appending to outlist, which needs to be a TensorArray; Python lists are not supported in `tf.range` loops at the moment.\r\n\r\nStill, while it should be possible to make that example work with `tf.range`, in the end it will probably not give you a speedup, because the model graphs need to be constructed anyway - so instead of having one large graph that contains every model in `self.net_list`, you'd have a while loop with a large body that contains every model in `self.net_list`."]}, {"number": 51583, "title": "Tensorflow 2.6 built without s3 support.", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian Linux, python 3.7. \r\n- TensorFlow installed from (source or binary): binary using pip\r\n- TensorFlow version: 2.6.0\r\n- Python version: 3.7, 3.8\r\n- Installed using virtualenv? pip? conda?: venv, conda\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\ntensorflow 2.6.0 built without s3 support however it was made default since 1.4.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n```\r\n$ pip install tensorflow==2.6.0\r\nCollecting tensorflow==2.6.0\r\n  Downloading tensorflow-2.6.0-cp37-cp37m-manylinux2010_x86_64.whl (458.3 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 458.3 MB 31 kB/s \r\n...\r\nInstalling collected packages: tensorflow\r\n  Attempting uninstall: tensorflow\r\n    Found existing installation: tensorflow 2.4.1\r\n    Uninstalling tensorflow-2.4.1:\r\n      Successfully uninstalled tensorflow-2.4.1\r\nSuccessfully installed tensorflow-2.6.0\r\n\r\n$ python\r\nPython 3.7.6 (default, Jan  8 2020, 19:59:22) \r\n[GCC 7.3.0] :: Anaconda, Inc. on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> from tensorflow.python.lib.io import file_io\r\n2021-08-20 08:47:18.398430: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\r\n2021-08-20 08:47:18.398446: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n>>> print(file_io.stat(\"s3://bucket/model\"))\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/bacek/miniconda3/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py\", line 871, in stat\r\n    return stat_v2(filename)\r\n  File \"/home/bacek/miniconda3/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py\", line 887, in stat_v2\r\n    return _pywrap_file_io.Stat(compat.path_to_str(path))\r\ntensorflow.python.framework.errors_impl.UnimplementedError: File system scheme 's3' not implemented (file: 's3://bucket/model')\r\n>>> \r\n\r\n```\r\n", "comments": ["This is intended. It is part of [modularization project](https://github.com/tensorflow/community/blob/master/rfcs/20190506-filesystem-plugin-modular-tensorflow.md) from 2 years ago and has been announced well in advance.\r\n\r\n[SIG IO](https://github.com/tensorflow/io) now has support for these filesystems.", "See also #51032.", "That PR https://github.com/tensorflow/tensorflow/pull/51432 removed update on Modular Filesystem from `RELEASE.md`.", "@mihaimaruseac Is there any documentation on how to enable S3 support with tfio? I assume dtfio should only need to be installed for this to work but I still get the same error message.", "@ConverJens  The way to use s3 is to just import tfio:\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow_io as tfio\r\n\r\nv = tf.io.read_file('s3://1234567')\r\n```\r\n\r\nThat will give you the s3 access.", "@yongtang Thanks for the clarification!\r\n\r\nI'm using TFX from master which recently started depending on TF 2.6, hence I can't (or don't want to/shouldn't) modify the internals. I suspect they will fix this by the next release.", "@ConverJens In case of TFX I think you may want to create issue there. @bacek can you confirm the issue is resolved with tfio installation?", "Yes, installing and explicitly importing tfio fixed this issue. However\nRELEASE.md needs updating.\n\nOn Mon, 23 Aug 2021, 23:16 Yong Tang, ***@***.***> wrote:\n\n> @ConverJens <https://github.com/ConverJens> In case of TFX I think you\n> may want to create issue there. @bacek <https://github.com/bacek> can you\n> confirm the issue is resolved with tfio installation?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/51583#issuecomment-903758044>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAAFFEOWWKTDRZIICI4QEIDT6JCZXANCNFSM5CPFF6CA>\n> .\n> Triage notifications on the go with GitHub Mobile for iOS\n> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>\n> or Android\n> <https://play.google.com/store/apps/details?id=com.github.android&utm_campaign=notification-email>\n> .\n>\n", "I believe `tf.io.gfile` doc has to be updated as well https://www.tensorflow.org/api_docs/python/tf/io/gfile/GFile It refers to s3 and hdfs like they are supported out of the box.", "@numerology Just adding in someone from the TFX team since TFT 1.3 just dropped and that uses TF 2.6 explicitly so this will affect all future versions of TFX it seems.", "I reached out to resolve a similar error. \r\n\r\nBy using https://github.com/tensorflow/tensorflow/issues/51583#issuecomment-902786636 comment, \r\nI succeeded to use tf.io.gfile APIs such as tf.io.gfile.exists and so on. \r\n\r\nBut tf.io.gfile.rename still failed when I run the below codes. \r\n\r\n```\r\n(py37) hyunseok@poc-gpu1:~/work/w4$ python\r\nPython 3.7.9 (default, May 23 2021, 05:54:20)\r\n[GCC 8.4.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n2021-09-08 05:30:51.506696: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\r\n2021-09-08 05:30:51.506723: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n>>> import tensorflow_io as tfio\r\n>>> tf.__version__\r\n'2.6.0'\r\n>>> tf.io.gfile.exists('s3://aiq-poodle-dev/test/test.txt')\r\nTrue\r\n>>> tf.io.gfile.rename('s3://aiq-poodle-dev/test/test.txt', 's3://aiq-poodle-dev/test/test-new.txt')\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/hyunseok/.venv/py37/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py\", line 626, in rename_v2\r\n    compat.path_to_bytes(src), compat.path_to_bytes(dst), overwrite)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: InvalidRequest: Unable to parse ExceptionName: InvalidRequest Message: You must specify at least one part\r\n>>>\r\n```\r\n\r\n\r\n\r\n\r\n", "@yongtang ,\r\nImporting `tensorflow_io` doesn't always fix it. In my case it doesn't work when I execute from a PEX file. PEX has all the dependencies including tfio, and I do import `tensorflow_io` but I get the error stated in the description. When executed with dependencies installed by pip, it works. What is the mechanism that is used to register S3 support in tensorflow itself? Is there any way I can trigger it explicitly rather than by importing `tensorflow_io`?\r\n\r\n", "@andrey-klochkov-liftoff I don't have experience with PEX file. Can you share a minimal reproducible steps that exposes the issue you mentioned. Also, are you running on Windows or Linux/macOS? Note s3 (and gcs) may not work correctly on Windows yet due to #49515 (which will be fixed if PR #49520 can be merged)", "@yongtang , it's hard for me to create a minimal reproducible artifact that'd demo the problem. Still, I think I see why it's happening. The `tensorflow_io_gcs_filesystem==0.20.0` wheel contains file `tensorflow_io/python/ops/__init__.py` that attempts to load library `libtensorflow_io.so` and fails to do so as this native library is not included into this wheel package. It seems to me that the intention was to make the gcs wheel load only `libtensorflow_io_gcs_filesystem.so` and initiate loading of the other tfio libraries from the `tensorflow_io` wheel, but that's not how it works under certain circumstances. It's hard to pinpoint when exactly `tensorflow_io_gcs_filesystem` starts initializing before `tensorflow_io` but when it does, syspath gets package `tensorflow.core.ops` pointing to `tensorflow_io_gcs_filesystem`, making it impossible to load the libraries.", "@andrey-klochkov-liftoff the `tensorflow_io_gcs_filesystem` will provide an alternative gcs support for tensorflow. However, if you are referring to s3 support then the invocation happens:\r\nhttps://github.com/tensorflow/io/blob/master/tensorflow_io/python/ops/__init__.py#L96", "@yongtang , if you download the `tensorflow_io_gcs_filesystem` wheel and unpack it, and grep for `libtensorflow_io.so`, you'll see that it contains a copy of the source file you're referring to:\r\n\r\n```\r\n$ pip download tensorflow_io_gcs_filesystem==0.20.0\r\nCollecting tensorflow_io_gcs_filesystem==0.20.0\r\nSaved ./tensorflow_io_gcs_filesystem-0.20.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\nSuccessfully downloaded tensorflow-io-gcs-filesystem\r\n\r\n$ unzip ./tensorflow_io_gcs_filesystem-0.20.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\n# output skipped\r\n\r\n$ rg libtensorflow_io.so\r\ntensorflow_io_gcs_filesystem-0.20.0.data/purelib/tensorflow_io/python/ops/__init__.py\r\n94:core_ops = LazyLoader(\"core_ops\", \"libtensorflow_io.so\")\r\n99:    # Note: load libtensorflow_io.so imperatively in case of statically linking\r\n101:        core_ops = _load_library(\"libtensorflow_io.so\")\r\n102:        plugin_ops = _load_library(\"libtensorflow_io.so\", \"fs\")\r\n```", "@yongtang , the root cause is the way the packages are built. Here are the steps demoing the problem:\r\n\r\n1. Build `tensorflow-io` wheel with \r\n\r\n    python setup.py bdist_wheel\r\n\r\n2. Build `tensorflow-io-gcs-filesystem`:\r\n\r\n    python setup.py bdist_wheel --project tensorflow-io-gcs-filesystem \r\n\r\n3. Check if `tensorflow_io` sources are included in the package (they shouldn't but they are):\r\n\r\n    unzip -l dist/tensorflow_io_gcs_filesystem-0.20.0-cp38-cp38-macosx_11_0_x86_64.whl | grep 'tensorflow_io/' | wc -l \r\n    103\r\n    \r\nIf I remove the `build` directory after step (1), then the package created at step (2) wouldn't contain `tensorflow_io` files. From a quick search at stackoverflow and `setuptools` docs, it seems there's no easy way to make `setuptools` do such clean up automatically from `setup.py` but `python setup.py clean -a` can be used between steps. \r\n\r\nThat's exactly what was done by #1476 but by some reason the `tensorflow_io_gcs_filesystem==0.20.0` package at pypi.org still has that problem while `0.21.0` doesn't have it. \r\n\r\nI guess no action is necessary. I'm posting all these details for those who can stumble into the same issue.", "@andrey-klochkov-liftoff yes the issue was fixed and applied in 0.21.0. For 0.20.0 as pip did not allow updating already published packages so we have to leave as is.", "@yongtang \r\n\r\nAre there any guide to resolve tf.io.gfile.rename issue? https://github.com/tensorflow/tensorflow/issues/51583#issuecomment-914930409 \r\n\r\nI tested it both Mac and Linux env with tensorflow-io==0.21.0 by using python3.7 new venv.\r\n\r\n**Linux**\r\n```\r\n$ python\r\nPython 3.7.9 (default, May 23 2021, 05:54:20)\r\n[GCC 8.4.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n2021-09-15 00:44:44.535239: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\r\n2021-09-15 00:44:44.535265: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n>>> import tensorflow_io as tfio\r\n>>> tfio.__version__\r\n'0.21.0'\r\n>>> tf.io.gfile.exists('s3://aiq-poodle-dev/test/test.txt')\r\nTrue\r\n>>> tf.io.gfile.rename('s3://aiq-poodle-dev/test/test.txt', 's3://aiq-poodle-dev/test/test-new.txt')\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/hyunseok/.venv/py37/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py\", line 624, in rename_v2\r\n    compat.path_to_bytes(src), compat.path_to_bytes(dst), overwrite)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: InvalidRequest: Unable to parse ExceptionName: InvalidRequest Message: You must specify at least one part\r\n```\r\n\r\n**Mac**\r\n```\r\n(py37) hyunseok:w4$ python\r\nPython 3.7.9 (v3.7.9:13c94747c7, Aug 15 2020, 01:31:08)\r\n[Clang 6.0 (clang-600.0.57)] on darwin\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> import tensorflow_io as tfio\r\n>>> tfio.__version__\r\n'0.21.0'\r\n>>> tf.io.gfile.exists('s3://aiq-poodle-dev/test/test.txt')\r\nTrue\r\n>>> tf.io.gfile.rename('s3://aiq-poodle-dev/test/test.txt', 's3://aiq-poodle-dev/test/test-new.txt')\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/hyunseok/.venv/py37/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py\", line 624, in rename_v2\r\n    compat.path_to_bytes(src), compat.path_to_bytes(dst), overwrite)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: InvalidRequest: Unable to parse ExceptionName: InvalidRequest Message: You must specify at least one part\r\n```"]}, {"number": 51582, "title": "An easy way to update tensors that complies with numpy syntax", "body": "**System information**\r\n- TensorFlow version (you are using): 2.6\r\n- Are you willing to contribute it (Yes/No): No (wouldn't know how)\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI would love to be able to do something like the following:\r\n```python\r\nt1 = np.zeros((2, 4))\r\nt2 = np.ones((2, 3))\r\n\r\nt1[:, 1:4] += t2\r\nt1[:, [3, 1, 1]] += t2\r\n```\r\nwithout having to use methods like `tensor_scatter_nd_update` over multiple lines of code...\r\n\r\n**Will this change the current api? How?**\r\nyes, it will be possible to use a syntax like in numpy, that everyone is familiar with.\r\n\r\n**Who will benefit with this feature?**\r\neveryone who needs to build tensors manually", "comments": ["TF tensors are supposed to be immutable", "Hi @ziofil !  \r\nWe see that the issue template has not been filled, could you please do so as it helps us analyse the issue .Thanks", "> TF tensors are supposed to be immutable\r\n\r\nI know, but then again there are methods like [`tf.tensor_scatter_nd_update`](https://www.tensorflow.org/api_docs/python/tf/tensor_scatter_nd_update), so effectively tensor are mutable if one uses the right methods. So why not allowing a clearer syntax?", "> Hi @ziofil !\r\n> We see that the issue template has not been filled, could you please do so as it helps us analyse the issue .Thanks\r\n\r\nDone.", "Hi @ziofil  , Got workaround on above operation using .numpy() and convert_to_tensor() method. \r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nt1 = tf.constant(np.zeros((2, 4)))\r\nt2 = tf.constant(np.ones((2, 3)))\r\nt1 = t1.numpy()\r\nt2 = t2.numpy()\r\n\r\nt1[:, 1:4] += t2\r\nprint(t1)\r\nprint(\"tensor_format\")\r\nt3=tf.convert_to_tensor(t1)\r\nprint(t3)\r\nt1[:, [3, 1, 1]] += t2\r\nprint(t1)\r\nprint(\"tensor_format\")\r\nt3=tf.convert_to_tensor(t1)\r\nprint(t3)\r\n```\r\nPlease find the [gist](https://colab.research.google.com/drive/143pBxmc1t_sSbRQ2yY68sLe8MafrNWgV?resourcekey=0-ttOkVT7mupjxZQwlpoh6UA#scrollTo=_9y6HqvPgvkO) for reference", "Thanks for the idea, but this is not differentiable... ", "Hi @sanatmpa1 ,Could you please look into this issue!"]}, {"number": 51572, "title": "[TFLite] Add int8 and int16x8 support for TRANSPOSE_CONV_3D operator", "body": "Hello,\r\n\r\nThis PR adds quantizable int8 and int16x8 implementations of Conv3DTranspose operator.\r\nThis PR depends on the [PR that adds support for int8 and int16x8 Conv3D operator](https://github.com/tensorflow/tensorflow/pull/51527) to be merged first.\r\n\r\nCheers,\r\nEddie", "comments": ["@teijeong @thaink could you review this PR?", "@teijeong, @thaink Can you please review this PR ? Thanks!", "@teijeong, @thaink  Can you please review this PR ? Thanks!", "@georgeedward2000 Can you please resolve conflicts? Thanks!", "@georgeedward2000 Can you please resolve conflicts? Thanks!", "@georgeedward2000 Can you please resolve conflicts? Thanks!", "> @georgeedward2000 Can you please resolve conflicts? Thanks!\r\n\r\nThanks, The merge conflict has now been resolved.\r\nBest regards,\r\nSaoirse"]}, {"number": 51561, "title": "LSTM & BiLSTM can't run correct results while batch processing on Mobile ", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux and Android\r\n- TensorFlow installed from (source or binary): pip install\r\n- TensorFlow version (or github SHA if from source): tensorflow2.5.0-gpu\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\nrun_model = tf.function(lambda x: basemodel(x))\r\n# This is important, let's fix the input size.\r\nBATCH_SIZE = 1\r\nSTEPS = 32\r\nINPUT_SIZE = 320\r\nCHANNEL = 1\r\nconcrete_func = run_model.get_concrete_function(\r\n  tf.TensorSpec([BATCH_SIZE, STEPS, INPUT_SIZE, CHANNEL], basemodel.inputs[0].dtype))\r\n\r\n\r\nMODEL_DIR = \"BiLSTM\"\r\nbasemodel.save(MODEL_DIR, save_format=\"tf\", signatures=concrete_func)\r\n\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_types = [tf.float16]\r\ntflite_model = converter.convert()\r\nopen(\"BiLSTM.tflite\", \"wb\").write(tflite_model)\r\n\r\n```\r\n\r\n**Standalone code to reproduce the issue** \r\nWe developed a text recognition model including BiLSTM basing on TF2.5, and convert the model to TFlite, which can run on mobile GPU successfully. \r\n\r\nWhile the batch size=1, the model can recognize the text correctly. But when btachsize>1, only the first batch result is correct, and others are incorrect. And before using the tflite model, we need to reset all variables:\r\n```\r\ninterpreter.reset_all_variables()\r\ninterpreter.set_tensor(input_details[0]['index'], X)\r\ninterpreter.invoke()\r\ny_pred = interpreter.get_tensor(output_details[0]['index'])\r\n```\r\nI think the LSTM states need to be reset after being called. Is there any solution to reset them within a batch?\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem.\r\nIf including tracebacks, please include the full traceback. Large logs and files\r\nshould be attached.\r\n", "comments": ["Yes, you need to call `interpreter.reset_all_variables()` after each `interpreter.invoke()`.\r\n\r\nIt should work for batch inference as well.", "> Yes, you need to call `interpreter.reset_all_variables()` after each `interpreter.invoke()`.\r\n> \r\n> It should work for batch inference as well.\r\n\r\nWe have added the `interpreter.reset_all_variables()` after each `interpreter.invoke()`. And the batch process can run well on the computer. However when we deployed this model to mobile,  the results are inconsistent. It seems that there is no status reset for each instance inside the batch. For example, we concat 4 images into (4,32,320,1) as the input, but only the first image can have correct prediction while the rest of them are wrong. \r\n\r\nCan you check the LSTM or BiLSTM implementation for the mobile phone and add the reset status inside the batch process for the sequence model?", "I see, adding YC.\r\n\r\nOn mobile (assume you're using c++), the equivalent c++ call is : **ResetVariableTensors**: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/interpreter.h#L624", "I have added this call: ResetVariableTensors, but it only works after the\ninterpreter invoke, not working for the LSTM inside the batch.\n\nOn Thu, Aug 19, 2021 at 17:45 renjie-liu ***@***.***> wrote:\n\n> I see, adding YC.\n>\n> On mobile (assume you're using c++), the equivalent c++ call is :\n> *ResetVariableTensors*:\n> https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/interpreter.h#L624\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/51561#issuecomment-902347128>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AIAHRB23YXGPJ76PFTAKQZ3T5WQSXANCNFSM5CM77HDA>\n> .\n> Triage notifications on the go with GitHub Mobile for iOS\n> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>\n> or Android\n> <https://play.google.com/store/apps/details?id=com.github.android&utm_campaign=notification-email>\n> .\n>\n", "Hi Renjie, \r\nThis is our engineering code:\r\n\r\n`//reset variables for models like lstm\r\n        if(config.resetVariable) {\r\n            interpreter.resetVariableTensors();\r\n        }\r\n        interpreter.runForMultipleInputsOutputs(inputBuffers, outputs);`\r\n\r\nAnd this is our model output:\r\n![image](https://user-images.githubusercontent.com/33585287/130269494-728a5376-da72-44d3-b7e5-c815e33f9512.png)\r\n\r\n\r\nThe prediction on the top is the tflite results on the computer and the bottom is from a mobile device. Is there anyway to reset the status of LSTM inside the batch?", "I see, in this case, I suggest there are two options:\r\n\r\n1) run prediction 1 by 1, it should always work\r\n2) if you really need batch inference, please set the batch_size during model conversion, and run the fixed batch size inference as well", "Hi,\r\n\r\nWe already used the fixed batch size while converting the tflite model\r\n\r\n`run_model = tf.function(lambda x: basemodel(x))\r\n  BATCH_SIZE = 4\r\n  STEPS = 32\r\n  INPUT_SIZE = 320\r\n  CHANNEL = 1\r\n  concrete_func = run_model.get_concrete_function(\r\n      tf.TensorSpec([BATCH_SIZE, STEPS, INPUT_SIZE, CHANNEL], basemodel.inputs[0].dtype))\r\n  MODEL_DIR = \"model\"\r\n  basemodel.save(MODEL_DIR, save_format=\"tf\", signatures=concrete_func)\r\n  \r\n  converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)\r\n  converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n  converter.target_spec.supported_types = [tf.float16]\r\n  tflite_model = converter.convert()\r\n  open(\"model.tflite\", \"wb\").write(tflite_model)`\r\n\r\nIs it possible that tensorflow team can solve this bug?"]}, {"number": 51559, "title": "Need TF-TRT support to INT32 OPs", "body": "Currently, some TF-TRT converters already allow INT32 data types. Need to find out other TensorRT layers that support INT32 data types and make the TF-TRt converters to reflect that. Need to add test cases.", "comments": []}, {"number": 51556, "title": "Faster R-CNN TFlite conversion and inference works on CPU, but when run on GPU results in segmentation fault during inference", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Debian\r\n- TensorFlow installation (pip package or built from source): pip\r\n- TensorFlow library (version, if pip package or github SHA, if built from source): 2.5.0\r\n\r\n### 2. Code\r\n\r\n#### Option B: Paste your code here or provide a link to a custom end-to-end colab\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport cv2 as cv\r\nimport time\r\n\r\ndef reduce_size(im,percent=None,new_width=None):\r\n    '''\r\n    Get a reduced size version of an image\r\n    \r\n    Inputs:\r\n        im: numpy array of an image\r\n        percent: if not None, the percent at which to scale the image\r\n        new_width: if not None, the new width to scale the image to (scales the\r\n                   height proportinally)\r\n                   \r\n    Returns: numpy array of new, smaller image\r\n    \r\n    Note: please only set either percent OR new_width, it doesn't make sense\r\n          to set both\r\n    '''\r\n    \r\n    if percent:\r\n        width = int(im.shape[1] * percent / 100)\r\n        height = int(im.shape[0] * percent / 100)\r\n        dim = (width, height)\r\n    elif new_width:\r\n        new_percent = new_width / im.shape[1]\r\n        height = int(im.shape[0] * new_percent)\r\n        dim = (new_width,height)\r\n        \r\n    small_im = cv.resize(im,dim,interpolation = cv.INTER_AREA)\r\n    \r\n    return small_im\r\n\r\nprint('tensorflow version: %s' %tf.__version__)\r\n\r\ntf.config.list_physical_devices()\r\n\r\nsaved_model_dir = 'faster_rcnn_resnet50_v1_800x1333_coco17_gpu-8/saved_model'\r\n\r\nimg_path = 'Test_image.jpg'\r\nim = cv.imread(img_path)\r\nsmall_im = reduce_size(im,percent=10)\r\ninput_tensor = tf.convert_to_tensor(small_im)\r\ninput_tensor = input_tensor[tf.newaxis, ...]\r\n\r\nprint('Loading model normally...', end='')\r\nstart_time = time.time()\r\ndetect_fn = tf.saved_model.load(saved_model_dir)\r\nelapsed_time = end_time - start_time\r\nprint('Done! Took {} seconds'.format(elapsed_time))\r\n\r\nprint('Inferring...', end='')\r\nstart_time = time.time()\r\ndetections = detect_fn(input_tensor)\r\nend_time = time.time()\r\nelapsed_time = end_time - start_time\r\nprint('Done! Took {} seconds'.format(elapsed_time))\r\n\r\nprint('Converting model to tflite...', end='')\r\nstart_time = time.time()\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\r\nconverter.allow_custom_ops=True\r\nconverter.experimental_new_converter = True\r\n\r\nconverter.target_spec.supported_ops = [\r\ntf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\r\ntf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\r\n]\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_types = [tf.float16]\r\nend_time = time.time()\r\nelapsed_time = end_time - start_time\r\ntflite_model = converter.convert()\r\nprint('Done! Took {} seconds'.format(elapsed_time))\r\n\r\nprint('Creating an interpreter...', end='')\r\nstart_time = time.time()\r\ninterpreter = tf.lite.Interpreter(model_content=tflite_model)\r\n\r\ninput_index = interpreter.get_input_details()[0][\"index\"]\r\noutput_index = interpreter.get_output_details()[0][\"index\"]\r\n\r\ninterpreter.resize_tensor_input(0, [1, input_tensor.shape[1], input_tensor.shape[2], 3])\r\ninterpreter.allocate_tensors()\r\nend_time = time.time()\r\nelapsed_time = end_time - start_time\r\nprint('Done! Took {} seconds'.format(elapsed_time))\r\n\r\nprint('Inferring image...', end='')\r\nstart_time = time.time()\r\ninterpreter.set_tensor(input_index, input_tensor)\r\ninterpreter.invoke()\r\nraw_prediction = interpreter.tensor(output_index)\r\nend_time = time.time()\r\nelapsed_time = end_time - start_time\r\nprint('Done! Took {} seconds'.format(elapsed_time))\r\n\r\n```\r\nExample model used:  [Faster R-CNN ResNet50 V1 800x1333](http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_800x1333_coco17_gpu-8.tar.gz) from the tensorflow 2.0 model zoo\r\n\r\nTest image I'm currently using (this is just to get any output at all, I plan to use a different image to test bounding boxes once I can get the code working):\r\n![Test_image](https://user-images.githubusercontent.com/50996925/129928612-b0baa83e-4f0e-46bb-b47c-fbee8c8fca7a.jpg)\r\n\r\n### 3. Failure after conversion\r\n\r\nThe above code runs fine on a CPU, but when run on a GPU, a segmentation fault is raised during the interpreter.invoke() command. I have tried a number of different options for the conversion step of converter.target_spec.supported_types = [tf.float16], including uint16 and some of the more experimental options, as well as just completely not including that step. In all cases, the code works on the CPU and results in a segment fault on the GPU, although for some the segmentation fault occurs much faster than with others.\r\n\r\nI expect there is some fix in the conversion script, but I'm not sure if it's a problem with my commands, or if a model this large is not yet possible to use with TFlite on a GPU.\r\n", "comments": ["fyi @impjdi @renjie-liu ", "Can you try just tf.float for GPU first? thanks!", "Sure! When I run that I just get the error\r\n\r\n```\r\n  File \"tflite_test.py\", line 79, in <module>\r\n    converter.target_spec.supported_types = [tf.float]\r\nAttributeError: module 'tensorflow' has no attribute 'float'\r\n```\r\nDoes that require an updated tensorflow version?", "sorry I mean tf.float32", "Oh, ok. That one results in the segmentation fault."]}, {"number": 51548, "title": " how to get the middle layer of tflite model with c++ API", "body": "I want to know how to get the middle layer of tflite model with c++ API\r\ni find some information in https://github.com/tensorflow/tensorflow/issues/49129, but it present with python\r\nthen I use the PreserveAllTensorsExperimental() of interpreterbuilder and interpreter->tensor() to extract middle layer tensor, but the tensor which i got is null, so how to do this correct with c++ API ?\r\n\r\n", "comments": []}, {"number": 51547, "title": "Initializing TFLite model causes crash on iOS", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.5.0\r\n\r\n**Describe the current behavior**\r\nThe model only has a preprocessing layer, being converted and tested to run successfully in Python environment. But when initializing this model on iOS project, it causes a crash on this side.\r\n\r\n**Describe the expected behavior**\r\nExpected to initialize and run successfully on iOS project.\r\n\r\n**Standalone code to reproduce the issue**\r\nUse the `get_mel_spectrogram()` function from kapre, [here](https://github.com/keunwoochoi/kapre/blob/ff6fe77cda572ee8eac4f35502925b62a84e491d/kapre/composed.py#L138), to create a custom mel-spectrogram layer in Tensorflow, then, convert to TFLite. \r\n\r\nBoth the conversion and inference process run successfully in the Python environment but fail when initializing this model on the iOS project. The iOS project is mainly based on this [Tensorflow iOS tutorial](https://github.com/tensorflow/examples/tree/master/lite/examples/sound_classification/ios).\r\n\r\nFor convenience, the TFLite model is [here](https://drive.google.com/file/d/1BQt8Yi0H-WouBm48NYh_r78zrSfG0Oif/view?usp=sharing)\r\n\r\n**Other info / logs** Log of the crash on iOS:\r\n```\r\nException Type:  EXC_BAD_ACCESS (SIGSEGV)\r\nException Subtype: KERN_INVALID_ADDRESS at 0xd4000000010691ad\r\nVM Region Info: 0xd4000000010691ad is not in any region.  Bytes after previous region: 15276209455021593006  \r\n      REGION TYPE                 START - END      [ VSIZE] PRT/MAX SHRMOD  REGION DETAIL\r\n      commpage (reserved)     1000000000-7000000000 [384.0G] ---/--- SM=NUL  ...(unallocated)\r\n--->  \r\n      UNUSED SPACE AT END\r\nTermination Signal: Segmentation fault: 11\r\nTermination Reason: Namespace SIGNAL, Code 0xb\r\nTerminating Process: exc handler [3629]\r\nTriggered by Thread:  0\r\nThread 0 name:  Dispatch queue: com.apple.main-thread\r\nThread 0 Crashed:\r\n0   MyApp                   0x0000000105eca898 0x10293c000 + 56158360\r\n1   MyApp                   0x0000000105eca884 0x10293c000 + 56158340\r\n2   MyApp                   0x0000000105ec8fc0 0x10293c000 + 56152000\r\n3   MyApp                   0x0000000105eca670 0x10293c000 + 56157808\r\n4   MyApp                   0x0000000105ec4054 0x10293c000 + 56131668\r\n5   MyApp                   0x0000000106138eb0 0x10293c000 + 58707632\r\n6   MyApp                   0x00000001066a698c 0x10293c000 + 64399756\r\n7   MyApp                   0x000000010677f398 0x10293c000 + 65287064\r\n8   MyApp                   0x00000001068d7c54 0x10293c000 + 66698324\r\n9   MyApp                   0x00000001068d850c 0x10293c000 + 66700556\r\n10  MyApp                   0x0000000106748880 0x10293c000 + 65063040\r\n11  MyApp                   0x0000000106748760 0x10293c000 + 65062752\r\n12  MyApp                   0x0000000106679834 0x10293c000 + 64215092\r\n13  MyApp                   0x00000001066791dc 0x10293c000 + 64213468\r\n14  MyApp                   0x0000000106675c30 0x10293c000 + 64199728\r\n15  MyApp                   0x0000000106675828 0x10293c000 + 64198696\r\n16  MyApp                   0x000000010665df2c 0x10293c000 + 64102188\r\n17  MyApp                   0x000000010665f35c 0x10293c000 + 64107356\r\n18  UIKitCore                       0x00000001b5e3b27c 0x1b5308000 + 11743868\r\n19  UIKitCore                       0x00000001b57d0254 0x1b5308000 + 5014100\r\n20  UIKitCore                       0x00000001b57d0598 0x1b5308000 + 5014936\r\n21  UIKitCore                       0x00000001b57ceed0 0x1b5308000 + 5009104\r\n22  UIKitCore                       0x00000001b5e75f8c 0x1b5308000 + 11984780\r\n23  UIKitCore                       0x00000001b5e778b4 0x1b5308000 + 11991220\r\n24  UIKitCore                       0x00000001b5e52e50 0x1b5308000 + 11841104\r\n25  UIKitCore                       0x00000001b5ed545c 0x1b5308000 + 12375132\r\n26  UIKitCore                       0x00000001b5ed9bfc 0x1b5308000 + 12393468\r\n27  UIKitCore                       0x00000001b5ed0ee0 0x1b5308000 + 12357344\r\n28  CoreFoundation                  0x00000001b3551be0 0x1b34b7000 + 633824\r\n29  CoreFoundation                  0x00000001b3551ae0 0x1b34b7000 + 633568\r\n30  CoreFoundation                  0x00000001b3550e28 0x1b34b7000 + 630312\r\n31  CoreFoundation                  0x00000001b354b3d0 0x1b34b7000 + 607184\r\n32  CoreFoundation                  0x00000001b354ab90 0x1b34b7000 + 605072\r\n33  GraphicsServices                0x00000001c986d598 0x1c986a000 + 13720\r\n34  UIKitCore                       0x00000001b5e34638 0x1b5308000 + 11716152\r\n35  UIKitCore                       0x00000001b5e39bb8 0x1b5308000 + 11738040\r\n36  libswiftUIKit.dylib             0x00000001c6325b54 0x1c6312000 + 80724\r\n37  MyApp                   0x000000010667101c 0x10293c000 + 64180252\r\n38  MyApp                   0x0000000106670f94 0x10293c000 + 64180116\r\n39  MyApp                   0x00000001066710b4 0x10293c000 + 64180404\r\n40  libdyld.dylib                   0x00000001b3229588 0x1b3228000 + 5512\r\nThread 0 crashed with ARM Thread State (64-bit):\r\n    x0: 0x000000016d4bf510   x1: 0x0000dc41303f3980   x2: 0x0000000000000003   x3: 0x0000000105eca83c\r\n    x4: 0x000000016d4bfd68   x5: 0x000000016d4bfd60   x6: 0x0000000000000073   x7: 0x000000016d4bfad8\r\n    x8: 0x34000000010691ad   x9: 0x00000002803c3980...\r\n``` \r\n", "comments": ["Can you also provide the exact code that you used? Or did you use the unmodified version of the example app and just replaced the model file in it?\r\n\r\nWithout the exact reproduction steps, I can only guess that this is probably caused somewhere around setting the input / output tensors in your app code.", "I actually modified the source code to meet my purpose, but I believe it is not too different from the original version of the example app. \r\n\r\nTo be more specific, the app crashes as soon as we initialize the model, which is this line of code:\r\n```python\r\ninterpreter = try Interpreter(modelPath: modelPath)\r\n```\r\n\r\nSo I believe you can reproduce the issue with the example app code and the model I provided above. If the issue is not reproduced, please tell me so we can investigate further.\r\n\r\nAnother insight that I gained throughout different trials was to \r\n- **Implement a TF Layer using customized TFLite-compatible version of STFT (which is [here](https://github.com/magenta/magenta/blob/41b891c137e8a51bd44322f0434ba8f3f7df0dba/magenta/models/onsets_frames_transcription/melspec_input.py))** --> This works OKAY on iOS.\r\n- **Implement a TF Layer using the [TF implementation of STFT](https://www.tensorflow.org/api_docs/python/tf/signal/stft) and convert it to TFLite (I also used SelectOps for this option)**  --> This causes crash on iOS but works okay in Python environment.\r\n\r\nSo my guess is the STFT itself, but you may find another root cause of this issue.\r\n\r\nThank you so much.", "Using the unmodified Sound Classification example with TFLite v2.5.0 dependencies with your model, I get a different error:\r\n\r\n```\r\n2021-09-09 22:05:18.309457+0900 SoundClassification[94397:26097954] Initialized TensorFlow Lite runtime.\r\n2021-09-09 22:05:18.309730+0900 SoundClassification[94397:26097954] Created TensorFlow Lite delegate for select TF ops.\r\n2021-09-09 22:05:18.311150+0900 SoundClassification[94397:26097954] TfLiteFlexDelegate delegate: 1 nodes delegated out of 59 nodes with 1 partitions.\r\nFatal error: Index out of range: file /AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/swiftlang/swiftlang-1103.2.25.8/swift/stdlib/public/core/ContiguousArrayBuffer.swift, line 444\r\n2021-09-09 22:05:20.487987+0900 SoundClassification[94397:26097954] Fatal error: Index out of range: file /AppleInternal/BuildRoot/Library/Caches/com.apple.xbs/Sources/swiftlang/swiftlang-1103.2.25.8/swift/stdlib/public/core/ContiguousArrayBuffer.swift, line 444\r\n```\r\n\r\nBased on the log message, it doesn't seem to be crashing immediately after the TFLite runtime initialization."]}, {"number": 51544, "title": "[INTEL MKL] BF16/FP32 RandomUniform vectorization opt on CPU", "body": "This PR is trying to bring this reverted #39747 back.\r\nIt changed the `Distribution` result length from fixed length `4` to `Eigen::internal::packet_traits<T>::size` and do computation with Eigen::Tensor to use Eigen packet feature for vectorization.\r\n\r\nPerf test cmd:\r\n```\r\nbazel run --distdir=./ --cxxopt=-D_GLIBCXX_USE_CXX11_ABI=0 --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mavx512f --copt=-mavx512pf --copt=-mavx512cd --copt=-mavx512bw --copt=-mavx512dq --copt=-DENABLE_INTEL_MKL_BFLOAT16  -- //tensorflow/core/kernels:random_op_test --benchmarks=..\r\n```\r\n\r\nBefore opt:\r\n```\r\nBM_cpu_RandomUniform_DT_BFLOAT16/1048576     424794       1666\t 2469.91857M items/s\r\nBM_cpu_RandomUniform_DT_BFLOAT16/2097152     667125        795\t 3147.52320M items/s\r\nBM_cpu_RandomUniform_DT_BFLOAT16/8388608    1877948        327\t 4480.56133M items/s\r\n```\r\n\r\nAfter opt: improved by 1.3~1.4x\r\n```\r\nBM_cpu_RandomUniform_DT_BFLOAT16/1048576     326237       2019\t 3215.74854M items/s\r\nBM_cpu_RandomUniform_DT_BFLOAT16/2097152     458964       1457\t 4572.45684M items/s\r\nBM_cpu_RandomUniform_DT_BFLOAT16/8388608    1396453        422\t 6021.31872M items/s\r\n```\r\n\r\nSigned-off-by: Lu Teng teng.lu@intel.com", "comments": ["@agramesh1 here's the RandomUniform vectorization PR, please help to communicate to verify this PR since it may cause some internal errors.", "@penpornk  Can you please review this PR ? Thanks!", "@penpornk Can you please review this PR ? Thanks!", "@Zantares Can you please resolve conflicts? Thanks!", "> @Zantares Can you please resolve conflicts? Thanks!\r\n\r\nDone.", "@tatianashp Can you please review this PR ? Thanks!", "I am not the right person to review this. \r\n@penpornk Can you help with this PR?", "@penpornk  Can you please review this PR ? Thanks!", "@penpornk Can you please review this PR ? Thanks!", "@penpornk Can you please review this PR ? Thanks!"]}, {"number": 51536, "title": "Support compression type \"SNAPPY\" in Tensorflow Python API", "body": "**System information**\r\n- TensorFlow version (you are using): 2.5.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\nFrom https://www.tensorflow.org/api_docs/python/tf/io/TFRecordOptions?hl=en, it does not appear that TensorFlow (up till v2.6.0) supports \"SNAPPY\" as a compression type in the Python API. However, in c++ source code https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/lib/io/record_writer.h#L44, this is already supported. For my use case, \"SNAPPY\" is preferred over \"ZLIB\" or \"GZIP\". Therefore, having \"SNAPPY\" as an option in Python TFRecord API is a desirable feature.\r\n\r\n**Will this change the current api? How?**\r\nYes. The `compression_type` field of TFRecordOptions will have valid values of \"GZIP\",\u00a0\"ZLIB\", \"SNAPPY\"(new) or\u00a0\"\"\u00a0(no compression).\r\n\r\n**Who will benefit with this feature?**\r\nUsers who want to use snappy as their compression algorithm in order to take advantage of its speed.\r\n\r\n**Any Other info.**\r\n\r\n", "comments": ["Hi!@zxiu2049 !We  see that the issue template has not been filled, Could you please do so as it helps us analyse the issue . ", "> Hi!@zxiu2049 !We see that the issue template has not been filled, Could you please do so as it helps us analyse the issue .\r\n\r\nHi @mohantym ! Thanks for the response. Modified the description based on the feature request template. Please let me know if that works. ", "Hi @Saduf2019  ,Could you please look into this issue ?", "Something like this works in the meantime until it's officially added:\r\n```\r\ndef enable_snappy_compression():\r\n    \"\"\"\r\n    Workaround Snappy not being a public option yet.\r\n    \"\"\"\r\n    tf.io.TFRecordOptions.compression_type_map[3] = \"SNAPPY\"\r\n```\r\nand then just:\r\n```\r\ntf.data.TFRecordDataset(file, compression_type=\"SNAPPY\")\r\n```"]}, {"number": 51532, "title": "tf.print() mixes up the keys and values in a nested dictionary, leading to incorrect representation of the object content", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -\r\n- TensorFlow installed from (source or binary): pip binary\r\n- TensorFlow version (use command below): 2.6.0\r\n- Python version: 3.7.11\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n**Describe the current behavior**\r\n\r\ntf.print mixes up the order of dictionary keys and values when printing a dict which is nested inside a namedtuple. See example below, tf.print claims that the key 'a' has the value 2, when in fact it has the value 1.\r\n\r\n**Describe the expected behavior**\r\n\r\ntf.print represents the content of the object correctly.\r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://colab.research.google.com/gist/Andreas5739738/d8abda0605692c3a37c28ba94da510d6/notebook.ipynb\r\n```\r\nimport tensorflow as tf\r\nfrom collections import namedtuple\r\n\r\n# create a dict inside a namedtuple\r\nX = namedtuple('X', ['x', 'y'])\r\ndata = X(x=tf.constant([0]), y={'b': tf.constant([2]), 'a': tf.constant([1])})\r\n\r\ndataset = tf.data.Dataset.from_tensor_slices(data)\r\noutput_item = list(dataset)[0]\r\n\r\nprint(f'Actual tensor content:\\n{output_item}\\n')\r\n\r\nprint('tf.print mixes up the order of the keys and values in the dict:')\r\ntf.print(output_item)\r\n```\r\nOutput:\r\n```\r\nActual tensor content:\r\nX(x=<tf.Tensor: shape=(), dtype=int32, numpy=0>, y={'b': <tf.Tensor: shape=(), dtype=int32, numpy=2>, 'a': <tf.Tensor: shape=(), dtype=int32, numpy=1>})\r\n\r\ntf.print mixes up the order of the keys and values in the dict:\r\nX(x=0, y={'b': 1, 'a': 2})\r\n```\r\n\r\n", "comments": ["_@Andreas5739738_ I am not pretty sure what it is exactly but I could find out that `tf.print` kernels do get into an issue when we define tensors inside nested python sets. \r\n\r\n_Do you have any inputs from your end?_\r\n\r\nHere's the link: [Exceptions](https://github.com/tensorflow/community/blob/master/rfcs/20180824-tf-print-v2.md#supported-input-types)\r\n\r\nSpecifically these points :\r\n![image](https://user-images.githubusercontent.com/64011471/129771214-f9c8992d-3d31-46e0-8410-8c229cb052ff.png)\r\n", "The nested structure I am using (namedtuple and dict) seems well supported by tf.nest otherwise, at least I haven't observed any problems anywhere in my data pipeline so far. tf.print seems to be the only operator that has issues with this setup.", "Hi! @Andreas5739738 ! I followed  [tf.dataset ](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#as_numpy_iterator)documentation , replaced` output_item = list(dataset)[0] ` with` output_item = list(dataset.as_numpy_iterator())[0]`and was able to replicate and resolve this issue in 2.6. please find the [gist ](https://colab.research.google.com/gist/mohantym/f5d044e710da26e6da6191c83dbd4863/notebook.ipynb#scrollTo=xWKC7vEbKIQz)for reference. Thanks!", "Hi, I don't think using as_numpy_iterator is a viable workaround for this bug in tf.print, since it will not work in graph mode. I came across this bug originally when printing dataset items inside a Dataset.map function (which runs in graph mode).", "Hi!@Andreas5739738 , Could you please try the above work around fix and update whether fix is working or not in graph mode? ", "Hi, tf.print is the only option I know of that can print output in graph mode. Neither `print()` nor `tensor.to_numpy()` are available in graph mode. So this is not a workaround that can be used in graph mode.", "Hi! @sanatmpa1 ,Could you please look into this issue , providing [gist](https://colab.research.google.com/gist/mohantym/f5d044e710da26e6da6191c83dbd4863/notebook.ipynb#scrollTo=xWKC7vEbKIQz) for reference."]}, {"number": 51527, "title": "[TFLite] Add int8 and int16x8 support for CONV_3D operator", "body": "Hello,\r\n\r\nThis PR adds quantizable int8 and int16x8 implementations of Conv3D operator. \r\nIt also adds support for 5D tensors per axis (/per channel) quantization.\r\n\r\nThanks,\r\nEddie", "comments": ["@jianlijianli could you review this change?", "@jianlijianli  Can you please review this PR ? Thanks!", "@georgeedward2000 Can you please resolve conflicts? Thanks!", "> @georgeedward2000 Can you please resolve conflicts? Thanks!\r\n\r\nThanks, the conflicts should be fixed now.\r\nbest regards,\r\nSaoirse"]}, {"number": 51526, "title": "CUDA information inconsistent in PyPI (and missing in release notes)", "body": "@jvishnuvardhan, #43712 is not solved, unfortunately: it is still hard to find out which CUDA version has been used to build TensorFlow pip packages.\r\n\r\n- Good: v2.5 release notes list \"CUDA11.2 and cuDNN 8.1.0\":\r\nhttps://github.com/tensorflow/tensorflow/releases/tag/v2.5.0\r\n\r\n- Bad: v2.6 release notes don't mention any CUDA/CuDNN information at all:\r\nhttps://github.com/tensorflow/tensorflow/releases/tag/v2.6.0\r\n\r\nOne might assume that v2.6 uses the same CUDA 11.2 as v2.5 if release notes don't report any change. (Still, it would be hard to find that information a few releases from now.)\r\n\r\nPyPI might be a good source for this type of information. However:\r\n\r\n- While PyPI lists \"GPU :: NVIDIA CUDA :: 11.2\" for `tf-nightly`, it lists \"GPU :: NVIDIA CUDA :: 11.0\" for `tensorflow` v2.6 (and v2.5):\r\nhttps://pypi.org/project/tf-nightly/2.7.0.dev20210815/\r\nhttps://pypi.org/project/tensorflow/2.6.0/\r\n\r\n", "comments": ["Agree with you that the info is inconsistent. best place to look at is TF webpage https://www.tensorflow.org/install/source_windows#gpu . You can see tested build configuration for most of the released branches. \r\n\r\nYou can also check here https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/pip_package/setup.py for dependencies.  \r\n\r\n@mihaimaruseac Please take a look at this issue. Thanks!", "@jvishnuvardhan thanks, these links are very helpful. From these, I can also see that the issue has been introduced in April (https://github.com/tensorflow/tensorflow/commit/68e6c8da5a56b4895114ec47fc6aeccb8027de88) and fixed some 10 days ago (https://github.com/tensorflow/tensorflow/commit/3daf758918c40c00560101b2395ffa96e8fea656), at least for 2.7.0 onwards. \r\n\r\nNot sure if past PyPI packages can be fixed.", "Sadly, they cannot.\r\n\r\nWe attempted to fix this on PyPI a few months ago but the tag was not available so packages would not be able to be uploaded."]}, {"number": 51521, "title": "libcudnn_adv_train.so not found when using LSTM, unless I run a BatchNorm before", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS Linux 7.9.2009\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.5.0\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source): 3.7.2\r\n- GCC/Compiler version (if compiling from source): GCC 9.3.0\r\n- CUDA/cuDNN version: CUDA 11.1, cuDNN 8.2\r\n- GPU model and memory: NVidia V100 16GB\r\n\r\n**Describe the current behavior**\r\n\r\nPlease note that I have CUDA and cuDNN installed in custom directories. This causes problems in dynamically loading cuDNN libs. (To be able to use TF with custom CUDA/cuDNN paths, I had to patch the built wheel, by setting RPATHs on the `*.so` inside the wheel)\r\n\r\nWhen running an LSTM (see repro code below), I get this error:\r\n```\r\nCould not load library libcudnn_adv_train.so.8. Error: libcudnn_ops_train.so.8: cannot open shared object file: No such file or directory\r\nPlease make sure libcudnn_adv_train.so.8 is in your library path!\r\nAborted (core dumped)\r\n```\r\nHowever, if I execute a BatchNorm layer right before, there is no error and I can use the LSTM. This is because, using BatchNorm triggers the load of `libcudnn_ops_train.so.8`, which works this way.\r\n\r\n**Describe the expected behavior**\r\n\r\nLSTM should work.\r\n\r\nMaybe `libcudnn_ops_train.so.8` should be manually loaded by TF ?\r\n\r\nI also expect not having the patch the wheel. If I set CUDA/cuDNN paths when configuring the build, why won't TF use these paths?\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\n# If I uncomment this, there is no crash.\r\n# bn = tf.keras.layers.BatchNormalization()\r\n# inputs = tf.random.normal([32, 10, 8, 8])\r\n# output = bn(inputs)\r\n\r\ninputs = tf.random.normal([32, 10, 8])\r\nlstm = tf.keras.layers.LSTM(4)\r\noutput = lstm(inputs)\r\n```\r\n", "comments": ["@lemairecarl I tried to run your code on colab using TF v2.5, 2.6.0(latest stable version of TF ) and didn't face any error reported .Please find the gist[ here ](https://colab.research.google.com/gist/sushreebarsa/4b0fbb80dbc09306ad2d351c2a4c748c/untitled388.ipynb)for reference. We see that you are using GCC/Compiler version (if compiling from source): GCC 9.3.0 ,could you please try to use GCC 7.3.1 and let us know if the issue still persists ? Thank you!", "I think a very important aspect to be able to reproduce this issue, is to have installed cuDNN in a custom path. If it's installed in the default path, you will not be able to reproduce this issue.\r\n\r\nI have access to GCC 7.3.0, do you think it will work?", "During the configure step of the build process, I give the custom paths where CUDA/cuDNN are installed on my system. However, the built wheel cannot be used with the custom cuDNN installation (unless the wheel is patched). Why doesn't the build process automatically add the corresponding RUNPATHs to the binaries in the wheel? (Such as `_pywrap_tensorflow_internal.so`)", "@mihaimaruseac Can you please take a look at it? Thanks!", "I have used the following workaround: I patched the RPATHs of cuDNN binaries to include $ORIGIN.\r\n\r\nAlso, please note that on the system I use, RPATHs should be used instead of RUNPATHs. (The tensorflow build process uses RUNPATHs)."]}, {"number": 51508, "title": "Use NNAPI to delegate model on DSP and how to I want to implement DSP zero-copy through Android Native Hardware Buffer", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using):\r\n- Are you willing to contribute it (Yes/No):\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nNow I\u2018m using NNAPI to delegate model on Qualcom DSP and I want to implement DSP zero-copy through Android Native Hardware Buffer and I want to know what should the values of the AHardwareBuffer_Format and  AHardwareBuffer_UsageFlags be.  Thanks a lot!\r\n\r\n**Will this change the current api? How?**\r\n\r\n**Who will benefit with this feature?**\r\n\r\n**Any Other info.**\r\n", "comments": ["@pianogGG , Thanks for reaching out!\r\n\r\nNNAPI currently does not have dedicated format or usage bits. And the support for user allocated hardware buffer varies driver by driver. At this moment, the feature is only recommended for advanced users.\r\n\r\nThe recommended format is AHARDWAREBUFFER_FORMAT_BLOB. And you may need to use/append CPU_READ_* or CPU_WRITE_* flags accordingly. "]}, {"number": 51502, "title": "Could not find device for node (`reduce_max` of complex)", "body": "```python\r\ntf.reduce_max(tf.constant([1 + 1j]))\r\n```\r\n[TF 2.5.0](https://anaconda.org/anaconda/tensorflow), Windows 10, Python 3.9.6.\r\n\r\n<details>\r\n  <summary><b>Error</b></summary>\r\n\r\n```python\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"D:\\Anaconda\\envs\\tf25_env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 206, in wrapper\r\n    return target(*args, **kwargs)\r\n  File \"D:\\Anaconda\\envs\\tf25_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 2908, in reduce_max\r\n    return reduce_max_with_dims(input_tensor, axis, keepdims, name,\r\n  File \"D:\\Anaconda\\envs\\tf25_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 2920, in reduce_max_with_dims\r\n    gen_math_ops._max(input_tensor, dims, keepdims, name=name))\r\n  File \"D:\\Anaconda\\envs\\tf25_env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 5781, in _max\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"D:\\Anaconda\\envs\\tf25_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 6897, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Value for attr 'T' of complex128 is not in the list of allowed values: float, double, int32, uint8, int16, int8, int64, bfloat16, uint16, half, uint32, uint64, qint8, quint8, qint32, qint16, quint16\r\n        ; NodeDef: {{node Max}}; Op<name=Max; signature=input:T, reduction_indices:Tidx -> output:T; attr=keep_dims:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64, DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]> [Op:Max]\r\n```\r\n</details>", "comments": ["It is said that\r\n```\r\nValue for attr 'T' of complex128 is not in the list of allowed values: float, double, int32, uint8, int16, int8, int64, bfloat16, uint16, half, uint32, uint64, qint8, quint8, qint32, qint16, quint16\r\n```\r\nI believe complex number is not supported yet?", "@OverLordGoldDragon,\r\n\r\nAs mentioned in the  error message and by @collinzrj, `complex128` is not supported by `tf.reduce_max` at this point of time. I've also tested in latest stable version`2.6.0` and its not supported yet. Thanks!", "@sanatmpa1 This is an unhandled exception - it helps the user to see something like\r\n\r\n```python\r\n   torch.max(torch.tensor([1 + 1j]))\r\n\r\nRuntimeError: \"max_all\" not implemented for 'ComplexFloat'\r\n```", "We likely will not support `reduce_max` for complex, since complex numbers have no natural ordering.  Numpy happens to choose to do lexigraphical ordering, but there isn't really a good justification for this.", "Sure, but the Issue's about exception handling.", "@OverLordGoldDragon what would you prefer to see?  We *could* catch it earlier and throw a runtime exception right in `reduce_max`, but you would still get a stack trace and it would still tell you which types are supported.", "There's too much noise - I'd prefer something like:\r\n\r\n```python\r\nTypeError: \"reduce_max\" not implemented for 'complex128'. \r\nSupported types are: float, double, int32, uint8, int16, int8, int64, bfloat16, uint16, half, uint32, uint64, qint8, quint8, qint32, qint16, quint16\r\n```"]}, {"number": 51501, "title": "Normalization and Quantization of inputs issue", "body": "I have observed differences between the documentation and the example.\r\nReference - https://www.tensorflow.org/lite/convert/metadata#normalization_and_quantization_parameters\r\n![tfliteinputnormalization](https://user-images.githubusercontent.com/47776253/129476236-f3d1dc4e-9202-4cf6-80ff-13d730870d50.JPG)\r\n\r\nBut in the example, I have found differences.\r\n\r\n![Capturefgregtrgtr](https://user-images.githubusercontent.com/47776253/129476310-9b0f1b17-ae54-410a-82ff-2f334546e50a.JPG)\r\n\r\nWe are not doing normalization when input and output are int8 and uint8? why is that so?\r\n\r\n\r\n![Capturesssssss](https://user-images.githubusercontent.com/47776253/129476426-ada45a4e-3624-46aa-842e-0868a154cc2b.JPG)\r\n\r\nAs per documentation, the output does not need normalization? why are we doing this in this example ?\r\n\r\nIn the example, we are not using any scale and zero point ? we are not using quantization params?\r\n", "comments": ["Hi @pranathibl where do the examples come from? Can you please give a pointer?"]}, {"number": 51500, "title": "TypeError: __array__() takes 1 positional argument but 2 were given", "body": "https://colab.research.google.com/drive/1gfsLuugiqEgAbyj7P6_6trgiNaq1dAW2\r\n\r\nI've tried downgrading Pillow to be 8.2.0 and 8.3.1 on my own machine, still not solving the problem,so it may be the tensorflow internal error.\r\n\r\nPlease teach me how to revise this code and let it run without bugs.\r\n\r\nAs I just paste the code onto the colab,I have no idea of the tf and python version, please help me check it.", "comments": ["Can you post the code to reproduce the error? Your Colab notebook is private so others cannot open it.", "@collinzrj Sorry,I didn't realize that, first time to use colab\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nimport PIL\r\nprint(PIL.__version__)\r\n\r\n\r\nclass Foo:\r\n    def __init__(self):\r\n        self.storage = np.zeros((10, 3, 1))\r\n\r\n    @staticmethod\r\n    def get_value(): \r\n        return np.array([[1], [2], [3]])\r\n\r\n    @tf.function\r\n    def case1(self):  # works\r\n        self.storage[0] = self.get_value()\r\n\r\n    def case2(self):  # works\r\n        self.storage[0] = tf.py_function(self.get_value, inp=[], Tout=tf.float32)\r\n\r\n    @tf.function  # fails\r\n    def case3(self):\r\n        self.storage[0] = tf.py_function(self.get_value, inp=[], Tout=tf.float32)\r\n\r\n\r\nif __name__ == '__main__':\r\n    foo = Foo()\r\n    foo.case1()\r\n    foo.case2()\r\n    foo.case3()\r\n\r\n```", "@Saduf2019 ,\r\nI was able to reproduce the issue in tf v2.4,v2.5 and nightly.Please find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/bd4e2927d626c6816f1468536570134a/51500.ipynb).", "@sjtusmartboy \r\nCan you refer to [this link](https://stackoverflow.com/questions/23944657/typeerror-method-takes-1-positional-argument-but-2-were-given) with same error and let us know, also[ this link](https://exerror.com/typeerror-array-takes-1-positional-argument-but-2-were-given/) has worked for few users.", "@Saduf2019 I've tried all these methods before posting this issue but none of these solutions worked. I think it's the tensorflow's internal error of combining tf.function and tf.py_function. If not, help me revise the code and let it run.Thanks", "I am tracing the call stack and I found that in `case3`, `tf.function` generates the code as below\r\n```\r\ndef outer_factory():\r\n\r\n    def inner_factory(ag__):\r\n\r\n        def tf__case3(self):\r\n            with ag__.FunctionScope('case3', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\r\n                ag__.ld(self).storage[0] = ag__.converted_call(ag__.ld(tf).py_function, (ag__.ld(self).get_value,), dict(inp=[], Tout=ag__.ld(tf).float32), fscope) ## critical\r\n        return tf__case3\r\n    return inner_factory\r\n```\r\nWhile in `case1`, it generates the code as this\r\n```\r\ndef outer_factory():\r\n\r\n    def inner_factory(ag__):\r\n\r\n        def tf__case1(self):\r\n            with ag__.FunctionScope('case1', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\r\n                ag__.ld(self).storage[0] = ag__.converted_call(ag__.ld(self).get_value, (), None, fscope) ## critical\r\n        return tf__case1\r\n    return inner_factory\r\n```\r\nThe line I marked critical in `case3` produce the problem, while `ag__.converted_call(ag__.ld(tf).py_function, (ag__.ld(self).get_value,), dict(inp=[], Tout=ag__.ld(tf).float32), fscope)` evaluates to `<tf.Tensor 'EagerPyFunc_1:0' shape=<unknown> dtype=float32>` which does not contain value. But in `case1`, `ag__.converted_call(ag__.ld(self).get_value, (), None, fscope)` evaluates to a numpy array, so it proceeds correctly. \r\nBut I did not figure out why and whose the `__array__` is called, any ideas?", "I got the same error with, so this has little do do with py_function.\r\n\r\n```\r\n@tf.function\r\ndef case3(self):\r\n     self.storage[0] = tf.constant(32.)\r\n```\r\n\r\nI think in this case we are supposed to get an error, because the right hand side is a 'symbolic' tensor (error occurs during `tf.function`'s trace-compilation), and the left hand-side is a numpy container. These two are incompatible, since during trace-compilation we in general do not know the value of the symbolic tensor.\r\n\r\nThe error message is definitely confusing and looks like a bug. Something like 'cannot convert a symbolic tensor to a numpy array' might be more useful.", "The Error message\r\n```\r\nTypeError: __array__() takes 1 positional argument but 2 were given\r\n```\r\nis thrown by numpy, when we set an item of a numpy ndarray to be an object like `x[0] = y`, the `__array__` method of that object will be called, and a parameter will be passed to it, \r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nclass Foo:\r\n  def __init__(self):\r\n    self.x = 3\r\n\r\n  def __array__(self):\r\n    print(x)\r\n    return np.array([self.x, self.x, self.x])\r\n\r\nx = np.zeros((10, 3))\r\nfoo = Foo()\r\nx[0] = foo\r\n```\r\nIf you run this code, the same error will be thrown\r\n\r\nAs I mentioned above \r\n\r\n> ag__.converted_call(ag__.ld(tf).py_function, (ag__.ld(self).get_value,), dict(inp=[], Tout=ag__.ld(tf).float32), fscope) evaluates to <tf.Tensor 'EagerPyFunc_1:0' shape=<unknown> dtype=float32>\r\n\r\nWhile the `__array__` method of `<tf.Tensor 'EagerPyFunc_1:0' shape=<unknown> dtype=float32>` is defined as \r\n```\r\ndef __array__(self):\r\n  raise NotImplementedError(\r\n      \"Cannot convert a symbolic Tensor ({}) to a numpy array.\"\r\n      \" This error may indicate that you're trying to pass a Tensor to\"\r\n      \" a NumPy call, which is not supported\".format(self.name))\r\n```\r\nI guess the expected behavior is throwing the `NotImplementedError`, but since an extra parameter is passed to `__array__`, an error is thrown before entering the method. This is the direct cause of the error, while I don't know whether `ag__.converted_call(ag__.ld(tf).py_function, (ag__.ld(self).get_value,), dict(inp=[], Tout=ag__.ld(tf).float32), fscope)` evaluates to an empty tensor is an expected behavior. ", "Indeed. A fix has been committed to avoid the extra argument error:\r\n\r\nhttps://github.com/tensorflow/tensorflow/commit/fc0f0e61ca9fe3ca3b9b58f51bcf00e0643ed9e3\r\n\r\n"]}, {"number": 51493, "title": "No registered 'EagerPyFunc' OpKernel for XLA_GPU_JIT devices compatible with node {{node EagerPyFunc}}){{node EagerPyFunc}}", "body": "**tensorflow 2.6\r\nubuntu 18.10\r\npython 3.6**\r\n\r\n### The whole error message:\r\n\r\nTraceback (most recent call last):\r\n  File \"main_Semantic3D.py\", line 626, in <module>\r\n    main1()\r\n  File \"main_Semantic3D.py\", line 562, in main1\r\n    model = Network(dataset, cfg)\r\n  File \"/home/sjtusmartboy/opt/Projects/RandLA-Net/Net.py\", line 97, in __init__\r\n    self.train( xyz_batch, color_batch)\r\n  File \"/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 885, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 950, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 3040, in __call__\r\n    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\r\n  File \"/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1964, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 596, in call\r\n    ctx=ctx)\r\n  File \"/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\r\n    inputs, attrs, num_outputs)\r\n**tensorflow.python.framework.errors_impl.InvalidArgumentError: Detected unsupported operations when trying to compile graph __inference_train_8311[_XlaMustCompile=true,config_proto=\"\\n\\007\\n\\0...02\\001\\000\",executor_type=\"\"] on XLA_GPU_JIT: EagerPyFunc (No registered 'EagerPyFunc' OpKernel for XLA_GPU_JIT devices compatible with node {{node EagerPyFunc}}){{node EagerPyFunc}}**\r\nThe op is created at: \r\nFile \"main_Semantic3D.py\", line 626, in <module>\r\n  main1()\r\nFile \"main_Semantic3D.py\", line 562, in main1\r\n  model = Network(dataset, cfg)\r\nFile \"/home/sjtusmartboy/opt/Projects/RandLA-Net/Net.py\", line 97, in __init__\r\n  self.train( xyz_batch, color_batch)\r\nFile \"/home/sjtusmartboy/opt/Projects/RandLA-Net/Net.py\", line 586, in train\r\n  self.adjacency_sparse_batch, self.scaledLaplacian_sparse_batch = self.get_graph(xyz_batch,\r\nFile \"/home/sjtusmartboy/opt/Projects/RandLA-Net/Net.py\", line 176, in get_graph\r\n  ret = tf.py_function(**DP.knn_search**, [xyz_batch, xyz_batch, cfg.k_n], [tf.int32, tf.float64]) [Op:__inference_train_8311]\r\n\r\n\r\n\r\n---------------------------------------------------------------------------------------------------------------------\r\n\r\n\r\n**knn_search is the wraper of an op, code is as follows,**\r\n\r\n\r\n```\r\nvoid cpp_knn_batch(const float* batch_data, const size_t batch_size, const size_t npts, const size_t dim,\r\n\t\t\tconst float* queries, const size_t nqueries,\r\n\t\t\tconst size_t K, long* batch_indices, float* batch_dist){\r\n\r\n\tfor(size_t bid=0; bid < batch_size; bid++){\r\n\r\n\t    std::cout<<1111111111111<<std::endl;\r\n\r\n\t\tconst float* points = &batch_data[bid*npts*dim];\r\n\t\tlong* indices = &batch_indices[bid*nqueries*K];\r\n\t\tfloat* dist = &batch_dist[bid*nqueries*K];\r\n\r\n\t\t// create the kdtree\r\n\t\ttypedef KDTreeTableAdaptor< float, float> KDTree;\r\n\t\tKDTree mat_index(npts, dim, points, 10);\r\n\t\t\r\n\t\tmat_index.index->buildIndex();\r\n\r\n\t\tstd::vector<float> out_dists_sqr(K);\r\n\t\tstd::vector<size_t> out_ids(K);\r\n\r\n\t\t// iterate over the points\r\n\t\tfor(size_t i=0; i<nqueries; i++){\r\n\t\t\tnanoflann::KNNResultSet<float> resultSet(K);\r\n\t\t\tresultSet.init(&out_ids[0], &out_dists_sqr[0] );\r\n\t\t\tmat_index.index->findNeighbors(resultSet, &queries[bid*nqueries*dim + i*dim], nanoflann::SearchParams(10));\r\n\t\t\tfor(size_t j=0; j<K; j++){\r\n\t\t\t\tindices[i*K+j] = long(out_ids[j]);\r\n\t\t\t\tdist[i*K+j] = float(out_dists_sqr[j]);\r\n\r\n\t\t\t}\r\n\t\t}\r\n\r\n\t}\r\n\r\n}\r\n\r\nvoid cpp_knn_batch_omp(const float* batch_data, const size_t batch_size, const size_t npts, const size_t dim, \r\n\t\t\t\tconst float* queries, const size_t nqueries,\r\n\t\t\t\tconst size_t K, long* batch_indices, float* batch_dist){\r\n\r\n# pragma omp parallel for\r\n\tfor(size_t bid=0; bid < batch_size; bid++){\r\n\r\n\t\tconst float* points = &batch_data[bid*npts*dim];\r\n\t\tlong* indices = &batch_indices[bid*nqueries*K];\r\n\t\tfloat* dist = &batch_dist[bid*nqueries*K];\r\n\r\n\t\t// create the kdtree\r\n\t\ttypedef KDTreeTableAdaptor< float, float> KDTree;\r\n\t\tKDTree mat_index(npts, dim, points, 10);\r\n\t\t\r\n\t\tmat_index.index->buildIndex();\r\n\r\n\t\tstd::vector<float> out_dists_sqr(K);\r\n\t\tstd::vector<size_t> out_ids(K);\r\n\r\n\t\t// iterate over the points\r\n\t\tfor(size_t i=0; i<nqueries; i++){\r\n\t\t\tnanoflann::KNNResultSet<float> resultSet(K);\r\n\t\t\tresultSet.init(&out_ids[0], &out_dists_sqr[0] );\r\n\t\t\tmat_index.index->findNeighbors(resultSet, &queries[bid*nqueries*dim + i*dim], nanoflann::SearchParams(10));\r\n\t\t\tfor(size_t j=0; j<K; j++){\r\n\t\t\t\tindices[i*K+j] = long(out_ids[j]);\r\n\t\t\t\tif(out_dists_sqr[j]>3.4028235e+37)\r\n\t\t\t\t    out_dists_sqr[j] = 0;\r\n\t\t\t\tdist[i*K+j] = sqrt(float(out_dists_sqr[j]));\r\n// \t\t\t\tstd::cout<<out_dists_sqr[j]<<std::endl;\r\n\t\t\t}\r\n\t\t}\r\n\r\n\t}\r\n\r\n}\r\n```\r\n\r\n------------------------------------------------------------------------------------------------------------------------------------------------\r\n\r\nSo what causes the error, the **tf.py_function** is not compatible with the xla or the **c++ op** is not compatible with the xla? If the code is not decorated with     `@tf.function(autograph=True, jit_compile=True)`, the program runs well.", "comments": ["Able to reproduce the error with the minimum code.\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndef my_numpy_func(x):  # This function must be numpy function, because it involves lots of scipy operations\r\n  # tf.function\r\n  return np.sinh(x)\r\n\r\n# @tf.function(input_signature=[tf.TensorSpec(None, tf.float32)]) # ok, but I have to use jit_compile parameter\r\n@tf.function(input_signature=[tf.TensorSpec(None, tf.float32)],jit_compile=True) # error because of jit_compile parameter\r\ndef tf_function(input):\r\n  y = tf.py_function(my_numpy_func, [input], tf.float32)\r\n  return y * y\r\n\r\na = tf_function(tf.constant(1.))\r\nprint(a)\r\n\r\n```\r\n\r\n\r\n### Error message\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"test10.py\", line 15, in <module>\r\n    a = tf_function(tf.constant(1.))\r\n  File \"/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 885, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 957, in _call\r\n    filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\r\n  File \"/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1964, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 596, in call\r\n    ctx=ctx)\r\n  File \"/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\r\n    inputs, attrs, num_outputs)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Detected unsupported operations when trying to compile graph __inference_tf_function_8[_XlaMustCompile=true,config_proto=\"\\n\\007\\n\\003CPU\\020\\001\\n\\007\\n\\003GPU\\020\\0012\\005*\\0010J\\0008\\001\\202\\001\\000\",executor_type=\"\"] on XLA_GPU_JIT: EagerPyFunc (No registered 'EagerPyFunc' OpKernel for XLA_GPU_JIT devices compatible with node {{node EagerPyFunc}}){{node EagerPyFunc}}\r\nThe op is created at: \r\nFile \"test10.py\", line 15, in <module>\r\n  a = tf_function(tf.constant(1.))\r\nFile \"test10.py\", line 12, in tf_function\r\n  y = tf.py_function(my_numpy_func, [input], tf.float32) [Op:__inference_tf_function_8]\r\n\r\n\r\n```", "In the first project code, `ret = tf.py_function(DP.knn_search, [xyz_batch, xyz_batch, cfg.k_n], [tf.int32, tf.float64])`, in which `DP.knn_search` is the python function that takes array parameter, while  `[xyz_batch, xyz_batch, cfg.k_n]` are all of type tensorflow tensor, how can I pass the tensorflow parameter into the python function without using `tf.py_function`?\r\n\r\n`DP.knn_search(xyz_batch.numpy(), xyz_batch.numpy(), cfg.k_n) ` is certainly not allowed since `tf.function` means graph mode while xxx.numpy() is in the eager mode. So all of these seems to be a paradox.", "Let me conclude my demand.\r\nWhat I have: 1)Python function: DP.knn_search\r\n                     2)parameter of fun is tensor\r\n\r\nWhat I need: tf.function(jit_compile=True)\r\n\r\nDifficulties: 1.cannot pass tensor into python function directly\r\n                   2. cannot use tf.py_function to wrap DP.knn_search since it contradicts tf.function(jit_compile=True)", "@sanatmpa1 Please first try the reproduction code and try to fix it.", "@sjtusmartboy,\r\n\r\nAs per documentation of `tf.function`, when setting `jit_compile=True`, it throws `InvalidArgumentError` if the whole function is not compileable by `XLA` and [here](https://www.tensorflow.org/xla/known_issues) are few known issues. Have you already took a look at this link?", "@sanatmpa1 I've found InvalidArgumentError in tf.function but not relative info in that link. Is tf.py_function not compileable by XLA?  But I think tensorflow should think a way to support it, because this issue is not uncommon and of great significance, more and more users will have a request of that in the near future.. If tensorflow has decided not to support it, would you please help me think of an alternative that will solve this problem?", "Hi currently `jit_compile=True` is not compatible with `tf.py_function` although there is a long-term plan to fix this (not near future likely)."]}, {"number": 51491, "title": "\"group_by_reducer\" scales badly with more images", "body": "I tried to use the tf.data.experimental.group_by_reducer Method for image-collage preprocessing. On my test-dataset (35 images collaged into 5 collages a 7 images) it worked well  and fast (~2.5sec with dataset.collage.take(1)). But then i used this setup for a set of 1414 images (to create 202 collages a 7 images) and found out that my method scales very bad (~90sec with dataset.collage.take(1)).\r\nI didn't found the reason why the execution time is dependent on the size of the dataset because there is no import of the full dataset at any time in the grouping loop.\r\nThe cProfile Tool showed me that the time consumption is located in {built-in method tensorflow.python._pywrap_tfe.TFE_Py_FastPathExecute} but i dont know what to do with this information.\r\n\r\n\r\n\r\nCode:\r\n\r\n```Python\r\nimport numpy as np\r\nimport os\r\n\r\nfrom tensorflow.python.keras.utils.np_utils import normalize\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Disable Tensorflow log messages\r\nimport tensorflow as tf\r\ntf.compat.v1.enable_eager_execution()   # Enable Execution of in-function package functions (Needed for reducer)\r\nimport pandas as pd\r\n\r\nfrom sklearn.model_selection import train_test_split\r\nfrom tensorflow.keras.layers.experimental.preprocessing import RandomRotation\r\nfrom tensorflow.keras.layers.experimental.preprocessing import RandomTranslation\r\nfrom tensorflow.keras.layers.experimental.preprocessing import RandomZoom\r\nfrom tensorflow.keras.layers.experimental.preprocessing import Rescaling\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.utils import to_categorical\r\n\r\n\r\nnp.random.seed(0)\r\ntf.random.set_seed(0)\r\n\r\n# ----------------------------- #\r\n# Class                         #\r\n# ----------------------------- #\r\nclass D3VEG:\r\n    def __init__(self, image_size=32, test_size: float = 0.2, validation_size: float = 0.33) -> None:\r\n        # Paths\r\n        DIR_IMG = '/home/denis/Schreibtisch/Masterarbeit/Daten/ProjektGem\u00fcse/imagesVegetables/'\r\n        DIR_DATA = '/home/denis/Schreibtisch/Masterarbeit/Daten/ProjektGem\u00fcse/dataVegetables.csv'\r\n\r\n        # User-defined constants\r\n        self.batch_size = 6\r\n        self.image_size = image_size\r\n        file_colname = 'Image_Name'\r\n        collage_group_colname = 'Object_Id'\r\n        collage_label_colname = 'Kartoffel_count'\r\n\r\n        # Load Data\r\n        df = pd.read_csv(DIR_DATA)\r\n\r\n        file_names = df[file_colname].values\r\n        obj_ID = df[collage_group_colname].values\r\n        labels = df[collage_label_colname].values\r\n        # Convert File Names to full Paths\r\n        file_paths = DIR_IMG + file_names\r\n\r\n        # Data-defined constants\r\n        self.num_collages = len(np.unique(obj_ID))\r\n        self.num_images = file_names.size\r\n\r\n        # ----------------------------- #\r\n        # Collage (Reducer) functions   #\r\n        \r\n        # Create Reducer\r\n        collage_reducer = tf.data.experimental.Reducer(self.init_func, self.reduce_func, self.finalize_func)\r\n\r\n        # Define grouping key\r\n        def key_f(tens):\r\n            #tf.dtypes.cast(obj_ID, tf.int64)\r\n            return tf.dtypes.cast(tens['ids'], tf.int64)\r\n        # Create grouping function\r\n        collage_function = tf.data.experimental.group_by_reducer(key_func=key_f,\r\n                            reducer=collage_reducer)\r\n\r\n        # End of Collage (Reducer) functions   #\r\n        # ----------------------------------   #\r\n\r\n        # Create Dataset\r\n        ds_images = tf.data.Dataset.from_tensor_slices({'ids': obj_ID, 'img': file_paths})\r\n        ds_labels = tf.data.Dataset.from_tensor_slices(labels)\r\n\r\n        # Create Collage\r\n        ds_collage = ds_images.apply(collage_function)\r\n        # Get labels for Collage\r\n        labels_collage = df.groupby(collage_group_colname)[collage_label_colname].first().values\r\n        print(labels_collage.shape)\r\n        labels_collage_norm = normalize(labels_collage)[0,:]\r\n        print(labels_collage_norm.shape)\r\n\r\n        ds_labels_collage = tf.data.Dataset.from_tensor_slices(labels_collage_norm)\r\n        #print(ds_labels_collage.shape)\r\n\r\n\r\n        # Add labels (y_data) to collage (x_data)\r\n        ds_collage = tf.data.Dataset.zip((ds_collage, ds_labels_collage))\r\n        #print(ds_collage.shape)\r\n\r\n        # Finalize Collage\r\n        self.collage = ds_collage.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n        self.collage_shape = (image_size*2, image_size*5, 3)\r\n\r\n        # Generate Train, Test and Validation Sets\r\n        dataset_size = labels_collage.shape[0]\r\n        train_size = 1.0 - test_size\r\n\r\n        train_count = int(train_size * dataset_size)\r\n        val_count = int(validation_size * train_count)\r\n\r\n        collage_shuffled = self.collage.shuffle(dataset_size, reshuffle_each_iteration=False)\r\n\r\n        train_dataset = collage_shuffled.take(train_count)\r\n        test_dataset = collage_shuffled.skip(train_count)\r\n        val_dataset = train_dataset.take(val_count)\r\n        train_dataset = train_dataset.skip(val_count)\r\n\r\n        # Batch Datasets\r\n        test_dataset = test_dataset.batch(batch_size=self.batch_size)\r\n        val_dataset = val_dataset.batch(batch_size=self.batch_size)\r\n        train_dataset = train_dataset.batch(batch_size=self.batch_size)\r\n\r\n        # Finalize Datasets\r\n        self.test_dataset = test_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n        self.val_dataset = val_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n        self.train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n\r\n        \r\n    def get_train_set(self) -> tf.data.Dataset:\r\n            return self.train_dataset\r\n    \r\n    def get_test_set(self) -> tf.data.Dataset:\r\n        return self.test_dataset\r\n\r\n    def get_val_set(self) -> tf.data.Dataset:\r\n        return self.val_dataset\r\n\r\n    # ----------------------------- #\r\n    # Collage (Reducer) functions   #\r\n    def init_func(self, _):\r\n        ## Initiate Object to start (and store) the Loop ##\r\n        img_stack = []\r\n        img_top = []\r\n\r\n        state = (img_stack, img_top)\r\n        return state\r\n\r\n    def reduce_func(self, state, feature):\r\n        ## Loops over each element in the group ##\r\n        img_stack = state[0]\r\n        img_top = state[1]\r\n        #print(feature)\r\n\r\n        # Load File\r\n        img = tf.io.read_file(feature['img'])\r\n        # convert the compressed string to a 3D uint8\r\n        img = tf.io.decode_jpeg(img, channels=3)\r\n        # Crop from middle (to get rectangular image)\r\n        img = tf.image.resize_with_crop_or_pad(img, 2500, 2500)\r\n\r\n        img = tf.expand_dims(img, axis=0)\r\n        if len(img_top) == 0:\r\n            # Bigger top-down image\r\n            img_top = tf.image.resize(img, [self.image_size*2, self.image_size*2])  # Resize to minimize shape (x2)\r\n        else:\r\n            img = tf.image.resize(img, [self.image_size, self.image_size])  # Resize to minimize shape\r\n            if len(img_stack) == 0:\r\n                # Just for first Image (transforms 'img_stack' to tensor)\r\n                img_stack = img\r\n            else:\r\n                img_stack = tf.concat((img_stack, img), axis=0)\r\n\r\n        state = (img_stack, img_top)\r\n        return state\r\n\r\n    def finalize_func(self, *state):\r\n        ## Create one output per Group ##\r\n        img_stack = state[0]\r\n        img_top = state[1]\r\n\r\n        for img_slot in np.arange(0, 5, 2):\r\n            # Create vertical combination (coloumn)\r\n            img_slot_single = tf.concat((img_stack[img_slot, :, :, :], \r\n                                        img_stack[img_slot+1, :, :, :]), axis=0)\r\n            # Combine column images horizontal\r\n            if img_slot == 0:\r\n                img_slot_all = img_slot_single\r\n            else:\r\n                img_slot_all = tf.concat((img_slot_all, img_slot_single), axis=1)\r\n\r\n        # Add bigger (top-down) image\r\n        img_collage = tf.concat((img_slot_all, tf.squeeze(img_top, 0)), axis=1)\r\n\r\n        #tf.ensure_shape(img_collage, [self.image_size*5, self.image_size*2, 3])\r\n        #print(img_collage.shape)\r\n\r\n        return img_collage\r\n    # End of Collage (Reducer) functions   #\r\n    # ----------------------------------   #\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    data = D3VEG()        \r\n\r\n    print(f\"image size: {data.image_size}\")\r\n    print(f\"batch: {data.batch_size}\")\r\n    print(f\"n collages: {data.num_collages}\")\r\n    print(f\"n images: {data.num_images}\")\r\n    for img, lab in data.collage.take(1):  # only take first element of dataset\r\n        print(f\"image shape: {img.shape}\")\r\n        print(f\"image shape: {lab.shape}\")\r\n        single_img = img\r\n        single_lab = lab\r\n\r\n    #print(single_img)\r\n    import matplotlib.pyplot as plt\r\n    plt.imshow(single_img.numpy().astype(np.uint8))\r\n    plt.title(f\"{np.round(single_lab, 4)}\", fontsize=20)\r\n    plt.show()\r\n```", "comments": ["@debroize ,\r\n\r\nIn order to expedite the trouble-shooting process, could you please provide dataset and the TensorFlow version you are using.Thanks!", "I am using tensorflow 2.4.1 and python 3.8.8.\r\nI don't know how to upload the images here so i created a repository on:\r\nhttps://github.com/debroize/DatasetVegetables\r\n\r\nThis is just the sample dataset, like i said the full set contains 1414 images (3,4 GB).\r\n\r\n[dataVegetables_small.csv](https://github.com/tensorflow/tensorflow/files/7002174/dataVegetables_small.csv)\r\n", "@debroize ,\r\nI was not able to download the .csv formatted data.Can you please provide the sample data.It helps to reproduce the issue from our side.Thanks!", "I can download the .csv by clicking on the \"dataVegetables_small.csv\" in my comment above, doesn't this work for you?\r\nThe .csv data is also available in the repository.\r\n\r\nTo clarify: The .csv file is for labels (y-values), the \"group-by\" value and the name of the images to load. So you need a folder [DIR_IMG = \"path_folder\"] with just the images (from my repository) as well as the .csv [DIR_DATA = \"path_csv.csv\"].\r\n\r\nPS: i updated the code so you can better see the output.", "@debroize ,\r\nWhile trying to execute the above code is taking long time interval than expected.Can you please try the code in latest tensorflow stable version 2.6 with the specific amount of data and let us know if the issue still persists.Thanks!", "I tried on python 3.9.6 and tensorflow 2.6.0. There is no major improvement in computation time (87 sec vs 97sec on tf 2.4) for taking one element via:\r\n\r\n```Python\r\nfor img, lab in data.collage.take(1):  # take first element of dataset\r\n        train_img = img\r\n        train_lab = lab \r\n```", "Additional information: At tensorflow 2.6 i get a warning message:\r\n```\r\nE tensorflow/core/framework/dataset.cc:552] Unimplemented: Cannot compute input sources for dataset of type ExperimentalGroupByReducerDataset, because the dataset does not implement `InputDatasets`.\r\n```\r\nBut it seems that this doesn't affect the output (collage is processed as expected)."]}]