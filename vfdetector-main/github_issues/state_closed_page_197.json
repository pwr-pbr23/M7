[{"number": 48803, "title": "Fix build failure with CUDA 11.3", "body": "Fix a typo introduced in e07069218c39cbfc4bbad79fc50c83d64b0546af to strip NCCL's relocatable device code.\r\n\r\n/cc @chsigg ", "comments": ["I'm not sure if this is related, but my GPU is not recognized by tf 2.5.0 in a conda environment running python 3.8.10.  I have **CUDA 11.3** and **cuDNN 8.2** installed.  My GPU is detected normally using tf 2.4.1 in the same environment.", "> I'm not sure if this is related, but my GPU is not recognized by tf 2.5.0 in a conda environment running python 3.8.10. I have **CUDA 11.3** installed. My GPU is detected normally using tf 2.4.1 in the same environment.\r\n\r\nAs a side note we don't support conda env here. You can ask support in conda repo.\r\n\r\nIt would be useful if you can test your issue in a python env following our official doc.", "This is not a conda problem.  It is a tf 2.5.0 problem.\r\n", "> This is not a conda problem. It is a tf 2.5.0 problem.\r\n\r\nCan you reproduce the same issue in a venv with our official documentation https://www.tensorflow.org/install/pip#2.-create-a-virtual-environment-recommended ?", "If this pull request is merged and a new verison of tf released, can I assume that tf 2.5+ GPU will work with CUDA 11.3/cuDNN 8.2?  Any info would be appreciated, as I am about to downgrade to CUDA 11.2 from 11.3 to get tf 2.5.0 recognize my GPU.  Thank you...", "Thanks Bairen, and sorry for the delay.\r\n\r\n> If this pull request is merged and a new verison of tf released, can I assume that tf 2.5+ GPU will work with CUDA 11.3/cuDNN 8.2? Any info would be appreciated, as I am about to downgrade to CUDA 11.2 from 11.3 to get tf 2.5.0 recognize my GPU. Thank you...\r\n\r\nI don't think this will change anything for pre-built binaries against CUDA 11.2. This change fixes building TF from source with CUDA 11.3.", "> This change fixes building TF from source with CUDA 11.3.\r\n\r\nThat is correct. \r\n\r\nAre we going to bump to CUDA 11.3 for the nightlies? That probably helps for @pythonic2020's case.", "> Are we going to bump to CUDA 11.3 for the nightlies? That probably helps for @pythonic2020's case.\r\n\r\nNo immediate plans, but of course we won't stay on 11.2 forever. :)", "@sanjoy Any update on this PR? Please. Thanks!\r\n", "Seems it has already been fixed by c8e4f2aa633c4f9b803fdeb5d8463f002387a2bf?"]}, {"number": 48801, "title": "Accessing numpy array from a Tensor object using dataset map", "body": "I am trying to access the numpy array from a tensor object that is processed with  https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map.\r\n\r\nI get the error: `AttributeError: 'Tensor' object has no attribute 'numpy'`\r\n\r\nWhen I try to access the tensor as: `np_array = tensor.numpy()`\r\n\r\nWhile if I use: `dataset.take(n)`, i am able to access the numpy array.\r\n\r\nFor more clarity on the situation I am facing, here is a short reproducible example of the error in a google colab:\r\n\r\nhttps://colab.research.google.com/drive/13ectGEMDSygcyuW4ip9zrWaHO3pSxc3p?usp=sharing\r\n\r\nTensorflow version: 2.4.1", "comments": ["I have resovled the issue. The answer is that I cannot access `.numpy()` inside a `.map()` function since `.numpy()` is Python code not pure TensorFlow code. I need to wrap my python function with https://www.tensorflow.org/api_docs/python/tf/py_function in order for it to work.\r\n\r\nHappy to close this ticket.\r\n\r\n\r\n\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48801\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48801\">No</a>\n"]}, {"number": 48800, "title": "Add initial docs for online memory planning in TensorFlow Lite Micro.", "body": "", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 48799, "title": "AttributeError: module 'tensorflow.compat.v2.__internal__' has no attribute 'tf2", "body": "Hey\r\nSome help on this bug, \r\nI am using tensorflow ==1.15\r\n\r\nTraceback (most recent call last):\r\n  File \"a2c.py\", line 7, in <module>\r\n    import  keras.backend as K\r\n  File \"/home/david/miniconda3/envs/kedro-environment/lib/python3.7/site-packages/keras/__init__.py\", line 20, in <module>\r\n    from . import initializers\r\n  File \"/home/david/miniconda3/envs/kedro-environment/lib/python3.7/site-packages/keras/initializers/__init__.py\", line 124, in <module>\r\n    populate_deserializable_objects()\r\n  File \"/home/david/miniconda3/envs/kedro-environment/lib/python3.7/site-packages/keras/initializers/__init__.py\", line 49, in populate_deserializable_objects\r\n    LOCAL.GENERATED_WITH_V2 = tf.__internal__.tf2.enabled()\r\nAttributeError: module 'tensorflow.compat.v2.__internal__' has no attribute 'tf2'\r\n\r\n", "comments": ["We don't support TensorFlow 1.x anymore. Please upgrade to a more recent TF version.", "I get the same error while using tensorflow ==2.4.1\r\n Error\r\n Traceback (most recent call last):\r\n  File \"a2c.py\", line 7, in <module>\r\n    import  keras.backend as K\r\n  File \"/home/david/miniconda3/envs/kedro-environment/lib/python3.7/site-packages/keras/__init__.py\", line 20, in <\r\nmodule>\r\n    from . import initializers\r\n  File \"/home/david/miniconda3/envs/kedro-environment/lib/python3.7/site-packages/keras/initializers/__init__.py\", \r\nline 124, in <module>\r\n    populate_deserializable_objects()\r\n  File \"/home/david/miniconda3/envs/kedro-environment/lib/python3.7/site-packages/keras/initializers/__init__.py\", \r\nline 49, in populate_deserializable_objects\r\n    LOCAL.GENERATED_WITH_V2 = tf.__internal__.tf2.enabled()\r\nAttributeError: module 'tensorflow.compat.v2.__internal__' has no attribute 'tf2'\r\n", "@Davidelvis \r\n\r\nCan you install with PIP as follows,\r\npip install tensorflow==2.4.1       [pip install tensorflow-estimator==2.4.*]\r\nLet us know if issue still persists. \r\nCould you also try installing TensorFlow in a new virtual environment and check if you are facing the same issue? \r\nThanks!", "Thanks so much @Saduf2019 and @bhack ", "@Davidelvis \r\nPlease move the issue to closed status as resolved.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48799\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48799\">No</a>\n"]}, {"number": 48798, "title": "Cadence HiFi 5 NN Library v1.5.0 integration", "body": "Integrate the HiFi 5 Neural Network Library v1.5.0\r\nUsed HiFi 5 NN Library kernels for conv, depthwise_conv and softmax\r\noperators int8 variant.\r\n\r\nSigned-off-by: Anirban Mandal <amandal@cadence.com>\r\nSigned-off-by: Biswa Dhal <bdhal@cadence.com>\r\nSigned-off-by: Bhanu Prakash Bandaru Venkata <bhanup@cadence.com>\r\nSigned-off-by: Chaitanya Sanjay Muley <cmuley@cadence.com>\r\nSigned-off-by: Harinarayanan E V <hariev@cadence.com>\r\nSigned-off-by: Harshavardhan Ravindra Joshi <joshih@cadence.com>\r\nSigned-off-by: Prasad Nikam <pnikam@cadence.com>", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "@advaitjain :Please merge this branch", "> @advaitjain :Please merge this branch\r\n\r\nI have pushed a commit with some updated formatting and small name changes. This PR is now ready to be merged."]}, {"number": 48797, "title": "Importing torchvision before tensorflow causes protobuf error.", "body": "**System information**\r\n<details>\r\n<summary>System information</summary>\r\n\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux x86_64\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary? (package: `tensorflow-cuda` from official Arch repos)\r\n- TensorFlow version (use command below): unknown 2.4.1\r\n- Python version: 3.9.4\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: CUDA=11.3.0, cuDNN=8.1.1.33\r\n- GPU model and memory: NVIDIA GeForce GTX 1060 6GB\r\n\r\n</details>\r\n\r\n**Describe the current behavior**\r\n\r\n```python\r\nimport torchvision\r\nimport tensorflow\r\n```\r\n\r\ncauses:\r\n\r\n```python\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/core/framework/resource_handle_pb2.py\", line 141, in <module>\r\n    ResourceHandleProto = _reflection.GeneratedProtocolMessageType('ResourceHandleProto', (_message.Message,), {\r\nSystemError: google/protobuf/pyext/descriptor.cc:354: bad argument to internal function\r\n```\r\n\r\nHowever,\r\n\r\n```python\r\nimport tensorflow\r\nimport torchvision\r\n```\r\n\r\n...causes no such error.\r\n\r\n**Describe the expected behavior**\r\n\r\nNo error.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```python\r\nimport torchvision\r\nimport tensorflow\r\n```\r\n\r\n**Other info / logs**\r\n\r\n<details>\r\n<summary>Traceback</summary>\r\n\r\n```python\r\nTraceback (most recent call last):\r\n  File \"/home/mulhaq/tmp.py\", line 2, in <module>\r\n    import tensorflow\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/__init__.py\", line 41, in <module>\r\n    from tensorflow.python.eager import context\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/eager/context.py\", line 32, in <module>\r\n    from tensorflow.core.framework import function_pb2\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/core/framework/function_pb2.py\", line 16, in <module>\r\n    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/core/framework/attr_value_pb2.py\", line 16, in <module>\r\n    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/core/framework/tensor_pb2.py\", line 16, in <module>\r\n    from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/core/framework/resource_handle_pb2.py\", line 141, in <module>\r\n    ResourceHandleProto = _reflection.GeneratedProtocolMessageType('ResourceHandleProto', (_message.Message,), {\r\nSystemError: google/protobuf/pyext/descriptor.cc:354: bad argument to internal function\r\n```\r\n\r\n</details>\r\n\r\nOther users with similar issue: https://stackoverflow.com/questions/65874607/torchvision-and-tensorflow-gpu-import-error", "comments": ["Can you try to reporduce this with:\r\n\r\n```\r\npip install tf-nightly-cpu\r\npip install --upgrade torchvision\r\n```", "@YodaEmbedding  I tried to import  in both ways using TF version 2.4.1 on colab and didn't face any protobuf errors. Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/b1942aff2b53f239d4124def9e45d45e/48797.ipynb). Thanks!", "@YodaEmbedding  Any update on this?. Please feel free to close the issue if the issue was resolved already. Thanks!", "Reinstalling my system `torchvision` seems to fix the issue. Not sure what was causing it.\r\n\r\nI could not reproduce in a virtual environment, either.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48797\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48797\">No</a>\n", "Calling tensorflow first (import tensorflow as tf) and all other dependencies before calling torch seems to solve the problem for me.", "Yes, the fix is:\r\n\r\n```python\r\nimport tensorflow  # BEFORE all other imports\r\n\r\nimport torchvision\r\n```\r\n\r\n**NOTE:** I still have this issue on newer versions of packages on Arch Linux. The fix is either to reinstall `torchvision` or to always import `tensorflow` first, as shown above. The issue is difficult to reproduce since fresh install fixes things. Perhaps it is related to the order in which packages are installed -- perhaps `torchvision` is somehow targeting older `tensorflow`-related libraries... and updating it again fixes this. `tensorflow-cuda` is from the official repositories, but `python-torchvision-cuda` is **manually installed** via https://aur.archlinux.org/cgit/aur.git/tree/PKGBUILD?h=python-torchvision&id=adbd243c43324663d21db47b89383aa536d1e573#n48. @kennedyCzar Are you also on Arch Linux?\r\n\r\nShould I reopen since the issue isn't *technically* resolved (I have merely found consistent workarounds)?", "I think you can open a ticket on arch in the meantime."]}, {"number": 48796, "title": "Example of tf.scatter_nd contains Session, which is obselete", "body": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/scatter_nd\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/scatter_nd\r\n\r\n## Description of issue (what needs changing):\r\nThe Code, \r\n\r\n```python\r\nwith tf.Session() as sess:\r\n      print(sess.run(scatter))\r\n```\r\nshould be replaced with `print(scatter)`, as the **`Sessions`** are no longer required in **`Tensorflow 2.x`**.\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct? : NA\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly? : Yes\r\n\r\n### Returns defined\r\n\r\nAre return values defined? : Yes\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? No\r\n\r\n### Usage example\r\n\r\nIs there a usage example? : Yes", "comments": ["@worldpeaceaspirer,\r\nThank you for identifying it. This should be fixed with [this CL](https://critique-ng.corp.google.com/cl/370902959). ", "This is fixed with latest TF api docs https://www.tensorflow.org/api_docs/python/tf/scatter_nd\r\nThanks!"]}, {"number": 48795, "title": "Edit CosineSimilarity documentation on metrics.py", "body": "Match dimensions of input and output of `l2_norm()`.\r\nApplied same work done on #48633 to `metrics.py`.\r\nIt would have been better if I'm informed to avoid opening similar pr.\r\n\r\nBy the way, I would like to suggest to edit comments on `cosine_similarity()` and `CosineSimilarity()` on `losses.py`.\r\nIt confuses readers because the output of \"cosine similarity\" is mutiplied with -1.\r\nIt should be mentioned or the comments might be misunderstood.\r\n\r\nPhrases to be modified are:\r\nAt line 1925\r\n`Computes the cosine similarity between labels and predictions.`   <= negative cosine similarity\r\nAt line 1951 ~ 1952\r\n```\r\nReturns:\r\n    Cosine similarity tensor.                                <= negative cosine similarity\r\n```\r\nAt line 1961\r\n`Computes the cosine similarity between labels and predictions.`   <= negative cosine similarity\r\n", "comments": ["Good to see your agreed.\r\nBut I haven't made any modification on the docstrings about -1 multiplication.\r\nWanted to pick others' brain.\r\n\r\nI'll comment here after pushing additional commit about that.", "It's done.\r\nPlease look into it.", "Actually, although I agreed that the first commit was a strict improvement. I'm not sure I feel comfortable with this change. It is strictly correct that this is the opposite of the standard cosine similarity, but it is very weird to have a method called cosine_similarity and have the docstring say it is negative cosine similarity. I'll take this one to the team's triage.", "Ideally the method should be renamed, but that would break backward compatibility if not done carefully. But all things considered, I liked the old docstring better. I don't like calling it negative cosine similarity", "I got your point and agree with you.\r\nMaybe I misunderstood that you would like to accept my suggestions.\r\nI'll look forward to this to be arranged.\r\n\r\nI pushed reverting commit.\r\n\r\nTY."]}, {"number": 48794, "title": "tensorflow2.3.2 compilation ERROR", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):win10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:None\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version:2.3.2\r\n- Python version:3.8.6\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):3.7.2\r\n- GCC/Compiler version (if compiling from source):MSVC2019\r\n- CUDA/cuDNN version:11.0/8.0.5\r\n- GPU model and memory:GeForce RTX 2080 ti\r\n\r\n**Describe the problem**\r\nERROR: C:/users/zn58887/_bazel_zn58887/e5awb3j2/external/nsync/BUILD:467:11: C++ compilation of rule '@nsync//:nsync_cpp' failed (Exit 2): python.exe failed: error executing command\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nbazel build -c dbg --copt=/wd4716 --copt=/FS --copt=THRUST_IGNORE_CUB_VERSION_CHECK --config=opt //tensorflow:tensorflow_cc.dll\r\n\r\n**Any other info / logs**\r\ncd C:/users/zn58887/_bazel_zn58887/e5awb3j2/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.0\r\n    SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\ATLMFC\\include;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\winrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\cppwinrt\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\ATLMFC\\lib\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\lib\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.19041.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.19041.0\\um\\x64\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\\\Extensions\\Microsoft\\IntelliCode\\CLI;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\bin\\HostX64\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\MSBuild\\Current\\bin\\Roslyn;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Team Tools\\Performance Tools\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.8 Tools\\x64\\;C:\\Program Files (x86)\\HTML Help Workshop;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.19041.0\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\\\MSBuild\\Current\\Bin;C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\Tools\\;;C:\\Windows\\system32;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=C:/Python38/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Python38/lib/site-packages\r\n    SET RUNFILES_MANIFEST_ONLY=1\r\n    SET TEMP=C:\\Users\\zn58887\\AppData\\Local\\Temp\r\n    SET TF2_BEHAVIOR=1\r\n    SET TF_CONFIGURE_IOS=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=7.5\r\n    SET TF_ENABLE_XLA=1\r\n    SET TF_NEED_CUDA=1\r\n    SET TMP=C:\\Users\\zn58887\\AppData\\Local\\Temp\r\n  C:/Python38/python.exe -B external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /Iexternal/nsync /Ibazel-out/x64_windows-dbg/bin/external/nsync /Iexternal/nsync/public /Ibazel-out/x64_windows-dbg/bin/external/nsync/public /showIncludes /MDd /Od /Z7 /DDEBUG /w /D_USE_MATH_DEFINES -DWIN32_LEAN_AND_MEAN -DNOGDI /wd4716 /FS THRUST_IGNORE_CUB_VERSION_CHECK /arch:AVX /TP -DNSYNC_ATOMIC_CPP11 -DNSYNC_USE_CPP11_TIMEPOINT -I./external/nsync//platform/c++11 -I./external/nsync//platform/win32 -I./external/nsync//platform/msvc -I./external/nsync//platform/x86_64 -I./external/nsync//public -I./external/nsync//internal -I./external/nsync//platform/posix /Fobazel-out/x64_windows-dbg/bin/external/nsync/_objs/nsync_cpp/mu.o /c external/nsync/internal/mu.c\r\nExecution platform: @local_execution_config_platform//:platform\r\nTHRUST_IGNORE_CUB_VERSION_CHECK\r\nc1xx: fatal error C1083: \u65e0\u6cd5\u6253\u5f00\u6e90\u6587\u4ef6: \u201cTHRUST_IGNORE_CUB_VERSION_CHECK\u201d: No such file or directory\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:  C:\\users\\zn58887\\_bazel_zn58887\\e5awb3j2\\execroot\\org_tensorflow\\external\\nsync\\public\\nsync_cpp.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:  C:\\users\\zn58887\\_bazel_zn58887\\e5awb3j2\\execroot\\org_tensorflow\\external\\nsync\\platform\\c++11\\platform.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:   C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\string.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\vcruntime.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\sal.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:       C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\concurrencysal.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\vadefs.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_memory.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_memcpy_s.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\errno.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\vcruntime_string.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_wstring.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:   C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\stdlib.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_malloc.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_search.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\stddef.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_wstdlib.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\limits.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:   C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\inttypes.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\stdint.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:   C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\stdio.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_wstdio.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_stdio_config.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:   C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\stdarg.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:   C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\mutex\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\yvals_core.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\xkeycheck.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\chrono\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\limits\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\cfloat\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:       C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\float.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\climits\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\cwchar\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:       C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\cstdio\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:       C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\wchar.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_wconio.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_wctype.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_wdirect.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_wio.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:         C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_share.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_wprocess.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_wtime.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\sys/stat.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:         C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\sys/types.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\intrin0.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\isa_availability.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\xstddef\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:       C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\cstddef\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\xtr1common\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:       C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\cstdlib\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\math.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:         C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_math.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:         C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_math_defines.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:       C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\initializer_list\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\ratio\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\type_traits\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\time.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\utility\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\xtimec.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\yvals.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:       C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\crtdbg.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\vcruntime_new_debug.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:         C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\vcruntime_new.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:       C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\crtdefs.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:       C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\use_ansi.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\system_error\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\__msvc_system_error_abi.hpp\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\cerrno\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\stdexcept\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\exception\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:       C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\malloc.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:       C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\vcruntime_exception.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\eh.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:         C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_terminate.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\xstring\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:       C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\iosfwd\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\cstring\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:       C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\xmemory\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\cstdint\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\new\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\xatomic.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\xutility\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\xcall_once.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\xerrc.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\atomic\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\xthreads.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\thread\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\memory\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\typeinfo\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:       C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\vcruntime_typeinfo.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\process.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_startup.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:       C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\math.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:       C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\vcruntime_startup.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\tuple\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:   C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\condition_variable\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:   C:\\users\\zn58887\\_bazel_zn58887\\e5awb3j2\\execroot\\org_tensorflow\\external\\nsync\\platform\\win32\\platform_c++11_os.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\sys/timeb.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\Windows.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\winapifamily.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\winpackagefamily.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\sdkddkver.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\excpt.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\windef.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\minwindef.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:       C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\specstrings.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\specstrings_strict.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:         C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\specstrings_undef.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\driverspecs.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:         C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\sdv_driverspecs.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:       C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\winnt.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\ctype.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\kernelspecs.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\basetsd.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\guiddef.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\pshpack4.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\poppack.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\pshpack4.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\poppack.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\pshpack4.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\pshpack2.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\poppack.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\pshpack2.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\pshpack2.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\poppack.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\poppack.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\pshpack8.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\poppack.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\pshpack1.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\poppack.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\pshpack1.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\poppack.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\poppack.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\apiset.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\ktmtypes.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\winbase.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\apisetcconv.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\minwinbase.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\apiquery2.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\processenv.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\fileapifromapp.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:       C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\fileapi.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\debugapi.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\utilapiset.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\handleapi.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\errhandlingapi.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\fibersapi.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\namedpipeapi.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\profileapi.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\heapapi.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\ioapiset.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\synchapi.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\interlockedapi.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\processthreadsapi.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\sysinfoapi.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\memoryapi.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\enclaveapi.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\threadpoollegacyapiset.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\threadpoolapiset.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\jobapi.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\jobapi2.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\wow64apiset.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\libloaderapi.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\securitybaseapi.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\namespaceapi.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\systemtopologyapi.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\processtopologyapi.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\securityappcontainer.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\realtimeapiset.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\winerror.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\timezoneapi.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\wingdi.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\winuser.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\pshpack2.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\poppack.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\tvout.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\winnls.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\datetimeapi.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\stringapiset.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:       C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\winnls.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\wincon.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\wincontypes.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\consoleapi.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\consoleapi2.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\consoleapi3.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\winver.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\verrsrc.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\winreg.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\reason.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\winnetwk.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\wnnc.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\stralign.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\winsvc.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\mcx.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\imm.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um\\ime_cmodes.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:  C:\\users\\zn58887\\_bazel_zn58887\\e5awb3j2\\execroot\\org_tensorflow\\external\\nsync\\platform\\msvc\\compiler.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:  C:\\users\\zn58887\\_bazel_zn58887\\e5awb3j2\\execroot\\org_tensorflow\\external\\nsync\\platform\\x86_64\\cputype.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:  C:\\users\\zn58887\\_bazel_zn58887\\e5awb3j2\\execroot\\org_tensorflow\\external\\nsync\\public\\nsync.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:   C:\\users\\zn58887\\_bazel_zn58887\\e5awb3j2\\execroot\\org_tensorflow\\external\\nsync\\public\\nsync_mu.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\users\\zn58887\\_bazel_zn58887\\e5awb3j2\\execroot\\org_tensorflow\\external\\nsync\\public\\nsync_atomic.h\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:   C:\\users\\zn58887\\_bazel_zn58887\\e5awb3j2\\execroot\\org_tensorflow\\external\\nsync\\public\\nsync_mu_wait.h\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\users\\zn58887\\_bazel_zn58887\\e5awb3j2\\execroot\\org_tensorflow\\external\\nsync\\public\\nsync_time.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\users\\zn58887\\_bazel_zn58887\\e5awb3j2\\execroot\\org_tensorflow\\external\\nsync\\public\\nsync_time_internal.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:   C:\\users\\zn58887\\_bazel_zn58887\\e5awb3j2\\execroot\\org_tensorflow\\external\\nsync\\public\\nsync_cv.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:   C:\\users\\zn58887\\_bazel_zn58887\\e5awb3j2\\execroot\\org_tensorflow\\external\\nsync\\public\\nsync_note.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:   C:\\users\\zn58887\\_bazel_zn58887\\e5awb3j2\\execroot\\org_tensorflow\\external\\nsync\\public\\nsync_counter.h\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:   C:\\users\\zn58887\\_bazel_zn58887\\e5awb3j2\\execroot\\org_tensorflow\\external\\nsync\\public\\nsync_waiter.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:   C:\\users\\zn58887\\_bazel_zn58887\\e5awb3j2\\execroot\\org_tensorflow\\external\\nsync\\public\\nsync_once.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:   C:\\users\\zn58887\\_bazel_zn58887\\e5awb3j2\\execroot\\org_tensorflow\\external\\nsync\\public\\nsync_debug.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:  C:\\users\\zn58887\\_bazel_zn58887\\e5awb3j2\\execroot\\org_tensorflow\\external\\nsync\\internal\\dll.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:  C:\\users\\zn58887\\_bazel_zn58887\\e5awb3j2\\execroot\\org_tensorflow\\external\\nsync\\internal\\sem.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:  C:\\users\\zn58887\\_bazel_zn58887\\e5awb3j2\\execroot\\org_tensorflow\\external\\nsync\\internal\\wait_internal.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:  C:\\users\\zn58887\\_bazel_zn58887\\e5awb3j2\\execroot\\org_tensorflow\\external\\nsync\\internal\\common.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:  C:\\users\\zn58887\\_bazel_zn58887\\e5awb3j2\\execroot\\org_tensorflow\\external\\nsync\\platform\\c++11\\atomic.h\u6b63\u5728\u751f\u6210\u4ee3\u7801...\r\nTarget //tensorflow:tensorflow_cc.dll failed to build\r\nINFO: Elapsed time: 82.343s, Critical Path: 9.33s\r\nINFO: 4405 processes: 3447 internal, 958 local.\r\nFAILED: Build did NOT complete successfully", "comments": ["@ZoeZhang91 ,\r\n\r\nTensorFlow v2.3 is built and tested against CUDA 10.1 and cuDNN 7.6. Could you please install the CUDA and cuDNN packages on your machine to compatible versions and check if you are facing same issue.\r\n\r\nFor more information please take a look at the [tested build configurations.](https://www.tensorflow.org/install/source_windows#gpu)Thanks\r\n\r\n\r\n\r\n", "@tilakrayal \r\n\r\nI've tried to build  2.4.1, and 2.4.0, but still with the same compilation error \" C++ compilation of rule '@nsync//:nsync_cpp' failed (Exit 2): python.exe failed: error executing command\".\r\n\r\n\r\n", "@tilakrayal  \r\nAnd now\uff0chere\u2018s another error: depthtospace_op_gpu.cu.cudafe1.stub.c(2): fatal error C1090: PDB API  call failed\uff0cerror code\u201c23\u201d:(0x00000006)", "@ZoeZhang91 ,\r\n\r\nLooks like this is a duplicate of issue #48040.\r\n\r\nCan you please confirm if we close this issue, since it is already being tracked there? Thanks!", "> @ZoeZhang91 ,\r\n> \r\n> Looks like this is a duplicate of issue #48040.\r\n> \r\n> Can you please confirm if we close this issue, since it is already being tracked there? Thanks!\r\n\r\n@tilakrayal  About the compilation error \" C++ compilation of rule '@nsync//:nsync_cpp' failed (Exit 2): python.exe failed: error executing command\", I've found the solution, the cause is that the command  --copt=THRUST_IGNORE_CUB_VERSION_CHECK with the '/' missing, so the right one is  --copt=/THRUST_IGNORE_CUB_VERSION_CHECK. \r\nSorry for my carelessness. And thanks for your reply, i'll close this issue#48794 first. The issue#48040 is not the same. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48794\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48794\">No</a>\n"]}, {"number": 48793, "title": "[TF2.5] Add Py39 to CUDA11.2 build Image", "body": "Addons uses this image to build our whl. While testing compatibility with TF2.5rc2 we noticed that py39 is missing from the docker image.\r\n\r\n\r\ncc @angerson @perfinion ", "comments": ["Looks alright to me. Thanks! Once this gets merged I can deploy it.\r\n\r\n@seanpmorgan In case you haven't seen it, I'm also testing out a unified Dockerfile here: https://github.com/tensorflow/build/pull/21", "`gcr.io/tensorflow-testing/nosla-cuda11.2-cudnn8.1-ubuntu18.04-manylinux2010-multipython` now has Python 3.9."]}, {"number": 48792, "title": "Minor fixes in docstring of keras Model.compile method", "body": "- Consistent usage of backquotes\r\n- minor change in wording\r\n- misspelling ie. > i.e.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F48792) for more info**.\n\n<!-- need_sender_cla -->", "@j-i-l please check sanity build failures ?", "@rthadur, I fixed the pylint errors (line-too-long) in cd0a3b6"]}, {"number": 48791, "title": "Help : Incorrect read of byte[] { Cannot convert between a TensorFlowLite tensor with type FLOAT32 and a Java object of type [B (which is compatible with the TensorFlowLite type UINT8)  }", "body": "The official tutorial mentions that tensor flow should support Byte[]. However, when passed to the model , the following error occurs: \r\n```\r\nE/AndroidRuntime: FATAL EXCEPTION: main\r\n    Process: com.example.se, PID: 6529\r\n    java.lang.RuntimeException: Failure delivering result ResultInfo{who=null, request=65537, result=-1, data=Intent { dat=content://com.android.providers.media.documents/document/audio:31 flg=0x1 }} to activity {com.example.se/com.example.se.Homepage}: java.lang.RuntimeException: java.lang.IllegalArgumentException: Cannot convert between a TensorFlowLite tensor with type FLOAT32 and a Java object of type [B (which is compatible with the TensorFlowLite type UINT8).\r\n        at android.app.ActivityThread.deliverResults(ActivityThread.java:5015)\r\n        at android.app.ActivityThread.handleSendResult(ActivityThread.java:5056)\r\n        at android.app.servertransaction.ActivityResultItem.execute(ActivityResultItem.java:51)\r\n        at android.app.servertransaction.TransactionExecutor.executeCallbacks(TransactionExecutor.java:135)\r\n        at android.app.servertransaction.TransactionExecutor.execute(TransactionExecutor.java:95)\r\n        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:2066)\r\n        at android.os.Handler.dispatchMessage(Handler.java:106)\r\n        at android.os.Looper.loop(Looper.java:223)\r\n        at android.app.ActivityThread.main(ActivityThread.java:7656)\r\n        at java.lang.reflect.Method.invoke(Native Method)\r\n        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:592)\r\n        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:947)\r\n     Caused by: java.lang.RuntimeException: java.lang.IllegalArgumentException: Cannot convert between a TensorFlowLite tensor with type FLOAT32 and a Java object of type [B (which is compatible with the TensorFlowLite type UINT8).\r\n        at com.example.se.Classify.onActivityResult(Classify.java:164)\r\n        at androidx.fragment.app.FragmentActivity.onActivityResult(FragmentActivity.java:170)\r\n        at android.app.Activity.dispatchActivityResult(Activity.java:8310)\r\n        at android.app.ActivityThread.deliverResults(ActivityThread.java:5008)\r\n        at android.app.ActivityThread.handleSendResult(ActivityThread.java:5056)\u00a0\r\n        at android.app.servertransaction.ActivityResultItem.execute(ActivityResultItem.java:51)\u00a0\r\n        at android.app.servertransaction.TransactionExecutor.executeCallbacks(TransactionExecutor.java:135)\u00a0\r\n        at android.app.servertransaction.TransactionExecutor.execute(TransactionExecutor.java:95)\u00a0\r\n        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:2066)\u00a0\r\n        at android.os.Handler.dispatchMessage(Handler.java:106)\u00a0\r\n        at android.os.Looper.loop(Looper.java:223)\u00a0\r\n        at android.app.ActivityThread.main(ActivityThread.java:7656)\u00a0\r\n        at java.lang.reflect.Method.invoke(Native Method)\u00a0\r\n        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:592)\u00a0\r\n        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:947)\u00a0\r\n     Caused by: java.lang.IllegalArgumentException: Cannot convert between a TensorFlowLite tensor with type FLOAT32 and a Java object of type [B (which is compatible with the TensorFlowLite type UINT8).\r\n        at org.tensorflow.lite.Tensor.throwIfTypeIsIncompatible(Tensor.java:427)\r\n        at org.tensorflow.lite.Tensor.getInputShapeIfDifferent(Tensor.java:287)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:146)\r\n        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:360)\r\n        at org.tensorflow.lite.Interpreter.run(Interpreter.java:319)\r\n        at com.example.se.Classify.onActivityResult(Classify.java:161)\r\n        at androidx.fragment.app.FragmentActivity.onActivityResult(FragmentActivity.java:170)\u00a0\r\n        at android.app.Activity.dispatchActivityResult(Activity.java:8310)\u00a0\r\n        at android.app.ActivityThread.deliverResults(ActivityThread.java:5008)\u00a0\r\n        at android.app.ActivityThread.handleSendResult(ActivityThread.java:5056)\u00a0\r\n        at android.app.servertransaction.ActivityResultItem.execute(ActivityResultItem.java:51)\u00a0\r\n        at android.app.servertransaction.TransactionExecutor.executeCallbacks(TransactionExecutor.java:135)\u00a0\r\n        at android.app.servertransaction.TransactionExecutor.execute(TransactionExecutor.java:95)\u00a0\r\n        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:2066)\u00a0\r\n        at android.os.Handler.dispatchMessage(Handler.java:106)\u00a0\r\n        at android.os.Looper.loop(Looper.java:223)\u00a0\r\n        at android.app.ActivityThread.main(ActivityThread.java:7656)\u00a0\r\n        at java.lang.reflect.Method.invoke(Native Method)\u00a0\r\n        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:592)\u00a0\r\n        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:947)\u00a0\r\n```\r\nMy main code is :\r\n```\r\npackage com.example.se;\r\n\r\nimport android.content.Context;\r\nimport android.content.Intent;\r\nimport android.content.res.AssetFileDescriptor;\r\nimport android.content.res.AssetManager;\r\nimport android.database.Cursor;\r\nimport android.media.AudioManager;\r\nimport android.net.Uri;\r\nimport android.net.rtp.AudioStream;\r\nimport android.os.Bundle;\r\nimport android.os.FileUtils;\r\nimport android.util.Log;\r\nimport android.view.LayoutInflater;\r\nimport android.view.View;\r\nimport android.view.ViewGroup;\r\nimport android.widget.Button;\r\nimport android.widget.Toast;\r\n\r\nimport androidx.annotation.NonNull;\r\nimport androidx.annotation.Nullable;\r\nimport androidx.fragment.app.Fragment;\r\n\r\nimport org.tensorflow.lite.Interpreter;\r\nimport org.tensorflow.lite.flex.FlexDelegate;\r\nimport java.io.BufferedInputStream;\r\nimport java.io.BufferedReader;\r\nimport java.io.ByteArrayOutputStream;\r\nimport java.io.File;\r\nimport java.io.FileInputStream;\r\nimport java.io.IOException;\r\nimport java.io.InputStream;\r\nimport java.io.InputStreamReader;\r\nimport java.lang.Object;\r\nimport java.net.URISyntaxException;\r\nimport java.nio.ByteBuffer;\r\nimport java.nio.MappedByteBuffer;\r\nimport java.nio.channels.FileChannel;\r\nimport java.util.ArrayList;\r\nimport java.util.HashMap;\r\nimport java.util.List;\r\nimport java.util.Map;\r\n\r\npublic class Classify extends Fragment {\r\n    private Button choose_file_button;\r\n    private Button stop_classify;\r\n    public static final int PICKFILE_RESULT_CODE = 1;\r\n    private Uri fileUri;\r\n    private String filePath; // This is the final file path\r\n    View classify_view;\r\n\r\n    // To load from asset folder\r\n    private static final String LABEL_FILENAME = \"file:///android_asset/labels.txt\";\r\n    private static final String MODEL_FILENAME = \"file:///android_asset/soundclassifier.tflite\";\r\n    private static final String LOG_TAG = \"Log tagges is here\";\r\n\r\n    // For label and modelfile\r\n    private List<String> labels = new ArrayList<String>();\r\n    private List<String> displayedLabels = new ArrayList<>();\r\n\r\n    // For the audio file\r\n    ByteArrayOutputStream out = new ByteArrayOutputStream();\r\n    InputStream in;\r\n    byte[] audioBytes;\r\n\r\n\r\n    // For machine learning\r\n    private final Interpreter.Options tfliteOptions = new Interpreter.Options();\r\n    private MappedByteBuffer tfLiteModel;\r\n    private Interpreter tfLite;\r\n    private final Interpreter.Options ftliteOptions = new Interpreter.Options();\r\n    float[] outputs;\r\n    private RecognizeCommands recognizeCommands = null;\r\n    // ToDo : Remove this if not needed\r\n\r\n    @Nullable\r\n    @Override\r\n    public View onCreateView(@NonNull LayoutInflater inflater, @Nullable ViewGroup container, @Nullable Bundle savedInstanceState) {\r\n        classify_view = inflater.inflate(R.layout.classify,container,false);\r\n\r\n        // Both finds the classify and stop classify button\r\n        choose_file_button = (Button) classify_view.findViewById(R.id.classify_button);\r\n        stop_classify = (Button) classify_view.findViewById(R.id.stop_classify);\r\n\r\n        // For labels file\r\n        String actualLabelFilename = LABEL_FILENAME.split(\"file:///android_asset/\",-1)[1];\r\n        Log.i(LOG_TAG,\"Reading labels from \" + actualLabelFilename);\r\n\r\n        BufferedReader br = null;\r\n        try{\r\n            br = new BufferedReader(new InputStreamReader(classify_view.getContext().getAssets().open(actualLabelFilename)));\r\n            String line;\r\n            while ((line = br.readLine()) != null){\r\n                labels.add(line);\r\n                if (line.charAt(0) != '_'){\r\n                    displayedLabels.add(line.substring(0,1).toUpperCase()+ line.substring(1));\r\n                }\r\n            }\r\n        } catch (IOException e){\r\n            throw new RuntimeException(\"Problem reading the label file!\",e);\r\n        }\r\n        // Creates the equal number of labels on the output file\r\n        outputs = new float[displayedLabels.size()];\r\n        Log.i(LOG_TAG,\"Labels file messages are :\"+ displayedLabels);\r\n\r\n        // ToDo : Implement Recognize Commands if not working\r\n\r\n        // Opening the model file\r\n        String actualModelFilename = MODEL_FILENAME.split(\"file:///android_asset/\",-1)[1];\r\n        try{\r\n            tfLiteModel = loadModelFile(classify_view.getContext().getAssets(), actualModelFilename);\r\n        } catch (Exception e){\r\n            throw new RuntimeException(e);\r\n        }\r\n\r\n        Log.i(LOG_TAG,\"The modal file is :\"+actualModelFilename);\r\n        Log.i(LOG_TAG,\"The actual content is :\"+tfLiteModel);\r\n\r\n        // ToDo : Model file opened here\r\n        try{\r\n            ftliteOptions.setNumThreads(1);\r\n            FlexDelegate flex = new FlexDelegate();\r\n            ftliteOptions.addDelegate(flex);\r\n            File openThis = new File(MODEL_FILENAME);\r\n            tfLite = new Interpreter(tfLiteModel,ftliteOptions);\r\n            // tfLite = new Interpreter(openThis);\r\n        } catch (Exception e){\r\n            throw new RuntimeException(e);\r\n        }\r\n        Log.i(LOG_TAG,\"TF lite file loaded. \");\r\n\r\n        choose_file_button.setOnClickListener(new View.OnClickListener() {\r\n            @Override\r\n            public void onClick(View v) {\r\n                Intent chooseFile = new Intent(Intent.ACTION_GET_CONTENT);\r\n                chooseFile.setType(\"*/*\");\r\n                chooseFile = Intent.createChooser(chooseFile, \"Choose a file\");\r\n                startActivityForResult(chooseFile, PICKFILE_RESULT_CODE);\r\n                // At this point we have the path of the file\r\n                // File path working.\r\n                /*\r\n                    For pie chart we can have : https://github.com/PhilJay/MPAndroidChart\r\n                 * */\r\n            }\r\n        });\r\n        return classify_view;\r\n    }\r\n    // This gets the file path\r\n    @Override\r\n    public void onActivityResult(int requestCode, int resultCode, Intent data) {\r\n        switch (requestCode) {\r\n            case PICKFILE_RESULT_CODE:\r\n                if (resultCode == -1) {\r\n                    fileUri = data.getData();\r\n                    filePath = fileUri.getPath();\r\n                    System.out.println(\"The selected file path is :\"+filePath);\r\n                    open_audio_file(fileUri);\r\n                    // Opens main audio file\r\n                    try{\r\n                        // Todo : Remove another loadModelFile @Depreciated\r\n                        tfLite.run(audioBytes,outputs);\r\n                        Log.i(LOG_TAG,\"The output is :\"+ outputs);\r\n                    }catch(Exception e){\r\n                        throw new RuntimeException(e);\r\n                    }\r\n                }\r\n                break;\r\n        }\r\n    }\r\n\r\n    public void open_audio_file(Uri filePath){\r\n        try{\r\n            in = new BufferedInputStream(getContext().getContentResolver().openInputStream(filePath));\r\n\r\n            int read;\r\n            byte[] buff = new byte[1024];\r\n            while ((read = in.read(buff)) > 0)\r\n            {\r\n                out.write(buff, 0, read);\r\n            }\r\n            out.flush();\r\n        }catch(Exception e){\r\n            throw new RuntimeException(e);\r\n        }\r\n        //Todo : Change the audio file to a float pointer\r\n        audioBytes = out.toByteArray();\r\n        for (int i = 0;i < audioBytes.length;i++){\r\n            Log.i(LOG_TAG,i+\" \"+audioBytes[i]);\r\n        }\r\n    }\r\n\r\n    // This method loads the TF lite file\r\n    private static MappedByteBuffer loadModelFile(AssetManager assets, String modelFileName)\r\n            throws IOException{\r\n        AssetFileDescriptor fileDescriptor = assets.openFd(modelFileName);\r\n        FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor());\r\n        FileChannel fileChannel = inputStream.getChannel();\r\n        long startOffset = fileDescriptor.getStartOffset();\r\n        long declaredLength = fileDescriptor.getDeclaredLength();\r\n        return fileChannel.map(FileChannel.MapMode.READ_ONLY,startOffset,declaredLength);\r\n    }\r\n\r\n}\r\n```\r\n\r\nI am trying to convert the.wav file into an byte array using the function : \r\n```\r\npublic void open_audio_file(Uri filePath){\r\n        try{\r\n            in = new BufferedInputStream(getContext().getContentResolver().openInputStream(filePath));\r\n\r\n            int read;\r\n            byte[] buff = new byte[1024];\r\n            while ((read = in.read(buff)) > 0)\r\n            {\r\n                out.write(buff, 0, read);\r\n            }\r\n            out.flush();\r\n        }catch(Exception e){\r\n            throw new RuntimeException(e);\r\n        }\r\n        //Todo : Change the audio file to a float pointer\r\n        audioBytes = out.toByteArray();\r\n        for (int i = 0;i < audioBytes.length;i++){\r\n            Log.i(LOG_TAG,i+\" \"+audioBytes[i]);\r\n        }\r\n    }\r\n```", "comments": ["I did verify that the byte[] file created is actually generating the output. This was done using the for loop and also verified using the [StackOverflow answer](https://stackoverflow.com/questions/67290748/how-to-read-wav-file-as-byte-array-in-android-studio).", "This is an intended behavior. You need to provide a float array for float inputs not the byte array. ", "@abattery I am reading in a .wav file from the system, what would be the best way to convert it to a float array?", "@lintian06 could you help? Looks like this issue is related to the sound classification example.", "@karundawadi If your model is generated from the Sound classification example from the Teachable Machine, you need to create a float buffer that holds audio PCM sample. ", "@abattery I converted a wav file to byte[] and converted it to a float buffer. However, upon passing it, it showed me a newer type of error, \r\n\r\nThe error is : \r\n```\r\n E/AndroidRuntime: FATAL EXCEPTION: main\r\n    Process: com.example.se, PID: 8184\r\n    java.lang.RuntimeException: Failure delivering result ResultInfo{who=null, request=65537, result=-1, data=Intent { dat=content://com.android.providers.media.documents/document/audio:31 flg=0x1 }} to activity {com.example.se/com.example.se.Homepage}: java.lang.RuntimeException: java.lang.IllegalArgumentException: Internal error: Failed to run on the given Interpreter: tensorflow/lite/kernels/reshape.cc:69 num_input_elements != num_output_elements (28750 != 0)\r\n    Node number 12 (RESHAPE) failed to invoke.\r\n    \r\n        at android.app.ActivityThread.deliverResults(ActivityThread.java:5015)\r\n        at android.app.ActivityThread.handleSendResult(ActivityThread.java:5056)\r\n        at android.app.servertransaction.ActivityResultItem.execute(ActivityResultItem.java:51)\r\n        at android.app.servertransaction.TransactionExecutor.executeCallbacks(TransactionExecutor.java:135)\r\n        at android.app.servertransaction.TransactionExecutor.execute(TransactionExecutor.java:95)\r\n        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:2066)\r\n        at android.os.Handler.dispatchMessage(Handler.java:106)\r\n        at android.os.Looper.loop(Looper.java:223)\r\n        at android.app.ActivityThread.main(ActivityThread.java:7656)\r\n        at java.lang.reflect.Method.invoke(Native Method)\r\n        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:592)\r\n        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:947)\r\n     Caused by: java.lang.RuntimeException: java.lang.IllegalArgumentException: Internal error: Failed to run on the given Interpreter: tensorflow/lite/kernels/reshape.cc:69 num_input_elements != num_output_elements (28750 != 0)\r\n    Node number 12 (RESHAPE) failed to invoke.\r\n    \r\n        at com.example.se.Classify.onActivityResult(Classify.java:165)\r\n        at androidx.fragment.app.FragmentActivity.onActivityResult(FragmentActivity.java:170)\r\n        at android.app.Activity.dispatchActivityResult(Activity.java:8310)\r\n        at android.app.ActivityThread.deliverResults(ActivityThread.java:5008)\r\n        \t... 11 more\r\n     Caused by: java.lang.IllegalArgumentException: Internal error: Failed to run on the given Interpreter: tensorflow/lite/kernels/reshape.cc:69 num_input_elements != num_output_elements (28750 != 0)\r\n    Node number 12 (RESHAPE) failed to invoke.\r\n    \r\n        at org.tensorflow.lite.NativeInterpreterWrapper.run(Native Method)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:163)\r\n        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:360)\r\n        at org.tensorflow.lite.Interpreter.run(Interpreter.java:319)\r\n        at com.example.se.Classify.onActivityResult(Classify.java:162)\r\n        \t... 14 more\r\n\r\n```\r\nThe code is : \r\n```\r\n byte[] audioBytes;\r\n float[] audioInput;\r\naudioBytes = out.toByteArray();\r\n        audioInput = new float[audioBytes.length];\r\n        outputs = new float[audioBytes.length];\r\n        for (int i = 0;i < audioBytes.length;i++){\r\n            audioInput[i] = (float) audioBytes[i];\r\n        }\r\n```\r\n\r\nAll other remaining aspects of the program was kept the same. The output and input both are in float []. ", "Is it possible to share your TFLite model to us to take a look at the graph?", "Yes, I have attached the file to this comment. \r\n\r\nThe link redirects to my google drive, where all the files are present. \r\n\r\n[Link to File](https://drive.google.com/drive/folders/1HA_90Bgic60Zurla_5OAK75Uu83EpKlB?usp=sharing)", "I ran your TFLite model with the TFLite model benchmark tool. It was successfully done. According to the model spec, you need to provide a float [1][44032] array. Please make sure that your inference code meets the model spec's requirement.", "Thank you I implemented the float specifications as you provided, it worked. \r\n\r\nThank you! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48791\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48791\">No</a>\n", "Glad to hear that!"]}, {"number": 48790, "title": "Create .zenodo.json", "body": "This is for clean metadata on TensorFlow's Zenodo DOI page. It won't be used until a new full release is made (probably 2.6).", "comments": ["Ahh, I bet I'll have to do this internally-first, because it introduces a new file in the root folder."]}, {"number": 48789, "title": "Clean up intermediate files from CI execution.", "body": "Manually tested that running test_all.sh when there is an error exits on the error with the proper error code, and also calls the cleanup function to delete the downloads and gen directories.\r\n\r\nFixes http://b/186570469\r\n", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 48788, "title": "Incorrect batch size info with keras.utils.Sequence", "body": "TensorFlow 2.4.1\r\n\r\nBatch size info is miscalculated when data is wrapped in Sequence. The example below is the output for the first epoch training on 10,000 points with batch_size=32, which should result in 313 mini-batch updates.  The batch number on the far left is correct (313/313), however, the size and batch before loss seem to be incorrect. \r\n\r\nOutput: \r\nEpoch 1/100\r\n313/313 [==============================] - 1s 966us/step - **_batch: 156.0000 - size: 31.9489_** - loss: 0.1579\r\n\r\n ", "comments": ["@sciann \r\nCould you please fill the template.\r\nand also share more details for us to analyse, simple stand alone code to replicate the issue faced or a colab gist with the code and error.Thanks\r\n\r\n\r\n\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Hi - I tested the Sequence using pure Keras code and everything works fine. However, we I use it through SciANN, which defines custom layers etc, it does not work properly. Note that SciANN does not make any adjustment to the Keras training. Any suggestions? \r\n\r\nClass to prepare data: \r\n\r\n```python\r\nclass Data(k.utils.Sequence):\r\n    \"\"\"\r\n    Converts fit() into fit_generator() interface.\r\n    \"\"\"\r\n\r\n    def __init__(self, inputs, outputs, sample_weights, batch_size, shuffle):\r\n        self._inputs = inputs\r\n        self._outputs = outputs\r\n        self._sample_weights = sample_weights\r\n        self._size = inputs[0].shape[0]\r\n        self._batch_size = batch_size\r\n        self._num_batches = int((self._size-1)/batch_size) + 1\r\n        self._shuffle = shuffle\r\n        self._ids = np.arange(0, self._size)\r\n        self._reshuffle()\r\n        print(\"\\nTotal samples: {} \".format(self._size))\r\n        print(\"Batch size: {} \".format(min(self._batch_size, self._size)))\r\n        print(\"Total batches: {} \\n\".format(self._num_batches))\r\n\r\n    def __len__(self):\r\n        return self._num_batches\r\n\r\n    def __getitem__(self, index):\r\n        start = index * self._batch_size\r\n        end = min(start + self._batch_size, self._size)\r\n        ids = self._ids[start: end]\r\n        inputs = [v[ids, :] for v in self._inputs]\r\n        outputs = [v[ids, :] for v in self._outputs]\r\n        sample_weights = [v[ids] for v in self._sample_weights]\r\n        return inputs, outputs, sample_weights\r\n    \r\n    def on_epoch_end(self):\r\n        self._reshuffle()\r\n\r\n    def get_data(self):\r\n        return self._inputs, self._outputs, self._sample_weights\r\n\r\n    def _reshuffle(self):\r\n        if self._num_batches > 1 and self._shuffle:\r\n            self._ids = np.random.choice(self._size, self._size, replace=False)\r\n```\r\n\r\nNow, pure Keras code: \r\n```python\r\nfrom tensorflow import keras as k\r\nimport numpy as np \r\n\r\nx = k.Input((1,))\r\nl1 = k.layers.Dense(10, activation='tanh')(x)\r\ny = k.layers.Dense(1)(l1)\r\n\r\nmodel = k.Model(x, y)\r\nmodel.compile(loss=k.losses.MSE)\r\n\r\ninputs = [np.linspace(0, 1, 1000).reshape(-1,1)]\r\noutputs = list(map(lambda x: np.sin(2*x), inputs))\r\nweights = list(map(lambda x: np.ones_like(x), inputs))\r\n\r\ndg = Data2(inputs, outputs, weights, 32, True)\r\n\r\nmodel.fit(dg, epochs=100)\r\n```\r\n\r\n\r\nSciANN code with the above issue: \r\n\r\n```python\r\nimport sciann as sn \r\nimport numpy as np \r\nfrom tensorflow import keras as k\r\n\r\nx = sn.Variable('x')\r\ny = sn.Functional('y', x, [10], 'tanh')\r\n\r\nmodel = sn.SciModel(x, y)\r\n\r\ninputs = [np.linspace(0, 1, 1000).reshape(-1,1)]\r\noutputs = list(map(lambda x: np.sin(2*x), inputs))\r\nweights = list(map(lambda x: np.ones_like(x).flatten(), inputs))\r\n\r\ndg = Data(inputs, outputs, weights, 32, True)\r\n\r\nmodel.train(dg, epochs=100)\r\n```", "@sciann @ehsanhaghighat I can reproduce your issue. As you mentioned, everything works as expected when you use `tf.keras`. The issue is reproducible only when you create a model using `sciann`. [Here](https://colab.research.google.com/gist/jvishnuvardhan/6bc29e8f932600be23c67d71641db3a3/48788.ipynb) is a gist for our reference. \r\n\r\nAs we don't have any experts of `SciANN`, this issue is better to be opened in their repo.  Alternatively, you could post this kind of support questions at Stackoverflow where there is a big community to support and learn from your questions.\r\n\r\nThis GitHub repo is mainly to resolve installation, bugs and performance related issues corresponding to `tensorflow` and `tf.keras`.  Thanks!\r\n\r\nI am closing this issue as it is related to other repository. Please feel free to reopen if I am mistaken. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48788\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48788\">No</a>\n", "I had a chance to debug the issue, and it seems to be rooted in the `train_generator_v1.py`. \r\n\r\nPlease use `tf.compat.v1.disable_eager_execution()` at the beginning of the code to get the same problem. \r\n\r\nSciANN works on the TF1. "]}, {"number": 48787, "title": "Tensorflow 2.4.1 hangs on any operation using Conda and RTX3070", "body": "Hello all. I'm having a bit of a trouble using Tensorflow on a dedicated conda environment. Any operation e.g. instantiating two tensors and printing them hangs the execution. I'm using:\r\n\r\n**System information**\r\n- Linux Ubuntu 20.04\r\n- Desktop with RTX 3070, nvidia drivers 460\r\n- CUDA Version 11.2\r\n\r\nI even tried to force it to use the CPU but no better results. It only works if I just do:\r\n\r\n`import tensorflow as tf`\r\n`print(tf.__version__)`\r\n\r\nand prints:\r\n\r\n`python3 main.py`\r\n`2021-04-27 22:14:42.169855: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1`\r\n`2.4.1`\r\n\r\nbut when making any operation such as:\r\n\r\n`a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])`\r\n`b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])`\r\n`c = tf.matmul(a, b)`\r\n\r\nit stops, printing this:\r\n\r\n![Screenshot from 2021-04-27 22-25-32](https://user-images.githubusercontent.com/30077568/116314881-9b312b80-a7a7-11eb-9179-f8d230dc9064.png)\r\n\r\nI even tried to add:\r\n`my_devices = tf.config.experimental.list_physical_devices(device_type='CPU')`\r\n`tf.config.experimental.set_visible_devices(devices= my_devices, device_type='CPU')`\r\n\r\nbut no luck :/ it ends up executing but takes minutes.\r\nThanks!\r\n", "comments": ["@luisArandas ,\r\n\r\nThe messages are just information logs stating that TensorFlow has successfully detected the GPU on your machine. You can safely ignore them.\r\n\r\nYou can also disable them by changing the log level using the below code snippet\r\n\r\nimport os\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \r\nimport tensorflow as tf\r\n\r\nPlease find the gist of the same [here](https://colab.research.google.com/gist/tilakrayal/b1802d7d788a2f10e2fb32459d56b26c/48787.ipynb).Thanks!", "Thank you @tilakrayal \r\n\r\nStill wondering why it takes minutes to run, and it doesn't seem it's tensor computation. Maybe that I have CUDA 11.2 installed and it is instantiating other version through conda?\r\n", "@luisArandas ,\r\n\r\nTensorFlow v2.4 is built and tested against CUDA 11.0 and cuDNN 8. Could you please install the CUDA and cuDNN packages on your machine to compatible versions and check if you are facing same issue.For more information please take a look at the [tested build configurations](https://www.tensorflow.org/install/source#gpu).\r\n\r\nThanks", "Same issue with Ubuntu 20.04. \r\n\r\nPython version: \r\n```\r\nPython 3.9.2 | packaged by conda-forge | (default, Feb 21 2021, 05:02:46)\r\n```\r\n\r\nTensorflow version: \r\n\r\n```\r\n\u276f conda list | grep tensorflow\r\ntensorflow                2.4.1           gpu_py39h8236f22_0  \r\ntensorflow-base           2.4.1           gpu_py39h29c2da4_0  \r\ntensorflow-estimator      2.4.1              pyheb71bc4_0  \r\ntensorflow-gpu            2.4.1                h30adc30_0 \r\n```\r\n```python\r\n\u276f python\r\nPython 3.9.2 | packaged by conda-forge | (default, Feb 21 2021, 05:02:46) \r\n[GCC 9.3.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n\r\n>>> import tensorflow as tf\r\n2021-04-30 14:32:10.400682: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\n\r\n>>> tf.add(1, 2)\r\n2021-04-30 14:32:26.991352: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-04-30 14:32:26.993581: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n2021-04-30 14:32:27.026516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-04-30 14:32:27.027085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce GTX 960M computeCapability: 5.0\r\ncoreClock: 1.176GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2021-04-30 14:32:27.027104: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\n2021-04-30 14:32:27.028731: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\r\n2021-04-30 14:32:27.028771: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\r\n2021-04-30 14:32:27.030183: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2021-04-30 14:32:27.030438: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2021-04-30 14:32:27.032093: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2021-04-30 14:32:27.033044: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\r\n2021-04-30 14:32:27.036642: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\r\n2021-04-30 14:32:27.036780: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-04-30 14:32:27.037699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-04-30 14:32:27.038214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2021-04-30 14:32:27.038509: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-04-30 14:32:27.038916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-04-30 14:32:27.039462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce GTX 960M computeCapability: 5.0\r\ncoreClock: 1.176GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2021-04-30 14:32:27.039482: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\n2021-04-30 14:32:27.039507: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\r\n2021-04-30 14:32:27.039522: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\r\n2021-04-30 14:32:27.039536: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2021-04-30 14:32:27.039550: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2021-04-30 14:32:27.039563: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2021-04-30 14:32:27.039577: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\r\n2021-04-30 14:32:27.039590: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\r\n2021-04-30 14:32:27.039645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-04-30 14:32:27.040215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-04-30 14:32:27.040651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2021-04-30 14:32:27.040677: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\n\r\n```", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48787\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48787\">No</a>\n", "I'm having the same problem here. I have 3060Ti and running Ubuntu 18.04 with driver 470.103.01. I used conda to install tensorflow-gpu 2.4. Even for simple operation like `python -c \"import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"` it can take a minute to finish execution. I tried tensorflow-gpu 2.1 and it's the same issue. But using CPU tensorflow is fast as it should be.\r\n\r\nDid you manage to solve this problem? "]}, {"number": 48785, "title": "Warnings related to Custom Layer ", "body": "**System information**\r\n- Windows 10 (64-bit): \r\n- TensorFlow version: 2.1.0\r\n- Python version: 3.6\r\n- CPU\r\n\r\n**Describe the current behavior**\r\nI have implemented the custom layer described [here](https://github.com/fabianbormann/Tensorflow-DeconvNet-Segmentation/blob/master/DeconvNet.py). This layer is the UpSampling layer described in the SegNet model.\r\n\r\nIn order to test the implementation, I wrote a short dummy code (see in the standalone version): \r\n\r\nAfter  running, the following Info, Warning and Errors appear:\r\n\r\n```\r\n\r\nINFO:tensorflow:Converted call: <bound method UnpoolingLayer.call of <__main__.UnpoolingLayer object at 0x00000223E0021748>>\r\n    args: (<tf.Tensor 'stage1_conv1_4/Identity:0' shape=(None, 64, 64, 64) dtype=float32>,)\r\n    kwargs: {}\r\n\r\nConverted call: <bound method UnpoolingLayer.call of <__main__.UnpoolingLayer object at 0x00000223E0021748>>\r\n    args: (<tf.Tensor 'stage1_conv1_4/Identity:0' shape=(None, 64, 64, 64) dtype=float32>,)\r\n    kwargs: {}\r\n\r\nINFO:tensorflow:Error transforming entity <bound method UnpoolingLayer.call of <__main__.UnpoolingLayer object at 0x00000223E0021748>>\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\zz19101\\Anaconda3\\envs\\tf21\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\", line 526, in converted_call\r\n    converted_f = conversion.convert(target_entity, program_ctx)\r\n  File \"C:\\Users\\zz19101\\Anaconda3\\envs\\tf21\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\conversion.py\", line 328, in convert\r\n    return _instantiate(entity, converted_entity_info, free_nonglobal_var_names)\r\n  File \"C:\\Users\\zz19101\\Anaconda3\\envs\\tf21\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\conversion.py\", line 266, in _instantiate\r\n    factory = converted_entity_info.get_factory()\r\n  File \"C:\\Users\\zz19101\\Anaconda3\\envs\\tf21\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\conversion.py\", line 92, in get_factory\r\n    assert self.module_name in sys.modules\r\nAssertionError\r\nError transforming entity <bound method UnpoolingLayer.call of <__main__.UnpoolingLayer object at 0x00000223E0021748>>\r\nWARNING:tensorflow:AutoGraph could not transform <bound method UnpoolingLayer.call of <__main__.UnpoolingLayer object at 0x00000223E0021748>> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: \r\nWARNING: AutoGraph could not transform <bound method UnpoolingLayer.call of <__main__.UnpoolingLayer object at 0x00000223E0021748>> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: \r\nModel: \"model_4\"\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\zz19101\\Anaconda3\\envs\\tf21\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\", line 526, in converted_call\r\n    converted_f = conversion.convert(target_entity, program_ctx)\r\n  File \"C:\\Users\\zz19101\\Anaconda3\\envs\\tf21\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\conversion.py\", line 328, in convert\r\n    return _instantiate(entity, converted_entity_info, free_nonglobal_var_names)\r\n  File \"C:\\Users\\zz19101\\Anaconda3\\envs\\tf21\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\conversion.py\", line 266, in _instantiate\r\n    factory = converted_entity_info.get_factory()\r\n  File \"C:\\Users\\zz19101\\Anaconda3\\envs\\tf21\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\conversion.py\", line 92, in get_factory\r\n    assert self.module_name in sys.modules\r\nAssertionError\r\n\r\n```\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\ndef max_pool_with_argmax(x):\r\n    \"\"\"According to the documentation, the value at each position in the argmax tensor \r\n    is calculated according to:  so that a maximum value at position [b, y, x, c] \r\n    becomes flattened index: (y * width + x) * channels + c if include_batch_in_index \r\n    is False; ((b * height + y) * width + x) * channels + c if include_batch_in_index is True.\r\n    \r\n    \"\"\"\r\n    return tf.nn.max_pool_with_argmax(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\r\n\r\n\r\nclass UnpoolingLayer(Layer):\r\n    \r\n    \"\"\" This class generates the Unpooling Layer present in the Segnet and \r\n    DeconvNet models.\r\n    \"\"\"\r\n    def __init__(self, pooling_argmax, stride=[1,2,2,1], **kwargs):\r\n        self.stride = stride\r\n        self.pooling_argmax = pooling_argmax\r\n        super(UnpoolingLayer, self).__init__(**kwargs)\r\n        \r\n    def build(self, input_shape):\r\n        super(UnpoolingLayer, self).build(input_shape)\r\n\r\n        \r\n    def call(self, inputs):\r\n       input_shape = K.cast(K.shape(inputs), dtype='int64')  # Convert\r\n       \r\n       output_shape = (input_shape[0],\r\n                       input_shape[1]*self.stride[1],\r\n                       input_shape[2]*self.stride[2],\r\n                       input_shape[3])\r\n       \r\n       argmax = self.pooling_argmax\r\n       one_like_mask = K.ones_like(argmax) # Create Tensor of 1s with same shape as argmax --> 4-dimensional tensor\r\n       batch_range = K.reshape(K.arange(start=0, stop=input_shape[0], dtype='int64'), \r\n                                 shape=[input_shape[0], 1, 1, 1]) # Create a tensor of shape (Batch Size, 1 ,1 ,1)\r\n       \r\n       b = one_like_mask * batch_range  # 4 dimensional tensor\r\n       #Multiply the ones mask by the batch range, so that we have a 4-dimension tensor, wth the pixels in the first dimension indicating the batch id for each index\r\n       y = argmax // (output_shape[2] * output_shape[3])\r\n       x = argmax % (output_shape[2] * output_shape[3]) // output_shape[3]\r\n       feature_range = K.arange(start=0, stop=output_shape[3], dtype='int64')  # Indicate the channel index\r\n       f = one_like_mask * feature_range\r\n       \r\n       updates_size = tf.size(inputs)  # Number of elements in the tensor\r\n       indices = K.transpose(K.reshape(K.stack([b, y, x, f]), [4, updates_size]))   # Generate a 2D array where the rows are the b, y, x , f values and the columns are actually the number of elements in the input tensor, and then just transpose it\r\n       values = K.reshape(inputs, [updates_size]) # flatten it to one dimension so that they can be feed to the tf.scatter\r\n       \r\n       \r\n       return tf.scatter_nd(indices, values, output_shape)\r\n   \r\n    def compute_output_shape(self, input_shape):\r\n        return (input_shape[0], input_shape[1] * 2, input_shape[2] * 2, input_shape[3])\r\n    \r\n    \r\n    def get_config(self):\r\n        base_config = super(UnpoolingLayer, self).get_config()\r\n        base_config['pooling_argmax'] = self.pooling_argmax\r\n        base_config['stride'] = self.stride\r\n        return base_config\r\n\r\n    @classmethod\r\n    def from_config(cls, config):\r\n        return cls(**config)\r\n       \r\n\r\nif __name__ == \"__main__\":\r\n    \r\n    \r\n   input_tensor = Input(shape=(128,128,1))\r\n   \r\n   pool1, pool1_argmax = Lambda(max_pool_with_argmax, name='max_pool1')(input_tensor)\r\n   \r\n   x = Conv2D(64, kernel_size=3, padding='same', kernel_initializer='he_normal', name='stage1_conv1')(pool1)\r\n   \r\n   unpool1 = UnpoolingLayer(pool1_argmax, name='unpool1')(x)\r\n   unpool1.set_shape(pool1.get_shape())\r\n   \r\n   x = Conv2D(64, kernel_size=3, padding='same', kernel_initializer='he_normal', name='stage1_conv1')(unpool1)\r\n   \r\n   model = Model(inputs = input_tensor, outputs = unpool1)\r\n   model.summary()\r\n```\r\n\r\nWhat can be causing these warnings? Can I just ignore them?", "comments": ["@pedrogalher \r\n\r\nI ran the code shared but faced a different error, please find the [gist](https://colab.research.google.com/gist/UsharaniPagadala/123b3202121c7b47cf0de23d769f3509/-48785.ipynb) here and share all dependencies such that we can replicate the issue reported .Thanks\r\n\r\n", "@UsharaniPagadala \r\n\r\nHi, thanks for your answer. I run the code in TF 13.1 and Keras 2.2.4 and it apparently works now. Here is the [colab](https://colab.research.google.com/drive/15j1qVC_33zQmtn12Cjbz30WY7m9P1n5g#scrollTo=qRlHE_bO77o9)\r\n\r\nCan you test it in your machine with this setup and double-check that it actually works?\r\n\r\nThank you", "@pedrogalher \r\nThank you for your update, glad its working fine for you, kindly move this issue to closed status as it is resolved.\r\n\r\nI don't have access to the colab you shared.Please provide me the access if it is required to reproduced the issue in the above mentioned tf versions .Please open a new issue if you'd like to work on this further.Thanks\r\n\r\n\r\n\r\n\r\n</div></b>", "@UsharaniPagadala \r\n\r\nHi! Could you try with this link: [colab](https://colab.research.google.com/drive/15j1qVC_33zQmtn12Cjbz30WY7m9P1n5g?usp=sharing)\r\n\r\nThank you :)", "@pedrogalher \r\nI tried running your [colab](https://colab.research.google.com/gist/UsharaniPagadala/9ba3cec01c42e4dc9594714b1fb85a3a/deconvnet.ipynb) provided,yes I could access it and didn't face any error.Thanks"]}, {"number": 48784, "title": "Limit number of parallel builds to nproc.", "body": "Without such a limit, running the test_cortex_m_corstone_300 script via github actions results in the ubild failing.\r\n\r\nSee https://github.com/tensorflow/tflite-micro/pull/29 for additional context.\r\n", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 48782, "title": "[Pluggable Device] Fix the MacOS regression for registering Pluggable\u2026", "body": "Earlier[ commit in ](https://github.com/tensorflow/tensorflow/pull/45784/commits/463cad1324fcfbb082ae757484614f77bdc3929d) pluggable [impl ](https://github.com/tensorflow/tensorflow/pull/45784) seems to have caused regression on mac platforms to register pluggable device. When _pywrap_tensorflow .so loads up the plugin it goes through the device initialization fine then it hands over to libtensorflow_framework dylib to query the plugin handle using the Platform name in MultiPlatformManager . And during this part it fails with \"Platform \" not found. Reverting the commit fixes the problem for Mac. The change was added to fix unit tests on MacOS tests, which seem to be working with this.\r\n\r\n@penpornk and @jzhoulon ", "comments": ["@kulinseth Thanks for the fix, i saw you remove some dependence, I remember if without these dependence, some Google Internal case will fail. @penpornk \r\n\r\n```\r\n     \"//tensorflow/core:core_cpu\",\r\n        \"//tensorflow/core:framework\",\r\n        \"//tensorflow/core:lib\",\r\n        \"//tensorflow/core:lib_internal\",\r\n        \"//tensorflow/core:protos_all_cc\",\r\n        \"//tensorflow/core/common_runtime:bfc_allocator\",\r\n        \"//tensorflow/core/common_runtime:dma_helper\",\r\n        \"//tensorflow/core/common_runtime:local_device\",\r\n        \"//tensorflow/core/common_runtime:process_state\",\r\n        \"//tensorflow/core/common_runtime:shared_counter\"\r\n```", "@kulinseth Many CIs broke. I think we can start with [Ubuntu Sanity](https://source.cloud.google.com/results/invocations/4ac4211c-efa2-4f5c-a3f0-9298e7aeaedf/log) and [Ubuntu CPU](https://source.cloud.google.com/results/invocations/f74fa7e3-949d-410a-aeb9-1ad7b094e324/targets).", "> @kulinseth Many CIs broke. I think we can start with [Ubuntu Sanity](https://source.cloud.google.com/results/invocations/4ac4211c-efa2-4f5c-a3f0-9298e7aeaedf/log) and [Ubuntu CPU](https://source.cloud.google.com/results/invocations/f74fa7e3-949d-410a-aeb9-1ad7b094e324/targets).\r\n\r\nThanks @penpornk , i was looking at some of the failures on MacOS CPU python3 (as it was readily available), which is in the logs:\r\n\r\n`\r\nbazel test --build_tag_filters=-no_oss,-no_oss_py2,-gpu,-tpu,-benchmark-test,-nomac,-no_mac,-v1only --test_tag_filters=-no_oss,-no_oss_py2,-gpu,-tpu,-benchmark-test,-nomac,-no_mac,-v1only  --spawn_strategy=standalone  --remote_timeout=600 --strategy=Javac=standalone  -- //tensorflow/python/data/kernel_tests:enumerate_test\r\n`\r\n\r\nIts working locally on mac:\r\n`\r\nINFO: Build completed successfully, 5682 total actions\r\n//tensorflow/python/data/kernel_tests:enumerate_test                     PASSED in 3.5s\r\n`\r\n\r\nAm i missing something to locally reproduce this issue ?\r\nMeanwhile i will setup a linux cpu machine to test it as well.", "@kulinseth Can you try running the test with [this script](https://cs.opensource.google/tensorflow/tensorflow/+/master:tensorflow/tools/ci_build/presubmit/macos/py37_cc/build.sh)? I think this is how the CI is set up.", "Check out this pull request on&nbsp; <a href=\"https://app.reviewnb.com/tensorflow/tensorflow/pull/48782\"><img align=\"absmiddle\"  alt=\"ReviewNB\" height=\"28\" class=\"BotMessageButtonImage\" src=\"https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png\"/></a> \n\n See visual diffs & provide feedback on Jupyter Notebooks. \n\n---\n\n <i>Powered by <a href='https://www.reviewnb.com/?utm_source=gh'>ReviewNB</a></i>", "All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F48782) for more info**.\n\n<!-- need_author_consent -->", "> @kulinseth Can you try running the test with [this script](https://cs.opensource.google/tensorflow/tensorflow/+/master:tensorflow/tools/ci_build/presubmit/macos/py37_cc/build.sh)? I think this is how the CI is set up.\r\n\r\nThanks @penpornk , I have further reduced the scope of change to just the `pluggable_init` target. This works on Mac as the plugin init registry is where the device registration was missing due to static initialization of the `plugin_runtime_impl`. I tested on Ubuntu machine few of these tests which are fixed.", "> Thank you very much, @kulinseth! Hope all the tests pass this time!\r\n\r\nLooks like the tests are fixed but the windows bazel build is failing :\r\nexe.tensorflow/tools/ci_build/builds/gen_win_out.exe\r\n\r\nCan't tell what is this related to? Any ideas @penpornk ?\r\n\r\n", "@kulinseth This looks like an existing failure. I'll pull the PR in. :)", "Manually setting CLA to yes since all three commits in this PR are authored by the same email address that has a CLA with us."]}, {"number": 48781, "title": "restoring checkpoint from 2.3 fails on TPU version 2.4.0 ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes \r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.4.0\r\n- Python version: 3.7.x\r\n\r\n\r\n**Describe the current behavior**\r\nWe have a checkpoint that is trained using tpu with tf 2.3. We recently upgraded to 2.4.0 and tried restoring the checkpoint using tpu. We get some internal error from tpu.\r\n\r\n**Describe the expected behavior**\r\nWe expect that the older checkpoints could be restored without any errors. \r\n\r\n\r\n**Standalone code to reproduce the issue**\r\n*Will soon provide checkpoint and code example*\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n![tf2 4_bug](https://user-images.githubusercontent.com/40743476/116276513-9b530c00-a752-11eb-93e7-5c6412f9ef46.png)\r\n<img width=\"1576\" alt=\"screen_shot 2021-04-27 at 12 16 40\" src=\"https://user-images.githubusercontent.com/40743476/116276559-a27a1a00-a752-11eb-8308-f32e88cf53f3.png\">\r\n<img width=\"1678\" alt=\"screen_shot 2021-04-27 at 12 17 09\" src=\"https://user-images.githubusercontent.com/40743476/116276832-e4a35b80-a752-11eb-87df-fb8667aeaf7a.png\">\r\n", "comments": ["@joannayoo0117  With out the Minimal code snippet, it will be difficult for us to debug the issue at our end. Please provide the simple standalone code/ colab link to reproduce the issue at our end.Thanks", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48781\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48781\">No</a>\n"]}, {"number": 48780, "title": "docs: added Contributor Over Time", "body": "This PR aims to show the Contributor Over Time for tensorflow.", "comments": ["I don't think this is relevant. We don't want to change a guidelines file to one with bragging contents."]}, {"number": 48779, "title": "installation on ubuntu 18.04 failed, followed official instructions", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution Ubuntu 18.04\r\n\r\n\r\n**Describe the problem**\r\n\r\nI followed https://www.tensorflow.org/install/gpu#ubuntu_1804_cuda_110 to install GPU enabled tensorflow\r\n\r\n```\r\nwget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\r\nsudo mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\r\nsudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub\r\nsudo add-apt-repository \"deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/ /\"\r\n```\r\n\r\nand I got error on the 4th command\r\n\r\n```\r\nW: GPG error: https://developer.download.nvidia.cn/compute/cuda/repos/ubuntu1804/x86_64  Release: The following signatures were invalid: BADSIG F60F4B3D7FA2AF80 cudatools <cudatools@nvidia.com>\r\nE: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release' is not signed.\r\nN: Updating from such a repository can't be done securely, and is therefore disabled by default.\r\nN: See apt-secure(8) manpage for repository creation and user configuration details.\r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@ssh352 ,\r\n\r\nIn order to expedite the trouble-shooting process, could you please provide the following information\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nTensorFlow installed from (source or binary):\r\nTensorFlow version:\r\nPython version:\r\nInstalled using virtualenv? pip? conda?:\r\nBazel version (if compiling from source):\r\nGCC/Compiler version (if compiling from source):\r\nCUDA/cuDNN version:\r\nGPU model and memory:\r\n \r\nand the exact sequence of commands / steps that you executed before running into the problem\r\n\r\nThanks!", "@tilakrayal Thank you for the response!\r\n\r\nOS Platform and Distribution ubuntu 18.04\r\nTensorFlow installed from (source or binary): binary \r\nTensorFlow version: 2.4\r\nPython version: python 3.7.7\r\nInstalled using virtualenv? pip? conda?: pip\r\nBazel version (if compiling from source):\r\nGCC/Compiler version (if compiling from source):\r\nCUDA/cuDNN version: cuda 11.0\r\nGPU model and memory: Nvidia P40 24G\r\n\r\nand the exact sequence of commands / steps that you executed before running into the problem\r\n\r\nI followed https://www.tensorflow.org/install/gpu#ubuntu_1804_cuda_110 to install Cuda to get GPU enabled tensorflow\r\n\r\nI did\r\n\r\n```\r\nwget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\r\nsudo mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\r\nsudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub\r\nsudo add-apt-repository \"deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/ /\"\r\n```\r\n\r\nand I got error on the 4th command\r\n\r\n```\r\nW: GPG error: https://developer.download.nvidia.cn/compute/cuda/repos/ubuntu1804/x86_64  Release: The following signatures were invalid: BADSIG F60F4B3D7FA2AF80 cudatools <cudatools@nvidia.com>\r\nE: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release' is not signed.\r\nN: Updating from such a repository can't be done securely, and is therefore disabled by default.\r\nN: See apt-secure(8) manpage for repository creation and user configuration details.\r\n```\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@ssh352 ,\r\n\r\nCan you please refer this issues for the similar type of error. [link1](https://github.com/NVIDIA/nvidia-docker/issues/1369),[link2](https://askubuntu.com/questions/732985/force-update-from-unsigned-repository),[link3](https://github.com/NVIDIA/nvidia-docker/issues/613)", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48779\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48779\">No</a>\n"]}, {"number": 48778, "title": "Probele with make when trying to build the Test_hello_world_test TinyML", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows\r\n- TensorFlow installed from (source or binary): Source\r\n- Tensorflow version (commit SHA if source): 1.12.0\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): PC\r\n\r\n**Describe the problem**\r\nI'm trying to build the Test_hello_world_test from the TinyML book using make command but I receive the following error.\r\nMake version is 4.3.\r\nI found some other issues but they don't resolve my probleme. I'am bocked at this stage.\r\nIt seems that the probleme is with the makefile\r\nCan Any One Help Me Please?\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n\r\nC:\\tensorflow>make -f tensorflow/lite/micro/tools/make/Makefile hello_world_test\r\nprocess_begin: CreateProcess(NULL, uname -m, ...) failed.\r\ntensorflow/lite/micro/tools/make/Makefile:47: pipe: No error\r\n-m \u00e9tait inattendu.\r\n'tr' n\u2019est pas reconnu en tant que commande interne\r\nou externe, un programme ex\u00e9cutable ou un fichier de commandes.\r\nFIND\u00a0: format incorrect de param\u00e8tre\r\nFIND\u00a0: format incorrect de param\u00e8tre\r\nLa syntaxe de la commande n\u2019est pas correcte.\r\nprocess_begin: CreateProcess(NULL, bash C:\\tensorflow\\tensorflow\\lite\\micro\\tools\\make\\flatbuffers_download.sh tensorflow/lite/micro/tools/make/downloads, ...) failed.\r\ntensorflow/lite/micro/tools/make/Makefile:570: pipe: Bad file descriptor\r\ntensorflow/lite/micro/tools/make/Makefile:572: *** Something went wrong with the flatbuffers download: .  Stop.", "comments": ["@Mon3am ,\r\n\r\nWe see that you are using tf version 1.15, there is no support for 1.x, please update to 2.x and let us know if you are using same issue.", "Hi\r\nthank you for your response\r\nI updated the Tensorflow to version 2.4.1 but I still receive the same error", "Please take a look at similar [thread](https://forums.tinyml.org/t/make-doesnt-work-on-hello-world-test-from-tinyml-book/344) for workarounds. ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48778\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48778\">No</a>\n"]}, {"number": 48777, "title": "After installing cudatoolkit 10.1, cudnn 7.6.5 & tf 2.3.0, I still can\u00b4t see my GPU device.", "body": "**System information**\r\nOS Platform and Distribution: Win10 x64\r\nTensorFlow installed from (source or binary): binary\r\nTensorFlow version: 2.3.0\r\nPython version: 3.8.5\r\nInstalled using conda\r\nCUDA toolkit/cuDNN version: 10.1 / 7.6.5\r\nGPU model and memory: GTX1650 Ti\r\n\r\n**Describe the problem**\r\nI have installed the above version of packages plus jupyter notebook in Miniconda. \r\n![image](https://user-images.githubusercontent.com/9957900/116236369-4669c280-a75f-11eb-8ed1-b016dfdb219a.png)\r\n\r\n![image](https://user-images.githubusercontent.com/9957900/116236390-4ec1fd80-a75f-11eb-9bce-6bc711392255.png)\r\n\r\n![image](https://user-images.githubusercontent.com/9957900/116236422-584b6580-a75f-11eb-88a1-5bd6d6371435.png)\r\n\r\n![image](https://user-images.githubusercontent.com/9957900/116236453-600b0a00-a75f-11eb-8a5c-88f521b6e1d7.png)\r\n\r\nI still can\u00b4t see my GPU device after running the code.\r\n![image](https://user-images.githubusercontent.com/9957900/116236592-87fa6d80-a75f-11eb-870f-2527ab50758b.png)\r\n\r\n**Execution**\r\n \r\nI have checked the compatibility of the versions and followed exactly the installation process.\r\n\r\nI can verify my CUDA installation from my cmd prompt using `nvcc --version`. \r\n![image](https://user-images.githubusercontent.com/9957900/116233269-60a1a180-a75b-11eb-99af-f24ab6733244.png)\r\n\r\nI have added the paths in my environment variable:\r\n![image](https://user-images.githubusercontent.com/9957900/116233360-7911bc00-a75b-11eb-98eb-3b5f622af955.png)\r\n\r\nI have rebooted before running the notebook and found no GPU running.", "comments": ["@epiedadjr  Could you please check whether are you facing the same issue outside the conda environment and let us know. Thanks!", "I have solved the problem. When I installed tensorflow-gpu, it also installed tensorflow non-GPU. My conda env uses non-GPU by default so I uninstalled tf and re-install with tf-gpu alone.\r\n\r\nThanks.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48777\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48777\">No</a>\n", "@epiedadjr  Good to hear that the issue is resolved and that's the reason I asked you to check outside conda environment.Thanks!"]}, {"number": 48776, "title": "[cherry-pick r2.5] Fix 'Illegal ambiguous match' on Windows with `--config=nogcp/noaws`.", "body": "Original PR: #48525", "comments": ["@mihaimaruseac would it be possible to get this into the 2.5 release?"]}, {"number": 48774, "title": "[RNN] Completely wrong predictions after dynamic range quantization", "body": "Hi everyone,  I'm using dynamic range quantization ([integer with float fallback](https://www.tensorflow.org/lite/performance/post_training_quantization#integer_with_float_fallback_using_default_float_inputoutput)) with a representative dataset, trying to resolved the prediction performance problem I highlighted in #48487.\r\nUnfortunately the predictions I get from the model are wrong and don't correspond at all to the ones the non-quantized model outputs. The class probabilities are often all zeros, a part from one very close to 1. You can see an example of the output here:\r\n```\r\ntf.Tensor(\r\n[[0.         0.         0.         0.         0.         0.\r\n  0.         0.         0.         0.         0.         0.\r\n  0.         0.         0.         0.         0.         0.\r\n  0.         0.         0.         0.         0.         0.\r\n  0.         0.         0.         0.         0.         0.\r\n  0.         0.         0.99609375 0.         0.         0.\r\n  0.         0.         0.        ]], shape=(1, 39), dtype=float32)\r\n```\r\n\r\n\r\nIn order to make the conversion work, I have to set `unroll=True` when instantiating the model, while I have `unroll=False` during training. If I don't set `unroll=True`, then I get `Failed to parse the model: pybind11::init(): factory function returned nullptr.` (_Originally posted by @wenjielu123 in https://github.com/tensorflow/tensorflow/issues/39392#issuecomment-791634847_)\r\n\r\nI'm handling the states myself, re-inputting the previous state in the next step.\r\n\r\nI tried many different combinations of the possible flags, as explained in https://www.tensorflow.org/lite/performance/post_training_quantization . They all output strange predictions, with the full integer quantization outputting all zeros, but a couple of classes with the same values, for example 26.\r\n\r\nAm I doing something wrong in the conversion? Why are the probabilities outputted by the model so off from the ones of the non-quantized model?\r\n\r\nThanks a lot for the help!\r\nLuca\r\n\r\n### 1. System information\r\n\r\nOS Platform and Distribution: Linux Ubuntu 20.04\r\nTensorFlow installation: pip package\r\nTensorFlow library: tf-nightly==2.6.0.dev20210407\r\n\r\n### 2. Code\r\n\r\nConversion code:\r\n```\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model) \r\nconverter.experimental_new_converter = True \r\nconverter.experimental_new_quantizer = True \r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT] \r\nconverter.representative_dataset = representative_dataset_generator \r\n# or also adding all the combinations of the following:\r\n# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8] \r\n# converter.inference_input_type = tf.uint8 \r\n# converter.inference_output_type = tf.uint8\r\nconverter.convert() \r\n```\r\n\r\nModel code:\r\n```\r\ndef _build_test_graph(self, with_tf_lite_ready_setup=False):\r\n        # Inputs\r\n        if with_tf_lite_ready_setup:\r\n            # Set the batch size of 1 when using TFLite, or it will result in a much bigger checkpoint that still only works with batch size 1\r\n            batch_size = 1\r\n            inputs = Input(shape=(1), batch_size=batch_size)\r\n        else:\r\n            batch_size = None\r\n            inputs = Input(shape=(None,))\r\n\r\n        # Input state\r\n        h_0 = [Input(shape=[self.state_dim], batch_size=batch_size)]\r\n\r\n        self.rnn_layer = tensorflow.keras.layers.GRU(self.state_dim, return_state=True, unroll=True)\r\n        # unroll is set to false during training for simplicity, but to true during conversion, because otherwise\r\n        # the conversion fails\r\n        rnn_inputs = tf.one_hot(tf.cast(inputs, tf.int32), depth=self.vocab_size)\r\n\r\n        embedder = Embedding(self.vocab_size, self.emb_dim, mask_zero=True)\r\n        m = embedder.compute_mask(inputs) # the token 0 is the padding token\r\n        # Apply RNN\r\n        out = self.rnn_layer(rnn_inputs, initial_state=h_0, mask=m)\r\n\r\n        rnn_out = out[0]\r\n        h_out = out[1:]\r\n\r\n        dense = Dense(self.vocab_size, activation=\"softmax\")\r\n        output = dense(rnn_out)\r\n\r\n        return keras.Model([inputs] + h_0, [output] + h_out)\r\n```", "comments": ["@jianlijianli could you triage this issue?", "Hi lucacampanella, thanks for creating the issue.\r\n\r\nSome background: tensorflow lite offers several quantization schemes, including dynamic range quantization (only weights are quantized, activation is left float in the model and quantized on the fly during inference) and full integer quantization (both weights and activations are quantized; activation can only be quantized by running some calibration data through the \"representative_dataset\" API). Fully integer quantization is triggered by the \"representative_dataset = ...\" API. It's supposed to be less or equal accurate than dynamic range quantization but it gives better speed and can offload to DSPs.\r\n\r\nIn the current thread, you are using the full integer quantization by providing the representative_dataset. The flags you are using are reasonable and the full integer qunatization for GRU should be unfused. https://github.com/tensorflow/tensorflow/issues/48487 uses dynamic range quantization, which is supposed to have better (or equal) accuracy. If accuracy is the main concern, I think full integer quantization might not be the most sensible direction.\r\n\r\nThat being said, we need to figure out the issue in this thread. @liufengdb, can you please help take a look since this is on the new quantizer? Thanks.\r\n", "Hi @jianlijianli and thanks a lot for the answer, very useful. \r\n\r\nI had the intuition that using full integer quantization would yield worse accuracy than the dynamic range, as you are saying. I tried going down this road mostly to use the flag EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8, because in #48487 it was suggested that one difference with CoreML was the handling of activations. \r\n\r\nBut if I understood correctly what you're saying, EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8 will also not help accuracy compared to the dynamic range, because in the best case the activations will be the same as the ones quantized on the fly by the dynamic range.\r\n\r\n So I guess this means there is no way to retain an accuracy similar to CoreML int8 with TFLite dynamic range because CoreML computes stuff in 16 bits and TFLite in 8 bits. Am I correct in this assumption?\r\n\r\nAnyway, it could be nice to solve this conversion issue, let me know if you need any more details.\r\n\r\nThanks again!", "Hi lucacampanella,\r\n\r\nThanks for the discussion and sharing more details about your use case.\r\n\r\nDidn't realized you are using EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8. With this extra flag, combined with \"representative_dataset\", the system performs a full integer quantization that has int8 weight and int16 activation (different from the int8 activation when EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8 is not set).\r\n\r\nIn theory, the accuracy of int16xint8 quantization sits in between int8xint8 (\"int8 full integer quantization\") and float32xint8 (\"dynamic range quantization\") and we will need to measure the accuracy to actually decide. (It could be possible int16xint8 is better than float32xint8)\r\n\r\nOne parameter for full integer quantization accuracy is the calibration dataset. If the representative_dataset is too small, it's not capturing all the essential min/max ranges so when a real data comes in, there will be clamping errors. On the other hand, if the representative_dataset is too large, it might captured some outlier (\"outlier\" is hard to quantify...) so the min/max range is unnecessarily large, which leads to wast of quantization space. I think we can try feed in more and less data to verify the accuracy.\r\n\r\nAnother possible approach is to use the [float16 quantization](https://www.tensorflow.org/lite/performance/post_training_float16_quant). Its accuracy should be close to float. It compress the model size by a factor of 2 but speed up is only observed in GPU.", "Hi jianlijianli,\r\nThanks a lot for the answer, makes it even clearer.\r\n\r\nI tried different sizes for the representative dataset and none seems to be helping. The problem also presents itself in all the inputs, which maybe points to the fact that something is really off in the calibration.\r\n\r\nCould the problem be that we consider the states as input? In order to keep the RNN \"stateless\" , we keep track of the states ourselves and fill the previous state as input to the next step to the model (as you can see from the code). In the representative dataset the state consists of floats, but when doing inference on the integer quantized model, the state will be of integers and may diverge amply from the states in the representative dataset?\r\n\r\nRegarding float16, it works very well for us and maintains the same accuracy as the unquantized model. We're trying to reduce the size of the checkpoints of the model even further because we have one language model for every language supported by the app that needs to fit on the device :)\r\n\r\nThanks again!", "Hi lucacampanella, thanks for the update. \r\n\r\nThere should be no difference between running regular inference and running calibration and the state during calibration should be handled the same way as running a regular float tflite inference. If the model is converted correctly, the state should be converted as well to integer with proper scale and zero points and for calibration we don't need to worry about integer yet.\r\n\r\nWith all this, I'm guessing that dynamic range quantization and float16 quantization are still the best option for better accuracy :)", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48774\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48774\">No</a>\n"]}, {"number": 48771, "title": "Fatal Signal 11 (SIGSEGV) Error ", "body": "I am trying to implement Tensor flow lite in my application. The code is attached below:\r\n\r\n    package com.example.se;\r\n\r\nimport android.content.Context;\r\nimport android.content.Intent;\r\nimport android.content.res.AssetFileDescriptor;\r\nimport android.content.res.AssetManager;\r\nimport android.database.Cursor;\r\nimport android.net.Uri;\r\nimport android.os.Bundle;\r\nimport android.os.FileUtils;\r\nimport android.util.Log;\r\nimport android.view.LayoutInflater;\r\nimport android.view.View;\r\nimport android.view.ViewGroup;\r\nimport android.widget.Button;\r\nimport android.widget.Toast;\r\n\r\nimport androidx.annotation.NonNull;\r\nimport androidx.annotation.Nullable;\r\nimport androidx.fragment.app.Fragment;\r\n\r\nimport org.tensorflow.lite.Interpreter;\r\n\r\nimport java.io.BufferedInputStream;\r\nimport java.io.BufferedReader;\r\nimport java.io.ByteArrayOutputStream;\r\nimport java.io.File;\r\nimport java.io.FileInputStream;\r\nimport java.io.IOException;\r\nimport java.io.InputStream;\r\nimport java.io.InputStreamReader;\r\nimport java.net.URISyntaxException;\r\nimport java.nio.MappedByteBuffer;\r\nimport java.nio.channels.FileChannel;\r\nimport java.util.ArrayList;\r\nimport java.util.HashMap;\r\nimport java.util.List;\r\nimport java.util.Map;\r\n\r\npublic class Classify extends Fragment {\r\n    private Button choose_file_button;\r\n    private Button stop_classify;\r\n    public static final int PICKFILE_RESULT_CODE = 1;\r\n    private Uri fileUri;\r\n    private String filePath; // This is the final file path\r\n    View classify_view;\r\n\r\n    // To load from asset folder\r\n    private static final String LABEL_FILENAME = \"file:///android_asset/labels.txt\";\r\n    private static final String MODEL_FILENAME = \"file:///android_asset/soundclassifier.tflite\";\r\n    private static final String LOG_TAG = \"Log tagges is here\";\r\n\r\n    // For label and modelfile\r\n    private List<String> labels = new ArrayList<String>();\r\n    private List<String> displayedLabels = new ArrayList<>();\r\n\r\n    // For the audio file\r\n    ByteArrayOutputStream out = new ByteArrayOutputStream();\r\n    BufferedInputStream in;\r\n    byte[] audioBytes;\r\n\r\n    // For machine learning\r\n    private final Interpreter.Options tfliteOptions = new Interpreter.Options();\r\n    private MappedByteBuffer tfLiteModel;\r\n    private Interpreter tfLite;\r\n    private Map<Object,Object> outputMap = new HashMap<>();\r\n    private final Interpreter.Options ftliteOptions = new Interpreter.Options();\r\n    private RecognizeCommands recognizeCommands = null;\r\n    // ToDo : Remove this if not needed\r\n\r\n    @Nullable\r\n    @Override\r\n    public View onCreateView(@NonNull LayoutInflater inflater, @Nullable ViewGroup container, @Nullable Bundle savedInstanceState) {\r\n        classify_view = inflater.inflate(R.layout.classify,container,false);\r\n\r\n        // Both finds the classify and stop classify button\r\n        choose_file_button = (Button) classify_view.findViewById(R.id.classify_button);\r\n        stop_classify = (Button) classify_view.findViewById(R.id.stop_classify);\r\n\r\n        // For labels file\r\n        String actualLabelFilename = LABEL_FILENAME.split(\"file:///android_asset/\",-1)[1];\r\n        Log.i(LOG_TAG,\"Reading labels from \" + actualLabelFilename);\r\n\r\n        BufferedReader br = null;\r\n        try{\r\n            br = new BufferedReader(new InputStreamReader(classify_view.getContext().getAssets().open(actualLabelFilename)));\r\n            String line;\r\n            while ((line = br.readLine()) != null){\r\n                labels.add(line);\r\n                if (line.charAt(0) != '_'){\r\n                    displayedLabels.add(line.substring(0,1).toUpperCase()+ line.substring(1));\r\n                }\r\n            }\r\n        } catch (IOException e){\r\n            throw new RuntimeException(\"Problem reading the label file!\",e);\r\n        }\r\n\r\n        Log.i(LOG_TAG,\"Labels file messages are :\"+ displayedLabels);\r\n\r\n        // ToDo : Implement Recognize Commands if not working\r\n\r\n        // Opening the model file\r\n        String actualModelFilename = MODEL_FILENAME.split(\"file:///android_asset/\",-1)[1];\r\n        try{\r\n            tfLiteModel = loadModelFile(classify_view.getContext().getAssets(), actualModelFilename);\r\n        } catch (Exception e){\r\n            throw new RuntimeException(e);\r\n        }\r\n\r\n        Log.i(LOG_TAG,\"The modal file is :\"+actualModelFilename);\r\n        Log.i(LOG_TAG,\"The actual content is :\"+tfLiteModel);\r\n\r\n        // ToDo : Model file opened here\r\n        try{\r\n            ftliteOptions.setNumThreads(1);\r\n            tfLite = new Interpreter(tfLiteModel,ftliteOptions);\r\n        } catch (Exception e){\r\n            throw new RuntimeException(e);\r\n        }\r\n        Log.i(LOG_TAG,\"TF lite file loaded. \");\r\n\r\n        choose_file_button.setOnClickListener(new View.OnClickListener() {\r\n            @Override\r\n            public void onClick(View v) {\r\n                Intent chooseFile = new Intent(Intent.ACTION_GET_CONTENT);\r\n                chooseFile.setType(\"*/*\");\r\n                chooseFile = Intent.createChooser(chooseFile, \"Choose a file\");\r\n                startActivityForResult(chooseFile, PICKFILE_RESULT_CODE);\r\n                // At this point we have the path of the file\r\n                // File path working.\r\n                /*\r\n                    For pie chart we can have : https://github.com/PhilJay/MPAndroidChart\r\n                 * */\r\n            }\r\n        });\r\n        return classify_view;\r\n    }\r\n    // This gets the file path\r\n    @Override\r\n    public void onActivityResult(int requestCode, int resultCode, Intent data) {\r\n        switch (requestCode) {\r\n            case PICKFILE_RESULT_CODE:\r\n                if (resultCode == -1) {\r\n                    fileUri = data.getData();\r\n                    filePath = fileUri.getPath();\r\n                    System.out.println(\"The selected file path is :\"+filePath);\r\n                    open_audio_file(fileUri);\r\n                    // Opens main audio file\r\n                    try{\r\n                        outputMap.put(0,\"outputScores\");\r\n                        // Todo : Remove another loadModelFile @Depreciated\r\n                        tfLite.run(audioBytes,outputMap);\r\n                        Log.i(LOG_TAG,\"The output is :\"+ outputMap);\r\n                    }catch(Exception e){\r\n                        throw new RuntimeException(e);\r\n                    }\r\n                }\r\n                break;\r\n        }\r\n    }\r\n\r\n    public void open_audio_file(Uri filePath){\r\n        try{\r\n            in = new BufferedInputStream(getContext().getContentResolver().openInputStream(filePath));\r\n            int read;\r\n            byte[] buff = new byte[1024];\r\n            while ((read = in.read(buff)) > 0)\r\n            {\r\n                out.write(buff, 0, read);\r\n            }\r\n            out.flush();\r\n        }catch(Exception e){\r\n            throw new RuntimeException(e);\r\n        }\r\n        audioBytes = out.toByteArray();\r\n        Log.i(LOG_TAG,\"The audio file is \" + audioBytes.toString());\r\n    }\r\n\r\n    // This method loads the TF lite file\r\n    private static MappedByteBuffer loadModelFile(AssetManager assets, String modelFileName)\r\n            throws IOException{\r\n        AssetFileDescriptor fileDescriptor = assets.openFd(modelFileName);\r\n        FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor());\r\n        FileChannel fileChannel = inputStream.getChannel();\r\n        long startOffset = fileDescriptor.getStartOffset();\r\n        long declaredLength = fileDescriptor.getDeclaredLength();\r\n        return fileChannel.map(FileChannel.MapMode.READ_ONLY,startOffset,declaredLength);\r\n    }\r\n\r\n}\r\n      \r\nThe tflite application was created using the teachable machine. Currently, in the application, I have tried to use a depreciated version of the Interpreter constructor. However, there was no success. Therefore, I defined options and rendered the application, however, I constantly get the same error. Attached below:\r\n\r\n04/27 00:44:57: Launching 'app' on Pixel 3a API 30.\r\nInstall successfully finished in 13 s 670 ms.\r\n$ adb shell am start -n \"com.example.se/com.example.se.Login_page\" -a android.intent.action.MAIN -c android.intent.category.LAUNCHER\r\nConnected to process 12447 on device 'emulator-5554'.\r\nCapturing and displaying logcat messages from application. This behavior can be disabled in the \"Logcat output\" section of the \"Debugger\" settings page.\r\nD/NetworkSecurityConfig: No Network Security Config specified, using platform default\r\nD/NetworkSecurityConfig: No Network Security Config specified, using platform default\r\nW/ComponentDiscovery: Class com.google.firebase.dynamicloading.DynamicLoadingRegistrar is not an found.\r\nI/FirebaseApp: Device unlocked: initializing all Firebase APIs for app [DEFAULT]\r\nI/FirebaseInitProvider: FirebaseApp initialization successful\r\nD/libEGL: loaded /vendor/lib/egl/libEGL_emulation.so\r\nD/libEGL: loaded /vendor/lib/egl/libGLESv1_CM_emulation.so\r\nD/libEGL: loaded /vendor/lib/egl/libGLESv2_emulation.so\r\nI/FirebaseAuth: [FirebaseAuth:] Preparing to create service connection to fallback implementation\r\nW/com.example.se: Accessing hidden method Landroid/view/View;->computeFitSystemWindows(Landroid/graphics/Rect;Landroid/graphics/Rect;)Z (greylist, reflection, allowed)\r\nW/com.example.se: Accessing hidden method Landroid/view/ViewGroup;->makeOptionalFitsSystemWindows()V (greylist, reflection, allowed)\r\nD/FirebaseAuth: Notifying id token listeners about a sign-out event.\r\nD/FirebaseAuth: Notifying auth state listeners about a sign-out event.\r\nD/HostConnection: HostConnection::get() New Host Connection established 0xf542d1f0, tid 12502\r\nD/HostConnection: HostComposition ext ANDROID_EMU_CHECKSUM_HELPER_v1 ANDROID_EMU_native_sync_v2 ANDROID_EMU_native_sync_v3 ANDROID_EMU_native_sync_v4 ANDROID_EMU_dma_v1 ANDROID_EMU_direct_mem ANDROID_EMU_host_composition_v1 ANDROID_EMU_host_composition_v2 ANDROID_EMU_YUV_Cache ANDROID_EMU_async_unmap_buffer GL_OES_EGL_image_external_essl3 GL_OES_vertex_array_object GL_KHR_texture_compression_astc_ldr ANDROID_EMU_host_side_tracing ANDROID_EMU_async_frame_commands ANDROID_EMU_gles_max_version_3_0 \r\nW/OpenGLRenderer: Failed to choose config with EGL_SWAP_BEHAVIOR_PRESERVED, retrying without...\r\nD/EGL_emulation: eglCreateContext: 0xf542c9a0: maj 3 min 0 rcv 3\r\nD/EGL_emulation: eglMakeCurrent: 0xf542c9a0: ver 3 0 (tinfo 0xf57788d0) (first time)\r\nI/Gralloc4: mapper 4.x is not supported\r\nD/HostConnection: createUnique: call\r\nD/HostConnection: HostConnection::get() New Host Connection established 0xf542dd50, tid 12502\r\nD/goldfish-address-space: allocate: Ask for block of size 0x100\r\nD/goldfish-address-space: allocate: ioctl allocate returned offset 0x3fbdbc000 size 0x2000\r\nD/HostConnection: HostComposition ext ANDROID_EMU_CHECKSUM_HELPER_v1 ANDROID_EMU_native_sync_v2 ANDROID_EMU_native_sync_v3 ANDROID_EMU_native_sync_v4 ANDROID_EMU_dma_v1 ANDROID_EMU_direct_mem ANDROID_EMU_host_composition_v1 ANDROID_EMU_host_composition_v2 ANDROID_EMU_YUV_Cache ANDROID_EMU_async_unmap_buffer GL_OES_EGL_image_external_essl3 GL_OES_vertex_array_object GL_KHR_texture_compression_astc_ldr ANDROID_EMU_host_side_tracing ANDROID_EMU_async_frame_commands ANDROID_EMU_gles_max_version_3_0 \r\nI/com.example.se: Background young concurrent copying GC freed 30675(2242KB) AllocSpace objects, 8(224KB) LOS objects, 90% free, 2531KB/26MB, paused 2.806ms total 524.254ms\r\nI/OpenGLRenderer: Davey! duration=1175ms; Flags=1, IntendedVsync=73082886249371, Vsync=73082886249371, OldestInputEvent=9223372036854775807, NewestInputEvent=0, HandleInputStart=73082894115840, AnimationStart=73082894159840, PerformTraversalsStart=73082894249840, DrawStart=73083121417840, SyncQueued=73083147195840, SyncStart=73083154696840, IssueDrawCommandsStart=73083154893840, SwapBuffers=73084012695840, FrameCompleted=73084068849840, DequeueBufferDuration=570000, QueueBufferDuration=3404000, GpuCompleted=72904454231491230, \r\nW/com.example.se: Verification of java.lang.String com.google.android.gms.common.ConnectionResult.getErrorMessage() took 198.255ms (15.13 bytecodes/s) (800B approximate peak alloc)\r\nW/com.example.se: Verification of android.app.PendingIntent com.google.android.gms.common.ConnectionResult.getResolution() took 144.927ms (20.70 bytecodes/s) (808B approximate peak alloc)\r\nI/Choreographer: Skipped 97 frames!  The application may be doing too much work on its main thread.\r\nW/com.example.se: Verification of void com.google.android.gms.common.api.internal.zabo.run() took 101.075ms (999.26 bytecodes/s) (2312B approximate peak alloc)\r\nI/AssistStructure: Flattened final assist data: 1548 bytes, containing 1 windows, 8 views\r\nW/System: Ignoring header X-Firebase-Locale because its value was null.\r\nW/System: Ignoring header X-Firebase-Locale because its value was null.\r\nD/FirebaseAuth: Notifying id token listeners about user ( VJoKjTuIjuWGm96BBpRROS6SKFX2 ).\r\nD/FirebaseAuth: Notifying auth state listeners about user ( VJoKjTuIjuWGm96BBpRROS6SKFX2 ).\r\nD/CompatibilityChangeReporter: Compat change id reported: 147798919; UID 10154; state: ENABLED\r\nI/Log tagges is here: Reading labels from labels.txt\r\nI/Log tagges is here: Labels file messages are :[0 Background Noise, 1 Cow, 2 Dog, 3 Hen, 4 Sheep]\r\nI/Log tagges is here: The modal file is :soundclassifier.tflite\r\n    The actual content is :java.nio.DirectByteBuffer[pos=0 lim=5780044 cap=5780044]\r\nI/tflite: Initialized TensorFlow Lite runtime.\r\nW/native: cpu_feature_guard.cc:36 The TensorFlow library was compiled to use SSE instructions, but these aren't available on your machine.\r\nA/libc: Fatal signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0xfffffff4 in tid 12447 (com.example.se), pid 12447 (com.example.se)\r\nWhat would be the best method to resolve this error?\r\n\r\nThe Gradle file is :\r\n\r\nplugins {\r\n    id 'com.android.application'\r\n    id 'com.google.gms.google-services'\r\n}\r\n\r\nandroid {\r\n    compileSdkVersion 30\r\n    buildToolsVersion \"30.0.3\"\r\n\r\n    defaultConfig {\r\n        applicationId \"com.example.se\"\r\n        minSdkVersion 25\r\n        targetSdkVersion 30\r\n        versionCode 1\r\n        versionName \"1.0\"\r\n\r\n        testInstrumentationRunner \"androidx.test.runner.AndroidJUnitRunner\"\r\n    }\r\n\r\n    buildTypes {\r\n        release {\r\n            minifyEnabled false\r\n            proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard-rules.pro'\r\n        }\r\n    }\r\n    compileOptions {\r\n        sourceCompatibility JavaVersion.VERSION_1_8\r\n        targetCompatibility JavaVersion.VERSION_1_8\r\n    }\r\n}\r\n\r\ndependencies {\r\n    implementation 'androidx.appcompat:appcompat:1.2.0'\r\n    implementation 'com.google.android.material:material:1.3.0'\r\n    implementation 'androidx.constraintlayout:constraintlayout:2.0.4'\r\n    implementation 'com.google.firebase:firebase-auth:20.0.3'\r\n    implementation 'com.google.firebase:firebase-database:19.7.0'\r\n    implementation \"org.tensorflow:tensorflow-lite:2.3.0\"\r\n    implementation \"org.tensorflow:tensorflow-lite-gpu:2.3.0\"\r\n    implementation \"org.tensorflow:tensorflow-lite-select-tf-ops:2.3.0\"\r\n    implementation \"org.tensorflow:tensorflow-lite-support:0.1.0-rc1\"\r\n    implementation \"org.tensorflow:tensorflow-lite-metadata:0.1.0-rc2\"\r\n    implementation 'androidx.lifecycle:lifecycle-livedata-ktx:2.2.0'\r\n    implementation 'androidx.lifecycle:lifecycle-viewmodel-ktx:2.2.0'\r\n    testImplementation 'junit:junit:4.+'\r\n    androidTestImplementation 'androidx.test.ext:junit:1.1.2'\r\n    androidTestImplementation 'androidx.test.espresso:espresso-core:3.3.0'\r\n}", "comments": ["See https://github.com/tensorflow/tensorflow/issues/48697#issuecomment-826589092.", "We know that TF 2.3 version has an issue with the SSE instructions. You need to upgrade your TF version to resolve the above error.", "@abattery Thank you updating the TF version did work. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48771\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48771\">No</a>\n"]}, {"number": 48770, "title": "Error with SIGSEGV while building for teachable machine output ", "body": "I am trying to implement Tensor flow lite in my application. The code is attached below: \r\n```\r\n    package com.example.se;\r\n\r\nimport android.content.Context;\r\nimport android.content.Intent;\r\nimport android.content.res.AssetFileDescriptor;\r\nimport android.content.res.AssetManager;\r\nimport android.database.Cursor;\r\nimport android.net.Uri;\r\nimport android.os.Bundle;\r\nimport android.os.FileUtils;\r\nimport android.util.Log;\r\nimport android.view.LayoutInflater;\r\nimport android.view.View;\r\nimport android.view.ViewGroup;\r\nimport android.widget.Button;\r\nimport android.widget.Toast;\r\n\r\nimport androidx.annotation.NonNull;\r\nimport androidx.annotation.Nullable;\r\nimport androidx.fragment.app.Fragment;\r\n\r\nimport org.tensorflow.lite.Interpreter;\r\n\r\nimport java.io.BufferedInputStream;\r\nimport java.io.BufferedReader;\r\nimport java.io.ByteArrayOutputStream;\r\nimport java.io.File;\r\nimport java.io.FileInputStream;\r\nimport java.io.IOException;\r\nimport java.io.InputStream;\r\nimport java.io.InputStreamReader;\r\nimport java.net.URISyntaxException;\r\nimport java.nio.MappedByteBuffer;\r\nimport java.nio.channels.FileChannel;\r\nimport java.util.ArrayList;\r\nimport java.util.HashMap;\r\nimport java.util.List;\r\nimport java.util.Map;\r\n\r\npublic class Classify extends Fragment {\r\n    private Button choose_file_button;\r\n    private Button stop_classify;\r\n    public static final int PICKFILE_RESULT_CODE = 1;\r\n    private Uri fileUri;\r\n    private String filePath; // This is the final file path\r\n    View classify_view;\r\n\r\n    // To load from asset folder\r\n    private static final String LABEL_FILENAME = \"file:///android_asset/labels.txt\";\r\n    private static final String MODEL_FILENAME = \"file:///android_asset/soundclassifier.tflite\";\r\n    private static final String LOG_TAG = \"Log tagges is here\";\r\n\r\n    // For label and modelfile\r\n    private List<String> labels = new ArrayList<String>();\r\n    private List<String> displayedLabels = new ArrayList<>();\r\n\r\n    // For the audio file\r\n    ByteArrayOutputStream out = new ByteArrayOutputStream();\r\n    BufferedInputStream in;\r\n    byte[] audioBytes;\r\n\r\n    // For machine learning\r\n    private final Interpreter.Options tfliteOptions = new Interpreter.Options();\r\n    private MappedByteBuffer tfLiteModel;\r\n    private Interpreter tfLite;\r\n    private Map<Object,Object> outputMap = new HashMap<>();\r\n    private final Interpreter.Options ftliteOptions = new Interpreter.Options();\r\n    private RecognizeCommands recognizeCommands = null;\r\n    // ToDo : Remove this if not needed\r\n\r\n    @Nullable\r\n    @Override\r\n    public View onCreateView(@NonNull LayoutInflater inflater, @Nullable ViewGroup container, @Nullable Bundle savedInstanceState) {\r\n        classify_view = inflater.inflate(R.layout.classify,container,false);\r\n\r\n        // Both finds the classify and stop classify button\r\n        choose_file_button = (Button) classify_view.findViewById(R.id.classify_button);\r\n        stop_classify = (Button) classify_view.findViewById(R.id.stop_classify);\r\n\r\n        // For labels file\r\n        String actualLabelFilename = LABEL_FILENAME.split(\"file:///android_asset/\",-1)[1];\r\n        Log.i(LOG_TAG,\"Reading labels from \" + actualLabelFilename);\r\n\r\n        BufferedReader br = null;\r\n        try{\r\n            br = new BufferedReader(new InputStreamReader(classify_view.getContext().getAssets().open(actualLabelFilename)));\r\n            String line;\r\n            while ((line = br.readLine()) != null){\r\n                labels.add(line);\r\n                if (line.charAt(0) != '_'){\r\n                    displayedLabels.add(line.substring(0,1).toUpperCase()+ line.substring(1));\r\n                }\r\n            }\r\n        } catch (IOException e){\r\n            throw new RuntimeException(\"Problem reading the label file!\",e);\r\n        }\r\n\r\n        Log.i(LOG_TAG,\"Labels file messages are :\"+ displayedLabels);\r\n\r\n        // ToDo : Implement Recognize Commands if not working\r\n\r\n        // Opening the model file\r\n        String actualModelFilename = MODEL_FILENAME.split(\"file:///android_asset/\",-1)[1];\r\n        try{\r\n            tfLiteModel = loadModelFile(classify_view.getContext().getAssets(), actualModelFilename);\r\n        } catch (Exception e){\r\n            throw new RuntimeException(e);\r\n        }\r\n\r\n        Log.i(LOG_TAG,\"The modal file is :\"+actualModelFilename);\r\n        Log.i(LOG_TAG,\"The actual content is :\"+tfLiteModel);\r\n\r\n        // ToDo : Model file opened here\r\n        try{\r\n            ftliteOptions.setNumThreads(1);\r\n            tfLite = new Interpreter(tfLiteModel,ftliteOptions);\r\n        } catch (Exception e){\r\n            throw new RuntimeException(e);\r\n        }\r\n        Log.i(LOG_TAG,\"TF lite file loaded. \");\r\n\r\n        choose_file_button.setOnClickListener(new View.OnClickListener() {\r\n            @Override\r\n            public void onClick(View v) {\r\n                Intent chooseFile = new Intent(Intent.ACTION_GET_CONTENT);\r\n                chooseFile.setType(\"*/*\");\r\n                chooseFile = Intent.createChooser(chooseFile, \"Choose a file\");\r\n                startActivityForResult(chooseFile, PICKFILE_RESULT_CODE);\r\n                // At this point we have the path of the file\r\n                // File path working.\r\n                /*\r\n                    For pie chart we can have : https://github.com/PhilJay/MPAndroidChart\r\n                 * */\r\n            }\r\n        });\r\n        return classify_view;\r\n    }\r\n    // This gets the file path\r\n    @Override\r\n    public void onActivityResult(int requestCode, int resultCode, Intent data) {\r\n        switch (requestCode) {\r\n            case PICKFILE_RESULT_CODE:\r\n                if (resultCode == -1) {\r\n                    fileUri = data.getData();\r\n                    filePath = fileUri.getPath();\r\n                    System.out.println(\"The selected file path is :\"+filePath);\r\n                    open_audio_file(fileUri);\r\n                    // Opens main audio file\r\n                    try{\r\n                        outputMap.put(0,\"outputScores\");\r\n                        // Todo : Remove another loadModelFile @Depreciated\r\n                        tfLite.run(audioBytes,outputMap);\r\n                        Log.i(LOG_TAG,\"The output is :\"+ outputMap);\r\n                    }catch(Exception e){\r\n                        throw new RuntimeException(e);\r\n                    }\r\n                }\r\n                break;\r\n        }\r\n    }\r\n\r\n    public void open_audio_file(Uri filePath){\r\n        try{\r\n            in = new BufferedInputStream(getContext().getContentResolver().openInputStream(filePath));\r\n            int read;\r\n            byte[] buff = new byte[1024];\r\n            while ((read = in.read(buff)) > 0)\r\n            {\r\n                out.write(buff, 0, read);\r\n            }\r\n            out.flush();\r\n        }catch(Exception e){\r\n            throw new RuntimeException(e);\r\n        }\r\n        audioBytes = out.toByteArray();\r\n        Log.i(LOG_TAG,\"The audio file is \" + audioBytes.toString());\r\n    }\r\n\r\n    // This method loads the TF lite file\r\n    private static MappedByteBuffer loadModelFile(AssetManager assets, String modelFileName)\r\n            throws IOException{\r\n        AssetFileDescriptor fileDescriptor = assets.openFd(modelFileName);\r\n        FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor());\r\n        FileChannel fileChannel = inputStream.getChannel();\r\n        long startOffset = fileDescriptor.getStartOffset();\r\n        long declaredLength = fileDescriptor.getDeclaredLength();\r\n        return fileChannel.map(FileChannel.MapMode.READ_ONLY,startOffset,declaredLength);\r\n    }\r\n\r\n}\r\n      \r\n```\r\n\r\nThe tflite application was created using the teachable machine. Currently, in the application, I have tried to use a depreciated version of the Interpreter constructor. However, there was no success.\u00a0Therefore, I defined options and rendered the application, however, I constantly get the same error. Attached below: \r\n\r\n```\r\n04/27 00:44:57: Launching 'app' on Pixel 3a API 30.\r\nInstall successfully finished in 13 s 670 ms.\r\n$ adb shell am start -n \"com.example.se/com.example.se.Login_page\" -a android.intent.action.MAIN -c android.intent.category.LAUNCHER\r\nConnected to process 12447 on device 'emulator-5554'.\r\nCapturing and displaying logcat messages from application. This behavior can be disabled in the \"Logcat output\" section of the \"Debugger\" settings page.\r\nD/NetworkSecurityConfig: No Network Security Config specified, using platform default\r\nD/NetworkSecurityConfig: No Network Security Config specified, using platform default\r\nW/ComponentDiscovery: Class com.google.firebase.dynamicloading.DynamicLoadingRegistrar is not an found.\r\nI/FirebaseApp: Device unlocked: initializing all Firebase APIs for app [DEFAULT]\r\nI/FirebaseInitProvider: FirebaseApp initialization successful\r\nD/libEGL: loaded /vendor/lib/egl/libEGL_emulation.so\r\nD/libEGL: loaded /vendor/lib/egl/libGLESv1_CM_emulation.so\r\nD/libEGL: loaded /vendor/lib/egl/libGLESv2_emulation.so\r\nI/FirebaseAuth: [FirebaseAuth:] Preparing to create service connection to fallback implementation\r\nW/com.example.se: Accessing hidden method Landroid/view/View;->computeFitSystemWindows(Landroid/graphics/Rect;Landroid/graphics/Rect;)Z (greylist, reflection, allowed)\r\nW/com.example.se: Accessing hidden method Landroid/view/ViewGroup;->makeOptionalFitsSystemWindows()V (greylist, reflection, allowed)\r\nD/FirebaseAuth: Notifying id token listeners about a sign-out event.\r\nD/FirebaseAuth: Notifying auth state listeners about a sign-out event.\r\nD/HostConnection: HostConnection::get() New Host Connection established 0xf542d1f0, tid 12502\r\nD/HostConnection: HostComposition ext ANDROID_EMU_CHECKSUM_HELPER_v1 ANDROID_EMU_native_sync_v2 ANDROID_EMU_native_sync_v3 ANDROID_EMU_native_sync_v4 ANDROID_EMU_dma_v1 ANDROID_EMU_direct_mem ANDROID_EMU_host_composition_v1 ANDROID_EMU_host_composition_v2 ANDROID_EMU_YUV_Cache ANDROID_EMU_async_unmap_buffer GL_OES_EGL_image_external_essl3 GL_OES_vertex_array_object GL_KHR_texture_compression_astc_ldr ANDROID_EMU_host_side_tracing ANDROID_EMU_async_frame_commands ANDROID_EMU_gles_max_version_3_0 \r\nW/OpenGLRenderer: Failed to choose config with EGL_SWAP_BEHAVIOR_PRESERVED, retrying without...\r\nD/EGL_emulation: eglCreateContext: 0xf542c9a0: maj 3 min 0 rcv 3\r\nD/EGL_emulation: eglMakeCurrent: 0xf542c9a0: ver 3 0 (tinfo 0xf57788d0) (first time)\r\nI/Gralloc4: mapper 4.x is not supported\r\nD/HostConnection: createUnique: call\r\nD/HostConnection: HostConnection::get() New Host Connection established 0xf542dd50, tid 12502\r\nD/goldfish-address-space: allocate: Ask for block of size 0x100\r\nD/goldfish-address-space: allocate: ioctl allocate returned offset 0x3fbdbc000 size 0x2000\r\nD/HostConnection: HostComposition ext ANDROID_EMU_CHECKSUM_HELPER_v1 ANDROID_EMU_native_sync_v2 ANDROID_EMU_native_sync_v3 ANDROID_EMU_native_sync_v4 ANDROID_EMU_dma_v1 ANDROID_EMU_direct_mem ANDROID_EMU_host_composition_v1 ANDROID_EMU_host_composition_v2 ANDROID_EMU_YUV_Cache ANDROID_EMU_async_unmap_buffer GL_OES_EGL_image_external_essl3 GL_OES_vertex_array_object GL_KHR_texture_compression_astc_ldr ANDROID_EMU_host_side_tracing ANDROID_EMU_async_frame_commands ANDROID_EMU_gles_max_version_3_0 \r\nI/com.example.se: Background young concurrent copying GC freed 30675(2242KB) AllocSpace objects, 8(224KB) LOS objects, 90% free, 2531KB/26MB, paused 2.806ms total 524.254ms\r\nI/OpenGLRenderer: Davey! duration=1175ms; Flags=1, IntendedVsync=73082886249371, Vsync=73082886249371, OldestInputEvent=9223372036854775807, NewestInputEvent=0, HandleInputStart=73082894115840, AnimationStart=73082894159840, PerformTraversalsStart=73082894249840, DrawStart=73083121417840, SyncQueued=73083147195840, SyncStart=73083154696840, IssueDrawCommandsStart=73083154893840, SwapBuffers=73084012695840, FrameCompleted=73084068849840, DequeueBufferDuration=570000, QueueBufferDuration=3404000, GpuCompleted=72904454231491230, \r\nW/com.example.se: Verification of java.lang.String com.google.android.gms.common.ConnectionResult.getErrorMessage() took 198.255ms (15.13 bytecodes/s) (800B approximate peak alloc)\r\nW/com.example.se: Verification of android.app.PendingIntent com.google.android.gms.common.ConnectionResult.getResolution() took 144.927ms (20.70 bytecodes/s) (808B approximate peak alloc)\r\nI/Choreographer: Skipped 97 frames!  The application may be doing too much work on its main thread.\r\nW/com.example.se: Verification of void com.google.android.gms.common.api.internal.zabo.run() took 101.075ms (999.26 bytecodes/s) (2312B approximate peak alloc)\r\nI/AssistStructure: Flattened final assist data: 1548 bytes, containing 1 windows, 8 views\r\nW/System: Ignoring header X-Firebase-Locale because its value was null.\r\nW/System: Ignoring header X-Firebase-Locale because its value was null.\r\nD/FirebaseAuth: Notifying id token listeners about user ( VJoKjTuIjuWGm96BBpRROS6SKFX2 ).\r\nD/FirebaseAuth: Notifying auth state listeners about user ( VJoKjTuIjuWGm96BBpRROS6SKFX2 ).\r\nD/CompatibilityChangeReporter: Compat change id reported: 147798919; UID 10154; state: ENABLED\r\nI/Log\u00a0tagges\u00a0is\u00a0here: Reading labels from labels.txt\r\nI/Log\u00a0tagges\u00a0is\u00a0here: Labels file messages are :[0 Background Noise, 1 Cow, 2 Dog, 3 Hen, 4 Sheep]\r\nI/Log\u00a0tagges\u00a0is\u00a0here: The modal file is :soundclassifier.tflite\r\n    The actual content is :java.nio.DirectByteBuffer[pos=0 lim=5780044 cap=5780044]\r\nI/tflite: Initialized TensorFlow Lite runtime.\r\nW/native: cpu_feature_guard.cc:36 The TensorFlow library was compiled to use SSE instructions, but these aren't available on your machine.\r\nA/libc: Fatal signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0xfffffff4 in tid 12447 (com.example.se), pid 12447 (com.example.se)\r\n```\r\nWhat would be the best method to resolve this error? \r\n\r\nThe Gradle file is : \r\n```\r\nplugins {\r\n    id 'com.android.application'\r\n    id 'com.google.gms.google-services'\r\n}\r\n\r\nandroid {\r\n    compileSdkVersion 30\r\n    buildToolsVersion \"30.0.3\"\r\n\r\n    defaultConfig {\r\n        applicationId \"com.example.se\"\r\n        minSdkVersion 25\r\n        targetSdkVersion 30\r\n        versionCode 1\r\n        versionName \"1.0\"\r\n\r\n        testInstrumentationRunner \"androidx.test.runner.AndroidJUnitRunner\"\r\n    }\r\n\r\n    buildTypes {\r\n        release {\r\n            minifyEnabled false\r\n            proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard-rules.pro'\r\n        }\r\n    }\r\n    compileOptions {\r\n        sourceCompatibility JavaVersion.VERSION_1_8\r\n        targetCompatibility JavaVersion.VERSION_1_8\r\n    }\r\n}\r\n\r\ndependencies {\r\n    implementation 'androidx.appcompat:appcompat:1.2.0'\r\n    implementation 'com.google.android.material:material:1.3.0'\r\n    implementation 'androidx.constraintlayout:constraintlayout:2.0.4'\r\n    implementation 'com.google.firebase:firebase-auth:20.0.3'\r\n    implementation 'com.google.firebase:firebase-database:19.7.0'\r\n    implementation \"org.tensorflow:tensorflow-lite:2.3.0\"\r\n    implementation \"org.tensorflow:tensorflow-lite-gpu:2.3.0\"\r\n    implementation \"org.tensorflow:tensorflow-lite-select-tf-ops:2.3.0\"\r\n    implementation \"org.tensorflow:tensorflow-lite-support:0.1.0-rc1\"\r\n    implementation \"org.tensorflow:tensorflow-lite-metadata:0.1.0-rc2\"\r\n    implementation 'androidx.lifecycle:lifecycle-livedata-ktx:2.2.0'\r\n    implementation 'androidx.lifecycle:lifecycle-viewmodel-ktx:2.2.0'\r\n    testImplementation 'junit:junit:4.+'\r\n    androidTestImplementation 'androidx.test.ext:junit:1.1.2'\r\n    androidTestImplementation 'androidx.test.espresso:espresso-core:3.3.0'\r\n}\r\n```", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48770\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48770\">No</a>\n"]}, {"number": 48769, "title": "Tensorflow latest GPU docker container doesn't include object detection API", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): From docker container\r\n- TensorFlow version: latest docker container\r\n- Python version: latest docker container\r\n- Installed using virtualenv? pip? conda?: from docker container\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: last docker container, looks like 11.2\r\n- GPU model and memory: Tesla P4\r\n\r\n**Describe the problem**\r\nI was under the impression (correct me if I am wrong about this) that I could use the docker container to do object detection tasks, mainly I would like to use the container to train models on my machine. However, it appears that this container does not include the Object Detection API and compiled protos that go along with it. \r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@mjbedford2017 ,\r\n\r\nIn order to expedite the trouble-shooting process, could you please provide the following information\r\nTensorFlow installed from (source or binary):\r\nTensorFlow version:\r\nPython version:\r\nInstalled using virtualenv? pip? conda?:\r\nBazel version (if compiling from source):\r\nGCC/Compiler version (if compiling from source):\r\nCUDA/cuDNN version:\r\nGPU model and memory:\r\n \r\nand the exact sequence of commands / steps that you executed before running into the problem\r\n\r\nThanks", "Hello, thank you for looking into this. Just to clarify, I am using the tensorflow docker container, which comes with software defined in the docker file. I got the docker container using \"latest GPU\" 2 days ago. Here is the docker file I believe it is using (latest GPU) https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dockerfiles/dockerfiles/gpu.Dockerfile\r\n\r\nTensorFlow installed from (source or binary): From binary.\r\nTensorFlow version: Latest release, 2.4\r\nPython version: 3.8\r\nInstalled using virtualenv? pip? conda?: Not sure, docker container?\r\nBazel version (if compiling from source): Not sure, docker container?\r\nGCC/Compiler version (if compiling from source): Not sure, docker container?\r\nCUDA/cuDNN version: Per docker file, this is 11.2 CUDA and cuDNN is 8.1.0.77-1\r\nGPU model and memory: Nvidia Tesla P4 with 8GB GPU RAM\r\n\r\nI am simply trying to use the docker container for training model. In order to do this, the \"Object Detection API\" needs to be installed. It does not seem to be included in the docker container and while I might be able to manually add it, each time an updated docker container is released, I would have to do it all over again. \r\n\r\nI would like this API in the container: https://github.com/tensorflow/models/tree/master/research/object_detection so I can do model stuff, like training. \r\n", "@mjbedford2017 ,\r\n\r\nTensorFlow v2.4 is built and tested against CUDA 11.0 and cuDNN 8. Could you please install the CUDA and cuDNN packages on your machine to compatible versions and check if you are facing same issue.For more information please take a look at the [tested build configurations.](https://www.tensorflow.org/install/source#gpu)\r\n\r\nThanks", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48769\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48769\">No</a>\n"]}, {"number": 48768, "title": "Request for an Efficient Way of handling NLP Tasks with Saving Model weights along with its tokenizer and architecture in JSON ", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.4.1\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n- In the Current Feature of TensorFlow, when we work with Natural Language Processing Based Tasks, we have the ability to only save the ```model architecture``` and ``` model weights```, that too with two different function calls. We need to mention an explicit file handling operation to save the ```tokenizer```  in JSON format too. This might lead to a bit of inefficiency.\r\n\r\n- Therefore , I would like to suggest and provide code for one single function , which would save the model weights , its architecture and the current tokenizer in JSON format ,  and along with it , a single load function to retrieve all these three files with one single function call. This will help to improve the efficiency and modular programming and ease of use of TensorFlow to save and load models with one single function call, rather than calling different function counterparts.\r\n\r\n**Will this change the current api? How?**\r\nNot to a great extent. Since these are two normal functions that will require ``` model``` as a parameter, it will save model architecture, its weights, and tokenizer.json will directly be saved from the tokenizer object created. \r\n\r\n**Who will benefit with this feature?**\r\nAll the developers who use TensorFlow for Natural Language Processing Tasks in deep learning.\r\n\r\n**Any Other info.**\r\nI already have the code snippet ready and have tested it with a couple of my models.\r\n", "comments": ["@harshgeek4coder thanks for the report! If you have a code snippet ready, could you post it as a gist or colab here and we could take a look?\r\n\r\nIs the goal to have JSON specifically? Or just a way to save a model architecture and weights. If the latter, the SavedModel format would be the way to do this today. Is there a reason that doesn't work for your use case?\r\nhttps://www.tensorflow.org/guide/keras/save_and_serialize\r\n\r\nThanks!", "Hey, @mattdangerw   Thanks for replying back. So the thing is, when we handle basic NLP Tasks, we require the tokenizer's saved state data for later use so that once we load the saved models, we need tokenizer's data to identify word indexes for each unique word in custom data for the model prediction.\r\n\r\nComing Back to your question, the main goal is to save Tokenizer's state in JSON format which will be required by the loaded model along with the model's loaded architecture state.\r\n\r\nThe Current ```SavedModel``` format can be used to save the model architecture, we also have to use```save_weights``` to save model weights explicitly and do some file handling operation to save Tokeniser's data in JSON format. But all these different functions take some time to be annotated manually.\r\nHere is the Flow of how It currently works [ NLP Operation ]:\r\n- Step 1: Save Model\r\n- Step 2: Save Model weights\r\n- Step 3: Save Tokenizer in JSON format\r\n\r\nAll of the above steps can be performed, but have to be done via three different function calls explicitly, including some manual annotation and file handling operation, which is a bit time-consuming. The same thing has to be done to load all the respective components which again takes more time to be done.\r\n\r\nKeeping this thing in mind and with the help of current TensorFlow's utility, I would like to contribute to TensorFlow's official repository and therefore would like to propose a single and simple function, which can be used with one simple call and can perform all these three tasks in one single function call. I have also written another custom function that could call all these three different components in one single call.\r\n\r\nHere is the ```Gist``` and ```Colab``` Link For your Further Reference : \r\n\r\n- https://colab.research.google.com/drive/1D1swi-aSZdTliGIYS03ZeOyuFdylUX48?usp=sharing\r\n\r\n- [Direct Link to Cell Of Colab - For ```save model''' function](https://colab.research.google.com/drive/1D1swi-aSZdTliGIYS03ZeOyuFdylUX48#scrollTo=71VEwiAjlYlM&line=1&uniqifier=1)\r\n\r\n- [Direct Link to Cell Of Colab - For ```load model''' function](https://colab.research.google.com/drive/1D1swi-aSZdTliGIYS03ZeOyuFdylUX48#scrollTo=-fOxOjLQRLxP&line=10&uniqifier=1)\r\n\r\n- [Gist File For the functions ](https://gist.github.com/harshgeek4coder/15c87917057db4937ace7b756e16b00b)\r\n\r\n\r\nThanks!", "Got it. Thanks!\r\n\r\nFor the SavedModel format, that is intended to save both the model architecture and the model weights. `model.save(some_path)` will do that.\r\n\r\nOn the tokenization front, we are actually working on new layers for tokenization (and mapping strings to indices generally), that will integrate better with a keras model:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/StringLookup\r\n\r\nTextVectorization supports different tokenization steps which you can pass in. The state of these layers will be reflected in your architecture and weights as normal.\r\n\r\nIf you use these, or write your own custom layer for tokenization, then using SavedModel directly (`model.save`) will be the simplest way to save your entire model state. You could still save the model architecture and weights separately if you want."]}]