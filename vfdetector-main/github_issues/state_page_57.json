[{"number": 39792, "title": "Failed to legalize operation 'xla_hlo.return'", "body": "I am using TensorFlow installed from source and running on Google-Cloud. My git commit id is b52f058cb7fe2aee523fb2f0ae8ba712d2339b3a .\r\n\r\nI am trying to test Reduce Op. I generated a frozen graph of .pbtxt format using a very simple program by using reduce_sum on 4*3*2 tensor. I generated graph def from it given below:\r\n\r\n```\r\nmodule attributes {tf.versions = {bad_consumers = [], min_consumer = 0 : i32, producer = 175 : i32}} {\r\n  func @main(%arg0: tensor<4x3x2xf32>) -> tensor<f32> attributes {tf.entry_function = {control_outputs = \"\", inputs = \"Placeholder\", outputs = \"Sum\"}} {\r\n    %0 = tf_executor.graph {\r\n      %outputs, %control = tf_executor.island wraps \"tf.Const\"() {device = \"\", value = dense<[0, 1, 2]> : tensor<3xi32>} : () -> tensor<3xi32>\r\n      %outputs_0, %control_1 = tf_executor.island wraps \"tf.Sum\"(%arg0, %outputs) {device = \"\", keep_dims = false} : (tensor<4x3x2xf32>, tensor<3xi32>) -> tensor<f32>\r\n      tf_executor.fetch %outputs_0 : tensor<f32>\r\n    }\r\n    return %0 : tensor<f32>\r\n  }\r\n```\r\n\r\nAbove is graphdef file. I converted it into Xla hlo using `./tf-opt --tf-executor-island-coarsening -canonicalize --xla-legalize-tf.` Which give the output as:\r\n\r\n```\r\nmodule attributes {tf.versions = {bad_consumers = [], min_consumer = 0 : i32, producer = 175 : i32}} {\r\n  func @main(%arg0: tensor<4x3x2xf32>) -> tensor<f32> attributes {tf.entry_function = {control_outputs = \"\", inputs = \"Placeholder\", outputs = \"Sum\"}} {\r\n    %0 = xla_hlo.constant dense<[0, 1, 2]> : tensor<3xi32>\r\n    %1 = tensor_cast %0 : tensor<3xi32> to tensor<3xi32>\r\n    %2 = \"xla_hlo.convert\"(%arg0) : (tensor<4x3x2xf32>) -> tensor<4x3x2xf32>\r\n    %3 = xla_hlo.constant dense<0.000000e+00> : tensor<f32>\r\n    %4 = \"xla_hlo.reduce\"(%2, %3) ( {\r\n    ^bb0(%arg1: tensor<f32>, %arg2: tensor<f32>):  // no predecessors\r\n      %6 = xla_hlo.add %arg1, %arg2 : tensor<f32>\r\n      \"xla_hlo.return\"(%6) : (tensor<f32>) -> ()\r\n    }) {dimensions = dense<[0, 1, 2]> : tensor<3xi64>} : (tensor<4x3x2xf32>, tensor<f32>) -> tensor<f32>\r\n    %5 = \"xla_hlo.convert\"(%4) : (tensor<f32>) -> tensor<f32>\r\n    return %5 : tensor<f32>\r\n  }\r\n}\r\n\r\n```\r\nNow I am trying to convert above hlo file to lhlo using command ./tf-opt  --hlo-legalize-to-lhlo\r\nBut an segmentation fault came.\r\n```\r\nb.txt:12:7: error: failed to legalize operation 'xla_hlo.return' that was explicitly marked illegal\r\n      \"xla_hlo.return\"(%6) : (tensor<f32>) -> ()\r\n      ^\r\nb.txt:12:7: note: see current operation: \"xla_hlo.return\"(%10) : (tensor<f32>) -> ()\r\nPLEASE submit a bug report to  and include the crash backtrace.\r\nStack dump:\r\n0.\tProgram arguments: ./tf-opt --hlo-legalize-to-lhlo b.txt \r\n./tf-opt[0x7fdd05d]\r\n./tf-opt[0x7fdb1ad]\r\n./tf-opt[0x7fdb6fd]\r\n/lib64/libpthread.so.0(+0x12dc0)[0x7fac3735fdc0]\r\n./tf-opt[0x7f7ba86]\r\n./tf-opt[0x7f7eb0e]\r\n./tf-opt[0x7f7deca]\r\n./tf-opt[0x7f7e3e6]\r\n./tf-opt[0x7f834b6]\r\n./tf-opt[0x7f2e932]\r\n./tf-opt[0x7f2f7ca]\r\n./tf-opt[0x7f345dd]\r\n./tf-opt[0x7d322dc]\r\n./tf-opt[0x7f1890b]\r\n./tf-opt[0x7f18c0c]\r\n./tf-opt[0x7f18c0c]\r\n./tf-opt[0x7f18c0c]\r\n./tf-opt[0x7f1995f]\r\n./tf-opt[0x7e0ebc9]\r\n./tf-opt[0x7e13c89]\r\n./tf-opt[0x7e13cfa]\r\n./tf-opt[0x7e1ae85]\r\n./tf-opt[0x5964480]\r\n./tf-opt[0x59648c5]\r\n./tf-opt[0x5964a80]\r\n./tf-opt[0x930390]\r\n/lib64/libc.so.6(__libc_start_main+0xf3)[0x7fac36d95873]\r\n./tf-opt[0xa38cce]\r\nSegmentation fault (core dumped)\r\n```\r\nThis is the whole output. \r\nSo is something still missing currently in the repo?\r\n", "comments": ["@yashjain1129 \r\nRequest you to fill [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).Provide the exact sequence of commands / steps that you executed before running into the problem.Thanks!", "Step by step description\r\n1) On Google colab run the following,\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\ntf.compat.v1.disable_eager_execution()\r\nx = tf.compat.v1.placeholder(tf.float32, shape=(4, 3, 2))\r\ny = tf.reduce_sum(x)\r\nwith tf.compat.v1.Session() as sess:\r\n    rand_array1 = np.random.rand(4, 3, 2)\r\n    (sess.run(y, feed_dict={x:rand_array1}))\r\n    tf.io.write_graph(sess.graph_def, '', 'graph1.pbtxt')\r\n```\r\n\r\nBy this we get a graph file.[https://drive.google.com/file/d/1D4XhBJIHmArOw3QJ83NX6jm1BlUnHAcj/view?usp=sharing](url)\r\n\r\nOn the above drive link you will get graph.pbtxt file.\r\n\r\n2)  `./tf-mlir-translate --graphdef-to-mlir --tf-enable-shape-inference-on-import=true --tf-input-arrays=Placeholder  --tf-input-shapes=4,3,2 --tf-output-arrays=Sum ./sample_files/graph.pbtxt  > a.txt`\r\n3) After above command, these two commands are there both will do the same work and you can try any of them\r\n`./tf-opt --tf-executor-island-coarsening -canonicalize --xla-legalize-tf  a.txt > b.txt`\r\nor\r\n` ./tf-opt --tf-executor-to-control-conversion --tf-raise-control-flow --xla-legalize-tf  a.txt > b.txt`\r\n4) After all these steps you will get the code in file b.txt as in the above issue. Now I want to convert this xla-hlo file into lhlo and then into affine. But conversion from hlo to lhlo is giving me the following error. \r\n```\r\nb.txt:12:7: error: failed to legalize operation 'xla_hlo.return' that was explicitly marked illegal\r\n\"xla_hlo.return\"(%6) : (tensor) -> ()\r\n```\r\nFull error is uploaded in the statement of issue which is above one.", "Please use proper markdown formatting around code/error blocks so this is readable.", "@mihaimaruseac my later comment is easy to follow and can be easily tested. I tried debugging from my side and found some bugs but was not able to remove completely. In my earlier commit history [https://github.com/tensorflow/tensorflow/pull/39700](url) I tried to solve. The for loop removing the argument in the ReduceOp function in hlo_legalize_to_lhlo.cc is giving segmentation fault. Also, hlo.return op need to be erased in the same function but not removed.", "What is the status of this?"]}, {"number": 39729, "title": "Is there any good detailed  description of GraphDef and Saved Model ?", "body": "\r\n## URL(s) with the issue:\r\n\r\nN/A\r\n\r\n## Description of issue (what needs changing):\r\n\r\nNeed clear documentation with details  on what makes all these different formats different. \r\n\r\n### Clear description\r\n\r\nLooking for  a clear description  (pun not intended)  of  GraphDef and Saved Model - their diffrences etc., needs for  them ( and others such as ckpt ) .\r\n\r\n### Correct links\r\n\r\nN/A\r\n\r\n### Parameters defined\r\n\r\nN/A\r\n\r\n### Returns defined\r\n\r\nN/A\r\n\r\n### Raises listed and defined\r\n\r\nN/A\r\n\r\n### Usage example\r\n\r\nN/A\r\n\r\n### Request visuals, if applicable\r\n\r\nN/A\r\n\r\n### Submit a pull request?\r\n\r\nN/A\r\n", "comments": ["@whatdhack,\r\nPlease check [this description](https://www.tensorflow.org/guide/saved_model#the_savedmodel_format_on_disk) for the SavedModel format and let us know if it helps Thanks!", "That looks good for SavedModel for TF 2.0 .  How about a similar page for TF 1.15 ?  How about the other model types (GraphDef/Forzen/ckpt)  ?", "@whatdhack,\r\ntf.saved_model is common for both TF 1.x and 2.x. You can read more about training checkpoints from [this link](https://www.tensorflow.org/guide/checkpoint). \r\n\r\nAlso, this question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is  a larger community that reads questions there.\r\n", "I do not think I can agree with that statement. Availability of basic clear documentation are part of the product  (open source or not). Saves users/developers time and energy.  How difficult is it to add a page to the already existing documentation ? I would have done that myself,if I knew exactly what the differences are, given the amount of time I have spent trying  to understand the differences. ", "You saw the SavedModel guide: https://www.tensorflow.org/guide/saved_model ?\r\n\r\nGraph optimization guide also useful: https://www.tensorflow.org/guide/graph_optimization\r\n", "Yes, have seen  that. Does not really explain  how contnts of Saved Model, GraphDef, Frozen model etc differ and which one is suitable for what.", "@lamberta Is there any update on this issue? I agree with @whatdhack . We do need good doc about these formats. Some basic concepts are not clear now, e.g. what's diff of saved model vs graph def, when to use which format.\r\n", "A comparison table would be very helpful for folks new to TF. Such a thing is ideal as an intro and decision-making point as users explore options then click to go deeper into docs for the one they believe is the best choice for their use case."]}, {"number": 39629, "title": "Successive STFT transforms increases signal amplitude", "body": "Hi,\r\nI successively applied tensorflow's STFT and iSTFT transforms several time on a signal, and the amplitude of the signal grows with each transform. I tried librosa's and scipy's STFT and this doesn't happen. Here is the exact code:\r\n\r\n```\r\nimport librosa\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport matplotlib.pyplot as plt\r\n\r\nlength=88\r\nfft_size = (length-1)*2   # 174\r\nhop_size = int(fft_size/4)# 43\r\n\r\ndef get_STFT_librosa(sig):\r\n    spec_librosa = librosa.core.stft(np.array(sig), n_fft=fft_size, hop_length=hop_size, win_length=fft_size)\r\n    return spec_librosa\r\n\r\ndef get_iSTFT_librosa(spec):\r\n    inverse = librosa.core.istft(spec, hop_length=hop_size, win_length=fft_size)\r\n    return inverse\r\n    \r\ndef get_STFT_tf(sig):\r\n    STFT = tf.signal.stft(np.array(sig), frame_length=fft_size, frame_step=hop_size, fft_length=fft_size)\r\n    STFT = STFT.numpy()\r\n    spec_tf = STFT.T\r\n    return spec_tf\r\n\r\ndef get_iSTFT_tf(spec):\r\n    STFT = tf.convert_to_tensor(spec.T)\r\n    sig = tf.signal.inverse_stft(STFT, frame_length=fft_size, frame_step=hop_size, fft_length=fft_size)\r\n    return sig.numpy()\r\n\r\ndef librosa_tf_comparison():\r\n    time = np.arange(0, 1000, 0.1);\r\n    sig = np.sin(time)\r\n\r\n    #STFT level 1\r\n    tf_STFT = get_STFT_tf(sig)\r\n    lib_STFT = get_STFT_librosa(sig)\r\n\r\n    tf_iSTFT = get_iSTFT_tf(tf_STFT)\r\n    lib_iSTFT = get_iSTFT_librosa(lib_STFT)\r\n\r\n    #STFT level 2\r\n    tf_STFT2 = get_STFT_tf(tf_iSTFT)\r\n    lib_STFT2 = get_STFT_librosa(lib_iSTFT)\r\n\r\n    tf_iSTFT2 = get_iSTFT_tf(tf_STFT2)\r\n    lib_iSTFT2 = get_iSTFT_librosa(lib_STFT2)\r\n\r\n\r\n    #STFT level 3\r\n    tf_STFT3 = get_STFT_tf(tf_iSTFT2)\r\n    lib_STFT3 = get_STFT_librosa(lib_iSTFT2)\r\n\r\n    tf_iSTFT3 = get_iSTFT_tf(tf_STFT3)\r\n    lib_iSTFT3 = get_iSTFT_librosa(lib_STFT3)\r\n\r\n    plt.plot(sig[:800])\r\n    plt.plot(tf_iSTFT[:800])\r\n    plt.plot(tf_iSTFT2[:800])\r\n    plt.plot(tf_iSTFT3[:800])\r\n    plt.show()\r\n\r\n    plt.plot(sig[:800])\r\n    plt.plot(lib_iSTFT[:800])\r\n    plt.plot(lib_iSTFT2[:800])\r\n    plt.plot(lib_iSTFT3[:800])\r\n    plt.show()\r\n\r\nlibrosa_tf_comparison()\r\n\r\n```\r\nHere is what the code gives:\r\n![librosa](https://user-images.githubusercontent.com/10775105/82160064-e69e4280-9892-11ea-9638-eb4445f45539.png)\r\nThis is what a simple sine looks like after three consecutive STFT/iSTFT with librosa (there is only one curve because they are merged, as should be)\r\n![tf](https://user-images.githubusercontent.com/10775105/82160062-e1d98e80-9892-11ea-8a3b-5fa285c687cb.png)\r\nThis is what the same curve looks like after three consecutive STFT/iSTFT with tensorflow. The original sine wave is in blue, I get the yellow curve after one STFT/iSTFT, then green, then red.\r\n\r\nThe factor between one iSTFT wave and the previous one seems to be always the same no matter the shape of the wave (for this set of parameters), about 0.659.\r\n\r\nI checked and the NOLA constraint is met with these parameters. Is this normal behaviour?", "comments": ["@ SushiEleonore  \r\nCan you please let us know which version of tensor flow are you facing this issue", "@Saduf2019 \r\nI have version 2.1.0", "I am able to replicate the issue faced, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/fe82e574db3f1839b1cd6444d6bd1b19/untitled188.ipynb)", "Was able to reproduce the issue in TF 2.5. Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/5a9f9c59f981e52f4ec722dbc7cbf6e1/untitled84.ipynb).Thanks!"]}, {"number": 39565, "title": "Recursive support for tf.io.gfile.glob", "body": "Currently, the `tf.io.gfile.glob` API do not support `recursive=True` kwargs, which is inconsistent with Python [glob.glob](https://docs.python.org/3/library/glob.html).\r\n\r\nExample to demonstrate the issue:\r\n\r\n```py\r\nimport glob\r\nimport tensorflow as tf\r\n\r\ntf.io.gfile.makedirs('/tmp/a/b/c')\r\n\r\ntf.io.gfile.glob('/tmp/a/**')  # ['/tmp/a/b']\r\nglob.glob('/tmp/a/**', recursive=True)  # ['/tmp/a/', '/tmp/a/b', '/tmp/a/b/c']\r\n```\r\nIt would be nice to support `recursive=True` for the Gfile API:\r\n\r\n```py\r\ntf.io.gfile.glob('/tmp/a/**', recursive=True)  # ['/tmp/a/', '/tmp/a/b', '/tmp/a/b/c']\r\n```", "comments": ["We will implement this functionality after conversion to modular filesystems.", "@michaelbanfield Nice, by curiosity, do you know if there will also be a `pathlib` like interface ?  https://docs.python.org/3/library/pathlib.html\r\n\r\n```py\r\npath = tf.io.gpath.GPath('gs://my_bucket')\r\nfor file in path.glob('**'):\r\n  ...\r\n```\r\nThat would be awesome", "Yes, we plan to follow existing APIs for convenience.", "#34371 is a duplicate", "Has this been resolved yet?"]}, {"number": 39560, "title": "Suggest to the user to define a cache volume for bazel", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/install/source#docker_linux_builds\r\n\r\n## Description of issue (what needs changing):\r\nWe the current info about Docker build from source we will lost the cache when we destroy the container\r\n### Clear description\r\nThe bazel cache will be stored in `/root/.cache/bazel/` that it is ephemeral and so it will lost if the container it is removed. So you are going to lost hours of builds just if you will restart the image with a new container. You need to suggest to mount an host volume for the bazel cache.\r\n\r\nFor example, why should someone use this method? How is it useful?", "comments": []}, {"number": 39554, "title": "tf.convert_to_tensor throws ValueError for tf.float64 tensor and dtype=tf.float32 instead of silently casting", "body": "I *think* this is a bug, at least it is inconsistent behavior.\r\n\r\n**System information**\r\n- custom code? no, just the minimal example to reproduce the error message\r\n- OS Platform and Distribution: Linux Ubuntu 18.04\r\n- PC\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: v2.1.0-rc2-17-ge5bf8de 2.1.0\r\n- Python version: 3.7.6 (default, Jan  8 2020, 19:59:22)\r\n\r\n**Describe the current behavior**\r\ntf.convert_to_tensor accepts numpy np.float64 arrays when dtype is tf.float32 (and returns a tf.float32 Tensor).\r\n\r\nIf the argument however is a tensor of type tf.float64, an error is thrown instead of returning a tf.float32 tensor\r\n**Describe the expected behavior**\r\nI would expect **tf.convert_to_tensor** to treat the float64-Tensor and the float64-ndarray the same. In my understanding it is in general use for all tensorflow operators and should accept a broad range of inputs. I see no reason to reject Tensors, but accept ndarrays.\r\n**Standalone code to reproduce the issue**\r\nScript:\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nv_np = np.ones(shape=(3), dtype=np.float64)\r\nprint(\"A\",v_np,type(v_np[0]))\r\nv_tf = tf.constant([1.0,1,1], dtype=tf.float64)\r\nprint(\"B\",v_tf,type(v_tf[0].numpy()))\r\nprint(\"C\",tf.convert_to_tensor(v_np,dtype=tf.float32))\r\nprint(\"D\",tf.convert_to_tensor(v_tf,dtype=tf.float32))\r\n```\r\nOutput:\r\n```\r\nA [1. 1. 1.] <class 'numpy.float64'>\r\nB tf.Tensor([1. 1. 1.], shape=(3,), dtype=float64) <class 'numpy.float64'>\r\nC tf.Tensor([1. 1. 1.], shape=(3,), dtype=float32)\r\nTraceback (most recent call last):\r\n  File \"/home/user/TENSORFLOW/myapp-tf/bug.py\", line 9, in <module>\r\n    print(\"D\",tf.convert_to_tensor(v_tf,dtype=tf.float32))\r\n  File \"/home/user/miniconda2/envs/tf20b/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1256, in convert_to_tensor_v2\r\n    as_ref=False)\r\n  File \"/home/user/miniconda2/envs/tf20b/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1290, in convert_to_tensor\r\n    (dtype.name, value.dtype.name, value))\r\nValueError: Tensor conversion requested dtype float32 for Tensor with dtype float64: <tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 1., 1.])>\r\n```\r\n\r\n", "comments": ["@gittar \r\nPlease refer to this [link](https://stackoverflow.com/questions/54798223/tensor-conversion-requested-dtype-int32-for-tensor-with-dtype-int64-while-esti) , [link2](https://stackoverflow.com/questions/57464461/tensor-conversion-requested-dtype-float64-for-tensor-with-dtype-float32) and let us know if it helps resolve your issue.\r\n#38225", "Yes. I can fix my program by casting the tf.float64 value to tf.float32 before invoking \r\ntf.convert_to_tensor(v_np,dtype=tf.float32)\r\nWhich would be a superflous call in this case.\r\n\r\nThe real context of my question is a function f() like\r\n```\r\ndef f(X):\r\n     mytensor = tf.convert_to_tensor(X, dtype=tf.float32)\r\n     (rest of the function working with the tf.float32 tensor \"mytensor\")\r\n```\r\nI would like my function to accept both numpy array and tf.Tensor and both float32 and float64 and convert it all to tf.float32 tensors. Currently the tf.convert_to_tensor call  accepts numpy arrays of float64 and float32 and tf.Tensor with tf.float32, but throws an error for tf.float64. \r\n\r\nWhy is it designed like that? If no silent conversion from 64bit to 32bit was desired it should reject also numpy arrays of float64. To get around  this in the above function I would need to do something like\r\n```\r\ndef f(X):\r\n     if isinstance(X,tf.Tensor) and (X.dtype == tf.float64):\r\n          mytensor = tf.cast(X,dtype=tf.float32)\r\n     else:\r\n          mytensor = tf.convert_to_tensor(X, dtype=tf.float32)\r\n     (rest of the function working with the tf.float32 tensor)\r\n```\r\nwhich is quite inelegant.\r\n\r\nFor better consistency I would propose to let tf.convert_to_tensor( X , dtype=tf.float32)  also accept values for X which are tensors of type tf.float64 (and vice versa if conversion to tf.float64 is desired, also tf.float32 arguments should be accepted).\r\n\r\nI understand that may be a breaking change for programs indeed relying on this (IMO) inconsistency, but I still would do it.", "Was able to reproduce the issue in TF-Nightly.Please find the attached [gist](https://colab.research.google.com/gist/saikumarchalla/f13d0fcfe0773594f96832f80f1650d8/untitled79.ipynb).Thanks!", "Is this still an issue?", "If it has not been changed I would still see this as inconsistency as detailed in my comment from May 21, 2020. Since there exists a workaround by doing casting beforehand it will not really block anyone  but I guess tensorflow should strive for consistency to avoid users running into surprising problems.", "any updates?", "It is still replicating in the 2.8 version. Attaching [gist](https://colab.sandbox.google.com/gist/mohantym/2febb530f924b49b6bab45a29829d355/git_39334.ipynb#scrollTo=ncuzgY60KGat) for reference. Thanks!"]}, {"number": 39537, "title": "[feature request] - please consider adding in gpumlib features to tensorflow", "body": "**[feature request] - please consider adding in gpumlib features to tensorflow**\r\n\r\n# Greetings\r\n\r\n**I would like to point out to:**\r\n- *incorporalting gpumlib features in tensorflow.*\r\n\r\n**motivations for the assessment:**\r\n- *gpumlib contains some interesting algorithms, that could perfectly enhance some features of tensorflow.*\r\n\r\n**the source code for the framework can be found at:**\r\n- *http://gpumlib.sourceforge.net/*", "comments": ["Hi @jakob82 ,\r\n\r\n> gpumlib contains some interesting algorithms, that could perfectly enhance some features of tensorflow.\r\n\r\nCan you please be more specific?\r\n\r\nThe TensorFlow team does not have cycles to look into this at the moment.  However, please feel free to post [an RFC](https://github.com/tensorflow/community/blob/master/governance/TF-RFCs.md) with more details if you want to take this on."]}, {"number": 39526, "title": "Documentation for ensuring CUPTI for Profiling is Misleading", "body": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/guide/profiler#install_the_profiler_and_gpu_prerequisites\r\n\r\n## Description of issue (what needs changing):\r\nThe documentation says to do `ldconfig -p | grep libcupti` to check that CUPTI exists on the path, and to do `export LD_LIBRARY_PATH=/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH` to fix it if it is not on the path.  However, the documentation can be misleading in situations where an old install of CUDA 10.0 has been replaced with 10.1 (at least on my installation).\r\n\r\n\r\nMy output when checking the path is as below:\r\n```console\r\ntyler@lambda2:/usr/local/cuda/bin$ ldconfig -p | grep libcupti\r\n\tlibcupti.so.10.0 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libcupti.so.10.0\r\n\tlibcupti.so (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libcupti.so\r\n```\r\n\r\nReading the documentation, this suggested to me that I did indeed have a version of libcupti on the path, and that everything should work. However, when I trained my model with the profiler on I saw the following error logs in the console.\r\n\r\n```\r\n2020-05-13 15:49:23.364143: I tensorflow/core/profiler/lib/profiler_session.cc:163] Profiler session started.\r\n2020-05-13 15:49:23.364212: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs\r\n2020-05-13 15:49:23.364588: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcupti.so.10.1'; dlerror: libcupti.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64\r\n2020-05-13 15:49:23.364606: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1415] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\r\n```\r\n\r\nAfter double checking that I had CUDA 10.1 installed and not 10.2, I did the below\r\n```console\r\ntyler@lambda2:~/$ export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/extras/CUPTI/lib64\r\ntyler@lambda2:~/$ echo $LD_LIBRARY_PATH\r\n/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/extras/CUPTI/lib64\r\n```\r\n\r\nThis then allows the profiler to load CUPTI\r\n```\r\n2020-05-13 18:18:51.560268: I tensorflow/core/profiler/lib/profiler_session.cc:163] Profiler session started.\r\n2020-05-13 18:18:51.560338: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs\r\n2020-05-13 18:18:51.561266: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcupti.so.10.1\r\n```\r\n\r\nHowever, rerunning the command from the documentation for checking that CUPTI is on the path gives the same output as before\r\n\r\n```console\r\ntyler@lambda2:~/$ ldconfig -p | grep libcupti\r\n\tlibcupti.so.10.0 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libcupti.so.10.0\r\n\tlibcupti.so (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libcupti.so\r\n```\r\n\r\n### Desired fixes\r\nAfter updating my path, I would expect that `ldconfig -p | grep libcupti` would update to show that `usr/local/cuda/extras/CUPTI/lib64` with version 10.1 is available. \r\n\r\nAdditionally, I believe the documentation should explicitly state that running `ldconfig -p | grep libcupti` should show `libcupti.so.10.1` or greater\r\n\r\n\r\n### Submit a pull request?\r\n\r\nNo, I'm not sure of what the best way to check for 10.1 or 10.2 would be\r\n", "comments": ["i think a better instruction is just to check if there's `libcupti.so.10.x` in `/usr/local/cuda/extras/CUPTI/lib64` because `ldconfig` won't show CUPTI lib files in some cases even if CUPTI has been correctly installed.", "how to fix this issue on windows10?", "I met the same problem that `ldconfig -p | grep libcupti ` shows the link info of the old install of CUDA instead of the latest install of CUDA in my server. This is because I have no uninstalled the old version of CUDA completely. After following the commands from the official guidance [https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#removing-cuda-tk-and-driver](url), I remove CUDA together with Nvidia driver and install CUDA 10.1 again, and the above problem is solved.\r\nHowever,  when I confirm that the CUPTI path has been added to `LD_LIBRARY_PATH`, the program still reminds me that can not load libcupti.so.10.0.  Then, I execute the following  commands: `sudo cp /usr/local/cuda-10.1/extras/CUPTI/lib64/libcupti.so /usr/local/lib/libcupti.so && sudo ldconfig\r\nsudo cp /usr/local/cuda-10.1/extras/CUPTI/lib64/libcupti.so.10.1 /usr/local/lib/libcupti.so.10.1 && sudo ldconfig`.\r\nAmazing, it solved.", "Any progressing \uff1f \r\nMy environment is :\r\n```Bash\r\necho $LD_LIBRARY_PATH\r\n```\r\noutput is \r\n```\r\n/usr/local/cuda/lib64::/usr/local/cuda/extras/CUPTI/lib64\r\n```\r\n```Bash\r\n$ ll /usr/local/cuda/extras/CUPTI/lib64\r\n```\r\noutput is : \r\n```\r\ndrwxr-xr-x 2 root root     4096 10\u6708 21 15:31 ./\r\ndrwxr-xr-x 6 root root     4096 10\u6708 21 15:31 ../\r\nlrwxrwxrwx 1 root root       16 10\u6708 21 15:31 libcupti.so -> libcupti.so.10.1*\r\nlrwxrwxrwx 1 root root       20 10\u6708 21 15:31 libcupti.so.10.1 -> libcupti.so.10.1.208*\r\n-rwxr-xr-x 1 root root  5700176 10\u6708 21 15:31 libcupti.so.10.1.208*\r\n-rw-r--r-- 1 root root 13516866 10\u6708 21 15:31 libcupti_static.a\r\n-rwxr-xr-x 1 root root  9716376 10\u6708 21 15:31 libnvperf_host.so*\r\n-rw-r--r-- 1 root root 14726370 10\u6708 21 15:31 libnvperf_host_static.a\r\n-rwxr-xr-x 1 root root  2349848 10\u6708 21 15:31 libnvperf_target.so*\r\n```\r\n", "@TylerADavis,\r\nThe command to check if CUPTI exists on a particular path has been updated. \r\n\r\nCould you please take a look at [this link](https://www.tensorflow.org/guide/profiler#install_the_profiler_and_gpu_prerequisites) and let us know if this is still an issue? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "> @TylerADavis,\r\n> The command to check if CUPTI exists on a particular path has been updated.\r\n> \r\n> Could you please take a look at [this link](https://www.tensorflow.org/guide/profiler#install_the_profiler_and_gpu_prerequisites) and let us know if this is still an issue? Thanks!\r\n\r\nI don't know how to use the ```install_and_run.py``` script . It raises error : \r\n```\r\nusage: test.py [-h] --envdir ENVDIR --logdir LOGDIR [--port PORT] [--version VERSION]\r\ntest.py: error: the following arguments are required: --envdir, --logdir\r\n```\r\nWhen I run \r\n```/sbin/ldconfig -N -v $(sed 's/:/ /g' <<< $LD_LIBRARY_PATH) | grep libcupti``` , \r\nIt gives : \r\n```\r\n/sbin/ldconfig.real: given more than once \u201c/usr/lib/x86_64-linux-gnu\u201d\r\n/sbin/ldconfig.real: given more than once \u201c/usr/lib\u201d\r\n        libcupti.so.11.0 -> libcupti.so.2020.1.1\r\n/sbin/ldconfig.real: /lib/x86_64-linux-gnu/ld-2.31.so is the dynamic linker, ignoring\r\n```", "@DachuanZhao,\r\nCould you please submit a new issue from [this link](https://github.com/tensorflow/tensorflow/issues/new/choose) and fill in the template, so that we can track the issue there. Thanks!", "@amahendrakar It seems that the updated instructions do resolve the misleading output, addressing the first of the two desired fixes I listed in the original post, thanks!. \r\n\r\nI believe the accompanying text could be still be made more clear. For example, `Ensure CUPTI exists on the path:` could be replaced with something like `Ensure the proper version of CUPTI for your version of TensorFlow, as described by the TensorFlow GPU requirements (https://www.tensorflow.org/install/source#gpu) , exists on the path:`. This is because some versions of TF require CUDA (and cupti) 10.0 or 10.1 or 11.0, and language reminding users to double check the version number could be helpful. \r\n\r\n\r\nRunning the new commands does indeed change the output before and after editing the path. Before editing the path, observe that only `libcupti.so.10.0` is printed:\r\n```bash\r\ntyler@lambda2:~$ /sbin/ldconfig -N -v $(sed 's/:/ /g' <<< $LD_LIBRARY_PATH) | \\\r\n> grep libcupti\r\n/sbin/ldconfig.real: Path `/usr/local/cuda-10.1/targets/x86_64-linux/lib' given more than once\r\n/sbin/ldconfig.real: Can't stat /usr/local/lib/i386-linux-gnu: No such file or directory\r\n/sbin/ldconfig.real: Can't stat /usr/local/lib/i686-linux-gnu: No such file or directory\r\n/sbin/ldconfig.real: Can't stat /lib/i686-linux-gnu: No such file or directory\r\n/sbin/ldconfig.real: Can't stat /usr/lib/i686-linux-gnu: No such file or directory\r\n/sbin/ldconfig.real: Can't stat /usr/local/lib/x86_64-linux-gnu: No such file or directory\r\n/sbin/ldconfig.real: Path `/lib/x86_64-linux-gnu' given more than once\r\n/sbin/ldconfig.real: Path `/usr/lib/x86_64-linux-gnu' given more than once\r\n/sbin/ldconfig.real: /lib/i386-linux-gnu/ld-2.27.so is the dynamic linker, ignoring\r\n\r\n/sbin/ldconfig.real: /lib/x86_64-linux-gnu/ld-2.27.so is the dynamic linker, ignoring\r\n\r\n/sbin/ldconfig.real: /lib/x86_64-linux-gnu/ld-2.27.so is the dynamic linker, ignoring\r\n\r\n/sbin/ldconfig.real: Cannot stat /usr/lib/x86_64-linux-gnu/libnvjpeg.so: No such file or directory\r\n\tlibcupti.so.10.0 -> libcupti.so.10.0.130\r\n```\r\nNow I edit the path and rerun the command, observing that libcupti.so.10.1 is now present:\r\n```bash\r\ntyler@lambda2:~$ export LD_LIBRARY_PATH=/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH\r\ntyler@lambda2:~$ /sbin/ldconfig -N -v $(sed 's/:/ /g' <<< $LD_LIBRARY_PATH) | \\\r\n> grep libcupti\r\n/sbin/ldconfig.real: Path `/usr/local/cuda-10.1/targets/x86_64-linux/lib' given more than once\r\n/sbin/ldconfig.real: Can't stat /usr/local/lib/i386-linux-gnu: No such file or directory\r\n/sbin/ldconfig.real: Can't stat /usr/local/lib/i686-linux-gnu: No such file or directory\r\n/sbin/ldconfig.real: Can't stat /lib/i686-linux-gnu: No such file or directory\r\n/sbin/ldconfig.real: Can't stat /usr/lib/i686-linux-gnu: No such file or directory\r\n/sbin/ldconfig.real: Can't stat /usr/local/lib/x86_64-linux-gnu: No such file or directory\r\n/sbin/ldconfig.real: Path `/lib/x86_64-linux-gnu' given more than once\r\n/sbin/ldconfig.real: Path `/usr/lib/x86_64-linux-gnu' given more than once\r\n/sbin/ldconfig.real: /lib/i386-linux-gnu/ld-2.27.so is the dynamic linker, ignoring\r\n\r\n\tlibcupti.so.10.1 -> libcupti.so.10.1.59\r\n/sbin/ldconfig.real: /lib/x86_64-linux-gnu/ld-2.27.so is the dynamic linker, ignoring\r\n\r\n/sbin/ldconfig.real: Cannot stat /usr/lib/x86_64-linux-gnu/libnvjpeg.so: No such file or directory\r\n\tlibcupti.so.10.0 -> libcupti.so.10.0.130\r\n```"]}, {"number": 39498, "title": "Construct tf.SparseTensor with tf.int32 dense_shape", "body": "**System information**\r\n- TensorFlow version (you are using): 2.2\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nCurrently, `tf.SparseTensor` raises an error when constructed with a `dense_shape` of\r\n`int32` dtype. This is annoying, as it e.g. prevents constructs of the form\r\n```\r\nsparse = tf.SparseTensor(indices, values, tf.shape(other_tensor))\r\n```\r\nbecause `tf.shape` by default returns an int32 tensor. \r\n\r\n**Will this change the current api? How?**\r\nInstead of throwing an error, `tf.SparseTensor.__init__` should convert int32 shapes to\r\nint64 shapes. Since the shapes are expected to have only a few entries, this should not\r\nlead to any unexpected performance impacts.\r\n\r\n**Who will benefit with this feature?**\r\nThis is mostly a very small convenience improvement, but has the benefit of making `tf.shape`\r\nand `tf.SparseTensor` interact more seamlessly.\r\n\r\n**Any Other info.**\r\nOne step further in that direction would be to have tf.shape return int64 tensors when called on a SparseTensor, but this would be a non backwards-compatible change, so I'm not sure if thats possible/worth it.", "comments": []}, {"number": 39487, "title": "Add support of float in lite/kernels/kernel_util.cc#CalculateActivationRangeQuantized", "body": "Source:  https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/kernel_util.cc#L197\r\n\r\nthe CalculateActivationRangeQuantized method which only supports int8 and int16 output and raise error for float type:\r\n\r\n```\r\n  int32_t qmin = 0;\r\n  int32_t qmax = 0;\r\n  if (output->type == kTfLiteUInt8) {\r\n    qmin = std::numeric_limits<uint8_t>::min();\r\n    qmax = std::numeric_limits<uint8_t>::max();\r\n  } else if (output->type == kTfLiteInt8) {\r\n    qmin = std::numeric_limits<int8_t>::min();\r\n    qmax = std::numeric_limits<int8_t>::max();\r\n  } else if (output->type == kTfLiteInt16) {\r\n    qmin = std::numeric_limits<int16_t>::min();\r\n    qmax = std::numeric_limits<int16_t>::max();\r\n  } else {\r\n    TF_LITE_ENSURE(context, false);\r\n  }\r\n```\r\n\r\nCould you add support so we can use float model after quantization", "comments": []}, {"number": 39479, "title": "Causal padding for tfp.layers.Convolution1DFlipout", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n**System information**\r\n- TensorFlow version (you are using): \r\ntensorflow: 2.2.0 \r\ntensorflow-probability: 0.9.0   \r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n**Describe the feature and the current behavior/state.** \r\nCan \"causal\" padding be added as an option to tfp.layers.Convolution1DFlipout just like it is available in tf.keras.layers.Conv1D ?\r\n\r\n\r\n", "comments": []}, {"number": 39467, "title": "Build tensorflow 2.2.0 failed in '@upb//:upb' with the length argument in strncpy", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n  Linux Ubuntu 18.04.4 LTS\r\n- TensorFlow installed from (source or binary):\r\n  source\r\n- TensorFlow version:\r\n  2.2.0\r\n- Python version:\r\n  3.7.7\r\n- Bazel version (if compiling from source):\r\n  2.0.0\r\n- GCC/Compiler version (if compiling from source):\r\n  10.1.0\r\n\r\n**Describe the problem**\r\n\r\n```console\r\nIn file included from /usr/include/string.h:494,                                                                \r\n                 from external/upb/upb/upb.h:16,                                                                                                                                                                                              \r\n                 from external/upb/upb/upb.c:2:                                                                 \r\nIn function 'strncpy',                                                                                         \r\n    inlined from 'upb_status_seterrmsg' at external/upb/upb/upb.c:40:3:                                         \r\n/usr/include/x86_64-linux-gnu/bits/string_fortified.h:106:10: error: '__builtin_strncpy' specified bound 127 equals destination size [-Werror=stringop-truncation]                                                             \r\n  106 |   return __builtin___strncpy_chk (__dest, __src, __len, __bos (__dest));                                                                                                                                                              \r\n      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                 \r\ncc1: all warnings being treated as errors                                                                      \r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build                                         \r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nBuild with bazel following the documentation.\r\n\r\n**Any other info / logs**\r\n\r\nIt's a trivial misuse of strncpy.  Here is a simple fix.\r\n\r\n```patch\r\n--- upb/upb/upb.c~      2020-05-12 14:33:15.046048687 -0500                                                                                                                                           \r\n+++ upb/upb/upb.c       2020-05-12 14:33:30.281987830 -0500                                                                                                                                           \r\n@@ -37,7 +37,7 @@                                                                                                                                                                                                                                             \r\n void upb_status_seterrmsg(upb_status *status, const char *msg) {                                                                                                                                                                                             \r\n   if (!status) return;                                                                                                                                                                                                                                       \r\n   status->ok = false;                                         \r\n-  strncpy(status->msg, msg, sizeof(status->msg));             \r\n+  strncpy(status->msg, msg, sizeof(status->msg)-1);           \r\n   nullz(status);                                              \r\n }                                                             \r\n                                                               \r\n```", "comments": ["This issue is already fixed in upb upstream, so I posted it here.", "@jxy added a ~~PR #39467~~  to update upb. (update: should be #39470.)", "@jxy  Update: Should be PR #39470.", "@jxy The fix is not straightforward, as grpc still uses repository_defs.bzl in upb which has been removed:\r\n\r\nhttps://github.com/protocolbuffers/upb/blob/d7d72f00753767ae639c12f2a7618c56ccb2425a/bazel/repository_defs.bzl\r\n\r\nWill need to patch grpc repo first. Then updates tf to get this fixed.", "Yes, this needs to wait for grpc to upgrade first.", "When can we compile TF 2.2.0 on Clear Linux without this bug ? ", "The current state of this is that tensorflow sadly still doesn't work on gcc 10 which is especially annoying since even CUDA 11.1 now supports gcc 10. As a downstream packager, I'm not really sure what the proper way to address this problem would be but I'd appreciate it if a tensorflow team member could fix it.", "Second that!", "Annoying comment, but necessary I guess: Any update?", "We don't update branches after release, except for security reasons. So to test if this is fixed, we should test on the r2.4 branch", "Of course, I was talking about the last branch here.", "The grpc upstream library has updated and includes the right upb library in https://github.com/grpc/grpc/commit/e2e6b1839e83b7373edda903fb17dd15a2cb996f (included in grpc 1.32.0/1.33.0/1.33.1/1.33.2), so updating tensorflow's grpc library in theory will resolve this issue.\r\n\r\nThough it looks like there are quite a few other dependencies that might be interleaved with grpc dependency so the update is not exactly straightforward.", "Actually, a PR #44282 has already been opened to update grpc which will resolve this issue (if the PR is able to get merged).", "This can be closed.", "Closing as requested", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39467\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39467\">No</a>\n", "I think this should be reopened due the rollback of #51923."]}, {"number": 39378, "title": "Java Module support", "body": "**Describe the problem**\r\nApplications using Java9+ benefit from libraries have Java Module (JPMS) support. This comes in two stages:\r\n\r\n1. Ideally, add `module-info.java` to the library. Either publish a separate artifact for Java9+ or simply add `META-INF/versions/9/module-info.class` to support both versions simultaneously (multi-release jar)\r\n2. If the library has split packages, you cannot add `module-info.java` yet in which case you can simply add `Automatic-Module-Name` to the manifest file and begin resolving the split package issue.\r\n\r\n* Multi-release JARs\r\n  * https://openjdk.java.net/jeps/238\r\n  * https://blog.codefx.org/tools/multi-release-jars-multiple-java-versions/", "comments": ["@cowwoc Could you please let us know if this issue still persists ? If it it resolved then please feel free to move this issue to close status ?Thanks!", "@kumariko Yes, the issue still persists.", "@cowwoc,\r\nDoes this helps https://www.tensorflow.org/install/lang_java_legacy#tensorflow_with_the_jdk . Thanks!", "@gadagashwini What are you asking? Did you add module-info.java to Tensorflow?", "@cowwoc, As you can see https://www.tensorflow.org/install/lang_java_legacy#tensorflow_with_the_jdk Tensorflow has Java compiler. Thanks!", "@gadagashwini Sure, but this issue is about \"Java Module\" support which is about a lot more than just providing Java support."]}, {"number": 39375, "title": "Unstack a ragged tensor stacked by the tf data api", "body": "**System information**\r\n- TensorFlow version (you are using): 2.2\r\n- Are you willing to contribute it (Yes/No): yes\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nFor efficiency reason when saving my structured data as a tf records i save batches of input instead of only a row. \r\nMy dataset contains mixtures of Ragged inputs and lists. \r\nEach tf Example contains a batch of N rows (here 10) batched together:\r\n\r\n```\r\n{'test': int64_list {\r\n   value: 1\r\n   value: 3\r\n   value: 9\r\n   value: 1\r\n }, 'test_offset': int64_list {\r\n   value: 0\r\n   value: 0\r\n   value: 0\r\n   value: 0\r\n   value: 0\r\n   value: 0\r\n   value: 3\r\n   value: 4\r\n   value: 4\r\n   value: 4\r\n   value: 4\r\n }}\r\n```\r\nThat i then parse using: \r\n```\r\nfeatures =  { \r\n       'test': tf.io.RaggedFeature(value_key='test', dtype=tf.int64, partitions=[ \r\n                tf.io.RaggedFeature.RowSplits(f\"test_offset\")])}\r\ndef mapper(ex):\r\n    return tf.io.parse_single_example(ex, features)\r\nres = dataset.map(mapper).batch(2)\r\n```\r\nWhen opening back the batches I want to batch them with another batch size for shuffling reasons. \r\nIf I try to batch with size 2 the resulting tensor will be a ragged tensor of shape (2, None, None). \r\n\r\nInstead I would like to have a shape (N*2, None). I managed to get that tensor by doing : \r\n\r\n\r\n```\r\nx = next(iter(re))\r\ntf.concat([x[0], x[1]], axis=1)\r\n```\r\n\r\nsplitting should be the same as `tf.unstack(x, axis=1)` which does not work and break on a \r\n\r\n> TypeError: object of type 'RaggedTensor' has no len()\r\n\r\n**Will this change the current api? How?**\r\nProvide a way of unstacking ragged tensors to be able to stack them properly. \r\n\r\n**Who will benefit with this feature?**\r\nUsers of ragged features\r\n\r\n**Any Other info.**\r\ngoogle colab: \r\nhttps://colab.research.google.com/gist/tanguycdls/f52dbd48a7c17ce282c82f91cd7547a6/untitled11.ipynb\r\n", "comments": ["I think that you can do what you want here just using `tf.Dataset.batch()` and `tf.Dataset.unbatch()` -- you shouldn't need to use `tf.unstack`.  Here's my attempt to reproduce your example, without having to mess with the io_example stuff:\r\n\r\n```\r\nB = 6\r\nN = 4\r\n\r\n# shape = [B, N, None]\r\nrt = tf.ragged.constant(\r\n    [[[1], [5, 7], [], []],\r\n     [[], [], [3, 2, 1], []],\r\n     [[], [], [], []],\r\n     [[], [], [18], []],\r\n     [[], [9, 9, 22], [], []],\r\n     [[5], [5], [5], [5]]]\r\n)\r\n\r\nds = tf.data.Dataset.from_tensor_slices({'test': rt})\r\nprint(\"Original dataset: each item has shape [N, None]\")\r\nfor item in ds: print(item)\r\n\r\nbatched = ds.batch(2)\r\nprint(\"Batched dataset: each item has shape [2, N, None]\")\r\nfor item in batched: print(item)\r\n\r\nrebatched = ds.unbatch().batch(2*N)\r\nprint(\"Rebatched dataset: each item has shape [2*N, None\")\r\nfor item in rebatched: print(item)\r\n```\r\n\r\nSo if you want to rebatch the dataset from size [2, None] to size [2*N, None], just unbatch it, and then batch it again.\r\n\r\nIf you did need to use `tf.unstack()` for some reason: it looks like it hasn't been implemented for ragged tensors yet; but I don't think it should be hard to implement.  Something like this:\r\n\r\n```\r\ndef ragged_unstack(value, num=None, axis=0):\r\n  if num is None:\r\n    num = value.shape[axis]\r\n  leading_slices = (Ellipsis,) * axis\r\n  return [value.__getitem__(leading_slices+(i,)) for i in range(num)]\r\n```\r\n", "Thanks @edloper, Unbatch works but i'm concerned about the performance of it. I tried to use your ragged_unstack but i'm not able to use it in tf data api using a map because `value.shape[0]`will be None when graphing the function.\r\n\r\n```\r\nres = dataset.map(mapper).batch(2).map(lambda x: x['test']).map(ragged_unstack)\r\ntensor = next(iter(res))['test']\r\n```\r\n> return _py_range(start_or_stop, stop, step)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/operators/py_builtins.py:351 _py_range\r\n        return range(start_or_stop)\r\nTypeError: 'NoneType' object cannot be interpreted as an integer\r\n\r\nI fixed the issue by passing num as a parameter (here default to two):\r\n\r\n````\r\ndef ragged_batch(value, num=2, axis=0):\r\n  if num is None:\r\n    num = value.shape[axis]\r\n  leading_slices = (Ellipsis,) * axis\r\n  return tf.concat([value.__getitem__(leading_slices+(i,)) for i in range(num)], axis=0)\r\n````\r\n\r\nIs it possible to use a for loop inside tf data map without having to provide the number manually or the fact its a graph forbids that usage ? \r\n\r\nThanks, ", "What's the performance issue with `unbatch`?\r\n\r\nAs for the shape of the batch dimension, I would expect it to preserve that info when we do batching, but it looks like it's not being preserved for some reason:\r\n\r\n```\r\n>>> ds = tf.data.Dataset.from_tensor_slices(tf.ragged.constant([[1, 2], [3]]))\r\n>>> batched = ds.batch(2)\r\n>>> print(ds.element_spec)\r\nRaggedTensorSpec(TensorShape([None]), tf.int32, 0, tf.int64)\r\n>>> print(batched.element_spec)\r\nRaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int64)\r\n```\r\n\r\nI would expect batched.element_spec's shape to be `[2, None]`.  In particular, the internal method that adds a batch dimension to the TensorSpec preserves it:\r\n\r\n```\r\n>>> ds.element_spec._batch(2)\r\nRaggedTensorSpec(TensorShape([2, None]), tf.int32, 1, tf.int64)\r\n```\r\n\r\nI'll look into why that dimension size is getting dropped.\r\n", "Looking at the code, I now remember that the shape isn't guaranteed to be statically fixed unless you pass `drop_remainder` when batching the dataset.  (In particular, the last element may have a shorter length than all the others.)  This works, using my `ragged_unstack`:\r\n\r\n```\r\n>>> batched = ds.batch(2, drop_remainder=True)\r\n>>> res = batched.map(lambda x: x['test']).map(ragged_unstack)\r\n>>> print(next(iter(res)))\r\n(<tf.RaggedTensor [[1], [5, 7], [], []]>, <tf.RaggedTensor [[], [], [3, 2, 1], []]>)\r\n```\r\n", "Thanks for the help, for the drop_remainder you're right it does not make any sense without it, it now works.\r\n\r\n> What's the performance issue with unbatch?\r\n\r\nI did some benchmarks between .unbatch().batch() and my method with each row in the TF records being a batch of 10^5 items. In prediction mode i want to score a very large batch at a time here i set it to 20*10^5. \r\nWith unbatch:\r\n````\r\n%%time\r\nres = dataset.map(mapper).unbatch().batch(20*10**5 , drop_remainder=True)\r\ntensor = next(iter(res))['test']\r\nprint(tensor.shape)\r\ntensor\r\n````\r\n> 2.92 s\r\n\r\n````\r\ndef ragged_batch(value, num=None, axis=0):\r\n  value = value['test']\r\n  if num is None:\r\n    num = value.shape[axis]\r\n  leading_slices = (Ellipsis,) * axis\r\n  return tf.concat([value.__getitem__(leading_slices+(i,)) for i in range(num)], axis=0)\r\n\r\n%%time\r\n# method where we concatenate the ragged right away.\r\nres = dataset.map(mapper).batch(2*10, drop_remainder=True).map(ragged_batch)\r\ntensor = next(iter(res))\r\nprint(tensor.shape)\r\ntensor\r\n````\r\n> 1.47 s\r\n\r\ndid the benchmark on collab here: https://colab.research.google.com/gist/tanguycdls/419484dda4d8ab9610eeb19e6823d52e/untitled11.ipynb#scrollTo=Wv8zOzIv457n\r\n\r\nIf you save your tf record with each row being 10^4 the difference is not that clear so it might not worth it. I dont know how tf unbatches and batches back ragged inputs but i think it might be costly if the offsets array needs to be fully recalculated.\r\n\r\nThanks\r\n"]}, {"number": 39323, "title": "InaccessibleTensorError: The tensor 'Tensor(\"Tile:0\", shape=(None, 3), dtype=float32)' cannot be accessed here: it is defined in another function or code block.", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS\r\n- Mobile device: No\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: 2.1.0\r\n- Python version: 3.6.9\r\n- CUDA/cuDNN version: None\r\n- GPU model and memory: None\r\n\r\n**Describe the current behavior**\r\nThrows the error.\r\n**Describe the expected behavior**\r\nReturns a tensor of shape (2, 6, 3), e.g.\r\n```\r\ntf.Tensor(\r\n[[[0.4200933  0.51168334 0.13771784]\r\n  [0.4200933  0.51168334 0.13771784]\r\n  [0.4200933  0.51168334 0.13771784]\r\n  [0.31555724 0.80608404 0.38079023]\r\n  [0.31555724 0.80608404 0.38079023]\r\n  [0.22353566 0.7539935  0.28550136]]\r\n\r\n [[0.3753245  0.10351241 0.61035573]\r\n  [0.51126313 0.4842764  0.5390732 ]\r\n  [0.1071049  0.8601215  0.69413567]\r\n  [0.1071049  0.8601215  0.69413567]\r\n  [0.         0.         0.        ]\r\n  [0.         0.         0.        ]]], shape=(2, 6, 3), dtype=float32)\r\n```\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\n@tf.function(input_signature=[\r\n        tf.TensorSpec(shape=(None, None, 3), dtype=tf.float32),\r\n        tf.TensorSpec(shape=(None, None, 1), dtype=tf.int32),\r\n    ])\r\ndef some_fz(x, dims):\r\n    batch_size = tf.shape(x)[0]\r\n    seq_len = tf.shape(x)[1]\r\n    dims = tf.cast(tf.math.round(dims), tf.int32)\r\n    new_lengths = tf.reduce_sum(dims, axis=1)\r\n    max_dim = tf.math.reduce_max(new_lengths)\r\n    pad_sizes = max_dim - new_lengths\r\n    new_batch = []\r\n    x = tf.expand_dims(x, axis=-2)\r\n    for i in tf.range(batch_size):\r\n        tensor_list = []\r\n        for j in tf.range(seq_len):\r\n            tiled = tf.tile(x[i][j], [dims[i][j][0], 1])\r\n            tensor_list.append(tiled)\r\n        new_tensor = tf.concat(tensor_list, axis=0)  # breaks here\r\n        new_tensor = tf.pad(new_tensor, [[0,pad_sizes[i][0]], [0,0]])\r\n        new_batch.append(new_tensor)\r\n    return tf.stack(new_batch)\r\n\r\nif __name__ == '__main__':\r\n    random = tf.random.uniform([2, 3, 3])\r\n    vector = tf.constant([[[3], [2], [1]], [[1], [1], [2]]])\r\n    out = some_fz(random, vector)\r\n```\r\n\r\n**Other info / logs** \r\n```\r\nTraceback (most recent call last):\r\n  File \"/Users/fcardina/Library/Preferences/PyCharmCE2019.2/scratches/scratch_2.py\", line 58, in <module>\r\n    out = some_fz(random, new_dimension)\r\n  File \"/Users/fcardina/anaconda3/envs/ttsTF/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\", line 568, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/Users/fcardina/anaconda3/envs/ttsTF/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\", line 615, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializers)\r\n  File \"/Users/fcardina/anaconda3/envs/ttsTF/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\", line 497, in _initialize\r\n    *args, **kwds))\r\n  File \"/Users/fcardina/anaconda3/envs/ttsTF/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 2389, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/Users/fcardina/anaconda3/envs/ttsTF/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 2703, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/Users/fcardina/anaconda3/envs/ttsTF/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 2593, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/Users/fcardina/anaconda3/envs/ttsTF/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\", line 978, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/Users/fcardina/anaconda3/envs/ttsTF/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\", line 439, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/Users/fcardina/anaconda3/envs/ttsTF/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\", line 968, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\ntensorflow.python.framework.errors_impl.InaccessibleTensorError: in converted code:\r\n\r\n    /Users/fcardina/Library/Preferences/PyCharmCE2019.2/scratches/scratch_2.py:47 some_fz  *\r\n        new_tensor = tf.concat(tensor_list, axis=0)\r\n    /Users/fcardina/anaconda3/envs/ttsTF/lib/python3.6/site-packages/tensorflow_core/python/util/dispatch.py:180 wrapper\r\n        return target(*args, **kwargs)\r\n    /Users/fcardina/anaconda3/envs/ttsTF/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py:1516 concat\r\n        return identity(values[0], name=name)\r\n    /Users/fcardina/anaconda3/envs/ttsTF/lib/python3.6/site-packages/tensorflow_core/python/util/dispatch.py:180 wrapper\r\n        return target(*args, **kwargs)\r\n    /Users/fcardina/anaconda3/envs/ttsTF/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py:267 identity\r\n        ret = gen_array_ops.identity(input, name=name)\r\n    /Users/fcardina/anaconda3/envs/ttsTF/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_array_ops.py:3829 identity\r\n        \"Identity\", input=input, name=name)\r\n    /Users/fcardina/anaconda3/envs/ttsTF/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py:742 _apply_op_helper\r\n        attrs=attr_protos, op_def=op_def)\r\n    /Users/fcardina/anaconda3/envs/ttsTF/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py:591 _create_op_internal\r\n        inp = self.capture(inp)\r\n    /Users/fcardina/anaconda3/envs/ttsTF/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py:641 capture\r\n        % (tensor, tensor.graph, self))\r\n\r\n    InaccessibleTensorError: The tensor 'Tensor(\"Tile:0\", shape=(None, 3), dtype=float32)' cannot be accessed here: it is defined in another function or code block. Use return values, explicit Python locals or TensorFlow collections to access it. Defined in: FuncGraph(name=while_body_59, id=5613077840); accessed from: FuncGraph(name=while_body_37, id=5612708472).\r\n```\r\n\r\n\r\nI tried to declare the list outside of the first loop, but it won't access the elements then. Doing tensor_list[i] would throw \r\n```\r\nTypeError: list indices must be integers or slices, not Tensor\r\n```\r\n\r\nI tried what is suggested here:\r\nhttps://github.com/tensorflow/tensorflow/issues/37512#issuecomment-600776581\r\nBut neither solution works. The first needs the lists to have the same size. The second complains that tf.autograph.experimental.set_loop_options has no shape_invariants argument.", "comments": ["Was able to reproduce the error with [TF v2.2](https://colab.research.google.com/gist/amahendrakar/8ebb8811ad21605d6c6d72d4ca175112/39323.ipynb#scrollTo=nSaL3BWd4EDp) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/f88fbd4b54b97427eb05a379c64dbf32/39323-tf-nightly.ipynb). Please find the attached gist. Thanks!", "I'm hoping that in a future version we'll support the plain list version, because right now things are a bit clunky to use.\r\n\r\nFor the first solution, the trouble in this case seems to be that TensorArray only supports elements of the same shape. But I think we can make it work by tiling inside the array and avoiding the `tf.tile`. I'm not sure this does exactly what you need, but here's a version that produces results:\r\n\r\n```\r\n    new_batch = tf.TensorArray(tf.float32, size=batch_size)\r\n    x = tf.expand_dims(x, axis=-2)\r\n    for i in tf.range(batch_size):\r\n        tensor_list = tf.TensorArray(tf.float32, size=0, dynamic_size=True)\r\n        for j in tf.range(seq_len):\r\n            # tiled = tf.tile(x[i][j], [dims[i][j][0], 1])\r\n            for k in tf.range(dims[i][j][0]):\r\n              tensor_list = tensor_list.write(tensor_list.size(), x[i][j])\r\n        new_tensor = tensor_list.stack()\r\n        new_tensor = tf.pad(new_tensor, [[0,pad_sizes[i][0]], [0,0], [0, 0]])\r\n        new_batch = new_batch.write(i, new_tensor)\r\n    return new_batch.stack()\r\n```\r\n\r\nThe second solution only works in TF 2.2 (that's when `set_loop_options` was added). I fudged the example by hardcoding some shapes, you'd need to use the proper ones in those `tf.zeros` and `shape_invariants`:\r\n\r\n```\r\n    new_batch = tf.zeros([0, 6, 3])\r\n    x = tf.expand_dims(x, axis=-2)\r\n    for i in tf.range(batch_size):\r\n        tf.autograph.experimental.set_loop_options(\r\n            shape_invariants=[(new_batch, tf.TensorShape([None, 6, 3]))]\r\n        )\r\n        tensor_list = tf.zeros([0, 3])\r\n        for j in tf.range(seq_len):\r\n            tf.autograph.experimental.set_loop_options(\r\n                shape_invariants=[(tensor_list, tf.TensorShape([None, 3]))]\r\n            )\r\n            tiled = tf.tile(x[i][j], [dims[i][j][0], 1])\r\n            tensor_list = tf.concat([tensor_list, tiled], axis=0)\r\n        new_tensor = tf.pad(tensor_list, [[0,pad_sizes[i][0]], [0,0]])\r\n        new_tensor = tf.expand_dims(new_tensor, 0)\r\n        new_batch = tf.concat([new_batch, new_tensor], axis=0)\r\n    return new_batch\r\n```", "Hi,\r\nthanks, that works. Quite clunky indeed. \r\n\r\nI did not realize that one of the issues was with the variable that defines the (outer) loop.\r\nHere are some examples of what work and what doesn't (counter intuitively, I' say)\r\n\r\nThis does NOT work\r\n```\r\n@tf.function(input_signature=[\r\n    tf.TensorSpec(shape=(None), dtype=tf.int32),\r\n    tf.TensorSpec(shape=(None), dtype=tf.int32),\r\n])\r\ndef foo(variable, loop_constant):\r\n    a_list = []\r\n    some_constant = 4\r\n    the_tensor = tf.ones(some_constant)\r\n    for i in range(loop_constant):\r\n        t = tf.random.shuffle(the_tensor)\r\n        a_list.append(t)\r\n    return a_list\r\n```\r\n\r\nThis DOES work, but it's obviously not acceptable\r\n```\r\n@tf.function(input_signature=[\r\n    tf.TensorSpec(shape=(None), dtype=tf.int32),\r\n    tf.TensorSpec(shape=(None), dtype=tf.int32),\r\n])\r\ndef foo(variable):\r\n    a_list = []\r\n    some_constant = 4\r\n    loop_constant = 5\r\n    the_tensor = tf.ones(some_constant)\r\n    for i in range(loop_constant):\r\n        t = tf.random.shuffle(the_tensor)\r\n        a_list.append(t)\r\n    return a_list\r\n```\r\nThis works and it's acceptable. Interestingly everything is defined within the same scope as the first example. I hope this becomes more pythonic in the future.\r\n```\r\n@tf.function(input_signature=[\r\n    tf.TensorSpec(shape=(None), dtype=tf.int32),\r\n    tf.TensorSpec(shape=(None), dtype=tf.int32),\r\n])\r\ndef foo(variable, loop_constant):\r\n    a_list = tf.TensorArray(tf.float32, size=loop_constant)\r\n    some_constant = 4\r\n    the_tensor = tf.ones(some_constant)\r\n    for i in range(loop_constant):\r\n        t = tf.random.shuffle(the_tensor)\r\n        a_list = a_list.write(i, t)\r\n    return a_list.stack()\r\n```\r\nRegarding the original question:\r\nI ended up using this, in case someone has the same issue and looks for an alternative.\r\n```\r\n    def call(self, x, dimensions):\r\n        dimensions = tf.squeeze(dimensions)\r\n        dimensions = tf.cast(tf.math.round(dimensions), tf.int32)\r\n        seq_len = tf.shape(x)[1]\r\n        batch_size = tf.shape(x)[0]\r\n        # build masks from dimensions\r\n        max_dim = tf.math.reduce_max(dimensions)\r\n        tot_dim = tf.math.reduce_sum(dimensions)\r\n        index_masks = tf.RaggedTensor.from_row_lengths(tf.ones(tot_dim), tf.reshape(dimensions, [-1])).to_tensor()\r\n        index_masks = tf.cast(tf.reshape(index_masks, (batch_size, seq_len * max_dim)), tf.float32)\r\n        non_zeros = seq_len * max_dim - tf.reduce_sum(max_dim - dimensions, axis=1)\r\n        # stack and mask\r\n        tiled = tf.tile(x, [1, 1, max_dim])\r\n        reshaped = tf.reshape(tiled, (batch_size, seq_len * max_dim, self.model_dimension))\r\n        mask_reshape = tf.multiply(reshaped, index_masks[:, :, tf.newaxis])\r\n        ragged = tf.RaggedTensor.from_row_lengths(mask_reshape[index_masks > 0], non_zeros)\r\n        return ragged.to_tensor()\r\n```", "was able to reproduce the issue in TF 2.5 and Nightly versions. Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/d7435fc6378bc8e837b47d48e4cc7c30/untitled79.ipynb).Thanks!"]}, {"number": 39305, "title": "control_dependencies with assert_equal", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/api_docs/python/tf/control_dependencies\r\n\r\n## Description of issue (what needs changing):\r\nDo we need to mention the debug use case in https://www.tensorflow.org/api_docs/python/tf/debugging/assert_equal#returns ?\r\n### Clear description\r\nWe declare in the note\r\n> Note: In TensorFlow 2 with eager and/or Autograph, you should not require this method, as code executes in the expected order. Only use tf.control_dependencies when working with v1-style code or in a graph context such as inside Dataset.map.\r\nBut there is any direct reference to the `assert_equal` use case\r\n\r\nFor example, why should someone use this method? How is it useful?\r\nTake a look at the issue [here](https://github.com/tensorflow/addons/issues/1794)", "comments": ["@bhack,\r\nSorry for the delayed response. Can you please elaborate on your point? Thanks! ", "Check https://github.com/tensorflow/tensorflow/issues/48699#issuecomment-825653937 /cc @mdanatg @MarkDaoust "]}, {"number": 39300, "title": "TFLite-Micro Operation Support for \"Dropout\"", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nN/A\r\n- TensorFlow installed from (source or binary):\r\nN/A\r\n- Tensorflow version (commit SHA if source):\r\nN/A\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):\r\nN/A\r\n\r\n**Describe the problem**\r\nHi, may I know the plan to support \"Dropout\" operator in TFLite-Micro?\r\nThanks for your help!\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n\r\n", "comments": []}, {"number": 39289, "title": "tf.Module.name_scope overrides parent scopes", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: macOS 10.15.5\r\n- Mobile device if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n**Describe the current behavior**\r\nThe `name_scope` of a `tf.Module` instance has a forward slash appended to the name, which causes the scope to disregard any parent scopes. Using `with tf.Module.name_scope` and `with tf.name_scope(mymod.name_scope.name):` both result in this issue. \r\n\r\n**Describe the expected behavior**\r\nEach of the following should have the same outcome:\r\n- `with tf.Module.name_scope:`\r\n- `with tf.name_scope(tf.Module.name_scope.name):`\r\n- `with tf.name_scope(tf.Module.name):`\r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\n\r\n\r\ndef my_test_mod_scopes():\r\n    mymod = tf.Module(name='mymod')\r\n    with tf.name_scope('first_scope'):\r\n         with mymod.name_scope:\r\n             tf.summary.scalar('scalar1', 84.9)\r\n         with tf.name_scope(mymod.name):\r\n             tf.summary.scalar('scalar2', 74.3)\r\n         with tf.name_scope(mymod.name_scope.name):\r\n             tf.summary.scalar('scalar3', 79.7)\r\n\r\nwith tf.summary.create_file_writer('./logs').as_default():\r\n    tf.summary.experimental.set_step(0)\r\n    my_test_mod_scopes()\r\n```\r\n![Screen Shot 2020-05-07 at 21 43 20](https://user-images.githubusercontent.com/31281983/81361269-e7bdbb80-90ab-11ea-84b9-4d41f84250b8.png)\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Was able to replicate the issue in 2.6.0-dev20210530,please find the gist [here ](https://colab.research.google.com/gist/sushreebarsa/6a46881c59f34e94e26fee26df4f5baf/untitled127.ipynb)..Thanks !"]}, {"number": 39269, "title": "Unintended tf.distribute.ReplicaContext.merge_call behavior on TPU", "body": "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 & Colab\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.2.0rc3\r\n- Python version: 3\r\n- CUDA/cuDNN version: 7.6\r\n- GPU model and memory: GTX1080Ti\r\n\r\n**Describe the current behavior**\r\nThe argument in merge_fn is the original input tensor.\r\n\r\n**Describe the expected behavior**\r\nAccording to the doc: \"merge_fn: Function that joins arguments from threads that are given as PerReplica\".\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport os\r\n\r\nimport tensorflow as tf\r\n\r\nif 'COLAB_TPU_ADDR' in os.environ:\r\n  resolver = tf.distribute.cluster_resolver.TPUClusterResolver(\r\n    tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\r\n  tf.config.experimental_connect_to_cluster(resolver)\r\n  tf.tpu.experimental.initialize_tpu_system(resolver)\r\n  strategy = tf.distribute.experimental.TPUStrategy(resolver)\r\nelse:\r\n  strategy = tf.distribute.MirroredStrategy()\r\n\r\n\r\n@tf.function\r\ndef step_fn():\r\n  v = tf.zeros([10])\r\n\r\n  def merge_fn(strategy, keys):\r\n    print(keys)\r\n\r\n  context = tf.distribute.get_replica_context()\r\n  context.merge_call(merge_fn, args=[v])\r\n\r\n\r\nstrategy.run(step_fn)\r\n```\r\n\r\n**Other info / logs** \r\n\r\nOn a two GPU machine, the output is\r\n```\r\nPerReplica:{\r\n  0: Tensor(\"zeros:0\", shape=(10,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0),\r\n  1: Tensor(\"replica_1/zeros:0\", shape=(10,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\r\n}\r\n```\r\nOn a Colab TPU, the output is\r\n```\r\nTensor(\"zeros:0\", shape=(10,), dtype=float32)\r\n```", "comments": ["In addition, the **strategy.run** has different behavior. Code to reproduce:\r\n```\r\nimport os\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.python.distribute import mirrored_strategy\r\nfrom tensorflow.python.tpu.ops import tpu_ops\r\n\r\nif 'COLAB_TPU_ADDR' in os.environ:\r\n  resolver = tf.distribute.cluster_resolver.TPUClusterResolver(\r\n    tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\r\n  tf.config.experimental_connect_to_cluster(resolver)\r\n  tf.tpu.experimental.initialize_tpu_system(resolver)\r\n  strategy = tf.distribute.experimental.TPUStrategy(resolver)\r\nelse:\r\n  strategy = tf.distribute.MirroredStrategy()\r\n\r\n\r\n@tf.function\r\ndef step_fn():\r\n  context = tf.distribute.get_replica_context()\r\n  v = tf.zeros([10], tf.int32) + context.replica_id_in_sync_group\r\n\r\n  def merge_fn(strategy, keys):\r\n    if isinstance(strategy, mirrored_strategy.MirroredStrategy):\r\n      keys = strategy.experimental_local_results(keys)\r\n      keys = tf.concat(keys, axis=0)\r\n    else:\r\n      keys = tpu_ops.all_to_all([keys for _ in range(8)], 0, 0, 8)\r\n    return keys\r\n\r\n  val = context.merge_call(merge_fn, args=[v])\r\n  return val\r\n\r\n\r\nret = strategy.run(step_fn)\r\nprint(ret)\r\n```\r\n\r\nResults on GPUs:\r\n```\r\ntf.Tensor([0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1], shape=(20,), dtype=int32)\r\n```\r\n\r\nResults on TPU\r\n```\r\nPerReplica:{\r\n  0: tf.Tensor(\r\n[[0 0 0 0 0 0 0 0 0 0]\r\n [1 1 1 1 1 1 1 1 1 1]\r\n [2 2 2 2 2 2 2 2 2 2]\r\n [3 3 3 3 3 3 3 3 3 3]\r\n [6 6 6 6 6 6 6 6 6 6]\r\n [7 7 7 7 7 7 7 7 7 7]\r\n [4 4 4 4 4 4 4 4 4 4]\r\n [5 5 5 5 5 5 5 5 5 5]], shape=(8, 10), dtype=int32),\r\n  1: tf.Tensor(\r\n[[0 0 0 0 0 0 0 0 0 0]\r\n [1 1 1 1 1 1 1 1 1 1]\r\n [2 2 2 2 2 2 2 2 2 2]\r\n [3 3 3 3 3 3 3 3 3 3]\r\n [6 6 6 6 6 6 6 6 6 6]\r\n [7 7 7 7 7 7 7 7 7 7]\r\n [4 4 4 4 4 4 4 4 4 4]\r\n [5 5 5 5 5 5 5 5 5 5]], shape=(8, 10), dtype=int32),\r\n  2: tf.Tensor(\r\n[[0 0 0 0 0 0 0 0 0 0]\r\n [1 1 1 1 1 1 1 1 1 1]\r\n [2 2 2 2 2 2 2 2 2 2]\r\n [3 3 3 3 3 3 3 3 3 3]\r\n [6 6 6 6 6 6 6 6 6 6]\r\n [7 7 7 7 7 7 7 7 7 7]\r\n [4 4 4 4 4 4 4 4 4 4]\r\n [5 5 5 5 5 5 5 5 5 5]], shape=(8, 10), dtype=int32),\r\n  3: tf.Tensor(\r\n[[0 0 0 0 0 0 0 0 0 0]\r\n [1 1 1 1 1 1 1 1 1 1]\r\n [2 2 2 2 2 2 2 2 2 2]\r\n [3 3 3 3 3 3 3 3 3 3]\r\n [6 6 6 6 6 6 6 6 6 6]\r\n [7 7 7 7 7 7 7 7 7 7]\r\n [4 4 4 4 4 4 4 4 4 4]\r\n [5 5 5 5 5 5 5 5 5 5]], shape=(8, 10), dtype=int32),\r\n  4: tf.Tensor(\r\n[[0 0 0 0 0 0 0 0 0 0]\r\n [1 1 1 1 1 1 1 1 1 1]\r\n [2 2 2 2 2 2 2 2 2 2]\r\n [3 3 3 3 3 3 3 3 3 3]\r\n [6 6 6 6 6 6 6 6 6 6]\r\n [7 7 7 7 7 7 7 7 7 7]\r\n [4 4 4 4 4 4 4 4 4 4]\r\n [5 5 5 5 5 5 5 5 5 5]], shape=(8, 10), dtype=int32),\r\n  5: tf.Tensor(\r\n[[0 0 0 0 0 0 0 0 0 0]\r\n [1 1 1 1 1 1 1 1 1 1]\r\n [2 2 2 2 2 2 2 2 2 2]\r\n [3 3 3 3 3 3 3 3 3 3]\r\n [6 6 6 6 6 6 6 6 6 6]\r\n [7 7 7 7 7 7 7 7 7 7]\r\n [4 4 4 4 4 4 4 4 4 4]\r\n [5 5 5 5 5 5 5 5 5 5]], shape=(8, 10), dtype=int32),\r\n  6: tf.Tensor(\r\n[[0 0 0 0 0 0 0 0 0 0]\r\n [1 1 1 1 1 1 1 1 1 1]\r\n [2 2 2 2 2 2 2 2 2 2]\r\n [3 3 3 3 3 3 3 3 3 3]\r\n [6 6 6 6 6 6 6 6 6 6]\r\n [7 7 7 7 7 7 7 7 7 7]\r\n [4 4 4 4 4 4 4 4 4 4]\r\n [5 5 5 5 5 5 5 5 5 5]], shape=(8, 10), dtype=int32),\r\n  7: tf.Tensor(\r\n[[0 0 0 0 0 0 0 0 0 0]\r\n [1 1 1 1 1 1 1 1 1 1]\r\n [2 2 2 2 2 2 2 2 2 2]\r\n [3 3 3 3 3 3 3 3 3 3]\r\n [6 6 6 6 6 6 6 6 6 6]\r\n [7 7 7 7 7 7 7 7 7 7]\r\n [4 4 4 4 4 4 4 4 4 4]\r\n [5 5 5 5 5 5 5 5 5 5]], shape=(8, 10), dtype=int32)\r\n}\r\n```", "@fengyang0317 \r\nWhile i run the code shared on tpu i face a different error, please find the [gist of the same](https://colab.sandbox.google.com/gist/Saduf2019/ff29cf83a0d2cd331dfca56867707cb9/tpu.ipynb)", "Could you run the code without '!pip install tf_nightly'. The code runs with 2.2.0rc4 in Colab.\r\nI think the error you get is caused by the unaligned TF version between Colab and TPU. Your Colab is tf-nightly and the TPU is using 2.2.0rc4.\r\n\r\nI started a stand-alone TPU node with TF nightly and did not meet the problem.", "Actually, I find that merge_call cannot enter the cross-replica context on TPU. The merge_fn is called on each replica. This behavior is different from GPU behavior and the document.", "I am able to replicate the issue reported, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/1ae9894150b4bb7f1ac95d8d33846ef7/untitled191.ipynb)", "Another question is the order of the all_gather output. Typically, the order is 0,1,2,3,6,7,4,5 according to device id.\r\n\r\nIs this order designed deliberately? Why not use the order 0,1,2,3,4,5,6,7?", "Was able to replicate the issue with TF 2.5,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/62ff44ac10d2819aad544db2cdb04285/untitled318.ipynb) ..Thanks!", "Was able to replicate the issue with TF 2.7, Attaching Gist of [GPU](https://colab.research.google.com/gist/mohantym/4930fb330fe50366c7ba6056aa51a972/untitled318.ipynb#scrollTo=MpmxhhpkUyqs) and [TPU](https://colab.research.google.com/gist/mohantym/513fd2056b6e9f9b9be3cb074669ff7e/untitled318.ipynb#scrollTo=6qurgSsdUu5d) for Reference. Thanks!"]}, {"number": 39268, "title": "Inconsistency in MirroredStrategy evaluation results for batch dependent metrics", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): colab (and from pip locally)\r\n- TensorFlow version (use command below): 2.2.0-rc4 (but also locally on 2.1)\r\n- Python version: 3.6.9 (and 3.6.8 locally) \r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: Quadro P50000 locally, colab otherwise\r\n\r\n**Describe the current behavior**\r\n\r\nWhen I use `MirroredStrategy` for model evaluation with whole-batch dependent metrics, there is some inconsistency in the metrics returned.\r\nThis has to do with the fact that the batches are separated before being sent to the different devices and the metrics are computed on each device before being averaged on the master device.\r\n\r\n**Describe the expected behavior**\r\n\r\nI would like the metrics evaluation to be independent of whether I use `MirroredStrategy` or not.\r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://colab.research.google.com/drive/1_Lohjz7qSjF7cGKCMO7F7-lIBDMTYJw5?usp=sharing\r\n\r\nYou can test that the metric computation is otherwise consistent by changing the flag to `False`.\r\n\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense\r\n\r\n\r\n# logical device separation\r\nphysical_devices = tf.config.list_physical_devices('GPU')\r\n\r\nif True:\r\n  tf.config.set_logical_device_configuration( \r\n      physical_devices[0], \r\n      [tf.config.LogicalDeviceConfiguration(memory_limit=8000), \r\n       tf.config.LogicalDeviceConfiguration(memory_limit=8000)])\r\n\r\n\r\n# my full batch dependent loss\r\ndef my_loss(y_true, y_pred):\r\n    return tf.reduce_max(tf.abs(y_true - y_pred))\r\n\r\n# my toy model\r\nmirrored_strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.ReductionToOneDevice())\r\nwith mirrored_strategy.scope():\r\n    model_distributed = Sequential(Dense(10))\r\n    model_distributed.compile(loss=my_loss)\r\n\r\n# my toy data\r\nx = tf.random.normal([32, 10])\r\ny = tf.random.normal([32, 10])\r\n\r\n# my experiments\r\nmetrics = model_distributed.evaluate(x, y)\r\nprint(metrics)\r\n\r\ny_pred = model_distributed.predict(x)\r\nprint(my_loss(y, y_pred))\r\n```\r\n\r\n**Other info / logs**\r\n\r\nA sample output from the previous code would for example be:\r\n```\r\n1/1 [==============================] - 0s 1ms/step - loss: 4.1214\r\n4.121423721313477\r\ntf.Tensor(4.1544814, shape=(), dtype=float32)\r\n```\r\n\r\nAn obvious solution is to not use `evaluate` but `predict` and iterate myself over the dataset (in my real use case I use a dataset and NCCL) computing the metrics myself. But I am then losing some nice properties of `evaluate` like the callbacks and I have to compute manually potentially a range of metrics.\r\n\r\nMaybe this isn't a bug but in which case it would be nice to have a warning in the docs. I also would like to know if there is a way to still use `evaluate` maybe with a custom `cross_device_ops`.", "comments": ["I have tried in colab with TF 2.2-rc3 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/dfeba6541562b066b70473c0e56a0e3d/untitled866.ipynb).Thanks!", "Whole batch dependent metrics are possible to implement if you create a custom metric: https://www.tensorflow.org/guide/keras/train_and_evaluate#custom_metrics. \r\n\r\nThis is how the standard metrics are implemented as well. In this you can define how each replica accumulates the results independently on their local batch, and how those values should be combined to give the final result. However, I think the only reduction types available currently are SUM and MEAN. We don't support MAX/MIN yet which is what you probably need for this case? \r\n\r\nYou can check our the inbuilt metrics implementations to see how they're made to work when used w distribution strategy: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/metrics.py\r\n\r\n", "Thanks for this info ! Can you point me to a specific metric which handles the distribution strategy, I didn't find one right away?\r\n\r\nRegarding the custom metric, I am not sure how the whole state thing works in the evaluation mode. I guess when fitting it just resets at every epoch, but what about when evaluating? Does it reset at every batch?\r\n\r\nIndeed I need something which can handle the max and the mean. Basically what I am trying to do is compute the PSNR of a whole volume given as a batch. The [formula](https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio) for the volume PSNR is `10 * log_10 (max(volume)**2 / mse(volume))`. Basically the `mse` over the volume could just be a mean reduction but then I need to compute the max over the volume and compute this `10 * log_10` operation.", "All the inbuilt metrics handle distribution strategy be defining update_state and result methods. There are wrappers for those in [metric_utils](https://github.com/tensorflow/tensorflow/blob/5d49dc5526324443931a33cc84d66c8bcae9cea2/tensorflow/python/keras/utils/metrics_utils.py#L63) which get used and handle the logic to make those methods work in distribution strategy context. \r\n\r\nBut all of them rely on averaging the underlying metric variables across replicas.. we don't support reduce_max yet across replicas. \r\n\r\nRe: state, metrics reset every epoch so I think in evaluation, they will not reset at all? @pavithrasv can confirm. ", "That's correct, they will not reset in evaluation.", "Ok too bad for the reduce_max. Maybe we should close this for the time being.", "Was able to replicate the issue with TF 2.5,please find the gist[ here](https://colab.research.google.com/gist/sushreebarsa/0e0f31dcdca22403f37732eee3ec276e/untitled866.ipynb#scrollTo=wjlNSm5QNx7d) ..Thanks!", "Was able to replicate this issue in [TF 2.7](https://colab.research.google.com/gist/mohantym/21cccf6c287482f3771d35e84271694a/untitled866.ipynb#scrollTo=wjlNSm5QNx7d) too .Thanks!"]}, {"number": 39263, "title": "Remove GCC_HOST_COMPILER_PREFIX as it may be out of sync with GCC_HOST_COMPILER_PATH", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL 7.5\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.2.0\r\n- Python version: 3.7.4\r\n- Bazel version (if compiling from source): 2.0.0\r\n- GCC/Compiler version (if compiling from source): 7.3.0\r\n\r\n\r\n**Describe the problem**\r\n\r\nThe file https://github.com/tensorflow/tensorflow/blob/1588f45ee56860d247a1c26ea228cb3721b4bf1b/third_party/gpus/cuda_configure.bzl has a documented environment variable `GCC_HOST_COMPILER_PATH` to set the path (or name) of a GCC host compiler. However it also uses an undocumented variable `GCC_HOST_COMPILER_PREFIX` to get the folder where the gcc binary resides (guessing from name) defaulting to `/usr/bin` if it isn't set:\r\nhttps://github.com/tensorflow/tensorflow/blob/1588f45ee56860d247a1c26ea228cb3721b4bf1b/third_party/gpus/cuda_configure.bzl#L1028-L1030\r\n\r\nI have 2 problems with that:\r\n- It is undocumented and hence hard to set right if you don't know for sure what it is\r\n- The default is wrong when the (documented!) `GCC_HOST_COMPILER_PATH`  is used\r\n\r\nThis leads to issues such as \r\n\r\n```\r\n external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -o bazel-out/k8-opt/bin/external/protobuf_archive/js_embed -Wl,-no-as-needed -pie -Wl,-z,relro,-z,now '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -no-canonical-prefixes -B/usr/bin -Wl,--gc-sections -Wl,@bazel-out/k8-opt/bin/external/protobuf_archive/js_embed-2.params)\r\n/usr/bin/ld.gold: error: /software/software/GCCcore/7.3.0/lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o: unsupported reloc 42 against global symbol _ITM_deregisterTMCloneTable\r\n/usr/bin/ld.gold: error: /software/software/GCCcore/7.3.0/lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o: unsupported reloc 42 against global symbol _ITM_registerTMCloneTable\r\n/usr/bin/ld.gold: error: bazel-out/k8-opt/bin/external/protobuf_archive/_objs/js_embed/embed.o: unsupported reloc 42 against global symbol std::ios_base::Init::~Init()\r\n/software/software/GCCcore/7.3.0/lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o(.text+0x1a): error: unsupported reloc 42\r\n/software/software/GCCcore/7.3.0/lib/gcc/x86_64-pc-linux-gnu/7.3.0/crtbeginS.o(.text+0x6b): error: unsupported reloc 42\r\nbazel-out/k8-opt/bin/external/protobuf_archive/_objs/js_embed/embed.o:embed.cc:function _GLOBAL__sub_I_main: error: unsupported reloc 42\r\ncollect2: error: ld returned 1 exit status\r\n```\r\n\r\nAs reported at https://github.com/easybuilders/easybuild-easyconfigs/pull/7800#issuecomment-471447493\r\n\r\nI hence propose to either completely remove that variable in favor of deriving its value from `GCC_HOST_COMPILER_PATH` or properly documenting it with a better default.\r\n\r\nIt does not seem to be required at all so it's likely best to just remove it. This should have been done by #34218 but for some reason that merge was reverted with a very misleading commit title: https://github.com/tensorflow/tensorflow/commit/f0571998d0195b5b243cf409a64d5fa17bd44d43\r\n\r\n@gunan @mihaimaruseac please take a look what went wrong", "comments": ["Before that flag was introduced we hard-coded -B/usr/bin, which is arguably significantly worse :)\r\n-B/usr/bin was needed because currently the toolchain is not good at figuring out where other binutils are when they are not in the same path as the compiler, which is a not uncommon setup for people building their own compilers.", "The right solution is to actually discover all binutils via PATH, like other build systems would.", "From the comment:\r\n\r\n     # TODO: when bazel stops adding '-B/usr/bin' by default, remove this\r\n     #       flag from the CROSSTOOL completely (see\r\n     #       https://github.com/bazelbuild/bazel/issues/563\r\n\r\nAnd as explained in #34202:\r\n\r\n> As the underlying Bazel issue bazelbuild/bazel#5634 is resolved, this code can (and should) go now\r\n\r\nSo I don't see why setting this is still required. And I also disagree with \"Before that flag was introduced\": That flag was never documented as far as I can tell. So are people supposed to use/rely on it?\r\n\r\nFor another datapoint: In Easybuild (install automation tool) we patch that file to set this to empty since forever as adding `/usr/bin` leads to (the mentioned) problems and haven't had any issues.\r\n\r\nAdditionally the removal was already accepted and merged (twice!) but has been removed again, I guess due to a mistake as no indication for a reason is visible and the commit message of https://github.com/tensorflow/tensorflow/commit/f0571998d0195b5b243cf409a64d5fa17bd44d43 is clearly wrong", "We're currently using this in our cross-compilation setup. We use a cross-compiler gcc for manylinux, but the host system's binutils. Removing this will get rolled back until somebody has time to hunt down regressions, root-cause them and then figure out how we'll need to adapt our setup. I think you're right that it can be removed, but it's a bit of work to change & test everything that relies on it.\r\n\r\nRe: the commit message: what's wrong about it?", "It also looks like there are still open issues in bazel around this:\r\nhttps://github.com/bazelbuild/bazel/issues/6834", "> We're currently using this in our cross-compilation setup.\r\n\r\nCan you clarify what exactly you mean by \"this\"?   \r\nEspecially did you try with #34218 applied (i.e. `cuda_defines[\"%{linker_bin_path}\"] = \"\"`)? I'd expect not setting the path would make it pick the binutils from PATH.\r\n\r\nOk just read the linked bazel issue and it seems PATH is discarded by Bazel.\r\n\r\nThen the comment quoted above (`when bazel stops adding '-B/usr/bin' by default, remove this`) is clearly wrong. This results in my second alternative of the proposal: \"properly documenting it with a better default.\"\r\n\r\nSo at the very least it should be documented because as the linked commit from bazelbuild/bazel#6834 states:\r\n> and [adding /usr/bin] was done to get Tensor Flow building on some (but failing on other?) versions of RedHat\r\n\r\nSo there are known failures with that added as well as without it. I'm wondering why it is now only done for the CUDA toolchain though and not for anything else.\r\n\r\n> Re: the commit message: what's wrong about it?\r\n\r\nThe commit message is \"Merge pull request #34218 from Flamefire:fix_missing_linker_path\" but it does revert that merge. Also interesting: The merge commit has a green CI tick while the revert commit has a failed CI tick :shrug: \r\n\r\nSo summary:\r\n- Check if that `linker_bin_path` setting is still required and remove if not. Otherwise:\r\n- Document `GCC_HOST_COMPILER_PREFIX` like the other variables\r\n- Opt (but recommended) default to the path of the `GCC_HOST_COMPILER`, maybe checking if binutils can be found there. IMO this is the right thing because having binutils separate is the exception rather than the norm.\r\n\r\nEdit: Oh and maybe don't name it  `GCC_HOST_COMPILER_PREFIX` if it is the `HOST_BINUTILS_PATH`", "@Flamefire Could you please let us know if this issue still persists ? If it it resolved then please feel free to move this issue to close status ? Thanks!", "Yes, the comment from https://github.com/tensorflow/tensorflow/issues/39263#issuecomment-627207228 still applies as-is with latest master. See the summary there"]}, {"number": 39173, "title": "tf.keras.metrics.MeanIoU API is practically unusable without a threshold", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip3\r\n- TensorFlow version (use command below): 2.1.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\n\r\ntf.keras.metrics.MeanIoU's constructor implementation does not take a threshold or list of thresholds as input argument. This is not only inconsistent the API used by other metrics (e.g. tf.keras.metrics.TruePositives, tf.keras.metrics.FalseNegatives) but also renders the API practically unusable because the outputs (i.e. predictions) from a network would generally be probability values in range from 0 to 1 and not a perfect 0 or 1 values. Hence, unless the constructor takes thresholds as argument and applies it to predictions before computing IoU, it is practically useless. It would always end up showing 0.5, or 0.25 or whatever the baseline random guess IOU happens to be in a given problem. \r\n\r\n**Describe the expected behavior**\r\n\r\ntf.keras.metrics.MeanIoU constructor should take threshold values as input and also apply those before computing the IoU.\r\n\r\n**Standalone code to reproduce the issue**\r\nNone required because the docs https://www.tensorflow.org/api_docs/python/tf/keras/metrics/MeanIoU proves the point where it only shows a example where preds are already binary values. \r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@dd1923,\r\nOn running the usage example given in the [MeanIoU documentation](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/MeanIoU), the output I got was similar to the example. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/4ee1f3307e5ceb596b6c6628408ecd17/39173.ipynb).\r\n\r\nCould you please provide a minimal code sample to reproduce the issue reported here. Thanks!", "@amahendrakar That was my point. Did you read my post above? \r\nMean IOU, implemented as a metric, is pretty much unusable without a threshold.\r\nYou can try replacing 1 values in pred to 0.9 in your example and see the output.", "Was able to reproduce the issue with [TF v2.1](https://colab.research.google.com/gist/amahendrakar/d79131d083e48803fbe32b9ed3fd5c43/39173-2-1.ipynb), [TF v2.2.0-rc4](https://colab.research.google.com/gist/amahendrakar/d375b59b12d50c91dcd8d474b274fe32/39173.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/8ab2ef9f8ff4d22de6e32aabbf29eced/39173-tf-nightly.ipynb). Please find the attached gist. Thanks!", "@pavithrasv any idea on when will this be addressed? Seems like a minor change on API side but it carries big impact on usability. ", "@dd1923 do you need threshold or something like argmax that choose the index with maximum probability?", "Need threshold to stay consistent with the rest of the API. See TruePositives, FalsePositives etc implementations https://www.tensorflow.org/api_docs/python/tf/keras/metrics/TruePositives?hl=TR", "> Need threshold to stay consistent with the rest of the API. See TruePositives, FalsePositives etc implementations https://www.tensorflow.org/api_docs/python/tf/keras/metrics/TruePositives?hl=TR\r\n\r\nI'm not sure this can be consistent -- it looks like `TruePositives` requires `y_pred` to be probabilities, i.e., [batch_size, H*W, n_classes], which is where `threshold` makes sense to label the output as either 0 or 1. Meanwhile `MeanIOU` requires `y_pred` to be predicted class id, i.e., [batch_size, H*W]\r\n\r\nI'd rather think the right way is allow this metrics to accept `y_pred` as probabilities and do argmax under the hood.", "First, at-least the docs of TruePositives and MeanIoU refer `y_pred` as `y_pred | The predicted values.`\r\n\r\nSecond,  on the docs it says IOU is defined as follows: `IOU = true_positive / (true_positive + false_positive + false_negative)` so it seems logical to me to think that if all the inputs of IoU function (namely true positives, false_positives and false negatives) work on thresholds then the resulting metric would also work on thresholds.\r\n\r\nThird, how would argmax handle the case of having 1 in more than one output classes?\r\n\r\nI think something along the lines of the following in the `update_state` method would do the trick, right before calling current implementation of update_state (for atleast the case where threshold is one value):\r\n\r\n\r\n`y_pred = tf.where(condition=tf.math.greater(y_pred, tf.cast(threshold, y_pred.dtype)),\r\n                          x=tf.cast(1.0, y_pred.dtype), y=y_pred)`\r\n\r\n `y_pred = tf.where(condition=tf.math.less_equal(y_pred, tf.cast(threshold, y_pred.dtype)),\r\n                          x=tf.cast(0.0, y_pred.dtype), y=y_pred)`", "Ok you want multilabel support, in that case having `threshold` makes sense", "@dd1923 Sorry about the delay. Will you be interested in sending a PR for this with test cases? I'll be happy to review and merge the change.", "A potential workaround I found on this stack overflow (https://stackoverflow.com/questions/60507120/how-to-correctly-use-the-tensorflow-meaniou-metric):\r\n\r\n\r\nclass MyMeanIOU(tf.keras.metrics.MeanIoU):\r\n\r\n    def update_state(self, y_true, y_pred, sample_weight=None):\r\n        return super().update_state(y_true, tf.argmax(y_pred, axis=-1), sample_weight)\r\n\r\nIn this case my y_true was a mask of shape batch,256,256,1 where the pixel values in the last dimension were 0,1 or 2. Then my y_pred was shape batch,256,256,3. This way the argmax takes from probability -> class value. Hope that helps!", "@pavithrasv I've opened #47410 , could you take a look and share your thoughts on the best way to make the changes to the `meanIoU()` interface?"]}, {"number": 39167, "title": "tf.io.gfile.listdir is inconsistent between GCS dir and local dir - adds trailing slashes", "body": "\r\n**System information**\r\n- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0\r\n- Python version: 3.6\r\n\r\n**Describe the current behavior**\r\n\r\nWhen listing the directory items for a GCS dir, listdir returns names with trailing slashes. \r\nWhen listing the directory items for a local dir, listdir returns names without trailing slashes. \r\n\r\n**Describe the expected behavior**\r\n\r\nThe behavior needs to be consistent.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\ntensorflow.io.gfile.listdir('gs://bucket/dir')\r\n>>> ['eval/', 'train/']\r\n\r\ntensorflow.io.gfile.listdir('..')\r\n>>> ['eval', 'train']\r\n```", "comments": ["Can you please test if this also happens on 2.2-rc4? On tf-nightly?", "> Can you please test if this also happens on 2.2-rc4?\r\n\r\nI've tested this on 2.2.0. It's still broken.\r\n\r\n\r\n```\r\ntensorflow.io.gfile.listdir('gs://gcp-public-data-landsat')\r\n\r\n...\r\n 'LC08/',\r\n 'LE00/',\r\n 'LE07/',\r\n 'LM01/',\r\n 'LM02/',\r\n 'LM03/',\r\n 'LM04/',\r\n 'LM05/',\r\n 'LO08/',\r\n 'LT00/',\r\n 'LT04/',\r\n 'LT05/',\r\n 'LT08/']\r\n```\r\n\r\n```\r\ntensorflow.io.gfile.listdir('..')\r\n\r\n['sys',\r\n 'opt',\r\n 'boot',\r\n 'bin',\r\n 'home',\r\n 'usr',\r\n...\r\n```", "Does still reproduce in tf-nightly? I recall sending a change that touched the `/` at the end of the paths.", "@Ark-kun \r\nPlease update as per above comment, If this is still an issue in nightly. ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39167\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39167\">No</a>\n", "This should be fixed in the 2.4 release, after [rewriting implementation](https://cs.opensource.google/tensorflow/tensorflow/+/master:tensorflow/core/platform/file_system_helper.cc;l=123-266;drc=8b5b9dc96666a3a5d27fad7179ff215e3b74b67c)", "Still the case with TF 2.4.1.\r\nLocal dir - no trailing slashes\r\ns3 bucket - no trailing slashes\r\ngcs bucket - WITH trailing slashes\r\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39167\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39167\">No</a>\n", "Can it be protected from auto-closing since it's clearly not fixed and easy to reproduce?", "I am facing this issue now as well on 2.4. Definitely not resolved. I will not be following this every month to make sure it doesn't go  stale, but wanted to let someone know.", "still the case in 2.5", "@Ark-kun ,\r\nIs this still an issue? Could you please confirm in TensorFlow latest stable version v.2.7. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39167\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39167\">No</a>\n", "> @Ark-kun , Is this still an issue? Could you please confirm in TensorFlow latest stable version v.2.7. Thanks!\r\n\r\n@tilakrayal \r\nYes, it's still an issue in 2.7.0. I'm not sure this issue will fix itself without an explicit fix.\r\n\r\n/reopen"]}, {"number": 39152, "title": "TensorFlow can't be build for PS4 using Orbis LLVM compiler", "body": "I tried to build TensorFlow for PS4. I added custom toolchain to bazel (and tested it on simple c++ project), but when I started to build Tensorflow I got a lot of errors.\r\n\r\nIs it possible to resolve it? Current TensorFlow code can't get license for PS4 publishing.\r\n\r\n```\r\n[0 / 1,100] [Prepa] Creating source manifest for //tensorflow:tensorflow.dll\r\nERROR: C:/users/user/_bazel_user/6p42r4kl/external/com_google_protobuf/BUILD:295:1: C++ compilation of rule '@com_google_protobuf//:protoc_lib' failed (Exit 1)\r\nIn file included from external/com_google_protobuf/src/google/protobuf/compiler/code_generator.cc:39:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/compiler/plugin.pb.h:24:\r\nexternal/com_google_protobuf/src\\google/protobuf/arena.h:541:15: error: use of typeid requires enabling RTTI\r\n    AllocHook(RTTI_TYPE_ID(T), n);\r\n              ^\r\nexternal/com_google_protobuf/src\\google/protobuf/arena.h:194:30: note: expanded from macro 'RTTI_TYPE_ID'\r\n#define RTTI_TYPE_ID(type) (&typeid(type))\r\n                             ^\r\nexternal/com_google_protobuf/src\\google/protobuf/arena.h:604:15: error: use of typeid requires enabling RTTI\r\n    AllocHook(RTTI_TYPE_ID(T), n);\r\n              ^\r\nexternal/com_google_protobuf/src\\google/protobuf/arena.h:194:30: note: expanded from macro 'RTTI_TYPE_ID'\r\n#define RTTI_TYPE_ID(type) (&typeid(type))\r\n                             ^\r\nIn file included from external/com_google_protobuf/src/google/protobuf/compiler/code_generator.cc:39:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/compiler/plugin.pb.h:26:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/generated_message_table_driven.h:34:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/map.h:49:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/map_type_handler.h:34:\r\nexternal/com_google_protobuf/src\\google/protobuf/parse_context.h:251:3: error: no type named 'uintptr_t' in namespace 'std'; did you mean simply 'uintptr_t'?\r\n  std::uintptr_t aliasing_ = kNoAliasing;\r\n  ^~~~~\r\ntoolchain/orbis/target/include\\sys/_types/_uintptr_t.h:13:22: note: 'uintptr_t' declared here\r\ntypedef __uintptr_t             uintptr_t;\r\n                                ^\r\nIn file included from external/com_google_protobuf/src/google/protobuf/compiler/code_generator.cc:39:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/compiler/plugin.pb.h:26:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/generated_message_table_driven.h:34:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/map.h:49:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/map_type_handler.h:34:\r\nexternal/com_google_protobuf/src\\google/protobuf/parse_context.h:225:38: error: no type named 'uintptr_t' in namespace 'std'; did you mean simply 'uintptr_t'?\r\n        aliasing_ = reinterpret_cast<std::uintptr_t>(flat.data()) -\r\n                                     ^~~~~\r\ntoolchain/orbis/target/include\\sys/_types/_uintptr_t.h:13:22: note: 'uintptr_t' declared here\r\ntypedef __uintptr_t             uintptr_t;\r\n                                ^\r\nIn file included from external/com_google_protobuf/src/google/protobuf/compiler/code_generator.cc:39:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/compiler/plugin.pb.h:26:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/generated_message_table_driven.h:34:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/map.h:49:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/map_type_handler.h:34:\r\nexternal/com_google_protobuf/src\\google/protobuf/parse_context.h:226:38: error: no type named 'uintptr_t' in namespace 'std'; did you mean simply 'uintptr_t'?\r\n                    reinterpret_cast<std::uintptr_t>(buffer_);\r\n                                     ^~~~~\r\ntoolchain/orbis/target/include\\sys/_types/_uintptr_t.h:13:22: note: 'uintptr_t' declared here\r\ntypedef __uintptr_t             uintptr_t;\r\n                                ^\r\nIn file included from external/com_google_protobuf/src/google/protobuf/compiler/code_generator.cc:39:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/compiler/plugin.pb.h:26:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/generated_message_table_driven.h:34:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/map.h:49:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/map_type_handler.h:34:\r\nexternal/com_google_protobuf/src\\google/protobuf/parse_context.h:336:40: error: cannot initialize object parameter of type 'google::protobuf::internal::EpsCopyInputStream' with an expression of type 'google::protobuf::internal::ParseContext'\r\n  bool Done(const char** ptr) { return DoneWithCheck(ptr, group_depth_); }\r\n                                       ^~~~~~~~~~~~~\r\nexternal/com_google_protobuf/src\\google/protobuf/parse_context.h:337:51: error: cannot initialize object parameter of type 'google::protobuf::internal::EpsCopyInputStream' with an expression of type 'google::protobuf::internal::ParseContext'\r\n  bool DoneNoSlopCheck(const char** ptr) { return DoneWithCheck(ptr, -1); }\r\n                                                  ^~~~~~~~~~~~~\r\nexternal/com_google_protobuf/src\\google/protobuf/parse_context.h:359:33: error: cannot initialize object parameter of type 'google::protobuf::internal::EpsCopyInputStream' with an expression of type 'google::protobuf::internal::ParseContext'\r\n    if (PROTOBUF_PREDICT_FALSE(!ConsumeEndGroup(tag))) return nullptr;\r\n                                ^~~~~~~~~~~~~~~\r\nexternal/com_google_protobuf/src\\google/protobuf/port_def.inc:217:53: note: expanded from macro 'PROTOBUF_PREDICT_FALSE'\r\n#define PROTOBUF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                                    ^\r\nIn file included from external/com_google_protobuf/src/google/protobuf/compiler/code_generator.cc:39:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/compiler/plugin.pb.h:26:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/generated_message_table_driven.h:34:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/map.h:49:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/map_type_handler.h:34:\r\nexternal/com_google_protobuf/src\\google/protobuf/parse_context.h:472:8: error: no type named 'uint32_t' in namespace 'std'; did you mean simply 'uint32_t'?\r\n  for (std::uint32_t i = 0; i < 4; i++) {\r\n       ^~~~~\r\ntoolchain/orbis/target/include\\sys/_types/_uint32_t.h:13:20: note: 'uint32_t' declared here\r\ntypedef __uint32_t      uint32_t;\r\n                        ^\r\nIn file included from external/com_google_protobuf/src/google/protobuf/compiler/code_generator.cc:39:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/compiler/plugin.pb.h:26:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/generated_message_table_driven.h:34:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/map.h:49:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/map_type_handler.h:34:\r\nexternal/com_google_protobuf/src\\google/protobuf/parse_context.h:475:25: error: no type named 'uint64_t' in namespace 'std'; did you mean simply 'uint64_t'?\r\n    res += (static_cast<std::uint64_t>(tmp) - 2) << (14 * (i + 1) - 1);\r\n                        ^~~~~\r\ntoolchain/orbis/target/include\\sys/_types/_uint64_t.h:13:21: note: 'uint64_t' declared here\r\ntypedef __uint64_t              uint64_t;\r\n                                ^\r\nIn file included from external/com_google_protobuf/src/google/protobuf/compiler/code_generator.cc:39:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/compiler/plugin.pb.h:26:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/generated_message_table_driven.h:34:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/map.h:49:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/map_type_handler.h:34:\r\nexternal/com_google_protobuf/src\\google/protobuf/parse_context.h:476:36: error: no member named 'int16_t' in namespace 'std'\r\n    if (PROTOBUF_PREDICT_TRUE(std::int16_t(tmp) >= 0)) {\r\n                              ~~~~~^\r\nexternal/com_google_protobuf/src\\google/protobuf/port_def.inc:206:55: note: expanded from macro 'PROTOBUF_PREDICT_TRUE'\r\n#define PROTOBUF_PREDICT_TRUE(x) (__builtin_expect(!!(x), 1))\r\n                                                      ^\r\nIn file included from external/com_google_protobuf/src/google/protobuf/compiler/code_generator.cc:39:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/compiler/plugin.pb.h:26:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/generated_message_table_driven.h:34:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/map.h:49:\r\nIn file included from external/com_google_protobuf/src\\google/protobuf/map_type_handler.h:34:\r\nexternal/com_google_protobuf/src\\google/protobuf/parse_context.h:575:14: error: cannot initialize object parameter of type 'google::protobuf::internal::EpsCopyInputStream' with an expression of type 'google::protobuf::internal::ParseContext'\r\n  auto old = PushLimit(ptr, size);\r\n             ^~~~~~~~~\r\nexternal/com_google_protobuf/src\\google/protobuf/parse_context.h:691:7: error: cannot initialize object parameter of type 'google::protobuf::internal::EpsCopyInputStream' with an expression of type 'google::protobuf::internal::ParseContext'\r\n      ctx->SetLastTag(tag);\r\n      ^~~\r\n13 errors generated.\r\nTarget //tensorflow:tensorflow.dll failed to build\r\nINFO: Elapsed time: 196.531s, Critical Path: 2.13s\r\nINFO: 5 processes: 5 local.\r\nFAILED: Build did NOT complete successfully\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\n```\r\nINFO: Analyzed target //tensorflow:tensorflow (164 packages loaded, 13275 targets configured).\r\nINFO: Found 1 target...\r\n[0 / 975] [Prepa] BazelWorkspaceStatusAction stable-status.txt\r\nERROR: C:/users/user/_bazel_user/6p42r4kl/external/com_google_protobuf/BUILD:295:1: C++ compilation of rule '@com_google_protobuf//:protoc_lib' failed (Exit 1)\r\nexternal/com_google_protobuf/src/google/protobuf/compiler/subprocess.cc:41:10: fatal error: 'signal.h' file not found\r\n#include <signal.h>\r\n         ^~~~~~~~~~\r\n1 error generated.\r\nTarget //tensorflow:tensorflow failed to build\r\nERROR: D:/workspace/tensorflow-build/target/tensorflow/tensorflow/c/BUILD:120:1 C++ compilation of rule '@com_google_protobuf//:protoc_lib' failed (Exit 1)\r\n\r\n```\r\n\r\nWhat parts of TF can we rewrite to get appropriate PS4 lib?", "comments": ["There is my **cc_toolchain_config.bzl**\r\n\r\n```\r\nload(\"@bazel_tools//tools/cpp:cc_toolchain_config_lib.bzl\",\r\n     \"feature\",\r\n     \"flag_group\",\r\n     \"flag_set\",\r\n     \"tool_path\")\r\nload(\"@bazel_tools//tools/build_defs/cc:action_names.bzl\", \"ACTION_NAMES\")\r\n\r\ndef _impl(ctx):\r\n    tool_paths = [\r\n        tool_path(\r\n            name = \"gcc\",\r\n            path = \"orbis/host_tools/bin/orbis-clang.exe\",\r\n        ),\r\n        tool_path(\r\n            name = \"ld\",\r\n            path = \"orbis/host_tools/bin/orbis-ld.exe\",\r\n        ),\r\n        tool_path(\r\n            name = \"ar\",\r\n            path = \"/bin/false\",\r\n        ),\r\n        tool_path(\r\n            name = \"cpp\",\r\n            path = \"orbis/host_tools/bin/orbis-clang++.exe\",\r\n        ),\r\n        tool_path(\r\n            name = \"gcov\",\r\n            path = \"/bin/false\",\r\n        ),\r\n        tool_path(\r\n            name = \"nm\",\r\n            path = \"/bin/false\",\r\n        ),\r\n        tool_path(\r\n            name = \"objdump\",\r\n            path = \"/bin/false\",\r\n        ),\r\n        tool_path(\r\n            name = \"strip\",\r\n            path = \"/bin/false\",\r\n        ),\r\n    ]\r\n\r\n    toolchain_include_directories_feature = feature(\r\n        name = \"toolchain_include_directories\",\r\n        enabled = True,\r\n        flag_sets = [\r\n            flag_set(\r\n                actions = [\r\n                    ACTION_NAMES.assemble,\r\n                    ACTION_NAMES.preprocess_assemble,\r\n                    ACTION_NAMES.linkstamp_compile,\r\n                    ACTION_NAMES.c_compile,\r\n                    ACTION_NAMES.cpp_compile,\r\n                    ACTION_NAMES.cpp_header_parsing,\r\n                    ACTION_NAMES.cpp_module_compile,\r\n                    ACTION_NAMES.cpp_module_codegen,\r\n                    ACTION_NAMES.lto_backend,\r\n                    ACTION_NAMES.clif_match,\r\n                ],\r\n                flag_groups = [\r\n                    flag_group(\r\n                        flags = [\r\n                            \"-isystem\",\r\n                            \"toolchain/orbis/host_tools/lib/clang/include\",\r\n                            \"-isystem\",\r\n                            \"toolchain/orbis/target/include\",\r\n                            \"-isystem\",\r\n                            \"toolchain/orbis/target/include_common\",\r\n                        ],\r\n                    ),\r\n                ],\r\n            ),\r\n        ],\r\n    )\r\n\r\n    return cc_common.create_cc_toolchain_config_info(\r\n        ctx = ctx,\r\n        toolchain_identifier = \"orbis-toolchain\",\r\n        host_system_name = \"windows\",\r\n        target_system_name = \"x86_64-unknown-orbis\",\r\n        target_cpu = \"x86_64\",\r\n        target_libc = \"unknown\",\r\n        compiler = \"orbis\",\r\n        abi_version = \"unknown\",\r\n        abi_libc_version = \"unknown\",\r\n        tool_paths = tool_paths,\r\n        features = [toolchain_include_directories_feature],\r\n        cxx_builtin_include_directories = [\"orbis/host_tools/lib/clang/include\",\"orbis/target/include\",\"orbis/target/include_common\"]\r\n    )\r\n\r\ncc_toolchain_config = rule(\r\n    implementation = _impl,\r\n    attrs = {},\r\n    provides = [CcToolchainConfigInfo],\r\n)\r\n```\r\n\r\nAnd **BUILD** file\r\n\r\n```\r\npackage(default_visibility = ['//visibility:public'])\r\n\r\nfilegroup(name = \"empty\")\r\n\r\nload(\":cc_toolchain_config.bzl\", \"cc_toolchain_config\")\r\n\r\ncc_toolchain_config(name = \"orbis_toolchain_config\")\r\n\r\ncc_toolchain(\r\n    name = \"orbis_toolchain\",\r\n    toolchain_identifier = \"orbis-toolchain\",\r\n    toolchain_config = \":orbis_toolchain_config\",\r\n    all_files = \":empty\",\r\n    compiler_files = \":empty\",\r\n    dwp_files = \":empty\",\r\n    linker_files = \":empty\",\r\n    objcopy_files = \":empty\",\r\n    strip_files = \":empty\",\r\n    supports_param_files = 0,\r\n)\r\n\r\ncc_toolchain_suite(\r\n    name = \"orbis\",\r\n    toolchains = {\r\n        \"x86_64\": \":orbis_toolchain\",\r\n    },\r\n)\r\n\r\n```", "Also I added following lines to **.bazelrc**:\r\n\r\n```\r\n# Orbis\r\nbuild:orbis --crosstool_top=//toolchain:orbis\r\nbuild:orbis --host_crosstool_top=@bazel_tools//tools/cpp:toolchain\r\nbuild:orbis --cpu=x86_64\r\n```\r\n\r\nAnd build by:\r\n\r\n```\r\nbazel build --config=orbis tensorflow:tensorflow --verbose_failures\r\nbazel build --config=orbis tensorflow:tensorflow.dll --verbose_failures\r\nbazel build --config=orbis tensorflow:libtensorflow.so --verbose_failures\r\n```", "Not a good assignee unfortunately.", "This is not a configuration we officially support, and unfortunately I will not be able to allocate proper amount of time to debug this.\r\nHowever, what you pasted above are all bazel configs. \r\nI would recommend reaching out to bazel team for help first. Then you should maybe start by creating a simple hello world program with the toolchain above with your compiler. Once that is working, then you may be able to get TF building.", "I successfully built the Hello World program. But TensorFlow gave the errors.", "I see, sorry for missing the error message you shared.\r\nFrom what I can tell, the build failed when it failed to find \"signal.h\" header. It means either your toolchain is misconfigured so this header cannot be found, or on the target platform this header just does not exist.\r\n\r\nUnfortunately, I am not knowledgeable about the target system to be able to comment on this. And this is not a system we in TensorFlow team have any experience on. Therefore, I will mark this community support.", "Just another bit of information. Looks like your build has failed when building protobuf. It did not even get to try building TF code. So a smaller example to iterate on can be protobuf build."]}, {"number": 39149, "title": "Rank-k cholesky up/downdates", "body": "**System information**\r\n- TensorFlow version (you are using): 2.1.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\n**Problem statement:** Given a positive-definite matrix `A` (n by n) with known Cholesky factor `L` (lower triangular), and another matrix `V` (n by k), compute the Cholesky up/down-dates of `A` with respect to `VV.T`, namely find *lower-triangular matrices* `M` and `K` such that `M M.T = A + V V.T` and  `K K.T = A - V V.T` (assuming the second is positive definite).\r\n\r\nIn my code I do this the costly way, by computing `A +/- V V.T` and then calling `tf.linalg.cholesky` on it. This takes O(n^3) time whereas this computation can be done in O(kn^2) time. This speedup is especially important as datasets grow (as n grows). For examples of algorithms that achieve this complexity see this [report by Seeger](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.585.5275&rep=rep1&type=pdf) and this [report by Walder](https://arxiv.org/abs/1011.1173). LINPACK implementations for [updates](http://www.netlib.no/netlib/linpack/dchud.f) and [downdates](http://www.netlib.no/netlib/linpack/dchdd.f) already exist and are [being used in R](https://www.rdocumentation.org/packages/SamplerCompare/versions/1.3.0/topics/chud).\r\n\r\n**Currently:** The operator `tf.linalg.LinearOperatorLowRankUpdate` can be used to perform low-rank updates (i.e. compute `A +/- V V.T` from `A`) but what we are interested in is the Cholesky of `A +/- V V.T`. Using `tf.linalg.cholesky` computes the factor afresh, and does not exploit the fact that we know `L`.\r\n\r\n**Desired feature:** Can we make a `tf.linalg.cholesky_rank_k_update` method which performs up/down-dates in O(kn^2) time?\r\n\r\n**Will this change the current api? How?**\r\nThis could involve a new method as part of `tf.linalg`. However, I'm not sure what could be the best way to integrate this new functionality. Input and guidance on this and any other points of this request would be much appreciated!\r\n\r\n**Who will benefit with this feature?**\r\nPotentially many users in the ML community, working in applications which require this operation. I intend to use this feature for Gaussian Processes, but it would also be useful for many other applications in linear-algebraic and statistical problems. For example, if you want to up/down-date the Cholesky of large covariance matrix by a lower-rank matrix, for example to sample data from the up/down-dated Gaussian, you would benefit quite a bit from this speedup.\r\n", "comments": ["@rmlarsen for FYI", "@csuter fyi", "For `k = 1` there is https://www.tensorflow.org/probability/api_docs/python/tfp/math/cholesky_update."]}, {"number": 39142, "title": "Adding Tab press for showing available methods and autocompletion for objects", "body": "**Describe the feature and the current behavior/state.**\r\nPressing the `tab` button does not show methods or autocomplete already defined objects when using Jupyter notebooks.\r\n\r\nI tried this solution [https://stackoverflow.com/questions/54281719/how-to-get-code-completion-in-a-jupyter-notebook-running-in-docker](url). It didn't do anything when I tried it though.\r\n\r\n`%config IPCompleter.greedy=True`\r\n\r\nExample of how it works in Jupyter notebook when installed with conda.\r\n```\r\nimport pandas as pd\r\npd.<tab_here>   # should show all availabe methods e.g. pd.read_csv(), pd.read_excel(), etc.\r\n```\r\n\r\n**System information**\r\nI used the following below and the feature was missing. I don't know if it has been addressed or fixed in the new versions.\r\n- TensorFlow Docker Image:  tensorflow/tensorflow:2.1.0-gpu-py3-jupyter\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- GPU model and memory: 1080Ti\r\n- Are you willing to contribute it (Yes/No): No because I don't know how to implement it.\r\n\r\n**Will this change the current api? How?**\r\nI don't think so. It's just an add-on I think.\r\n\r\n**Who will benefit with this feature?**\r\nThe showing of methods is a behavior that works when installing jupyter from conda and I would say is a standard feature in Jupyter notebooks. I've never seen anybody that couldn't hit tab and pull up methods or had autocomplete. It helps the user so they can see what options they have to call. This can save a massive amount of time and help the user be much more efficient.", "comments": ["Hi @pdubz-sudo ! \r\nCould you please try on latest stable version of TF 2.6 or nightly and let us know if this is still an issue.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "@mohantym Hey there! I tried the nightly build but the jupyter notebook didn't have the method list and autocomplete.\r\n\r\nFor example, doing `tf.__` and then hitting `tab` will have a drop down list of all the available methods which one can then choose from."]}, {"number": 39094, "title": "Add Bluetooth support to send Box Locations array", "body": "**System information**\r\n- Tensorflow Lite\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nAdd support to send box locations over Bluetooth\r\n\r\n**Who will benefit with this feature?**\r\n\r\nDevelopers on automation projects\r\n", "comments": ["For the completeness of the issue, perhaps you can elaborate more on this feature, what you are trying to do/use case?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "I am trying to send the array containing the recognized objects box location over Bluetooth to an HC-06 module. I get a null pointer exception when trying to get the array:\r\n\r\n`'void org.tensorflow.lite.examples.detection.LocationSender.send_location(float, float, float, float)' on a null object reference`\r\n\r\nPlease feel free to look at this only for detailed information.\r\n\r\nhttps://stackoverflow.com/questions/61553898/tensorflow-lite-android-object-detection-example-send-box-locations-over-blue\r\n"]}, {"number": 39056, "title": "Serializing a tensor and writing to tf.train.Example from within a graph", "body": "I would like to write tensorflow example records to a TFRecordWriter from inside an AutoGraph generated graph. I am running inference at scale over millions of examples and so don't want to collect all results in memory, but write them out as I go. I'm reading from a dataset.\r\nRunning everything inside a graph is way faster than breaking out every batch to process and save results.  So I just want to be able to write results from within the graph.\r\n\r\nThe documentation for tensorflow 2.0 states the following:\r\n\r\n> The simplest way to handle non-scalar features is to use tf.serialize_tensor to convert tensors to binary-strings. Strings are scalars in tensorflow.\r\n\r\nHowever, `tf.io.serialize_tensor` returns a tensor of byte-string. Creating an Example proto requires a bytes list, not a tensor.\r\n\r\nHow do I write a tf.train.Example to a tf record from inside a graph?\r\n\r\nCode to reproduce:\r\n\r\n```\r\n%tensorflow_version 2.x\r\nimport tensorflow as tf\r\n\r\n@tf.function\r\ndef example_write():\r\n  writer = tf.io.TFRecordWriter(\"test.tfr\")\r\n  x = tf.constant([[0, 1], [2, 3]])\r\n  x = tf.io.serialize_tensor(x)\r\n  feature = {\r\n      \"data\": tf.train.Features(\r\n        bytes_list=tf.train.BytesList(value=[x]))\r\n  }\r\n  ex = tf.train.Example(features=tf.train.Features(\r\n      feature=feature))\r\n  writer.write(ex.SerializeToString())\r\n\r\nexample_write()\r\n```\r\n\r\nand the error\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-6-df8a97eb17c9> in <module>()\r\n     12   writer.write(ex.SerializeToString())\r\n     13 \r\n---> 14 example_write()\r\n\r\n8 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    966           except Exception as e:  # pylint:disable=broad-except\r\n    967             if hasattr(e, \"ag_error_metadata\"):\r\n--> 968               raise e.ag_error_metadata.to_exception(e)\r\n    969             else:\r\n    970               raise\r\n\r\nTypeError: in user code:\r\n\r\n    <ipython-input-6-df8a97eb17c9>:6 example_write  *\r\n        feature = {\r\n\r\n    TypeError: <tf.Tensor 'SerializeTensor:0' shape=() dtype=string> has type Tensor, but expected one of: bytes\r\n```", "comments": ["@apcode \r\nThis question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged//tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n", "I have asked on SO, with no response.\r\n\r\nHaving looked into it, I might do two things:\r\n1) file a bug on the documentation which clearly states you can use tf.io.serialize_tensor to convert a tensor to a byte stream. Which it does not. It converts it to a tensor of type tf.string. So it cannot be used as the documentation suggests.\r\n\r\n2) File a feature request to be able to write tf records of tf examples from within a graph. None of the TFRecordWriter classes take a tensor!!", "I just modified your code a bit and end up with this:\r\n\r\n    def _bytes_feature(value):\r\n      \"\"\"Returns a bytes_list from a string / byte.\"\"\"\r\n      return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\r\n\r\n\r\n    @tf.function\r\n    def example_write():\r\n\r\n        writer = tf.io.TFRecordWriter(\"test.tfr\")\r\n\r\n        g = tf.Graph()\r\n\r\n        with g.as_default():\r\n            x = tf.constant([[[0, 1], [2, 3]],[[1, 1], [2, 2]]], dtype=tf.float32)\r\n            x = tf.io.serialize_tensor(x)\r\n\r\n        with tf.compat.v1.Session(graph=g).as_default() as sess:\r\n            x_feat = x.eval()\r\n\r\n        print(x_feat)\r\n        feature = {\r\n              \"data\": _bytes_feature(x_feat)\r\n            }\r\n\r\n        ex = tf.train.Example(features=tf.train.Features(\r\n            feature=feature))\r\n\r\n        writer.write(ex.SerializeToString())\r\n\r\n    example_write()\r\n\r\nThe key of this code is eval your \"x\" to end up with byte data, which could be consumed by tf.train.BytesList\r\nMy English is not good, so if you need more clarify, just comment below", "I think when you call eval() you take this out of the graph so when you write it out you're not doing so inside the computation graph. IIUC.", "Right. As the tf.train.BytesList only receive byte data, we must call eval() to take value from tensor. This small graph is just made for serialize tensor, so we don't need to put it inside computation graph.", "This would also be very helpful for me, preferably without requiring `tf.py_function`", "If you are serializing many tensors in a loop, say if you were creating `Example` objects, it would be more efficient to use the `.numpy()` method of the tensor, rather than creating an execution graph each time. So:\r\n```python\r\nx = tf.constant([[[0, 1], [2, 3]],[[1, 1], [2, 2]]], dtype=tf.float32)\r\nxs = tf.io.serialize_tensor(x.numpy())\r\n```", "@apcode ,\r\nCan you please try the code as [commented](https://github.com/tensorflow/tensorflow/issues/39056#issuecomment-748243172) in latest stable v2.7 and let us know if the issue still persists.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "@tilakrayal your \"commented\" link links to this thread, not the tensorflow documentation. I presume you mean the serialize_tensor page:  https://www.tensorflow.org/api_docs/python/tf/io/serialize_tensor", "Looking at this comment in https://www.tensorflow.org/api_docs/python/tf/io/serialize_tensor\r\n\r\n```\r\nfeature_of_bytes = tf.train.Feature(\r\n  bytes_list=tf.train.BytesList(value=[serialized_nonscalar.numpy()]))\r\nfeature_of_bytes\r\n\r\n# followed by \r\nwriter.write(example)\r\n\r\n```\r\n\r\nIt calls serialized_nonscalar.numpy().  So this takes it out of the graph IIUC.\r\n\r\nMy original problem was I was processing 100Ms of examples and it was extremely slow to keep jumping out of the graph to store a tf.train.Example. E.g. using tf.io.write_file(serialized_tensor) to save results inside the graph would take approx 1-2 hours to process 100Ms examples.  Having to leave the graph to save a tensor, such as calling tensor.numpy() would take over 24 hours for the same 100Ms examples.  Not insignificant.\r\n\r\nI think this problem is due to writing to a TFRecord from a Tensor, which is not possible.\r\n\r\nThe only way I can see to write to a file from within the graph is using  tf.io.write_file(serialized_tensor)\r\nThis file writing function seems to be the only one that takes a tensor and writes it to a file inside the computation graph.\r\n\r\nSo above does not resolve my problem because I cannot write tfrecords of examples from inside the computation graph.\r\n\r\nMy work around of just writing serialized tensors to a file using tf.io.write_file() works but not ideal as I have to post process these tensors into tf records.\r\n"]}, {"number": 39050, "title": "tf.nn.depthwise_conv2d with rank=1 kernels (separable filters)", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using):\r\nnigthly\r\n- Are you willing to contribute it (Yes/No):\r\nno\r\n\r\n**Describe the feature and the current behavior/state.**\r\nThere is a thread about twice calling DepWhiseConv2d TF ops when we have rank=1 kernels (separable filters) VS a single call to DepWhiseConv2d with 2d kernel.\r\nI suppose that is would be hard to fuse on trace two DepWhiseConv2d on the separable filter.\r\nSo I was asking why with the current DepWhiseConv2d in TF doesn't handle the kernel rank=1 case with an parameter for down the stack compiler/transformations (kernel size, input size, device type, etc.).\r\n\r\n**Will this change the current api? How?**\r\nYes\r\n**Who will benefit with this feature?**\r\nSeparable filters (gaussian blur, etc)\r\n**Any Other info.**\r\nSee https://github.com/tensorflow/addons/pull/1450#issuecomment-621351753 with follow-up @alextp and @rmlarsen comments.", "comments": ["@bhack @alextp  @rmlarsen  According to me this should be implemented in all other conv ops where this situation may arise like along wiith depthwise conv operation- Conv2D, Conv3D,...\r\n(If at all implementation is needed)", "/cc @jpienaar ", "Is the proposal here that DepthwiseConv2dNative (for different dimensions) has an additional attribute to say that is separable and in which case it gets a rank 1 kernel. And allows backends to decide whether they want to implement that as a single call with 2D kernel or 2 calls of DepthwiseConv2dNative with said rank 1 kernel? The rationale being that matching these two calls would be too difficult/fragile?\r\n\r\nSo it isn't a case where one would have\r\n\r\n%5 = tf.SomeKernelGeneration()\r\n%10 = DepthwiseConv2dNative(..., %5)\r\n%20 = DepthwiseConv2dNative(%10 ..., %5)\r\n\r\nand need to find cases where you have 1 dephtwise conv feeding into a next and they both share the same kernel, and if so one can convert to the other call form?", "I think that the framework can analyze if the  kernel Is rank==1. \nThen down to the stack It can see if it wants to separate the kernel reasoning on different parameters (input size, kernel size, hardware factors etc..). ", "Any news on this? We are adding a Gaussian filter again in Keras-cv:\n\nhttps://github.com/keras-team/keras-cv/pull/143"]}, {"number": 38943, "title": "Using tf.data.Dataset has big overhead", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL 7.5\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.1.0\r\n- Python version: 3.7.4\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: GTX 1080\r\n\r\n**Describe the current behavior**\r\n\r\nUsing a `Dataset` reduces performance by a small but significant amount, ~7% for ImageNet like data\r\n\r\n**Describe the expected behavior**\r\n\r\nUsing `Dataset` has no or only marginal performance impact\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom timeit import timeit\r\n\r\n\r\n@tf.function\r\ndef train_step(x, y):\r\n    model.train_on_batch(x, y)\r\n\r\n\r\nfor useData in (True, False):\r\n    model = tf.keras.applications.ResNet50(weights=None, classes=1000)\r\n    model.compile(\r\n        loss=tf.losses.SparseCategoricalCrossentropy(),\r\n        optimizer=tf.keras.optimizers.SGD(),\r\n        metrics=['accuracy'],\r\n        experimental_run_tf_function=True)\r\n\r\n    if useData:\r\n        x = tf.random.uniform([1, 32, 224, 224, 3])\r\n        y = tf.random.uniform([1, 32, 1], minval=0, maxval=999, dtype=tf.int64)\r\n        dataset = tf.data.Dataset.from_tensor_slices((x, y)).repeat()\r\n\r\n        def train(steps):\r\n            for x, y in dataset.take(steps):\r\n                train_step(x, y)\r\n    else:\r\n        x = tf.random.uniform([32, 224, 224, 3])\r\n        y = tf.random.uniform([32, 1], minval=0, maxval=999, dtype=tf.int64)\r\n\r\n        def train(steps):\r\n            for _ in range(steps):\r\n                train_step(x, y)\r\n\r\n    # warmup\r\n    train(2)\r\n    t = timeit(lambda: train(50), number=10)\r\n    print('useData: %s -> %s' % (useData, t))\r\n```\r\n\r\nSample output:\r\nuseData: True -> 89.92945478390902\r\nuseData: False -> 86.73652107780799\r\n\r\nFor more realistic training loops (e.g. including callbacks) the difference is even bigger.\r\nSome of my tests:\r\n\r\n```\r\nconstant: total images/sec: 496.47 (calculation(497.53) + preprocessing(1.06)) \r\ndataset:  total images/sec: 465.09 (calculation(478.64) + preprocessing(13.55)) \r\n```\r\n\r\nFirst number is calculated from training loop execution time (after warmup) the latter only the train-step and the difference (to the first number) which I called \"preprocessing\" as it is iterating over the dataset (calling next on the iterator by the for loop) and hence dominated by preprocessing functions if present (none here) including the `repeat` and `take` Dataset adapters.\r\n\r\nSo 2 conclusions: Getting elements from the iterator seems to be quite costly (1->13.6) and even the training loop itself gets slower (498 -> 479)\r\n\r\nThis would be a reason to avoid the dataset API.", "comments": ["Hi @Flamefire  Could you try some thing like this:\r\n```\r\nif useData:\r\n    x = tf.random.uniform([1, 32, 224, 224, 3])\r\n    y = tf.random.uniform([1, 32, 1], minval=0, maxval=999, dtype=tf.int64)\r\n    dataset = tf.data.Dataset.from_tensor_slices((x, y)).repeat()\r\n\r\n    def train(steps):\r\n        dataset = dataset.batch(batch_size=steps)\r\n        dataset = dataset.prefetch(1)\r\n        for x, y in dataset:\r\n            train_step(x, y)\r\n```\r\nWhat's the performance data?", "Did another experiment: Adding `@tf.function` above the `train` function slows it down significantly and using the dataset is now twice as fast:\r\n\r\n```\r\nuseData: True -> 165.09024090506136\r\nuseData: False -> 380.11968565313146\r\n```\r\n\r\nNot sure if that changes semantics though and it can't be easily done for the \"real\" code as some callbacks can't be run inside a tf.function\r\n\r\n> dataset = dataset.batch(batch_size=steps)\r\n\r\n`steps` is the number of batches, not the batch_size. The batch_size is 32 (wanted to avoid the batch layer which likely makes it worse, hence that is included in the uniform call already)\r\n\r\nPutting the `prefetch(1)` after the `take` (used to limit number of batches) it makes execution slighly slower, but can be called the same as difference is small: `useData: True -> 88.12129278900102`", "@Flamefire \r\nI ran the code shared and face [indentation errors](https://colab.sandbox.google.com/gist/Saduf2019/549fb894061cfdf050e0eb39040c108b/38943.ipynb), please provide complete code with all dependencies and indentation such that we could replicate the error faced.\r\nIf possible please provide colab gist for us to analyse the error faced.", "Yes, seems that I missed the code tags on Github, see the updated code above (the loop contents was not indented)", "@Flamefire \r\nI ran the code shared and face a different error, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/7d9a22a20bcb5c7e49ea6a70a8db2602/38943.ipynb)", "@Saduf2019 There seems to be an issue with your Colab instance and/or way of installing TF 2.1.0. I just verified this code locally on a system without a GPU and on our cluster with a GPU and it is working fine. Even if that error shown was be valid, it would be yet another bug of TF as the code is supposed to work according to the TF documentation (see \"custom training loop\")\r\n\r\nExample why your Colab instance is erroneous: Part of the call stack is\r\n\r\n```\r\n    578         xla_context.Exit()\r\n    579     else:\r\n--> 580       result = self._call(*args, **kwds)\r\n    581 \r\n    582     if tracing_count == self._get_tracing_count():\r\n```\r\n\r\nThe related code on my system and on Github is: https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/eager/def_function.py#L568\r\n\r\nAs you can see the line numbers don't match so your Colab instance is using another version of TF\r\n\r\nI restarted the colab you posted myself and it seems to be doing something, i.e. not immediately failing with an error. As it seems to be using CPU it's running for ages now. I'd suggest trying with a GPU where runtime is a few seconds.", "@Flamefire \r\nI ran the code on gpu, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/a69b82f1ab451fd6da3cf50f76c55da7/2.ipynb) and confirm if it replicated your issue.", "@Saduf2019 Yes this seems to work. The speed difference in that colab is only a bit more than 1% though, so I guess the used GPU is rather slow (total time is ~200s where on my machine it is ~90s)\r\n\r\nSeeing the difference from using tf.data.Dataset getting smaller the longer the GPU takes for training is expected so yes that replicates the issue.", "@Flamefire The `tf.data.Dataset` example is slicing a 4D tensor into a 3D tensor (which requires copying the data every step), while the non-Dataset code starts with 3D tensors and therefore doesn't need to copy. To compare apples to apples here, you should define the Dataset data with\r\n```\r\nx = tf.random.uniform([32, 224, 224, 3])\r\ny = tf.random.uniform([32, 1], minval=0, maxval=999, dtype=tf.int64)\r\ndataset = tf.data.Dataset.from_tensors((x, y)).repeat()\r\n```", "@aaudiber Thanks for the suggestion. I'd very much expected the trivial copy to be completely overlapped by the computation of the not-so-small Resnet especially as `prefetch` was used with no difference\r\n\r\nTried your suggestion anyway:   \r\nWith `from_tensor_slices` and `prefetch(1)`:\r\n```\r\nuseData: True -> 89.55927550140768\r\nuseData: False -> 87.00254090223461\r\n```\r\n\r\nWith `from_tensors` and `prefetch(1)`:\r\n```\r\nuseData: True -> 88.65487134549767\r\nuseData: False -> 86.93021802790463\r\n```\r\n\r\nSo you can see there is an effect but using the dataset is still slower especially as no real work is done by it.\r\n\r\nFor reference the update code:\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom timeit import timeit\r\n\r\n\r\n@tf.function\r\ndef train_step(x, y):\r\n    model.train_on_batch(x, y)\r\n\r\n\r\nfor useData in (True, False):\r\n    model = tf.keras.applications.ResNet50(weights=None, classes=1000)\r\n    model.compile(\r\n        loss=tf.losses.SparseCategoricalCrossentropy(),\r\n        optimizer=tf.keras.optimizers.SGD(),\r\n        metrics=['accuracy'],\r\n        experimental_run_tf_function=True)\r\n\r\n    if useData:\r\n        x = tf.random.uniform([32, 224, 224, 3])\r\n        y = tf.random.uniform([32, 1], minval=0, maxval=999, dtype=tf.int64)\r\n        dataset = tf.data.Dataset.from_tensors((x, y)).repeat()\r\n\r\n        def train(steps):\r\n            for x, y in dataset.take(steps).prefetch(1):\r\n                train_step(x, y)\r\n    else:\r\n        x = tf.random.uniform([32, 224, 224, 3])\r\n        y = tf.random.uniform([32, 1], minval=0, maxval=999, dtype=tf.int64)\r\n\r\n        def train(steps):\r\n            for _ in range(steps):\r\n                train_step(x, y)\r\n\r\n    # warmup\r\n    train(2)\r\n    t = timeit(lambda: train(50), number=10)\r\n    print('useData: %s -> %s' % (useData, t))\r\n\r\n```", "Thanks @Flamefire. \r\n\r\nThis is a difficult case for `tf.data.Dataset` because there isn't any preprocessing. `tf.data.Dataset` usually does preprocessing on the CPU, then transfers the data to the GPU afterward. The `tf.data.Dataset` example is slower because it is copying the tensors from GPU memory to CPU memory and back each time, while the non-Dataset example starts with the tensors on the GPU and doesn't need to move them at all since there isn't any preprocessing.\r\n\r\nIdeally we could use [tf.data.experimental.prefetch_to_device](https://www.tensorflow.org/api_docs/python/tf/data/experimental/prefetch_to_device) to prefetch to the GPU and recover the performance, but there is currently an outstanding bug with [prefetch_to_device](https://github.com/tensorflow/tensorflow/pull/37277#issuecomment-620202464). Once that gets fixed, the performance should be almost identical when using `prefetch_to_device`.", "I would also add that instead of having to explicitly take care of prefetching to device yourself through an experimental API, the recommended alternative is to use the tf.distribute API, which would takes care of prefetching to the device.", "I'm surprised by that because a) preprocessing could be much faster on GPU (in case it becomes a bottleneck) and b) it is usually practice to overlap host<->device copies with computation. Not having that by default with TF sounds like a major oversight.\r\n\r\nCan you elaborate what you mean by using the `tf.distribute` API? I would have expected that using a strategy like `OneDeviceStrategy(device='/gpu:0')` and placing the model and dataset definition inside that would be enough. But that didn't have any effect.\r\n\r\nAgain I'd expect the strategy and/or at least the fit/train_on_batch to be smart enough to overlap copies and computation", "The issue still persists in TF 2.4: https://colab.research.google.com/gist/Saduf2019/a69b82f1ab451fd6da3cf50f76c55da7/2.ipynb"]}]