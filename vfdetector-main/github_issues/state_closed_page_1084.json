[{"number": 20751, "title": "bug in tf.Print summarized formatting", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: YES\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.8\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\nIf you print a tensor of shape [n, 4] with tf.Print, by default (summarize=3 is the default value), you get:\r\n\r\n[[9 21 55]...]\r\n\r\nwhich wrongly looks like your tensor is of shape [n, 3].\r\n\r\nThe correct output should be:\r\n\r\n[[9 21 55...]...]\r\n\r\nHere is what you get with tf.Print(summarize=10):\r\n\r\n[[9 21 55 30][190 -42 236 4][89 -5]...]\r\n\r\nNow the vectors of size 4 are visible although the last one is still wrong (looks like a vector of size 2\r\n)", "comments": ["Added a PR #20768 for the fix.", "Nagging Assignee @poxvoculi: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 20750, "title": "RunOptions.FULL_TRACE produce wrong timestamps", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:binary\r\n- **TensorFlow version (use command below)**:v1.9.0-0-g25c197e023 1.9.0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**:n/a\r\n- **GCC/Compiler version (if compiling from source)**:n/a\r\n- **CUDA/cuDNN version**:9.0.176/7.1.1\r\n- **GPU model and memory**:P100 16G (can reproduce on other GPU model as well)\r\n- **Exact command to reproduce**: see below\r\n\r\n```python\r\n#!/usr/bin/env python\r\n# -*- coding: utf-8 -*-\r\n\r\nimport sys\r\nimport os\r\nimport tqdm\r\nfrom datetime import datetime\r\nimport tensorflow as tf\r\nfrom tensorflow.python.client import timeline\r\n\r\ndef build():\r\n    image = tf.random_normal(shape=[64,32,32,3], dtype=tf.float32)\r\n    label = tf.random_uniform(shape=[64], maxval=10, dtype=tf.int32)\r\n    l = tf.transpose(image, [0, 3, 1, 2])\r\n    for k in range(1, 100):\r\n        l = tf.layers.conv2d(l, 16, 3, data_format='channels_first',\r\n                name='conv{}'.format(k), padding='SAME')\r\n    l = tf.reduce_mean(l, [2, 3])\r\n\r\n    logits = tf.layers.dense(l, 10, name='linear')\r\n    cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)\r\n    cost = tf.reduce_mean(cost, name='cross_entropy_loss')\r\n    return cost\r\n\r\nif __name__ == '__main__':\r\n    with tf.device('/gpu:0'):\r\n        cost1 = build()\r\n    with tf.device('/gpu:1'), tf.variable_scope(tf.get_variable_scope(), reuse=True):\r\n        cost2 = build()\r\n    cost = cost1 + cost2\r\n    opt = tf.train.GradientDescentOptimizer(0.1)\r\n    train_op = opt.minimize(cost)\r\n\r\n    def write_tracing(idx, metadata):\r\n        tl = timeline.Timeline(step_stats=metadata.step_stats)\r\n        fname = os.path.join(\r\n            '.', 'chrome-trace-{}.json'.format(idx))\r\n        with open(fname, 'w') as f:\r\n            f.write(tl.generate_chrome_trace_format(\r\n                show_dataflow=True, show_memory=True))\r\n\r\n    config = tf.ConfigProto()\r\n    config.allow_soft_placement = True\r\n    with tf.Session(config=config) as sess:\r\n        sess.run(tf.global_variables_initializer())\r\n        opt = tf.RunOptions()\r\n        opt.trace_level = tf.RunOptions.FULL_TRACE\r\n\r\n        for k in tqdm.trange(100):\r\n            meta = tf.RunMetadata()\r\n            sess.run(train_op, options=opt, run_metadata=meta)\r\n\r\n            write_tracing(k, meta)\r\n\r\n            for devst in meta.step_stats.dev_stats:\r\n                for ns in devst.node_stats:\r\n                    micro = timestamp = ns.all_start_micros // 1000000\r\n                    timestamp = datetime.fromtimestamp(timestamp)\r\n                    diff = timestamp - datetime.now()\r\n                    if diff.days > 100:\r\n                        print(k, micro, timestamp)\r\n                        #import IPython as IP; IP.embed()\r\n                        #sys.exit()\r\n```\r\n\r\nThe code above trains a CNN on two GPUs with `FULL_TRACE` enabled. The returned profiling information contains correct timestamps, but sometimes contains timestamps that are many years in the future. It prints the following output:\r\n```\r\n...\r\n13 18446744073 2554-07-21 16:34:33                                                                                                                                                                  \r\n13 18446744073 2554-07-21 16:34:33               \r\n13 18446744073 2554-07-21 16:34:33                                                                                                                                                                  \r\n13 18446744073 2554-07-21 16:34:33               \r\n13 18446744073 2554-07-21 16:34:33               \r\n13 18446744073 2554-07-21 16:34:33                                                                                                                                                                  \r\n13 18446744073 2554-07-21 16:34:33               \r\n13 18446744073 2554-07-21 16:34:33                                                                                                                                                                  \r\n13 18446744073 2554-07-21 16:34:33               \r\n13 18446744073 2554-07-21 16:34:33               \r\n13 18446744073 2554-07-21 16:34:33\r\n...\r\n```\r\n\r\nThe issue was originally reported at https://github.com/tensorpack/tensorpack/issues/819.\r\nThe issue is more likely to happen after running about 50 steps.\r\nThe issue seems to disappear when training on one GPU, or training a small model.", "comments": ["@zheng-xq Can you have a look at this? Seems possibly GPU-related.", "@zheng-xq @tensorflowbutler  @ppwwyyxx \r\nIt seems like a problem in calling the cupti func:\r\ntensorflow\\core\\platform\\default\\gpu\\cupti_wrapper.cc\r\nCuptiWrapper::ActivityGetNextRecord -> cuptiActivityGetNextRecord\r\nAs the cupti-api reference mentioned, the reason is lack of device memory,is there anyway to resolve this problem?\r\nOr am I miss anything?\r\nLook forward to your reply.\r\n\r\nIt will return 0 timestamp on some CUPTI_ACTIVITY_KIND_CONCURRENT_KERNEL kernels in my testing.\r\nLOG:\r\n2018-08-21 11:37:10.099749: W tensorflow/core/platform/default/device_tracer.cc:583] ActivityCallback kernel->start:0 kernel->end:0 kernel->deviceId:0 kernel->streamId:13 kernel->correlationId:8928781\r\n2018-08-21 11:37:10.099759: W tensorflow/core/platform/default/device_tracer.cc:583] ActivityCallback kernel->start:0 kernel->end:0 kernel->deviceId:0 kernel->streamId:13 kernel->correlationId:8928789\r\n\r\nCupti func reference:\r\nhttps://www.cs.rit.edu/~ark/cuda/doc/html/cupti/group__CUPTI__ACTIVITY__API.html\r\n\r\nInputs the previous record returned by cuptiActivityGetNextRecord and returns the next activity record from the buffer. If input value is NULL, returns the first activity record in the buffer. **Records of kind CUPTI_ACTIVITY_KIND_CONCURRENT_KERNEL may contain invalid (0) timestamps, indicating that no timing information could be collected for lack of device memory.**", "Nagging Assignee @ymodak: It has been 45 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "CC @nluehr \r\n\r\nThis looks like an issue with CUPTI. Nathan, could you help us triage this issue?\r\n\r\nThanks in advance!", "I can reproduce this on CUDA 9.0, but it appears to be fixed in CUDA 10.0.", "Thanks Nathan for the quick update. Closing this issue.\r\n\r\n@ppwwyyxx feel free to re-open if the issue persists with CUDA 10 as well."]}, {"number": 20749, "title": "[XLA][AMDGPU] enable AMDGPU target", "body": "Enable AMDGPU target in XLA GPU build", "comments": ["@jlebar This is the very first PR related to enabling AMDGPU target for XLA. I tried to make this PR minimal and doesn't depend on the bigger PR #20277 which is still under review.", "@qlzh727 would you be willing to merge this for us?", "The build error in XLA test target could be resulted from recent TableGen separation in upstream LLVM between AMDGPU and legacy R600 architecture. I'll update the PR.", "@jlebar / @d0k I've revised the PR to address build issues encountered earlier. Could you review once again? Thanks.\r\n\r\nMoving forward I think it'd be good to open source the script to generate `llvm.autogenerated.BUILD`.", "@d0k should review this, as I'm not familiar with the correct output here.", "@jlebar, at least one googler need to approve the PR. Can u add your review/approval?", "We have an internal change to do this which should subsume this PR.  @d0k will comment here once that's submitted, then we should just be able to close this as a nop.", "ee9a16b2032c8cb96180b0e81fbae3076b54a883 should do it. I hope I got everything right."]}, {"number": 20748, "title": "Miss a '.support'", "body": "https://github.com/tensorflow/tensorflow/blob/365d2fc4d62540b2c6524500a7a58e7edab0dfa9/tensorflow/contrib/lite/java/demo/app/build.gradle#L47\r\n\r\nIt should be com.android.support.test instead of com.androidx.test. Otherwise, gradle will report an error", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Fix is merged."]}, {"number": 20747, "title": "TPU code running locally but not on TPU", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes, I did put the code below\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian 9\r\n- **TensorFlow installed from (source or binary)**: already installed while creating the VM\r\n- **TensorFlow version (use command below)**: 1.9.0-rc2\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: Not compiled\r\n- **GCC/Compiler version (if compiling from source)**: Not compiled\r\n- **CUDA/cuDNN version**: not installed\r\n- **GPU model and memory**: no GPU\r\n- **Exact command to reproduce**: ```python3 test.py --tpu=$TPU_NAME --model_dir=output -use-tpu=True --batch_size=24```\r\n\r\n### Describe the problem\r\nWhen I run the following code:\r\n\r\n```python\r\nfrom tensorflow.python.keras.applications.vgg16 import VGG16\r\nfrom tensorflow.python.keras import models\r\nfrom tensorflow.python.keras import layers\r\nfrom tensorflow.python.keras.preprocessing import image\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.python import keras\r\nfrom absl import flags\r\nimport absl.logging as _logging\r\nfrom tensorflow.contrib.tpu.python.tpu import tpu_config\r\nfrom tensorflow.contrib.tpu.python.tpu import tpu_estimator\r\nfrom tensorflow.contrib.tpu.python.tpu import tpu_optimizer\r\nimport numpy as np\r\nimport random\r\nimport math\r\nimport os\r\n\r\n\r\n#  Cloud TPU Cluster Resolver flags\r\ntf.flags.DEFINE_string(\r\n    \"tpu\", default=None,\r\n    help=\"The Cloud TPU to use for training. This should be either the name \"\r\n    \"used when creating the Cloud TPU, or a grpc://ip.address.of.tpu:8470 \"\r\n    \"url.\")\r\ntf.flags.DEFINE_string(\r\n    \"tpu_zone\", default=None,\r\n    help=\"[Optional] GCE zone where the Cloud TPU is located in. If not \"\r\n    \"specified, we will attempt to automatically detect the GCE project from \"\r\n    \"metadata.\")\r\ntf.flags.DEFINE_string(\r\n    \"gcp_project\", default=None,\r\n    help=\"[Optional] Project name for the Cloud TPU-enabled project. If not \"\r\n    \"specified, we will attempt to automatically detect the GCE project from \"\r\n    \"metadata.\")\r\n\r\n# Model specific parameters\r\ntf.flags.DEFINE_string(\r\n    \"master\", default=None,\r\n    help=\"GRPC URL of the master (e.g. grpc://ip.address.of.tpu:8470). You \"\r\n    \"must specify either this flag or --tpu.\")\r\ntf.flags.DEFINE_string(\"data_dir\", \"\",\r\n                       \"Path to directory containing the dataset\")\r\ntf.flags.DEFINE_string(\"model_dir\", 'output', \"Estimator model_dir\")\r\ntf.flags.DEFINE_integer(\"batch_size\", 3,\r\n                        \"Mini-batch size for the training. Note that this \"\r\n                        \"is the global batch size and not the per-shard batch.\")\r\ntf.flags.DEFINE_integer(\"train_steps\", 1, \"Total number of training steps.\")\r\ntf.flags.DEFINE_float(\"learning_rate\", 0.001, \"Learning rate.\")\r\n\r\ntf.flags.DEFINE_bool(\"use_tpu\", True, \"Use TPUs rather than plain CPUs\")\r\ntf.flags.DEFINE_integer(\"iterations\", 1,\r\n                        \"Number of iterations per TPU training loop.\")\r\ntf.flags.DEFINE_integer(\"num_shards\", 8, \"Number of shards (TPU chips).\")\r\n\r\nFLAGS = tf.flags.FLAGS\r\n\r\nfeature_names = [\r\n    'query',\r\n    'positive',\r\n    'negative']\r\n\r\ndef load_triplets():\r\n    triplets = []\r\n    triplet_file = os.path.join(FLAGS.data_dir, 'triplets.txt')\r\n    with tf.gfile.GFile(triplet_file) as f:\r\n        count = 0\r\n        for line in f:\r\n            triplets.append(line.strip().split(','))\r\n            count += 1\r\n            if count % 1000 == 0:\r\n                tf.logging.info(\"Loading {} triplets\".format(count))\r\n\r\n    tf.logging.info(\"Loading {} triplets\".format(count))\r\n    return triplets\r\n\r\ndef my_input_fn(triplet, label):\r\n    query_img = tf.image.decode_jpeg(triplet[0], channels=3)\r\n    query_img.set_shape([None, None, None])\r\n    query_img = tf.image.resize_images(query_img, [225, 225])\r\n    query_img.set_shape([225, 225, 3])\r\n    positive_img = tf.image.decode_jpeg(tf.read_file(triplet[1]), channels=3)\r\n    positive_img.set_shape([None, None, None])\r\n    positive_img = tf.image.resize_images(positive_img, [225, 225])\r\n    positive_img.set_shape([225, 225, 3])\r\n    negative_img = tf.image.decode_jpeg(tf.read_file(triplet[2]), channels=3)\r\n    negative_img.set_shape([None, None, None])\r\n    negative_img = tf.image.resize_images(negative_img, [225, 225])\r\n    negative_img.set_shape([225, 225, 3])\r\n\r\n    return dict(zip(feature_names, [query_img, positive_img, negative_img])), label\r\n\r\ndef random_flip_left_right(image, label):\r\n    augmented_query = tf.to_float(image['query'])\r\n    augmented_query = tf.image.random_flip_left_right(image['query'])\r\n    augmented_query = tf.cast(augmented_query, np.uint8)\r\n    augmented_positive = tf.to_float(image['positive'])\r\n    augmented_positive = tf.image.random_flip_left_right(image['positive'])\r\n    augmented_positive = tf.cast(augmented_positive, np.uint8)\r\n    augmented_negative = tf.to_float(image['negative'])\r\n    augmented_negative = tf.image.random_flip_left_right(image['negative'])\r\n    augmented_negative = tf.cast(augmented_negative, np.uint8)\r\n\r\n    return dict(zip(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\r\n\r\ndef random_flip_up_down(image, label):\r\n    augmented_query = tf.to_float(image['query'])\r\n    augmented_query = tf.image.random_flip_up_down(image['query'])\r\n    augmented_query = tf.cast(augmented_query, np.uint8)\r\n    augmented_positive = tf.to_float(image['positive'])\r\n    augmented_positive = tf.image.random_flip_up_down(image['positive'])\r\n    augmented_positive = tf.cast(augmented_positive, np.uint8)\r\n    augmented_negative = tf.to_float(image['negative'])\r\n    augmented_negative = tf.image.random_flip_up_down(image['negative'])\r\n    augmented_negative = tf.cast(augmented_negative, np.uint8)\r\n\r\n    return dict(zip(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\r\n\r\n\r\ndef random_brightness(image, label):\r\n    augmented_query = tf.to_float(image['query'])\r\n    augmented_query = tf.image.random_brightness(image['query'], max_delta=random.uniform(0.0, 1.0))\r\n    augmented_query = tf.cast(augmented_query, np.uint8)\r\n    augmented_positive = tf.to_float(image['positive'])\r\n    augmented_positive = tf.image.random_brightness(image['positive'], max_delta=random.uniform(0.0, 1.0))\r\n    augmented_positive = tf.cast(augmented_positive, np.uint8)\r\n    augmented_negative = tf.to_float(image['negative'])\r\n    augmented_negative = tf.image.random_brightness(image['negative'], max_delta=random.uniform(0.0, 1.0))\r\n    augmented_negative = tf.cast(augmented_negative, np.uint8)\r\n\r\n    return dict(zip(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\r\n\r\ndef random_contrast(image, label):\r\n    augmented_query = tf.to_float(image['query'])\r\n    augmented_query = tf.image.random_contrast(image['query'], lower=0.3, upper=1.0)\r\n    augmented_query = tf.cast(augmented_query, np.uint8)\r\n    augmented_positive = tf.to_float(image['positive'])\r\n    augmented_positive = tf.image.random_contrast(image['positive'], lower=0.3, upper=1.0)\r\n    augmented_positive = tf.cast(augmented_positive, np.uint8)\r\n    augmented_negative = tf.to_float(image['negative'])\r\n    augmented_negative = tf.image.random_contrast(image['negative'], lower=0.3, upper=1.0)\r\n    augmented_negative = tf.cast(augmented_negative, np.uint8)\r\n\r\n    return dict(zip(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\r\n\r\ndef random_hue(image, label):\r\n    augmented_query = tf.to_float(image['query'])\r\n    augmented_query = tf.image.random_hue(image['query'], max_delta=random.uniform(0.0, 0.5))\r\n    augmented_query = tf.cast(augmented_query, np.uint8)\r\n    augmented_positive = tf.to_float(image['positive'])\r\n    augmented_positive = tf.image.random_hue(image['positive'], max_delta=random.uniform(0.0, 0.5))\r\n    augmented_positive = tf.cast(augmented_positive, np.uint8)\r\n    augmented_negative = tf.to_float(image['negative'])\r\n    augmented_negative = tf.image.random_hue(image['negative'], max_delta=random.uniform(0.0, 0.5))\r\n    augmented_negative = tf.cast(augmented_negative, np.uint8)\r\n\r\n    return dict(zip(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\r\n\r\ndef random_saturation(image, label):\r\n    augmented_query = tf.to_float(image['query'])\r\n    augmented_query = tf.image.random_saturation(image['query'], lower=0.0, upper=2.0)\r\n    augmented_query = tf.cast(augmented_query, np.uint8)\r\n    augmented_positive = tf.to_float(image['positive'])\r\n    augmented_positive = tf.image.random_saturation(image['positive'], lower=0.0, upper=2.0)\r\n    augmented_positive = tf.cast(augmented_positive, np.uint8)\r\n    augmented_negative = tf.to_float(image['negative'])\r\n    augmented_negative = tf.image.random_saturation(image['negative'], lower=0.0, upper=2.0)\r\n    augmented_negative = tf.cast(augmented_negative, np.uint8)\r\n\r\n    return dict(zip(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\r\n\r\ndef random_rotate(image, label):\r\n    augmented_query = tf.to_float(image['query'])\r\n    augmented_query = tf.contrib.image.rotate(image['query'], angles=random.uniform(0, 360) * math.pi / 180)\r\n    augmented_query = tf.cast(augmented_query, np.uint8)\r\n    augmented_positive = tf.to_float(image['positive'])\r\n    augmented_positive = tf.contrib.image.rotate(image['positive'], angles=random.uniform(0, 360) * math.pi / 180)\r\n    augmented_positive = tf.cast(augmented_positive, np.uint8)\r\n    augmented_negative = tf.to_float(image['negative'])\r\n    augmented_negative = tf.contrib.image.rotate(image['negative'], angles=random.uniform(0, 360) * math.pi / 180)\r\n    augmented_negative = tf.cast(augmented_negative, np.uint8)\r\n\r\n    return dict(zip(feature_names, [augmented_query, augmented_positive, augmented_negative])), label\r\n\r\ndef train_input_fn(params):\r\n    batch_size = params[\"batch_size\"]\r\n    triplets = load_triplets()\r\n    triplets_const = tf.constant(triplets)\r\n    labels_const =tf.zeros([len(triplets)], tf.int32)\r\n    dataset = tf.data.Dataset.from_tensor_slices((triplets_const, labels_const))\r\n    dataset = dataset.shuffle(buffer_size=len(triplets))\r\n    triplets.clear()\r\n    dataset = dataset.map(my_input_fn)\r\n\r\n    augmented_flip_left_right = dataset.map(random_flip_left_right)\r\n    dataset = dataset.concatenate(augmented_flip_left_right)\r\n    augmented_flip_up_down = dataset.map(random_flip_up_down)\r\n    dataset = dataset.concatenate(augmented_flip_up_down)\r\n    augmented_brightness = dataset.map(random_brightness)\r\n    dataset = dataset.concatenate(augmented_brightness)\r\n    augmented_contrast = dataset.map(random_contrast)\r\n    dataset = dataset.concatenate(augmented_contrast)\r\n    augmented_hue = dataset.map(random_hue)\r\n    dataset = dataset.concatenate(augmented_hue)\r\n    augmented_saturation = dataset.map(random_saturation)\r\n    dataset = dataset.concatenate(augmented_saturation)\r\n    augmented_rotate = dataset.map(random_rotate)\r\n    dataset = dataset.concatenate(augmented_rotate)\r\n\r\n    ds = dataset.cache().repeat().apply(tf.contrib.data.batch_and_drop_remainder(batch_size))\r\n    triplets, labels = ds.make_one_shot_iterator().get_next()\r\n\r\n    return triplets, labels\r\n\r\n\r\ndef convnet_model_():\r\n    vgg_model = VGG16(weights=None, include_top=False)\r\n    x = vgg_model.output\r\n    x = layers.GlobalAveragePooling2D()(x)\r\n    x = layers.Dense(4096, activation='relu')(x)\r\n    x = layers.Dropout(0.6)(x)\r\n    x = layers.Dense(4096, activation='relu')(x)\r\n    x = layers.Dropout(0.6)(x)\r\n    x = layers.Lambda(lambda x_: keras.backend.l2_normalize(x_, axis=1))(x)\r\n    convnet_model = models.Model(inputs=vgg_model.input, outputs=x)\r\n\r\n    return convnet_model\r\n\r\n_EPSILON = keras.backend.epsilon()\r\ndef _loss_tensor(y_true, y_pred):\r\n    y_pred = keras.backend.clip(y_pred, _EPSILON, 1.0-_EPSILON)\r\n    loss = tf.convert_to_tensor(0, dtype=tf.float32)\r\n    g = tf.constant(1.0, shape=[1], dtype=tf.float32)\r\n    for i in range(0, FLAGS.batch_size, 3):\r\n        try:\r\n            q_embedding = y_pred[i+0]\r\n            p_embedding = y_pred[i+1]\r\n            n_embedding = y_pred[i+2]\r\n            D_q_p = keras.backend.sqrt(keras.backend.sum((q_embedding - p_embedding)**2))\r\n            D_q_n = keras.backend.sqrt(keras.backend.sum((q_embedding - n_embedding)**2))\r\n            loss = (loss + g + D_q_p - D_q_n)\r\n        except:\r\n            continue\r\n    loss = loss / FLAGS.batch_size\r\n    zero = tf.constant(0.0, shape=[1], dtype=tf.float32)\r\n\r\n    return tf.maximum(loss, zero)\r\n\r\n\r\ndef model_fn(features, labels, mode, params):\r\n    del params\r\n\r\n    convnet_model = convnet_model_()\r\n    first_input = layers.Input(shape=(225,225,3), name='low_visual1_input')\r\n    first_subsample = layers.Conv2D(3, kernel_size=1, strides=4, padding='same', name='low_visual1_subsampling')(first_input)\r\n    first_conv = layers.Conv2D(96, kernel_size=8,strides=4, padding='same', name='low_visual1_conv')(first_subsample)\r\n    first_max = layers.MaxPool2D(pool_size=3,strides=4,padding='same', name='low_visual1_max')(first_conv)\r\n    first_max = layers.Flatten(name='low_visual1_flatten')(first_max)\r\n    second_input = layers.Input(shape=(225,225,3), name='low_visual2_input')\r\n    second_subsample = layers.Conv2D(3, kernel_size=1, strides=8, padding='same', name='low_visual2_subsampling')(second_input)\r\n    second_conv = layers.Conv2D(96, kernel_size=8,strides=4, padding='same', name='low_visual2_conv')(second_subsample)\r\n    second_max = layers.MaxPool2D(pool_size=7,strides =2,padding='same', name='low_visual2_max')(second_conv)\r\n    second_max = layers.Flatten(name='low_visual2_flatten')(second_max)\r\n    merge_low_visual = layers.concatenate([first_max, second_max])\r\n    l2_norm_low_visual = layers.Lambda(lambda x: K.l2_normalize(x, axis=1), name='low_visual_l2_normalization')(merge_low_visual)\r\n    merge_two = layers.concatenate([l2_norm_low_visual, convnet_model.output])\r\n    emb = layers.Dense(4096, name='linear_embedding')(merge_two)\r\n    l2_norm_final = layers.Lambda(lambda  x: K.l2_normalize(x,axis=1), name='final_l2_normalization')(emb)\r\n    final_model = models.Model(inputs=[convnet_model.input, first_input, second_input], outputs=l2_norm_final)\r\n    final_model.summary()\r\n    if mode == tf.estimator.ModeKeys.PREDICT:\r\n        logits = final_model([features['query'], features['positive'], features['negative']], training=False)\r\n        predictions = {\r\n            'embedding': logits[0]\r\n        }\r\n        return tf.estimator.EstimatorSpec(\r\n            mode=tf.estimator.ModeKeys.PREDICT,\r\n            predictions=predictions,\r\n            export_outputs={\r\n                'classify': tf.estimator.export.PredictOutput(predictions)\r\n            })\r\n    logits_1 = final_model([features['query'], features['query'], features['query']], training=(mode == tf.estimator.ModeKeys.TRAIN))\r\n    logits_2 = final_model([features['positive'], features['positive'], features['positive']], training=(mode == tf.estimator.ModeKeys.TRAIN))\r\n    logits_3 = final_model([features['negative'], features['negative'], features['negative']], training=(mode == tf.estimator.ModeKeys.TRAIN))\r\n    logits = tf.concat([logits_1, logits_2, logits_3], 0)\r\n    loss = _loss_tensor(None, logits)\r\n    optimizer = tf.train.MomentumOptimizer(learning_rate=FLAGS.learning_rate, momentum=0.9, use_nesterov=True)\r\n\r\n    if FLAGS.use_tpu:\r\n        optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)\r\n    return tf.contrib.tpu.TPUEstimatorSpec(mode=tf.estimator.ModeKeys.TRAIN, loss=loss, train_op=optimizer.minimize(loss, tf.train.get_global_step()))\r\n\r\n\r\ndef main(argv):\r\n    del argv\r\n    tf.logging.set_verbosity(tf.logging.INFO)\r\n\r\n    if FLAGS.master is None and FLAGS.tpu is None:\r\n        raise RuntimeError('You must specify either --master or --tpu.')\r\n    if FLAGS.master is not None:\r\n        if FLAGS.tpu is not None:\r\n            tf.logging.warn('Both --master and --tpu are set. Ignoring '\r\n                      '--tpu and using --master.')\r\n        tpu_grpc_url = FLAGS.master\r\n    else:\r\n        tpu_cluster_resolver = (tf.contrib.cluster_resolver.TPUClusterResolver(FLAGS.tpu, zone=FLAGS.tpu_zone, project=FLAGS.gcp_project))\r\n        tpu_grpc_url = tpu_cluster_resolver.get_master()\r\n\r\n    run_config = tpu_config.RunConfig(master=tpu_grpc_url, model_dir=FLAGS.model_dir, save_checkpoints_secs=3600, session_config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True), tpu_config=tpu_config.TPUConfig(iterations_per_loop=FLAGS.iterations, num_shards=FLAGS.num_shards),)\r\n    estimator = tpu_estimator.TPUEstimator(model_fn=model_fn, use_tpu=FLAGS.use_tpu, config=run_config, train_batch_size=FLAGS.batch_size)\r\n    estimator.train(input_fn=train_input_fn, max_steps=FLAGS.train_steps)\r\n    img_input = tf.placeholder(tf.float32, [None, 225, 225, 3])\r\n    input_fn =tf.estimator.export.build_raw_serving_input_receiver_fn({\r\n        'query': img_input,\r\n        'positive': img_input,\r\n        'negative': img_input,\r\n    })\r\n    estimator.export_savedmodel('output', input_fn)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    tf.app.run()\r\n```\r\nI get the following error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 370, in <module>\r\n    tf.app.run()\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"test.py\", line 359, in main\r\n    estimator.train(input_fn=train_input_fn, max_steps=FLAGS.train_steps)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 376, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 1143, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 1168, in _train_model_default\r\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2162, in _call_model_fn\r\n    features, labels, mode, config)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 1131, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2414, in _model_fn\r\n    _train_on_tpu_system(ctx, model_fn_wrapper, dequeue_fn))\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2724, in _train_on_tpu_system\r\n    device_assignment=ctx.device_assignment)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu.py\", line 829, in shard\r\n    name=name)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu.py\", line 475, in replicate\r\n    device_assignment, name)[1]\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu.py\", line 635, in split_compile_and_replicate\r\n    outputs = computation(*computation_inputs)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2717, in multi_tpu_train_steps_on_single_shard\r\n    single_tpu_train_step, [_INITIAL_LOSS])\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py\", line 207, in repeat\r\n    cond, body_wrapper, inputs=inputs, infeed_queue=infeed_queue, name=name)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py\", line 169, in while_loop\r\n    name=\"\")\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3232, in while_loop\r\n    return_same_structure)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2952, in BuildLoop\r\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2924, in _BuildLoop\r\n    next_vars.append(_AddNextAndBackEdge(m, v))\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 666, in _AddNextAndBackEdge\r\n    _EnforceShapeInvariant(m, v)\r\n  File \"/home/julien_plu/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 610, in _EnforceShapeInvariant\r\n    (input_t.name, input_t.shape, n_shape))\r\nValueError: Input tensor 'Const_1:0' enters the loop with shape (), but has shape (1,) after one iteration. To allow the shape to vary across iterations, use the `shape_invariants` argument of tf.while_loop to specify a less-specific shape.\r\n```\r\nWhile if I run the exact same code with ```--use_tpu=False --master=''``` it works like a charm.\r\n\r\nIs it somehow related to a bug or is it me who is doing something wrong with dedicated TPU code?\r\n\r\nThanks in advance.", "comments": ["Thanks for the report Julien. \r\n\r\nI was able to reproduce this.  It appears the issue is that your loss is a vector but we are expecting the returned loss to be a scalar value.  The TPUEstimator machinery wraps your model in a training loop which returns the loss as the final result.  The \"dummy\" initial loss is a scalar value which means your model function must also return a scalar value to be retain the same shape.  Apply `tf.reduce_sum(loss)` fixes the issue.  \r\n\r\nI ended up summing the logits instead of the loss, as I was seeing a gradient error with the loss function you pasted in.  Hopefully this works for you -- please close the issue if this resolves your problem.\r\n\r\nI've filed a bug internally to track improving the error message. ", "Thanks a lot @rjpower for the fix, I will test it ASAP today and let you know :)\r\n\r\nWhat was the gradient error you have seen with my loss function? If I follow your fix I should be able to reproduce it? Basically the loss function I'm trying to reproduce is the one described in the Section 3 of this [paper](https://users.eecs.northwestern.edu/~jwa368/pdfs/deep_ranking.pdf)", "I don't have it handy, but the gradient error didn't appear TPU related: it was a warning from the optimizer that there were no gradients to the weight variables.  \r\n\r\nLooking at it, my guess is that in my reproduction the `try: ... except: continue` block failed to execute and so the loss was a constant zero.  If you don't see the error in the CPU execution then it's probably fine.", "Hummm... In my loss the constraint I have is that the batch size must be a multiple of 3 otherwise the loss fails. Maybe somewhere I forgot to take this into account, I will remove the ```try: ... except: continue``` and add a check if the loss equals 0, and see if I succeed to get this state.\r\n\r\nThanks a lot for everything as now I don't have anymore the issue with your fix :)"]}, {"number": 20746, "title": "Merge crop_and_resize with resize_bilinear_op internals", "body": "Improves performance of crop_and_resize.", "comments": ["@alextp Thanks for the review. Your suggestions have been incorporated. Anything else needed?", "It looks like this was a performance regression which we will have to roll back.\r\n\r\nMaybe we should add a benchmark for these ops so we can try this change again without a slowdown?", "Here is the rollback: https://github.com/tensorflow/tensorflow/commit/6795a8c3a3678fb805b6a8ba806af77ddfe61628", "Hi Alex,\r\n\r\nCan you please provide the details for the performance regression that you are seeing? We saw a noticeable performance improvement for our test cases. \r\n\r\nCheers,\r\nThor"]}, {"number": 20745, "title": "ar", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["This seems to have been an accident. Closing."]}, {"number": 20744, "title": "Fix for issue# 20361 - changed the test cases' inputs and expected su\u2026", "body": "\u2026ch that it passes on both x86 and ppc64le.\r\n\r\nFix for issue# 20361. The test case was earlier failing on ppc64le because it was designed to expect the results given on x86. But x86 was giving incorrect output for uint8 test cases. Please see the complete investigation mentioned in https://github.com/tensorflow/tensorflow/issues/20361.\r\n\r\nAs a fix, changed the input and expected output for the failing tests in such a way that now it passes on both the platforms.", "comments": ["@npanpaliya - I think the test TwoDimensionalResize and ThreeDimensionalResize also need to change.\r\n\r\nThe issue is ThreeDimensionalResize and ThreeDimensionalResize8Bit were taking the same input and expecting different output. The test should take the same input and expect the same output. If changing the uint8 test input, you need to change the float32 test input. ", "Making the same inputs and outputs for float related tests makes those test fails. This is because in case of floats we get float values for e.g. 7 vs 7.3333 or 9 vs 9.6667. So, the expected output would never be same for uint8 and float tests. For uint8 tests, it gets rounded off to nearest decimal. \r\nSo, it is difficult to come up with such input which gives exactly same output for both uint8 and float tests. I'll still try and see if I get such input/output data values.", "@andrehentz - Thanks for your review. Could you please merge this PR as all other checks are also passed?"]}, {"number": 20743, "title": "Tensorflow C++ GPU support", "body": "\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:N/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Window 10 64Bit\r\n- **TensorFlow installed from (source or binary)**:source\r\n- **TensorFlow version (use command below)**:1.7.0-rc1\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**:N/A\r\n- **GCC/Compiler version (if compiling from source)**:N/A\r\n- **CUDA/cuDNN version**:9.0/7.0\r\n- **GPU model and memory**:GTX960\r\n- **Exact command to reproduce**:N/A\r\n\r\n### Describe the problem\r\nI have successfully compiled the tensorflow1.7C++ version on windows10.In the prediction, I found that GPU is not used in the program. Is the GPU not supported by the tensorflowC++ interface?I am very anxious and hope to get help. Thank you very much.\r\n\r\n", "comments": ["You are not using bazel. how did you \"./configure\" and make it?", "@aimhabo I compile using CMake,as follows:\r\n1. Go to the tensorflow/tensorflow/contrib/cmake path, create the build folder, and CMD enters the build folder to execute the command:\r\n\r\n> cmake .. -G \"Visual Studio 14 2015\" -A x64 -DCMAKE_BUILD_TYPE=Release -DSWIG_EXECUTABLE=C:/tools/swigwin-3.0.12/swig.exe -DPYTHON_EXECUTABLE=C:/ProgramData/Anaconda3/envs/tfbuild/python.exe -DPYTHON_LIBRARIES=C:/ProgramData/Anaconda3/envs/tfbuild/libs/python35.lib -Dtensorflow_ENABLE_GPU=ON -Dtensorflow_ENABLE_GRPC_SUPPORT=OFF -Dtensorflow_BUILD_PYTHON_BINDINGS=OFF -Dtensorflow_BUILD_SHARED_LIB=ON\r\n\r\n2.Enter the build folder, use VS2015 to open tensorflow.sln, and then ALL build.", "@gulingfengze I got this in Cmake\r\n> CMake Error at CMakeLists.txt:422 (message):\r\n>   NCCL is required for GPU-build\r\n\r\nindeed, I cant find any \\*nccl\\*.a in cuda folders\r\n\r\noh, I haven't install nccl. "]}, {"number": 20742, "title": "[tf.keras] Fix deprecated use of normal distribution in initializers", "body": "Usage of `distribution='normal'` in `VarianceScaling` initializer was deprecated in #20197 and replaced with `truncated_normal`.", "comments": ["@qlzh727 Thanks for approving. The CI failure looks unrelated, should I rebase onto master?", "Oh, its fine. We will port the change to internal system and test it there. You can ignore the test flaky for now."]}, {"number": 20741, "title": "TFLite: Cannot use boolean scalar as input to TFLite model", "body": "Edit: Adding issue template\r\nHave I written custom code: No\r\nOS Platform and Distribution: Ubuntu 14.04 \r\nTensorFlow installed from: pip\r\nTensorFlow version: r1.9\r\nBazel version\r\nCUDA/cuDNN version\r\nGPU model and memory\r\nExact command to reproduce: tf.contrib.lite.toco_convert (More details below)\r\n\r\n\r\nI am trying to convert the [Facenet Tensorflow](https://github.com/davidsandberg/facenet) model into `TFLITE` format which I could use for an Android app. This Facenet model takes a tensor containing image data and a boolean scalar (is_training) as input:\r\n\r\n  `  feed_dict = { images_placeholder: images, phase_train_placeholder:False }`\r\n\r\nI follow the [Tensorflow lite guide](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/mobile/tflite/devguide.md) to convert models into TFLITE format. Here is an example: \r\n\r\n   ```\r\n import tensorflow as tf\r\n    \r\n    img = tf.placeholder(name=\"img\", dtype=tf.float32, shape=(1, 64, 64, 3))\r\n    val = img + tf.constant([1., 2., 3.]) + tf.constant([1., 4., 4.])\r\n    out = tf.identity(val, name=\"out\")\r\n    \r\n    with tf.Session() as sess:\r\n      tflite_model = tf.contrib.lite.toco_convert(sess.graph_def, [img], [out])\r\n      open(\"converteds_model.tflite\", \"wb\").write(tflite_model)\r\n\r\n```\r\nHere is my code:\r\n\r\n   ```\r\n with tf.Graph().as_default():\r\n    \r\n            with tf.Session() as sess:\r\n    \r\n                # Load the model\r\n                facenet.load_model(args.model)\r\n    \r\n                # Get input and output tensors\r\n                images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\r\n                embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\r\n                phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\r\n                #reshape as tflite does not accepts None dimension\r\n                images_placeholder = tf.reshape(images_placeholder, [1,160,160,3])\r\n                tflite_model = tf.contrib.lite.toco_convert(sess.graph_def, [images_placeholder, phase_train_placeholder], [embeddings])\r\n                open(\"converteds_model.tflite\", \"wb\").write(tflite_model)\r\n```\r\n\r\nThe program gives an error saying (I guess this happens as `tflite` does not support `tf.bool` just yet):\r\n\r\n```\r\n    File \"/.../facenet/tensorflow1.8/lib/python3.4/site-packages/tensorflow/contrib/lite/python/convert.py\", line 206, in toco_convert\r\n        input_tensor.dtype))\r\n    ValueError: Tensors phase_train:0 not known type tf.bool\r\n\r\n```\r\nIf I cast the `phase_train_placeholder` to the supported type `tf.int32`, just to see how it goes. Then it gives another error (I guess this happens as the convert function does not accept scalar):\r\n\r\n \r\n\r\n```\r\nFile \"/.../facenet/tensorflow1.8/lib/python3.4/site-packages/tensorflow/contrib/lite/python/convert.py\", line 217, in toco_convert\r\n        input_array.shape.dims.extend(map(int, input_tensor.get_shape()))\r\n      File \"/.../facenet/tensorflow1.8/lib/python3.4/site-packages/tensorflow/python/framework/tensor_shape.py\", line 591, in __iter__\r\n        raise ValueError(\"Cannot iterate over a shape with unknown rank.\")\r\n    ValueError: Cannot iterate over a shape with unknown rank.\r\n```\r\n\r\nCould you please suggest an workaround for this? I understand that TFLite is still in development but I could try to contribute this part if it is possible. Many thanks.\r\n \r\nI also posted to [SO](https://stackoverflow.com/questions/51307107/tensorflow-lite-boolean-scalar-as-input-tensor); however I think this is also an issue therefore I put it here as well.  ", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "This is likely currently not supported. You can work around this by passing an integer or float input type instead.\r\n", "The type checking code in convert.py was relaxed in https://github.com/tensorflow/tensorflow/commit/d3931c804ce9619ac0a0c84f42b43ce70ade93a7. \r\n\r\n@hoavt-54 would you mind trying your conversion again? Thanks for your patience.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?"]}, {"number": 20740, "title": "Should the loading model be in a separate thread?", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Centos 7.0\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.4\r\n- **Python version**:  2.7\r\n- **Bazel version (if compiling from source)**: 0.7.0\r\n- **GCC/Compiler version (if compiling from source)**:  4.8.5\r\n- **CUDA/cuDNN version**: 5.1.10\r\n- **GPU model and memory**: p40 etc\r\n- **Exact command to reproduce**: \r\n\r\n### Describe the problem\r\n\r\nNow, loading new model is using default thread pool, this may affect predict latency in serving.\r\n\r\nSorry to disturb, I have addressed this problem in https://github.com/tensorflow/serving/issues/910, but I think the root cause is in tensorflow's code.\r\n\r\nShould we provide a config for serving to use a separate thread pool when loading new model versions?\r\n\r\nI can provide a solution.\r\n", "comments": ["Take a look at session_inter_op_thread_pool. You can create two pools one for serving and one for loading.", "@azaks2 yes, but by default, you cannot choose a separate thread pool when load new model.", "You can pass the right thread pool via RunOptions::inter_op_thread_pool. Would that work for you?", "Nagging Assignee @azaks2: It has been 45 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 20739, "title": "Tensorflow lite, invalid quantization ranges", "body": "### System information\r\n- **Have I written custom code**: Y\r\n- **OS Platform and Distribution**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:  source\r\n- **TensorFlow version (use command below)**: v1.9.0-rc1-48-ge3f2b5903c 1.9.0-rc2\r\n- **Python version**: 3.5.2\r\n- **Bazel version**: release 0.15.0\r\n- **GCC/Compiler version**: 5.5\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A  \r\n\r\n### Describe the problem  \r\nHello! I am not really sure is it a bug or just my misunderstanding. According to the quantized training [tutorial](https://www.tensorflow.org/performance/quantization) command `create_eval_graph` is supposed to generate toco-ready graph with fake quantization nodes inside. For weights it's done via the following command:  \r\n```python \r\n    _InsertQuantOp(\r\n        context,\r\n        'weights_quant',\r\n        layer_match.weight_tensor.op, [layer_match.layer_op],\r\n        is_training,\r\n        moving_avg=False,\r\n        ema_decay=ema_decay,\r\n        quant_delay=quant_delay,\r\n        narrow_range=True, # [!!!!!!]\r\n        vars_collection=vars_collection,\r\n        bits=weight_bits,\r\n        consumer_scope=scope)\r\n```  \r\nHere narrow_range parameter forces mapping of float values to the [1, 255] range. However, as far as I was able to understand, all tensors quantization(weights included) is performed using function [ChooseQuantizationParams](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/kernels/internal/quantization_util.h) which assumes, that available range is [0, 255](for uint8). Hence, float weights are mapped to values that might be different then ones that was used during training. In my situation it leads to the significant difference(deep model) between output of the Tensorflow fake-quantized graph and Tensorflow lite model.  Difference is about 1e-1 for a single layer.\r\n\r\nDescribed is true for the --inference_type=QUANTIZED_UINT8 toco parameter, not sure about --inference_type=FLOAT and --quantize_weights=true(probably the same).\r\n\r\n### Source code / logs  \r\nI will prepare code snippets to reproduce in case I am right and described behavior can be considered as unexpected.   ", "comments": ["By the way, I wonder, why `create_eval_graph` uses fixed fake quantization([-6.0, 6.0] -> uint8)?  \r\n\r\nAccording to the original [paper](https://arxiv.org/pdf/1712.05877.pdf) the idea is to use min-max weights values and EMA during training. In my opinion it is expectable to do the same for the eval_graph. I mean, run `create_eval_graph`, evaluate network on the dataset to get the min-max values and then save -> transform to tflite. In comparison to the fixed ranges it would be more similar to the actual training procedure.  \r\n\r\nAlso, I think it's questionable to avoid bias quantization during training and quantize activations instead. Yes, toco quantizes biases  as int32, but it's not the same as it was during training. I mean, during training `act_quant` performs **8 bit** quantization of the conv result + float biases.  And during inference we start to treat bias as 32 bit value, what results in the slightly different inference values. But this shift results in the overall network bias and, in my case, the `tflite` model result is significantly different from the `create_eval_graph` one.  \r\n\r\nIt would be great to find out the ideas behind this approach. On the first look it is a bit counterintuitive.", "Good points, The latest version of TOCO should have this issue fixed. There was an error in the way NarrowRange was interpreted in toco, but things should be consistent with this  [submission](https://github.com/tensorflow/tensorflow/commit/9ba6943a1dbbc415b72835517ad58808ca6a6a3d#diff-3d2a7c9d6afe08caa50425e7cb9d234e). \r\n\r\nYour points regarding calculating min/max values using the eval graph is valid. However, this can be done only for the case of quantization post training. We have a tool in the works that does this and will update when it is ready.  Please note that eval_graph does not use fixed fake quantization. The values used are the ones that were learnt during training.  \r\n\r\nSo far we havent observed any difference in accuracy due to quantizing biases to int32 and therefore did not implement support for quantized biases. Can you provide an example where the difference is noticeable?\r\n", "@raghuraman-k Thanks for answer.  \r\n\r\nUnfortunately, I can't provide small and exhaustive source code example, because in my case drop in accuracy can be observed in complicated detection network, MaskRCNN. To be precise, ROIAlign seems to be rather sensitive to the input distribution changes. (Yes, ROIAlign and other related operations are not supported, however, I manually implemented them in C++ as separate functions. Also inserted additional fake quantization nodes for them).  \r\n\r\nBack to the weights quantization. Yes, you are right, quantization procedure is not like I thought before, however it has some drawbacks.  \r\n\r\nI was digging into the TOCO sources for a while and found out that weights are quantized 2 times, at least for the `quantize_weights=True` option. First, quantization parameters are applied [here](https://github.com/tensorflow/tensorflow/blob/9ba6943a1dbbc415b72835517ad58808ca6a6a3d/tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_fake_quant.cc\r\n) and then arrays are requantized [here](\r\nhttps://github.com/tensorflow/tensorflow/blob/9ba6943a1dbbc415b72835517ad58808ca6a6a3d/tensorflow/contrib/lite/toco/graph_transformations/quantize_weights.cc). Not sure about quantized inference, probably the same.\r\n\r\nAlso there is a difference in the TOCO quantization procedure and tensorflow FakeQuantize operation. For instance, the second is less precise than first(clipping in floats instead integers, or something of the kind).  \r\n\r\nBoth described facts introduce small delta between fake quantized weights during training and tensorflow lite quantized weights. As I sad before in some cases this bias leads to significant accuracy drop.  \r\n\r\nIf you are interesting, I fixed described above and recieved machine eps between tensorflow lite weights after dequantization and FakeQuantize node results. However, I have implementation only for the weights quantization case. ", "We just launched a post-training quantization toolkit. May you try running the post-training quantization flag to see if it improves your inference? Please let us know if it does not make your model smaller and faster.\r\n\r\nhttps://www.tensorflow.org/performance/post_training_quantization", "Nagging Assignee @raghuraman-k: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 20738, "title": "AttributeError: 'DataFrame' object has no attribute 'dtype'", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **I'm using the FashionMNIST code tutorial in  [ https://goo.gl/GtM6ov](https://goo.gl/GtM6ov)**:\r\n- **Mac OS 10.13.3**:\r\n- **Source**:\r\n- **TensorFlow version (1.8.0)**:\r\n- *Python 3.6.5 :: Anaconda, Inc.**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n\r\ntrain_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n        x={\"pixels\": features.values/255},\r\n        y=labels,\r\n        batch_size=100,\r\n        num_epochs=3,\r\n        shuffle=True)\r\nfeature_columns = [tf.feature_column.numeric_column(\"pixels\", shape=784)]\r\n\r\nclassifier = tf.estimator.LinearClassifier(\r\n    feature_columns = feature_columns,\r\n    n_classes = 10,\r\n    model_dir = \"./models/linear1\"\r\n)\r\n\r\nclassifier.train(input_fn=train_input_fn)\r\n\r\n\r\n--------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-84-5c962f10a4d9> in <module>()\r\n----> 1 classifier.train(input_fn=train_input_fn)\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)\r\n    361 \r\n    362     saving_listeners = _check_listeners_type(saving_listeners)\r\n--> 363     loss = self._train_model(input_fn, hooks, saving_listeners)\r\n    364     logging.info('Loss for final step: %s.', loss)\r\n    365     return self\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)\r\n    841       return self._train_model_distributed(input_fn, hooks, saving_listeners)\r\n    842     else:\r\n--> 843       return self._train_model_default(input_fn, hooks, saving_listeners)\r\n    844 \r\n    845   def _train_model_default(self, input_fn, hooks, saving_listeners):\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _train_model_default(self, input_fn, hooks, saving_listeners)\r\n    851       features, labels, input_hooks = (\r\n    852           self._get_features_and_labels_from_input_fn(\r\n--> 853               input_fn, model_fn_lib.ModeKeys.TRAIN))\r\n    854       worker_hooks.extend(input_hooks)\r\n    855       estimator_spec = self._call_model_fn(\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _get_features_and_labels_from_input_fn(self, input_fn, mode)\r\n    689   def _get_features_and_labels_from_input_fn(self, input_fn, mode):\r\n    690     \"\"\"Extracts the `features` and labels from return values of `input_fn`.\"\"\"\r\n--> 691     result = self._call_input_fn(input_fn, mode)\r\n    692     # TODO(anjalisridhar): What about the default DistributionStrategy? Perhaps\r\n    693     # using any input is alright in that case. There is also a\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _call_input_fn(self, input_fn, mode)\r\n    796       kwargs['config'] = self.config\r\n    797     with ops.device('/cpu:0'):\r\n--> 798       return input_fn(**kwargs)\r\n    799 \r\n    800   def _call_model_fn(self, features, labels, mode, config):\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/numpy_io.py in input_fn()\r\n    194         num_threads=num_threads,\r\n    195         enqueue_size=batch_size,\r\n--> 196         num_epochs=num_epochs)\r\n    197 \r\n    198     batch = (\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py in _enqueue_data(data, capacity, shuffle, min_after_dequeue, num_threads, seed, name, enqueue_size, num_epochs, pad_value)\r\n    390     elif isinstance(data, collections.OrderedDict):\r\n    391       types = [dtypes.int64\r\n--> 392               ] + [dtypes.as_dtype(col.dtype) for col in data.values()]\r\n    393       queue_shapes = [()] + [col.shape[1:] for col in data.values()]\r\n    394       get_feed_fn = _OrderedDictNumpyFeedFn\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py in <listcomp>(.0)\r\n    390     elif isinstance(data, collections.OrderedDict):\r\n    391       types = [dtypes.int64\r\n--> 392               ] + [dtypes.as_dtype(col.dtype) for col in data.values()]\r\n    393       queue_shapes = [()] + [col.shape[1:] for col in data.values()]\r\n    394       get_feed_fn = _OrderedDictNumpyFeedFn\r\n\r\n~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in __getattr__(self, name)\r\n   4370             if self._info_axis._can_hold_identifiers_and_holds_name(name):\r\n   4371                 return self[name]\r\n-> 4372             return object.__getattribute__(self, name)\r\n   4373 \r\n   4374     def __setattr__(self, name, value):\r\n\r\nAttributeError: 'DataFrame' object has no attribute 'dtype'\r\n\r\nThis is the error I'm getting.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nExact command to reproduce", "Thanks for your response. I've got the issue solved. Thank you", "@attitude95 please share how your issue got solved."]}, {"number": 20737, "title": "Extend the support of the exponential distribution to include 0", "body": "The support of the [Exponential Distribution](https://en.wikipedia.org/wiki/Exponential_distribution) includes 0. However in tensorflow (v1.8 compiled from source on ubuntu 16.04 using the cpu) it does not. Example:\r\n```\r\nimport tensorflow as tf\r\nexp = tf.distributions.Exponential(rate=1./2.)\r\nllh = exp.log_prob(value=0.) \r\n\r\nwith tf.Session() as sess:\r\n    print(sess.run(llh))\r\n```\r\nResult:\r\n`nan`\r\n\r\nIn that case Tensorflow differs to scipy's behaviour:\r\n```\r\nimport scipy as sp\r\nsp.stats.expon(scale=2.).logpdf(0.)\r\n```\r\nResult:\r\n`-0.6931471805599453`\r\n\r\nWould be great to adopt scipy's behaviour. Thank you\r\n\r\nEDIT:\r\nHave I written custom code: No\r\nOS Platform and Distribution: Ubuntu 16.04\r\nTensorFlow installed from: source\r\nTensorFlow version: 1.8.0\r\nBazel version: Build label: 0.11.1\r\nCUDA/cuDNN version: -/- (using CPU)\r\nGPU model and memory: - (using CPU)\r\nExact command to reproduce: see above\r\nPython:  3.6.3", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "+bayesflow-team <bayesflow-team@google.com>\n\nOn Sat, Sep 15, 2018, 11:49 AM Alfred Sorten Wolf <notifications@github.com>\nwrote:\n\n> Nagging Assignee @jvdillon <https://github.com/jvdillon>: It has been 44\n> days with no activity and this issue has an assignee. Please update the\n> label and/or status accordingly.\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/20737#issuecomment-421615391>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim8uJqSI1B9uPj0e53bip0xbxsXbbks5ubUu-gaJpZM4VM1KH>\n> .\n>\n", "@aboettcher,\r\nYour code works fine using [**`Tensorflow Probability (tfp)`** ](https://www.tensorflow.org/probability/api_docs/python/tfp). Please find [the Gist](https://colab.research.google.com/gist/rmothukuru/bd4bcd7556e4a68869beedb61a608832/gh_20737.ipynb) of the Working Code. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 20736, "title": "Putting batch_axis,seq_axis instead batch_dim, seq_dim according", "body": "According to [this](https://github.com/yongtang/tensorflow/blob/6a5d1dd1fb9fdea12f4b3572e9e94fed05245d15/tensorflow/python/ops/array_ops.py#L2622)", "comments": ["Btw, what about changing time_dim, batch_dim variables [L420](https://github.com/dimaxano/tensorflow/blob/e8c44d765146d228ee88e46b1e1f1e8fb3894818/tensorflow/python/ops/rnn.py#L420) to time_axis, batch_axis accordingly? Looks reasonable", "That will be ideal too, thanks", "@qlzh727  Completed. [commit](https://github.com/tensorflow/tensorflow/pull/20736/commits/ee7c2fc000d5640468343ec93b4878d1334d481c)", "Hi, @qlzh727. Is everything correct with this PR?", "Sorry for the late reply. LGTM."]}, {"number": 20735, "title": "[tfgan] Remove outdated estimator TODO", "body": "Training discriminator and generator with different ratios can already be done using `get_hooks_fn`.\r\n\r\nThis was resolved in #14723", "comments": ["Assign to @joel-shor to ensure the TODO has been addressed.\r\n\r\n\r\n\r\n", "Nagging Reviewer @joel-shor: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 14 days with no activity and the `awaiting review` label has been applied."]}, {"number": 20734, "title": "sys/sendfile.h is actually only defined for Linux.", "body": "For other systems (OS X/FreeBSD) header is missing.", "comments": ["Ping for review again.", "Ping @andrehentz for review."]}, {"number": 20733, "title": "Fix for LNK2019 error when compiling tf1.9 with CMake on Windows due to missing definition.", "body": "This is the suggested fix for the missing NumHyperthreadsPerCore definition #19761 which is still present in release 1.9.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!\n\nOn 12 July 2018 at 12:45, googlebot <notifications@github.com> wrote:\n\n> Thanks for your pull request. It looks like this may be your first\n> contribution to a Google open source project (if not, look below for help).\n> Before we can look at your pull request, you'll need to sign a Contributor\n> License Agreement (CLA).\n>\n> \ud83d\udcdd *Please visit https://cla.developers.google.com/\n> <https://cla.developers.google.com/> to sign.*\n>\n> Once you've signed (or fixed any issues), please reply here (e.g. I\n> signed it!) and we'll verify it.\n> ------------------------------\n> What to do if you already signed the CLA Individual signers\n>\n>    - It's possible we don't have your GitHub username or you're using a\n>    different email address on your commit. Check your existing CLA data\n>    <https://cla.developers.google.com/clas> and verify that your email is\n>    set on your git commits\n>    <https://help.github.com/articles/setting-your-email-in-git/>.\n>\n> Corporate signers\n>\n>    - Your company has a Point of Contact who decides which employees are\n>    authorized to participate. Ask your POC to be added to the group of\n>    authorized contributors. If you don't know who your Point of Contact is,\n>    direct the Google project maintainer to go/cla#troubleshoot (Public\n>    version <https://opensource.google.com/docs/cla/#troubleshoot>).\n>    - The email used to register you as an authorized contributor must be\n>    the email used for the Git commit. Check your existing CLA data\n>    <https://cla.developers.google.com/clas> and verify that your email is\n>    set on your git commits\n>    <https://help.github.com/articles/setting-your-email-in-git/>.\n>    - The email used to register you as an authorized contributor must\n>    also be attached to your GitHub account\n>    <https://github.com/settings/emails>.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/20733#issuecomment-404483888>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AjCqnxxW_SfWl7LPDFkJSrnE00qaAAGWks5uFzbzgaJpZM4VMsYK>\n> .\n>\n", "CLAs look good, thanks!\n\n<!-- ok -->", "To clarify, this is only an issue only appears when building with MKL on Windows, which is maybe how it didn't show up in testing. ", "Hi, is there any update on when this will be reviewed? Thanks.", "Sorry for the delay. Adding @andrehentz as reviewer.\r\n\r\n\r\n", "Nagging Reviewer @andrehentz: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 14 days with no activity and the `awaiting review` label has been applied.", "Ping  @andrehentz again for review.", "Adding @gunan since this is push to R1.9. ", "1.10 is out and we are preparing to cut 1.11.\r\nWe wont be creating a new tag, and publishing new binaries with this fix.\r\nI would consider 1.9 branch closed at this point."]}, {"number": 20732, "title": "Getting KeyError: u'LSTMBlockCell while loading graph", "body": "I have trained an LSTM model using tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell when I tried to load that model I got KeyError: u'LSTMBlockCell' and it was working fine when I was using Basic LSTM cell.\r\nTensorflow-gpu - 1.8.0\r\n\r\nError Log\r\n\r\nFile \"<stdin>\", line 1, in <module>\r\n  File \"/home/abhay/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1955, in import_meta_graph\r\n    **kwargs)\r\n  File \"/home/abhay/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/meta_graph.py\", line 743, in import_scoped_meta_graph\r\n    producer_op_list=producer_op_list)\r\n  File \"/home/abhay/anaconda2/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 432, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/abhay/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 460, in import_graph_def\r\n    _RemoveDefaultAttrs(op_dict, producer_op_list, graph_def)\r\n  File \"/home/abhay/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 227, in _RemoveDefaultAttrs\r\n    op_def = op_dict[node.op]\r\nKeyError: u'LSTMBlockCell'", "comments": ["I got the same issue when tried to load a trained model of [PTB Rnn](https://github.com/tensorflow/models/tree/master/tutorials/rnn/ptb)\r\n\r\nTensorflow-gpu - 1.8.0\r\nThe code used for loading model\r\n```\r\nwith tf.Session() as sess:\r\n  new_saver = tf.train.import_meta_graph('./trained_model/model.ckpt-24672.meta')\r\n  new_saver.restore(sess, tf.train.latest_checkpoint('./trained_model'))\r\n```\r\n\r\nError log\r\n```\r\n---------------------------------------------------------------------------\r\nKeyError                                  Traceback (most recent call last)\r\n<ipython-input-3-63da410a664c> in <module>()\r\n      1 with tf.Session() as sess:\r\n----> 2   new_saver = tf.train.import_meta_graph('./trained_model/model.ckpt-24672.meta')\r\n      3   new_saver.restore(sess, tf.train.latest_checkpoint('./trained_model'))\r\n\r\n/home/caomanhdat/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs)\r\n   1953       clear_devices=clear_devices,\r\n   1954       import_scope=import_scope,\r\n-> 1955       **kwargs)\r\n   1956 \r\n   1957   if meta_graph_def.HasField(\"saver_def\"):\r\n\r\n/home/caomanhdat/.local/lib/python2.7/site-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate)\r\n    741         name=(import_scope or scope_to_prepend_to_names),\r\n    742         input_map=input_map,\r\n--> 743         producer_op_list=producer_op_list)\r\n    744 \r\n    745     # Restores all the other collections.\r\n\r\n/home/caomanhdat/.local/lib/python2.7/site-packages/tensorflow/python/util/deprecation.pyc in new_func(*args, **kwargs)\r\n    430                 'in a future version' if date is None else ('after %s' % date),\r\n    431                 instructions)\r\n--> 432       return func(*args, **kwargs)\r\n    433     return tf_decorator.make_decorator(func, new_func, 'deprecated',\r\n    434                                        _add_deprecated_arg_notice_to_docstring(\r\n\r\n/home/caomanhdat/.local/lib/python2.7/site-packages/tensorflow/python/framework/importer.pyc in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list)\r\n    458   if producer_op_list is not None:\r\n    459     # TODO(skyewm): make a copy of graph_def so we're not mutating the argument?\r\n--> 460     _RemoveDefaultAttrs(op_dict, producer_op_list, graph_def)\r\n    461 \r\n    462   graph = ops.get_default_graph()\r\n\r\n/home/caomanhdat/.local/lib/python2.7/site-packages/tensorflow/python/framework/importer.pyc in _RemoveDefaultAttrs(op_dict, producer_op_list, graph_def)\r\n    225     # Remove any default attr values that aren't in op_def.\r\n    226     if node.op in producer_op_dict:\r\n--> 227       op_def = op_dict[node.op]\r\n    228       producer_op_def = producer_op_dict[node.op]\r\n    229       # We make a copy of node.attr to iterate through since we may modify\r\n\r\nKeyError: u'LSTMBlockCell'\r\n```", "Hi Anderson,\r\n\r\nI am waiting for your reply, I tried to resolve this problem but I am not able to solve please help.", "Hi all,\r\nI have resolved this issue, earlier i used to load model using this \r\n\r\n```\r\ntf.reset_default_graph()\r\nsaver = tf.train.import_meta_graph(\"{}.meta\".format(checkpoint_file))\r\nsaver.restore(sess, checkpoint_file)\r\n```\r\n\r\nBut sometimes I was getting an LSTMBLOACKcell error sometimes some variable is not initialized.\r\nNow While training, I am storing these variable to graph only.\r\n\r\n`var_list = (tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope) + tf.get_collection(tf.GraphKeys.SAVEABLE_OBJECTS, scope))\r\n`\r\nAnd the time of loading the graph I am loading the same list of variables.\r\n\r\n```\r\nsaver = tf.train.Saver(var_list)\r\nsaver.restore(sess, checkpoint_file)\r\n\r\n```\r\nNow its working fine, I am able to resume the training or making servable file.\r\n\r\nThanks\r\n", "Looks like this issue has been resolved, so I am closing the issue. Thanks!", "Hi @akanyaani \r\nyou mean I have to start the training from beginning,\r\nI'm trying to change the model to be in one .pd file so I got the same error but I'm doing this after the training is done and the ckpt files are saved \r\n ", "you just need to add `*.so` compiled file generated by model implementation.\r\nas follows add this line before session and import meta graph.\r\n`tf.load_op_library('<compiled_filename>.so')`\r\nthis function add a new op in tensorflow runtime.\r\nfor example. i compiled a model that contains a `RoiPooling` layer and generated `roi_pooling.so` file. so that i added this line to my code\r\n`tf.load_op_library('op/roi_pooling.so')`\r\n\r\nand finally it works : )"]}, {"number": 20731, "title": "Multiple dex files define Lorg/tensorflow/lite/NativeInterpreterWrapper;", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo, but have added images and used TOCO to make it an android app.\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nMacOS 10.12.6\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\nanaconda3\r\n\r\n- **TensorFlow version (use command below)**:\r\nv1.7.1-0-gc8137f3a8e 1.7.1, as TOCO wouldn't work on 1.8\r\n\r\n- **Python version**: \r\nPython 3.6.5 :: Anaconda, Inc.\r\n\r\n- **Bazel version (if compiling from source)**:\r\nN/A\r\n\r\n- **GCC/Compiler version (if compiling from source)**:\r\nN/A\r\n\r\n- **CUDA/cuDNN version**:\r\nN/A\r\n\r\n- **GPU model and memory**:\r\nIntel HD 6000 \r\n8GB DDR3\r\n\r\n- **Exact command to reproduce**:\r\nN/A\r\n\r\n### Describe the problem\r\nWhen trying to build the \"tflite\" app from tensorflow-for-poets2, I encounter an error; `Multiple dex files define Lorg/tensorflow/lite/NativeInterpreterWrapper;`. I have tried updating the SDK and finding a duplicate of the file defining NativeInterpreterWrapper (with no luck).\r\n\r\n### Source code / logs\r\n\r\nError log:\r\n```\r\norg.gradle.api.tasks.TaskExecutionException: Execution failed for task ':app:transformDexArchiveWithExternalLibsDexMergerForDebug'.\r\n\tat org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:100)\r\n\tat org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:70)\r\n\tat org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:63)\r\n\tat org.gradle.api.internal.tasks.execution.ResolveTaskOutputCachingStateExecuter.execute(ResolveTaskOutputCachingStateExecuter.java:54)\r\n\tat org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58)\r\n\tat org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:88)\r\n\tat org.gradle.api.internal.tasks.execution.ResolveTaskArtifactStateTaskExecuter.execute(ResolveTaskArtifactStateTaskExecuter.java:52)\r\n\tat org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:52)\r\n\tat org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:54)\r\n\tat org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43)\r\n\tat org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:34)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.run(DefaultTaskGraphExecuter.java:248)\r\n\tat org.gradle.internal.progress.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:336)\r\n\tat org.gradle.internal.progress.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:328)\r\n\tat org.gradle.internal.progress.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:197)\r\n\tat org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:107)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:241)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:230)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker.processTask(DefaultTaskPlanExecutor.java:124)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker.access$200(DefaultTaskPlanExecutor.java:80)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker$1.execute(DefaultTaskPlanExecutor.java:105)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker$1.execute(DefaultTaskPlanExecutor.java:99)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskExecutionPlan.execute(DefaultTaskExecutionPlan.java:625)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskExecutionPlan.executeWithTask(DefaultTaskExecutionPlan.java:580)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker.run(DefaultTaskPlanExecutor.java:99)\r\n\tat org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:63)\r\n\tat org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:46)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:55)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: java.lang.RuntimeException: com.android.builder.dexing.DexArchiveMergerException: Unable to merge dex\r\n\tat java.util.concurrent.ForkJoinTask$AdaptedCallable.exec(ForkJoinTask.java:1431)\r\n\tat java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)\r\n\tat java.util.concurrent.ForkJoinTask.externalAwaitDone(ForkJoinTask.java:326)\r\n\tat java.util.concurrent.ForkJoinTask.doJoin(ForkJoinTask.java:391)\r\n\tat java.util.concurrent.ForkJoinTask.join(ForkJoinTask.java:719)\r\n\tat java.util.ArrayList.forEach(ArrayList.java:1249)\r\n\tat com.android.builder.dexing.DxDexArchiveMerger.mergeMultidex(DxDexArchiveMerger.java:266)\r\n\tat com.android.builder.dexing.DxDexArchiveMerger.mergeDexArchives(DxDexArchiveMerger.java:133)\r\n\tat com.android.build.gradle.internal.transforms.DexMergerTransformCallable.call(DexMergerTransformCallable.java:97)\r\n\tat com.android.build.gradle.internal.transforms.ExternalLibsMergerTransform.transform(ExternalLibsMergerTransform.kt:121)\r\n\tat com.android.build.gradle.internal.pipeline.TransformTask$2.call(TransformTask.java:222)\r\n\tat com.android.build.gradle.internal.pipeline.TransformTask$2.call(TransformTask.java:218)\r\n\tat com.android.builder.profile.ThreadRecorder.record(ThreadRecorder.java:102)\r\n\tat com.android.build.gradle.internal.pipeline.TransformTask.transform(TransformTask.java:213)\r\n\tat sun.reflect.GeneratedMethodAccessor524.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.gradle.internal.reflect.JavaMethod.invoke(JavaMethod.java:73)\r\n\tat org.gradle.api.internal.project.taskfactory.DefaultTaskClassInfoStore$IncrementalTaskAction.doExecute(DefaultTaskClassInfoStore.java:173)\r\n\tat org.gradle.api.internal.project.taskfactory.DefaultTaskClassInfoStore$StandardTaskAction.execute(DefaultTaskClassInfoStore.java:134)\r\n\tat org.gradle.api.internal.project.taskfactory.DefaultTaskClassInfoStore$StandardTaskAction.execute(DefaultTaskClassInfoStore.java:121)\r\n\tat org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$1.run(ExecuteActionsTaskExecuter.java:122)\r\n\tat org.gradle.internal.progress.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:336)\r\n\tat org.gradle.internal.progress.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:328)\r\n\tat org.gradle.internal.progress.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:197)\r\n\tat org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:107)\r\n\tat org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeAction(ExecuteActionsTaskExecuter.java:111)\r\n\tat org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:92)\r\n\t... 30 more\r\nCaused by: com.android.builder.dexing.DexArchiveMergerException: Unable to merge dex\r\n\tat com.android.builder.dexing.DexArchiveMergerCallable.call(DexArchiveMergerCallable.java:72)\r\n\tat com.android.builder.dexing.DexArchiveMergerCallable.call(DexArchiveMergerCallable.java:36)\r\n\tat java.util.concurrent.ForkJoinTask$AdaptedCallable.exec(ForkJoinTask.java:1424)\r\n\t... 57 more\r\nCaused by: com.android.dex.DexException: Multiple dex files define Lorg/tensorflow/lite/NativeInterpreterWrapper;\r\n\tat com.android.dx.merge.DexMerger.readSortableTypes(DexMerger.java:661)\r\n\tat com.android.dx.merge.DexMerger.getSortedTypes(DexMerger.java:616)\r\n\tat com.android.dx.merge.DexMerger.mergeClassDefs(DexMerger.java:598)\r\n\tat com.android.dx.merge.DexMerger.mergeDexes(DexMerger.java:171)\r\n\tat com.android.dx.merge.DexMerger.merge(DexMerger.java:198)\r\n\tat com.android.builder.dexing.DexArchiveMergerCallable.call(DexArchiveMergerCallable.java:61)\r\n\t... 59 more\r\n```\r\n", "comments": ["Solved, clean and rebuild the project after updating everything."]}, {"number": 20730, "title": "tensorflow uses recomputer technology", "body": "System information\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\nTensorFlow installed from (source or binary):source\r\nTensorFlow version (use command below):1.8.0\r\nPython version: 3.5\r\nBazel version (if compiling from source):0.10.0\r\nGCC/Compiler version (if compiling from source): c++11\r\nCUDA/cuDNN version: 9/7\r\nGPU model and memory: gtx 1080ti, 11G\r\nExact command to reproduce:N/A\r\nDescribe the problem:\r\n\r\nIn order to understand how much gpu memory resources tensorflow can economize, I did some experiments.\r\nMy network is vgg-16 and dataset is mnist, batch size is 128. i estimate my gpu memory usage is 2.8GB.\r\nI close  all the RewriterConfig like:\r\n  rewrite_options.memory_optimization = rewriter_config_pb2.RewriterConfig.NO_MEM_OPT\r\n  rewrite_options.layout_optimizer = rewriter_config_pb2.RewriterConfig.OFF\r\n  rewrite_options.function_optimization = rewriter_config_pb2.RewriterConfig.OFF\r\n  rewrite_options.constant_folding = rewriter_config_pb2.RewriterConfig.OFF\r\n  rewrite_options.arithmetic_optimization = rewriter_config_pb2.RewriterConfig.OFF\r\n  rewrite_options.loop_optimization = rewriter_config_pb2.RewriterConfig.OFF\r\n  rewrite_options.dependency_optimization = rewriter_config_pb2.RewriterConfig.OFF\r\nAnd i gradually reduce the amount of gpu memory usage :\r\n\r\nGPU   memory usage | 2.883 | 2.5 | 2 | 1.5 | 1.307\r\n-- | -- | -- | -- | -- | --\r\naverage(iter   5000) | 337.161 | 336.968 | 339.018 | 338.409 | 412.119\r\naverage(iter   50000) | 3350.804 | 3352.093 | 3358.742 | 3373.366 | 4116.673\r\n\r\nI observed that the method used by tensorflow is recomputer. Why use recomputer technology instead of swapping technology? Is recompute faster than swapping? or ?\r\nIn the memory_optimizer.cc:1226, it has RecomputationRewritingPass function. After I close the function to test, i find that tensorflow has other block do same event.\r\nWhy tensorflow has two block to do same event ?\r\n\r\nThanks.\r\n", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 20729, "title": "Person Detection issue in Android App Using tenserflow Lite", "body": "Hi i am Using Android Detection Example App , here  i want to monitor a person in or out activity.\r\nbut my problem is it take more time to detect when a person walk ,some time cnt detect person.\r\n another problem is that after detecting cant track properly ..\r\n is this is the issue of camera video quality..? \r\nhow can i change the quality and  brightness of  camera in this app..?\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "yes i have written custom code on Multiboxtracker.java class.\r\nN/A\r\nN/A\r\nN/A\r\nSir i am using tenserflow Lite on android mobile phone , i am using tenserflow Lite demo app downloaded from  github (tensorflow/tensorflow/examples/android/). my issue is in this app.", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n", "thanks sir ,"]}, {"number": 20728, "title": "An error has occurred,when build the tensorflow demo using Android Studio", "body": "\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)*1.8*:\r\n- **Python version*2.7*: \r\n- **Bazel version (if compiling from source)*0.15.0*:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory*non*:\r\n- **Exact command to reproduce**:\r\nrefer link: https://www.tensorflow.org/mobile/android_build\r\n**### Error info, as follow:**\r\nProxy Authentication Required ( Forefront TMG requires authorization to fulfill the request. Access to the Web Proxy filter is denied.  )\r\n\r\norg.gradle.api.tasks.TaskExecutionException: Execution failed for task ':downloadFile'.\r\n\tat org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:100)\r\n\tat org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:70)\r\n\tat org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:63)\r\n\tat org.gradle.api.internal.tasks.execution.ResolveTaskOutputCachingStateExecuter.execute(ResolveTaskOutputCachingStateExecuter.java:54)\r\n\tat org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58)\r\n\tat org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:88)\r\n\tat org.gradle.api.internal.tasks.execution.ResolveTaskArtifactStateTaskExecuter.execute(ResolveTaskArtifactStateTaskExecuter.java:52)\r\n\tat org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:52)\r\n\tat org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:54)\r\n\tat org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43)\r\n\tat org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:34)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.run(DefaultTaskGraphExecuter.java:248)\r\n\tat org.gradle.internal.progress.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:336)\r\n\tat org.gradle.internal.progress.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:328)\r\n\tat org.gradle.internal.progress.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:197)\r\n\tat org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:107)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:241)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:230)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker.processTask(DefaultTaskPlanExecutor.java:124)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker.access$200(DefaultTaskPlanExecutor.java:80)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker$1.execute(DefaultTaskPlanExecutor.java:105)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker$1.execute(DefaultTaskPlanExecutor.java:99)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskExecutionPlan.execute(DefaultTaskExecutionPlan.java:625)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskExecutionPlan.executeWithTask(DefaultTaskExecutionPlan.java:580)\r\n\tat org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker.run(DefaultTaskPlanExecutor.java:99)\r\n\tat org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:63)\r\n\tat org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:46)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:55)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: org.gradle.api.UncheckedIOException: org.apache.http.client.ClientProtocolException: Proxy Authentication Required ( Forefront TMG requires authorization to fulfill the request. Access to the Web Proxy filter is denied.  )\r\n\tat org.gradle.internal.UncheckedException.throwAsUncheckedException(UncheckedException.java:57)\r\n\tat org.gradle.internal.UncheckedException.throwAsUncheckedException(UncheckedException.java:40)\r\n\tat org.gradle.internal.reflect.JavaMethod.invoke(JavaMethod.java:76)\r\n\tat org.gradle.api.internal.project.taskfactory.DefaultTaskClassInfoStore$StandardTaskAction.doExecute(DefaultTaskClassInfoStore.java:141)\r\n\tat org.gradle.api.internal.project.taskfactory.DefaultTaskClassInfoStore$StandardTaskAction.execute(DefaultTaskClassInfoStore.java:134)\r\n\tat org.gradle.api.internal.project.taskfactory.DefaultTaskClassInfoStore$StandardTaskAction.execute(DefaultTaskClassInfoStore.java:121)\r\n\tat org.gradle.api.internal.AbstractTask$TaskActionWrapper.execute(AbstractTask.java:731)\r\n\tat org.gradle.api.internal.AbstractTask$TaskActionWrapper.execute(AbstractTask.java:705)\r\n\tat org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$1.run(ExecuteActionsTaskExecuter.java:122)\r\n\tat org.gradle.internal.progress.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:336)\r\n\tat org.gradle.internal.progress.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:328)\r\n\tat org.gradle.internal.progress.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:197)\r\n\tat org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:107)\r\n\tat org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeAction(ExecuteActionsTaskExecuter.java:111)\r\n\tat org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:92)\r\n\t... 30 more\r\nCaused by: org.apache.http.client.ClientProtocolException: Proxy Authentication Required ( Forefront TMG requires authorization to fulfill the request. Access to the Web Proxy filter is denied.  )\r\n\tat de.undercouch.gradle.tasks.download.DownloadAction.openConnection(DownloadAction.java:400)\r\n\tat de.undercouch.gradle.tasks.download.DownloadAction.executeHttpProtocol(DownloadAction.java:202)\r\n\tat de.undercouch.gradle.tasks.download.DownloadAction.execute(DownloadAction.java:176)\r\n\tat de.undercouch.gradle.tasks.download.DownloadAction.execute(DownloadAction.java:127)\r\n\tat de.undercouch.gradle.tasks.download.Download.download(Download.java:64)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.gradle.internal.reflect.JavaMethod.invoke(JavaMethod.java:73)\r\n\t... 42 more\r\n\r\n", "comments": ["Try cleaning and rebuilding the project. That's what worked for me.", "Looks like it is failing to download the model:\r\nProxy Authentication Required ( Forefront TMG requires authorization to fulfill the request. Access to the Web Proxy filter is denied. )\r\n\r\nYou may need to configure the Android Studio proxy here: https://developer.android.com/studio/intro/studio-config#proxy\r\n\r\nWe have a convenient gradle task that downloads the model. If you don't want to automatically download the model using gradle, you can copy the models to downloads directory\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/build.gradle#L74 and use it. ", "@yuzhimin999  report back if it didn't work.", "Hi @shashishekhar \r\nUse the website to access such as \"https://storage.googleapis.com/download.tensorflow.org/models/tflite/mobilenet_v1_224_android_quant_2017_11_08.zip\",but Configured for the Android Studio proxy and still has the above errors during build. thanks a lot", "@yuzhimin999 : Which directory did you download the model to, it should be in project buildDirectory. The other way is to copy the model to assets and just change project.ext.TMP_DIR to \r\nprojectDir.toString() + '/assets' in build.gradle", "@yuzhimin999 : Please reopen if you are still having issues."]}, {"number": 20727, "title": "tf.contrib.seq2seq.AttentionWrapperState TypeError: __new__() missing 4 required positional arguments: 'time', 'alignments', 'alignment_history', and 'attention_state'", "body": "in the tensorflow r1.8:\r\n```\r\n tf.contrib.seq2seq.AttentionWrapperState(cell_state, attention, time, alignments, alignment_history,attention_state)\r\n```\r\nin the tensorflow r1.2 \r\n```\r\n tf.contrib.seq2seq.AttentionWrapperState(cell_state, attention, time, alignments, alignment_history,attention_state)\r\n```\r\n\r\nmy code is r1.2, but now i want to run it in the r1.8.\r\n```\r\n initial_state = tf.contrib.seq2seq.AttentionWrapperState(enc_state[0],\r\n                                                             _zero_state_tensors(rnn_size, \r\n                                                                                 batch_size, \r\n                                                                                 tf.float32)) \r\n with tf.variable_scope(\"decode\"):\r\n        training_logits = training_decoding_layer(dec_embed_input, \r\n                                                  summary_length, \r\n                                                  dec_cell, \r\n                                                  initial_state,\r\n                                                  output_layer,\r\n                                                  vocab_size, \r\n                                                  max_summary_length)\r\n    with tf.variable_scope(\"decode\", reuse=True):\r\n        inference_logits = inference_decoding_layer(embeddings,  \r\n                                                    vocab_to_int['<GO>'], \r\n                                                    vocab_to_int['<EOS>'],\r\n                                                    dec_cell, \r\n                                                    initial_state, \r\n                                                    output_layer,\r\n                                                    max_summary_length,\r\n                                                    batch_size)\r\n```\r\nwho can help me ?\r\nbecause the number of the argument of the AttentionWrapperState in the r1.2 is the same to the r1.8 , why it occurs error in the r1.8 , but well in the r1.2?\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n", "Same issue here", "Had the same issue when I moved the old-versioned codes to new environment, but found a workaround, kinda.... \r\nSimply give up initiating it with AttentionWrapperState, and do this:\r\n```\r\ninitial_state = decoder_cell.zero_state(dtype=tf.float32, batch_size=batch_size)\r\ninitial_state = initial_state.clone(cell_state=encoder_state[0])\r\n```\r\nAnd it worked \u30fd(\uff40\u0414\u00b4)\uff89\ufe35 \u253b\u2501\u253b \u253b\u2501\u253b\r\n\r\n(Tensorflow version: 1.13.1)"]}, {"number": 20726, "title": "How to get float type output data from \"dummy-quantization\" model?", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:binary\r\n- **TensorFlow version (use command below)**:1.8.0\r\n- **Python version**: 2.7.3\r\n- **Bazel version (if compiling from source)**:0.12.0\r\n- **GCC/Compiler version (if compiling from source)**: c++11\r\n- **CUDA/cuDNN version**:7.5.18\r\n- **GPU model and memory**:TITAN,12GB\r\n- **Exact command to reproduce**:N/A\r\n\r\n\r\n### Describe the problem\r\nI use \"dummy-quantization\" to generate the quantization type model of deeplabv3(mobilenetv2), the command like below:\r\n`\r\n --input_format=TENSORFLOW_GRAPHDEF \\\r\n  --output_format=TFLITE \\\r\n  --inference_type=QUANTIZED_UINT8 \\\r\n  --input_shape=1,513,513,3 \\\r\n  --input_array=sub_7 \\\r\n  --output_array=logits/semantic/BiasAdd \\\r\n  --default_ranges_min=0 \\\r\n  --default_ranges_max=6 \\\r\n  --mean_value=127.5 \\\r\n  --std_value=127.5`\r\nI want to run this model on the phone, but the output_array is not the last node in model, and I need to get the float type output data of \"logits/semantic/BiasAdd \". Now I use `out_ptr_uint8_t = interpreter->typed_output_tensor<uint8_t>(0);`  to get the uint8_t type output data, can you help me with how to get float type data?\r\n\r\n\r\n", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 20725, "title": "Fix incorrect link in security advisory TFSA-2018-001", "body": "This fix fixes the issue raised in #20722 where the commit link in security advisory TFSA-2018-001 was incorrect.\r\n\r\nThis fix fixes #20722.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 20724, "title": "TF 1.3 with AMD ROCm build error on ARM64 Ubuntu 16.04", "body": "I meet error at ARM64 ubuntu 16.04 with AMD ROCm and TF 1.3 https://github.com/ROCmSoftwarePlatform/tensorflow\r\n\r\nroot@:~/tensorflow# bazel build --config=opt --config=rocm //tensorflow/tools/pip_package:build_pip_package --verbose_failures\r\nERROR: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/io_bazel_rules_closure/closure/filegroup_external.bzl:23:16: name 'set' is not defined\r\nERROR: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/io_bazel_rules_closure/closure/webfiles/web_library.bzl:43:14: name 'set' is not defined\r\nERROR: error loading package '': Extension 'closure/filegroup_external.bzl' has errors\r\nERROR: error loading package '': Extension 'closure/filegroup_external.bzl' has errors\r\nINFO: Elapsed time: 4.595s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)", "comments": ["To build Tensorflow 1.3.0? There's an old version of TF that can only be built with Bazel 0.5.1, according to the tutorial. You have Bazel 0.15, which doesn't support the keyword set in the build scripts\r\n\r\ndownload bazel 0.51\r\nDownload bazel-<version>-dist.zip from the release page.\r\n\r\nNote: There is a single, architecture-independent distribution archive. There are no architecture-specific or OS-specific distribution archives.\r\n \r\nOn Unix-like systems such as Ubuntu Linux or macOS, do the following:\r\n\r\nOpen a shell or Terminal window.\r\n\r\nChange into the directory where you unpacked the distribution archive.\r\n\r\nArm64 patch bazel\r\nhttps://collaborate.linaro.org/display/BDTS/Building+and+Installing+Tensorflow+on+AArch64\r\n\r\nhttps://github.com/bazelbuild/bazel/commit/cc8e7166e29fee39d44e578cf98a06486084a6bd\r\n\r\nRun the compilation script: \r\n$bash ./compile.sh", "This is a very old branch well out of our support window.\r\nAlso support for ROCm is just being merged into our repository.\r\nI am pretty certain that TF 1.3 wont build successfully for ROCm.\r\nYou should reach out to ROCm or the author of the above instructions for this."]}, {"number": 20723, "title": "Mismatched Gradient Update with `tf.gather` Operation", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.7\r\n- **Python version**: 2.7.14 (Anaconda)\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: CUDA 9.0 / cuDNN 7.0\r\n- **GPU model and memory**: NVIDIA GTX 1080Ti\r\n- **Exact command to reproduce**: See below\r\n\r\n### Describe the problem\r\nI met the problem when I use tf.gather to slice into a 1D `codebook`  with the specified index, and generate an output Tensor. The loss function is determined based on the generated output Tensor (In the following code, I simply adopt the reduced sum of output Tensor). Then an optimization phase will be applied to fine tune the `codebook` to minimize the loss. The issue happens there is a mismatched updated codebook results when I use built-in `GradientDescentOptimizer` and manually defined one step update results.\r\n\r\n### Source code / logs\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n# Generate the synthetic codebook and index for testing\r\nN = 16\r\nshape = (4000, 4000)\r\nnp.random.seed(121)\r\ncodebook_np = np.random.randn(N)\r\nindex_np = np.random.randint(low=0, high=N, size=shape)\r\nlr = 0.001\r\n\r\n# Simple computation graph\r\ncodebook = tf.get_variable('codebook', shape=[N], dtype=tf.float32, \r\n                                              initializer=tf.constant_initializer(codebook_np))\r\nindex = tf.constant(index_np, name='index', dtype=tf.int64)\r\noutput = tf.gather(codebook, index, name='output')\r\nloss = tf.reduce_sum(output, name='loss')\r\n[grad_codebook] = tf.gradients(loss, codebook)\r\ngrad_codebook_dense = tf.convert_to_tensor(grad_codebook, name='grad_codebook_dense')\r\ncodebook_update = codebook - lr * grad_codebook_dense\r\nopt = tf.train.GradientDescentOptimizer(lr)\r\ntrain_op = opt.minimize(loss)\r\n\r\nsess = tf.Session()\r\nsess.run(tf.global_variables_initializer())\r\n\r\nprint('codebook [update]')\r\nprint(sess.run(codebook_update))\r\n_ = sess.run(train_op)\r\nprint('codebook [train_opt]:')\r\nprint(sess.run(codebook))\r\n```\r\nI expect to see these 2 updated codebook be same. However, the logs are shown belowed:\r\n```\r\ncodebook [update]\r\n[-1000.6481   -999.8909  -1001.59094 -1002.16235  -999.7602   -998.70636\r\n  -998.9787   -999.86896  -999.7241   -998.3734   -997.3994  -1000.765\r\n  -999.6122  -1000.2615   -997.9392  -1002.35077]\r\ncodebook [train_opt]:\r\n[-991.77435 -991.03503 -992.6951  -993.2531  -990.9072  -989.8781\r\n -990.1441  -991.01355 -990.8721  -989.553   -988.60187 -991.8886\r\n -990.7627  -991.3968  -989.12897 -993.43713]\r\n```\r\nRoughly 1% difference between the updated codebook. The updated code obtained from `train_opt` is always larger than the manually calculated value. \r\n", "comments": ["Nagging Assignee @angersson: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n", "This is just a numerical issue with float32. Replacing `codebook` to float64 in the code above will make the gap disappear."]}, {"number": 20722, "title": "TFSA-2018-001 commit link is invalid", "body": "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/security/advisory/tfsa-2018-001.md\r\n\r\nLinks to:\r\nhttps://github.com/tensorflow/tensorflow/commit/49f73c55d56edffebde4bca4a407ad69c1cae4333c55\r\n\r\nWhich is 404. Can you please update this with the correct commit? Thanks!", "comments": ["Created the PR #20725 for the link fix.", "Thank you for the really quick response!"]}]