[{"number": 32280, "title": "Fix the estimator and tb names.", "body": "", "comments": []}, {"number": 32279, "title": "Clarification in the validation_data argument of fit() in nsl.keras.AdversarialRegularization", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.0.0-rc0 \r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**:\r\n\r\nI am trying the newly released `neural_structured_learning` API. In order to do an experiment, I thought of starting with fine-tuning a VGG16 model and seeing the API's action in that case. I am interested in using the `validation_data` argument while calling `fit()` on a `nsl.keras.AdversarialRegularization` model. \r\n\r\nI tried to do two variants:\r\n\r\nFirst one: \r\n```python\r\nadv_model.fit({'feature': X_train, 'label': y_train},\r\n                   validation_data=(X_val, y_val),\r\n                   batch_size=128, epochs=2, verbose=1)\r\n```\r\n\r\nIt throws:\r\n\r\n```python\r\n---------------------------------------------------------------------------\r\nIndexError                                Traceback (most recent call last)\r\n<ipython-input-63-6a9e8b7f90e8> in <module>()\r\n      2 h = adv_model.fit({'feature': X_train, 'label': y_train},\r\n      3                   validation_data={'feature': X_val, 'label': y_val},\r\n----> 4                   batch_size=128, epochs=2, verbose=1)\r\n      5 print(\"Took {0:.2f} seconds\".format(time.time() - start))\r\n\r\n6 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/data_adapter.py in <genexpr>(.0)\r\n    223       inputs = (x,)\r\n    224 \r\n--> 225     num_samples = set(int(i.shape[0]) for i in nest.flatten(inputs))\r\n    226     if len(num_samples) > 1:\r\n    227       msg = \"Data cardinality is ambiguous:\\n\"\r\n\r\nIndexError: tuple index out of range\r\n```\r\n\r\nSecond one:\r\n```python\r\nadv_model.fit({'feature': X_train, 'label': y_train},\r\n                  validation_data={'feature': X_val, 'label': y_val},\r\n                   batch_size=128, epochs=2, verbose=1)\r\n```\r\n\r\nIt throws:\r\n\r\n```python\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-68-158557e95fb0> in <module>()\r\n      2 h = adv_model.fit({'feature': X_train, 'label': y_train},\r\n      3                   validation_data=(X_val, y_val),\r\n----> 4                   batch_size=128, epochs=2, verbose=1)\r\n      5 print(\"Took {0:.2f} seconds\".format(time.time() - start))\r\n\r\n5 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    732         max_queue_size=max_queue_size,\r\n    733         workers=workers,\r\n--> 734         use_multiprocessing=use_multiprocessing)\r\n    735 \r\n    736   def evaluate(self,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\r\n    222           validation_data=validation_data,\r\n    223           validation_steps=validation_steps,\r\n--> 224           distribution_strategy=strategy)\r\n    225 \r\n    226       total_samples = _get_total_number_of_samples(training_data_adapter)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in _process_training_inputs(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\r\n    561                                     class_weights=class_weights,\r\n    562                                     steps=validation_steps,\r\n--> 563                                     distribution_strategy=distribution_strategy)\r\n    564     elif validation_steps:\r\n    565       raise ValueError('`validation_steps` should not be specified if '\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in _process_inputs(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\r\n    591         batch_size=batch_size,\r\n    592         check_steps=False,\r\n--> 593         steps=steps)\r\n    594   adapter = adapter_cls(\r\n    595       x,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\r\n   2435           feed_input_shapes,\r\n   2436           check_batch_axis=False,  # Don't enforce the batch size.\r\n-> 2437           exception_prefix='input')\r\n   2438 \r\n   2439     # Get typespecs for the input data and sanitize it if necessary.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix)\r\n    528                        'Expected to see ' + str(len(names)) + ' array(s), '\r\n    529                        'but instead got the following list of ' +\r\n--> 530                        str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\r\n    531     elif len(names) > 1:\r\n    532       raise ValueError('Error when checking model ' + exception_prefix +\r\n\r\nValueError: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([[[[132., 140.,  64.],\r\n         [135., 142.,  64.],\r\n         [140., 145.,  64.],\r\n         ...,\r\n         [145., 141.,  70.],\r\n         [146., 134.,  86.],\r\n         [148., 128., 100.]],\r\n\r\n        [...\r\n```\r\n\r\nBut when I fit the model without `validation_data`, it works fine. \r\n\r\n**Describe the expected behavior**\r\n\r\nEither throw some light on the usage in the documentation or in the example.\r\n\r\n**Code to reproduce the issue**\r\n\r\nFor experimentation, I use Colab, so here's the [Colab notebook](https://colab.research.google.com/drive/1vEIpwdmS9Uj_QVlZVqLT5ZQu77BgKNwX). ", "comments": ["@sayakpaul Can you also post this issue on [tensorflow/neural-structured-learning repo](https://github.com/tensorflow/neural-structured-learning/issues) for more visibility to nsl owners? Thanks!", "@sayakpaul Thanks for your interest in Neural Structured Learning. \r\n\r\nI would recommend setting `validation_data` to a `tf.data.Dataset` object. `tf.data.Dataset` is able to handle a nested structure of Tensor / NumPy arrays. For example:\r\n\r\n```python\r\ntrain_data = tf.data.Dataset.from_tensor_slices(\r\n    {'feature': X_train, 'label': y_train}).batch(batch_size)\r\nval_data = tf.data.Dataset.from_tensor_slices(\r\n    {'feature': X_val, 'label': y_val}).batch(batch_size)\r\nval_steps = X_val.shape[0] / batch_size\r\nadv_model.fit(train_data, validation_data=val_data, validation_steps=val_steps,\r\n              epochs=2, verbose=1)\r\n```\r\n\r\nI will update the documentation to include a sample usage with `validation_data`.\r\n\r\nPlease post future issues on the [tensorflow/neural-structured-learning repo](https://github.com/tensorflow/neural-structured-learning/issues). Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32279\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32279\">No</a>\n", "Thanks @csferng. I was going through the image classification tutorial with NSL last night. I really liked the *Robustness Under Adversarial Perturbations* section. I think this ecosystem would definitely allow the community to dig into the world of adversarial learning from a code-first approach. I liked how comprehensive it was. You have the keras-like beautiful abstraction as well as many low-level ops. \r\n\r\nThank you. "]}, {"number": 32278, "title": "tf.keras.datasets.cifar10.load_data() cannot load lcoal files when cifar-10-batches-py mannully put to ~/.keras/dataset/", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.0.0-beta1\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n- tf.keras.datasets.cifar10.load_data() cannot load lcoal files when cifar-10-batches-py mannully put to ~/.keras/dataset/. \r\n- It still try to download dataset online, while my network connection is restricted.\r\n- similar behaviour happens when using tfds.load with data_dir setted\r\n**Describe the expected behavior**\r\nLoad local cifarl dataset to numpy array without reporting any errors\r\n**Code to reproduce the issue**\r\n1. put downloaded  cifar-10-batches-py to ~/.keras/datasets/\r\n2. code:\r\nimport tensorflow as tf\r\n(train_images,train_labels), (_, _) = tf.keras.datasets.cifar10.load_data()\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@kolingv, Could you provide the sample standalone code to reproduce the reported issue here. Thanks!", "@gadagashwini code is easy. Updted. ", "```tf.keras.datasets.cifar10.load_data()``` doesn't require you to store data locally. It provides a convenient option where you can download as well load the data in your instance on the fly.\r\nPerhaps you can use ```tf.keras.utils.get_file``` function to load data stored locally.\r\nSee https://www.tensorflow.org/api_docs/python/tf/keras/utils/get_file", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32278\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32278\">No</a>\n", "@ymodak \r\nAgain, my internet connection is restricted, I am not able to download cifar10 dataset from 'tf.keras.datasets.cifar10.load_data()'. The downloaed IP was blocked.\r\nI can only access it somewhere and put it locally. \r\n\r\nCan't they just add a few line codes to check wether it is already downloaded locally?\r\n\r\nAnyway, there are plenty codes on git to deal with cifar10, I downloaed and fixed it. \r\n\r\nps:  'tf.keras.utils.get_file' requires original url. just a file path cannot make it. I didn't try it since it's a waste of time", "You can do the following:\r\n1. download it from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\r\n2. rename it as cifar-10-batches-py.tar.gz\r\n3. copy it to \uff5e./keras/datasets/", "> You can do the following:\r\n> \r\n> 1. download it from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\r\n> 2. rename it as cifar-10-batches-py.tar.gz\r\n> 3. copy it to \uff5e./keras/datasets/\r\n\r\nThis works perfectly! Anyone facing the same issue, please try renaming the file! Btw the download speed is too slow when you try downloading the dataset locally to your computer", "> You can do the following:\r\n> \r\n> 1. download it from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\r\n> 2. rename it as cifar-10-batches-py.tar.gz\r\n> 3. copy it to \uff5e./keras/datasets/\r\n\r\nI think step 3 was intended to be `cp cifar-10-batches-py.tar.gz ~/.keras/datasets/`\r\nAlternatively: `curl https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz --create-dirs -o ~/.keras/cifar-10-batches-py.tar.gz`", "change the name and copy it to \uff5e./keras/datasets/ works perfect, thanks", "how i can find \uff5e./keras/datasets/ ?", "> how i can find \uff5e./keras/datasets/ ?\r\n\r\nthe path is `\uff5e/.keras/datasets/`", "> how i can find \uff5e./keras/datasets/ ?\r\n\r\nIf you are using anaconda then maybe can find it in C\r\nC:\\Users\\LWU3\\anaconda3\\Lib\\site-packages\\keras\\datasets", "> > how i can find \uff5e./keras/datasets/ ?\r\n> \r\n> the path is `\uff5e/.keras/datasets/`\r\n\r\nOK. Get it.", "> > > how i can find \uff5e./keras/datasets/ ?\r\n> > \r\n> > \r\n> > the path is `\uff5e/.keras/datasets/`\r\n> \r\n> OK. Get it.\r\n\r\nI tried the method in this post didn't work for me...Then I found solution from other post. In case it does not work for you you can run these 2 cmd below before you run the .load_data(). Good luck!\r\n\r\nimport ssl\r\nssl._create_default_https_context = ssl._create_unverified_context"]}, {"number": 32277, "title": "Fix build on Windows", "body": "absl/absl/debugging is not required to build. (build failure if include debugging)", "comments": []}, {"number": 32276, "title": "Memory keeps increasing with GradientTape", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.5\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0rc\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA 10.0.130\r\n- GPU model and memory: GeForce RTX 208, memory 10G\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI create a subclass model with a encoder layer and decoder layer. Encoder is to call tf bidirectional LSTM and decoder is just a dense layer. I train the model with GradientTape, looping to pass data with generator. The GPU memory keep increasing.  \r\n\r\n**Describe the expected behavior**\r\nThe GPU memory usage should be stable after the 1st epoch.\r\n\r\n**Code to reproduce the issue**\r\nI minimize my code and save it to https://github.com/ChenYang-ChenYang/tf-memory-increase\r\nYou can just run train.py to reproduce.\r\n\r\nThe memory increase from 700M at epoch 1 to 1080M at epoch 6 in the sample project. My actual project have much more data and more complex model. The memory increase to 10G after some epochs and OOM, so I can't continue to train.\r\n\r\n**Other info / logs**\r\nIf I change the sample project to use model.compile() and then fit(), instead of using GradientTape, the memory is stable.  But my actual project is complex, including seq2seq addons, multiple outputs and losses, so it is very difficult to change to use model.compile() and fit(). I have to use GradientTape.\r\nIt seems the memory is re-created and not released in each epoch or step.\r\nBy the way, I searched most of the tf memory issues, like https://github.com/tensorflow/tensorflow/issues/32052, https://github.com/tensorflow/tensorflow/issues/19385, https://github.com/tensorflow/tensorflow/issues/19671, none of them are the same or the solution doesn't work. The most common solution to release memory cache is to call tf.set_random_seed(1) in tf version 1.x. I tried to call tf.random.set_seed(1) in tf 2.0 but it didn't work. \r\n\r\n", "comments": ["I tried to execute your code with TF 2.0 rc1 and was not able to reproduce it.\r\nFollowing is the stack trace;\r\n```python\r\n----> 7     while eindex < len(inputs):\r\n      8         batch_input = inputs[sindex:eindex]\r\n      9         batch_target = targets[sindex:eindex]\r\n\r\nTypeError: object of type 'Tensor' has no len()\r\n```\r\nCan you please confirm? Thanks!\r\n", "@ymodak Thanks for the reply. how did you run the code? I tried again just now to download the project https://github.com/ChenYang-ChenYang/tf-memory-increase, activate my virtual environment in anaconda with tf 2.0rc, and can run 'python train.py' successfully. \r\nThe len() is called in get_batch() in train.py to create data generator. It should work in eager mode. ", "any update on the issue?", "Hi, sorry for the last response.  I just tried but couldn't reproduce.  Possibly it's already fixed.\r\n\r\nhttps://colab.corp.google.com/drive/1-AN8UK9fdufKc_S94gq9e5SyITRvbYh7#scrollTo=W44iBKEPMIF8\r\n\r\n```\r\nIteration 1   1049.54mb\r\nIteration 2   1057.66mb\r\nIteration 3   1056.96mb\r\nIteration 4   1063.93mb\r\nIteration 5   1059.28mb\r\nIteration 6   1067.30mb\r\nIteration 7   1061.53mb\r\nIteration 8   1068.94mb\r\nIteration 9   1064.90mb\r\nIteration 10  1072.23mb\r\nIteration 11  1066.85mb\r\nIteration 12  1074.11mb\r\nIteration 13  1070.71mb\r\nIteration 14  1075.72mb\r\nIteration 15  1071.78mb\r\nIteration 16  1077.85mb\r\nIteration 17  1073.74mb\r\nIteration 18  1079.09mb\r\nIteration 19  1074.56mb\r\nIteration 20  1080.32mb\r\n```\r\n\r\n\r\nCould you try tf-nightly to confirm? https://pypi.org/project/tf-nightly/\r\n", "Public colab: https://colab.sandbox.google.com/gist/kkimdev/11ab2ccc36859092d4b2384fd7d0ecbe/memory-keeps-increasing-with-gradienttape-github-32276-public.ipynb#scrollTo=eACARpHcscHi\r\n\r\n```\r\nIteration 0   1076.60mb\r\nIteration 1   2019.26mb\r\nIteration 2   2031.22mb\r\nIteration 3   2031.58mb\r\nIteration 4   2031.50mb\r\nIteration 5   2031.49mb\r\nIteration 6   2031.49mb\r\nIteration 7   2031.49mb\r\nIteration 8   2031.48mb\r\nIteration 9   2031.48mb\r\nIteration 10  2031.47mb\r\nIteration 11  2031.46mb\r\nIteration 12  2031.46mb\r\nIteration 13  2031.46mb\r\nIteration 14  2031.45mb\r\nIteration 15  2031.45mb\r\nIteration 16  2031.46mb\r\nIteration 17  2031.46mb\r\nIteration 18  2031.43mb\r\nIteration 19  2031.43mb\r\nIteration 20  2031.43mb\r\n```", "@kkimdev I verified with the same code on TF 2.0 stable version and the memory didn't increase after 9 epochs. The issue should have been resolved. I will close the case. Thanks."]}, {"number": 32275, "title": "Pin Tensorboard and estimator versions to a working nightly.", "body": "", "comments": []}, {"number": 32274, "title": "Update losses.py", "body": "In response to [issue](https://github.com/tensorflow/tensorflow/issues/32231)\r\nThe current axis (1) works only for Rank 2 tensors so changed it to -1 which works for  higher rank tensors (> 2). ", "comments": ["Thank you for the PR, can you add a test case for this fix?", "Please refer to this [notebook](https://colab.research.google.com/drive/17_8_ikj71Pb1i3_5eIxN5crLJfeEUSs4#scrollTo=dONBpiRPcuE9)", "Can you add a test case to the losses_test.py file that verifies the fix?", "@pavithrasv Updated losses_test.py please [verify](https://github.com/praveenjune17/tensorflow/blob/master/tensorflow/python/keras/losses_test.py)", "@pavithrasv  Can you please take a look on this PR? Thanks!", "@praveenjune17 Can you please check build failures. Thanks!", "@gbaned  seems the issue is due to the outdated code, the decorator '@test_util' needs to replaced. According to the logs..\r\n\r\nTraceback (most recent call last):\r\n  File \"/Volumes/BuildData/tmpfs/tmp/bazel/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/python/keras/losses_test.runfiles/org_tensorflow/tensorflow/python/keras/losses_test.py\", line 49, in <module>\r\n    class KerasLossesTest(test.TestCase, parameterized.TestCase):\r\n  File \"/Volumes/BuildData/tmpfs/tmp/bazel/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/python/keras/losses_test.runfiles/org_tensorflow/tensorflow/python/keras/losses_test.py\", line 117, in KerasLossesTest\r\n    @test_util.run_in_graph_and_eager_modes\r\nNameError: name 'test_util' is not defined\r\n\r\nSo I guess we need to replace \r\n--> @test_util.run_in_graph_and_eager_modes, by    \r\n--> @combinations.generate(combinations.combine(mode=['graph', 'eager'])). Since this is my first pull request in this repo I need help from someone to confirm the same.\r\n\r\n", "@pavithrasv Can you please assist on above comments from @praveenjune17. Thanks!", "@gbaned seems this has been fixed please [refer](https://github.com/tensorflow/tensorflow/pull/36990). Thanks!"]}, {"number": 32273, "title": "SSD anchors in Tensorflow detection API", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Non\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.12\r\n- Python version: python2.7\r\n- CUDA/cuDNN version: CUDA 10.0/ cuDNN 7.4.1\r\n- GPU model and memory: 1080Ti, 12GB\r\n\r\n**Describe the current behavior**\r\nDefault SSD_mobilenet_V2_config is below.\r\n```\r\nanchor_generator {\r\n  ssd_anchor_generator {\r\n    num_layers: 6\r\n    min_scale: 0.2\r\n    max_scale: 0.9\r\n    aspect_ratios: 1.0\r\n    aspect_ratios: 2.0\r\n    aspect_ratios: 0.5\r\n    aspect_ratios: 3.0\r\n    aspect_ratios: 0.33\r\n    }\r\n}\r\nimage_resizer {\r\n      fixed_shape_resizer {\r\n        height: 300\r\n        width: 300\r\n      }\r\n}\r\n```\r\nIf I set image_resizer {width:600, height:450} (4:3 input size), would base_anchor_size be set square or rectangle? [link](https://github.com/tensorflow/models/blob/1af55e018eebce03fb61bba9959a04672536107d/research/object_detection/anchor_generators/multiple_grid_anchor_generator.py#L213)\r\n```\r\nimage_resizer {\r\n      fixed_shape_resizer {\r\n        height: 450\r\n        width: 600\r\n      }\r\n}\r\n```\r\nI trace the ssd_anchor_create func code, it seems to set rectangle-like base_anchor_size, right?\r\n```\r\n    min_im_shape = tf.minimum(im_height, im_width)\r\n    scale_height = min_im_shape / im_height\r\n    scale_width = min_im_shape / im_width\r\n    base_anchor_size = [\r\n        scale_height * self._base_anchor_size[0],\r\n        scale_width * self._base_anchor_size[1]\r\n    ]\r\n```\r\n\r\nI want to ask how could I set specific size of anchor box for each layer?\r\nHow to check details of anchor bboxes after training model?\r\nThanks a lot\r\n\r\n", "comments": ["@wulungching This is more related to models repository. Could you post it in models repo [here](https://github.com/tensorflow/models/issues) and close this issue from this repo. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32273\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32273\">No</a>\n"]}, {"number": 32272, "title": "[r2.0-rc1 CherryPick]: Improve Layer docstrings in regards to autocasting.", "body": "I fixed the examples so they actually can run now. And I mentioned that currently, only the first argument to call() is casted.\r\n\r\nPiperOrigin-RevId: 262603558", "comments": []}, {"number": 32271, "title": "XLA inference slower than plain TF inference for ResNet50 (0.084s vs 0.115s) .", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.14\r\n- Python version: 2.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:10.1\r\n- GPU model and memory: T4\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nDo not see any  inference speedup  with  XLA enabled through TF_XLA_FLAGS=--tf_xla_auto_jit=2\r\n\r\n**Describe the expected behavior**\r\nExpected to see some improvement.  \r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\n# to run python ./xla_resnet2x.py --runtime TFXLACOMP\r\nfrom tensorflow.contrib.slim.nets import resnet_v1\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.slim as slim\r\nimport numpy as np\r\nimport time\r\nimport os\r\nfrom PIL import Image\r\nfrom tensorflow.contrib.compiler import xla\r\nimport argparse\r\n\r\nPATH_TO_CKPT = \"resnet_v1_50.ckpt\"\r\nTEST_IMAGE_PATHS = [ \"elephant_small.jpg\", \"tabby_tiger_cat.jpg\"]\r\nBATCH_SIZE=25\r\nMAX_BATCH_SIZE=1000\r\nHEIGHT=224\r\nWIDTH=224\r\nCHANNELS=3\r\n\r\n\r\ndef load_image_into_numpy_array(image, batch_size=1):\r\n  (im_width, im_height) = image.size\r\n  x = np.array(image.getdata()).reshape(\r\n      (HEIGHT, WIDTH, CHANNELS)).astype(np.uint8)\r\n  x = np.expand_dims(x, axis=0)\r\n  xsl = list (x.shape)\r\n  xsl[0] = batch_size#MAX_BATCH_SIZE\r\n  x = np.broadcast_to(x[0,:,:,:], xsl)\r\n  return x\r\n\r\ndef run_resnet_50():\r\n    # Create graph\r\n    inputs = tf.placeholder(tf.float32, shape=[BATCH_SIZE, HEIGHT, WIDTH, CHANNELS])\r\n    with slim.arg_scope(resnet_v1.resnet_arg_scope()):\r\n            net, end_points = resnet_v1.resnet_v1_50(inputs, is_training=False)\r\n\r\n    saver = tf.train.Saver()\r\n\r\n    with tf.Session() as sess:\r\n            saver.restore(sess, PATH_TO_CKPT)\r\n            representation_tensor = sess.graph.get_tensor_by_name('resnet_v1_50/pool5:0') # if you don't know names like these, consider referring to corresponding model file or generate .pbtxt file as mentioned in  @civilman628 's answer above\r\n            img = np.ones((batch_size, height, width, channels))   #load image here with size [1, 224,224, 3]\r\n            features = sess.run(representation_tensor, {'Placeholder:0': img})\r\n            print ( \"features\", features)\r\n\r\ndef renamed_ckpt_save(name):\r\n    with tf.Session() as sess:# Restore the TF checkpoint\r\n\r\n        for var_name, var_shape in tf.contrib.framework.list_variables(PATH_TO_CKPT):\r\n            var = tf.contrib.framework.load_variable(PATH_TO_CKPT, var_name)\r\n            new_name_parts = [name] + var_name.split('/')[1:]\r\n            new_name = '/'.join(new_name_parts)\r\n            var = tf.Variable(var, name=new_name)\r\n            print var_name, var_shape, var.name\r\n\r\n        ckpt_dir = \"/tmp/\"+name\r\n        if not os.path.exists(ckpt_dir):\r\n            os.mkdir(ckpt_dir)\r\n        sess.run(tf.global_variables_initializer())\r\n        saver = tf.train.Saver()\r\n        saver.save(sess, ckpt_dir)\r\n\r\ndef renamed_ckpt_mem(sess, name):\r\n\r\n        for var_name, var_shape in tf.contrib.framework.list_variables(PATH_TO_CKPT):\r\n            var = tf.contrib.framework.load_variable(PATH_TO_CKPT, var_name)\r\n            new_name_parts = [name] + var_name.split('/')[1:]\r\n            new_name = '/'.join(new_name_parts)\r\n            var = tf.Variable(var, name=new_name)\r\n            print var_name, var_shape, var.name\r\n\r\ndef build_graph_xla (inputs):\r\n\r\n    with slim.arg_scope(resnet_v1.resnet_arg_scope()):\r\n            net, end_points = resnet_v1.resnet_v1_50(inputs, is_training=False, scope=name)\r\n\r\n    if True: #with input_graph.as_default():\r\n      # Get handles to input and output tensors\r\n      ops = tf.get_default_graph().get_operations()\r\n      all_tensor_names = {output.name for op in ops for output in op.outputs}\r\n      tensor_dict = {}\r\n      for key in [\r\n          'pool5',\r\n      ]:\r\n        if name == '':\r\n            tensor_name = key + ':0'\r\n        else :\r\n            tensor_name = name+'/'+key + ':0'\r\n        if tensor_name in all_tensor_names:\r\n                tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\r\n                tensor_name)\r\n                print ( \"tensor_name\", tensor_name, tensor_dict[key])\r\n        else:\r\n           print( \"tensor_name \", tensor_name, \" not found\")\r\n\r\n    return tensor_dict\r\n\r\ndef restore_graph_xla (sess, name):\r\n    # Restore the TF checkpoint\r\n    saver = tf.train.Saver()\r\n    saver.restore(sess, \"/tmp/\"+name)\r\n\r\ndef build_graph (sess, input_graph, name='graph1'):\r\n\r\n    inputs = tf.placeholder(tf.float32, shape=[BATCH_SIZE, HEIGHT, WIDTH, CHANNELS])\r\n\r\n    with slim.arg_scope(resnet_v1.resnet_arg_scope()):\r\n            net, end_points = resnet_v1.resnet_v1_50(inputs, is_training=False, scope=name)\r\n\r\n    with input_graph.as_default():\r\n      # Get handles to input and output tensors\r\n      ops = tf.get_default_graph().get_operations()\r\n      all_tensor_names = {output.name for op in ops for output in op.outputs}\r\n      tensor_dict = {}\r\n      for key in [\r\n          'pool5',\r\n      ]:\r\n        if name == '':\r\n            tensor_name = key + ':0'\r\n        else :\r\n            tensor_name = name+'/'+key + ':0'\r\n        if tensor_name in all_tensor_names:\r\n                tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\r\n                tensor_name)\r\n                print ( \"tensor_name\", tensor_name, tensor_dict[key])\r\n        else:\r\n           print( \"tensor_name \", tensor_name, \" not found\")\r\n\r\n\r\n    # Restore the TF checkpoint\r\n    saver = tf.train.Saver()\r\n    saver.restore(sess, \"/tmp/\"+name)\r\n    return tensor_dict\r\n\r\nclass TfXla():\r\n    name = ''\r\n\r\n    @staticmethod\r\n    def build_graph_xla (inputs):\r\n\r\n        with slim.arg_scope(resnet_v1.resnet_arg_scope()):\r\n                net, end_points = resnet_v1.resnet_v1_50(inputs, is_training=False, scope=TfXla.name)\r\n\r\n        if True: #with input_graph.as_default():\r\n          # Get handles to input and output tensors\r\n          ops = tf.get_default_graph().get_operations()\r\n          all_tensor_names = {output.name for op in ops for output in op.outputs}\r\n          tensor_dict = {}\r\n          for key in [\r\n              'pool5',\r\n          ]:\r\n            if TfXla.name == '':\r\n                tensor_name = key + ':0'\r\n            else :\r\n                tensor_name = TfXla.name+'/'+key + ':0'\r\n            if tensor_name in all_tensor_names:\r\n                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\r\n                    tensor_name)\r\n                    print ( \"tensor_name\", tensor_name, tensor_dict[key])\r\n            else:\r\n               print( \"tensor_name \", tensor_name, \" not found\")\r\n\r\n        return tensor_dict\r\n\r\n    @staticmethod\r\n    def restore_graph_xla (sess, name):\r\n        # Restore the TF checkpoint\r\n        saver = tf.train.Saver()\r\n        saver.restore(sess, \"/tmp/\"+name)\r\n\r\n    @staticmethod\r\n    def build(sess, input_graph, name='', import_name='import'):\r\n        TfXla.name = name\r\n        with input_graph.as_default():\r\n            inputs = tf.placeholder(tf.float32, shape=[BATCH_SIZE, HEIGHT, WIDTH, CHANNELS])\r\n            tensor_dict = xla.compile (TfXla.build_graph_xla, [inputs,])\r\n            restore_graph_xla(sess, name)\r\n        return tensor_dict\r\n\r\n    @staticmethod\r\n    def run(sess, tensor_dict, image_tensor, image_np_expanded):\r\n        output_dict = sess.run(tensor_dict, feed_dict={image_tensor: image_np_expanded})\r\n        return output_dict\r\n\r\nclass Tf():\r\n\r\n    @staticmethod\r\n    def build(sess, graph, name='', import_name=None):\r\n        return build_graph(sess, graph, name=name)\r\n\r\n    @staticmethod\r\n    def run(sess, tensor_dict, image_tensor, image_np_expanded):\r\n        output_dict = sess.run(tensor_dict, feed_dict={image_tensor: image_np_expanded})\r\n        return output_dict\r\ndef run (runtime='TF', amp=False):\r\n\r\n    if runtime=='TF':\r\n        RunClass = Tf\r\n        import_name1= ''\r\n        import_name2= ''\r\n        placeholder_name1 = 'Placeholder:0'\r\n        placeholder_name2 = 'Placeholder_1:0'\r\n    elif runtime=='TFXLACOMP':\r\n        print (\"Setting XLA compile\")\r\n        RunClass = TfXla\r\n        #import_name1 = 'import1'\r\n        #import_name2 = 'import2'\r\n        #placeholder_name1 = 'import1/Placeholder:0'\r\n        #placeholder_name2 = 'import2/Placeholder_1:0'\r\n        import_name1= ''\r\n        import_name2= ''\r\n        placeholder_name1 = 'Placeholder:0'\r\n        placeholder_name2 = 'Placeholder_1:0'\r\n    elif runtime=='TFXLA':\r\n        os.environ['TF_XLA_FLAGS'] = \"--tf_xla_auto_jit=2\"\r\n        print (\"Setting XLA auto clustering\")\r\n        RunClass = Tf\r\n        #import_name1 = 'import1'\r\n        #import_name2 = 'import2'\r\n        #placeholder_name1 = 'import1/Placeholder:0'\r\n        #placeholder_name2 = 'import2/Placeholder_1:0'\r\n        import_name1= ''\r\n        import_name2= ''\r\n        placeholder_name1 = 'Placeholder:0'\r\n        placeholder_name2 = 'Placeholder_1:0'\r\n\r\n    graph = tf.Graph()\r\n\r\n    config = tf.ConfigProto()\r\n    config.gpu_options.allow_growth = True\r\n    #config.gpu_options.per_process_gpu_memory_fraction = 0.33\r\n    if amp:\r\n        config.graph_options.rewrite_options.auto_mixed_precision = 1\r\n        print \"Enabling AMP\"\r\n    with tf.Session(graph=graph, config=config) as sess:\r\n        #renamed_ckpt_mem(sess, 'resnet_v1_50_1')\r\n        #renamed_ckpt_mem(sess, 'resnet_v1_50_2')\r\n        tensor_dict1 = RunClass.build(sess, graph, name='resnet_v1_50_1', import_name=import_name1)\r\n        #tensor_dict2 = tensor_dict1 RunClass.build(sess, graph, name='resnet_v1_50_2', import_name=import_name2)\r\n        tensorboard_dir = os.environ['TENSORBOARD_DIR']\r\n        file_writer = tf.summary.FileWriter(tensorboard_dir, sess.graph)\r\n        image_path = TEST_IMAGE_PATHS[0]\r\n        print ( \"image_path {}\".format(image_path))\r\n        image = Image.open(image_path)\r\n        image = image.resize((WIDTH, HEIGHT))\r\n        image_np_expanded = load_image_into_numpy_array(image, batch_size=BATCH_SIZE)\r\n        image_tensor1 = graph.get_tensor_by_name(placeholder_name1)\r\n        #image_tensor2 = graph.get_tensor_by_name(placeholder_name2)\r\n        time0 = time.time()\r\n        for i in range(1,2001):\r\n            output_dict1 = RunClass.run(sess, tensor_dict1, image_tensor1, image_np_expanded)\r\n            #output_dict2 = RunClass.run(sess, tensor_dict2, image_tensor2, image_np_expanded)\r\n            if i % 100 == 0:\r\n                time_taken = (time.time() - time0 )/(i * 1.0)\r\n                print (i, time_taken)\r\n        time_taken = (time.time() - time0 )/(i * 1.0)\r\n        print (\"time_taken pb \", time_taken, \" pf \", time_taken/BATCH_SIZE , \"output_dict\", output_dict1, 'output_dict2')\r\n\r\nif __name__ == '__main__':\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument('--runtime', default='TF', help='TF or TFXLA or TFXLACOMP')\r\n    parser.add_argument('--amp', action='store_true', help='enable AMP')\r\n    parser.add_argument('--rewrite_ckpt', action='store_true',  help='rename checkpoints')\r\n    args = parser.parse_args()\r\n    if args.rewrite_ckpt:\r\n        renamed_ckpt_save('resnet_v1_50_1')\r\n        renamed_ckpt_save('resnet_v1_50_2')\r\n\r\n    run (args.runtime, args.amp)\r\n\r\n\r\n```\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@sgambient, Please provide us the minimal standalone code snippet. It will indeed help us to move faster. Thanks!", "I am not sure about what minimal is for you, but the following is a compact code for you to play with.   You will obviously need to  get the resNet50 checkpoint and test images.   Running is simple : python ./xla_resnet2x.py --runtime TFXLA (or TF) .  At the end of  a 2K iteration you will get an output with per batch/frame time.  \r\n\r\n```\r\nfrom tensorflow.contrib.slim.nets import resnet_v1\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.slim as slim\r\nimport numpy as np\r\nimport time\r\nimport os\r\nfrom PIL import Image\r\nfrom tensorflow.contrib.compiler import xla\r\nimport argparse\r\n\r\nPATH_TO_CKPT = \"resnet_v1_50.ckpt\"\r\nTEST_IMAGE_PATHS = [ \"elephant_small.jpg\", \"tabby_tiger_cat.jpg\"]\r\nBATCH_SIZE=25\r\nMAX_BATCH_SIZE=1000\r\nHEIGHT=224\r\nWIDTH=224\r\nCHANNELS=3\r\n\r\n\r\ndef load_image_into_numpy_array(image, batch_size=1):\r\n  (im_width, im_height) = image.size\r\n  x = np.array(image.getdata()).reshape(\r\n      (HEIGHT, WIDTH, CHANNELS)).astype(np.uint8)\r\n  x = np.expand_dims(x, axis=0)\r\n  xsl = list (x.shape)\r\n  xsl[0] = batch_size#MAX_BATCH_SIZE\r\n  x = np.broadcast_to(x[0,:,:,:], xsl)\r\n  return x\r\n\r\ndef run_resnet_50():\r\n    # Create graph\r\n    inputs = tf.placeholder(tf.float32, shape=[BATCH_SIZE, HEIGHT, WIDTH, CHANNELS])\r\n    with slim.arg_scope(resnet_v1.resnet_arg_scope()):\r\n            net, end_points = resnet_v1.resnet_v1_50(inputs, is_training=False)\r\n\r\n    saver = tf.train.Saver()\r\n\r\n    with tf.Session() as sess:\r\n            saver.restore(sess, PATH_TO_CKPT)\r\n            representation_tensor = sess.graph.get_tensor_by_name('resnet_v1_50/pool5:0') # if you don't know names like these, consider referring to corresponding model file or generate .pbtxt file as mentioned in  @civilman628 's answer above\r\n            img = np.ones((batch_size, height, width, channels))   #load image here with size [1, 224,224, 3]\r\n            features = sess.run(representation_tensor, {'Placeholder:0': img})\r\n            print ( \"features\", features)\r\n\r\ndef build_graph (sess, input_graph, name='graph1'):\r\n\r\n    inputs = tf.placeholder(tf.float32, shape=[BATCH_SIZE, HEIGHT, WIDTH, CHANNELS])\r\n\r\n    with slim.arg_scope(resnet_v1.resnet_arg_scope()):\r\n            net, end_points = resnet_v1.resnet_v1_50(inputs, is_training=False, scope=name)\r\n\r\n    with input_graph.as_default():\r\n      # Get handles to input and output tensors\r\n      ops = tf.get_default_graph().get_operations()\r\n      all_tensor_names = {output.name for op in ops for output in op.outputs}\r\n      tensor_dict = {}\r\n      for key in [\r\n          'pool5',\r\n      ]:\r\n        if name == '':\r\n            tensor_name = key + ':0'\r\n        else :\r\n            tensor_name = name+'/'+key + ':0'\r\n        if tensor_name in all_tensor_names:\r\n                tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\r\n                tensor_name)\r\n                print ( \"tensor_name\", tensor_name, tensor_dict[key])\r\n        else:\r\n           print( \"tensor_name \", tensor_name, \" not found\")\r\n\r\n\r\n    # Restore the TF checkpoint\r\n    saver = tf.train.Saver()\r\n    saver.restore(sess, \"/tmp/\"+name)\r\n    return tensor_dict\r\n\r\nclass TfXla():\r\n    name = ''\r\n\r\n    @staticmethod\r\n    def build_graph_xla (inputs):\r\n\r\n        with slim.arg_scope(resnet_v1.resnet_arg_scope()):\r\n                net, end_points = resnet_v1.resnet_v1_50(inputs, is_training=False, scope=TfXla.name)\r\n\r\n        if True: #with input_graph.as_default():\r\n          # Get handles to input and output tensors\r\n          ops = tf.get_default_graph().get_operations()\r\n          all_tensor_names = {output.name for op in ops for output in op.outputs}\r\n          tensor_dict = {}\r\n          for key in [\r\n              'pool5',\r\n          ]:\r\n            if TfXla.name == '':\r\n                tensor_name = key + ':0'\r\n            else :\r\n                tensor_name = TfXla.name+'/'+key + ':0'\r\n            if tensor_name in all_tensor_names:\r\n                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\r\n                    tensor_name)\r\n                    print ( \"tensor_name\", tensor_name, tensor_dict[key])\r\n            else:\r\n               print( \"tensor_name \", tensor_name, \" not found\")\r\n\r\n        return tensor_dict\r\n\r\n    @staticmethod\r\n    def restore_graph_xla (sess, name):\r\n        # Restore the TF checkpoint\r\n        saver = tf.train.Saver()\r\n        saver.restore(sess, \"/tmp/\"+name)\r\n\r\n    @staticmethod\r\n    def build(sess, input_graph, name='', import_name='import'):\r\n        TfXla.name = name\r\n        with input_graph.as_default():\r\n            inputs = tf.placeholder(tf.float32, shape=[BATCH_SIZE, HEIGHT, WIDTH, CHANNELS])\r\n            tensor_dict = xla.compile (TfXla.build_graph_xla, [inputs,])\r\n            restore_graph_xla(sess, name)\r\n        return tensor_dict\r\n\r\n    @staticmethod\r\n    def run(sess, tensor_dict, image_tensor, image_np_expanded):\r\n        output_dict = sess.run(tensor_dict, feed_dict={image_tensor: image_np_expanded})\r\n        return output_dict\r\n\r\nclass Tf():\r\n\r\n    @staticmethod\r\n    def build(sess, graph, name='', import_name=None):\r\n        return build_graph(sess, graph, name=name)\r\n\r\n    @staticmethod\r\n    def run(sess, tensor_dict, image_tensor, image_np_expanded):\r\n        output_dict = sess.run(tensor_dict, feed_dict={image_tensor: image_np_expanded})\r\n        return output_dict\r\n\r\ndef run (runtime='TF', amp=False):\r\n\r\n    if runtime=='TF':\r\n        RunClass = Tf\r\n        import_name1= ''\r\n        import_name2= ''\r\n        placeholder_name1 = 'Placeholder:0'\r\n        placeholder_name2 = 'Placeholder_1:0'\r\n    elif runtime=='TFXLACOMP':\r\n        print (\"Setting XLA compile\")\r\n        RunClass = TfXla\r\n        #import_name1 = 'import1'\r\n        #import_name2 = 'import2'\r\n        #placeholder_name1 = 'import1/Placeholder:0'\r\n        #placeholder_name2 = 'import2/Placeholder_1:0'\r\n        import_name1= ''\r\n        import_name2= ''\r\n        placeholder_name1 = 'Placeholder:0'\r\n        placeholder_name2 = 'Placeholder_1:0'\r\n    elif runtime=='TFXLA':\r\n        os.environ['TF_XLA_FLAGS'] = \"--tf_xla_auto_jit=2\"\r\n        print (\"Setting XLA auto clustering\")\r\n        RunClass = Tf\r\n        #import_name1 = 'import1'\r\n        #import_name2 = 'import2'\r\n        #placeholder_name1 = 'import1/Placeholder:0'\r\n        #placeholder_name2 = 'import2/Placeholder_1:0'\r\n        import_name1= ''\r\n        import_name2= ''\r\n        placeholder_name1 = 'Placeholder:0'\r\n        placeholder_name2 = 'Placeholder_1:0'\r\n\r\n    graph = tf.Graph()\r\n\r\n    config = tf.ConfigProto()\r\n    config.gpu_options.allow_growth = True\r\n    #config.gpu_options.per_process_gpu_memory_fraction = 0.33\r\n    if amp:\r\n        config.graph_options.rewrite_options.auto_mixed_precision = 1\r\n        print \"Enabling AMP\"\r\n    with tf.Session(graph=graph, config=config) as sess:\r\n        tensor_dict1 = RunClass.build(sess, graph, name='resnet_v1_50_1', import_name=import_name1)\r\n        #tensor_dict2 = tensor_dict1 RunClass.build(sess, graph, name='resnet_v1_50_2', import_name=import_name2)\r\n        tensorboard_dir = os.environ['TENSORBOARD_DIR']\r\n        file_writer = tf.summary.FileWriter(tensorboard_dir, sess.graph)\r\n        image_path = TEST_IMAGE_PATHS[0]\r\n        print ( \"image_path {}\".format(image_path))\r\n        image = Image.open(image_path)\r\n        image = image.resize((WIDTH, HEIGHT))\r\n        image_np_expanded = load_image_into_numpy_array(image, batch_size=BATCH_SIZE)\r\n        image_tensor1 = graph.get_tensor_by_name(placeholder_name1)\r\n        #image_tensor2 = graph.get_tensor_by_name(placeholder_name2)\r\n        time0 = time.time()\r\n        for i in range(1,2001):\r\n            output_dict1 = RunClass.run(sess, tensor_dict1, image_tensor1, image_np_expanded)\r\n            #output_dict2 = RunClass.run(sess, tensor_dict2, image_tensor2, image_np_expanded)\r\n            if i % 100 == 0:\r\n                time_taken = (time.time() - time0 )/(i * 1.0)\r\n                print (i, time_taken)\r\n        time_taken = (time.time() - time0 )/(i * 1.0)\r\n        print (\"time_taken per batch \", time_taken, \" per frame \", time_taken/BATCH_SIZE , )\r\n        print (\"output_dict\", output_dict1,)\r\n\r\nif __name__ == '__main__':\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument('--runtime', default='TF', help='TF or TFXLA or TFXLACOMP')\r\n    parser.add_argument('--amp', action='store_true', help='enable AMP')\r\n    args = parser.parse_args()\r\n    run (args.runtime, args.amp)\r\n\r\n```", "@sgambient, Thanks for updating the code. Please provide the resnet_v1_50.ckpt file. Thanks!", "The checkpoints are available at https://github.com/tensorflow/models/tree/master/research/slim .", "Where can I get the \"elephant_small.jpg\" and \"tabby_tiger_cat.jpg\" files?", "You can get those from the NVIDIA TensorRT download at https://developer.nvidia.com/nvidia-tensorrt-5x-download \r\n\r\n```\r\nensorrt# tar ztvf TensorRT-5.1.5.0.Ubuntu-16.04.5.x86_64-gnu.cuda-10.1.cudnn7.5.tar.gz | grep jpg\r\n-rw-rw-r-- erisuser/erisuser 1415684 2019-04-27 04:50 TensorRT-5.1.5.0/samples/python/uff_ssd/images/image2.jpg\r\n-rw-rw-r-- erisuser/erisuser  129862 2019-04-27 04:50 TensorRT-5.1.5.0/samples/python/uff_ssd/images/image1.jpg\r\n-rw-rw-r-- erisuser/erisuser  110969 2019-04-27 04:48 TensorRT-5.1.5.0/data/resnet50/tabby_tiger_cat.jpg\r\n-rw-rw-r-- erisuser/erisuser     60376 2019-04-27 04:48 TensorRT-5.1.5.0/data/resnet50/elephant_small.jpg\r\n\r\n```\r\n", "Thanks for your help @sgambient I'm able to run your program now.  However I can't reproduce the performance regression.\r\n\r\nOn a Titan-V I get:\r\n\r\n`--runtime=TF`: \r\ntime_taken per batch  0.043322897791862484  per frame  0.0017329159116744994\r\n\r\n`--runtime=TFXLA`:\r\ntime_taken per batch  0.04307499623298645  per frame  0.0017229998493194579\r\n\r\nOn a P100 I get:\r\n`--runtime=TF`: \r\ntime_taken per batch  0.05641450345516205  per frame  0.002256580138206482\r\n\r\n`--runtime=TFXLA`:\r\ntime_taken per batch  0.055896294474601746  per frame  0.00223585177898407                                                                          \r\n\r\nIt would be great if you could file a bug with some more information as outlined in https://www.tensorflow.org/xla#generating_great_bug_reports to help us reproduce the regression.", "Would be glad to .  However the following are  not generating anything in /tmp/generated . \r\n\r\n```\r\nTF_DUMP_GRAPH_PREFIX=/tmp/generated TF_XLA_FLAGS=\"--tf_xla_clustering_debug --tf_xla_auto_jit=2\" python ./xla_resnet2x.py --runtime TFXLA\r\n```\r\n\r\n```\r\nTF_DUMP_GRAPH_PREFIX=/tmp/generated TF_XLA_FLAGS=\"--tf_xla_clustering_debug --tf_xla_auto_jit=2 --dump_hlo_as_text --xla_dump_to=/tmp/generated\" python ./xla_resnet2x.py --runtime TFXLA\r\n```\r\n\r\n", "I suspect that's because your script is overriding the `TF_XLA_FLAGS` environment variable and thus the debugging flags are not being propagated.", "Here is the generated bug report.  The \"--dump_hlo_as_text\"  was not liked, hence had to be removed. \r\n\r\n\r\n", "\r\n[generated.tar.gz](https://github.com/tensorflow/tensorflow/files/3612348/generated.tar.gz)\r\n", "Thank you for the graph dumps.  Unfortunately nothing obviously bad jumps out.\r\n\r\nCan you try poking at the timeline TensorBoard generates: https://www.tensorflow.org/tensorboard/r2/tensorboard_profiling_keras to see if you spot anything unusual?\r\n\r\nCC @jbaiocchi @zongweiz ", "@sgambient \r\nPlease update as per above comment ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 32270, "title": "`tf.estimator` missing in 2019-09-05 nightlies (and broken in 2019-09-04)", "body": "#### System information\r\n\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): gLinux (like Debian)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): `v1.12.1-10423-g11e22c0 2.0.0-dev20190905` (`tf-nightly-2.0-preview==2.0.0.dev20190905`)\r\n- Python version: 3.6.8rc1\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n#### Describe the current behavior\r\n\r\nThe `tf.estimator` module appears not to exist:\r\n\r\n```python\r\n>>> import tensorflow as tf\r\n>>> tf.estimator\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nAttributeError: module 'tensorflow' has no attribute 'estimator'\r\n>>> tf.compat.v2.estimator\r\n<module 'tensorflow_estimator.python.estimator.api._v2.estimator' from '/tmp/tmp.hdyrTvpKDw/ve/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/api/_v2/estimator/__init__.py'>\r\n>>> tf.compat.v1.estimator\r\n<module 'tensorflow_estimator.python.estimator.api._v1.estimator' from '/tmp/tmp.hdyrTvpKDw/ve/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/api/_v1/estimator/__init__.py'>\r\n>>> tf.estimator\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nAttributeError: module 'tensorflow' has no attribute 'estimator'\r\n```\r\n\r\n#### Describe the expected behavior\r\n\r\nThe `tf.estimator` module should exist, given that it [is documented in\r\nthe TF 2.x APIs][1] and has been in previous nightlies.\r\n\r\n[1]: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/estimator\r\n\r\n#### Code to reproduce the issue\r\n\r\n```\r\npython -c '__import__(\"tensorflow\").estimator`\r\n```\r\n\r\n#### Other info / logs\r\n\r\nN/A\r\n", "comments": ["cc @mihaimaruseac @annarev ; this is blocking TensorBoard nightlies\r\nbecause it causes our smoke tests to fail.\r\n", "Sorry for the breakage! Tomorrow the issue should be fixed (thanks to Mihai).\r\n\r\nAlso today's pip packages have been removed today morning.", "Great\u2014presumably that\u2019s this commit, then:\r\n<https://github.com/tensorflow/tensorflow/commit/18c2cf989a2263ee212fbd5ac0b3085d9450b80a>\r\n\r\nThanks @mihaimaruseac and @annarev!\r\n", "Just tested the new nightly now:\r\n\r\n```console\r\n(9) mihaimaruseac@ankh:/tmp/gh/9$ python -c \"import tensorflow as tf; print('__'); print(tf.__version__); print('---'); print(tf.keras); print('~~~'); print(tf.estimator)\"\r\n__\r\n2.0.0-dev20190906\r\n---\r\n<module 'tensorflow_core.keras' from '/tmp/gh/9/lib/python3.6/site-packages/tensorflow_core/python/keras/api/_v2/keras/__init__.py'>\r\n~~~\r\n<module 'tensorflow_core.estimator' from '/tmp/gh/9/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/api/_v2/estimator/__init__.py'>\r\n```\r\n\r\nAll seems good", "Yep, and TensorBoard nightlies look good\u2014thanks again! :-)"]}, {"number": 32269, "title": "[r2.0-rc1 CherryPick]: Several tf.keras mixed precision API changes", "body": "This cherrypick deprecates a feature that will be removed in 2.0, and adds the replacement feature in 2.1. In particular, it deprecates the \"infer_with_float32_vars\" policy and adds the \"mixed_[b]float16\" policies.", "comments": []}, {"number": 32268, "title": "TF.Keras model creation results in different output node when eager is enabled or not", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Collab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): No\r\n- TensorFlow version (use command below):Google Collab default runtime / Tensorflow 1.14.0\r\ntf.keras 2.2.4-tf\r\n- Python version:Google Collab default runtime: 3.6.8 (default, Jan 14 2019, 11:02:34)\r\n[GCC 8.0.1 20180414 (experimental) [trunk revision 259383]]\r\n\r\n**Describe the current behavior**\r\n\r\nbuilding a tf.keras sequence model when eager mode is enabled vs not results in different output nodes.\r\n\r\n**Describe the expected behavior**\r\n\r\nGraph execution does not effect graph construction, the model should be the same.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nWith eager enabled:\r\n```\r\n# load tensorflow\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\nimport tensorflow as tf\r\nimport numpy as np\r\nprint(tf.__version__)\r\nAUTOTUNE = tf.data.experimental.AUTOTUNE\r\n#enable eager\r\ntf.enable_eager_execution()\r\nassert tf.multiply(6, 7).numpy() == 42\r\nprint(\"Eager execution: {}\".format(tf.executing_eagerly()))\r\n\r\n# build our model and print its outputs and summary\r\nbase_model = tf.keras.applications.NASNetMobile(input_shape=(IMG_SIZE, IMG_SIZE, 3),\r\n                                               include_top=False,\r\n                                               weights='imagenet')\r\nbase_model.trainable = False\r\noutput = tf.keras.layers.Dense(num_labels, activation = 'sigmoid', name=\"cinemanet_output\", input_shape=(None, 1056))\r\n\r\nmodel = tf.keras.Sequential([\r\n  base_model,\r\n  tf.keras.layers.GlobalAveragePooling2D(),\r\n  output])\r\nmodel.summary()\r\nprint(model.input.op.name)\r\nprint(model.output.op.name)\r\n```\r\n\r\nResults in:\r\n\r\n```\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nNASNet (Model)               (None, 7, 7, 1056)        4269716   \r\n_________________________________________________________________\r\nglobal_average_pooling2d (Gl (None, 1056)              0         \r\n_________________________________________________________________\r\ncinemanet_output (Dense)     (None, 229)               242053    \r\n=================================================================\r\nTotal params: 4,511,769\r\nTrainable params: 242,053\r\nNon-trainable params: 4,269,716\r\n_________________________________________________________________\r\nNASNet_input\r\ncinemanet_output/Identity\r\n```\r\n\r\nWithout Eager:\r\n\r\n```\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nNASNet (Model)               (None, 7, 7, 1056)        4269716   \r\n_________________________________________________________________\r\nglobal_average_pooling2d (Gl (None, 1056)              0         \r\n_________________________________________________________________\r\ncinemanet_output (Dense)     (None, 229)               242053    \r\n=================================================================\r\nTotal params: 4,511,769\r\nTrainable params: 242,053\r\nNon-trainable params: 4,269,716\r\n_________________________________________________________________\r\nNASNet_input\r\ncinemanet_output/Sigmoid\r\n```\r\n\r\nWhich results in a model with no output when saved to pb.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["See #32241 - this may be the root of that issue?", "@vade, Looks like the code is incomplete, Please provide the complete code to reproduce the issue. Since i tried executing the code, some of the variable such as IMG_SIZE is not defined. Thanks!", "Apologies, Im happy to put together a very limited GCS demo of the issue. Hold tight.", "Hi.\r\n\r\nEager Mode code in GCS:\r\nhttps://colab.research.google.com/drive/16g3-5kgD5KV5_vz0DY07_bIO0miXp-NP\r\n\r\nNo Eager Mode code in GCS:\r\nhttps://colab.research.google.com/drive/1JqmscKZTLy2GpUiTzSyOMDXepalPSZKR\r\n\r\n\r\nOne line of code difference : `tf.enable_eager_execution()`\r\n\r\nOutput with Eager:\r\n```\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nNASNet (Model)               (None, 7, 7, 1056)        4269716   \r\n_________________________________________________________________\r\nglobal_average_pooling2d (Gl (None, 1056)              0         \r\n_________________________________________________________________\r\ncinemanet_output (Dense)     (None, 229)               242053    \r\n=================================================================\r\nTotal params: 4,511,769\r\nTrainable params: 242,053\r\nNon-trainable params: 4,269,716\r\n_________________________________________________________________\r\nNASNet_input\r\ncinemanet_output/Identity\r\n```\r\n\r\nOutput with No Eager:\r\n```\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\nDownloading data from https://github.com/titu1994/Keras-NASNet/releases/download/v1.2/NASNet-mobile-no-top.h5\r\n19996672/19993432 [==============================] - 0s 0us/step\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nNASNet (Model)               (None, 7, 7, 1056)        4269716   \r\n_________________________________________________________________\r\nglobal_average_pooling2d (Gl (None, 1056)              0         \r\n_________________________________________________________________\r\ncinemanet_output (Dense)     (None, 229)               242053    \r\n=================================================================\r\nTotal params: 4,511,769\r\nTrainable params: 242,053\r\nNon-trainable params: 4,269,716\r\n_________________________________________________________________\r\nNASNet_input\r\ncinemanet_output/Sigmoid\r\n```\r\n\r\nSee the last print statement / output:\r\n", "@vade, Thanks for providing the GCS.", "I could reproduce the issue even in `tf-nightly`. Thanks!", "Thank you very much for looking into this. Much obliged, and thank you for all of your work on TF!", "Looking through https://github.com/tensorflow/tensorflow/issues/32241, it seems that the issue (different output node) was fixed, but freeze_graph is no longer supported.\r\nClosing this for now. If freeze_graph is an issue, please file another one :-)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32268\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32268\">No</a>\n"]}, {"number": 32267, "title": "[r2.0 CherryPick]: [INTEL MKL] Add support for Addv2", "body": "Recent changes to AddV2 in TF (https://github.com/tensorflow/tensorflow/commit/fc61fa8725db3229fc7dd08de3d2f664f87abbb4) caused up to ~50% regression in some of Intel's benchmarks. This PR fixes that. \r\n\r\nOriginal PR: #32124", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F32267) for more info**.\n\n<!-- need_author_consent -->", "@agramesh1 Could you please post `@googlebot I consent.`? Thank you!", "@googlebot I consent.", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F32267) for more info**.\n\n<!-- ok -->"]}, {"number": 32266, "title": "Document ParallelInterleaveDatasetV2 op", "body": "This PR adds documentation to the API spec for the `ParallelInterleaveDatasetV2` op in `tf.data`.\r\n\r\nI documented all the inputs and attributes in the `REGISTER_OP()` call for the op. I documented how the `num_parallel_calls` attribute affects the degree of parallelism at runtime. I also documented how the Python API creates instances of this op and how the `sloppy` attribute is set in a graph rewrite durning static optimization.", "comments": []}, {"number": 32265, "title": "tf.keras model.evaluate (and fit with validation) possible leak when running on TPU", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **'Linux-4.14.137+-x86_64-with-Ubuntu-18.04-bionic'** (Google Colab)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **No**\r\n- TensorFlow installed from (source or binary): **binary** (I think, it's the one already installed in Colab)\r\n- TensorFlow version (use command below): **1.14.0**\r\n- Python version: **3.6.8**\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: **Google Colab's TPU**\r\n\r\n**Describe the current behavior**\r\nWhen running `model.evaluate` in TPU, each time it gets executed it takes longer and longer. I started seeing this behavior when training (`model.fit()`) but only when providing validation data. I guess `model.evaluate` gets called when processing the validation set, so I tried to have a minimum reproduction sample with just directly calling `model.evaluate`.\r\n\r\nBut please note this is also a problem when running `fit` with validation data. Each epoch takes longer and longer. I can start with 10 seconds on epoch 1 and have like 160 seconds on epoch 50.\r\n\r\nOther *strange* and related behavior I can see:\r\n- Just when calling `evaluate`, you get two identical lines as output instead of just 1 as I would expect (calling `fit` without validation data outputs 1 line per epoch, but when calling it with validation data it outputs that same 1 line plus two identical lines corresponding to the `evaluation`)\r\n- each time `evaluate` is called it seems to incur in a \"setup\" time, since the step itself takes considerably less than than the total `evaluate` execution time\r\n- as you call it again and again, it seems both, this \"setup time\" and the \"evaluation time\" itself increase, but not exactly as much. It seems the setup time increases more than the evaluation time\r\n- the reproduction example below has very simple data and model, and you can still see this behavior with that. But it seems that with more complex models the time it takes for `evaluate` increases at a higher rate each time it gets called\r\n\r\n**Describe the expected behavior**\r\nEach time evaluate is called with the same data, it should take roughly the same time. Also, when running fit with validation, each epoch (after the first one at least) should also take roughly the same time (this does happen without validation data, but doesn't happen with validation)\r\n\r\n**Code to reproduce the issue**\r\n\r\nI tried to create a minimal example, so I'm not even training the model here before evaluating some data. But note this is also a problem when training, so I don't think using an untrained model here is related to the issue. In the same way, I'm using randomly generated data, but this happened to me when training with real images and masks, and also with higher batch size (I was using the recommended 1024, but I used 128 here so the example executes quicker)\r\n\r\n```python\r\nimport os\r\nimport time\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ntf.keras.backend.clear_session()\r\n\r\nTF_MASTER = 'grpc://{}'.format(os.environ['COLAB_TPU_ADDR'])\r\n\r\nwith tf.Session(TF_MASTER) as session:\r\n  print(session.list_devices())\r\n\r\nprint(\"Tensorflow Version:\", tf.VERSION)\r\nprint(\"Tensorflow Keras Version:\", tf.keras.__version__)\r\n\r\namount = 128\r\nsize = [256, 256]\r\nimages = np.array([np.random.rand(*size, 3).astype('float32') for i in range(amount)])\r\nmasks = np.array([np.random.rand(*size, 1).astype('float32') for i in range(amount)])\r\n\r\nds = tf.data.Dataset.from_tensor_slices((images, masks)).batch(amount, drop_remainder=True) # we need Dataset to run on TPU\r\nprint(ds)\r\n\r\n# very minimal model to demostrate the issue\r\ndef make_model(batch_size=None):\r\n  src = tf.keras.layers.Input(shape=(*size,3), batch_size=batch_size, dtype=tf.float32, name='Input')\r\n  outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(src)\r\n\r\n  model = tf.keras.Model(inputs=[src], outputs=[outputs])\r\n  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\r\n  return model\r\n\r\nresolver = tf.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\r\ntf.contrib.distribute.initialize_tpu_system(resolver)\r\nstrategy = tf.contrib.distribute.TPUStrategy(resolver)\r\nwith strategy.scope():\r\n  model = make_model(batch_size = 128)\r\nmodel.summary()\r\n\r\nfor i in range(30):\r\n  start_time = time.time()\r\n  model.evaluate(ds, steps=1)\r\n  print(\"--- %s seconds ---\" % (time.time() - start_time))\r\n```\r\n\r\nOutput:\r\n```\r\n1/1 [==============================] - 2s 2s/step\r\n1/1 [==============================] - 2s 2s/step\r\n--- 4.957882404327393 seconds ---\r\n1/1 [==============================] - 2s 2s/step\r\n1/1 [==============================] - 2s 2s/step\r\n--- 4.556092977523804 seconds ---\r\n1/1 [==============================] - 2s 2s/step\r\n1/1 [==============================] - 2s 2s/step\r\n--- 4.7304792404174805 seconds ---\r\n1/1 [==============================] - 2s 2s/step\r\n1/1 [==============================] - 2s 2s/step\r\n--- 5.154953479766846 seconds ---\r\n1/1 [==============================] - 3s 3s/step\r\n1/1 [==============================] - 3s 3s/step\r\n--- 5.432474136352539 seconds ---\r\n1/1 [==============================] - 3s 3s/step\r\n1/1 [==============================] - 3s 3s/step\r\n--- 5.930710315704346 seconds ---\r\n1/1 [==============================] - 3s 3s/step\r\n1/1 [==============================] - 3s 3s/step\r\n--- 5.949801683425903 seconds ---\r\n1/1 [==============================] - 3s 3s/step\r\n1/1 [==============================] - 3s 3s/step\r\n--- 6.352793455123901 seconds ---\r\n1/1 [==============================] - 3s 3s/step\r\n1/1 [==============================] - 3s 3s/step\r\n--- 7.153834581375122 seconds ---\r\n1/1 [==============================] - 4s 4s/step\r\n1/1 [==============================] - 4s 4s/step\r\n--- 7.319533348083496 seconds ---\r\n1/1 [==============================] - 4s 4s/step\r\n1/1 [==============================] - 4s 4s/step\r\n--- 7.719737529754639 seconds ---\r\n1/1 [==============================] - 4s 4s/step\r\n1/1 [==============================] - 4s 4s/step\r\n--- 8.089992761611938 seconds ---\r\n1/1 [==============================] - 4s 4s/step\r\n1/1 [==============================] - 4s 4s/step\r\n--- 8.87194037437439 seconds ---\r\n1/1 [==============================] - 5s 5s/step\r\n1/1 [==============================] - 5s 5s/step\r\n--- 9.02499771118164 seconds ---\r\n1/1 [==============================] - 5s 5s/step\r\n1/1 [==============================] - 5s 5s/step\r\n--- 9.39006233215332 seconds ---\r\n1/1 [==============================] - 5s 5s/step\r\n1/1 [==============================] - 5s 5s/step\r\n--- 9.687021970748901 seconds ---\r\n1/1 [==============================] - 5s 5s/step\r\n1/1 [==============================] - 5s 5s/step\r\n--- 10.596904754638672 seconds ---\r\n1/1 [==============================] - 6s 6s/step\r\n1/1 [==============================] - 6s 6s/step\r\n--- 10.745074272155762 seconds ---\r\n1/1 [==============================] - 6s 6s/step\r\n1/1 [==============================] - 6s 6s/step\r\n--- 11.3403902053833 seconds ---\r\n1/1 [==============================] - 6s 6s/step\r\n1/1 [==============================] - 6s 6s/step\r\n--- 11.945271015167236 seconds ---\r\n1/1 [==============================] - 7s 7s/step\r\n1/1 [==============================] - 7s 7s/step\r\n--- 12.67944622039795 seconds ---\r\n1/1 [==============================] - 7s 7s/step\r\n1/1 [==============================] - 7s 7s/step\r\n--- 13.195830345153809 seconds ---\r\n1/1 [==============================] - 7s 7s/step\r\n1/1 [==============================] - 7s 7s/step\r\n--- 14.408772230148315 seconds ---\r\n1/1 [==============================] - 7s 7s/step\r\n1/1 [==============================] - 7s 7s/step\r\n--- 14.38786506652832 seconds ---\r\n1/1 [==============================] - 8s 8s/step\r\n1/1 [==============================] - 8s 8s/step\r\n--- 14.985581636428833 seconds ---\r\n1/1 [==============================] - 8s 8s/step\r\n1/1 [==============================] - 8s 8s/step\r\n--- 15.89274287223816 seconds ---\r\n1/1 [==============================] - 9s 9s/step\r\n1/1 [==============================] - 9s 9s/step\r\n--- 16.433870792388916 seconds ---\r\n1/1 [==============================] - 9s 9s/step\r\n1/1 [==============================] - 9s 9s/step\r\n--- 17.08533024787903 seconds ---\r\n[...]\r\n```\r\n\r\n**Other info / logs**\r\n\r\nI created a Google Colab with this example, so you can execute it and check this behavior: https://colab.research.google.com/drive/1YgSSdlrfVpTfufGXNNXckYzOd-dzEbVI", "comments": ["I was able to reproduce the issue. Thanks!", "Btw, the workaround I'm using at the moment (since this is an important problem when training with validation data for more than a few epochs) is to use the `fit` arg `validation_freq`, with something like 5 or 10. That way you have many quick epochs (the ones without validation), and the evaluation stages you have are fewer and so they don't have the chance to increase their time enough to become a big problem. Of course, you loose intermediate validation, but at least you can quickly train 100 epochs without much trouble ;)", "Yeah, this is a known issue with the interaction with Keras + tf.distribute.Strategy in the TF 1.x. This is currently fixed in TF 2.x.", "@jhseu thanks, and do you know if latest 2.0 release works with cloud TPUs like in Colab? I read somewhere that it will be in 2.1, with the TPUStrategy, is that correct? So the final solution will be to wait for 2.1 release in order to use TF with cloud TPU?", "@raulmt TPUs are not officially supported in TF2.0. You can use `tf-nightly` which is `TF2.1` dev version. Thanks!", "Ok, thanks! Closing then\u2026", "I'm still facing the same issue while on **TFv2.3** (and using a TPU). The model would train well but at the end of each epoch, the memory consumption (of the VM running the training) increases significantly for which we cannot train the model for longer durations.\r\n\r\nPS: apart from `model.fit(...., validation_data=val_ds)`, I'm also using an extra validation set that calls `model.evaluate` with the help of the following callback like [this](https://github.com/tanzhenyu/image_augmentation/blob/master/image_augmentation/callbacks/extra_eval.py). I suspect that either of them should be responsible for the linear increase of memory consumption due to an internal memory leak!\r\n\r\nAny suggested fixes would be of much help to me.\r\n\r\n/cc: @jhseu, @tanzhenyu ", "> I'm still facing the same issue while on **TFv2.3** (and using a TPU). The model would train well but at the end of each epoch, the memory consumption (of the VM running the training) increases significantly for which we cannot train the model for longer durations.\r\n> \r\n> PS: apart from `model.fit(...., validation_data=val_ds)`, I'm also using an extra validation set that calls `model.evaluate` with the help of the following callback like [this](https://github.com/tanzhenyu/image_augmentation/blob/master/image_augmentation/callbacks/extra_eval.py). I suspect that either of them should be responsible for the linear increase of memory consumption due to an internal memory leak!\r\n> \r\n> Any suggested fixes would be of much help to me.\r\n> \r\n> /cc: @jhseu, @tanzhenyu\r\n\r\nHere you could find two notebooks that would help prove the veracity of the claim. \r\n1. [TPU Experiment 1 #32265](https://colab.research.google.com/gist/swghosh/23f46273d82857c9cf8eb30423fcde4d/tpu-experiment-1.ipynb): Notebook demonstrating use of `model.fit` (on a TPU) with `validation_data` argument specified.\r\n2. [TPU Experiment 2 #32265](https://colab.research.google.com/gist/swghosh/23f850cb447581d9f169a6914ed4681b/tpu-experiment-2.ipynb): Notebook demonstrating use of `model.fit` (on a TPU)\r\na) used with `validation_data` and an extra callback that does `model.evaluate(test_ds)` at `on_epoch_end`\r\nb) used with `validation_data` only\r\nc) used without `validation_data` argument.\r\n\r\nHope it helps."]}, {"number": 32264, "title": "Some XLA utility function in hlo_creation_utils", "body": "A split from: https://github.com/tensorflow/tensorflow/pull/32251", "comments": ["Fixed.", "Any idea what is going on with the 'Ubuntu CC' CI? It didn't run in 3 days.", "This change got imported, I need to make sure it runs locally before it will get committed. I think external bots are fine with this PR."]}, {"number": 32263, "title": "Add an XLA utility function HasOverlappinWindow.", "body": "This is a split from PR: https://github.com/tensorflow/tensorflow/pull/32251", "comments": ["Fixed the comments.", "@nouiz Could you please address Ubuntu Sanity errors? Thanks!", "I tried to fit it, but I don't understand why it do not like it.", "Any update? I should have fixed the build.", "The CI have an error in 'Linux GPU', but is related to Keras and as this PR only add new feature not currently used, I do not see how my PR could have caused it. So it is probably not related to my PR. If you think otherwise, tell me.\r\n\r\nThe 'Ubuntu Sanity' passed this time."]}, {"number": 32262, "title": "TF2.0 : Tensorflow object detection model zoo inference not working on gpu", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0-rc0\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA 10.0\r\n- GPU model and memory: GeForce RTX 2080 Ti\r\n\r\n**Describe the current behavior**\r\nRunning any of the saved models from [tensorflow model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md) leads to a segmentation fault.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport os\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nos.system('wget http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz')\r\nos.system('tar -xvf ssd_mobilenet_v2_coco_2018_03_29.tar.gz')\r\n\r\nwith tf.device('/device:GPU:0'):\r\n    loaded_model = tf.saved_model.load('ssd_mobilenet_v2_coco_2018_03_29/saved_model')\r\n    infer = loaded_model.signatures['serving_default']\r\n    sample_img = np.zeros((1,128,128,3))\r\n    predicted = infer(tf.constant(sample_img, tf.uint8))\r\n    print(predicted)\r\n```\r\n\r\n**gdb output**\r\n```\r\nThread 89 \"python3\" received signal SIGSEGV, Segmentation fault.\r\n[Switching to Thread 0x7ffbfbfff700 (LWP 7857)]\r\n0x00007fff4372b741 in tensorflow::NonMaxSuppressionV2GPUOp::Compute(tensorflow::OpKernelContext*) ()\r\n   from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so\r\n```", "comments": ["duplicate #32261", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32262\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32262\">No</a>\n"]}, {"number": 32261, "title": "TF2.0 : NonMaxSuppressionV2GPUOp segmentation fault", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): TF2.0.0-rc0\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA 10.0\r\n- GPU model and memory: GeForce RTX 2080 Ti\r\n\r\n**Describe the current behavior**\r\nTF2.0 has a Non Max Suppression V2 op gpu implementation which seg faults when it is run.\r\nDue to this [TF object detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md) saved models cannot be run in TF2.0.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.python.ops import gen_image_ops\r\n\r\nwith tf.device('/device:GPU:0'):\r\n    boxes = tf.random_uniform((10,4), dtype=tf.float32)\r\n    scores = tf.constant([1]*10, tf.float32)\r\n    max_output_size = tf.constant(1)\r\n    iou_threshold = tf.constant(0.5)\r\n\r\n    nms = gen_image_ops.non_max_suppression_v2(boxes, scores, max_output_size, iou_threshold)\r\n    print(nms)\r\n```\r\n\r\n**gdb output** \r\n```\r\nThread 1 \"python3\" received signal SIGSEGV, Segmentation fault.                                                                                                                          \r\n0x00007fff4372b741 in tensorflow::NonMaxSuppressionV2GPUOp::Compute(tensorflow::OpKernelContext*) ()                                                                                     \r\n   from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so\r\n```", "comments": ["cc @samikama ", "I think this is fixed with tf 2.0 nightly version '2.0.0-dev20190913'. Can you please confirm? Thanks!\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.python.ops import gen_image_ops\r\n\r\nwith tf.device('/device:GPU:0'):\r\n    boxes = tf.random.uniform((10,4), dtype=tf.float32)\r\n    scores = tf.constant([1]*10, tf.float32)\r\n    max_output_size = tf.constant(1)\r\n    iou_threshold = tf.constant(0.5)\r\n\r\n    nms = gen_image_ops.non_max_suppression_v2(boxes, scores, max_output_size, iou_threshold)\r\n    print(nms)\r\n```\r\nOutput:\r\n```python\r\ntf.Tensor([0], shape=(1,), dtype=int32)\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32261\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32261\">No</a>\n", "> I think this is fixed with tf 2.0 nightly version '2.0.0-dev20190913'. Can you please confirm? Thanks!\r\n> \r\n> ```python\r\n> import tensorflow as tf\r\n> from tensorflow.python.ops import gen_image_ops\r\n> \r\n> with tf.device('/device:GPU:0'):\r\n>     boxes = tf.random.uniform((10,4), dtype=tf.float32)\r\n>     scores = tf.constant([1]*10, tf.float32)\r\n>     max_output_size = tf.constant(1)\r\n>     iou_threshold = tf.constant(0.5)\r\n> \r\n>     nms = gen_image_ops.non_max_suppression_v2(boxes, scores, max_output_size, iou_threshold)\r\n>     print(nms)\r\n> ```\r\n> \r\n> Output:\r\n> \r\n> ```python\r\n> tf.Tensor([0], shape=(1,), dtype=int32)\r\n> ```\r\n\r\nThanks! It works here!", "or install newer version > 2.0 such as \r\n`pip install tensorflow-gpu==2.1.0`\r\nand it works for me"]}, {"number": 32260, "title": "Add SaveOptions object with option to whitelist op namespaces. ", "body": "All saved_model saving functions now have an options argument where the user may pass in a SaveOptions object.\r\n\r\nPiperOrigin-RevId: 266021878", "comments": []}, {"number": 32259, "title": "[r2.0 Cherrypick]:Implementing RFC#126: Allow Op names of the form RepoName>OpName.", "body": "PiperOrigin-RevId: 264491560", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F32259) for more info**.\n\n<!-- need_sender_cla -->", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F32259) for more info**.\n\n<!-- cla_yes -->"]}, {"number": 32258, "title": "[r2.0 CherryPick]: @tf.function: Show a warning message when tracing happens too frequently", "body": "When using @tf.function it's easy to trigger unnecessary retracings, but there is no way for user\r\nto know that's happening without this added warning.  There have been a lot of reports and\r\nwe consider this as one of the top usability issues now.", "comments": []}, {"number": 32257, "title": "[r2.0-CherryPick] Deduplicate Keras weights", "body": "", "comments": []}, {"number": 32256, "title": "[r2.0 Cherrypick]:Make calls to `tf.function(f)()`, `tf.function(f).get_concrete_function` and `tf.function(f).get_initialization_function` thread-safe.", "body": "", "comments": []}, {"number": 32255, "title": "TPU with tensorflow 2.0 -- 'DeleteIterator' OpKernel missing", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES\r\n- OS Platform and Distribution: Debian GNU/Linux 9\r\n- TensorFlow installed from (source or binary): /usr/bin/pip3\r\n- TensorFlow version (use command below): 2.0.0b1\r\n- Python version: 3.5.3\r\n- TPU type: v2-8\r\n- TPU software version: 1.14 \r\n\r\n**Describe the current behavior**\r\nI am running a TPU allocated by `ctpu up` in tensorflow 2.0 (I'm aware this isn't fully supported atm). I have a simple training loop functioning mostly following the guidelines here:\r\nhttps://www.tensorflow.org/beta/guide/distribute_strategy#using_tfdistributestrategy_with_custom_training_loops\r\n\r\nTo my surprise I have encountered few issues along the way, but one that I can't seem to remedy on my end is this:\r\n`tensorflow.python.framework.errors_impl.NotFoundError: No registered 'DeleteIterator' OpKernel for TPU devices compatible with node {{node DeleteIterator}}`\r\n\r\nThis error doesn't seem to actually break anything, but I'm worried there could be a TPU memory leak or something and that is difficult to verify without any useable TPU profiling tools for TF 2.0.\r\nEDIT: The bug does actually cause the program to crash after a few iterations.\r\n\r\n**Describe the expected behavior**\r\nI expect to be able to delete the iterator object within the TPU strategy scope.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nfor epoch in range(self.train_epochs):\r\n    with tf.device(self.device), self.distribution_strategy.scope():\r\n        dataset = self.fill_experience_buffer()\r\n        exp_buff = iter(dataset)\r\n\r\n        for step in tqdm(range(self.train_steps), \"Training epoch {}\".format(epoch)):\r\n            train_step(next(exp_buff))\r\n```\r\n\r\nThe issue occurs the second time around in the loop when the `exp_buff` variable is rewritten with `iter(dataset)`. I've tried explicitly freeing the object with 'del exp_buff' within and outside of the scope():, but the same error occurs regardless.\r\n\r\n**Other info / logs**\r\nFull error message here (the message appears 8 times, once for each TPU device, but the messages are identical:\r\n```\r\nException ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7f0bac1883c8>>\r\nTraceback (most recent call last):\r\n  File \"/home/youngalou/.local/lib/python3.5/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 531, in __del__\r\n    handle=self._handle, deleter=self._deleter)\r\n  File \"/home/youngalou/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 800, in delete_iterator\r\n    _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.NotFoundError: No registered 'DeleteIterator' OpKernel for TPU devices compatible with node {{node DeleteIterator}}\r\n        .  Registered:  device='CPU'\r\n  device='GPU'\r\n\r\nAdditional GRPC error information:\r\n{\"created\":\"@1567559533.240191338\",\"description\":\"Error received from peer\",\"file\":\"external/grpc/src/core/lib/surface/call.cc\",\"file_line\":1039,\"grpc_message\":\"No registered 'DeleteIterator' OpKernel for TPU devices compatible with node {{node DeleteIterator}}\\n\\t.  Registered:  device='CPU'\\n  device='GPU'\\n\",\"grpc_status\":5} [Op:DeleteIterator]\r\nException ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7f0bac188518>>\r\nTraceback (most recent call last):\r\n  File \"/home/youngalou/.local/lib/python3.5/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 531, in __del__\r\n    handle=self._handle, deleter=self._deleter)\r\n  File \"/home/youngalou/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 800, in delete_iterator\r\n    _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.NotFoundError: No registered 'DeleteIterator' OpKernel for TPU devices compatible with node {{node DeleteIterator}}\r\n        .  Registered:  device='CPU'\r\n  device='GPU'\r\n```", "comments": ["Looks like the code is incomplete.Can you please provide full code snippet to reproduce it on our environment.Thanks!\r\n", "Sorry about that! First time submitting a bug report.\r\nI've recreated a small standalone script that demonstrates the bug.\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ntpu_address = 'youngalou'\r\ndevice = '/job:worker'\r\ntrain_epochs = 100\r\ntrain_steps = 100\r\ndataset_size = 1000\r\nbatch_size = 256\r\n\r\ncluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_address)\r\ntf.config.experimental_connect_to_host(cluster_resolver.master())\r\ntf.tpu.experimental.initialize_tpu_system(cluster_resolver)\r\ntpu_strategy = tf.distribute.experimental.TPUStrategy(cluster_resolver)\r\n\r\ndef get_dataset():\r\n    dataset = tf.data.Dataset.from_tensor_slices((np.zeros((dataset_size,128),dtype=np.float32), np.zeros((dataset_size,1),dtype=np.float32)))\r\n    dataset = dataset.shuffle(dataset_size).repeat().batch(batch_size)\r\n    return tpu_strategy.experimental_distribute_dataset(dataset)\r\n\r\nfor _ in range(train_epochs):\r\n    with tf.device(device), tpu_strategy.scope():\r\n        dataset = get_dataset()\r\n        exp_buff = iter(dataset)\r\n\r\n        for _ in range(train_steps):\r\n            train_batch = next(exp_buff)\r\n```", "I have tried on colab with TF version 2.0 beta1 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/49dc704bebc4b101f2eddd0169c9e15c/untitled167.ipynb).Thanks!", "> \r\n> \r\n> Sorry about that! First time submitting a bug report.\r\n> I've recreated a small standalone script that demonstrates the bug.\r\n> \r\n> ```\r\n> import numpy as np\r\n> import tensorflow as tf\r\n> \r\n> tpu_address = 'youngalou'\r\n> device = '/job:worker'\r\n> train_epochs = 100\r\n> train_steps = 100\r\n> dataset_size = 1000\r\n> batch_size = 256\r\n> \r\n> cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_address)\r\n> tf.config.experimental_connect_to_host(cluster_resolver.master())\r\n> tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\r\n> tpu_strategy = tf.distribute.experimental.TPUStrategy(cluster_resolver)\r\n> \r\n> def get_dataset():\r\n>     dataset = tf.data.Dataset.from_tensor_slices((np.zeros((dataset_size,128),dtype=np.float32), np.zeros((dataset_size,1),dtype=np.float32)))\r\n>     dataset = dataset.shuffle(dataset_size).repeat().batch(batch_size)\r\n>     return tpu_strategy.experimental_distribute_dataset(dataset)\r\n> \r\n> for _ in range(train_epochs):\r\n>     with tf.device(device), tpu_strategy.scope():\r\n>         dataset = get_dataset()\r\n>         exp_buff = iter(dataset)\r\n> \r\n>         for _ in range(train_steps):\r\n>             train_batch = next(exp_buff)\r\n> ```\r\n\r\nHey! @youngalou , You don't need to open the strategy and device scope everytime. This produces different context ID, while training the model.\r\nSo, I'ld ask you to shift the `tf.device()` and `strategy.scope()` outside the loop.\r\n```python3\r\nwith tf.device(device), tpu_strategy.scope():\r\n    for _ in range(train_epochs):\r\n        dataset = get_dataset()\r\n        exp_buff = iter(dataset)\r\n\r\n        for _ in range(train_steps):\r\n            train_batch = next(exp_buff)\r\n```\r\nThis is supposed to work.", "And about `{{DeleteIterator}}` issue, This issue is raised when the code suddenly crashes and kills the execution. So while debugging TPU code, these errors are to be ignored (unless there's nothing else in the traceback, apart from these). Scroll up to find out what killed the code.\r\nIn your case there's a high chance, The TPU cannot process it since 2 different context IDs are produced for the same training graph.", "+1 to @captain-pool's recommendations. You should not enter the strategy scope in a loop, but move the loop inside the scope. Let us know if that fixes the issue. ", "Hi Louis,\r\n\r\nCould you try to call\r\n\"tf.config.experimental_connect_to_cluster(cluster_resolver)\"? In that way you don't need to enter the device scope as well.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32255\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32255\">No</a>\n", "@captain-pool Thanks for the quick response! I tried moving the scope outside of the loop as you \r\n suggested but that doesn't seem to fix the problem. Also, the traceback doesn't contain anything other than the errors posted originally.", "@rxsang It doesn't look like that function exists in this version of tensorflow (2.0.0b1).\r\n`AttributeError: module 'tensorflow._api.v2.config' has no attribute 'experimental_connect_to_cluster'`", "https://github.com/captain-pool/GSOC/blob/master/E1_TPU_Sample/image_retraining_tpu_strategy.py\n\nThis is a sample i wrote for GSoC. I guess this can serve as a reference.\n\nOn Thu, 12 Sep 2019, 1:10 am Louis Young, <notifications@github.com> wrote:\n\n> @rxsang <https://github.com/rxsang> It doesn't look like that method\n> exists in this version of tensorflow (2.0.0b1).\n> AttributeError: module 'tensorflow._api.v2.config' has no attribute\n> 'experimental_connect_to_cluster'\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/32255?email_source=notifications&email_token=ADKYRWKWBI56KEYYUKSNZETQJFCS7A5CNFSM4IUB25WKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD6PUHQY#issuecomment-530531267>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ADKYRWMJDRBU26UPDWIQER3QJFCS7ANCNFSM4IUB25WA>\n> .\n>\n", "@captain-pool In the code sample you provided you don't delete or rewrite the iterator so the same problem isn't present.", "Hey @younglou, why do you need to delete the iterator? In TPUs this problem is still persistent. You can't just iterate to the end of the dataset and wait for `StopIteration`. You have to provide the total number of steps to iterate for.\r\nSo your code should be like.\r\n```python3\r\nwith tf.device(device), tpu_strategy.scope():\r\n  dataset = iter(get_dataset().repeat())\r\n  for i in range(epochs * train_steps):\r\n    train_batch = next(dataset)\r\n```", "@captain-pool I need to create new iterators because I'm using this for a reinforcement learning training loop. Specifically I'm training a DQN and the dataset is an experience buffer that changes over time.\r\nAnd in the code snippet I created originally, there is a `train_steps` variable that provides the total number of iterations, so I'm not seeing what's different here.", "Hi, when the issue was created, TF2 TPU hasn't been enabled yet. And it has been launched in TF2.1. Could you try the same code again using TF2.2?", "Please test with latest version of TF 2.5 and verify if fixed. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32255\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32255\">No</a>\n"]}, {"number": 32254, "title": "Input placeholder with shape [1] of saved_model.pb accepts scaler input but throws error in later graph.", "body": "Env:\r\n* Mac OS\r\n* python 2.7\r\n* tensorflow 1.13.1 installed from pip\r\n\r\nDescription:\r\nI'm using estimator API to build model. Inside serving input function, my model has an int64 input placeholder with shape [1]. And this placeholder is later concatenated with another tensor. Then I trained the model and saved it to `*.pb` graph. However during serving time I mistakenly feed a scaler value to this placeholder:\r\n```\r\ndtype: DT_INT64\r\ntensor_shape {\r\n}\r\nint64_val: 182\r\n```\r\nAs you can see, there is no dimension info in this proto. It didn't immediately throw an error and it seems that the placeholder with shape [1] is compatible with it. However later during concatenating op I got the error:\r\n```\r\n*** _Rendezvous: <_Rendezvous of RPC that terminated with:\r\n        status = StatusCode.INVALID_ARGUMENT\r\n        details = \"ConcatOp : Expected concatenating dimensions in the range [0, 0), but got 0\r\n         [[{{node concat_77}}]]\"\r\n        debug_error_string = \"{\"created\":\"@1567706789.859604000\",\"description\":\"Error received from peer ipv6:[::1]:9000\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1041,\"grpc_message\":\"ConcatOp : Expected concatenating dimensions in the range [0, 0), but got 0\\n\\t [[{{node concat_77}}]]\",\"grpc_status\":3}\"\r\n```\r\nLater I realized I did something wrong in the dimension so I add the shape info to my input proto. The error is gone. The correct proto looks like:\r\n```\r\ndtype: DT_INT64\r\ntensor_shape {\r\n  dim {\r\n    size: 1\r\n  }\r\n}\r\nint64_val: 182\r\n```\r\nIn one word, a `saved_model.pb` with input placeholder of shape [1] accepts a scaler input and not throwing any error. However later in the concat operation, since we are doing `tf.concat([scaler, tf.constant([1])], axis=0)`, it throws an error since the scaler has 0 dimension.\r\n\r\nCode to reproduce the error:\r\n```\r\ndef serve_input_fn():\r\n    receiver_tensor = {}\r\n    serving_features = {}\r\n    receiver_tensor['my_input'] = tf.placeholder(shape=[1], dtype=tf.int64)\r\n    serving_features['my_feature'] = tf.concat([receiver_tensor['my_input'], [1]], axis=0)\r\n    return tf.estimator.export.ServingInputReceiver(serving_features, receiver_tensors)\r\n\r\n# create any estimater\r\nestimator.export(\"/tmp/my_model\", \"serve_input_fn\", mode=\"infer\")\r\n\r\n# serve the model and feed in the following input\r\nrequest.inputs['my_input'].CopyFrom(tf.contrib.util.make_tensor_proto(100, dtype=tf.int64))\r\noutput = stup.Predict(request, 10)\r\n```\r\n", "comments": ["@Mickky666 \r\nThis issue is more suitable for TensorFlow Serving repo. Please post it on Serving repo from [here](https://github.com/tensorflow/serving/issues). Thanks!", "> @Mickky666\r\n> This issue is more suitable for TensorFlow Serving repo. Please post it on Serving repo from [here](https://github.com/tensorflow/serving/issues). Thanks!\r\n\r\nSure, thanks.", "I am closing this issue and we can track the issue in TensorFlow Serving repo. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32254\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32254\">No</a>\n"]}, {"number": 32253, "title": "[r1.15:CherryPick]NNAPI TransposeConv op takes tensor inputs from TFLite node", "body": "This fixes NNAPI execution of models that contain transpose_conv.\r\n\r\nPiperOrigin-RevId: 267384015", "comments": []}, {"number": 32252, "title": "[r2.0-Cherrypick]NNAPI TransposeConv op takes tensor inputs from TFLite node", "body": "This fixes NNAPI execution of models that contain transpose_conv.\r\n\r\nPiperOrigin-RevId: 267384015", "comments": []}, {"number": 32251, "title": "Some XLA utility functions", "body": "Add to XLA those utility functions:\r\n- `ShapeUtil::EqualIgnoringElementType`\r\n\r\nAlso fill a TODO in comment to generalize some fusion optimization by reusing `ShapeUtil::EqualIgnoringElementType`. This will allow MOF fusion when the outputs have different element type, not just different float precision.\r\n\r\n@sanjoy @d0k ", "comments": ["Could these be split into multiple commits? Also are all these strictly additive non-functional changes? I saw a TODO removed and some logic changed. Is there a PR which uses those utilities?", "This is part of a bigger PR that I'm working on. It depends on 2 PR, this one and https://github.com/tensorflow/tensorflow/pull/31929\r\n\r\nTo help the review I split part of the bigger PR to come that was independent.\r\nI could make in the next few days the bigger PR that would include those 2 PRs.\r\n\r\nHow do you want me to split this PR? I can make 3:\r\nThe changes to window_utils, the changes to hlo_creation_utils and those that fill the TODO that I implemented?", "> The changes to window_utils, the changes to hlo_creation_utils and those that fill the TODO that I implemented?\r\n\r\nYes, that sounds great.", "The split is done. This PR only keep the TODO being filled.\r\nThe 2 others PR: https://github.com/tensorflow/tensorflow/pull/32263 and https://github.com/tensorflow/tensorflow/pull/32264\r\n\r\nI also updated the description of this PR."]}]