[{"number": 52623, "title": "missing Link to nightly version of BinaryCrossentropy", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy?version=nightly\r\n\r\nThe following links throws \"404\" error\r\nhttps://github.com/keras-team/keras/tree/v2.8.0/keras/losses.py#L494-L593\r\n\r\nhttps://github.com/keras-team/keras/tree/v2.8.0/keras/losses.py#L145-L155\r\n\r\nhttps://github.com/keras-team/keras/tree/v2.8.0/keras/losses.py#L247-L252\r\n\r\nhttps://github.com/keras-team/keras/tree/v2.8.0/keras/losses.py#L106-L143\r\n\r\n\r\n\r\n## Description of issue (what needs changing):\r\n\r\nNightly doc link is throwing \"404\" error\r\n\r\n\r\n", "comments": ["Those files are auto-generated. \r\n\r\nIt looks like keras-nightly names itself after the next version, before the branch exists. \r\n\r\nThe only way to fix this is here:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/docs/base_dir.py#L58\r\n\r\nI think, on the if-side of the last if/else, you'd need to check if you've got tf-nightly, and set the keras branch to \"master\" instead of `v{keras.__version__}`"]}, {"number": 52622, "title": "Update release notes to have proper indentation", "body": "Keras items were missing one level of indent", "comments": []}, {"number": 52620, "title": "cannot train wiht custom dataset", "body": "hello,\r\ni wanted to try to generate images with stylegan2. i have an dataset with 4823 images. when I run !python /content/drive/MyDrive/stylegan2/run_training.py --num-gpus=1 --data-dir=/content/drive/MyDrive/stylegan2/dataset/ --config=config-f --dataset=eye --mirror-augment=true --metric=none --total-kimg=4823 --min-h=8 --min-w=8 --res-log2=8 --result-dir=\"/content/drive/My Drive/stylegan2/results\" I get this output\r\n\r\n\r\n\r\n\r\n\r\nLocal submit - run_dir: /content/drive/My Drive/stylegan2/results/00002-stylegan2-eye-1gpu-config-f\r\ndnnlib: Running training.training_loop.training_loop() on localhost...\r\nStreaming data using training.dataset.TFRecordDataset...\r\nDataset shape = [3, 2048, 2048]\r\nDynamic range = [0, 255]\r\nLabel size    = 0\r\nConstructing networks...\r\nSetting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Loading... Done.\r\nSetting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Loading... Done.\r\n\r\nG                               Params    OutputShape          WeightShape     \r\n---                             ---       ---                  ---             \r\nlatents_in                      -         (?, 512)             -               \r\nlabels_in                       -         (?, 0)               -               \r\nlod                             -         ()                   -               \r\ndlatent_avg                     -         (512,)               -               \r\nG_mapping/latents_in            -         (?, 512)             -               \r\nG_mapping/labels_in             -         (?, 0)               -               \r\nG_mapping/Normalize             -         (?, 512)             -               \r\nG_mapping/Dense0                262656    (?, 512)             (512, 512)      \r\nG_mapping/Dense1                262656    (?, 512)             (512, 512)      \r\nG_mapping/Dense2                262656    (?, 512)             (512, 512)      \r\nG_mapping/Dense3                262656    (?, 512)             (512, 512)      \r\nG_mapping/Dense4                262656    (?, 512)             (512, 512)      \r\nG_mapping/Dense5                262656    (?, 512)             (512, 512)      \r\nG_mapping/Dense6                262656    (?, 512)             (512, 512)      \r\nG_mapping/Dense7                262656    (?, 512)             (512, 512)      \r\nG_mapping/Broadcast             -         (?, 18, 512)         -               \r\nG_mapping/dlatents_out          -         (?, 18, 512)         -               \r\nTruncation/Lerp                 -         (?, 18, 512)         -               \r\nG_synthesis/dlatents_in         -         (?, 18, 512)         -               \r\nG_synthesis/8x8/Const           32768     (?, 512, 8, 8)       (1, 512, 8, 8)  \r\nG_synthesis/8x8/Conv            2622465   (?, 512, 8, 8)       (3, 3, 512, 512)\r\nG_synthesis/8x8/ToRGB           264195    (?, 3, 8, 8)         (1, 1, 512, 3)  \r\nG_synthesis/16x16/Conv0_up      2622465   (?, 512, 16, 16)     (3, 3, 512, 512)\r\nG_synthesis/16x16/Conv1         2622465   (?, 512, 16, 16)     (3, 3, 512, 512)\r\nG_synthesis/16x16/Upsample      -         (?, 3, 16, 16)       -               \r\nG_synthesis/16x16/ToRGB         264195    (?, 3, 16, 16)       (1, 1, 512, 3)  \r\nG_synthesis/32x32/Conv0_up      2622465   (?, 512, 32, 32)     (3, 3, 512, 512)\r\nG_synthesis/32x32/Conv1         2622465   (?, 512, 32, 32)     (3, 3, 512, 512)\r\nG_synthesis/32x32/Upsample      -         (?, 3, 32, 32)       -               \r\nG_synthesis/32x32/ToRGB         264195    (?, 3, 32, 32)       (1, 1, 512, 3)  \r\nG_synthesis/64x64/Conv0_up      2622465   (?, 512, 64, 64)     (3, 3, 512, 512)\r\nG_synthesis/64x64/Conv1         2622465   (?, 512, 64, 64)     (3, 3, 512, 512)\r\nG_synthesis/64x64/Upsample      -         (?, 3, 64, 64)       -               \r\nG_synthesis/64x64/ToRGB         264195    (?, 3, 64, 64)       (1, 1, 512, 3)  \r\nG_synthesis/128x128/Conv0_up    2622465   (?, 512, 128, 128)   (3, 3, 512, 512)\r\nG_synthesis/128x128/Conv1       2622465   (?, 512, 128, 128)   (3, 3, 512, 512)\r\nG_synthesis/128x128/Upsample    -         (?, 3, 128, 128)     -               \r\nG_synthesis/128x128/ToRGB       264195    (?, 3, 128, 128)     (1, 1, 512, 3)  \r\nG_synthesis/256x256/Conv0_up    1442561   (?, 256, 256, 256)   (3, 3, 512, 256)\r\nG_synthesis/256x256/Conv1       721409    (?, 256, 256, 256)   (3, 3, 256, 256)\r\nG_synthesis/256x256/Upsample    -         (?, 3, 256, 256)     -               \r\nG_synthesis/256x256/ToRGB       132099    (?, 3, 256, 256)     (1, 1, 256, 3)  \r\nG_synthesis/512x512/Conv0_up    426369    (?, 128, 512, 512)   (3, 3, 256, 128)\r\nG_synthesis/512x512/Conv1       213249    (?, 128, 512, 512)   (3, 3, 128, 128)\r\nG_synthesis/512x512/Upsample    -         (?, 3, 512, 512)     -               \r\nG_synthesis/512x512/ToRGB       66051     (?, 3, 512, 512)     (1, 1, 128, 3)  \r\nG_synthesis/1024x1024/Conv0_up  139457    (?, 64, 1024, 1024)  (3, 3, 128, 64) \r\nG_synthesis/1024x1024/Conv1     69761     (?, 64, 1024, 1024)  (3, 3, 64, 64)  \r\nG_synthesis/1024x1024/Upsample  -         (?, 3, 1024, 1024)   -               \r\nG_synthesis/1024x1024/ToRGB     33027     (?, 3, 1024, 1024)   (1, 1, 64, 3)   \r\nG_synthesis/2048x2048/Conv0_up  51297     (?, 32, 2048, 2048)  (3, 3, 64, 32)  \r\nG_synthesis/2048x2048/Conv1     25665     (?, 32, 2048, 2048)  (3, 3, 32, 32)  \r\nG_synthesis/2048x2048/Upsample  -         (?, 3, 2048, 2048)   -               \r\nG_synthesis/2048x2048/ToRGB     16515     (?, 3, 2048, 2048)   (1, 1, 32, 3)   \r\nG_synthesis/images_out          -         (?, 3, 2048, 2048)   -               \r\nG_synthesis/noise0              -         (1, 1, 8, 8)         -               \r\nG_synthesis/noise1              -         (1, 1, 16, 16)       -               \r\nG_synthesis/noise2              -         (1, 1, 16, 16)       -               \r\nG_synthesis/noise3              -         (1, 1, 32, 32)       -               \r\nG_synthesis/noise4              -         (1, 1, 32, 32)       -               \r\nG_synthesis/noise5              -         (1, 1, 64, 64)       -               \r\nG_synthesis/noise6              -         (1, 1, 64, 64)       -               \r\nG_synthesis/noise7              -         (1, 1, 128, 128)     -               \r\nG_synthesis/noise8              -         (1, 1, 128, 128)     -               \r\nG_synthesis/noise9              -         (1, 1, 256, 256)     -               \r\nG_synthesis/noise10             -         (1, 1, 256, 256)     -               \r\nG_synthesis/noise11             -         (1, 1, 512, 512)     -               \r\nG_synthesis/noise12             -         (1, 1, 512, 512)     -               \r\nG_synthesis/noise13             -         (1, 1, 1024, 1024)   -               \r\nG_synthesis/noise14             -         (1, 1, 1024, 1024)   -               \r\nG_synthesis/noise15             -         (1, 1, 2048, 2048)   -               \r\nG_synthesis/noise16             -         (1, 1, 2048, 2048)   -               \r\nimages_out                      -         (?, 3, 2048, 2048)   -               \r\n---                             ---       ---                  ---             \r\nTotal                           30394636                                       \r\n\r\n\r\nD                     Params    OutputShape          WeightShape     \r\n---                   ---       ---                  ---             \r\nimages_in             -         (?, 3, 2048, 2048)   -               \r\nlabels_in             -         (?, 0)               -               \r\n2048x2048/FromRGB     128       (?, 32, 2048, 2048)  (1, 1, 3, 32)   \r\n2048x2048/Conv0       9248      (?, 32, 2048, 2048)  (3, 3, 32, 32)  \r\n2048x2048/Conv1_down  18496     (?, 64, 1024, 1024)  (3, 3, 32, 64)  \r\n2048x2048/Skip        2048      (?, 64, 1024, 1024)  (1, 1, 32, 64)  \r\n1024x1024/Conv0       36928     (?, 64, 1024, 1024)  (3, 3, 64, 64)  \r\n1024x1024/Conv1_down  73856     (?, 128, 512, 512)   (3, 3, 64, 128) \r\n1024x1024/Skip        8192      (?, 128, 512, 512)   (1, 1, 64, 128) \r\n512x512/Conv0         147584    (?, 128, 512, 512)   (3, 3, 128, 128)\r\n512x512/Conv1_down    295168    (?, 256, 256, 256)   (3, 3, 128, 256)\r\n512x512/Skip          32768     (?, 256, 256, 256)   (1, 1, 128, 256)\r\n256x256/Conv0         590080    (?, 256, 256, 256)   (3, 3, 256, 256)\r\n256x256/Conv1_down    1180160   (?, 512, 128, 128)   (3, 3, 256, 512)\r\n256x256/Skip          131072    (?, 512, 128, 128)   (1, 1, 256, 512)\r\n128x128/Conv0         2359808   (?, 512, 128, 128)   (3, 3, 512, 512)\r\n128x128/Conv1_down    2359808   (?, 512, 64, 64)     (3, 3, 512, 512)\r\n128x128/Skip          262144    (?, 512, 64, 64)     (1, 1, 512, 512)\r\n64x64/Conv0           2359808   (?, 512, 64, 64)     (3, 3, 512, 512)\r\n64x64/Conv1_down      2359808   (?, 512, 32, 32)     (3, 3, 512, 512)\r\n64x64/Skip            262144    (?, 512, 32, 32)     (1, 1, 512, 512)\r\n32x32/Conv0           2359808   (?, 512, 32, 32)     (3, 3, 512, 512)\r\n32x32/Conv1_down      2359808   (?, 512, 16, 16)     (3, 3, 512, 512)\r\n32x32/Skip            262144    (?, 512, 16, 16)     (1, 1, 512, 512)\r\n16x16/Conv0           2359808   (?, 512, 16, 16)     (3, 3, 512, 512)\r\n16x16/Conv1_down      2359808   (?, 512, 8, 8)       (3, 3, 512, 512)\r\n16x16/Skip            262144    (?, 512, 8, 8)       (1, 1, 512, 512)\r\n8x8/MinibatchStddev   -         (?, 513, 8, 8)       -               \r\n8x8/Conv              2364416   (?, 512, 8, 8)       (3, 3, 513, 512)\r\n8x8/Dense0            16777728  (?, 512)             (32768, 512)    \r\nOutput                513       (?, 1)               (512, 1)        \r\nscores_out            -         (?, 1)               -               \r\n---                   ---       ---                  ---             \r\nTotal                 41595425                                       \r\n\r\ntcmalloc: large alloc 1409286144 bytes == 0x55f1c7ba4000 @  0x7f7528fed1e7 0x7f7525ad346e 0x7f7525b23c7b 0x7f7525b2435f 0x7f7525bc6103 0x55efd81374b0 0x55efd8137240 0x55efd81ab0f3 0x55efd81a5ced 0x55efd8138bda 0x55efd81a6915 0x55efd81a5ced 0x55efd8138bda 0x55efd81a7737 0x55efd81a59ee 0x55efd8077e2b 0x55efd81a7fe4 0x55efd8138afa 0x55efd81a6915 0x55efd8138afa 0x55efd81a6c0d 0x55efd81a59ee 0x55efd8077e2b 0x55efd81a7fe4 0x55efd81a59ee 0x55efd8077e2b 0x55efd81a7fe4 0x55efd8138afa 0x55efd81a6915 0x55efd81a59ee 0x55efd81a56f3\r\ntcmalloc: large alloc 1409286144 bytes == 0x55f232770000 @  0x7f7528fef001 0x7f7525ad354f 0x7f7525b23b58 0x7f7525b27b17 0x7f7525bc6203 0x55efd8137544 0x55efd8137240 0x55efd81ab627 0x55efd81a59ee 0x55efd8138bda 0x55efd81a6915 0x55efd81a59ee 0x55efd8138bda 0x55efd81a7737 0x55efd81a59ee 0x55efd8077e2b 0x55efd81a7fe4 0x55efd8138afa 0x55efd81a6915 0x55efd8138afa 0x55efd81a6c0d 0x55efd81a59ee 0x55efd8077e2b 0x55efd81a7fe4 0x55efd81a59ee 0x55efd8077e2b 0x55efd81a7fe4 0x55efd8138afa 0x55efd81a6915 0x55efd81a59ee 0x55efd81a56f3\r\ntcmalloc: large alloc 1409286144 bytes == 0x55f286770000 @  0x7f7528fed1e7 0x7f7525ad346e 0x7f7525b23c7b 0x7f7525b23d18 0x7f7525bdfd79 0x7f7525be2e4c 0x7f7525d01e7f 0x7f7525d07fb5 0x7f7525d09e3d 0x7f7525d0b516 0x55efd8138720 0x55efd81382f9 0x7f7525be9e6b 0x55efd8220677 0x55efd81a7a2e 0x55efd8138afa 0x55efd81a6915 0x55efd81a59ee 0x55efd8138bda 0x55efd81a6915 0x55efd81a59ee 0x55efd8138bda 0x55efd81a7737 0x55efd81a59ee 0x55efd8077e2b 0x55efd81a7fe4 0x55efd8138afa 0x55efd81a6915 0x55efd8138afa 0x55efd81a6c0d 0x55efd81a59ee\r\nBuilding TensorFlow graph...\r\nInitializing logs...\r\nTraining for 4823 kimg...\r\n\r\n2021-10-22 14:38:27.176309: W tensorflow/core/common_runtime/bfc_allocator.cc:419] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.00GiB (rounded to 2147483648).  Current allocation summary follows.\r\n2021-10-22 14:38:27.178308: W tensorflow/core/common_runtime/bfc_allocator.cc:424] *****************************************_____*****_********_____________***************************\r\n2021-10-22 14:38:27.178369: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at fused_bias_act.cu:163 : Resource exhausted: OOM when allocating tensor with shape[4,32,2048,2048] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\nTraceback (most recent call last):\r\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1365, in _do_call\r\n    return fn(*args)\r\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\r\n    target_list, run_metadata)\r\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[4,32,2048,2048] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[{{node GPU0/G_loss/G/G_synthesis/2048x2048/Conv1/FusedBiasAct_1}}]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/content/drive/MyDrive/stylegan2/run_training.py\", line 218, in <module>\r\n    main()\r\n  File \"/content/drive/MyDrive/stylegan2/run_training.py\", line 213, in main\r\n    run(**vars(args))\r\n  File \"/content/drive/MyDrive/stylegan2/run_training.py\", line 136, in run\r\n    dnnlib.submit_run(**kwargs)\r\n  File \"/content/drive/MyDrive/stylegan2/dnnlib/submission/submit.py\", line 343, in submit_run\r\n    return farm.submit(submit_config, host_run_dir)\r\n  File \"/content/drive/MyDrive/stylegan2/dnnlib/submission/internal/local.py\", line 22, in submit\r\n    return run_wrapper(submit_config)\r\n  File \"/content/drive/MyDrive/stylegan2/dnnlib/submission/submit.py\", line 280, in run_wrapper\r\n    run_func_obj(**submit_config.run_func_kwargs)\r\n  File \"/content/drive/MyDrive/stylegan2/training/training_loop.py\", line 312, in training_loop\r\n    tflib.run(G_train_op, feed_dict_g)\r\n  File \"/content/drive/MyDrive/stylegan2/dnnlib/tflib/tfutil.py\", line 31, in run\r\n    return tf.get_default_session().run(*args, **kwargs)\r\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 956, in run\r\n    run_metadata_ptr)\r\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1180, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1359, in _do_run\r\n    run_metadata)\r\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1384, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[4,32,2048,2048] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[node GPU0/G_loss/G/G_synthesis/2048x2048/Conv1/FusedBiasAct_1 (defined at /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py:1748) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nOriginal stack trace for 'GPU0/G_loss/G/G_synthesis/2048x2048/Conv1/FusedBiasAct_1':\r\n  File \"/content/drive/MyDrive/stylegan2/run_training.py\", line 218, in <module>\r\n    main()\r\n  File \"/content/drive/MyDrive/stylegan2/run_training.py\", line 213, in main\r\n    run(**vars(args))\r\n  File \"/content/drive/MyDrive/stylegan2/run_training.py\", line 136, in run\r\n    dnnlib.submit_run(**kwargs)\r\n  File \"/content/drive/MyDrive/stylegan2/dnnlib/submission/submit.py\", line 343, in submit_run\r\n    return farm.submit(submit_config, host_run_dir)\r\n  File \"/content/drive/MyDrive/stylegan2/dnnlib/submission/internal/local.py\", line 22, in submit\r\n    return run_wrapper(submit_config)\r\n  File \"/content/drive/MyDrive/stylegan2/dnnlib/submission/submit.py\", line 280, in run_wrapper\r\n    run_func_obj(**submit_config.run_func_kwargs)\r\n  File \"/content/drive/MyDrive/stylegan2/training/training_loop.py\", line 231, in training_loop\r\n    G_loss, G_reg = dnnlib.util.call_func_by_name(G=G_gpu, D=D_gpu, opt=G_opt, training_set=training_set, minibatch_size=minibatch_gpu_in, **G_loss_args)\r\n  File \"/content/drive/MyDrive/stylegan2/dnnlib/util.py\", line 256, in call_func_by_name\r\n    return func_obj(*args, **kwargs)\r\n  File \"/content/drive/MyDrive/stylegan2/training/loss.py\", line 152, in G_logistic_ns_pathreg\r\n    fake_images_out, fake_dlatents_out = G.get_output_for(latents, labels, is_training=True, return_dlatents=True)\r\n  File \"/content/drive/MyDrive/stylegan2/dnnlib/tflib/network.py\", line 221, in get_output_for\r\n    out_expr = self._build_func(*final_inputs, **build_kwargs)\r\n  File \"/content/drive/MyDrive/stylegan2/training/networks_stylegan2.py\", line 340, in G_main\r\n    images_out = components.synthesis.get_output_for(dlatents, is_training=is_training, force_clean_graph=is_template_graph, **kwargs)\r\n  File \"/content/drive/MyDrive/stylegan2/dnnlib/tflib/network.py\", line 221, in get_output_for\r\n    out_expr = self._build_func(*final_inputs, **build_kwargs)\r\n  File \"/content/drive/MyDrive/stylegan2/training/networks_stylegan2.py\", line 647, in G_synthesis_stylegan2\r\n    x = block(x, res)\r\n  File \"/content/drive/MyDrive/stylegan2/training/networks_stylegan2.py\", line 593, in block\r\n    x = layer(x, layer_idx=res*2, fmaps=nf(res+1), kernel=3)\r\n  File \"/content/drive/MyDrive/stylegan2/training/networks_stylegan2.py\", line 572, in layer\r\n    return apply_bias_act(x, act=act)\r\n  File \"/content/drive/MyDrive/stylegan2/training/networks_stylegan2.py\", line 69, in apply_bias_act\r\n    return fused_bias_act(x, b=tf.cast(b, x.dtype), act=act, alpha=alpha, gain=gain)\r\n  File \"/content/drive/MyDrive/stylegan2/dnnlib/tflib/ops/fused_bias_act.py\", line 68, in fused_bias_act\r\n    return impl_dict[impl](x=x, b=b, axis=axis, act=act, alpha=alpha, gain=gain)\r\n  File \"/content/drive/MyDrive/stylegan2/dnnlib/tflib/ops/fused_bias_act.py\", line 193, in _fused_bias_act_cuda\r\n    return func_zero_2nd_grad(x, b)\r\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/custom_gradient.py\", line 168, in decorated\r\n    return _graph_mode_decorator(f, *args, **kwargs)\r\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/custom_gradient.py\", line 230, in _graph_mode_decorator\r\n    result, grad_fn = f(*args)\r\n  File \"/content/drive/MyDrive/stylegan2/dnnlib/tflib/ops/fused_bias_act.py\", line 163, in func_zero_2nd_grad\r\n    y = func_y(x, b)\r\n  File \"/content/drive/MyDrive/stylegan2/dnnlib/tflib/ops/fused_bias_act.py\", line 127, in func_y\r\n    y = cuda_kernel(x=x, b=b, ref=empty_tensor, grad=0, **cuda_kwargs)\r\n  File \"<string>\", line 96, in fused_bias_act\r\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\r\n    attrs, op_def, compute_device)\r\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\r\n    op_def=op_def)\r\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n", "comments": ["@Anonymud ,\r\nWe see that you are using tf version 1.15, 1.x is not actively supported, please update to latest v2.6 and let us know if you are using same issue.Thanks", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 52619, "title": "MirroredVariable has different values on replicas (only first device is correct)", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes, two lines\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -\r\n- TensorFlow installed from (source or binary): binary (pip)\r\n- TensorFlow version (use command below): 2.6.0 (but I also tried tf-nightly with the same result)\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source): -\r\n- GCC/Compiler version (if compiling from source): -\r\n- CUDA/cuDNN version: 11.2 / 8.1.1 (same behavior also with 11.4 / 8.2.4)\r\n- GPU model and memory: 4 x NVIDIA A40 (48GB)\r\n\r\n**Describe the current behavior**\r\n\r\nMinimal code example:\r\n\r\n```python\r\nimport tensorflow as tf\r\n    \r\nwith tf.distribute.MirroredStrategy().scope():\r\n    print(tf.Variable(1.))\r\n```\r\n\r\nOutput is:\r\n\r\n```\r\nINFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\r\nMirroredVariable:{\r\n  0: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.0>,\r\n  1: <tf.Variable 'Variable/replica_1:0' shape=() dtype=float32, numpy=0.0>,\r\n  2: <tf.Variable 'Variable/replica_2:0' shape=() dtype=float32, numpy=0.0>,\r\n  3: <tf.Variable 'Variable/replica_2:0' shape=() dtype=float32, numpy=0.0>\r\n}\r\n```\r\n\r\nThe problem is, as seen above, that the replicas do not contain the correct variable value, all are zero values except on the first device (the `numpy=0.0` parts). This is the same with 2 or 3 devices as well, not just with all 4.\r\n\r\n(The same code does produce the expected behavior on a different machine with 2x Titan RTX GPUs.)\r\n\r\nThis is simply the minimal reproducing example. The real-world consequence when performing multi-gpu training is that the first forward pass succeeds, but after the first SGD update, things become NaN.\r\n\r\n**Describe the expected behavior**\r\n\r\nExpected output would be:\r\n\r\n```\r\nINFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\r\nMirroredVariable:{\r\n  0: <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.0>,\r\n  1: <tf.Variable 'Variable/replica_1:0' shape=() dtype=float32, numpy=1.0>,\r\n  2: <tf.Variable 'Variable/replica_2:0' shape=() dtype=float32, numpy=1.0>,\r\n  3: <tf.Variable 'Variable/replica_2:0' shape=() dtype=float32, numpy=1.0>\r\n}\r\n```\r\n\r\n(Note the `numpy=1.0` parts.)\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```python\r\nimport tensorflow as tf\r\n    \r\nwith tf.distribute.MirroredStrategy().scope():\r\n    print(tf.Variable(1.))\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nThe server in question is a Dell PowerEdge R750xa with 4x Nvidia A40 GPUs.", "comments": ["Hi @sanatmpa1 ! Could you please look at this issue?", "Update: further debugging shows that this is a broader issue that also impacts the official CUDA samples that use multiple GPUs. Therefore, I believe the root cause is independent of TensorFlow.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52619\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52619\">No</a>\n"]}, {"number": 52618, "title": "Offline Documentation", "body": "Hello, TF Team.\r\nWould you please guide me to how I can generate offline documentation for tensorflow, since I work a lot in offline settings. Or better yet, point me to where I can get a ready-made PDF version of the docs. \r\nThanks.", "comments": ["@H-Sorkatti This is not a bug or feature request, for any further queries you may open this issue in [TF discussion forum](https://discuss.tensorflow.org/) as there is a larger community there.Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 52617, "title": "InaccessibleTensoreorrr: tensor not acessible here , present in another or code block", "body": "\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.6.0\r\n- Python version: 3.8.10\r\n- Bazel version (if compiling from source): no\r\n- GCC/Compiler version (if compiling from source): no\r\n- CUDA/cuDNN version: cuda_11.2\r\n- GPU model and memory: nvidia geforce rtx 2060 / 6gb \r\n\r\nI have implemented a post processing function for object detction model , which will also be used in mAP calcuation using tf,keras custom metric class support. Though while running the scipt in eager mode gives no porblem whatsoever,  but running the script in graph mode (by putting the main function in tf.function scope ), gives an InaccesibleTensorerror.\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\nlink to notebook : https://colab.research.google.com/drive/1Ei2t9coPNEVrfmejzaRUDIs-tm05EZFD?usp=sharing\r\n \r\n**error**\r\nInaccessibleTensorError: in user code:\r\n\r\n    <ipython-input-30-c33ccae08316>:147 post_process  *\r\n        keep_index = [index for index in range(len(final_probs)) if final_probs[index] > filter_threshold]\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1817 wrapper\r\n        return fn(x, y, *args, **kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:3962 greater\r\n        \"Greater\", x=x, y=y, name=name)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:750 _apply_op_helper\r\n        attrs=attr_protos, op_def=op_def)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py:597 _create_op_internal\r\n        inp = self.capture(inp)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py:647 capture\r\n        % (tensor, tensor.graph, self))\r\n\r\n    InaccessibleTensorError: The tensor 'Tensor(\"while/while_1/cond/strided_slice_5:0\", shape=(), dtype=float32)' cannot be accessed here: it is defined in another function or code block. Use return values, explicit Python locals or TensorFlow collections to access it. Defined in: FuncGraph(name=while_while_1_cond_true_56189, id=140026056052816); accessed from: FuncGraph(name=while_body_55673, id=140026059019408).\r\n", "comments": ["@yogeesh-alphaics ,\r\nCan you please this [comment](https://github.com/tensorflow/tensorflow/issues/37512) from the issue with the similar error.It helps.Thanks!\r\n", "@tilakrayal thanks for the direction , it helped. Hope in future tf graph execution is compatible with list too.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52617\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52617\">No</a>\n"]}, {"number": 52616, "title": "The keras.layere.reshape() is a dynamic-sized tensor ? convert CRNN model to TFLite cannot work on android GPU", "body": "### 1. System information\r\n\r\n- Linux Ubuntu 20.04,\r\n- android API 25\r\n- tf-nightly   keras=2.4.3\r\n\r\n### 2. Code\r\n\r\nCRNN model use rashape like this:\r\n\r\n     x = layers.Reshape((4, 128))(x)\r\n\r\nConvert code:\r\n\r\n    keras_model = models.load_model(model_path, custom_objects={ 'precision': precision, 'recall': recall, 'f_score': f_score})\r\n    converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\r\n    tflite_model = converter.convert()\r\n    open(save_mdl_path, \"wb\").write(tflite_model)\r\n\r\n### 3. (optional) Any other info / logs\r\n\r\nThe CRNN TFlite model  (have rashape) can work on Android CPU, but set GPU will get erro: \"java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors (tensor#40 is a dynamic-sized tensor).\"\r\n\r\nThe tflite model can work on android GPU when  delete the layers.rshape and GRU .\r\n\r\nI need reshspe layer for 3D to 2D dim. how I can do this?\r\n\r\nthanks advance\r\n ", "comments": ["Hi @Yunlei-AI ! Could you please provide a sample stand alone code to replicate this issue?", "> Hi @Yunlei-AI ! Could you please provide a sample stand alone code to replicate this issue?\r\n model:\r\n`\r\n    Input_audio = Input(shape=(64, 64,1), dtype='float32', name='audio')\r\n\r\n    RNN = layers.Bidirectional(layers.GRU(units=64, kernel_initializer='lecun_uniform',recurrent_activation = \r\n   'sigmoid',reset_after = True,name='RNN_GRU'))            \r\n                              \r\n    x = layers.Conv2D(128, (3, 3), activation=None,kernel_initializer='lecun_uniform', padding='same')(Input_audio)\r\n\r\n    x = layers.BatchNormalization()(x)\r\n\r\n    x = layers.Activation('relu')(x)\r\n\r\n    x = layers.AveragePooling2D((64, 16), padding='same')(x)\r\n\r\n    x = layers.Reshape((4, 128))(x)\r\n\r\n    x = RNN(x)\r\n\r\n    x = layers.GlobalMaxPooling1D()(x)\r\n\r\n    output = layers.Dense(1, activation='softmax', kernel_initializer='lecun_uniform')(x)\r\n\r\n    model = models.Model(Input_audio, output)\r\n\r\n`\r\n Work fine on android(API 21) CPU .  GPU will get \u2019dynamic-sized tensor\u2018 erro", "Hi @Yunlei-AI ! Sorry for the late response ,I was getting error in your model . Could you please share the same code with saved model in  Colab Gist. Attaching [Gist](https://colab.sandbox.google.com/gist/mohantym/ab658614959d4fb6157ba5a1938cc994/github_52616.ipynb) and issues with similar issues for reference . [#46725](https://github.com/tensorflow/tensorflow/issues/46725), [#51545](https://github.com/tensorflow/tensorflow/issues/51545) [#52061](https://github.com/tensorflow/tensorflow/issues/52061) . Thank you! ", "> Hi @Yunlei-AI ! Sorry for the late response ,I was getting error in your model . Could you please share the same code with saved model in Colab Gist. Attaching [Gist](https://colab.sandbox.google.com/gist/mohantym/ab658614959d4fb6157ba5a1938cc994/github_52616.ipynb) and issues with similar issues for reference . [#46725](https://github.com/tensorflow/tensorflow/issues/46725), [#51545](https://github.com/tensorflow/tensorflow/issues/51545) [#52061](https://github.com/tensorflow/tensorflow/issues/52061) . Thank you!\r\n\r\n\r\nHi @mohantym  I have shared the code in Colab Gist .Attching [Gist](https://colab.research.google.com/drive/17sq3yg_HPijtNBdjqy0-5tlJjbV3FBgO?usp=sharing)  \uff0cThe tflite model  work fine on Android(api 21) CPU ,it will get \"tensor#40 is a dynamic-sized tensor\"erro  when set  \"gpuDelegate = GpuDelegate()\"  ,and It will work fine on CPU and GPU  if \"rashape and RNN\" layers  were deleted", "Hi @sachinprasadhs! Could you please take a look at this issue?", "GPU delegate doesn't support dynamic shapes.\r\nYou need to specify the static size to use the GPU delegate or you can use the dynamic shape with CPU.\r\nPlease look into the responses in the issue [here](https://github.com/tensorflow/tensorflow/issues/38036) for more insights on this. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52616\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52616\">No</a>\n"]}, {"number": 52615, "title": "tensorflow lite libhexagon_nn_skel.so signed ", "body": "About the hexagon nn deployment in tensorflow lite, the libhexagon_nn_skel.so has  already signed\uff1f\r\nIs it possible to use hexnn_controller_request_unsigned_pd to avoid signing problem\u3002", "comments": ["@sprouteer Please have a look at the similar [issue1](https://github.com/tensorflow/tensorflow/issues/36681), [issue2](https://stackoverflow.com/questions/60223978/how-to-build-libhexagon-nn-skel-so-for-tflite)  for reference .This is not a bug or feature request, for any further queries you may open this issue in [TF discussion forum](https://discuss.tensorflow.org/) as there is a larger community there.Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 52614, "title": "[tensorflow/{compiler,core}/**/*.cc] Use `int` for `tuple_shapes_size` to match implementation in \"shape.h\"", "body": "Related: #52522\r\n> The correct type is `int`, as per: https://github.com/tensorflow/tensorflow/blob/0b6b491/tensorflow/compiler/xla/shape.h#L136\r\n", "comments": []}, {"number": 52613, "title": "[oneDNN] Conv3D fusions - part 2", "body": "Conv3D + Bias + Add\r\nConv3D + Bias + Activation", "comments": []}, {"number": 52612, "title": "Add BuildTensorSlice for building from unvalidated TensorSliceProtos.", "body": "This avoids several sources of crashes and undefined behavior when loading\r\ninvalid checkpoints.\r\n\r\nPiperOrigin-RevId: 392785704\r\nChange-Id: Icd9713c768b882f3b58b427eddac376060696833", "comments": []}, {"number": 52611, "title": "Lowering for tfl.sparse_to_dense to tosa", "body": "Sparse to dense can be implemented using a series of reshapes, constants,\r\nnumerical operations, and a final scatter. This should work to decompose into\r\na TOSA compatible form.", "comments": []}, {"number": 52609, "title": "fix building from source failed on Python 3.10 #51776", "body": "Building from source failed on Python 3.10\r\n...\r\n    from google.protobuf.pyext import _message\r\nAttributeError: module 'collections' has no attribute 'MutableSequence'\r\n...\r\n\r\nBackport a patch [1] from protobuf to fix it, and merge it\r\nto existed third_party/protobuf/protobuf.patch\r\n\r\n[1] https://github.com/protocolbuffers/protobuf/commit/9d61eada0f47d7be793983638c4a29707b192d0c\r\n\r\nSigned-off-by: Hongxu Jia <hongxu.jia@windriver.com>", "comments": []}, {"number": 52608, "title": "Specify boolean in the soft_placement docstrings", "body": null, "comments": []}, {"number": 52607, "title": "MirroredStrategy throw always AttributeError at the end of execution", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): v2.5.0-rc3-213-ga4dfb8d1a71 2.5.0\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: 11.2/8.1.0\r\n- GPU model and memory: 10x GTX 1080ti\r\n\r\n**Describe the current behavior**\r\nWhen using a strategy at the end of the program I got an AttributeError exception.\r\n```\r\nException ignored in: <function Pool.__del__ at 0x7f06a661ac10> \r\nTraceback (most recent call last): \r\n  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 268, in del \r\n  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 362, in put \r\nAttributeError: 'NoneType' object has no attribute 'dumps'\r\n```\r\nThe program works as expected, but it shows always that exception.\r\n\r\n**Describe the expected behavior**\r\nThe program should exit without this exception\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf \r\nstrategy = tf.distribute.MirroredStrategy()\r\n ```\r\n", "comments": ["Hi @TheEnigmist! Is this issue replicating in TF 2.6 too? Attaching Gist in [2.4](https://colab.research.google.com/gist/mohantym/e48e599458ec4ad9d93fad602f8ced92/github_52607.ipynb#scrollTo=vHQr5QPCSDuh),[2.5](https://colab.research.google.com/gist/mohantym/0a857a6c5c8d5fe541192185a54b379d/github_52607.ipynb#scrollTo=vHQr5QPCSDuh) and [2.6](https://colab.research.google.com/gist/mohantym/0a857a6c5c8d5fe541192185a54b379d/github_52607.ipynb#scrollTo=wpP0uFfdSF-I) for reference.", "> Hi @TheEnigmist! Is this issue replicating in TF 2.6 too? Attaching Gist in [2.4](https://colab.research.google.com/gist/mohantym/e48e599458ec4ad9d93fad602f8ced92/github_52607.ipynb#scrollTo=vHQr5QPCSDuh),[2.5](https://colab.research.google.com/gist/mohantym/0a857a6c5c8d5fe541192185a54b379d/github_52607.ipynb#scrollTo=vHQr5QPCSDuh) and [2.6](https://colab.research.google.com/gist/mohantym/0a857a6c5c8d5fe541192185a54b379d/github_52607.ipynb#scrollTo=wpP0uFfdSF-I) for reference.\r\n\r\nJust installed TF-gpu 2.6.0 and the Exception ignored appears. I don't know why it doesn't appear on colab executions", "Hi @sanatmpa1! Could you look at this issue .Similar Error stack trace replicated in this [issue](https://github.com/tensorflow/agents/issues/400) too.Attaching Gist in [2.4](https://colab.research.google.com/gist/mohantym/e48e599458ec4ad9d93fad602f8ced92/github_52607.ipynb#scrollTo=vHQr5QPCSDuh) ,[2.5 ](https://colab.research.google.com/gist/mohantym/0a857a6c5c8d5fe541192185a54b379d/github_52607.ipynb#scrollTo=vHQr5QPCSDuh),[2.6](https://colab.research.google.com/gist/mohantym/9004a1adc1ba5e52a6b2e8509a1b204b/github_52607.ipynb) and [nightly](https://colab.research.google.com/gist/mohantym/0a857a6c5c8d5fe541192185a54b379d/github_52607.ipynb#scrollTo=vHQr5QPCSDuh) for reference.", "@TheEnigmist,\r\n\r\nThis looks like an issue with Multi processing on windows. Can you please paste the complete stack trace of the error? Thanks! ", "> @TheEnigmist,\r\n> \r\n> This looks like an issue with Multi processing on windows. Can you please paste the complete stack trace of the error? Thanks!\r\n\r\nThis is the problem, that is the only stack trace printed. All other info are the normal print of finding GPU, setting GPU, etc.", "@TheEnigmist,\r\n\r\nI assume that this error occurs only in your machine, as it works fine in colab and in my local machine as well. Can you try creating a new environment and doing a fresh install of tensorflow `2.6.0` using this [guide](https://www.tensorflow.org/install/pip) and let us know if the issue still persists? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52607\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52607\">No</a>\n"]}, {"number": 52604, "title": "NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n-  Linux Mint Ubuntu 19.2\r\n- TensorFlow installed from pip install tensor flow\r\n- TensorFlow version: newest\r\n- Python version: 3.8.8\r\n- Installed using pip:\r\n- Want to install CUDA version\r\n- GPU model and memory: GTX 1060 NVIDIA driver 470 installed CUDA version 11.4\r\n\r\n\r\n\r\n**Describe the problem**\r\nIn  jupyter notebook tried running import\r\n```\r\nfrom keras.models import load_model\r\nimport cv2\r\nimport numpy as np\r\nfrom moviepy.editor import VideoFileClip\r\nimport pdb\r\nimport matplotlib.pyplot as plt\r\nimport matplotlib.image as mpimg\r\nfrom scipy.ndimage.measurements import label as scipyLabel \r\n\r\n```\r\ngot an error when trying to run `model = load_model('model.h5')` in the debug console of jupyter notebook i got a message saying \r\n```\r\n\r\n2021-10-21 10:18:44.284893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-10-21 10:18:44.322103: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\r\n2021-10-21 10:18:44.329961: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\n2021-10-21 10:18:44.330803: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n\r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nTo fix this issue I followed the instructions in the https://www.tensorflow.org/install/gpu website and ran the cod to install CUDA a\r\n\r\n```\r\n# Add NVIDIA package repositories\r\nwget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\r\nsudo mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\r\nsudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub\r\nsudo add-apt-repository \"deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/ /\"\r\nsudo apt-get update\r\n\r\nwget http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb\r\n\r\nsudo apt install ./nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb\r\nsudo apt-get update\r\n\r\nwget https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/libnvinfer7_7.1.3-1+cuda11.0_amd64.deb\r\nsudo apt install ./libnvinfer7_7.1.3-1+cuda11.0_amd64.deb\r\nsudo apt-get update\r\n\r\n# Install development and runtime libraries (~4GB)\r\nsudo apt-get install --no-install-recommends \\\r\n    cuda-11-0 \\\r\n    libcudnn8=8.0.4.30-1+cuda11.0  \\\r\n    libcudnn8-dev=8.0.4.30-1+cuda11.0\r\n\r\n# Reboot. Check that GPUs are visible using the command: nvidia-smi\r\n\r\n# Install TensorRT. Requires that libcudnn8 is installed above.\r\nsudo apt-get install -y --no-install-recommends libnvinfer7=7.1.3-1+cuda11.0 \\\r\n    libnvinfer-dev=7.1.3-1+cuda11.0 \\\r\n    libnvinfer-plugin7=7.1.3-1+cuda11.0\r\n\r\n```\r\nI rebooted my machine and check that my machine does in fact see the GPU and the GPU is listed with CUDA version 11.4 \r\nI ran the code again in jupyter notebook but no change to the output error message. \r\n\r\n**Any other info / logs**\r\n\r\nError message when ran  `model = load_model('model.h5')`\r\n```\r\n\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-5-d7950e9aea83> in <module>\r\n----> 1 model = load_model('model.h5')\r\n\r\n~/anaconda3/lib/python3.8/site-packages/keras/saving/save.py in load_model(filepath, custom_objects, compile, options)\r\n    198         if (h5py is not None and\r\n    199             (isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\r\n--> 200           return hdf5_format.load_model_from_hdf5(filepath, custom_objects,\r\n    201                                                   compile)\r\n    202 \r\n\r\n~/anaconda3/lib/python3.8/site-packages/keras/saving/hdf5_format.py in load_model_from_hdf5(filepath, custom_objects, compile)\r\n    178       model_config = model_config.decode('utf-8')\r\n    179     model_config = json_utils.decode(model_config)\r\n--> 180     model = model_config_lib.model_from_config(model_config,\r\n    181                                                custom_objects=custom_objects)\r\n    182 \r\n\r\n~/anaconda3/lib/python3.8/site-packages/keras/saving/model_config.py in model_from_config(config, custom_objects)\r\n     50                     '`Sequential.from_config(config)`?')\r\n     51   from keras.layers import deserialize  # pylint: disable=g-import-not-at-top\r\n---> 52   return deserialize(config, custom_objects=custom_objects)\r\n     53 \r\n     54 \r\n\r\n~/anaconda3/lib/python3.8/site-packages/keras/layers/serialization.py in deserialize(config, custom_objects)\r\n    206   \"\"\"\r\n    207   populate_deserializable_objects()\r\n--> 208   return generic_utils.deserialize_keras_object(\r\n    209       config,\r\n    210       module_objects=LOCAL.ALL_OBJECTS,\r\n\r\n~/anaconda3/lib/python3.8/site-packages/keras/utils/generic_utils.py in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name)\r\n    672 \r\n    673       if 'custom_objects' in arg_spec.args:\r\n--> 674         deserialized_obj = cls.from_config(\r\n    675             cls_config,\r\n    676             custom_objects=dict(\r\n\r\n~/anaconda3/lib/python3.8/site-packages/keras/engine/sequential.py in from_config(cls, config, custom_objects)\r\n    430     model = cls(name=name)\r\n    431     for layer_config in layer_configs:\r\n--> 432       layer = layer_module.deserialize(layer_config,\r\n    433                                        custom_objects=custom_objects)\r\n    434       model.add(layer)\r\n\r\n~/anaconda3/lib/python3.8/site-packages/keras/layers/serialization.py in deserialize(config, custom_objects)\r\n    206   \"\"\"\r\n    207   populate_deserializable_objects()\r\n--> 208   return generic_utils.deserialize_keras_object(\r\n    209       config,\r\n    210       module_objects=LOCAL.ALL_OBJECTS,\r\n\r\n~/anaconda3/lib/python3.8/site-packages/keras/utils/generic_utils.py in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name)\r\n    672 \r\n    673       if 'custom_objects' in arg_spec.args:\r\n--> 674         deserialized_obj = cls.from_config(\r\n    675             cls_config,\r\n    676             custom_objects=dict(\r\n\r\n~/anaconda3/lib/python3.8/site-packages/keras/layers/core.py in from_config(cls, config, custom_objects)\r\n   1003   def from_config(cls, config, custom_objects=None):\r\n   1004     config = config.copy()\r\n-> 1005     function = cls._parse_function_from_config(\r\n   1006         config, custom_objects, 'function', 'module', 'function_type')\r\n   1007 \r\n\r\n~/anaconda3/lib/python3.8/site-packages/keras/layers/core.py in _parse_function_from_config(cls, config, custom_objects, func_attr_name, module_attr_name, func_type_attr_name)\r\n   1055     elif function_type == 'lambda':\r\n   1056       # Unsafe deserialization from bytecode\r\n-> 1057       function = generic_utils.func_load(\r\n   1058           config[func_attr_name], globs=globs)\r\n   1059     elif function_type == 'raw':\r\n\r\n~/anaconda3/lib/python3.8/site-packages/keras/utils/generic_utils.py in func_load(code, defaults, closure, globs)\r\n    787   except (UnicodeEncodeError, binascii.Error):\r\n    788     raw_code = code.encode('raw_unicode_escape')\r\n--> 789   code = marshal.loads(raw_code)\r\n    790   if globs is None:\r\n    791     globs = globals()\r\n\r\nValueError: bad marshal data (unknown type code)\r\n```\r\nThanks to any help in advanced", "comments": ["Hi @jimhoggey! Could you look at these similar issues for above error. [Link1](https://www.py4u.net/discuss/17141),[Link2](https://stackoverflow.com/questions/30861493/how-to-fix-python-valueerrorbad-marshal-data),[Link3](https://github.com/keras-team/keras/issues/7440) ,Please post a stand alone code for further assistance . Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 52603, "title": "build tensorflow 2.6 on macOS Big Sur (11.6) M1 ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  macOS Big Sur v11.6 Apple M1 \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None\r\n- TensorFlow installed from (source or binary): source \r\n- TensorFlow version: 2.6.0\r\n- Python version: 3.8.12\r\n- Installed using virtualenv? pip? conda?: pip 21.3 (python 3.8) \r\n- Bazel version (if compiling from source): bazel 4.2.1-homebrew\r\n- GCC/Compiler version (if compiling from source): llvm  (Apple clang version 13.0.0 (clang-1300.0.29.3). /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\n- CUDA/cuDNN version: none\r\n- GPU model and memory: none\r\n\r\n\r\n\r\n**Describe the problem**\r\nI am trying to build tensorflow v2.6.0 on macOS Big Sur using the first version of M1 chip.\r\n\r\n1. cd ~/Downloads\r\n2. git clone https://github.com/meteorcloudy/tensorflow.git\r\n3. cd tensorflow\r\n4. modify .bazelversion to current version that I have installed using brew (4.2.1).\r\n5. unset PYTHONPATH env\r\n6. unset PYTHON_BIN_PATH env\r\n7. ./configure\r\n8. bazel build --config=v2 --config=opt --cpu=darwin_arm64 //tensorflow/tools/pip_package:build_pip_package\r\n9. ./bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\r\n10. cd /tmp/tensorflow_pkg\r\n11. pip install tensorflow-2.8.0-cp38-cp38-macosx_11_0_arm64.whl\r\nERROR: tensorflow-2.8.0-cp38-cp38-macosx_11_0_arm64.whl is not a supported wheel on this platform.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nI got the error saying that the whl is not supported on this platform.\r\nIs it something wrong when I use bazel? \r\nI have tried to use\r\n   bazel build --config=v2 --config=opt --config=macos_arm64 //tensorflow/tools/pip_package:build_pip_package\r\n   ./bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\r\nand I got the same error.\r\n\r\nPlease kindly let me know how to fix that. \r\nThanks\r\nKel\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@utrenic Could you please refer to the [build from source](https://www.tensorflow.org/install/source#macos) , please have a look at the similar issues [link1](https://stackoverflow.com/questions/66712926/how-to-install-tensorflow-2-x-on-mac-os-big-sur-catalina-mojave-without-anac), [link2](https://github.com/tensorflow/tensorflow/issues/52138) ,[link3](https://github.com/tensorflow/tensorflow/issues/42482)   and let us know if it helps ? Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52603\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52603\">No</a>\n"]}, {"number": 52602, "title": "Merge pull request #52583 from jhalakp-nvidia:trt-relu6-dynamic-range", "body": "PiperOrigin-RevId: 404585433\r\nChange-Id: I876e64dec04e374e90e7e9de5ab2521da05738fe", "comments": []}, {"number": 52601, "title": "Merge pull request #51359 from yongtang:46913-range-overflow", "body": "PiperOrigin-RevId: 391529518\r\nChange-Id: Ie3db4ae6d3c0f3dc88404e1dbdc22f7d03cbeb3b", "comments": ["This is a dupe of https://github.com/tensorflow/tensorflow/pull/52632? ", "Different branch, these are cherry-picks PRs for patch releases.", "Moving to #52666"]}, {"number": 52600, "title": "Merge pull request #51359 from yongtang:46913-range-overflow", "body": "PiperOrigin-RevId: 391529518\r\nChange-Id: Ie3db4ae6d3c0f3dc88404e1dbdc22f7d03cbeb3b", "comments": ["This is a dupe of https://github.com/tensorflow/tensorflow/pull/52632?", "Different branch, these are cherry-picks PRs for patch releases.", "Moving to #52665"]}, {"number": 52598, "title": "Try to fix MacOS CI tests", "body": "Let see if MacOS build pass now. If yes it could be caused by:\r\n\r\nhttps://github.com/bazelbuild/bazel/issues/5572", "comments": ["@joker-eph Have you tested your commit https://github.com/tensorflow/tensorflow/commit/c58cda59e107fe7f8a32e8489dfdba3f853b8bbd on MacOS?\r\n\r\nDid you find any specific workaround for https://github.com/bazelbuild/bazel/issues/5572 if related?\r\n", "> your commit c58cda5 on MacOS?\r\n\r\nThis commit fixed the CI at the time.\r\n\r\nThere are some constraints with this flag and the host environment (what kind of JDK is available I think). Where do you see the failure?", "> This commit fixed the CI at the time.\r\n\r\nI suppose probably it fixed the CI from a timeout\r\n\r\n> Where do you see the failure?\r\n\r\nIn think can check any PR in the last month of the MacOS CPU build log, as also the last time it worked it was before that commit (last `tf-nightly` release on MacOs was 2021-09-22).\r\n\r\nCan you see in this MacOS CPU build log if it was already failed? As I don't have access when it is WIP.\r\n\r\n\r\n\r\n", "P.s. you can check your original commit build failure (2021-09-22) at https://source.cloud.google.com/results/invocations/bc11c386-b7bc-4f05-b222-9362ae826bdf/log", "Just to add some references\n\nhttps://github.com/bazelbuild/bazel/issues/13241#issuecomment-834458002\nhttps://github.com/tensorflow/toolchains/pull/23\nhttps://github.com/tensorflow/toolchains/pull/25\n\n/cc @comius @av8ramit \n\n\n", "@mihaimaruseac As you have approved some of these PR in the toolchain repo can you check this flow? Thanks\r\n\r\nhttps://github.com/bazelbuild/bazel/issues/13241#issuecomment-834458002 -> https://github.com/tensorflow/toolchains/pull/23 -> https://github.com/tensorflow/toolchains/pull/25 -> https://github.com/tensorflow/tensorflow/commit/acf0e5a304902ad4e0748fe4b189d829a12c1f49 / https://github.com/tensorflow/tensorflow/commit/c58cda59e107fe7f8a32e8489dfdba3f853b8bbd", "I think that we need to fix this in the [tensorflow/toolchains repo](https://github.com/tensorflow/toolchains) as we had a rollback in June with the mentioned PR. \r\n\r\nCurrently `--nodistinct_host_configuration` in this repo is only in:\r\n\r\n```\r\ntensorflow/tools/ci_build/presubmit/macos/py37_cc/build.sh\r\ntensorflow/tools/ci_build/Dockerfile.cuda-clang\r\n```\r\n\r\nI suppose we are particularly sensitive to this option on the MacOS job as we don't use the RBE[\u00b9] as in the other jobs or a GCS bazel `--disk_cache` so the MacOs build it is really done in a \"cleanroom\" env and It is easy that it could take a long time to build and execute tests.\r\n\r\n\r\n[\u00b9]\r\n`\r\n--remote_executor=grpcs://remotebuildexecution.googleapis.com --remote_timeout=3600 --spawn_strategy=remote,worker,standalone,local --remote_download_toplevel\r\n`\r\n\r\nEDIT:\r\nAs we don't have a CI in the toolchains repo I really don't know how to test-explore a PR there.", "This is interesting find. I think we can test this internally, will be looking at this today.", "This is no longer needed, I think. We've fixed the macos issue."]}, {"number": 52597, "title": "Simple SSD, face detector, training ok with GradientTape BUT loss doesn't decrease if I train an identical model with Model.fit()", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes, custom\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04, and also on current Google Colab\r\n- TensorFlow installed from (source or binary): binary, GPU version\r\n- TensorFlow version (use command below): 2.5.1 (2.6 on Google Colab)\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: 11.4, 8.2\r\n- GPU model and memory: Geforce RTX 2080 Ti\r\n\r\n**Describe the current behavior**\r\n\r\nHi, I found a really interesting bug when I was building a simple SSD model to find faces on images.\r\n\r\nI have a simple, ResNet-like model, containing only convolutions and max pooling layers. I use the \"Faces in the Wild\" dataset from UMass. When I create a model and train it with using GradientTape it learns quickly, and after just 20 epochs it predicts very well face bounding boxes, and validation loss goes below 0.6. On the other hand, if I create the exactly the same model, use the same Adam optimizer, but I train the Model with Model.fit(), it just learns nothing. The validation loss starts from 1.8 and doesn't decrease at all.\r\n\r\nI found the issue first on my machine running Tensorflow 2.5.1, but I can reproduce the exactly same behaviour on Google Colab as well, currently running 2.6.0.\r\n\r\n**Describe the expected behavior**\r\n\r\nThe Model.fit() and the simple GradientTape training should work identical, both trained model should learn and predict similarly.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nPlease check out the code here in Google Colab:\r\nhttps://colab.research.google.com/drive/1LvahE1CBuvvxAi7PT0gqcSrFYPDBEJmY?usp=sharing\r\n\r\n**Other info / logs**\r\n\r\nPlease check out the ends of the verbose outputs of training loops:\r\n\r\nModel.fit() version output:\r\n[...]\r\nEpoch 18/20\r\n80/80 [==============================] - 9s 111ms/step - loss: 1.6102 - val_loss: 1.6888\r\nEpoch 19/20\r\n80/80 [==============================] - 9s 111ms/step - loss: 1.6102 - val_loss: 1.6888\r\nEpoch 20/20\r\n80/80 [==============================] - 9s 112ms/step - loss: 1.6102 - val_loss: 1.6888\r\n\r\nGradientTape version output:\r\n[...]\r\nepoch: [18/20], Train: [loss: 0.4297], Test: [loss: 0.5801]\r\nepoch: [19/20], Train: [loss: 0.4001], Test: [loss: 0.5757]\r\nepoch: [20/20], Train: [loss: 0.3962], Test: [loss: 0.5701]\r\n\r\nThanks for reading it, let me know what do you think.", "comments": ["Hi @qspi \r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999) . Thanks!", "Hi @mohantym thanks a lot for your help, I got it, I raise this on keras issue tracker."]}, {"number": 52596, "title": "Mixed precision training incompatible with BinaryCrossentropy label smoothing", "body": "### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**: Yes\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows Server 2012 R2\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**: -\r\n-   **TensorFlow installed from (source or binary)**: binary\r\n-   **TensorFlow version (use command below)**: v2.6.0-rc2-32-g919f693420e 2.6.0\r\n-   **Python version**: 3.9.6\r\n-   **Bazel version (if compiling from source)**: -\r\n-   **GCC/Compiler version (if compiling from source)**: -\r\n-   **CUDA/cuDNN version**: 11.2.2 / 8.1\r\n-   **GPU model and memory**: NVIDIA Titan X (Pascal), 12288 MiB\r\n-   **Exact command to reproduce**: see example below\r\n\r\n### Describe the problem\r\nReporting a possible bug. When setting float16 mixed precision policy and using label smoothing in BinaryCrossentropy, training returns a TypeError. Turning off either the mixed precision policy or label smoothing gives no errors. Passing a float16 to the label_smoothing argument does not help.\r\n\r\n### Source code / logs\r\n\r\n**Reproducible example**\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n# Set mixed precision policy\r\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\r\n\r\n# Create some random data\r\ninputs  = tf.random.normal((64, 256, 256, 1))\r\ntargets = tf.constant(np.random.choice(\r\n    a       = [0, 1],\r\n    size    = (64, 256, 256, 1),\r\n    replace = True\r\n))\r\n\r\n# Create simple model\r\nmodel = tf.keras.Sequential([\r\n    tf.keras.Input(shape=(256, 256, 1)),\r\n    tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu')\r\n])\r\n\r\nmodel.compile(\r\n    optimizer = 'adam',\r\n    loss      = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.1)\r\n)\r\n\r\n# Train model\r\nmodel.fit(inputs, targets, batch_size=8)\r\n```\r\n\r\n**Traceback**\r\n```\r\nTraceback (most recent call last):\r\n\r\n  File \"G:\\[redacted]\\src\\debug1.py\", line 36, in <module>\r\n    model.fit(inputs, targets, batch_size=8)\r\n\r\n  File \"F:\\conda_env\\[redacted]\\lib\\site-packages\\keras\\engine\\training.py\", line 1184, in fit\r\n    tmp_logs = self.train_function(iterator)\r\n\r\n  File \"F:\\conda_env\\[redacted]\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 885, in __call__\r\n    result = self._call(*args, **kwds)\r\n\r\n  File \"F:\\conda_env\\[redacted]\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 933, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializers)\r\n\r\n  File \"F:\\conda_env\\[redacted]\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 759, in _initialize\r\n    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n\r\n  File \"F:\\conda_env\\[redacted]\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3066, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _ = self._maybe_define_function(args, kwargs)\r\n\r\n  File \"F:\\conda_env\\[redacted]\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3463, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n\r\n  File \"F:\\conda_env\\[redacted]\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3298, in _create_graph_function\r\n    func_graph_module.func_graph_from_py_func(\r\n\r\n  File \"F:\\conda_env\\[redacted]\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1007, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n\r\n  File \"F:\\conda_env\\[redacted]\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 668, in wrapped_fn\r\n    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n\r\n  File \"F:\\conda_env\\[redacted]\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 994, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\n\r\nTypeError: in user code:\r\n\r\n    F:\\conda_env\\[redacted]\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\r\n        return step_function(self, iterator)\r\n    F:\\conda_env\\[redacted]\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\r\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n    F:\\conda_env\\[redacted]\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\r\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    F:\\conda_env\\[redacted]\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\r\n        return self._call_for_each_replica(fn, args, kwargs)\r\n    F:\\conda_env\\[redacted]\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\r\n        return fn(*args, **kwargs)\r\n    F:\\conda_env\\[redacted]\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\r\n        outputs = model.train_step(data)\r\n    F:\\conda_env\\[redacted]\\lib\\site-packages\\keras\\engine\\training.py:788 train_step\r\n        loss = self.compiled_loss(\r\n    F:\\conda_env\\[redacted]\\lib\\site-packages\\keras\\engine\\compile_utils.py:201 __call__\r\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\r\n    F:\\conda_env\\[redacted]\\lib\\site-packages\\keras\\losses.py:141 __call__\r\n        losses = call_fn(y_true, y_pred)\r\n    F:\\conda_env\\[redacted]\\lib\\site-packages\\keras\\losses.py:245 call  **\r\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\r\n    F:\\conda_env\\[redacted]\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\r\n        return target(*args, **kwargs)\r\n    F:\\conda_env\\[redacted]\\lib\\site-packages\\keras\\losses.py:1805 binary_crossentropy\r\n        y_true = tf.__internal__.smart_cond.smart_cond(label_smoothing, _smooth_labels,\r\n    F:\\conda_env\\[redacted]\\lib\\site-packages\\tensorflow\\python\\framework\\smart_cond.py:56 smart_cond\r\n        return true_fn()\r\n    F:\\conda_env\\[redacted]\\lib\\site-packages\\keras\\losses.py:1803 _smooth_labels\r\n        return y_true * (1.0 - label_smoothing) + 0.5 * label_smoothing\r\n    F:\\conda_env\\[redacted]\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1383 binary_op_wrapper\r\n        raise e\r\n    F:\\conda_env\\[redacted]\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1367 binary_op_wrapper\r\n        return func(x, y, name=name)\r\n    F:\\conda_env\\[redacted]\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1710 _mul_dispatch\r\n        return multiply(x, y, name=name)\r\n    F:\\conda_env\\[redacted]\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\r\n        return target(*args, **kwargs)\r\n    F:\\conda_env\\[redacted]\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:530 multiply\r\n        return gen_math_ops.mul(x, y, name)\r\n    F:\\conda_env\\[redacted]\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6244 mul\r\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\r\n    F:\\conda_env\\[redacted]\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:555 _apply_op_helper\r\n        raise TypeError(\r\n\r\n    TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type float16 of argument 'x'.\r\n```", "comments": ["@ghup1 \r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThank you!", "@sushreebarsa Thanks for the response. Reposted the issue [here](https://github.com/keras-team/keras/issues/15528).", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52596\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52596\">No</a>\n"]}, {"number": 52595, "title": "[TF:TRT] Move definition of TrtPrecisionMode and ProfileStrategy to a separate header", "body": "The TF-TRT cpp converter needs to include the definition of `TrtPrecisionMode` and `ProfileStrategy`. Previously, these were defined in `convert/utils.h` which depends on `third_party/tensorrt/NvInfer.h`.  This third party header is not installed along with the rest of the header files. This PR moves the definitions to a separate header file. This way `trt_converter_api.h` is not dependent on `NvInfer.h` anymore. \r\n\r\nTracker: #45481\r\n\r\nTagging @bixia1 for review.", "comments": ["Resolved conflicts."]}, {"number": 52594, "title": "Failed to invoke the interpreter with error: Provided data count XXX must match the required count 3.", "body": "### 1. System information\r\n\r\n- OSX 11.5.2, iOS 14.7.1, CentOS 8.4.2105 \r\n- TensorFlow v2.6.0 custom built for server (CentOS 8.4.2105)\r\n- TensorFlow library 'TensorFlowLiteSwift', '~> 2.6'\r\n\r\nThe CentOS custom built tensorflow was built with the following optimization flags:\r\n```\r\n-march=native -msse4_1 -msse4_2 -mssse3 -mcx16 -mpopcnt\r\n```\r\n\r\nOn the CentOS 8 box I successfully trained a custom model using `faster_rcnn_resnet152_v1` for it's configuration. I'm able to run the model on images and mp4 files successfully. \r\n\r\nI converted the model on the CentOS box for tflite. \r\n\r\nI copied the model into the `tensorflow/examples/tree/master/lite/examples/object_detection/ios` example project and updated the Podfile to use tflite 2.6.\r\n\r\n### 2. Code\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nsaved_model_dir = \"exported-models/barbell_3/saved_model\"\r\n\r\n# Convert the model\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\r\nconverter.target_spec.supported_ops = [\r\n  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\r\n  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\r\n]\r\n\r\ntflite_model = converter.convert()\r\n\r\n# Save the model.\r\nwith open('model.tflite', 'wb') as f:\r\n  f.write(tflite_model)\r\n```\r\n\r\n\r\nModelDataHandler.swift\r\nCase 1\r\n```\r\n  // MARK: Model parameters\r\n  let batchSize = 1\r\n  let inputChannels = 3\r\n  let inputWidth = 1024\r\n  let inputHeight = 1024\r\n```\r\n\r\nCase 2\r\n```\r\n  // MARK: Model parameters\r\n  let batchSize = 1\r\n  let inputChannels = 3\r\n  let inputWidth = 1\r\n  let inputHeight = 1\r\n```\r\n\r\n\r\n\r\n### 3. Failure after conversion\r\n\r\n\r\n#### Case 1\r\n- Interpreter can't load model\r\n\r\n```\r\nFailed to invoke the interpreter with error: Provided data count 3145728 must match the required count 3.\r\n```\r\n\r\nNote 1024 * 1024 * 3 = 3145728\r\n\r\nNote the netron graph entry point shows the input should be `1x1x1=3` followed by a while loop whose 3rd element is (1x1024x1024x3).\r\n\r\nPresumably, these are the correct parameters however see case 2.\r\n\r\n#### Case 2\r\n\r\nIf I set the inputWidth and inputHeight to 1x1 the interpreter loads, the app starts and then crashes with an Out of Memory error (in a popup window) - however, nothing is logged in the XCode console and no errors are given for tensorflow lite.\r\n\r\n```\r\n2021-10-20 09:28:46.565241-0500 ObjectDetection[723:92493] Initialized TensorFlow Lite runtime.\r\nINFO: Initialized TensorFlow Lite runtime.\r\n```\r\n\r\nIs it the case that the correct parameters are inputHeight=1 and inputWidth=1 and that my model is using too much OS memory on the phone?\r\n\r\nIf that's true are there guidelines on which model training config params are suitable for phones (both iOS and Andriod)? That is, models with better input size and hidden layer size etc?\r\n\r\n\r\n### 4. (optional) RNN conversion support\r\n\r\n\r\n### 5. (optional) Any other info / logs\r\n\r\n<img width=\"1394\" alt=\"netron\" src=\"https://user-images.githubusercontent.com/128980/138111306-28d3f186-6461-4795-a798-9777cb203496.png\">\r\n\r\n", "comments": ["https://github.com/tensorflow/tensorflow/issues/46199", "https://github.com/tensorflow/tensorflow/issues/35864", "Reading https://www.tensorflow.org/lite/tutorials/model_maker_object_detection it looks like the solution may be to use the `EfficientDet` model architecture and to train the model using `TensorFlow Lite Model Maker`.", "I made 2 mistakes:\r\n1. I didn't export the model as a tflite graph\r\n2. I was using an unsupported model `faster_rcnn_resnet152_v1`\r\n\r\nRetraining a `ssd_mobilenet_v2` and then exporting using `export_tflite_graph_tf2.py` before the conversion worked!\r\n\r\nOf note, the `export_tflite_graph_tf2.py` tool will exit with an error if an unsupported model is used however the conversion lib function `tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)` doesn't warn/error/exit with an unsupported model. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52594\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52594\">No</a>\n"]}, {"number": 52593, "title": "[NNAPI]call memcpy() with null pointer dereference.", "body": "1. create `initialize.tflite` with [model_personalization](https://github.com/tensorflow/examples/tree/master/lite/examples/model_personalization) `tflite-transfer-convert`.\r\n1. execute delegate with the following option.\r\n   ```cpp\r\n   tflite::StatefulNnApiDelegate::Options options;\r\n   options.accelerator_name = \"nnapi-reference\"; // use CPU\r\n   auto delegate = new tflite::StatefulNnApiDelegate(options);\r\n   ```\r\n1. fatal error has occurred.\r\n   ```txt\r\n   signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0x0\r\n   Cause: null pointer dereference\r\n   ```\r\n1. `nn_input_memory_->get_data_ptr()` returns `nullptr`.\r\n   - [total_input_byte_size](https://github.com/tensorflow/tensorflow/blob/e042c277ab6375bf4060e099dd20a101cc0685e0/tensorflow/lite/delegates/nnapi/nnapi_delegate.cc#L5700-L5701) == 0", "comments": ["@miaowang14 Can you take a look at this?", "I suspect that just adding the check would not make the model run well through NNAPI delegate. We'd need to figure out the root cause on the nn_input_memory_ is not properly updated.", "@miaowang14 \r\nHow about this conditional expression ?"]}, {"number": 52592, "title": "Will Tensorflow support Keras in the future? ", "body": "In the [release notes](https://github.com/tensorflow/tensorflow/blob/master/RELEASE.md) 2.6 release notes, it is mentioned that keras is going to be separated from tensorflow. \r\n \r\nMy query is - Does this mean that tf.keras will be in sync with the separated keras library? (I understand that tf.python.keras is deprecated and will be removed). \r\n\r\nSo as a recommendation, should I use tf.keras or directly import and use keras in my future projects?", "comments": ["@adsk2050 \r\n\r\nPlease refer to below post and you may raise your query there as well.\r\nhttps://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999\r\n\r\nOr post this issue on [keras-team/keras repo](https://github.com/keras-team/keras/issues).\r\nTo know more refer to:", "@adsk2050 Keras will be part (a high level API) of Tensorflow. Only GitHub repository is moving to keras-team/keras to focus on Keras related bugs and performance issues. So, if you have any bugs/performance related issues related keras, they need to be opened in keras-team/keras repository.\r\n\r\n> My query is - Does this mean that tf.keras will be in sync with the separated keras library? (I understand that tf.python.keras is deprecated and will be removed).\r\n> \r\n\r\nYes, `tf.keras` will be in sync with `keras`.\r\n\r\n> So as a recommendation, should I use tf.keras or directly import and use keras in my future projects?\r\nAs keras has some dependencies that will be imported through tensorflow, it is always recommended to import keras as shown below\r\n\r\n`from tensorflow import keras`\r\n\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing this as this was resolved. Thanks!"]}, {"number": 52590, "title": "Following machine learning tutorial of Google gives wrong results", "body": "# The case:\r\nI have to follow this Tutorial for school and reproduce the results:\r\n[Predicting Customer Lifetime Value with AI Platform: training the models](https://cloud.google.com/architecture/clv-prediction-with-offline-training-train)\r\nThis task should be the first step of my bachelor thesis and I have to reproduce this result very naive, so with the same parameters. I am trying on this for weeks now.\r\n\r\nI did this already in Tensorflow 2 with newer commands, than tried the same in Tensorflow 1. Both gave the same results like in the code below. The code below was my last try so far, by loading the old packages for TF, so I can use the EXACT same commands and code structure, like they did. \r\nI will post the whole in detail, but I think it is structured really well (like the {}.py files of the tutorial), for you to understand. \r\nThe data preparation I did in BigQuery and saved the train, eval and test set to [my GitHub Repo](https://github.com/timmy-ops/DNNs_for_CLVs) for importing them easily. \r\nThe original .py files, which are named like my cells you can find in [their GitHub Repo](https://github.com/GoogleCloudPlatform/tensorflow-lifetime-value/tree/0f8c16ea70a2e7da370965e23e9e2154978364fa/clv_mle/trainer).\r\n\r\nThere are 4 cells of code in my Colab plus the module imports and below I wrote the current and expected behaviour...\r\n```\r\n@#title IMPORT MODULES and GitHub Repos\r\nimport pandas as pd\r\nfrom datetime import datetime\r\nimport numpy as np\r\n!pip install gast==0.2.2\r\n\r\n%tensorflow_version 1.x\r\nimport tensorflow as tf\r\nfrom tensorflow import feature_column as tfc\r\nfrom six import iteritems\r\nimport shutil\r\n\r\n#only for the hypertune path fn:\r\nimport json\r\nimport os\r\n\r\n! git clone https://github.com/GoogleCloudPlatform/tensorflow-lifetime-value.git\r\n! git clone https://github.com/timmy-ops/DNNs_for_CLVs\r\n```\r\n```\r\n#@title DNN: context.py\r\n\r\nclass CLVFeatures(object):\r\n\r\n  HEADERS = ['customer_id', 'monetary_dnn', 'monetary_btyd', 'frequency_dnn',\r\n             'frequency_btyd', 'recency', 'T', 'time_between',\r\n             'avg_basket_value', 'avg_basket_size', 'cnt_returns',\r\n             'has_returned', 'frequency_btyd_clipped', 'monetary_btyd_clipped',\r\n             'target_monetary_clipped', 'target_monetary']\r\n  HEADERS_DEFAULT = [[''], [0.0], [0.0], [0],\r\n                     [0], [0], [0], [0.0],\r\n                     [0.0], [0.0], [0],\r\n                     [-1], [0], [0.0],\r\n                     [0.0], [0.0]]\r\n  NUMERICS = {\r\n      'monetary_dnn': [],\r\n      'recency': [],\r\n      'frequency_dnn': [],\r\n      'T': [],\r\n      'time_between': [],\r\n      'avg_basket_value': [],\r\n      'avg_basket_size': [],\r\n      'cnt_returns': []}\r\n  CATEGORICALS_W_LIST = {\r\n      'has_returned': [0, 1]}\r\n  CROSSED = []\r\n  KEY = 'customer_id'\r\n  UNUSED = [KEY, 'monetary_btyd', 'frequency_btyd', 'frequency_btyd_clipped',\r\n            'monetary_btyd_clipped', 'target_monetary_clipped']\r\n  TARGET_NAME = 'target_monetary'\r\n\r\n  def __init__(self, ignore_crosses=False): #, is_dnn=None\r\n\r\n    #if not is_dnn:\r\n    #  return\r\n\r\n    self.ignore_crosses = ignore_crosses\r\n    (self.headers, self.numerics_names, self.categorical_names) = self._keep_used()\r\n    self.continuous, self.categorical = self._make_base_features()\r\n\r\n    if not self.ignore_crosses:\r\n      self.crossed_for_wide, self.crossed_for_deep = self._make_crossed()\r\n  \r\n  def _keep_used(self):\r\n    headers = [h for h in self.HEADERS if h not in self.UNUSED]\r\n    numerics_names = {\r\n        k: v for k, v in iteritems(self.NUMERICS)\r\n        if (k not in self.UNUSED) and (k != self.TARGET_NAME)\r\n    }\r\n    categorical_names = {\r\n        k: v for k, v in iteritems(self.CATEGORICALS_W_LIST)\r\n        if k not in self.UNUSED    \r\n    }                          \r\n    return headers, numerics_names, categorical_names\r\n  \r\n  def get_key(self):\r\n    return self.KEY\r\n  \r\n  def get_used_headers(self, with_key=False, with_target=False):\r\n    used_headers = [h for h in self.headers if h != self.TARGET_NAME]\r\n\r\n    if with_key:\r\n      used_headers.insert(0, self.KEY)\r\n    if with_target:\r\n      used_headers.append(self.TARGET_NAME)\r\n\r\n    return used_headers\r\n\r\n  def get_defaults(self, headers_names=None, with_key=False):\r\n    if headers_names is None:\r\n      headers_names = self.get_used_headers(with_key)\r\n\r\n    keep_indexes = [self.HEADERS.index(n) for n in headers_names]\r\n    return [self.HEADERS_DEFAULT[i] for i in keep_indexes]\r\n\r\n  def get_all_names(self):\r\n    return self.HEADERS\r\n\r\n  def get_all_defaults(self):\r\n    return self.HEADERS_DEFAULT\r\n\r\n  def get_unused(self):\r\n    return self.UNUSED\r\n\r\n  def get_target_name(self):\r\n    return self.TARGET_NAME\r\n\r\n  def _make_base_features(self):\r\n    continuous = {\r\n        key_name: tfc.numeric_column(key_name)\r\n        for key_name in self.numerics_names.keys()\r\n    }\r\n    categorical = {\r\n        key_name: tfc.categorical_column_with_vocabulary_list(\r\n            key=key_name,\r\n            vocabulary_list=voc)\r\n        for key_name, voc in self.categorical_names.items()\r\n    }    \r\n    return continuous, categorical\r\n\r\n  def get_base_features(self):\r\n    return self.continous, self.categorical\r\n\r\n  def _prepare_for_crossing(self, key_name, num_bck, boundaries):\r\n    key = None\r\n    if key_name in self.continuous.keys():\r\n      if boundaries is not None:\r\n        key = tfc.bucketized_column(self.continuous[key_name], boundaries)\r\n      else:\r\n        key = tfc.categorical_column_with_identity(key_name, num_bck)\r\n    elif key_name in self.categorical.keys():\r\n      key = key_name\r\n    else:\r\n      key = key_name\r\n    return key\r\n\r\n  def _make_crossed(self):\r\n    f_crossed_for_wide = []\r\n    f_crossed_for_deep = []\r\n    for to_cross in self.CROSSED:\r\n      key = []\r\n      bck_size = 1\r\n      for (key, bck, bnd) in to_cross:\r\n        keys.append(self._prepare_for_crossing(key, bck, bnd))\r\n        bck_size *= bck\r\n\r\n      t_crossed = tfc.crossed_column(keys, min(bck_size, 10000))\r\n      t_dimension = int(bck_size**0.25)\r\n      f_crossed_for_wide.append(t_crossed)\r\n      f_crossed_for_deep.append(tfc.embedding_column(t_crossed, t_dimension))\r\n    return f_crossed_for_wide, f_crossed_for_deep\r\n\r\n  def get_wide_features(self):\r\n    wide_features = self.categorical.values()\r\n    if not self.ignore_crosses:\r\n      wide_features += self.crossed_for_wide\r\n    return wide_features  \r\n\r\n  def get_deep_features(self, with_continuous=True):\r\n    deep_features = [tfc.indicator_column(f) for f in self.categorical.values()]\r\n    if with_continuous:\r\n      deep_features += self.continuous.values()\r\n    if not self.ignore_crosses:\r\n      deep_features += self.crossed_for_deep\r\n    return deep_features         \r\n```\r\n```\r\n#@title DNN: model.py\r\n\r\nclvf = CLVFeatures(ignore_crosses=True)\r\n\r\ndef parse_csv(csv_row):\r\n  columns = tf.decode_csv(csv_row, record_defaults = clvf.get_all_defaults())\r\n  features = dict(zip(clvf.get_all_names(), columns))\r\n  \r\n  for column_name in clvf.get_unused():\r\n    features.pop(column_name)\r\n\r\n  target = features.pop(clvf.get_target_name())\r\n\r\n  return features, target\r\n\r\n\r\ndef dataset_input_fn(data_folder, prefix=None, mode=None, params=None, count=None):\r\n  shuffle = True if mode == tf.estimator.ModeKeys.TRAIN else False\r\n\r\n  filenames = tf.matching_files('{}{}*.csv'.format(data_folder, prefix))\r\n\r\n  dataset = tf.data.TextLineDataset(filenames).skip(1)\r\n  dataset = dataset.map(parse_csv)\r\n  if shuffle:\r\n    dataset = dataset.shuffle(buffer_size=params.buffer_size)\r\n  dataset = dataset.repeat(count=count)\r\n  dataset = dataset.batch(params.batch_size)\r\n\r\n  iterator = tf.compat.v1.data.make_one_shot_iterator(dataset) \r\n  \r\n  features, target = iterator.get_next()\r\n\r\n  return features, target\r\n\r\ndef read_train(data_folder, params):\r\n  return dataset_input_fn(\r\n      data_folder=data_folder,\r\n      prefix='train',\r\n      params=params,\r\n      mode=tf.estimator.ModeKeys.TRAIN)\r\n\r\n\r\ndef read_eval(data_folder, params):\r\n  return dataset_input_fn(data_folder=data_folder,\r\n                          prefix='eval',\r\n                          params=params)\r\n\r\n\r\ndef read_test(data_folder, params):\r\n  return dataset_input_fn(data_folder=data_folder,\r\n                          prefix='test',\r\n                          params=params,\r\n                          count=1)\r\n\r\ndef rmse_evaluator(labels, predictions):\r\n  pred_values = predictions['predictions']\r\n  return {'rmse': tf.metrics.root_mean_squared_error(labels, pred_values)} \r\n\r\ndef get_learning_rate(params):\r\n  global_step = tf.train.get_global_step()\r\n  learning_rate = tf.train.exponential_decay(                    \r\n      learning_rate = params.learning_rate,\r\n      global_step = global_step,                                                                \r\n      decay_steps = params.checkpoint_steps,\r\n      decay_rate = params.learning_decay_rate,\r\n      staircase = True)\r\n  return learning_rate\r\n\r\ndef get_optimizer(params):\r\n  optimizer = tf.train.ProximalAdagradOptimizer(\r\n      learning_rate = get_learning_rate(params),                                                \r\n      l1_regularization_strength = params.l1_regularization,\r\n      l2_regularization_strength = params.l2_regularization)\r\n  return optimizer\r\n\r\ndef get_estimator(config, params, model_dir):   \r\n  estimator = tf.estimator.DNNRegressor(\r\n      feature_columns=clvf.get_deep_features(),\r\n      hidden_units=params.hidden_units,\r\n      config=config,\r\n      model_dir=model_dir,\r\n      optimizer=lambda: get_optimizer(params),\r\n      batch_norm=True,\r\n      dropout=params.dropout)\r\n  \r\n  estimator = tf.contrib.estimator.add_metrics(estimator, rmse_evaluator)       \r\n  return estimator\r\n```\r\n```\r\n#@title DNN: task.py (Hyperparameter + parser.args)\r\n\r\nTRAIN_SIZE = 100000      #length of trainset is 883, but this param is given\r\nNUM_EPOCHS = 70\r\nBATCH_SIZE = 5\r\nNUM_EVAL = 20\r\n\r\nLEARNING_DECAY_RATE = 0.7\r\nHIDDEN_UNITS = '128 64 32 16'\r\nLEARNING_RATE = 0.00135\r\nL1_REGULARIZATION = 0.0216647\r\nL2_REGULARIZATION = 0.0673949\r\nDROPOUT = 0.899732\r\nSHUFFLE_BUFFER_SIZE = 10000\r\n\r\njob_dir = '/content/model_checkpoint/'\r\ndata_src = '/content/DNNs_for_CLVs/'\r\nignore_crosses = False #default\r\nlearning_rate_decay = True\r\n\r\nhypertune = False #adds numbers to ouputpath when turned on 'True'\r\nresume = False #default (takes old savings for start if turned on 'True -> you may turn off hypertune then?)\r\n\r\n\r\ndef csv_serving_input_fn():\r\n  clvf = CLVFeatures(ignore_crosses=True)\r\n  used_headers = clvf.get_used_headers(with_key=True, with_target=False)\r\n  default_values = clvf.get_defaults(used_headers)\r\n\r\n  rows_string_tensor = tf.placeholder(dtype=tf.string, shape=[None],      #not compatible with egaer execution and tf.function?\r\n                                      name='csv_rows')\r\n  receiver_tensor = {'csv_rows': rows_string_tensor}\r\n\r\n  row_columns = tf.expand_dims(rows_string_tensor, -1)\r\n  columns = tf.decode_csv(row_columns, record_defaults=default_values)\r\n\r\n  features = dict(zip(used_headers, columns))\r\n\r\n  return tf.estimator.export.ServingInputReceiver(features, receiver_tensor)\r\n```\r\n```\r\n#@title DNN: task.py (main execution)\r\n\r\ntf.logging.set_verbosity(tf.compat.v1.logging.INFO)\r\n\r\nif hypertune:\r\n  config = json.loads(os.environ.get('TF_CONFIG', '{}'))\r\n  trial = config.get('task', {}).get('trial', '')\r\n  model_dir = os.path.join(job_dir, trial)\r\nelse:\r\n  model_dir = job_dir\r\n\r\ndata_folder = '{}'.format(data_src)\r\n\r\ntrain_steps = (TRAIN_SIZE/BATCH_SIZE) * NUM_EPOCHS\r\ncheckpoint_steps = int((TRAIN_SIZE/BATCH_SIZE) * (\r\n      NUM_EPOCHS/NUM_EVAL))\r\n\r\nconfig = tf.estimator.RunConfig(\r\n    save_checkpoints_steps=checkpoint_steps\r\n)\r\n\r\nhidden_units = [int(n) for n in HIDDEN_UNITS.split()]\r\n\r\nparams = tf.contrib.training.HParams(\r\n    num_epochs = NUM_EPOCHS,\r\n    train_steps = train_steps,\r\n    batch_size = BATCH_SIZE,\r\n    hidden_units = hidden_units,\r\n    learning_rate = LEARNING_RATE,\r\n    ignore_crosses = ignore_crosses,\r\n    buffer_size = SHUFFLE_BUFFER_SIZE,\r\n    learning_rate_decay = learning_rate_decay,\r\n    learning_decay_rate = LEARNING_DECAY_RATE,\r\n    l1_regularization = L1_REGULARIZATION,\r\n    l2_regularization = L2_REGULARIZATION,\r\n    dropout= DROPOUT,\r\n    checkpoint_steps = checkpoint_steps)\r\n\r\nestimator = None\r\n\r\nestimator = get_estimator(config=config,\r\n                          params=params,\r\n                          model_dir=model_dir)\r\n\r\ntrain_spec = tf.estimator.TrainSpec(\r\n    input_fn=lambda: read_train(data_folder, params),\r\n    max_steps=train_steps)\r\n\r\neval_spec = tf.estimator.EvalSpec(\r\n    input_fn=lambda: read_eval(data_folder, params),\r\n    exporters=[\r\n        tf.estimator.LatestExporter(\r\n            name='estimate',\r\n            serving_input_receiver_fn=csv_serving_input_fn,\r\n            exports_to_keep=1,\r\n            as_text=True\r\n        )\r\n    ],\r\n    steps=1000,\r\n    throttle_secs=1,\r\n    start_delay_secs=1\r\n)\r\n\r\nif not resume:\r\n    print('Removing previous trained model...')\r\n    shutil.rmtree(model_dir, ignore_errors=True)\r\nelse:\r\n    print('Resuming training...')\r\n\r\ntf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\r\n        \r\nestimator.evaluate(lambda: read_test(data_folder, params), name=\"Test Set\")\r\n```\r\n\r\n\r\n### System information:\r\n- Have I written custom code: rather reproduced\r\n- OS Platform: Big Sur 11.6\r\n- TensorFlow version: 1.15.1 here, but same issue occured in TF2\r\n- Python version: default version on Google Colab\r\n\r\n### Describe the current behavior\r\nThrough the whole training process the RMSE is around 5341.822 and after the evaluation:\r\n```\r\n{'average_loss': 17710520.0,\r\n 'global_step': 12362,\r\n 'label/mean': 3189.7307,\r\n 'loss': 87154410.0,\r\n 'prediction/mean': 0.2885886,\r\n 'rmse': 4208.3867}\r\n```\r\nSo I am pretty new to the whole thing, but I think this model didn't learn anything.\r\n\r\n\r\n### Describe the expected behavior\r\nSo the result I should get is given on the very below of the tutorial in this table marked as DNN (947.9). \r\n\r\nModel | RMSE\r\n-- | --\r\nDNN | 947.9\r\nPareto/NBD | 1558\r\n\r\n#### by the way\r\nIt should be possible to copy the cells and execute them like they stand in this post, but you should decrease the train_size param. Because otherwise it will take one hour to learn, or... even not to learn.\r\n\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["Hi guys, I just had the idea to add you over here. Because you created the whole thing first and may know the best what is the problem over here. I would really appreciate some input!\r\n\r\n@m-mayran\r\n@lukmanr", "@timmy-ops ,\r\nLooks like the code is supporting only 1.x version.Can you please provide the code which supports the 2.x version.It helps to reproduce the issue in our end.Thanks!  ", "@tilakrayal \r\nSure! I just rewrote it.  \r\nOne thing to add again... if the train_size parameter is 100000 it takes one hour to learn, but at the moment a decrease does not really do anything with the result.\r\n```\r\n#@title DNN: git clone and module import\r\n! git clone https://github.com/timmy-ops/DNNs_for_CLVs\r\n\r\nimport pandas as pd\r\nfrom datetime import datetime\r\nimport numpy as np\r\n#MODEL \r\n!pip install -U tensorflow-addons\r\nimport tensorflow as tf\r\nimport tensorflow_addons as tfa\r\nfrom tensorflow import feature_column as tfc\r\nfrom six import iteritems\r\nimport shutil\r\n#only for the hypertune path fn:\r\nimport json\r\nimport os\r\n```\r\n```\r\n#@title DNN: context.py\r\n\r\nclass CLVFeatures(object):\r\n\r\n  HEADERS = ['customer_id', 'monetary_dnn', 'monetary_btyd', 'frequency_dnn',\r\n             'frequency_btyd', 'recency', 'T', 'time_between',\r\n             'avg_basket_value', 'avg_basket_size', 'cnt_returns',\r\n             'has_returned', 'frequency_btyd_clipped', 'monetary_btyd_clipped',\r\n             'target_monetary_clipped', 'target_monetary']\r\n  HEADERS_DEFAULT = [[''], [0.0], [0.0], [0],\r\n                     [0], [0], [0], [0.0],\r\n                     [0.0], [0.0], [0],\r\n                     [-1], [0], [0.0],\r\n                     [0.0], [0.0]]\r\n  NUMERICS = {\r\n      'monetary_dnn': [],\r\n      'recency': [],\r\n      'frequency_dnn': [],\r\n      'T': [],\r\n      'time_between': [],\r\n      'avg_basket_value': [],\r\n      'avg_basket_size': [],\r\n      'cnt_returns': []}\r\n  CATEGORICALS_W_LIST = {\r\n      'has_returned': [0, 1]}\r\n  CROSSED = []\r\n  KEY = 'customer_id'\r\n  UNUSED = [KEY, 'monetary_btyd', 'frequency_btyd', 'frequency_btyd_clipped',\r\n            'monetary_btyd_clipped', 'target_monetary_clipped']\r\n  TARGET_NAME = 'target_monetary'\r\n\r\n  def __init__(self, ignore_crosses=False): #, is_dnn=None\r\n\r\n    #if not is_dnn:\r\n    #  return\r\n\r\n    self.ignore_crosses = ignore_crosses\r\n    (self.headers, self.numerics_names, self.categorical_names) = self._keep_used()\r\n    self.continuous, self.categorical = self._make_base_features()\r\n\r\n    if not self.ignore_crosses:\r\n      self.crossed_for_wide, self.crossed_for_deep = self._make_crossed()\r\n  \r\n  def _keep_used(self):\r\n    headers = [h for h in self.HEADERS if h not in self.UNUSED]\r\n    numerics_names = {\r\n        k: v for k, v in iteritems(self.NUMERICS)\r\n        if (k not in self.UNUSED) and (k != self.TARGET_NAME)\r\n    }\r\n    categorical_names = {\r\n        k: v for k, v in iteritems(self.CATEGORICALS_W_LIST)\r\n        if k not in self.UNUSED    \r\n    }                          \r\n    return headers, numerics_names, categorical_names\r\n  \r\n  def get_key(self):\r\n    return self.KEY\r\n  \r\n  def get_used_headers(self, with_key=False, with_target=False):\r\n    used_headers = [h for h in self.headers if h != self.TARGET_NAME]\r\n\r\n    if with_key:\r\n      used_headers.insert(0, self.KEY)\r\n    if with_target:\r\n      used_headers.append(self.TARGET_NAME)\r\n\r\n    return used_headers\r\n\r\n  def get_defaults(self, headers_names=None, with_key=False):\r\n    if headers_names is None:\r\n      headers_names = self.get_used_headers(with_key)\r\n\r\n    keep_indexes = [self.HEADERS.index(n) for n in headers_names]\r\n    return [self.HEADERS_DEFAULT[i] for i in keep_indexes]\r\n\r\n  def get_all_names(self):\r\n    return self.HEADERS\r\n\r\n  def get_all_defaults(self):\r\n    return self.HEADERS_DEFAULT\r\n\r\n  def get_unused(self):\r\n    return self.UNUSED\r\n\r\n  def get_target_name(self):\r\n    return self.TARGET_NAME\r\n\r\n  def _make_base_features(self):\r\n    continuous = {\r\n        key_name: tfc.numeric_column(key_name)\r\n        for key_name in self.numerics_names.keys()\r\n    }\r\n    categorical = {\r\n        key_name: tfc.categorical_column_with_vocabulary_list(\r\n            key=key_name,\r\n            vocabulary_list=voc)\r\n        for key_name, voc in self.categorical_names.items()\r\n    }    \r\n    return continuous, categorical\r\n\r\n  def get_base_features(self):\r\n    return self.continous, self.categorical\r\n\r\n  def _prepare_for_crossing(self, key_name, num_bck, boundaries):\r\n    key = None\r\n    if key_name in self.continuous.keys():\r\n      if boundaries is not None:\r\n        key = tfc.bucketized_column(self.continuous[key_name], boundaries)\r\n      else:\r\n        key = tfc.categorical_column_with_identity(key_name, num_bck)\r\n    elif key_name in self.categorical.keys():\r\n      key = key_name\r\n    else:\r\n      key = key_name\r\n    return key\r\n\r\n  def _make_crossed(self):\r\n    f_crossed_for_wide = []\r\n    f_crossed_for_deep = []\r\n    for to_cross in self.CROSSED:\r\n      key = []\r\n      bck_size = 1\r\n      for (key, bck, bnd) in to_cross:\r\n        keys.append(self._prepare_for_crossing(key, bck, bnd))\r\n        bck_size *= bck\r\n\r\n      t_crossed = tfc.crossed_column(keys, min(bck_size, 10000))\r\n      t_dimension = int(bck_size**0.25)\r\n      f_crossed_for_wide.append(t_crossed)\r\n      f_crossed_for_deep.append(tfc.embedding_column(t_crossed, t_dimension))\r\n    return f_crossed_for_wide, f_crossed_for_deep\r\n\r\n  def get_wide_features(self):\r\n    wide_features = self.categorical.values()\r\n    if not self.ignore_crosses:\r\n      wide_features += self.crossed_for_wide\r\n    return wide_features  \r\n\r\n  def get_deep_features(self, with_continuous=True):\r\n    deep_features = [tfc.indicator_column(f) for f in self.categorical.values()]\r\n    if with_continuous:\r\n      deep_features += self.continuous.values()\r\n    if not self.ignore_crosses:\r\n      deep_features += self.crossed_for_deep\r\n    return deep_features         \r\n```\r\n```\r\n#@title DNN: context.py\r\n\r\nclass CLVFeatures(object):\r\n\r\n  HEADERS = ['customer_id', 'monetary_dnn', 'monetary_btyd', 'frequency_dnn',\r\n             'frequency_btyd', 'recency', 'T', 'time_between',\r\n             'avg_basket_value', 'avg_basket_size', 'cnt_returns',\r\n             'has_returned', 'frequency_btyd_clipped', 'monetary_btyd_clipped',\r\n             'target_monetary_clipped', 'target_monetary']\r\n  HEADERS_DEFAULT = [[''], [0.0], [0.0], [0],\r\n                     [0], [0], [0], [0.0],\r\n                     [0.0], [0.0], [0],\r\n                     [-1], [0], [0.0],\r\n                     [0.0], [0.0]]\r\n  NUMERICS = {\r\n      'monetary_dnn': [],\r\n      'recency': [],\r\n      'frequency_dnn': [],\r\n      'T': [],\r\n      'time_between': [],\r\n      'avg_basket_value': [],\r\n      'avg_basket_size': [],\r\n      'cnt_returns': []}\r\n  CATEGORICALS_W_LIST = {\r\n      'has_returned': [0, 1]}\r\n  CROSSED = []\r\n  KEY = 'customer_id'\r\n  UNUSED = [KEY, 'monetary_btyd', 'frequency_btyd', 'frequency_btyd_clipped',\r\n            'monetary_btyd_clipped', 'target_monetary_clipped']\r\n  TARGET_NAME = 'target_monetary'\r\n\r\n  def __init__(self, ignore_crosses=False): #, is_dnn=None\r\n\r\n    #if not is_dnn:\r\n    #  return\r\n\r\n    self.ignore_crosses = ignore_crosses\r\n    (self.headers, self.numerics_names, self.categorical_names) = self._keep_used()\r\n    self.continuous, self.categorical = self._make_base_features()\r\n\r\n    if not self.ignore_crosses:\r\n      self.crossed_for_wide, self.crossed_for_deep = self._make_crossed()\r\n  \r\n  def _keep_used(self):\r\n    headers = [h for h in self.HEADERS if h not in self.UNUSED]\r\n    numerics_names = {\r\n        k: v for k, v in iteritems(self.NUMERICS)\r\n        if (k not in self.UNUSED) and (k != self.TARGET_NAME)\r\n    }\r\n    categorical_names = {\r\n        k: v for k, v in iteritems(self.CATEGORICALS_W_LIST)\r\n        if k not in self.UNUSED    \r\n    }                          \r\n    return headers, numerics_names, categorical_names\r\n  \r\n  def get_key(self):\r\n    return self.KEY\r\n  \r\n  def get_used_headers(self, with_key=False, with_target=False):\r\n    used_headers = [h for h in self.headers if h != self.TARGET_NAME]\r\n\r\n    if with_key:\r\n      used_headers.insert(0, self.KEY)\r\n    if with_target:\r\n      used_headers.append(self.TARGET_NAME)\r\n\r\n    return used_headers\r\n\r\n  def get_defaults(self, headers_names=None, with_key=False):\r\n    if headers_names is None:\r\n      headers_names = self.get_used_headers(with_key)\r\n\r\n    keep_indexes = [self.HEADERS.index(n) for n in headers_names]\r\n    return [self.HEADERS_DEFAULT[i] for i in keep_indexes]\r\n\r\n  def get_all_names(self):\r\n    return self.HEADERS\r\n\r\n  def get_all_defaults(self):\r\n    return self.HEADERS_DEFAULT\r\n\r\n  def get_unused(self):\r\n    return self.UNUSED\r\n\r\n  def get_target_name(self):\r\n    return self.TARGET_NAME\r\n\r\n  def _make_base_features(self):\r\n    continuous = {\r\n        key_name: tfc.numeric_column(key_name)\r\n        for key_name in self.numerics_names.keys()\r\n    }\r\n    categorical = {\r\n        key_name: tfc.categorical_column_with_vocabulary_list(\r\n            key=key_name,\r\n            vocabulary_list=voc)\r\n        for key_name, voc in self.categorical_names.items()\r\n    }    \r\n    return continuous, categorical\r\n\r\n  def get_base_features(self):\r\n    return self.continous, self.categorical\r\n\r\n  def _prepare_for_crossing(self, key_name, num_bck, boundaries):\r\n    key = None\r\n    if key_name in self.continuous.keys():\r\n      if boundaries is not None:\r\n        key = tfc.bucketized_column(self.continuous[key_name], boundaries)\r\n      else:\r\n        key = tfc.categorical_column_with_identity(key_name, num_bck)\r\n    elif key_name in self.categorical.keys():\r\n      key = key_name\r\n    else:\r\n      key = key_name\r\n    return key\r\n\r\n  def _make_crossed(self):\r\n    f_crossed_for_wide = []\r\n    f_crossed_for_deep = []\r\n    for to_cross in self.CROSSED:\r\n      key = []\r\n      bck_size = 1\r\n      for (key, bck, bnd) in to_cross:\r\n        keys.append(self._prepare_for_crossing(key, bck, bnd))\r\n        bck_size *= bck\r\n\r\n      t_crossed = tfc.crossed_column(keys, min(bck_size, 10000))\r\n      t_dimension = int(bck_size**0.25)\r\n      f_crossed_for_wide.append(t_crossed)\r\n      f_crossed_for_deep.append(tfc.embedding_column(t_crossed, t_dimension))\r\n    return f_crossed_for_wide, f_crossed_for_deep\r\n\r\n  def get_wide_features(self):\r\n    wide_features = self.categorical.values()\r\n    if not self.ignore_crosses:\r\n      wide_features += self.crossed_for_wide\r\n    return wide_features  \r\n\r\n  def get_deep_features(self, with_continuous=True):\r\n    deep_features = [tfc.indicator_column(f) for f in self.categorical.values()]\r\n    if with_continuous:\r\n      deep_features += self.continuous.values()\r\n    if not self.ignore_crosses:\r\n      deep_features += self.crossed_for_deep\r\n    return deep_features         \r\n```\r\n```\r\n#@title DNN: model.py\r\n\r\nclvf = CLVFeatures(ignore_crosses=True)\r\n\r\ndef parse_csv(csv_row):\r\n  columns = tf.io.decode_csv(csv_row, record_defaults = clvf.get_all_defaults())\r\n  features = dict(zip(clvf.get_all_names(), columns))\r\n  \r\n  for column_name in clvf.get_unused():\r\n    features.pop(column_name)\r\n\r\n  target = features.pop(clvf.get_target_name())\r\n\r\n  return features, target\r\n\r\n\r\ndef dataset_input_fn(data_folder, prefix=None, mode=None, count=None):\r\n  shuffle = True if mode == tf.estimator.ModeKeys.TRAIN else False\r\n\r\n  filenames = tf.io.matching_files('{}{}*.csv'.format(data_folder, prefix))\r\n  dataset = tf.data.TextLineDataset(filenames).skip(1)\r\n  dataset = dataset.map(parse_csv)\r\n  if shuffle:\r\n    dataset = dataset.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\r\n  dataset = dataset.repeat(count=count)\r\n  dataset = dataset.batch(BATCH_SIZE)\r\n\r\n  iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)   #tf.compat.v1.data.make_one_shot_iterator(dataset)/#tf.compat.v1.data.make_initializable_iterator(dataset)\r\n  \r\n  features, target = iterator.get_next()\r\n\r\n  return features, target\r\n\r\ndef read_train(data_folder):\r\n  return dataset_input_fn(\r\n      data_folder=data_folder,\r\n      prefix='train',\r\n      mode=tf.estimator.ModeKeys.TRAIN)\r\n\r\n\r\ndef read_eval(data_folder):\r\n  return dataset_input_fn(data_folder=data_folder,\r\n                          prefix='eval')\r\n\r\n\r\ndef read_test(data_folder):\r\n  return dataset_input_fn(data_folder=data_folder,\r\n                          prefix='test',\r\n                          count=1)\r\n\r\ndef rmse_evaluator(labels, predictions):\r\n  pred_values = predictions['predictions']\r\n  return {'rmse': tf.compat.v1.metrics.root_mean_squared_error(labels, pred_values)} #tf.cast(labels, tf.float32)\r\n\r\ndef get_learning_rate():\r\n  global_step = tf.compat.v1.train.get_global_step()\r\n  learning_rate = tf.compat.v1.train.exponential_decay(                    \r\n      learning_rate = LEARNING_RATE,\r\n      global_step = global_step,                                                                \r\n      decay_steps = checkpoint_steps,\r\n      decay_rate = LEARNING_DECAY_RATE,\r\n      staircase = True)\r\n  return learning_rate\r\n\r\ndef get_optimizer():\r\n  optimizer = tfa.optimizers.ProximalAdagrad(\r\n      learning_rate = get_learning_rate(),                                                \r\n      l1_regularization_strength = L1_REGULARIZATION,\r\n      l2_regularization_strength = L2_REGULARIZATION)\r\n  return optimizer\r\n\r\ndef get_estimator(config, model_dir):    #estimator_name\r\n  estimator = tf.estimator.DNNRegressor(\r\n      feature_columns=clvf.get_deep_features(),\r\n      hidden_units=hidden_units,\r\n      config=config,\r\n      model_dir=model_dir,\r\n      optimizer=lambda: get_optimizer(),\r\n      batch_norm=True,\r\n      dropout=DROPOUT)\r\n  \r\n  estimator = tf.estimator.add_metrics(estimator, rmse_evaluator)       \r\n  return estimator\r\n```\r\n```\r\n#@title DNN: task.py (Hyperparameter + parser.args)\r\n\r\nTRAIN_SIZE = 100000      #actually the length of the train set is 883 (googles default: 100000)\r\nNUM_EPOCHS = 70\r\nBATCH_SIZE = 5\r\nNUM_EVAL = 20\r\n\r\nLEARNING_DECAY_RATE = 0.7\r\nHIDDEN_UNITS = '128 64 32 16'\r\nLEARNING_RATE = 0.00135\r\nL1_REGULARIZATION = 0.0216647\r\nL2_REGULARIZATION = 0.0673949\r\nDROPOUT = 0.899732\r\nSHUFFLE_BUFFER_SIZE = 10000\r\n\r\nhypertune = False #adds numbers to ouputpath when turned on 'True'\r\njob_dir = ('/content/model_checkpoint')\r\ndata_src = ('/content/DNNs_for_CLVs')\r\nignore_crosses = False #default\r\nlearning_rate_decay = True\r\nresume = False #default\r\n\r\n\r\ndef csv_serving_input_fn():\r\n  clvf = CLVFeatures(ignore_crosses=True)\r\n  used_headers = clvf.get_used_headers(with_key=True, with_target=False)\r\n  default_values = clvf.get_defaults(used_headers)\r\n\r\n  rows_string_tensor = tf.compat.v1.placeholder(dtype=tf.string, shape=[None],      #not compatible with egaer execution and tf.function?\r\n                                      name='csv_rows')\r\n  receiver_tensor = {'csv_rows': rows_string_tensor}\r\n\r\n  row_columns = tf.compat.v1.expand_dims(rows_string_tensor, -1)\r\n  columns = tf.io.decode_csv(row_columns, record_defaults=default_values)\r\n\r\n  features = dict(zip(used_headers, columns))\r\n\r\n  return tf.estimator.export.ServingInputReceiver(features, receiver_tensor)\r\n```\r\n```\r\n#@title DNN: task.py (main execution)\r\n\r\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\r\n\r\nif hypertune:\r\n  config = json.loads(os.environ.get('TF_CONFIG', '{}'))\r\n  trial = config.get('task', {}).get('trial', '')\r\n  model_dir = os.path.join(job_dir, trial)\r\nelse:\r\n  model_dir = job_dir\r\n\r\ndata_folder = '{}/'.format(data_src)\r\n\r\ntrain_steps = (TRAIN_SIZE/BATCH_SIZE) * NUM_EPOCHS\r\ncheckpoint_steps = int((TRAIN_SIZE/BATCH_SIZE) * (\r\n      NUM_EPOCHS/NUM_EVAL))\r\n\r\nconfig = tf.estimator.RunConfig(\r\n    save_checkpoints_steps=checkpoint_steps\r\n)\r\n\r\nhidden_units = [int(n) for n in HIDDEN_UNITS.split()]\r\n\r\nestimator = None\r\n\r\nestimator = get_estimator(config=config,\r\n                          model_dir=model_dir)\r\n\r\ntrain_spec = tf.estimator.TrainSpec(\r\n    input_fn=lambda: read_train(data_folder),   #but the input IS a tuple!\r\n    max_steps=train_steps)\r\n\r\neval_spec = tf.estimator.EvalSpec(\r\n    input_fn=lambda: read_eval(data_folder),\r\n    exporters=[\r\n        tf.estimator.LatestExporter(\r\n            name='estimate',\r\n            serving_input_receiver_fn=csv_serving_input_fn,\r\n            exports_to_keep=1,\r\n            as_text=True\r\n        )\r\n    ],\r\n    steps=1000,\r\n    throttle_secs=1,\r\n    start_delay_secs=1\r\n)\r\n\r\nif not resume:\r\n    print('Removing previous trained model...')\r\n    shutil.rmtree(model_dir, ignore_errors=True)\r\nelse:\r\n    print('Resuming training...')\r\n\r\ntf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\r\n        \r\nestimator.evaluate(lambda: read_test(data_folder), name=\"Test Set\")\r\n```\r\n## Output:\r\n```\r\n{'average_loss': 17708200.0,\r\n 'global_step': 12362,\r\n 'label/mean': 3189.7307,\r\n 'loss': 20264198.0,\r\n 'prediction/mean': 0.66893655,\r\n 'rmse': 4208.1113}\r\n```\r\nAnd through the whole training process the RMSE is about: **5341.655**", "@Saduf2019 ,\r\nI was able to reproduce the issue in tf-[nightly](https://colab.research.google.com/gist/tilakrayal/d5e85f7f428e3e1f6fba9e9adfc8f9e0/nightlyuntitled101.ipynb).In tf v2.5 and v2.6, the code is running for very long time which is more than expected.Please find the gist [here](https://colab.research.google.com/gist/tilakrayal/adf4d5ec9204f97df0473e59e92f5836/kopie_von_bachelor_thesis_progress_tf1.ipynb).", "@timmy-ops Sorry for the late response. \r\n\r\nI think this is more related to that repo. Please post them https://github.com/GoogleCloudPlatform/tensorflow-lifetime-value/issues so that code owners in that repo will resolve the issue faster. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 52588, "title": "Modifying the Categorical Cross entropy for Mirrored strategy/Distributed training causing low validation accuracy.", "body": "### System information\r\n\r\n-   **Have I written custom code (yes)\r\n-   **OS Platform and Distribution (Windows)\r\n-   **TensorFlow installed from (binary)\r\n-   **TensorFlow version (2.4.1)\r\n-   **Python version(3.7.9)\r\n-   **CUDA/cuDNN version(11.1/8/0):\r\n-   **GPU model and memory(Titan XP, 12 GB):\r\n\r\n### Describe the problem\r\nFor **normal (single GPU training)** current loss is being calculated as follows:\r\n\r\n```\r\ndef compute_loss(labels, predictions):\r\n    loss = tf.reduce_mean(\r\n    tf.keras.losses.categorical_crossentropy(y_true=labels, y_pred=predictions)\r\n    )\r\n    return loss\r\n```\r\n\r\nFor **Mirrored strategy/Distributed training (8 GPU)**, I am computing loss as follows:\r\n\r\n```\r\nloss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=False,\r\n              reduction=tf.keras.losses.Reduction.NONE)\r\ndef compute_loss(labels, predictions):\r\n    per_example_loss = loss_object(labels, predictions) \r\n    return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\r\n```\r\n\r\nBut in the Distributed strategy the loss is not converging as fast and getting very poor validation accuracy as compared to the original.\r\n", "comments": ["@ashishsb0307 \r\nIn order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose),\r\nThanks!", "> @ashishsb0307 In order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose), Thanks!\r\n\r\nHave opened a new issue under suitable category as followed in the template link. [#52589](https://github.com/tensorflow/tensorflow/issues/52589)", "@ashishsb0307 Thank you for the update! Could you please close this ticket as we will track the other issue #52589 ?  Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52588\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52588\">No</a>\n"]}, {"number": 52586, "title": "ValueError ----> 1 cnn.fit(X_train, y_train, epochs=2)", "body": "Code:\r\ncnn.fit(X_train, y_train, epochs=2)\r\n\r\nI got an error:\r\nValueError Traceback (most recent call last)\r\nin ()\r\n----> 1 cnn.fit(X_train, y_train, epochs=2)\r\n\r\nMy Code Link in colab:\r\nhttps://colab.research.google.com/drive/1dy-q0E8B7siaWNRhG9CVNWuw1NBIOTl2?usp=sharing\r\n\r\nTotal Code:\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import datasets, layers, models\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\n\r\n(X_train, y_train), (X_test,y_test) = datasets.mnist.load_data()\r\nX_train.shape\r\n\r\nX_test.shape\r\n\r\nplt.figure(figsize=(15,2))\r\nplt.imshow(X_train[0])\r\n\r\ny_train[:10]\r\ny_train = y_train.reshape(-1,)\r\ny_train[:10]\r\n\r\nclasses = [\"five\",\"zero\",\"four\",\"one\",\"nine\",\"two\",\"one\",\"three\",\"one\",\"four\"]\r\n\r\ndef plot_sample(X, y, index):\r\n    plt.figure(figsize = (15,3))\r\n    plt.imshow(X[index])\r\n    plt.xlabel(classes[y[index]])\r\n\r\nX_train = X_train / 255.0\r\nX_test = X_test / 255.0\r\n\r\ncnn = models.Sequential([\r\nlayers.Conv2D(filters=28, kernel_size=(3, 3), activation='relu',\r\ninput_shape=(28, 28, 3)),\r\nlayers.MaxPooling2D((2, 2)),\r\nlayers.Conv2D(filters=56, kernel_size=(3, 3), activation='relu'),\r\nlayers.MaxPooling2D((2, 2)),\r\nlayers.Flatten(),\r\nlayers.Dense(28, activation='relu'),\r\nlayers.Dense(10, activation='softmax')\r\n])\r\n\r\ncnn.compile(optimizer='adam',\r\nloss='sparse_categorical_crossentropy',\r\nmetrics=['accuracy'])\r\n############ Error in below code############\r\ncnn.fit(X_train, y_train, epochs=2)", "comments": ["Hi @shajibul!I have fixed above issue by changing input_shape = (28,28,1) and reshaping the train,test data from Mnist dataset. Attaching [Gist ](https://colab.research.google.com/gist/mohantym/e2c5b4d25c8024097af32cd6e878df44/github_52586.ipynb)for reference.", "> Hi @shajibul!I have fixed above issue by changing input_shape = (28,28,1) and reshaping the train,test data from Mnist dataset. Attaching [Gist ](https://colab.research.google.com/gist/mohantym/e2c5b4d25c8024097af32cd6e878df44/github_52586.ipynb)for reference.\r\n\r\nThanks a lot.", "ok @shajibul! Feel free to close this issue if it helped . Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52586\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52586\">No</a>\n", "Yes, Thanks a lot"]}]