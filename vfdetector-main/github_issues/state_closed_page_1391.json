[{"number": 11332, "title": "[feature request] Inconsistency of new Decoder api and Dense layer", "body": "TF 1.1 has released new seq2seq API (`tf.contrib.seq2seq.BasicDecoder` etc.) and Decoders have `output_layer` parameter, which must be subclass of `tf.layers.Layer`.\r\n\r\nIf one wants to use dense projection, it has to do `from tensorflow.python.layers.core import Dense` which seems a bit inconvenient. \r\n\r\nMaybe the better way is to include `Dense` and `Dropout` classes into `tf.layers`? After that, one could write just `tf.layers.Dense` or `tf.layers.Dropout`.", "comments": ["This seems like a small fix in https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/python/layers/layers.py, I can prepare it if it makes sense.", "I checked internally, and it sounds like we are planning to address this in the next 2-4 weeks, after a few other internal dependencies are worked out (constraints API and Network class). Thanks for offering to make the fix; I think the right thing is to close for now, and ask you to reopen if you don't see an appropriate change roll out in a month or so. ", "Ok, thanks for the detailed response:)"]}, {"number": 11331, "title": "Backport get_started.md to 1.2.0", "body": "", "comments": ["Closing since this already seems to be in all of 1.2.0, 1.3.0-rc0, master"]}, {"number": 11330, "title": "Use mcpu instead of march for ppc64le", "body": "march is not support by gcc on ppc64le", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "Can one of the admins verify this patch?", "My company has already signed the CLA.", "@tensorflow-jenkins test this please"]}, {"number": 11329, "title": " tf.image.rgb_to_grayscale Bug?", "body": "Hi,\r\nI have the same problem with this one with the current version of tensorflow under python 3.5. It seems that tf.image.rgb_to_grayscale cannot accept RGB input. Wonder if anyone could check this. Many thanks.\r\n\r\nhttps://stackoverflow.com/questions/40924184/error-while-feeding-images-to-tensorflow-graph", "comments": ["That Stack Overflow question doesn't describe a bug... instead the original questioner was defining a placeholder of the wrong size (1 channel instead of 3 channels). I'm going to close this as working-as-intended, but feel free to reopen if you can show a minimal example that demonstrates a bug."]}, {"number": 11328, "title": "wide_n_deep AttributeError (master) and ValueError (r1.2)", "body": "I'm using TensorFlow 1.2.1. When I run `python wide_n_deep_tutorial.py --model_type=wide` from the [Linear Model tutorial](https://www.tensorflow.org/tutorials/wide), I get the following AttributeError:\r\n\r\n```\r\n  File \"wide_n_deep_tutorial.py\", line 139, in build_estimator\r\n    m = tf.estimator.LinearClassifier(\r\nAttributeError: 'module' object has no attribute 'LinearClassifier'\r\n```\r\n\r\nI tried switching to r1.2, as suggested in #11256, but got this ValueError on r1.2:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"wide_n_deep_tutorial.py\", line 234, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/usr/tensorflow/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"wide_n_deep_tutorial.py\", line 197, in main\r\n    FLAGS.train_data, FLAGS.test_data)\r\n  File \"wide_n_deep_tutorial.py\", line 186, in train_and_eval\r\n    m.fit(input_fn=lambda: input_fn(df_train), steps=train_steps)\r\n  File \"/home/usr/tensorflow/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 289, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/usr/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 455, in fit\r\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)\r\n  File \"/home/usr/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 953, in _train_model\r\n    features, labels = input_fn()\r\n  File \"wide_n_deep_tutorial.py\", line 186, in <lambda>\r\n    m.fit(input_fn=lambda: input_fn(df_train), steps=train_steps)\r\n  File \"wide_n_deep_tutorial.py\", line 148, in input_fn\r\n    for k in CATEGORICAL_COLUMNS}\r\n  File \"wide_n_deep_tutorial.py\", line 148, in <dictcomp>\r\n    for k in CATEGORICAL_COLUMNS}\r\n  File \"/home/usr/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/sparse_tensor.py\", line 132, in __init__\r\n    indices_shape = indices.get_shape().with_rank(2)\r\n  File \"/home/usr/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.py\", line 632, in with_rank\r\n    raise ValueError(\"Shape %s must have rank %d\" % (self, rank))\r\nValueError: Shape (0,) must have rank 2\r\n```\r\n", "comments": ["Resolved by using `tf.contrib.learn.LinearClassifier` and using its `fit` function.", "Thanks!"]}, {"number": 11327, "title": "Backprop through conv2d with large tensors fails", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nUbuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:\r\nsource\r\n- **TensorFlow version (use command below)**:\r\n1.1.0\r\n- **Python version**: \r\n3.5.2\r\n- **Bazel version (if compiling from source)**:\r\n0.4.5\r\n- **CUDA/cuDNN version**:\r\nCUDA Version 8.0.61\r\n- **GPU model and memory**:\r\nGeForce GTX 1080, 8GB\r\n- **Exact command to reproduce**:\r\n```\r\nimport tensorflow as tf\r\n\r\nproj = tf.Variable( tf.random_normal([720,1,400,600], stddev = 2) )\r\nkernel = tf.Variable( tf.random_normal([1, 401, 1, 1], stddev = .5), trainable = True )\r\nproj = tf.nn.conv2d(\r\n    input = proj,\r\n    filter = kernel,\r\n    strides = [ 1, 1, 1, 1 ],\r\n    padding = 'SAME',\r\n    data_format = 'NCHW',\r\n    name = 'ramlak-filter'\r\n)\r\ngrad = tf.gradients( proj, kernel, proj )\r\n\r\nwith tf.Session() as sess:\r\n    sess.run( tf.global_variables_initializer() )\r\n    print( sess.run( grad ) )\r\n```\r\n\r\n### Describe the problem\r\nBackpropagation through `conv2d` for large tensors produces an error for me (see log below). This is true for the code above. Lowering the batch size in `proj` from 720 to 100 eliminates the error. The issue has been confirmed by another user at [stackoverflow](https://stackoverflow.com/questions/44901742/tensorflow-error-while-backpropagating-through-conv2d).\r\n\r\n### Source code / logs\r\n```\r\nNotFoundError (see above for traceback): No algorithm without scratch worked!\r\n\t [[Node: gradients/ramlak-filter_grad/Conv2DBackpropFilter = Conv2DBackpropFilter[T=DT_FLOAT, data_format=\"NCHW\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Variable/read, gradients/ramlak-filter_grad/Shape_1, ramlak-filter)]]\r\n[log.txt](https://github.com/tensorflow/tensorflow/files/1128268/log.txt)\r\n\r\n```\r\n\r\nPlease find the full log attached.\r\n\r\n", "comments": ["@yzhwang  can you take a look?", "Just updated to TF 1.2.1 (built from source), but the issue persists.", "@ma0ho Thanks. I will take a look later today.", "I can also confirm that issue in freshly compiled  `1.2.1`. ", "Thanks @ma0ho and @ktamiola . I was able to reproduce this too. Investigating now.", "Hi @ma0ho \r\nJust to make sure I understand it correctly: are you trying to use a 1-dimensional filter with both height and width as 1, and the feature map count being 401, or are you trying to use a filter with size [1, 401] and a feature map count as 1?\r\ntensorflow's conv2d requires filter to be of the following format:\r\nA 4-D tensor of shape [filter_height, filter_width, in_channels, out_channels]\r\nSo if I change the filter to [1, 1, 1, 401], it actually outputs the correct OOM error:\r\nResourceExhaustedError: OOM when allocating tensor with shape[720,401,400,600].", "@yzhwang: No, exactly as given in the example I'm using a 1D filter width 401 with one in and one output channel.. I'm sure this is not an OOM problem. ", "Maybe I should make the use case a bit more clear:\r\n\r\nI implement a classic CT (computed tomography) reconstruction algorithm (filtered backprojection) in Tensorflow. The goal is to adjust some of the steps by training and to add additional (trainable) pre-/postprocessing steps. In such a CT setup I have many 2D projection images. One of the steps is to filter all those projection images with the same `1xM` filter kernel. The projection images are stacked in a `NxHxW` tensor, where N is the number of projection images. In order to be able to filter them all with the **same** filter kernel, I reshape this to an `Nx1xHxW` tensor, such that N is now the batch dimension (note that I'm using format NCHW, therefore input is ` [batch, channels, height, width]`). Then I convolve with a `1xMx1x1` kernel in order to filter every projection image (every batch in this case) with a `1xM` kernel.\r\n\r\nHope this clarification helps to understand my problem..", "@ma0ho I found that when I run it on a build targeting cpu only, the issue does not appear. Obviously this is not a solution to the problem but it might be a clue as to the cause?", "Hi @ma0ho \r\nSome updates from our side:\r\n1) This bug is due to one cudnn function didn't pick the correct internal kernel to call for backward filter conv. We have already filed a bug to NVIDIA.\r\n2) We are working on a workaround to improve the internal logic of conv ops to handle this case. I will let you know once the code is pushed to github repo.", "@yzhwang: Thanks for your investigation so far!", "Fantastic! Thank you @yzhwang !", "Same error to conv3d when setting one dimension of the filter to 1.\r\nThe real error for me is out of memory, when I change the filter size the error disappear.", "@pobingwanghai Could you provide more info as @ma0ho does in the template? It would be much easier for me to debug the problem if you could offer a reproducer too. I guess the OOM error is probably an intended behavior or another issue. But it would be nice if you can offer more info first so that I can have a look. Thank you!", "@ma0ho I think the commit that fixes this bug has been pushed to tensorflow. https://github.com/tensorflow/tensorflow/commit/db596594b5653b43fcb558a4753b39904bb62cbd\r\nI have tested it internally to make sure it fixes the bug. Please confirm this with the OSS version. Thank you!", "@yzhwang Hi, Wang, I got a similar issue as below. I have a moderate model with dozens of thousands of weights and 128 batch size of 128x128 size images. Can you tell me how to fix this? Thx a lot! I am using tensorflow r1.3 / python 3.6.1 / CUDA/cuDNN version: CUDA Version 8.0.61, GPU model and memory: GeForce GTX 1080, 8GB. \r\n\r\nPython 3.6.1 |Continuum Analytics, Inc.| (default, May 11 2017, 13:09:58)\r\nType \"copyright\", \"credits\" or \"license\" for more information.\r\n\r\nIPython 6.1.0 -- An enhanced Interactive Python.\r\n\r\nRestarting kernel...  \r\n\r\nINFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.NotFoundError'>, No algorithm without scratch worked!\r\n         [[Node: gradients/dilated_conv6/convolution_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NHWC\", padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/dilated_conv6/convolution_grad/Shape, dilated_conv6/weights/read, gradients/dilated_conv6/convolution/BatchToSpaceND_grad/SpaceToBatchND)]]\r\n         [[Node: Adam/update/_552 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1777_Adam/update\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\nCaused by op 'gradients/dilated_conv6/convolution_grad/Conv2DBackpropInput', defined at:\r\n  File \"/home/zhen/anaconda2/envs/tensorflow/lib/python3.6/site-packages/spyder/utils/ipython/start_kernel.py\", line 231, in <module>\r\n......\r\nNotFoundError (see above for traceback): No algorithm without scratch worked!\r\n\t [[Node: gradients/dilated_conv6/convolution_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NHWC\", padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/dilated_conv6/convolution_grad/Shape, dilated_conv6/weights/read, gradients/dilated_conv6/convolution/BatchToSpaceND_grad/SpaceToBatchND)]]\r\n\t [[Node: Adam/update/_552 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1777_Adam/update\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\r\n\r\n\r\n", "Hi @zhenhe168 . I don't think r1.3 branch does not contain my commit that fixed this error: https://github.com/tensorflow/tensorflow/commit/db596594b5653b43fcb558a4753b39904bb62cbd. Could you try from head of master branch? I've confirmed it contains this commit.", "thx for the quick response.\nI am a newbie. May I ask whether there is any other easier way to install\nthe latest stable version, other then building tf source codes?\n\nOn Mon, Aug 14, 2017 at 5:07 PM, Yangzihao Wang <notifications@github.com>\nwrote:\n\n> Hi @zhenhe168 <https://github.com/zhenhe168> . I don't think r1.3 branch\n> does not contain my commit that fixed this error: db59659\n> <https://github.com/tensorflow/tensorflow/commit/db596594b5653b43fcb558a4753b39904bb62cbd>.\n> Could you try from head of master branch? I've confirmed it contains this\n> commit.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/11327#issuecomment-322342414>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AV-ZhyM2MA1tzllcwLPuRiOWHELcMu3bks5sYOExgaJpZM4OPx9j>\n> .\n>\n", "Fixed with https://github.com/tensorflow/tensorflow/commit/db596594b5653b43fcb558a4753b39904bb62cbd. @ma0ho if you believe this didn't solve your issue, please let us know.", "Thx, Yangzhihao. will try again on this Friday. So far, I have trouble\ndoing docker installation of latest build on my machine. :(\n\nOn Wed, Aug 23, 2017 at 11:54 AM, Yangzihao Wang <notifications@github.com>\nwrote:\n\n> Fixed with db59659\n> <https://github.com/tensorflow/tensorflow/commit/db596594b5653b43fcb558a4753b39904bb62cbd>.\n> @ma0ho <https://github.com/ma0ho> if you believe this didn't solve your\n> issue, please let us know.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/11327#issuecomment-324428402>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AV-ZhwVE1OE-WDCq59Q_SyqT0KvKqYSUks5sbHVbgaJpZM4OPx9j>\n> .\n>\n", "Hi, is this bug solved already in version 1.3?", "It is fixed in head so if you build from source you won't see the bug. The commit that solved this bug didn't get into r1.3, but will be included in our next release.", "Thanks @yzhwang, as I see the nightly build of tensorflow for windows-gpu has not succeeded for more than a month, so I'm not sure that I can build it myself. Is there any guess when will be the next release?", "Sorry for the trouble. Previous release dates suggest a 2 month release cycle. But I'm not sure if this will always be the case. You can also patch in https://github.com/tensorflow/tensorflow/commit/db596594b5653b43fcb558a4753b39904bb62cbd with an earlier version of tensorflow if you need them immediately.", "Thanks a lot @yzhwang ", "Works for me now. Thx for bug fixing!\n\nZhen sent from my iPhone\n\n> On Sep 6, 2017, at 11:00 PM, Hadar Porat <notifications@github.com> wrote:\n> \n> Thanks a lot @yzhwang\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub, or mute the thread.\n> \n", ">>> import tensorflow\r\n**Bus error (core dumped)**\r\n\r\n\r\nHas anyone solved the above issue", "@TamizhPS Are you sure this is a relevant issue? If so please provide more info as the original reporter did, so that I can take a closer look. Thank you!", "Facing the same issue.\r\n\r\nStacktrace:\r\n```\r\nFound 28709 images belonging to 7 classes.\r\nFound 7178 images belonging to 7 classes.\r\nEpoch 1/10\r\n\r\n---------------------------------------------------------------------------\r\n\r\nNotFoundError                             Traceback (most recent call last)\r\n\r\n<ipython-input-15-87899e1fd701> in <module>()\r\n     36   return model, test_generator\r\n     37 \r\n---> 38 model, test_generator = train_eval_model(model)\r\n\r\n9 frames\r\n\r\n<ipython-input-15-87899e1fd701> in train_eval_model(model)\r\n     27                                 validation_data=test_generator,\r\n     28                                 validation_steps=validation_steps,\r\n---> 29                                 callbacks=[callbacks])\r\n     30 \r\n     31   print(\"history.history['accuracy'][-1]: \", history.history['accuracy'][-1])\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)\r\n    106   def _method_wrapper(self, *args, **kwargs):\r\n    107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access\r\n--> 108       return method(self, *args, **kwargs)\r\n    109 \r\n    110     # Running inside `run_distribute_coordinator` already.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n   1096                 batch_size=batch_size):\r\n   1097               callbacks.on_train_batch_begin(step)\r\n-> 1098               tmp_logs = train_function(iterator)\r\n   1099               if data_handler.should_sync:\r\n   1100                 context.async_wait()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    778       else:\r\n    779         compiler = \"nonXla\"\r\n--> 780         result = self._call(*args, **kwds)\r\n    781 \r\n    782       new_tracing_count = self._get_tracing_count()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    805       # In this case we have created variables on the first call, so we run the\r\n    806       # defunned version which is guaranteed to never create variables.\r\n--> 807       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n    808     elif self._stateful_fn is not None:\r\n    809       # Release the lock early so that multiple threads can perform the call\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)\r\n   2827     with self._lock:\r\n   2828       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n-> 2829     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n   2830 \r\n   2831   @property\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _filtered_call(self, args, kwargs, cancellation_manager)\r\n   1846                            resource_variable_ops.BaseResourceVariable))],\r\n   1847         captured_inputs=self.captured_inputs,\r\n-> 1848         cancellation_manager=cancellation_manager)\r\n   1849 \r\n   1850   def _call_flat(self, args, captured_inputs, cancellation_manager=None):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n   1922       # No tape is watching; skip to running the function.\r\n   1923       return self._build_call_outputs(self._inference_function.call(\r\n-> 1924           ctx, args, cancellation_manager=cancellation_manager))\r\n   1925     forward_backward = self._select_forward_and_backward_functions(\r\n   1926         args,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)\r\n    548               inputs=args,\r\n    549               attrs=attrs,\r\n--> 550               ctx=ctx)\r\n    551         else:\r\n    552           outputs = execute.execute_with_cancellation(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     58     ctx.ensure_initialized()\r\n     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n---> 60                                         inputs, attrs, num_outputs)\r\n     61   except core._NotOkStatusException as e:\r\n     62     if name is not None:\r\n\r\nNotFoundError:  No algorithm worked!\r\n\t [[node sequential/conv2d/Conv2D (defined at <ipython-input-10-87899e1fd701>:29) ]] [Op:__inference_train_function_2283]\r\n\r\nFunction call stack:\r\ntrain_function\r\n\r\n```\r\n\r\nI am working in Google Colab and the this issue came out of nowhere since I ran the same code many times before as well and it worked and trained expectedly. But now, with no significant changes in the code, it's throwing in this error."]}, {"number": 11326, "title": "ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'", "body": "Windows 10 Home\r\nPython 3.6\r\nCUDA 8.0 & 7.5 \r\ncuDNN 5.1 (for both 8.0 and 7.5)\r\nCUDA path variables set (to 8.0)\r\nGeForce GTX 970\r\ntensorflow installed from:\r\nhttps://github.com/tensorflow/tensorflow/tree/r1.2\r\nhttp://i.imgur.com/tqTp5LA.png\r\n\r\nI also have Theano and CNTK installed and they both work\r\n\r\nthe error happens when importing tensorflow\r\n`import tensorflow as tf`\r\n\r\n```\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"D:\\Programs\\Anaconda3.6\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"D:\\Programs\\Anaconda3.6\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 978, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 961, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 950, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 648, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 560, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 205, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Programs\\Anaconda3.6\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"D:\\Programs\\Anaconda3.6\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"D:\\Programs\\Anaconda3.6\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"D:\\Programs\\Anaconda3.6\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"D:\\Programs\\Anaconda3.6\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"D:\\Programs\\Anaconda3.6\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"D:\\Programs\\Anaconda3.6\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 52, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"D:\\Programs\\Anaconda3.6\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"D:\\Programs\\Anaconda3.6\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 978, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 961, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 950, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 648, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 560, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 205, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Programs\\Anaconda3.6\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"D:\\Programs\\Anaconda3.6\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"D:\\Programs\\Anaconda3.6\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"D:\\Programs\\Anaconda3.6\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n```", "comments": ["@mrry has a great script to help diagnose these problems. What are the results of that?\r\n\r\nCheck out this post here: https://stackoverflow.com/questions/42011070/\r\n\r\nThese problems are often caused by the MSVCP140.DLL not being installed and/or in your path. \r\n\r\n(Side bar: Are you installing tensorflow in the root of your anaconda and then accessing it through an environment or all through root?)", "Sorry for the late response,\r\nMSVCP140.DLL is installed and is in my PATH\r\n\r\nI installed tensorflow with Anaconda's pip to the default location and I am accessing it from a different folder.", "Just ran the script and got this result:\r\n```\r\nERROR: Failed to import the TensorFlow module.\r\n\r\n- Python version is 3.6.\r\n- The official distribution of TensorFlow for Windows requires Python version 3.5.\r\n\r\n- TensorFlow is installed at: D:\\Programs\\Anaconda3.6\\lib\\site-packages\\tensorflow\r\nThe thread 'MainThread' (0x12f8) has exited with code 0 (0x0).\r\nThe program '[7320] python.exe' has exited with code -1 (0xffffffff).\r\n```\r\nI installed the new version of tensorflow for python 3.6", "Sorry, I'm confused by your update. Do you mean that you installed the new version of TF for Windows, which works with 3.6, and you're still experiencing the problem? ", "Sorry for the confusion,\r\nI didn't change anything, I just ran the script.\r\nI always had the new version of tensorflow that is compatible with 3.6 installed, with Python 3.6 itself (anaconda).\r\nAnd also sorry for the late responses, I live in Australia.", "The latest version of TensorFlow *is* compatible with Python 3.6 (I've updated the [self-check script](https://gist.github.com/mrry/ee5dbcfdd045fa48a27d56664411d41c) to reflect that). \r\n\r\nYou mentioned that CUDA is in your `%PATH%`... have you also added the cuDNN `bin\\` directory to your path?", "Yes.\r\nhttp://i.imgur.com/vinpQwY.png\r\n\r\nThe script returns:\r\n```\r\nERROR: Failed to import the TensorFlow module.\r\n\r\n- Python version is 3.6.\r\n\r\n- TensorFlow is installed at: D:\\Programs\\Anaconda3.6\\lib\\site-packages\\tensorflow\r\n\r\n- All required DLLs are present. Please open an issue on the\r\n  TensorFlow GitHub page: https://github.com/tensorflow/tensorflow/issues\r\nAn exception has occurred, use %tb to see the full traceback.\r\n\r\nSystemExit: -1\r\n```", "Oh, and your script's exception traceback:\r\n```\r\n---------------------------------------------------------------------------\r\nSystemExit                                Traceback (most recent call last)\r\n<ipython-input-1-fc5b8d96e0e5> in <module>()\r\n    106 \r\n    107 if __name__ == \"__main__\":\r\n--> 108   main()\r\n\r\n<ipython-input-1-fc5b8d96e0e5> in main()\r\n    103   TensorFlow GitHub page: https://github.com/tensorflow/tensorflow/issues\"\"\")\r\n    104 \r\n--> 105   sys.exit(-1)\r\n    106 \r\n    107 if __name__ == \"__main__\":\r\n\r\nSystemExit: -1\r\n```", "OK, in that case there must be some missing dependency. In the same terminal as you used to run `ipython`, can you try running [Dependency Walker](http://www.dependencywalker.com/) on the file `D:\\Programs\\Anaconda3.6\\lib\\site-packages\\tensorflow\\python\\_pywrap_tensorflow_internal.pyd`, and let us know what DLLs it reports as missing?", "I'm, not too sure how to use this, but this is what I got:\r\nhttp://i.imgur.com/lh8Byqk.png", "Can you get the full list of modules that have \"Error opening file.\" next to them? Annoyingly, the `API-MS-WIN-*.DLL` and `EXT-MS-WIN-*.DLL` modules are false negatives, but hopefully something else turns up in the list.", "https://pastebin.com/npcKuW1y", "From the list of missing dependencies:\r\n\r\n> `CUDNN64_6.DLL`\r\n\r\nIt looks like that DLL depends on cuDNN 6! I assume at some point our nightly builds changed to use cuDNN 6 instead of cuDNN 5.1. Can you try upgrading to cuDNN 6, updating all of the necessary paths, and see if that fixes the problem?", "Yay!\r\nIt finally works!\r\nThanks", "Thanks for persevering! I'll have to figure out how to upgrade the script so that we can handle cuDNN 5.1 versus 6 issues....", "I know this issue has been beaten to death but I can't seem to figure out what I am doing wrong.\r\n\r\nI am using a conda virtual environment with python 3.5.4\r\nI have tensorflow-gpu 1.3 installed via pip install tensorflow-gpu\r\nMy CUDA is installed on my D:\\ drive (D:\\deeplearning\\CUDA\\v9.0)\r\nI also downloaded cudnn 5.1 as well as cudnn 6 and both cudnn64_5.dll and cudnn64_6.dll are in the D:\\deeplearning\\CUDA\\v9.0\\bin folder\r\n\r\nI have D:\\deeplearning\\CUDA\\v9.0\\bin set in my environment path\r\nI also have a path to MSVCP140.DLL\r\n\r\nWhen I run import tensorflow as tf I am still getting  ImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nI am not sure if it makes a difference but I do have CUDA 9 installed instead of CUDA 8 and visual studios 2017.", "I had CUDA 8.\r\nIf CUDA 8 doesn't work, try running the self-check script (scroll up and find it).\r\nIf that doesn't work either, run dependency walker and send in the list of dependencies.", "Yes I just verified that it needs CUDA 8 (runtime and development). It works now thanks!", "DO NOT USER python 3.6 ,try python 3.5", "Tensorflow has moved on to python 3.6 quite a while ago\r\n\r\nEDIT: And Tensorflow uses CUDA 9.0 these days too", "I will try 3.6 again with CUDA 9.0. \r\nThx arduano ", "ERROR:root:Internal Python error in the inspect module.\r\nBelow is the traceback from this internal error.\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-36-eeb151527e4e>\", line 1, in <module>\r\n    model.fit(X, y,\r\nNameError: name 'model' is not defined\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'NameError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1148, in get_records\r\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\r\n    return f(*args, **kwargs)\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\r\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\inspect.py\", line 1502, in getinnerframes\r\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\inspect.py\", line 1460, in getframeinfo\r\n    filename = getsourcefile(frame) or getfile(frame)\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\inspect.py\", line 696, in getsourcefile\r\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\inspect.py\", line 733, in getmodule\r\n    if ismodule(module) and hasattr(module, '__file__'):\r\n  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 8, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-36-eeb151527e4e>\", line 1, in <module>\r\n    model.fit(X, y,\r\nNameError: name 'model' is not defined\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'NameError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "> ERROR:root:Internal Python error in the inspect module.\r\n> Below is the traceback from this internal error.\r\n> \r\n> Traceback (most recent call last):\r\n> File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\r\n> exec(code_obj, self.user_global_ns, self.user_ns)\r\n> File \"\", line 1, in\r\n> model.fit(X, y,\r\n> NameError: name 'model' is not defined\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n> File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\r\n> stb = value._render_traceback_()\r\n> AttributeError: 'NameError' object has no attribute '_render_traceback_'\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n> File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in\r\n> from tensorflow.python.pywrap_tensorflow_internal import *\r\n> File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in\r\n> _pywrap_tensorflow_internal = swig_import_helper()\r\n> File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n> _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n> File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\imp.py\", line 242, in load_module\r\n> return load_dynamic(name, filename, file)\r\n> File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\imp.py\", line 342, in load_dynamic\r\n> return _load(spec)\r\n> ImportError: DLL load failed: The specified module could not be found.\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n> File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1148, in get_records\r\n> return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\r\n> File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\r\n> return f(*args, **kwargs)\r\n> File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes records = fix_frame_records_filenames(inspect.getinnerframes(etb, context)) File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\inspect.py\", line 1502, in getinnerframes frameinfo = (tb.tb_frame,) + getframeinfo(tb, context) File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\inspect.py\", line 1460, in getframeinfo filename = getsourcefile(frame) or getfile(frame) File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\inspect.py\", line 696, in getsourcefile if getattr(getmodule(object, filename), '**loader**', None) is not None: File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\inspect.py\", line 733, in getmodule if ismodule(module) and hasattr(module, '**file**'): File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow__init__.py\", line 50, in **getattr**\r\n> module = self._load() File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow__init__.py\", line 44, in _load\r\n> module = _importlib.import_module(self.**name**) File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\importlib__init__.py\", line 127, in import_module\r\n> return _bootstrap._gcd_import(name[level:], package, level)\r\n> File \"\", line 1006, in _gcd_import\r\n> File \"\", line 983, in _find_and_load\r\n> File \"\", line 953, in _find_and_load_unlocked\r\n> File \"\", line 219, in _call_with_frames_removed\r\n> File \"\", line 1006, in _gcd_import\r\n> File \"\", line 983, in _find_and_load\r\n> File \"\", line 967, in _find_and_load_unlocked\r\n> File \"\", line 677, in _load_unlocked\r\n> File \"\", line 728, in exec_module\r\n> File \"\", line 219, in _call_with_frames_removed File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core__init__.py\", line 42, in\r\n> from . _api.v2 import audio File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core_api\\v2\\audio__init__.py\", line 10, in\r\n> from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n> File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 8, in\r\n> from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow__init__.py\", line 50, in **getattr**\r\n> module = self._load() File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow__init__.py\", line 44, in _load\r\n> module = _importlib.import_module(self.**name**) File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\importlib__init__.py\", line 127, in import_module\r\n> return _bootstrap._gcd_import(name[level:], package, level) File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python__init__.py\", line 49, in\r\n> from tensorflow.python import pywrap_tensorflow\r\n> File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in\r\n> raise ImportError(msg)\r\n> ImportError: Traceback (most recent call last):\r\n> File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\r\n> exec(code_obj, self.user_global_ns, self.user_ns)\r\n> File \"\", line 1, in\r\n> model.fit(X, y,\r\n> NameError: name 'model' is not defined\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n> File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\r\n> stb = value._render_traceback_()\r\n> AttributeError: 'NameError' object has no attribute '_render_traceback_'\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n> File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in\r\n> from tensorflow.python.pywrap_tensorflow_internal import *\r\n> File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in\r\n> _pywrap_tensorflow_internal = swig_import_helper()\r\n> File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n> _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n> File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\imp.py\", line 242, in load_module\r\n> return load_dynamic(name, filename, file)\r\n> File \"C:\\Users\\user\\Anaconda3\\envs\\teff\\lib\\imp.py\", line 342, in load_dynamic\r\n> return _load(spec)\r\n> ImportError: DLL load failed: The specified module could not be found.\r\n> \r\n> Failed to load the native TensorFlow runtime.\r\n> \r\n> See https://www.tensorflow.org/install/errors\r\n> \r\n> for some common reasons and solutions. Include the entire stack trace\r\n> above this error message when asking for help.\r\n\r\nI have this error plz help"]}, {"number": 11325, "title": "[contribution] 3d geometric transformations?", "body": "Hi!\r\nI wonder if you see purpose in adding 3d geometric transformations to contrib? (such as those available in [transforms3d library](https://github.com/matthew-brett/transforms3d))\r\nI've written a few of those in tensorflow for one of my projects and I wonder if it would be worth doing some refactoring and documentation to make it contribution-worthy?\r\nI've implemented them using tf python functions, I haven't done any lower level performance optimisation, is that fine?", "comments": ["You could send a PR to add them to contrib.", "This issue is automatically closed due to lack of activity. Please re-open if this is still an issue for you. Thanks!"]}, {"number": 11324, "title": "TypeError: concat() got an unexpected keyword argument 'concat_dim'", "body": "I got this error message regarding to tf.concat\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-3-bf534f0e5e9f> in <module>()\r\n     42 \r\n     43 combined_mask = tf.concat(concat_dim=2, values=[bit_mask_class,\r\n---> 44                                                 bit_mask_background])\r\n     45 \r\n     46 # Lets reshape our input so that it becomes suitable for\r\n\r\nTypeError: concat() got an unexpected keyword argument 'concat_dim'\r\n```\r\n\r\nCode: https://github.com/datomnurdin/tensorflow-image-segmentation/blob/master/index.ipynb\r\n\r\nPlease advice. Thank you.", "comments": ["It looks like that code was written for an older version of TensorFlow. From TensorFlow 1.0 onwards, [`tf.concat()`](https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/concat) takes the arguments `values` and `axis`. Replacing `concat_dim` with `axis` will fix the problem.", "It worked!! Thanks!!"]}, {"number": 11323, "title": "Minor fix typo", "body": "Minor fix comments typo.", "comments": ["Can one of the admins verify this patch?", "@caisq ping."]}, {"number": 11322, "title": "[OpenCL] Fixes SYCL registration for MapStageOp (#117)", "body": "* [OpenCL] Fixes SYCL registration for MapStageOp\r\n\r\nAs the MapStageOp is actually run on the host, we need to ensure that\r\nboth the 'key' and 'indices' tensors are in host memory. This now\r\nmirrors what CUDA is doing.\r\n\r\n* [OpenCL] Fixes device name comparison map_stage_op_test\r\n\r\nChanges the expected device name string, as the device name could be\r\n'/device:SYCL:0' or '/device:GPU:0'.\r\n\r\nThe CUDA device name reported by test_util is in the form '/gpu:0',\r\nwhile the device name used in the nodes looks like '/device:GPU:0'. When\r\nrunning on CUDA we need to change the expected device name accordingly,\r\nhowever this isn't a problem on SYCL.", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "Thanks, @lukeiwanski "]}, {"number": 11321, "title": "Is 'tf.concat' 's API is wrong?", "body": "According 'tf.concat' 's API (0.12):\r\n\r\n`t1 = [[1, 2, 3], [4, 5, 6]]`\r\n`t2 = [[7, 8, 9], [10, 11, 12]]`\r\n`tf.concat(0, [t1, t2])`\r\n\r\nwhile console returns:\r\n\r\n`tf.concat(0, [t1, t2])\r\nTraceback (most recent call last):`\r\n`File \"<ipython-input-65-5990b998f0fa>\", line 1, in <module>\r\n    tf.concat(0, [t1, t2])`\r\n`File \"E:\\SDK\\Anaconda2\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1044, in concat\r\n    ).assert_is_compatible_with(tensor_shape.scalar())`\r\n`File \"E:\\SDK\\Anaconda2\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\", line 732, in assert_is_compatible_with\r\n    raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))`\r\n`ValueError: Shapes (2, 2, 3) and () are incompatible`\r\n\r\n**BUT I try to swap the params' position, it is well.**\r\n\r\n`t1 = [[1, 2, 3], [4, 5, 6]]`\r\n`t2 = [[7, 8, 9], [10, 11, 12]]`\r\n`tf.concat([t1, t2], 0)`", "comments": ["As this API defined [here](https://www.tensorflow.org/api_docs/python/tf/concat):\r\n\r\n```python\r\ntf.concat\r\n\r\nconcat(\r\n    values,\r\n    axis,\r\n    name='concat'\r\n)\r\n```\r\n\r\nAnd args must follow:\r\n\r\n- `values`: A list of `Tensor` objects or a single `Tensor`.\r\n- `axis`: 0-D int32 `Tensor`. Dimension along which to concatenate.\r\n- `name`: A name for the operation (optional).\r\n", "@ScorpioCPH \r\nI have some problems when clicking your URL (Maybe my HOSTS is not correctly haha )\r\n\r\nI wonder know what's difference between your URL and below API:\r\n[https://www.tensorflow.org/versions/r0.12/api_docs/python/array_ops.html#concat](tf.concat)\r\n\r\nDoes this API is out-of-date ? Thanks a lot !"]}, {"number": 11320, "title": "BeamSearchDecoder Bug on beam_width", "body": "### System information\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 14.04\r\n- TensorFlow installed from (source or binary): Pip Binary\r\n- TensorFlow version (use command below): 1.2.1\r\n- Python version: 3.4\r\n### My coustom code\r\n```python\r\nclass Model():\r\n'''\r\nA seq2seq model\r\nplaceholder: \r\n    encoder_input, a int32 tensor shaped [None, max_encoder_len]\r\n    encoder_length, a int32 tensor shaped [None]\r\n    decoder_input, a int32 tensor shaped [None, max_decoder_len]\r\ncell:\r\n    LSTMCell. cell.output_size = 128\r\n'''\r\n\r\n    # some irrespective code\r\n\r\n    @property\r\n    def _prediction(self):\r\n        with self._graph.as_default():\r\n            GO_SYMBOL = [500]\r\n            END_SYMBOL = 501\r\n\r\n            initial_state = self.encoder['final_state']\r\n\r\n            decoder = tf.contrib.seq2seq.BeamSearchDecoder(\r\n                cell=self.cell,\r\n                embedding=lambda tokens:tf.nn.embedding_lookup(self._decoder_embedding, tokens),\r\n                start_tokens=GO_SYMBOL,\r\n                end_token=END_SYMBOL,\r\n                initial_state=initial_state,\r\n                beam_width=self._beam_size, # self._beam_size = 1 is ok \r\n                                            # but self._beam_size = 2 runs wrong\r\n                output_layer=self._output_projection_layer\r\n            )\r\n\r\n            outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(\r\n                decoder=decoder,\r\n                maximum_iterations=self._max_decoder_len\r\n            )\r\n\r\n            return outputs.predicted_ids[:, :, 0]\r\n\r\n    # some irrespective code\r\n\r\n    def predict(self, word_list):\r\n        '''\r\n        Args:\r\n            word_list: [word0, word1...]. 1-dimentional array\r\n        return:\r\n            outputs: [o0, o1...]. 1-dimentional array\r\n                     where oi is word_index\r\n        '''\r\n        length = len(word_list)\r\n        word_index_list = preprocess.words_to_indices(word_list) # turn words to numbers\r\n        if len(word_index_list) < self._max_encoder_len:\r\n            word_index_list.extend([0] * (self._max_encoder_len - len(word_index_list)))\r\n\r\n        feed_dict = {\r\n            self.input_length['encoder_input']: [word_index_list],\r\n            self.input_length['encoder_length']: [length]\r\n        }\r\n\r\n        (\r\n            output\r\n        ) = self._session.run([\r\n            self._prediction\r\n        ],\r\n            feed_dict = feed_dict\r\n        )\r\n\r\n        return output\r\n```\r\n### Error Desciption\r\nIt is ok to build tfGraph. But I get into trouble when calling Model.predict().\r\nIf the beam_width is set as 1, the program can normally run. And it raise the following error when the beam_width is set as 2.\r\n```\r\n  File \"/home/runke/lxtest/algorithm/algorithm/estimation/get_earnings.py\", line 347, in _prediction\r\n    output_layer=self._output_projection_layer\r\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py\", line 193, in __init__\r\n    initial_state, self._cell.state_size)\r\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/util/nest.py\", line 325, in map_structure\r\n    structure[0], [func(*x) for x in entries])\r\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/util/nest.py\", line 325, in <listcomp>\r\n    structure[0], [func(*x) for x in entries])\r\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py\", line 374, in _maybe_split_batch_beams\r\n    return self._split_batch_beams(t, s)\r\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py\", line 339, in _split_batch_beams\r\n    ([self._batch_size, self._beam_width], t_shape[1:]), 0))\r\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2451, in reshape\r\n    name=name)\r\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/home/runke/lxtest/env3/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 128 values, but the requested shape has 256\r\n         [[Node: Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](encoder/rnn/while/Exit_2, concat)]]\r\n```", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 11319, "title": "c: fix a possible segmentfault", "body": "We also need allocation for `output_values_` when updating `output_`, or we will get a segment fault on:\r\n\r\n```c++\r\nstatic void TF_Run_Setup(int noutputs, TF_Tensor** c_outputs,\r\n                         TF_Status* status) {\r\n  status->status = Status::OK();\r\n  for (int i = 0; i < noutputs; ++i) {\r\n    c_outputs[i] = nullptr;\r\n  }\r\n}\r\n```\r\n", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "Thanks, @yorkie!", ":)"]}, {"number": 11318, "title": "TypeError: Input 'strides' of 'StridedSlice' Op has type int32 that does not match type int64 of argument 'begin'.", "body": "I just want to get a slice of a tensor. It works for int32 but not for int64:\r\n\r\n```\r\nIn [35]: import tensorflow as tf\r\n    ...: a=tf.Variable([0,1,2], dtype=tf.int64)\r\n    ...: i = tf.constant(1, dtype=tf.int64)\r\n    ...: a[i]\r\n    ...:\r\n<long stack trace>\r\nTypeError: Input 'strides' of 'StridedSlice' Op has type int32 that does not match type int64 of argument 'begin'.\r\nIn [36]: import tensorflow as tf\r\n    ...: a=tf.Variable([0,1,2], dtype=tf.int32)\r\n    ...: i = tf.constant(1, dtype=tf.int32)\r\n    ...: a[i]\r\n    ...:\r\nOut[36]: <tf.Tensor 'strided_slice_22:0' shape=() dtype=int32>\r\n```", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "It looks like a bug for me... I mean, why can't int64 be used as a simple index? What happen if I have a vector of more than 2^32 elements?", "Invoking @vrv who has suffered a long time working on the differences in behavior between int32 and int64. \r\n\r\nCan you not do a cast from int64 to int32 to get the effect you want? I.e., do you really have a >4B-element vector that you want to access in practice? \r\n", "StridedSlice definitely supports int64 indices, I think the problem is that the datatype of 'begin' is int64 and the datatype of 'strides' is int32, and that's a type mismatch.\r\n\r\n@aselle: my guess is that there's some kind of missing cast to match the dtype of 'begin' somewhere in the SliceHelper.  Do you know the code well enough to know what the fix is quickly?", "@minhlab knowing the version of TensorFlow and all the information requested in the template would help to make sure it's not already fixed.", "In fact, I think this was already fixed two months ago in https://github.com/tensorflow/tensorflow/pull/9000/files, and you are probably using an older version of TF that doesn't have the bug fix.", "Hi @vrv, you're right. After running pip install --upgrade, the problem was gone."]}, {"number": 11317, "title": "Point protobuf to 0b059a3d8a8f8aa40dde7bea55edca4ec5dfea66", "body": "This change won't be needed after updating protobuf to a version\r\ncontaining google/protobuf@0b059a3", "comments": ["https://ci.tensorflow.org/job/tensorflow-pull-requests-mac/5617/consoleFull\r\nGetting this error:\r\n```\r\nINFO: From Compiling tensorflow/core/framework/allocator.cc:\r\ntensorflow/core/framework/allocator.cc:121:12: warning: unused function 'MakeCpuAllocator' [-Wunused-function]\r\nAllocator* MakeCpuAllocator() {\r\n           ^\r\n1 warning generated.\r\nERROR: /Users/jenkins/workspace/tensorflow-pull-requests-mac/tensorflow/compiler/xla/BUILD:158:1: C++ compilation of rule '//tensorflow/compiler/xla:util' failed: cc_wrapper.sh failed: error executing command \r\n  (cd /private/var/tmp/_bazel_jenkins/13e370a18c169b19baeafefb05212b85/execroot/tensorflow-pull-requests-mac && \\\r\n  exec env - \\\r\n    PATH=/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin \\\r\n    PYTHON_BIN_PATH=/usr/bin/python \\\r\n    PYTHON_LIB_PATH=/usr/local/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages \\\r\n    TF_NEED_CUDA=0 \\\r\n    TF_NEED_OPENCL=0 \\\r\n    TMPDIR=/var/folders/2w/kjgvq26s1s71qntt8nk1hyw80008p3/T/ \\\r\n  external/local_config_cc/cc_wrapper.sh -U_FORTIFY_SOURCE -fstack-protector -Wall -Wthread-safety -Wself-assign -fcolor-diagnostics -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/local-opt/bin/tensorflow/compiler/xla/_objs/util/tensorflow/compiler/xla/util.d '-frandom-seed=bazel-out/local-opt/bin/tensorflow/compiler/xla/_objs/util/tensorflow/compiler/xla/util.o' -DEIGEN_MPL2_ONLY -DSNAPPY -iquote . -iquote bazel-out/local-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/local-opt/genfiles/external/bazel_tools -iquote external/protobuf -iquote bazel-out/local-opt/genfiles/external/protobuf -iquote external/eigen_archive -iquote bazel-out/local-opt/genfiles/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/local-opt/genfiles/external/local_config_sycl -iquote external/gif_archive -iquote bazel-out/local-opt/genfiles/external/gif_archive -iquote external/jpeg -iquote bazel-out/local-opt/genfiles/external/jpeg -iquote external/com_googlesource_code_re2 -iquote bazel-out/local-opt/genfiles/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/local-opt/genfiles/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/local-opt/genfiles/external/fft2d -iquote external/highwayhash -iquote bazel-out/local-opt/genfiles/external/highwayhash -iquote external/png_archive -iquote bazel-out/local-opt/genfiles/external/png_archive -iquote external/zlib_archive -iquote bazel-out/local-opt/genfiles/external/zlib_archive -iquote external/snappy -iquote bazel-out/local-opt/genfiles/external/snappy -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/protobuf/src -isystem bazel-out/local-opt/genfiles/external/protobuf/src -isystem external/eigen_archive -isystem bazel-out/local-opt/genfiles/external/eigen_archive -isystem external/gif_archive/lib -isystem bazel-out/local-opt/genfiles/external/gif_archive/lib -isystem external/farmhash_archive/src -isystem bazel-out/local-opt/genfiles/external/farmhash_archive/src -isystem external/png_archive -isystem bazel-out/local-opt/genfiles/external/png_archive -isystem external/zlib_archive -isystem bazel-out/local-opt/genfiles/external/zlib_archive -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c tensorflow/compiler/xla/util.cc -o bazel-out/local-opt/bin/tensorflow/compiler/xla/_objs/util/tensorflow/compiler/xla/util.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\ntensorflow/compiler/xla/util.cc:261:15: error: no member named 'accumulate' in namespace 'std'\r\n  return std::accumulate(xs.begin(), xs.end(), 1, std::multiplies<int64>());\r\n         ~~~~~^\r\n```", "Can you try adding `#include <numeric>` in tensorflow/compiler/xla/util.cc?", "My guess is that protobuf previously transitively included that header, but doesn't after the update.", "@jhseu Thanks, that fixed the error. There were two downloading errors in other two jobs, turned out\r\nhttp://mirror.bazel.build/github.com/google/protobuf/archive/0b059a3d8a8f8aa40dde7bea55edca4ec5dfea66.tar.gz doesn't work, so I put the github url before it.", "@jhseu Can we merge this now?", "@frankchn can merge it in when he has a moment."]}, {"number": 11316, "title": "order of execution of functions in cond statement is inconsistent", "body": "### Inconsistency and/or feature request.\r\n\r\nTensorflows control flow method\r\n`tf.cond(condition, fn1, fn2)`\r\nexecutes both functions fn1 and fn2 and returns only one depending on the evaluation of condition. In addition, the order in which the two functions are evaluated varies or is undefined as the following code shows:\r\n```\r\nvar1 = tf.Variable(tf.zeros(1), trainable=False, name='var1')\r\nvar2 = tf.Variable(tf.zeros(1), trainable=False, name='var2')\r\nupdate_var1 = tf.assign(var1,var1 +1)\r\nupdate_var2 = tf.assign(var2,var2 +1)\r\ntraining = tf.placeholder(tf.bool)\r\ndef f1():\r\n  with tf.control_dependencies([update_var1]):\r\n    return var1 + 10*var2\r\ndef f2():\r\n  with tf.control_dependencies([update_var2]):\r\n    return var1 + 10*var2\r\n\r\nfinal = tf.cond(training, f1, f2)\r\nsess = tf.Session()\r\nsess.run(tf.global_variables_initializer())\r\nfor i in range(10):\r\n  print(sess.run(final, feed_dict={training: False}))\r\n```\r\nThe output of this varies from run to run, but a typical example is:\r\n```\r\n[ 10.] \r\n[ 22.] \r\n[ 33.]\r\n[ 44.]\r\n[ 55.]\r\n[ 66.]\r\n[ 77.]\r\n[ 87.]\r\n[ 98.]\r\n[ 110.]\r\n```\r\nFor the lines with 10, 87 and 98 the order of execution apparently was:\r\n1. update var1\r\n2. evaluate and return var1 * 10*var2\r\n3. **update var2**\r\n\r\nwhile for the lines with 22, 33, 44, 55, 66, 77 and 110 the order of execution must have been:\r\n1. update var1\r\n2. **update var2**\r\n3. evaluate and return var1 * 10*var2 \r\n\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nSee code in description\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux\r\n- **TensorFlow installed from (source or binary)**:\r\nfrom binary\r\n- **TensorFlow version (use command below)**:\r\n('v1.2.0-rc2-21-g12f033d', '1.2.0')\r\n- **Python version**: \r\nPython 2.7.13 |Anaconda 4.3.1 (64-bit)\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n", "comments": ["If you create the `tf.assign()` ops outside the branch functions, this is working as intended. I [answered the question on Stack Overflow](https://stackoverflow.com/a/44936931/3574081) with an explanation of how to make this consistent. "]}, {"number": 11315, "title": "tf.assert_equal throws \"object was never used\" error in v1.2.x", "body": "The following code is copied from some tensorflow repository outside.\r\n\r\n`tf.assert_equal( tf.size( x ), tf.constant( 1 ) )`\r\n\r\nWhile running in tensorflow v1.2.0 or v1.2.1, it throws the following log.\r\n\r\n`ERROR:tensorflow:==================================\r\nObject was never used (type <class 'tensorflow.python.framework.ops.Operation'>):\r\n<tf.Operation 'update_hyper/cond/assert_equal/Assert/Assert' type=Assert>\r\nIf you want to mark it as used call its \"mark_used()\" method.\r\nIt was originally created here:\r\n['File \"/usr/lib64/python3.5/runpy.py\", line 193, in _run_module_as_main\\n    \"__main__\", mod_spec)', 'File \"/usr/lib64/python3.5/runpy.py\", line 85, in _run_code\\n    exec(code, run_globals)', 'File \"/usr/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\\n    app.launch_new_instance()', 'File \"/usr/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\\n    app.start()', 'File \"/usr/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\\n    ioloop.IOLoop.instance().start()', 'File \"/usr/lib64/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\\n    super(ZMQIOLoop, self).start()', 'File \"/usr/lib64/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\\n    handler_func(fd_obj, events)', 'File \"/usr/lib64/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\\n    return fn(*args, **kwargs)', 'File \"/usr/lib64/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\\n    self._handle_recv()', 'File \"/usr/lib64/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\\n    self._run_callback(callback, msg)', 'File \"/usr/lib64/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\\n    callback(*args, **kwargs)', 'File \"/usr/lib64/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\\n    return fn(*args, **kwargs)', 'File \"/usr/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\\n    return self.dispatch_shell(stream, msg)', 'File \"/usr/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\\n    handler(stream, idents, msg)', 'File \"/usr/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\\n    user_expressions, allow_stdin)', 'File \"/usr/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\\n    res = shell.run_cell(code, store_history=store_history, silent=silent)', 'File \"/usr/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)', 'File \"/usr/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\\n    interactivity=interactivity, compiler=compiler, result=result)', 'File \"/usr/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\\n    if self.run_code(code, result):', 'File \"/usr/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\\n    exec(code_obj, self.user_global_ns, self.user_ns)', 'File \"<ipython-input-13-85a15e405d64>\", line 1, in <module>\\n    h1 = m1.fit( nn_train_x, nn_train_y, epochs=epochs, batch_size=batch_size, verbose=0 )', 'File \"/usr/lib/python3.5/site-packages/keras/models.py\", line 870, in fit\\n    initial_epoch=initial_epoch)', 'File \"/usr/lib/python3.5/site-packages/keras/engine/training.py\", line 1490, in fit\\n    self._make_train_function()', 'File \"/usr/lib/python3.5/site-packages/keras/engine/training.py\", line 1014, in _make_train_function\\n    self.total_loss)', 'File \"<ipython-input-5-1252bd787625>\", line 7, in get_updates\\n    opt_update = self.optimizer.apply_gradients( grads )', 'File \"/data/jupyter/yellowfin/yellowfin.py\", line 223, in apply_gradients\\n    update_hyper_op = self.update_hyper_param()', 'File \"/data/jupyter/yellowfin/yellowfin.py\", line 191, in update_hyper_param\\n    lambda: self._mu_var) )', 'File \"/usr/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 289, in new_func\\n    return func(*args, **kwargs)', 'File \"/usr/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1814, in cond\\n    orig_res_t, res_t = context_t.BuildCondBranch(true_fn)', 'File \"/usr/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1689, in BuildCondBranch\\n    original_result = fn()', 'File \"/data/jupyter/yellowfin/yellowfin.py\", line 190, in <lambda>\\n    self._mu = tf.identity(tf.cond(self._do_tune, lambda: self.get_mu_tensor(),', 'File \"/data/jupyter/yellowfin/yellowfin.py\", line 180, in get_mu_tensor\\n    tf.assert_equal(tf.size(root), tf.constant(1) )', 'File \"/usr/lib/python3.5/site-packages/tensorflow/python/ops/check_ops.py\", line 318, in assert_equal\\n    return control_flow_ops.Assert(condition, data, summarize=summarize)', 'File \"/usr/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py\", line 170, in wrapped\\n    return _add_should_use_warning(fn(*args, **kwargs))', 'File \"/usr/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py\", line 139, in _add_should_use_warning\\n    wrapped = TFShouldUseWarningWrapper(x)', 'File \"/usr/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py\", line 96, in __init__\\n    stack = [s.strip() for s in traceback.format_stack()]']\r\n==================================`\r\n\r\nWhat I expect would be an exception thrown only when the assertion evaluates to false.\r\n\r\nWhy is it a must to use object returned from assert statement?", "comments": ["It seems to be a feature, not a bug. Tensorflow now seems to warn you when you create debug operations but don't use them.", "@langmore @ebrevdo Can either of you comment on this?", "If you're just creating tf.assert_equal, and not using it, you're doing it wrong.  Creating the op does not actually run the assertion.  you need to do something like:\r\n\r\n```\r\nwith tf.control_dependencies([tf.assert_equal(...)]):\r\n  output = tf.identity(output)\r\n\r\n# now use output inside your session.run.\r\n```"]}, {"number": 11314, "title": "There is no work_sharder file in tensorflow/core/framework", "body": "I am reading the `Add a new op` section in official website. There is a link [https://www.github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/core/framework/work_sharder.h](work_sharder.h), and this link is 404 not found. Then i tried to find the work_shader.h in tensorflow/tensorlfow/core/framework, and i failed. where can i find work_sharder.h file and detailed documentation of it ?\r\nThx.\r\n", "comments": ["Found it, in tensorflow/core/util/work_sharder.cc"]}, {"number": 11313, "title": "tf.nn.embedding_lookup_sparse behaves not as expected", "body": "Simple repeated code:\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n\r\na = tf.constant([[2,3], [3,0]])\r\nb = tf.constant([0, 3])\r\n\r\ns = tf.SparseTensor(tf.cast(a, tf.int64), b, dense_shape=(4,5))\r\n\r\nn = np.random.rand(5,3)\r\nnn = tf.Variable(n, name='aha')\r\n\r\nr = tf.nn.embedding_lookup_sparse(nn, s, None,combiner='sum')\r\n\r\nsess = tf.Session()\r\nsess.run(tf.global_variables_initializer())\r\n\r\nprint sess.run(r)\r\n```\r\n\r\n**expected results**: 2*3\r\n\r\n```python\r\n[[ 0.45522392  0.67905994  0.79126569]\r\n [ 0.62346977  0.42459864  0.03796264]]\r\n```\r\n\r\nbut **actual results**: 4\\*3\r\n\r\n```python\r\n[[ 0.          0.          0.        ]\r\n [ 0.          0.          0.        ]\r\n [ 0.45522392  0.67905994  0.79126569]\r\n [ 0.62346977  0.42459864  0.03796264]]\r\n```\r\n\r\nI do not get it. Can anyone help to clarify the result?\r\n\r\nTensorflow version: 1.2.1, installed with pip.\r\nOS: mac os 10.12.5 \r\n\r\n[tf.nn.embedding_lookup_sparse](https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup_sparse)\r\n\r\nAnother problem: I am using a partitioned variable to lookup. Pseudo code:\r\n\r\n```python\r\na = tf.getVariable(...) # it is a partitioned variable, pass partitioner to it\r\nb = list(a)\r\n\r\nresult = []\r\nfor p in b:\r\n    result.append( tf.nn.embedding_lookup_sparse(p, sparseTensor, None, combiner='sum'))\r\n\r\nfinal_result = tf.concat(result, 0)\r\n\r\nsess.run(final_result)\r\n```\r\n\r\nif I remove the `tf.concat`, and replace it with:\r\n\r\n```python\r\nfor ff in final_result:\r\n    sess.run(ff)\r\n```\r\n\r\nThe part of code behaves as expected. But when I do concat, it crashes and the error message is:\r\n\r\n```python\r\nInvalidArgumentError (see above for traceback): segment ids are not increasing\r\n\t [[Node: embedding_lookup_sparse = SparseSegmentSum[T=DT_DOUBLE, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](embedding_lookup_sparse/embedding_lookup, embedding_lookup_sparse/Unique:1, embedding_lookup_sparse/Cast)]]\r\n```\r\n\r\nAfter a serious investigation, I understand **segment ids are not increasing**. It means that:\r\n\r\n```python\r\nsparse_ids = [[1,0],[0,1]] # invalid\r\nsparse_ids = [[0,1],[1,0]] # valid\r\n```\r\nThis is documented in the previous link I provided. But I have printed all the sparse indices and values using `tf.Print`. Everything seems fine. \r\n\r\nSo my question is : does `tf.concat` apply any special rules\uff1f\r\n\r\n", "comments": ["@chunyang-wen \r\n\r\nif you run \r\n\r\n```\r\nIn [37]: a = tf.constant([[3,0], [2, 3]])                                                           \r\n\r\nIn [38]: b = tf.constant([0, 3])                                                                    \r\n\r\nIn [39]: s = tf.SparseTensor(tf.cast(a, tf.int64), b, dense_shape=(4,5))                            \r\n\r\nIn [40]: r = tf.nn.embedding_lookup_sparse(nn, s, None,combiner='sum')\r\n```\r\n\r\nYou will get the same result error.\r\n\r\n"]}, {"number": 11312, "title": "tf.gfile.FastGFile(filename, 'r').read()  error: 'utf-8' codec can't decode byte 0xff", "body": "\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\nTensorFlow 1.2.0\r\n\r\nimage_data = tf.gfile.FastGFile(filename, 'r').read()   \r\npython2.7 is good\uff0cbut Python3.5 error \uff1a  'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\r\n\r\nwhy???", "comments": ["Python 3 introduces a distinction between the \"r\" and \"rb\" modes for [opening a file](https://docs.python.org/3/library/functions.html#open). Using the \"r\" mode will cause Python to interpret the file contents as text&mdash;in your case (and the common case) using an UTF-8 encoding&mdash;but the error message indicates that data is binary format (presumably some image format, based on your variable name). Changing the code to use the mode \"rb\"  should fix the problem and work in both versions of Python:\r\n\r\n```python\r\nimage_data = tf.gfile.FastGFile(filename, 'rb').read()\r\n```", "def read_pickle_from_file(filename):\r\n  with tf.gfile.Open(filename, 'rb') as f:\r\n    data_dict = pickle.load(f)\r\n  return data_dict\r\nfile_name = './cifar-10-batches-py/data_batch_1'\r\nUnicodeDecodeError: 'ascii' codec can't decode byte 0x8b in position 6: ordinal not in range(128)", "JUST change it.\r\n\r\nwith tf.gfile.Open(filename, 'r') as f:\r\n    data_dict = cPickle.load(f)\r\nto\r\n  with open(filename, 'rb') as f:\r\n    data_dict = cPickle.load(f, encoding='bytes')\r\n\r\nimportant thing is mode 'rb' and encoding='bytes'\r\nIf you working on some open sources, you will encounter additional errors about the variable type. \r\nBut the problems are easier to manage than this file open and encoding problem, so it's a good idea to fix this way.\r\n\r\nI had done with in CIFAR 10 python code. which is:\r\nhttps://github.com/dndusdndus12/models/tree/master/tutorials/image/cifar10_estimator\r\ngenerate_cifar10_tfrecords.py", "I'm sorry I fixed it with rb as well. my error log was from another code", "@mrry comment solved my problem. :)"]}, {"number": 11311, "title": "AttributeError: 'Tensor' object has no attribute 'assign_add'", "body": "I'm trying to use \"assign_add\" : \r\nhttps://www.tensorflow.org/api_docs/python/tf/assign_add\r\n\r\nmy code : \r\naccum_ops = tf.assign_add(accum_grad, grad, name=name)\r\n\r\nOutput ; \r\nAttributeError: 'Tensor' object has no attribute 'assign_add'\r\n\r\nHas the name changed ?\r\n", "comments": ["Please show me the `version` of `TensorFlow`:\r\n\r\n```python\r\nimport tensorflow as tf\r\nprint tf.__version__\r\n```", ">>> import tensorflow as tf\r\n>>> print tf.__version__\r\n1.2.1", "As this method defined:\r\n\r\n```python\r\ntf.assign_add\r\n\r\nassign_add(\r\n    ref,\r\n    value,\r\n    use_locking=None,\r\n    name=None\r\n)\r\n```\r\n\r\n**Args:**\r\n\r\n- ref: A mutable Tensor.\r\n\r\nSo `accum_grad` must be reference-typed.\r\n\r\n> The most common way to create a reference-typed tensor is to define a tf.Variable\r\n\r\nFrom [stackoverflow](https://stackoverflow.com/a/37959933/3167471)", "If the statement `accum_ops = tf.assign_add(accum_grad, grad, name=name)` yields the error `AttributeError: 'Tensor' object has no attribute 'assign_add'`, then I'm betting that you've accidentally created a tensor called `tf`, which has overwritten the module alias `import tensorflow as tf`. Such are the joys of a dynamic language like Python! The solution would be to rename that tensor to something other than `tf`.\r\n\r\nFeel free to reopen if I'm wrong here....", "@Nicolas99-9 How did you fix it? I have the same issue", "@swethmandava As here referred : https://github.com/tensorflow/tensorflow/issues/30468\r\nI change the \r\n`tf.assign_add()`\r\nwith\r\n` tf.compat.v1.assign_add()`"]}, {"number": 11310, "title": "My problem---tensor-flow connect with Windows IIS?Hello,i just ask a question three days ago, but no response,can you spend some time to reply me?", "body": "I set up a tensorflow system, use flask grammar to set up . And in local computer, all run ok, no error.\r\nBut when I mount it in IIS, as Web API to use, It always show FASTCGI error. Does tensorflow incompatiable with IIS?", "comments": ["Sorry i don't understand \r\n\r\n> mount it in IIS, as Web API to use\r\n\r\ncan you show me an `example` with more details?", "I am not sure what do you mean by web API.\r\ntensorflow does not have any web API.\r\n\r\nWith the little amount of information provided, we have no idea how to help out.\r\nI will close this issue. But please feel free to file a new issue, and this time make sure to provide all the information required by the template.", "Sorry, i just have time to reply you. Thanks for replying me.\r\nI means I use Flask to call tensor-flow py. And mount Flask to windows IIS. Local run ok. But in IIS will show FastCgi error. Check local run is ok,no error. But when in IIS, when i import keras, it will show fastcgi error. but when don't import keras, it will ok. If tensor-flow isun-incompatible with IIS?\r\n![image](https://user-images.githubusercontent.com/22673941/28155106-ad5993c6-67df-11e7-8213-1ebd62ee9772.png)\r\n![image](https://user-images.githubusercontent.com/22673941/28155154-f8f86406-67df-11e7-8df8-8c980d042834.png)\r\n![image](https://user-images.githubusercontent.com/22673941/28155181-1faf8642-67e0-11e7-98f8-a3c8dbb15f85.png)\r\n![image](https://user-images.githubusercontent.com/22673941/28155934-3ccda850-67e3-11e7-94e4-feeb92533f87.png)\r\n![image](https://user-images.githubusercontent.com/22673941/28157236-6a36720e-67e8-11e7-807f-31fdbe7e7196.png)\r\n![image](https://user-images.githubusercontent.com/22673941/28157302-a0157e42-67e8-11e7-987c-165e227e618c.png)\r\n![image](https://user-images.githubusercontent.com/22673941/28157368-d98ddc8c-67e8-11e7-82a0-1a90c0208534.png)\r\n", "We do not have direct support for neither Flask, or use with IIS. The issue you are seeing seems to be coming from these.\r\nIf everything runs OK locally, there does not seem to be any issues with running/installing TF.\r\n\r\nI recommend reaching out to developers of flask, or Microsoft for support with these components."]}, {"number": 11309, "title": "Mixture of multivariate distributions", "body": "Consider a mixture of 2-dimensional Gaussians in TensorFlow:\r\n```python\r\nds = tf.contrib.distributions\r\n\r\ncat = ds.Categorical(probs=[0.3, 0.2, 0.5])\r\ncomps = [ds.MultivariateNormalDiag(loc=[-5.0, -5.0], scale_diag=tf.ones(2)),\r\n         ds.MultivariateNormalDiag(loc=[0.0, 0.0], scale_diag=tf.ones(2)),\r\n         ds.MultivariateNormalDiag(loc=[5.0, 5.0], scale_diag=tf.ones(2))]\r\n\r\nmix = ds.Mixture(cat=cat, components=comps)\r\n```\r\nThis works because each `MultivariateNormalDiag` distribution has a batch shape of `()`. It is compatible with the `Categorical`'s batch shape.\r\n\r\nNow consider a mixture of 2-dimensional Bernoulli's, or Gamma's, or Laplace, or StudentT's. We need an equivalent `MultivariateBernoulli`, `MultivariateGamma`, etc. distribution which allows us to fix the batch shape and increase the event shape.\r\n\r\nAre there plans to make such distributions available? \r\n\r\nWhat about edge cases such as a matrixvariate (k-variate) Bernoulli, where additional parameter dimensions determine the batch shape and the event shape is fixed at 2 (k)?\r\n\r\n@ebrevdo , @jvdillon. Issue motivated by https://github.com/blei-lab/edward/issues/686.", "comments": ["@ebrevdo can you comment on this if you have a chance?", "@jvdillon Do you think `ds.Independent` is the answer to this problem?", "If youre ok with all elements being independent, then yes I believe `Independent` is what you want.  If you'd like to induce correlation, then you can, eg, used `TransformedDistribution` with the `Affine` bijector.", "@jvdillon I'd like to implement a `MultivariateBernoulli` with induced correlations as mentioned in your last comment. I'm not too familiar with the `tfp`, but I've found an example from [here](https://arxiv.org/pdf/1711.10604.pdf):\r\n\r\n\r\n```\r\nvector_laplace = tfd.TransformedDistribution(\r\n                                              distribution=tfd.Laplace(loc=0., scale=1.),\r\n                                              bijector=tfb.Affine(\r\n                                                                    shift=tf.Variable(tf.zeros(d)),\r\n                                                                    scale_tril=tfd.fill_triangular(\r\n                                                                                             tf.Variable(tf.ones(d*(d+1)/2))\r\n                                                                    )\r\n                                              ),\r\n                                              event_shape=[d]\r\n)\r\n```\r\n\r\nUnfortunately, the `tfb.Affine` class seems to have been deprecated. Is this just composed by chaining `tfb.Shift` and `tfb.Scale`. If not, how would this be replicated with the current TFP API?\r\n\r\nAlso, the `tfb.Scale` class doesn't take a lower triangle covariance matrix for the scale parameter, does this change the parameterization and optimization of this distribution?\r\n\r\nThanks!\r\n"]}, {"number": 11308, "title": "Reading data from GCS, processing hangs indefinitely", "body": "\r\n### System information\r\n- Using the ml engine example here: https://github.com/GoogleCloudPlatform/cloudml-samples/tree/master/census/estimator/trainer\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OSX 10.11.5\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.1.0\r\n- **Python version**: 2.7.12\r\n\r\n### Describe the problem\r\nThis code runs fine if I point it to local data. It also runs fine if I point it to the public dataset gs://cloudml-public/census/data/adult.data.csv in the instructions. However, when I make a copy of that public dataset and store it in my own GCS bucket the code just hangs after listing these common warnings:\r\n```\r\n2017-07-05 16:14:50.392729: W tensorflow/core/platform/cpu_feature_guard.cc:45] The \r\nTensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your \r\nmachine and could speed up CPU computations.\r\n2017-07-05 16:14:50.392761: W tensorflow/core/platform/cpu_feature_guard.cc:45] The \r\nTensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-05 16:14:50.392767: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-05 16:14:50.392772: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-07-05 16:14:50.392776: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n```\r\nI am assuming the issue is permissions related or that the file can't be found but rather than failing or giving an error it just runs indefinitely. I'm not entirely sure if this is happening during the string_input_producer step, the read_up_to step or even as part of the shuffle_batch. It seems like a bug that nothing is causing the code to fail.\r\n\r\n    files = tf.concat([\r\n      tf.train.match_filenames_once(filename)\r\n      for filename in filenames\r\n    ], axis=0)\r\n\r\n    filename_queue = tf.train.string_input_producer(\r\n        files, num_epochs=num_epochs, shuffle=shuffle)\r\n    reader = tf.TextLineReader(skip_header_lines=skip_header_lines)\r\n\r\n    _, rows = reader.read_up_to(filename_queue, num_records=batch_size)\r\n    # DNNLinearCombinedClassifier expects rank 2 tensors.\r\n    row_columns = tf.expand_dims(rows, -1)\r\n    columns = tf.decode_csv(row_columns, record_defaults=CSV_COLUMN_DEFAULTS)\r\n    features = dict(zip(CSV_COLUMNS, columns))\r\n\r\n    # Remove unused columns\r\n    for col in UNUSED_COLUMNS:\r\n      features.pop(col)\r\n\r\n    if shuffle:\r\n      # This operation maintains a buffer of Tensors so that inputs are\r\n      # well shuffled even between batches.\r\n      features = tf.train.shuffle_batch(\r\n          features,\r\n          batch_size,\r\n          capacity=batch_size * 10,\r\n          min_after_dequeue=batch_size*2 + 1,\r\n          num_threads=multiprocessing.cpu_count(),\r\n          enqueue_many=True,\r\n          allow_smaller_final_batch=True\r\n      )\r\n\r\n", "comments": ["As a first step, perhaps you could use tf.print() to figure out where the code is hanging? ", "I think I've narrowed it down. It's actually hanging on this code:\r\n```\r\nfiles = tf.concat([\r\n  tf.train.match_filenames_once(filename)\r\n  for filename in filenames\r\n], axis=0)\r\n```\r\nIf I remove the code, then the program is able to run with the data in my bucket. But I don't see anything in the source code to suggest why it's getting stuck. ", "I agree that none of the primitives you're invoking ought to hang.\r\n\r\nCan you chop things up further, and isolate which of the filename values in filenames is causing train.match_filenames_once() to hang up? The particular filename might tell us something useful. ", "Sorry about the delay! Easy to narrow down as only one file was being sent in. It's a copy of the census file placed in my own bucket instead of the public bucket it was originally in. This was the public file location: gs://cloudml-public/census/data/adult.data.csv. When calling the script with this location there was no hang but when calling it in the exact same way but altering the bucket name and folder to point to my own bucket the issue surfaced.", "@dobbysock1002 , please close the issue if it is resolved (as it seems to be). Thanks!", "This issue is automatically closed due to lack of activity. Please re-open if this is still an issue for you. Thanks!", "ETA for this fix?"]}, {"number": 11307, "title": "Feature are incompatible with given information in evaluate() using contrib.learn.SVM", "body": "Code is as follows:\r\n```\r\ndef svm_tf(file):\r\n\tX,Y,training_size, index = process_data(file)\r\n\tdef input_fn():\r\n\t\treturn {\r\n              'example_id': tf.constant(index[:training_size]),\r\n              'multi_dim_feature': tf.constant(X[:training_size].values.tolist()),\r\n        }, tf.constant(Y[:training_size])\r\n\r\n\tfeature_columns = [tf.contrib.layers.real_valued_column(\"multi_dim_feature\",dimension=4)]\r\n\tsvm = learn.SVM(feature_columns=feature_columns,\r\n\t\t\t\t\tl1_regularization=0.0,\r\n\t\t\t\t\tl2_regularization=1.0,\r\n\t\t\t\t\texample_id_column='example_id')\t\r\n\tsvm.fit(input_fn=input_fn,steps=50)\r\n\r\n        def test_input():\r\n\t\treturn{\r\n\t\t'example_id': tf.constant(index[training_size:]),\r\n\t\t'features': tf.constant(X[training_size:].values.tolist())\r\n\t\t}, tf.constant(Y[training_size:])\r\n\t \r\n\r\n\taccuracy = svm.evaluate(input_fn=test_input,steps=1)['accuracy']\r\n\tprint('\\nAccuracy :{0:f}\\n'.format(accuracy))\r\n```\r\n\r\n\t\r\n\t\r\n\r\n\r\nHowever, when I run the program, it runs into error as follows:\r\n```\r\nTraceback (most recent call last):\r\n  File \"subscriber.py\", line 84, in <module>\r\n    svm_tf(file)\r\n  File \"subscriber.py\", line 75, in svm_tf\r\n    accuracy = svm.evaluate(input_fn=test_input,steps=1)['accuracy']\r\n  File \"/home/annie/.local/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 289, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/annie/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 543, in evaluate\r\n    log_progress=log_progress)\r\n  File \"/home/annie/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 827, in _evaluate_model\r\n    self._check_inputs(features, labels)\r\n  File \"/home/annie/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 757, in _check_inputs\r\n    (str(features), str(self._features_info)))\r\nValueError: Features are incompatible with given information. Given features: {'example_id': <tf.Tensor 'Const:0' shape=(1000,) dtype=string>, 'features': <tf.Tensor 'Const_1:0' shape=(1000, 4) dtype=float32>}, required signatures: {'example_id': TensorSignature(dtype=tf.string, shape=TensorShape([Dimension(4000)]), is_sparse=False), 'multi_dim_feature': TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(4000), Dimension(4)]), is_sparse=False)}.\r\n```\r\n\r\nI cannot find any relevant questions online and therefore is very lost\r\nPlease help! Thanks in advance\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 11306, "title": "adds missing \"pass\" to empty method in tf.contrib.learn.DNNClassifier doc", "body": "adds missing \"pass\" to empty method in tf.contrib.learn.DNNClassifier doc", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "Not sure how to handle the googlebot CLA label, I am a googler.\r\n\r\nupdate: added my email address per go/cla#troubleshoot", "@nickgeorge It might be easier to submit the fix from internal."]}, {"number": 11305, "title": "Branch 160981881 (DO NOT MERGE YET)", "body": "", "comments": []}, {"number": 11304, "title": "TensorFlow on Kieler Open Source und Linux Tage?", "body": "Hi,\r\n\r\nI didn't find any contact information for the TensorFlow project, so I try it here :-)\r\n\r\nWe are organising our 15th \"Kieler Open Source und Linux Tage\" (northern of Germany, www.kielux.de), a conference with 4 parallel tracks with talks and workshops and a smal exhibition for open source community projects and companies.\r\n\r\nIs there anybody who would like to hold a talk and/or give a TensorFlow workshop and/or make a booth on our event (14th - 16th September)?\r\n\r\nPlease answer by eMail to kontakt @ kilux.de .\r\n\r\nCu Hauke", "comments": ["This seems like a better request to post to the TensorFlow Discuss mailing list (https://groups.google.com/a/tensorflow.org/forum/#!forum/discuss), rather than to this issue tracking tool. Please try there, and have a great workshop!"]}, {"number": 11302, "title": "Fixed 32-bit build error in tensor_forest.", "body": "This patch fixes the build error described in #11229.", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "Fixed the CLA to include my work email in addition to my personal one. I signed it!", "Thanks for finding this!  The change actually isn't the best solution, so I'll fix this internally.  Should be committed in a day or so.", "Hi @gilberthendry,\r\n\r\nI'm not sure if you've fixed this yet, but it seems to me that \r\n``` c++\r\ntypedef Eigen::TensorMap<\r\n    Eigen::Tensor<const float, 1, 1, long>, 0>  // NOLINT(runtime/int)\r\n    SingleDimStorageType;\r\n```\r\nat `tensorflow/contrib/tensor_forest/kernels/v4/input_target.h:23`\r\nshould be replaced with:\r\n``` c++\r\ntypedef Eigen::TensorMap<\r\n    Eigen::Tensor<const float, 1, 1, Eigen::DenseIndex>, 0>  // NOLINT(runtime/int)\r\n    SingleDimStorageType;\r\n```\r\nto match\r\n``` c++\r\ntemplate <typename T, int NDIMS = 1, typename IndexType = Eigen::DenseIndex>\r\nstruct TTypes {\r\n// Rank-<NDIMS> tensor of scalar type T.\r\ntypedef Eigen::TensorMap<Eigen::Tensor<T, NDIMS, Eigen::RowMajor, IndexType>,\r\nEigen::Aligned> Tensor;\r\n```\r\nat `tensorflow/tensorflow/blob/master/tensorflow/core/framework/tensor_types.h:24`\r\n\r\nBe aware `Eigen::DenseIndex` has been depreciated as of [Eigen 3.3.0](http://eigen.tuxfamily.org/index.php?title=3.3) and should be replaced by `Eigen::Index`, so it might be worth sticking `Eigen::Index` in there instead.\r\n", "Actually I replaced it with tensorflow::TTypes<float, 1>::ConstTensor, which is more portable I think.", "4de7361c43adc65c442359104a17c449a02eee7a and 14101a8ba173b44179b2a9317781f140eb61b0a1 seems to have fixed this issue for me, I managed to successfully compile and run Tensorflow on a 32-bit Raspberry Pi 3. Cheers @gilberthendry for fixing this bug!", "Yes, thanks @gilberthendry! I'm closing my pull request now"]}]