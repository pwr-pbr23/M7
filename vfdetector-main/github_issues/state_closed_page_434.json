[{"number": 40847, "title": "Training has slowed down 46 times when fit on TF2.0 compared to TF1.15?", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Amazon Linux AMI 2018.03, rhel fedora\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:NA\r\n- TensorFlow installed from (source or binary):I installed via pip install tensorflow==2.0.0\r\n- TensorFlow version (use command below): 2.0.0 and 1.15.2\r\n- Python version: 3.6.10 \r\n- Bazel version (if compiling from source):NA\r\n- GCC/Compiler version (if compiling from source):NA\r\n- CUDA/cuDNN version: Cuda compilation tools: release 10.0, V10.0.130\r\n- GPU model and memory: NVIDIA Corporation GV100GL [Tesla V100 SXM2 16GB] (rev a1)\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI would like to serve my keras model with TensorFlow serving using a TensorFlow SavedModel format.  I was following TF's tutorial on how to do that at this link https://www.tensorflow.org/tfx/tutorials/serving/rest_simple.   I found out though that this requires TF2.x.  So I installed TF2.0.0 and tried to refit my model using all the same code.  However, the training time takes 46 times as long(=46 times more expensive) in TF2.0.0 as compared to TF1.15.2.  So I can't continue that path.   Obviously there have been some changes in TF2.0.0, suggesting I may need to change how I create models and fit them?  However, I don't know what I should do.\r\n**Describe the expected behavior**\r\nI expect that TF2.0.0 be able to fit models at speeds that are comparable to TF1.15.2\r\n**Standalone code to reproduce the issue**\r\nI don't know if you need to see all of the model (it is an encode-decode model for object detection).  Here is the troublesome bit and the output receive (in TF1.15.2 and TF2.0.0)\r\n```\r\n#create the model\r\nmodel = Model(input_img,d1)\r\n\r\n#review the model   \r\nmodel.summary()\r\n\r\n#Compile the model\r\nmodel.compile(optimizer=optimizer,loss=theLoss,metrics =['accuracy'])\r\n\r\n#save the only the best weights acheived during training\r\nfilepath='weights.best.hdf5'\r\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc',verbose=1,save_best_only=True,mode='max')\r\ncallbacks_list=[checkpoint]\r\n\r\ny_train = to_categorical(y_train,num_classes=2)\r\nX_train = X_train\r\n\r\n#fit model\r\nmodel.fit(X_train,y_train,validation_split=(0.15),epochs=1,batch_size=2,verbose=1,callbacks=callbacks_list,shuffle=True)\r\n```\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\nHere is the logs for the fitting of the first epoch.  First in TF1.15 and then in TF2.0.0\r\n\r\nTF1.15 (51 seconds per epoch)\r\n`\r\nTrain on 850 samples, validate on 150 samples\r\n848/850 [============================>.] - ETA: 0s - loss: 44.0265 - acc: 0.5417\r\nEpoch 00001: val_acc improved from -inf to 0.97858, saving model to weights.best.hdf5\r\n850/850 [==============================] - 50s 59ms/sample - loss: 44.0126 - acc: 0.5419 - val_loss: 37.6455 - val_acc: 0.9786\r\n`\r\n\r\nTF2.0 ( 2324 seconds per epoch.  Side note, TF2.0 skipped saving the best model weights using the checkpoint?)\r\n`\r\nTrain on 850 samples, validate on 150 samples\r\n848/850 [============================>.] - ETA: 5s - loss: 44.8913 - accuracy: 0.5424 WARNING:tensorflow:Can save best model only with val_acc available, skipping.\r\n850/850 [==============================] - 2324s 3s/sample - loss: 44.8785 - accuracy: 0.5425 - val_loss: 41.7605 - val_accuracy: 0.0883\r\n`\r\n", "comments": ["@ctmckee,\r\nCould you please provide the complete code to reproduce the issue reported here.\r\n\r\nAlso, please check if you are facing the same issue with the latest version of TensorFlow v2.2. Thanks!", "Here is the full code to reproduce.  I will try on v2.2 as well.\r\n\r\n```\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\nimport tensorflow.keras.backend as K\r\nfrom tensorflow.keras.models import Model, load_model\r\nfrom tensorflow.keras.initializers import glorot_normal, VarianceScaling,he_normal\r\nfrom tensorflow.keras.utils import to_categorical, HDF5Matrix\r\nfrom tensorflow.keras.callbacks import ModelCheckpoint\r\nfrom tensorflow.keras.layers import Dense, Flatten, Input, GlobalMaxPooling2D, Dropout, Conv2D,Activation,MaxPooling2D,Add\r\nfrom tensorflow.keras.layers import BatchNormalization, concatenate, UpSampling2D, Concatenate\r\nfrom tensorflow.keras.optimizers import Adam, Nadam, RMSprop\r\nfrom tensorflow.keras import regularizers\r\n\r\ntf.compat.v1.reset_default_graph()\r\nK.clear_session()\r\n\r\n#hyperparams\r\ninput_img = Input(shape=(512,512,1))\r\nch1=32\r\nch2=ch1*2\r\nch3=ch2*2\r\nch4 = ch3*2\r\nch5 = ch4*2\r\nks=3\r\nrg = 0.01\r\ninit = glorot_normal(seed=0)\r\nactivation = 'relu'\r\noptimizer = Adam(learning_rate=0.00001)\r\ntheLoss = 'categorical_crossentropy'\r\n\r\n#model layers\r\nxin = Conv2D(ch1,ks,padding='same',use_bias=1,kernel_initializer=init,kernel_regularizer=regularizers.l2(rg),bias_initializer='zeros')(input_img)\r\nx1 = Conv2D(ch1,ks,padding='same',use_bias=1,kernel_initializer=init,kernel_regularizer=regularizers.l2(rg),bias_initializer='zeros')(xin)\r\nx1 = Activation(activation)(x1)\r\nx1 = BatchNormalization(axis=-1)(x1)\r\nx1 = Add()([xin,x1])\r\nx1 = MaxPooling2D((2,2),padding='same')(x1) #image size = 256\r\n\r\nxin = Conv2D(ch2,ks,padding='same',use_bias=1,kernel_initializer=init,kernel_regularizer=regularizers.l2(rg),bias_initializer='zeros')(x1)\r\nx2 = Conv2D(ch2,ks,padding='same',use_bias=1,kernel_initializer=init,kernel_regularizer=regularizers.l2(rg),bias_initializer='zeros')(xin)\r\nx2 = Activation(activation)(x2)\r\nx2 = BatchNormalization(axis=-1)(x2)\r\nx2 = Add()([xin,x2])\r\nx2 = MaxPooling2D((2,2),padding='same')(x2) #image size = 128\r\n\r\nxin = Conv2D(ch3,ks,padding='same',use_bias=1,kernel_initializer=init,kernel_regularizer=regularizers.l2(rg),bias_initializer='zeros')(x2)\r\nx3 = Conv2D(ch3,ks,padding='same',use_bias=1,kernel_initializer=init,kernel_regularizer=regularizers.l2(rg),bias_initializer='zeros')(xin)\r\nx3 = Activation(activation)(x3)\r\nx3 = BatchNormalization(axis=-1)(x3)\r\nx3 = Add()([xin,x3])\r\nx3 = MaxPooling2D((2,2),padding='same')(x3) #image size = 64\r\n\r\nxin = Conv2D(ch4,ks,padding='same',use_bias=1,kernel_initializer=init,kernel_regularizer=regularizers.l2(rg),bias_initializer='zeros')(x3)\r\nx4 = Conv2D(ch4,ks,padding='same',use_bias=1,kernel_initializer=init,kernel_regularizer=regularizers.l2(rg),bias_initializer='zeros')(xin)\r\nx4 = Activation(activation)(x4)\r\nx4 = BatchNormalization(axis=-1)(x4)\r\nx4 = Add()([xin,x4])\r\nx4 = MaxPooling2D((2,2),padding='same')(x4) #image size = 32\r\n\r\nxin = Conv2D(ch5,ks,padding='same',use_bias=1,kernel_initializer=init,kernel_regularizer=regularizers.l2(rg),bias_initializer='zeros')(x4)\r\nx5 = Conv2D(ch5,ks,padding='same',use_bias=1,kernel_initializer=init,kernel_regularizer=regularizers.l2(rg),bias_initializer='zeros')(xin)\r\nx5 = Activation(activation)(x5)\r\nx5 = BatchNormalization(axis=-1)(x5)\r\nx5 = Add()([xin,x5])\r\n\r\nencoded = MaxPooling2D((2,2),padding='same')(x5) #image size = 16\r\nxu = Conv2D(ch5,(1,1),padding='valid')(encoded)\r\n\r\nx6 = concatenate([xu,encoded],axis=-1)\r\nx6 = UpSampling2D((2,2), interpolation='bilinear')(x6)                  #image size = 32\r\nx6 = Conv2D(ch5,kernel_size=(1,1),padding='same',use_bias=1,kernel_initializer=init,kernel_regularizer=regularizers.l2(rg),bias_initializer='zeros')(x6)\r\nx6 = Conv2D(ch5,ks,padding='same',use_bias=1,kernel_initializer=init,kernel_regularizer=regularizers.l2(rg),bias_initializer='zeros')(x6)\r\nx6 = Conv2D(ch5,ks,padding='same',use_bias=1,kernel_initializer=init,kernel_regularizer=regularizers.l2(rg),bias_initializer='zeros')(x6)\r\nx6 = Activation(activation)(x6)\r\nx6 = BatchNormalization(axis=-1)(x6)\r\n\r\n\r\nx7 = concatenate([x6,x4],axis=-1)\r\nx7 = UpSampling2D((2,2), interpolation='bilinear')(x7)                  #image size =  64\r\nx7 = Conv2D(ch4,kernel_size=(1,1),padding='same',use_bias=1,kernel_initializer=init,kernel_regularizer=regularizers.l2(rg),bias_initializer='zeros')(x7)\r\nx7 = Conv2D(ch4,ks,padding='same',use_bias=1,kernel_initializer=init,kernel_regularizer=regularizers.l2(rg),bias_initializer='zeros')(x7)\r\nx7 = Conv2D(ch4,ks,padding='same',use_bias=1,kernel_initializer=init,kernel_regularizer=regularizers.l2(rg),bias_initializer='zeros')(x7)\r\nx7 = Activation(activation)(x7)\r\nx7 = BatchNormalization(axis=-1)(x7)\r\n\r\n\r\nx8 = concatenate([x7,x3],axis=-1)\r\nx8 = UpSampling2D((2,2), interpolation='bilinear')(x8)                  #image size = 128\r\nx8 = Conv2D(ch3,kernel_size=(1,1),padding='same',use_bias=1,kernel_initializer=init,kernel_regularizer=regularizers.l2(rg),bias_initializer='zeros')(x8)\r\nx8 = Conv2D(ch3,ks,padding='same',use_bias=1,kernel_initializer=init,kernel_regularizer=regularizers.l2(rg),bias_initializer='zeros')(x8)\r\nx8 = Conv2D(ch3,ks,padding='same',use_bias=1,kernel_initializer=init,kernel_regularizer=regularizers.l2(rg),bias_initializer='zeros')(x8)\r\nx8 = Activation(activation)(x8)\r\nx8 = BatchNormalization(axis=-1)(x8)\r\n\r\n\r\nx9 = concatenate([x8,x2],axis=-1)\r\nx9 = UpSampling2D((2,2), interpolation='bilinear')(x9)                  #image size = 256\r\nx9 = Conv2D(ch2,kernel_size=(1,1),padding='same',use_bias=1,kernel_initializer=init,kernel_regularizer=regularizers.l2(rg),bias_initializer='zeros')(x9)\r\nx9 = Conv2D(ch2,ks,padding='same',use_bias=1,kernel_initializer=init,kernel_regularizer=regularizers.l2(rg),bias_initializer='zeros')(x9)\r\nx9 = Activation(activation)(x9)\r\nx9 = BatchNormalization(axis=-1)(x9)\r\n\r\n\r\nx10 = concatenate([x9,x1],axis=-1)\r\nx10 = UpSampling2D((2,2), interpolation='bilinear')(x10)                  #image size = 512\r\nx10 = Conv2D(ch1,kernel_size=(1,1),padding='same',use_bias=1,kernel_initializer=init,kernel_regularizer=regularizers.l2(rg),bias_initializer='zeros')(x10)\r\nx10 = Conv2D(ch1,ks,padding='same',use_bias=1,kernel_initializer=init,kernel_regularizer=regularizers.l2(rg),bias_initializer='zeros')(x10)\r\nx10 = Activation(activation)(x10)\r\nx10 = BatchNormalization(axis=-1)(x10)\r\n\r\ndecoded = Conv2D(2,(1,1),padding='valid',use_bias=1)(x10)\r\nd1 = Activation('softmax')(decoded)\r\n\r\n#create the model\r\nmodel = Model(input_img,d1)\r\n\r\n#review the model   \r\nmodel.summary()\r\n\r\n#Compile the model\r\nmodel.compile(optimizer=optimizer,loss=theLoss,metrics =['accuracy'])\r\n\r\n#save the only the best weights acheived during training\r\nfilepath='weights.best.hdf5'\r\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc',verbose=1,save_best_only=True,mode='max')\r\ncallbacks_list=[checkpoint]\r\n\r\n#fit the model\r\ny_train = to_categorical(y_train,num_classes=2)\r\nX_train=X_train\r\nmodel.fit(X_train,y_train,validation_split=(0.15),epochs=1,batch_size=2,verbose=1,callbacks=callbacks_list,shuffle=True)\r\n```", "@ctmckee,\r\nI am facing an error stating `NameError: name 'y_train' is not defined` on running the code. Could you please share the dataset and all supporting files you are using as well? Thanks!", "I cannot share the data set.  It is proprietary.  Let me see if can create a fake batch of data", "I tested on TF2.2.0 with CUDA 10.1\r\n\r\nThe time issue is resolved.  Although it still won't save my checkpoint.  I'll track that down.\r\n```\r\n425/425 [==============================] - ETA: 0s - loss: 44.4419 - accuracy: 0.5496WARNING:tensorflow:Can save best model only with val_acc available, skipping.\r\n425/425 [==============================] - 26s 62ms/step - loss: 44.4419 - accuracy: 0.5496 - val_loss: 47.7793 - val_accuracy: 0.0371\r\n```"]}, {"number": 40846, "title": "Add SaveableObjects to SavedModel.", "body": "When objects are loaded from the SavedModel, they don't retain their `_gather_saveables_for_checkpoint` functions, which can result in values not being loaded from the checkpoint.\r\n\r\nThis CL adds a field in the SavedModel proto that stores a save and restore function for each SaveableObject in each node. When loading into Python, the SaveableObjects are restored using the functions.\r\n\r\nPiperOrigin-RevId: 318512603\r\nChange-Id: I9b2b773c263703e9eb8e6114c631160ff4f7d1c1", "comments": []}, {"number": 40845, "title": "third_party/flatbuffers references missing filemirror.tensorflow.org/https://github.com/google/flatbuffers/archive/a4b2884e4ed6116335d534af8f58a84678b74a17.zip", "body": "**Describe the problem**\r\nSome of our builds are failing (but the failure is not directly related to this missing file):\r\n> WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/https://github.com/google/flatbuffers/archive/a4b2884e4ed6116335d534af8f58a84678b74a17.zip failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\n\r\nThe URL is from TensorFlow r2.2 https://github.com/tensorflow/tensorflow/blob/r2.2/third_party/flatbuffers/workspace.bzl#L11\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\n$ wget \"https://storage.googleapis.com/mirror.tensorflow.org/https://github.com/google/flatbuffers/archive/a4b2884e4ed6116335d534af8f58a84678b74a17.zip\"\r\n--2020-06-26 20:59:28--  https://storage.googleapis.com/mirror.tensorflow.org/https://github.com/google/flatbuffers/archive/a4b2884e4ed6116335d534af8f58a84678b74a17.zip\r\nResolving storage.googleapis.com (storage.googleapis.com)... 2a00:1450:4007:815::2010, 216.58.213.176, 172.217.22.144, ...\r\nConnecting to storage.googleapis.com (storage.googleapis.com)|2a00:1450:4007:815::2010|:443... connected.\r\nHTTP request sent, awaiting response... 404 Not Found\r\n2020-06-26 20:59:29 ERROR 404: Not Found.\r\n```\r\n\r\nHowever, the second URL is fine:\r\n```\r\nwget \"https://github.com/google/flatbuffers/archive/a4b2884e4ed6116335d534af8f58a84678b74a17.zip\"\r\n--2020-06-26 20:59:50--  https://github.com/google/flatbuffers/archive/a4b2884e4ed6116335d534af8f58a84678b74a17.zip\r\nResolving github.com (github.com)... 140.82.118.3\r\nConnecting to github.com (github.com)|140.82.118.3|:443... connected.\r\nHTTP request sent, awaiting response... 302 Found\r\nLocation: https://codeload.github.com/google/flatbuffers/zip/a4b2884e4ed6116335d534af8f58a84678b74a17 [following]\r\n--2020-06-26 20:59:50--  https://codeload.github.com/google/flatbuffers/zip/a4b2884e4ed6116335d534af8f58a84678b74a17\r\nResolving codeload.github.com (codeload.github.com)... 140.82.112.10\r\nConnecting to codeload.github.com (codeload.github.com)|140.82.112.10|:443... connected.\r\nHTTP request sent, awaiting response... 200 OK\r\nLength: unspecified [application/zip]\r\nSaving to: 'a4b2884e4ed6116335d534af8f58a84678b74a17.zip'\r\n\r\na4b2884e4ed6116335d534af8f58a84678b74a17.zip                                                              [   <=>                                                                                                                                                                                                                                                                   ] 564.91K   749KB/s               ^\r\n```", "comments": ["@lissyx \r\nCan you please share exact steps/commands performed before running into this issue.", "> @lissyx\r\n> Can you please share exact steps/commands performed before running into this issue.\r\n\r\n`bazel build`, and as stated above the link itself return 404, if you read the `wget`.", "I mirrored it now. Should be fixed, after a while until everything propagates", "The link should not have 2 `https` in it.", "Error introduced in adf6e22e4af83afd55e0da3caa7e7959def1e6b6, fixed in ac539cf0447b9d50841b727fb9808e30cdcd3484", "@lissyx \r\nAs the error is fixed please confirm if we may move this to closed status.", "> @lissyx\r\n> As the error is fixed please confirm if we may move this to closed status.\r\n\r\nYes, it seems fixed with this, thanks!", "Moving to closed status with confirmation.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40845\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40845\">No</a>\n"]}, {"number": 40844, "title": "Implementation of T-LSTM keras layer", "body": "This is a feature request regarding the implementation of T-LSTM cells. This feature enables taking into account time within unevenly sampled data, like medical consulting, queue arrivals, traffic flow and so on.\r\n\r\nReferences:\r\nPaper: [Patient Subtyping via Time-Aware LSTM Networks](https://www.kdd.org/kdd2017/papers/view/patient-subtyping-via-time-aware-lstm-networks)\r\n[Tensorflow implementation by the author](https://www.google.com/url?sa=t&source=web&rct=j&url=https://github.com/illidanlab/T-LSTM&ved=2ahUKEwiU2PS3lKDqAhVkGbkGHf9LDOwQFjAAegQIAxAB&usg=AOvVaw1hTrTDWbewgCVIfbk94_-j)", "comments": ["@dougzec \r\n\r\n Do you have any use case that requires the feature you are interested in? Please feel free to submit a PR if you have use cases that supports that feature.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40843, "title": "[DLPack] Fix memory leak in from_dlpack", "body": "Fixed the way on returning the PyObject*\r\nFix https://github.com/tensorflow/tensorflow/issues/40061", "comments": ["Can you now cherry-pick this into the r2.3 branch?\n\nOn Tue, Jun 30, 2020 at 10:29 PM TensorFlow Copybara <\nnotifications@github.com> wrote:\n\n> Merged #40843 <https://github.com/tensorflow/tensorflow/pull/40843> into\n> master.\n>\n> \u2014\n> You are receiving this because your review was requested.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/40843#event-3500725309>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRIXY6D6UIGZHNRBEQDRZLCR3ANCNFSM4OJQRIOQ>\n> .\n>\n\n\n-- \n - Alex\n", "@alextp Made it at https://github.com/tensorflow/tensorflow/pull/41017"]}, {"number": 40842, "title": "how can i run tensorflow in second gpu ", "body": "I am tired to make TensorFlow 2.1 to work in the second , third, fourth GPU  \r\nbut every time TensorFlow uses the first GPU \r\nI have 4 GPU and I want to train 4 model each model in different GPU \r\n\r\n**System information**\r\n- windows 10 x64 \r\n- python 3.6 \r\n- TensorFlow  2.1 \r\n- nvcc: NVIDIA (R) Cuda compiler driver\r\n Copyright (c) 2005-2019 NVIDIA Corporation\r\n Built on Fri_Feb__8_19:08:26_Pacific_Standard_Time_2019\r\n Cuda compilation tools, release 10.1, V10.1.105\r\n- GPU : Tesla K20Xm\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 441.22       Driver Version: 441.22       CUDA Version: 10.2     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla K20Xm         TCC  | 00000000:03:00.0 Off |                    0 |\r\n| N/A   29C    P8    18W / 235W |      9MiB /  5696MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla K20Xm         TCC  | 00000000:04:00.0 Off |                    0 |\r\n| N/A   26C    P8    18W / 235W |      9MiB /  5696MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  Tesla K20Xm         TCC  | 00000000:83:00.0 Off |                    0 |\r\n| N/A   22C    P8    18W / 235W |      9MiB /  5696MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  Tesla K20Xm         TCC  | 00000000:84:00.0 Off |                  N/A |\r\n| N/A   21C    P8    18W / 235W |      9MiB /  5696MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\nI tired before run jupyter notebook write this command \r\nset CUDA_VISIBLE_DEVICES=0 & jupyter notebook\r\nset CUDA_VISIBLE_DEVICES=1 & jupyter notebook\r\nset CUDA_VISIBLE_DEVICES=2 & jupyter notebook\r\nset CUDA_VISIBLE_DEVICES=3 & jupyter notebook\r\nalso inside jupyter  \r\nimport os\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,2,3\"\r\nwhat is solution please ??\r\n", "comments": ["Hi @abdoelsayed2016, in order to use multiple GPUs with Tensorflow please take a look at the [Distributed training with TensorFlow guide](https://www.tensorflow.org/guide/distributed_training). This guide walks through the distribution strategies available and shows how to use them.\r\n\r\nIf don't want to do distributed training but just want control over which device operations happen on, check out [tf.device in the guide.](https://www.tensorflow.org/guide/gpu#manual_device_placement) Note that if you have more than one GPU in your system, the GPU with the lowest ID will be selected by default. If you would like to run on a different GPU, you will need to specify the preference explicitly, [as shown here.](https://www.tensorflow.org/guide/gpu#using_a_single_gpu_on_a_multi-gpu_system)", "hi @nikitamaia  , thank for your replay \r\nI want to run each jupyter in different gpu ,\r\nin this [link ](https://www.tensorflow.org/guide/gpu#using_a_single_gpu_on_a_multi-gpu_system) , i need to change all code in jupyter to add it \r\ni need a solution to make TensorFlow use not default gpu:0", "I'm not sure I understand your question? The solution to make TF not use default gpu:0 is what is explained in that link. You have to set it explicitly. Let me know if I'm misunderstanding what you are asking about.", "Ahh I see, looks like those VarHandleOp are being executed on GPU 0. It's difficult to say much more without a minimal reproducible example, but something else you might want to try is using [tf.config.set_visible_devices](https://www.tensorflow.org/api_docs/python/tf/config/set_visible_devices) to specify which devices are visible to the runtime. This will allow you to make only 1 of your 4 GPUs available for memory allocation and operations.", "@nikitamaia \r\nthank you for your solution last link work with me ", "Glad to hear it! Closing this issue now since a solution was found."]}, {"number": 40841, "title": "Update pooling.py", "body": "Corrected output_shape formula in the docstring for tf.keras.layers.MaxPool2D", "comments": []}, {"number": 40840, "title": "Python3.9 support", "body": "Has anyone tried to build tensorflow for Python3.9? For the assembly, everything seems to go fine, except for troubles with installing some pypi packages (Maybe there is a problem in Windows, installing using .wheel passes). Almost all the necessary packages are present except for grpcio. It turns out, we just need to wait until it appears.", "comments": ["We need to wait until official release of Python 3.9 and then we need to have our dependencies (numpy, pybind, grpcio, etc.) also update.", "@skaldek \r\nPlease update as per above comment.", "> We need to wait until official release of Python 3.9 and then we need to have our dependencies (numpy, pybind, grpcio, etc.) also update.\r\n\r\nHi @skaldek Python 3.9 is officially released, so when do you plan to add 3.9 support to TensorFlow?", "As mentioned in the quote, when all of our dependencies support py3.9", "I may be wrong, but I believe this is the case:\r\n\r\n```\r\npython3.8 -m pipdeptree -p tensorflow | grep \"^  -\" | sed \"s/  - //\" | sed \"s/ \\[.*]//\" | xargs python3.9 -m pip install\r\n```\r\n\r\nwhich is essentially\r\n```\r\npython3.9 -m pip install absl-py astunparse flatbuffers gast google-pasta grpcio h5py keras-preprocessing numpy opt-einsum protobuf six tensorboard tensorflow-estimator termcolor typing-extensions wheel wrapt\r\n```\r\n\r\nworks fine for me. Am I missing anything?", "Anyone interested in updates, best follow https://github.com/tensorflow/tensorflow/issues/44485"]}, {"number": 40839, "title": "tf.io.decode_image(img, channels=3) outputs 4 channels when reading 4-channel BMP", "body": "**EDIT:** attached a sample BMP file\r\n[rgb32.zip](https://github.com/tensorflow/tensorflow/files/4845825/rgb32.zip)\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution: Windows 10\r\n- TensorFlow installed from (source or binary): binary (pip)\r\n- TensorFlow version: 2.2.0\r\n- Python version: 3.7.7\r\n\r\n**Describe the current behavior**\r\nWhen reading in a **4-channel BMP**:\r\n- `tf.io.decode_image(img, channels=3)` gives shape **(..., ..., 4) instead of (..., ..., 3)**\r\n- `tf.io.decode_bmp(img, channels=3)` gives the following error\r\n```\r\nTraceback (most recent call last):\r\n  File \"channels.py\", line 44, in <module>\r\n    loop()\r\n  File \"channels.py\", line 14, in loop\r\n    img = tf.io.decode_bmp(img, channels=3)\r\n  File \"C:\\Users\\mattchee\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_image_ops.py\", line 899, in decode_bmp\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"C:\\Users\\mattchee\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 6653, in raise_from_not_ok_status     \r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: channels attribute 3 does not match bits per pixel from file 4 [Op:DecodeBmp]\r\n```\r\n\r\nI'm following [this guide](https://www.tensorflow.org/tutorials/load_data/images#load_using_tfdata) to load images efficiently so `tf.keras.preprocessing.image.load_img(img_path, color_mode=\"rgb\")` is not an option.\r\n\r\n**Describe the expected behavior**\r\nThis is inconsistent with `tf.io.decode_image(img, channels=3)` and `tf.io.decode_png(img, channels=3)` which give shape (..., ..., 3) when reading a 4-channel PNG.\r\n\r\nBoth `tf.io.decode_image(img, channels=3)` and `tf.io.decode_bmp(img, channels=3)` would be expected to give shape (..., ..., 3) when reading in a 4-channel BMP.\r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\nimg = tf.io.read_file(img_path)\r\nimg = tf.io.decode_image(img, channels=3)\r\nprint(img.shape) # This prints (64, 127, 4)\r\n```\r\nOr\r\n```python\r\nimg = tf.io.read_file(img_path)\r\nimg = tf.io.decode_bmp(img, channels=3) # Error\r\nprint(img.shape)\r\n```", "comments": ["@mchanchee Can you share a sample bmp file to reproduce the issue?", "Can you also test with `tf-nightly`. There has been a refactoring of `tf.io.decode_image` recently which I think covers this issue too.", "Thank you for reporting the issue. It appears to be an inherent issue with `decode_bmp` op. I will look into it and loop back with updates. In the meantime, it would be helpful if you could please share the bmp file for reproducing the issue.", "Thank you for looking into it\r\n@yongtang @hyeygit  I've added a sample BMP file to the issue description.\r\n@mihaimaruseac I've tried with `tf-nightly 2.5.0-dev20200628` and got the same problem as described above.\r\n", "I've tried it with `tf-nightly 2.4.0-dev20200708` and it's all good.\r\n\r\nThank you very much for fixing the issue!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40839\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40839\">No</a>\n", "Again, thank you for reporting, also for confirming that the issue is fixed!"]}, {"number": 40838, "title": "issue with parallelizing dataset", "body": "tensorflow version: '2.1.0'\r\n\r\nI am trying the dataset pipeline from tensorflow web page: https://www.tensorflow.org/guide/data_performance. on P3.8x GPU, Amazon EC2.\r\nit is mentioned that using\r\n```\r\nbenchmark(\r\n    tf.data.Dataset.range(2)\r\n    .interleave(ArtificialDataset)\r\n)\r\n```\r\nwe can parallelize dataset, however I get a total different behavior.\r\nI increased the num_samples in given ArtificialDataset to 1000, and changed the benchmark to print the sample\r\n```\r\ndef benchmark(dataset, num_epochs=1):\r\n         start_time = time.perf_counter()\r\n         for epoch_num in range(num_epochs):\r\n             for sample in dataset:\r\n                 # Performing a training step\r\n                 tf. print(sample)\r\n                 time.sleep(0.01)\r\n         tf.print(\"Execution time:\", time.perf_counter() - start_time)\r\n```\r\nand when I run\r\n```\r\nbenchmark(\r\n         tf.data.Dataset.range(2)\r\n         .interleave(ArtificialDataset)\r\n     )\r\n```\r\nI get\r\n```\r\n[0]\r\nExecution time: 0.10175556794274598\r\n```\r\nfor \r\n```\r\nbenchmark(\r\n         tf.data.Dataset.range(4)\r\n         .interleave(ArtificialDataset)\r\n     )\r\n```\r\nI get\r\n```\r\n[0]\r\n[0]\r\n[0]\r\n[1]\r\n[1]\r\n[2]\r\nExecution time: 0.29265988897532225\r\n```\r\nwhich means it doesn't go through the whole dataset. what I am expecting based on documentation is that it should open up 2 datasets, each with 1000 samples and in parallel generates the numbers. if not how can I get this functionality using this dataset API?\r\n\r\n\r\n\r\n", "comments": ["has this been fixed?\r\nhttps://github.com/tensorflow/tensorflow/issues/19933\r\n\r\nit seems dataset API is still slow.", "@alexmil2019 \r\nCan you please try with the latest tf versions and let us know if this is still an issue.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "running on TF 2.4:\r\n\r\n benchmark(\r\n    ...:          tf.data.Dataset.range(4)\r\n    ...:          .interleave(ArtificialDataset)\r\n    ...:      )\r\n[0]\r\n[0]\r\n[0]\r\n[1]\r\n[1]\r\n[2]\r\nExecution time: 0.3579983730000009\r\n\r\nthe same!", "Hi @alexmil2019 Could you please let us know if this is still an issue in latest stable TF v2.6.0 ?Thank you!\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40838\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40838\">No</a>\n"]}, {"number": 40837, "title": "\"12 bytes lost due to alignment ...\" error on magic_wand example for SparkFun Edge", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OSX Catalina (10.15.5)\r\n- TensorFlow installed from (source or binary): source\r\n- Tensorflow version (commit SHA if source): 44f2f014e5d84e195af7de6f9d9400df3d3a00dd\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): SparkFun Edge\r\n\r\n**Describe the problem**\r\nCannot view/display any debug information from UART output but receive an error instead, using screen command: \r\n\r\n`screen ${DEVICENAME} 115200 `\r\n\r\nI also tried to explicitly substitute the actual device name, but I get the same error result. I only get this single line of output, indicating something is wrong:\r\n\r\n`12 bytes lost due to alignment. To avoid this loss, please make sure the tensor_arena is 16 bytes aligned.`\r\n\r\nNote: I have followed this same sequence (and settings) on other examples for SparkFun Edge (**Hello World** and **Person Detection**) and for both of those builds, I do get proper/expected UART debug output using screen, so this error seems specific to the magic_wand example.\r\n\r\nEvery time I then reset the board, I get this same error repeated in screen.\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\nI followed the readme instructions for the example exactly:\r\ntensorflow/lite/micro/examples/magic_wand/README.md, under the \"Deploy to SparkFun Edge\", Specifically, from the root directory cloned from GitHub, I executed these commands:\r\n\r\n```\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=sparkfun_edge magic_wand_bin\r\n\r\ncp tensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/tools/apollo3_scripts/keys_info0.py \\\r\ntensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/tools/apollo3_scripts/keys_info.py\r\n\r\npython3 tensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/tools/apollo3_scripts/create_cust_image_blob.py \\\r\n--bin tensorflow/lite/micro/tools/make/gen/sparkfun_edge_cortex-m4/bin/magic_wand.bin \\\r\n--load-address 0xC000 \\\r\n--magic-num 0xCB \\\r\n-o main_nonsecure_ota \\\r\n--version 0x0\r\n\r\npython3 tensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/tools/apollo3_scripts/create_cust_wireupdate_blob.py \\\r\n--load-address 0x20000 \\\r\n--bin main_nonsecure_ota.bin \\\r\n-i 6 \\\r\n-o main_nonsecure_wire \\\r\n--options 0x1\r\n\r\nexport BAUD_RATE=921600\r\nexport DEVICENAME=/dev/tty.usbserial-A50285BI\r\n```\r\nand then flash the binary using the boatload button sequence as described while executing this command:\r\n\r\n```\r\npython3 tensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/tools/apollo3_scripts/uart_wired_update.py \\\r\n-b ${BAUD_RATE} ${DEVICENAME} \\\r\n-r 1 \\\r\n-f main_nonsecure_wire.bin \\\r\n-i 6\r\n```\r\n\r\nAll commands seem to execute correctly, no errors displayed, and boatload process is successful. After hitting the board reset button, I get the yellow light blinking rapidly after a few seconds (I assume it is working at this point). Then, using the screen command to view UART output, I get the above error instead of the expected output of \"Magic Starts!\".\r\n", "comments": ["Hi @pfliegster,\r\nYour UART communication is working, this is where you get the error from.\r\n\r\nDid you modify `kTensorArenaSize` in the `main_functions.cc`? Try playing around with this.\r\n\r\nOtherwise you might try one of the already given Keras or TF Lite models instead of your own: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/magic_wand/train/netmodels/CNN", "@lheim  - thanks for the suggestion. I'm am quite new to this code base, so I really haven't tried to tweak anything yet, but rather just run the built-in examples as-is.\r\n\r\nHowever, following your train of thought ... looking at the definition for `kTensorArenaSize` in `main_functions.cc` for this example, I'm guessing modifications here will change the size of `tensor_arena[]`, but otherwise not directly affect it's alignment in memory ... if I understand the error correctly, I would think I need some kind of linker script command or pre-processor directive to ensure alignment of this buffer on a 16-byte boundary.\r\n\r\nCurrently `kTensorArenaSize = 60 * 1024;`, so it this buffer will naturally be a multiple of 16-bytes in size, I just don't know how to control its alignment (or fix whatever the true cause of that error message might be).\r\n\r\nSo ... just to test, I tried just adding 4, 8, and 12 to the size value, but each of these creates the same erroneous output. I suspect that this example project is just missing some alignment mechanism that is there in some of the other examples, or there is some other more intrinsic problem with this example. I'll try to dig into this a bit on my own, but hoped the TF gardeners who know the code best (or pros like yourself who have experience navigating around this code base) would have a ready solution.\r\n\r\nThanks for the idea & for the reference on training my own model too, I'll look that over.\r\n\r\n", "Dear,\r\nPlease try to Insert \"alignas(16)\" in the line that defines tensor_arena in main_functions.cc like below:\r\n  alignas(16) uint8_t tensor_arena[kTensorArenaSize];", "@kcoh7777 - Thank you! That fixed the issue ... you're a genius! I really appreciate the help.\r\n\r\nOf course, now it only recognizes \"slope\", but I think that is a different issue. Anyway, I don't know if exactly how to get the solution/fix pushed back into the git repo (or if I even have privilege to do so), but if you do - please do so. Thanks!"]}, {"number": 40835, "title": "Writable", "body": "@mihaimaruseac \r\nThis PR add all missing function to `tf_writable_file` so it contains a lot of boilerplate code. In the lastest commit https://github.com/tensorflow/tensorflow/commit/f60f6f0c1f68d729b2e501d5a0a668466acb7cda, Tensorflow add the ability to compose object instead of re-upload. It has a variable `offset` to control which offset of internal temporary file to upload. \r\n\r\nBut `UploadFile` does not allow us to set `offset`. So I choose to truncate the data in the internal temporary file after each upload ( So the next time, we will only upload the new arrived data ). This has a benefit over the old approach: keep the internal temporary file size small. But the operation `open` and `close` are a little expensive.\r\n\r\nIf this approach does not work very well, I will make a PR agains `google-cloud-cpp` to add `offset` to `UploadFile` ( this is quite simple but we will have to wait to the next release )\r\n\r\nWhat do you think ?", "comments": ["Let's do both: keep the current approach (the one in this PR, I'm going to review it soon) and also make a PR against `google-cloud-cpp`", "I forgot to truncate the `outfile` when `offset == 0`. I also use `outfile->flush()` instead of `outfile->operator<<`.\r\nAbout the PR against `google-cloud-cpp`. it is a bit more complicated when we use `ResumableUpload`. I will see if I could convince `google-cloud-cpp` maintainers to accept this feature.", "`google-cloud-cpp` maintainers have accepted the feature request. Here is the link https://github.com/googleapis/google-cloud-cpp/issues/4437"]}, {"number": 40834, "title": "class_weight based on predicted labels rather than true labels", "body": "**System information**\r\n- TensorFlow version (you are using): tensorflow 2.0\r\n- Are you willing to contribute it (Yes/No): No, I am currently unable to do so.\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nLet's stick to a two-class classification problem as an example to keep things simple so we can borrow concepts from the confusion matrix.\r\n\r\nSo I assume (since this doesn't seem to be documented) that class_weight weighs based on the true labels.\r\nIf this is the case then this would allow us to increase the recall of our model, as doing so puts more emphasis on true positives and false negatives.\r\n\r\nBut what if we want to increase precision instead? We should be able to do so by weighing classes based on the predicted labels instead, as this would put more emphasis on true positives and false positives instead. \r\n\r\n**Will this change the current api? How?**\r\n\r\nThis could be done by creating an extra parameter for the fit function called \"predicted_class_weight\".\r\nThen to avoid confusion the old \"class_weight\" should be renamed to \"true_class_weight\".\r\n\r\n**Who will benefit with this feature?**\r\n\r\nOne of the biggest drawbacks of the Keras API in its current state is that it's seemingly impossible to put emphasis on precision rather than recall.\r\n\r\nThere are numerous classification problems that require precision over recall. So this would benefit a lot of data scientists.\r\n\r\n**Any Other info.**\r\n\r\n/", "comments": ["Instead of adding a parameter, you can override the model train_step to add custom weighting there. Read more about overriding train_step here: https://keras.io/guides/customizing_what_happens_in_fit/"]}, {"number": 40833, "title": "pull", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40833) for more info**.\n\n<!-- need_sender_cla -->"]}, {"number": 40832, "title": "XLA throws an error when beta1 = 0 in Adam optimizer", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: 7.6\r\n- GPU model and memory: GTX 1070\r\n\r\n\r\n**Describe the current behavior**\r\nThrows an error when beta1 = 0.\r\n\r\n**Describe the expected behavior**\r\nNo errors.\r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://colab.research.google.com/gist/fengyang0317/26486c2740955cff9c88f7d02e9832a0/use-xla-with-tf-function.ipynb\r\n", "comments": ["I am able to replicate the issue reported, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/af24fa4f0ab41824958bb56dbfd86db5/untitled244.ipynb)", "@fengyang0317 I think this was resolved in recent `tf-nightly`. I cannot reproduce the issue with `tf-nightly`.\r\n\r\nCan you please verify once and close the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40832\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40832\">No</a>\n"]}, {"number": 40831, "title": "Post-training quantization", "body": "Hi everyone,\r\n\r\nI've recently worked with the 2 models: \"conv\" and \"low_latency_conv\" of the speech_commands example.\r\n```\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/speech_commands\r\n```\r\nI succeed to obtain respectively, 88% and 81% of testing accuracy.\r\nI'd like to use a quantization of int16 (int8 will be just as good), but I can't because of the tf.contrib.quantize function which is deprecated in tf2.0. It advises me to install tf1.15, unfortunately, I'm not allowed to install it.\r\n\r\nI've tried this solution which seems interesting:\r\n```\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\ntflite_quant_model = converter.convert()\r\n```\r\n\r\nWith a pbtxt saved model, the \"from_saved_model\" function crash with the error :\r\n```\r\nOSError: Cannot parse file saved_model.pbtxt': 1:1 : Message type \"tensorflow.SavedModel\" has no field named \"node\"..\r\n```\r\nAnd when I convert it to a frozen model (with freeze.py) to have a \"save_model.pb\", it crashes in\"converter.convert()\"\r\nwith the error:\r\n```\r\n\"ValueError: This converter can only convert a single ConcreteFunction. Converting multiple functions is under development.\"\r\n```\r\n\r\nHas anyone found a way to quantize it ?\r\n\r\nP.S.: In the description of the create_conv_model function (in models.py), I think the second layer [MaxPool] is missing in the code.\r\n\r\n**System information**\r\n- Windows 7\r\n- TensorFlow 2.1.0\r\n", "comments": ["Hi @David-LETINAUD,\r\nI'm not sure if understand your question correctly. Are you trying to save your just converted model?\r\n\r\nAs seen in your code, you're using Tensorflow Lite for this. You can save your `tflite_quant_model` by simply:\r\n```python\r\nopen('tflite_quant_model.tflite', 'wb').write(tflite_quant_model)\r\n```\r\n\r\nYou can then load this model with the Tensorflow Lite Interpreter, see more [here](https://www.tensorflow.org/lite/guide/inference#load_and_run_a_model_in_python).\r\nFor more about the quantization process, see [here](https://www.tensorflow.org/lite/performance/post_training_quantization).", "Hi @lheim,\r\nThanks for your help.\r\n\r\nI've already trained a speech recognition model with tensorflow 2.1. It gives me saved_model.pbtxt or saved_model.pb (if i convert it to a frozen model). \r\nI want to go a bit deeper and try to find the loss of accuracy between a model that stores weights in 32bits and another one with 16bits (or even 8bits).\r\nSince I can't quantify it during training (tf 1.15 missing), I tried to find a way to quantify it after training. \r\nOn the internet, I found a way to do this with tflite, which opens the tensorflow model to convert it back to a tflite model, quantify it, and then save it.\r\n\r\nThis is the little script, which is supposed to do just that:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nsaved_model_dir = \"/model_path/\"\r\n\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\ntflite_quant_model = converter.convert()\r\n```\r\n", "@David-LETINAUD \r\n\r\nIs this still an issue can you please try with the latest tf version [2.4.1] and let us know.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40831\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40831\">No</a>\n"]}, {"number": 40830, "title": "The tenorflow_framework shared object contains public HWLOC symbols. which causes HWLOC unexpected behavior it links dynamically with some other library.", "body": "**System information**\r\n- Have I written custom code: No\r\n- OS Platform and Distribution: Ubuntu 16.04, Fedora 30 (and possibly any other Linux)\r\n- TensorFlow installed from: C binary package (libtensorflow-cpu-linux-x86_64-1.14.0.tar.gz)\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version: Not applicable\r\n\r\n**Describe the current behavior**\r\n\r\nWhen I run `nm libtensorflow_framework.so.1.14.0 | grep T | grep hwloc` on Linux, I get the following output:\r\n\r\n```\r\n...\r\n00000000012d9fc0 T hwloc_bitmap_copy\r\n00000000012d9fb0 T hwloc_bitmap_dup\r\n00000000012da6e0 T hwloc_bitmap_fill\r\n00000000012dbc20 T hwloc_bitmap_first\r\n00000000012dbc90 T hwloc_bitmap_first_unset\r\n00000000012d9ea0 T hwloc_bitmap_free\r\n...\r\n00000000012e78a0 T hwloc_topology_insert_group_object\r\n00000000012e7a50 T hwloc_topology_insert_misc_object\r\n00000000012e7110 T hwloc_topology_is_thissystem\r\n00000000012e7b00 T hwloc_topology_load\r\n00000000012e5bf0 T hwloc_topology_reconnect\r\n00000000012e8330 T hwloc_topology_restrict\r\n...\r\n```\r\nAnd many other publicly available HWLOC interfaces that are included in` tenorflow_framework.so` as public symbols.\r\n\r\nSo when some application linked with TensorFlow and some other library that dynamically links with HWLOC, then part of HWLOC interfaces calls located inside `libhwloc.so` but other interfaces located inside `tensorflow_framework.so` shared object. \r\n\r\nLibraries dependencies structure:\r\n\r\n![tensorflow+hwloc](https://user-images.githubusercontent.com/22097249/85857265-2de8ee80-b7c2-11ea-823e-600e2840f4e6.png)\r\n\r\nFor example, when the library(\"Some Lib\" on the scheme) call `hwloc_topology_init` then it goes to the HWLOC library located inside `tensorflow_framework.so`. But when it calls the `hwloc_topology_get_complete_cpuset` method, then it goes to the shared HWLOC library. This means that we have two instances of HWLOC library which are divided between two shared objects.\r\n\r\nThis situation causes HWLOC unexpected behavior inside other libraries (e.g. the \"Some Lib\" library on the scheme).\r\n\r\n**Describe the expected behavior**\r\n\r\nThe expected behavior is to not deliver any HWLOC interfaces as part of public interface of the TensorFlow shared object.\r\n\r\n**Standalone code to reproduce the issue:**\r\n\r\nTo reproduce this issue, we need at least two source code files: for the application and for the library.\r\n\r\nsome_lib.cpp:\r\n```c++\r\n#include <iostream>\r\n#include <hwloc.h>\r\n\r\nvoid print_bitmap(hwloc_const_bitmap_t bitmap) {\r\n    if (bitmap == NULL) {\r\n        printf(\"mask is: NULL\\n\");\r\n        return;\r\n    }\r\n    char* buf = new char[256];\r\n    hwloc_bitmap_snprintf(buf, 256, bitmap);\r\n    printf(\"mask is: %s\\n\", buf);\r\n    delete [] buf;\r\n}\r\n\r\nextern void print_topology_info() {\r\n    hwloc_topology_t topology;\r\n    hwloc_cpuset_t   process_cpu_affinity_mask;\r\n    hwloc_nodeset_t  process_node_affinity_mask;\r\n\r\n    // Parse topology\r\n    hwloc_topology_init( &topology );\r\n    hwloc_topology_load( topology );\r\n\r\n    // Getting process affinity mask\r\n    process_cpu_affinity_mask  = hwloc_bitmap_alloc();\r\n    process_node_affinity_mask = hwloc_bitmap_alloc();\r\n\r\n    hwloc_get_cpubind(topology, process_cpu_affinity_mask, 0);\r\n    hwloc_cpuset_to_nodeset(topology, process_cpu_affinity_mask, process_node_affinity_mask);\r\n\r\n    print_bitmap(process_cpu_affinity_mask);\r\n    print_bitmap(process_node_affinity_mask);\r\n    printf(\"Complete:\\n\");\r\n    print_bitmap(hwloc_topology_get_complete_cpuset(topology));\r\n    print_bitmap(hwloc_topology_get_complete_nodeset(topology));\r\n    printf(\"Allowed:\\n\");\r\n    print_bitmap(hwloc_topology_get_allowed_cpuset(topology));\r\n    print_bitmap(hwloc_topology_get_allowed_nodeset(topology));\r\n}\r\n```\r\n\r\napplication.cpp:\r\n```\r\n#include <iostream>\r\n\r\nextern void print_topology_info();\r\n\r\nint main() {\r\n    print_topology_info();\r\n}\r\n```\r\n\r\nBuild steps:\r\n```\r\n# another compiler is also applicable\r\ng++ -c -fpic some_lib.cpp\r\ng++ -shared -o some_lib.so some_lib.o -lhwloc\r\n\r\ng++ application.cpp -o some_app -ltensorflow some_lib.so\r\n```\r\nOutput:\r\n```\r\nmask is: 0x000000ff\r\nmask is: 0x0\r\nComplete:\r\nmask is: NULL\r\nmask is: 0x00000001\r\nAllowed:\r\nmask is: 0x000000ff\r\nmask is: 0x00000001\r\n```\r\n\r\nExpected output:\r\n```\r\nmask is: 0x000000ff\r\nmask is: 0xf...f\r\nComplete:\r\nmask is: 0x000000ff\r\nmask is: 0xf...f\r\nAllowed:\r\nmask is: 0x000000ff\r\nmask is: 0xf...f\r\n```\r\n\r\n**Other info/logs** :\r\n\r\nProofs of different HWLOC interfaces location:\r\n\r\nHere is some information that was obtained via GDB during application debugging:\r\n\r\nShared objects location:\r\n```\r\n0x00007fffecdf1430  0x00007fffece1869a - tbbbind -> hwloc\r\n0x00007fffed750e80  0x00007fffee5971b4 - libtensorflow_framework.so.1 (static hwloc)\r\n```\r\nMethod addresses (can be easily correlated with corresponding shared object):\r\n```\r\n0x7fffecdf66a0 <hwloc_topology_init> - tbbbind -> hwloc\r\n0x7fffecdf80c0 <hwloc_topology_load> - tbbbind -> hwloc\r\n0x7fffecdfe2a0 <hwloc_get_cpubind>   - tbbbind -> hwloc\r\n0x7fffeef4d6c8 <hwloc_cpuset_to_nodeset(hwloc_topology_t, hwloc_const_cpuset_t, hwloc_nodeset_t)> - libtensorflow_framework.so.1 (static hwloc)\r\n0x7fffeef4d644 <hwloc_topology_get_complete_cpuset(hwloc_topology_t)> - libtensorflow_framework.so.1 (static hwloc)\r\n0x7fffeef4d686 <hwloc_topology_get_complete_nodeset(hwloc_topology_t)> - libtensorflow_framework.so.1 (static hwloc)\r\n0x7fffeef4d665 <hwloc_topology_get_allowed_cpuset(hwloc_topology_t)> - libtensorflow_framework.so.1 (static hwloc)\r\n0x7fffeef4d6a7 <hwloc_topology_get_allowed_nodeset(hwloc_topology_t)> - libtensorflow_framework.so.1 (static hwloc)\r\n```\r\n\r\n**Workaround:**\r\nAdd `-lhwloc` flag to application compilation string to directly link the HWLOC shared object. After this change, all HWLOC interfaces will be located within the HWLOC shared object.\r\n", "comments": ["Can you try with master/2.2/1.15 instead of 1.14? 1.14 has been released in a somewhat broken state and is no longer in the support window", "Paul was working on this before he left. He added hwloc dependency instead of libnuma.\r\n@guptapriya do you know who works with tensorflow sig-networking, and multi-CPU efforts?\r\n\r\nI think the main question is if we need the hwloc symbols exported by TF libraries to be used by ops/kernels, potentially collectives?", "@mihaimaruseac looks like TensorFlow 1.15 does not contain such public symbols and I cannot reproduce this issue with this version of the TensorFlow library.", "Thank you @ivankochin for checking. Can your application use 1.15?", "@mihaimaruseac ,\r\n\r\nI am a member of the team that develops the library that links with HWLOC dynamically. In the scheme below our library may be associated with the \"Some Lib\" element. \r\n\r\nWe have no dependency on the TensorFlow library, but one of our customers affected by this unexpected behavior with Tensorflow 1.14, and the customer isn't able to update the TensorFlow version now.", "Unfortunately we cannot update TF 1.14 either as it is outside the support window, per our patch policy.", "@gunan - I think @dubey is works with the SIG networking, among others. ", "@dubey could you take a look at this issue? Should we be exporting hwloc symbols? ", "Hi Gunan, I checked with Ayush, he is not deeply involved in the NUMA effort as well as SIG networking.\r\n\r\nIs there any way to check if this hwloc symbols is used by anyone? Maybe removing it and see it breaks?", "Goldie, Could you help us find the SIG networking contact for this issue?", "@gunan It is an issue that has been fixed a long time ago (since 1.15 I think). See https://github.com/tensorflow/tensorflow/pull/29807 for more details.", "Thank you very much for the information @byronyi And as far as I can see, the report is about 1.14. So, the solution is to use a newer version of TF.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40830\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40830\">No</a>\n"]}, {"number": 40829, "title": "Different depth wise convolution for different images in the batch", "body": "Hello, I have a situation where I want to apply different depth wise convolutions to different image in a samples batch.\r\nLets say I have a batch of N images of shape (H x W x C) and N depthwise conv2d filter of shape (K x K x C x 1) I want to apply each one of these N convolutions to each one of the images. Normally, we can do this with tf.unstack along axis 0 on the batch of image and the convolution kernels volume and then process each of images apart using tf.nn.deptwise_conv2d and use tf.concat to build the final result. However, I can't do this cause N is the batch size inside a kerase layer so its value is unkown before compiling the model. Can you suggest a solution or make a version of tf.nn.deptwise_conv2d that supports seperate convolution kernels for separate images?", "comments": ["Hello again,\r\n\r\nIt turns out we can achieve this uisng current Tensorflow operations, I was able to hack this by using tf.unstack on the channels dimension and then using data_format='NCHW':\r\n\r\n```\r\nkernels = tf.expand_dims(kernels , 4) # (C x K x K x N x 1)\r\nkernels = tf.unstack(onehot_2d, axis=0) # [(K x K x N x 1)] * C\r\nsamples = tf.unstack(tf.expand_dims(input_tensor, 0), axis=4) # [(1 x N x Hx W)] * C\r\nfiltered = [tf.nn.depthwise_conv2d(sample, kernel, [1, 1, 1, 1], 'VALID', data_format='NCHW') \r\n                 for (sample, kernel) in zip(samples, kernels)] # [(1 x N x P x P)] * C\r\noutput = tf.concat(filtered, axis=0) # (C x N x P x P)\r\nreturn tf.transpose(output, perm=[1, 2, 3, 0]) # (N x P x P x C)\r\n```"]}, {"number": 40828, "title": "TF Chat Room", "body": "Added the [TensorFlow Chat Room on Stackoverflow](https://chat.stackoverflow.com/rooms/216694/tensorflow) URL in the resources section.", "comments": ["I'm unsure where we draw the line on what we include in the README and what not. Adding @martinwicke  for policy", "The initial commit (f5d859777b3340319d44cc4f8897cad9039d0ddd) is fine, although we should add something like \"(not actively monitored by the TensorFlow team)\". \r\n\r\n@theadactyl where do you think this pointer would be best? I'm actually thinking the community site: https://www.tensorflow.org/community/forums, rather than resources, which seems to be more about consumable content than interactive forums.", "But yeah, the other two commits look like a mistake to me.", "@martinwicke @mihaimaruseac The other two commits are indeed a mistake, I messed up my TensorFlow fork branches while working on another contribution to the repo, I will fix this.", "@martinwicke @mihaimaruseac I have fixed the accidental commits. I apologize yet again for this confusion.", "LGTM\n\nOn Tue, Jun 30, 2020 at 10:16 AM Mihai Maruseac <notifications@github.com>\nwrote:\n\n> *@mihaimaruseac* approved this pull request.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/40828#pullrequestreview-440227196>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ABREJVPWU5U6URIBVIEGUITRZIMV7ANCNFSM4OJIYOCQ>\n> .\n>\n"]}, {"number": 40827, "title": "Incorrect TF nightly version", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version: 2.3\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): \r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n`pip install tf-nightly` installs TF v2.5. Shouldn't it be TF v2.3???\r\n\r\nPyPI link - https://pypi.org/project/tf-nightly-gpu/2.5.0.dev20200626/\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\n```\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@AjayReyo Due to some simple mistake in the TF build code, `TF2.5` version ( https://pypi.org/project/tf-nightly-gpu/2.5.0.dev20200626/) was created. Correct version is adjusted back to `TF2.4dev` (https://pypi.org/project/tf-nightly/2.4.0.dev20200630/ ).\r\n\r\nAs next stable version is `TF2.3`, the `tf-nightly` is `TF2.4dev2020MMDD` (MM, DD- two digits for month and day respectively)\r\n\r\n\r\nSo if you run\r\n\r\n```\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\n```\r\n\r\nThe output will show correctly as `2.4.0-dev20200630`. Sorry for the confusion. Thanks!\r\n\r\nPlease close the issue if this was resolved for you. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "This has been resolved.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40827\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40827\">No</a>\n"]}, {"number": 40826, "title": "Invalid argument: Input to reshape is a tensor with 4300800 values, but the requested shape has 19268370432", "body": "Please make sure that this is a bug. As per our\r\nGitHub Policy,\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template\r\n\r\nSystem information\r\n\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): 20.04\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -\r\nTensorFlow installed from (source or binary): source\r\nTensorFlow version (use command below): 2.2.0\r\nPython version: 3.8\r\nBazel version (if compiling from source): 2.0\r\nGCC/Compiler version (if compiling from source): 9.3.0\r\nCUDA/cuDNN version:\r\nGPU model and memory: Radeon VII\r\n\r\nHi,\r\n\r\nI am using bert-for-tf2 over tensorflow 2.2.0,  keras 2.4.3, and the AMD rocm 3.5.1 environment, and sometimes I get an error like the following one:\r\n\r\nFile \"bert-decept.py\", line 543, in\r\nhistory = fit_model(model, data, BATCH_SIZE, EPOCHS, tensorboard_callback, model_checkpoint_callback,\r\nFile \"bert-decept.py\", line 438, in fit_model\r\nhistory = model.fit(\r\nFile \"/home/papadako/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py\", line 766, in fit\r\nreturn func.fit(\r\nFile \"/home/papadako/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_arrays.py\", line 649, in fit\r\nreturn fit_loop(\r\nFile \"/home/papadako/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_arrays.py\", line 386, in model_iteration\r\nbatch_outs = f(ins_batch)\r\nFile \"/home/papadako/.local/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\", line 3631, in call\r\nfetched = self._callable_fn(*array_vals,\r\nFile \"/home/papadako/.local/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1470, in call\r\nret = tf_session.TF_SessionRunCallable(self._session._session,\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\r\n(0) Invalid argument: Input to reshape is a tensor with 4300800 values, but the requested shape has 19268370432\r\n[[{{node bert_1/encoder/layer_7/attention/self/query/Tensordot}}]]\r\n[[Func/training_2/AdamW/gradients/gradients/bert_1/encoder/layer_7/output/dropout_62/cond_grad/StatelessIf/then/_11515/input/_23174/_9837]]\r\n(1) Invalid argument: Input to reshape is a tensor with 4300800 values, but the requested shape has 19268370432\r\n[[{{node bert_1/encoder/layer_7/attention/self/query/Tensordot}}]]\r\n0 successful operations.\r\n0 derived errors ignored.\r\n\r\nor\r\n\r\nFile \"bert-decept.py\", line 543, in\r\nhistory = fit_model(model, data, BATCH_SIZE, EPOCHS, tensorboard_callback, model_checkpoint_callback,\r\nFile \"bert-decept.py\", line 438, in fit_model\r\nhistory = model.fit(\r\nFile \"/home/papadako/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py\", line 766, in fit\r\nreturn func.fit(\r\nFile \"/home/papadako/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_arrays.py\", line 649, in fit\r\nreturn fit_loop(\r\nFile \"/home/papadako/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_arrays.py\", line 386, in model_iteration\r\nbatch_outs = f(ins_batch)\r\nFile \"/home/papadako/.local/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\", line 3631, in call\r\nfetched = self._callable_fn(*array_vals,\r\nFile \"/home/papadako/.local/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1470, in call\r\nret = tf_session.TF_SessionRunCallable(self._session._session,\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\r\n(0) Invalid argument: Size 0 must be non-negative, not -1737945760\r\n[[{{node bert/encoder/layer_5/attention/self/query/Tensordot/Reshape}}]]\r\n[[Func/training/AdamW/gradients/gradients/bert/encoder/layer_9/output/dropout_30/cond_grad/StatelessIf/then/_696/input/_2295/_3389]]\r\n(1) Invalid argument: Size 0 must be non-negative, not -1737945760\r\n[[{{node bert/encoder/layer_5/attention/self/query/Tensordot/Reshape}}]]\r\n\r\nAt least in my non-experienced eyes it seems like an invalid pointer reference. The error does not happen for the CPU backend. Does anyone have any idea/insight about what might be the problem? Is there any other information that I could probably provide to solve this? I have also reported this in the rocm tensorflow repo https://github.com/ROCmSoftwarePlatform/tensorflow-upstream/issues/1026\r\n\r\nBest regards\r\nPanagiotis", "comments": ["@papadako,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the dataset you are using. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "This is probably a rocm problem which is currently discussed in https://github.com/ROCmSoftwarePlatform/tensorflow-upstream/issues/1026\r\nSo I am closing this", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40826\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40826\">No</a>\n"]}, {"number": 40825, "title": "Quantized tflite model's inference slower than the un-quantized tflite model on Raspberry Pi", "body": "**Issue** \r\nI have two keras models, named as model1.h5 and model2.h5.\r\n\r\n- They are converted into tflite model, named as model1.tflite and model2.tflite through code:\r\n\r\n```\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_model = converter.convert()\r\n```\r\n\r\n- They are quantized and converted into tflite model, named as quanmodel1.tflite and quanmodel2.tflite through code:\r\n```\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model) \r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\ntflite_quant_model = converter.convert()\r\n```\r\nWhen I run the four tflite models on Raspberry Pi for inference, I find the inference speed per image (listed below) is strange:\r\n\r\n- model1.tflite (model size 240 KB) -- 0.1s;\r\n- quanmodel1.tflite (model size 68KB) -- 0.2s;\r\n- model2.tflite (model size 1990 KB) -- 0.17s;\r\n- quanmodel2.tflite (model size 514 KB) -- 0.1s.\r\n\r\nWhy the inference speed of model1.tflite is faster than that of quantized model (quanmodel1.tflite) while model2.tflite is slower than that of quanmodel2.tflite?", "comments": ["@pkb14197 \r\nPlease provide sample code for us to replicate the issue faced along with the version or share a colab gist with the error faced.", "> @pkb14197\r\n> Please provide sample code for us to replicate the issue faced along with the version or share a colab gist with the error faced.\r\n\r\nThe code of converting the models to tflite model has been shown above. The same codes are used to convert the two models. However the inference speed for model1 is strange.", "@pkb14197 Can you please the code to create the model? I want to check the root-cause of the issue. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40824, "title": "Saver not created because there are no variables in the graph to restore", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Y\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 10\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.74\r\n- GPU model and memory: Intel(R) HD Graphics 530\r\n\r\nI write in C# and use ML.net but the error comes from Tensorflow library.\r\nWhile trying to Fit the model\r\n`ITransformer model = trainingPipeline.Fit(trainingDataView);\r\n`\r\n it gives following error:\r\nSaver not created because there are no variables in the graph to restore", "comments": ["@kwijik \r\n\r\nCan you please help us with the simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "@ravikyram Thank you for your answer.\r\nI generated an image classification model with Visual Studio. After I tried to change some hyper-parameters like number of epochs, batchsize, etc to see if it will give better results. But it gave me an error \"Saver not created because there are no variables in the graph to restore\". I began to look for an error, returned initial parameters and tried to recreate default model:\r\n`ModelBuilder.CreateModel()` \r\nCreateModel() works good till the moment when it calls\r\n`ITransformer model = trainingPipeline.Fit(trainingDataView);`\r\nHere something goes wrong and I have the error.", "@kwijik \r\n\r\nWill it be possible to share complete code snippet to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "@ravikyram  \r\nYou will find the code here https://github.com/kwijik/ict \r\nThere are 5 .cs files and a folder _images_ with images.", "@kwijik I am not able to reproduce the issue. Please give us complete steps to reproduce the issue. Thanks!\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@gowthamkpr No problem. You can use the code from  https://github.com/kwijik/ict . If for some reason you cannot, follow these steps:\r\n1 Install Visual studio 2019\r\n2 Download images from my repository\r\n3 Install ML.Net and Model Builder\r\n4 Try to generate image classification model (here is an example https://dotnet.microsoft.com/apps/machinelearning-ai/ml-dotnet/model-builder) \r\nAfter I describe my actions here https://github.com/tensorflow/tensorflow/issues/40824#issuecomment-651021357", "@kwijik We need a minimal reproducible code... Can you please share a small code snippet that can reproduce this issue. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40824\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40824\">No</a>\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40824\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40824\">No</a>\n"]}, {"number": 40823, "title": "Dot model generation not working when input_shape is not specified (Maybe just missing error message) ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04.4 / 20.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.8.2\r\n\r\n\r\n**Current behavior**\r\n\r\nWhen using an arbitrary network architecture but without **input_shape** being defined in the first layer, the `plot_model` and `model_to_dot` functions do not work properly (at least from my point of view). The dot model returned only contains a node for the model name (_sequential_ in this case), the saved image only contains this _sequential_-node as well. \r\n\r\n![image](https://user-images.githubusercontent.com/23249088/85840675-324ee080-b79d-11ea-9141-e3051175a657.png)\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\nUsing Python 3.7 with Keras (2.3.1) and Tensorflow (2.1.0) the functions would generate the model without specifying an input shape. With Tensorflow 2.2 this behavior broke.\r\n\r\nSince the input_shape is an optional parameter this should not happen without throwing an error/exception in my opinion. If this is a desired behavior then I would at least expect an error message which would tell me that an input shape is missing. \r\n\r\nBut if the model builds and trains without the input shape, then it should also be convertible to a dot format or image.\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\nfrom keras.utils import plot_model\r\nfrom keras.models import Sequential\r\nfrom keras.layers import Conv2D\r\n\r\nmodel = Sequential()\r\n\r\n# Does not work\r\nmodel.add(Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\"))\r\n\r\n# Works\r\n# model.add(Conv2D(32, (3, 3), input_shape=(1, 100, 100), padding=\"same\", activation=\"relu\"))\r\n\r\nplot_model(model, 'model.png')\r\n```\r\n\r\n**Output of model to dot**\r\n\r\nNot working:\r\n\r\ndigraph G {\r\nconcentrate=True;\r\ndpi=96;\r\nrankdir=TB;\r\nnode [shape=record];\r\n140054209647712 [label=sequential];\r\n}\r\n\r\nWorking:\r\n\r\ndigraph G {\r\nconcentrate=True;\r\ndpi=96;\r\nrankdir=TB;\r\nnode [shape=record];\r\n139879434642768 [label=\"conv2d_input: InputLayer\"];\r\n139879443480480 [label=\"conv2d: Conv2D\"];\r\n139879434642768 -> 139879443480480;\r\n}", "comments": ["Was able to reproduce the issue with [TF v2.2](https://colab.research.google.com/gist/amahendrakar/839eabb0065cdcca00470c227089d2c3/40823-tf-keras.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/02bc6476e501c577409ebfa638781fde/40823-tf-keras.ipynb#scrollTo=HH1dcQTf4HdH). However, output is different when using just [keras](https://colab.research.google.com/gist/amahendrakar/62fb86d0c32c556d6273e8631c5f0107/40823-keras.ipynb#scrollTo=HH1dcQTf4HdH) (not tf.keras). Please find the linked gist. \r\n - keras output\r\n![keras](https://user-images.githubusercontent.com/57165142/85890507-1b46d780-b80b-11ea-98ec-1f158f5df3f6.png)\r\n\r\n- tf.keras output\r\n![tf-keras](https://user-images.githubusercontent.com/57165142/85890519-23067c00-b80b-11ea-8cca-88756da26f1c.png)\r\n\r\nThanks!", "Was able to reproduce  the issue using TF version 2.7.0. Please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/788bef88cdf6442ba918b134c16e1366/untitled85.ipynb).Thanks!", "Hi There,\n\n This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! \n\n Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40823\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40823\">No</a>\n"]}, {"number": 41802, "title": "Process finished with exit code 139 (interrupted by signal 11: SIGSEGV)", "body": "```\r\nimport os\r\nimport zipfile\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.optimizers import RMSprop\r\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n\r\nprint(tf.__version__)\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\r\npath ='/media/jake/mark-4tb3/input/datasets/cats_and_dogs_filtered/'\r\n\r\ntrain_dir = os.path.join(path + 'train')\r\nvalidation_dir = os.path.join(path + 'validation')\r\nbase_dir = path + 'cats_and_dogs_filtered/'\r\n# Directory with our training cat pictures\r\ntrain_cats_dir = os.path.join(train_dir, 'cats')\r\ntrain_dogs_dir = os.path.join(validation_dir,'dogs')\r\nvalidation_cats_dir = os.path.join(validation_dir,'cats')\r\nvalidation_dogs_dir = os.path.join(validation_dir,'dogs')\r\n\r\n\r\nmodel = tf.keras.models.Sequential([\r\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\r\n    tf.keras.layers.MaxPooling2D(2, 2),\r\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\r\n    tf.keras.layers.MaxPooling2D(2,2),\r\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\r\n    tf.keras.layers.MaxPooling2D(2,2),\r\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\r\n    tf.keras.layers.MaxPooling2D(2,2),\r\n    tf.keras.layers.Flatten(),\r\n    tf.keras.layers.Dense(512, activation='relu'),\r\n    tf.keras.layers.Dense(1, activation='sigmoid')\r\n])\r\n\r\n\r\nmodel.compile(loss='binary_crossentropy',\r\n              optimizer=RMSprop(lr=1e-4),\r\n              metrics=['accuracy'])\r\n\r\n# All images will be rescaled by 1./255\r\ntrain_datagen = ImageDataGenerator(rescale=1./255)\r\ntest_datagen = ImageDataGenerator(rescale=1./255)\r\n\r\n# Flow training images in batches of 20 using train_datagen generator\r\ntrain_generator = train_datagen.flow_from_directory(\r\n        train_dir,  # This is the source directory for training images\r\n        target_size=(150, 150),  # All images will be resized to 150x150\r\n        batch_size=20,\r\n        # Since we use binary_crossentropy loss, we need binary labels\r\n        class_mode='binary')\r\n\r\n# Flow validation images in batches of 20 using test_datagen generator\r\nvalidation_generator = test_datagen.flow_from_directory(\r\n        validation_dir,\r\n        target_size=(150, 150),\r\n        batch_size=10,\r\n        class_mode='binary')\r\n\r\nhistory = model.fit(\r\n      train_generator,\r\n      steps_per_epoch=100,  # 2000 images = batch_size * steps\r\n      epochs=100,\r\n      validation_data=validation_generator,\r\n      validation_steps=10,  # 1000 images = batch_size * steps\r\n      verbose=2)\r\nprint('start')\r\nimport matplotlib.pyplot as plt\r\nacc = history.history['accuracy']\r\nval_acc = history.history['val_accuracy']\r\nloss = history.history['loss']\r\nval_loss = history.history['val_loss']\r\n\r\nepochs = range(len(acc))\r\n\r\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\r\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\r\nplt.title('Training and validation accuracy')\r\n\r\nplt.figure()\r\n\r\nplt.plot(epochs, loss, 'bo', label='Training Loss')\r\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\r\nplt.title('Training and validation loss')\r\nplt.legend()\r\n\r\nplt.show()\r\n```\r\n\r\nPython Version : 3.7.3\r\nTensorflow Version : 2.0-gpu \r\nOS: Ubuntu 19.10\r\ncuda-version :10.2 \r\n\r\n\r\n`Process finished with exit code 139 (interrupted by signal 11: SIGSEGV)\r\n`\r\n\r\n\r\n=====================================\r\njupyer lab error message\r\n\r\n```\r\n 23:09:35.676 LabApp] Starting buffering for 9f1747f3-2ef3-4674-9138-d24f57c4c2a5:5200ed2a-c87d-480b-b325-a681221a239d\r\n2020-06-26 23:09:38.208214: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-06-26 23:09:38.286106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\nname: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582\r\npciBusID: 0000:0b:00.0\r\n2020-06-26 23:09:38.286735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \r\nname: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582\r\npciBusID: 0000:42:00.0\r\n2020-06-26 23:09:38.286880: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2020-06-26 23:09:38.287654: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2020-06-26 23:09:38.287729: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.0/lib64\r\n2020-06-26 23:09:38.287777: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.0/lib64\r\n2020-06-26 23:09:38.287821: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.0/lib64\r\n2020-06-26 23:09:38.287863: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.0/lib64\r\n2020-06-26 23:09:38.290019: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-06-26 23:09:38.290041: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\n2020-06-26 23:09:45.449530: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-06-26 23:09:45.473556: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3492915000 Hz\r\n2020-06-26 23:09:45.474671: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4dc7330 executing computations on platform Host. Devices:\r\n2020-06-26 23:09:45.474700: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\n2020-06-26 23:09:45.661486: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4def5d0 executing computations on platform CUDA. Devices:\r\n2020-06-26 23:09:45.661527: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1\r\n2020-06-26 23:09:45.661537: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): TITAN Xp, Compute Capability 6.1\r\n2020-06-26 23:09:45.661754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-06-26 23:09:45.661774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      \r\n[I 23:09:50.294 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports\r\nkernel 9f1747f3-2ef3-4674-9138-d24f57c4c2a5 restarted\r\n```\r\n", "comments": ["@SlowMonk Can you please give the entire code with dataset for us to reproduce this issue? Thanks!", "I changed it to the cuda-version 10.0 and it still gives error \r\nProcess finished with exit code 139 (interrupted by signal 11: SIGSEGV)\r\n\r\nand jupyter notebook just kernel died \r\n\r\nthis error caused in \r\n\r\n```\r\n# Flow training images in batches of 20 using train_datagen generator\r\ntrain_generator = train_datagen.flow_from_directory(\r\n        train_dir,  # This is the source directory for training images\r\n        target_size=(150, 150),  # All images will be resized to 150x150\r\n        batch_size=20,\r\n        # Since we use binary_crossentropy loss, we need binary labels\r\n        class_mode='binary')\r\n```", "@SlowMonk \r\nI ran the code shared and face different error as data set and complete code is missing, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/572c5322dea68e792b7c8b00f231ccc5/untitled295.ipynb).", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "@SlowMonk Are you able to figure out the above error? I too am getting a similar error when training tensorflow models."]}, {"number": 40822, "title": "Not able to install tensorflow through pip", "body": "\r\n![issue](https://user-images.githubusercontent.com/45734921/85836310-00537380-b7c9-11ea-818e-d678d1534409.png)\r\n\r\n\r\n- OS Platform and Distribution : win 10\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version: 2.2\r\n- Python version: 3.7\r\n- Installed using : pip with no virtual env\r\n\r\n\r\nSo I tried to install tensorflow >= 2.0.0 with pip and no virtual env, but it always says ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none) and ERROR: No matching distribution found for tensorflow. Can anyone help me with it? Thanks.\r\n\r\n", "comments": ["@PeaNButT \r\nPlease check if you have the latest version of pip installed. You can upgrade pip using the below command.\r\n\r\npython3 -m pip install --upgrade pip\r\n\r\nAlso check if you have met all the system requirements for installing TensorFlow from [this link](https://www.tensorflow.org/install/pip#system-requirements).\r\n\r\nHere are few similar issues you could refer to.\r\n#38750 #20444 [link](https://stackoverflow.com/questions/48720833/could-not-find-a-version-that-satisfies-the-requirement-tensorflow)", "@Saduf2019 \r\nI have checked all the requirement, and I'm using windows 10 (64-bit), Python 3.7.3,  pip version 20.1.1. It still says \r\n\" ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\r\nERROR: No matching distribution found for tensorflow\"", "Thanks, problem solved, I was using Python 32 bit, now I have changed to 64 bit.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40822\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40822\">No</a>\n"]}, {"number": 40821, "title": "Tensorflow-Lite for Flutter", "body": "There is only one plugin of Flutter which is not official.\r\nAny plan to make a plugin for Flutter ?", "comments": ["Are you referring to https://pub.dev/packages/tflite_flutter ? That was actually a Google Summer of Code (GSoC) project, and is currently the recommended path for Flutter development. We're working on improving related documentation and samples."]}, {"number": 40820, "title": "How can I enable aws during running configure?", "body": "@tensorflower-gardener @gunan \r\nEnvironment:\r\nUbuntu 16.04\r\npython 3.6\r\nbazel 0.26.0\r\n\r\nI built tensorflow 1.14 from source. I want to enable aws, but I did not find anyway.\r\nHow can I enable it?", "comments": ["> I built tensorflow 1.14 from source. I want to enable aws, but I did not find anyway.\r\n> How can I enable it?\r\n\r\n@ibrahimLearning,\r\nCould you please elaborate the issue you are facing or the use case you're trying to implement. Thanks!", "Unfortunately 1.14 was not properly released. Can you attempt 1.15 instead?\r\n\r\nAlso, what do you mean by enabling AWS? S3 filesystem?", "@mihaimaruseac \r\n> what do you mean by enabling AWS? S3 filesystem?\r\n\r\nI just want this (https://www.tensorflow.org/install/source):\r\nDo you wish to build TensorFlow with Amazon AWS Platform support? [Y/n]: Y\r\nAmazon AWS Platform support will be enabled for TensorFlow.\r\n\r\nbut I did not find this, during TF1.14 installation.", "The exact question as specified in that snippet has been introduced in `tensorlfow==1.10`:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/4dcfddc5d12018a5a0fdca652b9221ed95e9eb23/configure.py#L1468-L1469\r\n\r\nAnd got removed by the time `tensorflow==1.12` got released.\r\n\r\nThey got removed in https://github.com/tensorflow/tensorflow/commit/d56c298f1ef14b5a738e1e0b7bbc66fcd736be3e#diff-ade1d3e4b7c35655f854151d899df62b and since then these filesystems are enabled by default if supported by the operating system.", "Closing issue, as AWS is now default enabled, except on windows.\r\nOn windows, I don't think our AWS or GCP support ever worked."]}, {"number": 40819, "title": "Installation error", "body": "After installing tensorflow-gpu=2.0.0, \"import tensorflow as tf\" reports an error\uff1a\r\nAttributeError: module 'tensorflow' has no attribute 'compat'\r\n\r\nHow to deal with it?", "comments": ["I can't even install tensorflow on windows 10\r\nmy pip version 20.1.1\r\npython version: 3.8.2\r\nI have already installed CUDA toolKit and added to my system variables", "> I can't even install tensorflow on windows 10\r\n> my pip version 20.1.1\r\n> python version: 3.8.2\r\n> I have already installed CUDA toolKit and added to my system variables\r\n\r\nMaybe it's a version problem. You'd better install Python version 3.7\u3002\r\nNow I've solved that problem.\r\n![image](https://user-images.githubusercontent.com/51586022/85832091-072ab800-b7c2-11ea-995a-5581d51ed754.png)\r\nThe problem is tensorflow-estimator==2.2.0\uff01\uff01\uff01So uninstall it and retry install again.\r\nconda uninstall tensorflow-estimator\r\nconda install tensorflow-estimator==2.0.0 \r\nconda install tensorflow-gpu==2.0.0 \r\n", "@RengarWang \r\nPlease confirm your issue is resolved so we could move this to closed status.", "> @RengarWang\r\n> Please confirm your issue is resolved so we could move this to closed status.\r\n\r\nyes,it is solved,thanks.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40819\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40819\">No</a>\n"]}, {"number": 40818, "title": "Tensorflow models getting lag on safari-12 and safari-13 (Iphone5 to Iphone 8 and MAC IOS 12)", "body": "Hello,\r\n\r\nWe ran the web-version of tensor-flow models([facemesh](https://github.com/tensorflow/tfjs-models/tree/master/facemesh)) on safari-12/safari-13 version on different devices like iphon5 to iphone8 and MAC(IOS12).\r\n\r\n\r\nBut the model's inferences getting slowed down and facing lag on these devices.\r\n\r\nPlease suggest me any improvement can be done on this platforms (like safari-12/13 and iphone5 to iphone 8 and MAC IOS-12).\r\n\r\n ", "comments": ["@vasanthhr \r\n\r\nI think this issue belongs to models repo. You can raise an issue in models repo from [here](https://github.com/tensorflow/models/issues/new/choose).Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40818\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40818\">No</a>\n"]}]