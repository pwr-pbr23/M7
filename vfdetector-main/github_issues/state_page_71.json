[{"number": 22208, "title": "LookupError: No gradient defined for operation type: ResizeNearestNeighborGrad or ResizeBilinearGrad", "body": "### System information:\r\n- **OS Platform and Distribution**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:binary\r\n- **TensorFlow version**:1.10.0\r\n- **Python version**:2.7.x\r\n- **CUDA/cuDNN version**:9.0.x\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:Nope\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:N/\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**:N/A\r\n- **GPU model and memory**: Geforce 940mx\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\nI want to the gradient of any of [these image resizing operations](https://www.tensorflow.org/api_docs/python/tf/image/ResizeMethod) inside the neural network. But seems to be any of these does not define the gradient ops for them. I see there is a [similar issue ](https://github.com/tensorflow/tensorflow/issues/7641) which has not been answered yet. I also asked in the [SO](https://stackoverflow.com/questions/52264891/lookuperror-no-gradient-defined-for-operation-type-resizenearestneighborgrad) but still, I did not get an answer for this. \r\n\r\n### Source code / logs\r\n\r\n      \r\n\t\tdifferences = tf.subtract(images_fake, images_real)\r\n\t\talpha_shape = [params.batch_size] + [1] * (differences.shape.ndims - 1)\r\n\t\talpha = tf.random_uniform(shape=alpha_shape, minval=0., maxval=1.)\r\n\t\tinterpolates = images_real + (alpha * differences)\r\n\t\td_model = Model(params, args.mode, interpolates, reuse_variables, images_fake, 1)\r\n\t\tgradients = tf.gradients(d_model.logistic_linear, [interpolates])[0]\r\n\t\tslopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\r\n\t\tgradient_penalty = tf.reduce_mean((slopes - 1.) ** 2)\r\n\t\t_gradient_penalty = 10 * gradient_penalty\r\n\r\nInside my model, it uses [ tf.image.resize_bicubic()](https://www.tensorflow.org/api_docs/python/tf/image/resize_bicubic). But I see there are some [exisiting implementation](https://github.com/tensorflow/tensorflow/commit/3331c574bcfd85787d7a4f3d1b1b139239a6595b) for this. But not sure how those things get it them working. Please let me know how this can be achieved. These image resizing cannot be done as preprocessing it needs to be done inside a model. Any help would be really appreciated. ", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nBazel version\nGPU model and memory\nExact command to reproduce\nMobile device", "Any update on this", "I think the patch 3331c574b will be released with r1.11. Would you mind taking a try on \r\n+ 1.11-rc: `pip install tensorflow==1.11.0rc0`\r\n+ or nightly version: `pip install tf-nightly`", "yeap, I will try and let you know. Thanks ", "@GPrathap Hi, any update if you tried ?", "Sorry for the late reply, I was on my vacation.\r\n\r\nStill I am getting this error. \r\n\r\n`LookupError: No gradient defined for operation 'discriminator/gradients/discriminator/decoder/ResizeBilinear_grad/ResizeBilinearGrad' (op type: ResizeBilinearGrad)`\r\n\r\nI installed `pip install tensorflow-gpu==1.11.0rc0`\r\n\r\n", "Could you provide a minimal example?", "As I explained in the above, to find the total loss I calculate the gradient of the model. When the model is going through backpropagation stage it is trying to calculate the gradient of gradient where this error comes from. I guess in the tensorflow gradient of the gradient is not defined for these image resizing operations. That is why I am getting this error. I guess you can close this issue because I might try to calculate the loss in a different way where it is not required to calculate the gradient of  gradient.\r\n\r\nThanks ", "Yes, `ResizeBilinearGradGrad` is missing, unfortunately. I think contribution is welcome if you'd like to implement it.", "@GPrathap how did you fix it?", "Nope, I haven't fixed it, I changed the loss function ", "@GPrathap can you provide the loss function that you did? I want to implement WGAN-GP loss and I have the same problem ", "You may find it here, I am not sure which will help you or not. \r\n\r\nhttps://github.com/GPrathap/monodepth/blob/master/monodepth_main_new_loss.py#L222 \r\nhttps://github.com/GPrathap/monodepth/blob/master/monodepth_model_gan.py#L381\r\n\r\nJust have a look :) ", "Contributions welcome (to add grad of grad)!", "Has there been any progress in this issue? If someone has implemented or knows how to implement this, can you post it here please?", "Check my new answer below\r\n~~Hi, I may be wrong but I'm quite confident that second derivative of a linear op should be zero (None).\r\nI checked this numerically by looking at the output of the gradient of tf.image.resize (or keras UpSampling2D ) vs changing its input and I found out (as expected) that the output depends only on resize factor. So as a quick fix I used:\r\n`\r\n@tf.RegisterGradient(\"ResizeBilinearGrad\")\r\ndef _ResizeBilinearGrad_grad(unused_op, grad):\r\n    return None,None\r\n`\r\nCan someone confirm my thoughts?~~", "@gtanzi . I too think that the second gradient is zero So you can return None w.r.t the original image. But is it correct to return None for the second argument as well?\r\n", "@SNMS95 I'm not sure becasue I'm still confused about what exactly needs a definition (i.e. the second order gradient of op Vs the \"the first order gradient of grad_fn with respect to dy \" [here](https://www.tensorflow.org/api_docs/python/tf/custom_gradient)) If I understood correctly from [here](https://www.tensorflow.org/api_docs/python/tf/RegisterGradient) , for an op with m inputs and n outputs, the gradient function should return m objects. The first derivative of op defined [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_grad.py) returns [something,None] so I guess op takes two imputs but only use one? I've never dealt with custom gradient before", "@gtanzi \r\nI found that the gradient function for the \u2018ResizeBilinearGrad\u2019 op is not implemented in Tensorflow and that this is causing the said error. Also,custom gradients for nonexistant ops can be registered using @tf.RegisterGradient(\u201cname_of_op\u201d), but I don\u2019t know what exactly it should return. The required gradient function should have the form as given below:\r\n\r\n@tf.RegisterGradient(\u201cResizeBilinearGrad\u201d)\r\ndef _ResizeBilinearGradGrad(op, grad):\r\n    return (A,B)\r\n\r\nWhere,\r\ngrad - gradients w.r.t to the outputs of ResizeBilinearGrad op\r\nop - \u2018ResizeBilinearGrad\u2019\r\nA - gradients w.r.t first input to the op\r\nB - gradients w.r.t input image\r\n\r\nThe inputs to the \u2018ResizeBilinearGrad\u2019 op are:\r\nA - gradients calculated till that point (Not sure!!)\r\nB - the original input image", "@SNMS95 \r\nAfter some thoughts on your comments I now think my first naive answer was completely wrong. The main reason being that tf is not asking the second derivative of ResizeBilinear, but rather the first derivative of ResizeBilinearGrad with respect to its inputs ( from which it can later perform second order derivative with chain rule). \r\nThe upscaling op should take an image X with shape <img src=\"https://render.githubusercontent.com/render/math?math=(%5Calpha%20x%20%5Cbeta)%0A\">  and return a scaled image Y with shape (i x j) like:\r\n<img src=\"https://render.githubusercontent.com/render/math?math=Y_%7Bij%7D%20%3D%20c_%7Bij%7D%5E%7B%5Calpha%5Cbeta%7DX_%7B%5Calpha%5Cbeta%7D%0A\">\r\nwhere the c coefficients (in bilinear interp) do not depend on X but only on the scaling factors.\r\n\r\nNow, as you suggest,  ResizeBilinearGrad inputs are indeed:\r\n\r\n> G1 - gradients calculated till that point of shape (ixj) (-> I too think it's right looking at the code)\r\n> X - the original input image  \r\n> \r\n\r\ni.e.\r\n\r\nResizeBilinearGrad( <img src=\"https://render.githubusercontent.com/render/math?math=G1%5E%7Bij%7D\">,X): \r\n&nbsp;&nbsp; return:<img src=\"https://render.githubusercontent.com/render/math?math=G1%5E%7Bij%7Dc_%7Bij%7D%5E%7B%5Calpha%5Cbeta%7D\">  \r\n\r\nand ResizeBilinearGradGrad ( op= ResizeBilinearGrad , grad=G2): \r\n&nbsp;&nbsp; return:[A,B]\r\n\r\n\r\nI believe ResizeBilinearGrad uses X only to determine the output shape (? I'm not sure why ResizeBilinearGrad needs X), I assume the second outputs of _ResizeBilinearGradGrad must be None.\r\nHowever this is not true for the first output (as I wrongly suggest before) and should be (including the backprop of grad G2):\r\n&nbsp;&nbsp;<img src=\"https://render.githubusercontent.com/render/math?math=c_%7Bij%7D%5E%7B%5Calpha%5Cbeta%7D%20G2_%7B%5Calpha%5Cbeta%7D\">\r\nWhich is just the upscaling of G2.\r\nSooo my second guess is:\r\n\r\n```\r\n@tf.RegisterGradient(\"ResizeBilinearGrad\")\r\ndef _ResizeBilinearGrad_grad(op, grad):\r\n    up = tf.image.resize(grad,tf.shape(op.inputs[0])[1:-1])\r\n    return up,None\r\n\r\n```\r\n\r\nI did perform a simple test:\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n@tf.RegisterGradient(\"ResizeBilinearGrad\")\r\ndef _ResizeBilinearGrad_grad(op, grad):\r\n    up = tf.image.resize(grad,tf.shape(op.inputs[0])[1:-1])\r\n    return up,None\r\n\r\na = np.zeros((1, 2, 2, 1), dtype=np.float32)\r\na[0, 0, 0, 0] = 2.0\r\n\r\nx = tf.constant(a)\r\nup=  tf.keras.layers.UpSampling2D((2,2), data_format='channels_last', interpolation='bilinear')\r\nwith tf.GradientTape() as g_tape:\r\n    g_tape.watch(x)\r\n    with tf.GradientTape(persistent=True) as g_tape2:\r\n        g_tape2.watch(x)\r\n        y = x\r\n        y = up(y) \r\n        t = (y**2)   \r\n        \r\n    up1 = g_tape2.gradient(y,x) \r\n    g1 = g_tape2.gradient(t,x) \r\ng2 = g_tape.gradient(g1,x) \r\n\r\n\r\nprint('######################')\r\nprint('x',x[0, :, :, 0])\r\nprint('up(x)',y[0, :, :, 0])\r\nprint(\"up'(x)\",up1[0, :, :, 0])\r\nprint('g1',g1[0, :, :, 0])\r\nprint('g2',g2[0, :, :, 0])\r\n```\r\nAnd checked these with Wolphram Mathematica. It may be useful to perform more checks.\r\nwhat you think?\r\n", "@gtanzi  I am not really an expert in this but if the calculated gradients are the same in Mathematica as well, I do hope that this might be correct.\r\n"]}, {"number": 22182, "title": "\"master\" in cluster spec for distributed training ", "body": "Hi,\r\n\r\nGiven in the sample code [mnist_replica.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/python/mnist_replica.py), `tf.train.ClusterSpec()` needs to be used to define the cluster for distributed training.  The function `tf.train.ClusterSpec()` can only take `\"ps\"` and `\"worker\"` hosts, but `\"master\"` is not allowed. As far as I know, `\"master\"` is usually defined as a special worker and should be a part of the worker hosts, referred as `task_id = 0`. This makes sense to me.\r\n\r\nHowever, in the context of `tf.estimator`, if `\"cluster\"` is set in `TF_CONFIG`, it must have one `\"chief\"` node, in addition to `\"worker\"`. For example,\r\n\r\n```\r\nTF_CONFIG='{\r\n    \"cluster\": {\r\n        \"chief\": [\"host0:2222\"],\r\n        \"worker\": [\"host1:2222\", \"host2:2222\", \"host3:2222\"],\r\n        \"ps\": [\"host4:2222\", \"host5:2222\"]\r\n    },\r\n    \"task\": {\"type\": \"chief\", \"index\": 0}\r\n}'\r\n```\r\nI am trying to use `TF_CONFIG` for all our distributed training work, but it looks like to be inconsistent. For example, we need to do some preprocessing in the above `TF_CONFIG` (i.e., combining `\"chief\"` and `\"worker\"` hosts, and re-index them), to use it for `tf.train.ClusterSpec()`. \r\n\r\nIs there any better standard we can follow to achieve our goal?\r\n\r\nThanks \r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Host OS: Ubuntu16.04LST\r\nDocker image: 1.10.0-gpu", "any idea?", "@llidev We see that you are using TF v1.x which is not actively supported and we recommend you to upgrade latest TF versions(2.4 or later).Please refer to the [migration](https://www.tensorflow.org/guide/migrate) doc .\r\nEstimators are not recommended for new code. Estimators  can behave unexpectedly, especially when combined with TF 2 code. Could you please refer to this [link](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier) for more details  and let us know if it helps?\r\nThanks!"]}, {"number": 22162, "title": "tf.map_fn causes error when importing the same graph twice and connecting them", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: binary (pip in conda environment)\r\n- **TensorFlow version (use command below)**: v1.10.1-0-g4dcfddc5d1 1.10.1\r\n- **Python version**: 3.6.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 9.0\r\n- **GPU model and memory**: GTX 1070 / 8GB\r\n- **Exact command to reproduce**: below\r\n\r\n\r\n### Describe the problem\r\nI am trying to load the same graph twice (with different variable weights) to perform stage-wise object detection with one connected graph. I import them with different name scopes, but still I get an error message because there is some bug in the tf.map_fn:\r\n```\"tensorflow.python.framework.errors_impl.InvalidArgumentError: Invalid loop structure: Loop \"map/while/while_context\" has more than one LoopCond node: \"graph2/map/while/LoopCond\" and \"graph1/map/while/LoopCond\". This is an internal bug, please file a bug report with instructions on how to reproduce the error.\"```\r\n\r\nMinimal example to reproduce is below, but to me it ocurred with the faster-rcnn meta architecture from the object detection framework, where the first loop that causes this error is in the \"preprocess\" funtion of \"object_detection.meta_architectures.faster_rcnn_meta_arch.py\" at line 535. When I changed the tf.name_scope from 'Preprocessor' to something else in just one of the graphs, it threw this error from a different usage of the map_fn further down the graph.\r\n\r\nfrom object_detection.meta_architectures.faster_rcnn_meta_arch.py (line 535):\r\n```python\r\n    if inputs.dtype is not tf.float32:\r\n      raise ValueError('`preprocess` expects a tf.float32 tensor')\r\n    with tf.name_scope('Preprocessor'): #when I change this in one of the graphs, the error doesn't occur here anymore\r\n      outputs = shape_utils.static_or_dynamic_map_fn(\r\n          self._image_resizer_fn,\r\n          elems=inputs,\r\n          dtype=[tf.float32, tf.int32],\r\n          parallel_iterations=self._parallel_iterations)\r\n      resized_inputs = outputs[0]\r\n      true_image_shapes = outputs[1]\r\n      return (self._feature_extractor.preprocess(resized_inputs),\r\n              true_image_shapes)\r\n```\r\nThis would actually be my workaround if this doesn't get fixed, to just rename all the map_fn scopes before training each subgraph.\r\n\r\n### Script to reproduce bug\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndef build_map_graph(name_scope=''):\r\n    graph = tf.Graph()\r\n    with graph.as_default():\r\n        input_tensor = tf.placeholder(tf.float32, shape=[None, 1], name='input')\r\n\r\n        def mult(input):\r\n            input = tf.multiply(input, 2)\r\n            return input\r\n\r\n        with tf.name_scope(name_scope):\r\n            multiplied = tf.map_fn(mult, input_tensor)\r\n        out_tensor = tf.identity(multiplied, name='output')\r\n\r\n    return graph\r\n\r\ndef build_simple_graph():\r\n    graph = tf.Graph()\r\n    with graph.as_default():\r\n        input_tensor = tf.placeholder(tf.float32, shape=[None, 1], name='input')\r\n\r\n        multiplied = tf.multiply(input_tensor, 2)\r\n        out_tensor = tf.identity(multiplied, name='output')\r\n\r\n    return graph\r\n\r\n\r\ndef connect_graphs(both_are_map_graphs=False, rename_second=False):\r\n    test_data = np.asarray([[1.0], [2.0]], dtype=np.float32)\r\n\r\n    graph1 = build_map_graph()\r\n    g1_graph_def = graph1.as_graph_def()\r\n\r\n    g2_map_name_scope = 'graph2_map' if rename_second else ''\r\n    graph2 = build_map_graph(g2_map_name_scope) if both_are_map_graphs else build_simple_graph()\r\n\r\n    g2_graph_def = graph2.as_graph_def()\r\n\r\n    connected_graph = tf.Graph()\r\n\r\n    with connected_graph.as_default():\r\n        tf.import_graph_def(g1_graph_def, name='graph1')\r\n\r\n        g1_output_tensor = tf.get_default_graph().get_tensor_by_name('graph1/output:0')\r\n        g1_input_tensor = tf.get_default_graph().get_tensor_by_name('graph1/input:0')\r\n\r\n        tf.import_graph_def(g2_graph_def, name='graph2', input_map={'input': g1_output_tensor})\r\n        g2_output_tensor = tf.get_default_graph().get_tensor_by_name('graph2/output:0')\r\n\r\n        with tf.Session() as sess:\r\n            result = sess.run(g2_output_tensor, {g1_input_tensor: test_data})\r\n            print(result)\r\n\r\n\r\n#runs fine\r\nconnect_graphs(both_are_map_graphs=False)\r\nconnect_graphs(both_are_map_graphs=True, rename_second=True)\r\n\r\n#throws error\r\nconnect_graphs(both_are_map_graphs=True)\r\n```\r\n\r\nEdit:\r\nchanged connect_graphs(both_are_map_graphs=False, rename_second=True) to connect_graphs(both_are_map_graphs=True, rename_second=True) in the example to better demonstrate the issue.", "comments": ["CC @skye, can you take a look?", "I encountered a similar problem while trying to connect two models. It looks like always adding a name argument to the call to tf.map_fn() is a temporary workaround. Otherwise, it seems that the while ops will always end up in the same name scope, and only the loop condition ops in distinct name scopes. ", "@stefsietz @kree-colemcalughlin According to [this test](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/graph/control_flow_test.cc#L118-L145), one scope can only contain one loop_control. That means, `tf.map_fn()` need to be put under different scopes. @stefsietz For your test code, it will work if changing the last line to `connect_graphs(both_are_map_graphs=True, rename_second=True)`.\r\n\r\n@skye Is my understanding correct?", "> @stefsietz @kree-colemcalughlin According to [this test](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/graph/control_flow_test.cc#L118-L145), one scope can only contain one loop_control. That means, `tf.map_fn()` need to be put under different scopes. @stefsietz For your test code, it will work if changing the last line to `connect_graphs(both_are_map_graphs=True, rename_second=True)`.\r\n> \r\n> @skye Is my understanding correct?\r\n\r\nYes, sorry actually the second \"connect_graphs\" test call was supposed to be connect_graphs(both_are_map_graphs=True, rename_second=True) to demonstrate this behaviour.", "@stefsietz If using `connect_graphs(both_are_map_graphs=True, rename_second=True)`, there will be no errors. If this solves your problem, could you close this issue?", "@feihugis no, this does not solve the problem, this merely corrects the minimal example I provided to demonstrate the problem to the way I initially intended it to be. The real world scenario where I am facing this problem is like this:\r\nI am training to separate stages with the tensorflow object detection framework. Then I am connecting them together for inference (the second graph gets the cropped detections from the first stage as inputs). I import the two graphs with different name scopes, but still I get this error message unless I go into deep into the tensorflow code and add a name scope right to the beginning of \"shape_utils.static_or_dynamic_map_fn\", which I then have to change for each graph when running the provided export script.\r\n\r\nThis can't be the way it's supposed to be. When I import the 2 graphs with different name scopes, I expect to be able to connect them. If I'd get a frozen graph from someone else, I couldn't go in and export it again with a different map_fn name scope like my current workaround. The error message is even stating `\"This is an internal bug, please file a bug report with instructions on how to reproduce the error.\"`. Please look into the provided example seriously:\r\nThe rename_second= True in `connect_graphs(both_are_map_graphs=True, rename_second=True)`\r\ncauses the map_fn name scope to be renamed in the graph BUILD not when IMPORTING. `connect_graphs(both_are_map_graphs=True, rename_second=False)` still imports the graphs with two different names, but here the bug is caused.", "here is a new example, where i have implemented a function that manipulates the GraphDef, doing some necessary renaming. This function could be optionally included in the \"import_graph_def\" function. Should I make a pull request for this?\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndef build_map_graph(name_scope=''):\r\n    graph = tf.Graph()\r\n    with graph.as_default():\r\n        input_tensor = tf.placeholder(tf.float32, shape=[None, 1], name='input')\r\n\r\n        def mult(input):\r\n            input = tf.multiply(input, 2)\r\n            return input\r\n\r\n        with tf.name_scope(name_scope):\r\n            multiplied = tf.map_fn(mult, input_tensor)\r\n            print(multiplied.name)\r\n        out_tensor = tf.identity(multiplied, name='output')\r\n\r\n    return graph\r\n\r\ndef build_simple_graph():\r\n    graph = tf.Graph()\r\n    with graph.as_default():\r\n        input_tensor = tf.placeholder(tf.float32, shape=[None, 1], name='input')\r\n\r\n        multiplied = tf.multiply(input_tensor, 2)\r\n        out_tensor = tf.identity(multiplied, name='output')\r\n\r\n    return graph\r\n\r\ndef rename_frame_name(graphdef, suffix):\r\n    for n in graphdef.node:\r\n        if \"while\" in n.name:\r\n            if \"frame_name\" in n.attr:\r\n                n.attr[\"frame_name\"].s = str(n.attr[\"frame_name\"]).replace(\"while_context\",\r\n                                                                           \"while_context\" + suffix).encode('utf-8')\r\n\r\n\r\ndef connect_graphs(both_are_map_graphs=False, rename_second=False):\r\n    test_data = np.asarray([[1.0], [2.0]], dtype=np.float32)\r\n\r\n    graph1 = build_map_graph()\r\n    g1_graph_def = graph1.as_graph_def()\r\n\r\n    g2_map_name_scope = 'graph2_map' if rename_second else ''\r\n    graph2 = build_map_graph(g2_map_name_scope) if both_are_map_graphs else build_simple_graph()\r\n\r\n    g2_graph_def = graph2.as_graph_def()\r\n\r\n    connected_graph = tf.Graph()\r\n\r\n    with connected_graph.as_default():\r\n        g1name = \"graph1\"\r\n        g2name = \"graph2\"\r\n\r\n        rename_frame_name(g1_graph_def, g1name)\r\n        rename_frame_name(g2_graph_def, g2name)\r\n\r\n        tf.import_graph_def(g1_graph_def, name=g1name)\r\n\r\n        g1_output_tensor = tf.get_default_graph().get_tensor_by_name('graph1/output:0')\r\n        g1_input_tensor = tf.get_default_graph().get_tensor_by_name('graph1/input:0')\r\n\r\n        tf.import_graph_def(g2_graph_def, name=g2name, input_map={'input': g1_output_tensor})\r\n        g2_output_tensor = tf.get_default_graph().get_tensor_by_name('graph2/output:0')\r\n\r\n        with tf.Session() as sess:\r\n            result = sess.run(g2_output_tensor, {g1_input_tensor: test_data})\r\n            print(result)\r\n\r\n\r\n#runs fine\r\nconnect_graphs(both_are_map_graphs=False)\r\nconnect_graphs(both_are_map_graphs=True, rename_second=True)\r\n\r\n#now doesn't throw error anymore\r\nconnect_graphs(both_are_map_graphs=True)\r\n```", "> @feihugis no, this does not solve the problem, this merely corrects the minimal example I provided to demonstrate the problem to the way I initially intended it to be. The real world scenario where I am facing this problem is like this:\r\n> I am training to separate stages with the tensorflow object detection framework. Then I am connecting them together for inference (the second graph gets the cropped detections from the first stage as inputs). I import the two graphs with different name scopes, but still I get this error message unless I go into deep into the tensorflow code and add a name scope right to the beginning of \"shape_utils.static_or_dynamic_map_fn\", which I then have to change for each graph when running the provided export script.\r\n> \r\n> This can't be the way it's supposed to be. When I import the 2 graphs with different name scopes, I expect to be able to connect them. If I'd get a frozen graph from someone else, I couldn't go in and export it again with a different map_fn name scope like my current workaround. The error message is even stating `\"This is an internal bug, please file a bug report with instructions on how to reproduce the error.\"`. Please look into the provided example seriously:\r\n> The rename_second= True in `connect_graphs(both_are_map_graphs=True, rename_second=True)`\r\n> causes the map_fn name scope to be renamed in the graph BUILD not when IMPORTING. `connect_graphs(both_are_map_graphs=True, rename_second=False)` still imports the graphs with two different names, but here the bug is caused.\r\n\r\n@stefsietz I add some logging code to the function `def connect_graphs()` as below. When `connect_graphs(both_are_map_graphs=True, rename_second=False)`, the output will be `Graph1 scope name: ;` and `Graph2 scope name: ;`. That means they have the same scope name. Is my understanding correct?\r\n\r\nSure, you can submit a PR. The expert in TensorFlow group will help you.\r\n```\r\ndef connect_graphs(both_are_map_graphs=False, rename_second=False):\r\n    test_data = np.asarray([[1.0], [2.0]], dtype=np.float32)\r\n\r\n    graph1 = build_map_graph()\r\n    g1_graph_def = graph1.as_graph_def()\r\n    ##################################################\r\n    print(\"Graph1 scope name: {};\".format(graph1.get_name_scope()))\r\n    ##################################################\r\n\r\n    g2_map_name_scope = 'graph2_map' if rename_second else ''\r\n    graph2 = build_map_graph(g2_map_name_scope) if both_are_map_graphs else build_simple_graph()\r\n    ##################################################\r\n    print(\"Graph2 scope name: {};\".format(graph2.get_name_scope()))\r\n    ##################################################\r\n\r\n    g2_graph_def = graph2.as_graph_def()\r\n\r\n    connected_graph = tf.Graph()\r\n\r\n    with connected_graph.as_default():\r\n        tf.import_graph_def(g1_graph_def, name='graph1')\r\n\r\n        g1_output_tensor = tf.get_default_graph().get_tensor_by_name('graph1/output:0')\r\n        g1_input_tensor = tf.get_default_graph().get_tensor_by_name('graph1/input:0')\r\n\r\n        tf.import_graph_def(g2_graph_def, name='graph2', input_map={'input': g1_output_tensor})\r\n        g2_output_tensor = tf.get_default_graph().get_tensor_by_name('graph2/output:0')\r\n\r\n        with tf.Session() as sess:\r\n            result = sess.run(g2_output_tensor, {g1_input_tensor: test_data})\r\n            print(result)\r\n```\r\n"]}, {"number": 22137, "title": "ps0 will be OOM using MonitoredTrainingSession when workers too many", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: No\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.4\r\n- **Python version**: 2.7.5\r\n- **Bazel version (if compiling from source)**: 1.9\r\n- **GCC/Compiler version (if compiling from source)**: 4.9.2\r\n- **CUDA/cuDNN version**: CPU\r\n- **GPU model and memory**: CPU\r\n- **Exact command to reproduce**: Using MonitoredTrainingSession and thousands of workers.\r\n\r\n\r\n### Describe the problem\r\nMy model is large and complex. Thousands of worker&ps are needed and MonitoredTrainingSession is used. In the stage of initialization, the memory of ps0 will raise up to 100G and then OOM, but other ps work correctly. Op device placement is tf.train.replica_device_setter and no other special strategy.\r\n\r\nI open the log_device_placement and found that all ops related with report_uninitialized_xxx are placed on ps0. I think this is the root cause.\r\n\r\nI change the code as PR #22136 , and then it works correctly.\r\n", "comments": ["@drpngx Hi, do you have some updates?", "This appears to be waiting for final review from @martinwicke -- reassigning to him."]}, {"number": 22129, "title": "[Feature Request] Exporting TF-Hub for the Best Model", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: N/A\r\n- **TensorFlow version (use command below)**: N/A\r\n- **Python version**: N/A\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\nI believe that it might be helpful to have `BestExporter` equivalent for `tf-hub` too. Currently, there is no way to export hub corresponding to the bet model. The easiest way to achieve this (or at least the way I did) is to trigger the `LatestHubExporter` within the `export` of `BestExporter`.\r\n\r\nAnother design proposal:\r\nThe exporters can be chained. However, I do not know of any other use cases (other than the one above).", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Updated!", "I can submit a PR with my solution. But I believe that chaining would be a better way to go about it."]}, {"number": 22108, "title": "tf.nightly-gpu will create \"nan\" in  next batch train value", "body": "\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: \r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.11.0   (use tf-night-gpu)\r\n- **Python version**:2.7\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 9.0 /7.1\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI installed  tf-night-gpu, and my` tf.__version__` was `1.11.0-dev20180905`\r\nit only use `tf-night-gpu` can create  the `tf.keras.applications.InceptionResNetV2` model so i can't without. my problem is the  `tf-night-gpu` will create `nan`  in  next batch model output \r\n\r\n### Source code / logs\r\nin first batch train the\r\n```\r\n('keras.layers.Embedding_input: ', <tf.Tensor: id=4586198, shape=(64, 1), dtype=int32, numpy=\r\narray([[3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3]], dtype=int32)>)\r\n('Embedding_output:  ', <tf.Tensor: id=4586379, shape=(64, 1, 256), dtype=float32, numpy=\r\narray([[[ 0.01097491, -0.02041122,  0.04823625, ..., -0.0155656 ,\r\n          0.01521399, -0.0496642 ]],\r\n\r\n       [[ 0.01097491, -0.02041122,  0.04823625, ..., -0.0155656 ,\r\n          0.01521399, -0.0496642 ]],\r\n\r\n       [[ 0.01097491, -0.02041122,  0.04823625, ..., -0.0155656 ,\r\n          0.01521399, -0.0496642 ]],\r\n\r\n       ...,\r\n\r\n       [[ 0.01097491, -0.02041122,  0.04823625, ..., -0.0155656 ,\r\n          0.01521399, -0.0496642 ]],\r\n\r\n       [[ 0.01097491, -0.02041122,  0.04823625, ..., -0.0155656 ,\r\n          0.01521399, -0.0496642 ]],\r\n\r\n       [[ 0.01097491, -0.02041122,  0.04823625, ..., -0.0155656 ,\r\n          0.01521399, -0.0496642 ]]], dtype=float32)>)\r\n```\r\nthe next batch train , have same `keras.layers.Embedding_input: `\r\n```\r\n`Epoch 1 Batch 0 Loss 2.0415\r\n(''keras.layers.Embedding_input:: ', <tf.Tensor: id=4607289, shape=(64, 1), dtype=int32, numpy=\r\narray([[3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3],\r\n       [3]], dtype=int32)>)\r\n(''keras.layers.Embedding_output::  ', <tf.Tensor: id=4607374, shape=(64, 1, 256), dtype=float32, numpy=\r\narray([[[nan, nan, nan, ..., nan, nan, nan]],\r\n\r\n       [[nan, nan, nan, ..., nan, nan, nan]],\r\n\r\n       [[nan, nan, nan, ..., nan, nan, nan]],\r\n\r\n\r\n       [[nan, nan, nan, ..., nan, nan, nan]],\r\n\r\n       [[nan, nan, nan, ..., nan, nan, nan]],\r\n\r\n       [[nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)>)`\r\n```\r\nand \"nan\" forever.....", "comments": ["@Q82822 could you please give a minimal code example that reproduces the issue?", "the minimal code at  here , it is just part of my project code. the inpout is word_index.\r\nthe batch size = 64  \r\nuse tf-nightly-gpu.\r\nplatform = jupyter notebook.\r\nin first batch size was worked, but in next batch train will be \"nan\". but this problem only happen in \"tf-nightly-gpu\"\r\n```\r\nclass  RNN_Decoder(tf.keras.Model):\r\n    def __init__(self, embedding_dim, units, vocab_size):\r\n        super(RNN_Decoder, self).__init__()\r\n        self.units = units\r\n        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\r\n    def call(self, x, features, hidden):\r\n        print('embedding_input:  ', x)\r\n        x = self.embedding(x)\r\n        print('embedding_output:  ', x)\r\n\r\ndecoder = RNN_Decoder(embedding_dim, units, vocab_size)\r\n\r\nfor epoch in range(20):\r\n    hidden = decoder.reset_state(batch_size=64)\r\n    dec_input = tf.expand_dims([tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\r\n        with tf.GradientTape() as tape:\r\n            features = encoder(img_tensor)\r\n            for i in range(1, target.shape[1])\r\n            predictions, hidden, _ = decoder(dec_input, features, hidden)\r\n```"]}, {"number": 22095, "title": "3D convolutions on GPU with large input produces incorrect results on some GPUs", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, see reproduction script below.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.5 LTS\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: Binary via pip\r\n- **TensorFlow version (use command below)**: 1.10.1\r\n- **Python version**: 3.6.3\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: GCC 5.4.0\r\n- **CUDA/cuDNN version**: CUDA 9.0 / cuDNN 7.2\r\n- **GPU model and memory**: GTX 1080 Ti\r\n- **Exact command to reproduce**: See script below.\r\n\r\n```\r\n== cat /etc/issue ===============================================\r\nLinux gpu01 4.4.0-116-generic #140-Ubuntu SMP Mon Feb 12 21:23:04 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04.5 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux gpu01 4.4.0-116-generic #140-Ubuntu SMP Mon Feb 12 21:23:04 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy                    1.14.2\r\nprotobuf                 3.6.1\r\ntensorflow-gpu           1.10.1\r\ntensorflow-tensorboard   1.5.1\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.10.1\r\ntf.GIT_VERSION = v1.10.1-0-g4dcfddc5d1\r\ntf.COMPILER_VERSION = v1.10.1-0-g4dcfddc5d1\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /usr/local/cuda/lib64\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nWed Sep  5 16:19:24 2018\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 387.26                 Driver Version: 387.26                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 108...  On   | 00000000:04:00.0 Off |                  N/A |\r\n| 23%   38C    P0    64W / 250W |      1MiB / 11172MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  GeForce GTX 108...  On   | 00000000:05:00.0 Off |                  N/A |\r\n| 23%   36C    P2    65W / 250W |      1MiB / 11172MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  GeForce GTX 108...  On   | 00000000:08:00.0 Off |                  N/A |\r\n| 23%   42C    P0    77W / 250W |      1MiB / 11172MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  GeForce GTX 108...  On   | 00000000:09:00.0 Off |                  N/A |\r\n| 23%   42C    P0    63W / 250W |      1MiB / 11172MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   4  GeForce GTX 108...  On   | 00000000:85:00.0 Off |                  N/A |\r\n| 23%   35C    P0    63W / 250W |      1MiB / 11172MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   5  GeForce GTX 108...  On   | 00000000:86:00.0 Off |                  N/A |\r\n| 23%   38C    P0    73W / 250W |      1MiB / 11172MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   6  GeForce GTX 108...  On   | 00000000:89:00.0 Off |                  N/A |\r\n| 23%   38C    P0    72W / 250W |      1MiB / 11172MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   7  GeForce GTX 108...  On   | 00000000:8A:00.0 Off |                  N/A |\r\n| 23%   36C    P0    71W / 250W |      1MiB / 11172MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a\r\n/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-9.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart.so.9.0.176\r\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart_static.a\r\n/usr/local/cuda-9.1/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-9.1/doc/man/man7/libcudart.7\r\n/usr/local/cuda-9.1/targets/x86_64-linux/lib/libcudart.so.9.1.85\r\n/usr/local/cuda-9.1/targets/x86_64-linux/lib/libcudart_static.a\r\n```\r\n\r\n### Describe the problem\r\n3D convolutions on GPU with large batches fail to calculate the correct result for the last part of the batch. The first entries will be correct, however, after some point the resulting values will be random. This is the case for at least the GTX 1080 Ti and the GeForce GTX 980 Ti gpus. It produces the correct result however on the CPU and at least the K80 GPU.\r\n\r\n### Source code / logs\r\n\r\nA small reproduction script:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n\r\n\r\nrun_on_gpu = True  # Set to false for the correct result, computed on the CPU.\r\nbatch_size = 128  # Try out a large batch, that just fits into memory. Small batches work fine.\r\n\r\n\r\n\r\nrandom_state = np.random.RandomState(42)\r\n\r\ninputs = tf.placeholder(tf.float32, (None, 29, 72, 72, 1), 'inputs')\r\n\r\ndevice_name = '/gpu:0' if run_on_gpu else '/cpu:0'\r\n\r\nwith tf.device(device_name):\r\n    weights = tf.constant(random_state.randn(3, 3, 3, 1, 32).astype(np.float32))\r\n    outputs = tf.nn.conv3d(inputs, weights, strides=(1, 1, 1, 1, 1), padding='SAME', dilations=(1, 1, 1, 1, 1))\r\n    weights = tf.constant(random_state.randn(1, 1, 1, 32, 16).astype(np.float32))\r\n    outputs = tf.nn.conv3d(outputs, weights, strides=(1, 1, 1, 1, 1), padding='VALID', dilations=(1, 1, 1, 1, 1))\r\n\r\nsession = tf.Session()\r\n\r\nrandom_inputs = random_state.randn(batch_size, 29, 72, 72, 1).astype(np.float32)\r\n\r\na = session.run(outputs, feed_dict={inputs: random_inputs})[-1]\r\nb = session.run(outputs, feed_dict={inputs: random_inputs[-1:]})[0]\r\n\r\n# Should print the same line, twice.\r\nprint(a.shape, a.ravel()[0])\r\nprint(b.shape, b.ravel()[0])\r\n```\r\n\r\nThis script should print the same line twice.\r\n\r\nExpected result:\r\n```\r\n(29, 72, 72, 16) -5.843975\r\n(29, 72, 72, 16) -5.843975\r\n```\r\n\r\nActual result:\r\n```\r\n(29, 72, 72, 16) -4.591032\r\n(29, 72, 72, 16) -5.843975\r\n```\r\n\r\nRun on a GeForce GTX 1080 Ti:\r\n\r\n```\r\nPython 3.6.3\r\nTensorflow 1.10.1\r\nNumpy 1.15.1\r\n\r\n2018-09-05 15:55:27.172809: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-09-05 15:55:27.685907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\r\npciBusID: 0000:8a:00.0\r\ntotalMemory: 10.91GiB freeMemory: 10.75GiB\r\n2018-09-05 15:55:27.685952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0\r\n2018-09-05 15:55:28.161475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-09-05 15:55:28.161524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 \r\n2018-09-05 15:55:28.161532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N \r\n2018-09-05 15:55:28.161948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10398 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:8a:00.0, compute capability: 6.1)\r\n\r\n(29, 72, 72, 16) -4.591032\r\n(29, 72, 72, 16) -5.843975\r\n```\r\n\r\nRun on a GeForce GTX 980 Ti:\r\n\r\n```\r\nPython 3.6.3\r\nTensorflow 1.5.1\r\nNumpy 1.14.2\r\n\r\n2018-09-05 16:05:54.557373: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-09-05 16:05:57.096399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties:\r\nname: GeForce GTX 980 Ti major: 5 minor: 2 memoryClockRate(GHz): 1.076\r\npciBusID: 0000:02:00.0\r\ntotalMemory: 5.94GiB freeMemory: 5.83GiB\r\n2018-09-05 16:05:57.096467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:02:00.0, compute capability: 5.2)\r\n\r\n(29, 72, 72, 16) -4.591032\r\n(29, 72, 72, 16) -5.843975\r\n```\r\n\r\nRun on a K80:\r\n\r\n```\r\nPython 3.6.5\r\nTensorflow 1.5.1\r\nNumpy 1.15.0\r\n\r\n2018-09-05 14:37:31.279189: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-09-05 14:37:32.131417: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-09-05 14:37:32.131763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties:\r\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\r\npciBusID: 0000:00:1e.0\r\ntotalMemory: 11.17GiB freeMemory: 11.10GiB\r\n2018-09-05 14:37:32.131795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)\r\n\r\n(29, 72, 72, 16) -5.843975\r\n(29, 72, 72, 16) -5.843975\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Done. Please look at this as it has quite an impact on using 3D convolutions.", "This is not just a problem with large batch sizes, but rather, large inputs. The script:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n\r\n\r\nrun_on_gpu = True  # Set to false for the correct result, computed on the CPU.\r\n\r\n\r\n\r\nrandom_state = np.random.RandomState(42)\r\n\r\ninputs = tf.placeholder(tf.float32, (None, 1, 1, 1, 1), 'inputs')\r\n\r\ndevice_name = '/gpu:0' if run_on_gpu else '/cpu:0'\r\n\r\nwith tf.device(device_name):\r\n    outputs = tf.tile(inputs, (1, 160, 320, 320, 16))\r\n    weights = tf.constant(random_state.randn(1, 1, 1, 16, 16).astype(np.float32))\r\n    outputs = tf.nn.conv3d(outputs, weights, strides=(1, 1, 1, 1, 1), padding='VALID')\r\n\r\nsession = tf.Session()\r\n\r\nrandom_inputs = random_state.randn(1, 1, 1, 1, 1).astype(np.float32)\r\n\r\na = session.run(outputs, feed_dict={inputs: random_inputs})\r\n\r\nprint(a.shape, a.ravel()[-1])\r\n```\r\n\r\nProduces different results for the GTX 1080 Ti and CPU.", "@robieta Any progress?", "Hi! Apologies for my late response.\r\n\r\nI have replicated your finding that behavior on a 1080 is incorrect. Thank you so much for providing such a clear minimal reproduction.\r\n\r\nI've opened an internal ticket with our op team, and I'll update this issue as that progresses.", "That's really interesting.", "@robieta It has been 2 and a half months. What is the status, because this bug has been confirmed and is impacting training and evaluating large 3D models.", "I can reproduce this too (TF1.12, CUDA9, Ubuntu 16, TitanXP 12GB and Tesla V100 16GB)\r\nThe 3D Conv result on GPU is completely wrong for certain input shapes/batch_sizes.\r\n\r\nWhat triggers is:\r\n1) having at least two 3D convolutions (with or without Relu in between).  a single 3D conv is OK\r\n2) certain input shapes and batch sizes (some are OK, but many produce wrong result)\r\n3) CPU result is always OK\r\n\r\nI've implemented the same test cases in PyTorch and it always works correctly. \r\n\r\nAlso downloading Nvidia docker container of Tensorflow works OK on GPU\r\nhttps://www.nvidia.com/en-us/gpu-cloud/containers/\r\n(those dockers Nvidia rebuilds from source for each Tensorflow version). \r\n   \r\nSo it seems the issues is specifically with \"tensorflow-gpu\" (pip built by Tensorflow)\r\n\r\nIt has been ~8 months this issue was reported.  It's unbelievable how long it takes to resolve it. (especially since this is a basic operation of any 3D network)", "I on the other hand, can no longer reproduce this bug with the snippets that I posted before with:\r\n\r\nTensorflow 1.31.1\r\nCUDA 10.0\r\nNvidia driver 410.79\r\nUbuntu 16.04\r\nPython 3.6.3\r\ncudnn 7.4.2\r\n\r\non a GTX 1080 ti.\r\n\r\n@myron Can you try upgrading to this setup? Do you have a simple reproduction snippet?", "Hi, so I can't test TF 1.13 yet (I cant upgrade to CUDA10 just yet). \r\nBut for my setup, I get this bug (try both images_sizes)\r\n\r\nTF 1.12.2\r\nCUDA9\r\nNVIDIA driver 418.56\r\nUbuntu 16.04\r\nPython 3.6\r\ncudnn 7.5\r\n\r\nhere is the snippet\r\n@gerbenvv, does this work for you without errors?\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nbatch_size = 128  \r\nimage_size = (32,32,72,1)\r\n#image_size = (64,72,64,1)\r\n\r\ninputs = tf.placeholder(tf.float32, (None,)+image_size, 'inputs')\r\nweights1 = tf.convert_to_tensor(np.random.random((3,3,3,1,32)), np.float32)\r\nweights2 = tf.convert_to_tensor(np.random.random((1, 1, 1, 32, 16)), np.float32)\r\nrandom_inputs = np.random.random((batch_size,)+image_size).astype(np.float32)\r\n\r\nsession = tf.Session()\r\n\r\nwith tf.device('/cpu:0'):\r\n    outputs_cpu = tf.nn.conv3d(inputs, weights1, strides=(1,1,1,1,1), padding='SAME')\r\n    outputs_cpu = tf.nn.conv3d(outputs_cpu, weights2, strides=(1,1,1,1,1), padding='SAME')\r\n    a_cpu = session.run(outputs_cpu, feed_dict={inputs: random_inputs})\r\n\r\nwith tf.device('/gpu:0'):\r\n    outputs_gpu = tf.nn.conv3d(inputs, weights1, strides=(1,1,1,1,1), padding='SAME')\r\n    outputs_gpu = tf.nn.conv3d(outputs_gpu, weights2, strides=(1,1,1,1,1), padding='SAME')\r\n    a_gpu = session.run(outputs_gpu, feed_dict={inputs: random_inputs})\r\n  \r\nprint('CPUshape', a_cpu.shape, 'GPUshape', a_gpu.shape)\r\nif np.allclose(a_cpu, a_gpu):\r\n    print('CPU vs GPU, OK (same)')\r\nelse:\r\n    print('CPU vs GPU, bad!!!')\r\n```", "Alright, so upgrading to Tensorflow 1.31.1, CUDA 10.0 solved it for me. \r\nThis issue can probably be closed now."]}, {"number": 22092, "title": "TF Record, Example, and SeqeunceExample inconsistency(?) / Documentation request", "body": "I have posted 2 stack overflow questions regarding TF Records and (Sequence)Examples.\r\nI even had a bounty on one. \r\nDespite only receiving up-votes. Neither received any support.\r\nBoth had an associated Colab document to assist.\r\n\r\nThe questions where\r\n\r\n1. [Store images as byte strings or per channel?]https://stackoverflow.com/questions/52035692/tensorflow-v1-10-store-images-as-byte-strings-or-per-channel)\r\n\r\n2. [Recovering TF Records](https://stackoverflow.com/questions/52064866/tensorflow-1-10-tfrecorddataset-recovering-tfrecords)\r\n\r\nWith the corresponding colabs\r\n\r\n[Colab 1](https://colab.research.google.com/drive/1HUGoXfgxp0A_0eSdaCzutOkFvnYZ-egv)\r\n[Colab 2](https://colab.research.google.com/drive/1M10tbHih5eJ8LiApJSKKpNM79IconYJX)\r\n\r\n\r\nI am creating an issue as I am struggling to see the consistency in the behavior between tf Records, Example, SequenceExample, Feature, Features, FeatureList, FeatureLists, FixLenFeature, FixLenSequenceFeature, and VarLenFeature.\r\n\r\nIn this [Colab](https://colab.research.google.com/drive/1M10tbHih5eJ8LiApJSKKpNM79IconYJX)\r\n\r\nI survey 10 ways of encoding an array / array of arrays.\r\n\r\n-    Example: Int64 feature (int array)\r\n-    Example: Float feature (float array)\r\n-    Example: Bytes feature (int array dumped to byte string)\r\n-    SequenceExample: Int64 feature list (array of int arrays)\r\n-    SequenceExample: Float feature list (array of float arrays)\r\n-    SequenceExample: Bytes feature list (array of int arrays dumped to byte strings)\r\n-    Example: Bytes feature (array of int arrays all of which is dumped to byte string)\r\n-    SequenceExample: Bytes feature list (array of int arrays dumped to byte strings)\r\n-    SequenceExample: Bytes feature list (array of int arrays all of which is dumped to byte string)\r\n-    SequenceExample: Bytes feature list (array of int arrays, where each int is dumped to byte string)\r\n\r\nIn short, with the exception of 8, I was able to 'recover' (write to tf.record and read back the data). However, it should be noted that for methods 7 and 10, the retrieved array is flattened.\r\n\r\nFurther, when I state 'recover' I mean that of course that the feature is wrapped in an addition array. e.g. shape (3, ) becomes (1, 3).\r\n\r\n\r\nAs most tutorials of TF Record, Example and SequenceExample are just a rehashing of the one example provided in the TF Docs (for a movie recommender system, although code is provided for images). \r\n\r\nI think it would be beneficial for a \"style guide\" of sorts, given that one can their data in a myriad of ways. (e.g. are byte strings superior to float feature lists? should one break their image / sequence down per channel? why is there FixLenSeqeuenceFeature but no VarLenSequenceFeature?, if Example and SequenceExample are meant to contain a single data record, why are the only options List based features?)\r\n\r\nI would be happy to contribute to more documentation / examples if I knew the answer to these questions. However, to my unexperienced eyes the mismatch between converting data into a (Sequence)Example and extracting it out from a Record is bewildering.\r\n\r\n\r\n\r\n-------\r\n\r\nTensorFlow Butler requested information:\r\n\r\nHave I written custom code: yes, see linked colabs and S.O. posts.\r\nOS Platform and Distribution: N/a (irrelevant, but Ubuntu 16.04LTS / macOS High Sierra)\r\nTensorFlow installed from: (irrelevant, but conda / Colab's V.M.)\r\nTensorFlow version: 1.10\r\nBazel version: N/a\r\nCUDA/cuDNN version: N/a (irrelevant but latest / Colab's V.M.'s)\r\nGPU model and memory: N/a (irrelevant, but NVIDIA Titan X / NVIDIA Titan V / Colab's GPU)\r\nExact command to reproduce: see linked to code\r\nMobile device: N/a  (irrelevant) \r\n\r\n\r\nThis is more of a \"meta\" question regarding the structuring of Example / SequenceExample, the correspondingly needed Feature, Features, FeatureList, FeatureLists, etc and the parsing equivalents FixedLenFeature, VariableLenFeature, FixedLenSequenceFeature.\r\n\r\nMore specifically:\r\n\r\n- a request for more documentation\r\n- a request for \"best\" practices recording encoding of rank 2+ tensors\r\n\r\n   +  e.g. if I have a sequence in an _numpy.ndarray_ with _n_ channels should I \"dump\" (call _.tostring()_) on the entire sequence and store in a BytesFeature in an Example? or split each channel up into a Float/Int Feature (or dump to BytesFeature) in an Example / SequenceExample. \r\n\r\n-  a request for \"best\" practices as to why ever use Example, when it seems that the \"context features\" are equivalent and then if sequence features are needed later it is easier to adapt? (i.e. the difference between context features in sequence example and normal features of example rather than just calling context features \"meta-data\" of the sequences)\r\n\r\n- a request for \"best' practices for recording rank 0 tensors (as they have to be wrapped into a feature list, so should similarly typed features be concatenated together)\r\n\r\n- a request for elucidating why sometimes decoding a bytes array losses the rank from which it was encoded (see linked colab)\r\n\r\n- a request for a mid-tier api at the feature level e.g. remove the need for the user to define how a feature should be encoded as a record and then decoded  (parsed) from a serialized record. I have a conceptual prototype that I can include here or in another colab if interested. \r\n\r\netc, etc\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@tensorflowbutler O.P. updated ", "@poxvoculi here is a [concept](https://colab.research.google.com/drive/1HrSYF1I7rBGaNQ7388Ss3epWPLTloEC6)", "tf.Example encoding (or more generally, proto encoding) is a thing for Servo, and for TFRecords, but we don't talk about it much in our main docs because it's sort of an advanced topic. Not sure this is the most important thing about our docs right now, but leaving it here for consideration.", "@martinwicke while I understand that TFRecords are sort of an advanced topic, how to use them should be transparent as their use alone can accelerate training ~30%\r\n\r\nAnyway, the main thing is partly dealing with the inconsistency / duplicate code needed for read/write  to TF Records. \r\n\r\nI find it currently incredibly infuriating the number of hoops that have to be jumped through to use TFRecords with a custom estimator because certain operations can not be done inside `dataset.map` (at least not in the traditional mode, perhaps with eager...) e.g. unwrapping the forced requirements of lists and decoding binary strings\r\n\r\nSo I made this [concept](https://gitlab.com/SumNeuron/fio) which if you clone,  run a jupyter notebook in `/jupyter` and open the file `Demo`  you can see an example that requires a single interface to write to and read from a TF Record. However to truly get the values back, one needs to wait until after sessions.run otherwise you get an error...\r\n\r\n\r\n", "@martinwicke further why is int64 feature types even a thing? since most tf layer functions will through an error when seeing an integer typed tensor?", "Derek or Jiri may have some ideas how we can make it easier to use TFRecords.", "@martinwicke, @mrry @jsimsa  I provided a concept (see above), which involves defining a singular schema for the data. This works for both example and sequence example, because to convert to a sequence example, one must only specify what features are the sequence features.\r\n\r\nNonetheless, it is clear that the interface to TF Records is clunky. Consider a `serving_input_receiver_fn` which requires, once again, use of the `tf.FixedLenFeature` / `tf.VarLenFeature`.  All of this could be circumvented with the singular data schema object that could serve to read / write to tf records as well as parse those read records. \r\n\r\nThen users, in addition to a config json, could have a schema json which makes it clear what the expected information is for a singular example. ", "@lamberta @mrry @jsimsa @MarkDaoust  I am still waiting for some assistance with this. Use of TF records, even with `tf.data.TFRecordDataset(<files>)` can be problematic, especially with `SequenceExamples` in unwrapping the forced wrapped features and feating into an input_fn for a custom estimator. \r\n\r\n\r\nMy point is that it is unclear the best way to do something simple with TF records and given how much of the \"higher\" level apis require knowledge of lower level apis, it is just unacceptable the lack of support. \r\n", "@martinwicke  I know TF is in the midst of a huge transition to TF2. However, should it be of interest to anyone in the TF team I submitted a proposal for \"summer of code\" along the line of working with TF Records / (Sequence)Example / Features. "]}, {"number": 22080, "title": "The performance of FusedBatchNormGradGrad is very low", "body": "When I test the performance of GAN model (https://github.com/tensorflow/models/tree/master/research/gan), I find to use FusedBatchNorm can boost the performance by 20% to 30% (https://github.com/tensorflow/models/issues/5206).\r\n\r\nHowever, when use gan_loss with gradient_penalty, there is no performance improvement with FusedBatchNorm.  I find the root cause is FusedBatchNormGradGrad is very low performance.\r\n\r\nI propose to set fused_batch_norm to false on (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/gan/python/losses/python/losses_impl.py#L367) to use BatchNormGradGrad to replace FusedBatchNormGradGrad. There is about 20% performance improvement with this change. \r\nChange\r\n`disc_interpolates = discriminator_fn(interpolates, generator_inputs)`\r\nto \r\n`disc_interpolates = discriminator_fn(interpolates, generator_inputs, fused_batch_norm=false)`\r\n   \r\n", "comments": ["@joel-shor , any comments for this, thanks. ", "This is very strange. I'd like to investigate. How did you benchmark the performance degradation? If it was code, would you mind pasting the code you used to benchmark?", "Just run https://github.com/tensorflow/models/blob/master/research/gan/cifar/train.py with some CPU specific setting. \r\nI test on Intel CPU, no GPU. ", "Can you paste your sample output?", "**Before change:**\r\n\r\n./cifar/train.py  -dl /dataset/tensorflow/cifar10/ --num_inter_threads 2 --num_intra_threads 28 --batch_size 32\r\nINFO:tensorflow:SyncReplicasV2: replicas_to_aggregate=9; total_num_replicas=10\r\nINFO:tensorflow:SyncReplicasV2: replicas_to_aggregate=9; total_num_replicas=10\r\nWARNING:tensorflow:update_ops in create_train_op does not contain all the  update_ops in GraphKeys.UPDATE_OPS\r\nWARNING:tensorflow:update_ops in create_train_op does not contain all the  update_ops in GraphKeys.UPDATE_OPS\r\n==========inter 2 intra: 28\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nINFO:tensorflow:Graph was finalized.\r\n2018-09-05 16:35:18.421355: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\r\nINFO:tensorflow:Restoring parameters from ./cifar-train-log/unconditional/model.ckpt-2200\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nINFO:tensorflow:Saving checkpoints for 2200 into ./cifar-train-log/unconditional/model.ckpt.\r\n\r\nUser settings:\r\n\r\n   KMP_AFFINITY=granularity=fine,verbose,compact,1,0\r\n   KMP_BLOCKTIME=4\r\n   KMP_SETTINGS=1\r\n   OMP_NUM_THREADS=28\r\n\r\nINFO:tensorflow:Tensor(\"status_message:0\", shape=(), dtype=string) = Starting train step: 2200\r\nINFO:tensorflow:Tensor(\"status_message:0\", shape=(), dtype=string) = Starting train step: 2210 (1.506 sec)\r\nINFO:tensorflow:Tensor(\"status_message:0\", shape=(), dtype=string) = Starting train step: 2220 (1.386 sec)\r\nINFO:tensorflow:Tensor(\"status_message:0\", shape=(), dtype=string) = Starting train step: 2230 (1.368 sec)\r\nINFO:tensorflow:Tensor(\"status_message:0\", shape=(), dtype=string) = Starting train step: 2240 (1.390 sec)\r\nINFO:tensorflow:Tensor(\"status_message:0\", shape=(), dtype=string) = Starting train step: 2250 (1.401 sec)\r\nINFO:tensorflow:Tensor(\"status_message:0\", shape=(), dtype=string) = Starting train step: 2260 (1.437 sec)\r\nINFO:tensorflow:Tensor(\"status_message:0\", shape=(), dtype=string) = Starting train step: 2270 (1.462 sec)\r\nINFO:tensorflow:Tensor(\"status_message:0\", shape=(), dtype=string) = Starting train step: 2280 (1.436 sec)\r\nINFO:tensorflow:Tensor(\"status_message:0\", shape=(), dtype=string) = Starting train step: 2290 (1.417 sec)\r\nINFO:tensorflow:global_step/sec: 6.78513\r\n\r\n**After Change:**\r\npython ./cifar/train.py  -dl /dataset/tensorflow/cifar10/ --num_inter_threads 2 --num_intra_threads 28 --batch_size 32\r\nINFO:tensorflow:SyncReplicasV2: replicas_to_aggregate=9; total_num_replicas=10\r\nINFO:tensorflow:SyncReplicasV2: replicas_to_aggregate=9; total_num_replicas=10\r\nWARNING:tensorflow:update_ops in create_train_op does not contain all the  update_ops in GraphKeys.UPDATE_OPS\r\nWARNING:tensorflow:update_ops in create_train_op does not contain all the  update_ops in GraphKeys.UPDATE_OPS\r\n==========inter 2 intra: 28\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nINFO:tensorflow:Graph was finalized.\r\n2018-09-05 16:51:42.265883: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\r\nINFO:tensorflow:Restoring parameters from ./cifar-train-log/unconditional/model.ckpt-500\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nINFO:tensorflow:Saving checkpoints for 500 into ./cifar-train-log/unconditional/model.ckpt.\r\n\r\nUser settings:\r\n\r\n   KMP_AFFINITY=granularity=fine,verbose,compact,1,0\r\n   KMP_BLOCKTIME=4\r\n   KMP_SETTINGS=1\r\n   OMP_NUM_THREADS=28\r\n\r\nINFO:tensorflow:Tensor(\"status_message:0\", shape=(), dtype=string) = Starting train step: 700 (1.292 sec)\r\nINFO:tensorflow:Tensor(\"status_message:0\", shape=(), dtype=string) = Starting train step: 710 (1.266 sec)\r\nINFO:tensorflow:Tensor(\"status_message:0\", shape=(), dtype=string) = Starting train step: 720 (1.193 sec)\r\nINFO:tensorflow:Tensor(\"status_message:0\", shape=(), dtype=string) = Starting train step: 730 (1.222 sec)\r\nINFO:tensorflow:Tensor(\"status_message:0\", shape=(), dtype=string) = Starting train step: 740 (1.248 sec)\r\nINFO:tensorflow:Tensor(\"status_message:0\", shape=(), dtype=string) = Starting train step: 750 (1.256 sec)\r\nINFO:tensorflow:Tensor(\"status_message:0\", shape=(), dtype=string) = Starting train step: 760 (1.235 sec)\r\nINFO:tensorflow:Tensor(\"status_message:0\", shape=(), dtype=string) = Starting train step: 770 (1.223 sec)\r\nINFO:tensorflow:Tensor(\"status_message:0\", shape=(), dtype=string) = Starting train step: 780 (1.244 sec)\r\nINFO:tensorflow:Tensor(\"status_message:0\", shape=(), dtype=string) = Starting train step: 790 (1.201 sec)\r\nINFO:tensorflow:global_step/sec: 8.10213", "WARNING:tensorflow:update_ops in create_train_op does not contain all the update_ops in GraphKeys.UPDATE_OPS\r\nWARNING:tensorflow:update_ops in create_train_op does not contain all the update_ops in GraphKeys.UPDATE_OPS\r\nDo you solve this problems? I have the same question,please give me some advice to solve this problem,Thanks.\r\n", "I propose to set fused_batch_norm to false on (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/gan/python/losses/python/losses_impl.py#L367) to use BatchNormGradGrad to replace FusedBatchNormGradGrad. There is about 20% performance improvement with this change.\r\nChange\r\ndisc_interpolates = discriminator_fn(interpolates, generator_inputs)\r\nto\r\ndisc_interpolates = discriminator_fn(interpolates, generator_inputs, fused_batch_norm=false)\r\n\r\nHere is a workaround for this problem. ", "print(tf.get_collection(tf.GraphKeys.UPDATE_OPS)) is tf.operation.but print(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)) is tf.variable,why,"]}, {"number": 22069, "title": "freeze_graph.py with --input_saved_model argument gives `IOError: SavedModel file does not exist`", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nno\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nUbuntu 18.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\nn/a\r\n- **TensorFlow installed from (source or binary)**:\r\npip\r\n- **TensorFlow version (use command below)**:\r\n1.10.1\r\n- **Python version**:\r\n2.7.15rc1\r\n- **Bazel version (if compiling from source)**:\r\nn/a\r\n- **GCC/Compiler version (if compiling from source)**:\r\nn/a\r\n- **CUDA/cuDNN version**:\r\nn/a\r\n- **GPU model and memory**:\r\nn/a\r\n- **Exact command to reproduce**:\r\n```\r\n#first, train the model with\r\npython tensorflow/models/research/deeplab/train.py \\\r\n    --logtostderr \\\r\n    --clone_on_cpu=True \\\r\n    --training_number_of_steps=900 \\ # 90000 \\\r\n    --train_split=\"train\" \\\r\n    --model_variant=\"mobilenet_v2\" \\\r\n    --atrous_rates=6 \\\r\n    --atrous_rates=12 \\\r\n    --atrous_rates=18 \\\r\n    --output_stride=16 \\\r\n    --decoder_output_stride=4 \\\r\n    --train_crop_size=128 \\\r\n    --train_crop_size=128 \\\r\n    --train_batch_size=1 \\\r\n    --dataset=\"cityscapes\" \\\r\n    --tf_initial_checkpoint=${PATH_TO_INITIAL_CHECKPOINT} \\\r\n    --train_logdir=${PATH_TO_TRAIN_DIR} \\\r\n    --dataset_dir=${PATH_TO_DATASET}\r\n\r\n#then try to freeze the output\r\npython tensorflow/python/tools/freeze_graph.py \\\r\n     --input_saved_model=${PATH_TO_TRAIN_DIR} \\\r\n     --output_graph=${PATH_TO_TRAIN_DIR}/frozen_graph.pb \\\r\n     --output_node_names=MobilenetV2/expanded_conv_16/output\r\n```\r\n\r\n### Describe the problem\r\nThe first problem is that the train.py script seems to change the structure of the graph. Specifically, the input and output nodes from the `initial_checkpoint` are missing. The normal `output_node_names` such as softmax, predictions etc do not appear in the trained graph.pbtxt, which is why I have used `MobilenetV2/expanded_conv_16/output`. The ImageTensor also does not appear as an input_node.\r\nHowever, the problem with missing nodes is not the focus of this issue.\r\n\r\nThe second problem is that `freeze_graph.ph` with the `--input_saved_model` option gives \r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/username/.local/lib/python2.7/site-packages/tensorflow/python/tools/freeze_graph.py\", line 382, in <module>\r\n    run_main()\r\n  File \"/home/username/.local/lib/python2.7/site-packages/tensorflow/python/tools/freeze_graph.py\", line 379, in run_main\r\n    app.run(main=my_main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/username/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/home/username/.local/lib/python2.7/site-packages/tensorflow/python/tools/freeze_graph.py\", line 378, in <lambda>\r\n    my_main = lambda unused_args: main(unused_args, flags)\r\n  File \"/home/username/.local/lib/python2.7/site-packages/tensorflow/python/tools/freeze_graph.py\", line 272, in main\r\n    flags.saved_model_tags, checkpoint_version)\r\n  File \"/home/username/.local/lib/python2.7/site-packages/tensorflow/python/tools/freeze_graph.py\", line 229, in freeze_graph\r\n    input_saved_model_dir, saved_model_tags).graph_def\r\n  File \"/home/username/.local/lib/python2.7/site-packages/tensorflow/python/tools/saved_model_utils.py\", line 42, in get_meta_graph_def\r\n    saved_model = reader.read_saved_model(saved_model_dir)\r\n  File \"/home/username/.local/lib/python2.7/site-packages/tensorflow/contrib/saved_model/python/saved_model/reader.py\", line 55, in read_saved_model\r\n    raise IOError(\"SavedModel file does not exist at: %s\" % saved_model_dir)\r\nIOError: SavedModel file does not exist at: /path/given/in/PATH_TO_TRAIN_DIR\r\n\r\n$ls ${PATH_TO_TRAIN_DIR}\r\n-rw-r--r-- 1 username username    21786 Sep  3 15:28 model.ckpt-0.index\r\n-rw-r--r-- 1 username username 21955616 Sep  3 15:28 model.ckpt-0.data-00000-of-00001\r\n-rw-r--r-- 1 username username  3070908 Sep  3 15:28 model.ckpt-0.meta\r\n-rw-r--r-- 1 username username  6081043 Sep  4 10:54 graph.pbtxt\r\n-rw-r--r-- 1 username username 21955616 Sep  4 10:54 model.ckpt-900.data-00000-of-00001\r\n-rw-r--r-- 1 username username    21786 Sep  4 10:54 model.ckpt-900.index\r\n-rw-r--r-- 1 username username  3070908 Sep  4 10:54 model.ckpt-900.meta\r\n-rw-r--r-- 1 username username      541 Sep  4 10:54 checkpoint\r\n\r\n```\r\n", "comments": ["I have since discovered that some of the options I was supplying to `train.py` were not recommended for MobileNetV2. My goal is to keep the same network structure of MobileNetV2 (as far as possible, given that I am using a different number of classes), but retrain the weights. If the network structure would stay the same, I think `freeze_graph.py` would have no problems with missing nodes.\r\n\r\nSee also https://stackoverflow.com/questions/52177020/trying-to-retrain-a-tensorflow-model-input-and-output-nodes-disappear", "Closing this issue for now. Feel free to reopen.", "What is the reason for closing? I have seen examples elsewhere where people have the same problem, so I don't think it's just me. I think it could be a user error which we all have in common, or a bug. Either way, I don't think it has been resolved, so I would think that it shouldn't be closed?", "@chrisrapson , it looks like you are trying to freeze a checkpoint, not a SavedModel. A SavedModel should have a saved_model.pb and associated variables-- please see https://www.tensorflow.org/guide/saved_model", "@karmel yes, I am trying to freeze a checkpoint, not a SavedModel. Isn't that what `freeze_graph.py` is for? The first line of `freeze_graph.py` reads:\r\n\r\n`Converts checkpoint variables into Const ops in a standalone GraphDef file.`\r\n\r\nIf what I am doing is not the correct way to convert `ckpt` files to `pb` files, then what is?", "A SavedModel includes checkpointed vars, so that comment refers to the component of the SavedModel that is checkpointed vars, which it inserts into the other component, which is the graph def. I don't think a checkpoint alone has enough information in it to produce a frozen graph currently. @gargn to confirm.", "In order to freeze a graph, you need to provide either a SavedModel or a non-frozen GraphDef (i.e. a GraphDef with variables) and the checkpoints. Freeze graph can then produce a GraphDef with all of the weights represented as constants.\r\n\r\nIn your case you might be able to freeze the graph with a command such as the following:\r\n```\r\nbazel build tensorflow/python/tools:freeze_graph && \\\r\nbazel-bin/tensorflow/python/tools/freeze_graph \\\r\n--input_graph=${PATH_TO_TRAIN_DIR}/graph.pbtxt \\\r\n--input_binary=false \\\r\n--input_checkpoint=${PATH_TO_TRAIN_DIR}/checkpoint/model.ckpt-100 \\\r\n--output_graph=${PATH_TO_TRAIN_DIR}/frozen_graph.pb \\\r\n--output_node_names=MobilenetV2/expanded_conv_16/output\r\n```", "Thanks @gargn, that solves the second problem I referred to, and allows me to successfully generate a frozen graph from my checkpoint. Unfortunately, when I try to use the frozen graph, it tells me\r\n\r\n`TypeError: Cannot interpret feed_dict key as Tensor: the name 'ImageTensor:0' refers to a Tensor which does not exist. The operation, 'ImageTensor', does not exist in the graph.`\r\n\r\nSo the first problem still persists. I expected my checkpoint graph to have the same input/output nodes as the `tf_initial_checkpoint`, and for this checkpoint to have the same input/output nodes as the frozen graph which was bundled with it in a tar file. (Specifically, [this tar file](http://download.tensorflow.org/models/deeplabv3_mnv2_pascal_train_aug_2018_01_29.tar.gz).)\r\n\r\nIs that expectation correct? If not, how do I take a downloaded model (pb or ckpt) and retrain it? When I testedt the downloaded pb file, I found that it is already very good at image segmentation. I am looking to modify it slightly to segment only 4 classes instead of 30, and to teach it these classes by training it on my own data.", "Can you provide the exact steps to reproduce this problem? Namely the `train.py` script, the commands you are using to run the training script, and any additional files used during the retraining process?\r\n \r\n@karmel might have context?", "The command is as I wrote in the original issue. The `train.py` script is part of the tensorflow repo in the models/research/deeplab directory. The last three arguments are:\r\ntf_initial_checkpoint - which is the index file, downloaded as part of the tar file I linked in my previous message\r\ntrain_logdir - which is an empty directory\r\ndataset_dir - which is a directory filled with tfrecords (created with the `convert_cityscapes.sh` script in the models/research/deeplab/datasets directory)\r\n"]}, {"number": 22059, "title": "Optimizing slice of variable not possible", "body": "Applying the gradient of a variable slice currently results in a `NotImplemented` error of tf.train.Optimizer.\r\n\r\n**The following two examples are working:**\r\n```python\r\n### WORKING ###\r\nX = tf.Variable(2, dtype=tf.float32)\r\ny = tf.constant(10, dtype=\"float32\")\r\nloss = y - (X*X)\r\n\r\nvariables=[X]\r\ngradient = tf.gradients(loss, variables)\r\ngradient = [(g, v) for g, v in zip(gradient, variables)]\r\ntrain_op = tf.train.AdamOptimizer().apply_gradients(gradient)\r\n```\r\n\r\n```python\r\n### WORKING ###\r\nbig_X = tf.Variable([2,3,4], dtype=tf.float32)\r\nX = big_X[0]\r\ny = tf.constant(10, dtype=\"float32\")\r\nloss = y - (X*X)\r\n\r\ntrain_op = train_op = tf.train.AdamOptimizer().minimize(loss)\r\n```\r\n\r\n**The following example throws an error:**\r\n```python\r\n### NOT WORKING ###\r\nbig_X = tf.Variable([2,3,4], dtype=tf.float32)\r\nX = big_X[0]\r\ny = tf.constant(10, dtype=\"float32\")\r\nloss = y - (X*X)\r\n\r\nvariables=[X]\r\ngradient = tf.gradients(loss, variables)\r\ngradient = [(g, v) for g, v in zip(gradient, variables)]\r\ntrain_op = tf.train.AdamOptimizer().apply_gradients(gradient)\r\n```\r\nThe error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-22-10282dee2005>\", line 10, in <module>\r\n    train_op = tf.train.AdamOptimizer().apply_gradients(gradient)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/optimizer.py\", line 605, in apply_gradients\r\n    update_ops.append(processor.update_op(self, grad))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/optimizer.py\", line 189, in update_op\r\n    raise NotImplementedError(\"Trying to update a Tensor \", self._v)\r\nNotImplementedError: ('Trying to update a Tensor ', <tf.Tensor 'strided_slice_9:0' shape=() dtype=float32>)\r\n```\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: NA\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.10.1-0-g4dcfddc5d1 1.10.1\r\n- **Python version**: 3.6.5\r\n- **Bazel version (if compiling from source)**: NA\r\n- **GCC/Compiler version (if compiling from source)**: NA\r\n- **CUDA/cuDNN version**: NA\r\n- **GPU model and memory**: NA\r\n- **Exact command to reproduce**: NA", "comments": ["I debugged this problem:\r\nSince this variable slice is a Tensor, it gets wrapped by the class `_TensorProcessor` in `tensorflow/python/training/optimizer.py`.\r\nSince `update_op()` is not implemented in this special case, the gradient cannot be applied.\r\n\r\nThere would be multiple solutions to this problem:\r\n- Make variable slices return another special variable type\r\n- Implement `update_op()` in `_TensorProcessor` for tensors supporting some `.assign()` method\r\n", "I cannot quite understand what are the reasons for this to not be implemented?\r\nThis, combined with a still unresolved issue https://github.com/tensorflow/tensorflow/issues/1325 where imported model's variables are not visible makes retraining a pretrained model practically impossible. ", "@Hoeze Is this still an issue? Thanks!", "@jvishnuvardhan Yes, the issue is still the same", "Are there any news on this? The implementation of this would be helpful for us as well", "Hi @rmlarsen, is some extension to lift this limitation on the TensorFlow roadmap? Applying an optimizer to a slice of a variable would unblock quite a few more flexible approaches to training certain classes of models.", "Was able to replicate the issue with TF v2.5 ,please find the [gist](https://colab.research.google.com/gist/mohantym/d56d576d5b9be925de8e765d3a17746e/22059.ipynb) here .Thanks!"]}, {"number": 22028, "title": "Graph Transorform fold_constants does not work with NoOp as output node", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nOS X 10.13.6\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\nN/A\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n- **TensorFlow version (use command below)**:\r\nv1.10.0-rc1-19-g656e7a2b34 1.10.0\r\n- **Python version**:\r\nPython 3.6.5\r\n- **Bazel version (if compiling from source)**:\r\nN/A\r\n- **GCC/Compiler version (if compiling from source)**:\r\nN/A\r\n- **CUDA/cuDNN version**:\r\nN/A\r\n- **GPU model and memory**:\r\nN/A\r\n- **Exact command to reproduce**:\r\nN/A\r\n\r\n### Describe the problem\r\nI run the [Graph Transform](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms/) tool and apply the transformation `fold_constants(ignore_errors=true)`. One of the output nodes I specify is a variable initializer (i.e. a `NoOp`). This causes the `fold_constants` transformation to fail and my graph is not optimized.\r\n\r\n### Source code / logs\r\n```python\r\nfrom tensorflow.tools import graph_transforms\r\n\r\nwith tf.Graph().as_default():\r\n    # Setup a graph\r\n    \r\n    tf.variables_initializer(variables_to_initialize, name='initializer')\r\n    \r\n    graph_def = tf.get_default_graph().as_graph_def()\r\n\r\noutput_nodes = ['graph_output', 'initializer']\r\ngraph_def = graph_transforms.TransformGraph(\r\n        graph_def, input_nodes, output_nodes, [\r\n           'fold_constants(ignore_errors=true)'\r\n        ])\r\n```\r\nOutput\r\n\r\n    2018-09-03 14:28:06.751967: I tensorflow/tools/graph_transforms/transform_graph.cc:318] Applying fold_constants\r\n    2018-09-03 14:28:06.756892: E tensorflow/tools/graph_transforms/transform_graph.cc:333] fold_constants: Ignoring error Tried to fetch data for 'initializer', which produces no output.  To run to a node but not fetch any data, pass 'initializer' as an argument to the 'target_node_names' argument of the Session::Run API.\r\n", "comments": []}, {"number": 22027, "title": "tfcompile: minimum_alignment_for_allocation and kAlign = 64", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04.1\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: -\r\n- **TensorFlow installed from (source or binary)**: Yes\r\n- **TensorFlow version (use command below)**: v1.10.1-0-g4dcfddc5d1\r\n- **Python version**: 3.6.5\r\n- **Bazel version (if compiling from source)**: 0.16.1\r\n- **GCC/Compiler version (if compiling from source)**: 7.3.0\r\n- **CUDA/cuDNN version**: -\r\n- **GPU model and memory**: -\r\n- **Exact command to reproduce**: -\r\n\r\n\r\n### Describe the problem\r\n\r\ntfcompile uses `minimum_alignment_for_allocation` to check if it can call Eigen on a tensor. `minimum_alignment_for_allocation` uses the minimum alignment of `malloc` but the buffers that tfcompile uses are allocated by `MallocContiguousBuffers` which currently always returns buffers with a minimum alignment of `kAlign` = 64.\r\n\r\n\r\n### Source code / logs\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/4dcfddc5d12018a5a0fdca652b9221ed95e9eb23/tensorflow/compiler/xla/service/cpu/target_machine_features.cc#L34-L43\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/4dcfddc5d12018a5a0fdca652b9221ed95e9eb23/tensorflow/compiler/aot/runtime.h#L36-L37\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/4dcfddc5d12018a5a0fdca652b9221ed95e9eb23/tensorflow/compiler/aot/runtime.h#L29", "comments": ["I'm wondering what the bug / issue here is?", "The issue is that if one compiles a graph using tfcompile, then the resulting code does not use Eigen to compute the convolution and matrix multiplication. This is because tfcompile assumes that the data for Eigen is not properly aligned, even though they are.\r\n\r\nI noticed the issue on a 32 bit target, but I think this will also happen on a 64 bit target."]}, {"number": 22023, "title": "Tensorflow build fails with vectorization ", "body": "### System information\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Ubuntu 16.04, 18.04 \r\n- **TensorFlow installed from (source or binary)**:  source \r\n- **TensorFlow version (use command below)**:  1.8.0 \r\n- **Python version**:  2.7.15rc1\r\n- **Bazel version (if compiling from source)**:  0.12.0\r\n- **GCC/Compiler version (if compiling from source)**: gcc-7.3.0, gcc-6.3.0\r\n- **CUDA/cuDNN version**: NA\r\n- **GPU model and memory**: NA\r\n- **Exact command to reproduce**:  ` bazel build -c opt  --incompatible_load_argument_is_label=false --incompatible_disallow_uncalled_set_constructor=false  --config=opt  --copt=\"-mzvector\" //tensorflow/tools/pip_package:build_pip_package`\r\n\r\n**Description:** \r\nWhile building TensorFlow with vectorization on s390x platform, faced following issues :\r\n**With gcc 6.3.0 , Ubuntu 16.04, z13**  :\r\n\r\n```\r\nINFO: From Compiling external/snappy/snappy-sinksource.cc [for host]:\r\ncc1plus: warning: command line option '-Wno-implicit-function-declaration' is valid for C/ObjC but not for C++\r\nSlow read: a 7184608-byte read from /root/.cache/bazel/_bazel_root/9b63c66f147d91a5644a0e81d48c020e/external/org_sqlite/sqlite3.c took 26065ms.\r\nERROR: /root/.cache/bazel/_bazel_root/9b63c66f147d91a5644a0e81d48c020e/external/org_sqlite/BUILD:35:1: C++ compilation of rule '@org_sqlite//:org_sqlite' failed (Exit 1)\r\nexternal/org_sqlite/sqlite3.c: In function 'vdbeRecordCompareInt':\r\nexternal/org_sqlite/sqlite3.c:76283:1: internal compiler error: in maybe_record_trace_start, at dwarf2cfi.c:2284\r\n}\r\n\u02c6\r\n0x1385bc7 maybe_record_trace_start\r\n        ../../gcc-6.3.0/gcc/dwarf2cfi.c:2284\r\n0x1388285 scan_trace\r\n        ../../gcc-6.3.0/gcc/dwarf2cfi.c:2462\r\n0x13888dd create_cfi_notes\r\n        ../../gcc-6.3.0/gcc/dwarf2cfi.c:2616\r\n0x13888dd execute_dwarf2_frame\r\n        ../../gcc-6.3.0/gcc/dwarf2cfi.c:2974\r\n0x13888dd execute\r\n        ../../gcc-6.3.0/gcc/dwarf2cfi.c:3454\r\nPlease submit a full bug report,\r\nwith preprocessed source if appropriate.\r\nPlease include the complete backtrace with any bug report.\r\nSee <http://gcc.gnu.org/bugs.html> for instructions.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 1795.018s, Critical Path: 24.14s\r\nFAILED: Build did NOT complete successfully\r\n```\r\n**With gcc 6.3.0/7.3.0 , Ubuntu 16.04, z14**  :\r\n\r\n```\r\nERROR: /tensorflow/tensorflow/core/kernels/BUILD:436:1: C++ compilation of rule '//tensorflow/core/kernels:split_lib' failed (Exit 1)\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:427:0,\r\n                from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14,\r\n                from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                from ./tensorflow/core/kernels/split_lib.h:20,\r\n                from tensorflow/core/kernels/split_lib_cpu.cc:18:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/ZVector/PacketMath.h: In function 'Eigen::internal::Packet4f Eigen::internal::vec_splat_packet4f(const Packet4f&)':\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/ZVector/PacketMath.h:657:11: error: request for member 'v4f' in 'splat', which is of non-class type 'Eigen::internal::Packet4f {aka __vector(4) float}'\r\n    splat.v4f[0] = vec_splat(from.v4f[0], 0);\r\n          \u02c6\u02dc\u02dc\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/ZVector/PacketMath.h:657:35: error: request for member 'v4f' in 'from', which is of non-class type 'const Packet4f {aka const __vector(4) float}'\r\n    splat.v4f[0] = vec_splat(from.v4f[0], 0);\r\n                                  \u02c6\u02dc\u02dc\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/ZVector/PacketMath.h:657:44: internal compiler error: tree check: expected class 'type', have 'exceptional' (error_mark) in s390_fn_types_compatible, at config/s390/s390-c.c:727\r\n    splat.v4f[0] = vec_splat(from.v4f[0], 0);\r\n                                           \u02c6\r\n0x80cc535f tree_class_check_failed(tree_node const*, tree_code_class, char const*, int, char const*)\r\n       ../../gcc-6.3.0/gcc/tree.c:9704\r\n```\r\n\r\n**With gcc 7.3.0 , Ubuntu 18.04, z14**  :\r\n```\r\n\r\nINFO: From Compiling tensorflow/contrib/lite/util.cc:\r\ntensorflow/contrib/lite/util.cc: In function 'TfLiteIntArray* tflite::ConvertArrayToTfLiteIntArray(int, const int*)':\r\ntensorflow/contrib/lite/util.cc:25:24: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   for (size_t i = 0; i < rank; i++) {\r\n                      \u02dc\u02dc\u02c6\u02dc\u02dc\u02dc\u02dc\u02dc\r\nERROR: /scratch/ecos0030/nayana/tensorflow/tensorflow/contrib/lite/kernels/BUILD:43:1: C++ compilation of rule '//tensorflow/contrib/lite/kernels:eig         en_support' failed (Exit 1)\r\nIn file included from external/eigen_archive/Eigen/Core:248:0,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from tensorflow/contrib/lite/kernels/eigen_support.cc:17:\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h: In function 'Packet Eigen::internal::pround(const Packet&) [with Packet = __vector(2         ) double]':\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h:471:86: error: '__builtin_s390_vfi' was not declared in this scope\r\ntemplate<> EIGEN_STRONG_INLINE Packet2d pround<Packet2d>(const Packet2d& a) { return vec_round(a); }\r\n                                                                                      \u02c6\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h:471:86: note: suggested alternative: '__builtin_s390_vfidb'\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h: In function 'Packet Eigen::internal::pceil(const Packet&) [with Packet = __vector(2)          double]':\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h:472:86: error: '__builtin_s390_vfi' was not declared in this scope\r\ntemplate<> EIGEN_STRONG_INLINE Packet2d pceil<Packet2d>(const  Packet2d& a) { return vec_ceil(a); }\r\n                                                                                      \u02c6\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h:472:86: note: suggested alternative: '__builtin_s390_vfidb'\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h: In function 'Packet Eigen::internal::pfloor(const Packet&) [with Packet = __vector(2         ) double]':\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h:473:86: error: '__builtin_s390_vfi' was not declared in this scope\r\ntemplate<> EIGEN_STRONG_INLINE Packet2d pfloor<Packet2d>(const Packet2d& a) { return vec_floor(a); }\r\n                                                                                      \u02c6\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h:473:86: note: suggested alternative: '__builtin_s390_vfidb'\r\nIn file included from external/eigen_archive/Eigen/Core:427:0,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from tensorflow/contrib/lite/kernels/eigen_support.cc:17:\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h: In function 'Packet Eigen::internal::pmadd(const Packet&, const Packet&, const Packe         t&) [with Packet = __vector(4) float]':\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h:1073:141: error: cannot convert 'const Packet4f {aka const __vector(4) float}' to '__         vector(2) double' for argument '1' to '__vector(2) double __builtin_s390_vfmadb(__vector(2) double, __vector(2) double, __vector(2) double)'\r\ntemplate<> EIGEN_STRONG_INLINE Packet4f pmadd<Packet4f>  (const Packet4f& a, const Packet4f& b, const Packet4f& c) { return vec_madd(a, b, c); }\r\n                                                                                                                                             \u02c6\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h: In function 'Packet Eigen::internal::pxor(const Packet&, const Packet&) [with Packet          = __vector(4) float]':\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h:1078:118: error: invalid parameter combination for intrinsic '__builtin_s390_vec_xor'\r\ntemplate<> EIGEN_STRONG_INLINE Packet4f pxor<Packet4f>   (const Packet4f& a, const Packet4f& b) { return vec_xor(a, b); }\r\n                                                                                                                      \u02c6\r\nIn file included from external/eigen_archive/Eigen/Core:248:0,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from tensorflow/contrib/lite/kernels/eigen_support.cc:17:\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h: In function 'Packet Eigen::internal::pround(const Packet&) [with Packet = __vector(4         ) float]':\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h:1080:87: error: '__builtin_s390_vfi' was not declared in this scope\r\ntemplate<> EIGEN_STRONG_INLINE Packet4f pround<Packet4f> (const Packet4f& a) { return vec_round(a); }\r\n                                                                                       \u02c6\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h:1080:87: note: suggested alternative: '__builtin_s390_vfidb'\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h: In function 'Packet Eigen::internal::pceil(const Packet&) [with Packet = __vector(4)          float]':\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h:1081:87: error: '__builtin_s390_vfi' was not declared in this scope\r\ntemplate<> EIGEN_STRONG_INLINE Packet4f pceil<Packet4f>  (const Packet4f& a) { return vec_ceil(a); }\r\n                                                                                       \u02c6\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h:1081:87: note: suggested alternative: '__builtin_s390_vfidb'\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h: In function 'Packet Eigen::internal::pfloor(const Packet&) [with Packet = __vector(4         ) float]':\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h:1082:87: error: '__builtin_s390_vfi' was not declared in this scope\r\ntemplate<> EIGEN_STRONG_INLINE Packet4f pfloor<Packet4f> (const Packet4f& a) { return vec_floor(a); }\r\n                                                                                       \u02c6\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h:1082:87: note: suggested alternative: '__builtin_s390_vfidb'\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/MathFunctions.h: In function 'Packet Eigen::internal::pexp(const Packet&) [with Packet = __vector(         2) double]':\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/MathFunctions.h:101:8: error: '__builtin_s390_vfi' was not declared in this scope\r\n   fx = vec_floor(fx);\r\n        \u02c6\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/MathFunctions.h:101:8: note: suggested alternative: '__builtin_s390_vfidb'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n```\r\n\r\n", "comments": ["We also tried to build eigen separately , the build is successful on z14.  Trying to debug the issue with TensorFlow. \r\nAny inputs on what could be causing the above issues?\r\n", "TensorFlow Lite uses a non-traditional approach for importing and including Eigen, so it's quite possible there are some platform/flag-specific issues that it's not handling properly. See also https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/kernels/internal/optimized/eigen_tensor_reduced_instantiations_oss.h", "I too faced issues while building TensorFlow with vectorization on s390x platform.\r\nWith gcc 6.3.0, 7.3.0 and 8.2.0 , Ubuntu 16.04, z13 : `bazel build -c opt --config=opt --copt=\"-mzvector\" //tensorflow/tools/pip_package:build_pip_package` fails with below error.\r\n```\r\nERROR: /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/org_sqlite/BUILD:35:1: C++ compilation of rule '@org_sqlite//:org_sqlite' failed (Exit 1)\r\nexternal/org_sqlite/sqlite3.c: In function 'vdbeRecordCompareInt':\r\nexternal/org_sqlite/sqlite3.c:76283:1: internal compiler error: in maybe_record_trace_start, at dwarf2cfi.c:2284\r\n }\r\n ^\r\n0x803dfd59 maybe_record_trace_start\r\n        ../../gcc-6.3.0/gcc/dwarf2cfi.c:2284\r\n0x803e0767 scan_trace\r\n        ../../gcc-6.3.0/gcc/dwarf2cfi.c:2462\r\n0x803e0ec7 create_cfi_notes\r\n        ../../gcc-6.3.0/gcc/dwarf2cfi.c:2616\r\n0x803e0ec7 execute_dwarf2_frame\r\n        ../../gcc-6.3.0/gcc/dwarf2cfi.c:2974\r\n0x803e0ec7 execute\r\n        ../../gcc-6.3.0/gcc/dwarf2cfi.c:3454\r\nPlease submit a full bug report,\r\nwith preprocessed source if appropriate.\r\nPlease include the complete backtrace with any bug report.\r\nSee <http://gcc.gnu.org/bugs.html> for instructions.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 404.383s, Critical Path: 33.09s\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nAny idea what could be causing this?", "I'm not familiar with the sqlite dependency, but we might consider excluding TensorFlow Lite from the default s390x platform builds.", "+gunan per the issues with sqlite.", "Looks like sqlite does not build on s390x?\r\nmaybe we also need to exclude sqlite ops in s390x?\r\nDo we now that the failing code works/supports big endian?", "@gunan  We are observing different issues with different GCC version with vectorization:\r\n\r\n1. With gcc 6.3.0 , Ubuntu 16.04, z13 :   Sqlite build issue\r\n2. With gcc 6.3.0/7.3.0 , Ubuntu 16.04, z14 :  TF build failure on Eigen /internal compiler error. \r\n3. With gcc 7.3.0 , Ubuntu 18.04, z14 :  TF buil dfailure on Eigen. \r\nWe are currently investigating more on Eigen failures. (Any pointers on this would be helpful)\r\n\r\nFor sqlite , tried to comment out download sqlite code from `tensorflow/workspace.bzl` but it didn't help. Is there any option in configure through which we can disable this feature?", "I assume that sqlite build issue is everywhere. But with newer gcc versions\nthere is also the eigen build issue.\n\nFor sqlite, we have to conditionally exclude sqlite targets if we are\nbuilding for s390x.\nDo you have a link for that build result(log)?\n\nOn Tue, Sep 18, 2018 at 5:02 AM Nayana Thorat <notifications@github.com>\nwrote:\n\n> @gunan <https://github.com/gunan> We are observing different issues with\n> different GCC version with vectorization:\n>\n>    1. With gcc 6.3.0 , Ubuntu 16.04, z13 : Sqlite build issue\n>    2. With gcc 6.3.0/7.3.0 , Ubuntu 16.04, z14 : TF build failure on\n>    Eigen /internal compiler error.\n>    3. With gcc 7.3.0 , Ubuntu 18.04, z14 : TF buil dfailure on Eigen.\n>    We are currently investigating more on Eigen failures. (Any pointers\n>    on this would be helpful)\n>\n> For sqlite , tried to comment out download sqlite code from\n> tensorflow/workspace.bzl but it didn't help. Is there any option in\n> configure through which we can disable this feature?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/22023#issuecomment-422364146>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AHlCOY03j0JtMim2g2NGllMd3sGdOnnkks5ucODVgaJpZM4WXOaw>\n> .\n>\n", "@gunan I have tried TensorFlow build v1.8.0 on local z13 vm with gcc 6.3.0 on Ubuntu 16.04.\r\nBelow is the log for sqlite.  Please note we have not observed sqlite issue ( or may be build didn't reach till sqlite module) with z14.  \r\n\r\n```\r\nINFO: From Compiling external/snappy/snappy-sinksource.cc [for host]:\r\ncc1plus: warning: command line option '-Wno-implicit-function-declaration' is valid for C/ObjC but not for C++\r\nSlow read: a 7184608-byte read from /root/.cache/bazel/_bazel_root/9b63c66f147d91a5644a0e81d48c020e/external/org_sqlite/sqlite3.c took 26065ms.\r\nERROR: /root/.cache/bazel/_bazel_root/9b63c66f147d91a5644a0e81d48c020e/external/org_sqlite/BUILD:35:1: C++ compilation of rule '@org_sqlite//:org_sqlite' failed (Exit 1)\r\nexternal/org_sqlite/sqlite3.c: In function 'vdbeRecordCompareInt':\r\nexternal/org_sqlite/sqlite3.c:76283:1: internal compiler error: in maybe_record_trace_start, at dwarf2cfi.c:2284\r\n}\r\n\u02c6\r\n0x1385bc7 maybe_record_trace_start\r\n        ../../gcc-6.3.0/gcc/dwarf2cfi.c:2284\r\n0x1388285 scan_trace\r\n        ../../gcc-6.3.0/gcc/dwarf2cfi.c:2462\r\n0x13888dd create_cfi_notes\r\n        ../../gcc-6.3.0/gcc/dwarf2cfi.c:2616\r\n0x13888dd execute_dwarf2_frame\r\n        ../../gcc-6.3.0/gcc/dwarf2cfi.c:2974\r\n0x13888dd execute\r\n        ../../gcc-6.3.0/gcc/dwarf2cfi.c:3454\r\nPlease submit a full bug report,\r\nwith preprocessed source if appropriate.\r\nPlease include the complete backtrace with any bug report.\r\nSee <http://gcc.gnu.org/bugs.html> for instructions.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 1795.018s, Critical Path: 24.14s\r\nFAILED: Build did NOT complete successfully\r\n```", "Do we know if sqlite has big endian support, by the way?", "I just tried steps to compile sqlite from https://www.sqlite.org/howtocompile.html\r\nthis works on Ub16.04 + gcc 7.3.0 + z14 vm", "With gcc 6.3.0 , Ubuntu 16.04, z13 : using bazel 0.15.0 instead of bazel 0.12.0, Build for vectorization does not fail with the `sqlite3.c` error anymore but fails with the eigen issue in PacketMath.h similarly seen on z14.\r\n```\r\nERROR: /home/test/tensorflow/tensorflow/contrib/lite/kernels/BUILD:43:1: C++ compilation of rule '//tensorflow/contrib/lite/kernels:eigen_support' failed (Exit 1)\r\nIn file included from external/eigen_archive/Eigen/Core:427:0,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from tensorflow/contrib/lite/kernels/eigen_support.cc:17:\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h: In function 'Eigen::internal::Packet4f Eigen::internal::vec_splat_packet4f(const Packet4f&)':\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h:657:11: error: request for member 'v4f' in 'splat', which is of non-class type 'Eigen::internal::Packet4f {aka __vector(4) float}'\r\n     splat.v4f[0] = vec_splat(from.v4f[0], 0);\r\n           ^~~\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h:657:35: error: request for member 'v4f' in 'from', which is of non-class type 'const Packet4f {aka const __vector(4) float}'\r\n     splat.v4f[0] = vec_splat(from.v4f[0], 0);\r\n                                   ^~~\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h:657:44: internal compiler error: tree check: expected class 'type', have 'exceptional' (error_mark) in s390_fn_types_compatible, at config/s390/s390-c.c:727\r\n     splat.v4f[0] = vec_splat(from.v4f[0], 0);\r\n                                            ^\r\n0x80cc5367 tree_class_check_failed(tree_node const*, tree_code_class, char const*, int, char const*)\r\n        ../../gcc-6.3.0/gcc/tree.c:9704\r\n```", "Can you sync to master and try building again? We recently updated all of our Eigen dependencies, and I'd like to see if you're hitting the same issue.", "@jdduke I have tried building v1.12.0 with vectorization on Ubuntu 18.04 with gcc v7.3.0, Bazel v0.15.0 on s390x platform .\r\n\r\ncommand used:\r\n` bazel --host_jvm_args=\"-Xms512m\" --host_jvm_args=\"-Xmx1024m\" build --config=opt --copt=\"-mzvector\" //tensorflow/tools/pip_package:build_pip_package `\r\n\r\nHowever got an error: \r\n\r\n```\r\nERROR: /root/tensorflow/tensorflow/contrib/lite/kernels/BUILD:158:1: C++ compilation of rule '//tensorflow/contrib/lite/kernels:builtin_op_kernels' failed (Exit 1)^M\r\nIn file included from external/eigen_archive/Eigen/Core:431:0,\r\n                from ./third_party/eigen3/Eigen/Core:1,\r\n                from ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:28,\r\n                from tensorflow/contrib/lite/kernels/space_to_batch_nd.cc:19:\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h: In function 'Packet Eigen::internal::pmin(const Packet&, const Packet&) [with Packet = __vector(2) double]':\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h:454:115: *error: '__builtin_s390_vec_min' matching variant requires z14 or higher*\r\ntemplate<> EIGEN_STRONG_INLINE Packet2d pmin<Packet2d>(const Packet2d& a, const Packet2d& b) { return vec_min(a, b); }\r\n```\r\n\r\nNow, started build on z14 vm. will share the result.", "Tensorflow build  with vectorization failed on z14  with an error:\r\n\r\n ```\r\n\r\nERROR: /home/dev/tensorflow/tensorflow/contrib/lite/kernels/BUILD:57:1: C++ compilation of rule '//tensorflow/contrib/lite/kernels:eigen_support' failed (Exit 1)^M\r\nIn file included from external/eigen_archive/Eigen/Core:251:0,\r\n                 from ./tensorflow/contrib/lite/kernels/internal/optimized/eigen_tensor_reduced_instantiations_oss.h:26,\r\n                 from ./tensorflow/contrib/lite/kernels/internal/optimized/eigen_spatial_convolutions.h:37,\r\n                 from tensorflow/contrib/lite/kernels/eigen_support.cc:20:\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h: In function 'Packet EigenForTFLite::internal::pround(const Packet&) [with Packet = __vector(2) double]':\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h:471:86: error: '__builtin_s390_vfi' was not declared in this scope\r\n template<> EIGEN_STRONG_INLINE Packet2d pround<Packet2d>(const Packet2d& a) { return vec_round(a); }\r\n                                                                                      ^\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h:471:86: note: suggested alternative: '__builtin_s390_vfidb'\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h: In function 'Packet EigenForTFLite::internal::pceil(const Packet&) [with Packet = __vector(2) double]':\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h:472:86: error: '__builtin_s390_vfi' was not declared in this scope\r\n template<> EIGEN_STRONG_INLINE Packet2d pceil<Packet2d>(const  Packet2d& a) { return vec_ceil(a); }\r\n\r\n```\r\n\r\n", "@jdduke looks like an eigen issue?\r\nNow that we have unfrozen our eigen version, we can actually push a fix and update our dependency.\r\nCould you take a look?", "Yeah, it's interesting that this is failing within TensorFlow Lite, but not TensorFlow (which would also ahve the Eigen dependency).  @rmlarsen do you know if there's anything we ought to be doing differently to allow for vectorized Eigen builds?", "How do we build tensorflow with vectorization on Intel?\r\nDo we need to enable it while configuring? Or do we specify some flags? Like how we do it on z13 and higher using the `--copt=\"-mzvector\"` flag.", "@gunan any info regarding vectorization on intel, as we are facing issues with s390x, wanted to check on intel.", "I think in x86 land, vectorization means building with avx/avx2 and avx512 support.\r\nI do not think that has a direct translation to s390x", "@gunan  I tried building TensorFlow v1.12.0 with an option --copt=-DEIGEN_ENABLE_AVX512 \r\nIs it the correct flag to enable vectorization  for x86? \r\n` bazel build --copt=-DEIGEN_ENABLE_AVX512 //tensorflow/tools/pip_package:build_pip_package `\r\n\r\nI could also build TensorFlow wheel and install but got a message as below: \r\n```\r\n>>> import tensorflow as tf\r\n>>> sess = tf.Session()\r\n: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n\r\n```\r\n\r\n\r\n", "Also checking with @benoitsteiner whats the exact command for x86 through https://github.com/tensorflow/tensorflow/issues/4775", "@gunan @benoitsteiner an you please confirm if using flag --copt=-DEIGEN_ENABLE_AVX512 is correct on Intel for vectorization?\r\n\r\nWe are still struggling with TensorFlow build failures on s390x with vectorization using flag  -march=z14 -mzvector.\r\n\r\n\r\n\r\n\r\n\r\n", "I have tried simple example using eigen vector functions on both the platforms : Intel and s390x.\r\nOn Intel , the code can compile with vectorization (by default -msse2 ) and generates output.\r\n\r\nOn s390x, compilation failed with an error:` __builtin_s390_vfi was not declared in this scope`.\r\nSame issue is observed while building TensorFlow with vectorization on z14 vm.\r\n\r\nI have used -march=z14 -mzvector flags on z14 s390x vm.\r\nReference: http://eigen.tuxfamily.org/index.php?ti ... torization\r\n\r\nCould you confirm if Eigen supports vectorization for s390x? ", "`--copt=-DEIGEN_ENABLE_AVX512` sounds like the right flag to use avx512 level vectorization in eigen code. However, I am quite certain that that define cannot work on s390x. Even if that is enabled, you still need `-mavx512f` flag, and last time I checked there were either build or test failures when we enabled avx512 instructions.\r\n\r\nThe question about if eigen supports s390x vectorization, I am afraid I have no answer to that. Eigen maintainers will be able to answer that. http://eigen.tuxfamily.org/bz/ should be a batter route to get a hold of them.", "@gunan Thanks for your inputs . \r\nYes ..the --copt=-DEIGEN_ENABLE_AVX512 flag I used for Intel only.  For s390x, I tried with -march=z14 -mzvector flags.\r\n\r\nI am trying to reach Eigen community however they have disabled sign in to new users.  Now waiting for reply for emails that I sent to mentioned id. \r\n\r\nMeanwhile I will try to rebuild and investigate further on vectorization for s390x. \r\n\r\n", "@Nayana-ibm \r\nThe build problem probably is this one. We also ran into it while trying to build tensorflow:\r\nhttps://gcc.gnu.org/bugzilla/show_bug.cgi?id=89952\r\nI've attached an experimental patch for GCC which is currently being tested.\r\n\r\nEigen has been optimized for IBM z14 using GCC builtins. It uses the set of altivec-style builtins which introduce \"vector\" as a keyword. This allows defining vector data types more conveniently. That's why -mzvector is required during build.", "@Nayana-ibm \r\nIs this still an issue could you please try on latest tf version and let us know.", "Thanks @Saduf2019, I tried building TensorFlow v2.5.0 and v2.6.0 with vectorization on Ubuntu 18.04 with gcc v7.5.0, Bazel v3.7.2 on s390x platform and found that this issue still exists. ", "On TensorFlow v2.5.0 using flag `--copt=\"-march=z14\" --copt=\"-mzvector\"`:\r\n\r\n```bash\r\nERROR: /home/test/tensorflow/tensorflow/compiler/tf2xla/ops/BUILD:34:21: C++ compilation of rule '//tensorflow/compiler/tf2xla/ops:_xla_ops.so' failed (Exit 1): gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections ... (remaining 107 argument(s) skipped)\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/ConfigureVectorization.h:414:0,\r\n                 from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:22,\r\n                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14,\r\n                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from ./tensorflow/core/framework/tensor_shape.h:21,\r\n                 from ./tensorflow/core/framework/partial_tensor_shape.h:20,\r\n                 from ./tensorflow/core/framework/attr_value_util.h:23,\r\n                 from ./tensorflow/core/framework/node_def_util.h:23,\r\n                 from ./tensorflow/core/framework/shape_inference.h:21,\r\n                 from ./tensorflow/core/framework/common_shape_fns.h:20,\r\n                 from tensorflow/compiler/tf2xla/ops/xla_ops.cc:23:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/ZVector/PacketMath.h: In function 'Packet Eigen::internal::pround(const Packet&) [with Packet = __vector(2) double]':\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/ZVector/PacketMath.h:440:86: error: '__builtin_s390_vfi' was not declared in this scope\r\n template<> EIGEN_STRONG_INLINE Packet2d pround<Packet2d>(const Packet2d& a) { return vec_round(a); }\r\n                                                                                      ^\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/ZVector/PacketMath.h:440:86: note: suggested alternative: '__builtin_s390_vfidb'\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/ZVector/PacketMath.h: In function 'Packet Eigen::internal::pceil(const Packet&) [with Packet = __vector(2) double]':\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/ZVector/PacketMath.h:441:86: error: '__builtin_s390_vfi' was not declared in this scope\r\n template<> EIGEN_STRONG_INLINE Packet2d pceil<Packet2d>(const  Packet2d& a) { return vec_ceil(a); }\r\n```\r\n\r\nOn TensorFlow v2.6.0 using flag `--copt=\"-march=z14\" --copt=\"-mzvector\"`:\r\n```bash\r\nERROR: /home/test/tensorflow/tensorflow/core/platform/BUILD:120:11: C++ compilation of rule '//tensorflow/core/platform:abi' failed (Exit 1): gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections ... (remaining 33 argument(s) skipped)\r\nIn file included from external/eigen_archive/Eigen/Core:223:0,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from ./tensorflow/core/platform/bfloat16.h:21,\r\n                 from ./tensorflow/core/platform/types.h:21,\r\n                 from ./tensorflow/core/platform/abi.h:20,\r\n                 from tensorflow/core/platform/abi.cc:16:\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h:98:55: error: expected '}' before numeric constant\r\n static Packet2d p2d_ZERO_ = { numext::bit_cast<double>0x8000000000000000ull),\r\n                                                       ^~~~~~~~~~~~~~~~~~~~~\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h:98:55: error: cannot resolve overloaded function 'bit_cast' based on conversion to type 'double'\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h:111:8: error: 'Packet4f' does not name a type\r\n static _EIGEN_DECLARE_CONST_FAST_Packet4f(ZERO, 0); //{ 0.0, 0.0, 0.0, 0.0}\r\n        ^\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h:112:8: error: 'Packet4i' does not name a type\r\n static _EIGEN_DECLARE_CONST_FAST_Packet4i(MINUS1,-1); //{ -1, -1, -1, -1}\r\n        ^\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h:113:8: error: 'Packet4f' does not name a type\r\n static Packet4f p4f_MZERO = { 0x80000000, 0x80000000, 0x80000000, 0x80000000};\r\n        ^~~~~~~~\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h:116:8: error: 'Packet4i' does not name a type\r\n static Packet4i p4i_COUNTDOWN = { 0, 1, 2, 3 };\r\n        ^~~~~~~~\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h:117:8: error: 'Packet4f' does not name a type\r\n static Packet4f p4f_COUNTDOWN = { 0.0, 1.0, 2.0, 3.0 };\r\n        ^~~~~~~~\r\nexternal/eigen_archive/Eigen/src/Core/arch/ZVector/PacketMath.h:118:8: error: 'Packet2d' does not name a type\r\n static Packet2d p2d_COUNTDOWN = reinterpret_cast<Packet2d>(vec_sld(reinterpret_cast<Packet16uc>(p2d_ZERO), reinterpret_cast<Packet16uc>(p2d_ONE), 8));\r\n        ^~~~~~~~\r\n```", "@kun-lu20 I created an MR to fix the bit_cast error in Eigen [here](https://gitlab.com/libeigen/eigen/-/merge_requests/694).\r\n\r\nHopefully that fixes all the other errors you get too.  Eigen's packetmath tests now pass for the zvector backend (at least using qemu, I don't have actual hardware to test).\r\n\r\nThe `__builtin_s390*` errors must be a compiler bug (or mismatch between compiler and default system include directories).  Eigen doesn't explicitly use those functions.", "Thanks @cantonios ! We are looking forward to testing it with the latest TensorFlow release on s390x systems."]}, {"number": 21923, "title": "\u00c0 trous 1D convolution slow in certain scenarios ", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.10.1\r\n- **Python version**: 3.5.2\r\n- **CUDA/cuDNN version**: 9.0.176\r\n- **GPU model and memory**: CPU\r\n- **Exact command to reproduce**: See below\r\n- **Bazel version**: N/A\r\n- **Mobile device**: N/A\r\n\r\n### Describe the problem\r\nRunning\r\n\r\n``\r\ntf.nn.atrous_conv2d(images, filters, rate=dilation_rate, padding=\"SAME\")\r\n``\r\n\r\nand\r\n\r\n``\r\ntf.nn.convolution(images, filters, dilation_rate=[dilation_rate, dilation_rate], padding=\"SAME\")\r\n``\r\n\r\ntakes much more time to run than:\r\n\r\n``\r\ntf.nn.convolution(images, filters, dilation_rate=[1, dilation_rate], padding=\"SAME\")\r\n``\r\n\r\nfor `1D` convolutions.\r\n\r\nI don't think this is supposed to behave like this, provided that the input data is one dimensional along the width or the height (i.e. ``shape = [batch, 1, width, channels] or [batch, height, 1, channels]``) since in this case, no dilation is needed on the corresponding axis.\r\n\r\nA person using `tf.nn.atrous_conv2d` for `1D` \"\u00e0 trous\" convolutions might never notice the issue here, and his network will be really slow to train.\r\n\r\n### Source code / logs\r\nA small snippet to compare the performance of the different methods\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport time\r\n\r\n# Scenario\r\nbatch_size = 100\r\nchannels = 3\r\no_channels = 10\r\nimage_size = 160\r\nfilter_size = 3\r\n\r\n# Dummy images and filters\r\nimages = tf.random_normal(shape=[batch_size, 1, image_size, channels],  dtype=tf.float32)\r\nfilters = tf.random_normal(shape=[1, filter_size, channels, o_channels], dtype=tf.float32)\r\n\r\n# Ops definition\r\nnormal_conv = tf.nn.convolution(images, filters, padding=\"SAME\")\r\natrous_convs = []\r\natrous_convs_wrapper = []\r\nfor i in [5, 10, 20, 50]:\r\n    atrous_convs.append({\"dilation\": i, \"op\": tf.nn.convolution(images, filters, dilation_rate=[1, i], padding=\"SAME\")})\r\n    atrous_convs_wrapper.append({\"dilation\": i, \"op\": tf.nn.convolution(images, filters, dilation_rate=[i, i], padding=\"SAME\")})\r\n    # Or\r\n    # atrous_convs_wrapper.append({\"dilation\": i, \"op\": tf.nn.atrous_conv2d(images, filters, rate=i, padding=\"SAME\")})\r\n# Test\r\nwith tf.Session() as sess:\r\n    repeats = 50\r\n    \r\n    for conv in atrous_convs:\r\n        op1 = conv[\"op\"]\r\n        op2 = [elt for elt in atrous_convs_wrapper if elt[\"dilation\"] == conv[\"dilation\"]][0][\"op\"]\r\n        op1_res, op2_res = sess.run([op1, op2])\r\n        np.testing.assert_equal(op1_res, op2_res)\r\n    \r\n    # Benchmark normal method\r\n    start = time.time()\r\n    for _ in range(repeats):\r\n        _ = sess.run(normal_conv)\r\n    end = time.time()\r\n    normal_conv_time = int((end - start) / repeats * 1000)\r\n\r\n    # Benchmark atrous conv method\r\n    for conv in atrous_convs:\r\n        start = time.time()\r\n        for _ in range(repeats):\r\n            _ = sess.run(conv[\"op\"])\r\n        end = time.time()\r\n        conv.update({\"time\": int((end - start) / repeats * 1000)})\r\n    \r\n    for conv in atrous_convs_wrapper:\r\n        start = time.time()\r\n        for _ in range(repeats):\r\n            _ = sess.run(conv[\"op\"])\r\n        end = time.time()\r\n        conv.update({\"time\": int((end - start) / repeats * 1000)})\r\n\r\n    print(\"Normal conv: {}ms\".format(normal_conv_time))\r\n    for conv in atrous_convs:\r\n        print(\"Atrous conv w/ dilation {}: {}ms\".format(conv[\"dilation\"], conv[\"time\"]))\r\n    for conv in atrous_convs_wrapper:\r\n        print(\"Atrous conv(wrapper) w/ dilation {}: {}ms\".format(conv[\"dilation\"], conv[\"time\"]))\r\n\r\n```\r\n\r\nreturns\r\n\r\n```\r\nNormal conv: 1ms\r\nAtrous conv w/ dilation 5: 1ms\r\nAtrous conv w/ dilation 10: 2ms\r\nAtrous conv w/ dilation 20: 1ms\r\nAtrous conv w/ dilation 50: 2ms\r\nAtrous conv(wrapper) w/ dilation 5: 4ms\r\nAtrous conv(wrapper) w/ dilation 10: 9ms\r\nAtrous conv(wrapper) w/ dilation 20: 15ms\r\nAtrous conv(wrapper) w/ dilation 50: 47ms\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version\nMobile device", "@tensorflowbutler Done :)", "Thank you for bringing this to our attention!\r\nIn its main computation path, TF implements atrous/dilated convolution as a sequence of\r\nSpaceToBatch -> Regular Conv -> BatchToSpace\r\nops. In preparation of feeding the first SpaceToBatch op, we zero-pad the input tensor to have a size multiple of the dilation rate along the corresponding dimensions:\r\nhttps://github.com/tensorflow/tensorflow/blob/9d1ff68c97b97da3d28042751e055e296dcb007a/tensorflow/python/ops/nn_ops.py#L494\r\nBy specifying a dilation rate in the ranges of [5, 10, 20, 50], you effectively end up with convolutions whose input tensor is correspondingly [5, 160], [10, 160], [20, 160], [50, 160] instead of the original/intended [1, 160], which explains the slowdown you have observed.\r\nNot sure what is the best way to enforce that the user employs [1, dilation_rate] instead of [dilation_rate, dilation_rate]?", "The best might be to simply specify it in the documentation. Something along theses lines for the [atrous_conv2d doc](https://www.tensorflow.org/api_docs/python/tf/nn/atrous_conv2d):\r\n\r\n- Before\r\n\r\n> This function is a simpler wrapper around the more general tf.nn.convolution, and exists only for backwards compatibility. You can use tf.nn.convolution to perform 1-D, 2-D, or 3-D atrous convolution.\r\n\r\n\r\n- After\r\n\r\n> This function is a simpler wrapper around the more general tf.nn.convolution, and exists only for backwards compatibility. Make sure to use tf.nn.convolution to perform 1-D, 2-D, or 3-D atrous convolutions, by specifying the proper dilation rate for your input.\r\n\r\n> Be especially wary not to use this function to perform 1-D atrous convolutions, since we zero-pad the input tensor to have a size multiple of the dilation rate along the corresponding dimensions, which will affect the performance of the operation.\r\n\r\nOr you could put up a warning in the atrous_conv2d function if you notice that the input tensor is one dimensional along the width or height axis.", "@skye Hi, is there any update made in the documentation as per above ?"]}, {"number": 21915, "title": "Batch normalization implemented incorrectly in canned DNN estimators", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: all\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.10\r\n- **Python version**: 3.6.2\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nBatch normalization is implemented incorrectly in canned DNN estimators.  In _dnn_logit_fn_builder, batch normalization is applied after the dense layer which includes the activation function.  But batch normalization should be applied to the inputs to a layer, prior to the activation function.  See the original paper by Ioffe, Szegedy: \" ... we focus on transforms that consist of an affine transformation followed by anelement-wise nonlinearity:\r\nz = g(Wu + b)\r\nwhere W and b are learned parameters of the model, and g(\u00b7) is the nonlinearity such as sigmoid or ReLU. ...  We add the BN transform immediately before the nonlinearity, by normalizing x = Wu+ b.\"\r\n\r\nAlso see the many published reference implementations of batch normalization.\r\n\r\nThe current implementation is not only incorrect but produces very poor results.  \r\n\r\n### Source code / logs\r\n", "comments": ["ping @ispirmustafa ", "Also one must add the update ops for batch norm vars to the train op, cf. the comments for the batch_normalization method in layers.normalization.py.  See PR #21916 .", "Hi @lukmanr , agreed that it should be applied before relu. re: update-ops, head handles it by default.", "Hi @lukmanr,\r\n\r\nCan you provide some evidence that the current ordering of BN and activation hurts the performance of your use case?\r\n\r\nThere are evidences that the ordering in the original paper is not correct: \r\nhttp://redd.it/67gonq, \r\nhttps://github.com/cvjena/cnn-models/issues/3\r\nhttps://github.com/ducha-aiki/caffenet-benchmark/blob/master/batchnorm.md\r\nMore here:\r\nhttps://www.google.com/search?q=batch+norm+before+or+after+activation\r\n\r\nSo apparently this is a topic up for discussion. In my use case I found the result was better with BN following activation.", "Hi @hjmus,\r\n\r\nThanks for the references on ordering; I'll comment below.  The bigger issue for the implementation in canned DNNs is probably the lack of use of the mean/variance update ops.  \r\n\r\n@ispirmustafa I don't see any change to train_ops related to BN in the heads.  I also don't see it in the original commit for the feature. You have to add the mean/variance update ops to the train_op like so:\r\n\r\n       update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n       with tf.control_dependencies(update_ops):\r\n              train_op = optimizer.minimize(loss)\r\n\r\nOtherwise the mean/variance vars in BN layers never get updated and BN is not really in effect.  This is really easy to miss in the current implementation of layers.batch_normalization, and there have been multiple requests to address this, by adding warnings or make the update ops the default behavior:  #21229, #21595, #14809, #14699.  It looks like the Canned DNN implementation missed this as well.  I incuded a suggested fix in the PR.\r\n\r\nRe: ordering, I have only previously implemented BN applied before relu.  I find the discussion online confounds multiple issues, including the best explanation for what BN is really doing, with evolving best practices for CNNs.  Worth noting that we are talking about DNNs not CNNs here.  I did try a side-by-side comparison of a custom DNN, with BN before relu (and update ops properly added) against the same architecture in canned DNNs on [this Kaggle data set](https://www.kaggle.com/c/acquire-valued-shoppers-challenge/data) and got terrible results with the canned DNNs, even after hypertuning, which lead me to investigate BN in canned DNNs.  I can't publish the code at the moment as it has yet to go through Google's open sourcing process. ", "As said by @ispirmustafa ,  update_ops is handled by Head by default:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/8dfb7532f8278e53a86a847ba6aa9c441f7b021b/tensorflow/python/estimator/canned/head.py#L1545-L1550", "Thank you @hjmus.\r\nI've chat with Christian, Sergey. They don't have a strong opinion about the right order. So let's make this an optional which doesn't change the current behavior . I'll recommend something on the PR. ", "Hi @lukmanr \r\nCould you please update the progress on your PR #21916 ? \r\nThank you"]}, {"number": 21891, "title": "Search in Embedding Projector using Japanese or Hindi text causes Cannot read property 'toString' of undefined", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\nVisiting http://projector.tensorflow.org/?config=https://ecraft2learn.github.io/ai/word-embeddings/hi/projector.json using Chrome 68\r\n\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nAfter visiting http://projector.tensorflow.org/?config=https://ecraft2learn.github.io/ai/word-embeddings/hi/projector.json using Chrome 68 and then entering any Hindi text in the Search field the console shows\r\n\r\nUncaught TypeError: Cannot read property 'toString' of undefined\r\n    at b (?config=https://ecraft2learn.github.io/ai/word-embeddings/hi/projector.json:formatted:60928)\r\n    at ?config=https://ecraft2learn.github.io/ai/word-embeddings/hi/projector.json:formatted:61345\r\n    at Array.forEach (<anonymous>)\r\n    at a.query (?config=https://ecraft2learn.github.io/ai/word-embeddings/hi/projector.json:formatted:61344)\r\n    at ?config=https://ecraft2learn.github.io/ai/word-embeddings/hi/projector.json:formatted:66646\r\n    at ?config=https://ecraft2learn.github.io/ai/word-embeddings/hi/projector.json:formatted:66171\r\n    at Array.forEach (<anonymous>)\r\n    at HTMLElement.b.notifyInputChanged (?config=https://ecraft2learn.github.io/ai/word-embeddings/hi/projector.json:formatted:66170)\r\n    at HTMLElement.b.onTextChanged (?config=https://ecraft2learn.github.io/ai/word-embeddings/hi/projector.json:formatted:66185)\r\n    at HTMLElement.<anonymous> (?config=https://ecraft2learn.github.io/ai/word-embeddings/hi/projector.json:formatted:66151)\r\nb @ ?config=https://ecraft2learn.github.io/ai/word-embeddings/hi/projector.json:formatted:60928\r\n(anonymous) @ ?config=https://ecraft2learn.github.io/ai/word-embeddings/hi/projector.json:formatted:61345\r\na.query @ ?config=https://ecraft2learn.github.io/ai/word-embeddings/hi/projector.json:formatted:61344\r\n(anonymous) @ ?config=https://ecraft2learn.github.io/ai/word-embeddings/hi/projector.json:formatted:66646\r\n(anonymous) @ ?config=https://ecraft2learn.github.io/ai/word-embeddings/hi/projector.json:formatted:66171\r\nb.notifyInputChanged @ ?config=https://ecraft2learn.github.io/ai/word-embeddings/hi/projector.json:formatted:66170\r\nb.onTextChanged @ ?config=https://ecraft2learn.github.io/ai/word-embeddings/hi/projector.json:formatted:66185\r\n(anonymous) @ ?config=https://ecraft2learn.github.io/ai/word-embeddings/hi/projector.json:formatted:66151\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["@ToonTalk this seems to happen for any search input text at all (e.g. \"x\"), not just japanese or hindi inputs - does that match what you're seeing?\r\n\r\nI ran this through the debugger and it seems to be coming from this line triggered when `p.index` is 19999:\r\nhttps://github.com/tensorflow/tensorboard/blob/1.10/tensorboard/plugins/projector/vz_projector/util.ts#L157\r\n\r\nOn loading the page, I noticed a message shows up saying: \"Number of tensors (20000) do not match the number of lines in metadata (19999).\"\r\n\r\nSo I'm guessing the issue has something to do with that discrepancy, and the search predicate is being evaluated on a 20,000th tensor entry that has no corresponding metadata and as a result `p.metadata[fieldName]` returns undefined.\r\n\r\n@dsmilkov @nsthorat does this diagnosis seem right?  Do you know where the right place would be to add the appropriate guarding logic?\r\n\r\n", "Thanks for looking into this. Yes just \"x\" reproduces the problem.\r\n\r\nHowever when  I checked the metadataPath in https://ecraft2learn.github.io/ai/word-embeddings/hi/projector.json (which is https://ecraft2learn.github.io/ai/word-embeddings/hi/projector-labels.tsv) it sure seems to be 20000 lines (e.g. opening it in Chrome dev tools shows 20001 as the final blank line). The same for the tensorPath. \r\n\r\nI too see the warning about 19999 when I load it but have no memory of seeing that when I posted this.\r\n\r\nI just found that line 89 displays as \ufffd and seems to be Unicode FFFD. And line 2147 is \u200bdisplays as a small red dot in dev tools\r\n\r\nI made a new version with a better word filter. http://projector.tensorflow.org/?config=https://ecraft2learn.github.io/ai/word-embeddings/hi/projector_v2.json and the problem went away.\r\n\r\nBy the way the data came from https://fasttext.cc/docs/en/crawl-vectors.html\r\n\r\nPerhaps the projector needs to deal better with unexpected entries such as  as \ufffd ?", "When I mentioned a line with small red dot it turns out it was a https://en.wikipedia.org/wiki/Zero-width_non-joiner\r\n\r\nI finally got the search button to work with 15 languages but the zero-width non-joiner occurred 3 times in the Sinhalese version and that caused the same problem as the original post until I eliminated it."]}, {"number": 21836, "title": "tf.test.is_gpu_available(True) allocates all GPU(s) VRAM", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**:  1.10.0-devel-gpu-py3\r\n- **TensorFlow version (use command below)**: 1.10.0-devel-gpu-py3\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: CUDA: V9.0.176 cuDNN: V7.1.4\r\n- **GPU model and memory**: 2x 1080ti 11GB\r\n- **Exact command to reproduce**:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\ndata_format = 'channels_first' if tf.test.is_gpu_available(True) \\\r\n    else 'channels_last'\r\n# At this point, all memory is allocated across all GPUs\r\nconfig = tf.ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nsess = tf.Session(config=config)\r\n# All VRAM still allocated\r\n```\r\n\r\n### Describe the problem\r\nUsing tf.test.is_gpu_available(True) to check if a system GPU is available allocates all the VRAM available.", "comments": ["same issue in #8136 but got no response there", "We ran into this same issue too. Moving `tf.test.is_gpu_available()` to after `sess = tf.Session(config=config)` solves the problem. It seems that `tf.test.is_gpu_available()` starts it's own session with the default config, which consumes all of the gpus' resources, leaving none for the session you initialize afterwards."]}, {"number": 21835, "title": "New feature request: LOBPCG in addition to Lanczos?", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nN/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nall\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\nall\r\n- **TensorFlow installed from (source or binary)**:\r\nN/A\r\n- **TensorFlow version (use command below)**:\r\nN/A\r\n- **Python version**:\r\nN/A\r\n- **Bazel version (if compiling from source)**:\r\nN/A\r\n- **GCC/Compiler version (if compiling from source)**:\r\nN/A\r\n- **CUDA/cuDNN version**:\r\nN/A\r\n- **GPU model and memory**:\r\nN/A\r\n- **Exact command to reproduce**:\r\nN/A\r\n\r\n### Describe the problem\r\nTensorFlow now has a native implementation of Lanczos https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/solvers/python/ops/lanczos.py\r\n\r\nIt could be useful to add a native TensorFlow implementation of LOBPCG, see https://en.wikipedia.org/wiki/LOBPCG which is an alternative to Lanczos  and has some advantages, e.g., warm-starts. SciPy has the Python native implementation https://docs.scipy.org/doc/scipy-1.1.0/reference/generated/scipy.sparse.linalg.lobpcg.html used in Scikit for manifold spectral embedding http://scikit-learn.org/stable/modules/generated/sklearn.manifold.spectral_embedding.html and for spectral clustering http://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html\r\n\r\nReference implementations of LOBPCG are described in \r\n\r\n1. Knyazev, Andrew V. (2001). \"Toward the Optimal Preconditioned Eigensolver: Locally Optimal Block Preconditioned Conjugate Gradient Method\". SIAM Journal on Scientific Computing. 23 (2): 517\u2013541. doi:10.1137/S1064827500366124\r\n2. Knyazev, A. V.; Argentati, M. E.; Lashuk, I.; Ovtchinnikov, E. E. (2007). \"Block Locally Optimal Preconditioned Eigenvalue Xolvers (BLOPEX) in Hypre and PETSc\". SIAM Journal on Scientific Computing. 29 (5): 2224. arXiv:0705.2626\u202fFreely accessible. doi:10.1137/060661624\r\n\r\nLOBPCG can be easily adopted to compute partial SVD and PCA for a data matrix X without ever computing its covariance matrix X'*X, i.e. in matrix-free fashion, see comments at https://www.mathworks.com/matlabcentral/fileexchange/48-lobpcg-m\r\n\r\nNVIDIA has implemented LOBPCG in its nvGRAPH library introduced in CUDA 8.\r\n\r\nA first simple step could be to write a single-vector (non-block) version LOPCG, which would be very similar to already existing https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/solvers/python/ops/linear_equations.py\r\nbut instead of solving Ax=rhs would produce a single eigenvector of selfadjoint matrix `A`  matrix-free where the action of the matrix A is represented by  `operator`, corresponding to the largest (or smallest) eigenvalue, possibly constrained to be orthogonal to a set of given vectors Y. The latter would allow computing several main eigenvectors one-by-one, putting all previously computed eigenvectors into Y.\r\n\r\nI can help with the implementation if numerical issues arise.\r\n\r\n### Source code / logs\r\nN/A\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Done adding N/A", "@rmlarsen , can you comment on the feasibility of this feature request?"]}, {"number": 21830, "title": "Canned TensorForest Tracking", "body": "Implementation steps for https://github.com/tensorflow/community/blob/master/rfcs/20180626-tensor-forest.md\r\n\r\n\r\n- [x] classification only and inference only  the tf/core/kernerl part https://github.com/tensorflow/tensorflow/pull/21803\r\n- [ ] classification only and inference only the tf/estimator python part https://github.com/tensorflow/estimator/pull/9\r\n- [ ] classification only and with training https://github.com/tensorflow/tensorflow/pull/23889\r\n- [ ] end2end classification estimator with tests and docs.\r\n- [ ] regression support \r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "ohh, it seems that this feature will not be able to be supported in the near future, right?", "hey, thanks for the interest, we already have a version of tensor_forest here https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/tensor_forest please take a look  ", "@yupbank yeah, thanks, I am using it. looking forward to your early success : )", "hi, @yupbank, may I ask you a question? I found that setting the same base_random_seed for TensorForest generate different classification performance.\r\nFor example,\r\n```\r\nparams = tf.contrib.tensor_forest.python.tensor_forest.ForestHParams(\r\nnum_classes=10, num_features=64, regression=False,\r\nnum_trees=50, max_nodes=1000, base_random_seed=2)\r\n\r\nclassifier = tf.contrib.tensor_forest.client.random_forest.TensorForestEstimator(params)\r\nclassifier.fit(x=x_train, y=y_train)\r\ny_out = classifier.predict(x=x_test)\r\n\r\nyyy = [x for x in y_out]\r\n\r\ny_hat = np.array([x['classes'] for x in yyy])\r\nprint(accuracy_score(y_test, y_pred=y_hat))\r\n# first run:  0.9629629629629629\r\n# second run: 0.968013468013468\r\n# third run:  0.9646464646464646\r\n```\r\n\r\nThe base random seed is non-zero, it's supposed to produce the same result.\r\nThus, I wonder where else does the code have randomness?\r\nDoes this problem lead to a failure to reproduce the results?", "sure.. which version are you using? this should have been fixed via https://github.com/tensorflow/tensorflow/commit/470305c95c6b607e87ca476e5a109e5993f3cf6f#diff-e8520a546dc972466f7f1c3923bcff6e \r\n\r\ncan you please open a new issue and tag me? sorry this issue is mainly for us to track our dev process", "OK, @yupbank , the version is 1.12.0, and I still can see this bug : )", "Hi, I see most of the items you have listed in tracking have been merged/Closed. Could you please close this request if this issue has served it's purpose.Thanks!"]}, {"number": 21818, "title": "Unable to import tensorrt on macOS", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS, 10.13.6\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.10.0\r\n- **Python version**: 2.7.15\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:  `python -c 'from tensorflow.contrib import tensorrt as trt'`\r\n\r\n\r\n### Describe the problem\r\nUnable to import tensorrt\r\n\r\n### Source code / logs\r\n```\r\n(/private/tmp/scratch.nwani/1534993632/dev) \u279c  1534993632 python\r\nPython 2.7.15 |Anaconda, Inc.| (default, May  1 2018, 18:37:05)\r\n[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)] on darwin\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> from tensorflow.contrib import tensorrt as trt\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/private/tmp/scratch.nwani/1534993632/dev/lib/python2.7/site-packages/tensorflow/contrib/tensorrt/__init__.py\", line 25, in <module>\r\n    from tensorflow.contrib.tensorrt.python import *\r\n  File \"/private/tmp/scratch.nwani/1534993632/dev/lib/python2.7/site-packages/tensorflow/contrib/tensorrt/python/__init__.py\", line 23, in <module>\r\n    from tensorflow.contrib.tensorrt.python.trt_convert import calib_graph_to_infer_graph\r\n  File \"/private/tmp/scratch.nwani/1534993632/dev/lib/python2.7/site-packages/tensorflow/contrib/tensorrt/python/trt_convert.py\", line 23, in <module>\r\n    from tensorflow.contrib.tensorrt.wrap_conversion import calib_convert\r\n  File \"/private/tmp/scratch.nwani/1534993632/dev/lib/python2.7/site-packages/tensorflow/contrib/tensorrt/wrap_conversion.py\", line 28, in <module>\r\n    _wrap_conversion = swig_import_helper()\r\n  File \"/private/tmp/scratch.nwani/1534993632/dev/lib/python2.7/site-packages/tensorflow/contrib/tensorrt/wrap_conversion.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_wrap_conversion', fp, pathname, description)\r\nImportError: dynamic module does not define init function (init_wrap_conversion)\r\n>>>\r\n```\r\n", "comments": ["At the same time, this is succeeding:\r\n```\r\npython -c 'from tensorflow.contrib.lite.toco.python import tensorflow_wrap_toco'\r\n```\r\nSo I thought to compare the symbols.\r\n```\r\n(/private/tmp/scratch.nwani/1534993632/dev) \u279c  1534993632 nm .//dev/lib/python2.7/site-packages/tensorflow/contrib/lite/toco/python/_tensorflow_wrap_toco.so | grep tensorflow_wrap_toco\r\n0000000000003230 T _init_tensorflow_wrap_toco\r\n                 U init_tensorflow_wrap_toco\r\n                 I init_tensorflow_wrap_toco (indirect for init_tensorflow_wrap_toco)\r\n\r\n(/private/tmp/scratch.nwani/1534993632/dev) \u279c  1534993632 nm /private/tmp/scratch.nwani/1534993632/dev/lib/python2.7/site-packages/tensorflow/contrib/tensorrt/_wrap_conversion.so  | grep wrap_conversion\r\n0000000000003670 t _init_wrap_conversion <---------- small 't' :(\r\n                 U init_wrap_conversion\r\n                 I init_wrap_conversion (indirect for init_wrap_conversion)\r\n```\r\nThen, I went on to build from source to see what is going on. Looking at the object files, I saw that both are capital 'T':\r\n```\r\nsome-mac-box:~ nwani$ nm /private/var/tmp/_bazel_nwani/c8db850cfe278c8297aabaa8ebedf47a/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/contrib/tensorrt/_objs/_wrap_conversion.so/tensorflow/contrib/tensorrt/wrap_conversion.pic.o  | grep init_\r\n00000000000005d0 T _init_wrap_conversion\r\nsome-mac-box:~ nwani$ nm /private/var/tmp/_bazel_nwani/c8db850cfe278c8297aabaa8ebedf47a/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/contrib/lite/toco/python/_objs/_tensorflow_wrap_toco.so/tensorflow/contrib/lite/toco/python/tensorflow_wrap_toco.pic.o | grep init_\r\n0000000000000000 T _init_tensorflow_wrap_toco\r\n```\r\n\r\nBut then in the genereated DSOs, I found that the trouble some one hides the init symbol :(\r\n```\r\nsome-mac-box:~ nwani$ nm /private/var/tmp/_bazel_nwani/c8db850cfe278c8297aabaa8ebedf47a/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/tools/pip_package/simple_console.runfiles/org_tensorflow/tensorflow/contrib/lite/toco/python/_tensorflow_wrap_toco.so | grep init_tensor\r\n0000000000002150 T _init_tensorflow_wrap_toco\r\n                 I init_tensorflow_wrap_toco (indirect for init_tensorflow_wrap_toco)\r\n                 U init_tensorflow_wrap_toco\r\nsome-mac-box:~ nwani$ nm /private/var/tmp/_bazel_nwani/c8db850cfe278c8297aabaa8ebedf47a/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/contrib/tensorrt/_wrap_conversion.so | grep init_wra\r\n0000000000002e20 t _init_wrap_conversion <----- why you small 't'?\r\n                 I init_wrap_conversion (indirect for init_wrap_conversion)\r\n                 U init_wrap_conversion\r\n```\r\nSurprisingly, the versions scripts are identical:\r\n```\r\nsome-mac-box:~ nwani$ diff /private/var/tmp/_bazel_nwani/c8db850cfe278c8297aabaa8ebedf47a/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/contrib/lite/toco/python/tensorflow_wrap_toco_versionscript.lds /private/var/tmp/_bazel_nwani/c8db850cfe278c8297aabaa8ebedf47a/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/contrib/tensorrt/wrap_conversion_versionscript.lds\r\n2c2\r\n< init_tensorflow_wrap_toco\r\n---\r\n> init_wrap_conversion\r\n```", "Okay, I think I know what is happening. In the generated lds scripts, `_tensorflow_wrap_toco.so` exports the required symbol because of `*tensorflow*` and not because of `init_tensorflow_wrap_toco` because the actual symbol started with an underscore: `_init_tensorflow_wrap_toco` . None of the patterns listed in the lds script match for `_wrap_conversion.so` and hence the symbol `_init_wrap_conversion` remains non-exposed. ", "Where is the linker script you are looking at? Is it part of the gen rule for the swig wrapper?", "The scripts are:\r\n```\r\n/xxx/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/contrib/tensorrt/wrap_conversion_versionscript.lds\r\n/xxx/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/python/pywrap_tensorflow_internal_versionscript.lds\r\n```\r\nProbably generated by: https://github.com/tensorflow/tensorflow/blob/4a00a658050e105fca6304f4e73d15b383f472c7/tensorflow/tensorflow.bzl#L1388-L1427", "FWIW, I applied the following patch and then rebuilt tensorflow and the problem went away.\r\n\r\n```patch\r\ndiff --git a/tensorflow/tensorflow.bzl b/tensorflow/tensorflow.bzl\r\nindex 301b59a20d..41d9430dd0 100644\r\n--- a/tensorflow/tensorflow.bzl\r\n+++ b/tensorflow/tensorflow.bzl\r\n@@ -1398,7 +1398,7 @@ def _append_init_to_versionscript_impl(ctx):\r\n       template=ctx.file.template_file,\r\n       output=ctx.outputs.versionscript,\r\n       substitutions={\r\n-        \"global:\":\"global:\\n     init_%s;\\n     PyInit_*;\"%(mod_name),\r\n+        \"global:\":\"global:\\n     init_%s;\\n     _init_%s;\\n     PyInit_*;\\n     _PyInit_*;\"%(mod_name, mod_name),\r\n       },\r\n       is_executable=False,\r\n     )\r\n@@ -1407,7 +1407,7 @@ def _append_init_to_versionscript_impl(ctx):\r\n       template=ctx.file.template_file,\r\n       output=ctx.outputs.versionscript,\r\n       substitutions={\r\n-        \"*tensorflow*\":\"*tensorflow*\\ninit_%s\\nPyInit_*\\n\"%(mod_name),\r\n+        \"*tensorflow*\":\"*tensorflow*\\ninit_%s\\n_init_%s\\nPyInit_*\\n_PyInit_*\\n\"%(mod_name, mod_name),\r\n       },\r\n       is_executable=False,\r\n     )\r\n--\r\n```", "Nagging Assignee @miaout17: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Great! I'm glad that this is resolved.", "@tofulawrence  Wait, how is this resolved? I applied that patch locally. It is not part of tensorflow yet. The official build of tensorflow on PyPI still faces this issue. ", "Sorry, @nehaljwani. I misread the comment. I'll reopen. ", "On macos, we have no official support for GPUs.\r\nTensorRT is an nvidia library that accelerates inference on GPUs.\r\n\r\nSo I would say this is a strictly unsupported feature you are trying to use.\r\nWe will not be actively trying to patch this, or create a patch release for this. But it will be available when the patch ends up in the release.\r\nMarking as community support."]}, {"number": 21782, "title": "profiler trace_steps is not match global step in distribution training", "body": "### System information\r\n\r\n== cat /etc/issue ===============================================\r\nLinux gpu0198 3.10.0-229.el7.x86_64 #1 SMP Fri Mar 6 11:36:42 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"7 (Core)\"\r\nVERSION_ID=\"7\"\r\nCENTOS_MANTISBT_PROJECT_VERSION=\"7\"\r\nREDHAT_SUPPORT_PRODUCT_VERSION=\"7\"\r\n\r\n== are we in docker =============================================\r\nYes\r\n\r\n== compiler =====================================================\r\nc++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-28)\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux gpu0198 3.10.0-229.el7.x86_64 #1 SMP Fri Mar 6 11:36:42 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy                              1.14.5\r\nprotobuf                           3.6.1\r\ntensorflow-gpu                     1.10.0\r\n\r\n== check for virtualenv =========================================\r\nTrue\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.10.0\r\ntf.GIT_VERSION = v1.10.0-0-g656e7a2b34\r\ntf.COMPILER_VERSION = v1.10.0-0-g656e7a2b34\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH :/usr/local/nvidia/cpu_lib:/nodemanager/lib/native:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/java//jre/lib/amd64/server:/nodemanager/lib/native\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nWed Aug 22 03:12:21 2018\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 390.46                 Driver Version: 390.46                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla V100-PCIE...  On   | 00000000:86:00.0 Off |                    0 |\r\n| N/A   28C    P0    38W / 250W |      0MiB / 16160MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart.so.9.0.176\r\n/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart_static.a \r\n\r\n\r\n### Describe the problem\r\n\r\nWhen I use tensorflow profiler to get the timeline for distribution training, I found the trace_steps didn't match the global step and it result in useless timeline.\r\nI check the profile_context.py and find that the profile step is not related to the global step.\r\n\r\ndistribution config:\r\nps 2\r\nworker 8\r\n1 gpu per worker\r\n\r\n### Source code / logs\r\nsync code:\r\nwith tf.contrib.tfprof.ProfileContext(profile_dir=FLAGS.train_dir,\r\n                                                trace_steps=range(100, 200,3),\r\n                                                dump_steps=[200],\r\n                                                enabled=FLAGS.enable_profile,\r\n                                                debug=FLAGS.enable_profile_debug) as pctx:\r\n...\r\n...\r\n                optimizer = tf.train.SyncReplicasOptimizer(\r\n                    opt=optimizer,\r\n                    replicas_to_aggregate=FLAGS.replicas_to_aggregate,\r\n                    total_num_replicas=worker_replicas,\r\n                    variable_averages=variable_averages,\r\n                    variables_to_average=moving_average_variables)\r\n\r\n\r\nsync train log :\r\nworker 0:\r\ndebug: tracing step: 148\r\ndebug: tracing step: 151\r\nINFO:tensorflow:global step 19: loss = 2.1377 (8.300 sec/step)\r\ndebug: tracing step: 154\r\ndebug: tracing step: 157\r\n\r\nasync code:\r\nwith tf.contrib.tfprof.ProfileContext(profile_dir=FLAGS.train_dir,\r\n                                                trace_steps=range(800, 900),\r\n                                                dump_steps=[200],\r\n                                                enabled=FLAGS.enable_profile,\r\n                                                debug=FLAGS.enable_profile_debug) as pctx:\r\n\r\nasync train log:\r\nworker 0:\r\ndebug: tracing step: 838\r\nINFO:tensorflow:global step 2198: loss = 2.0687 (6.361 sec/step)\r\ndebug: tracing step: 839\r\n\r\nworker 7:\r\ndebug: tracing step: 825\r\nINFO:tensorflow:global step 3137: loss = 2.5605 (7.343 sec/step)\r\ndebug: tracing step: 826\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "### System information\r\n- **Have I written custom code \uff1aYes\r\n- **OS Platform and Distribution: docker Centos7  with v100\r\n- **Mobile device if the issue happens on mobile device: No\r\n- **TensorFlow installed from: binary\r\n- **TensorFlow version :1.10.0\r\n- **Python version: 2.7\r\n- **CUDA/cuDNN version: cuda-9.0 and cudnn 7", "@asimshankar: Who maintains this tool?", "@zhangyaobit : Mind taking a look?", "@PaulChongPeng The trace_steps used in timeline is intended to capture just a single step when program makes a single call to `session.run()`.  Each `session.run()` generates `run_metadata` protobuf which is overwritten every time. `global_step` doesn't get overwritten hence the difference as seen above. ", "So tensorflow profiler doesn't support to get the timeline for a global step when training distribution? \r\nHow can I get the the timeline for a global step to check my distribution training performance bottleneck\uff1f", "global_step should be fine and it is not affected. You can access and get the timeline for global_step using tensorflow profiler. Make sure to include tf.contrib.framework.create_or_get_global_step() or tf.train.create_or_get_global_step() in your code. \r\n\r\n", "@wt-huang \r\nI checked my code ,and confirmed  that I had used tf.train.create_global_step() in my training code.\r\nI checked tensorflow profiler code again:\r\n _profiled_run function in tensorflow/tensorflow/python/profiler/profile_context.py use profile_context._new_step() and profile_context._should_trace(self, step, graph, fetches) to check whether should trace or not.\r\n`\r\ndef _new_step(self):\r\n    acquired = self._lock.acquire(False)\r\n    yield (self._step, acquired)\r\n    self._step += 1\r\n    self._trace_next_step = False\r\n    self._dump_next_step = False\r\n    if acquired:\r\n      self._lock.release()\r\n\r\n  def _should_trace(self, step, graph, fetches):\r\n    \"\"\"Whether should do tracing at current step.\"\"\"\r\n    if self._traced_steps > MAX_TRACED_STEPS:\r\n      return False\r\n    # Check user-set tracing steps.\r\n    if step in self._trace_steps or self._trace_next_step:\r\n      self._traced_steps += 1\r\n      return True\r\n\r\n`\r\n\r\nThe step  which is used to check whether should trace or not is not related to the global step."]}, {"number": 21748, "title": "train_spec.max_steps is ignored by tf.estimator.train_and_evaluate()", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.10.0-0-g656e7a2b34 1.10.0\r\n- **Python version**: 3.6.4\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:  CUDA Version 9.1.85\r\n- **GPU model and memory**: Tesla K80\r\n- **Exact command to reproduce**: The following script\r\n\r\n```\r\nimport tensorflow as tf\r\ntf.logging.set_verbosity(20)\r\nimport math\r\nimport numpy as np\r\n\r\nx = np.array([[1,2,3.3, 2,10], [2,4.6,45,5,3],[5,5,56,2,1],[1,2,3,4,100],[10,2,1,4,50]]).astype(np.float32)\r\ny=np.array([0,0,0,1,1]).astype(np.float32)\r\nbatch_size = 2\r\n\r\ntrain_input_fn = tf.estimator.inputs.numpy_input_fn(x={'x': x},\r\n        y=y,\r\n        batch_size=batch_size,\r\n        num_epochs=1,\r\n        shuffle=True\r\n        )\r\n\r\neval_input_fn = tf.estimator.inputs.numpy_input_fn(x={'x': np.array([[1,2,3,1,4], [1,23,4,1,90]]).astype(np.float32)},\r\n        y=np.array([0,1]).astype(np.float32),\r\n        batch_size=batch_size,\r\n        num_epochs=1,\r\n        shuffle=False\r\n        )\r\n\r\ndnn = tf.estimator.DNNClassifier([32],\r\n    feature_columns=[tf.feature_column.numeric_column('x', shape=[5])])\r\n\r\nsteps_per_epoch = math.ceil(len(x) / batch_size)\r\nepochs = 3\r\n\r\ntrain_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=epochs * steps_per_epoch)\r\neval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn)\r\n\r\ntf.estimator.train_and_evaluate(dnn, train_spec, eval_spec)\r\n```\r\n\r\n### Describe the problem\r\ntf.estimator.train_and_evaluate() stops after 1 iteration with tf 1.10. It works fine with tf 1.9. Training should occur 9 times (=3 epochs x 3 steps per epoch) in total.\r\n\r\n### Source code / logs\r\n\r\nThe traceback with tf v1.9.0-0-g25c197e023 1.9.0:\r\n```\r\nINFO:tensorflow:Using default config.\r\nWARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpgn5y57s6\r\nINFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpgn5y57s6', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.tr\r\naining.server_lib.ClusterSpec object at 0x7f29437f6908>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': \r\n0, '_num_worker_replicas': 1}\r\nINFO:tensorflow:Running training and evaluation locally (non-distributed).\r\nINFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:Done calling model_fn.\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nINFO:tensorflow:Graph was finalized.\r\n2018-08-21 01:06:30.556250: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nINFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpgn5y57s6/model.ckpt.\r\nINFO:tensorflow:loss = 11.228095, step = 1\r\nINFO:tensorflow:Saving checkpoints for 3 into /tmp/tmpgn5y57s6/model.ckpt.\r\nINFO:tensorflow:Loss for final step: 0.016822023.\r\nINFO:tensorflow:Calling model_fn.\r\nWARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\r\nWARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\r\nINFO:tensorflow:Done calling model_fn.\r\nINFO:tensorflow:Starting evaluation at 2018-08-21-01:06:31\r\nINFO:tensorflow:Graph was finalized.\r\nINFO:tensorflow:Restoring parameters from /tmp/tmpgn5y57s6/model.ckpt-3\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nINFO:tensorflow:Finished evaluation at 2018-08-21-01:06:32\r\nINFO:tensorflow:Saving dict for global step 3: accuracy = 1.0, accuracy_baseline = 0.5, auc = 0.99999905, auc_precision_recall = 0.999999, average_loss = 0.27123037, global_step = 3, label/mean = 0.5, los\r\ns = 0.54246074, precision = 1.0, prediction/mean = 0.4936065, recall = 1.0\r\n...\r\n---Information of steps 1-9 is shown.---\r\n```\r\n\r\nWith tf 1.10, the program ends after step 3:\r\n```\r\nINFO:tensorflow:Using default config.\r\nWARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp686id5oc\r\nINFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp686id5oc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f10547942b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\r\nINFO:tensorflow:Running training and evaluation locally (non-distributed).\r\nINFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:Done calling model_fn.\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nINFO:tensorflow:Graph was finalized.\r\n2018-08-21 01:17:17.979737: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nINFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp686id5oc/model.ckpt.\r\nINFO:tensorflow:loss = 6.8426137, step = 1\r\nINFO:tensorflow:Saving checkpoints for 3 into /tmp/tmp686id5oc/model.ckpt.\r\nINFO:tensorflow:Calling model_fn.\r\nWARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\r\nWARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\r\nINFO:tensorflow:Done calling model_fn.\r\nINFO:tensorflow:Starting evaluation at 2018-08-21-01:17:19\r\nINFO:tensorflow:Graph was finalized.\r\nINFO:tensorflow:Restoring parameters from /tmp/tmp686id5oc/model.ckpt-3\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nINFO:tensorflow:Finished evaluation at 2018-08-21-01:17:19\r\nINFO:tensorflow:Saving dict for global step 3: accuracy = 1.0, accuracy_baseline = 0.5, auc = 0.99999905, auc_precision_recall = 0.999999, average_loss = 0.371122, global_step = 3, label/mean = 0.5, loss = 0.742244, precision = 1.0, prediction/mean = 0.42290705, recall = 1.0\r\nINFO:tensorflow:Saving 'checkpoint_path' summary for global step 3: /tmp/tmp686id5oc/model.ckpt-3\r\nINFO:tensorflow:Loss for final step: 1.7909913.\r\n```", "comments": ["In the code above, 'num_epochs' in tf.estimator.inputs.numpy_input_fn() actually determines the total number of steps, although the [documentation](https://www.tensorflow.org/versions/r1.10/api_docs/python/tf/estimator/train_and_evaluate) says \"the only supported stop condition for model training is train_spec.max_steps.\"", "Any news on this? I bumped into the same issue recently.. ", "@danielhomola It seems the number of steps is determined by the input function. Change the `num_epochs` in tf.estimator.inputs.numpy_input_fn(). If you use tf.data.Dataset, .repeat() will change the epoch number.", "I found this to be not the case.. I increased repeat in my script and train_eval still terminated after one epoch.. ", "@danielhomola Does my snippet above behave differently on your system? `num_epochs` of the `train_input_fn` changes nothing?", "I used a custom input_fn of my own not `train_input_fn`..", "Did anyone solved it? Having the same problem...", "Having the same problem here. If I set steps in EvalSpec, then train will continue after steps of eval is done. I didn't check the code, but it seems that the end-of-input exception of *eval* stops *train*...", "Ive digged into the code a few days ago and somewhere was a TODO that they have to fix the OutOfRangeError after fixing some other bug.\r\n\r\nFor now i restart the training after each epoch and reload the whole model again which takes quite some time. Maybe its worth to change the version of tf...", "@KuenstlicheIntelligenz Thanks for checking the source. In tf 1.12, I now use tf.data.Dataset, and the epoch number is determined by the dataset, not by the train_spec.", "I used tf 1.8.0 and python2. It seems that max_steps determines the total steps, not by the epoch numbers in TrainSpec."]}, {"number": 21737, "title": "Population Based training with tf.Estimator", "body": "OS Platform and Distribution N/A\r\nTensorFlow installed from N/A\r\nTensorFlow version 1.10\r\nBazel version N/A\r\nCUDA/cuDNN version N/A\r\nGPU model and memory N/A\r\nExact command to reproduce N/A\r\nMobile device N/A\r\n\r\nFeature request:\r\n\r\nCan you implement population-based training with tf.Estimator? \r\nhttps://deepmind.com/blog/population-based-training-neural-networks/", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "I have updated my feature request ", "Nagging Assignee @ispirmustafa: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Thanks @agniszczotka -- that is an interesting area of research. While we don't currently have resources to devote to a pre-baked solution here, we are happy to consider contributions that enable population based training for Estimators-- let us know if you are interested.", "@karmel I'd love to take a crack at this. Any pointers before I get started? ", "Great-- anything that can also work for Keras would be preferred-- so, if you represent additional functionality as layers/models that then become part of a canned Estimator, we have much wider applicability and flexibility. Thanks, and looking forward to updates--", "Alright, I'll get started right away. I'm creating a PR to track progress.", "Please find a toy [example](https://github.com/agniszczotka/PBT-TF.Estimator-with-Ray.Tune/blob/master/trainable_estimator_with_pbt.py) showing how to use tf.Estimator with [Ray.Tune implementation of PBT](https://ray.readthedocs.io/en/latest/tune-schedulers.html#population-based-training-pbt).\r\n", "@agniszczotka \r\nIs this still an issue ?\r\nWe see that you are using TF v1.x which is not actively supported and we recommend you to upgrade latest TF versions(2.4 or later).Please refer to the [migration](https://www.tensorflow.org/guide/migrate) doc .\r\nEstimators are not recommended for new code. Estimators  can behave unexpectedly, especially when combined with TF 2 code. Could you please refer to this [link](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier) for more details  and let us know if it helps?\r\nThanks!"]}, {"number": 21724, "title": "[license] fft2d's license is overly short and provides no enough declaration", "body": "In order to create tensorflow package for linux distributions, the distributions maintainers need to make sure the software being redistributed are free software. While looking into TensorFlow's dependencies, I found fft2d's license very confusing because it doesn't provide enough detail.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/third_party/fft2d/LICENSE\r\n\r\nI raised a discussion in Debian's legal mailing list https://lists.debian.org/debian-legal/2018/08/msg00005.html , and the two follow-ups said the fft2d license is missing the right to distribute modified code. If modified fft2d indeed cannot be redistributed, then fft2d cannot be considered as a free software.\r\n\r\nApart from that, is it possible to build TensorFlow without fft2d with sensible change to the build system? I haven't looked into the code yet.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "As far as I can see, the only place where this is actually used is the [spectrogram op](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/spectrogram.cc). \r\n\r\nThere currently isn't a build switch to turn this off, although it would be fairly straightforward to do.", "If anyone wants to add such a switch (--no-fft2d) we'd accept it. "]}, {"number": 21673, "title": "Feature Request: make grid image summary adapt to different channel number", "body": "- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:\r\nBinary\r\n- **TensorFlow version (use command below)**:\r\n1.10.0\r\n- **Python version**:\r\n3.6\r\n- **Bazel version**:\r\nN/A\r\n- **CUDA/cuDNN version**:\r\nN/A\r\n- **GPU model and memory**:\r\nN/A\r\n- **Exact command to reproduce**:\r\nN/A\r\n- **Mobile device**:\r\nN/A\r\n\r\n### Describe the problem\r\n\r\nIn image-to-image translation, sometimes we need to transform a grey image to a colored one and vice versa. In this case, image summary need to concatenate different images with different number of channels together. In tensorflow.contrib.gan standard library, this will produce a bug.\r\n\r\nI request to add an automatic mechanism to complete image channel, e.g. tile up gery image to have 3 channels. It's quite simple, and I write a workaround code. Hope this can help you add this feature.\r\n\r\n### Source code / logs\r\n\r\nFirst, a compulsory function for converting channel number. Notice it's input is a 3D image (H, W, C).\r\n\r\n```python\r\ndef convert_channel(image):\r\n  H, W = image.get_shape()[:2]\r\n  image = array_ops.tile(image, [1, 1, math_ops.maximum(1, 4 - array_ops.shape(image)[2])])\r\n  image = array_ops.slice(image, [0, 0, 0], [H, W, 3])\r\n  return image\r\n```\r\n\r\nSecond, apply this before any concatenation of image summary.\r\n\r\nThank you.\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Relevant field updated.", "any update about this request?"]}, {"number": 21526, "title": "Address missing TensorFlow operations to TFLite:", "body": "We track operations that we need add to TensorFlow Lite here:\r\n\r\n- [ ] Conv3d (https://github.com/tensorflow/tensorflow/issues/19658)\r\n- [ ] Quantized TransposeConv (https://github.com/tensorflow/tensorflow/issues/21394)\r\n- [ ] SpaceToBatchND (non-4D) (https://github.com/tensorflow/tensorflow/issues/21266)\r\n- [ ] BatchToSpaceND (non-4D) (https://github.com/tensorflow/tensorflow/issues/21266)\r\n- [ ] SquaredDifference (quantized) (https://github.com/tensorflow/tensorflow/issues/21986)\r\n- [ ] t2t model ops (Abs, All, BatchMatMul, Cos, DatasetToSingleElement, Enter, Exit, Fill, FloorMod, GatherNd, IsFinite, ListDiff, LoopCond, MapDataset, MatrixBandPart, Merge, PaddedBatchDatasetV2, Range, RefEnter, ScatterNd, Switch, TensorSliceDataset, Where, ZerosLike, convert_gradient_to_tensor_HBc3xYw22Mw) (https://github.com/tensorflow/tensorflow/issues/20679)\r\n- [ ] RandomUniform (https://github.com/tensorflow/tensorflow/issues/23651)\r\n- [ ] Quantized Div (https://github.com/tensorflow/tensorflow/issues/21526)\r\n\r\nPlease comment with new operations you may want, we will add them to the list and remove your comment. Thanks!", "comments": ["Hi, If anyone's not working on this, then I would like to work on it.", "Hi, is it worth waiting for implementation FakeQuantWithMinMaxVarsPerChannel?", "Hi all,\r\n\r\nAs we work toward fleshing out the builtin op library for TensorFlow Lite, we've been working on an experimental feature that allows using select TensorFlow ops from within the TensorFlow Lite runtime. The goal is to help reduce some of the friction for using models that rely on ops not yet natively supported by TensorFlow Lite (at the cost of increased binary size). This feature requires opting in during model conversion, as well as adding an additional dependency. More details can be found [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/using_select_tf_ops.md). \r\n\r\nFeedback is very much appreciated (either via GitHub or directly via tflite@tensorflow.org), and we'll be adding and refining functionality over the coming weeks. Cheers.", "> Hi, is it worth waiting for implementation FakeQuantWithMinMaxVarsPerChannel?\r\n\r\nIt is unlikely that we'll adding additional support for FakeQuant ops in the near future. Your best bet is to look into using [post-training quantization](https://www.tensorflow.org/lite/performance/post_training_quantization).\r\n\r\n", "@suharshs @jdduke  Hi, I want to know when conv3d feature will be release?", "Hi @StephenLee2016  Conv3D is one of the [select TF ops](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/using_select_tf_ops.md) supported via tflite_convert.", "> Hi all,\r\n> \r\n> As we work toward fleshing out the builtin op library for TensorFlow Lite, we've been working on an experimental feature that allows using select TensorFlow ops from within the TensorFlow Lite runtime. The goal is to help reduce some of the friction for using models that rely on ops not yet natively supported by TensorFlow Lite (at the cost of increased binary size). This feature requires opting in during model conversion, as well as adding an additional dependency. More details can be found [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/using_select_tf_ops.md).\r\n> \r\n> Feedback is very much appreciated (either via GitHub or directly via [tflite@tensorflow.org](mailto:tflite@tensorflow.org)), and we'll be adding and refining functionality over the coming weeks. Cheers.\r\n\r\n\r\n\r\n> Hi all,\r\n> \r\n> As we work toward fleshing out the builtin op library for TensorFlow Lite, we've been working on an experimental feature that allows using select TensorFlow ops from within the TensorFlow Lite runtime. The goal is to help reduce some of the friction for using models that rely on ops not yet natively supported by TensorFlow Lite (at the cost of increased binary size). This feature requires opting in during model conversion, as well as adding an additional dependency. More details can be found [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/using_select_tf_ops.md).\r\n> \r\n> Feedback is very much appreciated (either via GitHub or directly via [tflite@tensorflow.org](mailto:tflite@tensorflow.org)), and we'll be adding and refining functionality over the coming weeks. Cheers.\r\n\r\nTF version is 1.12.0\uff0c I can not find target_ops options in tflite_convert,   why?", "@ToBigboss Please note that you will need to build from source to gain early access to the new features.", "Is there any plans to add ResourceGather Ops? i'm having issues converting a model using an embedded layer to tflite", "Do TFLite quantized operations require that input and output have the same quantization range?\r\nI'd expect that input comes from the previous layer and output is result of the current layer so that they might have different zero points and scales. But when I look at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/maximum_minimum.cc#L72\r\nit looks as if it assumed that the scale and zero point is the same for both input and output.\r\n\r\nIs that the case?", "hi,\r\nAny update on  Quantized TransposeConv (#21394) issue?\r\nIs it already part of any release or yet under development?\r\n\r\nRegards\r\nShailendra Singh Yadav", "I am getting issue while running toco for Fast style transfer model shared at \r\nhttps://github.com/hwalsuklee/tensorflow-fast-style-transfer\r\n\r\nAfter enabling quantization aware training for same on tensorflow v 1.12.0  and running toco for QUANTIZED_UINT8  i am getting issues as :\r\n\r\n2019-01-15 14:03:41.824819: F tensorflow/contrib/lite/toco/tooling_util.cc:1635] Array ExpandDims, which is an input to the Reshape operator producing the output array truediv, is lacking min/max data, which is necessary for quantization. If accuracy matters, either target a non-quantized output format, or run quantized training with your model from a floating point checkpoint to change the input graph to contain min/max information. If you don't care about accuracy, you can pass --default_ranges_min= and --default_ranges_max= for easy experimentation.\r\nAborted (core dumped)\r\n\r\nAfter i give default min and max ranges parameters i get:\r\n\r\n2019-01-15 14:04:15.560076: F tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:474] Unimplemented: this graph contains an operator of type Div for which the quantized form is not yet implemented. Sorry, and patches welcome (that's a relatively fun patch to write, mostly providing the actual quantized arithmetic code for this op).\r\nAborted (core dumped)\r\n\r\nIs there any Plans to enable Quantized Div and expanddims?\r\n\r\n\r\nOverall operations used in frozen file summary :\r\n\r\nsummarize_graph --\r\nFound 1 possible inputs: (name=content, type=float(1), shape=[8,256,256,3])\r\nNo variables spotted.\r\nFound 1 possible outputs: (name=Tanh, op=Tanh)\r\nFound 1679928 (1.68M) const parameters, 0 (0) variable parameters, and 224 control_edges\r\nOp types used: 508 Const, 205 Identity, 128 Sub, 56 AssignSub, 56 Switch, 45 RealDiv, 44 Pow, 44 Mul, 37 Add, 32 Mean, 29 AssignAdd, 28 Assign, 28 Minimum, 28 Min, 28 Merge, 28 Maximum, 28 Max, 28 GreaterEqual, 28 FakeQuantWithMinMaxVars, 16 SquaredDifference, 16 StopGradient, 16 BiasAdd, 14 Conv2D, 10 Relu, 5 Slice, 2 Conv2DBackpropInput, 1 MirrorPad, 1 Placeholder, 1 Tanh\r\n\r\n", "Yes, we're tracking support for quantized div internally.", "Hi there, may I make a request for tf.DepthToSpace to be added to this list as well?", "> We track operations that we need add to TensorFlow Lite here:\r\n> \r\n>     * [ ]  Conv3d (#19658)\r\n> \r\n>     * [ ]  Quantized TransposeConv (#21394)\r\n> \r\n>     * [ ]  SpaceToBatchND (non-4D) (#21266)\r\n> \r\n>     * [ ]  BatchToSpaceND (non-4D) (#21266)\r\n> \r\n>     * [ ]  SquaredDifference (quantized) (#21986)\r\n> \r\n>     * [ ]  t2t model ops (Abs, All, BatchMatMul, Cos, DatasetToSingleElement, Enter, Exit, Fill, FloorMod, GatherNd, IsFinite, ListDiff, LoopCond, MapDataset, MatrixBandPart, Merge, PaddedBatchDatasetV2, Range, RefEnter, ScatterNd, Switch, TensorSliceDataset, Where, ZerosLike, convert_gradient_to_tensor_HBc3xYw22Mw) (#20679)\r\n> \r\n>     * [ ]  RandomUniform (#23651)\r\n> \r\n>     * [ ]  Quantized Div (#21526)\r\n> \r\n> \r\n> Please comment with new operations you may want, we will add them to the list and remove your comment. Thanks!\r\n\r\n\r\nHI,it seems not support Concatenation operator ,i have get the frozen file and run the script with this :+1: \r\necho 'starting convert fake model into tflite model:'${model_name}.....\r\n\r\n    tflite_path=\"./models/${model_name}/fake/model.tflite\"\r\n\r\n    test -f ${tflite_path} || tflite_convert --output_file=./models/${model_name}/fake/model.tflite \\\r\n                    --graph_def_file=./models/${model_name}/fake/model.pb \\\r\n                        --inference_type=QUANTIZED_UINT8 \\\r\n                            --input_arrays=input \\\r\n                            --output_arrays=${model_output} \\\r\n                            --mean_values=${mean_values} \\\r\n                            --std_dev_values=${std_dev_values}\\\r\n #                          --default_ranges_min=0 \\\r\n#                           --default_ranges_max=1\r\n\r\nthen i get this log ,i can fix this by point the default_min and max but obvisous that cause precision drop,so can you help with this problem? if you have any ideas please let me konw,thanks a lot \r\n\r\nRuntimeError: TOCO failed see console for info.\r\nb\"2019-01-23 14:17:34.565022: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 2558 operators, 4086 arrays (0 quantized)\\n2019-01-23 14:17:34.633795: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 2558 operators, 4086 arrays (0 quantized)\\n2019-01-23 14:17:37.296631: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 686 operators, 2332 arrays (1 quantized)\\n2019-01-23 14:17:37.318914: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 686 operators, 2332 arrays (1 quantized)\\n2019-01-23 14:17:37.325635: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 633 operators, 2279 arrays (1 quantized)\\n2019-01-23 14:17:37.337665: F tensorflow/contrib/lite/toco/tooling_util.cc:1634] Array resnext50_32x4d_type_c/block1/unit_0/conv2_grouped/Conv/Conv2D, which is an input to the Concatenation operator producing the output array resnext50_32x4d_type_c/block1/unit_0/conv2_grouped/concat, is lacking min/max data, which is necessary for quantization. If accuracy matters, either target a non-quantized output format, or run quantized training with your model from a floating point checkpoint to change the input graph to contain min/max information. If you don't care about accuracy, you can pass --default_ranges_min= and --default_ranges_max= for easy experimentation.\\nAborted (core dumped)\\n\"\r\nNone", "Hi @Vincent630, please file your issue separately, or better yet post as a question on StackOverflow with the `tensorflow-lite` tag. Thanks.", "Hi,\r\n\r\nI'm trying to convert a model built on Keras that uses Embedding, Conv1D and Dense layers. However, unfortunately, I'm getting an error related to unsupported operation.\r\n\r\n* Environment: Docker container\r\n* TF version: 1.13.0-rc0 (released 7 days ago).\r\n\r\n```\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If \r\nthose are native TensorFlow operators, you might be able to use the extended runtime by passing\r\n--enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling \r\ntf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this\r\n error with --allow_custom_ops, or by setting allow_custom_ops=True when calling \r\ntf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION,\r\n CONV_2D, EXPAND_DIMS, FULLY_CONNECTED, GATHER, RESHAPE, SHAPE, SOFTMAX, SQUEEZE,\r\n TRANSPOSE. Here is a list of operators for which you will need custom implementations: \r\nResourceGather.\r\n```\r\n\r\nI have noticed that the ResourceGather was added 4 days ago:\r\n\r\n![image](https://user-images.githubusercontent.com/5129209/51966727-9026ae00-246d-11e9-97fc-3694d50f8418.png)\r\n\r\nWhen is a new release coming up?\r\n\r\nCheers,\r\nWilder", "Hi,\r\n\r\nI managed to convert my network (architecture below) to a TFlite file using the nightly build. However, there is also another change: prior to the conversion, the graph has been frozen.\r\n\r\nBefore using TFlite, I did:\r\n\r\n```\r\nconstant_graph = graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), pred_node_names)\r\ngraph_io.write_graph(constant_graph, export_path, output_file, as_text=False)\r\n```\r\n\r\n* Environment: Docker container\r\n* TF version: 1.13.0-dev20190125\r\n\r\nNow, I will send it to the development team and see if they can actually use the model on Android/iOS.\r\n\r\n![image](https://user-images.githubusercontent.com/5129209/51971424-5fe50c80-2479-11e9-8fcf-16431d159f13.png)\r\n\r\nCheers,\r\nWilder", "quantized pow ", "Hi Assignees.!\r\n\r\nTill when can we expect the t2t model ops (BatchMatMul, Cos, Enter, GatherNd, IsFinite, ListDiff, LoopCond, MatrixBandPart, ScatterNd, Where) to be available for use ?\r\n\r\nThanks in advance..!", "`LoopCond` requires support for control flow, which is being tracked separately (and is a top priority for the TensorFlow Lite team).", "Any update on Quantized TransposeConv (#21394) issue?", "Please add instance normalization layer also in tensorflow and lite ", "`tf.cumsum` appears also not to be implemented in `tf.__version__` in '1.13.0-rc1'\r\n```bash\r\ntensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: Cumsum\r\n``` ", "`ReverseV2` appears also not to be implemented in `tf.__version__` in '1.13.0-rc1' (which is used for Bidirectional LSTM/Recurrent models in tf.keras\r\n\r\n```shell\r\n2019-02-25 10:57:27.228030: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: ReverseV2\r\n```", "Our model requires, on top of things already mentioned:\r\n'NextIteration', 'TensorArrayReadV3', 'TensorArrayScatterV3', 'TensorArraySizeV3', 'TensorArrayWriteV3'\r\n\r\nThanks!", "Hi,\r\n\r\nIs sigmoid function already included? As i am getting errors while trying to access the quantized values from the last sigmoid output layer. And even when it quantizes successfully, I am getting only one value - 0. Now i need to get a range of values from the output sigmoid layer. So do we have to exclude the sigmoid layer while performing the quantization?\r\n\r\nRegards\r\nSaraswathy.", "Hi, \r\n\r\nAny updates about when Quantized Div and ResizeNearestNeighbor operations will be supported by TFlite?\r\n\r\nHas anyone tried to implement a custom operation for ResizeNearestNeighbor using these guidelines https://www.tensorflow.org/lite/guide/ops_custom?\r\n\r\nRegards,\r\n\r\nFeliphe\r\n", "Hi,\r\nOne operation is static rnn's \"unstack\" operator. Without this, we cannot do quantization-aware training and fully quantize the model using toco. (Correct me if I'm wrong or there is a walk around for this issue) Thanks in advance!", "Hi @TF-Deve, could you file a new bug for the quantization-specific unstack variant? I think there should be a straightforward path for us to add this. Feel free to assign to me. Thanks.", "> Hi @TF-Deve, could you file a new bug for the quantization-specific unstack variant? I think there should be a straightforward path for us to add this. Feel free to assign to me. Thanks.\r\n\r\nHi @jdduke , I have filled a new issue regarding to this. I @ you in the issue. Thanks a lot!\r\nThe new issue: #27760 ", "Where is mentioned as supported on https://www.tensorflow.org/lite/guide/ops_compatibility in this section : The following TensorFlow Lite operations are fully supported and used in place of the TensorFlow operations listed above:\r\n\r\nBut I am unable to use it and here it is mentioned unsupported, can someone explain the difference?", "Is there ETA tflite roadmap for supporting operations for RNN and LSTM ?", "> Where is mentioned as supported on https://www.tensorflow.org/lite/guide/ops_compatibility in this section : The following TensorFlow Lite operations are fully supported and used in place of the TensorFlow operations listed above:\r\n> \r\n> But I am unable to use it and here it is mentioned unsupported, can someone explain the difference?\r\n\r\nFacing the same issue. Can somebody take a look at this?", "> Is there ETA tflite roadmap for supporting operations for RNN and LSTM ?\r\n\r\nYes we're actively working on control flow, which should enable generalized RNN and LSTM. \r\nSee also the public RFC\r\nhttps://github.com/tensorflow/community/pull/83/files\r\nWe're hoping to get this working in Q2. \r\n\r\nMeanwhile, you can try our experimental feature to run fused RNN/LSTM by modifying the graph construction code: \r\nhttps://g3doc.corp.google.com/third_party/tensorflow/lite/experimental/examples/lstm/g3doc/README.md?cl=head", "`AsString, ParseExample` should be added as I am stuck because of these operations in my custom tensorflow model while converting and getting inference on Android.", "Hello Guys! I'd like to deploy a 3D Conv model in Android, are there any news regarding the implementation of such features? If not, could someone enlight me if there is any other alternative I could pursue to implement the model in mobile? Thank you very much", "Hi! Like the above commenter, I also wanted to followup on the status of Conv3D support in tflite or possible alternative operations? Thank you!", "Hi, I want to know when BatchMatMul and ScatterNd  feature will be added?", "Hello, is there any plan to implement ExtractImagePatches (tf.extract_image_patches) to TFLite? Thanks", "@garoxas: There are no plans to support `ExtractImagePatches` in the near future. If that's part of the graph's pre-processing, you might exclude it during conversion and doing the pre-processing manually. Are you including that operator explicitly? Or are you using higher-level APIs for constructing the graph?\r\n\r\n@guerrillacaptain: We should support import of BatchMatMul already. While it's not a native TensorFlow Lite operator, it should be converted properly. If you're seeing otherwise please file a separate issue.\r\n\r\n@tgpsantos: You should be able to convert and use Conv3D with the [instructions here on using select TF ops](https://www.tensorflow.org/lite/guide/ops_select).\r\n\r\n", "@jdduke it's using the tf.extract_image_patches ops explicitly", "ScatterNd is commonly used between word_embedding and actual transformer structure, looking forward to its implementation.", "Regarding post https://github.com/tensorflow/tensorflow/issues/22146 , I would like to upvote priority for dilated convolutions having padding different than \"same\". **Espacially needed padding is \"causal\"**. Current conversion problem is wrong output shape.\r\n\r\n**More precisely I would like to upvote support for TCN (Temporal Convolutional Neural Networks), which are applicable in all kinds of sequence analysis problems.** \r\n\r\n**WaveNet** is one of the most known examples of TCN.\r\nMost popular implementation of TCN (and WaveNet) is here: https://github.com/philipperemy/keras-tcn.\r\nUnfortunately, only TCNs with padding \"same\" are currently converted without output shape miscalculation (padding not applicable for real-time solutions).\r\n\r\nDilated convolutions with \"causal\" padding are used in many other applications.\r\n\r\nFrom comments under mentioned thread https://github.com/tensorflow/tensorflow/issues/22146, I see that **some work in direction of fixing conversion support of this padding was already done by @ANSHUMAN87 in pull requests waiting for approval https://github.com/tensorflow/tensorflow/pull/28410 https://github.com/tensorflow/tensorflow/pull/27867 https://github.com/tensorflow/tensorflow/pull/28179** , which fills me with hope, that support for TCNs could be achieved in near future.\r\n\r\nProbably the more votes an idea gets, the higher chance of prioritisation, therefore here goes an upvote from me.\r\n\r\nWith best regards.", "@gitathrun ScatterNd is supported now via TF Select in master\r\n", "@windmaple Great news, I will test it out, I assume it is tf ver 1.14? same version in the Colab?\r\n\r\nPS: I have checked the source code directory at ../lite/toco/tflite/, is seems the ``` whitelisted_flex_ops.cc ``` file is not there, this file has been removed to \r\n```\r\nlite/delegates/flex/whitelisted_flex_ops.cc\r\n```\r\n\r\nIt probably better to update this file location change in the documentation page: https://www.tensorflow.org/lite/guide/ops_select\r\n", "@windmaple Oh, I saw the update happens days ago, probably I need manually git clone the \"master\" branch and build it?", "You can install tf-nightly", "@windmaple I installed tf-nightly and use bazel to build from source to test the code, and I found two issues for the tflite_convert cmdline tool or ```tf.lite.TFLiteConverter.from_frozen_graph ```\r\nIt throws an error:\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-4-a3977a74b44b> in <module>()\r\n      4 \r\n      5 dev_converter = tf.lite.TFLiteConverter.from_frozen_graph(dev_graph_def_file, dev_input_arrays, dev_output_arrays)\r\n----> 6 dev_tflite_model = dev_converter.convert()\r\n      7 open(\"use_lite_single_input_tf_15_dev.tflite\", \"wb\").write(dev_tflite_model)\r\n\r\n3 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/lite.py in convert(self)\r\n    987           input_tensors=self._input_tensors,\r\n    988           output_tensors=self._output_tensors,\r\n--> 989           **converter_kwargs)\r\n    990     else:\r\n    991       result = _toco_convert_graph_def(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)\r\n    435       input_data.SerializeToString(),\r\n    436       debug_info_str=debug_info_str,\r\n--> 437       enable_mlir_converter=enable_mlir_converter)\r\n    438   return data\r\n    439 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n    153       fp_toco.write(toco_flags_str)\r\n    154       fp_input.write(input_data_str)\r\n--> 155       fp_debug.write(debug_info_str)\r\n    156 \r\n    157     # Reserve an output file\r\n\r\n/usr/lib/python3.6/tempfile.py in func_wrapper(*args, **kwargs)\r\n    622             @_functools.wraps(func)\r\n    623             def func_wrapper(*args, **kwargs):\r\n--> 624                 return func(*args, **kwargs)\r\n    625             # Avoid closing the file as long as the wrapper is alive,\r\n    626             # see issue #18879.\r\n\r\nTypeError: a bytes-like object is required, not 'str'\r\n```\r\n\r\nSolution 1: But, it works fine by using \r\n```\r\ntf.lite.TFLiteConverter.from_saved_model\r\n```\r\nSolution 2: \r\nUse Python 2 instead of Python 3, then cmdline tflite_convert works fine.", "any updates on NearestNeighbourResize?", "ResizeNearestNeighbor is now fully supported (as of 1.13 or perhaps earlier, I believe).", "Thanks @jdduke, Is NearestNeighbourResize is supported in the tflite-gpu for mobiles? We used the benchmarking tool from tensorflow  and it showed that the tensorflow.keras.layers.UpSampling2D((2,2), data_format=None)(x) is not supported by the Mobile GPU. We are using tflite version : 1.13.1. ", "This may be helpful for someone using NearestNeighbourResize in their model and planning to run that on mobile-gpu. I converted the Upsampliing layer to use bilinear which is supported by GPU on mobile. By this change, the processing speed has improved a lot because some other layers which were below it on the graph also ran on GPU.  \r\n\r\nNow I have another problem which is the EXP operation which is there is tflite but not in tflite-GPU. Because of this single layer my whole processing is affected. Is there a way to create an EXP operation for tflite-GpuDelegate? ", "Can we have support for `tf.image.ResizeMethod.BICUBIC` ? Currently only bilinear and nearest neighbor are supported.", "Greetings and thank you for all your work! \r\nI would like to request the following operations to be added to the list, if possible: TensorArrayV3, TensorArrayScatterV3, TensorArrayReadV3, TensorArraySizeV3, TensorArrayGatherV3, TensorArrayWriteV3\r\nThank you for your time. ", "@suharshs \r\nI would like request the following operations to be added to the list, if possible:TensorListFromTensor, TensorListReserve, TensorListStack, While.", "Here are a few more operators that haven't been mentioned before: CropAndResize, DenseToDenseSetOperation, NonMaxSuppressionV3, StatelessWhile.\r\n\r\nAlso +1 for TensorListFromTensor, TensorListReserve, TensorListStack mentioned earlier.\r\n", "I would like to ask to add the following operations to the list: ComplexAbs, RFFT, Real (as required for audio processing with `tf.signal.stft` + `tf.signal.mfccs_from_log_mel_spectrograms`). (see also #27303 and #33897)", "Just wanted to mention that the previously mentioned ops TensorListFromTensor, TensorListReserve, TensorListStack, While are required for an RNN to run. Thanks.", "@jdduke I still can't use batchmatmul in TF1.15\uff0cI use `converter.target_spec.supported_ops = [tf.lite.OpsSet.SELECT_TF_OPS,\r\n                                           tf.lite.OpsSet.TFLITE_BUILTINS,\r\n                                           tf.lite.OpsSet.TFLITE_BUILTINS_INT8]`, and it still says `Here is a list of operators for which you will need custom implementations: BatchMatMul.`", "> I use converter.target_spec.supported_ops = [tf.lite.OpsSet.SELECT_TF_OPS, tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.TFLITE_BUILTINS_INT8], and it still says Here is a list of operators for which you will need custom implementations: BatchMatMul.\r\n\r\nIf you just use `tf.lite.OpsSet.SELECT_TF_OPS` does it work? Also note that SELECT_TF_OPS are general incompatible with quantized models.", "If I only use`tf.lite.OpsSet.SELECT_TF_OPS` and set `converter.post_training_quantize = False`\uff0canother error reports: `RuntimeError: Regular TensorFlow ops are not supported by this interpreter. Make sure you invoke the Flex delegate before inference.Node number 0 (FlexSlice) failed to prepare.\r\n`", "You'll need to either manually build the TFLite runtime, or use our nightly Select TF ops build for Android/iOS, to execute these Flex ops. See https://www.tensorflow.org/lite/guide/ops_select. We're working on some improvements to this, in particular, supporting execution of those ops from within the Python PIP environment without a rebuild.", "> @garoxas: There are no plans to support `ExtractImagePatches` in the near future. If that's part of the graph's pre-processing, you might exclude it during conversion and doing the pre-processing manually. Are you including that operator explicitly? Or are you using higher-level APIs for constructing the graph?\r\n> \r\n> @guerrillacaptain: We should support import of BatchMatMul already. While it's not a native TensorFlow Lite operator, it should be converted properly. If you're seeing otherwise please file a separate issue.\r\n> \r\n> @tgpsantos: You should be able to convert and use Conv3D with the [instructions here on using select TF ops](https://www.tensorflow.org/lite/guide/ops_select).\r\n\r\nHi, @jdduke \r\nWhen can tflite support ExtractImagePatches ops? I use the ops explicitly. Or is there any way to use ExtractImagePatches in tflite?", "\r\nRuntimeError: Quantization not yet supported for op: RESIZE_NEAREST_NEIGHBOR\r\n----------\r\ntensorflow version = 2.0.0\r\nStill no support of this error. \r\n---------------------------------------------------------------------------\r\n```\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-1-26f0299d545c> in <module>\r\n     20 tflite_converter.inference_output_type = tf.uint8\r\n     21 \r\n---> 22 tflite_model = tflite_converter.convert()\r\n     23 open(output_model_name, \"wb\").write(tflite_model)\r\n     24 \r\n\r\n~/Environments/liveness/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py in convert(self)\r\n    448     if self._is_calibration_quantize():\r\n    449       result = self._calibrate_quantize_model(result, constants.FLOAT,\r\n--> 450                                               constants.FLOAT)\r\n    451 \r\n    452     return result\r\n\r\n~/Environments/liveness/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py in _calibrate_quantize_model(self, result, inference_input_type, inference_output_type)\r\n    237     return calibrate_quantize.calibrate_and_quantize(\r\n    238         self.representative_dataset.input_gen, inference_input_type,\r\n--> 239         inference_output_type, allow_float)\r\n    240 \r\n    241   def _get_base_converter_args(self):\r\n\r\n~/Environments/liveness/lib/python3.7/site-packages/tensorflow_core/lite/python/optimize/calibrator.py in calibrate_and_quantize(self, dataset_gen, input_type, output_type, allow_float)\r\n     76     return self._calibrator.QuantizeModel(\r\n     77         np.dtype(input_type.as_numpy_dtype()).num,\r\n---> 78         np.dtype(output_type.as_numpy_dtype()).num, allow_float)\r\n\r\n~/Environments/liveness/lib/python3.7/site-packages/tensorflow_core/lite/python/optimize/tensorflow_lite_wrap_calibration_wrapper.py in QuantizeModel(self, input_py_type, output_py_type, allow_float)\r\n    113 \r\n    114     def QuantizeModel(self, input_py_type, output_py_type, allow_float):\r\n--> 115         return _tensorflow_lite_wrap_calibration_wrapper.CalibrationWrapper_QuantizeModel(self, input_py_type, output_py_type, allow_float)\r\n    116 CalibrationWrapper_swigregister = _tensorflow_lite_wrap_calibration_wrapper.CalibrationWrapper_swigregister\r\n    117 CalibrationWrapper_swigregister(CalibrationWrapper)\r\n\r\nRuntimeError: Quantization not yet supported for op: RESIZE_NEAREST_NEIGHBOR\r\n```", "> RESIZE_NEAREST_NEIGHBOR\r\n\r\nPlease upgrade to TF 2.1 or the latest TF 2.2RC.", "@jdduke It's working in 2.1 thanks", "Was quantized div added? I received the error below when trying to convert my model (tf-nightly 2.3.0.dev20200610)\r\n\r\n```python\r\nRuntimeError: Quantization not yet supported for op: DIV\r\n```", "Any plans to add ELU support? Several people have already asked. \r\n`tf-nightly 2.4.0.dev20200715`\r\n`RuntimeError: Quantization not yet supported for op: 'ELU'.`", "> RuntimeError: Quantization not yet supported for op: 'ELU'.\r\n\r\nThanks for flagging, we added float ELU support in 1.14, we'll look into adding quantization support in the next release (after 2.3).", "Are there still plans for adding support for Conv3D as an actual TFLite operator (not just as a select TF op)?", "> > RuntimeError: Quantization not yet supported for op: 'ELU'.\r\n> \r\n> Thanks for flagging, we added float ELU support in 1.14, we'll look into adding quantization support in the next release (after 2.3).\r\n\r\nI see the commit that adds quantized int8 elu, by any change quantization support is coming?\r\nhttps://github.com/tensorflow/tensorflow/commit/918f876bf812fd744151fea29b2df4aa18acfa8f", "Thanks for the great work.\r\n\r\nI was wondering whether there are any plans to add support for `MatrixDiagPartV3` / [tf.linalg.diag_part](https://www.tensorflow.org/api_docs/python/tf/linalg/diag_part) to TFLite?", "> Are there still plans for adding support for Conv3D as an actual TFLite operator (not just as a select TF op)?\r\n\r\nYes, we're working on this for the next TF release.\r\n\r\n> I was wondering whether there are any plans to add support for MatrixDiagPartV3 / tf.linalg.diag_part to TFLite?\r\n\r\nNo immediate plans, can you talk more about the model and/or use-case that requires this op? You might also take a look at https://www.tensorflow.org/lite/guide/ops_select if that works for your needs.", "@jdduke Thanks for your reply. I take early layer activations of a pre-trained MobileNet and calculate the Gram matrix on those activations, to extract information on image style. Similar to [this](https://www.tensorflow.org/tutorials/generative/style_transfer#calculate_style) tutorial. I need to keep the model as lightweight as possible, so I tried only using the diagonal part of the Gram matrix, and feed that into a dense layer (instead of the entire Gram matrix). I'm very happy with the results, but now I can't compile it to tf lite.", "Can also the following be added to the `Tensorflow Lite`?\r\n\r\n    tf.BoostedTreesEnsembleResourceHandleOp\r\n    tf.BoostedTreesPredict", "Was Exp added as a supported operator? I am facing an issue while full integer-quantizing YOLOv4. The graph adds nodes to dequantize before every Exp operation. I am using tf-nightly", "Would it be possible to add: `tf.Digamma` ?", "Is it worth waiting for implementation of Conv1D? I know that I can use Conv2D instead of Conv1D, but I have to measure performance of my MCU which uses the same Conv1D and make a comparison with Conv2D for different models (if I implemented Conv1D with Conv2D, it should use the same resources and complexity of a Conv2D, so I wouldn't do anything).", "@Lucy20211 \r\n\r\n> Is it worth waiting for implementation of Conv1D? I know that I can use Conv2D instead of Conv1D, but I have to measure performance of my MCU which uses the same Conv1D and make a comparison with Conv2D for different models (if I implemented Conv1D with Conv2D, it should use the same resources and complexity of a Conv2D, so I wouldn't do anything).\r\n\r\nFacing the same issue, only that I don't know how to use Conv2D instead of Conv1D. Could you point me to some tutorial/reference? ", "Hi @mirkomartn,\r\n\r\nwhat you could do is well summarized in the last comment here: #43141.", "@Lucy20211 Great, thank you!", "Wanted to add `tf.Selu` to the list of tflite ops for promotion. It is available using Select TF Ops but will be nice to have it as a built-in since we already have ELU. Thanks!", "https://github.com/tensorflow/tensorflow/issues/50595 requests BroadcastGradientArgs, DynamicStitch, EluGrad, Sign, StridedSliceGrad, UnsortedSegmentSum", "Can tf.einsum be supported? ", "> Can tf.einsum be supported?\r\n\r\ntf.einsum with static shape is fully supported via our converter. I think you need dynamic shape, right?", "Hi, \r\nCould you please assist with **AssignVariableOp, ReadVariableOp, VarHandleOp** ? Is it worth waiting?\r\nI know it's possible to use it with SELECT_TF_OPS, but such an option increases dll size significantly, so it would be nice to have it as a build-in. Thanks!", "Failed porting `TensorListFromTensor` as a custom op. Is it going to be added? I know I can use it through select ops, which will create a Flex version with the new experimental converter. But the `.aar` file created for Android gets too large", "Would be useful to have:\r\n\r\n`AvgPool3D, MaxPool3D, TensorListFromTensor, TensorListGetItem, TensorListReserve, TensorListSetItem, TensorListStack`\r\n\r\nModel is I3D with a custom top layer."]}, {"number": 21522, "title": "Model Parallelism Memory usage issue", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code**: Yes\r\n- **OS Platform and Distribution**: Linux Ubuntu 16.04\r\n- **Mobile device**: N/A\r\n- **TensorFlow installed from**: From binary\r\n- **TensorFlow version**: 1.9\r\n- **Python version**: 3.6.1\r\n- **Bazel version**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: 5.4.0\r\n- **CUDA/cuDNN version**: 9.0.176\r\n- **GPU model and memory**: Tested on 4X GeForce GTX 1080 with 10GB\r\n- **Exact command to reproduce**: `CUDA_VISIBLE_DEVICES=0,1,2,3 python3 train.py --data-dir=Datasets_Path/cityscapes/ --input-size=\"1000,1000\" --batch-size=1`\r\n\r\n### Describe the problem\r\nI run the above Model training on single GPU and on multiple GPUs and it looks like the memory is being allocated several times. The model size is about 10,7 GB. By distributing over several GPUs the total model size should not be increased. But as you can see it almost triples. Thereby I can not profit from model parallelism. Even a input size of 1200 x 1200 return an OOM error.\r\n\r\nThe following screenshots show the memory usage on different GPUs:\r\n\r\n### On GPU:0\r\n![gpu0](https://user-images.githubusercontent.com/8779942/43915687-c2372af4-9c0b-11e8-8eac-c7d3d28b7844.png)\r\n\r\n\r\n### On GPU:0 and 1\r\n![gpu01](https://user-images.githubusercontent.com/8779942/43915680-bda22de0-9c0b-11e8-957e-79321a8a834b.png)\r\n\r\n\r\n### On GPU:0, 1 and 3\r\n![gpu012](https://user-images.githubusercontent.com/8779942/43915644-a35d67ec-9c0b-11e8-8cd6-e79e948699c4.png)\r\n\r\n\r\n### On GPU:0, 1,2 and 3\r\n![gpu0123](https://user-images.githubusercontent.com/8779942/43915637-9b08e7a6-9c0b-11e8-9621-5e679af4bae6.png)\r\n\r\n\r\n\r\n\r\n### Source code / logs\r\n[Source code](https://github.com/reger-men/PSPNet-Tensorflow-ModelParallelism)\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nBazel version\nMobile device", "@zheng-xq , could you ptal.", "It's an issue and I'm still waiting for a response.\r\n", "@reger-men : Sorry, this seemed to have fallen through the triage cracks.\r\n\r\nI took a quick look at the attached code, but there is a lot of it :). Is it possible to write a more succinct example demonstrating the problem? In general though, this could happen if there are model parameters that are being read across GPUs. I'd have to spend a lot more time looking at the framework you're using to be sure that this isn't the case, but if you could write a shorter snippet, that would be helpful. Thanks.\r\n\r\n(@azaks2 FYI)", "@asimshankar Thank you for taking the time for this issue. \r\nI just created a new branch **cifar10** its a short example that shows a similar problem on model Parallelism.\r\nYou can change the script argument as you need _(eg. input size, batch size, etc)_\r\n\r\n", "guys,\r\nThis is serious issue. really appreciate if you could fix it\r\nThanks for your support\r\nBest Regards\r\nMazda", "@reger-men : Is it possible to get a shorter snippet that demonstrates the problem (ideally one that doesn't require downloading the dataset or figuring out how exactly to run the command in your repository). Could you elaborate on what you mean by \"memory is being allocated multiple times\"? @msabony1966 : Perhaps you have another, simpler, example demonstrating the problem?\r\n\r\nNote that TensorFlow doesn't return GPU memory to the system when it allocates it. So the memory usage you see in `nvidia-smi` will be the peak memory utilized on each GPU, which in-turn would need to account for both model parameters hosted on the device as well as the size of intermediate tensors computed along the way.\r\n\r\nIs it possible that even with model parallelism you're doing some operations that require parameters hosted on one GPU to be transferred to another GPU or something? Or that there are intermediate tensors computed on a single GPU that are larger than the memory footprint of that single GPU?", "@asimshankar as you can see in the screeshots, when I run the training on only 1 GPU the allocated memory is about 10GB. Run the same model with the same parameters (batch_size, input_size, etc.) on multiple GPUs required more than 24GB. How to explain that?\r\n\r\nMy understanding the using of model parallelism, if my model is very large and does not fit into a single GPU. Therefore I distribute the model on different GPUs to make training possible. Of course, the data here has to be exchanged between the GPUs for both forward and backward propagation and the only way is through the host. But this does not explain why too much memory is allocated on the GPUs.\r\n\r\nI already inserted a new branch in the repo [\"cifar10\"](https://github.com/reger-men/PSPNet-Tensorflow-ModelParallelism.git). You can also observe the same problem there.", "@reger-men : The memory consumed by a model depends on the computation in the model, not just variable placement. For example, consider this trivial computation:\r\n\r\n```python\r\nx = tf.random_uniform([1000, 1000, 1000]) # A ~4GB tensor\r\ny = tf.add(x, 1.)\r\nz = tf.add(y, 1.)\r\n\r\nwith tf.Session() as sess:\r\n  sess.run(z)\r\n```\r\n\r\nThis computation will consume 4GB. If I split it across 2 GPUs with something like:\r\n\r\n```python\r\nwith tf.device(\"/gpu:0\"):\r\n  x = tf.random_uniform([1000, 1000, 1000])\r\n  y = tf.add(x, 1.)\r\nwith tf.device(\"/gpu:1\"):\r\n  z = tf.add(y, 1.)\r\n\r\nwith tf.Session() as sess:\r\n  sess.run(z)\r\n```\r\n\r\nit will consume 4GB on each GPU since a 4GB tensor needs to be materialized in the memory of each device.\r\n\r\nWhen distributing the computation across devices the memory usage characteristics would depend on how the computation (and thus intermediate tensor values) is distributed. Consider another trivial program:\r\n\r\n```python\r\na = tf.random_uniform([1000, 1000, 1000]) # ~4GB\r\nb = tf.random_uniform([1000, 1000, 1000]) # ~4GB\r\nc = tf.random_uniform([1000, 1000, 1000]) # ~4GB\r\nd = tf.add_n([a, b, c])\r\ne = tf.reduce_sum(d)\r\n\r\nwith tf.Session() as sess:\r\n  sess.run(e)\r\n```\r\n\r\nwill consume ~12GB on one GPU (as 3 4GB tensors are materialized), but if you split it across 3 GPUs like:\r\n\r\n```python\r\nwith tf.device(\"/gpu:0\"):\r\n  a = tf.random_uniform([1000, 1000, 1000])\r\nwith tf.device(\"/gpu:1\"):\r\n  b = tf.random_uniform([1000, 1000, 1000])\r\nwith tf.device(\"/gpu:2\"):\r\n  c = tf.random_uniform([1000, 1000, 1000])\r\n  d = tf.add_n([a, b, c])\r\n  e = tf.reduce_sum(d)\r\n\r\nwith tf.Session()\r\n  sess.run(e)\r\n```\r\n\r\nthen it will consume ~4GB on GPU 0, ~4GB on GPU 1 and ~12GB on GPU 2 (since a 4GB tensor is materialized on each GPU, but additionally a 4GB tensor is shipped from GPU 0 to GPU 2 and another 4GB tensor is shipped from GPU 1 to GPU 2).\r\n\r\nBut if you split it like:\r\n\r\n```python\r\nwith tf.device(\"/gpu:0\"):\r\n  a = tf.random_uniform([1000, 1000, 1000])\r\nwith tf.device(\"/gpu:1\"):\r\n  b = tf.random_uniform([1000, 1000, 1000])\r\n  b_1 = tf.add(a, b)\r\nwith tf.device(\"/gpu:2\"):\r\n  c = tf.random_uniform([1000, 1000, 1000])\r\n  d = tf.add(b_1, c)\r\n  e = tf.reduce_sum(d)\r\n\r\nwith tf.Session()\r\n  sess.run(e)\r\n```\r\n\r\nit will consume ~4GB on GPU 1, ~8GB on GPU 1 and ~8GB on GPU 2, and if you split it like:\r\n\r\n```python\r\nwith tf.device(\"/gpu:0\"):\r\n  a = tf.random_uniform([1000, 1000, 1000])\r\n  a_1 = tf.reduce_sum(a)\r\nwith tf.device(\"/gpu:1\"):\r\n  b = tf.random_uniform([1000, 1000, 1000])\r\n  b_1 = tf.reduce_sum(b)\r\nwith tf.device(\"/gpu:2\"):\r\n  c = tf.random_uniform([1000, 1000, 1000])\r\n  c_1 = tf.reduce_sum(c)\r\n  e = tf.add_n([a_1, b_1, c_1])\r\n\r\nwith tf.Session()\r\n  sess.run(e)\r\n```\r\n\r\nit will consume ~4GB on each device.\r\n\r\nDoes that make sense?\r\n\r\nNote that the TensorFlow runtime is free to optimize the graph execution and in theory could do such memory saving transformations itself. However, as of _today_, the examples I've described above should have the characteristics described.\r\n\r\nI haven't had the time to dig into your sample code to understand the custom framework being used to build the network and even so running it seems to require setting up a dataset etc. first. You might get some hint of where the memory is coming from by looking at the shapes of tensors being shipped across devices.  From a cursory look at https://github.com/reger-men/PSPNet-Tensorflow-ModelParallelism/blob/279285d4e9ea9741d7208a0e4c37d3ecf42d55c7/model.py#L75 it seems that the tensors `conv3_1_1x1_proj_bn1` and `conv3_1_1x1_increase_bn` are being shipped from GPU 0 to 1, so I'd look at the shapes of those tensors, and any others going across devices. Besides the tensors being shipped, there is also the question of what the shapes and sizes of intermediate tensors being computed on the device is. \r\n\r\nAgain, the code you have is a lot to go through to figure this out. If you can reduce it to a [minimal, complete, verifiable example](https://stackoverflow.com/help/mcve) that will make it easier to figure out if there is a real problem or if the behavior you're seeing is justified given how the model is being distributed across devices.\r\n\r\nHope that helps.", "@asimshankar Thank you for the clarification.\r\nI have considered what you have described and yet the memory allocation was well above the theoretical value. \r\n\r\nLet us look at the following example (Btw, I have already uploaded it under Cifar10 Branch): \r\nAt https://github.com/reger-men/PSPNet-Tensorflow-ModelParallelism/blob/cifar10/include/model.py#L26\r\n\r\nWith consideration of the input (`10x32x3x32x32`) in this order(batch_size, preview filter number, channel, height, width)  which gives about 4MB including the processing (`conv 3x3 64 filters, Max_pool 2x2 and dropout of 0.25`), we come to about **40MB**. The memory allocation on GPU1, where this part run is about **2GB**. The model just contains 5 layers.\r\n\r\nThanks,\r\n\r\n\r\n", "I think I'm also facing a similar issue. I am trying to implement automated model parallelism. I run some partitioning algorithms and use that information to do multi-GPU model-parallel device placement. When I distribute InceptionV3 on 2 GPUs, where ~30k nodes are placed on GPU1 and ~17k nodes are placed on GPU2, both GPUs use more memory compared to the single-GPU case. To be more specific, after I set the **allow_growth** parameter to _True_ and limit the available GPU memory fraction, the multi-GPU model parallel execution still consumes more memory per GPU compared to the single-GPU execution.\r\n\r\n@asimshankar I couldn't understand the reason because even with the reasoning you explained above, a multi-GPU placement shouldn't consume **more** memory. Am I missing something or is this an issue related to the memory allocator?"]}, {"number": 21491, "title": "Consider automatic casting rules for promoting dtypes", "body": "### System information\r\n\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NA\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: NA\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: NA\r\n- **TensorFlow installed from (source or binary)**: NA\r\n- **TensorFlow version (use command below)**: unknown 1.10.0-rc1\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: NA\r\n- **GCC/Compiler version (if compiling from source)**: NA\r\n- **CUDA/cuDNN version**: NA\r\n- **GPU model and memory**: NA\r\n- **Exact command to reproduce**:\r\n\r\nArithmetic between objects with different dtypes only works with Python scalars, not Tensors:\r\n```\r\n# this works\r\n>>> tf.constant(1.0) * 2\r\n<tf.Tensor: id=4, shape=(), dtype=float32, numpy=2.0>\r\n\r\n# this doesn't\r\n>>> tf.constant(1.0) * tf.constant(2)\r\nInvalidArgumentError: cannot compute Mul as input #0 was expected to be a int32 tensor but is a float tensor [Op:Mul] name: mul/\r\n```\r\n\r\n### Describe the problem\r\n\r\nNumPy has well defined [casting rules](https://docs.scipy.org/doc/numpy/reference/ufuncs.html#casting-rules) for converting between dtypes. If an operation cannot be performed natively on the given dtypes (e.g., `np.add` between float32 and float64), then one or more of the inputs will be promoted to a higher data-type, e.g., float32 -> float64.\r\n\r\nThis is highly convenient, and remains one of the major annoyances when porting NumPy code to TensorFlow. TensorFlow code ends up littered with calls to `tf.cast()`. It's particularly annoying for any use-cases that require types other than float32, e.g., models that use complex numbers, because you can't simply cast every argument to float32.\r\n\r\nAn argument for not implementing this would be that TensorFlow strives to be more explicit than NumPy, and this could lead to unintended performance degradation. But I'm struggling to imagine cases where this would actually be the case. It's also easy to avoid by using explicit casting on everything, which could still be utilized by users who concerned about it. There are lots of areas where NumPy got things wrong by being undisciplined (e.g., indexing rules) but I have not heard any complaints about this one.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Yes, this is still an issue.", "cc @benoitsteiner  @ebrevdo @aselle can you please respond or reassign?", "Thinking about this a little more, the biggest reason why this might not work as well for TensorFlow as it does for NumPy is our preference for small data types (e.g., float32/int32 over float64/int64). NumPy's dtype promotion rules end up promoting even int32 + float32 into float64. This is rarely what a TensorFlow user would want, but conversely it's dangerous to assume that every int32 would fit in float32.", "Now I think this is probably a good idea after all. Users who care about maximum performance will need to think hard and do manual type casting \u2014 there\u2019s no way around it. But the truth is that most users don\u2019t need max performance in every single operation. At most, they need it only in the slowest part of their code. If his level APIs like Keras issued a performance warning when the optimization target is float64 and code is running on a GPU/TPU, that would probably be more than sufficient.", "Agree. For example: I found myself with the necessity of having the extra precision float64 only for some specific operations on the network, these operations can also be performed separately after the training. Having to train a new model with float64 just for this is quite time consuming...\r\nAnd AFAIK there is no easy way to convert all the weights to float64, this means to have to change all the variables instantiations and random numbers generation manually to float64 (e.g. use a tf_type variable everywhere in the code). If the code is complex (more than a simple prototyping script) this becomes also a time consuming task... and several headaches!\r\n\r\nI would like the tf operations inside my network (that I instantiate with a sonnet module, i.e. with weights sharing) to automatically cast the weights to tf.float64 if the input that I specify is a float64 placeholder... The intermediate casts could be added automatically in the graph when the network is \"attached\" to the input. Would this be a reasonable behaviour?\r\n\r\nOr in alternative, could we set something like a default tf_type to modify the tf defaults after the import (something similar to the default values of matplotlib). In this way if I would set the tf.default to float64 all the operations which are not specified would become a float64, while now are float32 by default. Would this be better/easier instead?"]}, {"number": 21409, "title": "[Feature Request] Main improvements for the c++-API", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: a bit, but this is not the problem\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 64 Bit\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: No\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: every version\r\n- **Python version**: no python bindings\r\n- **Bazel version (if compiling from source)**: using cmake\r\n- **GCC/Compiler version (if compiling from source)**: MSVC 1910\r\n- **CUDA/cuDNN version**: no\r\n- **GPU model and memory**: no\r\n- **Exact command to reproduce**: not necessary\r\n\r\n## Main improvements for the c++-API.\r\nI am really having a lot of trouble using the tensorflow api with c++. Building from sources took some time, but i fixed it. At the moment i am able to train a basic model, but not really further. I would really appreciate, if you take a look at these points \r\n\r\n### Very Important\r\n- Official support for c++\r\n- Offer downloading the c++ built binaries for Windows and Linux, CPU and GPU, 64bit\r\n- Way more examples for c++ (tried some [here](https://github.com/PinkySan/TensorflowHandlingTests))\r\n- Exporting the models must be supported (e.g. simple Save) (tried it [here](https://github.com/PinkySan/TensorflowSimpleSaver))\r\n\r\n### Important\r\n- Focussing the error is out of heap space building-problem\r\n- Building the static library without the shared library (both in the same cmake file)\r\n\r\n### Nice to have\r\n- Conanize the build (externals should be conan packages)\r\n- Conanize tensorflow itself\r\n\r\n\r\nIf anyone else got other ideas or problems, feel free to add these", "comments": ["Sounds cool :+1:\n\nOn Mon, 6 Aug 2018, 15:54 PinkySan, <notifications@github.com> wrote:\n\n> System information\n>\n>    - *Have I written custom code (as opposed to using a stock example\n>    script provided in TensorFlow)*: a bit, but this is not the problem\n>    - *OS Platform and Distribution (e.g., Linux Ubuntu 16.04)*: Windows\n>    10 64 Bit\n>    - *Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\n>    happens on mobile device*: No\n>    - *TensorFlow installed from (source or binary)*: source\n>    - *TensorFlow version (use command below)*: every version\n>    - *Python version*: no python bindings\n>    - *Bazel version (if compiling from source)*: using cmake\n>    - *GCC/Compiler version (if compiling from source)*: MSVC 1910\n>    - *CUDA/cuDNN version*: no\n>    - *GPU model and memory*: no\n>    - *Exact command to reproduce*: not necessary\n>\n> Main improvements for the c++-API.\n>\n> I am really having a lot of trouble using the tensorflow api with c++.\n> Building from sources took some time, but i fixed it. At the moment i am\n> able to train a basic model, but not really further. I would really\n> appreciate, if you take a look at these points\n> Very Important\n>\n>    - Official support for c++\n>    - Offer downloading the c++ built binaries for Windows and Linux, CPU\n>    and GPU, 64bit\n>    - Way more examples for c++\n>    - Exporting the models must be supported (e.g. simple Save)\n>\n> Important\n>\n>    - Focussing the error is out of heap space building-problem\n>    - Building the static library without the shared library (both in the\n>    same cmake file)\n>\n> Nice to have\n>\n>    - Conanize the build (externals should be conan packages)\n>    - Conanize tensorflow itself\n>\n> If anyone else got other ideas or problems, feel free to add these\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/21409>, or mute the\n> thread\n> <https://github.com/notifications/unsubscribe-auth/AFjlg4oM2-2kcAL1XkmUbzn1A-fRRwadks5uOEqygaJpZM4VwbGo>\n> .\n>\n", "spread the word!", "@josh11b this request seems pretty open-ended. But could you comment on our plans for future C++ support? I think C++ _is_ considered one of our officially supported languages, and is probably second-most popular after Python. ", "I don't know of anyone explicitly working on the C++ API at this time, so I'm going to mark this as \"contributions welcome\". I believe there are some issues with providing C++ libraries as binaries, though, because in general it is hard to make stable C++ ABI.\r\n", "I totally understand that it is pretty hard to make a stable C++  ABI and API. \r\nWhat about clearly announcing, that the C++ binaries are not a stable C++ ABI. But at least providing the binaries would help.\r\n\r\nEven after building a tensorflow application in C++ (which takes a lot of effort due to lack of c++ examples and tutorials), it is not possible to save the model and its variables into a SavedModel, which can be loaded and used within python. (I know WriteBinaryProto, WriteTextProto and the SaveV2-Ops). But the inner connection between variable-nodes and saved variables (by SaveV2) is missing.", "@PinkySan Sound like a good solution"]}]