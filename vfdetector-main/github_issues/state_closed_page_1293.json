[{"number": 14327, "title": "Mixed precision not enabled with TF1.4 on Tesla V100", "body": "Hi there,\r\n\r\nI was interested in testing my neural net (an Autoencoder that serves as a generator + a CNN as a discriminator)  that uses 3dconv/deconv layers with the new Volta architecture and benefit from the Mixed-Precision training. I compiled the most recent source code of Tensorflow 1.4 with CUDA 9 and CudNN 7.0 and cast all the trainable variables used by my conv/deconv layers to tf.float16. Also, all my input and output tensors have sizes that are multiple of 8. \r\n\r\nI have two issues so far:\r\n- I do not see any substantial speed improvement, the training time is roughly similar to when using tf.float32. My understanding is that with the Volta and cuDNN 7.0, Mixed Precision should be  automatically detected by TF and hence should use Tensor Core math. Am I wrong, or is there anything I should do to enable it? FYI, I also tried the TF1.5 nighlty build, and it seems that it is even slower than my custom 1.4.\r\n- I also noticed that the Maxpool3D layers are not supporting TF.float16 yet and need a float32 input. Any plan to change that anytime soon ?\r\n\r\nThanks for your support!", "comments": ["For point 1, please ask a question on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow), which is better suited for questions that are not bugs or feature requests.\r\n\r\nFor point 2, can you split it (or reword this issue) into a separate feature request?\r\n\r\nThanks!", "Sure, I just wrote a separate issue.\r\n", "@furybubu the way to troubleshoot this would be to isolate performance problem to individual ops.\r\nThere's probably a long road of improvements ahead in order to make TF make full use of Volta architectures.\r\n\r\nFor instance, here are some microbenchmarks on V100 using Amazon/Nvidia tensorflow images: https://medium.com/@yaroslavvb/peak-performance-of-amazon-p3-instances-f2bc48f9ef71 \r\n\r\n", "@yaroslavvb Thanks for your reply. I tried the script you wrote for your benchmark and my results seem to be fairly different from what you have. In my case, both float32 and float exhibit the same plateau around 15 Tops/s, I do not see the peaks at 87ish Tops/s like yours.\r\nMy feeling is that my tensorflow build is probably not handling half precision correctly (Like I said, I compiled 1.4rc sources with CUDA 9/CudNN 7.0 support). Would you be kind enough to share the TF build that you used for your benchmarks?\r\n", "@furybubu \r\nI've used Amazon Machine Learning for CUDA 9 image (ami-60df1418), and also NVidia's NGC container (`docker pull nvcr.io/nvidia/tensorflow:17.10`). I have not observed difference on the microbenchmark for those two images.\r\n\r\nVerbally I've been told by NVidia employees that getting TF to utilize Volta in NGC container required significant amount of customization from\u00a0the official version, and that eventually those changes will get merged back into main tensorflow.", "@yaroslavvb thanks for your insight. I am guessing now my best option is to call Nvidia!", "This appears to be resolved, so I'm closing the issue to keep the tracker focused. Feel free to re-open if needed."]}, {"number": 14326, "title": "Branch 174861804", "body": "", "comments": ["XLA is known broken. Will push anyway. @hawkinsp FYI."]}, {"number": 14325, "title": "Issue while importing tensorflow", "body": "I am trying to import tensorflow in Ubuntu 14.04 having cuda 7.5 installed. I am using tensorflow 1.4. There is issue related to\r\n importerror: libcudart.so.8.0: cannot open shared object file: no such file or directory.\r\nKindly help!!\r\n![screenshot from 2017-11-07 17-31-46 1](https://user-images.githubusercontent.com/33459515/32506944-dd8f450e-c3dd-11e7-91b8-0870e086f137.png)\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 14324, "title": "input_dims not a constant expression in slice_op.cc ", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian 9.0 (with a Gentoo Prefix)\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: c81acfb025abe417d80ffa677edfe2dd1bcda58e (15 hours old)\r\n- **Python version**: 3.6.3\r\n- **Bazel version (if compiling from source)**: 0.6.1\r\n- **GCC/Compiler version (if compiling from source)**: 6.4.0\r\n- **CUDA/cuDNN version**: no CUDA\r\n- **GPU model and memory**: no GPU\r\n- **Exact command to reproduce**: bazel build --config=mkl --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n\r\n### Describe the problem\r\nIt seems that 8011eda4b7 merged a C++ error in file [tensorflow/core/kernels/slice_op.cc line 255](https://github.com/tensorflow/tensorflow/blob/db430c4bb275e05ee65dc27c7f771f778bfcbcf2/tensorflow/core/kernels/slice_op.cc#L255).\r\nAs seen [line 232](https://github.com/tensorflow/tensorflow/blob/db430c4bb275e05ee65dc27c7f771f778bfcbcf2/tensorflow/core/kernels/slice_op.cc#L232), input_dims is a constant (const), but is not a constant expression (constexpr), thus it should not be used as a template parameter.\r\n\r\n### Source code / logs\r\n```\r\nERROR: /local/esimon/prefix/usr/local/src/tensorflow/tensorflow/core/kernels/BUILD:780:1: C++ compilation of rule '//tensorflow/core/kernel$\r\n:slice_op' failed (Exit 1).\r\ntensorflow/core/kernels/slice_op.cc: In member function 'void tensorflow::MklSliceOp<Device, T>::Compute(tensorflow::OpKernelContext*)':\r\ntensorflow/core/kernels/slice_op.cc:255:35: error: the value of 'input_dims' is not usable in a constant expression\r\n         functor::Slice<Device, T, input_dims>()(\r\n                                   ^~~~~~~~~~\r\ntensorflow/core/kernels/slice_op.cc:232:15: note: 'input_dims' was not initialized with a constant expression\r\n     const int input_dims = input.dims();\r\n               ^~~~~~~~~~\r\ntensorflow/core/kernels/slice_op.cc:255:45: error: the value of 'input_dims' is not usable in a constant expression\r\n         functor::Slice<Device, T, input_dims>()(\r\n                                             ^\r\ntensorflow/core/kernels/slice_op.cc:232:15: note: 'input_dims' was not initialized with a constant expression\r\n     const int input_dims = input.dims();\r\n               ^~~~~~~~~~\r\ntensorflow/core/kernels/slice_op.cc:255:45: note: in template argument for type 'int'\r\n         functor::Slice<Device, T, input_dims>()(\r\n                                             ^\r\n```", "comments": ["@gunan @drpngx @aselle , can you please take a look?\r\nIt might be related to https://github.com/tensorflow/tensorflow/pull/11140", "It seems to have been fixed in d0a5d885\r\nI'm closing."]}, {"number": 14323, "title": "tensorflow.python.framework.errors_impl.InvalidArgumentError: Shape mismatch in tuple component 0", "body": "When I use tensorflow to build my own neural network and run it, I meet a very strange error. The error is that tensorflow.python.framework.errors_impl.InvalidArgumentError: Shape mismatch in tuple component 0. Expected [400], got [3200]. I have no idea about how [3200] comes, could anyone can help to fix this problem? The input of the neural network is a 400-dimension vector.\r\n\r\nHere is my code:\r\n\r\n\r\ntf.logging.set_verbosity(tf.logging.INFO)\r\n\r\n\r\ndef _cnn_model_fn(features,labels,mode):\r\n  input_layer = tf.reshape(features['inputs'],[-1,400])\r\n  print(features['inputs'].shape)\r\n  fc1 = tf.layers.dense(input_layer,1024,activation=tf.nn.relu)\r\n  fc2 = tf.layers.dense(fc1,1024,activation=tf.nn.relu)\r\n  fc3 = tf.layers.dense(fc2,1024,activation=tf.nn.relu)\r\n  fc4 = tf.layers.dense(fc3,1,activation=tf.nn.sigmoid)\r\n  print(fc4.shape)\r\n  labels = tf.reshape(labels,[-1,1])\r\n  fc4 = tf.reshape(fc4,[-1,1])\r\n  print(labels.shape)\r\n  print(fc4.shape)\r\n  if mode in (Modes.PREDICT,Modes.EVAL):\r\n    print(\"P and E\")\r\n    pre = fc4\r\n  if mode in (Modes.TRAIN,Modes.EVAL):\r\n    print('T and E')\r\n    global_step = tf.contrib.framework.get_or_create_global_step()\r\n    loss = tf.losses.mean_squared_error(labels=labels,predictions=fc4)\r\n    tf.summary.scalar('OptimizeLoss',loss)\r\n  if mode == Modes.PREDICT:\r\n    print('P')\r\n    predictions = {\r\n        'vaule': pre\r\n    }\r\n    export_outputs = {\r\n        'prediction': tf.estimator.export.PredictOutput(predictions)\r\n    }\r\n    return tf.estimator.EstimatorSpec(\r\n        mode, predictions=predictions, export_outputs=export_outputs)\r\n  if mode == Modes.TRAIN:\r\n    print('T')\r\n    optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\r\n    print('optimizer')\r\n    train_op = optimizer.minimize(loss)\r\n    print('train_op')\r\n    return tf.estimator.EstimatorSpec(mode,loss=loss,train_op=train_op)\r\n  if mode == Modes.EVAL:\r\n    print('E')\r\n    eval_metric_ops = {\r\n    'accuracy':tf.metrics.accuray(labels,pre)\r\n    }\r\n    return tf.estimator.EstimatorSpec(mode,loss=loss,eval_metric_ops=eval_metric_ops)\r\n\r\n\r\ndef build_estimator(model_dir):\r\n  return tf.estimator.Estimator(\r\n      model_fn=_cnn_model_fn,\r\n      model_dir=model_dir,\r\n      config=tf.contrib.learn.RunConfig(save_checkpoints_secs=60))\r\n\r\n\r\ndef serving_input_fn():\r\n  inputs = {'inputs': tf.placeholder(tf.float32, [None, 400])}\r\n  return tf.estimator.export.ServingInputReceiver(inputs, inputs)\r\n\r\n\r\ndef read_and_decode(filename_queue):\r\n  reader = tf.TFRecordReader()\r\n  _, serialized_example = reader.read(filename_queue)\r\n\r\n  features = tf.parse_single_example(\r\n      serialized_example,\r\n      features={\r\n          'image_raw': tf.FixedLenFeature([], tf.string),\r\n          'label': tf.FixedLenFeature([], tf.float32),\r\n      })\r\n\r\n  image = tf.decode_raw(features['image_raw'], tf.uint8)\r\n  image.set_shape([400])\r\n  print('image')\r\n  print(image.shape)\r\n  image = tf.cast(image, tf.float32)\r\n  label = tf.cast(features['label'], tf.float32)\r\n  return image, label\r\n\r\n\r\ndef input_fn(filename, batch_size=100):\r\n  filename_queue = tf.train.string_input_producer([filename])\r\n\r\n  image, label = read_and_decode(filename_queue)\r\n  images, labels = tf.train.batch(\r\n      [image, label], batch_size=batch_size)\r\n  print(images.shape)\r\n\r\n  return {'inputs': images}, labels\r\n\r\n\r\ndef get_input_fn(filename, batch_size=100):\r\n  return lambda: input_fn(filename, batch_size)\r\n\r\n\r\ndef generate_experiment_fn(data_dir,\r\n                           train_batch_size=100,\r\n                           eval_batch_size=100,\r\n                           train_steps=5000,\r\n                           eval_steps=100,\r\n                           **experiment_args):\r\n\r\n  def _experiment_fn(output_dir):\r\n    return Experiment(\r\n        build_estimator(output_dir),\r\n        train_input_fn=get_input_fn(\r\n            filename=os.path.join(data_dir, 'train.tfrecords'),\r\n            batch_size=train_batch_size),\r\n        eval_input_fn=get_input_fn(\r\n            filename=os.path.join(data_dir, 'test.tfrecords'),\r\n            batch_size=eval_batch_size),\r\n        export_strategies=[saved_model_export_utils.make_export_strategy(\r\n            serving_input_fn,\r\n            default_output_alternative_key=None,\r\n            exports_to_keep=1)],\r\n        train_steps=train_steps,\r\n        eval_steps=eval_steps,\r\n        **experiment_args\r\n    )\r\n  return _experiment_fn\r\n\r\n\r\nif __name__ == '__main__':\r\n  parser = argparse.ArgumentParser()\r\n  parser.add_argument(\r\n      '--data_dir',\r\n      help='GCS or local path to training data',\r\n      type = str,\r\n      default = '/Users/hanjun/Desktop/OS/scripts'\r\n      #required=True\r\n  )\r\n  parser.add_argument(\r\n      '--train_batch_size',\r\n      help='Batch size for training steps',\r\n      type=int,\r\n      default=100\r\n  )\r\n\r\n  parser.add_argument(\r\n      '--eval_batch_size',\r\n      help='Batch size for evaluation steps',\r\n      type=int,\r\n      default=100\r\n  )\r\n\r\n  parser.add_argument(\r\n      '--train_steps',\r\n      help='Steps to run the training job for.',\r\n      type=int,\r\n      default=5000\r\n  )\r\n\r\n  parser.add_argument(\r\n      '--eval_steps',\r\n      help='Number of steps to run evalution for at each checkpoint',\r\n      default=100,\r\n      type=int\r\n  )\r\n\r\n  parser.add_argument(\r\n      '--output_dir',\r\n      help='GCS location to write checkpoints and export models',\r\n      type = str,\r\n      default = '/Users/hanjun/Desktop/OS/Model'\r\n      #required=True\r\n  )\r\n  parser.add_argument(\r\n      '--job-dir',\r\n      help='this model ignores this field, but it is required by gcloud',\r\n      default='junk'\r\n  )\r\n\r\n  parser.add_argument(\r\n      '--eval_delay_secs',\r\n      help='How long to wait before running first evaluation',\r\n      default=10,\r\n      type=int\r\n  )\r\n  parser.add_argument(\r\n      '--min_eval_frequency',\r\n      help='Minimum number of training steps between evaluations',\r\n      default=1,\r\n      type=int\r\n  )\r\n\r\n\r\n  args = parser.parse_args()\r\n  arguments = args.__dict__\r\n\r\n  # unused args provided by service\r\n  arguments.pop('job_dir', None)\r\n  arguments.pop('job-dir', None)\r\n\r\n  output_dir = arguments.pop('output_dir')\r\n\r\n  # Run the training job\r\n  learn_runner.run(generate_experiment_fn(**arguments), output_dir)", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 14322, "title": "Cannot reload tensorflow with importlib", "body": "System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nI just tried reloading tensorflow using importlib\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 10\r\n- **TensorFlow installed from (source or binary)**:\r\ntensorflow-gpu from pip\r\n- **TensorFlow version (use command below)**:\r\n1.3.0\r\n- **Python version**: \r\n3.6.2\r\n- **CUDA/cuDNN version**:\r\nCUDA 8, CuDNN 6\r\n- **GPU model and memory**:\r\nGeForce GTX 960M, 2GB\r\n- **Exact command to reproduce**:\r\nimport tensorflow as tf\r\nimport importlib\r\nimportlib.reload(tf)\r\n\r\n### Describe the problem\r\nI won't really call it a problem. I was just trying to explore some part of tensorflow by checking out some stuffs. I just thought of reloading the module but it won't work. I don't know if this is something that should work or it's just a side effect of how tensorflow is implemented. Just adding it in in case it's something that should work.\r\n\r\n### Source code / logs\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"D:\\VirtualEnv\\tensorflow\\lib\\importlib\\__init__.py\", line 166, in reload\r\n    _bootstrap._exec(spec, module)\r\n  File \"<frozen importlib._bootstrap>\", line 608, in _exec\r\n  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 205, in _call_with_frames_removed\r\n  File \"D:\\VirtualEnv\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 40, in <module>\r\n    del python\r\nNameError: name 'python' is not defined\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 14321, "title": "Fix issue in the `Defun` docs", "body": "This fix fixes a couple of typos in the `Defun` docs:\r\n`tf.Constant` -> `tf.constant`\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please"]}, {"number": 14320, "title": "Supervisor does not initialize parameters", "body": "Hi\uff0c \r\n      It throws an exception when I tried to initialize parameters with tf.train.Supervisor where the net is contructed with tensorlayer. The code is like this:\r\n \r\n```\r\n    init_op = tf.global_variables_initializer()\r\n    saver = tf.train.Saver()\r\n    config = tf.ConfigProto()\r\n    config.gpu_options.allow_growth = True\r\n    sv = tf.train.Supervisor(logdir=FLAGS.summary_dir, save_summaries_secs=0, saver=None)\r\n    with sv.managed_session(config=config) as sess:\r\n           init_ = sess.run(init_op)\r\n           net.print_params()\r\n           net.print_layers()\r\n            tl.layers.print_all_variables()\r\n```\r\nand the exception is:\r\n\r\n```\r\nCannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`\r\nTraceback (most recent call last):\r\n  File \"/home/recsys/anaconda3/envs/tf1.2/lib/python3.6/site-packages/tensorlayer/layers.py\", line 309, in print_params\r\n    val = p.eval()\r\n  File \"/home/recsys/anaconda3/envs/tf1.2/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 463, in eval\r\n    return self._variable.eval(session=session)\r\n  File \"/home/recsys/anaconda3/envs/tf1.2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 606, in eval\r\n    return _eval_using_default_session(self, feed_dict, self.graph, session)\r\n  File \"/home/recsys/anaconda3/envs/tf1.2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3914, in _eval_using_default_session\r\n    raise ValueError(\"Cannot evaluate tensor using `eval()`: No default \"\r\nValueError: Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"MainEntryPtb.py\", line 65, in <module>\r\n    train_rnn(FLAGS)\r\n  File \"/home/recsys/wangjian/learntf/TFTemplate/examples/ptb.py\", line 122, in train_rnn\r\n    net.print_params()\r\n  File \"/home/recsys/anaconda3/envs/tf1.2/lib/python3.6/site-packages/tensorlayer/layers.py\", line 313, in print_params\r\n    raise Exception(\"Hint: print params details after tl.layers.initialize_global_variables(sess) or use network.print_params(False).\")\r\nException: Hint: print params details after tl.layers.initialize_global_variables(sess) or use network.print_params(False).\r\n```\r\n\r\nIt seems that when I run initialize op `init_ = sess.run(init_op)`  it does not really work.\r\n\r\nI use tensorflow v1.2.1 and python3.6", "comments": ["All the exceptions are thrown from tensorlayer. Why would you think \"Supervisor does not initialize parameters\"?", "As if tensorflow initializes parameters succeed,  the following code could run without any exception.\r\n```\r\n           net.print_params()\r\n           net.print_layers()\r\n            tl.layers.print_all_variables()\r\n```\r\nThis exception indicate parameters initialization is now succeed.", "> As if tensorflow initializes parameters succeed, the following code could run without any Exception.\r\n\r\nYou probably came to this wrong conclusion only because of the misleading messages from tensorlayer: ` Hint: print params details after tl.layers.initialize_global_variables(sess)`, which is irrelevant to the bug you're seeing.\r\nIn fact TensorFlow is already giving you the correct message: you need `with sess.as_default()`.\r\nAnyway this issue is not a bug of tensorflow -- it's just about the usage of tensorlayer.", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 14319, "title": "add not equal op to tf_op_files.txt", "body": "Adding the kernel op `NotEqual` to tf_ops_list.txt", "comments": ["Can one of the admins verify this patch?", "@petewarden, ping?", "@petewarden any luck with this?", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 14318, "title": "updated keras backend with missing methods", "body": "Hi,\r\n\r\nThe keras backend in the tensorflow repository is currently missing:\r\n\r\nconv3d_transpose \r\ncumprod\r\ncumsum\r\ndepthwise_conv2d\r\nidentity\r\nlocal_conv1d\r\nlocal_conv2d\r\nlogsumexp\r\ntile\r\n\r\nfrom the __init__.py file.\r\n\r\nThey are present in the _impl.backend package but haven't been brought through via imports in the __int__.py file.\r\n\r\nRegards,\r\n\r\nAlex\r\n\r\n\r\n\r\n", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "@tensorflow-jenkins test this please", "Looks like you will also need to update the golden API. Could you run\r\n    $ bazel build tensorflow/tools/api/tests:api_compatibility_test\r\n    $ bazel-bin/tensorflow/tools/api/tests/api_compatibility_test \\\r\n          --update_goldens True\r\n", "@martinwicke could you approve the API change? Thanks!", "fine for API, assuming tests are fixed.", "@al3xsh mind updating the goldens as per @yifeif comment?", "Apologies for the delay - I can't do this until I'm back in my office - which wont be until next week!\r\n\r\nI'll try and do it as soon as possible after then!\r\n\r\nRegards,\r\n\r\nAlex", "@al3xsh any progress on this?", "Massive apologies - I have been snowed under at work.  I aim to get this done today (or the weekend at the latest!).\r\n\r\nSorry!\r\n\r\nAlex", "@yifeif @drpngx @rmlarsen I have updated the goldens as per the request using the commands provided.  I'm not sure what to do with it now though!  Git tells me there is nothing to commit.\r\n\r\nThe output of \"$ bazel-bin/tensorflow/tools/api/tests/api_compatibility_test --update_goldens True\" is:\r\n\r\n```\r\nalex@ubuntu:~/tensorflow$ bazel-bin/tensorflow/tools/api/tests/api_compatibility_test --update_goldens True\r\ns.s.\r\n----------------------------------------------------------------------\r\nRan 4 tests in 0.000s\r\n\r\nOK (skipped=2)\r\n```\r\n\r\nI'm sorry - I'm not familiar with the TensorFlow build process, so may well be messing something up.\r\n\r\nAny ideas what to do with it now?\r\n\r\nRegards,\r\n\r\nAlex", "Could you run those with Py2? The compatibility tests only do their thing with Py2 for technical reasons.  ", "@martinwicke \r\n\r\nThanks for the help.  I've installed python 2.7 in an anaconda environment, exported PYTHON_BIN_PATH to point to the python in the environment and rerun everything, but I still don't see any changes in git.  See log below:\r\n\r\n```\r\n(tf_dev_py2) alex@ubuntu:~/tensorflow$ export PYTHON_BIN_PATH=\"/home/alex/anaconda3/envs/tf_dev_py2/bin/python\"\r\n(tf_dev_py2) alex@ubuntu:~/tensorflow$ bazel build tensorflow/tools/api/tests:api_compatibility_test --incompatible_load_argument_is_label=false --local_resources 4096,.5,1.0\r\nWARNING: /home/alex/tensorflow/tensorflow/core/BUILD:1795:1: in includes attribute of cc_library rule //tensorflow/core:framework_headers_lib: '../../external/nsync/public' resolves to 'external/nsync/public' not below the relative path of its package 'tensorflow/core'. This will be an error in the future. Since this rule was created by the macro 'cc_header_only_library', the error might have been caused by the macro implementation in /home/alex/tensorflow/tensorflow/tensorflow.bzl:1086:30\r\nWARNING: /home/alex/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.\r\nWARNING: /home/alex/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.\r\nINFO: Analysed target //tensorflow/tools/api/tests:api_compatibility_test (0 packages loaded).\r\nINFO: Found 1 target...\r\nTarget //tensorflow/tools/api/tests:api_compatibility_test up-to-date:\r\n  bazel-bin/tensorflow/tools/api/tests/api_compatibility_test\r\nINFO: Elapsed time: 0.528s, Critical Path: 0.00s\r\nINFO: Build completed successfully, 1 total action\r\n(tf_dev_py2) alex@ubuntu:~/tensorflow$ bazel-bin/tensorflow/tools/api/tests/api_compatibility_test --update_goldens True\r\ns.s.\r\n----------------------------------------------------------------------\r\nRan 4 tests in 0.000s\r\n\r\nOK (skipped=2)\r\n(tf_dev_py2) alex@ubuntu:~/tensorflow$ git status\r\nOn branch master\r\nYour branch is up-to-date with 'origin/master'.\r\nnothing to commit, working directory clean\r\n(tf_dev_py2) alex@ubuntu:~/tensorflow$ \r\n```\r\nAny ideas?\r\n\r\nRegards,\r\n\r\nAlex\r\n", "@al3xsh it's skipping the tests, so it looks like you're still running python3. Can you try `python2 blaze-bin/...`?", "Hi @drpngx, I've tried that and it still says the same:\r\n\r\n```\r\n(tf_dev_py2) alex@ubuntu:~/tensorflow$ python --version\r\nPython 2.7.14 :: Anaconda, Inc.\r\n(tf_dev_py2) alex@ubuntu:~/tensorflow$ python2 bazel-bin/tensorflow/tools/api/tests/api_compatibility_test --update_goldens True\r\ns.s.\r\n----------------------------------------------------------------------\r\nRan 4 tests in 0.001s\r\n\r\nOK (skipped=2)\r\n(tf_dev_py2) alex@ubuntu:~/tensorflow$ \r\n```\r\n\r\nSorry for being a pain - any more ideas? \r\n\r\nAlex", "@gunan any reason why the test is not running?\r\n Also, maybe we could make the test fail if `--update_goldens` is set to `True`.", "I think you probably need to rerun configure to change the python version you are using. once configure is run, the environment variables are hardcoded and will override what you set unless you run configure.\r\n\r\nThe test will be skipped when run on python3. Instead of using `unittest.skip` we can just modify the first few lines of the test to fail in different scenarios.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Not sure why this is running python3 still. \r\nIt looks like we have `PY2AND3` that we could change to `PY2ONLY` for that rule?", "PY2_AND_3 just tells bazel not to try and auto-convert the code to another python version in case of a mismatch (which never works anyway). @gunan we should definitely improve the output of this to make clear what is happening for Py3.\r\n\r\n@al3xsh can you reconfigure for Py2 and run the update? Sorry for the complication. ", "Nagging Assignee @jhseu: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->", "Hi @drpngx and @martinwicke,\r\n\r\nI have now managed to run the bazel build process as requested and have pushed the changes.  The results of the commands were:\r\n\r\n```\r\n(tf_dev) alex@ubuntu:~/tensorflow$ bazel-bin/tensorflow/tools/api/tests/api_compatibility_test --update_goldens True\r\nWARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\r\nERROR:tensorflow:TensorFlow API backwards compatibility test\r\nThis test ensures all changes to the public API of TensorFlow are intended.\r\n\r\nIf this test fails, it means a change has been made to the public API. Backwards\r\nincompatible changes are not allowed. You can run the test as follows to update\r\ntest goldens and package them with your change.\r\n\r\n    $ bazel build tensorflow/tools/api/tests:api_compatibility_test\r\n    $ bazel-bin/tensorflow/tools/api/tests/api_compatibility_test \\\r\n          --update_goldens True\r\n\r\nYou will need an API approval to make changes to the public TensorFlow API. This\r\nincludes additions to the API.\r\n\r\nERROR:tensorflow:1 differences found between API and golden.\r\nERROR:tensorflow:Issue 1\t: Change detected in python object: tensorflow.keras.backend.\r\nWARNING:tensorflow:Golden file update requested!\r\nAll test failures have been skipped, see the logs for detected diffs.\r\nThis test is now going to write new golden files.\r\nMake sure to package the updates together with your change.\r\n\r\nYou will need an explicit API approval. This may take longer than a normal\r\nreview.\r\n\r\n..WARNING:tensorflow:Unexpected hidden op name: ConjugateTranspose\r\nWARNING:tensorflow:Unexpected hidden op name: ScaleImageGrad\r\nWARNING:tensorflow:Unexpected hidden op name: MutexAcquire\r\nWARNING:tensorflow:Unexpected hidden op name: TensorArrayPackV2\r\nWARNING:tensorflow:Unexpected hidden op name: AccumulateNV2\r\nWARNING:tensorflow:Unexpected hidden op name: ReaderWorkQueueLengthV2\r\nWARNING:tensorflow:Unexpected hidden op name: SparseSelectLastK\r\nWARNING:tensorflow:Unexpected hidden op name: Mutex\r\nWARNING:tensorflow:Unexpected hidden op name: TensorArrayPackV3\r\nWARNING:tensorflow:Unexpected hidden op name: AddV2\r\nWARNING:tensorflow:Unexpected hidden op name: HistogramFixedWidth\r\nWARNING:tensorflow:Unexpected hidden op name: TensorArrayUnpackV3\r\nWARNING:tensorflow:Unexpected hidden op name: ReaderWorkQueueLength\r\nWARNING:tensorflow:Unexpected hidden op name: TensorArrayUnpackV2\r\nWARNING:tensorflow:Unexpected hidden op name: MutexRelease\r\n..\r\n----------------------------------------------------------------------\r\nRan 4 tests in 4.517s\r\n\r\nOK\r\n(tf_dev) alex@ubuntu:~/tensorflow$ git status\r\nOn branch master\r\nYour branch is up-to-date with 'origin/master'.\r\nChanges not staged for commit:\r\n  (use \"git add <file>...\" to update what will be committed)\r\n  (use \"git checkout -- <file>...\" to discard changes in working directory)\r\n\r\n\tmodified:   tensorflow/tools/api/golden/tensorflow.keras.backend.pbtxt\r\n\tmodified:   tensorflow/workspace.bzl\r\n\r\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\r\n(tf_dev) alex@ubuntu:~/tensorflow$ git add .\r\n(tf_dev) alex@ubuntu:~/tensorflow$ git commit -m \"updated goldens as per discussion\"\r\n```\r\n\r\nDoes this look ok?\r\n\r\nRegards,\r\n\r\nAlex", "I the process, I fear you have replicated all commits from master during some period. Can you clean the commit history?", "@martinwicke \r\n\r\nI'm sorry - I have no idea what I have done :( \r\n\r\nI had managed to mess up the name in one of the git commits, which meant that the CLA got messed up.  In trying to fix that name I appear to have royally screwed up the commit history!  \r\n\r\nWould it be easier to just start again and submit a new PR?\r\n\r\nSorry for being a pain :(\r\n\r\nAlex", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "Nagging Assignee @jhseu: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Yeah, mind submitting a new PR? We'll need to address both the CLA and the merge conflicts before we can merge. Thanks!"]}, {"number": 14317, "title": "added reuse in kwargs checking for reusing shared variable", "body": "When I am implementing DeepID2 from \"Deep Learning Face Representation by Joint\r\nIdentification-Verification by Yi Sun, Xiaogang Wang and Xiaoou Tang\", I realise that using same architecture for two inputs (two face image) and sharing weight (if I didn't misunderstand) when feedforward, there is a layer called locally connected convolution, and only keras implemented LocallyConnected2D, when I trying to reuse weight, but failed because the layer didn't allow \"reuse\" as a kwargs, so when I added it, it seems working (I am not expert in deep learning, so I am not sure if I am doing it correct, so I'm always trying any way)", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed it!", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_author_cla -->", "Can one of the admins verify this patch?", "We're not accepting commits to the 1.4 branch. If you still want to do this change, can you make it in the master branch?"]}, {"number": 14316, "title": "C++ model Saving(after training) not generating 'modelName.meta' file for Prediction", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 17.04\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 1.3.0\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: 0.5.1\r\n- **GCC/Compiler version (if compiling from source)**: 6.0.3\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:\r\n\r\n`session->Run({{\"save/Const:0\", newModelFile}}, {}, {\"save/control_dependency\"}, nullptr)`\r\n\r\n### Describe the problem\r\nI am trying to train a model file in C++ and save the trained model file.\r\n\r\nwhen I save the model file with below command in C++\r\n\r\n`session->Run({{\"save/Const:0\", 'newModelFile'}}, {}, {\"save/control_dependency\"}, nullptr)`\r\n\r\nFollowing files are generated\r\n1. newModelFile.index\r\n2. newModelFile.data-00000-of-00001\r\n\r\nBut when the training and saving is done in Python with below command \r\n\r\n```\r\nwith tf.Session() as sess:\r\n    tf.train.Saver(tf.trainable_variables()).save(sess, 'newModelFile')\r\n\r\n```\r\nFollowing files are getting generated\r\n1. newModelFile.index\r\n2. newModelFile.data-00000-of-00001\r\n3. newModelFile.meta\r\n\r\nAs we can see 'newModelFile.meta' is not getting generated in C++\r\n\r\n**Requirement - To do prediction in C++ from trained model file (in C++)**   \r\n\r\nI have found the code in C++ which meets the above requirement at https://stackoverflow.com/questions/35508866/tensorflow-different-ways-to-export-and-run-graph-in-c/43639305#43639305\r\n\r\nBUT\r\n\r\nthe code makes use of 'newModelFile.meta' file which is not generated during training in C++\r\n\r\n1. Can I please know how to generate 'newModelFile.meta' file in C++ to use it for prediction\r\n2. Is there any other way to make predictions in c++ from the checkpoint files \r\n3. Is there a way to generate .pb in c++ after training instead of generating checkpoint files so that it can directly be loaded for prediction\r\n\r\nStackoverflow :  https://stackoverflow.com/questions/47154881/tensorflow-c-model-savingafter-training-not-generating-modelname-meta-file\r\n", "comments": ["As far as I know, you can only save metagraph in python and load it in C++. ", "\u00c4hmmm .... I have the same problem!\r\nDid you find a solution to the question? I have to save my trained model, otherwise it makes no sense to use tensorflow :-("]}, {"number": 14315, "title": "Does tensorflow support RowSparsePull and RowSparsePush when using embedding_lookup_sparse?", "body": "", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 14314, "title": "eager module has no attributes", "body": "My OS is Ubuntu 16.04\r\nPython version is 3.5\r\nTensorflow version is 14.0\r\nwhen I tried a simple code for TF Eager module\r\n\r\n`import tensorflow as tf`\r\n`import tensorflow.contrib.eager as tfe`\r\n`tfe.enable_eager_execution()`\r\n`x = [[2.]]`\r\n`m = tf.matmul(x, x)`\r\n\r\nI got a error\r\nAttributeError: module 'tensorflow.contrib.eager' has no attribute 'enable_eager_execution'\r\nSo what's wrong?", "comments": ["From Eager [user guide](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/g3doc/guide.md):\r\n\r\n> Eager execution is not included in the latest release (version 1.4) of TensorFlow. To use it, you will need to build TensorFlow from source or install the nightly builds.", "@sunreef Thank you!", "This works for me:\r\n\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.eager as tfe\r\ntfe.enable_eager_execution()", "you just need to include tensorflow as tf, since enable_eager_execution() is an attribute of tensorflow itself."]}, {"number": 14313, "title": "Feature request: add tf.decode_libsvm op", "body": "Hi, since libsvm format is used widespreadly to store sparse data, and is supported by many main-stream frameworks:\r\n+ spark: [LibSVMDataSource](https://spark.apache.org/docs/2.0.0/api/java/org/apache/spark/ml/source/libsvm/LibSVMDataSource.html)\r\n+ sklearn: [load_svmlight_file](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_svmlight_file.html)\r\n+ xgboost: [LibSVM format](https://github.com/dmlc/xgboost/blob/master/demo/binary_classification/README.md)\r\n\r\nCould tensorflow support to parse libsvm format like [`tf.decode_csv`](https://www.tensorflow.org/versions/master/api_docs/python/tf/decode_csv)?", "comments": ["@facaiy I added a very rudimentary implementation of `decode_libsvm` in PR #14330. It is pretty rough as am not sure about the api. Please take a look and comment.", "It looks like a few developers have written their own libsvm-format parser ops [based on previous issues](https://github.com/tensorflow/tensorflow/search?q=libsvm&type=Issues&utf8=%E2%9C%93), and a PR (above, #14330) has already been opened. Neat!\r\n\r\n@davidsoergel may be interested in this also.", "Nice work, thank you, @yongtang! I'd like to take a look if time allows."]}, {"number": 14312, "title": "R1.4", "body": "", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "We have a separate PR that will merge 1.4 back into master."]}, {"number": 14310, "title": "ONNX Support (Run ONNX nodes using TF)", "body": "As per https://github.com/tensorflow/tensorflow/issues/12888.\r\n\r\nAuthors of ONNX-TF package: Arpith Jacob, Tian Jin, Gheorghe-Teodor Bercea from IBM Research.\r\n\r\n## Objective\r\nWe are porting a subset of our package of ONNX-TF from here https://github.com/tjingrant/onnx-tf. Specifically, we want to enable users to do the following:\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom onnx import helper\r\nfrom onnx.onnx_pb2 import TensorProto\r\n\r\nX = np.random.randn(3, 2).astype(np.float32)\r\nY_ref = np.clip(X, 0, np.inf)\r\n\r\nnode_def = helper.make_node(\r\n  \"Relu\", [\"X\"], [\"X\"])\r\n\r\ngraph_def = helper.make_graph(\r\n  [node_def],\r\n  name=\"test\",\r\n  inputs=[helper.make_tensor_value_info(\"X\", TensorProto.FLOAT, [3, 2])],\r\n  outputs=[helper.make_tensor_value_info(\"X\", TensorProto.FLOAT, [3, 2])])\r\n\r\ninput_dict, output_dict = tf.contrib.onnx.prepare(helper.make_model(graph_def))\r\nwith tf.Session() as sess:\r\n  out = sess.run(output_dict['X'], feed_dict={input_dict['X']: X})\r\n\r\nnp.testing.assert_almost_equal(out, Y_ref)\r\n```\r\n## Current support for ONNX:\r\nThis implementation passes all the backend tests here https://github.com/onnx/onnx/blob/master/onnx/backend/test.py except for RNN. It supports all the models in the ONNX model zoo (https://github.com/onnx/models).\r\n\r\n## What we will be doing:\r\nWe are still working on fixing some of the tests as well as clearing as many TODO's as we can.\r\nThe ONNX RNN API changed very recently and we may do another PR for RNN support.\r\n\r\n## We'd like your opinions:\r\nWe have not imported the ONNX package dependency (https://github.com/onnx/onnx) as we'd like to get TF team's opinion regarding whether/how we should import ONNX package dependency. The benefit is that we can check for the legality of ONNX node/graph declaration. Also we need a bunch of Proto definition like GraphProto/TensorProto.\r\n\r\n@arpith-jacob, @doru1004", "comments": ["Can one of the admins verify this patch?", "anything blocking", "Hah, no rush on my side. Just saw no activity. Have a great week!\r\n\r\nAlex Newman\r\n", "@posix4e sorry deleted my previous comment b/c I mistook you for a reviewer but then realized my mistake (since the question seems to be for the Google side). Posting this for anyone who's confused about what happened : ) . ", "@tjingrant we're happy to consider something like this as a separate repository in github.com/tensorflow, but would prefer to avoid moving it to contrib due to the onnx dependency. Perhaps let's discuss on the issue?"]}, {"number": 14309, "title": "ONNX Support", "body": "As per https://github.com/tensorflow/tensorflow/issues/12888.\r\n\r\nWe are porting a subset of our package of ONNX-TF from here https://github.com/tjingrant/onnx-tf. Specifically, we want to enable users to do the following:\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom onnx import helper\r\nfrom onnx.onnx_pb2 import TensorProto\r\n\r\nX = np.random.randn(3, 2).astype(np.float32)\r\nY_ref = np.clip(X, 0, np.inf)\r\n\r\nnode_def = helper.make_node(\r\n  \"Relu\", [\"X\"], [\"X\"])\r\n\r\ngraph_def = helper.make_graph(\r\n  [node_def],\r\n  name=\"test\",\r\n  inputs=[helper.make_tensor_value_info(\"X\", TensorProto.FLOAT, [3, 2])],\r\n  outputs=[helper.make_tensor_value_info(\"X\", TensorProto.FLOAT, [3, 2])])\r\n\r\ninput_dict, output_dict = tf.contrib.onnx.prepare(helper.make_model(graph_def))\r\nwith tf.Session() as sess:\r\n  out = sess.run(output_dict['X'], feed_dict={input_dict['X']: X})\r\n\r\nnp.testing.assert_almost_equal(out, Y_ref)\r\n```\r\n\r\nWe are still working on fixing some of the tests as well as clearing as many TODO's as we can.\r\nThe ONNX RNN API changed very recently and we are still updating our implementations with respect to that.\r\n\r\nWe have not imported the ONNX package dependency as we'd like to get TF team's opinion regarding whether/how we should import ONNX package dependency. The benefit is that we can check for the legality of ONNX node/graph declaration.", "comments": ["Can one of the admins verify this patch?", "Can one of the admins verify this patch?"]}, {"number": 14308, "title": "Code Cleanup for Makefile iOS Build", "body": "Just cleanup the coding of Makefile iOS Build, should be reducing maintenance effort.\r\n\r\nThe Makefile part is skipped for the moment, I will finish it later (not in this PR).\r\n\r\nI am planning to add automatic `Selective Registration` to Makefile build by only specifying the graph file path, to both Android and iOS (I think the biggest usage of this Makefile is custom building). Once I finish the coding, will raise a PR.", "comments": ["Can one of the admins verify this patch?", "Please see PR #13959 \r\nIt cleans up the Makefiles and adds the ability to build just one architecture.  It is reviewed and is waiting for some CI tests to pass. \r\nI was planning on adding selective registration on top of that too but great if you do. \r\n", "@powderluv oh, I did not notice that PR. If you are already working on that, then I will just close this, as this is not a functional improvement. Just feel free to take any coding from here if you found something good (thought I doubt if any). Thanks. ", "Closing as PR #13959 is implementing the same thing.", "@powderluv by the way, if selective registration is on your list, feel free to go, I havent started the working yet.", "here it is PR #14421 . Please test it out and lmk if it works well for you. "]}, {"number": 14307, "title": "Update Custom Op instructions to use tf.sysconfg flags", "body": "", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please", "@jhseu, looks like a bunch of tests failed due to an internal error. Could you re-run?", "@jhseu, good to go? :-)"]}, {"number": 14306, "title": "Segmentation fault when using bidirectional_dynamic_rnn + orthogonal_initializer", "body": "### System information\r\n- **Have I written custom code**: Yes\r\n- **OS Platform and Distribution**: Ubuntu 14.04 LTS (kernel: 3.16.0-77-generic)\r\n- **TensorFlow installed from**: source\r\n- **TensorFlow version**: 1.4.0rc1 (ae04712e3b74bc85445e12c90e375f980a907e2d) \r\n- **Python version**:  2.7.10\r\n- **Bazel version**: 0.7.0\r\n- **GCC/Compiler version**: 4.8.5\r\n- **CUDA/cuDNN version**: 8.0/6.0.21\r\n- **GPU model and memory**: Maxwell Titan X with 12 GiB memory\r\n- **Exact command to reproduce**: see https://gist.github.com/nryant/57f7810e333fa94379cad201eeff24c8\r\n\r\n\r\n### Describe the problem\r\nI recently upgraded from 1.4.0-rc0 to 1.4.0-rc1 and found that a number of my model architectures fail to compile. After a bit of a detective work, I tracked the issue down to the use of ``bidirectional_dynamic_rnn`` in conjunction with a ``VariableScope`` in which ``initializer=orthogonal_initializer()``. See, for example, the test program at\r\n\r\n    https://gist.github.com/nryant/57f7810e333fa94379cad201eeff24c8\r\n\r\nRunning this will result in a segfault with 1.4.0-rc1, but not with earlier versions. The problem is specific to the combination of ``orthogonal_initializer`` and ``bidirectional_dynamic_rnn`` and does not replicate with other initializers (e.g., ``uniform_unit_scaling_initializer``) or ``dynamic_rnn``. Nor does the choice of RNN cell appear to matter.\r\n", "comments": ["I can reproduce it with tf-nightly-gpu. @ebrevdo can you please take a look?\r\nThanks", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "Could you give us a hint of where this happens? If possible, with the latest source tree, if you could build with ASAN, that would be really nice. I'm assuming that you are seeing this only on GPUs?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 14305, "title": "Merge 1.4 branch back into master", "body": "This merge only includes version string updates.", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this State. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Done. Made the Bazel version updates you made in your CL."]}, {"number": 14304, "title": "Up", "body": "Sorry:) It was mistake", "comments": ["Can one of the admins verify this patch?", "Can one of the admins verify this patch?"]}, {"number": 14303, "title": "tf.metrics.mean_per_class_accuracy does not assume num_classes", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: ('v1.2.0-5-g435cdfc', '1.2.1')\r\n- **Python version**: 2.7.6\r\n- **CUDA/cuDNN version**: 5.1\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nWhen I run an Experiment with `tf.metrics.mean_per_class_accuracy` as a metric, I get the following error. This is unexpected because all other metrics simply need predictions and labels. Also, `num_classes` is already known by the graph in the model head.\r\n```\r\nERROR:tensorflow:Could not create metric ops for MetricSpec(metric_fn=mean_per_class_accuracy, prediction_key=classes, label_key=None, weight_key=None), mean_per_class_accuracy() takes at least 3 arguments (2 given).\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/usr/local/home/rasmi/trainer/task.py\", line 282, in <module>\r\n    learn_runner.run(generate_experiment_fn(args), args.job_dir)\r\n  File \"/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.py\", line 210, in run\r\n    return _execute_schedule(experiment, schedule)\r\n  File \"/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.py\", line 47, in _execute_schedule\r\n    return task()\r\n  File \"/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\", line 495, in train_and_evaluate\r\n    self.train(delay_secs=0)\r\n  File \"/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\", line 275, in train\r\n    hooks=self._train_monitors + extra_hooks)\r\n  File \"/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.py\", line 665, in _call_train\r\n    monitors=hooks)\r\n  File \"/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 289, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 455, in fit\r\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)\r\n  File \"/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 1007, in _train_model\r\n    _, loss = mon_sess.run([model_fn_ops.train_op, model_fn_ops.loss])\r\n  File \"/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 505, in run\r\n    run_metadata=run_metadata)\r\n  File \"/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 842, in run\r\n    run_metadata=run_metadata)\r\n  File \"/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 798, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 960, in run\r\n    run_metadata=run_metadata))\r\n  File \"/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 1178, in after_run\r\n    induce_stop = m.step_end(self._last_step, result)\r\n  File \"/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 357, in step_end\r\n    return self.every_n_step_end(step, output)\r\n  File \"/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 677, in every_n_step_end\r\n    validation_outputs = self._evaluate_estimator()\r\n  File \"/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/monitors.py\", line 653, in _evaluate_estimator\r\n    metrics=self.metrics, hooks=self.hooks, name=self.name)\r\n  File \"/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 289, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 543, in evaluate\r\n    log_progress=log_progress)\r\n  File \"/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 829, in _evaluate_model\r\n    model_fn_results = self._get_eval_ops(features, labels, metrics)\r\n  File \"/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 1196, in _get_eval_ops\r\n    metrics, features, labels, model_fn_ops.predictions))\r\n  File \"/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 269, in _make_metrics_ops\r\n    result[name] = metric.create_metric_ops(features, labels, predictions)\r\n  File \"/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/metric_spec.py\", line 428, in create_metric_ops\r\n    weights=inputs[self.weight_key] if self.weight_key else None)\r\n  File \"/usr/local/home/rasmi/virtualenvs/python2env/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/metric_spec.py\", line 166, in _named_metric_fn\r\n    return metric_fn(**kwargs)\r\nTypeError: mean_per_class_accuracy() takes at least 3 arguments (2 given)\r\n```\r\n\r\n### Source code / logs\r\nI create my Experiment as follows:\r\n```\r\n    return tf.contrib.learn.Experiment(\r\n        train_input_fn = train_input,\r\n        eval_input_fn = eval_input,\r\n        train_steps = 10000,\r\n        eval_steps = 100,\r\n        eval_metrics = {\r\n          \"mean_per_class_accuracy\": tf.contrib.learn.MetricSpec(\r\n            metric_fn=tf.metrics.mean_per_class_accuracy,\r\n            prediction_key=tf.contrib.learn.PredictionKey.CLASSES\r\n          )\r\n      }\r\n```", "comments": ["Here is a quick workaround. Essentially, define a wrapper function which gets `num_classes` from elsewhere in your model.py and passes it to `eval_metrics`. But ideally this can be inferred from elsewhere in the graph.\r\n```\r\ndef mean_per_class_accuracy(labels, predictions):\r\n      return tf.metrics.mean_per_class_accuracy(labels, predictions, num_classes=len(model.LABELS))\r\n\r\nreturn tf.contrib.learn.Experiment(\r\n        train_input_fn = train_input,\r\n        eval_input_fn = eval_input,\r\n        train_steps = 10000,\r\n        eval_steps = 100,\r\n        eval_metrics = {\r\n          \"mean_per_class_accuracy\": tf.contrib.learn.MetricSpec(\r\n            metric_fn=mean_per_class_accuracy,\r\n            prediction_key=tf.contrib.learn.PredictionKey.CLASSES\r\n          )\r\n      }\r\n\r\n```\r\n", "I guess the doc says following for num_classes,\r\n`num_classes: The possible number of labels the prediction task can have. This value must be provided, since a confusion matrix of dimension = [num_classes, num_classes] will be allocated.`", "This looks like a feature/cleanup request. @alextp, can you take a look?", "> This is unexpected because all other metrics simply need predictions and labels. \r\n\r\nIt seems not true, see `tf.metrics.recall_at_k(labels, predictions, k)` and ` tf.metrics.mean(values)`\r\n\r\nPerhaps curried function is a better design for `tf.metrics`, for example:\r\n```python\r\ndef xxx_metrics(a, b=None):\r\n    def fn(label, prediction):\r\n        # do something\r\nreturn fn\r\n```", "This is why MetricSpec was dropped on the transition from tf.contrib.learn.Estimator to tf.estimator.Estimator. Instead, metrics are returned from the model_fn. If you switch to tf.estimator.Estimator and return your metrics from the model_fn this issue should go away.", "If that is the preferred approach going forward, then there is no need to modify this in contrib. The above workaround will suffice for those using the contrib Estimator. Thanks Alex! "]}, {"number": 14302, "title": "TF CNN benchmark resnet-50 not freeing up GPU memory after being terminated", "body": "Hi\r\n\r\nI've ran some of the cnn benchmarks on an cluster that uses SLURM, on a Nvidia XP. One of my jobs got stuck. When I cancelled the script, it seems not to free up the GPU memory anymore after that.\r\ntotalMemory: 11.90GiB freeMemory: 365.94MiB\r\n\r\nNow I can't run any more scripts. How can I free up my GPU memory again?\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: cnn_benchmarks \r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Cluster node with amd cpu and NVidia XP\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.4\r\n- **Python version**: 2.7 \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**: GCC version:  gcc version 4.8.5 20150623 (Red Hat 4.8.5-16) (GCC) \r\n- **CUDA/cuDNN version**: Cuda8, Cudnn 6\r\n- **GPU model and memory**: Nvidia XP\r\n- **Exact command to reproduce**: python tf_cnn_benchmarks.py --model=resnet50 --num_gpus=1 --local_parameter_device=gpu\r\n\r\n### Source code / logs\r\n2017-11-06 21:45:35.243801: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX FMA\r\n2017-11-06 21:45:35.832723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: \r\nname: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582\r\npciBusID: 0000:41:00.0\r\ntotalMemory: 11.90GiB freeMemory: 365.94MiB\r\n2017-11-06 21:45:35.832780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN Xp, pci bus id: 0000:41:00.0, compute capability: 6.1)\r\n2017-11-06 21:45:46.271894: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 144.00MiB.  Current allocation summary follows.\r\n2017-11-06 21:45:46.271976: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (256): \tTotal Chunks: 18, Chunks in use: 18. 4.5KiB allocated for chunks. 4.5KiB in use in bin. 576B client-requested in use in bin.\r\n2017-11-06 21:45:46.271992: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (512): \tTotal Chunks: 2, Chunks in use: 2. 1.5KiB allocated for chunks. 1.5KiB in use in bin. 1.5KiB client-requested in use in bin.\r\n2017-11-06 21:45:46.272005: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (1024): \tTotal Chunks: 7, Chunks in use: 7. 9.2KiB allocated for chunks. 9.2KiB in use in bin. 9.0KiB client-requested in use in bin.\r\n2017-11-06 21:45:46.272016: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2017-11-06 21:45:46.272029: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (4096): \tTotal Chunks: 1, Chunks in use: 1. 4.0KiB allocated for chunks. 4.0KiB in use in bin. 3.9KiB client-requested in use in bin.\r\n2017-11-06 21:45:46.272040: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2017-11-06 21:45:46.272052: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (16384): \tTotal Chunks: 2, Chunks in use: 2. 32.0KiB allocated for chunks. 32.0KiB in use in bin. 32.0KiB client-requested in use in bin.\r\n2017-11-06 21:45:46.272063: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2017-11-06 21:45:46.272076: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (65536): \tTotal Chunks: 1, Chunks in use: 1. 90.8KiB allocated for chunks. 90.8KiB in use in bin. 90.8KiB client-requested in use in bin.\r\n2017-11-06 21:45:46.272087: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2017-11-06 21:45:46.272097: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2017-11-06 21:45:46.272108: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2017-11-06 21:45:46.272120: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (1048576): \tTotal Chunks: 1, Chunks in use: 1. 1.17MiB allocated for chunks. 1.17MiB in use in bin. 1.17MiB client-requested in use in bin.\r\n2017-11-06 21:45:46.272131: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (2097152): \tTotal Chunks: 2, Chunks in use: 2. 5.91MiB allocated for chunks. 5.91MiB in use in bin. 5.91MiB client-requested in use in bin.\r\n2017-11-06 21:45:46.272143: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (4194304): \tTotal Chunks: 1, Chunks in use: 1. 5.06MiB allocated for chunks. 5.06MiB in use in bin. 5.06MiB client-requested in use in bin.\r\n2017-11-06 21:45:46.272153: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2017-11-06 21:45:46.272164: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2017-11-06 21:45:46.272176: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2017-11-06 21:45:46.272186: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2017-11-06 21:45:46.272197: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (134217728): \tTotal Chunks: 1, Chunks in use: 0. 128.66MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2017-11-06 21:45:46.272208: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2017-11-06 21:45:46.272220: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin for 144.00MiB was 128.00MiB, Chunk State: \r\n2017-11-06 21:45:46.272296: I tensorflow/core/common_runtime/bfc_allocator.cc:649]   Size: 128.66MiB | Requested Size: 0B | in_use: 0, prev:   Size: 1.0KiB | Requested Size: 1.0KiB | in_use: 1\r\n2017-11-06 21:45:46.272309: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400000 of size 1280\r\n2017-11-06 21:45:46.272318: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400500 of size 256\r\n2017-11-06 21:45:46.272326: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400600 of size 256\r\n2017-11-06 21:45:46.272341: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400700 of size 256\r\n2017-11-06 21:45:46.272350: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400800 of size 256\r\n2017-11-06 21:45:46.272358: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400900 of size 256\r\n2017-11-06 21:45:46.272368: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400a00 of size 768\r\n2017-11-06 21:45:46.272376: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400d00 of size 256\r\n2017-11-06 21:45:46.272385: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400e00 of size 256\r\n2017-11-06 21:45:46.272393: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400f00 of size 1536\r\n2017-11-06 21:45:46.272402: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401500 of size 256\r\n2017-11-06 21:45:46.272411: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401600 of size 256\r\n2017-11-06 21:45:46.272420: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401700 of size 1536\r\n2017-11-06 21:45:46.272428: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401d00 of size 256\r\n2017-11-06 21:45:46.272438: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401e00 of size 256\r\n2017-11-06 21:45:46.272447: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401f00 of size 1024\r\n2017-11-06 21:45:46.272455: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e402300 of size 256\r\n2017-11-06 21:45:46.272465: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e402400 of size 256\r\n2017-11-06 21:45:46.272474: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e402500 of size 16384\r\n2017-11-06 21:45:46.272482: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e406500 of size 256\r\n2017-11-06 21:45:46.272491: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e406600 of size 256\r\n2017-11-06 21:45:46.272499: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e406700 of size 16384\r\n2017-11-06 21:45:46.272507: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e40a700 of size 256\r\n2017-11-06 21:45:46.272516: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e40a800 of size 256\r\n2017-11-06 21:45:46.272528: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e40a900 of size 4096\r\n2017-11-06 21:45:46.272537: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e40b900 of size 92928\r\n2017-11-06 21:45:46.272546: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e422400 of size 256\r\n2017-11-06 21:45:46.272554: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e422500 of size 1228800\r\n2017-11-06 21:45:46.272562: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e54e500 of size 768\r\n2017-11-06 21:45:46.272571: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e54e800 of size 2654208\r\n2017-11-06 21:45:46.272580: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e7d6800 of size 1536\r\n2017-11-06 21:45:46.272589: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e7d6e00 of size 5308416\r\n2017-11-06 21:45:46.272597: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ece6e00 of size 1536\r\n2017-11-06 21:45:46.272606: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ece7400 of size 3538944\r\n2017-11-06 21:45:46.272614: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f047400 of size 1024\r\n2017-11-06 21:45:46.272623: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x1020f047800 of size 134907904\r\n2017-11-06 21:45:46.272631: I tensorflow/core/common_runtime/bfc_allocator.cc:676]      Summary of in-use Chunks by size: \r\n2017-11-06 21:45:46.272645: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 18 Chunks of size 256 totalling 4.5KiB\r\n2017-11-06 21:45:46.272655: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 768 totalling 1.5KiB\r\n2017-11-06 21:45:46.272665: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 1024 totalling 2.0KiB\r\n2017-11-06 21:45:46.272675: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 1280 totalling 1.2KiB\r\n2017-11-06 21:45:46.272686: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 4 Chunks of size 1536 totalling 6.0KiB\r\n2017-11-06 21:45:46.272695: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 4096 totalling 4.0KiB\r\n2017-11-06 21:45:46.272706: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 16384 totalling 32.0KiB\r\n2017-11-06 21:45:46.272716: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 92928 totalling 90.8KiB\r\n2017-11-06 21:45:46.272725: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 1228800 totalling 1.17MiB\r\n2017-11-06 21:45:46.272735: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 2654208 totalling 2.53MiB\r\n2017-11-06 21:45:46.272749: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 3538944 totalling 3.38MiB\r\n2017-11-06 21:45:46.272760: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 5308416 totalling 5.06MiB\r\n2017-11-06 21:45:46.272772: I tensorflow/core/common_runtime/bfc_allocator.cc:683] Sum Total of in-use chunks: 12.28MiB\r\n2017-11-06 21:45:46.272786: I tensorflow/core/common_runtime/bfc_allocator.cc:685] Stats: \r\nLimit:                   147783680\r\nInUse:                    12875776\r\nMaxInUse:                 12875776\r\nNumAllocs:                      35\r\nMaxAllocSize:              5308416\r\n\r\n2017-11-06 21:45:46.272799: W tensorflow/core/common_runtime/bfc_allocator.cc:277] *********___________________________________________________________________________________________\r\n2017-11-06 21:45:46.272823: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[9216,4096]\r\n2017-11-06 21:45:56.273596: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 64.00MiB.  Current allocation summary follows.\r\n2017-11-06 21:45:56.273635: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (256): \tTotal Chunks: 18, Chunks in use: 18. 4.5KiB allocated for chunks. 4.5KiB in use in bin. 576B client-requested in use in bin.\r\n2017-11-06 21:45:56.273649: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (512): \tTotal Chunks: 2, Chunks in use: 2. 1.5KiB allocated for chunks. 1.5KiB in use in bin. 1.5KiB client-requested in use in bin.\r\n2017-11-06 21:45:56.273661: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (1024): \tTotal Chunks: 7, Chunks in use: 7. 9.2KiB allocated for chunks. 9.2KiB in use in bin. 9.0KiB client-requested in use in bin.\r\n2017-11-06 21:45:56.273672: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2017-11-06 21:45:56.273684: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (4096): \tTotal Chunks: 2, Chunks in use: 2. 8.0KiB allocated for chunks. 8.0KiB in use in bin. 7.8KiB client-requested in use in bin.\r\n2017-11-06 21:45:56.273695: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2017-11-06 21:45:56.273707: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (16384): \tTotal Chunks: 4, Chunks in use: 4. 64.0KiB allocated for chunks. 64.0KiB in use in bin. 64.0KiB client-requested in use in bin.\r\n2017-11-06 21:45:56.273718: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2017-11-06 21:45:56.273731: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (65536): \tTotal Chunks: 2, Chunks in use: 1. 181.5KiB allocated for chunks. 90.8KiB in use in bin. 90.8KiB client-requested in use in bin.\r\n2017-11-06 21:45:56.273742: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2017-11-06 21:45:56.273754: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2017-11-06 21:45:56.273765: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2017-11-06 21:45:56.273777: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (1048576): \tTotal Chunks: 2, Chunks in use: 1. 2.34MiB allocated for chunks. 1.17MiB in use in bin. 1.17MiB client-requested in use in bin.\r\n2017-11-06 21:45:56.273788: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (2097152): \tTotal Chunks: 3, Chunks in use: 1. 8.44MiB allocated for chunks. 2.53MiB in use in bin. 2.53MiB client-requested in use in bin.\r\n2017-11-06 21:45:56.273800: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (4194304): \tTotal Chunks: 2, Chunks in use: 2. 10.12MiB allocated for chunks. 10.12MiB in use in bin. 8.44MiB client-requested in use in bin.\r\n2017-11-06 21:45:56.273813: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (8388608): \tTotal Chunks: 1, Chunks in use: 1. 15.64MiB allocated for chunks. 15.64MiB in use in bin. 15.64MiB client-requested in use in bin.\r\n2017-11-06 21:45:56.273823: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2017-11-06 21:45:56.273834: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (33554432): \tTotal Chunks: 1, Chunks in use: 0. 40.13MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2017-11-06 21:45:56.273852: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (67108864): \tTotal Chunks: 1, Chunks in use: 1. 64.00MiB allocated for chunks. 64.00MiB in use in bin. 64.00MiB client-requested in use in bin.\r\n2017-11-06 21:45:56.273863: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2017-11-06 21:45:56.273874: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2017-11-06 21:45:56.273884: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin for 64.00MiB was 64.00MiB, Chunk State: \r\n2017-11-06 21:45:56.273895: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400000 of size 1280\r\n2017-11-06 21:45:56.273904: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400500 of size 256\r\n2017-11-06 21:45:56.273913: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400600 of size 256\r\n2017-11-06 21:45:56.273921: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400700 of size 256\r\n2017-11-06 21:45:56.273929: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400800 of size 256\r\n2017-11-06 21:45:56.273937: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400900 of size 256\r\n2017-11-06 21:45:56.273946: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400a00 of size 768\r\n2017-11-06 21:45:56.273955: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400d00 of size 256\r\n2017-11-06 21:45:56.273963: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400e00 of size 256\r\n2017-11-06 21:45:56.273972: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e400f00 of size 1536\r\n2017-11-06 21:45:56.273981: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401500 of size 256\r\n2017-11-06 21:45:56.273989: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401600 of size 256\r\n2017-11-06 21:45:56.273997: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401700 of size 1536\r\n2017-11-06 21:45:56.274005: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401d00 of size 256\r\n2017-11-06 21:45:56.274014: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401e00 of size 256\r\n2017-11-06 21:45:56.274029: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e401f00 of size 1024\r\n2017-11-06 21:45:56.274038: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e402300 of size 256\r\n2017-11-06 21:45:56.274046: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e402400 of size 256\r\n2017-11-06 21:45:56.274056: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e402500 of size 16384\r\n2017-11-06 21:45:56.274065: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e406500 of size 256\r\n2017-11-06 21:45:56.274074: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e406600 of size 256\r\n2017-11-06 21:45:56.274084: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e406700 of size 16384\r\n2017-11-06 21:45:56.274093: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e40a700 of size 256\r\n2017-11-06 21:45:56.274101: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e40a800 of size 256\r\n2017-11-06 21:45:56.274109: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e40a900 of size 4096\r\n2017-11-06 21:45:56.274117: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e422400 of size 256\r\n2017-11-06 21:45:56.274126: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e54e500 of size 768\r\n2017-11-06 21:45:56.274138: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e7d6800 of size 1536\r\n2017-11-06 21:45:56.274149: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020e7d6e00 of size 5308416\r\n2017-11-06 21:45:56.274157: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020ece6e00 of size 1536\r\n2017-11-06 21:45:56.274166: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f047400 of size 1024\r\n2017-11-06 21:45:56.274174: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f047800 of size 16384\r\n2017-11-06 21:45:56.274182: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1020f04b800 of size 67108864\r\n2017-11-06 21:45:56.274191: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021304b800 of size 16384\r\n2017-11-06 21:45:56.274199: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021304f800 of size 16400384\r\n2017-11-06 21:45:56.274207: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10213ff3800 of size 4096\r\n2017-11-06 21:45:56.274216: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10213ff4800 of size 92928\r\n2017-11-06 21:45:56.274225: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x1021400b300 of size 1228800\r\n2017-11-06 21:45:56.274299: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x10214137300 of size 2654208\r\n2017-11-06 21:45:56.274308: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x102143bf300 of size 5308416\r\n2017-11-06 21:45:56.274317: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x1020e40b900 of size 92928\r\n2017-11-06 21:45:56.274325: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x1020e422500 of size 1228800\r\n2017-11-06 21:45:56.274333: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x1020e54e800 of size 2654208\r\n2017-11-06 21:45:56.274342: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x1020ece7400 of size 3538944\r\n2017-11-06 21:45:56.274351: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x102148cf300 of size 42077440\r\n2017-11-06 21:45:56.274359: I tensorflow/core/common_runtime/bfc_allocator.cc:676]      Summary of in-use Chunks by size: \r\n2017-11-06 21:45:56.274369: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 18 Chunks of size 256 totalling 4.5KiB\r\n2017-11-06 21:45:56.274381: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 768 totalling 1.5KiB\r\n2017-11-06 21:45:56.274391: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 1024 totalling 2.0KiB\r\n2017-11-06 21:45:56.274401: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 1280 totalling 1.2KiB\r\n2017-11-06 21:45:56.274412: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 4 Chunks of size 1536 totalling 6.0KiB\r\n2017-11-06 21:45:56.274422: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 4096 totalling 8.0KiB\r\n2017-11-06 21:45:56.274433: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 4 Chunks of size 16384 totalling 64.0KiB\r\n2017-11-06 21:45:56.274443: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 92928 totalling 90.8KiB\r\n2017-11-06 21:45:56.274454: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 1228800 totalling 1.17MiB\r\n2017-11-06 21:45:56.274463: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 2654208 totalling 2.53MiB\r\n2017-11-06 21:45:56.274474: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 5308416 totalling 10.12MiB\r\n2017-11-06 21:45:56.274489: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 16400384 totalling 15.64MiB\r\n2017-11-06 21:45:56.274500: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 67108864 totalling 64.00MiB\r\n2017-11-06 21:45:56.274510: I tensorflow/core/common_runtime/bfc_allocator.cc:683] Sum Total of in-use chunks: 93.64MiB\r\n2017-11-06 21:45:56.274522: I tensorflow/core/common_runtime/bfc_allocator.cc:685] Stats: \r\nLimit:                   147783680\r\nInUse:                    98191360\r\nMaxInUse:                101730304\r\nNumAllocs:                      45\r\nMaxAllocSize:             67108864\r\n\r\n2017-11-06 21:45:56.274536: W tensorflow/core/common_runtime/bfc_allocator.cc:277] *_*****_****************************************************************____________________________\r\n2017-11-06 21:45:56.274550: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[4096,4096]\r\nTensorFlow:  1.4\r\nModel:       alexnet\r\nMode:        training\r\nSingleSess:  False\r\nBatch size:  32 global\r\n             32 per device\r\nDevices:     ['/gpu:0']\r\nData format: NCHW\r\nOptimizer:   sgd\r\nVariables:   parameter_server\r\n==========\r\nGenerating model\r\nTraceback (most recent call last):\r\n  File \"tf_cnn_benchmarks.py\", line 46, in <module>\r\n    tf.app.run()\r\n  File \"/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"tf_cnn_benchmarks.py\", line 42, in main\r\n    bench.run()\r\n  File \"/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", line 892, in run\r\n    return self._benchmark_cnn()\r\n  File \"/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", line 1068, in _benchmark_cnn\r\n    start_standard_services=start_standard_services) as sess:\r\n  File \"/usr/lib64/python2.7/contextlib.py\", line 17, in __enter__\r\n    return self.gen.next()\r\n  File \"/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py\", line 964, in managed_session\r\n    self.stop(close_summary_writer=close_summary_writer)\r\n  File \"/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py\", line 792, in stop\r\n    stop_grace_period_secs=self._stop_grace_secs)\r\n  File \"/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py\", line 389, in join\r\n    six.reraise(*self._exc_info_to_raise)\r\n  File \"/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py\", line 953, in managed_session\r\n    start_standard_services=start_standard_services)\r\n  File \"/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py\", line 708, in prepare_or_wait_for_session\r\n    init_feed_dict=self._init_feed_dict, init_fn=self._init_fn)\r\n  File \"/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py\", line 279, in prepare_session\r\n    sess.run(init_op, feed_dict=init_feed_dict)\r\n  File \"/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 889, in run\r\n    run_metadata_ptr)\r\n  File \"/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1120, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1317, in _do_run\r\n    options, run_metadata)\r\n  File \"/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1336, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[9216,4096]\r\n\t [[Node: v/cg/affine0/weights/Initializer/truncated_normal/TruncatedNormal = TruncatedNormal[T=DT_INT32, _class=[\"loc:@v/cg/affine0/weights\"], dtype=DT_FLOAT, seed=1234, seed2=149, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](v/cg/affine0/weights/Initializer/truncated_normal/shape)]]\r\n\r\nCaused by op u'v/cg/affine0/weights/Initializer/truncated_normal/TruncatedNormal', defined at:\r\n  File \"tf_cnn_benchmarks.py\", line 46, in <module>\r\n    tf.app.run()\r\n  File \"/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"tf_cnn_benchmarks.py\", line 42, in main\r\n    bench.run()\r\n  File \"/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", line 892, in run\r\n    return self._benchmark_cnn()\r\n  File \"/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", line 986, in _benchmark_cnn\r\n    (image_producer_ops, enqueue_ops, fetches) = self._build_model()\r\n  File \"/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", line 1236, in _build_model\r\n    gpu_compute_stage_ops, gpu_grad_stage_ops)\r\n  File \"/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", line 1524, in add_forward_pass_and_gradients\r\n    self.model.add_inference(network)\r\n  File \"/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/models/alexnet_model.py\", line 45, in add_inference\r\n    cnn.affine(4096)\r\n  File \"/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py\", line 311, in affine\r\n    initializer=tf.truncated_normal_initializer(stddev=stddev))\r\n  File \"/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py\", line 117, in get_variable\r\n    var = tf.get_variable(name, shape, dtype, *args, **kwargs)\r\n  File \"/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1203, in get_variable\r\n    constraint=constraint)\r\n  File \"/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1092, in get_variable\r\n    constraint=constraint)\r\n  File \"/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 417, in get_variable\r\n    return custom_getter(**custom_getter_kwargs)\r\n  File \"/home/kklein/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py\", line 86, in inner_custom_getter\r\n    var = getter(*args, **kwargs)\r\n  File \"/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 394, in _true_getter\r\n    use_resource=use_resource, constraint=constraint)\r\n  File \"/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 805, in _get_single_variable\r\n    constraint=constraint)\r\n  File \"/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 213, in __init__\r\n    constraint=constraint)\r\n  File \"/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 303, in _init_from_args\r\n    initial_value(), name=\"initial_value\", dtype=dtype)\r\n  File \"/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 779, in <lambda>\r\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\r\n  File \"/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/init_ops.py\", line 309, in __call__\r\n    shape, self.mean, self.stddev, dtype, seed=self.seed)\r\n  File \"/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/random_ops.py\", line 172, in truncated_normal\r\n    shape_tensor, dtype, seed=seed1, seed2=seed2)\r\n  File \"/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/gen_random_ops.py\", line 588, in _truncated_normal\r\n    name=name)\r\n  File \"/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\r\n    op_def=op_def)\r\n  File \"/home/kklein/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[9216,4096]\r\n\t [[Node: v/cg/affine0/weights/Initializer/truncated_normal/TruncatedNormal = TruncatedNormal[T=DT_INT32, _class=[\"loc:@v/cg/affine0/weights\"], dtype=DT_FLOAT, seed=1234, seed2=149, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](v/cg/affine0/weights/Initializer/truncated_normal/shape)]]\r\n\r\nsrun: error: gpu08: task 0: Exited with exit code 1\r\n\r\n", "comments": ["Is there anything else running on the same XP gpu?\r\n\r\nTo free up GPU memory, you can try approaches recommended on stackoverflow, for example:\r\nhttps://stackoverflow.com/questions/15197286/how-can-i-flush-gpu-memory-using-cuda-physical-reset-is-unavailable\r\n", "The admin had to relaunch the node on the cluster. My script turned into a zombie a threw the gpu off the bus :dagger: \r\nI'm now running my stuff again.\r\n\r\nThanks", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @bignamehyp: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Close this issue due to inactivity. "]}, {"number": 14301, "title": "CUDA_ERROR_OUT_OF_MEMORY tensorflow 1.4", "body": "### System information\r\nOS - High Sierra 10.13\r\nTensorflow - 1.4\r\nKeras - 2.0.9\r\nCUDA - 9\r\ncuDNN - 7\r\n\r\n### Describe the problem\r\nCUDA_ERROR_OUT_OF_MEMORY running tensorflow on GPU\r\n\r\nSimple program:\r\n```\r\nimport tensorflow as tf\r\nwith tf.device('/gpu:0'):\r\n    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\r\n    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\r\n    c = tf.matmul(a, b)\r\n\r\nwith tf.Session() as sess:\r\n    print (sess.run(c))\r\n```\r\n\r\nOutput:\r\n```\r\n(tensorflow) Smit-Shilu:Desktop smitshilu$ python gputest.py \r\n2017-11-07 08:55:50.690390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:856] OS X does not support NUMA - returning NUMA node zero\r\n2017-11-07 08:55:50.690536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1031] Found device 0 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.6705\r\npciBusID: 0000:c3:00.0\r\ntotalMemory: 11.00GiB freeMemory: 10.81GiB\r\n2017-11-07 08:55:50.690560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:c3:00.0, compute capability: 6.1)\r\n2017-11-07 08:55:50.690914: E tensorflow/stream_executor/cuda/cuda_driver.cc:936] failed to allocate 10.27G (11026294784 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\n2017-11-07 08:55:50.691022: E tensorflow/stream_executor/cuda/cuda_driver.cc:936] failed to allocate 9.24G (9923664896 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\n[[ 22.  28.]\r\n [ 49.  64.]]\r\n```\r\n\r\nCUDA_ERROR_OUT_OF_MEMORY when import Keras after upgrading to 10.13 and 1.4\r\n\r\n```\r\n>>> from keras.callbacks import *\r\nUsing TensorFlow backend.\r\n2017-11-06 16:30:54.704584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:856] OS X does not support NUMA - returning NUMA node zero\r\n2017-11-06 16:30:54.704700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1031] Found device 0 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.6705\r\npciBusID: 0000:c3:00.0\r\ntotalMemory: 11.00GiB freeMemory: 10.81GiB\r\n2017-11-06 16:30:54.704725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:c3:00.0, compute capability: 6.1)\r\n2017-11-06 16:30:54.705019: E tensorflow/stream_executor/cuda/cuda_driver.cc:936] failed to allocate 10.27G (11026489344 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\n2017-11-06 16:30:54.705125: E tensorflow/stream_executor/cuda/cuda_driver.cc:936] failed to allocate 9.24G (9923840000 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\n```", "comments": ["This seems to be a duplicate of #14107.\r\n\r\nFor questions related to reducing memory usage for your specific case, please ask a question on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow), which we also monitor. Thanks!", "@angersson I am not sure whether it is duplicate or not. But I couldn't find a solution for this. The problem wasn't there for 1.2 ", "#14107 discusses 1.4's extra GPU memory usage compared to older versions, which seems to be the same issue that you're facing.\r\n\r\nFor help with making adjustments for your specific case, [Stack Overflow](http://stackoverflow.com/questions/tagged/tensorflow) is our preferred location to ask questions. Thanks!", "I have the same problem, how do you fix it.  The out of memory error also occurs in pytorch when you allocate memory more than 8gb or so"]}, {"number": 14300, "title": "improve int data type check in session", "body": "right now this would fail\r\n```\r\nimport tensorflow as tf\r\nsess = tf.InteractiveSession()\r\ntf.placeholder(tf.string, name='t').eval(feed_dict={'t_1:0': 1})\r\n```\r\nwith  \r\n```\r\nTypeError: object() takes no parameters\r\n```", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please.", "@yupbank session_test is failing, can you look at this?", "ah... i made a mistake by specifying the sting type use tf directly.. ", "@tensorflow-jenkins test this please.", "@tensorflow-jenkins test this please.", "```\r\nAssertionError: \"Type of feed value 1 with type <type 'int'> is not\" does not match \"Type of feed value 1 with type <class 'int'> is not compatible with Tensor type <class 'object'>.\r\n```\r\n\r\ni need to learn python 3 terms ... \r\n\r\n\r\n```\r\n//tensorflow/python/kernel_tests:slice_op_test                          TIMEOUT in 301.2s\r\n```\r\nsomeone is having a flaky test.. ", "@tensorflow-jenkins test this please.", "Jenkins, test this please.\r\n\r\nslice_op_test is broken. ", "weird error messages...\r\n\r\ni don't know what's broken or how can i even help ? ", "Looks like the tests here are all good. @sb2nov this is ready to merge.", "@tensorflow-jenkins test this please"]}, {"number": 14299, "title": "padded_batch fails on nested shapes", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Arch Linux, fully updated\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: v1.3.0-rc1-4086-g028809769d 1.4.0-rc1\r\n- **Python version**: 3.6.3\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**: gcc (GCC) 7.2.0\r\n- **CUDA/cuDNN version**: cuda 9.0.176-4 cuDNN 7.0.3-1\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nTrying to use tf.data.Dataset.padded_batch fails with type error for any nested shape\r\nsee [stack overflow question](https://stackoverflow.com/questions/47103249/how-to-use-tf-data-dataset-padded-batch-with-a-nested-shape)\r\n\r\n### Source code / logs\r\n```\r\nimport tensorflow as tf\r\ndef generator():\r\n    while 1:\r\n        yield [[[1]*3 for y in range(32)] for x in range(32)],[[[0]*cnum for y in range(1)]for x in range(1)]\r\ndataset = tf.data.Dataset.from_generator(generator,tf.float32)\r\nshapes = (tf.TensorShape([None,None,None,3]),tf.TensorShape([None,5]))\r\nbatch = dataset.padded_batch(1,shapes)\r\n```\r\nnote: I'm not sure if the additional None dimension representing batch should be added to the generator or not but this code does reproduce the error I'm having.\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1263, in _partial_shape_to_tensor\r\n    shape_like = tensor_shape.as_shape(shape_like)\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\", line 849, in as_shape\r\n    return TensorShape(shape)\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\", line 455, in __init__\r\n    self._dims = [as_dimension(d) for d in dims_iter]\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\", line 455, in <listcomp>\r\n    self._dims = [as_dimension(d) for d in dims_iter]\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\", line 397, in as_dimension\r\n    return Dimension(value)\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\", line 32, in __init__\r\n    self._value = int(value)\r\nTypeError: int() argument must be a string, a bytes-like object or a number, not 'TensorShape'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 710, in padded_batch\r\n    return PaddedBatchDataset(self, batch_size, padded_shapes, padding_values)\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1309, in __init__\r\n    input_dataset.output_shapes, _partial_shape_to_tensor, padded_shapes)\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/data/util/nest.py\", line 519, in map_structure_up_to\r\n    results = [func(*tensors) for tensors in zip(*all_flattened_up_to)]\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/data/util/nest.py\", line 519, in <listcomp>\r\n    results = [func(*tensors) for tensors in zip(*all_flattened_up_to)]\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1271, in _partial_shape_to_tensor\r\n    return ops.convert_to_tensor(shape_like, dtype=dtypes.int64)\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 887, in convert_to_tensor\r\n    as_ref=False)\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 977, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 233, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 212, in constant\r\n    value, dtype=dtype, shape=shape, verify_shape=verify_shape))\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\", line 399, in make_tensor_proto\r\n    _AssertCompatible(values, dtype)\r\n  File \"/usr/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\", line 314, in _AssertCompatible\r\n    (dtype.name, repr(mismatch), type(mismatch).__name__))\r\nTypeError: Expected int64, got TensorShape([Dimension(None), Dimension(None), Dimension(None), Dimension(3)]) of type 'TensorShape' instead.\r\n```\r\n", "comments": ["I think the problem is in this line:\r\n\r\n```python\r\ndataset = tf.data.Dataset.from_generator(generator,tf.float32)\r\n```\r\n\r\nTo match the signature of `generator()`, which returns a pair of objects, the `output_types` argument should be a pair of types, rather than a single type `tf.float32`. For example, changing that line as follows makes your code work for me:\r\n\r\n```python\r\ndataset = tf.data.Dataset.from_generator(generator, (tf.float32, tf.float32))\r\n```", "I can confirm that this does fix the problem.  It would be nice if we could somehow add information to the above exception as it does seem cryptic to newer users.  Not sure how that would be done though.  I'll close for now as the initial issue is resolved.  Thanks mrry for your help!"]}, {"number": 14298, "title": "Updating the bazel version in the install from sources page.", "body": "", "comments": []}, {"number": 14297, "title": "Fix batch dataset op test", "body": "", "comments": ["I changed my mind. I will disable the test in pip. We can choose to re-enable it, but ideally we would come up with a solution that uses bazel to include all the required deps. ", "Jenkins, test this please."]}]