[{"number": 49771, "title": "[CherryPick]:Prevent division by 0.", "body": "PiperOrigin-RevId: 370962554\nChange-Id: I0b9b62f4d8e1046dd88f9433f8dfeaf61a901680", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49771) for more info**.\n\n<!-- need_author_consent -->"]}, {"number": 49770, "title": "[CherryPick]:Prevent division by 0.", "body": "PiperOrigin-RevId: 370962554\nChange-Id: I0b9b62f4d8e1046dd88f9433f8dfeaf61a901680", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49770) for more info**.\n\n<!-- need_author_consent -->"]}, {"number": 49769, "title": "tensorflow lite x64 minimal build", "body": "i do all intruction that described in this link [https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/minimal](url)\r\n\r\ni success build tensorflow lite, but its win32\r\n\r\nhow to change to x64", "comments": ["@terryheo could you take a look?", "@budibeta \r\nIs this still an issue, could you please try on latest tf version and let us know.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49769\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49769\">No</a>\n"]}, {"number": 49768, "title": "Prevent division by 0.", "body": "PiperOrigin-RevId: 370962554\nChange-Id: I0b9b62f4d8e1046dd88f9433f8dfeaf61a901680", "comments": []}, {"number": 49767, "title": "BERT model not using GPU for training", "body": "I am following [this tutorial](https://www.tensorflow.org/text/tutorials/classify_text_with_bert) to use BERT for an NLP competition on Kaggle. \r\n\r\nI have created the model based on the tutorial but using the Kaggle data for training. But when I try to train with GPU enabled it still uses CPU only. I tried running my code and Colab with GPU enabled and there also the GPU is not being used, so it's not a Kaggle specific issue.\r\n\r\nSo far I have tried the small models [2/128](https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2) and [8/512](https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8) and both are using CPU only while the GPU sits on 0% utilization and 2MB memory use.\r\n\r\nThe TF version is 2.5.0 which gives this warning when importing the libraries:\r\n\r\n```\r\n/opt/conda/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.5.0 (nightly versions are not supported). \r\n The versions of TensorFlow you are currently using is 2.5.0 and is not supported. \r\nSome things might work, some things might not.\r\nIf you were to encounter a bug, do not file an issue.\r\nIf you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \r\nYou can find the compatibility matrix in TensorFlow Addon's readme:\r\nhttps://github.com/tensorflow/addons\r\n  UserWarning,\r\n```\r\nBut downgrading TF gives other errors that I am not able to resolve so I haven't tried running on older versions yet.\r\nAny help is appreciated, thanks in advance.", "comments": ["@kartik727 ,\r\n\r\nI am to able to execute the code in v2.5 with GPU enabled and haven't faced any issues.Please find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/f719fa27121c3aaf83210f38221e16ca/49767.ipynb).\r\n\r\nCould you please create a virtual environment and test your code again. It helps. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 49766, "title": "The finish project is crashing in the device.", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No , the finish project only.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Realme 7\r\n- TensorFlow installed from (source or binary): Used google colab\r\n- TensorFlow version (use command below): 2.5.0\r\n- Python version: 3.7.10 (Used google colab )\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: Colab free GPU\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nThe \"finish\" app given in \"Build a handwritten digit classifier app with TensorFlow Lite \" tutorial is crashing everytime in the device.\r\nI am facing the problem from trying to build the \"finish\" app from this :\r\nhttps://developer.android.com/codelabs/digit-classifier-tflite?authuser=1#2\r\n\r\nAnd then trying to build project from the folder below :\r\nlite/codelabs/digit_classifier/android/finish/\r\n\r\nAndroid Studio Version :\r\n4.2.1\r\n\r\n**Describe the expected behavior**\r\nThe app \"finish\" should recognize text digits.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you\r\nwant to contribute a PR? (yes/no): - Briefly describe your candidate solution\r\n(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n\r\n\r\nI am using the device realme RMX2151 ,it is built fine but while opening the app it is directly crashing. Can anyone suggest any fix to it or anyone found this issue earlier ??", "comments": ["@Rontu22 ,\r\n\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code and dataset to reproduce the issue reported here.\r\n\r\nAlso please take a look at this [issue](https://github.com/tensorflow/tensorflow/issues/38688) with similar error.It helps.\r\nThanks", "@tilakrayal  following is the error occured after building the app : \r\n\r\n2021-05-27 12:42:48.320 29720-29758/org.tensorflow.lite.codelabs.digitclassifier E/AndroidRuntime: FATAL EXCEPTION: pool-1-thread-1\r\n    Process: org.tensorflow.lite.codelabs.digitclassifier, PID: 29720\r\n    java.lang.IllegalArgumentException: Internal error: Cannot create interpreter: Didn't find op for builtin opcode 'CONV_2D' version '5'\r\n    \r\n    Registration failed.\r\n    \r\n        at org.tensorflow.lite.NativeInterpreterWrapper.createInterpreter(Native Method)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.init(NativeInterpreterWrapper.java:72)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:63)\r\n        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:237)\r\n        at org.tensorflow.lite.codelabs.digitclassifier.DigitClassifier.initializeInterpreter(DigitClassifier.kt:66)\r\n        at org.tensorflow.lite.codelabs.digitclassifier.DigitClassifier.access$initializeInterpreter(DigitClassifier.kt:31)\r\n        at org.tensorflow.lite.codelabs.digitclassifier.DigitClassifier$initialize$1.run(DigitClassifier.kt:48)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)\r\n        at java.lang.Thread.run(Thread.java:919)\r\n", "The logccat output is as follows : \r\n\r\n2021-05-27 12:42:47.915 29720-29720/? I/digitclassifie: Late-enabling -Xcheck:jni\r\n2021-05-27 12:42:47.948 29720-29720/? E/digitclassifie: Unknown bits set in runtime_flags: 0x8000\r\n2021-05-27 12:42:47.963 29720-29720/? E/RefClass: java.lang.reflect.InvocationTargetException\r\n2021-05-27 12:42:48.245 29720-29720/org.tensorflow.lite.codelabs.digitclassifier W/digitclassifie: Accessing hidden method Landroid/view/View;->computeFitSystemWindows(Landroid/graphics/Rect;Landroid/graphics/Rect;)Z (greylist, reflection, allowed)\r\n2021-05-27 12:42:48.246 29720-29720/org.tensorflow.lite.codelabs.digitclassifier W/digitclassifie: Accessing hidden method Landroid/view/ViewGroup;->makeOptionalFitsSystemWindows()V (greylist, reflection, allowed)\r\n2021-05-27 12:42:48.294 29720-29720/org.tensorflow.lite.codelabs.digitclassifier W/digitclassifie: Accessing hidden method Landroid/graphics/FontFamily;-><init>()V (greylist, reflection, allowed)\r\n2021-05-27 12:42:48.294 29720-29720/org.tensorflow.lite.codelabs.digitclassifier W/digitclassifie: Accessing hidden method Landroid/graphics/FontFamily;->addFontFromAssetManager(Landroid/content/res/AssetManager;Ljava/lang/String;IZIII[Landroid/graphics/fonts/FontVariationAxis;)Z (greylist, reflection, allowed)\r\n2021-05-27 12:42:48.294 29720-29720/org.tensorflow.lite.codelabs.digitclassifier W/digitclassifie: Accessing hidden method Landroid/graphics/FontFamily;->addFontFromBuffer(Ljava/nio/ByteBuffer;I[Landroid/graphics/fonts/FontVariationAxis;II)Z (greylist, reflection, allowed)\r\n2021-05-27 12:42:48.294 29720-29720/org.tensorflow.lite.codelabs.digitclassifier W/digitclassifie: Accessing hidden method Landroid/graphics/FontFamily;->freeze()Z (greylist, reflection, allowed)\r\n2021-05-27 12:42:48.294 29720-29720/org.tensorflow.lite.codelabs.digitclassifier W/digitclassifie: Accessing hidden method Landroid/graphics/FontFamily;->abortCreation()V (greylist, reflection, allowed)\r\n2021-05-27 12:42:48.294 29720-29720/org.tensorflow.lite.codelabs.digitclassifier W/digitclassifie: Accessing hidden method Landroid/graphics/Typeface;->createFromFamiliesWithDefault([Landroid/graphics/FontFamily;Ljava/lang/String;II)Landroid/graphics/Typeface; (greylist, reflection, allowed)\r\n2021-05-27 12:42:48.316 29720-29720/org.tensorflow.lite.codelabs.digitclassifier I/SurfaceFactory: [static] sSurfaceFactory = com.mediatek.view.impl.SurfaceFactoryImpl@6dd0dd3\r\n2021-05-27 12:42:48.320 29720-29758/org.tensorflow.lite.codelabs.digitclassifier E/AndroidRuntime: FATAL EXCEPTION: pool-1-thread-1\r\n    Process: org.tensorflow.lite.codelabs.digitclassifier, PID: 29720\r\n    java.lang.IllegalArgumentException: Internal error: Cannot create interpreter: Didn't find op for builtin opcode 'CONV_2D' version '5'\r\n    \r\n    Registration failed.\r\n    \r\n        at org.tensorflow.lite.NativeInterpreterWrapper.createInterpreter(Native Method)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.init(NativeInterpreterWrapper.java:72)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:63)\r\n        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:237)\r\n        at org.tensorflow.lite.codelabs.digitclassifier.DigitClassifier.initializeInterpreter(DigitClassifier.kt:66)\r\n        at org.tensorflow.lite.codelabs.digitclassifier.DigitClassifier.access$initializeInterpreter(DigitClassifier.kt:31)\r\n        at org.tensorflow.lite.codelabs.digitclassifier.DigitClassifier$initialize$1.run(DigitClassifier.kt:48)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)\r\n        at java.lang.Thread.run(Thread.java:919)\r\n2021-05-27 12:42:48.325 29720-29720/org.tensorflow.lite.codelabs.digitclassifier D/ColorViewRootUtil: initSwipState, isDisplayCompatApp false\r\n2021-05-27 12:42:48.325 29720-29720/org.tensorflow.lite.codelabs.digitclassifier D/ColorViewRootUtil: updateScreenSize, mScreenHeight 2400,mScreenWidth:1080,height:2400,width:1080\r\n2021-05-27 12:42:48.328 29720-29720/org.tensorflow.lite.codelabs.digitclassifier D/WindowManager: Add to mViews: DecorView@92843c5[MainActivity], this = android.view.WindowManagerGlobal@a29111a,pkg= org.tensorflow.lite.codelabs.digitclassifier\r\n2021-05-27 12:42:48.347 29720-29758/? I/Process: Sending signal. PID: 29720 SIG: 9\r\n", "I am facing the problem from trying to build the \"finish\" app from this : \r\n[https://developer.android.com/codelabs/digit-classifier-tflite?authuser=1#2](url)\r\n\r\nAnd then trying to build  project from the folder below : \r\nlite/codelabs/digit_classifier/android/finish/ \r\n\r\n\r\n\r\nAndroid Studio Version : \r\n4.2.1\r\n\r\n\r\n", "Fixing in https://github.com/tensorflow/examples/pull/322. This is because the default TF version in Colab has been upgraded to 2.5, so that TFLiteConverter create TFLite models that contain newer ops which isn't supported in the old TF 2.2 interpreter.\r\n\r\n@lintian06 Should we specify dynamic dependency (`implementation 'org.tensorflow:tensorflow-lite:2.+'`) in the final app?", "Thanks @khanhlvg! \"2.+\" sounds a good idea.", "Thanks a lot for all of your kind support.\r\n", "After applying (implementation 'org.tensorflow:tensorflow-lite:2.+') in the final app , I am getting the following error message . Please some one help me out.\r\n\r\n\r\n2021-06-02 22:46:43.774 17776-17776/? I/digitclassifie: Late-enabling -Xcheck:jni\r\n2021-06-02 22:46:43.796 17776-17776/? E/digitclassifie: Unknown bits set in runtime_flags: 0x8000\r\n2021-06-02 22:46:43.806 17776-17776/? E/RefClass: java.lang.reflect.InvocationTargetException\r\n2021-06-02 22:46:44.043 17776-17776/? W/digitclassifie: Accessing hidden method Landroid/view/View;->computeFitSystemWindows(Landroid/graphics/Rect;Landroid/graphics/Rect;)Z (greylist, reflection, allowed)\r\n2021-06-02 22:46:44.044 17776-17776/? W/digitclassifie: Accessing hidden method Landroid/view/ViewGroup;->makeOptionalFitsSystemWindows()V (greylist, reflection, allowed)\r\n2021-06-02 22:46:44.076 17776-17776/? W/digitclassifie: Accessing hidden method Landroid/graphics/FontFamily;-><init>()V (greylist, reflection, allowed)\r\n2021-06-02 22:46:44.076 17776-17776/? W/digitclassifie: Accessing hidden method Landroid/graphics/FontFamily;->addFontFromAssetManager(Landroid/content/res/AssetManager;Ljava/lang/String;IZIII[Landroid/graphics/fonts/FontVariationAxis;)Z (greylist, reflection, allowed)\r\n2021-06-02 22:46:44.076 17776-17776/? W/digitclassifie: Accessing hidden method Landroid/graphics/FontFamily;->addFontFromBuffer(Ljava/nio/ByteBuffer;I[Landroid/graphics/fonts/FontVariationAxis;II)Z (greylist, reflection, allowed)\r\n2021-06-02 22:46:44.076 17776-17776/? W/digitclassifie: Accessing hidden method Landroid/graphics/FontFamily;->freeze()Z (greylist, reflection, allowed)\r\n2021-06-02 22:46:44.076 17776-17776/? W/digitclassifie: Accessing hidden method Landroid/graphics/FontFamily;->abortCreation()V (greylist, reflection, allowed)\r\n2021-06-02 22:46:44.076 17776-17776/? W/digitclassifie: Accessing hidden method Landroid/graphics/Typeface;->createFromFamiliesWithDefault([Landroid/graphics/FontFamily;Ljava/lang/String;II)Landroid/graphics/Typeface; (greylist, reflection, allowed)\r\n2021-06-02 22:46:44.089 17776-17811/? I/tflite: Initialized TensorFlow Lite runtime.\r\n2021-06-02 22:46:44.090 17776-17811/? I/tflite: Created TensorFlow Lite delegate for NNAPI.\r\n2021-06-02 22:46:44.092 17776-17811/? E/AndroidRuntime: FATAL EXCEPTION: pool-1-thread-1\r\n    Process: org.tensorflow.lite.codelabs.digitclassifier, PID: 17776\r\n    java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.applyDelegate(Native Method)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.applyDelegates(NativeInterpreterWrapper.java:492)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.init(NativeInterpreterWrapper.java:88)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:66)\r\n        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:287)\r\n        at org.tensorflow.lite.codelabs.digitclassifier.DigitClassifier.initializeInterpreter(DigitClassifier.kt:66)\r\n        at org.tensorflow.lite.codelabs.digitclassifier.DigitClassifier.access$initializeInterpreter(DigitClassifier.kt:31)\r\n        at org.tensorflow.lite.codelabs.digitclassifier.DigitClassifier$initialize$1.run(DigitClassifier.kt:48)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)\r\n        at java.lang.Thread.run(Thread.java:919)\r\n2021-06-02 22:46:44.097 17776-17776/? I/SurfaceFactory: [static] sSurfaceFactory = com.mediatek.view.impl.SurfaceFactoryImpl@9a0d8f5\r\n2021-06-02 22:46:44.103 17776-17776/? D/ColorViewRootUtil: initSwipState, isDisplayCompatApp false\r\n2021-06-02 22:46:44.104 17776-17776/? D/ColorViewRootUtil: updateScreenSize, mScreenHeight 2400,mScreenWidth:1080,height:2400,width:1080\r\n2021-06-02 22:46:44.107 17776-17776/? D/WindowManager: Add to mViews: DecorView@1730f71[MainActivity], this = android.view.WindowManagerGlobal@f183156,pkg= org.tensorflow.lite.codelabs.digitclassifier\r\n2021-06-02 22:46:44.113 17776-17811/? I/Process: Sending signal. PID: 17776 SIG: 9", "Sorry for the issue - it looks like the TFLite model converted with TF 2.5 isn't compatible with NNAPI. I submitted a temporary fix https://github.com/tensorflow/examples/commit/f8ea518e0efdbf5d7c75b314133b29e8e0212e70 to avoid using NNAPI while we look further into the issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49766\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49766\">No</a>\n"]}, {"number": 49765, "title": "Prevent infinite loop/stack overflow in TFLite `while` op.", "body": "PiperOrigin-RevId: 370800333\nChange-Id: I6a2e4ff849da339545c449db2af7e11ce6ff02c3", "comments": []}, {"number": 49764, "title": "Prevent infinite loop/stack overflow in TFLite `while` op.", "body": "PiperOrigin-RevId: 370800333\nChange-Id: I6a2e4ff849da339545c449db2af7e11ce6ff02c3", "comments": []}, {"number": 49763, "title": "Prevent infinite loop/stack overflow in TFLite `while` op.", "body": "PiperOrigin-RevId: 370800333\nChange-Id: I6a2e4ff849da339545c449db2af7e11ce6ff02c3", "comments": []}, {"number": 49762, "title": "Prevent infinite loop/stack overflow in TFLite `while` op.", "body": "PiperOrigin-RevId: 370800333\nChange-Id: I6a2e4ff849da339545c449db2af7e11ce6ff02c3", "comments": []}, {"number": 49761, "title": "Keras spectral normalization (SN) function has stopped working", "body": "Something must have happened to Keras overnight because suddenly two Keras features have stopped working. I already reported the ```from keras.utils import plot_model```  bug. Now there's another. ```spectral_normalization.py``` is a function that takes a keras layer as input and implements the SN regularization algorithm. Since this morning it throws an ```AssertionError```.\r\n```\r\n> /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/wrappers.py(50)__init__()\r\n     48 \r\n     49   def __init__(self, layer, **kwargs):\r\n---> 50     assert isinstance(layer, Layer)\r\n     51     self.layer = layer\r\n     52     super(Wrapper, self).__init__(**kwargs)\r\n```\r\nOf course, I can just not use spectral normalization, but it makes a HUGE difference in model stability. Thanks.", "comments": ["@arsinnius \r\n\r\nWe see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced]\r\n\r\nThanks", "UsharaniPagadala, I apologize for not following the template but I'm new at this.\r\n\r\n**System information**\r\nI'm running the program ```spectral_normalization``` copyrighted in 2020 by the Tensorflow team on google colab using a GPU. \r\nThe Tensorflow version is ```v2.5.0-0-ga4dfb8d1a71 2.5.0```. \r\nThe python version is 3.7.10\r\n\r\n**Current Behavior**\r\n```spectral_normalization``` is a wrapper for ```tf.keras.layers``` but it is not recognizing Keras layers. It throws the ```AssertionError``` shown above. \r\n\r\n**Standalone Code to Reproduce the Issue**\r\nAn MWE is\r\n```\r\nfrom keras.layers import Conv2D, Layer\r\nlayer = Conv2D\r\nif not isinstance(layer, Layer):\r\n    raise ValueError(\r\n        'Please initialize `TimeDistributed` layer with a '\r\n        '`Layer` instance. You passed: {input}'.format(input=layer))\r\n```\r\nThe above code causes multiple errors but the first is the ```ValueError```\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-7-4e881acf7107>\", line 6, in <module>\r\n    '`Layer` instance. You passed: {input}'.format(input=layer))\r\nValueError: Please initialize `TimeDistributed` layer with a `Layer` instance. You passed: <class 'keras.layers.convolutional.Conv2D'>\r\n```\r\nThanks again.\r\n\r\n ", "You last gist is not a valid test as `Conv2D` is not an instance is a class.\r\n```python\r\nfrom keras.layers import Conv2D, Layer\r\nimport inspect \r\nlayer_b = Conv2D\r\nprint(inspect.isclass(layer_b))\r\nprint(layer_b.__name__)\r\n```\r\n\r\n```\r\nTrue\r\nConv2D\r\n````\r\n\r\n Can you clearly share just a few line example to reproduce the bug?", "Thank you, bhack. \r\n\r\nBased on your request, I got a copy of ```spectral_normalization``` from\r\n```\r\nhttps://github.com/tensorflow/addons/blob/v0.13.0/tensorflow_addons/layers/spectral_normalization.py#L21-L130\r\n```\r\nput it in my directory and ran the following code:\r\n```\r\nfrom keras.layers import Conv2D, Input\r\nfrom spectral_normalization import SpectralNormalization\r\n\r\ndef foo_model( k_size, latent_dim, pwr_iter):\r\n  z = Input(shape=(latent_dim,))\r\n  x = SpectralNormalization(Conv2D(2**7, \r\n                                    kernel_size=(2, k_size), padding='same',   \r\n                                    ), power_iterations=pwr_iter)(z)\r\n  return Model(z, x)\r\n  \r\nf_model = foo_model(5, 128, 1)\r\n```\r\nThree frames down, it gave the following error:\r\n```\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/wrappers.py in __init__(self, layer, **kwargs)\r\n     48 \r\n     49   def __init__(self, layer, **kwargs):\r\n---> 50     assert isinstance(layer, Layer)\r\n     51     self.layer = layer\r\n     52     super(Wrapper, self).__init__(**kwargs)\r\n\r\nAssertionError: \r\n```\r\nMy conclusion is that it's not recognizing a valid Keras layer. I hope this is okay and thanks again\r\n", "I cannot run your code:\r\n```python\r\nfrom tensorflow.keras.layers import Conv2D, Input\r\nfrom tensorflow_addons.layers import SpectralNormalization\r\n\r\ndef foo_model( k_size, latent_dim, pwr_iter):\r\n  z = Input(shape=(latent_dim,))\r\n  x = SpectralNormalization(Conv2D(2**7, \r\n                                    kernel_size=(2, k_size), padding='same',   \r\n                                    ), power_iterations=pwr_iter)(z)\r\n  return Model(z, x)\r\n  \r\nf_model = foo_model(5, 128, 1)\r\n```\r\n\r\n``` \r\nValueError: Input 0 of layer conv2d_2 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 128)\r\n```\r\n\r\nCan you share a valid example to reproduce your issue?", "Hello bhack,\r\n\r\nThanks for your help. You didn't run my code. You ran the tensorflow version. My code is Keras-based. When I run the tensorflow version, I get the same error you did. When I run the Keras version, I get the ```AssertionError```. If you run the code exactly as I wrote it, you will reproduce the ```AssertionError```. \r\n\r\nMore broadly, I wonder if the fact that the two versions produce different errors is telling us something about the underlying issue. Thanks again.", "The old Keras is not support anymore. You need to use `tf.keras` in general and also for tensorflow addons compatibility.", "bhack, when I converted the Keras code to tensorflow, the error disappeared. That also explains why it happened so suddenly. Thank you for all your help.", "bhack, when I converted the Keras code to tensorflow, the error disappeared. That also explains why it happened so suddenly. Thank you for all your help.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49761\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49761\">No</a>\n"]}, {"number": 49760, "title": "Revert \"Revert \"[CherryPick]: Prevent a null pointer exception in TFLite\"\"", "body": "Reverts tensorflow/tensorflow#49759", "comments": []}, {"number": 49759, "title": "Revert \"[CherryPick]: Prevent a null pointer exception in TFLite\"", "body": "Reverts tensorflow/tensorflow#49752", "comments": []}, {"number": 49758, "title": "Prevent a null pointer dereference in TFLite.", "body": "PiperOrigin-RevId: 370800353\nChange-Id: Ic9c9712ce5c6e384c954dcd640a5bd9ff05c9a05", "comments": []}, {"number": 49757, "title": "Prevent a null pointer dereference in TFLite.", "body": "PiperOrigin-RevId: 370800353\nChange-Id: Ic9c9712ce5c6e384c954dcd640a5bd9ff05c9a05", "comments": []}, {"number": 49756, "title": "Prevent a null pointer dereference in TFLite.", "body": "PiperOrigin-RevId: 370800353\nChange-Id: Ic9c9712ce5c6e384c954dcd640a5bd9ff05c9a05", "comments": []}, {"number": 49755, "title": "Prevent a null pointer dereference in TFLite.", "body": "PiperOrigin-RevId: 370800353\nChange-Id: Ic9c9712ce5c6e384c954dcd640a5bd9ff05c9a05", "comments": []}, {"number": 49754, "title": "Cloning a model with the \"Add\" layer - Custom mask layers require a config and must override get_config", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04.5 TLS (Google Colab)\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.5.0\r\n\r\n**Description**\r\n\r\nIf the model with the \"Add\" layer is a part of another model, then when I try to clone it, the following warning appears:\r\n\r\n```\r\nCustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\r\n```\r\n\r\nThis warning appeared only in version 2.5.0\r\n\r\n**Code**\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Input, Add\r\nfrom tensorflow.keras.models import Model\r\n\r\ninput1 = Input(1)\r\ninput2 = Input(1)\r\nx = Add()([input1, input2])\r\nmodel_a = Model([input1, input2], x)\r\n\r\ninput3 = Input(1)\r\ninput4 = Input(1)\r\nx = model_a([input3, input4])\r\nmodel_b = Model([input3, input4], x)\r\n\r\nmodel_b_clone = tf.keras.models.clone_model(model_b)\r\n```\r\n\r\n**Output**\r\n\r\n```\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\r\n  category=CustomMaskWarning)\r\n```\r\n\r\n\r\n", "comments": ["I was able to reproduce the issue in TF v2.5 and nightly.Executed in v2.4 without error.Please find of gist [here](https://colab.research.google.com/gist/tilakrayal/36ba13908e4e968e7da4e61df2dc2569/49754.ipynb).", "@rustequal \r\nPlease update as per above comment, we do not face any error in tf 2.4 which is stable version of tf.", "> @rustequal\r\n> Please update as per above comment, we do not face any error in tf 2.4 which is stable version of tf.\r\n\r\nyes, I confirm it. Since TF 2.5.0 is installed in Google Colab by default, I have to roll back to version 2.4.1. Hopefully this bug will be fixed in TF 2.5. I indicated this in the description of the problem, that this warning appears only in TF 2.5.0", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "It's not just cloning. Also saving a model with an Add layer triggers this warning. Example adapted from above:\r\n\r\n```python\r\nfrom tensorflow.keras.layers import Input, Add\r\nfrom tensorflow.keras.models import Model\r\n\r\ninput1 = Input(1)\r\ninput2 = Input(1)\r\nx = Add()([input1, input2])\r\nmodel_a = Model([input1, input2], x)\r\nmodel_a.save('model_a')\r\n```", "@rustequal Agree with you that it was an issue with old versions. \r\n\r\nThis was resolved in recent `tf-nightly`.[Here](https://colab.research.google.com/gist/jvishnuvardhan/a8ca3bd6772f390b855cf765b4df7eaa/untitled.ipynb) is a gist for reference. If you want stable version, then it will be available in the upcoming `TF2.8` in near future. Thanks!\r\n\r\nI am closing this issue as this was resolved. Please feel free to reopen if the issue persists again. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49754\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49754\">No</a>\n"]}, {"number": 49753, "title": "[CherryPick]: Prevent a null pointer exception in TFLite", "body": null, "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49753) for more info**.\n\n<!-- need_author_consent -->", "All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49753) for more info**.\n\n<!-- need_author_consent -->", "All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49753) for more info**.\n\n<!-- need_author_consent -->", "All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49753) for more info**.\n\n<!-- need_author_consent -->"]}, {"number": 49752, "title": "[CherryPick]: Prevent a null pointer exception in TFLite", "body": null, "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49752) for more info**.\n\n<!-- need_author_consent -->", "All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49752) for more info**.\n\n<!-- need_author_consent -->"]}, {"number": 49751, "title": "micro:BATCH_MATMUL PR3-5", "body": "micro: port operator BATCH_MATMUL kernel from lite with test\r\n\r\nComplete implementation of TFLM operator BATCH_MATMUL and associated TFLM test code.\r\n\r\nPR step 5 of the work to port operator BATCH_MATMUL as tracked in Issue #46504", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "With TFLM moving to its own GitHub repository, we are not going to be merging any TFLM specific pull requests in the TensorFlow repository starting today.\r\n\r\nI am closing the current PR but please feel free to open a new PR in https://github.com/tensorflow/tflite-micro/.\r\n\r\nhttps://groups.google.com/a/tensorflow.org/g/micro/c/W4DACgjPmOE\r\n"]}, {"number": 49750, "title": "Prevent a null pointer exception in TFLite", "body": "PiperOrigin-RevId: 370800206\nChange-Id: Idd437ebce4ff224120d8eefc1c14c062173b71d6", "comments": []}, {"number": 49749, "title": "Prevent a null pointer exception in TFLite", "body": "PiperOrigin-RevId: 370800206\nChange-Id: Idd437ebce4ff224120d8eefc1c14c062173b71d6", "comments": []}, {"number": 49748, "title": "Fix another division by 0 in TFLite", "body": "PiperOrigin-RevId: 370800181\nChange-Id: I924809166a6131f5075e6d45c455106538d755f9", "comments": []}, {"number": 49747, "title": "Fix another division by 0 in TFLite", "body": "PiperOrigin-RevId: 370800181\nChange-Id: I924809166a6131f5075e6d45c455106538d755f9", "comments": []}, {"number": 49746, "title": "Fix another division by 0 in TFLite", "body": "PiperOrigin-RevId: 370800181\nChange-Id: I924809166a6131f5075e6d45c455106538d755f9", "comments": []}, {"number": 49745, "title": "Fix another division by 0 in TFLite", "body": "PiperOrigin-RevId: 370800181\nChange-Id: I924809166a6131f5075e6d45c455106538d755f9", "comments": []}, {"number": 49744, "title": "Handle one more division by 0 in TFLite.", "body": "PiperOrigin-RevId: 370800140\nChange-Id: I9ab42e5aaccf02f226d1282611490a54cf7d273e", "comments": []}, {"number": 49743, "title": "Handle one more division by 0 in TFLite.", "body": "PiperOrigin-RevId: 370800140\nChange-Id: I9ab42e5aaccf02f226d1282611490a54cf7d273e", "comments": []}, {"number": 49742, "title": "Handle one more division by 0 in TFLite.", "body": "PiperOrigin-RevId: 370800140\nChange-Id: I9ab42e5aaccf02f226d1282611490a54cf7d273e", "comments": []}]