[{"number": 4461, "title": "Tutorials documentation spelling mistake", "body": "At url: https://www.tensorflow.org/versions/r0.10/tutorials/image_recognition/index.html\n\nI've found that In following paragraph '299 pixel **high**' is written, which I think should be '299 pixel **hight**'\n\nThe whole paragraph is following in 'Usage with the C++ API' section:\n\n\"This gives us a vector of Tensor objects, which in this case we know will only be a single object long. You can think of a Tensor as a multi-dimensional array in this context, and it holds a 299 pixel **high**, 299 pixel width, 3 channel image as float values. If you have your own image-processing framework in your product already, you should be able to use that instead, as long as you apply the same transformations before you feed images into the main graph.\"\n", "comments": ["Thanks. I guess you mean height but feel free to send over a PR for this.\n", "I've applied for Google CLA, after approving I'll make PR for this. thanks.\n"]}, {"number": 4460, "title": "Fix farmhash build on Windows", "body": "I tried to add windows `config_setting` in `tensorflow/BUILD`, but it's not accessible from external library, so I had to add into every relevant BUILD file. @mrry @damienmg @dslomov\n", "comments": ["@meteorcloudy, thanks for your PR! By analyzing the annotation information on this pull request, we identified @keveman and @ysuematsu to be potential reviewers\n", "Can one of the admins verify this patch?\n", "I've already removed it in the last commit. \ud83d\ude01\n", "@meteorcloudy Thanks! Didn't see it in the review view :).\n", "@tensorflow-jenkins test this please.\n", "Can we test this again please?\n", "@tensorflow-jenkins test this please.\n", "Mind resolving the new conflicts? That flaky test should be fixed now.\n", "Conflicts resolved!  jpeg, png are already buildable after rebase, only need to fix farmhash. Please test again!\n", "Jenkins, test this please\n", "Can you merge the latest master into your pull request? We have commits there that fix the jenkins test.\n", "Hmm, nevermind, weird, your change is already up-to-date. Let's try this again:\n\nJenkins, test this please\n"]}, {"number": 4459, "title": "(#4380) TensorFlow master build failing: error: invalid initialization of reference  ", "body": "Created a new issue as I cannot re-open #4380 .\n\n@poxvoculi @girving Do you have any idea on #4380 ?\n", "comments": ["This is a question better suited for StackOverflow. Please ask it there and tag it with the `tensorflow` tag.\n"]}, {"number": 4458, "title": "bazel build tensorflow/python/tools:strip_unused throws linker error", "body": "I am trying to solve the problem of running a retrained model on iOS described in issue [2883](https://github.com/tensorflow/tensorflow/issues/2883). However when I call this command I run into linker error:\n\n> bazel build tensorflow/python/tools:strip_unused\n\nThe linker error says:\n\n> bazel-out/local-fastbuild/bin/tensorflow/core/libversion_lib.a(version_info.pic.o): In function `tf_git_version()':\n> version_info.cc:(.text+0x0): multiple definition of`tf_git_version()'\n> bazel-out/local-fastbuild/bin/tensorflow/core/libframework_internal.lo(version_info.pic.o):version_info.cc:(.text+0x0): first defined here\n> bazel-out/local-fastbuild/bin/tensorflow/core/libversion_lib.a(version_info.pic.o): In function `tf_compiler_version()':\n> version_info.cc:(.text+0xd): multiple definition of`tf_compiler_version()'\n> bazel-out/local-fastbuild/bin/tensorflow/core/libframework_internal.lo(version_info.pic.o):version_info.cc:(.text+0xd): first defined here\n> collect2: error: ld returned 1 exit status\n> Target //tensorflow/python/tools:strip_unused failed to build\n\nI tried it on both Mac and Ubuntu Linux with the same error. I am operating on git commit a6c5f8e. Can someone help me how to build this tool?\n", "comments": ["I tried building with an earlier build and it worked. I chose commit 5b265ff. So I suppose in between those commits something was broken.\n", "@jart Could you take a look at this? Thanks.\n", "Later commits 8fdb974 and its successor 5563229 do build properly (caveat: the `giflib` link seems broken). The master I have used on this \"dichotomy\" breaks (f6e0f64f).\n\nI picked 8fdb974 for testing due to modification related to the duplicate symbols in the next commit (5563229). Unfortunately this did not pin-point the issue.\n\nIt seems the problem is \"indirect\". Perhaps some wildcard somewhere includes twice the same file (there was a similar issue in the `Makefile` in `tensorflow/contrib/makefile`), or an issue with how the `extern` declaration is used by the build system (e.g. in `tensorflow/core/public/version.h`). Just a guess. Hope this serves.\n", "I tried to reproduce this error. I compiled Bazel from HEAD. I fetched TensorFlow at HEAD. I ran `./configure` and `bazel build tensorflow/python/tools:strip_unused` and I ended up with this:\n\n```\nINFO: From ProtoCompile tensorflow/python/training/checkpoint_state_pb2.py:\nexternal/protobuf/python: warning: directory does not exist.\nINFO: From ProtoCompile tensorflow/contrib/session_bundle/manifest_pb2.py:\nexternal/protobuf/python: warning: directory does not exist.\nINFO: From ProtoCompile tensorflow/contrib/tensorboard/plugins/projector/projector_config_pb2.py:\nexternal/protobuf/python: warning: directory does not exist.\nERROR: /usr/local/google/home/jart/code/tensorflow-clean/tensorflow/contrib/tfprof/tools/tfprof/BUILD:42:1: null failed: linux-sandbox failed: error executing command \n  (cd /usr/local/google/home/jart/.cache/bazel/_bazel_jart/534cc9069a4bd39f8bace6b1039c6506/bazel-sandbox/978fc997-2a45-4494-836a-df35eb0b4705-842/execroot/tensorflow-clean && \\\n  exec env - \\\n  /usr/local/google/home/jart/.cache/bazel/_bazel_jart/534cc9069a4bd39f8bace6b1039c6506/execroot/tensorflow-clean/_bin/linux-sandbox @/usr/local/google/home/jart/.cache/bazel/_bazel_jart/534cc9069a4bd39f8bace6b1039c6506/bazel-sandbox/978fc997-2a45-4494-836a-df35eb0b4705-842/linux-sandbox.params -- bazel-out/host/bin/external/protobuf/protoc '--python_out=bazel-out/local-fastbuild/genfiles/' -I. -Iexternal/protobuf/python -Ibazel-out/local-fastbuild/genfiles/external/protobuf/python tensorflow/contrib/tfprof/tools/tfprof/tfprof_log.proto tensorflow/contrib/tfprof/tools/tfprof/tfprof_output.proto).\nexternal/protobuf/python: warning: directory does not exist.\ntensorflow/core/framework/tensor_shape.proto: File not found.\ntensorflow/core/framework/types.proto: File not found.\ntensorflow/contrib/tfprof/tools/tfprof/tfprof_output.proto: Import \"tensorflow/core/framework/tensor_shape.proto\" was not found or had errors.\ntensorflow/contrib/tfprof/tools/tfprof/tfprof_output.proto: Import \"tensorflow/core/framework/types.proto\" was not found or had errors.\ntensorflow/contrib/tfprof/tools/tfprof/tfprof_output.proto:9:12: \"DataType\" is not defined.\ntensorflow/contrib/tfprof/tools/tfprof/tfprof_output.proto:45:12: \"TensorShapeProto\" is not defined.\nTarget //tensorflow/python/tools:strip_unused failed to build\nINFO: Elapsed time: 53.186s, Critical Path: 40.69s\n```\n\nI'm putting it here for anyone who might search this error. I'm still  investigating a solution.\n", "I turned off Bazel sandboxing and `//tensorflow/python/tools:strip_unused` builds, so I'm unable to reproduce this error. Try updating to HEAD, updating Bazel, and then running ./configure again. It should work. I'm not sure what happened before. But I can tell you that we're planning on doing significant cleanup to the way we generate that version_info.cc file.\n", "Would `configure` checking for the exact required Bazel version help too?\n", "Good idea @ic. It's something we definitely need. So I filed #4975.\n"]}, {"number": 4457, "title": "Improved iOS camera example and binary footprint optimizations", "body": "This PR has a variety of cleanup changes and fixes to help demonstrate advanced features of iOS development like memory mapping and loading retrained models. It also includes some related changes that help shrink the binary footprint of the final executable on iOS.\n", "comments": ["@petewarden, thanks for your PR! By analyzing the annotation information on this pull request, we identified @martinwicke, @tensorflower-gardener and @vrv to be potential reviewers\n", "@cwhipkey this PR isn't urgent, but I was wondering if you could review it?\n", "Jenkins, test this please.\n"]}, {"number": 4456, "title": "when will beam search be implemented", "body": "The current version of tensorflow still use a greedy algorithm for seq2seq decoder. I wonder when will beam search be implemented in future versions since this has already been discussed in other issues.\n", "comments": ["https://github.com/tensorflow/tensorflow/issues/654 could that one be pulled? It is not marked as \"contributions welcome\" so I don't know if Google has any ambitions to merge this feature with the main branch.\n", "Actually #654 is marked as \"contributions welcome\".  Let's consolidate discussion on that issue, so there's one place to look.\n"]}, {"number": 4455, "title": "Distributed TF managed session: inter_op_parallelism_threads and intra_op_parallelism_threads has no effect", "body": "We are using:\n\n``` .python\nwith sv.managed_session(\n  server.target,\n  config=tf.ConfigProto(log_device_placement=True,\n                        inter_op_parallelism_threads=1,\n                        intra_op_parallelism_threads=1),\n) as sess:\n```\n\nbut TensorFlow still launches a number of threads proportional to the number of cores on each process. I counted +50 threads used by each process on my 24 vcore machine.\n\nWhat can we do to limit the number of threads in a managed session.\n\nEDIT: @yaroslavvb identified the problem. See the end of the thread about Session vs Server options.\n", "comments": ["Do you have it set by some previous sessions in the same process?\n  // Note that the first Session created in the process sets the\n  // number of threads for all future sessions unless use_per_session_threads is\n  // true or session_inter_op_thread_pool is configured.\n", "There are two places to configure remote session with tf.ConfigProto\n1. when you create a session with remote master: tf.Session(\"grpc://\",\nconfig=...)\n2. when you launch remote master: tf.train.Server(config=...)\n\nDocs says that tf.train.Server(config=...) specifies \"specifies default\noptions for all sessions that run on this server.\"\nDoes this mean that tf.Session(\"grpc://\", config=config) settings are\nignored?\n\nOn Tue, Sep 20, 2016 at 11:56 AM, Jianmin Chen notifications@github.com\nwrote:\n\n> Do you have it set by some previous sessions in the same process?\n> // Note that the first Session created in the process sets the\n> // number of threads for all future sessions unless\n> use_per_session_threads is\n> // true or session_inter_op_thread_pool is configured.\n> \n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/4455#issuecomment-248398213,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AABaHN1nBabzUG7dDxPDuNBF92L6rW4iks5qsCx1gaJpZM4KAXtD\n> .\n", "@jmchen-g this is the only session in our program.\n", "Anything new on this? We're completely trashing our AWS instances right now with load averages in the 3 digit range for TF distributed running on 16 docker processes on the same machine. Being able to limit the number of computational threads seems to be essential for us. \n", "Have you tried using config option in Server?\n\nOn Sep 28, 2016 3:01 AM, \"Henrik Holst\" notifications@github.com wrote:\n\n> Anything new on this? We're completely trashing our AWS instances right\n> now with load averages in the 3 digit range for TF distributed running on\n> 16 docker processes on the same machine. Being able to limit the number of\n> computational threads seems to be essential for us.\n> \n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/4455#issuecomment-250124942,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AABaHEY81iJrN20KLam7oD-5HeQtMkYyks5qujsIgaJpZM4KAXtD\n> .\n", "@yaroslavvb This is why they pay you the big bucks (hopefully) ;-) Thank you for solving the problem- now we're down to 6 threads per worker which should be manageable for a modern CPU. \n", "@hholst80 no problem. It's a bit confusing to me too, you can pass it in either tf.Session(config=) or tf.train.Server(config=), and some options (inter_op_parallelism_threads) seem to be silently ignored in the first method, while others (log_device_placement) are respected. We had a similar problem of too much CPU usage because of this\n\n@mrry any advice as to whether we should ever use tf.Session(config=) option when session connects to distributed master?\n", "There are several options that are relevant to individual sessions, and should be passed in the session constructor if you want to set them.\n\nFrom a quick look at [`master_session.cc`](https://github.com/tensorflow/tensorflow/blob/0db279f16ce21568c414694ea55e2dec07ad6972/tensorflow/core/distributed_runtime/master_session.cc) it appears that the only `ConfigProto` options respected in the distributed master are those under `ConfigProto.graph_options`. The `SimplerPlacer` uses `log_device_placement` and `allow_soft_placement` as well. `device_filters` is also used when constructing the session, and determines what servers the session can contact.\n\nSince the `tf.train.Server` owns its set of devices and shares them between sessions on that server, any options relevant to creating devices (or configuring e.g. their thread pools) should be passed when constructing the server instead.\n", "Closing as this  appears to be resolved. Thanks @yaroslavvb and @mrry.\n"]}, {"number": 4454, "title": "Make grpc buildable on Windows", "body": "grpc++_unsecure needs zlib to build, adding @zlib_archive as a dependency\n\nWith this patch `@grpc//:grpc_cpp_plugin` and `@grpc//:grpc++_unsecure` is buildable on Windows\n@mrry @damienmg @dslomov\n", "comments": ["Can one of the admins verify this patch?\n", "@meteorcloudy, thanks for your PR! By analyzing the annotation information on this pull request, we identified @mrry and @kirilg to be potential reviewers\n", "@meteorcloudy Is there a corresponding issue against https://github.com/grpc/grpc for adding this? We'd like to keep the diff between our forked/fixed build file and the standard one small, so that we can switch back to using it instead.\n", "@tensorflow-jenkins test this please.\n", "Don't we have gRPC on Bazel too? Having just to vendor gRPC would be preferable for Bazel also.\n", "@damienmg Yes, but there are two open issues on the Bazel support that prevent us from using it directly: https://github.com/grpc/grpc/issues/7707 and https://github.com/grpc/grpc/issues/7851.\n", "@mrry I see.  I can send a PR to grpc to add `//external:zlib` as a dependency of `grpc++_unsecure` which [they already did for `grpc` target](https://github.com/grpc/grpc/commit/f2f24e2f93bba8ae939beb53980ac8e042c372c0). Then we bind `@zlib_archive//:zlib` as `zlib` in `workspace.bzl`. This should make us easier to switch back later.\n", "@tensorflow-jenkins test this please.\n"]}, {"number": 4453, "title": "Remove state_ops.variable_op()?", "body": "I'm reading the source code, and I find there is a comment saying that \n`# TODO(mrry): Move this to where it is used, so we can get rid of this op wrapper?`\nin the [state_ops.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/state_ops.py#L151)\n\nSo, I searched and found that only `variables.py` calls it twice times [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/variables.py#L305), and [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/variables.py#L322).\n\nBTW, some `xx_test.py` also call it, but I think it's easy to change. \nIn a word, could I handle the issue and update all the files?@mrry \n\nI output the file list which call the `variable_op()`:\n\n```\nVariables.py\nVariables_test.py\nVariable_ops_test.py\nTensor_util_test.py\nMoving_averages_test.py\nLearning_rate_decay_test.py\nGraph_util_test.py\nControl_flow_ops_py_test.py\n```\n", "comments": ["I think the problem with this particular function is that it's used at various places in the internal Google codebase, which makes it difficult to remove in the open-source version.\n\n@drpngx is currently working on tightening our Python API, so I'll assign this issue to him.\n", "Thanks for volunteering!\nYes, there is some internal usage. I don't think it's too bad but it will require manual work. Give me a few days to assess the damage.\n", "@drpngx Sounds good~ \n", "Sorry for the delay. I have verified that it's possible to do these changes internally, but some might be higher risk. Feel free to remove use to that interface within the code, but leave out the definition.\n", "@drpngx Ok, I'm on it.\n", "Fixed, close.\n"]}, {"number": 4452, "title": "contrib/quantization: Open file in binary mode", "body": "This fixes the following error:\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 53: invalid start byte\n", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->\n", "@olesalscheider, thanks for your PR! By analyzing the annotation information on this pull request, we identified @petewarden, @tensorflower-gardener and @ilya-edrenkin to be potential reviewers\n", "Can one of the admins verify this patch?\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "Jenkins, test this please.\n"]}, {"number": 4451, "title": "TensorFlow demo app crashes with my own model", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\n\nhttps://github.com/tensorflow/tensorflow/issues/1269\n### Environment info\n\nOperating System: Linux ubuntu\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`) \n   ce3572a08b9ecfa5c8dd94921c2011f37b58e608\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\n1. Followin this tutorial: https://www.tensorflow.org/versions/r0.9/how_tos/image_retraining/index.html\n   I built a model via transfer learning using custom images. \n2. I edited WORKSPACE and built demo.apk\n   App crashed.\n3. Then i used inception5h.zip  as referenced in https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android.\n   The app run without any problem.\n### What other attempted solutions have you tried?\n\nThen i looked at issue https://github.com/tensorflow/tensorflow/issues/1269 for guidance.\n1.    ---Edited tensorflowImagelistener.java---\n\n``` java\n  private static final int NUM_CLASSES = 4; //1001;\n  private static final int INPUT_SIZE = 299; //224\n  private static final int IMAGE_MEAN = 128; //117\n  private static final float IMAGE_STD = 128; //1;\n  private static final String INPUT_NAME = \"Mul:0\"; //\"input:0\"; \n  private static final String OUTPUT_NAME = \"final_result:0\"; //\"output:0\";\n```\n1. ---I even stripped the graph using strip_unused.py using ----\n\n``` sh\n  bazel build tensorflow/python/tools:strip_unused\n  bazel-bin/tensorflow/python/tools/strip_unused --input_graph=/tmp/inception.pb   --output_graph=/tmp/stripped_inception.pb --input_node_names=\"Mul:0\" --output_node_names=\"final_result\" --input_binary=true\n```\n1. --In strip_unused_lib.py i added if else clause as referenced by @dmirk quick-n-dirty from #1269---\n\n``` python\n      if \"jpeg\" in node.op.lower():\n        placeholder_node.attr[\"dtype\"].CopyFrom(tf.AttrValue(\n            type=tf.uint8.as_datatype_enum))\n      else:\n        placeholder_node.attr[\"dtype\"].CopyFrom(tf.AttrValue(\n            type=placeholder_type_enum))\n```\n1. For some reason i still got this error. See attached \n   [oldlogcat.txt](https://github.com/tensorflow/tensorflow/files/479719/oldlogcat.txt)\n\n``` sh\ntensorflow_jni.cc:304 Error during inference: Invalid argument: No OpKernel was registered to support Op 'DecodeJpeg' with these attrs.  Registered kernels:\n```\n1. As a last resort i did this modification to tensorflow_jni.cc as referenced in #1269. See attached [logcat.txt](https://github.com/tensorflow/tensorflow/files/479718/logcat.txt)\n\n``` cc\n      // Copy 3 values\n      input_tensor_mapped(0, i, j, 0) =\n          (static_cast<float>(src->red) - g_image_mean) / g_image_mean;//g_image_std;\n      input_tensor_mapped(0, i, j, 1) =\n          (static_cast<float>(src->green) - g_image_mean) / g_image_mean;//g_image_std;\n      input_tensor_mapped(0, i, j, 2) =\n          (static_cast<float>(src->blue) - g_image_mean) / g_image_mean;//g_image_std;\n```\n\nbut i think this dint help any much. however i dint find the opkernel error\n### Logs or other output that would be helpful\n", "comments": ["@fninsiima Can you confirm that the app is indeed trying to load `stripped_inception.pb`? The relevant log lines regarding this don't seem to be in oldlogcat.txt.\n", "I renamed the stripped file to tensorflow_inception_graph.pb after i transferred it to the assets folder.\n\nI'm not sure what i should be looking for.\n\nThis is part of the output when i build it\n\n``` sh\nINFO: Found 1 target...\nINFO: From Processing Android resources for //tensorflow/examples/android:tensorflow_demo:\nError: Warning: AndroidManifest.xml already defines debuggable (in http://schemas.android.com/apk/res/android); using existing value in manifest.\nTarget //tensorflow/examples/android:tensorflow_demo up-to-date:\n  bazel-bin/tensorflow/examples/android/tensorflow_demo_deploy.jar\n  bazel-bin/tensorflow/examples/android/tensorflow_demo_unsigned.apk\n  bazel-bin/tensorflow/examples/android/tensorflow_demo.apk\nINFO: Elapsed time: 48.021s, Critical Path: 32.03s\n```\n\nBefore this there are a few warnings... that i've ignored.\n", "@fninsiima Try the strip_unused command again, but this time with `--input_node_names=\"Mul\"`. I think the extra \":0\" is confusing the script. It should tell you `997 ops in the final graph` if everything works right.\n", "Okay.\n\nI did as you instructed and was successful. Thanks a lot.\n", "I did the same, but still crashed.", "hello, I'm also trying to run the retrained tensorflow model on my htc one M8, but the app is crashing. \r\nI followed this tutorial: https://medium.com/@mgazar/experimenting-with-tensorflow-on-android-part-2-12f3dc294eaf#.gbp69dmst\r\n\r\nSteps:\r\n- retrained inception v3 with the stanford dogs dataset\r\n- used strip_unused\r\n- copied stripped_retrained_inception.pb and retrained_labels.txt to the demo assets folder\r\n- modified ClassifierActivity.java (there is no TensorFlowImageListener in my project) : INPUT_SIZE = 299, IMAGE_MEAN = 128, IMAGE_STD = 128, INPUT_NAME = \"Mul:0\", OUTPUT_NAME = \"final_result:0\" \r\n\r\nHere are my logs: \r\n\r\n01-31 16:13:20.571 16771 16771 D tensorflow: CameraActivity: onCreate org.tensorflow.demo.ClassifierActivity@5923b39\r\n01-31 16:13:20.586 16771 16771 D tensorflow: CameraActivity: onStart org.tensorflow.demo.ClassifierActivity@5923b39\r\n01-31 16:13:20.586 16771 16771 D tensorflow: CameraActivity: onResume org.tensorflow.demo.ClassifierActivity@5923b39\r\n01-31 16:13:20.679 16771 16771 I tensorflow: CameraConnectionFragment: Adding size: 1920x1088\r\n01-31 16:13:20.679 16771 16771 I tensorflow: CameraConnectionFragment: Adding size: 1920x1080\r\n01-31 16:13:20.679 16771 16771 I tensorflow: CameraConnectionFragment: Adding size: 1808x1080\r\n01-31 16:13:20.679 16771 16771 I tensorflow: CameraConnectionFragment: Adding size: 1440x1088\r\n01-31 16:13:20.679 16771 16771 I tensorflow: CameraConnectionFragment: Adding size: 1280x960\r\n01-31 16:13:20.679 16771 16771 I tensorflow: CameraConnectionFragment: Adding size: 1088x1088\r\n01-31 16:13:20.679 16771 16771 I tensorflow: CameraConnectionFragment: Adding size: 1280x720\r\n01-31 16:13:20.679 16771 16771 I tensorflow: CameraConnectionFragment: Adding size: 960x720\r\n01-31 16:13:20.679 16771 16771 I tensorflow: CameraConnectionFragment: Adding size: 736x736\r\n01-31 16:13:20.679 16771 16771 I tensorflow: CameraConnectionFragment: Adding size: 960x544\r\n01-31 16:13:20.679 16771 16771 I tensorflow: CameraConnectionFragment: Adding size: 864x480\r\n01-31 16:13:20.679 16771 16771 I tensorflow: CameraConnectionFragment: Adding size: 800x480\r\n01-31 16:13:20.679 16771 16771 I tensorflow: CameraConnectionFragment: Adding size: 720x480\r\n01-31 16:13:20.679 16771 16771 I tensorflow: CameraConnectionFragment: Adding size: 768x432\r\n01-31 16:13:20.679 16771 16771 I tensorflow: CameraConnectionFragment: Adding size: 640x480\r\n01-31 16:13:20.679 16771 16771 I tensorflow: CameraConnectionFragment: Adding size: 576x432\r\n01-31 16:13:20.680 16771 16771 I tensorflow: CameraConnectionFragment: Adding size: 640x360\r\n01-31 16:13:20.680 16771 16771 I tensorflow: CameraConnectionFragment: Adding size: 480x320\r\n01-31 16:13:20.680 16771 16771 I tensorflow: CameraConnectionFragment: Not adding size: 384x288\r\n01-31 16:13:20.680 16771 16771 I tensorflow: CameraConnectionFragment: Not adding size: 352x288\r\n01-31 16:13:20.680 16771 16771 I tensorflow: CameraConnectionFragment: Not adding size: 320x240\r\n01-31 16:13:20.680 16771 16771 I tensorflow: CameraConnectionFragment: Not adding size: 240x160\r\n01-31 16:13:20.680 16771 16771 I tensorflow: CameraConnectionFragment: Not adding size: 176x144\r\n01-31 16:13:20.680 16771 16771 I tensorflow: CameraConnectionFragment: Chosen size: 480x320\r\n01-31 16:13:20.731 16771 16771 I native  : tensorflow_inference_jni.cc:97 Native TF methods loaded.\r\n01-31 16:13:20.731 16771 16771 I native  : tensorflow_inference_jni.cc:85 Creating new session variables for b33ca6a0c3ec0367\r\n01-31 16:13:20.731 16771 16771 I native  : tensorflow_inference_jni.cc:113 Loading Tensorflow.\r\n01-31 16:13:20.733 16771 16771 I native  : tensorflow_inference_jni.cc:120 Session created.\r\n01-31 16:13:20.733 16771 16771 I native  : tensorflow_inference_jni.cc:126 Acquired AssetManager.\r\n01-31 16:13:20.733 16771 16771 I native  : tensorflow_inference_jni.cc:128 Reading file to proto: file:///android_asset/stripped_inception.pb\r\n01-31 16:13:20.733 16771 16771 I native  : jni_utils.cc:126 Opening asset stripped_inception.pb from disk with copy.\r\n01-31 16:13:20.733 16771 16771 W native  : jni_utils.cc:131 Compressed proto is larger than 64mb; if problems occur  turn off compression for protocol buffer files in APK.\r\n01-31 16:13:21.829 16771 16771 F native  : jni_utils.cc:136 Check failed: message->ParseFromArray(memory, data_size) \r\n01-31 16:13:21.829 16771 16771 F libc    : Fatal signal 6 (SIGABRT), code -6 in tid 16771 (tensorflow.demo)\r\n01-31 16:13:21.885   462   462 F DEBUG   : *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***\r\n01-31 16:13:21.886   462   462 F DEBUG   : Build fingerprint: 'htc/orange_uk/htc_m8:6.0/MRA58K/663331.4:user/release-keys'\r\n01-31 16:13:21.886   462   462 F DEBUG   : Revision: '0'\r\n01-31 16:13:21.886   462   462 F DEBUG   : ABI: 'arm'\r\n01-31 16:13:21.886   462   462 F DEBUG   : pid: 16771, tid: 16771, name: tensorflow.demo  >>> org.tensorflow.demo <<<\r\n01-31 16:13:21.886   462   462 F DEBUG   : signal 6 (SIGABRT), code -6 (SI_TKILL), fault addr --------\r\n01-31 16:13:21.912   462   462 F DEBUG   : Abort message: 'jni_utils.cc:136 Check failed: message->ParseFromArray(memory, data_size) '\r\n01-31 16:13:21.913   462   462 F DEBUG   :     r0 00000000  r1 00004183  r2 00000006  r3 b6f13b7c\r\n01-31 16:13:21.913   462   462 F DEBUG   :     r4 b6f13b84  r5 b6f13b34  r6 00000054  r7 0000010c\r\n01-31 16:13:21.913   462   462 F DEBUG   :     r8 bed9a6d4  r9 bed9a558  sl bed9a810  fp b9204cb0\r\n01-31 16:13:21.913   462   462 F DEBUG   :     ip 00000006  sp bed9a500  lr b6c89471  pc b6c8a9ec  cpsr 400f0010\r\n01-31 16:13:21.932   462   462 F DEBUG   : \r\n01-31 16:13:21.932   462   462 F DEBUG   : backtrace:\r\n01-31 16:13:21.932   462   462 F DEBUG   :     #00 pc 000439ec  /system/lib/libc.so (tgkill+12)\r\n01-31 16:13:21.932   462   462 F DEBUG   :     #01 pc 0004246d  /system/lib/libc.so (pthread_kill+32)\r\n01-31 16:13:21.932   462   462 F DEBUG   :     #02 pc 0001b87f  /system/lib/libc.so (raise+10)\r\n01-31 16:13:21.932   462   462 F DEBUG   :     #03 pc 00018a31  /system/lib/libc.so (__libc_android_abort+34)\r\n01-31 16:13:21.933   462   462 F DEBUG   :     #04 pc 00016830  /system/lib/libc.so (abort+4)\r\n01-31 16:13:21.933   462   462 F DEBUG   :     #05 pc 006aa551  /data/app/org.tensorflow.demo-2/lib/arm/libtensorflow_demo.so\r\n01-31 16:13:21.933   462   462 F DEBUG   :     #06 pc 006aa6fb  /data/app/org.tensorflow.demo-2/lib/arm/libtensorflow_demo.so\r\n01-31 16:13:21.933   462   462 F DEBUG   :     #07 pc 006aa713  /data/app/org.tensorflow.demo-2/lib/arm/libtensorflow_demo.so\r\n01-31 16:13:21.933   462   462 F DEBUG   :     #08 pc 0009080d  /data/app/org.tensorflow.demo-2/lib/arm/libtensorflow_demo.so\r\n01-31 16:13:21.934   462   462 F DEBUG   :     #09 pc 00097695  /data/app/org.tensorflow.demo-2/lib/arm/libtensorflow_demo.so (Java_org_tensorflow_contrib_android_TensorFlowInferenceInterface_initializeTensorFlow+724)\r\n01-31 16:13:21.934   462   462 F DEBUG   :     #10 pc 000268f9  /data/app/org.tensorflow.demo-2/oat/arm/base.odex (offset 0x26000) (int org.tensorflow.contrib.android.TensorFlowInferenceInterface.initializeTensorFlow(android.content.res.AssetManager, java.lang.String)+116)\r\n01-31 16:13:21.934   462   462 F DEBUG   :     #11 pc 0003b32d  /data/app/org.tensorflow.demo-2/oat/arm/base.odex (offset 0x26000) (org.tensorflow.demo.Classifier org.tensorflow.demo.TensorFlowImageClassifier.create(android.content.res.AssetManager, java.lang.String, java.lang.String, int, int, int, float, java.lang.String, java.lang.String)+1416)\r\n01-31 16:13:21.935   462   462 F DEBUG   :     #12 pc 0002f7af  /data/app/org.tensorflow.demo-2/oat/arm/base.odex (offset 0x26000) (void org.tensorflow.demo.ClassifierActivity.onPreviewSizeChosen(android.util.Size, int)+538)\r\n01-31 16:13:21.935   462   462 F DEBUG   :     #13 pc 000272e7  /data/app/org.tensorflow.demo-2/oat/arm/base.odex (offset 0x26000) (void org.tensorflow.demo.CameraActivity$1.onPreviewSizeChosen(android.util.Size, int)+66)\r\n01-31 16:13:21.935   462   462 F DEBUG   :     #14 pc 0002c9b5  /data/app/org.tensorflow.demo-2/oat/arm/base.odex (offset 0x26000) (void org.tensorflow.demo.CameraConnectionFragment.setUpCameraOutputs(int, int)+1360)\r\n01-31 16:13:21.936   462   462 F DEBUG   :     #15 pc 0002c197  /data/app/org.tensorflow.demo-2/oat/arm/base.odex (offset 0x26000) (void org.tensorflow.demo.CameraConnectionFragment.openCamera(int, int)+58)\r\n01-31 16:13:21.936   462   462 F DEBUG   :     #16 pc 0002a5ff  /data/app/org.tensorflow.demo-2/oat/arm/base.odex (offset 0x26000) (void org.tensorflow.demo.CameraConnectionFragment.access$000(org.tensorflow.demo.CameraConnectionFragment, int, int)+58)\r\n01-31 16:13:21.936   462   462 F DEBUG   :     #17 pc 00028ddf  /data/app/org.tensorflow.demo-2/oat/arm/base.odex (offset 0x26000) (void org.tensorflow.demo.CameraConnectionFragment$1.onSurfaceTextureAvailable(android.graphics.SurfaceTexture, int, int)+90)\r\n01-31 16:13:21.936   462   462 F DEBUG   :     #18 pc 032eb9a3  /system/framework/arm/boot.oat (offset 0x2256000)\r\n01-31 16:13:22.012  1093  1503 E HtcWifiRssiMonitor: newrssi =-61 , oldRssi= -61\r\n01-31 16:13:22.314  1093 16836 E ActivityManager: App crashed! Process: org.tensorflow.demo\r\n\r\n\r\nAny idea why it's crashing on my android phone? The original demo with tensorflow_inception_graph.pb and ClassifierActivity.java unchanged works as expected.\r\n", "@GeorgianaPetria From your log:\r\n```\r\n01-31 16:13:20.733 16771 16771 I native : jni_utils.cc:126 Opening asset stripped_inception.pb from disk with copy.\r\n01-31 16:13:20.733 16771 16771 W native : jni_utils.cc:131 Compressed proto is larger than 64mb; if problems occur turn off compression for protocol buffer files in APK.\r\n01-31 16:13:21.829 16771 16771 F native : jni_utils.cc:136 Check failed: message->ParseFromArray(memory, data_size)\r\n```\r\n\r\nYou can use the nocompress_extensions = [\"pb\"] Bazel directive to disable compression on your android_binary target.", "@andrewharp, thanks. that was the problem. \r\nI disabled the compression for .pb files in build.gradle:\r\n\r\naaptOptions { noCompress 'pb' }\r\n", "@andrewharp I try the strip_unused command and get 997 ops. But app crashes on importGraphDef.\r\nHere are my logs:\r\njava.lang.RuntimeException: Error initializing TensorFlow!\r\n                                                                       at org.tensorflow.demo.ClassifierActivity.onPreviewSizeChosen(ClassifierActivity.java:141)\r\n                                                                       at org.tensorflow.demo.CameraActivity$1.onPreviewSizeChosen(CameraActivity.java:158)\r\n                                                                       at org.tensorflow.demo.CameraConnectionFragment.setUpCameraOutputs(CameraConnectionFragment.java:394)\r\n                                                                       at org.tensorflow.demo.CameraConnectionFragment.openCamera(CameraConnectionFragment.java:411)\r\n                                                                       at org.tensorflow.demo.CameraConnectionFragment.access$000(CameraConnectionFragment.java:63)\r\n                                                                       at org.tensorflow.demo.CameraConnectionFragment$1.onSurfaceTextureAvailable(CameraConnectionFragment.java:94)\r\n                                                                       at android.view.TextureView.getHardwareLayer(TextureView.java:394)\r\n                                                                       at android.view.TextureView.draw(TextureView.java:330)\r\n                                                                       at android.view.View.updateDisplayListIfDirty(View.java:16197)\r\n                                                                       at android.view.View.draw(View.java:16998)\r\n                                                                       at android.view.ViewGroup.drawChild(ViewGroup.java:3777)\r\n                                                                       at android.view.ViewGroup.dispatchDraw(ViewGroup.java:3560)\r\n                                                                       at android.view.View.updateDisplayListIfDirty(View.java:16192)\r\n                                                                       at android.view.View.draw(View.java:16998)\r\n                                                                       at android.view.ViewGroup.drawChild(ViewGroup.java:3777)\r\n                                                                       at android.view.ViewGroup.dispatchDraw(ViewGroup.java:3560)\r\n                                                                       at android.view.View.draw(View.java:17235)\r\n                                                                       at android.view.View.updateDisplayListIfDirty(View.java:16197)\r\n                                                                       at android.view.View.draw(View.java:16998)\r\n                                                                       at android.view.ViewGroup.drawChild(ViewGroup.java:3777)\r\n                                                                       at android.view.ViewGroup.dispatchDraw(ViewGroup.java:3560)\r\n                                                                       at android.view.View.updateDisplayListIfDirty(View.java:16192)\r\n                                                                       at android.view.View.draw(View.java:16998)\r\n                                                                       at android.view.ViewGroup.drawChild(ViewGroup.java:3777)\r\n                                                                       at android.view.ViewGroup.dispatchDraw(ViewGroup.java:3560)\r\n                                                                       at android.view.View.updateDisplayListIfDirty(View.java:16192)\r\n                                                                       at android.view.View.draw(View.java:16998)\r\n                                                                       at android.view.ViewGroup.drawChild(ViewGroup.java:3777)\r\n                                                                       at android.view.ViewGroup.dispatchDraw(ViewGroup.java:3560)\r\n                                                                       at android.view.View.draw(View.java:17235)\r\n                                                                       at com.android.internal.policy.DecorView.draw(DecorView.java:801)\r\n                                                                       at android.view.View.updateDisplayListIfDirty(View.java:16197)\r\n                                                                       at android.view.ThreadedRenderer.updateViewTreeDisplayList(ThreadedRenderer.java:676)\r\n                                                                       at android.view.ThreadedRenderer.updateRootDisplayList(ThreadedRenderer.java:682)\r\n                                                                       at android.view.ThreadedRenderer.draw(ThreadedRenderer.java:796)\r\n                                                                       at android.view.ViewRootImpl.draw(ViewRootImpl.java:2989)\r\n                                                                       at android.view.ViewRootImpl.performDraw(ViewRootImpl.java:2783)\r\n                                                                       at android.view.ViewRootImpl.performTraversals(ViewRootImpl.java:2374)\r\n                                                                       at android.view.ViewRootImpl.doTraversal(ViewRootImpl.java:1364)\r\n                                                                       at android.view.ViewRootImpl$TraversalRunnable.run(ViewRootImpl.java:6757)\r\n                                                                       at android.view.Choreographer$CallbackRecord.run(Choreographer.java:923)\r\n                                                                       at android.view.Choreographer.doCallbacks(Choreographer.java:735)\r\n                                                                       at android.view.Choreographer.doFrame(Choreographer.java:667)\r\n                                                                       at android.view.Choreographer$FrameDisplayEventReceiver.run(Choreographer.java:909)\r\n                                                                       at android.os.Handler.handleCallback(Handler.java:755)\r\n                                                                       at android.os.Handler.dispatchMessage(Handler.java:95)\r\n                                                                       at android.os.Looper.loop(Looper.java:156)\r\n                                                                       at android.app.ActivityThread.main(ActivityThread.java:6524)\r\n                                                                       at java.lang.reflect.Method.invoke(Native Method)\r\n                                                                       at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:941)\r\n                                                                       at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:831)\r\n                                                                    Caused by: java.lang.UnsupportedOperationException: Op BatchNormWithGlobalNormalization is not available in GraphDef version 21. It has been removed in version 9. Use tf.nn.batch_normalization().\r\n                                                                       at org.tensorflow.Graph.importGraphDef(Native Method)\r\n                                                                       at org.tensorflow.Graph.importGraphDef(Graph.java:113)\r\n                                                                       at org.tensorflow.Graph.importGraphDef(Graph.java:97)\r\n                                                                       at org.tensorflow.contrib.android.TensorFlowInferenceInterface.load(TensorFlowInferenceInterface.java:402)\r\n03-05 18:42:02.972 4844-4844/org.tensorflow.demo E/AndroidRuntime:     at org.tensorflow.contrib.android.TensorFlowInferenceInterface.initializeTensorFlow(TensorFlowInferenceInterface.java:91)\r\n                                                                       at org.tensorflow.demo.TensorFlowImageClassifier.create(TensorFlowImageClassifier.java:102)\r\n                                                                       at org.tensorflow.demo.ClassifierActivity.onPreviewSizeChosen(ClassifierActivity.java:131)\r\n                                                                       \t... 50 more\r\n                                                              ", "I was successful with the stripped_inception.pb file. But the Inception v3 model  is much lower than the previous, it takes about 10 seconds to recognize each image. I have followed the TensorFlow For Poets codelab. Do anyone get the same problem?", " i followed codelabs-tensorflow-for-poets tutorial [part 1](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#0) and [2](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets-2/#0).  I trained using  mobilenet and iceptionv3 as well with my custom images(separately). I want to further export it in android but the app force closes with this \" ERROR:  java.lang.RuntimeException: Failed to load model from 'file:///android_asset/graph.pb'  \" . (this error occurs in both the cases). can anyone please tell what might have went wrong ?", "@Abhi-Pawar I am seeing same issue. Were you able to figure out the cause and have you fixed it ", "I am having the same problem the file app crashes when ever I run it .I retrained the model and use strip_unused .py to load in the TensorFlowAndroidDemo but app continously crashing what I need to do regarding this.\r\n\r\n07/06 06:53:31: Launching app\r\n$ adb push C:\\Users\\AndroidStudioProjects\\TensorFlowAndroidDemo-master\\app\\build\\outputs\\apk\\app-debug.apk /data/local/tmp/org.tensorflow.tensorflowdemo\r\n$ adb shell pm install -t -r \"/data/local/tmp/org.tensorflow.tensorflowdemo\"\r\n\tpkg: /data/local/tmp/org.tensorflow.tensorflowdemo\r\nSuccess\r\n\r\n\r\n$ adb shell am start -n \"org.tensorflow.tensorflowdemo/org.tensorflow.demo.CameraActivity\" -a android.intent.action.MAIN -c android.intent.category.LAUNCHER\r\nClient not ready yet..Waiting for process to come online\r\nConnected to process 13456 on device samsung-sm_j500f-0369b8f7\r\nCapturing and displaying logcat messages from application. This behavior can be disabled in the \"Logcat output\" section of the \"Debugger\" settings page.\r\nE/Zygote: v2\r\nI/SELinux: Function: selinux_compare_spd_ram, SPD-policy is existed. and_ver=SEPF_SM-J500F_5.1.1 ver=48\r\nI/SELinux: Function: selinux_compare_spd_ram , priority [1] , priority version is VE=SEPF_SM-J500F_5.1.1_0048\r\nE/SELinux: [DEBUG] get_category: variable seinfo: default sensitivity: NULL, cateogry: NULL\r\nI/art: Late-enabling -Xcheck:jni\r\nI/libpersona: KNOX_SDCARD checking this for 10351\r\n              KNOX_SDCARD not a persona\r\nD/TimaKeyStoreProvider: in addTimaSignatureService\r\nD/TimaKeyStoreProvider: TimaSignature is unavailable\r\nD/ActivityThread: Added TimaKesytore provider\r\nE/art: Failed sending reply to debugger: Broken pipe\r\nI/art: Debugger is no longer active\r\nI/InjectionManager: Inside getClassLibPath + mLibMap{0=, 1=}\r\nW/ResourcesManager: getTopLevelResources: org.tensorflow.tensorflowdemo for user  0\r\nI/InjectionManager: Inside getClassLibPath caller \r\nD/InjectionManager: InjectionManager\r\n                    fillFeatureStoreMap org.tensorflow.tensorflowdemo\r\nI/InjectionManager: Constructor org.tensorflow.tensorflowdemo, Feature store :{}\r\n                    featureStore :{}\r\nW/ResourcesManager: getTopLevelResources: org.tensorflow.tensorflowdemo for user  0\r\nD/DisplayManager: DisplayManager()\r\nW/ResourcesManager: getTopLevelResources: org.tensorflow.tensorflowdemo for user  0\r\nD/PhoneWindow: *FMB* installDecor mIsFloating : false\r\n               *FMB* installDecor flags : -2139028096\r\nW/linker: libtensorflow_demo.so: unused DT entry: type 0x6ffffffe arg 0x28cc\r\n          libtensorflow_demo.so: unused DT entry: type 0x6fffffff arg 0x3\r\nD/Activity: performCreate Call Injection manager\r\nI/InjectionManager: dispatchOnViewCreated > Target : org.tensorflow.demo.CameraConnectionFragment isFragment :true\r\n                    dispatchOnViewCreated > Target : org.tensorflow.demo.CameraActivity isFragment :false\r\nD/OpenGLRenderer: Use EGL_SWAP_BEHAVIOR_PRESERVED: true\r\nD/PhoneWindow: *FMB* isFloatingMenuEnabled mFloatingMenuBtn : null\r\n               *FMB* isFloatingMenuEnabled return false\r\nI/Adreno-EGL: <qeglDrvAPI_eglInitialize:379>: EGL 1.4 QUALCOMM build: AU_LINUX_ANDROID_LA.BR.1.1.3_RB1.05.01.00.032.018_msm8916_32_refs/tags/AU_LINUX_ANDROID_LA.BR.1.1.3_RB1.05.01.00.032.018__release_AU (I856e09677e)\r\n              OpenGL ES Shader Compiler Version: E031.25.03.04\r\n              Build Date: 05/03/15 Sun\r\n              Local Branch: \r\n              Remote Branch: refs/tags/AU_LINUX_ANDROID_LA.BR.1.1.3_RB1.05.01.00.032.018\r\n              Local Patches: NONE\r\n              Reconstruct Branch: NOTHING\r\nI/OpenGLRenderer: Initialized EGL, version 1.4\r\nD/OpenGLRenderer: Enabling debug mode 0\r\nI/CameraManagerGlobal: getCameraService: Reconnecting to camera service\r\nI/tensorflow: CameraConnectionFragment: Adding size: 1440x1080\r\n              CameraConnectionFragment: Adding size: 1280x720\r\n              CameraConnectionFragment: Adding size: 1056x864\r\n              CameraConnectionFragment: Adding size: 960x720\r\n              CameraConnectionFragment: Adding size: 880x720\r\n              CameraConnectionFragment: Adding size: 800x480\r\n              CameraConnectionFragment: Adding size: 720x480\r\n              CameraConnectionFragment: Adding size: 640x480\r\n              CameraConnectionFragment: Adding size: 528x432\r\n              CameraConnectionFragment: Not adding size: 352x288\r\n              CameraConnectionFragment: Not adding size: 320x240\r\n              CameraConnectionFragment: Not adding size: 176x144\r\n              CameraConnectionFragment: Chosen size: 528x432\r\nI/CameraManager: Using legacy camera HAL.\r\nI/tensorflow: CameraConnectionFragment: Opening camera preview: 528x432\r\nI/CameraDeviceState: Legacy camera service transitioning to state CONFIGURING\r\nI/RequestThread-0: Configure outputs: 2 surfaces configured.\r\nD/Camera: app passed NULL surface\r\nI/CameraDeviceState: Legacy camera service transitioning to state IDLE\r\nI/tensorflow: CameraConnectionFragment: Getting assets.\r\nI/native: tensorflow_jni.cc:115 Loading TensorFlow.\r\n          tensorflow_jni.cc:117 Making new SessionOptions.\r\n          tensorflow_jni.cc:120 Got config, 0 devices\r\n          tensorflow_jni.cc:123 Session created.\r\n          tensorflow_jni.cc:126 Graph created.\r\n          tensorflow_jni.cc:130 Acquired AssetManager.\r\n          tensorflow_jni.cc:132 Reading file to proto: file:///android_asset/tensorflow_inception_graph.pb\r\nI/native: stat_summarizer.cc:33 StatSummarizer found 515 nodes\r\nI/native: tensorflow_jni.cc:137 Creating session.\r\nI/native: tensorflow_jni.cc:145 TensorFlow graph loaded from: file:///android_asset/tensorflow_inception_graph.pb\r\n          jni_utils.cc:145 Opening asset imagenet_comp_graph_label_strings.txt from disk with copy.\r\n          jni_utils.cc:165 Read 2 values from file:///android_asset/imagenet_comp_graph_label_strings.txt\r\n          tensorflow_jni.cc:149 2 label strings loaded from: file:///android_asset/imagenet_comp_graph_label_strings.txt\r\n          tensorflow_jni.cc:154 Initialization done in 538ms\r\nI/tensorflow: CameraConnectionFragment: TensorFlow initialized.\r\nI/RequestQueue: Repeating capture request set.\r\nI/Timeline: Timeline: Activity_idle id: android.os.BinderProxy@c68926c time:140831480\r\nW/LegacyRequestMapper: convertRequestMetadata - control.awbRegions setting is not supported, ignoring value\r\n                       Only received metering rectangles with weight 0.\r\nI/CameraDeviceState: Legacy camera service transitioning to state CAPTURING\r\nI/tensorflow: TensorFlowImageListener: Initializing at size 528x432\r\nW/MessageQueue: Handler (android.os.Handler) {2162ee9} sending message to a Handler on a dead thread\r\n                java.lang.IllegalStateException: Handler (android.os.Handler) {2162ee9} sending message to a Handler on a dead thread\r\n                    at android.os.MessageQueue.enqueueMessage(MessageQueue.java:325)\r\n                    at android.os.Handler.enqueueMessage(Handler.java:631)\r\n                    at android.os.Handler.sendMessageAtTime(Handler.java:600)\r\n                    at android.os.Handler.sendMessageDelayed(Handler.java:570)\r\n                    at android.os.Handler.post(Handler.java:326)\r\n                    at org.tensorflow.demo.TensorFlowImageListener.onImageAvailable(TensorFlowImageListener.java:195)\r\n                    at android.media.ImageReader$ListenerHandler.handleMessage(ImageReader.java:548)\r\n                    at android.os.Handler.dispatchMessage(Handler.java:102)\r\n                    at android.os.Looper.loop(Looper.java:135)\r\n                    at android.app.ActivityThread.main(ActivityThread.java:5910)\r\n                    at java.lang.reflect.Method.invoke(Native Method)\r\n                    at java.lang.reflect.Method.invoke(Method.java:372)\r\n                    at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:1405)\r\n                    at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1200)\r\nI/art: Background sticky concurrent mark sweep GC freed 18080(945KB) AllocSpace objects, 0(0B) LOS objects, 4% free, 7MB/7MB, paused 1.803ms total 106.143ms", "@Shazuka\r\n\r\nMaybe you can open a new issue as this one was closed.\r\nAlso, I posted this issue in 2016 using an old tensorflow repo.\r\nYou might also want to include the version of tensorflow, OS etc in the issue.", "I have the same problem, java.lang.RuntimeException: Failed to load model from 'opt_mnist_convnet.pb'\r\nbut when I am trying the old created model its working fine. when I retrained this old model with more epoch then it shows this exception. Please help me.", "> I have the same problem, java.lang.RuntimeException: Failed to load model from 'opt_mnist_convnet.pb'\r\n> but when I am trying the old created model its working fine. when I retrained this old model with more epoch then it shows this exception. Please help me.\r\n\r\nI meet the same problem, have you solved it?"]}, {"number": 4450, "title": "Set re2 repository commit to the latest", "body": "This makes re2 buildable on Windows with MSVC toolchain. @mrry @damienmg @dslomov\n", "comments": ["Can one of the admins verify this patch?\n", "@meteorcloudy, thanks for your PR! By analyzing the annotation information on this pull request, we identified @danmane, @kirilg and @tensorflower-gardener to be potential reviewers\n", "@tensorflow-jenkins test this please.\n", "Hmm.. Is it my change that's causing the failure? Can we rerun it?\n", "@tensorflow-jenkins test this please.\n", "(Looks like a transient failure for one of the external repositories... but let's test again to be sure.)\n", "Still failing. I'm sure it's unrelated to this CL, but that test is becoming is problem. Do you know what's wrong with it?\n"]}, {"number": 4449, "title": "Fixed ./configure on Windows", "body": "Fixed some configuration issues when building tensorflow on Windows. @mrry @damienmg @dslomov \n", "comments": ["Can one of the admins verify this patch?\n", "@meteorcloudy, thanks for your PR! By analyzing the annotation information on this pull request, we identified @aselle, @vrv and @itsmeolivia to be potential reviewers\n", "LGTM but @mrry might want to take a look pending his Windows work.\n", "@tensorflow-jenkins test this please.\n"]}, {"number": 4448, "title": "Fixed cuda_configure.bzl for Windows", "body": "`cuda_configure` is the first blocker when building tensorflow on Windows. We shouldn't even run cuda_configure if cuda support is not enabled, but this patch could unblock us easily. @mrry @damienmg @dslomov \n", "comments": ["@meteorcloudy, thanks for your PR! By analyzing the annotation information on this pull request, we identified @davidzchen to be a potential reviewer\n", "Can one of the admins verify this patch?\n", "Jenkins, test this please.\n", "@mrry - This change looks good to me. Can you take a look and merge if there are no other feedback? Thanks!\n", "Thanks for the fix!\n"]}, {"number": 4447, "title": "Fix to run on Xcode 8.0", "body": "Xcode 8.0 shows its version code as `Xcode 8.0` (no micro version)\nso the version check failed,\nbecause `80` is less than `730`.\n\nThis change checks required major/minor/micro version separately,\nand makes the script to run on Xcode 8.0.\n", "comments": ["@tyfkda, thanks for your PR! By analyzing the annotation information on this pull request, we identified @petewarden to be a potential reviewer\n", "Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "Jenkins, test this please.\n", "Jenkins stopped:\n\n```\n#1\u200b86\u200b8 2016/09/19 1:40 Build \u200btimed \u200bout \u200b(after \u200b120 \u200bminutes). \u200bMarking \u200bthe \u200bbuild \u200bas \u200bfailed.\n```\n\nI'm not sure this failure is caused by my change.\nIs it worth a try restart CI?\n", "Console output:\nhttps://ci.tensorflow.org/job/tensorflow-pull-requests-mac/1930/console\n", "Jenkins, test this please.\n"]}, {"number": 4446, "title": "Update artifact version in gcs_test Dockerfile", "body": "", "comments": ["@caisq, thanks for your PR! By analyzing the annotation information on this pull request, we identified @martinwicke to be a potential reviewer\n"]}, {"number": 4445, "title": "WIP: DO NOT MERGE: Remove pylint whitelist from ci_sanity.sh", "body": "", "comments": ["@caisq, thanks for your PR! By analyzing the annotation information on this pull request, we identified @tensorflower-gardener, @ilblackdragon and @benoitsteiner to be potential reviewers\n", "@tensorflow-jenkins test this please.\n", "Do you want to extend this more?\n", "There are wrinkles to be ironed out internally before this can be merged. Let me close this for now.\n"]}, {"number": 4444, "title": "Code snippet in the TensorFlow for Poets codelab is confusing", "body": "Based on [this](http://stackoverflow.com/q/39562938/3574081) Stack Overflow question.\n\nIn [section 5](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/index.html?index=..%2F..%2Findex#4), the first `python` command has a leading `#`:\n\n``` bash\n# python tensorflow/examples/image_retraining/retrain.py \\\n--bottleneck_dir=/tf_files/bottlenecks \\\n--how_many_training_steps 500 \\\n--model_dir=/tf_files/inception \\\n--output_graph=/tf_files/retrained_graph.pb \\\n--output_labels=/tf_files/retrained_labels.txt \\\n--image_dir /tf_files/flower_photos\n```\n\nThe second one doesn't:\n\n``` bash\npython tensorflow/examples/image_retraining/retrain.py \\\n--bottleneck_dir=/tf_files/bottlenecks \\\n--model_dir=/tf_files/inception \\\n--output_graph=/tf_files/retrained_graph.pb \\\n--output_labels=/tf_files/retrained_labels.txt \\\n--image_dir /tf_files/flower_photos\n```\n\nIf you copy and paste the first command, you'll get an unintuitive error like `\"--bottleneck_dir=/tf_files/bottlenecks: No such file or directory\"`. We should remove the leading `#` or somehow make it clearer (and consistent across both snippets) that this is a shell prompt.\n", "comments": ["Since `/tf_files/..` is an absolute path you probably have to make sure where this tensorflow folder is located and change the code to the following after chaning the directory with `cd` :\n\n`python tf_files/tensorflow/examples/image_retraining/retrain.py --bottleneck_dir=tf_files/bottlenecks --how_many_training_steps 500 --model_dir=tf_files/inception --output_graph=tf_files/retrained_graph.pb --output_labels=tf_files/retrained_labels.txt --image_dir tf_files/images\n`\n", "FYI I'm looking into how to update the codelab, and will update this bug once it's resolved.\n", "It looks like Wolff added the codelab - assigning to him to get it fixed up.\n", "I removed all the leading % and # (which I was using to indicated whether you were in or not in Docker). "]}, {"number": 4443, "title": "Breaking change of `sparse_softmax_cross_entropy_with_logits` in v0.10: bug or feature", "body": "When dealing with sequences of different lengths and RNNs, it is very common to pad \"out-of-range\" part of the input sequence. More than that, labels should also be padded. It is convenient to pad labels with bogus value `-1` and not introducing any new valid label values.\n\nPrior to version 0.10, `sparse_softmax_cross_entropy_with_logits` returned `0.0` for logits that correspond to `-1` labels. These cross-entropy values thus weren't influencing calculation of loss, effectively being ignored. \n\nSomewhere along the way between v0.9 and v0.10 this behavior has changed, and:\n- `nan` is now being returned for logits that correspond to `-1` labels\n- gradient calculation results in `nan`\n\nNew behavior silently breaks the code that rely on the assumption that zero cross-entropy will be returned and valid gradients will be calculated in case of labels `-1` .\n\nThe goal of this issue is to discuss the possibility and practicability of reverting to the old behavior, i.e.:\n- returning `0.0` for logits that correspond to `-1` labels\n- fixing gradient computation\n\nI would also like to point out that it would be very good to document changes, that could potentially break user code, in the release notes (in the section \"breaking changes\"). \n\n<sub>Sad story: in my case, it took some time to understand what's happening. Current version of documentation says that passing `-1` labels is illegal and leads to incorrect gradient calculations. It was not the case when I've written my code. I couldn't know about this change, as I cannot possibly re-read all the documentation every time I update tensorflow. I spent about 2 weeks exploring NaN loss and thought it's a gradient explosion. I almost threw away a perfectly good model. Advice for future me: if stuck, read the docs AGAIN ;) </sub>\n\nRelated:  #1234 \n### Code snippet to reproduce the issue\n\nI tried hard to produce a minimum amount of code, but, well, ... it's still huge.\n(gist:  [b98a33b2513aac8dca8f70a0a16bc592](https://gist.github.com/ivan-aksamentov/b98a33b2513aac8dca8f70a0a16bc592))\n\nImagine `x` to be an output of RNN. Notice that  `X_i = 0.0`, `Y_i = -1` and `MASK_i` = 0.0 for pading (indices greater then `LENGTH`)\n\n```\nfrom __future__ import print_function, division\nimport tensorflow as tf\n\nI = 1  # input size\nT = 6  # sequence length (num timesteps)\nB = 3  # batch size\nC = 7  # number of classes\n\nX = [\n    [[0.0], [1.0], [2.0], [3.0], [0.0], [0.0]],\n    [[0.0], [1.0], [2.0], [0.0], [0.0], [0.0]],\n    [[0.0], [1.0], [2.0], [3.0], [4.0], [5.0]],\n]\n\nY = [\n    [0, 1, 2, 3, -1, -1],\n    [0, 1, 2, -1, -1, -1],\n    [0, 1, 2, 3, 4, 5],\n]\n\nMASK = [\n    [1, 1, 1, 1, 0, 0],\n    [1, 1, 1, 0, 0, 0],\n    [1, 1, 1, 1, 1, 1],\n]\n\nLENGTHS = [4, 3, 6]\n\nx = tf.placeholder(shape=[B, T, I], dtype=tf.float32, name=\"x\")\ny = tf.placeholder(shape=[B, T], dtype=tf.int32, name=\"y\")\nmask = tf.placeholder(shape=[B, T], dtype=tf.bool, name=\"mask\")\nlengths = tf.placeholder(shape=[B], dtype=tf.int32, name=\"lengths\")\n\nx_flat = tf.reshape(x, shape=[B * T, I])\ny_flat = tf.reshape(y, shape=[B * T])\nmask_flat = tf.reshape(mask, shape=[B * T])\n\nw = tf.Variable(tf.random_normal(mean=0.0, stddev=1e-2, shape=[I, C]), name=\"w\")\nb = tf.Variable(tf.random_normal(mean=0.0, stddev=1e-2, shape=[C]), name=\"b\")\n\nz = tf.nn.xw_plus_b(x_flat, w, b, name=\"z\")\n\nxentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(z, y_flat)\n\nxentropy_masked = tf.select(\n    mask_flat,\n    xentropy,\n    tf.zeros_like(xentropy)\n)\n\nxentropy_masked = tf.reshape(xentropy_masked, [B, T])\n\nxentropy_sum = tf.reduce_sum(xentropy_masked, reduction_indices=1)\n\nxentropy_sum_norm = tf.div(\n    xentropy_sum, tf.cast(lengths, dtype=tf.float32)\n)\n\nloss = tf.reduce_mean(xentropy_sum_norm)\n\nopt = tf.train.GradientDescentOptimizer(learning_rate=1e-3)\ngrads_and_vars_op = opt.compute_gradients(loss)\n\nwith tf.Session() as sess:\n    sess.run(tf.initialize_all_variables())\n    grads_ops = [g for (g, v) in grads_and_vars_op]\n\n    fetches = [\n        xentropy, xentropy_masked\n    ]\n    fetches.extend(grads_ops)\n\n    xe, xe_masked, grads, _ = sess.run(fetches, feed_dict={\n        x: X,\n        y: Y,\n        mask: MASK,\n        lengths: LENGTHS\n    })\n\n    print(\"xe:\\n\", xe)\n    print(\"xe_masked:\\n\", xe_masked)\n    print(\"grads:\\n\", grads)\n\nprint(\"tf.__version__: \", tf.__version__)\n```\n### Desired, old output\n\nwith [tensorflow-0.9.0-cp27-none-linux_x86_64.whl](https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl)\n\n```\nxe:\n [ 1.94680917  1.95220029  1.97665489  1.90392613  0.          0.\n  1.94680917  1.95220029  1.97665489  0.          0.          0.\n  1.94680917  1.95220029  1.97665489  1.90392613  1.99289608  1.89933121]\nxe_masked:\n [[ 1.94680917  1.95220029  1.97665489  1.90392613  0.          0.        ]\n [ 1.94680917  1.95220029  1.97665489  0.          0.          0.        ]\n [ 1.94680917  1.95220029  1.97665489  1.90392613  1.99289608  1.89933121]]\ngrads:\n [[ 0.23479398 -0.01371239 -0.27168125 -0.16881087  0.00719513 -0.03152646\n   0.24374181]]\ntf.__version__:  0.9.0\n```\n### New output\n\nwith [tensorflow-0.10.0-cp27-none-linux_x86_64.whl](https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0-cp27-none-linux_x86_64.whl)\n\n```\nxe:\n [ 1.96044326  1.94155979  1.98353648  1.90060949         nan         nan\n  1.96044326  1.94155979  1.98353648         nan         nan         nan\n  1.96044326  1.94155979  1.98353648  1.90060949  1.93305326  1.96117282]\nxe_masked:\n [[ 1.96044326  1.94155979  1.98353648  1.90060949  0.          0.        ]\n [ 1.96044326  1.94155979  1.98353648  0.          0.          0.        ]\n [ 1.96044326  1.94155979  1.98353648  1.90060949  1.93305326  1.96117282]]\ngrads:\n [[ nan  nan  nan  nan  nan  nan  nan]]\ntf.__version__:  0.10.0\n```\n", "comments": ["See the related bug.\n\nThis is only going to get more strict. Passing labels that are out of range is a sign of a hidden bug; one that may have model builders searching for a long time before figuring out the true problem. Starting in a few days, this op will raise exceptions when passed invalid labels on CPU. On GPU it will continue to return NaNs because we can't easily pass error flags back from the GPU.\n\nDocumentation is being updated to reflect this behavior.\n"]}, {"number": 4442, "title": "predict function loads only the first batch from the input_fn", "body": "I have a regular `input_fn_valid` function. \nWhen using `estimator.evaluate(input_fn=input_fn_valid)` everything is OK and the model is evaluated on the whole dataset. But calling `probs = estimator.predict(input_fn=input_fn_valid)` only returns the predicted values of the first batch (The size of `probs` is equal to `batch_size` parameter). \nI'm using TensorFlow 0.10 and test it on Ubuntu (GPU) and MAC OSX (CPU).\nIs it a bug in the predict function?\n", "comments": ["setting `as_iterable=True`, solve the problem.\n", "@amirj Once I set to as_iterable=True, unable to iterate over prediction, could you suggest a way to do the same."]}, {"number": 4441, "title": "tensorflow read multi-type csv error", "body": "my csv file has 10 column, CONTINUOUS_COLUMNS are  float , and left are string.\nmy code : \n`parse_fn = lambda example:tf.decode_csv(example, [tf.constant([], dtype=tf.float32) if i in CONTINUOUS_COLUMNS else tf.constant([], dtype=tf.string)  for i in COLUMNS ]  ,field_delim='\\t' )`\n`inputs = tf.contrib.learn.read_batch_examples([FLAGS.train], 256, tf.TextLineReader,num_epochs=1,queue_capacity=10000, parse_fn=parse_fn)`\n\nerror \n`Traceback (most recent call last):\n  File \"wide-batch.py\", line 241, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"wide-batch.py\", line 238, in main\n    train_and_eval()\n  File \"wide-batch.py\", line 232, in train_and_eval\n    m.fit(input_fn=lambda: input_fn(stat), steps=FLAGS.train_steps,monitors=[validation_monitor])\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 240, in fit\n    max_steps=max_steps)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 548, in _train_model\n    features, targets = input_fn()\n  File \"wide-batch.py\", line 232, in <lambda>\n    m.fit(input_fn=lambda: input_fn(stat), steps=FLAGS.train_steps,monitors=[validation_monitor])\n  File \"wide-batch.py\", line 180, in input_fn\n    inputs = tf.contrib.learn.read_batch_examples([FLAGS.train], 256, tf.TextLineReader,num_epochs=1,queue_capacity=10000, parse_fn=parse_fn)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/graph_io.py\", line 82, in read_batch_examples\n    read_batch_size=read_batch_size, parse_fn=parse_fn, name=name)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/graph_io.py\", line 210, in read_keyed_batch_examples\n    allow_smaller_final_batch=allow_smaller_final_batch)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/input.py\", line 899, in shuffle_batch_join\n    tensor_list_list = _validate_join(tensor_list_list)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/input.py\", line 421, in _validate_join\n    for tl in tensor_list_list]\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 737, in convert_n_to_tensor_or_indexed_slices\n    as_ref=as_ref))\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 698, in convert_to_tensor_or_indexed_slices\n    return convert_to_tensor(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 621, in convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 630, in _autopacking_conversion_function\n    return _autopacking_helper(v, inferred_dtype, name or \"packed\")\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 572, in _autopacking_helper\n    \"%s to %s (Tensor is: %r)\" % (elem.dtype, dtype, elem))\nTypeError: Cannot convert a list containing a tensor of dtype <dtype: 'string'> to <dtype: 'float32'> (Tensor is: <tf.Tensor 'read_batch_examples/read/DecodeCSV:1' shape=() dtype=string>)`\n", "comments": ["Can you follow the example here and see if it works for you? http://stackoverflow.com/questions/37091899/how-to-actually-read-csv-data-in-tensorflow\n", "Closing automatically due to lack of recent activity. Please reopen when further information becomes available. Thank you.\n", "I would think this makes more sense : https://stackoverflow.com/questions/43674569/is-there-a-general-way-to-set-the-record-defaults-for-tf-decode-csv"]}, {"number": 4440, "title": "GradientChecker file not found", "body": "link - https://github.com/tensorflow/tensorflow/tree/r0.10/tensorflow/python/kernel_tests/gradient_checker.py\n\nrefered in -\nhttps://www.tensorflow.org/versions/r0.9/how_tos/adding_an_op/index.html#define-the-ops-interface\n", "comments": ["Thanks for reporting. @martinwicke could you take a look at this? Thanks.\n", "@jmchen-g @martinwicke what is the status? I'm interested in this too.\n", "This appears to already be resolved. Thanks!"]}, {"number": 4439, "title": "tensorflow add new op : could attr accept  scalar tensor ? ", "body": "In  https://www.tensorflow.org/versions/r0.10/how_tos/adding_an_op/index.html  \n, I can't find detail doc about this,   could anyone  give   more detail info?   \n", "comments": ["I answered this on [Stack Overflow](http://stackoverflow.com/a/39563531/3574081).\n"]}, {"number": 4438, "title": "tf.import_graph_def() requires a non-empty name", "body": "After updating version of tenserflow  there is now an issue when loading with my old models. \n\n./importer.py\", line 241, in import_graph_def\n    raise ValueError('tf.import_graph_def() requires a non-empty `name` '\nValueError: tf.import_graph_def() requires a non-empty `name` if `input_map` is used.\n\nThe same is case when i try colorize model colorize-20160110\n\nhow to fix this. The code is given below\nimport tensorflow as tf\nimport skimage.transform\nfrom skimage.io import imsave, imread\n\ndef load_image(path):\n    img = imread(path)\n    # crop image from center\n    short_edge = min(img.shape[:2])\n    yy = int((img.shape[0] - short_edge) / 2)\n    xx = int((img.shape[1] - short_edge) / 2)\n    crop_img = img[yy : yy + short_edge, xx : xx + short_edge]\n    # resize to 224, 224\n    img = skimage.transform.resize(crop_img, (224, 224))\n    # desaturate image\n    return (img[:,:,0] + img[:,:,1] + img[:,:,2]) / 3.0\n\nshark_gray = load_image(\"shark.jpg\").reshape(1, 224, 224, 1)\n\nwith open(\"colorize.tfmodel\", mode='rb') as f:\n    fileContent = f.read()\n\ngraph_def = tf.GraphDef()\ngraph_def.ParseFromString(fileContent)\ngrayscale = tf.placeholder(\"float\", [1, 224, 224, 1])\ntf.import_graph_def(graph_def, input_map={ \"grayscale\": grayscale }, name='')\n\nwith tf.Session() as sess:\n    inferred_rgb = sess.graph.get_tensor_by_name(\"inferred_rgb:0\")\n    inferred_batch = sess.run(inferred_rgb, feed_dict={ grayscale: shark_gray })\n    imsave(\"shark-color.jpg\", inferred_batch[0])\n    print (\"saved shark-color.jpg\")\n", "comments": ["The old version of `tf.import_graph_def()` was broken if you specified both `input_map` and `name=''`. It looks like the fix is quite easy for your case, though. Simply remove the explicit `name=''` (which is not recommended, since it can lead to unpredictable names for the imported nodes), and use `return_elements=[\"inferred_rgb:0\"]` to get the `inferred_rgb` tensor as a return value from `tf.import_graph_def()`:\n\n``` python\n# [...]\ngraph_def = tf.GraphDef()\ngraph_def.ParseFromString(fileContent)\ngrayscale = tf.placeholder(tf.float32, [1, 224, 224, 1])\ninferred_rgb, = tf.import_graph_def(graph_def, input_map={\"grayscale\": grayscale },\n                                    return_elements=[\"inferred_rgb:0\"])\n\nwith tf.Session() as sess:\n  inferred_batch = sess.run(inferred_rgb, feed_dict={grayscale: shark_gray})\n  imsave(\"shark-color.jpg\", inferred_batch[0])\n  print (\"saved shark-color.jpg\")\n```\n", ">@mrry  Simply remove the explicit name='' (which is not recommended, since it can lead to unpredictable names for the imported nodes)\r\n\r\nI was looking over the code i [think](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/importer.py)  trying to find out why my retrained graph is reporting a miss mach in labels and tensor objects, and saw that the name **karg was set default to None. If this variable is not encapsulated should its state ever be able to put it in a state of error? could we call it code cleanup to set the default name to a empty string or are we expecting unicode?  \r\n\r\n\r\n\r\ni know this is a old post but i was thinking about adding some debug information to the function and wanted to see if i should include this aspect... ", "@fenderrex I'm not sure I understand your question. The default behavior when `name=None` is to add a prefix of `\"import\"` (perhaps with a suffix of `\"_1\"`, `\"_2\"`, etc. if that prefix has already been used). If there's a particular change you'd suggest, feel free to open a new issue describing it, and we'll take a look!"]}, {"number": 4437, "title": "why there are no documents about tf.nn.seq2seq   ", "body": "the file tensorflow/python/ops/seq2seq contains models like tf.nn.seq2seq.embedding_attention_seq2seq, but there are not any documentation about these models in the online documentation (https://www.tensorflow.org/versions/r0.10/api_docs/python/nn.html#neural-network)\n\nor there is but i didn't find it?\n", "comments": ["@lukaszkaiser Could you take a look at this? Thanks.\n", "The seq2seq module does not use the dynamic unrolling functions. We need a new module that uses them, and it will probably have a new API and the current seq2seq will be deprecated. That's why we're not documenting it -- because we're not committing to this API and it might go away.\n"]}, {"number": 4436, "title": "How to restore the model when use distributed  tensorflow ??", "body": "I write a simple distributed tensorflow example, the code is here:\nhttps://github.com/thewintersun/distributeTensorflowExample\n\nI use 2 server as the ps server, 2 server as the worker server. \n**The command is as follow:**\n**At ps server:**\n\nCUDA_VISIBLE_DEVICES='' python distribute.py --ps_hosts=192.168.100.42:2222,192.168.100.22:2223 --worker_hosts=192.168.100.30:2224,192.168.100.253:2225 --job_name=ps --task_index=0\n\nCUDA_VISIBLE_DEVICES='' python distribute.py --ps_hosts=192.168.100.42:2222,192.168.100.22:2223 --worker_hosts=192.168.100.30:2224,192.168.100.253:2225 --job_name=ps --task_index=1\n\n**At worker server:**\n\nCUDA_VISIBLE_DEVICES=0 python distribute.py --ps_hosts=192.168.100.42:2222,192.168.100.22:2223 --worker_hosts=192.168.100.30:2224,192.168.100.253:2225 --job_name=worker --task_index=0\n\nCUDA_VISIBLE_DEVICES=0 python distribute.py --ps_hosts=192.168.100.42:2222,192.168.100.22:2223 --worker_hosts=192.168.100.30:2224,192.168.100.253:2225 --job_name=worker --task_index=1\n\n**The train process is ok.\n## But when I stop the chief worker process and restart it ,  I expect the program will restore the model from the checkpoint file , but it print the following error and exit :**\n\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:839] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 970, pci bus id: 0000:01:00.0)\nI tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {192.168.100.42:2222, 192.168.100.22:2223}\nI tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {localhost:2224, 192.168.100.253:2225}\nI tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2224\nE tensorflow/core/client/tensor_c_api.cc:485] Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./checkpoint/model.ckpt-0\n         [[Node: save/restore_slice_2 = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=\"/job:ps/replica:0/task:1/cpu:0\"](_recv_save/Const_0_S1, save/restore_slice_2/tensor_name, save/restore_slice_2/shape_and_slice)]]\nTraceback (most recent call last):\n  File \"distribute.py\", line 77, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"distribute.py\", line 60, in main\n    with sv.managed_session(server.target) as sess:\n  File \"/usr/lib/python2.7/contextlib.py\", line 17, in **enter**\n    return self.gen.next()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 942, in managed_session\n    self.stop(close_summary_writer=close_summary_writer)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 768, in stop\n    stop_grace_period_secs=self._stop_grace_secs)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py\", line 357, in join\n    six.reraise(*self._exc_info_to_raise)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 931, in managed_session\n    start_standard_services=start_standard_services)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 680, in prepare_or_wait_for_session\n    init_feed_dict=self._init_feed_dict, init_fn=self._init_fn)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py\", line 164, in prepare_session\n    max_wait_secs=max_wait_secs, config=config)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py\", line 224, in recover_session\n    saver.restore(sess, ckpt.model_checkpoint_path)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1129, in restore\n    {self.saver_def.filename_tensor_name: save_path})\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 382, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 655, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 723, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 743, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./checkpoint/model.ckpt-0\n         [[Node: save/restore_slice_2 = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=\"/job:ps/replica:0/task:1/cpu:0\"](_recv_save/Const_0_S1, save/restore_slice_2/tensor_name, save/restore_slice_2/shape_and_slice)]]\nCaused by op u'save/restore_slice_2', defined at:\n  File \"distribute.py\", line 77, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"distribute.py\", line 49, in main\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 861, in __init__\n    restore_sequentially=restore_sequentially)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 519, in build\n    filename_tensor, vars_to_save, restore_sequentially, reshape)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 272, in _AddRestoreOps\n    values = self.restore_op(filename_tensor, vs, preferred_shard)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 187, in restore_op\n    preferred_shard=preferred_shard)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/io_ops.py\", line 203, in _restore_slice\n    preferred_shard, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 359, in _restore_slice\n    preferred_shard=preferred_shard, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2310, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1232, in __init__\n##     self._traceback = _extract_stack()\n\nIs anyone can tell me how to restore the model when use distribute tensorflow??\n", "comments": ["the error is :\nE tensorflow/core/client/tensor_c_api.cc:485] Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./checkpoint/model.ckpt-0\n\nbut at position \" ./checkpoint/model.ckpt-0\" , the file is exist.\n", "@mrry \n", "I discovered when I run the ps process at a machine and run the worker chief process at another machine , then the problem will occur.\n\nBut if I run the ps process and the worker chief process at the same machine,  the chief worker process will  reload the model from the checkpoint file success. \n\nI don't know why is this ?\n\nIs anyone can give a reply? thank you.\n", "I am facing the same problem. I suppose that is /job:ps/.. and /job:worker/.. on the same machine would be translated to /job:lcoalhost/....... But It still be translated to /job:localhost even your ps is another machine, so the saver.restore can not find the right ps==localhost . I am trying on freeze_graph function. PS.still have no success\n", "@arg0 I don't think that is the real problem. This is something I also see on my machine (the hostname is translated into \"localhost\" if it matches the IP of the machine) and check-pointing works fine there. Are you using the r0.10 release candidate?\n\n@thewintersun can you replicate the problem with only one worker? Are you using a shared network filesystem such that all nodes can access the checkpoint directory (and read from it)?\n", "Usually the summary is written by the chief worker to some dir and when it restores, the ps need to be able to locate and have access to that dir also. Is it the case for you guys?\n", "@hholst80 \n1. If use only one worker, the problem is the same , still can not reload the model at the chief worker if the chief worker and the ps not run at the same machine. \n2. I am not using a shared network filesystem. But I think there is not need a shared network system. \n", "@jmchen-g \nyes.\n\nIt seems that the ps can not find the checkpoint file.\n\nI guess when the chief worker reload the model , the worker notify the ps to reload paramter value from the same checkpoint dir .\n\nIs that means the chief worker and ps must in the same machine ???\n", "@thewintersun Are you still having problems with this?\n", "@tatatodd \nyes, still have this problem\n", "@thewintersun I believe you need to use a shared network filesystem, so that the PS can read the checkpoints that were written by the chief.  You do not need to run the chief and ps on the same machine; a shared filesystem is enough.\n\n@concretevitamin will know for sure.\n", "@tatatodd  ok\n", "Todd is exactly correct (try using HDFS)  :)\n\nOn Fri, Oct 7, 2016 at 6:29 PM, thewintersun notifications@github.com\nwrote:\n\n> @tatatodd https://github.com/tatatodd ok\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/4436#issuecomment-252394023,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AAkLHqJpszmzfx3tiObcGLPfd0P4lLvyks5qxvITgaJpZM4J_2nm\n> .\n", "@concretevitamin  \nis the tensorflow already support the HDFS?\n", "@thewintersun hdfs has been supported by the latest version(r0.11) of tf. Check this [How to run tensorflow on hadoop](https://www.tensorflow.org/versions/r0.11/how_tos/hadoop/index.html#how-to-run-tensorflow-on-hadoop) plz.\n", "@thewintersun I hope this answers your question.  I'm closing this out, but feel free to comment on this issue or file a new issue if you still run into problems.  Thanks!\n"]}, {"number": 4435, "title": "Fix cmake files for highwayhash and re2.", "body": "Tested via the following:\n$ cd tensorflow/contrib/cmake\n$ mkdir build\n$ cd build\n$ cmake ..\n$ make\n", "comments": ["@gunan, thanks for your PR! By analyzing the annotation information on this pull request, we identified @lilac, @ageron and @mrry to be potential reviewers\n", "Jenkins, test this please.\n"]}, {"number": 4434, "title": "Why is quantized graph inference takes much more time than using the original graph?", "body": "I followed this [tutorial](https://www.tensorflow.org/versions/r0.10/how_tos/quantization/index.html) in order to quantize my graph into 8 bit.I can't share the exact graph here but i can say it's a simple convolutional neural network.\n\nWhen i run the [benchmark tool](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/benchmark) over the original and quantized networks it's clear that the quantized network is much much slower (100 ms vs. 4.5 ms).\n\nSlowest nodes in original network :\n\n```\ntime average [ms]   [%] [cdf%]  [Op]    [Name]\n1.198   26.54%  26.54%  MatMul  fc10/fc10/MatMul\n0.337   7.47%   34.02%  Conv2D  conv2/Conv2D\n0.332   7.36%   41.37%  Conv2D  conv4/Conv2D\n0.323   7.15%   48.53%  Conv2D  conv3/Conv2D\n0.322   7.14%   55.66%  Conv2D  conv5/Conv2D\n0.310   6.86%   62.53%  Conv2D  conv1/Conv2D\n0.118   2.61%   65.13%  Conv2D  conv2_1/Conv2D\n0.105   2.32%   67.45%  MaxPool pool1\n```\n\nSlowest nodes in quantized network :\n\n```\ntime average [ms]   [%] [cdf%]  [Op]    [Name]\n8.289   47.67%  47.67%  QuantizedMatMul fc10/fc10/MatMul_eightbit_quantized_bias_add\n5.398   5.33%   53.00%  QuantizedConv2D conv5/Conv2D_eightbit_quantized_conv\n5.248   5.18%   58.18%  QuantizedConv2D conv4/Conv2D_eightbit_quantized_conv\n4.981   4.92%   63.10%  QuantizedConv2D conv2/Conv2D_eightbit_quantized_conv\n4.908   4.85%   67.95%  QuantizedConv2D conv3/Conv2D_eightbit_quantized_conv\n3.167   3.13%   71.07%  QuantizedConv2D conv5_1/Conv2D_eightbit_quantized_conv\n3.049   3.01%   74.08%  QuantizedConv2D conv4_1/Conv2D_eightbit_quantized_conv\n2.973   2.94%   77.02%  QuantizedMatMul fc11/MatMul_eightbit_quantized_bias_add\n```\n\nWhat is the reason for that ? \nIs it the expected behavior for quantized network ?\n### Environment info\n\nOperating System: Ubuntu 16.04\nInstalled from source, without GPU support :\n1. commit hash = 37256f4\n2. bazel version = \nBuild label: 0.3.1\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Fri Jul 29 09:09:52 2016 (1469783392)\nBuild timestamp: 1469783392\nBuild timestamp as int: 1469783392\n", "comments": ["Is it just the first run or consistently slow for many inferences?\n", "Im using the benchmark tool, which run several inferences.\nI also ran it several times and get the same results.\n\nOn Tue, Sep 20, 2016, 03:25 Jianmin Chen notifications@github.com wrote:\n\n> Is it just the first run or consistently slow for many inferences?\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/4434#issuecomment-248167422,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AGN1ANVdeD91M8ThW5gAZKAYLL4HH6I9ks5qrygHgaJpZM4J_0eh\n> .\n", "i will list few simple steps to reproduce the same behavior with inception graph :\n1. run my script [classify_image.py](https://gist.github.com/yossibiton/ba571473470824e5fee47c555d01697b) - basically i took [this script](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/imagenet/classify_image.py) and added small changed to support quantized graph and timing. \n   It will download the inception graph file and then run forward pass 100 times over an image. I got **average time per forward pass = 785 [ms]**\n2. now we will quantize the graph and replace the original graph file (run from you tensorflow repository folder)\n   `python tensorflow/contrib/quantization/tools/quantize_graph.py --input=/tmp/imagenet/classify_image_graph_def.pb --output_node_names=\"softmax\" --output=/tmp/imagenet/classify_image_graph_q_def.pb --mode=eightbit`\n3. we will replace the original graph file with the quantized one :\n\n```\nmv /tmp/imagenet/classify_image_graph_def.pb /tmp/imagenet/backup_classify_image_graph_def.pb\nmv /tmp/imagenet/classify_image_graph_q_def.pb /tmp/imagenet/classify_image_graph_def.pb \n```\n1. running 'classify_image.py' again (now the quantized graph will be used). \n   This time i got **average time per forward pass = 6551 [ms]**\n   That means the quantized graph is about **10x slower**\n", "Actually this has been reported several times before, see here: https://github.com/tensorflow/tensorflow/issues/2807  I've also found the same issue when I played around with 8-bit quantisation. So far it seems that the matrix multiplication as a core operation in the convolution is not optimised yet. It was mentioned in this thread that they are actively working on the problem https://github.com/tensorflow/tensorflow/issues/1592 Since 8-bit quantisation was also mentioned in their new paper on machine translation, I'd expect that the optimised version is being released soon (but this is just an educated guess) \n", "@petewarden Could you take a look? Thanks.\n", "+1 on this. Any progress? We're also seeing slower performance on CPU.\n", "@jmchen-g  @chenliu0831  have your benchmark done on mobile devices ? ", "@austingg Our iOS developer didn't end up benchmarking it given those issues. Instead we are looking into metal to reconstruct the network with trained weight", "@chenliu0831 great. Metal use gpu, but support only limited operator. ", "I'm running into this issue also, not only is the network 4 times slower, but it doesn't actually work anymore. I haven't measured the accuracy, but it's a pose estimation algorithm, so I don't need to measure the accuracy to see that it's no longer estimating the pose.", "@mddrill have you solved your problem? I ran into the same situation ", "@clumsydzd no I was never able to figure it out.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Hello, I have a similar problem too. I cannot observe any difference between my optimised graph and my quantised graph in terms of run time. Were you able to solve your problem? Thanks. ", "Nope. Was never able to do it.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "@petewarden @suharshs any comment? Thanks!", "From https://github.com/tensorflow/tensorflow/issues/2807:\r\n\r\nWe are focusing our eight-bit efforts on TF Lite (visible at tensorflow/contrib/lite), so we aren't expecting TensorFlow's quantized performance to improve in cases where it's not currently fast. These tend to be on x86 platforms (we're concentrating on ARM performance for mobile), and for models that use ops that we don't have quantized implementations for (which is most models outside a few vision-related ones we've optimized for).\r\n\r\nSince we're not likely to see changes in this area soon, I'm closing this as infeasible. Pull requests or other help in this area would be very welcome of course!", "@isabel-schwende -- can you please tell me which machine translation paper. I want to see. thanks", "There's a section in this paper from 2016 on how they used 8-bit quantization for machine translation https://arxiv.org/abs/1609.08144 ", "Seems that the quantized model is faster on machine with AVX/AVX2 CPU, and tensorflow was built to support AVX/AVX2."]}, {"number": 4433, "title": "Add a collections attribute to node_def", "body": "This updates add_to_collection method in the Python API to update (or create) a ListValue of `collections` in the attr map of each node def. This has been prescribed by @jameswex to solve Issue #3495, in order to have tensorboard show the collections that a node belongs to in the node info box.\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for proposing this change. From my reading of issue #3495, it looks like we already have a more general representation for graph collections, in the [`MetaGraphDef.collection_def`](https://github.com/tensorflow/tensorflow/blob/7df9c6860e00b91eda0e550b11d9be52d9341d85/tensorflow/core/protobuf/meta_graph.proto#L65) field, and a better solution would be to enhance the graph visualizer so that it could accept `MetaGraphDef` protocol buffers in addition to `GraphDef` protos. Since a `MetaGraphDef` includes a `GraphDef` as one of its fields, this should not be too difficult.\n\nI'm going to close this PR now, but we'd be glad to review a contribution that re-uses the existing tools for representing graph collections in the `MetaGraphDef`.\n"]}, {"number": 4432, "title": "wrong tf.control_dependencies using tf.case  and tf.cond", "body": "add tf.control_dependencies in one branch of tf.case infulunce the other brach:\ntf version: rc10\n\nas we can see below, the tfvar is increasing no mather brach f1 or f2 is executed\nchange tf.case to tf.cond will get the same output.\n\n`def testTF_case_with_control_dependencies():\n\n```\nisTraining=tf.placeholder(tf.bool,shape=[])\ntfvar=tf.Variable(tf.constant(0),tf.int32);\n\nincrease_tfvar_op=tf.assign_add(tfvar.ref(), 1);\n\nsess=tf.Session()\nsess.run(tf.initialize_all_variables())\n\ndef f1():\n    print ('f1')\n    with tf.control_dependencies([increase_tfvar_op]):\n        return -tfvar;  #if return tfvar directly, no control_dependencies is added\n\ndef f2():\n    print('f2')\n    with tf.control_dependencies([]):\n        return tfvar*10;\ncaseResult = tf.case([(isTraining, f1)], default=f2)\n\nb=True;\nfor t in range(4):\n    b=not b;\n    print('\\n------')\n    print('isTraining: ',end='')\n    print(b)\n    beforeCase=sess.run(tfvar)\n    print('\\ttfvar before run case: %d'%beforeCase)\n    r=sess.run(caseResult,feed_dict={isTraining:b})\n    print('case result:%d'%r)\n    aftercase=sess.run(tfvar)\n    print('\\ttfvar after run case: %d'%aftercase)`\n```\n\noutput:\nf2\nf2\nf1\n\n---\n\nisTraining: False\n    tfvar before run case: 0\ncase result:10\n    tfvar after run case: 1\n\n---\n\nisTraining: True\n    tfvar before run case: 1\ncase result:-2\n    tfvar after run case: 2\n\n---\n\nisTraining: False\n    tfvar before run case: 2\ncase result:30\n    tfvar after run case: 3\n\n---\n\nisTraining: True\n    tfvar before run case: 3\ncase result:-4\n    tfvar after run case: 4\n", "comments": ["I believe this is similar to the cond() and you can find the explanation here: https://www.tensorflow.org/versions/r0.10/api_docs/python/control_flow_ops.html#cond\n\nBasically the increase op will always run in both cases.\n", "@jmchen-g thanks,  but the document is not consistent with the actual behavier.\n\nset b to False, and add tf.Print to f1() will get no output at all, which means f1 is not invoked when the condition is False.\n\nthe changed f1():\n\n```\ndef f1():\n    print ('f1')\n    with tf.control_dependencies([increase_tfvar_op]):\n        return tf.Print(-tfvar, data=[tfvar]) ;\n```\n", "This is how cond works, here's some explanation -- http://stackoverflow.com/questions/37063952/confused-by-the-behavior-of-tf-cond/37064128#37064128\n\nBasically it's how TensorFlow runtime works:\n- increase_tfvar_op is a dependency of f1\n- f1 and f2 are dependencies of cond\n- therefore increase_tfvar_op is a dependency of cond\n\nDependencies must be computed before tf.cond is ready to execute. It's smart enough to figure out that f1 doesn't need to be executed, but not smart enough to figure out that increase_tfvar_op doesn't need to be. \n", "@yaroslavvb thanks for you explanation~  \nI follow the stackoverflow solution and it works.\n\n**Just move the dependency into f1()!!!**  \n\nFor the convenience of other people, the correct version is :+1: \n`def testTF_case_with_control_dependencies():\n\n```\nisTraining=tf.placeholder(tf.bool,shape=[])\ntfvar=tf.Variable(tf.constant(0),tf.int32);\n\n#increase_tfvar_op=tf.assign_add(tfvar.ref(), 1); #this line is moved to f1()\n\nsess=tf.Session()\nsess.run(tf.initialize_all_variables())\n\ndef f1():\n    print ('f1')\n    increase_tfvar_op=tf.assign_add(tfvar.ref(), 1);\n    with tf.control_dependencies([increase_tfvar_op]):\n        return -tfvar;  #if return tfvar directly, no control_dependencies is added\n\ndef f2():\n    print('f2')\n    with tf.control_dependencies([]):\n        return tfvar*10;\ncaseResult = tf.case([(isTraining, f1)], default=f2)\n\nb=True;\nfor t in range(4):\n    b=not b;\n    print('\\n------')\n    print('isTraining: ',end='')\n    print(b)\n    beforeCase=sess.run(tfvar)\n    print('\\ttfvar before run case: %d'%beforeCase)\n    r=sess.run(caseResult,feed_dict={isTraining:b})\n    print('case result:%d'%r)\n    aftercase=sess.run(tfvar)\n    print('\\ttfvar after run case: %d'%aftercase)`\n```\n"]}]