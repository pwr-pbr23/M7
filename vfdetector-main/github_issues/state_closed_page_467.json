[{"number": 39801, "title": "Sparse Categorical CrossEntropy in Google Collab", "body": "https://pastebin.com/efb18WPB\r\nI've been in trouble when configure the model.compile and model.fit in Google Collaboratory.\r\nI want my model in\r\n- Divided into train set and validation set\r\n- Implement image augmentation\r\n- Use Image Data Generator\r\n- Sequential Model and using more than 1 hidden layer\r\n- Training the model in max 30 minutes\r\n- Accuracy min 85%\r\n- Could predict picture if we upload it.\r\n\r\nI've been new in this ML. Please help me ASAP. Thankyou for your participation.", "comments": ["@zerowu49 As far your code is concerned, there are two changes you need to make here, one is change the loss function,\r\n\r\n`loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()`\r\n\r\nAnd another change would be to change the input_shape from `(150, 150, 3)` to `(200, 250, 3)` because in your data generator you have specified your target shape as `(200,, 250)`\r\n\r\n`tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(200, 250, 3))`", "@zerowu49,\r\nPlease check @abhipn's comment and let us know if it works.\r\n\r\nI was able to run the code without any issues after making the suggested changes, please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/de056e4a4acc9dae035cb8aa635cf915/39801.ipynb). Thanks!", "> \r\n> \r\n> @zerowu49 As far your code is concerned, there are two changes you need to make here, one is change the loss function,\r\n> \r\n> `loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()`\r\n> \r\n> And another change would be to change the input_shape from `(150, 150, 3)` to `(200, 250, 3)` because in your data generator you have specified your target shape as `(200,, 250)`\r\n> \r\n> `tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(200, 250, 3))`\r\n\r\nThankyou, the model works. But how to optimize the model here?", "@zerowu49 One major change you need to make would be not use data augmentation techniques on validation dataset, you should only do that for train data. You can use rescale `normalization` for validation data like below,\r\n\r\n`\r\ntest_datagen = ImageDataGenerator(rescale=1./255,)\r\n`\r\n\r\nApart from that, try out different filter sizes, layers, activations, learning rate, epochs, batch size etc., to optimize your model. You have to try and find best hyperparameters that results in best accuracy. There's no fixed correct answer here. Good luck.", "@zerowu49,\r\nIs this still an issue? Please feel free to close the issue if resolved. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 39800, "title": "how to multi scale train using tf.data.dataset", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n", "comments": ["@fengxiuyaun \r\nPlease refer to [this link](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras) and [link2](https://stackoverflow.com/questions/52161605/tensorflow-multi-scale-training )let us know if it helps.", "> @fengxiuyaun\r\n> Please refer to [this link](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras) and [link2](https://stackoverflow.com/questions/52161605/tensorflow-multi-scale-training)let us know if it helps.\r\n \r\nthank you very much. Please show me a example?\r\n", "I don't know how to load dif size pictures of dif batch using tf.data.dataset. eg, 1th batch, picture size is 256,; 2th batch, size is 384..... ", "@fengxiuyaun \r\nCan you check [this link](https://stackoverflow.com/questions/49641098/tensorflow-dataset-batch-not-showing-the-real-batch-size) [link1](https://adventuresinmachinelearning.com/tensorflow-dataset-tutorial/) [link2](https://www.kaggle.com/jalammar/intro-to-data-input-pipelines-with-tf-data) [link3](https://towardsdatascience.com/how-to-use-dataset-in-tensorflow-c758ef9e4428) and let us know.", "> @fengxiuyaun\r\n> Can you check [this link](https://stackoverflow.com/questions/49641098/tensorflow-dataset-batch-not-showing-the-real-batch-size) [link1](https://adventuresinmachinelearning.com/tensorflow-dataset-tutorial/) [link2](https://www.kaggle.com/jalammar/intro-to-data-input-pipelines-with-tf-data) [link3](https://towardsdatascience.com/how-to-use-dataset-in-tensorflow-c758ef9e4428) and let us know.\r\n\r\nno help", "@fengxiuyaun Please post this question on stackoverflow as this issue is not related to bug/performance, build/install or feature request related issues. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n"]}, {"number": 39799, "title": "exclude_col parameter in CSVDataset.", "body": "Resolves #39069.\r\nAdds an optional parameter exclude_col in tf.data.experimental.CsvDataset.\r\nSigned-off-by: Steenu Johnson <steenu.johnson@students.iiserpune.ac.in>", "comments": ["@rachellim could you please review? thanks", "@rachellim Yes. If total_cols is calculated from user\u00a0specified record_defaults and exclude_cols, some possible errors are not\u00a0handled.\r\nFor example, if total_cols as calculated above is less than the actual number of columns, all columns>total_cols will be excluded. If len(select_cols) equals len(record_defaults), no error will be raised but the purpose of exclude_cols is not met in this case.", "@rachellim Thanks for your suggestion. I am working on it. I have a couple of questions here. \r\n1.Suppose the CSV have 10 columns, all having integer values. User specifies record defaults = [tf.int32]*3 and exclude_cols = [2,3]. What is the expected behaviour of CSVDataset in this case? Should it throw an error or only select columns [1,4,5]?\r\n 2. If it selects columns [1,4,5], then select_cols and exclude_cols will be mutually exclusive but would not be complements. Is this fine? Or if it does throw an error, could you please point me to the implementation where this is being handled? \r\nThanks for your time again.\r\n", "@rachellim Yes. I agree. exclude_cols would be more useful if the user do not have to specify record_defaults. Can you please check on the original issue to confirm user expectations and guide me through the next steps? ", "@rachellim Can you please assist on above comments from @stjohnso98. Thanks!", "Yup - @stjohnso98, I've commented on the original issue at #39069 -- feel free to add to that discussion as well if you have further thoughts. Thanks!", "Looks like we've gotten a response on the original issue. I think adding `exclude_cols` as a python param on CsvDataset makes sense, and we should raise an error if the number of columns in the CSV file doesn't match the expected based on `record_defaults`. I believe CsvDataset already does this error checking, but would be good to double check (e.g. adding a unit test for this case if it doesn't already exist). \r\n\r\n@stjohnso98 let me know if you have further questions!", "@rachellim Sorry. I am a bit confused. Please correct me if i am wrong. In CsvDataset, record_default is a list of default dtypes, where each element corresponds to a selected column. Hence when select_cols is specified, len(record_defaults) should equal len(select_cols). It raises an error only when this criteria is not met. In the above case I mentioned when select_cols is derived from exclude_cols and a possibly mistaken length of record_default, the len(record_defaults) equals len(select_cols) and it doesn't raise an error in this case. ", "Thanks for your suggestions. I will make these changes.", "@rachellim Thanks for your comments. I have made the requested changes. Can you please review it again? Please let me know if there is anything wrong or in case I am missing something regarding the backward and forward compatibility changes. \r\nAlso, I am not clear on the 3 weeks forward compatibility check. Could you please tell me what is expected of CSVDataset and exclude_cols when the forward compatibility window has not expired?", "The forward compatibility window largely applies to the nightly build (and the internal build within google). When the window hasn't expired, we go through the `else` codepath, i.e. use the old version of the op. ", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39799) for more info**.\n\n<!-- need_author_cla -->", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39799) for more info**.\n\n<!-- cla_yes -->", "Overrided CLA status because the github commit was associated with the wrong email (my personal email instead of my google.com email)", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39799) for more info**.\n\n<!-- need_author_cla -->", "@rachellim Thanks for your review. I have made the other changes as well. Can you please review it again?\r\nAlso, the cla issue happened again. \r\nThanks.", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39799) for more info**.\n\n<!-- cla_yes -->", "Overrided CLA status because the github commit was associated with the wrong email (my personal email instead of my google.com email)", "@stjohnso98, looks like some checks are failing. You'll have to add an api_def_CSVDatasetV2.pbtxt file for the failing `//tensorflow/core/api_def:api_test` test. You can base it on https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/api_def/base_api/api_def_CSVDataset.pbtxt\r\n\r\nYou'll also have to update golden apis for the api_compatibility_test to pass. You can do so as follows:\r\n```\r\n    $ bazel build tensorflow/tools/api/tests:api_compatibility_test\r\n    $ bazel-bin/tensorflow/tools/api/tests/api_compatibility_test \\\r\n          --update_goldens True\r\n```\r\n\r\nThanks!", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39799) for more info**.\n\n<!-- need_author_cla -->", "@rachellim Thanks for your comment. I have made the suggested changes. Can you please review it again?\r\nAlso cla status has changed. Apologies to bring it up again.", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39799) for more info**.\n\n<!-- cla_yes -->", "No worries! Thanks for the fix :)", "All checks have passed. Why is the merging delayed? ", "> All checks have passed. Why is the merging delayed?\r\n\r\n@stjohnso98  It is processing internally. Thanks!"]}, {"number": 39797, "title": "Using Sequence as validation data in Model.fit", "body": "According to the documentation, Model.fit_generator is deprecated now in favor of Model.fit, which now supports Sequence and generators. However, the doc also states that Sequence object cannot be used for the validation set. Is there any plan to add support to enable the use of Sequence or other custom generators in the future?\r\n", "comments": ["This would be a very useful feature. I think that is counterintuitive to use your `x` data as `tf.keras.Sequence` and your `validation_data` as a `tuple` or `tf.data.Dataset`. And,  I didn't find any tutorial of how to porting codes that use`tf.keras.Sequence` to `tf.data.Dataset`, and it does not seem to be easy enough to justify the lack of a guide about how to do this migration. If `tf.keras.Sequence` is not deprecated, why `validation_data` argument in `tf.keras.fit()` cannot support it?", "> And, I didn't find any tutorial of how to porting codes that use tf.keras.Sequence to tf.data.Dataset, and it does not seem to be easy enough to justify the lack of a guide about how to do this migration.\r\n\r\nI deleted my former response here because I checked the code since then. Validator does no longer support Sequence, that is indeed true. However there is a quick and easy solution to the port problem from Sequence to Dataset API for the Validator set, although in my eye it is not a clean one, because you return to Datasets and their disadvantages (also it might fail for some use cases): \r\n\r\n- Take `tf.keras.Sequence` subclass\r\n- Create a new `tf.data.Dataset` by using [`tf.data.Dataset.from_generator`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator). `tf.keras.Sequence` has implemented the iter interface (i.e.` __iter__` with yield) so you can just pass that as the generator for the dataset..", "I think we have implemented the support for all the data types, and you can use Sequence for validation_data as well. Basically training data and validation data have the same set of supported types.\r\n\r\nThe docstring will be updated in https://github.com/tensorflow/tensorflow/pull/38979. Closing this bug since it working as intended."]}, {"number": 39796, "title": "Spleeter error", "body": "Hey, this is the error i get (at the bottom) it seems like everything runs smoothly until you see a dll error pop up in the lines, then a few more times further down..if anyone knows what to do, let me know. thanks\r\n\r\nStarting processing of all songs\r\nProcessing E:\\Hoodie chasing forever\\y2mate.com - Hoodie Allen - King To Me_HKYBI6ybN8s.mp3\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\mgood\\AppData\\Roaming\\SpleeterGUI\\python\\Lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\mgood\\AppData\\Roaming\\SpleeterGUI\\python\\Lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\mgood\\AppData\\Roaming\\SpleeterGUI\\python\\Lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"D:\\obj\\windows-release\\37amd64_Release\\msi_python\\zip_amd64\\imp.py\", line 242, in load_module\r\n  File \"D:\\obj\\windows-release\\37amd64_Release\\msi_python\\zip_amd64\\imp.py\", line 342, in load_dynamic\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\nDuring handling of the above exception, another exception occurred:\r\nTraceback (most recent call last):\r\n  File \"D:\\obj\\windows-release\\37amd64_Release\\msi_python\\zip_amd64\\runpy.py\", line 193, in _run_module_as_main\r\n  File \"D:\\obj\\windows-release\\37amd64_Release\\msi_python\\zip_amd64\\runpy.py\", line 85, in _run_code\r\n  File \"C:\\Users\\mgood\\AppData\\Roaming\\SpleeterGUI\\python\\Lib\\site-packages\\spleeter\\__main__.py\", line 58, in <module>\r\n    entrypoint()\r\n  File \"C:\\Users\\mgood\\AppData\\Roaming\\SpleeterGUI\\python\\Lib\\site-packages\\spleeter\\__main__.py\", line 54, in entrypoint\r\n    main(sys.argv)\r\n  File \"C:\\Users\\mgood\\AppData\\Roaming\\SpleeterGUI\\python\\Lib\\site-packages\\spleeter\\__main__.py\", line 36, in main\r\n    enable_logging()\r\n  File \"C:\\Users\\mgood\\AppData\\Roaming\\SpleeterGUI\\python\\Lib\\site-packages\\spleeter\\utils\\logging.py\", line 60, in enable_logging\r\n    tf_logger = get_tensorflow_logger()\r\n  File \"C:\\Users\\mgood\\AppData\\Roaming\\SpleeterGUI\\python\\Lib\\site-packages\\spleeter\\utils\\logging.py\", line 27, in get_tensorflow_logger\r\n    from tensorflow.compat.v1 import logging\r\n  File \"C:\\Users\\mgood\\AppData\\Roaming\\SpleeterGUI\\python\\Lib\\site-packages\\tensorflow\\__init__.py\", line 99, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\Users\\mgood\\AppData\\Roaming\\SpleeterGUI\\python\\Lib\\site-packages\\tensorflow_core\\__init__.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\mgood\\AppData\\Roaming\\SpleeterGUI\\python\\Lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\mgood\\AppData\\Roaming\\SpleeterGUI\\python\\Lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"D:\\obj\\windows-release\\37amd64_Release\\msi_python\\zip_amd64\\__init__.py\", line 127, in import_module\r\n  File \"C:\\Users\\mgood\\AppData\\Roaming\\SpleeterGUI\\python\\Lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\mgood\\AppData\\Roaming\\SpleeterGUI\\python\\Lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\mgood\\AppData\\Roaming\\SpleeterGUI\\python\\Lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\mgood\\AppData\\Roaming\\SpleeterGUI\\python\\Lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\mgood\\AppData\\Roaming\\SpleeterGUI\\python\\Lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"D:\\obj\\windows-release\\37amd64_Release\\msi_python\\zip_amd64\\imp.py\", line 242, in load_module\r\n  File \"D:\\obj\\windows-release\\37amd64_Release\\msi_python\\zip_amd64\\imp.py\", line 342, in load_dynamic\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\nFailed to load the native TensorFlow runtime.\r\nSee https://www.tensorflow.org/install/errors\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\nFinished processing all songs\r\n\r\nRun complete\r\n", "comments": ["@mark5452 \r\nWhat is make/model of your cpu?\r\nI suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)\r\nMake sure to download the latest[ microsoft visual c++ redistributable from here.](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads)\r\n.Also, please follow the instructions from to install from [Tensorflow website](https://www.tensorflow.org/install/source_windows).\r\n\r\nPlease, check Your CPU/Python is on 32 bits?Please, refer #36167 and see if it helps you.Please, refer similar issue #36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204\r\nThanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39796\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39796\">No</a>\n"]}, {"number": 39795, "title": "add tf.version.version_info similar to sys.version_info", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: \r\n*NA*\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: \r\n*CentOS 7*\r\n- **TensorFlow installed from (source or binary)**:\r\n*binary: pip*\r\n- **TensorFlow version (use command below)**:\r\n*2.3.0-dev20200522*\r\n- **Python version**:\r\n*3.7.6*\r\n\r\n- **Exact command to reproduce**:\r\n*Feature request*\r\n\r\n### Describe the problem\r\nIt is inconvenient to parse `tf.version.VERSION` to do version-specific logic.  The request is to provide a function more like `sys.version_info` so that the consumer doesn't need to parse a string.\r\n\r\n### Source code / logs\r\nConsider the output of `tf.version.VERSION`:\r\n```\r\ntf.version.VERSION\r\n'2.3.0-dev20200522'\r\n```\r\nContrast that output with `sys.version_info`:\r\n```\r\n>>> import sys\r\n>>> sys.version_info\r\nsys.version_info(major=3, minor=7, micro=6, releaselevel='final', serial=0)\r\n```\r\n\r\nThe request is to add a function that will return a object similar to `sys.version_info`'s output.  Parsing that string is harder than first imagined.  Notice that not only are the \"fields\" concatenated together, depending on the build, the fields are different.  For instance, an older release gives `2.1.0`.\r\n\r\nto be consistent with the other names in tf.version, I propose `tf.version.VERSION_INFO`.  What fields? major, minor, and micro are a must.  However since it is dictionary-like, it wouldn't hurt to have all versions (such as git and compiler) also included.\r\n\r\nNo workaround is requested.\r\n", "comments": ["@mihaimaruseac Do we want to this in python only or with c++ `tf.session/wrapper`? \r\n\r\nThis is for the standard + ext SemVer attrs (`pip install semver`):\r\n\r\n```python\r\nimport tensorflow as tf \r\nimport semver\r\nfrom pprint import pprint\r\nsem = semver.VersionInfo.parse(tf.__version__)\r\npprint(sem)\r\n```\r\n```python\r\nVersionInfo(major=2, minor=5, patch=0, prerelease='dev20201227', build=None)\r\n```", "I think Python only should be good for start.\r\n\r\nIn C++ we already have the components separated.", "https://github.com/tensorflow/tensorflow/issues/39795#issuecomment-751472512 should be the right wait to parse the components, according to API owners."]}, {"number": 39794, "title": "Failed installing tensorflow 2.1.0 into Cloud Functions runtime Python 3.7", "body": "Hi all,\r\n\r\nI'm trying to create a cloud function with the following config:\r\n\r\nRuntime:\r\n`Python 3.7`\r\n\r\nMemory:\r\n`256 MiB`\r\n\r\nrequirements.txt:\r\n`tensorflow==2.1.0`\r\n\r\nWhen I deploy, I got the following error:\r\n`Build failed: {\"cacheStats\": [{\"status\": \"MISS\", \"hash\": \"54f4df7672bd136f86b67fd4d2390e30c509db5\", \"type\": \"docker_layer_cache\", \"level\": \"global\"}, {\"status\": \"MISS\", \"hash\": \"54f4df7672bd136f86b6730c509db5\", \"type\": \"docker_layer_cache\", \"level\": \"project\"}]}`\r\n\r\nThis version is the one in which my model has been trained.\r\n\r\nHow to fix it?", "comments": ["Can you try installing TF 2.0 instead? I think TF 2.1 Cloud Functions is not supported currently.\r\nAlso refer this [thread](https://github.com/tensorflow/tensorflow/issues/34707)", "> Can you try installing TF 2.0 instead? I think TF 2.1 Cloud Functions is not supported currently.\r\n> Also refer this [thread](https://github.com/tensorflow/tensorflow/issues/34707)\r\n\r\n@ymodak I've changed for `tensorflow==2.0.0b0` version but still not working, with a different error related to memory.\r\n\r\nI've increased the memory allocated to 2GiB, now I receive the following message when I try to deploy:\r\n\r\n```\r\nDeployment failure:\r\nBuild failed: gzip_tar_runtime_package gzip /tmp/tmpFtGSwL.tar -1\r\nexited with error [Errno 12] Cannot allocate memory\r\ngzip_tar_runtime_package is likely not on the path; Error ID: F2E01257\r\n```\r\n\r\nI'm trying to run a prediction of a custom model of a CNN architecture, if it helps for the analysis.", "Can you try reducing the batch size and check if the error still happens?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39794\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39794\">No</a>\n"]}, {"number": 39793, "title": "In tensorflow, for custom layers that need arguments at instantialion, does the get_config method need overriding?", "body": "Ubuntu - 20.04,\r\nTensorflow - 2.2.0,\r\nTensorboard - 2.2.1\r\n\r\nI have [read](https://www.tensorflow.org/guide/keras/custom_layers_and_models#you_can_optionally_enable_serialization_on_your_layers) that one needs to reimplement the `get_config` method in order for a custom layer to be serializable.\r\n\r\nI have a custom layer that accepts arguments in its `__init__`. It uses another custom layer and that consumes arguments in its `__init__` as well. I can:\r\n\r\nWithout Tensorboard callbacks:\r\n\r\n1. Use them in a model both in eager model and graph form\r\n2. Run `tf.saved_model.save` and it executes without a glich\r\n3. Load the thus saved model using `tf.saved_model.load` and it loads the model saved in 2. above\r\n4. I can call `model(input)` the loaded model. I can also call 'call_and_return_all_conditional_losses(input)` and they run right as well\r\n\r\nWith Tensorboard callbacks:\r\n\r\nAll of the above (can .fit, save, load, predict from loaded etc) except.. While running fit i get \r\n```WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer PREPROCESS_MONSOON has arguments in `__init__` and therefore must override `get_config`.```\r\n\r\nPasting the entire code here that can be run end to end. You just need to have tensorflow 2 installed. Please delete/add the callbacks (only tensorboard callbacks is there) to `.fit` to see the two behaviors mentioned above\r\n\r\n```\r\nimport pandas as pd\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers as l\r\nfrom tensorflow import keras as k\r\nimport numpy as np\r\n\r\n##making empty directories\r\nimport os\r\nos.makedirs('r_data',exist_ok=True)\r\nos.makedirs('r_savedir',exist_ok=True)\r\n\r\n#Preparing the dataset\r\nmnist = tf.keras.datasets.mnist\r\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\nx_train_ = pd.DataFrame(x_train.reshape(60000,-1),columns = ['col_'+str(i) for i in range(28*28)])\r\nx_test_ = pd.DataFrame(x_test.reshape(10000,-1),columns = ['col_'+str(i) for i in range(28*28)])\r\nx_train_['col_cat1'] = [np.random.choice(['a','b','c','d','e','f','g','h','i']) for i in range(x_train_.shape[0])]\r\nx_test_['col_cat1'] = [np.random.choice(['a','b','c','d','e','f','g','h','i','j']) for i in range(x_test_.shape[0])]\r\nx_train_['col_cat2'] = [np.random.choice(['a','b','c','d','e','f','g','h','i']) for i in range(x_train_.shape[0])]\r\nx_test_['col_cat2'] = [np.random.choice(['a','b','c','d','e','f','g','h','i','j']) for i in range(x_test_.shape[0])]\r\nx_train_[np.random.choice([True,False],size = x_train_.shape,p=[0.05,0.95]).reshape(x_train_.shape)] = np.nan\r\nx_test_[np.random.choice([True,False],size = x_test_.shape,p=[0.05,0.95]).reshape(x_test_.shape)] = np.nan\r\nx_train_.to_csv('r_data/x_train.csv',index=False)\r\nx_test_.to_csv('r_data/x_test.csv',index=False)\r\npd.DataFrame(y_train).to_csv('r_data/y_train.csv',index=False)\r\npd.DataFrame(y_test).to_csv('r_data/y_test.csv',index=False)\r\n\r\n#**THE MAIN LAYER THAT WE ARE TALKING ABOUT**\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow import feature_column\r\nimport os\r\n\r\nclass NUM_TO_DENSE(layers.Layer):\r\n    def __init__(self,num_cols):\r\n        super().__init__()\r\n        self.keys = num_cols\r\n        self.keys_all = self.keys+[str(i)+'__nullcol' for i in self.keys]\r\n#     def get_config(self):\r\n\r\n#         config = super().get_config().copy()\r\n#         config.update({\r\n#             'keys': self.keys,\r\n#             'keys_all': self.keys_all,\r\n#         })\r\n#         return config\r\n    def build(self,input_shape):\r\n        def create_moving_mean_vars():\r\n            return tf.Variable(initial_value=0.,shape=(),dtype=tf.float32,trainable=False)\r\n        self.moving_means_total = {t:create_moving_mean_vars() for t in self.keys}\r\n        self.layer_global_counter = tf.Variable(initial_value=0.,shape=(),dtype=tf.float32,trainable=False)\r\n\r\n    def call(self,inputs, training = True):\r\n        null_cols = {k:tf.math.is_finite(inputs[k]) for k in self.keys}\r\n        current_means = {}\r\n        def compute_update_current_means(t):\r\n            current_mean = tf.math.divide_no_nan(tf.reduce_sum(tf.where(null_cols[t],inputs[t],0.),axis=0),\\\r\n                                  tf.reduce_sum(tf.cast(tf.math.is_finite(inputs[t]),tf.float32),axis=0))\r\n            self.moving_means_total[t].assign_add(current_mean)\r\n            return current_mean\r\n        \r\n        if training:\r\n            current_means = {t:compute_update_current_means(t) for t in self.keys}\r\n            outputs = {t:tf.where(null_cols[t],inputs[t],current_means[t]) for t in self.keys}\r\n            outputs.update({str(k)+'__nullcol':tf.cast(null_cols[k],tf.float32) for k in self.keys})\r\n            self.layer_global_counter.assign_add(1.)\r\n        else:\r\n            outputs = {t:tf.where(null_cols[t],inputs[t],(self.moving_means_total[t]/self.layer_global_counter))\\\r\n                       for t in self.keys}\r\n            outputs.update({str(k)+'__nullcol':tf.cast(null_cols[k],tf.float32) for k in self.keys})\r\n        return outputs\r\n\r\n\r\nclass PREPROCESS_MONSOON(layers.Layer):\r\n    def __init__(self,cat_cols_with_unique_values,num_cols):\r\n        '''cat_cols_with_unqiue_values: (dict) {'col_cat':[unique_values_list]}\r\n        num_cols: (list) [num_cols_name_list]'''\r\n        super().__init__()\r\n        self.cat_cols = cat_cols_with_unique_values\r\n        self.num_cols = num_cols\r\n#     def get_config(self):\r\n\r\n#         config = super().get_config().copy()\r\n#         config.update({\r\n#             'cat_cols': self.cat_cols,\r\n#             'num_cols': self.num_cols,\r\n#         })\r\n#         return config\r\n    def build(self,input_shape):\r\n        self.ntd = NUM_TO_DENSE(self.num_cols)\r\n        self.num_colnames = self.ntd.keys_all\r\n        self.ctd = {k:layers.DenseFeatures\\\r\n                    (feature_column.embedding_column\\\r\n                     (feature_column.categorical_column_with_vocabulary_list\\\r\n                      (k,v),tf.cast(tf.math.ceil(tf.math.log(tf.cast(len(self.cat_cols[k]),tf.float32))),tf.int32).numpy()))\\\r\n                   for k,v in self.cat_cols.items()}\r\n        self.cat_colnames = [i for i in self.cat_cols]\r\n        self.dense_colnames = self.num_colnames+self.cat_colnames\r\n    def call(self,inputs,training=True):\r\n        dense_num_d = self.ntd(inputs,training=training)\r\n        dense_cat_d = {k:self.ctd[k](inputs) for k in self.cat_colnames}\r\n        \r\n        dense_num = tf.stack([dense_num_d[k] for k in self.num_colnames],axis=1)\r\n        dense_cat = tf.concat([dense_cat_d[k] for k in self.cat_colnames],axis=1)\r\n        dense_all = tf.concat([dense_num,dense_cat],axis=1)\r\n        return dense_all\r\n\r\n##Inputs\r\nlabel_path = 'r_data/y_train.csv'\r\ndata_path = 'r_data/x_train.csv'\r\nmax_epochs = 100\r\nbatch_size = 32\r\nshuffle_seed = 42\r\n\r\n##Creating layer inputs\r\ndfs = pd.read_csv(data_path,nrows=1)\r\ncdtypes_x = dfs.dtypes\r\nnc = list(dfs.select_dtypes(include=[int,float]).columns)\r\noc = list(dfs.select_dtypes(exclude=[int,float]).columns)\r\ncdtypes_y = pd.read_csv(label_path,nrows=1).dtypes\r\ndfc = pd.read_csv(data_path,usecols=oc)\r\nccwuv = {i:list(pd.Series(dfc[i].unique()).dropna()) for i in dfc.columns}\r\npreds_name = pd.read_csv(label_path,nrows=1).columns\r\n\r\n##creating datasets\r\ndataset = tf.data.experimental.make_csv_dataset(\r\n    'r_data/x_train.csv',batch_size, column_names=cdtypes_x.index,prefetch_buffer_size=1,\r\nshuffle=True,shuffle_buffer_size=10000,shuffle_seed=shuffle_seed)\r\nlabels = tf.data.experimental.make_csv_dataset(\r\n    'r_data/y_train.csv',batch_size, column_names=cdtypes_y.index,prefetch_buffer_size=1,\r\nshuffle=True,shuffle_buffer_size=10000,shuffle_seed=shuffle_seed)\r\ndataset = tf.data.Dataset.zip((dataset,labels))\r\n\r\n##CREATING NETWORK\r\np = PREPROCESS_MONSOON(cat_cols_with_unique_values=ccwuv,num_cols=nc)\r\n\r\nindict = {}\r\nfor i in nc:\r\n    indict[i] = k.Input(shape = (), name=i,dtype=tf.float32)\r\nfor i in ccwuv:\r\n    indict[i] = k.Input(shape=(), name=i,dtype=tf.string)\r\nx = p(indict)\r\nx = l.BatchNormalization()(x)\r\nx = l.Dense(10,activation='relu',name='dense_1')(x)\r\npredictions = l.Dense(10,activation=None,name=preds_name[0])(x)\r\nmodel = k.Model(inputs=indict,outputs=predictions)\r\n\r\n##Compiling model\r\nmodel.compile(optimizer=k.optimizers.Adam(),\r\n              loss=k.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n              metrics=['sparse_categorical_accuracy'])\r\n\r\n##callbacks\r\nlog_dir = './tensorboard_dir/no_config'\r\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\r\n\r\n## Fit model on training data\r\nhistory = model.fit(dataset,\r\n                    batch_size=64,\r\n                    epochs=30,\r\n                    steps_per_epoch=5,\r\n                    validation_split=0.,\r\n                   callbacks = [tensorboard_callback])\r\n\r\n#saving the model\r\ntf.saved_model.save(model,'r_savedir')\r\n#loading the model\r\nmodel = tf.saved_model.load('r_savedir')\r\n\r\n##Predicting on loaded model\r\nfor i in dataset:\r\n    print(model(i[0],training=False))\r\n    break\r\n\r\n```  \r\n\r\nI have commented out the part from the code where i override the config files in my custom layers and you can comment them in and the Warning about the layers not being serializable would go away.\r\n\r\nQuestion:\r\nDo i or do i not need to override the `config` method in order to make a custom layer that accepts arguments in `__init__` serializable?\r\n\r\nThank you in advance for help", "comments": ["@nitinmnsn \r\nThis question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged//tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n", "Can you please refer to [this link](https://stackoverflow.com/questions/61947226/in-tensorflow-for-custom-layers-that-need-arguments-at-instantialion-does-the) and let us know if it helps.", "That question is asked by me only. No it doesn't help. I think it is more suited to GitHub since what is happening is a direct contradiction of documentation. And this is happening just in version 2.2.0 . I am able to save load and use custom layers without overriding `get_config` and documentation says it can't be.. though there is a warning and that, in earlier versions, used to be an error. \r\nLooking forward to some clarification and help. Thank you", "any update on this?", "The serialization it is related to `model.to_json()` that is requested by the Tensorboard for the model summary:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/a4dfb8d1a71385bd6d122e4f27f86dcebb96712d/tensorflow/python/keras/callbacks.py#L1986\r\n\r\nYou can reproduce yourself just using `model.to_json()` without the Tensorboard callback.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39793\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39793\">No</a>\n"]}, {"number": 39791, "title": "Improving the performance of reads from S3 by parallelizing downloads", "body": "- Updates the S3 File system in TensorFlow to read a file from S3 in parallel using the AWS SDK's transfer manager. \r\n- To support this PR, I made a PR to AWS SDK https://github.com/aws/aws-sdk-cpp/pull/1349, and have updated the version of SDK to match the release after that PR. \r\n- This PR also adds an override of the buffer size for TFRecordDataset similar to what's done for TPU GCS file system. This helps reduce overhead of network calls and thus improves performance, by reading larger parts of a file at once. \r\n\r\n**Benchmarking**\r\nThe following code snippet when run with TFRecords prepared from the ImageNet dataset with images resized to 480px (prepared using scripts [here](https://github.com/aws-samples/deep-learning-models/tree/master/utils/tensorflow)) gives **~2600 images/sec** when data is on S3. Same script when run with vanilla TF gives **~200 images/sec**, i.e. 13x speedup.\r\n\r\n```\r\nimport tensorflow as tf\r\nimport pathlib\r\nfrom timeit import default_timer as timer\r\nimport time\r\nimport os\r\nimport argparse\r\n\r\nparser = argparse.ArgumentParser()\r\nparser.add_argument('--buffer-size', type=int, default=None)\r\nparser.add_argument('--path-type', type=str, default='s3')\r\nparser.add_argument('--path', type=str, default='s3://aws-tensorflow-benchmarking/imagenet-armand/train-480px/')\r\nparser.add_argument('--num-batches', type=int, default=1000)\r\nparser.add_argument('--batch-size', type=int, default=128)\r\nparser.add_argument('--cache-processing', type=str, default='true')\r\nargs = parser.parse_args()\r\n\r\nif args.path_type == 'local':\r\n    data_dir = pathlib.Path('/home/ubuntu/imagenet-480px/')\r\n    train_tdf = tf.data.TFRecordDataset([i.as_posix() for i in data_dir.glob('train*')], buffer_size=args.buffer_size)\r\nelif args.path_type == 's3':\r\n    files = tf.data.Dataset.list_files(os.path.join(args.path, 'train*'))\r\n    train_tdf = tf.data.TFRecordDataset(files, buffer_size=args.buffer_size)\r\nelse:\r\n    raise NotImplementedError()\r\n\r\nfeatures = {'image/encoded' : tf.io.FixedLenFeature((), tf.string, \"\"),\r\n            'image/class/label': tf.io.FixedLenFeature([1], tf.int64,  -1),\r\n                                         }\r\nCACHE = {'image': None, 'label': None}\r\n\r\ndef parse(record):\r\n    record = tf.io.parse_single_example(record, features)\r\n    if args.cache_processing != 'true' or CACHE['image'] is None:\r\n        image = record['image/encoded']\r\n        image = tf.image.decode_jpeg(image)\r\n        image = tf.image.resize(image, (224, 224))/255.\r\n        CACHE['image'] = image\r\n    else:\r\n        image = CACHE['image']\r\n    if args.cache_processing != 'true' or CACHE['label'] is None:\r\n        label = record['image/class/label']\r\n        label -= 1\r\n        CACHE['label'] = label\r\n    else:\r\n        label = CACHE['label']\r\n    return image, label\r\n\r\n\r\ndef benchmark(iterator):\r\n    start_time = time.perf_counter()\r\n    i = 0\r\n    for sample in iterator:\r\n        # Performing a training step\r\n        i += 1\r\n        if i% 10 == 0:\r\n            print(f\"Batch {i}: Time from start {time.perf_counter() - start_time}, Speed (imgs/sec): {i * args.batch_size / (time.perf_counter() - start_time)}\")\r\n        if i == args.num_batches:\r\n            break\r\n    cur_time = time.perf_counter()\r\n    print(f\"Total execution time: {cur_time - start_time}, Speed (imgs/sec):{i *args.batch_size / (cur_time - start_time)}\")\r\n\r\n\r\niterator = train_tdf.map(parse, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(args.batch_size) \\\r\n                 .prefetch(tf.data.experimental.AUTOTUNE)\r\n\r\nbenchmark(iterator)\r\n```", "comments": []}, {"number": 39790, "title": "RuntimeError: Inputs and outputs not all float|uint8|int16 types.Node number 4 (ADD) failed to invoke.", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): binary \r\n- TensorFlow version (or github SHA if from source):TF 2.2.0 from anaconda \r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\nimport tensorflow as tf\r\n# Path to the frozen graph file\r\ngraph_def_file = 'savedModel.pb'\r\n# A list of the names of the model's input tensors\r\ninput_arrays = ['input.1']\r\n# A list of the names of the model's output tensors\r\noutput_arrays = ['4358']\r\n# Load and convert the frozen graph\r\nconverter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(\r\n  graph_def_file, input_arrays, output_arrays)\r\n\r\n\r\nconverter.target_spec.supported_ops = [\r\n    tf.lite.OpsSet.TFLITE_BUILTINS,\r\n    tf.lite.OpsSet.SELECT_TF_OPS,\r\n]\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_types = [tf.float16]\r\ntflite_fp16_model = converter.convert()\r\ntflite_model_fp16_file = \"tf_model.tflite\"\r\nopen(tflite_model_fp16_file , \"wb\").write(tflite_fp16_model)\r\n\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\n2020-05-22 20:38:17.870933: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-05-22 20:38:17.872070: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\r\n2020-05-22 20:38:17.872351: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-7CPMA5J): /proc/driver/nvidia/version does not exist\r\n2020-05-22 20:38:17.872996: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-05-22 20:38:17.880532: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3192000000 Hz\r\n2020-05-22 20:38:17.882702: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f5b64000b60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-05-22 20:38:17.882997: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\nhttps://drive.google.com/file/d/17d8lFYY-4Z7iExnLNdYbjOt6EQpVbDdI/view?usp=sharing\r\n```\r\n\r\n**Failure details**\r\nIf the conversion is successful, but the generated model is wrong,\r\nstate what is wrong:\r\n- Producing wrong results and/or decrease in accuracy\r\n- Producing correct results, but the model is slower than expected (model generated from old converter)\r\n\r\nModel not running gives error  as below.\r\n\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n> [{'name': 'input.1', 'index': 0, 'shape': array([  1,   3, 256, 256], dtype=int32), 'shape_signature': array([  1,   3, 256, 256], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\r\n> [{'name': '4358', 'index': 4138, 'shape': array([ 1, 17,  3], dtype=int32), 'shape_signature': array([ 1, 17,  3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\r\n> Traceback (most recent call last):\r\n>   File \"test_graph.py\", line 20, in <module>\r\n>     interpreter.invoke()\r\n>   File \"/home/shreyas/.local/lib/python3.8/site-packages/tensorflow/lite/python/interpreter.py\", line 511, in invoke\r\n>     self._interpreter.Invoke()\r\n>   File \"/home/shreyas/.local/lib/python3.8/site-packages/tensorflow/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py\", line 113, in Invoke\r\n>     return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_Invoke(self)\r\n> RuntimeError: Inputs and outputs not all float|uint8|int16 types.Node number 4 (ADD) failed to invoke.\r\n", "comments": ["#37099 issue has the same problem, solution isnt working for me.", "https://colab.research.google.com/gist/jaggernaut007/efe78df81a697c2f39652cb0cbe88169/untitled0.ipynb\r\n\r\nCode implementation", "Was able to reproduce the issue with [TF v2.2](https://colab.research.google.com/gist/amahendrakar/7c1f34e9fc39f8e24dda699d59b26c12/39790.ipynb). \r\n\r\nWhereas, running the code with [TF-nightly](https://colab.research.google.com/gist/amahendrakar/bfd74703cb85b1b2ce765fb87514acc7/39790-tf-nightly.ipynb#scrollTo=JFA6IZKtnYC5), throws an error stating `RuntimeError: Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.Node number 3 (FlexAddV2) failed to prepare.`. \r\nPlease find the attached gist. Thanks!", "I am also seeing this issue. Any hope of a near term fix? I am blocked.", "This is working as intended.\r\nThe model has Addv2 which accepts type int64. Tensorflow lite doesn't support Addv2 with int64 input/output.\r\nSince, you used SELECT_TF_OPS that means all non supported ops will be exported as TF ops and run in TF.\r\nTo run the generated tflite file, you need to use Interpreter which supports SELECT.\r\nPlease follow the guide on creating interpreter\r\nhttps://www.tensorflow.org/lite/guide/ops_select\r\n\r\nAnother way is to update your model to use int32 instead of int64, and convert without SELECT_TF_OPS and use regular interpreter.\r\n\r\nThanks", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39790\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39790\">No</a>\n"]}, {"number": 39789, "title": "Keras List index is out of range!", "body": "Hey all!\r\nI am getting this obscure error for which I could find no solution online. I am trying to make this piece of code that finds the relation between two numbers. For testing purposes, I am using simple data where the relation is to simply add 5. Here is how my training data looks like:-\r\n`0,5`\r\n`1,6`\r\n`2,7`\r\n`3,8`\r\n`4,9`\r\n`...`\r\nNow, I am trying to sketch out a simple model that accomplishes what I want to do. However, It does not even get to the training part of the code and simply _terminates_ with this obscure error:-\r\n\r\n```\r\n2020-05-22 20:00:25.521151: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-05-22 20:00:25.523749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-05-22 20:00:25.523805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      \r\nTraceback (most recent call last):\r\n  File \"main.py\", line 34, in <module>\r\n    history = model.fit(train_data, epochs=100, verbose=1)\r\n  File \"/home/awesome_ruler/.local/lib/python3.7/site-packages/keras/engine/training.py\", line 1239, in fit\r\n    validation_freq=validation_freq)\r\n  File \"/home/awesome_ruler/.local/lib/python3.7/site-packages/keras/engine/training_arrays.py\", line 141, in fit_loop\r\n    if issparse(fit_inputs[i]) and not K.is_sparse(feed[i]):\r\nIndexError: list index out of range\r\n\r\n```\r\nI am not understanding the source of this error as the iterator that `model.fit` is using was not written by me but is being used from the libraries themselves. For reference, here is my code:-\r\n```\r\n# -*- coding: utf-8 -*-\r\n# @author = Neel Gupta\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom keras.models import Sequential\r\nfrom keras.layers import Dense\r\nfrom keras.optimizers import SGD\r\nimport matplotlib.pyplot as pyplot\r\nimport csv\r\n\r\ndef csv_arr(csv_f):\r\n    results = []\r\n    # the loop..\r\n    with open(csv_f) as csvfile:\r\n        reader = csv.reader(csvfile, quoting=csv.QUOTE_NONNUMERIC)  # change contents to floats\r\n        for row in reader:  # each row is a list\r\n            results.append(row)\r\n    # returning the output\r\n    return np.asarray(results)\r\n\r\ntrain_data = np.reshape(csv_arr(\"train.csv\"), (15,2))\r\ntest_data = csv_arr(\"test.csv\")\r\n\r\nx_data = tf.keras.Input(shape=(15,2))\r\n\r\nmodel = Sequential()\r\nmodel.add(Dense(4, input_dim=2, activation='relu', kernel_initializer='glorot_uniform'))\r\nmodel.add(Dense(1, activation='linear'))\r\nopt = SGD(lr=0.01, momentum=0.9)\r\nmodel.compile(loss='mean_squared_error', optimizer=opt, )\r\n\r\n# fit model\r\nhistory = model.fit(train_data, epochs=100, verbose=1)\r\n\r\n# getting model's summary\r\nmodel.summary()\r\n\r\n# plot loss during training\r\npyplot.title('Loss / Mean Squared Error')\r\npyplot.plot(history.history['loss'], label='train')\r\npyplot.plot(history.history['val_loss'], label='test')\r\npyplot.legend()\r\npyplot.show()\r\n\r\n```\r\nI am using Tensorflow GPU, which is right now not using the acceleration due to some missing/broken libs. I am using TensorFlow version `2.2.0` and keras version `2.3`. Additionally, I am trying to use CUDA `10.1`. I do not know what other cause there is to my error. Can someone shed any light on this", "comments": ["@neel04 \r\nI ran the code shared by you and face an error, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/e87851087ec8c4731be5336dc55b6e4e/untitled197.ipynb), please share all dependencies.", "@Saduf2019 As discussed in my question above, the training data looks something like this:-\r\n`0,5`\r\n`1,6`\r\n`2,7`\r\n`3,8`\r\n`4,9`\r\n\r\nWhere 5 is added to each number. So, you can simply create a file named `train.csv` and modify the path in the Colab notebook. The `csv` file would contain data in the given format. My function will then convert this to an array automatically upon running the code. \r\n\r\nRegards,\r\nNeel Gupta ", "@neel04 \r\nI ran the code with the csv and face [this error](https://colab.sandbox.google.com/gist/Saduf2019/f78fcad22fee1d84c8cb91d8b637fd09/untitled197.ipynb), can you please share a colab gist with the error for us to analyse it.", "@Saduf2019 I think that the problem is arising due to the incorrect length of training data. You can copy/paste this exact sequence in the `train.csv` for further use.\r\n\r\n`0,5`\r\n`1,6`\r\n`2,7`\r\n`3,8`\r\n`4,9`\r\n`5,10`\r\n`6,11`\r\n`7,12`\r\n`8,13`\r\n`9,14`\r\n`10,15`\r\n`11,16`\r\n`12,17`\r\n`13,18`\r\n`14,19`", "I am able to replicate the issue reported, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/42189e7e4645183431851f04b22028ea/untitled204.ipynb) Thanks!", "@neel04 I am seeing different error when I ran with `tf-nightly`.  Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/d8e56e50e614a4ae2d13a60cc9fbb2ca/untitled204.ipynb). Thanks!\r\n\r\n```\r\nEpoch 1/100\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-7-ccc2488cdec7> in <module>()\r\n     30 \r\n     31 # fit model\r\n---> 32 history = model.fit(train_data, epochs=100, verbose=1)\r\n     33 \r\n     34 # getting model's summary\r\n\r\n10 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    966           except Exception as e:  # pylint:disable=broad-except\r\n    967             if hasattr(e, \"ag_error_metadata\"):\r\n--> 968               raise e.ag_error_metadata.to_exception(e)\r\n    969             else:\r\n    970               raise\r\n\r\nValueError: in user code:\r\n\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:802 train_function  *\r\n        return step_function(self, iterator)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:792 step_function  **\r\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:968 run\r\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2351 call_for_each_replica\r\n        return self._call_for_each_replica(fn, args, kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2710 _call_for_each_replica\r\n        return fn(*args, **kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:785 run_step  **\r\n        outputs = model.train_step(data)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:753 train_step\r\n        self.trainable_variables)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2685 _minimize\r\n        trainable_variables))\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:562 _aggregate_gradients\r\n        filtered_grads_and_vars = _filter_grads(grads_and_vars)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:1271 _filter_grads\r\n        ([v.name for _, v in grads_and_vars],))\r\n\r\n    ValueError: No gradients provided for any variable: ['dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'].\r\n```", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 39788, "title": "Formula error display in RMSprop", "body": "\r\n## URL(s) with the issue: https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/keras/optimizers/RMSprop\r\n\r\n## Description of issue (what needs changing): the sub-indexes in the formula are not displayed correctly.\r\n\r\n### Clear description\r\nAs an example, meansquared_{t} appears like mean_{s}quaredt and so on.\r\n", "comments": ["This is fixed with TF 2.2 api docs and above. Thanks!\r\nhttps://www.tensorflow.org/versions/r2.2/api_docs/python/tf/keras/optimizers/RMSprop"]}, {"number": 39787, "title": "Keras: list index is out of range!", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n", "comments": ["@neel04,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and the TensorFlow version you are using.\r\n\r\nAlso, if this question is not a TensorFlow bug or feature request, it is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) as there is a larger community that reads questions there. Thanks!", "Hi @neel04, I think it would be best to close either this or #39789, as they are duplicate threads referring to the same issue. Just a quick suggestion on logistics in passing, thanks!"]}, {"number": 39786, "title": "Convert to tflite issue", "body": "**System information**\r\n- OS Platform and Distribution: elementary OS 5.1.3 Hera (based on Ubuntu 18.04 LTS)\r\n- TensorFlow installed from (source or binary): binary , pip installed \r\n- TensorFlow version (or github SHA if from source): 1.14.0\r\n\r\n**Provide the text output from tflite_convert**\r\n```\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONV_2D, ELU, FULLY_CONNECTED, L2_NORMALIZATION, LESS, MAX_POOL_2D, MUL, RANGE, RESHAPE, SHAPE, STRIDED_SLICE. Here is a list of operators for which you will need custom implementations: Enter, Exit, LoopCond, Merge, Switch, TensorArrayGatherV3, TensorArrayReadV3, TensorArrayScatterV3, TensorArraySizeV3, TensorArrayV3, TensorArrayWriteV3.\r\n```\r\n\r\n\r\n\r\n**Standalone code to reproduce the issue** \r\n toco --graph_def_file=/out/saved_model.pb --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --output_file=/out/saved_model.tflite --inference_input_type=QUANTIZED_UINT8 --input_arrays=images --output_arrays=features --input_shapes=1,128,64,3 --std_dev_values=127 --mean_values=128 --enable_select_tf_opsA\r\n\r\n**Environment capture script result**\r\n```\r\n== check python ===================================================\r\npython version: 2.7.17\r\npython branch: \r\npython build version: ('default', 'Apr 15 2020 17:20:14')\r\npython compiler version: GCC 7.5.0\r\npython implementation: CPython\r\n\r\n\r\n== check os platform ===============================================\r\nos: Linux\r\nos kernel version: #38~18.04.1-Ubuntu SMP Tue Mar 31 04:17:56 UTC 2020\r\nos release version: 5.3.0-46-generic\r\nos platform: Linux-5.3.0-46-generic-x86_64-with-elementary-5.1.3-hera\r\nlinux distribution: ('elementary', '5.1.3', 'hera')\r\nlinux os distribution: ('elementary', '5.1.3', 'hera')\r\nmac version: ('', ('', '', ''), '')\r\nuname: ('Linux', 'asuspro', '5.3.0-46-generic', '#38~18.04.1-Ubuntu SMP Tue Mar 31 04:17:56 UTC 2020', 'x86_64', 'x86_64')\r\narchitecture: ('64bit', '')\r\nmachine: x86_64\r\n\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\nCopyright (C) 2017 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== check pips ===================================================\r\nnumpy (1.16.6)\r\nprotobuf (3.11.3)\r\ntensorflow (1.14.0)\r\ntensorflow-estimator (1.14.0)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.version.VERSION = 1.14.0\r\ntf.version.GIT_VERSION = v1.14.0-rc1-22-gaf24dc91b5\r\ntf.version.COMPILER_VERSION = 4.8.5\r\nSanity check: array([1], dtype=int32)\r\n      9322:\tfind library=libc.so.6 [0]; searching\r\n      9322:\t search cache=/etc/ld.so.cache\r\n      9322:\t  trying file=/lib/x86_64-linux-gnu/libc.so.6\r\n      9322:\t\r\n      9322:\tfind library=libpthread.so.0 [0]; searching\r\n      9322:\t search cache=/etc/ld.so.cache\r\n      9322:\t  trying file=/lib/x86_64-linux-gnu/libpthread.so.0\r\n      9322:\t\r\n      9322:\tfind library=libdl.so.2 [0]; searching\r\n      9322:\t search cache=/etc/ld.so.cache\r\n      9322:\t  trying file=/lib/x86_64-linux-gnu/libdl.so.2\r\n      9322:\t\r\n      9322:\tfind library=libutil.so.1 [0]; searching\r\n      9322:\t search cache=/etc/ld.so.cache\r\n      9322:\t  trying file=/lib/x86_64-linux-gnu/libutil.so.1\r\n      9322:\t\r\n      9322:\tfind library=libz.so.1 [0]; searching\r\n      9322:\t search cache=/etc/ld.so.cache\r\n      9322:\t  trying file=/lib/x86_64-linux-gnu/libz.so.1\r\n      9322:\t\r\n      9322:\tfind library=libm.so.6 [0]; searching\r\n      9322:\t search cache=/etc/ld.so.cache\r\n      9322:\t  trying file=/lib/x86_64-linux-gnu/libm.so.6\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /lib/x86_64-linux-gnu/libpthread.so.0\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /lib/x86_64-linux-gnu/libc.so.6\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /lib/x86_64-linux-gnu/libm.so.6\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /lib/x86_64-linux-gnu/libz.so.1\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /lib/x86_64-linux-gnu/libutil.so.1\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /lib/x86_64-linux-gnu/libdl.so.2\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tinitialize program: /usr/bin/python\r\n      9322:\t\r\n      9322:\t\r\n      9322:\ttransferring control: /usr/bin/python\r\n      9322:\t\r\n      9322:\tfind library=libffi.so.6 [0]; searching\r\n      9322:\t search cache=/etc/ld.so.cache\r\n      9322:\t  trying file=/usr/lib/x86_64-linux-gnu/libffi.so.6\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /usr/lib/x86_64-linux-gnu/libffi.so.6\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so\r\n      9322:\t\r\n      9322:\tfind library=libopenblasp-r0-34a18dc3.3.7.so [0]; searching\r\n      9322:\t search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/tls/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/tls/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/tls/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/tls:/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs\t\t(RPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/_multiarray_umath.so)\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/tls/haswell/x86_64/libopenblasp-r0-34a18dc3.3.7.so\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/tls/haswell/libopenblasp-r0-34a18dc3.3.7.so\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/tls/x86_64/libopenblasp-r0-34a18dc3.3.7.so\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/tls/libopenblasp-r0-34a18dc3.3.7.so\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/haswell/x86_64/libopenblasp-r0-34a18dc3.3.7.so\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/haswell/libopenblasp-r0-34a18dc3.3.7.so\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/x86_64/libopenblasp-r0-34a18dc3.3.7.so\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/libopenblasp-r0-34a18dc3.3.7.so\r\n      9322:\t\r\n      9322:\tfind library=libgfortran-ed201abd.so.3.0.0 [0]; searching\r\n      9322:\t search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs\t\t(RPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/_multiarray_umath.so)\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/libgfortran-ed201abd.so.3.0.0\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/libgfortran-ed201abd.so.3.0.0\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/libopenblasp-r0-34a18dc3.3.7.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/_multiarray_umath.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/_multiarray_tests.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/linalg/lapack_lite.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/linalg/_umath_linalg.so\r\n      9322:\t\r\n      9322:\tfind library=libbz2.so.1.0 [0]; searching\r\n      9322:\t search cache=/etc/ld.so.cache\r\n      9322:\t  trying file=/lib/x86_64-linux-gnu/libbz2.so.1.0\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /lib/x86_64-linux-gnu/libbz2.so.1.0\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /usr/lib/python2.7/lib-dynload/bz2.x86_64-linux-gnu.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /usr/lib/python2.7/lib-dynload/future_builtins.x86_64-linux-gnu.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/fft/fftpack_lite.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/random/mtrand.so\r\n      9322:\t\r\n      9322:\tfind library=libcrypto.so.1.1 [0]; searching\r\n      9322:\t search cache=/etc/ld.so.cache\r\n      9322:\t  trying file=/usr/lib/x86_64-linux-gnu/libcrypto.so.1.1\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /usr/lib/x86_64-linux-gnu/libcrypto.so.1.1\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /usr/lib/python2.7/lib-dynload/_hashlib.x86_64-linux-gnu.so\r\n      9322:\t\r\n      9322:\tfind library=libtensorflow_framework.so.1 [0]; searching\r\n      9322:\t search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/tls/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/tls/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/tls/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/tls:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../tls/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../tls/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../tls/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../tls:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/..\t\t(RUNPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/haswell/x86_64/libtensorflow_framework.so.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/haswell/libtensorflow_framework.so.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/x86_64/libtensorflow_framework.so.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/libtensorflow_framework.so.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/haswell/x86_64/libtensorflow_framework.so.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/haswell/libtensorflow_framework.so.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/x86_64/libtensorflow_framework.so.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../../_solib_k8/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/libtensorflow_framework.so.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/tls/haswell/x86_64/libtensorflow_framework.so.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/tls/haswell/libtensorflow_framework.so.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/tls/x86_64/libtensorflow_framework.so.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/tls/libtensorflow_framework.so.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/haswell/x86_64/libtensorflow_framework.so.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/haswell/libtensorflow_framework.so.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/x86_64/libtensorflow_framework.so.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/libtensorflow_framework.so.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../tls/haswell/x86_64/libtensorflow_framework.so.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../tls/haswell/libtensorflow_framework.so.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../tls/x86_64/libtensorflow_framework.so.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../tls/libtensorflow_framework.so.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../haswell/x86_64/libtensorflow_framework.so.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../haswell/libtensorflow_framework.so.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../x86_64/libtensorflow_framework.so.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../libtensorflow_framework.so.1\r\n      9322:\t\r\n      9322:\tfind library=librt.so.1 [0]; searching\r\n      9322:\t search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/..\t\t(RUNPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/librt.so.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../librt.so.1\r\n      9322:\t search cache=/etc/ld.so.cache\r\n      9322:\t  trying file=/lib/x86_64-linux-gnu/librt.so.1\r\n      9322:\t\r\n      9322:\tfind library=libstdc++.so.6 [0]; searching\r\n      9322:\t search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/..\t\t(RUNPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/libstdc++.so.6\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../libstdc++.so.6\r\n      9322:\t search cache=/etc/ld.so.cache\r\n      9322:\t  trying file=/usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n      9322:\t\r\n      9322:\tfind library=libgcc_s.so.1 [0]; searching\r\n      9322:\t search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python:/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/..\t\t(RUNPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/libgcc_s.so.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../libgcc_s.so.1\r\n      9322:\t search cache=/etc/ld.so.cache\r\n      9322:\t  trying file=/lib/x86_64-linux-gnu/libgcc_s.so.1\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /lib/x86_64-linux-gnu/libgcc_s.so.1\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /lib/x86_64-linux-gnu/librt.so.1\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../libtensorflow_framework.so.1\r\n      9322:\t\r\n      9322:\tfind library=libhdfs.so [0]; searching\r\n      9322:\t search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/..\t\t(RUNPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../libhdfs.so\r\n      9322:\t search cache=/etc/ld.so.cache\r\n      9322:\t search path=/lib/x86_64-linux-gnu/tls/haswell/x86_64:/lib/x86_64-linux-gnu/tls/haswell:/lib/x86_64-linux-gnu/tls/x86_64:/lib/x86_64-linux-gnu/tls:/lib/x86_64-linux-gnu/haswell/x86_64:/lib/x86_64-linux-gnu/haswell:/lib/x86_64-linux-gnu/x86_64:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu/tls/haswell/x86_64:/usr/lib/x86_64-linux-gnu/tls/haswell:/usr/lib/x86_64-linux-gnu/tls/x86_64:/usr/lib/x86_64-linux-gnu/tls:/usr/lib/x86_64-linux-gnu/haswell/x86_64:/usr/lib/x86_64-linux-gnu/haswell:/usr/lib/x86_64-linux-gnu/x86_64:/usr/lib/x86_64-linux-gnu:/lib/tls/haswell/x86_64:/lib/tls/haswell:/lib/tls/x86_64:/lib/tls:/lib/haswell/x86_64:/lib/haswell:/lib/x86_64:/lib:/usr/lib/tls/haswell/x86_64:/usr/lib/tls/haswell:/usr/lib/tls/x86_64:/usr/lib/tls:/usr/lib/haswell/x86_64:/usr/lib/haswell:/usr/lib/x86_64:/usr/lib\t\t(system search path)\r\n      9322:\t  trying file=/lib/x86_64-linux-gnu/tls/haswell/x86_64/libhdfs.so\r\n      9322:\t  trying file=/lib/x86_64-linux-gnu/tls/haswell/libhdfs.so\r\n      9322:\t  trying file=/lib/x86_64-linux-gnu/tls/x86_64/libhdfs.so\r\n      9322:\t  trying file=/lib/x86_64-linux-gnu/tls/libhdfs.so\r\n      9322:\t  trying file=/lib/x86_64-linux-gnu/haswell/x86_64/libhdfs.so\r\n      9322:\t  trying file=/lib/x86_64-linux-gnu/haswell/libhdfs.so\r\n      9322:\t  trying file=/lib/x86_64-linux-gnu/x86_64/libhdfs.so\r\n      9322:\t  trying file=/lib/x86_64-linux-gnu/libhdfs.so\r\n      9322:\t  trying file=/usr/lib/x86_64-linux-gnu/tls/haswell/x86_64/libhdfs.so\r\n      9322:\t  trying file=/usr/lib/x86_64-linux-gnu/tls/haswell/libhdfs.so\r\n      9322:\t  trying file=/usr/lib/x86_64-linux-gnu/tls/x86_64/libhdfs.so\r\n      9322:\t  trying file=/usr/lib/x86_64-linux-gnu/tls/libhdfs.so\r\n      9322:\t  trying file=/usr/lib/x86_64-linux-gnu/haswell/x86_64/libhdfs.so\r\n      9322:\t  trying file=/usr/lib/x86_64-linux-gnu/haswell/libhdfs.so\r\n      9322:\t  trying file=/usr/lib/x86_64-linux-gnu/x86_64/libhdfs.so\r\n      9322:\t  trying file=/usr/lib/x86_64-linux-gnu/libhdfs.so\r\n      9322:\t  trying file=/lib/tls/haswell/x86_64/libhdfs.so\r\n      9322:\t  trying file=/lib/tls/haswell/libhdfs.so\r\n      9322:\t  trying file=/lib/tls/x86_64/libhdfs.so\r\n      9322:\t  trying file=/lib/tls/libhdfs.so\r\n      9322:\t  trying file=/lib/haswell/x86_64/libhdfs.so\r\n      9322:\t  trying file=/lib/haswell/libhdfs.so\r\n      9322:\t  trying file=/lib/x86_64/libhdfs.so\r\n      9322:\t  trying file=/lib/libhdfs.so\r\n      9322:\t  trying file=/usr/lib/tls/haswell/x86_64/libhdfs.so\r\n      9322:\t  trying file=/usr/lib/tls/haswell/libhdfs.so\r\n      9322:\t  trying file=/usr/lib/tls/x86_64/libhdfs.so\r\n      9322:\t  trying file=/usr/lib/tls/libhdfs.so\r\n      9322:\t  trying file=/usr/lib/haswell/x86_64/libhdfs.so\r\n      9322:\t  trying file=/usr/lib/haswell/libhdfs.so\r\n      9322:\t  trying file=/usr/lib/x86_64/libhdfs.so\r\n      9322:\t  trying file=/usr/lib/libhdfs.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n      9322:\t\r\n      9322:\tfind library=libssl.so.1.1 [0]; searching\r\n      9322:\t search cache=/etc/ld.so.cache\r\n      9322:\t  trying file=/usr/lib/x86_64-linux-gnu/libssl.so.1.1\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /usr/lib/x86_64-linux-gnu/libssl.so.1.1\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /usr/lib/python2.7/lib-dynload/_ssl.x86_64-linux-gnu.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\t\r\n      9322:\t\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /usr/lib/python2.7/lib-dynload/_csv.x86_64-linux-gnu.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /usr/lib/python2.7/lib-dynload/termios.x86_64-linux-gnu.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/framework/fast_tensor_util.so\r\n      9322:\t\r\n      9322:\tfind library=libuuid.so.1 [0]; searching\r\n      9322:\t search cache=/etc/ld.so.cache\r\n      9322:\t  trying file=/lib/x86_64-linux-gnu/libuuid.so.1\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /lib/x86_64-linux-gnu/libuuid.so.1\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/wrapt/_wrappers.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /usr/lib/python2.7/lib-dynload/_json.x86_64-linux-gnu.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /usr/lib/python2.7/lib-dynload/_multiprocessing.x86_64-linux-gnu.so\r\n      9322:\t\r\n      9322:\tfind library=libhdf5-9028dcc4.so.103.0.0 [0]; searching\r\n      9322:\t search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/tls/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/tls/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/tls/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/tls:/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs\t\t(RPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/_errors.so)\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/tls/haswell/x86_64/libhdf5-9028dcc4.so.103.0.0\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/tls/haswell/libhdf5-9028dcc4.so.103.0.0\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/tls/x86_64/libhdf5-9028dcc4.so.103.0.0\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/tls/libhdf5-9028dcc4.so.103.0.0\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/haswell/x86_64/libhdf5-9028dcc4.so.103.0.0\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/haswell/libhdf5-9028dcc4.so.103.0.0\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/x86_64/libhdf5-9028dcc4.so.103.0.0\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/libhdf5-9028dcc4.so.103.0.0\r\n      9322:\t\r\n      9322:\tfind library=libhdf5_hl-db841637.so.100.1.1 [0]; searching\r\n      9322:\t search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs\t\t(RPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/_errors.so)\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/libhdf5_hl-db841637.so.100.1.1\r\n      9322:\t\r\n      9322:\tfind library=libsz-1c7dd0cf.so.2.0.1 [0]; searching\r\n      9322:\t search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./tls/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./tls/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./tls/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./tls:/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/.\t\t(RPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/libhdf5-9028dcc4.so.103.0.0)\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./tls/haswell/x86_64/libsz-1c7dd0cf.so.2.0.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./tls/haswell/libsz-1c7dd0cf.so.2.0.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./tls/x86_64/libsz-1c7dd0cf.so.2.0.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./tls/libsz-1c7dd0cf.so.2.0.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./haswell/x86_64/libsz-1c7dd0cf.so.2.0.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./haswell/libsz-1c7dd0cf.so.2.0.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./x86_64/libsz-1c7dd0cf.so.2.0.1\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./libsz-1c7dd0cf.so.2.0.1\r\n      9322:\t\r\n      9322:\tfind library=libaec-2147abcd.so.0.0.4 [0]; searching\r\n      9322:\t search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/.\t\t(RPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/libhdf5-9028dcc4.so.103.0.0)\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./libaec-2147abcd.so.0.0.4\r\n      9322:\t\r\n      9322:\tfind library=libz-a147dcb0.so.1.2.3 [0]; searching\r\n      9322:\t search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/.\t\t(RPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/libhdf5-9028dcc4.so.103.0.0)\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./libz-a147dcb0.so.1.2.3\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./libz-a147dcb0.so.1.2.3\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./libaec-2147abcd.so.0.0.4\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./libsz-1c7dd0cf.so.2.0.1\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/libhdf5-9028dcc4.so.103.0.0\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/libhdf5_hl-db841637.so.100.1.1\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/_errors.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/defs.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/_objects.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/_conv.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5r.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5t.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/utils.so\r\n      9322:\t\r\n      9327:\tfind library=libc.so.6 [0]; searching\r\n      9327:\t search cache=/etc/ld.so.cache\r\n      9327:\t  trying file=/lib/x86_64-linux-gnu/libc.so.6\r\n      9327:\t\r\n      9327:\t\r\n      9327:\tcalling init: /lib/x86_64-linux-gnu/libc.so.6\r\n      9327:\t\r\n      9327:\t\r\n      9327:\tinitialize program: sh\r\n      9327:\t\r\n      9327:\t\r\n      9327:\ttransferring control: sh\r\n      9327:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5z.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5a.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5s.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5p.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5ac.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/_proxy.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5d.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5ds.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5f.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5g.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5i.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5fd.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5pl.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5o.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5l.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/_lib/_ccallback_c.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/sparse/_sparsetools.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/sparse/_csparsetools.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/_shortest_path.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/_tools.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/_traversal.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/_min_spanning_tree.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/_reordering.so\r\n      9322:\t\r\n      9322:\tfind library=libjpeg-3b10b538.so.9.3.0 [0]; searching\r\n      9322:\t search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/tls/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/tls/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/tls/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/tls:/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs\t\t(RPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/_imaging.so)\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/tls/haswell/x86_64/libjpeg-3b10b538.so.9.3.0\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/tls/haswell/libjpeg-3b10b538.so.9.3.0\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/tls/x86_64/libjpeg-3b10b538.so.9.3.0\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/tls/libjpeg-3b10b538.so.9.3.0\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/haswell/x86_64/libjpeg-3b10b538.so.9.3.0\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/haswell/libjpeg-3b10b538.so.9.3.0\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/x86_64/libjpeg-3b10b538.so.9.3.0\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/libjpeg-3b10b538.so.9.3.0\r\n      9322:\t\r\n      9322:\tfind library=libopenjp2-b3d7668a.so.2.3.1 [0]; searching\r\n      9322:\t search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs\t\t(RPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/_imaging.so)\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/libopenjp2-b3d7668a.so.2.3.1\r\n      9322:\t\r\n      9322:\tfind library=libtiff-bd1961ca.so.5.5.0 [0]; searching\r\n      9322:\t search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs\t\t(RPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/_imaging.so)\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/libtiff-bd1961ca.so.5.5.0\r\n      9322:\t\r\n      9322:\tfind library=liblzma-6cd627ed.so.5.2.4 [0]; searching\r\n      9322:\t search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./tls/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./tls/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./tls/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./tls:/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/.\t\t(RPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/libtiff-bd1961ca.so.5.5.0)\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./tls/haswell/x86_64/liblzma-6cd627ed.so.5.2.4\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./tls/haswell/liblzma-6cd627ed.so.5.2.4\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./tls/x86_64/liblzma-6cd627ed.so.5.2.4\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./tls/liblzma-6cd627ed.so.5.2.4\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./haswell/x86_64/liblzma-6cd627ed.so.5.2.4\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./haswell/liblzma-6cd627ed.so.5.2.4\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./x86_64/liblzma-6cd627ed.so.5.2.4\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./liblzma-6cd627ed.so.5.2.4\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./liblzma-6cd627ed.so.5.2.4\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/libjpeg-3b10b538.so.9.3.0\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/libtiff-bd1961ca.so.5.5.0\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/libopenjp2-b3d7668a.so.2.3.1\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/_imaging.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/_scandir.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/ndimage/_nd_image.so\r\n      9322:\t\r\n      9322:\tfind library=libopenblasp-r0-2ecf47d5.3.7.dev.so [0]; searching\r\n      9322:\t search path=/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/tls/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/tls/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/tls/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/tls:/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/haswell/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/haswell:/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/x86_64:/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs\t\t(RPATH from file /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/_fblas.so)\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/tls/haswell/x86_64/libopenblasp-r0-2ecf47d5.3.7.dev.so\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/tls/haswell/libopenblasp-r0-2ecf47d5.3.7.dev.so\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/tls/x86_64/libopenblasp-r0-2ecf47d5.3.7.dev.so\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/tls/libopenblasp-r0-2ecf47d5.3.7.dev.so\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/haswell/x86_64/libopenblasp-r0-2ecf47d5.3.7.dev.so\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/haswell/libopenblasp-r0-2ecf47d5.3.7.dev.so\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/x86_64/libopenblasp-r0-2ecf47d5.3.7.dev.so\r\n      9322:\t  trying file=/home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/libopenblasp-r0-2ecf47d5.3.7.dev.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/libopenblasp-r0-2ecf47d5.3.7.dev.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/_fblas.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/_flapack.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/_flinalg.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/_solve_toeplitz.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/_decomp_update.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/cython_blas.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/cython_lapack.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/special/_ufuncs.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/special/_ufuncs_cxx.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/special/specfun.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/special/_comb.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/special/_ellip_harm_2.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/interpolate/_fitpack.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/interpolate/dfitpack.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/interpolate/_bspl.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/interpolate/_ppoly.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/interpolate/interpnd.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/spatial/ckdtree.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/spatial/qhull.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/_lib/messagestream.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/spatial/_voronoi.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/spatial/_distance_wrap.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/spatial/_hausdorff.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling init: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/ndimage/_ni_label.so\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /usr/bin/python [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /lib/x86_64-linux-gnu/libutil.so.1 [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /lib/x86_64-linux-gnu/libz.so.1 [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /usr/lib/x86_64-linux-gnu/libffi.so.6 [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/_multiarray_umath.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/_multiarray_tests.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/linalg/lapack_lite.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/linalg/_umath_linalg.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/libopenblasp-r0-34a18dc3.3.7.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /usr/lib/python2.7/lib-dynload/bz2.x86_64-linux-gnu.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /lib/x86_64-linux-gnu/libbz2.so.1.0 [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /usr/lib/python2.7/lib-dynload/future_builtins.x86_64-linux-gnu.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/fft/fftpack_lite.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/random/mtrand.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /usr/lib/python2.7/lib-dynload/_hashlib.x86_64-linux-gnu.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/../libtensorflow_framework.so.1 [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /usr/lib/python2.7/lib-dynload/_ssl.x86_64-linux-gnu.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /usr/lib/x86_64-linux-gnu/libssl.so.1.1 [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /usr/lib/x86_64-linux-gnu/libcrypto.so.1.1 [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\t\r\n      9322:\t\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /usr/lib/python2.7/lib-dynload/_csv.x86_64-linux-gnu.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /usr/lib/python2.7/lib-dynload/termios.x86_64-linux-gnu.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/tensorflow/python/framework/fast_tensor_util.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /lib/x86_64-linux-gnu/libuuid.so.1 [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/wrapt/_wrappers.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /usr/lib/python2.7/lib-dynload/_json.x86_64-linux-gnu.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /usr/lib/python2.7/lib-dynload/_multiprocessing.x86_64-linux-gnu.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/_errors.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/defs.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/_objects.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/_conv.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5r.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5t.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/utils.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5z.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5a.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5s.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5p.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5ac.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/_proxy.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5d.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5ds.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5f.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5g.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5i.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5fd.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5pl.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5o.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/h5l.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/libhdf5_hl-db841637.so.100.1.1 [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/libhdf5-9028dcc4.so.103.0.0 [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./libsz-1c7dd0cf.so.2.0.1 [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./libaec-2147abcd.so.0.0.4 [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /lib/x86_64-linux-gnu/libdl.so.2 [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/_lib/_ccallback_c.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/sparse/_sparsetools.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/sparse/_csparsetools.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/_shortest_path.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/_tools.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/_traversal.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/_min_spanning_tree.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/sparse/csgraph/_reordering.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/_imaging.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/libopenjp2-b3d7668a.so.2.3.1 [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/libtiff-bd1961ca.so.5.5.0 [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/libjpeg-3b10b538.so.9.3.0 [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/h5py/.libs/./libz-a147dcb0.so.1.2.3 [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/PIL/.libs/./liblzma-6cd627ed.so.5.2.4 [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /lib/x86_64-linux-gnu/librt.so.1 [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/_scandir.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/ndimage/_nd_image.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/_fblas.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/_flapack.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/_flinalg.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/_solve_toeplitz.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/_decomp_update.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/cython_blas.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/cython_lapack.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/special/_ufuncs.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/special/_ufuncs_cxx.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/special/specfun.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/special/_comb.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/special/_ellip_harm_2.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/interpolate/_fitpack.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/interpolate/dfitpack.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/interpolate/_bspl.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/interpolate/_ppoly.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/interpolate/interpnd.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/spatial/ckdtree.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /usr/lib/x86_64-linux-gnu/libstdc++.so.6 [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/spatial/qhull.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/linalg/../.libs/libopenblasp-r0-2ecf47d5.3.7.dev.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /lib/x86_64-linux-gnu/libgcc_s.so.1 [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/numpy/core/../.libs/libgfortran-ed201abd.so.3.0.0 [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/_lib/messagestream.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/spatial/_voronoi.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/spatial/_distance_wrap.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /lib/x86_64-linux-gnu/libm.so.6 [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/spatial/_hausdorff.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /home/andreiungureanu/.local/lib/python2.7/site-packages/scipy/ndimage/_ni_label.so [0]\r\n      9322:\t\r\n      9322:\t\r\n      9322:\tcalling fini: /lib/x86_64-linux-gnu/libpthread.so.0 [0]\r\n      9322:\t\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\n./tf_env_collect.sh: line 147: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n\r\n== tensorflow installed from info ==================\r\nName: tensorflow\r\nVersion: 1.14.0\r\nSummary: TensorFlow is an open source machine learning framework for everyone.\r\nHome-page: https://www.tensorflow.org/\r\nAuthor-email: packages@tensorflow.org\r\nLicense: Apache 2.0\r\nLocation: /home/andreiungureanu/.local/lib/python2.7/site-packages\r\n\r\n== python version  ==============================================\r\n(major, minor, micro, releaselevel, serial)\r\n(2, 7, 17, 'final', 0)\r\n\r\n== bazel version  ===============================================\r\n```", "comments": ["@AndreiUngureanu101 \r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "Thanks for the response, I updated the details about the error.\r\n\r\nI'm trying to convert the Deep SORT model presented here:\r\n\r\nhttps://github.com/nwojke/deep_sort\r\n\r\nusing the ckpt, meta and pb files that can be downloaded from here:\r\n\r\nhttps://drive.google.com/drive/folders/1m2ebLHB2JThZC8vWGDYEKGsevLssSkjo\r\n\r\nThanks!", "So I got passed the error running this:\r\n\r\n```\r\ntoco --graph_def_file=workspace/saved_model.pb --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --output_file=workspace/saved_model.tflite --inference_type=QUANTIZED_UINT8 --input_type=QUANTIZED_UINT8 inference type=QUANTIZED_UINT8 --data_type=QUANTIZED_UINT8 --input_arrays=images --output_arrays=features --input_shapes=1,128,64,3 --std_dev_values=127 --mean_values=128 --default_ranges_min=2 --default_ranges_max=16\r\n```\r\nand got a new error:\r\n```\r\nCheck failed: s.ok() Unimplemented: this graph contains an operator of type Cast for which the quantized form is not yet implemented. Sorry, and patches welcome (that's a relatively fun patch to write, mostly providing the actual quantized arithmetic code for this op).\r\nFatal Python error: Aborted\r\n```", "@AndreiUngureanu101 \r\nPlease refer these below links and let us know if it helps:\r\n\r\n#32452 #39614 #26478 [link](https://stackoverflow.com/questions/50153289/unsupported-tensorflow-op-dequantize?rq=1) [link1](https://www.gitmemory.com/issue/tensorflow/tensorflow/27314/478650089)", "@Saduf2019, thanks for the reply but none of these solutions worked", "@AndreiUngureanu101 \r\nCan you please provide with simple stand alone code for us to replicate the latest error faced by you \"Check failed: s.ok() Unimplemented: this graph contains an operator of type Cast.....\r\nFatal Python error: Aborted\" or if possible please share a colab gist with the error faced.", "Hi @Saduf2019,\r\n\r\nHere are the steps I took before getting the error:\r\n\r\n- I downloaded `mars-small128.pb` from: https://drive.google.com/drive/folders/1m2ebLHB2JThZC8vWGDYEKGsevLssSkjo and renamed it to 'saved_model.pb'\r\n- I installed tensorflow v1.14.0\r\n- I browsed the graph to get the 'input_arrays', 'output_arrays' and 'input_shapes' values\r\n- I ran the following line: \r\n\r\n``\r\ntoco --graph_def_file=workspace/saved_model.pb --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --output_file=workspace/saved_model.tflite --inference_type=QUANTIZED_UINT8 --input_type=QUANTIZED_UINT8 inference type=QUANTIZED_UINT8 --data_type=QUANTIZED_UINT8 --input_arrays=images --output_arrays=features --input_shapes=1,128,64,3 --std_dev_values=127 --mean_values=128 --default_ranges_min=2 --default_ranges_max=16\r\n``\r\n\r\nand got the error. I'm not sure what the 'default_ranges_min' and 'default_ranges_max' parameters mean so I just put two values there.\r\n\r\nThat's about it. Thanks for checking this error!\r\n\r\n", "1. toco is a deprecated method of converting models. If possible, switch to using the Python API instead. I have added some sample code below for reference (The `.from_frozen_graph` can be defined [this](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/lite/TFLiteConverter#from_frozen_graph) way and the attributes which can be added are [here](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/lite/TFLiteConverter#attributes))\r\n\r\n2. Also, the Cast op does not have a quantized implementation yet. By using [these steps](https://www.tensorflow.org/lite/performance/post_training_quantization#integer_with_float_fallback_using_default_float_inputoutput) instead, the Cast op will be float but operators that can be quantized will be converter to integer ops. \r\n\r\nHere is a possible workflow to get you started (this will not work as you need to modify the `representative_dataset_gen()` function to provide sample data that can be used to quantize the model. As these are images, use ~100-500 images that were used during training -- if you can access it -- otherwise use any random images. If the images were preprocessed, then ensure you preprocess these images as well):\r\n\r\n```\r\nconverter = tf.lite.TFLiteConverter.from_frozen_graph(\r\n    graph_def_file='workspace/saved_model.pb', \r\n    input_arrays=['images'],\r\n    output_arrays=['features'],\r\n    input_shapes={'images' : [1, 128, 64, 3]}\r\n)\r\n# Instead of the following 2 lines, use \".optimizations\" and \".representative_dataset\" instead.\r\n# converter.inference_type = tf.uint8\r\n# converter.quantized_input_stats = {'images': (128, 127)} # (mean, standard deviation)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\ndef representative_dataset_gen():\r\n  for _ in range(num_calibration_steps):\r\n    # Get sample input data as a numpy array in a method of your choosing.\r\n    yield [input]\r\nconverter.representative_dataset = representative_dataset_gen\r\nconverter.inference_input_type = tf.uint8 # Remove this if you want your model to have float input\r\nconverter.inference_output_type = tf.uint8 # Remove this if you want your model to have float output\r\ntflite_model = converter.convert()\r\n\r\ntflite_model_size = open('workspace/saved_model.tflite', 'wb').write(tflite_model)\r\nprint('TFLite Model is %d bytes' % tflite_model_size)\r\n```\r\n\r\n", "Closing issue due to user inactivity. Feel free to re-open it if the issue persists.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39786\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39786\">No</a>\n"]}, {"number": 39785, "title": "TF-TRT test Binary op conversion in dynamic shape mode ", "body": "This PR adds explicit batch and dynamic shape tests to the Binary op converter. Tagging @bixia1 for review.", "comments": []}, {"number": 39784, "title": "Tf.shape() does not support RaggedTensor", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n\r\nYes\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n\r\nUbuntu 16.04\r\n\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n\r\nNo\r\n\r\n- TensorFlow installed from (source or binary):\r\n\r\nbinary\r\n\r\n- TensorFlow version (use command below):\r\n\r\nv2.1.0-rc2-17-ge5bf8de 2.1.0\r\n\r\n- Python version:\r\n\r\n3.6.8\r\n\r\n- Bazel version (if compiling from source):\r\n\r\nNo\r\n\r\n- GCC/Compiler version (if compiling from source):\r\n\r\nNo\r\n\r\n- CUDA/cuDNN version:\r\n\r\nCPU only\r\n\r\n- GPU model and memory:\r\n\r\nCPU only\r\n\r\n**Describe the current behavior**\r\nCalling `tf.shape()` on a RaggedTensor results in an error:\r\n`TypeError: object of type 'RaggedTensor' has no len `\r\n\r\n\r\n**Describe the expected behavior**\r\nIt should return the shape of the tensor, similar to calling `RaggedTensor.shape`\r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://colab.research.google.com/drive/1aN0DJwRbjDrt9-xu3tWmoNvth24a1wm0?usp=sharing\r\n\r\n```\r\nimport tensorflow as tf\r\nragged = tf.ragged.constant([[0.1, 0.3, 0.5],\r\n                                           [0.1],\r\n                                            [0.4,0.5]])\r\nprint(ragged)\r\nprint(ragged.shape)\r\ntf.shape(ragged)\r\n```\r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to**\r\n-", "comments": ["I have tried in colab with TF version 2.1.0, 2.2.0, nightly version (2.3.0-dev20200522) and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/36d3b2a96c8c192d2250ba20be34f86c/untitled928.ipynb).Thanks!", "@JohannesAck Are you looking for `ragged.bounding_shape()`?\r\n` print(ragged.bounding_shape()) # tf.Tensor([3 3], shape=(2,), dtype=int64)`\r\n\r\ntf.shape(x) output dynamic shape of `x` where as x.shape() output static shape (with `None` in its dimensions wherever applicable). Dynamic shape cannot be possible if a tensor has a `None` in its dimensions.  Please check this [resource](https://stackoverflow.com/questions/37096225/how-to-understand-static-shape-and-dynamic-shape-in-tensorflow) for more info about x.shape versus tf.shape(x).\r\n\r\nPlease check the following example about shape function of ragged tensor. \r\n\r\n\r\n> The RaggedTensor.shape attribute returns a tf.TensorShape for a ragged tensor, where ragged dimensions have size None:\r\n> \r\n> tf.ragged.constant([[\"Hi\"], [\"How\", \"are\", \"you\"]]).shape\r\n> \r\n> TensorShape([2, None])\r\n> \r\n> The method tf.RaggedTensor.bounding_shape can be used to find a tight bounding shape for a given RaggedTensor:\r\n> \r\n> print(tf.ragged.constant([[\"Hi\"], [\"How\", \"are\", \"you\"]]).bounding_shape())\r\n> \r\n> tf.Tensor([2 3], shape=(2,), dtype=int64)\r\n\r\nPlease check [ragged_tensor](https://www.tensorflow.org/guide/ragged_tensor) guide on TensorFlow website. \r\n\r\nPlease take a look at the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/8cc8e51e02892828243291b32103ac4f/39784.ipynb). Please verify once and close the issue if this was resolved for you. Thanks!\r\n\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39784\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39784\">No</a>\n"]}, {"number": 39783, "title": "how to get the shared library containing the TfLite Delegate.of tf.lite.experimental.load delegate", "body": "I am doing a real-time palm detection, using opencv to get the camera screen and input it into the tiflite model, to get the palm position and other information, and finally using opencv to frame the palm.The system I use is ubuntu18.04 and the language is python3.7.If I only use the CPU, I have done it. Because the delay is too large, I want to use the GPU to accelerate the model prediction.But I didn't find any example of GPU acceleration of tflite model on linux, both android and ios. I only saw the delegate GPU on the python api.\r\nLike,follow:\r\n> tf.lite.Interpreter(\r\n>     model_path=None, model_content=None, experimental_delegates=None\r\n> )\r\n\r\n\r\n> tf.lite.experimental.load_delegate(\r\n>     library, options=None\r\n> )\r\n\r\nlibrary | Name of shared library containing the TfLiteDelegate.\r\n\r\noptions | Dictionary of options that are required to load the delegate. All keys and values in the dictionary should be convertible to str. Consult the documentation of the specific delegate for required and legal options. (default None)\r\n\r\nBut I don't know how to generate the library which containing the TfLiteDelegate.\r\nCan anyone give me some advice\uff1fThanks very much.\r\n\r\n\r\n\r\n", "comments": ["A quick clarification: Is the model running on a desktop, or an Android/iOS phone?", "It's running on a desktop of ubuntu,thanks.", "For now, gpu delegate only works on Android and iOS.\r\nhttps://github.com/tensorflow/tensorflow/issues/37116#issuecomment-592230951", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 39782, "title": "How to get the learning rate in optimizer during training?", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): TF 2.0\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nWhen I am training the model with `tf.keras.optimizers.Adam` optimizer, I want to extract the learning rate during training to add it into the tensorboard. I did not find any API for this function. And the only result I found on Google is https://stackoverflow.com/questions/55622400/can-you-extract-the-current-learning-rate-from-tf-keras-adam, which suggested to calculate it by myself. I wonder if such API exists or will be added in the future.\r\n\r\n**Will this change the current api? How?**\r\nNo. May add new features.\r\n\r\n**Who will benefit with this feature?**\r\nPotentially everyone.\r\n\r\n**Any Other info.**\r\n", "comments": ["You may try https://github.com/keras-team/keras/issues/2823#issuecomment-221895779 in this case.", "> You may try [keras-team/keras#2823 (comment)](https://github.com/keras-team/keras/issues/2823#issuecomment-221895779) in this case.\r\n\r\nThis is basically calculating the learning rate by ourselves and is duplicate with the code inside the optimizer. And it also relies on correct math when writing the code. Why not adding an API to extract the learning rate directly instead of writing extra code?", "Hi, @zhangjh915 \r\nYou misunderstand that case. It's a custom lr scheduler, so we need to calculate the new lr according to training steps or epochs.\r\nIf you just need log the lr to tensorboard, a `tf.keras.callbacks.Callback` can be useful.\r\n\r\n```python\r\nclass LearningRateLoggingCallback(tf.keras.callbacks.Callback):\r\n\r\n    def on_epoch_end(self, epoch):\r\n        lr = self.model.optimizer.lr\r\n        tf.summary.scalar('learning rate', data=lr, step=epoch)\r\n```\r\n\r\nHere has an example: [TensorBoard Scalars: Logging training metrics in Keras](https://www.tensorflow.org/tensorboard/scalars_and_keras)", "It might be a meta algorithm. Feeding the feedback loop.\n\nOn Fri, Jun 5, 2020, 1:48 PM luozhouyang <notifications@github.com> wrote:\n\n> Hi, @zhangjh915 <https://github.com/zhangjh915>\n> You misunderstand that case. It's a custom lr scheduler, so we need to\n> calculate the new lr according to training steps or epochs.\n> If you just need log the lr to tensorboard, a tf.keras.callbacks.Callback\n> can be useful.\n>\n> class LearningRateLoggingCallback(tf.keras.callbacks.Callback):\n>\n>     def on_epoch_end(self, epoch):\n>         lr = self.model.optimizer.lr\n>         tf.summary.scalar('learning rate', data=lr, step=epoch)\n>\n> Here has an example: TensorBoard Scalars: Logging training metrics in\n> Keras <https://www.tensorflow.org/tensorboard/scalars_and_keras>\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/39782#issuecomment-639429912>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AIT525SAIF57HNU4LB5YBOTRVDLR3ANCNFSM4NHQ7MFQ>\n> .\n>\n", "> Hi, @zhangjh915\r\n> You misunderstand that case. It's a custom lr scheduler, so we need to calculate the new lr according to training steps or epochs.\r\n> If you just need log the lr to tensorboard, a `tf.keras.callbacks.Callback` can be useful.\r\n> \r\n> ```python\r\n> class LearningRateLoggingCallback(tf.keras.callbacks.Callback):\r\n> \r\n>     def on_epoch_end(self, epoch):\r\n>         lr = self.model.optimizer.lr\r\n>         tf.summary.scalar('learning rate', data=lr, step=epoch)\r\n> ```\r\n> \r\n> Here has an example: [TensorBoard Scalars: Logging training metrics in Keras](https://www.tensorflow.org/tensorboard/scalars_and_keras)\r\n\r\nI am using a customer training loop so I cannot use callback. And if I directly extract the learning rate from the optimizer, say `optimizer.lr`, it is always the initial learning rate instead of the varying learning rate during training.", "@zhangjh915 This is what I need too, I htop there is an API which helps us to retrieve this param", "@zhangjh915 @minhhoangbui \r\nFrom this code, you can get the decayed learning rate during training.\r\n```\r\nprint(optimizer._decayed_lr('float32').numpy())\r\n```", "Are there any update on this issue? I desperately need an API to log actual learning rate and writing the calculation having big risk of math error.", "> Are there any update on this issue? I desperately need an API to log actual learning rate and writing the calculation having big risk of math error.\r\n\r\nProblem solved. Try what @noirmist said.", "Hello\r\n\r\nHow can I log the learning rate if using tf.keras.optimizers.schedules.ExponentialDecay", "@marcojulioarg \r\n\r\nin general, you should be able to do this:\r\n\r\n```\r\nif isinstance(optimizer.lr, tf.keras.optimizers.schedules.LearningRateSchedule):\r\n    current_lr = optimizer.lr(optimizer.iterations)\r\nelse:\r\n    current_lr = optimizer.lr\r\n```\r\n\r\nLearning rate schedulers have to define a `__call__` method that takes a `step` argument. You can get the updated training step using `optimizer.iterations`---this keeps track over epochs as well.\r\n\r\nNB: If you have no trainable weights whatsoever in your model, then the learning rate will be constant regardless if you're using a learning rate scheduler or not."]}, {"number": 39781, "title": "[TF.Distribute] ctx.all_reduce is failed in the codition depends on layer-intenal variable.", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab GPU\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:  No\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.2\r\n- GPU model and memory: I don't know (Google Colab served  one.)\r\n\r\n**Describe the current behavior**\r\n\r\n```python\r\nclass DataDepInitInternal(DataDepInit):\r\n  \"\"\"\r\n  initialized is internal variable as Bool\r\n  w is internal variable as Tensor\r\n  \"\"\"\r\n  def initialize(self, x):\r\n    ctx = tf.distribute.get_replica_context()\r\n    if ctx:\r\n      n = ctx.num_replicas_in_sync * 1.0\r\n      mean,*_ = ctx.all_reduce(tf.distribute.ReduceOp.SUM, [tf.reduce_mean(x, axis=[0, 1, 2], keepdims=True) / n])\r\n    return mean\r\n\r\n  def call(self, x, first=True):\r\n    if self.initialized: # <- this condition and below assignment cause error.\r\n      self.initialized.assign(True)\r\n      self.w.assign(self.initialize(x))\r\n    return x - self.w\r\n```\r\n**Describe the expected behavior**\r\nlike this. (this layer use argument for condition, but I don't want to use it.\r\n```python\r\nclass DataDepInitInternal(DataDepInit):\r\n  \"\"\"\r\n  initialized is internal variable as Bool\r\n  w is internal variable as Tensor\r\n  \"\"\"\r\n  def initialize(self, x):\r\n    ctx = tf.distribute.get_replica_context()\r\n    if ctx:\r\n      n = ctx.num_replicas_in_sync * 1.0\r\n      mean,*_ = ctx.all_reduce(tf.distribute.ReduceOp.SUM, [tf.reduce_mean(x, axis=[0, 1, 2], keepdims=True) / n])\r\n    return mean\r\n\r\n  def call(self, x, first=True):\r\n    if first:\r\n      self.initialized.assign(True)\r\n      self.w.assign(self.initialize(x))\r\n    return x - self.w\r\n```\r\n\r\n**Standalone code to reproduce the issue**\r\nAll reproducal code is here. https://colab.research.google.com/gist/MokkeMeguru/dbe76b1da29366f9e52fef849c449e7e/data-dep-iinitialization.ipynb\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\nsee. colab, please.\r\n\r\nThanks!", "comments": ["I have tried in colab with TF -GPU 2.2 , nightly versions and was able to reproduce the issue.Please, find the gist [here.](https://colab.sandbox.google.com/gist/ravikyram/ec28440b0c1c433ac4bb7f1c46c379c2/untitled927.ipynb)Thanks!", "I tried to run the code on colab with TF v2.5 and faced different error .Please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/2de6ebed2587cfd2286ff76dc4eaa8cd/untitled320.ipynb)..Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39781\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39781\">No</a>\n"]}, {"number": 39780, "title": "`tf.Module` saves in an invalid state when `tf.function` references a variable defined in another scope", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux, Fedora 32 x86_64\r\n- TensorFlow installed from (source or binary): `pip install tensorflow`, \r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.8.2\r\n- CUDA/cuDNN version: 10.2.89 / 7.6.5.32\r\n- GPU model and memory: NVIDIA GeForce GTX 960M\r\n\r\n**Describe the current behavior**\r\nI am wrapping a Keras model within a `tf.Module` which has a `tf.function` that runs a training step. As part of that I calculate a loss. If the loss function references a variable defined in a different scope, the model seems to serialize successfully, but `saved_model_cli show --dir $DIR --all` crashes with a `KeyError` related to the `tf.function` when run on the model that was saved. This suggests that the model saved was in some way invalid---something that should have been caught prior to saving.\r\n\r\n```\r\njosh@achebe:~/Projects/Umpire$ ./venv/bin/saved_model_cli show --dir ai/umpire_regressor --all\r\n\r\nMetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\r\n\r\nsignature_def['__saved_model_init_op']:\r\n  The given SavedModel SignatureDef contains the following input(s):\r\n  The given SavedModel SignatureDef contains the following output(s):\r\n    outputs['__saved_model_init_op'] tensor_info:\r\n        dtype: DT_INVALID\r\n        shape: unknown_rank\r\n        name: NoOp\r\n  Method name is: \r\nWARNING:tensorflow:From /home/josh/Projects/Umpire/venv/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\nTraceback (most recent call last):\r\n  File \"./venv/bin/saved_model_cli\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/home/josh/Projects/Umpire/venv/lib/python3.8/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 1153, in main\r\n    args.func(args)\r\n  File \"/home/josh/Projects/Umpire/venv/lib/python3.8/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 714, in show\r\n    _show_all(args.dir)\r\n  File \"/home/josh/Projects/Umpire/venv/lib/python3.8/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 306, in _show_all\r\n    _show_defined_functions(saved_model_dir)\r\n  File \"/home/josh/Projects/Umpire/venv/lib/python3.8/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 186, in _show_defined_functions\r\n    trackable_object = load.load(saved_model_dir)\r\n  File \"/home/josh/Projects/Umpire/venv/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py\", line 578, in load\r\n    return load_internal(export_dir, tags)\r\n  File \"/home/josh/Projects/Umpire/venv/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py\", line 602, in load_internal\r\n    loader = loader_cls(object_graph_proto,\r\n  File \"/home/josh/Projects/Umpire/venv/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py\", line 123, in __init__\r\n    self._load_all()\r\n  File \"/home/josh/Projects/Umpire/venv/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py\", line 134, in _load_all\r\n    self._load_nodes()\r\n  File \"/home/josh/Projects/Umpire/venv/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py\", line 264, in _load_nodes\r\n    node, setter = self._recreate(proto, node_id)\r\n  File \"/home/josh/Projects/Umpire/venv/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py\", line 370, in _recreate\r\n    return factory[kind]()\r\n  File \"/home/josh/Projects/Umpire/venv/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py\", line 359, in <lambda>\r\n    \"function\": lambda: self._recreate_function(proto.function),\r\n  File \"/home/josh/Projects/Umpire/venv/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py\", line 397, in _recreate_function\r\n    return function_deserialization.recreate_function(\r\n  File \"/home/josh/Projects/Umpire/venv/lib/python3.8/site-packages/tensorflow/python/saved_model/function_deserialization.py\", line 265, in recreate_function\r\n    concrete_function_objects.append(concrete_functions[concrete_function_name])\r\nKeyError: '__inference_fit_action_1159'\r\n```\r\n\r\n**Describe the expected behavior**\r\nWhen I try to serialize a model, it should either serialize in a form that can be read by `saved_model_cli` or an error should be emitted.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import Input, Model\r\nfrom tensorflow.keras.layers import Dense\r\n\r\nfX = tf.float32\r\n\r\nclass TrainableAI(tf.Module):\r\n    def __init__(self, keras_model, *args, **kwargs):\r\n        self.model = keras_model\r\n        super().__init__(*args, **kwargs)\r\n\r\n    @tf.function(input_signature=[\r\n        tf.TensorSpec(shape=(1,14,), dtype=fX),#1d_features\r\n        tf.TensorSpec(shape=(1,19,), dtype=fX),# true_action_values\r\n    ])\r\n    def fit_action(self, _1d_features, true_action_values):\r\n        estimated_action_values = self.model(_1d_features)\r\n        mse = tf.keras.losses.MeanSquaredError()\r\n        loss = mse(estimated_action_values, true_action_value)\r\n\r\n\r\ninput = Input(shape=(14,), name='1d_features', dtype=fX)\r\ndense = Dense(64, activation='relu', name=\"dense0\")(input)\r\naction_value_estimate = Dense(1, activation='linear', name='estimate')(dense)\r\ntrue_action_value = Input([1], dtype=fX, name='true_action_values')\r\n\r\nmodel = Model(inputs=input, outputs=action_value_estimate, name='umpire_regressor')\r\ntrainable_ai = TrainableAI(model)\r\n\r\ntf.saved_model.save(trainable_ai, 'umpire_regressor')\r\n```\r\n\r\nThen `saved_model_cli show --dir umpire_regressor --all`\r\n\r\nNote that there is a typo where `action_value_estimate` is referenced instead of `action_value_estimates`. `action_value_estimate` without the trailing `s` is defined in the `if __name__==\"__main__\"` block. Resolving this typo resolves the error; however, the bug is that this was saved in an invalid state instead of an exception being thrown.\r\n\r\nI tried running this in a Kaggle container running TF 2.1.0 and it caught the problem, so this may be a regression post-2.1.0.", "comments": ["Was able to reproduce the error with [TF v2.1](https://colab.research.google.com/gist/amahendrakar/3fd00db62d096e0f5a9322d26b7f2931/39780-2-1.ipynb#scrollTo=vNy2Pmpl1F2_), [TF v2.2](https://colab.research.google.com/gist/amahendrakar/70be824d707de6f0925fe71b3f9e0a96/39780-2-2.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/e95ee8d4da90a02f03d760aba6fecff4/39780-tf-nightly.ipynb). Please find the attached gist. Thanks!", "Yep, looks like it. By contrast, the Kaggle container running 2.1.0 gives `\r\nValueError: Attempted to save a function b'__inference_fit_action_95' which references a symbolic Tensor Tensor(\"true_action_values:0\", shape=(None, 1), dtype=float32) that is not a simple constant. This is not supported.`", "@joshhansen I think this was resolved in recent `tf-nightly`. I am not able to reproduce the issue. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/1a2069fa920e8ffd6567288de9207915/39780-tf-nightly.ipynb). Thanks!\r\n\r\nPlease verify once and close the issue if this was resolved for you. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39780\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39780\">No</a>\n"]}, {"number": 39779, "title": "tfa ReduceLROnPlateau callback from Tf keras is not recognizing cohen kappa metrics direction in 'Auto' mode", "body": "", "comments": []}, {"number": 39778, "title": "cuda 10.2 issue", "body": "Can tensorflow provide alternative CUDA prebuilt version as pytorch does?\r\n\r\nthis is really behind pytorch official site say supports cuda 10.1 only:\r\n\r\n![image](https://user-images.githubusercontent.com/21303438/82635669-44d07a00-9c33-11ea-9bad-d407999f4331.png)\r\n\r\nYou can see pytorch is so user-friendly it provides every CUDA version prebuilt binarys.... I mean every not literally every but at least the decent on of CUDA 10.2.. (since cuda 11 out, 10.2 is not the newest)\r\n\r\nBut 10.2 is really common used in pytorch now...", "comments": ["Duplicate of #39247 \r\n\r\nMeanwhile, you can symlink CUDA 10.2 to CUDA 10.1 and TF will work without any issues.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39778\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39778\">No</a>\n"]}, {"number": 39777, "title": "AttributeError: module 'tensorflow.keras.layers.experimental' has no attribute 'EinsumDense'", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  mac os \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binany (pip)\r\n- TensorFlow version:  2.2.0\r\n- Python version: 3.6.0\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@asking1233,\r\nAs per the [documentation for EinsumDense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/EinsumDense) the API is available only on TF-nightly.\r\n\r\nUsing TF-nightly, I was able to import the API without any issues, please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/6ebf3f4e9c27407f36401c2376805b46/39777.ipynb). Thanks!", "thanks,I  get it", "Marking the issue as closed, as it is resolved."]}, {"number": 39776, "title": "'Model' object has no attribute 'total_loss' [2.2 Eager]", "body": "Below works in TF 2.1 and 2.0 Eager & Graph, and 2.2 Graph, but not 2.2 Eager; how, then, are we to get gradients in 2.2 Eager?\r\n\r\n<hr>\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Input, Dense\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras import backend as K\r\n\r\nipt = Input((16,))\r\nout = Dense(16)(ipt)\r\nmodel = Model(ipt, out)\r\nmodel.compile('adam', 'mse')\r\n\r\nx = y = np.random.randn(32, 16)\r\nmodel.train_on_batch(x, y)\r\n\r\noutputs = model.optimizer.get_gradients(model.total_loss, model.trainable_weights)\r\ninputs  = [model.inputs[0], model._feed_targets[0]]\r\n\r\ngrads_fn = K.function(inputs, outputs)\r\ngrads    = grads_fn([x, y])\r\n_ = [print(g.shape) for g in grads]\r\n```\r\n\r\n", "comments": ["[Figured it out](https://stackoverflow.com/questions/61887944/how-to-get-gradients-in-tf-2-2-eager/#answer-61952452)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39776\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39776\">No</a>\n"]}, {"number": 39775, "title": "Broken in v2.2.0: set_visible_devices() is used with tf.keras.mixed_precision", "body": "If you use set_visible_devices with tf.keras.mixed_precision, you get a crash in v2.2.0.\r\n\r\nThis was fixed in this commit: https://github.com/tensorflow/tensorflow/commit/f748283ee01059be52da5dada6e2157d9f6732ba\r\n\r\nHowever, for some reason, in v2.2.0 the fix is applied in a way that is very broken and ineffective. On `master` this seems like this commit was applied correctly.\r\n\r\nSpecifically, on tag v2.2.0:\r\n```python\r\n  device_attr_list = device_lib.list_local_devices()\r\n  if not skip_local:\r\n    _log_device_compatibility_check(policy_name, device_attr_list)\r\n    return\r\n```\r\nOn master: \r\n```python\r\n  if not skip_local:\r\n    device_attr_list = device_lib.list_local_devices()\r\n    _log_device_compatibility_check(policy_name, device_attr_list)\r\n    return\r\n```\r\nThe whole point of `skip_local` is to avoid calling that function so moving this line renders that fix ineffective.\r\n\r\nI'm a little confused how this happened, maybe a cherry pick gone wrong, but I thought I would put this issue here in case anyone hits this issue. I don't know if v2.2.0 can be fixed or we just have to wait for v2.3.0 (since master has the fix).", "comments": ["If nothing needs to be done (because the fix is already on master and it's too late to fix v2.2.0), please feel free to close this issue.", "@gibiansky \r\n\r\nRequest you to share colab link or simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "@ravikyram \r\n\r\n```\r\n$ python --version\r\nPython 3.8.2\r\n$ nvidia-smi\r\nFri May 22 14:55:49 2020       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 418.40.04    Driver Version: 418.40.04    CUDA Version: 10.1     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla V100-SXM2...  On   | 00000000:00:1B.0 Off |                    0 |\r\n| N/A   33C    P0    37W / 300W |      0MiB / 16130MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla V100-SXM2...  On   | 00000000:00:1C.0 Off |                    0 |\r\n| N/A   31C    P0    36W / 300W |      0MiB / 16130MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  Tesla V100-SXM2...  On   | 00000000:00:1D.0 Off |                    0 |\r\n| N/A   34C    P0    39W / 300W |      0MiB / 16130MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\r\n| N/A   36C    P0    39W / 300W |      0MiB / 16130MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n$ cat test.py\r\nimport tensorflow as tf\r\n\r\nprint(tf.__version__)\r\nprint(tf.__git_version__)\r\n\r\ndevices = tf.config.list_physical_devices(\"GPU\")\r\ntf.config.experimental.set_visible_devices(devices[1], \"GPU\")\r\ntf.keras.mixed_precision.experimental.set_policy(\"mixed_float16\")\r\n$ python test.py\r\n2.2.0                                                                                                                                                                                                                      \r\nv2.2.0-rc4-8-g2b96f3662b                                                                                                                                                                                                   \r\n2020-05-22 14:54:03.085746: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1                                                                               \r\n2020-05-22 14:54:03.220530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:03.221673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:                                                                                                       \r\npciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0                                                                                                                                                   \r\ncoreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s                                                                                                                             \r\n2020-05-22 14:54:03.221763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:03.222822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties:                                                                                                       \r\npciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0                                                                                                                                                   \r\ncoreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s                                                                                                                             \r\n2020-05-22 14:54:03.222893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:03.223974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 2 with properties:                                                                                                       \r\npciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0                                                                                                                                                   \r\ncoreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s                                                                                                                             \r\n2020-05-22 14:54:03.224043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:03.225141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 3 with properties:                                                                                                       \r\npciBusID: 0000:00:1e.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0                                                                                                                                                   \r\ncoreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s                                                                                                                             \r\n2020-05-22 14:54:03.225387: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1                                                                          \r\n2020-05-22 14:54:03.227125: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10                                                                            \r\n2020-05-22 14:54:03.228854: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10                                                                             \r\n2020-05-22 14:54:03.229144: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10                                                                            \r\n2020-05-22 14:54:03.231083: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10                                                                          \r\n2020-05-22 14:54:03.232247: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10                                                                          \r\n2020-05-22 14:54:03.236724: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7                                                                              \r\n2020-05-22 14:54:03.236820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:03.237974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:03.239110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:03.240261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:03.241376: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:03.242512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:03.243646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:03.244761: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:03.245842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1, 2, 3                                                                                                \r\n2020-05-22 14:54:03.246859: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA                                              \r\n2020-05-22 14:54:03.275798: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2300050000 Hz                                                                                                        \r\n2020-05-22 14:54:03.277499: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4708000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:                           \r\n2020-05-22 14:54:03.277525: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version                                                                                           \r\n2020-05-22 14:54:03.391569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:03.392912: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5619d1dc11a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:                           \r\n2020-05-22 14:54:03.392939: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0                                                                    \r\n2020-05-22 14:54:03.393122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:03.394229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:                                                                                                       \r\npciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0                                                                                                                                                   \r\ncoreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s                                                                                                                             \r\n2020-05-22 14:54:03.394278: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1                                                                          \r\n2020-05-22 14:54:03.394301: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10                                                                            \r\n2020-05-22 14:54:03.394323: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10                                                                             \r\n2020-05-22 14:54:03.394345: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10                                                                            \r\n2020-05-22 14:54:03.394365: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10                                                                          \r\n2020-05-22 14:54:03.394386: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10                                                                          \r\n2020-05-22 14:54:03.394400: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7                                                                              \r\n2020-05-22 14:54:03.394461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:03.395606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:03.396677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 1                                                                                                         \r\n2020-05-22 14:54:03.396718: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1                                                                          \r\n2020-05-22 14:54:03.401843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:                                                                       \r\n2020-05-22 14:54:03.401866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      1                                                                                                                                \r\n2020-05-22 14:54:03.401879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   N                                                                                                                                \r\n2020-05-22 14:54:03.402669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:03.403797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:03.394229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:                                                                                                       \r\npciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0                                                                                                                                                   \r\ncoreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s                                                                                                                             \r\n2020-05-22 14:54:03.394278: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1                                                                          \r\n2020-05-22 14:54:03.394301: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10                                                                            \r\n2020-05-22 14:54:03.394323: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10                                                                             \r\n2020-05-22 14:54:03.394345: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10                                                                            \r\n2020-05-22 14:54:03.394365: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10                                                                          \r\n2020-05-22 14:54:03.394386: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10                                                                          \r\n2020-05-22 14:54:03.394400: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7                                                                              \r\n2020-05-22 14:54:03.394461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:03.395606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:03.396677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 1                                                                                                         \r\n2020-05-22 14:54:03.396718: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1                                                                          \r\n2020-05-22 14:54:03.401843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:                                                                       \r\n2020-05-22 14:54:03.401866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      1                                                                                                                                \r\n2020-05-22 14:54:03.401879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   N                                                                                                                                \r\n2020-05-22 14:54:03.402669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:03.403797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:03.404819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14865 MB memory) -> physical GPU (device: 1, name: Tesla \r\n.0)                                                                   \r\n2020-05-22 14:54:04.402216: I tensorflow/compiler/jit/xla_gpu_device.cc:161] Ignoring visible XLA_GPU_JIT device. Device number is 0, reason: Invalid argument: device CUDA:0 not supported by XLA service\r\n2020-05-22 14:54:04.402466: I tensorflow/compiler/jit/xla_gpu_device.cc:161] Ignoring visible XLA_GPU_JIT device. Device number is 2, reason: Invalid argument: Invalid device ordinal value (2). Valid range is [0, 1].\r\n2020-05-22 14:54:04.402591: I tensorflow/compiler/jit/xla_gpu_device.cc:161] Ignoring visible XLA_GPU_JIT device. Device number is 3, reason: Invalid argument: Invalid device ordinal value (3). Valid range is [0, 1].\r\n2020-05-22 14:54:04.749691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:04.750812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:                         \r\npciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0                                                                     \r\ncoreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s                                               \r\n2020-05-22 14:54:04.750887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:04.751418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties:                         \r\npciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0                                                                     \r\ncoreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s                                               \r\n2020-05-22 14:54:04.751484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:04.752587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 2 with properties:                         \r\npciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0                                                                     \r\ncoreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s                                               \r\n2020-05-22 14:54:04.752653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:04.753719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 3 with properties:                         \r\npciBusID: 0000:00:1e.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0                                                                     \r\ncoreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s                                               \r\n2020-05-22 14:54:04.753769: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-05-22 14:54:04.753790: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-05-22 14:54:04.753812: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-05-22 14:54:04.753835: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-05-22 14:54:04.753854: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-05-22 14:54:04.753874: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-05-22 14:54:04.753890: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-05-22 14:54:04.753948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:04.755053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:04.755629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:04.756738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:04.757839: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:04.758940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:04.759498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:04.760500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-22 14:54:04.761334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1, 2, 3                  \r\n2020-05-22 14:54:04.761390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-05-22 14:54:04.761406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 1 2 3                                            \r\n2020-05-22 14:54:04.761419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N Y Y Y                                            \r\n2020-05-22 14:54:04.761426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   Y N Y Y                                            \r\n2020-05-22 14:54:04.761435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 2:   Y Y N Y                                            \r\n2020-05-22 14:54:04.761440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 3:   Y Y Y N                                            \r\nTraceback (most recent call last):\r\n  File \"test.py\", line 8, in <module>\r\n    tf.keras.mixed_precision.experimental.set_policy(\"mixed_float16\")\r\n  File \"/home/experiments/new-data-control/env/lib/python3.8/site-packages/tensorflow/python/keras/mixed_precision/experimental/policy.py\", line 551, in set_policy\r\n    policy = Policy(policy)\r\n  File \"/home/experiments/new-data-control/env/lib/python3.8/site-packages/tensorflow/python/keras/mixed_precision/experimental/policy.py\", line 348, in __init__\r\n    device_compatibility_check.log_device_compatibility_check(name,\r\n  File \"/home/experiments/new-data-control/env/lib/python3.8/site-packages/tensorflow/python/keras/mixed_precision/experimental/device_compatibility_check.py\", line 157, in log_device_compatibility_check\r\n    device_attr_list = device_lib.list_local_devices()\r\n  File \"/home/experiments/new-data-control/env/lib/python3.8/site-packages/tensorflow/python/client/device_lib.py\", line 43, in list_local_devices\r\n    _convert(s) for s in _pywrap_device_lib.list_devices(serialized_config)\r\nRuntimeError: TensorFlow device (GPU:0) is being mapped to multiple CUDA devices (0 now, and 1 previously), which is not supported. This may be the result of providing different GPU configurations (ConfigProto.gpu_options, for example different visible_device_list) when creating mu\r\nltiple Sessions in the same process. This is not  currently supported, see https://github.com/tensorflow/tensorflow/issues/19083\r\n```", "/cc @reedwm ", "As you noted, I embarrassingly tried and failed to fix this in f748283ee01059be52da5dada6e2157d9f6732ba. This was broken even in master until fixed in 2730e4b0bcba80799ddc10f52081927848540f30, but the latter commit did not make it into 2.2. The reason this happened is that I made a small refactor after manually testing the change before submitting it, but did not realize I accidentally broke the fix.\r\n\r\n[This post](https://github.com/tensorflow/tensorflow/issues/38516#issuecomment-613712149) has a hacky workaround for 2.2.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39775\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39775\">No</a>\n", "The proposed hack didn't work for me.\r\ntensorflow version 2.2.0\r\ncuda version 10.1", "Make sure you run the hack before setting the Keras policy. If it still doesn't work, please share an example to reproduce the hack not working", "Thanks. \r\nI resolved the issue by updating NVidia driver version to NVIDIA-SMI 440.33.01 "]}, {"number": 39774, "title": "Custom Keras model adds extra dimension to scalar inputs", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.7.3\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: TITAN V (12036MiB)\r\n\r\n**Describe the current behavior**\r\n\r\nI am creating a custom Keras model that takes scalar inputs (i.e. inputs have shape [batch_size]). When I compile the model and pass in a tf.data.Dataset to model.fit(), the shape of the input data is changed to [batch_size, 1]. \r\n\r\nHowever, when I train in a training loop using an iterator, the shape of the input data is [batch_size]. \r\n\r\nThis happens both locally and on Colab.\r\n\r\n**Describe the expected behavior**\r\nThe current behavior adds a side effect of changing the data input shape when using model.fit(). This behavior is inconsistent, since an extra dimension is not added to scalar inputs when training iteratively. The expected behavior would not add an extra dimension to scalar inputs, or at least be consistent between model.fit() and iterative training.\r\n\r\n**Standalone code to reproduce the issue**\r\nColab Notebook: https://colab.research.google.com/drive/14RyEYCRtYCwryJhkd4koYnK04RlUoqrI?usp=sharing\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nclass ToyModel(tf.keras.Model):\r\n  def call(self, inputs):\r\n    # Inputs are scalar, so we should only have a batch dimesion.\r\n    print(\"Input shape is {}\".format(inputs.shape))\r\n    return tf.reduce_sum(inputs)\r\n\r\ntoy_model = ToyModel()\r\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\r\nloss = tf.keras.losses.MeanSquaredError()\r\n\r\ndata_size = 10\r\ndata_inputs = np.float32(np.random.randn(data_size))\r\ndata_outputs = np.float32(np.random.randn(data_size))\r\ndataset = tf.data.Dataset.from_tensor_slices(\r\n    (data_inputs, data_outputs)).batch(data_size)\r\n\r\n# Train iteratively\r\niterator = iter(dataset)\r\ninputs, outputs = iterator.next()\r\nwith tf.GradientTape() as tape:\r\n  predictions = toy_model(inputs)\r\n  loss_value = loss(outputs, predictions)\r\ngrads = tape.gradient(loss_value, toy_model.trainable_weights)\r\noptimizer.apply_gradients(zip(grads, toy_model.trainable_weights))\r\n# Input shape is [batch_size]\r\n\r\n# Now, try training with fit() instead\r\ntoy_model.compile(optimizer=optimizer, loss=loss)\r\ntoy_model.fit(dataset, epochs=1)  \r\n# Input shape is [batch_size, 1]\r\n\r\n```\r\n\r\n", "comments": ["Was able to reproduce the issue with [TF v2.2](https://colab.research.google.com/gist/amahendrakar/149b5e8291940bc45ef9491e7d7f9454/39774.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/a82c862bd1db9fbbe3045c7e57cb68fc/39774-tf-nightly.ipynb). Please find the attached gist. Thanks!", "@keyonvafa I think this is not a bug but intended behavior. Under the hood, some functionality of `model.fit` require the shape to be like that but it will not change your original data shape. Does this concern you for your use-case? Can you please mention little more details how this affects your use-case? Thanks!", "@jvishnuvardhan Thanks for the response. The main issue for me is the inconsistency. Sometimes when I'm prototyping I'll train iteratively so I can debug in Eager mode. When I run it in the terminal I'll change training to `model.fit`, but I also have to include lines like `inputs = inputs[:, 0]` and `outputs = outputs[:, 0]`. ", "@keyonvafa Is this still an issue for you? Are you interested in contributing to update any part of the code. Any update need to be backward compatible. Thanks!", "@jvishnuvardhan Thanks for the note. For now I'm avoiding this issue by only using iterative training. I unfortunately don't have the bandwidth to contribute to the code", "@keyonvafa Do you want to close the issue or keep it open? Thanks!", "@jvishnuvardhan It seems like others are having the same issue so I'm fine keeping it open. Thanks!", "Sure. I am adding `contributions welcome` labels so that community can pick it up and contribute. Thanks!", "I've been having this issue with Tensorflow 2.2, not Tensorflow 1.x.", "@keyonvafa , That was wrongly triggered message, please ignore it. Thanks!", "Was able to replicate the issue with TF 2.5,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/be51a75a08d8426a19e4c05a49119035/untitled295.ipynb) ..Thanks!", "> I think this is not a bug but intended behavior.\r\n\r\n@jvishnuvardhan i think this is clearly a bug right? because it's inconsistent behavior between using custom Model vs iterative training. Could you fix this? Thx.", "Hi There,\n\n This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! \n\n Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39774\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39774\">No</a>\n"]}, {"number": 39773, "title": "TFLite library fix for r2.1 branch", "body": "This PR contains the following cherry-picks to fix a link failure with TFLite library.\r\n\r\n5b1fbe0268 TFLite: tools: make: add fftsg2d.c file in the build resources for libtensorflow-lite.a\r\n7f190ecb9f TFLite: tools: make: remove hash and flags files from the build sources for libtensorflow-lite.a\r\ndcb6a33c40 Update Makefile of TFLite not to include main() function\r\n", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39773) for more info**.\n\n<!-- need_author_consent -->", "@terryheo Can you please sign CLA? Thanks!", "@googlebot I consent.", "@vinceab could you consent cherry-picking your changes into r2.1 branch?", "@googlebot I consent.", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39773) for more info**.\n\n<!-- ok -->", "Note though that we can only merge this when we do a new patch release."]}, {"number": 39772, "title": "Example of using SavedModel", "body": "This issue regards TensorFlow 2.2.0\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/guide/saved_model\r\nhttps://www.tensorflow.org/api_docs/python/tf/saved_model/save\r\n\r\n## Description of issue:\r\n\r\n_TL;DR:I went through the links posted and still I don't understand how to properly use SavedModel format while defining tags, input and output tensor names, etc._ \r\n\r\nFor instance, say I have this very simple model: \r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\ninputs = tf.keras.Input(shape=(3,))\r\nx = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)\r\noutputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)\r\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\r\n```\r\nCalling `model.save(folder)` will easily save the model on SavedModel format. However, if I want to load it and use it somewhere else in a production environment I need to know how to define and name the SignatureDefs, input/output tensors of the sub-graph, tags etc. \r\n\r\nBut after reading and studying thoroughly the extensive documentation for hours, I didn't see any concrete example of how to do so. ", "comments": ["[Documentation](https://www.tensorflow.org/guide/saved_model#creating_a_savedmodel_from_keras)\n\nWe can load the SavedModel back into Python with `tf.saved_model.load` and see how Admiral Hopper's image is classified.\n\n`loaded = tf.saved_model.load(model_save_path)\nprint(list(loaded.signatures.keys()))  # [\"serving_default\"]`", "@dhiegomaga \r\nPlease update as per above comment", "@sushantag9  I know. My question regards how to save the model using custom sub-graphs and input and output names. \r\nIf I do what you said and try to load it using the TensorFlow C API, I need to find out the input and output **tensor names** in the graph, **which should be defined when saving the model.** If I want to use a different sub-graph of the network, I should be able to define different input and output tensors bound to a tag. \r\nNone of this is clear in the documentation because all examples are using [model subclassing](https://www.tensorflow.org/guide/keras/overview#model_subclassing), and the only one using the standard model approach doesn't specify any tensor names, instead just saves the default graph (i.e., without defining any SignatureDefs), shown bellow: \r\n\r\n```python\r\nx = input_layer.Input((4,), name=\"x\")\r\ny = core.Dense(5, name=\"out\")(x)\r\nmodel = training.Model(x, y)\r\ntf.saved_model.save(model, '/tmp/saved_model/')\r\n# The exported SavedModel takes \"x\" with shape [None, 4] and returns \"out\"\r\n# with shape [None, 5]\r\n```\r\n\r\n", "@dhiegomaga,\r\nDocumentation of [Saved Model](https://www.tensorflow.org/guide/saved_model) now comprises [Specifying the Signatures](https://www.tensorflow.org/guide/saved_model#specifying_signatures_during_export), [Loading a Saved Model in C++](https://www.tensorflow.org/guide/saved_model#load_a_savedmodel_in_c), etc..\r\n\r\nAlso. please find the documentation related to [Save and Serialize](https://www.tensorflow.org/guide/keras/save_and_serialize).\r\n\r\nThanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 39771, "title": "Initial cache support for filesystem plugins", "body": "@mihaimaruseac \r\nThis is the c api version of `file_block_cache`, `ram_file_block_cache` and `expiring_lru_cache`\n\nAnd we can add a `local_block_cache` which save cached file to local disk. this is slower than saving to ram but it is useful for huge file. what do you think ?", "comments": ["It is unclear how these would be used and there is a potential for ABI compatibility breakage.\r\n\r\nLet's try to write plugin functionality step by step in small CLs and include what's needed, as needed.\r\n\r\nFor example, let's try the following schedule:\r\n\r\n1. first CL with just the plugin registration for both S3 and GCS. See [the existing windows implementation](https://cs.opensource.google/tensorflow/tensorflow/+/master:tensorflow/c/experimental/filesystem/plugins/windows/windows_filesystem.cc).\r\n2. Next CL, ability to create file (`NewWritableFile`, `NewAppendableFile`) for both filesystems. No need to actually write to them yet\r\n3. Next PR, write to the files. Alternatively, ability to read from existing files (`NewRandomAccessFile`)\r\n4. The part from 3 that was not done (read from existing files / write to files)\r\n5. Now we finally can write an end-to-end test when we write to a file and then read the contents back. Here we finally need to add caching and everything else.\r\n6. \"Directory\" support\r\n7. Rename support\r\n8. Copy support\r\n9. `GetChildren`\r\n10. globbing\r\netc.\r\n\r\nHaving smaller PRs makes it way faster to review them too.\r\n\r\nSure, its more work on your side to try to split them but will result in better code in the end.\r\n\r\nConverting this to draft as we're trying to get smaller CLs.", "Because of there are some files which are deeply dependent on TensorFlow core, I have to copy some file from Tensorflow core to this PR to make sure we can detach the plugin from TF. However, as you suggested, I will make a PR for plugins registration for S3 and GCS and tackle the errors later", "@mihaimaruseac \r\nI had opened an issue and they told me a solution to allow bazel build on Windows without `--dynamic_mode=off` ( which we maybe need to fix our problem on Windows ). However, I don't know how big this project could be. So I would like to ask you whether it is ok if I contribute to bazel while awaiting your review ? Thank you\r\n\r\nThe link to the issue\r\nhttps://github.com/bazelbuild/bazel/issues/11482#issuecomment-634786247", "That works too. If you create PRs against Bazel, please tag me on the PRs too.\r\n\r\nRegarding copying files from the cc part of TF, let's decide what and how much to copy at the time when we need that.\r\n\r\nI think the best approach is to try and split the PRs for the filesystems here. If they are small I can review fast (< 30 mins of delay if during working hours). If they are large I need to dedicate a lot of time to review, so I need to find some day with fewer meetings, block time off, start the review. That's why I suggest doing smaller PRs.", "@mihaimaruseac \r\nHere is a PR for registration GCS filesystem https://github.com/tensorflow/tensorflow/pull/39952\r\nHere is a progress tracker for the feature I am working on at Bazel https://github.com/bazelbuild/bazel/issues/11515", "#39952 landed \ud83c\udf89 ", "@mihaimaruseac \r\n> #39952 landed \ud83c\udf89\r\n\r\nThank you. And I have already fixed the problems with `--dynamic_mode=fully` on Windows but I haven't made a PR yet since I am testing it. I have tried building some parts of Tensorflow (old `s3_file_system_test` which needs `--dynamic_mode=off` before) too. I think we could build entierly Tensorflow in dynamical mode on Windows but some dependencies do not support building dll by Bazel (e.g absl, protobuf ) yet so it will take some time. But I would like to ask if it worth building Tensorflow dynamically on Windows since we will have to convert all the dependencies to DLL too ( it is because Bazel does not support DLL very well in general ). I think I can work on DLL issue after GSoC if it is ok\r\n\r\nAnd I will send you a PR for NewWritableFile for gcs tomorrow.", "This is really good news", "@mihaimaruseac \r\nNext week is my final exam so I will have to delay a little bit. I am so sorry", "No worries about it. Good luck on the exams.", "@mihaimaruseac \r\nThis is the PR to add the `init` for `filesystem_ops`. https://github.com/tensorflow/tensorflow/pull/40153\r\nThis is the PR which I made against Bazel https://github.com/bazelbuild/bazel/pull/11524", "@mihaimaruseac \r\nI am writing the PR for GCS. There is a point I want to make clear. Should I use c++17 features for the gcs filesystem ?\r\nIn particular, I needs 2 things, `std::string_view` and `std::filesystem` ( for creating cross-platform temporary file for `WritatbleFile`)", "Our Windows infrastructure does not support C++17 :( Let's try to keep C++14 compatibility", "@mihaimaruseac \r\nhttps://github.com/tensorflow/tensorflow/pull/40451\r\nThis is a small PR for GCS Path Parser.\r\n\r\nAnother things I would like to ask you.\r\n- I think I should create a PR against `c/tf_env.h` to mimic this function since gcs needs it and I think other functions may need it as well.\r\nhttps://github.com/tensorflow/tensorflow/blob/fbe175972d6c9fe354068f2d51f6a357e414c77c/tensorflow/core/platform/path.h#L93\r\n\r\n- What do you prefer ? `FD*` or `std::fstream` for a temporary file. I personally prefer `std::fstream` over `FD*` since we want to delete the temporary file at the end, we will have to wrap `FD*` in a class or overload `std::fstream`. Current implementation delete the temporary file in the destructor of class `GCSWritableFile`. Is there any guarantee that `Cleanup` will be called no matter what happened ? If so, We can remove the file in `Cleanup` and no need to overwrite or wrap.", "`std::fstream` is better, I think.\r\n\r\n+1 for the addtion to `c/tf_env.h`.\r\n\r\nWe cannot guarantee that `Cleanup` gets called. We should manually delete the file in the plugin when it is no longer needed.", "@mihaimaruseac \r\nThis PR adds the function TF_GetTempFileName\r\nhttps://github.com/tensorflow/tensorflow/pull/40528", "@mihaimaruseac \r\n- This PR add the support for NewWritableFile for GCS https://github.com/tensorflow/tensorflow/pull/40582\r\n- I am thinking of adding a macro like\r\n```\r\n#ifdef TESTING\r\n#define STATIC\r\n#else \r\n#define STATIC static\r\n#end \r\n```\r\nand a `cc_test` like\r\n```\r\ncc_test {\r\n name = \"gcs_test\",\r\n src= [\r\n  \"gcs_filesystem.cc\",\r\n  \"gcs_filesystem_test.cc\"\r\n ],\r\n define = [\r\n  \"TESTING\"\r\n ]\r\n}\r\n```\r\nSo I can call function from `gcs_filesystem.cc` to test in `gcs_filesystem_test.cc`. What do you think ?", "Why do we need to test a static function? We should be able to test some exposed API that uses that", "I would like to have a lightweight testing for each filesystem before we run `modular_filesystem_test`, since `modular_filesystem_test` in general does not cover all characterictis of the filesystem. I think removing `static` from these functions and call it in `gcs_filesystem_testing` is far cheaper than running `modular_filesystem_test`\r\nWe could test any function like this one\r\nhttps://github.com/tensorflow/tensorflow/blob/2e3310031296f9232f7a58a5cfca2ee03b9a7c91/tensorflow/c/experimental/filesystem/plugins/gcs/gcs_filesystem.cc#L107", "Makes sense. We could remove the `static`, add `.h` to expose them and include the `.h` in the testing suite.\r\n\r\n`static` does not show up in the name mangling, so the integration would still work.", "Thank you. But I think using macro makes more sense as it keeps the filesystem untouched when build shared object (no symbol exposed) and we can call those functions in the `gcs_filesystem_test` since they are `srcs` in the same rule `cc_test`", "Ok. Let's go with the macro version, but we should document it in the code", "Ok. I will send you a PR tomorrow", "@mihaimaruseac \r\nThis PR #40618 add gcs_filesystem_test", "@mihaimaruseac \r\nThis PR add new appendable file, cleanup and fix a memory leak error https://github.com/tensorflow/tensorflow/pull/40641", "@mihaimaruseac \r\nThis PR add `tf_random_access_file` #40710 ", "@mihaimaruseac \r\nThis PR adds `tf_read_only_memory_region` #40948. I will send you a PR for filesystem operations ( CreateDir, ... ) and one or two PRs for testing and we barely finish with the GCS filesystem. \r\n\r\nWe have an important TODO: Implementing a caching mechanism. Only GCS filesystem uses a cache mechanism so I think we could keep it inside the plugin's boundary.\r\n\r\nAbout the timeline, since `s3` and `hdsf` filesystems have already used their own libraries, it won't take much time as gcs", "No worries about the timeline, it looks on track from my point of view, given the requirements of small modular changes and the need to cut on dependencies.\r\n\r\nI agree that we can keep the cache mechanism in the plugin's boundary", "@mihaimaruseac \r\nThis PR adds test for `writable_file` and `read_only_memory_region` #40968 \r\nThis PR adds filesystem ops #40995 ", "@mihaimaruseac \r\nThank for the feedbacks with GSoC \ud83c\udf89 \r\nThis PR removes static member `std::string` #41068 ", "@mihaimaruseac \r\nThis PR adds create dir, delete dir/file #41082 ", "Close by smaller PRs"]}, {"number": 39770, "title": "could not find the module", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.2.0\r\n- Python version: 3.7.4\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.2/7.6.5\r\n- GPU model and memory: Geforce gtx 1650 4gb\r\n\r\n(tfpose) C:\\Users\\mysel\\algo_od\\git\\tf-pose-estimation>pip install --ignore installed --upgrade tensorflow-gpu\r\n\r\nUsage:\r\n  pip install [options] <requirement specifier> [package-index-options] ...\r\n  pip install [options] -r <requirements file> [package-index-options] ...\r\n  pip install [options] [-e] <vcs project url> ...\r\n  pip install [options] [-e] <local project path> ...\r\n  pip install [options] <archive url/path> ...\r\n\r\nambiguous option: --ignore (--ignore-installed, --ignore-requires-python?)\r\n\r\n(tfpose) C:\\Users\\mysel\\algo_od\\git\\tf-pose-estimation>pip install --ignore-installed --upgrade tensorflow-gpu\r\nCollecting tensorflow-gpu\r\n  Using cached tensorflow_gpu-2.2.0-cp37-cp37m-win_amd64.whl (460.4 MB)\r\nCollecting wheel>=0.26; python_version >= \"3\"\r\n  Downloading wheel-0.34.2-py2.py3-none-any.whl (26 kB)\r\nCollecting numpy<2.0,>=1.16.0\r\n  Using cached numpy-1.18.4-cp37-cp37m-win_amd64.whl (12.8 MB)\r\nCollecting tensorboard<2.3.0,>=2.2.0\r\n  Using cached tensorboard-2.2.1-py3-none-any.whl (3.0 MB)\r\nCollecting keras-preprocessing>=1.1.0\r\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 42 kB 271 kB/s\r\nCollecting grpcio>=1.8.6\r\n  Downloading grpcio-1.29.0-cp37-cp37m-win_amd64.whl (2.3 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2.3 MB 1.3 MB/s\r\nProcessing c:\\users\\mysel\\appdata\\local\\pip\\cache\\wheels\\7c\\06\\54\\bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\\termcolor-1.1.0-cp37-none-any.whl\r\nCollecting tensorflow-gpu-estimator<2.3.0,>=2.2.0\r\n  Using cached tensorflow_gpu_estimator-2.2.0-py2.py3-none-any.whl (470 kB)\r\nCollecting six>=1.12.0\r\n  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\r\nProcessing c:\\users\\mysel\\appdata\\local\\pip\\cache\\wheels\\cc\\af\\1a\\498a24d0730ef484019e007bb9e8cef3ac00311a672c049a3e\\absl_py-0.9.0-py3-none-any.whl\r\nCollecting opt-einsum>=2.3.2\r\n  Using cached opt_einsum-3.2.1-py3-none-any.whl (63 kB)\r\nCollecting gast==0.3.3\r\n  Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\r\nCollecting google-pasta>=0.1.8\r\n  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\r\nCollecting h5py<2.11.0,>=2.10.0\r\n  Using cached h5py-2.10.0-cp37-cp37m-win_amd64.whl (2.5 MB)\r\nCollecting protobuf>=3.8.0\r\n  Downloading protobuf-3.12.1-cp37-cp37m-win_amd64.whl (1.0 MB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.0 MB 1.6 MB/s\r\nCollecting astunparse==1.6.3\r\n  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\r\nCollecting scipy==1.4.1; python_version >= \"3\"\r\n  Using cached scipy-1.4.1-cp37-cp37m-win_amd64.whl (30.9 MB)\r\nCollecting wrapt>=1.11.1\r\n  Downloading wrapt-1.12.1.tar.gz (27 kB)\r\nCollecting google-auth<2,>=1.6.3\r\n  Downloading google_auth-1.15.0-py2.py3-none-any.whl (89 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 89 kB 1.8 MB/s\r\nCollecting tensorboard-plugin-wit>=1.6.0\r\n  Using cached tensorboard_plugin_wit-1.6.0.post3-py3-none-any.whl (777 kB)\r\nCollecting werkzeug>=0.11.15\r\n  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 298 kB 1.7 MB/s\r\nCollecting google-auth-oauthlib<0.5,>=0.4.1\r\n  Using cached google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\r\nCollecting markdown>=2.6.8\r\n  Downloading Markdown-3.2.2-py3-none-any.whl (88 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 88 kB 2.0 MB/s\r\nCollecting requests<3,>=2.21.0\r\n  Downloading requests-2.23.0-py2.py3-none-any.whl (58 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 58 kB 1.1 MB/s\r\nCollecting setuptools>=41.0.0\r\n  Downloading setuptools-46.4.0-py3-none-any.whl (583 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 583 kB 1.7 MB/s\r\nCollecting rsa<4.1,>=3.1.4\r\n  Downloading rsa-4.0-py2.py3-none-any.whl (38 kB)\r\nCollecting pyasn1-modules>=0.2.1\r\n  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\r\nCollecting cachetools<5.0,>=2.0.0\r\n  Using cached cachetools-4.1.0-py3-none-any.whl (10 kB)\r\nCollecting requests-oauthlib>=0.7.0\r\n  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\r\nCollecting importlib-metadata; python_version < \"3.8\"\r\n  Downloading importlib_metadata-1.6.0-py2.py3-none-any.whl (30 kB)\r\nCollecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\r\n  Using cached urllib3-1.25.9-py2.py3-none-any.whl (126 kB)\r\nCollecting idna<3,>=2.5\r\n  Downloading idna-2.9-py2.py3-none-any.whl (58 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 58 kB 787 kB/s\r\nCollecting chardet<4,>=3.0.2\r\n  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 133 kB 1.3 MB/s\r\nCollecting certifi>=2017.4.17\r\n  Downloading certifi-2020.4.5.1-py2.py3-none-any.whl (157 kB)\r\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 157 kB 939 kB/s\r\nCollecting pyasn1>=0.1.3\r\n  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\r\nCollecting oauthlib>=3.0.0\r\n  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\r\nCollecting zipp>=0.5\r\n  Downloading zipp-3.1.0-py3-none-any.whl (4.9 kB)\r\nBuilding wheels for collected packages: wrapt\r\n  Building wheel for wrapt (setup.py) ... done\r\n  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-win_amd64.whl size=33377 sha256=8f9b6e9ff0ab7c409644869dfbd50a922c41dda7f4e6768b3159bdf551be6be5\r\n  Stored in directory: c:\\users\\mysel\\appdata\\local\\pip\\cache\\wheels\\62\\76\\4c\\aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\r\nSuccessfully built wrapt\r\nERROR: awscli 1.18.41 requires botocore==1.15.41, which is not installed.\r\nERROR: awscli 1.18.41 requires colorama<0.4.4,>=0.2.5; python_version != \"3.4\", which is not installed.\r\nERROR: awscli 1.18.41 requires docutils<0.16,>=0.10, which is not installed.\r\nERROR: awscli 1.18.41 requires PyYAML<5.4,>=3.10; python_version != \"3.4\", which is not installed.\r\nERROR: awscli 1.18.41 has requirement rsa<=3.5.0,>=3.1.2, but you'll have rsa 4.0 which is incompatible.\r\nInstalling collected packages: wheel, numpy, pyasn1, rsa, setuptools, pyasn1-modules, six, cachetools, google-auth, protobuf, tensorboard-plugin-wit, werkzeug, oauthlib, urllib3, idna, chardet, certifi, requests, requests-oauthlib, google-auth-oauthlib, absl-py, zipp, importlib-metadata, markdown, grpcio, tensorboard, keras-preprocessing, termcolor, tensorflow-gpu-estimator, opt-einsum, gast, google-pasta, h5py, astunparse, scipy, wrapt, tensorflow-gpu\r\nSuccessfully installed absl-py-0.9.0 astunparse-1.6.3 cachetools-4.1.0 certifi-2020.4.5.1 chardet-3.0.4 gast-0.3.3 google-auth-1.15.0 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 grpcio-1.29.0 h5py-2.10.0 idna-2.9 importlib-metadata-1.6.0 keras-preprocessing-1.1.2 markdown-3.2.2 numpy-1.18.4 oauthlib-3.1.0 opt-einsum-3.2.1 protobuf-3.12.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.23.0 requests-oauthlib-1.3.0 rsa-4.0 scipy-1.4.1 setuptools-46.4.0.post20200518 six-1.15.0 tensorboard-2.2.1 tensorboard-plugin-wit-1.6.0.post3 tensorflow-gpu-2.2.0 tensorflow-gpu-estimator-2.2.0 termcolor-1.1.0 urllib3-1.25.9 werkzeug-1.0.1 wheel-0.34.2 wrapt-1.12.1 zipp-3.1.0\r\n\r\n(tfpose) C:\\Users\\mysel\\algo_od\\git\\tf-pose-estimation>python\r\nPython 3.7.7 (default, May  6 2020, 11:45:54) [MSC v.1916 64 bit (AMD64)] :: Anaconda, Inc. on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"D:\\Anaconda\\envs\\tfpose\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"D:\\Anaconda\\envs\\tfpose\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"D:\\Anaconda\\envs\\tfpose\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"D:\\Anaconda\\envs\\tfpose\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"D:\\Anaconda\\envs\\tfpose\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"D:\\Anaconda\\envs\\tfpose\\lib\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"D:\\Anaconda\\envs\\tfpose\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 50, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"D:\\Anaconda\\envs\\tfpose\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 69, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"D:\\Anaconda\\envs\\tfpose\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"D:\\Anaconda\\envs\\tfpose\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"D:\\Anaconda\\envs\\tfpose\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"D:\\Anaconda\\envs\\tfpose\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"D:\\Anaconda\\envs\\tfpose\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@rajat997 \r\n\r\nWhat is make/model of your cpu?\r\nI suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)\r\nMake sure to download the [latest microsoft visual c++ redistributable from here](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads).\r\n.Also, please follow the instructions from to install from [Tensorflow website](https://www.tensorflow.org/install/source_windows).\r\n\r\nPlease, check Your CPU/Python is on 32 bits?Please, refer #36167 and see if it helps you.Please, refer similar issue #36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204\r\nThanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39770\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39770\">No</a>\n"]}]