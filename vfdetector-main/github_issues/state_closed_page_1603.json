[{"number": 4822, "title": "contrib: add naturali neccessary ops", "body": "Including lookahead ops and warpctc ops\n", "comments": ["Can one of the admins verify this patch?\n", "@plutoshe, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @keveman and @ville-k to be potential reviewers.\n"]}, {"number": 4821, "title": "Request for documentation: quantize_training in python", "body": "Poking around, I find https://github.com/tensorflow/tensorflow/search?utf8=%E2%9C%93&q=quantize_training\n\nHowever there is no documents that I can find describe how this can be used. Can we add some example and also documentation around it so that people can start to play with it?\n", "comments": ["@jmchen-g might be able to provide details here.\n", "@petewarden Is this deprecated code?", "I am working on exposing this, will update when changes have been made. Thanks.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assigneee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Hi, the quantized training rewrites are documented and available here:\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/quantize\r\n\r\nNote, they will not work on all models, though we are working on improving how well they generalize.\r\n\r\nYou can convert these Fake quantized models to fully quantized mobile models via TensorFlow Lite.\r\nhttps://www.tensorflow.org/mobile/tflite/"]}, {"number": 4820, "title": "Thread created by SummaryWriter not killed", "body": "Hi,\n\nI noticed that the _EventLoggerThread created by summary writer does not get killed by the close method, which will make the number of threads keep increasing until it exceeds the system capacity. Is there any particular reason to not kill these threads?\n\nBest \n", "comments": ["@wyx-cornell Thanks for filing this issue!\n\nLooking at the code, I believe you're right, and this is a bug.  Have you run into a real-world problem because of this, or did you just notice via code inspection as well?\n\nWould you like to file a pull request to fix this?  Contributions are welcome!\n", "Hi, I am working on this, since haosdent is not working on it anymore.", "I'll try to reproduce this, and I'll work on this if I can reproduce this.", "@wyx-cornell , according to the latest code and I have tested, number of threads will increase only when you create a new writer every time you want to add_summary. Also, if you kill the thread when close the writer, there will be no thread serving you when you reopen this writer.\r\n\r\nhow about kill the thread when close the writer and create a new thread when reopen the writer?", "I was directed to this particular issue from #2788. I had been using tf.trainLoggingTensorHook which I am assuming uses the lower level summary writers under the hood. I am on tensorflow version 1.2 and upon seeing this I removed the logging and I went from intermittent hanging on start of run to now consistent successful training runs upon every start. I was seeing similar gdb traces on all my threads to the above linked issue and it seems all my threads were in lock. If this isn't the same issue I'm more than willing to open a new one, but it at least seemed related. ", "@GrandathePanda , can you provide a minimal test case so we can reproduce?", "@suiyuan2009 \r\nBelow is a test that can reproduce:\r\nWe want to make a call from C++ to python and TF. Thus, an embedded python interpreter is used. \r\nHowever, the Py_EndInterpreter call fails with error message: \r\n\r\n> Fatal Python error: Py_EndInterpreter: not the last thread\r\n\r\nThis is because there is a daemon thread _EventLoggerThread is still running after the python script finishes. \r\n\r\nThe output of this test is:\r\n>[33, 67.0]\r\n>[<_MainThread(MainThread, started 140735723737984)>, <_EventLoggerThread(Thread-1, started daemon 123145450090496)>]\r\n>Fatal Python error: Py_EndInterpreter: not the last thread\r\n\r\n\r\ntest.py file:\r\n```python\r\n# import logging as logger\r\nimport sys\r\nimport time\r\nimport tensorflow as tf\r\nfrom tensorflow.python.platform import tf_logging as logging\r\nfrom tensorflow.python.client import timeline\r\nimport threading\r\n\r\nclass Train(object):\r\n\r\n    def run(self):\r\n        v = tf.Variable(dtype=tf.float32, initial_value=tf.constant(1.0))\r\n        a = tf.placeholder(tf.float32, shape=None, name=\"a\")\r\n        b = tf.reduce_mean(a, name=\"b\")\r\n        c = tf.add(b, v, name=\"c\")\r\n        add = tf.assign(v, c, name=\"assign\")\r\n        global_step = tf.contrib.framework.get_or_create_global_step()\r\n        sum = tf.summary.scalar(name=\"sum\", tensor=c)\r\n        global_step_inc = tf.assign_add(global_step, 1)\r\n        hooks = [tf.train.StopAtStepHook(last_step=20)]\r\n        ckpt_dir = './tmp/s1/'\r\n        logging.info('begin run')\r\n        with tf.train.MonitoredTrainingSession(checkpoint_dir=ckpt_dir, hooks=hooks) as mon_sess:\r\n            while not mon_sess.should_stop():\r\n                print (mon_sess.run([global_step_inc, add], feed_dict={a: [1.0, 2.0, 3.0]}))\r\n        logging.info('[finish run]')\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    print(sys.version)\r\n    Train().run()\r\n    print threading.enumerate()\r\n```\r\n\r\nAnd the test cpp code:\r\n\r\n```cpp\r\n#include \"Python.h\"\r\n#include<iostream>\r\n\r\nint main(int argc, char* argv[]) {\r\n    // initialize Python\r\n    Py_Initialize() ;\r\n    PyEval_InitThreads() ; // nb: creates and locks the GIL\r\n    PyThreadState* state = PyThreadState_Get();\r\n    PyEval_ReleaseThread(state);\r\n\r\n    PyEval_AcquireThread(state);\r\n\r\n    const char* pythonFileName = argv[1];\r\n    FILE* to_run_script= fopen(pythonFileName, \"r\");\r\n    std::cout << \"Run file \" << pythonFileName << std::endl;\r\n    PyObject * main_module = PyImport_ImportModule(\"__main__\");\r\n    PyObject* global_symbol_table = PyModule_GetDict(main_module);;\r\n    if (to_run_script != NULL) {\r\n        PyRun_File(to_run_script, pythonFileName, Py_file_input, global_symbol_table, global_symbol_table);\r\n\r\n        // if python side has daemon thread. Py_EndInterpreter will throw 'not the last thread' exception.\r\n        Py_EndInterpreter(state);\r\n\r\n        if (!PyErr_Occurred()) {\r\n            return 0;\r\n        }else {\r\n            PyErr_PrintEx(1);\r\n        }\r\n    }\r\n    PyEval_ReleaseThread(state);\r\n    Py_Finalize() ;\r\n}\r\n```", "I think this is still up-to-date.\r\nSee [here](https://github.com/rwth-i6/returnn/blob/a923504d7265214efb74ef67509db9ac72b84d1c/tests/test_TFUtil.py#L678) and [here](https://github.com/rwth-i6/returnn/blob/3f1e9a235e28f41e695686a345410f32e929a663/TFUtil.py#L4466). This test case still runs with latest TF, e.g. [here](https://travis-ci.org/rwth-i6/returnn/jobs/501581634).\r\n(**Edit:** Just noticed that the test case actually does not check whether this is still really the case.)", "@whjiang it's a long time, I'll take a look in this week."]}, {"number": 4819, "title": "Fix /WHOLEARCHIVE linking on Windows in Bazel build", "body": "/WHOLEARCHIVE has a bug linking static library compiled from empty source file.\n\nFixed related source files by adding some include statements as placeholder.\n\nThis change will make users able to use Bazel to build C++ example trainer with Visual Studio 2015 update 2 (or newer verison). Older versions of VS works fine without this change because Bazel will directly link object files instead of using /WHOLEARCHIVE (it's not supported)\n@mrry \n", "comments": ["@meteorcloudy, thanks for your PR! By analyzing the history of the files in this pull request, we identified @dm-jrae and @jhseu to be potential reviewers.\n", "Can one of the admins verify this patch?\n", "@tensorflow-jenkins test this please.\n", "@tensorflow-jenkins test this please\n", "Not sure why it's still failing, can you test it again please?\n", "@tensorflow-jenkins test this please\n"]}, {"number": 4818, "title": "jkjk", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\n\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\n\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\n### Environment info\n\nOperating System:\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\nIf installed from binary pip package, provide:\n1. A link to the pip package you installed:\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`)\n2. The output of `bazel version`\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\n### What other attempted solutions have you tried?\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment or provide link).\n", "comments": []}, {"number": 4817, "title": "Supported `tf.float16` in `tf.decode_raw`.", "body": "This fixes #4782.\n", "comments": ["Can one of the admins verify this patch?\n", "@haosdent, thanks for your PR! By analyzing the history of the files in this pull request, we identified @keveman, @tensorflower-gardener and @vrv to be potential reviewers.\n", "@benoitsteiner Would you help review this when your available? Thank you very much.\n", "@benoitsteiner Thanks a lot for your kindly helps, would you help review this again? Thank you in advance!\n", "@tensorflow-jenkins test this please\n"]}, {"number": 4816, "title": "tensroflow 0.11rc conflict with boost.python generated so", "body": "My application will use both tensorflow and some so generated by boost.python(1.53) running on centos 6.3 with cuda 7.5 and cudnn 4 .\nThe problem is everything is fine with tensorflow 0.10, but changing to tensorflow 0.11rc, then \nI will always face segmentation fault (double free) before the program stop running, especially if using numpy also, and if changing import library sequence  might decrease the chance of facing double free, but still not fully solve the problem.\n", "comments": ["@chenghuige As we have limited resources, we can only provide support for specific bugs in TensorFlow.\n\nFeel free to reply with a specific reproducible scenario if you feel there is a bug in TensorFlow that we can fix.  Thanks!\n"]}, {"number": 4815, "title": "Neural Network Exchange Format (NNEF)", "body": "Do you want to support and contribute to the standardizzation of provisional [NNEF](https://www.khronos.org/nnef) effort by Kronos Group? Google is still in the [promoter member list](https://www.khronos.org/members/member_list)\n", "comments": ["Thanks for filing the issue @bhack \n\nSeeing as NNEF is the the proposal/design phase, there isn't a specific feature for us to implement at this time.  We may revisit this in the future.\n", "I know that it is provisional but my issue was also about if you plan to take part to this process as Kronos member. Can you reply me to this point? \n", "IMHO standard is hard to make useful at this point since the set of useful neural network primitives is changing so fast. Two years ago people wouldn't have thought about adding GRU unit, a year ago people would miss some neural attention primitives, and next year there may be categorically new ops or ops that unify existing ops redundant. Like with ReLU -> ReLU6 -> ReLUN, then ReLUN with trainable N which technically makes all other versions of ReLU redundant. So a standard would end up either missing someone's favorite primitive, or grow so large that it's not practical to be implemented by everyone (ie, like with TensorFlow GraphDef format which grew to incude 450+ different op types)\n", "Yes in this field standards will be always behind state of the art. So a standard can evolve on research sediments. If we not start in some way we will leave only margin for near metal de facto (closed) standard like cudnn that in some way it is dictacting low level interfaces.\n", "+CC @zstone (TF product manager)\n", "I see this as an opportunity to start a collective effort for finding a subset of what research is cooking in different burners and what it is \"ready\" for eating at inference and that impact near metal production (open or closed source). I think that a multi stakeholder effort for finding an agreement to update the standard one or two times at year could be feasible. /cc @fchollet\n"]}, {"number": 4814, "title": "[Feature Request] Make streaming metrics resettable", "body": "Hi! \nCurrently, the streaming metrics are (as far as I know) not resettable. I'd like to be able to e.g. reset the counter after each epoch. This way, having e.g. a very bad accuracy in the beginning of training will not still influence the accuracy value ten epochs later. It makes it easier to compare my results to runs obtained outside tensorflow.\n\nThe only workaround I found is to do `sess.run(tf.initialize_local_variables())` after each epoch, but of course this can have bad side effects if I have other local variables that I don't want to reset.\n\nOr is there a way to achieve what I want that I didn't think of?\n", "comments": ["@untom Thanks for filing the issue!  The request sounds reasonable to me.  We welcome contributions!\n\nMaybe @nathansilberman @langmore might know whether there's some existing way to reset streaming metrics; I couldn't come up with anything either.\n", "Streaming metrics add two local variables `total` and `count`. You can find and reset them to get the required behavior. Please see the example below. Hope this helps.\n\n``` python\nimport tensorflow as tf\n\nvalue = 0.1\nwith tf.name_scope('foo'):\n    mean_value, update_op = tf.contrib.metrics.streaming_mean(value)\n\ninit_op = [tf.initialize_variables(tf.local_variables())]\nstream_vars = [i for i in tf.local_variables() if i.name.split('/')[0] == 'foo']\nreset_op = [tf.initialize_variables(stream_vars)]\nwith tf.Session() as sess:\n    sess.run(init_op)\n    for j in range(3):\n        for i in range(9):\n            _, total, count = sess.run([update_op] + stream_vars) \n            mean_val = sess.run([mean_value])\n            print total, count, mean_val\n        sess.run(reset_op)\n        print ''\n```\n", "Thanks, that is very useful. It seems to me that i would make sense if the metrics would all return a `reset_op` together with the other ops. But that would break existing code. A workaround could be to only return the reset_op if the user specifies an optional `return_reset_op=True` parameter when creating the OP. Is that a sensible approach for this?\n", "Agree with @untom .\r\nWhen building a multi-target training graph, there might be tens of prediction to evaluate on tens of labels. It would be nightmare to generate this local_variable reset op manually.\r\nFollowing @AshishBora 's way, I'am getting the last 4 variable from local_variable list. But this doesn't seems to be extensible.\r\n", "Thank you @AshishBora for your guidance. However I am encountering an issue using TF-Slim. The problem is that the TF-Slim use tf.train.Supervisor() and after that the graph is finalized and cannot be be modified. I get the following error:\r\n\r\n``raise RuntimeError(\"Graph is finalized and cannot be modified.\")\r\nRuntimeError: Graph is finalized and cannot be modified.``\r\n\r\nSo the above solution won't work.\r\n\r\nIs there any other solution?\r\nThanks", "You can run the following to reset the local variables used by metric computation:\r\nsession.run(tf.local_variables_initializer())\r\n\r\nTo avoid the issue of graph finalization, just create a reference to this op BEFORE session creation:\r\n\r\nreset_op = tf.local_variables_initializer()\r\n... session created\r\nsession.run(reset_op)\r\n\r\n", "Note that this is tightly coupled to #9498.", "Thank you @nathansilberman .\r\nUnfortunately it didn't work. Looks like the supervisor is much smarter than that!\r\nMoreover I the the problem with tf.local_variables_initializer() is that by defining the reset_op it may reset all variables.\r\nI am not %100 sure though. \r\nBut thank you so much for the hint. I think I may find the solution from this.", "Alternatively, you can always define the metrics within a name scope and\nonly reset the local variables within that name scope.\n\nOn Fri, Jun 2, 2017 at 11:01 AM, Amirsina Torfi <notifications@github.com>\nwrote:\n\n> Thank you @nathansilberman <https://github.com/nathansilberman> .\n> Unfortunately it didn't work. Looks like the supervisor is much smarter\n> than that!\n> Moreover I the the problem with tf.local_variables_initializer() is that\n> by defining the reset_op it may reset all variables.\n> I am not %100 sure though.\n> But thank you so much for the hint. I think I may find the solution from\n> this.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/4814#issuecomment-305813151>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AUMnHAfTXrDFN2hDwEKY06TUPgPd57jNks5sACPjgaJpZM4KQz81>\n> .\n>\n", "@untom I made it. Thanks to @nathansilberman .\r\n\r\nI made a pull request to tensorflow for changing slim.learning.train and I added a reset_op for metric.\r\nAlthough different changes must be made to train_image_classifier.py provided by slim, but the first pull request is necessary to accept.\r\n\r\npull request:\r\n#10400\r\nhttps://github.com/tensorflow/tensorflow/pull/10400#issuecomment-305853010", "@untom I just stumbled upon your discussion. I am struggling with the same issue and I just started wrapping all my code up [here](https://github.com/petrux/LiTeFlow/tree/streaming-comp). Please, note that it is still a development and unstable branch and may rapidly change in the next few hours. Any feedback or suggestion is more than welcome. The idea is to have a easy way for having both streaming computation and batch-based computation of metrics. I would be carefule with the idea suggested @AshishBora since it sounds like breaking encapsulation -- but I see that's the quickest way to go.", "Concluding the suggestions by @AshishBora (https://github.com/tensorflow/tensorflow/issues/4814#issuecomment-254197646) and @nathansilberman (https://github.com/tensorflow/tensorflow/issues/4814#issuecomment-305688961) I came up with this function to create all three ops with one call, while keeping the variables encapsulated (fixed a side effect issue @untom mentioned (https://github.com/tensorflow/tensorflow/issues/4814#issuecomment-314851485)):\r\n\r\n```python\r\ndef create_reset_metric(metric, scope='reset_metrics', **metric_args):\r\n  with tf.variable_scope(scope) as scope:\r\n    metric_op, update_op = metric(**metric_args)\r\n    vars = tf.contrib.framework.get_variables(\r\n                 scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\r\n    reset_op = tf.variables_initializer(vars)\r\n  return metric_op, update_op, reset_op\r\n```\r\n\r\nAn example to create the operations inside the graph is then like this:\r\n\r\n```python\r\nepoch_loss, epoch_loss_update, epoch_loss_reset = create_reset_metric(\r\n                    tf.contrib.metrics.streaming_mean_squared_error, 'epoch_loss',\r\n                    predictions=output, labels=target)\r\n```", "does local_variables_initializer only return variables from the current scope? Otherwise this can have bad side effects", "Indeed, it has! Thanks, I changed it to use `vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)` now, which already filters by scope.", "what's the best practice to use this\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\npred = tf.placeholder(shape=[3],dtype=tf.int32)\r\nlabel = tf.placeholder(shape=[3],dtype=tf.int32)\r\nv,op = tf.metrics.accuracy(pred,label)\r\nreset_op = tf.local_variables_initializer()\r\n\r\nsess = tf.InteractiveSession()\r\nsess.run(reset_op)\r\nfor i in range(10):\r\n    print(sess.run([v,op,reset_op],{pred:[0,1,2],label:[0,1,2]}))\r\n```\r\n\r\nI get \r\n```\r\n[0.0, 1.0, None]\r\n[1.0, 1.0, None]\r\n[0.0, 0.0, None]\r\n[inf, 1.0, None]\r\n[0.0, 1.0, None]\r\n[0.0, 1.0, None]\r\n[1.0, 1.0, None]\r\n[inf, inf, None]\r\n[0.0, 0.0, None]\r\n[0.0, inf, None]\r\n```\r\nI add control dependency to this \r\n```python\r\nimport tensorflow as tf\r\n\r\npred = tf.placeholder(shape=[3],dtype=tf.int32)\r\nlabel = tf.placeholder(shape=[3],dtype=tf.int32)\r\nv,op = tf.metrics.accuracy(pred,label)\r\nreset_op = tf.local_variables_initializer()\r\nop = tf.tuple([op],control_inputs=[reset_op])[0]\r\nv = tf.tuple([v],control_inputs=[op])[0]\r\n\r\nsess = tf.InteractiveSession()\r\nsess.run(reset_op)\r\nfor i in range(10):\r\n    print(sess.run([v],{pred:[0,1,2],label:[0,1,2]}))\r\n```\r\nresults is wired too\r\n```\r\n[0.0]\r\n[1.0]\r\n[0.0]\r\n[0.0]\r\n[0.0]\r\n[inf]\r\n[0.0]\r\n[1.0]\r\n[1.0]\r\n[1.0]\r\n```\r\n", "You are doing what I did wrong in the first place: You are using the `tf.local_variables_initializer()`. Try using another reset op which only resets the variables you need, e.g. by selecting the variables you need:\r\n\r\n```python\r\nwith tf.variable_scope(\"reset_metrics_accuracy_scope\") as scope:\r\n    v, op = tf.metrics.accuracy(pred, label)\r\n    vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\r\n    reset_op = tf.variables_initializer(vars)\r\n```\r\n\r\nYou would then call `sess.run(op)` whenever your metric should be updated, `sess.run(reset_op)` whenever you want to reset it, and `sess.run(v)` whenever you want to know its value.", "@shoeffner : I'm not sure if this has changed in the last version 1.3 of TF, but 'vars' is an empty list when I use your snippet above.\r\n\r\nTo be more precise, I always run into the exception of my code, which is based on your proposal:\r\n\r\n```python\r\nclass MetricOp(object):\r\n    def __init__(self, name, value, update, reset):\r\n        self._name = name\r\n        self._value = value\r\n        self._update = update\r\n        self._reset = reset\r\n\r\n    @property\r\n    def name(self):\r\n        return self._name\r\n\r\n    @property\r\n    def value(self):\r\n        return self._value\r\n\r\n    @property\r\n    def update(self):\r\n        return self._update\r\n\r\n    @property\r\n    def reset(self):\r\n        return self._reset\r\n\r\n\r\ndef create_metric(scope: str, metric: callable, **metric_args) -> MetricOp:\r\n    with tf.variable_scope(scope) as scope:\r\n        metric_op, update_op = metric(**metric_args)\r\n        scope_vars = tf.contrib.framework.get_variables(\r\n            scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\r\n\r\n        if len(scope_vars) == 0:\r\n            raise Exception(\"No local variables found.\")\r\n\r\n        reset_op = tf.variables_initializer(scope_vars)\r\n    return MetricOp('MetricOp', metric_op, update_op, reset_op)\r\n```\r\n\r\nSorry, could fix that by myself. It was caused by wrapping my coll to this function with a name_scope:\r\n\r\n```python\r\nwith tf.name_scope('Metrics'):  # <---\r\n    targets = tf.argmax(y, 1)\r\n    accuracy_op = metrics.create_metric(\"Accuracy\", tf.metrics.accuracy,\r\n                                        labels=targets, predictions=model.prediction_op)\r\n    precision_op = metrics.create_metric(\"Precision\", tf.metrics.precision,\r\n                                         labels=targets, predictions=model.prediction_op)\r\n```", "@bsautermeister \r\nYou can use scope.original_name_scope wrapping with a name_scope instead of scope.\r\n\r\n    vars = tf.contrib.framework.get_variables(\r\n                 scope.original_name_scope, collection=tf.GraphKeys.LOCAL_VARIABLES)", "@sguada  @AshishBora @astorfi \r\n\r\nHi, Thank you for the leads. I am new to TF. I like to use the separate evaluation process in `tf.slim` with `slim.evaluation.evaluation_loop` .  Is there a workaround to reset the `streaming_accuracy` after a predefined `num_evals`  if I use `slim.evaluation.evaluation_loop`?\r\n\r\n\r\n", "@studentSam0000 You might want to take a look at this [tf slim example](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim#evaluation-loop), where they already use some metrics. However, if you really want to reset your streaming accuracy, you could probably use a hook in which you call the reset op, something along these lines:\r\n\r\n```python\r\nclass ResetHook(tf.train.SessionRunHook):\r\n    \"\"\"Hook to perform reset metrics every N steps.\"\"\"\r\n\r\n    def __init__(self, reset_op, every_step=50):\r\n        self.reset_op = reset_op\r\n        self.every_step = every_step\r\n        self.reset = False\r\n\r\n    def begin(self):\r\n        self._global_step_tensor = tf.train.get_global_step()\r\n        if self._global_step_tensor is None:\r\n            raise RuntimeError(\"Global step should be created to use ResetHook.\")\r\n\r\n    def before_run(self, run_context):\r\n        if self.reset:\r\n            return tf.train.SessionRunArgs(fetches=self.reset_op)\r\n        return tf.train.SessionRunArgs(fetches=self._global_step_tensor)\r\n\r\n    def after_run(self, run_context, run_values):\r\n        if self.reset:\r\n            self.reset = False\r\n            return\r\n        global_step = run_values.results\r\n        if global_step % self.every_step == 0:\r\n            self.reset = True\r\n```\r\n\r\nUsing with the snippet above (https://github.com/tensorflow/tensorflow/issues/4814#issuecomment-314801758) you can then build something like this:\r\n\r\n```python\r\nepoch_loss, epoch_loss_update, epoch_loss_reset = create_reset_metric(\r\n                    tf.contrib.metrics.streaming_mean_squared_error, 'epoch_loss',\r\n                    predictions=output, labels=target)\r\n\r\nreset_hook = ResetHook(epoch_loss_reset, 10)\r\n\r\ntf.contrib.slim.evaluation.evaluation_loop('local', 'checkpoints', 'logs', num_evals=1000, \r\n    ..., hooks=[reset_hook])\r\n```\r\n\r\nI haven't tested the hook, but I used a similar hook to [perform traces](https://github.com/shoeffner/ann3depth/blob/baa3455f873fe1a77b1132af410d285cf81b07e5/src/tfhelper.py#L192-L249) a while ago and just adjusted that one a little bit, but you should get the idea of how it works.", "I've been using the `METRIC_VARIABLES` collection as the `var_list` for `variables_initializer` to reset metrics with a control dependency before updating them, similar in spirit to @shoeffner's approach.", "@gadagashwini With TF 2, this can be closed.", "@rmothukuru With TF 2, this can be now closed (the `tf.keras.metrics` are resettable).", "@foxik,\r\nThank you for the confirmation. Closing the issue as it has been fixed. "]}, {"number": 4813, "title": "OpenCL support", "body": "", "comments": []}, {"number": 4812, "title": "How do you check the code runtime-result without build it ?", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\n\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\n\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\n### Environment info\n\nOperating System:\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\nIf installed from binary pip package, provide:\n1. A link to the pip package you installed:\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`)\n2. The output of `bazel version`\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\n### What other attempted solutions have you tried?\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment or provide link).\n", "comments": ["@sm4241 Please formulate a more specific question, and ask questions that aren't bugs or feature requests on StackOverflow, as explained in the text above.\n"]}, {"number": 4811, "title": "Wrong Answer", "body": "", "comments": []}, {"number": 4810, "title": "#bug# How do you check the code runtime-result without build it ? ", "body": "According to this [link](http://stackoverflow.com/questions/39890170/tensorflow-build-fail-at-october-6-2016),I think some developer can't build it .\nI'm not that familiar with the source code now and can't coding without debug.\n", "comments": ["Sorry for the time, now I think I could build the stable 0.10 version to get  familiar with it.\n"]}, {"number": 4809, "title": "Getting Send/Recv timings for distributed TF", "body": "I'm trying to troubleshoot some slowness in our distributed models , and it would be useful to have access to timing of Send/Recv ops across graph partition.\n\ncc @suharshs because maybe StatsPublisherInterface is relevant?\n\nFor instance, a toy benchmark [here](https://gist.github.com/yaroslavvb/1124bb02a9fd4abce3d86caf2f950cb2) adds 100MB vectors of 1's in one process to variable in another process on local machine. If I look at timeline/stepstats, I see 120ms of emptiness, followed by 20ms in `AddOp` followed by another 700ms of missing time.\n\nBecause it's a toy benchmark, I can figure out that 120ms is spent in transferring 100MB from one TF runtime to another, and 700ms is spent making the result available to Python client. But it's harder to do this on a large model\n\n<img width=\"1298\" alt=\"screen shot 2016-10-06 at 5 27 51 pm\" src=\"https://cloud.githubusercontent.com/assets/23068/19175296/47ddfe64-8bea-11e6-9882-a4a59a9823c8.png\">\n", "comments": ["cc @prb12 the timeline wizard\n", "Yes - the way trace data is collected for Send/Recv nodes in our internal tracer is somewhat out-of-band and isn't implemented in the current open-source distributed tracing.  Neither is the GPUTracer support (though that is an easy 2 line change).  \n\nBoth of these issues need to be addressed in the current refactoring which suharshs@ is doing to the various Session implementation.  I've been meaning to improve our internal Send/Recv tracing for some time, but it has never reached the top of the todo list ;-)\n\nTo do a nice job of visualizing this, it would probably be necessary to make the tf.Timeline class accept the rewritten post-partitioning GraphDefs which can now be retrieved in the RunMetadata.  (This will also get rid of all of the 'Unknown' ops in the timeline!)\n", "Great to know this is being worked on! I think having the raw tracing data retrievable is higher priority than nice visualization -- if I had some way to see send/recv timing in the .pbtxt file I could diagnose things already . BTW, I don't see post-partitioning GraphDefs in RunMetadata when running with `tf.RunOptions.FULL_TRACE`, is there some extra option to turn that on?\n", ">  BTW, I don't see post-partitioning GraphDefs in RunMetadata when running with tf.RunOptions.FULL_TRACE, is there some extra option to turn that on?\n\n`RunOptions.output_partition_graphs`\n\nIt's a separate flag because the GraphDefs are typically large and you don't want to collect them every time.\n", ">  if I had some way to see send/recv timing in the .pbtxt file I could diagnose things already\n\nRecv ops are async and don't currently get traced into StepStats.  I think that Send ops are traced, but may get filtered out (need to check). \n\nTo visualize what's going on, the UI needs to connect the start of the Send op with the _end_ of the Recv op (since this is approximately the time taken on the wire).  Note that Recv ops typically fire immediately and wait around on the remote machine until the matching Send op executes.    \n\nSince there are typically _many_ outstanding Recvs at any given time, mostly just waiting for data to arrive, showing them in the UI as regular op rectangles results in a largely useless and cluttered UI.   The Chrome UI has 'flow events' which would let me draw arrows from Sends to Recvs and this might be easier to understand and more compact (\"vertical arrows are good, diagonal arrows imply something is taking a long time\")  \n\nAnyhow ... that's the plan, but it's hard to find time to work on this.\n", "@pb12 I don't see \"Send\" ops in run_metadata.step_stats, where should I look to see if it's filtered out?\n", "For historical reasons, it actually happens in `ExecutorState::NodeDone` [here](https://github.com/tensorflow/tensorflow/blob/0a4f5b6bda405814af59803829216762e030728d/tensorflow/core/common_runtime/executor.cc#L1603)\n\n... and the test being done inside `SetTimelineLabel` makes very little sense any more.\n\n```\nbool ExecutorState::NodeDone(const Status& s, const Node* node,\n                             const TaggedNodeSeq& ready, NodeExecStats* stats,\n                             TaggedNodeReadyQueue* inline_ready) {\n  if (stats) {\n    nodestats::SetAllEnd(stats);\n    if (!SetTimelineLabel(node, stats)) {\n      // Only record non-transfer nodes.\n      stats_collector_->Save(impl_->params_.device->name(), stats);\n    } else {\n      delete stats;\n    }\n  }\n```\n\nI personally would prefer to see the Send op and both halves of the async Recv op in the timeline, with an arrow from the Send to RecvDone so that you can see the transfer latency.  However, last time I tried to change this lots of people complained ;-)\n", "recently came up here http://stackoverflow.com/questions/41867993/tensorflow-one-of-20-parameter-server-is-very-slow", "I am also stuck on measuring the network performance for distributed TF. Any updates on this feature would be really appreciated!", "There's been a feature added recently that provides a work-around -- `tf.Print` nodes now print microsecond-level timestamp to stderr.\r\n\r\nSo you could use tf.Print to wrap nodes responsible for sending/receiving data (ie, generally variable accesses), log things to stderr, and then parse stderr logs for exact timings.\r\n\r\nOne possible snag -- wrapping an op in tf.Print guarantees that the op is executed after tf.Print, but it may not be executed immediately after tf.Print. So you could log the timings and take minimum over many tries to get more precise timing. Also, you may use utility like https://github.com/yaroslavvb/stuff/blob/master/linearize to force TensorFlow to do all computations serially, and double check that the execution order that is chosen does not insert ops between `tf.Print` and the target op.\r\n\r\n", "Thanks for @prb12 to point out `ExecutorState::NodeDone` inside `executor.cc`. I managed to get send/receive timing by commenting out related code inside` executor.cc` and compile TensorFlow from source. \r\n\r\nAlthough it does not output a good UI inside `chrome://tracing`, I am able to analyze the timing from raw JSON file. :)\r\n\r\na detailed explanation here http://stackoverflow.com/a/42823232/3117069", "@Joranson I did the same thing by changing SetTimelineLabel() to return void and then in ExecutorState::NodeDone() recording all the nodes. After this I didn't see any specific mention of send/recv in the name or op. They show up as unknown and clutters everything when loaded on chrome trace viewer.  Did you see similar thing?\r\n\r\n@prb12 I like your idea of connecting async recv and send with arrows. Do you know what is good place to start for doing this code change?", "when does Recv Op start executing? In my understanding, since Recv Op has no dependency, it will start immediately when thread pool is avaliable, but it's not a good idea because all parameters will be downloaded and stored on computing device at same time.", "I noticed there is a [profiler and advisor tool](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler) in tf official code, and it supports `distributed runtime check` like `Checks RecvTensor RPC latency and bandwidth.`, when will this check be available in open source tf?", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "My [PR](https://github.com/tensorflow/tensorflow/pull/14604) to address this problem is already merged (Thanks to @prb12 and co) which makes RecvTensor ops to show up in tracing metadata. Chrome Tracing can visualize the RecvTensor ops. However, it removes the details of them (Source/Destination/Tensor Name/Size).\r\n\r\nI have also developed a small [tracing visualization tool](https://github.com/xldrx/tensorflow-runtime-metadata-visualization/) which retains the details as well as separates network and computing ops.\r\n\r\nAn output example can be found [here](http://htmlpreview.github.io/?https://github.com/xldrx/tensorflow-runtime-metadata-visualization/blob/master/example-inception-train-4w-1ps.html).\r\n\r\n![Inception Timeline](https://github.com/xldrx/tensorflow-runtime-metadata-visualization/blob/master/example-inception-train-4w-1ps.png?raw=true \"Inception Timeline\")", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignees @suharshs, @prb12: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignees @suharshs, @prb12: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignees @suharshs, @prb12: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This issue is now obsolete."]}, {"number": 4808, "title": ".ckpt file cann't be freezed into .pb after run eval_image_classifier.py", "body": "This is a very strange issue i meet. i do not know what changes are made by eval_image_classifier.py\n### Environment info\n\nUbuntu 16.04\n### Steps:\n1. Train inception v1 (slim) model and get .ckpt files.\n2. Run freeze_graph to freeze .ckpt file into .pb file, like cmd below:\n\n**bazel-bin/tensorflow/python/tools/freeze_graph \\\n --input_graph=/home/tensorflow/v1.3sgd_copy/graph.pbtxt \\\n --input_checkpoint=/home/tensorflow/v1.3sgd_copy/model.ckpt-73074 \\\n --output_graph=/home/tensorflow/v1.3sgd_copy/freeze.pb \\\n --output_node_names=InceptionV1/Logits/Predictions/Softmax**\n\nyou will get:\n\n**Converted 173 variables to const ops.\n1766 ops in the final graph.**\n\n 3, Run model evaluation by cmd below\n\n**python eval_image_classifier.py \\\n  --checkpoint_path=/home/tensorflow/v1.3sgd_copy/model.ckpt-73074 \\\n  --eval_dir=/home/tensorflow/v1.3sgd_copy/ \\\n  --dataset_name=animals \\\n  --dataset_split_name=validation \\\n  --dataset_dir=/home/data/datadic_train/ \\\n  --model_name=inception_v1 \\\n  --batch_size=256 \\\n  --labels_offset=0**\n\nthen you will get the result like: \n**I tensorflow/core/kernels/logging_ops.cc:79] eval/Accuracy[0.7301592]**\n\n 4, Now run the cmd in step 2 again to freeze the same .ckpt file\n\nCMD:\n\n**bazel-bin/tensorflow/python/tools/freeze_graph \\\n --input_graph=/home/tensorflow/v1.3sgd_copy/graph.pbtxt \\\n --input_checkpoint=/home/tensorflow/v1.3sgd_copy/model.ckpt-73074 \\\n --output_graph=/home/tensorflow/v1.3sgd_copy/freeze.pb \\\n --output_node_names=InceptionV1/Logits/Predictions/Softmax**\n\nThen you will get errors: **Attempting to use uninitialized value accuracy/total**\n### Log\n\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\nTraceback (most recent call last):\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 134, in <module>\n    tf.app.run()\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 131, in main\n    FLAGS.output_graph, FLAGS.clear_devices, FLAGS.initializer_nodes)\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 120, in freeze_graph\n    sess, input_graph_def, output_node_names.split(\",\"))\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/framework/graph_util.py\", line 226, in convert_variables_to_constants\n    returned_variables = sess.run(variable_names)\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 717, in run\n    run_metadata_ptr)\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 915, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 965, in _do_run\n    target_list, options, run_metadata)\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 985, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.FailedPreconditionError: Attempting to use uninitialized value accuracy/total\n     [[Node: _send_accuracy/total_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=381203147379632588, tensor_name=\"accuracy/total:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](accuracy/total)]]\n", "comments": ["At very beginning, i run eval_image_classifier.py after training, and then try to freeze *.ckpt file, but not run pass. Now the above steps in thread 1 can repro the issue.\n", "@civilmanxx I think the problem is that you're specifying the following two flags to `eval_image_classifier.py`\n\n```\npython eval_image_classifier.py \\\n--checkpoint_path=/home/tensorflow/v1.3sgd_copy/model.ckpt-73074 \\\n--eval_dir=/home/tensorflow/v1.3sgd_copy/ \\\n```\n\nI'm suspecting that passing --eval_dir to point to the same directory where your checkpoint is stored is causing the checkpoint to be overwritten.  To confirm this, you can try running `ls -l /home/tensorflow/v1.3sgd_copy` before and after you run `eval_image_classifier.py`, and compare the output.\n\nAs a fix, I'd suggest setting your `--eval_dir` to a different directory.\n\nLet me know if that works!\n", "Yes, set to a different path for **--eval_dir**  works. I see a new **graph.pbtxt** is created for evaluation. It is smaller than the one under **--train_dir**. So the root cause is if set train_dir and eval_dir to the same folder, new **graph.pbtxt** under validation phase will replace the old one, which lead to freeze_graph fail.\n\nthanks a lot.\n"]}, {"number": 4807, "title": "Upgrade to libjpeg-turbo", "body": "TensorFlow seems to be using the classic libjpeg v 0.9, but libjpeg-turbo is heavily optimized to leverage SIMD on various platforms (x86, ARM, POWER, etc.), and is both API and ABI compatible with libjpeg, at least up to libjpeg 0.8. Given TensorFlow's goal of portability across a wide varierty of platforms, I'm wondering if libjpeg was decided upon instead of libjpeg-turbo for portability, or was this just an omission? \n\nlibjpeg-turbo speeds up JPEG decoding by about 2x, and since that reduces decoding latency and increases throughput, it not only improves performance of TensorFlow on the CPU, but especially on the GPU, which tends to wait for the CPU to provide decoded images. Moreover, that could result in a major performance improvement on more CPU-underpowered platforms such as ARM (e.g. via NEON SIMD on the NVIDIA TX1 platform which uses the NEON-capable Cortex A57, or on ARM Cortex A8 on a Samsung Galaxy S).\n", "comments": ["@mkolod Thanks for filing this issue!\n\nSwitching to libjpeg-turbo sounds like a reasonable thing to investigate.  We welcome contributions!\n\nIf anyone is going to attempt this, probably the two areas to focus on are:\n1. Benchmarks showing the actual performance when used within TensorFlow.\n2. A breakdown of the portability tradeoffs between the two libraries.\n\nAdding @prb12 @poxvoculi since they might be interested, and might know some of the history behind why libjpeg was chosen over libjpeg-turbo (if any).\n", "We should definitely switch. libjpeg-turbo supports all the platforms we're on, and it seems that both Chrome and Firefox are already using it.\n", "Self-assigning so I can test it out internally as well.\n", "@jhseu I actually managed to add it in my own experiments, but it seems to be failing at runtime, even though compilation succeeds (more on this in a moment). I suppose the big question about how to distribute such a change to the community is how to deal with the fact that the libjpeg-turbo code is largely assembly (SSE2, NEON, AltiVec, etc.). When building from source, it may be tricky doing it from Bazel without say genrules. Also, the current assembly mnemonics specifically call for nasm, though maybe there's an easier way. In my experiments, I have a genrule that calls turbo's own build, which is based on autotools (autoconf/configure/make, with make calling nasm), but that's a Rube Goldberg solution at best. Another option is of course to pull a pre-built static lib (libjpeg.a) from some CDN, removing the dependence on dealing with building assembly code, and just having a cc_library that provides headers and uses a pre-built lib. I'm not sure which approach would be preferable to the community.\n", "@jhseu Regarding the runtime failure after swapping out the libjpeg v9-based libjpeg.a with libjpeg-turbo based lib (API and ABI-compatible with libjpeg v8), I swapped out both the static lib (compiled with -fPIC) and the headers, the Bazel build completed on my machine, but there's a runtime failure while decoding. There's no clear exception, the queues that run the jpeg decoding just shut down with an OutOfRangeError (must be a silent error). I'm planning to start debugging that tomorrow. Generally, libjpeg-turbo with API and ABI support for libjpeg v8 should be good enough, because libjpeg v9 only added a nonstandard color transform to \"Lossless SmartScale,\" which is neither a community nor industry standard (only supported in libjpeg v9 and no other library or image capture device). See [here](http://www.libjpeg-turbo.org/About/Jpeg-9) about why libjpeg-turbo only goes until libjpeg v8 support. So, it's a bit odd that there's an issue since unless there's an API incompatibility, libjpeg-turbo is a drop-in for libjpeg. I'll keep you posted what I find and then share a branch on a fork or something. Like I said, my solution may not be ideal, it's tricky dealing with assembly-based builds, and it's tricker still to know what's preferable from the project's overall standards point of view for custom code like this.\n", "@jhseu BTW, the way Caffe deals with turbo is that it just uses OpenCV, which comes with it. I'm not sure about whether other frameworks upgraded to turbo (Torch hasn't, I know that almost for sure), but that assembly code base makes for a complex build for sure.\n", "@jhseu Also, many Linux distros already come with libjpeg-turbo (as libjpeg.so for compatibility with libjpeg), but I assume that relying on the uncertainty of whether a shared lib is there is complicated if one is to support platforms other than popular Linux distros such as Ubuntu. So, some static linking would probably be better, which is how libjpeg was already integrated (but libjpeg was pure C so it could use a cc_library rule and build from source without nasm, etc.).\n", "@jhseu Also for a quick benchmark, I've done AlexNet profiling, and JPEG decode was consuming about 30% of the CPU time, with Core i7 6 cores fully utilized serving one GTX 1080. AlexNet is a good case here because it's light on GPU compute and exposes inefficiencies elsewhere in the system, such as I/O (frequent gradient updates, lots of disk requests for large datasets read via queues, e.g. ImageNet), etc. JPEG decoding is important here because the GPUs tend to wait for the CPU to finish decoding and so the GPU utilization is low if decoding takes too long. I found that AlexNet training (batch size 128-1,024) could be sped up by 20% on average on above mentioned GTX 1080 via a switch from libjpeg to libjpeg-turbo. This may matter less for say Inception v3 or ResNet-50, but it will still help, particularly in multi-GPU environments which are more CPU-bound for decoding.\n", "@mkolod Ah, thanks for researching this so thoroughly.\n\nAs a general principle, we prefer to build and statically link dependencies for all required features. This simplifies deployment in certain settings (e.g., distributed training) and helps with reproducibility.\n\nThe right thing to do is to create a new rule that underneath uses genrule to compile assembly with nasm. I'm unsure about whether we'd want to add nasm as a required build-time dependency, though.\n\nUnassigning since it's not clear we want to make libjpeg-turbo default because of the nasm dependency. Making it optional seems reasonable, though.\n", "@jhseu I'll try to look into making turbo optional in the Bazel build, right now I have it on for all cases. Meanwhile, I wanted to share some perf figures of how this would impact decoding. The base case here is Caffe and CNTK, which use OpenCV and get about 1k ImageNet images decoded per CPU core on a CPU the same as mine (6-core Core i7-5930K 3.50GHz). I used the standard ImageNet protobufs generated using the ImageNet preprocessing script from the Inception code base. The figures are as follows, on a per core basis:\n\nbase case: 219 images/sec\n\nbase + Fast IDCT (see issue #5072): 233 im/sec\n\nbase + Fast IDCT + libjpeg-turbo: 356 im/sec\n\nbase + Fast IDCT + libjpeg-turbo + pre-resized images (to 256x256, can crop it down to 227x227 for AlexNet at runtime with random crops, etc.): 700 im/sec\n\nThe Caffe/CNTK perf is at 1k im/sec, but that's also in benchmarks with pre-resized images (one shouldn't have to do anything else than cropping at runtime, definitely not padding, etc.). For lighter networks like AlexNet, the image decode is definitely a bottleneck. For heavier networks like Inception, it may not be an issue, but again, it could be an issue for more CPU-challenged platforms like ARM, even for inference.\n\n[Here](https://github.com/mkolod/tf_perf_eval/blob/master/io/only_decode_benchmark.py) is the script I used for this benchmark. I'll post the Bazel integration with the libjpeg-turbo build shortly. For making turbo optional, I wonder if it shouldn't be a configure option, like the CUDA/CUDNN/HDFS support right now? If not, what's another option for conditional inclusion into the build?\n", "Yeah, as a ./configure option makes sense. We also optionally allow configuration through environment variables with running ./configure, so it can be a hidden option if ./configure gets too large in the future.\n\nWe should check for the presence of nasm during ./configure if the user enables it.\n", "@jhseu Yes, I'm following the HDFS support, in that I provide options for both interactive selection and the env var. Furthermore, invalid selections, such as choosing libjpeg-turbo when the build support for assembly is not available, causes a configure failure and a recommendation to install the appropriate tools, or select N during the libjpeg-turbo prompt (or selecting 0 using the env var) to fall back to libjpeg. This should make libjpeg-turbo completely optional, and improve performance for users who have the appropriate tooling on their OS or Docker container.\n", "Hey @mkolod did https://github.com/tensorflow/tensorflow/commit/52ffc792fdef41de20ac60dc61d4e809d83b558d end up working out for you? It would be helpful to get feedback. Especially if you have time to review the BUILD file, in case there's some select() statements we forgot to write tuning those constants for various platforms."]}, {"number": 4806, "title": "Fix configure script readlink incompatibility on Darwin.", "body": "#4699 introduced a change that broken the build on OS X since `readlink` works\n\ndifferently.\n\nThis change fixes the `readlink` invocations so that they work on both platforms\nand avoid failing the `configure` script if the path is not a symlink.\n", "comments": ["@davidzchen, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @vrv and @keveman to be potential reviewers.\n", "@tensorflow-jenkins test this please.\n", "This also fixes #2630.\n"]}, {"number": 4805, "title": "Update configure", "body": "b/31910117\n\ncorrectly finds python3 bin libraries\n", "comments": ["Can one of the admins verify this patch?\n", "@itsmeolivia, thanks for your PR! By analyzing the history of the files in this pull request, we identified @davidzchen, @vrv and @keveman to be potential reviewers.\n", "Jenkins, test this please.\n"]}, {"number": 4804, "title": "Change to use contrib.tfprof since write_op_log is already exposed", "body": "", "comments": ["@terrytangyuan, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener to be a potential reviewer.\n", "LGTM!\n"]}, {"number": 4803, "title": "Adjusted buffer size to reduce memory usage and increase performance", "body": "This small tweak to the im2col buffer size shows improvements in some of our benchmark's latency, and reduces overall memory used.\n", "comments": ["@petewarden, thanks for your PR! By analyzing the history of the files in this pull request, we identified @mrry and @tensorflower-gardener to be potential reviewers.\n", "@tensorflow-jenkins test this please.\n"]}, {"number": 4802, "title": "Branch 135386248", "body": "", "comments": ["@tensorflow-jenkins test this please.\n"]}, {"number": 4801, "title": "[Windows] Fix build by avoiding use of non-standard 0-size array.", "body": "Fixes #4798.\n", "comments": ["@mrry, thanks for your PR! By analyzing the history of the files in this pull request, we identified @yifeif, @tensorflower-gardener and @sherrym to be potential reviewers.\n", "@tensorflow-jenkins test this please.\n", "@gunan: Is there a cunning way we could trigger the Windows Jenkins build on demand for a PR? (I tested it locally and it built, but it'd be nice to have a green tick to go with it :).\n", "Now that we have 3 windows executors, I can set up windows build to run for every PR.\nWould that work?\n\nI can quickly get you a test we can link for this, but unfortunately I cannot get the green tick without adding it to all presubmits and getting all the PR tests to run again.\n", "I'm happy to take a chance on merging this, since it builds for me locally!\n\nBut it'd be awesome to run Windows presubmits for every PR. Maybe an optional check at first though, in case it starts blocking people for no good reason?\n"]}, {"number": 4800, "title": "Updated the links in docs to match the markdown sytnax.", "body": "Refer to [markdown syntax](https://daringfireball.net/projects/markdown/syntax#link),\nthe `[` should come after `)` without spaces or new line character. This fixs\nthe broken links when generate PDF/EPUB books by Gitbook.\n", "comments": ["@haosdent, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @ilblackdragon and @vrv to be potential reviewers.\n", "Can one of the admins verify this patch?\n", "@terrytangyuan Sorry for the delay, may you help review this patch? Thank you in advance. \n", "Thanks! @tensorflow-jenkins Test this please. \n", "For the changes in the python API, I believe it would make sense to update the actual py code instead of the docs since the docs are automatically generated. \n", "Hi, @rohan100jain Thanks a lot for review! I change both shard documents in python API and python source code. e.g., For `Candidate Sampling Algorithms Reference`, I change `tensorflow/python/ops/nn.py` and `tensorflow/g3doc/api_docs/python/functions_and_classes/shard1/tf.nn.sampled_softmax_loss.md`\n\nShould I need to revert anything?\n", "Thats great! But I think you might have missed out some such as https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/ops.py#L2128\netc. \n\nDon't think you need to revert anything but what I'm saying is that if the .py files for all the ops are not changed this problem with re-occur because someone will regenerate and we'll get the broken links back again. So I guess it would be great if you can look through all the python API docs that were changed in this PR and see if there are corresponding .py documentation that might need to be changed as well. \n", "@rohan100jain Thanks a lot! My bad use `\\]\\s\\([#h]` to search it, I should use `\\]\\s+\\([#h]` Would you like to help review my patch to fix this issue?\n"]}, {"number": 4799, "title": "Error building PIP package on Windows", "body": "Hi,\n\nI followed the new instructions for the [CMake build on Windows](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cmake/README.md).\nThe C++ example program `tf_tutorials_example_trainer.exe` build and run successfully.\nBut the build of the PIP package exited with the following error:\n\n```\nld_pip_package.vcxproj\" (Standardziel) (1) ->\n\"C:\\Users\\jonas\\projects\\tensorflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensor flow.vcxproj\" (Standardziel) (3) ->\n(ClCompile Ziel) ->\nC:\\Users\\jonas\\projects\\tensorflow\\tensorflow\\python\\lib\\core\\py_func.cc(165): \nerror C2466: cannot allocate an array of constant size 0 [C:\\Users\\jonas\\projec ts\\tensorflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow.vcxproj]\n\n    2398 Warnung(en)\n    1 Fehler\n```\n", "comments": ["Thanks for reporting this. As you've already noticed, this is a duplicate of #4798, so I'm going to close this as a duplicate and report there when it's fixed.\n"]}, {"number": 4798, "title": "Error building on Windows", "body": "(Copied from @laudney's comment on #17)\n\n> I've tried to follow your instructions. All seem to work flawlessly (for about 45min) until it failed with:\n> \n> ```\n> The target \"BeforeGenerateProjectPriFile\" listed in a BeforeTargets attribute at \"C:\\Program Files (x86)\\MSBuild\\Microsoft\\NuGet\\Microsoft.NuGet.targets (186,61)\" does not exist in the project, and will be ignored.\n> Done Building Project \"H:\\PycharmProjects\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_build_pip_package.vcxproj\" (default targets) -- FAILED.\n> \n> \"H:\\PycharmProjects\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_build_pip_package.vcxproj\" (default target) (1) ->\n> \"H:\\PycharmProjects\\tensorflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow.vcxproj\" (default target) (3) ->\n> \"H:\\PycharmProjects\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_cpu.vcxproj\" (default target) (4) ->\n> \"H:\\PycharmProjects\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_framework.vcxproj\" (default target) (5) ->\n> (CustomBuild target) ->\n>   C:\\Program Files (x86)\\MSBuild\\Microsoft.Cpp\\v4.0\\V140\\Microsoft.CppCommon.targets(171,5): error MSB6006: \"cmd.exe\" exited with code 1. [H:\\PycharmProjects\\t\n> ensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_framework.vcxproj]\n> \n>     30 Warning(s)\n>     1 Error(s)\n> ```\n", "comments": ["@laudney It looks like the error (namely `\"cmd.exe\" exited with code 1`), happened early in the build - can you post the entire log (e.g., by adding the `/filelogger` flag to `MSBuild` and uploading the resulting `msbuild.log` as a gist)?\n", "@mrry Yes. I've just done that and I've noticed it was due to \"git.exe\" not in my PATH. I'm trying it again and will report back.\n", "@mrry New error below after 1h of compilation. Please let me know if you need the log.\n\n\"C:\\src\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_build_pip_package.vcxproj\" (default target) (1) ->\n\"H:\\PycharmProjects\\tensorflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow.vcxproj\" (default target) (3) ->\n(ClCompile target) ->\n  H:\\PycharmProjects\\tensorflow\\tensorflow\\python\\lib\\core\\py_func.cc(165): error C2466: cannot allocate an array of constant size 0 [H:\\PycharmProjects\\tensor\nflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow.vcxproj]\n", "exactly the same error in #4799 \n", "Thanks for this report! I've found the problem (a recent change to `py_func.cc`) and am working on a fix.\n"]}, {"number": 4797, "title": "Error following the wide and deep tutorial ", "body": "I've been trying to follow through the wide and deep tutorial on a different data set and I am getting the below error.\n\nI am using this version of tensorflow: tensorflow-0.11.0rc0-cp27-none-linux_x86_64.whl\non python: Python 2.7.5\n\nAll my fields are strings (features and labels)\n\nI am adding the relevant code snippets\n\n```\nf1Col = tf.contrib.layers.sparse_column_with_keys(\"f1\", keys = [\"l1\", \"l2\", \"l3\"])\n..\n..\nI've defined all columns similar to this one (no hash bucket ones)\n..\n..\n\n```\n\n```\nwide_columns = [\n  tf.contrib.layers.crossed_column(columns = [f1Col, f2Col, f3Col] , hash_bucket_size = 1e7),\n  ...\n  defined all crossed columns like the above one with smaller hash buckets for ones with less features\n  ...\n]\n```\n\n```\ndeep_columns = [\n    tf.contrib.layers.embedding_column(f1Col, dimension=8),\n    ...\n   defined all my features here as embedding columns exactly as the one above\n   ....\n]\n```\n\ntried this with both settings for enable_centered_bias the error changes a bit but is still the same\n\n```\nimport tempfile\nmodel_dir = tempfile.mkdtemp()\nm = tf.contrib.learn.DNNLinearCombinedClassifier(\n    model_dir=model_dir,\n    linear_feature_columns=wide_columns,\n    dnn_feature_columns=deep_columns,\n    dnn_hidden_units=[1000, 500, 250], enable_centered_bias = False)\n```\n\n```\ndef input_fn(df):\n  categorical_cols = {k: tf.SparseTensor(\n      indices=[[i, 0] for i in range(df[k].size)],\n      values=df[k].values,\n      shape=[df[k].size, 1])\n                      for k in my_features_col_list}\n  label = tf.constant(df['my_label_col'].values)\n  return categorical_cols, label\n\ndef train_input_fn():\n  return input_fn(features)\n\ndef eval_input_fn():\n  return input_fn(features)\n```\n\nthen when I try to fit like this:\n`m.fit(input_fn=train_input_fn, steps=200)`\n\nI get the following error. I am not sure if I hit a bug or did something wrong. I am getting some warnings in the earlier code about combiner function defaults changing\n\nThen again when executing the fit I get the 2 warnings and then the error below them:\n\n```\nWARNING:tensorflow:Given features: {'f1': <tensorflow.python.framework.ops.SparseTensor object at 0xc5bf690>, ... required signatures: {'f1': TensorSignature(dtype=tf.string, shape=None, is_sparse=True), ...\n\nWARNING:tensorflow:Given targets: Tensor(\"Const:0\", shape=(2019,), dtype=string), required signatures: TensorSignature(dtype=tf.string, shape=TensorShape([Dimension(2019)]), is_sparse=False).\n\n```\n\n```\n---------------------------------------------------------------------------\nUnimplementedError                        Traceback (most recent call last)\n<ipython-input-29-8f5351c1fdf8> in <module>()\n----> 1 m.fit(input_fn=train_input_fn, steps=200)\n\n/usr/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc in fit(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\n    331                              steps=steps,\n    332                              monitors=monitors,\n--> 333                              max_steps=max_steps)\n    334     logging.info('Loss for final step: %s.', loss)\n    335     return self\n\n/usr/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc in _train_model(self, input_fn, steps, feed_fn, init_op, init_feed_fn, init_fn, device_fn, monitors, log_every_steps, fail_on_nan_loss, max_steps)\n    706           fail_on_nan_loss=fail_on_nan_loss,\n    707           hooks=hooks,\n--> 708           max_steps=max_steps)\n    709 \n    710   def _extract_metric_update_ops(self, eval_dict):\n\n/usr/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.pyc in _monitored_train(graph, output_dir, train_op, loss_op, global_step_tensor, init_op, init_feed_dict, init_fn, log_every_steps, supervisor_is_chief, supervisor_master, supervisor_save_model_secs, keep_checkpoint_max, supervisor_save_summaries_steps, feed_fn, steps, fail_on_nan_loss, hooks, max_steps)\n    283       while not super_sess.should_stop():\n    284         _, loss = super_sess.run([train_op, loss_op], feed_fn() if feed_fn else\n--> 285                                  None)\n    286       return loss\n    287 \n\n/usr/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/monitored_session.pyc in run(self, fetches, feed_dict, options, run_metadata)\n    366                           feed_dict=feed_dict,\n    367                           options=options,\n--> 368                           run_metadata=run_metadata)\n    369 \n    370   def should_stop(self):\n\n/usr/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/monitored_session.pyc in run(self, fetches, feed_dict, options, run_metadata)\n    519                               feed_dict=feed_dict,\n    520                               options=options,\n--> 521                               run_metadata=run_metadata)\n    522       except errors.AbortedError:\n    523         self.close()\n\n/usr/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/monitored_session.pyc in run(self, *args, **kwargs)\n    486 \n    487   def run(self, *args, **kwargs):\n--> 488     return self._sess.run(*args, **kwargs)\n    489 \n    490 \n\n/usr/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/monitored_session.pyc in run(self, fetches, feed_dict, options, run_metadata)\n    617                                   feed_dict=feed_dict,\n    618                                   options=options,\n--> 619                                   run_metadata=run_metadata)\n    620 \n    621     for hook in self._hooks:\n\n/usr/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/monitored_session.pyc in run(self, *args, **kwargs)\n    486 \n    487   def run(self, *args, **kwargs):\n--> 488     return self._sess.run(*args, **kwargs)\n    489 \n    490 \n\n/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)\n    715     try:\n    716       result = self._run(None, fetches, feed_dict, options_ptr,\n--> 717                          run_metadata_ptr)\n    718       if run_metadata:\n    719         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n\n/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)\n    913     if final_fetches or final_targets:\n    914       results = self._do_run(handle, final_targets, final_fetches,\n--> 915                              feed_dict_string, options, run_metadata)\n    916     else:\n    917       results = []\n\n/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\n    963     if handle is None:\n    964       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n--> 965                            target_list, options, run_metadata)\n    966     else:\n    967       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n\n/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)\n    983         except KeyError:\n    984           pass\n--> 985       raise type(e)(node_def, op, message)\n    986 \n    987   def _extend_graph(self):\n\nUnimplementedError: Cast string to float is not supported\n     [[Node: ToFloat = Cast[DstT=DT_FLOAT, SrcT=DT_STRING, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](ExpandDims)]]\n\nCaused by op u'ToFloat', defined at:\n  File \"/usr/lib64/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib64/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2827, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-29-8f5351c1fdf8>\", line 1, in <module>\n    m.fit(input_fn=train_input_fn, steps=200)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 333, in fit\n    max_steps=max_steps)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 662, in _train_model\n    train_op, loss_op = self._get_train_ops(features, targets)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py\", line 195, in _get_train_ops\n    features)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/target_column.py\", line 206, in training_loss\n    loss_unweighted = self._loss_fn(logits, target)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/target_column.py\", line 389, in _log_loss_with_two_classes\n    math_ops.to_float(target))\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 661, in to_float\n    return cast(x, dtypes.float32, name=name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 616, in cast\n    return gen_math_ops.cast(x, base_type, name=name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 419, in cast\n    result = _op_def_lib.apply_op(\"Cast\", x=x, DstT=DstT, name=name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 749, in apply_op\n    op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2380, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1298, in __init__\n    self._traceback = _extract_stack()\n\nUnimplementedError (see above for traceback): Cast string to float is not supported\n     [[Node: ToFloat = Cast[DstT=DT_FLOAT, SrcT=DT_STRING, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](ExpandDims)]]\n```\n", "comments": ["Thanks for filing the issue @mahdeto.  Note that we primarily use github issues to track bugs and feature requests.  This is a question better suited for StackOverflow. Please ask it there and tag it with the `tensorflow` tag.  Thanks!\n\nAs for the error you're encountering, I'd suggest starting with the provided example code:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/learn/wide_n_deep_tutorial.py\n\nIf you can boil the problem down to that example code, or a small change to that example code, feel free to comment on this issue or file a new issue.\n", "my problem was that the classes needed to be integers, leaving it here in case someone else runs into this\n", "I'm getting pretty much the same error as well.  My stack overflow thread is here:\n\nhttp://stackoverflow.com/questions/40186722/python-tensorflow-cast-string-to-float-is-not-supported-in-linear-model\n\nHave any of you managed to resolve the problem?\n", "I am getting the same issue with TF 0.12 on windows. The Wide N deep turorial has several errors, including this one. I tried to ensure we have numbers in all features where conversions may be performed, rest being categorical data. Has anyone found a fix? The tutorial does not run at all on Win 10.", "i also solved by making all continuous features integer values", "I am using W10, Python3 and Tensorflow 1.9\r\n\r\nThe source of the error in my code was in the feature definition. I had a boolean feature with a `default_value` of -1 like this:\r\n\r\n    tf.feature_column.categorical_column_with_vocabulary_list( \r\n        key='partial_funding_indicator', vocabulary_list=['True', 'False'],\r\n        dtype=tf.string, **default_value=-1**, num_oov_buckets=None)\r\n\r\nThe issue did not arise when the `default_value` was changed to `0`:\r\n\r\n    tf.feature_column.categorical_column_with_vocabulary_list(\r\n        key='partial_funding_indicator', vocabulary_list=['True', 'False'],\r\n        dtype=tf.string, **default_value=0**, num_oov_buckets=None)\r\n\r\n`default_value` is the integer ID value to return for out-of-vocabulary feature values.  For example, in a list/file of value like `['True', 'False']` to make `default_value == True`, it would be `default_value=0`; the list index."]}, {"number": 4796, "title": "Make tutorial_example_trainer build on Windows with Bazel", "body": "With these changes, we are able to build the C++ example trainer by \n`bazel build --host_cpu=x64_windows_msvc --cpu=x64_windows_msvc -c opt tensorflow/cc:tutorials_example_trainer` \nwith Bazel from HEAD on Windows.\nI modified the BUILD files carefully, hopefully it won't break TF build on other platform.\n@mrry @damienmg @dslomov\n", "comments": ["Can one of the admins verify this patch?\n", "@meteorcloudy, thanks for your PR! By analyzing the history of the files in this pull request, we identified @josh11b, @vrv and @jhseu to be potential reviewers.\n", "Thanks for sending this in, Yun!\n", "@tensorflow-jenkins test this please.\n", "You are welcome! Looks like there are many failures, I'll look into it.\n", "Can we test it again?\n", "@tensorflow-jenkins test this please.\n", "@mrry could you take another look?\n", "@mrry Just pushed, please review again. :)\n", "@tensorflow-jenkins test this please.\n", "From the error message in Linux GPU, looks like we should also pull `depthwise_conv_grad_op` out of deps, but  `depthwise_conv_grad_op` [needs `depthwise_conv_op.h`](https://github.com/meteorcloudy/tensorflow/blob/fe74dfaf000ecef0b36b847f50bb0283e8a8ac71/tensorflow/core/kernels/BUILD#L1617). What should we do?\n", "Or maybe they are in the deps for a reason? See these two commits b51ef0cd06e1bfb529b272e55010790ff3ead31f, 99e298a84775fcfe91ce0e2d40566d4bd00f53f9\n", "I'm not sure what the proper solution would be for them. Assigning to @jmchen-g, since he wrote those ops originally.\n", "Which deps are not clear here? If you mean why it is in the deps of nn, Depthwise is one of the convs that we need to support in TF and is commonly used to reduce the computing needs for a model.\n", "OK, I see. Sounds like `depthwise_conv_ops` is supposed to be in deps of nn. I've deleted my last commit. Please test again? \n", "@mrry Are you OK with keeping `depthwise_conv_ops` in deps of `nn`? If so, I think this PR is ready to be merged.\n", "@meteorcloudy Yes, that's fine. I suspect our existing build rules are not as clean as they could be for this op, but that shouldn't derail what you're trying to do :).\n\nI'll go ahead and merge now.\n", "Nice, thanks! \\o/\n", "This change is causing problems in testing now with BUILD rules. Apparently select() and glob() don't play nicely with each other. \n", "@rohan100jain Can you show me the error message? I wonder why it's not causing problem before.. Users are beginning to try Windows build with Bazel now, reverting this will completely break them.\n", "Even after fixing the bug at  https://github.com/tensorflow/tensorflow/pull/4796/files#diff-15609f78c0cd35bfdc31f9d8bd9b1e91R984 \n\nthere are failures like: \n\nhttps://ci.tensorflow.org/job/tensorflow-cl-sanity/14995/console\n\nI tried various combinations of glob() and select() and none seem to work. \n", "Just want to follow up on this. I managed to build label_image example using the same procedure. Have to fix a bug at https://github.com/bssrdf/tensorflow/commit/58f93bd1d5cf47e7cffa63b59569233e5d2faa34#diff-f6254560279f78a9d74e66dfd2d85977 for it to build on win. But it failed to run due to some file path issue\n\n$ bazel-bin/tensorflow/examples/label_image/label_image\nE C:\\tools\\msys64\\var\\tmp\\Bazel\\s5nfxnhX\\execroot\\tensorflow\\tensorflow\\examples\\label_image\\main.cc:279] Not found: Failed to load compute graph at 'tensorflow/examples/label_image/data/tensorflow_inception_graph.pb'\n\nalthough the file tensorflow_inception_graph.pb is present in that directory.\n", "@rohan100jain Hmm.. This is weird.\nHere's what I tested:\nI reset my branch to c20da148738df38c589fefc6287b64194b0ddbee, which is just before reverting this change.\nAnd I ran `bazel build --nobuild tensorflow/...` on Mac, Linux and Windows. It all passed.\n\nFor `glob()` and `select()`, as long as you don't use `select` as arguments of `glob`, they will work just fine. So I'm not sure why it's failing like that on ci.\n\nCan you give me some instructions to reproduce this error?\n", "I believe there is nothing wrong with this PR, but I am not sure how to get it back. Another PR or can you revert the revert commit? @mrry @rohan100jain \n", "I think the best way forward is another PR. Should be quick to review if it's the same as the last one :).\n", "OK, PR sent. https://github.com/tensorflow/tensorflow/pull/5009\n"]}, {"number": 4795, "title": "Make //tensorflow/cc:cc_ops compile for Android", "body": "It seems that the bazel target //tensorflow/cc:cc_ops is currently not compilable for Android. From what I saw, this is at least because of the missing platform specific headers (e.g. in tensorflow/core/platform/gif.h).\n\nMaking the cc_ops compilable for Android would allow to fully use tensorflow on Android. In particular, I'm trying to build tensorflow for Android with the operations to be able to provide [javacpp-presets](https://github.com/bytedeco/javacpp-presets) which allow an automated generation of complete Java bindings. Therefore they can be used to completely omit the jni/C++ code in Android applications that want to use tensorflow.\n", "comments": ["The Android version of TF uses a different build tree so that we can concentrate on binary size, etc. You'll find that most of cc_ops is provided by //tensorflow/core:android_tensorflow_lib\n"]}, {"number": 4794, "title": "Configure failed on NFS: Device or resource busy", "body": "On Rocks OS (CentOS 6.5) cluster, filesystem is on NFS.\n\nWhen run \"./configure\", it failed at \"ERROR: /home/shiyemin/.cache/bazel/_bazel_shiyemin/df39eb3667102dfbd2ad9a81b93b57e9/server/.nfs0000000000cdec5400000995 (Device or resource busy).\". Then the configuration stoped.\n\nI've seen this error, but never like this. I think maybe \"configure\" did not kill all sub-processes in time.\n\nAnd i found it failed at \"bazel clean --expunge\".\n", "comments": ["@shiyemin see the related issue #3652\n\nYou probably want to get your bazel output directory onto your local filesystem, rather than NFS.\n", "@tatatodd This should work, and i will try it latter(some experiments is running).\nHowever, i'm just curious that why everything works fine on \"v0.11.0 RC0\" but fails on current version.\n\nThanks very much!\n", "@shiyemin If your bazel output directory is on NFS, rather than the local filesystem, the build might sometimes work, but very slowly.  So it's possible that things just happened to work previously.\n\nI.e. it's best to ensure your bazel output directory is on the local filesystem, to avoid these problems to begin with, and to have reasonable build times.\n\nI'm closing this out, but feel free to comment or file a new issue if you run into further problems.  Thanks!\n"]}, {"number": 4793, "title": "Fix types in create_vocabulary (translate model)", "body": "I encountered this bug when going through seq2seq tutorial - https://www.tensorflow.org/versions/r0.11/tutorials/seq2seq/index.html#neural-translation-model\n", "comments": ["@ofilip, thanks for your PR! By analyzing the history of the files in this pull request, we identified @vrv, @keveman and @ilblackdragon to be potential reviewers.\n", "Can one of the admins verify this patch?\n", "@tensorflow-jenkins test this please\n", "This change looks good to me, thanks for doing it! Dear admins, please merge when possible. Thanks!\n"]}]