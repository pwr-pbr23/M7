[{"number": 19794, "title": "Update CONTRIBUTING.md", "body": "Just update clang-tidy to `clang-tidy`.", "comments": []}, {"number": 19793, "title": "Adding the autograph operators dependency to the pip package.", "body": "", "comments": []}, {"number": 19792, "title": "Correcting the number of flop for MatMul", "body": "Cf https://github.com/tensorflow/tensorflow/issues/19746\r\n\r\nGiven two matrices A of shape (m, p) and B of shape (p, q), the number of floating point operations (FLOP) should be mq(2p-1).\r\n\r\nCalculating the number of FLOP using tensorflow's profiler gives 2mqp instead of mq(2p-1).\r\n\r\n\r\n```\r\nimport tensorflow as tf\r\ng = tf.Graph()\r\nwith g.as_default():\r\n    m, p, q = 25, 16, 9\r\n    A = tf.Variable(tf.zeros([m, p]))\r\n    B = tf.Variable(tf.zeros([p, q]))\r\n    C = tf.matmul(A,B)\r\n\r\n    flops = tf.profiler.profile(g, options = tf.profiler.ProfileOptionBuilder.float_operation())\r\n    if flops is not None:\r\n        print('FLOP should be', m * q * (2 * p - 1))\r\n        print('Calculated FLOP', flops.total_float_ops)\r\n```", "comments": ["There is a test that fails:\r\n\r\n```\r\nexec ${PAGER:-/usr/bin/less} \"$0\" || exit 1\r\n-----------------------------------------------------------------------------\r\n/b/s/w/ir/run/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/matmul_op_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/matmul_op_test.py:231: ComplexWarning: Casting complex values to real discards the imaginary part\r\n  m * k).astype(dtype).reshape([m, k])\r\n/b/s/w/ir/run/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/matmul_op_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/matmul_op_test.py:235: ComplexWarning: Casting complex values to real discards the imaginary part\r\n  k * n).astype(dtype).reshape([k, n])\r\nsssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss2018-06-06 17:48:56.892095: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX\r\n.........................ssssssssssss........................ssssssssssssF.....................................................................................................................................\r\n======================================================================\r\nFAIL: testTransposedStatistics (__main__.MatMulStatsTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/b/s/w/ir/run/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/matmul_op_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/matmul_op_test.py\", line 156, in testTransposedStatistics\r\n    self.assertEqual(7200, flops)\r\nAssertionError: 7200 != 6975\r\n----------------------------------------------------------------------\r\nRan 268 tests in 3.490s\r\nFAILED (failures=1, skipped=85)\r\n```", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->", "@drpngx The unit test is wrong, I corrected it. e92ab37a625d486931cdcfa6cbd8bc32f7cd5d3c", "CLAs look good, thanks!\n\n<!-- ok -->", "XLA error: (`binary_ops_test`)\r\n```\r\n2018-06-08 18:22:19.585682: E tensorflow/stream_executor/cuda/cuda_driver.cc:903] failed to allocate 4B (4 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\n```\r\n\r\nMacOS error:\r\n```\r\n==================Model Analysis Report======================\r\nDoc:\r\nscope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\r\nrequested bytes: The memory requested by the operation, accumulatively.\r\noutput bytes: The memory that is output from the operation (not necessarilty allocated by the operation)\r\npeak bytes: The peak amount of memory that the operation is holding at some point.\r\nresidual bytes: The memory not de-allocated after the operation finishes.\r\nProfile:\r\nnode name | requested bytes | peak bytes | residual bytes | output bytes\r\n_TFProfRoot (--/80.00KB, --/80.00KB, --/80.00KB, --/80.00KB)\r\n  mul (80.00KB/80.00KB, 80.00KB/80.00KB, 80.00KB/80.00KB, 80.00KB/80.00KB)\r\n  _retval_mul_0_0 (0B/0B, 0B/0B, 0B/0B, 0B/0B)\r\n======================End of Report==========================\r\nParsing Inputs...\r\n=========================Options=============================\r\n-max_depth                  10000\r\n-min_bytes                  0\r\n-min_peak_bytes             0\r\n-min_residual_bytes         0\r\n-min_output_bytes           0\r\n-min_micros                 1\r\n-min_accelerator_micros     0\r\n-min_cpu_micros             0\r\n-min_params                 0\r\n-min_float_ops              0\r\n-min_occurrence             0\r\n-step                       -1\r\n-order_by                   micros\r\n-account_type_regexes       .*\r\n-start_name_regexes         .*\r\n-trim_name_regexes\r\n-show_name_regexes          .*\r\n-hide_name_regexes\r\n-account_displayed_op_only  true\r\n-select                     bytes,output_bytes,peak_bytes,residual_bytes\r\n-output                     stdout:\r\n==================Model Analysis Report======================\r\nDoc:\r\nscope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\r\nrequested bytes: The memory requested by the operation, accumulatively.\r\noutput bytes: The memory that is output from the operation (not necessarilty allocated by the operation)\r\npeak bytes: The peak amount of memory that the operation is holding at some point.\r\nresidual bytes: The memory not de-allocated after the operation finishes.\r\nProfile:\r\nnode name | requested bytes | peak bytes | residual bytes | output bytes\r\n_TFProfRoot (--/80.00KB, --/80.00KB, --/80.00KB, --/80.00KB)\r\n  mul (80.00KB/80.00KB, 80.00KB/80.00KB, 80.00KB/80.00KB, 80.00KB/80.00KB)\r\n  _retval_mul_0_0 (0B/0B, 0B/0B, 0B/0B, 0B/0B)\r\n======================End of Report==========================\r\n..\r\n======================================================================\r\nFAIL: testComplexCodeView (__main__.PrintModelAnalysisTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/Volumes/BuildData/tmpfs/bazel_output/_bazel_kbuilder/d1b2600cd78e76a92812a06683f5de10/execroot/org_tensorflow/bazel-out/darwin-opt/bin/tensorflow/python/profiler/model_analyzer_test.runfiles/org_tensorflow/tensorflow/python/profiler/model_analyzer_test.py\", line 240, in testComplexCodeView\r\n    self.assertLess(145660, tfprof_node.total_float_ops)\r\nAssertionError: 145660 not less than 140929L\r\n----------------------------------------------------------------------\r\n```\r\n\r\nAre the stats used to make memory projections?", "The failed test looks like it just needs to be updated with the new number; not sure about the OOM error. @hawkinsp might have a better idea?", "@karmel Yes, the values in the unit tests were probably calculated with wrong formulas. In the faulty unit test, an RNN is built and then gradients are calculated. I'm not sure how the RNN are implemented precisely so I cannot manage to get the right number of flops. If anyone would like to contribute by calculating the right number of flops... ", "Nagging Assignee @drpngx: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @drpngx: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@hawkinsp - Any chance you want to help out here? Not sure how the original test value was calculated, but this contribution is waiting on some assistance in fixing the test.", "@karmel The XLA failure looks like a flaky test, I very much doubt it has anything to do with this change.", "Great, thanks. Approving, in that case.", "My pleasure.", "Hm. Not sure why this didn't ever complete. Rerunning tests.", "I would like to push back on this change for the following reasons: \r\n\r\nIt is not clear if the fix is even correct in practice. I mean that is that the flops ARE mq(2p-1). I agree this is the case on the white board but, the following very reasonable implementation:\r\n\r\nsum = 0\r\nfor i=0 to p\r\nsum += a[i] * b[i]\r\n\r\nhas 2mpq FLOPS and not mq(2p-1)\r\n\r\n2. The change is incomplete (i.e. it creates inconsistencies). The flop computation of conv2d, depthwise convolutions and possibly others where not fixed. I think that having slightly inflated **consistent** flop computation is  better than having two formulas giving different results.\r\n\r\n3. This change is negligible when used for diagnostic reasons (unless one is multiplying very small matrices), but brakes some code that actually uses these numbers.\r\n\r\n"]}, {"number": 19791, "title": "r", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": []}, {"number": 19790, "title": "Adding the autograph operators dependency to the pip package.", "body": "", "comments": []}, {"number": 19789, "title": "Removed unneeded file copy that was causing failure in Pi builds", "body": "", "comments": ["Weird failures. I'm going to try again, but I think it might be some disk space issue.\r\n```\r\nERROR: /Volumes/BuildData/tmpfs/bazel_output/_bazel_kbuilder/d1b2600cd78e76a92812a06683f5de10/external/nsync/BUILD:462:1: Couldn't build file external/nsync/_objs/nsync_cpp/external/nsync/internal/cv.o: C++ compilation of rule '@nsync//:nsync_cpp' failed: Unexpected IO error.: xcode-locator failed with code 1.\r\n```", "That failure is a known bazel issue on macos.\r\nLooks like reruns all passed.", "Can you take another look @gunan? I've fixed the merge error that you spotted, thanks!"]}, {"number": 19788, "title": "Cherrypicks2", "body": "", "comments": []}, {"number": 19787, "title": "Branch 199311231", "body": "", "comments": []}, {"number": 19786, "title": "contrib/eagerpython/datasets: Resource naming workaround.", "body": "tensorflow/contrib/eager/python/datasets_test.py was failing on GPU\r\nbecause two tests - testTensorsPlacedOnDevice() and\r\ntestTensorsExplicitPrefetchToDevice() we're creating\r\nFunctionBufferResources with the same shared_name, leading to\r\nunintentional interference.\r\n\r\nThis change will make the tests pass and allow the use of\r\ntf.contrib.eager.Iterator and\r\ntf.data.Dataset.apply(prefetching_ops.prefetch_to_device)\r\nin the same process without interference.\r\n\r\nHowever, a more appropriate fix would probably be to use\r\nanonymous function buffering resources (similar to\r\nAnonymousIteratorHandle) when eager execution is enabled,\r\ndoing away with sharing by name.\r\n\r\nCC @allenlavoie @rohan100jain @mrry @av8ramit ", "comments": []}, {"number": 19785, "title": "R1.8", "body": "Hello everyone,\r\nI want to test the awesome tensorflow on android device. ", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->", "r1.8 has already been merged back into master."]}, {"number": 19784, "title": "Replaced explicit __metaclass__ assignment with @six.add_metaclass", "body": "`__metaclass__ `only works for Python 2. In Python 3 it has no effect since the metaclass syntax is\r\n\r\n    class A(meta=abc.ABCMeta):\r\n        ...\r\n\r\n`@six.add_metaclass` covers both variants.", "comments": ["I'm not familiar enough with that feature. @allenlavoie are you?\r\n\r\nIt begs the question, since we had this for a long time, why we don't test for it, and why no one noticed. If it isn't useful I would vote for removing it altogether, or if it does, then testing for it.", "@superbobry sorry this dropped out of the radar. Could you pull rebase and push again?", "@drpngx done", "I think the ``tensorflow/tools/api/tests:api_compatibility_test`` failure is harmless. The classes do indeed lack the ``__metaclass__`` attribute, because the metaclass [is applied](https://github.com/benjaminp/six/blob/68112f3193c7d4bef5ad86ed1b6ed528edd9093d/six.py#L835-L848) via a decorator, but this is not a breaking change (unless the API users actually relied on the presence of ``__metaclass__``, which is a bad idea anyway as it is not 2/3 compatible. ", "Sorry this dropped off the radar. Testing...", "Failures seem unrelated, testing again.", "Seems to break api_compatibility test. Should the golden files be updated?", "@superbobry could you update the goldens?", "This is a worthwhile change, but yes, please regenerate the golden files to reflect the changes.", "I triggered the tests which should fail and leave a log containing how to update the goldens.", "```\r\nERROR:tensorflow:19 differences found between API and golden.\r\nIssue 1\t: Object tensorflow.linalg.LinearOperatorCirculant2D.__metaclass__ expected but not found (removed).\r\nIssue 2\t: Object tensorflow.linalg.LinearOperatorDiag.__metaclass__ expected but not found (removed).\r\nIssue 3\t: Object tensorflow.linalg.LinearOperatorIdentity.__metaclass__ expected but not found (removed).\r\nIssue 4\t: Object tensorflow.linalg.LinearOperator.__metaclass__ expected but not found (removed).\r\nIssue 5\t: Object tensorflow.linalg.LinearOperatorScaledIdentity.__metaclass__ expected but not found (removed).\r\nIssue 6\t: Object tensorflow.linalg.LinearOperatorCirculant.__metaclass__ expected but not found (removed).\r\nIssue 7\t: Object tensorflow.linalg.LinearOperatorCirculant3D.__metaclass__ expected but not found (removed).\r\nIssue 8\t: 'path: \"tensorflow.data.Dataset\"\\ntf_class {\\n  is_instance: \"<class \\\\\\'tensorf [truncated]... != 'path: \"tensorflow.data.Dataset\"\\ntf_class {\\n  is_instance: \"<class \\\\\\'tensorf [truncated]...\r\n  path: \"tensorflow.data.Dataset\"\r\n  tf_class {\r\n    is_instance: \"<class \\'tensorflow.python.data.ops.dataset_ops.Dataset\\'>\"\r\n    is_instance: \"<type \\'object\\'>\"\r\n    member {\r\n      name: \"output_classes\"\r\n      mtype: \"<class \\'abc.abstractproperty\\'>\"\r\n    }\r\n    member {\r\n      name: \"output_shapes\"\r\n      mtype: \"<class \\'abc.abstractproperty\\'>\"\r\n    }\r\n    member {\r\n      name: \"output_types\"\r\n      mtype: \"<class \\'abc.abstractproperty\\'>\"\r\n    }\r\n    member_method {\r\n      name: \"__init__\"\r\n-     argspec: \"args=[\\'self\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"apply\"\r\n      argspec: \"args=[\\'self\\', \\'transformation_func\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"batch\"\r\n      argspec: \"args=[\\'self\\', \\'batch_size\\', \\'drop_remainder\\'], varargs=None, keywords=None, defaults=[\\'False\\'], \"\r\n    }\r\n    member_method {\r\n      name: \"cache\"\r\n      argspec: \"args=[\\'self\\', \\'filename\\'], varargs=None, keywords=None, defaults=[\\'\\'], \"\r\n    }\r\n    member_method {\r\n      name: \"concatenate\"\r\n      argspec: \"args=[\\'self\\', \\'dataset\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"filter\"\r\n      argspec: \"args=[\\'self\\', \\'predicate\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"flat_map\"\r\n      argspec: \"args=[\\'self\\', \\'map_func\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"from_generator\"\r\n      argspec: \"args=[\\'generator\\', \\'output_types\\', \\'output_shapes\\', \\'args\\'], varargs=None, keywords=None, defaults=[\\'None\\', \\'None\\'], \"\r\n    }\r\n    member_method {\r\n      name: \"from_sparse_tensor_slices\"\r\n      argspec: \"args=[\\'sparse_tensor\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"from_tensor_slices\"\r\n      argspec: \"args=[\\'tensors\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"from_tensors\"\r\n      argspec: \"args=[\\'tensors\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"interleave\"\r\n      argspec: \"args=[\\'self\\', \\'map_func\\', \\'cycle_length\\', \\'block_length\\', \\'num_parallel_calls\\'], varargs=None, keywords=None, defaults=[\\'1\\', \\'None\\'], \"\r\n    }\r\n    member_method {\r\n      name: \"list_files\"\r\n      argspec: \"args=[\\'file_pattern\\', \\'shuffle\\', \\'seed\\'], varargs=None, keywords=None, defaults=[\\'None\\', \\'None\\'], \"\r\n    }\r\n    member_method {\r\n      name: \"make_initializable_iterator\"\r\n      argspec: \"args=[\\'self\\', \\'shared_name\\'], varargs=None, keywords=None, defaults=[\\'None\\'], \"\r\n    }\r\n    member_method {\r\n      name: \"make_one_shot_iterator\"\r\n      argspec: \"args=[\\'self\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"map\"\r\n      argspec: \"args=[\\'self\\', \\'map_func\\', \\'num_parallel_calls\\'], varargs=None, keywords=None, defaults=[\\'None\\'], \"\r\n    }\r\n    member_method {\r\n      name: \"padded_batch\"\r\n      argspec: \"args=[\\'self\\', \\'batch_size\\', \\'padded_shapes\\', \\'padding_values\\', \\'drop_remainder\\'], varargs=None, keywords=None, defaults=[\\'None\\', \\'False\\'], \"\r\n    }\r\n    member_method {\r\n      name: \"prefetch\"\r\n      argspec: \"args=[\\'self\\', \\'buffer_size\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"range\"\r\n      argspec: \"args=[], varargs=args, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"reduce\"\r\n      argspec: \"args=[\\'self\\', \\'initial_state\\', \\'reduce_func\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"repeat\"\r\n      argspec: \"args=[\\'self\\', \\'count\\'], varargs=None, keywords=None, defaults=[\\'None\\'], \"\r\n    }\r\n    member_method {\r\n      name: \"shard\"\r\n      argspec: \"args=[\\'self\\', \\'num_shards\\', \\'index\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"shuffle\"\r\n      argspec: \"args=[\\'self\\', \\'buffer_size\\', \\'seed\\', \\'reshuffle_each_iteration\\'], varargs=None, keywords=None, defaults=[\\'None\\', \\'None\\'], \"\r\n    }\r\n    member_method {\r\n      name: \"skip\"\r\n      argspec: \"args=[\\'self\\', \\'count\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"take\"\r\n      argspec: \"args=[\\'self\\', \\'count\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"window\"\r\n      argspec: \"args=[\\'self\\', \\'size\\', \\'shift\\', \\'stride\\', \\'drop_remainder\\'], varargs=None, keywords=None, defaults=[\\'None\\', \\'1\\', \\'False\\'], \"\r\n    }\r\n    member_method {\r\n      name: \"zip\"\r\n      argspec: \"args=[\\'datasets\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n  }\r\nIssue 9\t: Object tensorflow.linalg.LinearOperatorZeros.__metaclass__ expected but not found (removed).\r\nIssue 10\t: Object tensorflow.data.Dataset.__metaclass__ expected but not found (removed).\r\nIssue 11\t: Object tensorflow.linalg.LinearOperatorLowRankUpdate.__metaclass__ expected but not found (removed).\r\nIssue 12\t: Object tensorflow.data.FixedLengthRecordDataset.__metaclass__ expected but not found (removed).\r\nIssue 13\t: Object tensorflow.linalg.LinearOperatorBlockDiag.__metaclass__ expected but not found (removed).\r\nIssue 14\t: Object tensorflow.linalg.LinearOperatorKronecker.__metaclass__ expected but not found (removed).\r\nIssue 15\t: Object tensorflow.linalg.LinearOperatorFullMatrix.__metaclass__ expected but not found (removed).\r\nIssue 16\t: Object tensorflow.data.TFRecordDataset.__metaclass__ expected but not found (removed).\r\nIssue 17\t: Object tensorflow.linalg.LinearOperatorComposition.__metaclass__ expected but not found (removed).\r\nIssue 18\t: Object tensorflow.data.TextLineDataset.__metaclass__ expected but not found (removed).\r\nIssue 19\t: Object tensorflow.linalg.LinearOperatorLowerTriangular.__metaclass__ expected but not found (removed).\r\n```", "@superbobry could you update the goldens?", "Hm, `api_compatibility_test` passes locally, and I don't seem to have `tf.data.experimental`:\r\n\r\n```bash\r\n$ ls tensorflow/tools/api/golden/v*/tensorflow.data.*                                                                                                          \r\ntensorflow/tools/api/golden/v1/tensorflow.data.-dataset.pbtxt                     tensorflow/tools/api/golden/v2/tensorflow.data.-dataset.pbtxt\r\ntensorflow/tools/api/golden/v1/tensorflow.data.-fixed-length-record-dataset.pbtxt tensorflow/tools/api/golden/v2/tensorflow.data.-fixed-length-record-dataset.pbtxt\r\ntensorflow/tools/api/golden/v1/tensorflow.data.-iterator.pbtxt                    tensorflow/tools/api/golden/v2/tensorflow.data.-iterator.pbtxt\r\ntensorflow/tools/api/golden/v1/tensorflow.data.-t-f-record-dataset.pbtxt          tensorflow/tools/api/golden/v2/tensorflow.data.-t-f-record-dataset.pbtxt\r\ntensorflow/tools/api/golden/v1/tensorflow.data.-text-line-dataset.pbtxt           tensorflow/tools/api/golden/v2/tensorflow.data.-text-line-dataset.pbtxt\r\ntensorflow/tools/api/golden/v1/tensorflow.data.pbtxt\r\n```\r\n\r\nYet it failed here: https://source.cloud.google.com/results/invocations/56ac801e-0f06-4a97-b3cd-aea9d1e5a08a/targets/%2F%2Ftensorflow%2Ftools%2Fapi%2Ftests:api_compatibility_test/log", "Fine for API review.", "@superbobry did you run with py2?", "Yes, I ran on Python 2.7.", "Nagging Assignee @drpngx: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "To be submitted internally."]}, {"number": 19783, "title": "[RFC] Added support for sequence_numeric_column to bucketized_column", "body": "This is a work in progress.\r\n\r\nCaveats:\r\n* the current implementation only works when the bucketized_column is used in the dense context;\r\n* sequence columns are >=2 dimensional, so I had to drop the 1-D constraint from `bucketized_column`.\r\n\r\nCloses #18975", "comments": ["@roumposg could you take a look?", "Nagging Reviewer : It has been 15 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "Will reopen once I get it working.", "Hi, @superbobry \r\nDo you get this feature working now?"]}, {"number": 19782, "title": "Fix for Raspberry Pi build breakage", "body": "https://github.com/tensorflow/tensorflow/pull/17885 was missing a guard for the definition of `double()`, so it was being defined even on non-Android ARM platforms like the Pi.", "comments": []}, {"number": 19781, "title": "Fixing the adamax_test rtol to be more lenient.", "body": "", "comments": []}, {"number": 19780, "title": "Change order of installations.", "body": "", "comments": []}, {"number": 19779, "title": "Minor spelling corrections / clarifications + resolve issue #19778", "body": "I want to clarify something about using global step with tf.contrib.model_pruning, which I think is not clearly explained (and lead to me not seeing my mistake for 3 weeks). Also, address the illegal summary names from issue #19778.", "comments": ["> I'm pretty novice to designing tests; how would you go about doing this? I looked at the tests in pruning_test.py, but didn't get very far.\r\n\r\nDo you have a short piece of code to reproduce #19778? Post is as a comment and I'll help you turn it into a test.", "The following code will give you #19778:\r\n\r\nEdit: thanks a lot for helping me out/teaching me how to make a test!!\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.model_pruning as pruning\r\n\r\ntf.reset_default_graph()\r\n\r\n# Global step.\r\nglobal_step = tf.train.get_or_create_global_step()\r\n\r\n# Input data.\r\ndata = tf.get_variable('data', shape=[1, 10, 10, 1], initializer=tf.random_normal_initializer())\r\n\r\n# Single conv layer with pruning mask.\r\noutputs = 1\r\nkernel = [2, 2]\r\nconv = pruning.masked_conv2d(data, outputs, kernel)\r\n\r\nwith tf.Session() as sess:\r\n    \r\n    # Pruning hyperparameters.\r\n    pruning_hparams = pruning.get_pruning_hparams().parse(\"\")\r\n\r\n    # Pruning object.\r\n    pruning_obj = pruning.Pruning(pruning_hparams, global_step=global_step)\r\n    \r\n    # Pruning summaries.\r\n    pruning_obj.add_pruning_summaries()\r\n    \r\n    # Summary.\r\n    summary_writer = tf.summary.FileWriter('.', graph=sess.graph)\r\n```"]}, {"number": 19778, "title": "tensorflow.contrib.model_pruning: using illegal summary names", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.8.0-0-g93bc2e2072\r\n- **Python version**: 3.6.5\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\n\r\nCalling [`add_pruning_summaries()`](https://github.com/tensorflow/tensorflow/blob/83543deedb68fef61ea7e709de3f462a1edd13ce/tensorflow/contrib/model_pruning/python/pruning.py#L509) leads to illegal summary names for the masks that contain colons, due to `tf.Variable.name` being used instead of `tf.Variable.op.name` (as is done for the [thresholds](https://github.com/tensorflow/tensorflow/blob/83543deedb68fef61ea7e709de3f462a1edd13ce/tensorflow/contrib/model_pruning/python/pruning.py#L524)). This leads to TensorFlow printing the following info:\r\n\r\n> INFO:tensorflow:Summary name model/Conv/mask:0/sparsity is illegal; using model/Conv/mask_0/sparsity instead.\r\n\r\nWhich I think is unnecessary. I will create a PR to let the summary name for masks make use of `tf.Variable.op.name` as well.\r\n", "comments": ["Nagging Assignee @shivaniag: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Working on PR, see #19779", "Nagging Assignee @shivaniag: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Fixed. See PR"]}, {"number": 19777, "title": "how to use map_fn to output different shaped tensors", "body": "The result of my processed unpacked tensors may have different shape, but map_fn can only output consisstent shaped tensors, how to achieve that so the output can list of different sized tensors?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 44 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 19776, "title": "einsum contraction order (is undocumented)", "body": "### Describe the problem\r\nThe documentation for `tf.einsum` does not specify the order of the contraction. However, for contractions with three and more tensors, the contraction order is crucial as it determines the runtime complexity. The only thing one finds in the documentation is the following:\r\n\r\n> This function behaves like `numpy.einsum` [...]\r\n\r\nThe `numpy.einsum` function has an additional parameter `optimize` and is able to peform a greedy optimisation for the contraction order. As far as I understood the tensorflow code, `tf.einsum` simply contracts tensors from left to right.\r\nWould it be possible to adopt the optimisation code from numpy for tensorflow? If not, at least the documentation should indicate the contraction order. Thank you!", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Dear @tensorflowbutler, the issue template is not relevant for this issue as this is a documentation issue.", "We currently don't have anybody working on this. It would be great if you could help us by working on this and submitting a PR. Let us know if you need further clarification. Thanks!\r\n", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you.", "Is there a formal dependence of tensorflow on numpy (and if yes, which version)? If I could use numpy 1.14, the numpy function `einsum_path` [1] could be used to implement this.\r\n\r\n[1] https://docs.scipy.org/doc/numpy/reference/generated/numpy.einsum_path.html", "Closing this issue , Please refer this link for update https://github.com/tensorflow/tensorflow/pull/23921#issuecomment-518861095 . Thank you. "]}, {"number": 19775, "title": "Tensorflow python version incompatibility", "body": "Hey,\r\n\r\nI use `inceptionv3` to classify various images. I experienced that images are classified with a different probabillity on different versions of python. I set up three environments:\r\n1. Tensorflow (b'v1.8.0-0-g93bc2e2072' 1.8.0) with python 3.6.2 with anaconda (no gpu support) (Windows 10)\r\n2. Tensorflow (b'v1.8.0-0-g93bc2e2072' 1.8.0) with python 2.7.12 installed via plain pip. (no GPU) (Ubuntu 16.04)\r\n3. Tensorflow (b'v1.8.0-0-g93bc2e2072' 1.8.0) with python 3.5.2 installed via plain pip. (no GPU) (Ubuntu 16.04)\r\n\r\nEnvironment 1 and 3 give the same results. Using python2 gives the lower probabilities on the correct class than given by the other two setups.\r\n\r\nHeres a little example I just created to outline the error and show how the classification performed:\r\n```python\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nfrom PIL import Image\r\nimport json, os\r\n\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.slim as slim\r\nfrom tensorflow.contrib.slim.nets import inception\r\n\r\nFLAGS = tf.flags.FLAGS\r\ntf.flags.DEFINE_string('image_name', 'cropped_panda.jpg', 'Image name with file ending.')\r\ntf.flags.DEFINE_integer('top_k', 5, 'Top k predictions to print out.')\r\ntf.flags.DEFINE_integer('image_height', 299, 'The image height for inception_v3 model.')\r\ntf.flags.DEFINE_integer('image_width', 299, 'The image width for inception_v3 model.')\r\ntf.flags.DEFINE_integer('image_channels', 3, 'The number of channels of for inception_v3 model.')\r\ntf.flags.DEFINE_integer('image_N_classes', 1000, 'The number of classes in the inception_v3 model.')\r\ntf.flags.DEFINE_float('weight_decay', 0.0, 'The weight decay applied to each edge/weight at each update step.')\r\n\r\n\r\ndef load_images(batch_shape, pathPrefix='../../images/'):\r\n    num_images = batch_shape[0]\r\n    image_path = os.path.join(pathPrefix, FLAGS.image_name)\r\n    image = Image.open(image_path)\r\n\r\n    # crop\r\n    wide = image.width > image.height\r\n    new_w = FLAGS.image_width if not wide else int(image.width * FLAGS.image_width / image.height)\r\n    new_h = FLAGS.image_height if wide else int(image.height * FLAGS.image_height / image.width)\r\n\r\n    images = np.zeros(batch_shape)\r\n    for idx in range(num_images):\r\n        image = image.resize((new_w, new_h)).crop((0, 0, FLAGS.image_width, FLAGS.image_height))\r\n        image = (np.asarray(image) / 255.0).astype(np.float32)\r\n        images[idx, :, :, :] = image\r\n    return images\r\n\r\n\r\ndef get_logits(image_placeholder):\r\n    preprocessed = tf.multiply(tf.subtract(image_placeholder, 0.5), 2.0)\r\n    arg_scope = inception.inception_v3_arg_scope(weight_decay=FLAGS.weight_decay)\r\n    with slim.arg_scope(arg_scope):\r\n        logits, _ = inception.inception_v3(\r\n            preprocessed, FLAGS.image_N_classes + 1, is_training=False, reuse=False)\r\n        logits = logits[:, 1:]\r\n        probs = tf.nn.softmax(logits)\r\n    return logits, probs\r\n\r\n\r\ndef get_inception_session(sess=None, pathToInception='../../'):\r\n    saver = tf.train.Saver()\r\n    saver.restore(sess, os.path.join(pathToInception, 'inception_v3.ckpt'))\r\n    return sess\r\n\r\n\r\ndef main(argsunused):\r\n    images = load_images((1, FLAGS.image_height, FLAGS.image_width, FLAGS.image_channels))\r\n    image_placeholder = tf.placeholder(tf.float32, (1, FLAGS.image_height, FLAGS.image_width, FLAGS.image_channels))\r\n    logits, preds = get_logits(image_placeholder)\r\n\r\n    with tf.Session() as sess:\r\n        sess = get_inception_session(sess)\r\n        top_k = tf.nn.top_k(preds, k=FLAGS.top_k)\r\n        values, indices = sess.run([top_k.values, top_k.indices], feed_dict={image_placeholder: images})\r\n        for (index, value) in zip(indices[0], values[0]):\r\n            print(\"Class %d with prob: %f\" % (index, value))\r\n\r\n\r\nif __name__ == '__main__':\r\n    tf.app.run()\r\n```\r\nIf I misssused something here, please be so kind and explain my mistake:)\r\n\r\nRegards\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes. Uses the elements shown in the example.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: See above (windows and ubuntu 16.04)\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: b'v1.8.0-0-g93bc2e2072' 1.8.0\r\n- **Python version**: 2.7.12, 3.5.2, 3.6.2\r\n- **Bazel version (if compiling from source)**: -\r\n- **GCC/Compiler version (if compiling from source)**: -\r\n- **CUDA/cuDNN version**: -\r\n- **GPU model and memory**: -\r\n- **Exact command to reproduce**: -", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "@reedwm thanks for the response. Just added the missing fields.", "@icebreaker2, what probabilities do you get? Do you experience this issue when using Imagenet on the pretrained models [here](https://github.com/tensorflow/models/tree/master/research/slim)?\r\n\r\n/CC @sguada any ideas why inception would perform differently on Python 2 vs 3?", "In the following I added the top5 results of the common giant panda example with inceptionv3 and inceptionv4 (with inceptionv4 the differences are fewer).\r\n\r\nWith Python 2 and inceptionv3 I get (panda example, top5):\r\n```shell\r\nClass 388 with prob: 0.840522\r\nClass 384 with prob: 0.008873\r\nClass 812 with prob: 0.005004\r\nClass 387 with prob: 0.003787\r\nClass 995 with prob: 0.001669\r\n```\r\n\r\nWith Python 3 and inceptionv3 I get (panda example, top5):\r\n```shell\r\nClass 388 with prob: 0.816696\r\nClass 384 with prob: 0.010089\r\nClass 812 with prob: 0.004649\r\nClass 387 with prob: 0.002653\r\nClass 995 with prob: 0.001971\r\n```\r\n\r\nWith Python 2 and inceptionv4 I get (panda example, top5):\r\n```shell\r\nClass 388 with prob: 0.891811\r\nClass 387 with prob: 0.004732\r\nClass 384 with prob: 0.002913\r\nClass 378 with prob: 0.000739\r\nClass 375 with prob: 0.000680\r\n```\r\n\r\nWith Python 3 and inceptionv4 I get (panda example, top5):\r\n```shell\r\nClass 388 with prob: 0.897901\r\nClass 387 with prob: 0.002995\r\nClass 384 with prob: 0.002632\r\nClass 375 with prob: 0.000646\r\nClass 378 with prob: 0.000644\r\n```", "Nagging Assignee @sguada: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @sguada: It has been 30 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @sguada: It has been 45 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @sguada: It has been 60 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I don't know why it would perform differently.", "/CC @gunan, any ideas why Python 2 and Python 3 would have numerical differences, leading to different results on Inception v3?", "Python 2 and python 3 have quite a bit of differences. Here is a small number of them:\r\nhttps://www.geeksforgeeks.org/important-differences-between-python-2-x-and-python-3-x-with-examples/\r\n\r\nSo it can really be as simple as division operator behaving differently, or maybe the two different python distros rounding numbers differently, or random number generators behaving differently. There are a lot of possibilities.", "Thanks for the info! I'm surprised there is a difference in accuracy between Python 2 and 3, because these differences should not affect the result of a TensorFlow graph. But, there is a difference, so marking as contributions welcome if anyone wants to investigate this.", "Latest tf versions does not support 2 , please check here for latest installation requirements https://www.tensorflow.org/install/pip . Thank you"]}, {"number": 19773, "title": "I have a problem with a script python that launch a choregraphe behavior", "body": "\r\nI have this script write in python 2.7:\r\nfrom naoqi import ALProxy\r\n\r\ntts = ALProxy(\"ALBehaviorManager\", \"127.0.0.1\" , 9559)\r\ntts.runBehavior(\"<NomeBehavior>\");\r\n\r\nwhen launch this script, however, i have this result:\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\franc\\eclipse-workspace\\Connection\\src\\connection.py\", line 7, in <module>\r\n    from naoqi import ALProxy\r\n  File \"C:\\Program Files (x86)\\Aldebaran\\Choregraphe 1.14.5.1\\lib\\naoqi.py\", line 14, in <module>\r\n    import _inaoqi_d as _inaoqi\r\nImportError: DLL load failed: Impossibile trovare il modulo specificato.\r\nCould not find _inaoqi, trying with _inaoqi_d\r\n\r\n\r\nsomeone knows how to solve it? \r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "I apologize, but I am having a hard time understanding what the problem is, where the problem is, and what version it affects. Please resubmit and pay attention to the issue template (https://github.com/tensorflow/tensorflow/issues/new). Please provide all the information it asks. Thank you.\r\n"]}, {"number": 19772, "title": "I have a problem with a python script that launch a choregraphe behavior", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": []}, {"number": 19770, "title": "Tensorflow 1.8.0 Java tests fail with error \"Building Java resource jar failed (Segmentation fault): singlejar failed\"", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04 s390x\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: v1.8.0\r\n- **Python version**: Python 2.7.12\r\n- **Bazel version (if compiling from source)**: 0.12.0\r\n- **GCC/Compiler version (if compiling from source)**: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609\r\n- **CUDA/cuDNN version**: NA\r\n- **GPU model and memory**: NA\r\n- **JDK Version**:\r\n```\r\ntest@f6c9f944adde:~/tensorflow$ java -version\r\nopenjdk version \"1.8.0_171\"\r\nOpenJDK Runtime Environment (build 1.8.0_171-8u171-b11-0ubuntu0.16.04.1-b11)\r\nOpenJDK 64-Bit Zero VM (build 25.171-b11, interpreted mode)\r\n```\r\n- **Exact command to reproduce**:\r\n```\r\ntest@f6c9f944adde:~/tensorflow$ ./configure  \r\n  Extracting Bazel installation...\r\n  You have bazel 0.12.0- (@non-git) installed.\r\n  Please specify the location of python. [Default is /usr/bin/python]:\r\n\r\n\r\n  Found possible Python library paths:\r\n    /usr/local/lib/python2.7/dist-packages\r\n    /usr/lib/python2.7/dist-packages\r\n  Please input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]\r\n\r\n  Do you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: Y\r\n  jemalloc as malloc support will be enabled for TensorFlow.\r\n\r\n  Do you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: N\r\n  No Google Cloud Platform support will be enabled for TensorFlow.\r\n\r\n  Do you wish to build TensorFlow with Hadoop File System support? [Y/n]: N\r\n  No Hadoop File System support will be enabled for TensorFlow.\r\n\r\n  Do you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: N\r\n  No Amazon S3 File System support will be enabled for TensorFlow.\r\n\r\n  Do you wish to build TensorFlow with Apache Kafka Platform support? [Y/n]: N\r\n  No Apache Kafka Platform support will be enabled for TensorFlow.\r\n\r\n  Do you wish to build TensorFlow with XLA JIT support? [y/N]: N\r\n  No XLA JIT support will be enabled for TensorFlow.\r\n\r\n  Do you wish to build TensorFlow with GDR support? [y/N]: N\r\n  No GDR support will be enabled for TensorFlow.\r\n\r\n  Do you wish to build TensorFlow with VERBS support? [y/N]: N\r\n  No VERBS support will be enabled for TensorFlow.\r\n\r\n  Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: N\r\n  No OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\n  Do you wish to build TensorFlow with CUDA support? [y/N]: N\r\n  No CUDA support will be enabled for TensorFlow.\r\n\r\n  Do you wish to download a fresh release of clang? (Experimental) [y/N]: N\r\n  Clang will not be downloaded.\r\n\r\n  Do you wish to build TensorFlow with MPI support? [y/N]: N\r\n  No MPI support will be enabled for TensorFlow.\r\n\r\n  Please specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]:\r\n\r\n\r\n  Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: N\r\n  Not configuring the WORKSPACE for Android builds.\r\n\r\n  Preconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See tools/bazel.rc for more details.\r\n        --config=mkl            # Build with MKL support.\r\n        --config=monolithic     # Config for mostly static monolithic build.\r\n  Configuration finished\r\n```\r\n\r\nBuild tensorflow using \r\n```\r\nbazel build -c opt //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\nExecute the tests \r\n```\r\ntest@f6c9f944adde:~/tensorflow$ bazel --host_jvm_args=\"-Xms512m\" --host_jvm_args=\"-Xmx1024m\" test --test_timeout 300,450,1200,3600 --build_tests_only -- //tensorflow/java/...\r\nWARNING: /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/protobuf_archive/WORKSPACE:1: Workspace name in /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/protobuf_archive/WORKSPACE (@com_google_protobuf) does not match the name given in the repository's definition (@protobuf_archive); this will cause a build error in future versions\r\nINFO: Analysed 13 targets (3 packages loaded).\r\nINFO: Found 13 test targets...\r\nSlow read: a 17792073-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/local_jdk/lib/ct.sym took 279596ms.\r\nSlow read: a 660545-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/local_jdk/jre/lib/jsse.jar took 8904ms.\r\nSlow read: a 65000897-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/local_jdk/jre/lib/rt.jar took 1050262ms.\r\nSlow read: a 407746-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/local_jdk/lib/jconsole.jar took 7045ms.\r\nSlow read: a 2033434-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/local_jdk/jre/lib/ext/nashorn.jar took 36359ms.\r\nSlow read: a 3861228-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/local_jdk/jre/lib/ext/cldrdata.jar took 69984ms.\r\nSlow read: a 7615736-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/local_jdk/jre/lib/s390x/server/libjvm.so took 139747ms.\r\nSlow read: a 923944-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/local_jdk/jre/lib/s390x/libmlib_image.so took 18312ms.\r\nSlow read: a 1178929-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/local_jdk/jre/lib/ext/localedata.jar took 20124ms.\r\nSlow read: a 3135616-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/local_jdk/jre/lib/charsets.jar took 54969ms.\r\nSlow read: a 3509496-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/local_jdk/jre/lib/resources.jar took 52916ms.\r\nSlow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Sstring_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 295367ms.\r\nSlow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Suser_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 295164ms.\r\nSlow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Sno_Uop_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 219115ms.\r\nSlow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Sarray_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 210040ms.\r\nSlow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Sstate_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 228118ms.\r\nSlow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Smath_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 211957ms.\r\nSlow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Scandidate_Usampling_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 209071ms.\r\nSlow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Snn_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 220945ms.\r\nSlow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Scontrol_Uflow_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 204621ms.\r\nSlow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Slogging_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 215215ms.\r\nSlow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Straining_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 202976ms.\r\nSlow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Sio_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 197636ms.\r\nSlow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Srandom_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 157546ms.\r\nSlow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Ssparse_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 185855ms.\r\nSlow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Sdata_Uflow_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 194397ms.\r\nSlow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Sparsing_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 194407ms.\r\nSlow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Slinalg_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 192693ms.\r\nSlow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Simage_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 171085ms.\r\nSlow read: a 807616-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/local_jdk/jre/lib/s390x/libawt.so took 10783ms.\r\nSlow read: a 18318086-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/local_jdk/lib/tools.jar took 189336ms.\r\nSlow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/s390x-opt/bin/_solib_piii/_U_S_Stensorflow_Sjava_Clibtensorflow_Ujni.so___Utensorflow/libtensorflow_framework.so took 150482ms.\r\nSlow read: a 6885456-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/bazel_tools/third_party/java/jdk/langtools/javac-9+181-r4173-1.jar took 52658ms.\r\nSlow read: a 9200450-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/bazel_tools/tools/jdk/turbine_deploy.jar took 71876ms.\r\nSlow read: a 37198458-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath-impl.jar took 426726ms.\r\nSlow read: a 16268324-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath.jar took 190506ms.\r\nSlow read: a 11497298-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/bazel_tools/tools/jdk/JavaBuilder_deploy.jar took 141703ms.\r\nERROR: /home/test/tensorflow/tensorflow/java/BUILD:54:1: Building Java resource jar failed (Segmentation fault): singlejar failed: error executing command external/bazel_tools/tools/jdk/singlejar/singlejar --normalize --dont_change_compression --exclude_build_data --output bazel-out/host/bin/tensorflow/java/libprocessor_library.jar --sources ... (remaining 3 argument(s) skipped)\r\nSlow read: a 49095408-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/s390x-opt/bin/tensorflow/java/libtensorflow_jni.so took 521931ms.\r\nSlow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/s390x-opt/bin/_solib_piii/_U_S_Stensorflow_Sjava_Csource_Uwriter_Utest___Utensorflow/libtensorflow_framework.so took 230369ms.\r\nINFO: Elapsed time: 7966.630s, Critical Path: 2784.06s\r\nFAILED: Build did NOT complete successfully\r\n//tensorflow/java:ConstantTest                                        NO STATUS\r\n//tensorflow/java:OperandsTest                                        NO STATUS\r\n//tensorflow/java:OperationBuilderTest                                NO STATUS\r\n//tensorflow/java:OperationTest                                       NO STATUS\r\n//tensorflow/java:PrimitiveOpTest                                     NO STATUS\r\n//tensorflow/java:SavedModelBundleTest                                NO STATUS\r\n//tensorflow/java:ScopeTest                                           NO STATUS\r\n//tensorflow/java:SessionTest                                         NO STATUS\r\n//tensorflow/java:ShapeTest                                           NO STATUS\r\n//tensorflow/java:TensorFlowTest                                      NO STATUS\r\n//tensorflow/java:TensorTest                                          NO STATUS\r\n//tensorflow/java:source_writer_test                                  NO STATUS\r\n\r\nExecuted 0 out of 13 tests: 1 fails to build and 12 were skipped.\r\n```\r\n\r\n### Describe the problem\r\nI have successfully compiled tensorflow from source using same configure procedure as above and built it with the following command:\r\n```\r\nbazel build -c opt //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\nAfter that I tried executing the tests which failed with the error as stated above. I tried running just a single test from the Java module which produced the same error as above with the following error:\r\n```\r\nERROR: /home/test/tensorflow/tensorflow/java/BUILD:54:1: Building Java resource jar failed (Segmentation fault): singlejar failed: error executing command external/bazel_tools/tools/jdk/singlejar/singlejar --normalize --dont_change_compression --exclude_build_data --output bazel-out/host/bin/tensorflow/java/libprocessor_library.jar --sources ... (remaining 3 argument(s) skipped)\r\n```", "comments": ["@jart could you please help with this.", "@gunan Could you please guide us on how to resolve this issue?\r\n\r\n", "@asimshankar have you seen this error before?\r\n@Nayana-ibm do you have any more detailed information or logs?", "Hi Gunan, \r\n\r\nBelow are the logs for building/testing java module for tensorflow v1.8.0 on s390x.\r\n\r\nBazel build:\r\n```\r\ntest@f6c9f944adde:~/tensorflow$ bazel build -c opt //tensorflow/java/...\r\nWARNING: /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/protobuf_archive/WORKSPACE:1: Workspace name in /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/protobuf_archive/WORKSPACE (@com_google_protobuf) does not match the name given in the repository's definition (@protobuf_archive); this will cause a build error in future versions\r\nINFO: Analysed 54 targets (0 packages loaded).\r\nINFO: Found 54 targets...\r\nERROR: /home/test/tensorflow/tensorflow/java/BUILD:54:1: Building Java resource jar failed (Segmentation fault): singlejar failed: error executing command external/bazel_tools/tools/jdk/singlejar/singlejar --normalize --dont_change_compression --exclude_build_data --output bazel-out/host/bin/tensorflow/java/libprocessor_library.jar --sources ... (remaining 3 argument(s) skipped)\r\nINFO: Elapsed time: 2.837s, Critical Path: 0.67s\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nBazel test:\r\n```\r\ntest@f6c9f944adde:~/tensorflow$ bazel test -c opt //tensorflow/java/...\r\n....................................................................................................\r\nWARNING: /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/protobuf_archive/WORKSPACE:1: Workspace name in /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/protobuf_archive/WORKSPACE (@com_google_protobuf) does not match the name given in the repository's definition (@protobuf_archive); this will cause a build error in future versions\r\nINFO: Analysed 54 targets (74 packages loaded).\r\nINFO: Found 41 targets and 13 test targets...\r\nINFO: From Executing genrule //tensorflow/java:java_op_gen_sources:\r\n2018-08-10 04:09:38.204968: I tensorflow/java/src/gen/cc/op_generator.cc:61] Generating Java wrappers for 'array' operations\r\n2018-08-10 04:09:38.216246: I tensorflow/java/src/gen/cc/op_generator.cc:61] Generating Java wrappers for 'candidate_sampling' operations\r\n2018-08-10 04:09:38.227087: I tensorflow/java/src/gen/cc/op_generator.cc:61] Generating Java wrappers for 'control_flow' operations\r\n2018-08-10 04:09:38.238592: I tensorflow/java/src/gen/cc/op_generator.cc:61] Generating Java wrappers for 'data_flow' operations\r\n2018-08-10 04:09:38.250242: I tensorflow/java/src/gen/cc/op_generator.cc:61] Generating Java wrappers for 'image' operations\r\n2018-08-10 04:09:38.260534: I tensorflow/java/src/gen/cc/op_generator.cc:61] Generating Java wrappers for 'io' operations\r\n2018-08-10 04:09:38.276852: I tensorflow/java/src/gen/cc/op_generator.cc:61] Generating Java wrappers for 'linalg' operations\r\n2018-08-10 04:09:38.292713: I tensorflow/java/src/gen/cc/op_generator.cc:61] Generating Java wrappers for 'logging' operations\r\n2018-08-10 04:09:38.307859: I tensorflow/java/src/gen/cc/op_generator.cc:61] Generating Java wrappers for 'math' operations\r\n2018-08-10 04:09:38.321356: I tensorflow/java/src/gen/cc/op_generator.cc:61] Generating Java wrappers for 'nn' operations\r\n2018-08-10 04:09:38.334795: I tensorflow/java/src/gen/cc/op_generator.cc:61] Generating Java wrappers for 'no' operations\r\n2018-08-10 04:09:38.347530: I tensorflow/java/src/gen/cc/op_generator.cc:61] Generating Java wrappers for 'parsing' operations\r\n2018-08-10 04:09:38.366438: I tensorflow/java/src/gen/cc/op_generator.cc:61] Generating Java wrappers for 'random' operations\r\n2018-08-10 04:09:38.375990: I tensorflow/java/src/gen/cc/op_generator.cc:61] Generating Java wrappers for 'sparse' operations\r\n2018-08-10 04:09:38.391752: I tensorflow/java/src/gen/cc/op_generator.cc:61] Generating Java wrappers for 'state' operations\r\n2018-08-10 04:09:38.401685: I tensorflow/java/src/gen/cc/op_generator.cc:61] Generating Java wrappers for 'string' operations\r\n2018-08-10 04:09:38.416854: I tensorflow/java/src/gen/cc/op_generator.cc:61] Generating Java wrappers for 'training' operations\r\n2018-08-10 04:09:38.437646: I tensorflow/java/src/gen/cc/op_generator.cc:61] Generating Java wrappers for 'user' operations\r\nERROR: /home/test/tensorflow/tensorflow/java/BUILD:54:1: Building Java resource jar failed (Segmentation fault): singlejar failed: error executing command external/bazel_tools/tools/jdk/singlejar/singlejar --normalize --dont_change_compression --exclude_build_data --output bazel-out/host/bin/tensorflow/java/libprocessor_library.jar --sources ... (remaining 3 argument(s) skipped)\r\nINFO: Elapsed time: 196.828s, Critical Path: 33.94s\r\nFAILED: Build did NOT complete successfully\r\n//tensorflow/java:ConstantTest                                        NO STATUS\r\n//tensorflow/java:GraphTest                                           NO STATUS\r\n//tensorflow/java:OperandsTest                                        NO STATUS\r\n//tensorflow/java:OperationBuilderTest                                NO STATUS\r\n//tensorflow/java:OperationTest                                       NO STATUS\r\n//tensorflow/java:PrimitiveOpTest                                     NO STATUS\r\n//tensorflow/java:SavedModelBundleTest                                NO STATUS\r\n//tensorflow/java:ScopeTest                                           NO STATUS\r\n//tensorflow/java:SessionTest                                         NO STATUS\r\n//tensorflow/java:ShapeTest                                           NO STATUS\r\n//tensorflow/java:TensorFlowTest                                      NO STATUS\r\n//tensorflow/java:TensorTest                                          NO STATUS\r\n//tensorflow/java:source_writer_test                                  NO STATUS\r\n\r\nExecuted 0 out of 13 tests: 13 were skipped.\r\n```\r\n\r\nJava version:\r\n```\r\ntest@f6c9f944adde:~/tensorflow$ java -version\r\nopenjdk version \"1.8.0_162\"\r\nOpenJDK Runtime Environment (build 1.8.0_162-b12)\r\nEclipse OpenJ9 VM (build openj9-0.8.0, JRE 1.8.0 Linux s390x-64 Compressed References 20180315_97 (JIT enabled, AOT enabled)\r\nOpenJ9   - e24e8aa9\r\nOMR      - 3e8296b4\r\nJCL      - ee1e77df1d based on jdk8u162-b12)\r\n```\r\n\r\nBazel version:\r\n```\r\ntest@f6c9f944adde:~/tensorflow$ bazel version\r\nBuild label: 0.12.0- (@non-git)\r\nBuild target: bazel-out/s390x-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Sat Apr 23 09:09:27 +50355 (1526892800967)\r\nBuild timestamp: 1526892800967\r\nBuild timestamp as int: 1526892800967\r\n```", "I have never seen this error before. \r\n@asimshankar any ideas?\r\n@meteorcloudy who can help us with potential java build issues with bazel?", "/cc @cushon Have you ever seen similar error before?", "@meteorcloudy no, it doesn't look familiar. Is there a minimal repro?", "I haven't seen this before.\r\nCould there be an endianness assumption in the [singlejar tool](https://github.com/bazelbuild/bazel/tree/master/src/java_tools/singlejar) that is being violated on the s390x?", "@duane-ibm I will take this over.\r\nIs this still reproducible?", "I think this is a bazel issue.\r\nI saw this happen when building bazel itself, too.\r\n```\r\nSlow read: a 2033434-byte read from /tmp/bazel_3VU1HM86/out/external/local_jdk/jre/lib/ext/nashorn.jar took 6299 ms.\r\nSlow read: a 3146698-byte read from /home/gunan/workspace/bazel/third_party/java/jdk/langtools/jdk_compiler.jar took 9439 ms.\r\nSlow read: a 2055100-byte read from /home/gunan/workspace/bazel/third_party/error_prone/error_prone_core-2.3.2-SNAPSHOT.jar took 6091 ms.\r\nSlow read: a 4394459-byte read from /home/gunan/workspace/bazel/third_party/java/jdk/langtools/javac-9+181-r4173-1.srcjar took 13312 ms.\r\nSlow read: a 6885456-byte read from /home/gunan/workspace/bazel/third_party/java/jdk/langtools/javac-9+181-r4173-1.jar took 20646 ms.\r\nSlow read: a 18318385-byte read from /tmp/bazel_3VU1HM86/out/external/local_jdk/lib/tools.jar took 55635 ms.\r\nSlow read: a 17792882-byte read from /tmp/bazel_3VU1HM86/out/external/local_jdk/lib/ct.sym took 53152 ms.\r\nSlow read: a 3509547-byte read from /tmp/bazel_3VU1HM86/out/external/embedded_jdk/jre/lib/resources.jar took 11153 ms.\r\nSlow read: a 3509547-byte read from /tmp/bazel_3VU1HM86/out/external/local_jdk/jre/lib/resources.jar took 10420 ms.\r\nSlow read: a 65012836-byte read from /tmp/bazel_3VU1HM86/out/external/local_jdk/jre/lib/rt.jar took 205540 ms.\r\nSlow read: a 2734339-byte read from /home/gunan/workspace/bazel/third_party/guava/guava-25.1-jre.jar took 8159 ms.\r\nSlow read: a 17792882-byte read from /tmp/bazel_3VU1HM86/out/external/embedded_jdk/lib/ct.sym took 55194 ms.\r\nSlow read: a 2657505-byte read from /home/gunan/workspace/bazel/third_party/jgit/org.eclipse.jgit-4.10.0.201712302008-r.jar took 8095 ms.\r\nSlow read: a 3780056-byte read from /home/gunan/workspace/bazel/third_party/netty/netty-all-4.1.17.Final.jar took 11446 ms.\r\nSlow read: a 3135616-byte read from /tmp/bazel_3VU1HM86/out/external/local_jdk/jre/lib/charsets.jar took 9473 ms.\r\nSlow read: a 3861228-byte read from /tmp/bazel_3VU1HM86/out/external/local_jdk/jre/lib/ext/cldrdata.jar took 11402 ms.\r\nSlow read: a 7632160-byte read from /tmp/bazel_3VU1HM86/out/external/local_jdk/jre/lib/s390x/server/libjvm.so took 24542 ms.\r\nSlow read: a 3135616-byte read from /tmp/bazel_3VU1HM86/out/external/embedded_jdk/jre/lib/charsets.jar took 9488 ms.\r\n```\r\n\r\n@meteorcloudy Could you loop in someone who is knowledgeable about bazel with java?\r\n\r\n", "@cushon Have you ever seem errors like this?", "@meteorcloudy I haven't seen either segmentation faults in singlejar or 'slow read' warnings for those files. Is there a repro?", "@duane-ibm Is it possible to create a minimal repo for this bug?", "@meteorcloudy @cushon There are two different issues here. \r\n1.  Slow read warnings\r\n2. Building Java resource jar failed (Segmentation fault): singlejar failed\r\n\r\nThe slow read issue is seen when using `Openjdk`,  which is currently being looked at by @gunan \r\n@duane-ibm Could you comment on singlejar issue? \r\n", "@meteorcloudy Building tensorflow works fine using `bazel build -c opt //tensorflow/tools/pip_package:build_pip_package`\r\nThe `singlejar` issue is seen when running the tests `bazel test -c opt //tensorflow/java/...`", "@duane-ibm I couldn't reproduce the singlejar failure with Bazel 0.17.1, can you try upgrading Bazel?", "@meteorcloudy FYI this issue is happening on IBM s390x machines (different CPU architecture, big endian)\r\nI was hoping this may be something in java that a java expert can help with.", "@duane-ibm I had much better results with using bazel on ubuntu 18.04 (bionic) and openJDK 1.11\r\nCould you try that setup?", "@gunan Thanks. Any specific version of bazel? Or 0.12.0 is fine?", "I used the latest version of bazel (0.17.1).\r\nWith openjdk 11, I was able to build it from sources in 15 minutes.", "Yes bazel 0.17.1 built with openjdk11 worked for me.\r\nAlthough while building Tensorflow 1.8.0 build fails with following error \r\n```\r\nERROR: /home/test/tensorflow/tensorflow/contrib/lite/toco/python/BUILD:22:1: Linking of rule '//tensorflow/contrib/lite/toco/python:_tensorflow_wrap_toco.so' failed (Exit 1)\r\ngcc: error: tensorflow_wrap_toco_versionscript.lds: No such file or directory\r\n```\r\ngcc version:\r\n```\r\ntest@3df991c9ea6c:~/tensorflow$ gcc --version\r\ngcc (Ubuntu 7.3.0-16ubuntu3) 7.3.0\r\nCopyright (C) 2017 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n```\r\nAny specific version of gcc to be used? \r\n\r\n", "Looks like I used this version:\n$ gcc --version\ngcc (Ubuntu 7.3.0-16ubuntu3) 7.3.0\nCopyright (C) 2017 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\nThe error you see looks like there is a BUILD dependency problem in tf lite.\nDo we need TF lite linked into TF for s390x?\n\nOn Mon, Sep 24, 2018 at 8:51 PM duane-ibm <notifications@github.com> wrote:\n\n> Yes bazel 0.17.1 built with openjdk11 worked for me.\n> Although while building Tensorflow 1.8.0 build fails with following error\n>\n> ERROR: /home/test/tensorflow/tensorflow/contrib/lite/toco/python/BUILD:22:1: Linking of rule '//tensorflow/contrib/lite/toco/python:_tensorflow_wrap_toco.so' failed (Exit 1)\n> gcc: error: tensorflow_wrap_toco_versionscript.lds: No such file or directory\n>\n> gcc version:\n>\n> test@3df991c9ea6c:~/tensorflow$ gcc --version\n> gcc (Ubuntu 7.3.0-16ubuntu3) 7.3.0\n> Copyright (C) 2017 Free Software Foundation, Inc.\n> This is free software; see the source for copying conditions.  There is NO\n> warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n>\n> Any specific version of gcc to be used?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/19770#issuecomment-424198360>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AHlCOeFNgCW1A84XB3c0Vp5B80ZFR-4fks5ueahdgaJpZM4Uae-x>\n> .\n>\n", "Hi @gunan ,\r\n\r\nHave you successfully been able to build Tensorflow v1.8.0 on UB 16.04?\r\nDo we need TF lite linked into TF for s390x? =>  We are not sure about this, any suggestions from you?\r\n\r\n\r\n", "I was not able to build bazel successfully on ubuntu 16.04, so was not able to build any version of TF.\r\n\r\nI would say we can omit tflite for s390x.\r\n\r\n", "@gunan we actually used adoptOpenjdk10 to build bazel on UB 16.04, although faced issues with the tensorflow v1.8.0 build as mentioned in above comments.\r\n\r\nTensorflow build for v1.10.1 completed successfully, however the java tests still seems to fail with the below error:\r\n```\r\nERROR: /home/test/tensorflow_1.10.1/tensorflow/java/BUILD:54:1: Building tensorflow/java/libprocessor_library-class.jar (1 source file) failed (Exit 1)\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/io/IOException.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/util/Collection.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/util/Collections.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/util/HashMap.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/util/Map.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/util/Set.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/util/regex/Matcher.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/util/regex/Pattern.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/javax/annotation/processing/AbstractProcessor.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/javax/annotation/processing/Filer.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/javax/annotation/processing/Messager.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/javax/annotation/processing/ProcessingEnvironment.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/javax/annotation/processing/RoundEnvironment.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/javax/lang/model/SourceVersion.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/javax/lang/model/element/AnnotationMirror.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/javax/lang/model/element/AnnotationValue.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/javax/lang/model/element/Element.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/javax/lang/model/element/ExecutableElement.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/javax/lang/model/element/Modifier.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/javax/lang/model/element/TypeElement.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/javax/lang/model/element/TypeParameterElement.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/javax/lang/model/element/VariableElement.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/javax/lang/model/type/TypeMirror.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/javax/lang/model/type/TypeVariable.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/javax/lang/model/util/ElementFilter.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/javax/lang/model/util/Elements.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/javax/tools/Diagnostic.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/javax/tools/Diagnostic$Kind.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/javax/annotation/processing/Processor.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/Object.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/String.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/Override.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/annotation/Annotation.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/annotation/Retention.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/annotation/RetentionPolicy.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/annotation/Target.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/annotation/ElementType.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/io/Serializable.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/Iterable.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/AutoCloseable.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/Enum.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/Comparable.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/Deprecated.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/IllegalStateException.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/Byte.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/Character.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/Short.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/Long.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/Float.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/Integer.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/Double.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/Boolean.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/Void.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/Throwable.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/RuntimeException.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/Exception.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/util/Iterator.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/Class.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/reflect/Type.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/CharSequence.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/reflect/GenericDeclaration.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/reflect/AnnotatedElement.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/io/File.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/nio/file/Path.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/Appendable.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/AssertionError.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/Error.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/util/AbstractMap.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/util/Map$Entry.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/javax/lang/model/AnnotatedConstruct.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/javax/lang/model/element/ElementKind.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/javax/lang/model/element/Parameterizable.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/javax/lang/model/element/QualifiedNameable.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/util/List.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/javax/lang/model/element/Name.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/javax/lang/model/type/ReferenceType.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/reflect/TypeVariable.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/StringBuilder.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/AbstractStringBuilder.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/StringBuffer.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/util/regex/MatchResult.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/javax/lang/model/type/DeclaredType.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/IllegalArgumentException.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nerror: warnings found and -Werror specified\r\nINFO: Elapsed time: 19.800s, Critical Path: 8.06s\r\nINFO: 46 processes: 46 local.\r\nFAILED: Build did NOT complete successfully\r\n//tensorflow/java:ConstantTest                                        NO STATUS\r\n//tensorflow/java:GraphTest                                           NO STATUS\r\n//tensorflow/java:OperandsTest                                        NO STATUS\r\n//tensorflow/java:OperationBuilderTest                                NO STATUS\r\n//tensorflow/java:OperationTest                                       NO STATUS\r\n//tensorflow/java:PrimitiveOpTest                                     NO STATUS\r\n//tensorflow/java:SavedModelBundleTest                                NO STATUS\r\n//tensorflow/java:ScopeTest                                           NO STATUS\r\n//tensorflow/java:SessionTest                                         NO STATUS\r\n//tensorflow/java:ShapeTest                                           NO STATUS\r\n//tensorflow/java:TensorFlowTest                                      NO STATUS\r\n//tensorflow/java:TensorTest                                          NO STATUS\r\n//tensorflow/java:source_writer_test                                  NO STATUS\r\n\r\nFAILED: Build did NOT complete successfully\r\n```", "The warnings are not fatal, and the build should succeed if you ignore them. The reason the build is failing is the use of `-Werror`. As an experiment, can you try building without flag flag and see if it works?\r\n\r\n```\r\nwarning: bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath8.jar(/java/lang/IllegalArgumentException.class): major version 54 is newer than 53, the highest major version supported by this compiler.\r\n  It is recommended that the compiler be upgraded.\r\nerror: warnings found and -Werror specified\r\n```\r\n\r\nThe warnings are the expected result of JDK 10 not being supported by the default toolchain yet.", "Redirecting to @sjamesr as he is now our resident java expert.", "resolved by https://github.com/bazelbuild/bazel/pull/11162", "@gunan Please close this one"]}, {"number": 19769, "title": "[XLA] Allow the tuple simplifier to operate on only subcomputations", "body": "This change optionally allows for the tuple simplifier to exclude the entry computation from its processing.\r\n\r\n", "comments": ["@jlebar could you take a look? Feel free to suggest another reviewer otherwise.", "thanks - will do all those.  that LOG(INFO) was debug left in by mistake.\r\n", "Updated", "update done.  thanks :)\r\n", "Does someone have to tell the CI system run run the unit tests, so that it will be merged?", "@drpngx can you help us get this committed?", "Sure, kicking off the tests...", "Merged. Thank you for the contribution!"]}, {"number": 19768, "title": "Unity Tensorflow crash", "body": "Have I written custom code: NO\r\nOS Platform and Distribution: MacOS\r\nTensorFlow installed from: source\r\nTensorFlow version: 1.8\r\nBazel version: Build label: 0.13.1-homebrew\r\nCUDA/cuDNN version: NA\r\nGPU model and memory: NA\r\nExact command to reproduce: NA\r\n\r\nI am using the example for Android. I try to build it to `.aar` file. I put the aar file to `Plugins/Android`. And put the .so file to `Assets/Plugins/Android/libs` When I start the apps, I got the crash. \r\n\r\n> 06-05 16:50:17.865 26605 26639 E AndroidRuntime: Caused by: java.lang.IllegalArgumentException: No OpKernel was registered to support Op 'All' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n06-05 16:50:17.865 26605 26639 E AndroidRuntime:   <no registered kernels>\r\n06-05 16:50:17.865 26605 26639 E AndroidRuntime: \r\n06-05 16:50:17.865 26605 26639 E AndroidRuntime: \t [[Node: assert_equal/All = All[Tidx=DT_INT32, keep_dims=false](assert_equal/Equal, assert_equal/Const)]]\r\n06-05 16:50:17.865 26605 26639 E AndroidRuntime: \tat org.tensorflow.Session.run(Native Method)\r\n06-05 16:50:17.865 26605 26639 E AndroidRuntime: \tat org.tensorflow.Session.access$100(Session.java:48)\r\n06-05 16:50:17.865 26605 26639 E AndroidRuntime: \tat org.tensorflow.Session$Runner.runHelper(Session.java:285)\r\n06-05 16:50:17.865 26605 26639 E AndroidRuntime: \tat org.tensorflow.Session$Runner.run(Session.java:235)\r\n06-05 16:50:17.865 26605 26639 E AndroidRuntime: \tat org.tensorflow.contrib.android.TensorFlowInferenceInterface.run(TensorFlowInferenceInterface.java:142)\r\n06-05 16:50:17.865 26605 26639 E AndroidRuntime: \tat org.tensorflow.demo.TensorFlowObjectDetectionAPIModel.recognizeImage(TensorFlowObjectDetectionAPIModel.java:158)\r\n06-05 16:50:17.865 26605 26639 E AndroidRuntime: \tat org.tensorflow.demo.DetectorActivity$3.run(DetectorActivity.java:289)\r\n06-05 16:50:17.865 26605 26639 E AndroidRuntime: \tat android.os.Handler.handleCallback(Handler.java:751)\r\n06-05 16:50:17.865 26605 26639 E AndroidRuntime: \tat android.os.Handler.dispatchMessage(Handler.java:95)\r\n06-05 16:50:17.865 26605 26639 E AndroidRuntime: \tat android.os.Looper.loop(Looper.java:154)\r\n06-05 16:50:17.865 26605 26639 E AndroidRuntime: \tat android.os.HandlerThread.run(HandlerThread.java:61)", "comments": ["Nagging Assignee @skye: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @skye: It has been 30 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @skye: It has been 44 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @skye: It has been 60 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Not all operations are included in the default builds for TensorFlow Mobile to keep the binary size smaller. You may need to use [selective registration](https://github.com/tensorflow/tensorflow/blob/915cf10d4bcbb51f079f6841aeaf876b430a920b/tensorflow/python/tools/print_selective_registration_header.py#L15) to include the 'All' op and build from source.\r\n\r\nAssigning to @petewarden , who I believe might have some pointers on documentation for selective registration (see also #10299)", "There's some documentation on the process of adding ops here:\r\nhttps://www.tensorflow.org/mobile/prepare_models\r\n\r\nIt's not very easy to do unfortunately, so we are working on improvements for TensorFlow Lite."]}, {"number": 19767, "title": "Update install_linux.md", "body": "This not necessary and adds confusion to the instruction outlined in the Docker session. It is not necessary to have all Nvidia System Requirements.\r\n\r\nThe host machine only requires Nvidia drivers, not the CUDA toolkit or cuDNN.\r\n\r\nThe containers require CUDA toolkit and cuDNN to be present. See:\r\nhttps://github.com/nvidia/nvidia-docker/wiki/CUDA#requirements", "comments": []}, {"number": 19766, "title": "Illegal instruction (core dumped) When importing tensorflow", "body": "### System information\r\n- **Have I written custom code**: No\r\n- **OS Platform and Distribution**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from**: source\r\n- **TensorFlow version**: 1.8\r\n- **Python version**: 2.7.12\r\n- **Bazel version**: 0.14.0\r\n- **GCC/Compiler version**: 5.4.0\r\n- **CUDA/cuDNN version**: 9.2/7.1.4\r\n- **GPU model and memory**: GeForce GT 740 4GB\r\n- **Exact command to reproduce**: `import tensorflow`\r\n\r\n### Describe the problem\r\n`Illegal instruction (core dumped)` upon importing tensorflow.\r\n\r\n### Source code / logs (gdb output)\r\n```\r\n#0  0x00007fffd4c3891f in std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, tensorflow::Node::NodeClass>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, tensorflow::Node::NodeClass> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_Hashtable<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, tensorflow::Node::NodeClass> const*>(std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, tensorflow::Node::NodeClass> const*, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, tensorflow::Node::NodeClass> const*, unsigned long, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const&, std::__detail::_Mod_range_hashing const&, std::__detail::_Default_ranged_hash const&, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const&, std::__detail::_Select1st const&, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, tensorflow::Node::NodeClass> > const&) () from /home/avidbeam/.local/lib/python2.7/site-packages/tensorflow/python/../libtensorflow_framework.so\r\n#1  0x00007fffd4b75acc in __static_initialization_and_destruction_0(int, int) [clone .constprop.386] ()\r\n   from /home/avidbeam/.local/lib/python2.7/site-packages/tensorflow/python/../libtensorflow_framework.so\r\n#2  0x00007ffff7de76ba in call_init (l=<optimized out>, argc=argc@entry=1, argv=argv@entry=0x7fffffffdcb8, \r\n    env=env@entry=0xacaf00) at dl-init.c:72\r\n#3  0x00007ffff7de77cb in call_init (env=0xacaf00, argv=0x7fffffffdcb8, argc=1, l=<optimized out>) at dl-init.c:30\r\n#4  _dl_init (main_map=main_map@entry=0xe25890, argc=1, argv=0x7fffffffdcb8, env=0xacaf00) at dl-init.c:120\r\n#5  0x00007ffff7dec8e2 in dl_open_worker (a=a@entry=0x7fffffffbcb0) at dl-open.c:575\r\n#6  0x00007ffff7de7564 in _dl_catch_error (objname=objname@entry=0x7fffffffbca0, \r\n    errstring=errstring@entry=0x7fffffffbca8, mallocedp=mallocedp@entry=0x7fffffffbc9f, \r\n    operate=operate@entry=0x7ffff7dec4d0 <dl_open_worker>, args=args@entry=0x7fffffffbcb0) at dl-error.c:187\r\n#7  0x00007ffff7debda9 in _dl_open (\r\n    file=0x7fffdfd37384 \"/home/avidbeam/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\", mode=-2147483646, caller_dlopen=0x51ad19 <_PyImport_GetDynLoadFunc+233>, nsid=-2, argc=<optimized out>, \r\n    argv=<optimized out>, env=0xacaf00) at dl-open.c:660\r\n#8  0x00007ffff75ecf09 in dlopen_doit (a=a@entry=0x7fffffffbee0) at dlopen.c:66\r\n#9  0x00007ffff7de7564 in _dl_catch_error (objname=0x9b91d0, errstring=0x9b91d8, mallocedp=0x9b91c8, \r\n    operate=0x7ffff75eceb0 <dlopen_doit>, args=0x7fffffffbee0) at dl-error.c:187\r\n#10 0x00007ffff75ed571 in _dlerror_run (operate=operate@entry=0x7ffff75eceb0 <dlopen_doit>, \r\n    args=args@entry=0x7fffffffbee0) at dlerror.c:163\r\n#11 0x00007ffff75ecfa1 in __dlopen (file=<optimized out>, mode=<optimized out>) at dlopen.c:87\r\n#12 0x000000000051ad19 in _PyImport_GetDynLoadFunc ()\r\n#13 0x000000000051a8e4 in _PyImport_LoadDynamicModule ()\r\n#14 0x00000000005b7b1b in ?? ()\r\n#15 0x00000000004bc3fa in PyEval_EvalFrameEx ()\r\n#16 0x00000000004c136f in PyEval_EvalFrameEx ()\r\n#17 0x00000000004b9ab6 in PyEval_EvalCodeEx ()\r\n#18 0x00000000004b97a6 in PyEval_EvalCode ()\r\n#19 0x00000000004b96df in PyImport_ExecCodeModuleEx ()\r\n#20 0x00000000004b2b06 in ?? ()\r\n#21 0x00000000004a4ae1 in ?? ()\r\n#22 0x00000000004a4513 in PyImport_ImportModuleLevel ()\r\n```\r\n", "comments": ["This is likely because your CPU does not support AVX instructions. [Since TensorFlow 1.6](https://github.com/tensorflow/tensorflow/releases/tag/v1.6.0) the release binaries are compiled with AVX support and running those instructions on CPUs that do not support it will result in this error.\r\n\r\n@gunan may know if we are working on detecting this and writing out an error message. However, in the mean time you'll probably have to build from source or using unofficial builds like those mentioned in https://github.com/yaroslavvb/tensorflow-community-wheels\r\n\r\nHope that helps!", "I figured that I did not have `protobuf` during my first installation yet `bazel` built the pip package successfully.\r\nI decided to install `libprotoc 3.5.0` from source then I built tensorflow for c++ with `bazel build tensorflow:libtensorflow_cc.so` then I followed up with `bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package` for python. Fortunately, I noticed that the actions count this time were more than my previous build and the problems got fixed\r\n\r\nThanks !", "Thanks for the heads up @asimshankar Indeed my CPU doesn't support AVX instruction set."]}, {"number": 19765, "title": " from tensorflow.tools.api.generator.api import *  # pylint: disable=redefined-builtin ImportError: No module named 'tensorflow.tools.api'", "body": "I came across this issue when I import tensorflow on a server:\r\nthe configurations are as follows:\r\nUbuntu 16.04.4 LTS\r\nKernel: 4.13.0-1011\r\nTensorflow 0.18\r\n\r\n>>> import tensorflow\r\n/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/__init__.py\", line 26, in <module>\r\n    from tensorflow.tools.api.generator.api import *  # pylint: disable=redefined-builtin\r\nImportError: No module named 'tensorflow.tools.api'\r\n\r\nAny idea how to solve this problem?  \r\nThanks!\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 30 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Well I actually have the same problem what was your solution ?", "I get the same error. Any solutions?\r\nI'm using Win 10 with conda.", "ok, I downgraded tensorflow to 1.3 and import works"]}, {"number": 19764, "title": " auto load_file_system_library", "body": "From https://www.tensorflow.org/extend/add_filesys we can build a custom filesystem plugin, and explictily load it like this :\r\n\r\n```\r\nfrom tensorflow.python.framework import load_library\r\nload_library.load_file_system_library(\"xxxx.so\")\r\n```\r\nBut this is hard to use, and user who want to use xxxx.so `must change his code`.\r\nIs there a way to call `load_library.load_file_system_library` automatically when a environment variable such as `FILE_SYSTEM_LIBRARY` is set.\r\n\r\nTo sum up with a user story:\r\n1. user set environment variable  FILE_SYSTEM_LIBRARY=xxxx.so\r\n2. user use xxxx.so related method in his script directly without explictily loading  xxxx.so.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 19763, "title": " Key linear_model/two_linear_1/batch_normalization21/gamma/Adam_1 not found in checkpoint", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["This issue has no contents, so I'm closing it. Please submit a question on [Stack Overflow](http://stackoverflow.com/questions/tagged/tensorflow) if you are having trouble but are not reporting a bug or feature request. Thanks!"]}]