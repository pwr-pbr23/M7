[{"number": 54239, "title": "tensorflow.python.keras.api._v1.keras.layers' has no attribute 'experimental'", "body": "\r\n**System information**\r\n- Linux Ubuntu 16.04\r\n- TensorFlow version: 1.15.5\r\n- Python version: 3.7\r\n- Installed using virtualenv\r\n\r\n**Describe the problem**\r\n\r\nCommand \r\n\r\nimport tensorflow_model_optimization\r\n\r\nError that I get\r\nFile \"test.py\", line 2, in <module>\r\n    import tensorflow_model_optimization\r\n  File \"/home/marlin/.local/lib/python3.7/site-packages/tensorflow_model_optimization/__init__.py\", line 86, in <module>\r\n    from tensorflow_model_optimization.python.core.api import clustering\r\n  File \"/home/marlin/.local/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/api/__init__.py\", line 19, in <module>\r\n    from tensorflow_model_optimization.python.core.api import sparsity\r\n  File \"/home/marlin/.local/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/api/sparsity/__init__.py\", line 16, in <module>\r\n    from tensorflow_model_optimization.python.core.api.sparsity import keras\r\n  File \"/home/marlin/.local/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/api/sparsity/keras/__init__.py\", line 18, in <module>\r\n    from tensorflow_model_optimization.python.core.sparsity.keras.prune import prune_low_magnitude\r\n  File \"/home/marlin/.local/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/prune.py\", line 22, in <module>\r\n    from tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\r\n  File \"/home/marlin/.local/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py\", line 33, in <module>\r\n    from tensorflow_model_optimization.python.core.sparsity.keras import prune_registry\r\n  File \"/home/marlin/.local/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/prune_registry.py\", line 26, in <module>\r\n    class PruneRegistry(object):\r\n  File \"/home/marlin/.local/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/prune_registry.py\", line 96, in PruneRegistry\r\n    layers.experimental.preprocessing.Rescaling.__class__: [],\r\n  File \"/home/marlin/anaconda/envs/hific-compress1/lib/python3.7/site-packages/tensorflow_core/python/util/module_wrapper.py\", line 193, in __getattr__\r\n    attr = getattr(self._tfmw_wrapped_module, name)\r\nAttributeError: module 'tensorflow.python.keras.api._v1.keras.layers' has no attribute 'experimental'\r\n\r\n\r\n\r\n\r\n\r\n**I can not upgrade to tensorflow 2.x as I have other dependencies on tensorflow 1.15.5 and trying to quantize my model. Am I doing anything wrong here?**", "comments": ["Hi @prmudgal ! After installing  Model Optimization 0.6.0 , I was able to  execute import command. you can select suitable version for quantization from [here](https://github.com/tensorflow/model-optimization/releases). Attaching [gist](https://colab.sandbox.google.com/gist/mohantym/32fd372196967deed35aa4e9c939b217/github_54239.ipynb) for reference.Thank you", "@mohantym It worked, Thanks ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54239\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54239\">No</a>\n"]}, {"number": 54238, "title": "Fix bazelisk installation paths", "body": "This originally broke our tests because bazel couldn't be found. The\nbashrc didn't include the new bin directory, and so none of the\nfollowing commands worked correctly. I installed bazelisk into /usr/bin\ninstead.\n", "comments": []}, {"number": 54237, "title": "Github still lists 2.6.2 as the release, but pip installs 2.7.0", "body": "What is the current version in such a case?", "comments": ["@surak \r\nIn order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose),Thanks!", "There is no proper template for issues on the repo itself. It is what is written here. The \u201creleases\u201d page shows 2.6.2. Pip downloads 2.7. What is the stable version?", "@surak Thank  you for the quick response!\r\nThe latest stable TF version is 2.7.0 , please have a look on this [link](https://www.tensorflow.org/install/source#tested_build_configurations)  of tested build configuration for reference.\r\nThanks!", "Great - then, whoever administers github, please make a release. \r\n\r\nHave a look. Go to the main page, here: https://github.com/tensorflow/tensorflow\r\nand check on the right side, at RELEASES:\r\n![Screen Shot 2022-02-02 at 16 05 57](https://user-images.githubusercontent.com/878399/152180213-ca76c2ba-c2cd-441d-9dcf-4dd195b6d149.png)\r\n\r\n", "@surak @sushreebarsa\r\n\r\nGitHub shows the latest uploaded version not the latest version of TF !!! \r\n\r\nThe last uploaded version is TF 2.6.2 because security or critical updates were done on it. Please do not mix the last activity and the latest version.\r\n\r\nThanks.", "I know, Mark. But there\u2019s no indication of what is the actual latest release anywhere on the GitHub page written in a clear, unambiguous way. Sure, there is a 2.7, and even a 2.8-rc, but not a clear way for sysadmins to decide. ", "@markub3327 Thank you for the response!\r\n@surak Please have a look at https://github.com/tensorflow/tensorflow , where the latest released version of TF is `2.8.0 ` now.\r\nIt was showing TF 2.6.2 as latest due to some updates were done on it.\r\nPlease move this issue to closed status if it is resolved for you?\r\nThanks!\r\n\r\n", "@surak The latest tested version of TF is [here](https://www.tensorflow.org/install/source#tested_build_configurations) like @sushreebarsa mentioned. GitHub Releases is only informative for developers and sysadmins may look at https://www.tensorflow.org/install pages.\r\n\r\nThanks.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "There is still no clear indication of what the current release is on the github page. ", "@surak **GitHub** shows the `latest uploaded version for the recent activity not the latest version of TF`. Please refer [official ](https://www.tensorflow.org/) site of TensorFlow where stable TF version is 2.8.0 .\r\nThanks!", "@surak \r\nLatest and stable Tensorflow version is 2.8.0. It is updated in Tensorflow githib release notes \r\nTake a look [here](https://github.com/tensorflow/tensorflow/releases)", "@gadagashwini thanks, but only shows the most recent version created. If an older version has a bug fix release issued, that one will come up on top.... And this is my beef here. The page the way you show seems correct now, it wasn't when I opened this issue - look at the comment above: https://github.com/tensorflow/tensorflow/issues/54237#issuecomment-1028034032", "Seems nobody cares, or get it so I will close it.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54237\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54237\">No</a>\n", "This is the standard procedure for all other packages. It's not soemething that TF itself is at fault.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54237\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54237\">No</a>\n"]}, {"number": 54236, "title": "[ROCm] Fixes to make //tensorflow/compiler/xla/service/gpu/tests:mlir_gemm_t\u2026", "body": "\u2026est work with TFRT BEF Thunk on ROCm.", "comments": ["/cc @chsigg @hanbinyoon ", "@chsigg I fixed the merge conflicts in this PR.", "Thanks Rohit, this looks great, thanks a lot! I will merge this change manually."]}, {"number": 54234, "title": "How to debug custom loss function?", "body": "\r\nI know about 2 things needed to debug tensorflow in eager mode:\r\n- add `run_eagerly=True` when compiling model\r\n- add `tf.config.run_functions_eagerly(True)` line\r\n\r\nNeither is working when it comes to debugging custom loss function. I used [simple MNIST example](https://www.tensorflow.org/datasets/keras_example) to recreate the issue:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow_datasets as tfds\r\n\r\ntf.config.run_functions_eagerly(True)  # does not help\r\n\r\n(ds_train, ds_test), ds_info = tfds.load(\r\n    'mnist',\r\n    split=['train', 'test'],\r\n    shuffle_files=True,\r\n    as_supervised=True,\r\n    with_info=True,\r\n)\r\n\r\ndef normalize_img(image, label):\r\n  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\r\n  return tf.cast(image, tf.float32) / 255., label\r\n\r\n\r\ndef custom_loss(y_true, y_pred):\r\n    stop = 1   # BREAKPOINT HERE NOT WORKING!\r\n\r\n\r\nds_train = ds_train.map(\r\n    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\r\nds_train = ds_train.cache()\r\nds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\r\nds_train = ds_train.batch(128)\r\nds_train = ds_train.prefetch(tf.data.AUTOTUNE)\r\n\r\nds_test = ds_test.map(\r\n    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\r\nds_test = ds_test.batch(128)\r\nds_test = ds_test.cache()\r\nds_test = ds_test.prefetch(tf.data.AUTOTUNE)\r\n\r\nmodel = tf.keras.models.Sequential([\r\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\r\n  tf.keras.layers.Dense(128, activation='relu'),\r\n  tf.keras.layers.Dense(10)\r\n])\r\nmodel.compile(\r\n    optimizer=tf.keras.optimizers.Adam(0.001),\r\n    # loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n    loss=custom_loss,\r\n    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\r\n    run_eagerly=True,       # does not help either\r\n)\r\n\r\nmodel.fit(\r\n    ds_train,\r\n    epochs=6,\r\n    validation_data=ds_test,\r\n)\r\n```\r\n", "comments": ["Hi @dankal444 ! 2.x versions run eagerly by default and loss function has to be a differential one.  Above code was working after replacing custom loss with this code snippet. You can know more about  creating custom loss from[ here](https://keras.io/api/losses/). Thank you!\r\n```\r\ndef custom_loss(y_true, y_pred):\r\n    y_true = tf.cast(y_true,tf.float32)\r\n    y_pred = tf.cast(y_pred,tf.float32)\r\n    squared_difference = tf.square(y_true - y_pred)\r\n    return tf.reduce_mean(squared_difference, axis=-1)  # Note the `axis=-1`\r\n```\r\n", "Hi @mohantym this is not a question about this specific *toy example*. As you can see custom loss computation is empty, intentionally. I just want the debugger to stop there so it is much easier to implement the loss, try some things, fix shapes, etc.", "@dankal444 ! I have tried to catch the bug using try catch block and [tf.print()](https://www.tensorflow.org/api_docs/python/tf/print) . Attaching updated [gist](https://colab.sandbox.google.com/gist/mohantym/f21ad71a2cb6bdb19dd4f031b82bd347/github_54234.ipynb#scrollTo=liEiG7qIsARM) for reference. Thanks!", "@mohantym What is this gist for? What it has to do with debugging issue here?", "@dankal444 ! I thought your query was on debugging custom loss function. I understand that you wanted  to stop at loss function instead of throwing exception.  I updated gist accordingly to debug loss function. Thank you!", "@mohantym \r\n\r\n> I thought your query was on debugging custom loss function\r\n\r\nyes\r\n\r\n> I understand you wanted to stop at loss function instead of throwing exception\r\n\r\nyes\r\n\r\n> I updated gist accordingly to debug loss function\r\n\r\nbut if you set breakpoint in the loss function it does not work. As I have wrote \"I just want the debugger to stop there so it is much easier to implement the loss, try some things, fix shapes, etc.\"", "@dankal444 When you run `model.fit`, it creates a graph and I think TF/keras inspects it. In the case where there is nothing returning from a custom loss function (which is must for a model and should be differentiable), it is throwing an error. I am not exactly sure how to make the breakpoint approach to work but this is not a technically a bug. Thanks!\r\n\r\n[Here](https://colab.research.google.com/gist/jvishnuvardhan/2ea6433e97aded319007916a716359f1/github_54234.ipynb) is a gist for our reference. If you want to contribute, please feel free to submit any PR to update the code. Thanks!\r\n\r\nPlease note that Keras development moved to another repository [keras-team/keras repo.](https://github.com/keras-team/keras/issues) to focus entirely on only keras. Thanks!", "So, TLDR: you can't..\r\n\r\nBut there is a workaround - overwriting `train_step` function:\r\nhttps://keras.io/guides/customizing_what_happens_in_fit/\r\nYou can debug there.\r\n\r\nNote that not everything that works in eager mode will work in no-eager mode. Had to struggle with many not-supported things", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54234\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54234\">No</a>\n"]}, {"number": 54233, "title": "I got an error on trainingstart = model.fit(x=x_train, y=y_train, epochs=10, batch_size=64)", "body": "I don,t know what type of error i'm facing right now, need help ASAP\r\n\r\nEpoch 1/10\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\nC:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_976/3417244454.py in <module>\r\n----> 1 trainingstart = model.fit(x=x_train, y=y_train, epochs=10, batch_size=64)\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py in error_handler(*args, **kwargs)\r\n     65     except Exception as e:  # pylint: disable=broad-except\r\n     66       filtered_tb = _process_traceback_frames(e.__traceback__)\r\n---> 67       raise e.with_traceback(filtered_tb) from None\r\n     68     finally:\r\n     69       del filtered_tb\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     56   try:\r\n     57     ctx.ensure_initialized()\r\n---> 58     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n     59                                         inputs, attrs, num_outputs)\r\n     60   except core._NotOkStatusException as e:\r\n\r\nInvalidArgumentError:  Received a label value of 32 which is outside the valid range of [0, 11).  Label values: 16 7 17 1 13 4 8 3 24 1 8 12 11 30 16 0 18 15 0 32 16 30 10 31 21 12 6 9 0 23 19 5 21 3 6 8 11 31 14 31 19 5 27 0 32 32 0 19 4 7 16 3 31 27 18 31 20 19 1 22 22 26 6 8\r\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\r\n (defined at C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend.py:5113)\r\n]] [Op:__inference_train_function_703]\r\n\r\nErrors may have originated from an input operation.\r\nInput Source operations connected to node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:\r\nIn[0] sparse_categorical_crossentropy/Reshape_1 (defined at C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend.py:5109)\t\r\nIn[1] sparse_categorical_crossentropy/Reshape (defined at C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend.py:3561)\r\n\r\nOperation defined at: (most recent call last)\r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\r\n>>>     return _run_code(code, main_globals, None,\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 87, in _run_code\r\n>>>     exec(code, run_globals)\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\r\n>>>     app.launch_new_instance()\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\r\n>>>     app.start()\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\r\n>>>     self.io_loop.start()\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\r\n>>>     self.asyncio_loop.run_forever()\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 596, in run_forever\r\n>>>     self._run_once()\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\r\n>>>     handle._run()\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\r\n>>>     self._context.run(self._callback, *self._args)\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\r\n>>>     await self.process_one()\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\r\n>>>     await dispatch(*args)\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\r\n>>>     await result\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\r\n>>>     reply_content = await reply_content\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\r\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\r\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\r\n>>>     result = self._run_cell(\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\r\n>>>     return runner(coro)\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\r\n>>>     coro.send(None)\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\r\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\r\n>>>     if (await self.run_code(code, result,  async_=asy)):\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\r\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\r\n>>> \r\n>>>   File \"C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_976/117376915.py\", line 1, in <module>\r\n>>>     trainingstart = model.fit(x=x_train, y=y_train, epochs=32, batch_size=64)\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\r\n>>>     tmp_logs = self.train_function(iterator)\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\r\n>>>     return step_function(self, iterator)\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\r\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\r\n>>>     outputs = model.train_step(data)\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 809, in train_step\r\n>>>     loss = self.compiled_loss(\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\r\n>>>     loss_value = loss_obj(y_t, y_p, sample_weight=sw)\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\r\n>>>     losses = call_fn(y_true, y_pred)\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 245, in call\r\n>>>     return ag_fn(y_true, y_pred, **self._fn_kwargs)\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1737, in sparse_categorical_crossentropy\r\n>>>     return backend.sparse_categorical_crossentropy(\r\n>>> \r\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5113, in sparse_categorical_crossentropy\r\n>>>     res = tf.nn.sparse_softmax_cross_entropy_with_logits(\r\n>>> \r\n\r\n", "comments": ["@asfainqa \r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "i used jupyter notebook for fruits recognition project\r\n![image](https://user-images.githubusercontent.com/98821328/151976506-8af72e1a-a33e-4b6c-8069-724e6e9900b8.png)\r\n![image](https://user-images.githubusercontent.com/98821328/151976593-76736491-5799-484e-b864-05aba40614ac.png)\r\n![image](https://user-images.githubusercontent.com/98821328/151976646-8bda592b-4286-4992-bac0-402700d6d6f0.png)\r\n![image](https://user-images.githubusercontent.com/98821328/151976702-b550b4d3-175b-44cd-9fe2-26b1e5a9aa90.png)\r\n![image](https://user-images.githubusercontent.com/98821328/151976791-87a63397-3e7c-434b-bedc-cb79d1529df8.png)\r\n![image](https://user-images.githubusercontent.com/98821328/151976846-a51cf4ad-bc3b-47d4-ab34-5d6a45bc9d73.png)\r\nand i got stuck during the train model.\r\nI used the dataset from https://www.kaggle.com/sshikamaru/fruit-recognition\r\n\r\n", "@asfainqa Thank you for the update!\r\nCould you please provide the notebook link or colab gist of your code to reproduce this issue and please let us know which TF version you are using ? Please refer this[ link](https://keras.io/guides/training_with_built_in_methods).Thanks!", "OOO I already solve it, so i guess you can close the issue. The problem is within my dataset", "@asfainqa Thank you for the update!\r\nClosing this issue as it is resolved .Thanks!"]}, {"number": 54232, "title": "tf.data.Dataset.from_generator() does not work with tf.data.experimental.enable_debug_mode()", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n- TensorFlow version (use command below): `v2.7.0-0-gc256c071bb2 2.7.0`\r\n- Python version: 3.7.12\r\n\r\n**Describe the current behavior**\r\n\r\n\r\n\r\n`tf.data.Dataset.from_generator()` does not work when `tf.data.experimental.enable_debug_mode()` is called in advance.\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\ntf.data.experimental.enable_debug_mode()\r\n\r\ndef gen():\r\n    yield from iter(range(10))\r\n\r\ndataset = tf.data.Dataset.from_generator(gen, output_signature=tf.TensorSpec(shape=(), dtype=tf.int32))\r\n\r\nfor item in dataset:\r\n    print(item)\r\n```\r\n\r\nResults in\r\n\r\n```\r\n  ...\r\n\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 810, in get_iterator\r\n    return self._iterators[iterator_id]\r\n\r\nTypeError: unhashable type: 'numpy.ndarray'\r\n\r\n\r\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNext]\r\n```\r\n\r\nFrom a small investigation it seems that the \"obvious\" solution \u2014\u00a0changing https://github.com/tensorflow/tensorflow/blob/ffe6f62b7f8e57177c26ca3b38c0929d5f64b43f/tensorflow/python/data/ops/dataset_ops.py#L833 to\r\n\r\n```python\r\nreturn np.int64(ret)\r\n```\r\n\r\ndoes not fix the issue, even though `np.int64(0)` is hashable, while `np.array(0, dtype=np.int64)` is not.\r\n\r\nAdditionally, I tried a workaround and added to `_GeneratorState` the following method:\r\n\r\n```python\r\n@staticmethod\r\ndef _fix_iterator_id(iterator_id):\r\n    assert isinstance(iterator_id, np.ndarray)\r\n    assert iterator_id.ndim == 0\r\n    assert iterator_id.dtype == np.int64\r\n    return np.int64(iterator_id)\r\n```\r\n\r\nand added calls to it from `get_iterator()` and `iterator_completed()`. However, this triggered yet another issue: in `tf.python.ops.script_ops`, `FuncRegistry` started throwing an error `ValueError('callback pyfunc_63 is not found')`.\r\n\r\n**Describe the expected behavior**\r\n\r\nNo crash.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nhttps://colab.research.google.com/gist/dniku/80456bc9d30fbaaadca4a22469c2c1df/tf_dataset_from_generator_with_debug_mode_crash.ipynb", "comments": ["@sachinprasadhs ,\r\nI was able to reproduce the issue in tf v2.5, v2.7 and nightly.Please find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/356927cf329e036cb4cb873ad5615437/54232.ipynb).", "@dniku , If you have identified the issue in the code and the probable fix, could you please raise a PR. Thanks!", "I have not, and my small investigation only hints at what will _not_ resolve this issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54232\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54232\">No</a>\n"]}, {"number": 54230, "title": "Refactoring of ConvertUnary", "body": "ConvertUnary is rewritten using OpConverterBase \r\n", "comments": ["@drivanov Would you please fix the first conversation block. When creating new PRs:\r\nFirst conversation block: put only the information that you want to go with the commit message there.\r\nSecond conversation block: put more details, such as related PRs, background of the work, explanation of the problem trying to solve and the approach taken, etc.\r\n", "I will approve this after the other two PRs are merged.", "NOTE: This PR should be slightly adjusted if it will be merged after  \r\n[PR#54181](https://github.com/tensorflow/tensorflow/pull/54181):**Implementation of converters for unary operators \"Round\" and \"Sign\"**\r\n[PR#53718](https://github.com/tensorflow/tensorflow/pull/53718): **Converter for Tile operation**", "@drivanov would you please rebase and squash the commits into one?", "[PR#55082](https://github.com/tensorflow/tensorflow/pull/55082)  is a substitute for that one."]}, {"number": 54229, "title": "Avoid dequantizing with qi16 convolution", "body": "This avoids the decompose-hybrid-quantization pass for quantized int16\r\nconvolutions. Those convolutions contain a non-quantized int64 bias.\r\nThe hybrid decompose pass is only used when a mixed floating point and\r\nquantized operator is detected.\r\n\r\nAlso properly set the double_round field in the TOSA rescale after\r\nconvolution. When 16-bit scaling is involved, double_round must be\r\nfalse.\r\n\r\nSigned-off-by: Eric Kunze <eric.kunze@arm.com>", "comments": []}, {"number": 54228, "title": "TF->TOSA: Ignore stride if shrink axis mask is set", "body": "Strided slice should ignore stride if shrink_axis_mask is set for\r\nthat dimension. Set strides to 1 for those dimensions. Otherwise\r\nthe reshape ends up with dimensions of size 0, which are invalid.", "comments": []}, {"number": 54227, "title": "[ROCm] fix dockerfile.rocm", "body": "Dockerfile.rocm is still using py36", "comments": ["@cheshire sorry for the churn here, but this is just a fix for an out of date CI dockerfile.", "Duplicate of https://github.com/tensorflow/tensorflow/pull/54093"]}, {"number": 54226, "title": "Update version numbers for TensorFlow 2.8.0", "body": "Before merging this PR, please double check that it has correctly updated\n`core/public/version.h`, `tools/pip_package/setup.py`, and\n`tensorflow/tensorflow.bzl`. Also review the execution notes below:\n\n```\nMajor: 2 -> 2\nMinor: 8 -> 8\nPatch: 0 -> 0\n\nNo lingering old version strings \"2.8.0-rc1\" found in source directory \n\"tensorflow/\". Good.\nNo lingering old version strings \"2.8.0rc1\" found in source directory \n\"tensorflow/\". Good.\n```", "comments": []}, {"number": 54225, "title": "build_pip_package is broken", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL 8.5\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: git HEAD\r\n- Python version: 3.6.8\r\n- Installed using virtualenv? pip? conda?: n/a\r\n- Bazel version (if compiling from source): 3.7.2\r\n- GCC/Compiler version (if compiling from source): 10.3.0\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nbuild fails with\r\n\r\nERROR: /home/andrew/src/tensorflow/WORKSPACE:23:14: error loading package '@com_github_grpc_grpc//src/compiler': in /home/andrew/.cache/bazel/_bazel_andrew/c61c5f84d239689cb19a72cfde16be9f/external/com_github_grpc_grpc/bazel/grpc_build_system.bzl: in /home/andrew/.cache/bazel/_bazel_andrew/c61c5f84d239689cb19a72cfde16be9f/external/build_bazel_rules_apple/apple/ios.bzl: in /home/andrew/.cache/bazel/_bazel_andrew/c61c5f84d239689cb19a72cfde16be9f/external/build_bazel_rules_apple/apple/internal/ios_rules.bzl: in /home/andrew/.cache/bazel/_bazel_andrew/c61c5f84d239689cb19a72cfde16be9f/external/build_bazel_rules_swift/swift/swift.bzl: in /home/andrew/.cache/bazel/_bazel_andrew/c61c5f84d239689cb19a72cfde16be9f/external/build_bazel_rules_swift/swift/internal/swift_proto_library.bzl: Extension 'swift/internal/swift_protoc_gen_aspect.bzl' has errors and referenced by '//external:grpc_python_plugin'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Analysis failed\r\nINFO: Elapsed time: 60.334s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (194 packages loaded, 3623 targets configured)\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nbazel build --config=nonccl //tensorflow/tools/pip_package:build_pip_package --verbose_failures\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@cfRod @nSircombe ", "I just confirmed this issue with bazel 4.2.2 as well.", "OK, works with bazel 5.0.0, sorry for the noise.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54225\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54225\">No</a>\n"]}, {"number": 54224, "title": "Issue with load_model and custom_object_scope", "body": "So as it seems like there is an issue with load_model for tensorflow 2.7.0, \r\nThis was not happening for me on tensorflow 2.4.1 and everything was running smoothly.\r\n\r\nLet's get to the topic. \r\n\r\nWhen i try to load my model instance i am getting an error the first time i try to load it i'll highlight my code here.\r\n   ```\r\n with K.utils.custom_object_scope(\r\n        {\r\n            \"r2\": r2,\r\n            \"r2_keras\": r2,\r\n            \"AttentionAugmentation2D\": AttentionAugmentation2D,\r\n            \"Functional\": tf.keras.models.Model,\r\n        }\r\n    ):\r\n        with GzipFile(filename, \"rb\") as fs:\r\n            estimator = pickle.load(fs)\r\n            keras_model = pickle.load(fs)\r\n            model_h5_instance = h5py.File(BytesIO(keras_model), \"r\")\r\n            estimator.estimator = K.models.load_model(\r\n                model_h5_instance, compile=False\r\n            )\r\n```\r\nit is also noted that the instance that i am using for saving is obviously a tf.keras.models.Model() instance\r\n\r\nso the first time this line `estimator.estimator = K.models.load_model(model_h5_instance, compile=False)`  runs i am getting this error:\r\n`AttirbuteError: module 'keras.api._v2.keras.models' has no attribute \"Functional\"`\r\nthe second time i run this line it loads the model regularly.\r\nalso noting that i have already tried to pass the custom objects on load_model.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow version (use command below): 2.7.0\r\n- Python version: 3.8\r\n- CUDA/cuDNN version: 11.6\r\n- GPU model and memory: GTX 1050 TI", "comments": ["@deepNeuralNick \r\nIn order to expedite the trouble-shooting process, please fill the [template](https://github.com/tensorflow/tensorflow/issues/new/choose),and  provide a code snippet to reproduce the issue reported here. Please refer this [link ](https://www.tensorflow.org/api_docs/python/tf/keras/models/load_model),Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54224\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54224\">No</a>\n"]}, {"number": 54223, "title": " [TFLite] Enable reference int8 fully connected with output shape with dimensions > 2 ", "body": "Hi,\r\n\r\nThis PR enables reference int8 support for fully connected with output shape with dimensions > 2 in TensorFlow Lite.\r\nRelevant issue which describes this is here: https://github.com/tensorflow/tensorflow/issues/53501 \r\n\r\nThis PR also contains an update to the SimpleTestQuantizedOutputShape3DInt16 to ensure that output shape with dimensions >2 is verified.\r\n\r\nThanks,\r\nSaoirse", "comments": ["Could you add a e2e test case under the lite_v2_test.py?", "Hi, Thanks for review. I have added end to end test to lite_v2_test.py. Please let me know if there is anything I need to add/change.\r\n\r\nBest regards,\r\nSaoirse", "Seems auto-merge is not happening but the changes are merged into master now, so we can close this. Thank you for the PR.\r\n"]}, {"number": 54222, "title": "Node 'training/Adam/gradients/gradients/batch_normalization_8/cond_grad/StatelessIf': Connecting to invalid output 3 of source node batch_normalization_8/cond which has 3 outputs. Try using tf.compat.v1.experimental.output_all_intermediates(True).", "body": "<em>Please make sure that this is an issue related to keras.\r\ntag:keras_template</em>\r\n\r\n**Important Notice**\r\n\r\nPlease note that `tf.keras` code was moved entirely to\r\n[keras-team/keras](https://github.com/keras-team/keras) repository\r\n\r\nYou can open any code/doc bugs, performance issues, and feature requests\r\n in [keras-team/keras](https://github.com/keras-team/keras/issues) repository\r\n\r\n`tf.keras` related issues opened in\r\n[tensorflow/tensorflow](https://github.com/tensorflow/tensorflow) repository may\r\nnot get attention as [keras-team/keras](https://github.com/keras-team/keras)\r\nrepository is dedicated for the development of `keras` code\r\n", "comments": ["@Hjiwnain ,\r\nIn order to expedite the trouble-shooting process, could you please provide a minimal code snippet and the TensorFlow version you are using.", "Also please take a look at this [link](https://www.tensorflow.org/api_docs/python/tf/compat/v1/experimental/output_all_intermediates) for the information regarding tf.compat.v1.experimental.output_all_intermediates.It helps.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54222\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54222\">No</a>\n"]}, {"number": 54219, "title": "clang: error: no such file or directory: '/d2ReducedOptimizeHugeFunctions'", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  windows11\r\n- Bazel version (if compiling from source): 4.2.2\r\n\r\n\r\n**Describe the problem**\r\n    I want to build tensorflowLite from source, I use this command: `bazel build -c opt --fat_apk_cpu=armeabi-v7a --host_crosstool_top=@bazel_tools//tools/cpp:toolchain //tensorflow/lite/java:tensorflow-lite`,  and it occurs this error:\r\n\r\n`ERROR: D:/desktop/ky/tensorflow-master/tensorflow/lite/kernels/internal/BUILD:838:11: Compiling tensorflow/lite/kernels/internal/mfcc.cc failed: (Exit 1): clang failed: error executing command\r\n  cd C:/users/25486/_bazel_25486/v4xxzvgh/execroot/org_tensorflow\r\n  SET ANDROID_BUILD_TOOLS_VERSION=30.0.3\r\n    SET ANDROID_NDK_API_LEVEL=21\r\n    SET ANDROID_NDK_HOME=D:/SoftWare/Andriod/ndk/21.4.7075529\r\n    SET ANDROID_SDK_API_LEVEL=29\r\n    SET ANDROID_SDK_HOME=D:/SoftWare/Andriod\r\n    SET PATH=D:\\SoftWare\\Msys2\\usr\\bin;D:\\SoftWare\\Msys2\\bin;C:\\Windows;C:\\Windows\\System32;C:\\Windows\\System32\\WindowsPowerShell\\v1.0;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;D:\\SoftWare\\Python\\Scripts\\;D:\\SoftWare\\Python\\;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Windows\\System32\\OpenSSH\\;D:\\SoftWare\\Xshell\\;D:\\SoftWare\\WinSCP\\WinSCP\\;D:\\SoftWare\\mingw64\\bin;D:\\SoftWare\\Cmake\\bin;D:\\SoftWare\\Ninja;D:\\SoftWare\\Andriod\\platform-tools;D:\\SoftWare\\Git\\Git\\cmd;D:\\SoftWare\\Gradle\\gradle-6.8.3\\bin;D:\\SoftWare\\bazel;D:\\SoftWare\\Java\\jdk1.8.0_202\\bin;C:\\Users\\25486\\AppData\\Local\\Microsoft\\WindowsApps;D:\\SoftWare\\Bandizip\\;D:\\SoftWare\\VSCode\\Microsoft VS Code\\bin;D:\\SoftWare\\mingw64\\bin;D:\\SoftWare\\Java\\jdk1.8.0_202\\bin;\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=D:/SoftWare/Python/python.exe\r\n    SET PYTHON_LIB_PATH=D:/SoftWare/Python/lib/site-packages\r\n    SET RUNFILES_MANIFEST_ONLY=1\r\n    SET TF2_BEHAVIOR=1\r\n  external/androidndk/ndk/toolchains/llvm/prebuilt/windows-x86_64/bin/clang -D__ANDROID_API__=21 -isystemexternal/androidndk/ndk/sysroot/usr/include/arm-linux-androideabi -target armv7-none-linux-androideabi -march=armv7-a -mfloat-abi=softfp -mfpu=vfpv3-d16 -gcc-toolchain external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/windows-x86_64 -fpic -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig -Werror=return-type -Werror=int-to-pointer-cast -Werror=pointer-to-int-cast -Werror=implicit-function-declaration -mthumb -Os -g -DNDEBUG -MD -MF bazel-out/android-armeabi-v7a-opt/bin/tensorflow/lite/kernels/internal/_objs/audio_utils/mfcc.pic.d -frandom-seed=bazel-out/android-armeabi-v7a-opt/bin/tensorflow/lite/kernels/internal/_objs/audio_utils/mfcc.pic.o -fPIC -iquote . -iquote bazel-out/android-armeabi-v7a-opt/bin -iquote external/fft2d -iquote bazel-out/android-armeabi-v7a-opt/bin/external/fft2d /W0 /D_USE_MATH_DEFINES -DWIN32_LEAN_AND_MEAN -DNOGDI /experimental:preprocessor /d2ReducedOptimizeHugeFunctions /std:c++14 -DFARMHASH_NO_CXX_STRING -mfpu=neon -O3 -ffunction-sections -fdata-sections -fno-exceptions --sysroot=external/androidndk/ndk/platforms/android-21/arch-arm -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c tensorflow/lite/kernels/internal/mfcc.cc -o bazel-out/android-armeabi-v7a-opt/bin/tensorflow/lite/kernels/internal/_objs/audio_utils/mfcc.pic.o\r\nExecution platform: @local_execution_config_platform//:platform\r\nclang: error: no such file or directory: '/W0'\r\n\r\nclang: error: no such file or directory: '/D_USE_MATH_DEFINES'\r\n\r\nclang: error: no such file or directory: '/experimental:preprocessor'\r\n\r\nclang: error: no such file or directory: '/d2ReducedOptimizeHugeFunctions'\r\n\r\nclang: error: no such file or directory: '/std:c++14'\r\n\r\nTarget //tensorflow/lite/java:tensorflow-lite failed to build\r\nINFO: Elapsed time: 21.998s, Critical Path: 17.47s\r\nINFO: 95 processes: 73 internal, 22 local.\r\nFAILED: Build did NOT complete successfully`\r\n\r\nI have installed visual studio 2019, but in the error info above, I gusess the reason may be it can't find the visual studio??  please help...\r\n\r\n", "comments": ["@fushwLZU \r\nIn order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose), and refer this [issue ](https://github.com/tensorflow/tensorflow/issues/50783) ?\r\nThanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54219\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54219\">No</a>\n"]}, {"number": 54218, "title": "OpenMPI issue causes import tensorflow to hang intermittently?", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1.  It must be a bug, a feature request, or a significant problem with the\r\n    documentation (for small docs fixes please send a PR instead).\r\n2.  The form below must be filled out.\r\n3.  It shouldn't be a TensorBoard issue. Those go\r\n    [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**:Yes\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 20.04\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**: n/a\r\n-   **TensorFlow installed from (source or binary)**: Binary\r\n-   **TensorFlow version (use command below)**:tf.version.VERSION = 2.7.0\r\n-   **Python version**: (3, 8, 10, 'final', 0)\r\n-   **Bazel version (if compiling from source)**: n/a\r\n-   **GCC/Compiler version (if compiling from source)**: n/a\r\n-   **CUDA/cuDNN version**:CUDA Version: 11.4 \r\n-   **GPU model and memory**: 4 x A6000 48GB\r\n-   **Exact command to reproduce**:  import tensorflow as tf\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\nImporting tensorflow into a jupyter notebook hangs pseudorandomly.  After five months we've be unable to isolate a cause or devise a 100% effective workaround.  Sometimes the line \"import tensorflow as tf\" works, other times it hangs.  Often we're forced to do a full power off to clear this condition but even that isn't 100% effective.  We're not trying to do distributed (multi-node) training.  We're just working with the four GPUs on this machine.  Thanks for your help!\r\n\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nThis command produces the output below.\r\nstrace -ttt python -c 'import tensorflow as tf; print(tf.__version__)' | tee -a strace-python.txt\r\n\r\n1643302791.282122 openat(AT_FDCWD, \"/usr/lib/x86_64-linux-gnu/openmpi/lib/openmpi3/mca_ess_singleton.so\", O_RDONLY|O_CLOEXEC) = 7\r\n1643302791.282146 read(7, \"\\177ELF\\2\\1\\1\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0>\\0\\1\\0\\0\\0\\340'\\0\\0\\0\\0\\0\\0\"..., 832) = 832\r\n1643302791.282169 fstat(7, {st_mode=S_IFREG|0644, st_size=27704, ...}) = 0\r\n1643302791.282194 mmap(NULL, 29544, PROT_READ, MAP_PRIVATE|MAP_DENYWRITE, 7, 0) = 0x7f3d5f678000\r\n1643302791.282216 mmap(0x7f3d5f67a000, 12288, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 7, 0x2000) = 0x7f3d5f67a000\r\n1643302791.282243 mmap(0x7f3d5f67d000, 4096, PROT_READ, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 7, 0x5000) = 0x7f3d5f67d000\r\n1643302791.282267 mmap(0x7f3d5f67e000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 7, 0x5000) = 0x7f3d5f67e000\r\n1643302791.282295 close(7)              = 0\r\n1643302791.282371 mprotect(0x7f3d5f67e000, 4096, PROT_READ) = 0\r\n1643302791.282524 pipe([7, 8])          = 0\r\n1643302791.282551 pipe([9, 10])         = 0\r\n1643302791.282575 stat(\"/usr/bin/orted\", {st_mode=S_IFREG|0755, st_size=14648, ...}) = 0\r\n1643302791.282611 clone(child_stack=NULL, flags=CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID|SIGCHLD, child_tidptr=0x7f3dba183a10) = 1251309\r\n1643302791.285529 close(8)              = 0\r\n1643302791.285554 close(9)              = 0\r\n1643302791.285581 read(7, \r\n\r\n\r\n^Cstrace: Process 1251181 detached\r\n\r\n(command hung and had to be terminated with ctrl-c)\r\n\r\n*****\r\n\r\nHere is an ifconfig.\r\n\r\neno1: flags=4099<UP,BROADCAST,MULTICAST>  mtu 1500\r\n        ether 3c:ec:ef:7f:e4:3a  txqueuelen 1000  (Ethernet)\r\n        RX packets 0  bytes 0 (0.0 B)\r\n        RX errors 0  dropped 0  overruns 0  frame 0\r\n        TX packets 0  bytes 0 (0.0 B)\r\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\r\n        device memory 0xf3d00000-f3d7ffff  \r\n\r\nenxb03af2b6059f: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\r\n        ether b0:3a:f2:b6:05:9f  txqueuelen 1000  (Ethernet)\r\n        RX packets 60  bytes 3904 (3.9 KB)\r\n        RX errors 0  dropped 0  overruns 0  frame 0\r\n        TX packets 92  bytes 16432 (16.4 KB)\r\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\r\n\r\neth1: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\r\n        inet 192.168.23.188  netmask 255.255.255.0  broadcast 192.168.23.255\r\n        inet6 fe80::27f0:4e0d:bcfe:3279  prefixlen 64  scopeid 0x20<link>\r\n        ether 3c:ec:ef:7f:e5:d6  txqueuelen 1000  (Ethernet)\r\n        RX packets 243180  bytes 83830328 (83.8 MB)\r\n        RX errors 19963008343767  dropped 58  overruns 0  frame 0\r\n        TX packets 273889  bytes 161266394 (161.2 MB)\r\n        TX errors 19997367730176  dropped 0 overruns 0  carrier 0  collisions 0\r\n\r\nlo: flags=73<UP,LOOPBACK,RUNNING>  mtu 65536\r\n        inet 127.0.0.1  netmask 255.0.0.0\r\n        inet6 ::1  prefixlen 128  scopeid 0x10<host>\r\n        loop  txqueuelen 1000  (Local Loopback)\r\n        RX packets 5303219  bytes 11465259037 (11.4 GB)\r\n        RX errors 0  dropped 0  overruns 0  frame 0\r\n        TX packets 5303219  bytes 11465259037 (11.4 GB)\r\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\r\n\r\n\r\n******\r\n\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 470.94       Driver Version: 470.94       CUDA Version: 11.4     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  NVIDIA RTX A6000    On   | 00000000:21:00.0 Off |                  Off |\r\n| 30%   32C    P8    22W / 300W |      8MiB / 48685MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  NVIDIA RTX A6000    On   | 00000000:22:00.0 Off |                  Off |\r\n| 30%   41C    P8    26W / 300W |    451MiB / 48685MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  NVIDIA RTX A6000    On   | 00000000:41:00.0  On |                  Off |\r\n| 30%   44C    P8    33W / 300W |   1065MiB / 48682MiB |      8%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  NVIDIA RTX A6000    On   | 00000000:43:00.0 Off |                  Off |\r\n| 30%   38C    P8    21W / 300W |      8MiB / 48685MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                                  |\r\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n|        ID   ID                                                   Usage      |\r\n|=============================================================================|\r\n|    0   N/A  N/A      2829      G   /usr/lib/xorg/Xorg                  4MiB |\r\n|    1   N/A  N/A      2829      G   /usr/lib/xorg/Xorg                  4MiB |\r\n|    1   N/A  N/A   1669191      C   /usr/bin/python3                  443MiB |\r\n|    2   N/A  N/A      2829      G   /usr/lib/xorg/Xorg                230MiB |\r\n|    2   N/A  N/A      3143      G   /usr/bin/gnome-shell               62MiB |\r\n|    2   N/A  N/A      4284      G   /usr/lib/firefox/firefox          285MiB |\r\n|    2   N/A  N/A      4518      G   /usr/lib/firefox/firefox            4MiB |\r\n|    2   N/A  N/A      5140      G   gnome-control-center               28MiB |\r\n|    2   N/A  N/A     13899      G   /usr/bin/nvidia-settings            0MiB |\r\n|    2   N/A  N/A   1668753      C   /usr/bin/python3                  443MiB |\r\n|    2   N/A  N/A   1691476      G   /usr/lib/firefox/firefox            4MiB |\r\n|    3   N/A  N/A      2829      G   /usr/lib/xorg/Xorg                  4MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n\r\n", "comments": ["@camda03 ,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code and dataset to reproduce the issue reported here.", "[tf_strace_fail.txt](https://github.com/tensorflow/tensorflow/files/7971039/tf_strace_fail.txt)\r\n[tf_strace_success.txt](https://github.com/tensorflow/tensorflow/files/7971043/tf_strace_success.txt)\r\n\r\nAll it takes is the strace command that I've provided.\r\n\r\nstrace -ttt python -c 'import tensorflow as tf; print(tf.version)' | tee -a strace-python.txt\r\n\r\nI've seen cases in which I reboot the machine, run this command, and it hangs as shown.\r\n\r\nIf this fails in a Jupyter notebook, all it takes is \"import tensorflow as tf\"' to make the notebook hang.\r\nThe notebook never gets to our code in these cases.\r\n\r\nThis fails randomly, for no reason that we understand. Previously some thought that this was a hardware issue.\r\nHowever, the hardware has been replaced and this still occurs.\r\n\r\nFor the past two days I've been running our code without incident. (Big surprise to me.)\r\nWhy is this working at the moment?  How long will it keep working? I wish I knew.\r\n\r\nIt's like flipping a coin or throwing dice, whether our notebooks and strace will work or hang.\r\n\r\nHere are two logfiles. Both were done using the strace command that I've provided.\r\n\r\nOne worked, one hung.\r\n\r\nWill these help?\r\n\r\nThanks!\r\n\r\n\r\nP.S. This is our model.  We run this on one A6000.  This lets us run (if nothing hangs) up to four at a time.\r\n\r\nModel: \"model\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nlayer_0 (InputLayer)         [(None, 23963)]           0         \r\n_________________________________________________________________\r\nlayer_1 (Dense)              (None, 23963)             574249332 \r\n_________________________________________________________________\r\nlayer_2 (Dense)              (None, 23963)             574249332 \r\n_________________________________________________________________\r\nlayer_3 (Dense)              (None, 23963)             574249332 \r\n_________________________________________________________________\r\nlayer_4 (Dense)              (None, 23963)             574249332 \r\n_________________________________________________________________\r\noutput_layer (Dense)         (None, 22)                527208    \r\n=================================================================\r\nTotal params: 2,297,524,536\r\nTrainable params: 2,297,524,536\r\nNon-trainable params: 0\r\n\r\n", "Here is ompi_info FYI.\r\n\r\nThanks!\r\n\r\nompi_info\r\n                 Package: Debian OpenMPI\r\n                Open MPI: 4.0.3\r\n  Open MPI repo revision: v4.0.3\r\n   Open MPI release date: Mar 03, 2020\r\n                Open RTE: 4.0.3\r\n  Open RTE repo revision: v4.0.3\r\n   Open RTE release date: Mar 03, 2020\r\n                    OPAL: 4.0.3\r\n      OPAL repo revision: v4.0.3\r\n       OPAL release date: Mar 03, 2020\r\n                 MPI API: 3.1.0\r\n            Ident string: 4.0.3\r\n                  Prefix: /usr\r\n Configured architecture: x86_64-pc-linux-gnu\r\n          Configure host: lcy01-amd64-020\r\n           Configured by: buildd\r\n           Configured on: Wed Apr 15 13:14:35 UTC 2020\r\n          Configure host: lcy01-amd64-020\r\n  Configure command line: '--build=x86_64-linux-gnu' '--prefix=/usr'\r\n                          '--includedir=${prefix}/include'\r\n                          '--mandir=${prefix}/share/man'\r\n                          '--infodir=${prefix}/share/info'\r\n                          '--sysconfdir=/etc' '--localstatedir=/var'\r\n                          '--disable-silent-rules'\r\n                          '--libdir=${prefix}/lib/x86_64-linux-gnu'\r\n                          '--runstatedir=/run' '--disable-maintainer-mode'\r\n                          '--disable-dependency-tracking'\r\n                          '--disable-silent-rules'\r\n                          '--disable-wrapper-runpath'\r\n                          '--with-package-string=Debian OpenMPI'\r\n                          '--with-verbs' '--with-libfabric' '--with-psm2'\r\n                          '--with-jdk-dir=/usr/lib/jvm/default-java'\r\n                          '--enable-mpi-java'\r\n                          '--enable-opal-btl-usnic-unit-tests'\r\n                          '--with-libevent=external'\r\n                          '--with-pmix=/usr/lib/x86_64-linux-gnu/pmix'\r\n                          '--disable-silent-rules' '--enable-mpi-cxx'\r\n                          '--with-hwloc=/usr' '--with-libltdl'\r\n                          '--with-devel-headers' '--with-slurm' '--with-sge'\r\n                          '--without-tm' '--sysconfdir=/etc/openmpi'\r\n                          '--libdir=${prefix}/lib/x86_64-linux-gnu/openmpi/lib'\r\n                          '--includedir=${prefix}/lib/x86_64-linux-gnu/openmpi/include'\r\n                Built by: buildd\r\n                Built on: Wed Apr 15 13:20:16 UTC 2020\r\n              Built host: lcy01-amd64-020\r\n              C bindings: yes\r\n            C++ bindings: yes\r\n             Fort mpif.h: yes (all)\r\n            Fort use mpi: yes (full: ignore TKR)\r\n       Fort use mpi size: deprecated-ompi-info-value\r\n        Fort use mpi_f08: yes\r\n Fort mpi_f08 compliance: The mpi_f08 module is available, but due to\r\n                          limitations in the gfortran compiler and/or Open\r\n                          MPI, does not support the following: array\r\n                          subsections, direct passthru (where possible) to\r\n                          underlying Open MPI's C functionality\r\n  Fort mpi_f08 subarrays: no\r\n           Java bindings: yes\r\n  Wrapper compiler rpath: rpath\r\n              C compiler: gcc\r\n     C compiler absolute: /usr/bin/gcc\r\n  C compiler family name: GNU\r\n      C compiler version: 9.3.0\r\n            C++ compiler: g++\r\n   C++ compiler absolute: /usr/bin/g++\r\n           Fort compiler: gfortran\r\n       Fort compiler abs: /usr/bin/gfortran\r\n         Fort ignore TKR: yes (!GCC$ ATTRIBUTES NO_ARG_CHECK ::)\r\n   Fort 08 assumed shape: yes\r\n      Fort optional args: yes\r\n          Fort INTERFACE: yes\r\n    Fort ISO_FORTRAN_ENV: yes\r\n       Fort STORAGE_SIZE: yes\r\n      Fort BIND(C) (all): yes\r\n      Fort ISO_C_BINDING: yes\r\n Fort SUBROUTINE BIND(C): yes\r\n       Fort TYPE,BIND(C): yes\r\n Fort T,BIND(C,name=\"a\"): yes\r\n            Fort PRIVATE: yes\r\n          Fort PROTECTED: yes\r\n           Fort ABSTRACT: yes\r\n       Fort ASYNCHRONOUS: yes\r\n          Fort PROCEDURE: yes\r\n         Fort USE...ONLY: yes\r\n           Fort C_FUNLOC: yes\r\n Fort f08 using wrappers: yes\r\n         Fort MPI_SIZEOF: yes\r\n             C profiling: yes\r\n           C++ profiling: yes\r\n   Fort mpif.h profiling: yes\r\n  Fort use mpi profiling: yes\r\n   Fort use mpi_f08 prof: yes\r\n          C++ exceptions: no\r\n          Thread support: posix (MPI_THREAD_MULTIPLE: yes, OPAL support: yes,\r\n                          OMPI progress: no, ORTE progress: yes, Event lib:\r\n                          yes)\r\n           Sparse Groups: no\r\n  Internal debug support: no\r\n  MPI interface warnings: yes\r\n     MPI parameter check: runtime\r\nMemory profiling support: no\r\nMemory debugging support: no\r\n              dl support: yes\r\n   Heterogeneous support: no\r\n mpirun default --prefix: no\r\n       MPI_WTIME support: native\r\n     Symbol vis. support: yes\r\n   Host topology support: yes\r\n            IPv6 support: no\r\n      MPI1 compatibility: no\r\n          MPI extensions: affinity, cuda, pcollreq\r\n   FT Checkpoint support: no (checkpoint thread: no)\r\n   C/R Enabled Debugging: no\r\n  MPI_MAX_PROCESSOR_NAME: 256\r\n    MPI_MAX_ERROR_STRING: 256\r\n     MPI_MAX_OBJECT_NAME: 64\r\n        MPI_MAX_INFO_KEY: 36\r\n        MPI_MAX_INFO_VAL: 256\r\n       MPI_MAX_PORT_NAME: 1024\r\n  MPI_MAX_DATAREP_STRING: 128\r\n           MCA allocator: bucket (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n           MCA allocator: basic (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n           MCA backtrace: execinfo (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                 MCA btl: self (MCA v2.1.0, API v3.1.0, Component v4.0.3)\r\n                 MCA btl: openib (MCA v2.1.0, API v3.1.0, Component v4.0.3)\r\n                 MCA btl: vader (MCA v2.1.0, API v3.1.0, Component v4.0.3)\r\n                 MCA btl: tcp (MCA v2.1.0, API v3.1.0, Component v4.0.3)\r\n            MCA compress: bzip (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n            MCA compress: gzip (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                 MCA crs: none (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                  MCA dl: dlopen (MCA v2.1.0, API v1.0.0, Component v4.0.3)\r\n               MCA event: external (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n               MCA hwloc: external (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                  MCA if: linux_ipv6 (MCA v2.1.0, API v2.0.0, Component\r\n                          v4.0.3)\r\n                  MCA if: posix_ipv4 (MCA v2.1.0, API v2.0.0, Component\r\n                          v4.0.3)\r\n         MCA installdirs: env (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n         MCA installdirs: config (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n              MCA memory: patcher (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n               MCA mpool: hugepage (MCA v2.1.0, API v3.0.0, Component v4.0.3)\r\n             MCA patcher: overwrite (MCA v2.1.0, API v1.0.0, Component\r\n                          v4.0.3)\r\n                MCA pmix: flux (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                MCA pmix: isolated (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                MCA pmix: ext3x (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n               MCA pstat: linux (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n              MCA rcache: grdma (MCA v2.1.0, API v3.3.0, Component v4.0.3)\r\n           MCA reachable: weighted (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n           MCA reachable: netlink (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n               MCA shmem: mmap (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n               MCA shmem: posix (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n               MCA shmem: sysv (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n               MCA timer: linux (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n              MCA errmgr: default_app (MCA v2.1.0, API v3.0.0, Component\r\n                          v4.0.3)\r\n              MCA errmgr: default_tool (MCA v2.1.0, API v3.0.0, Component\r\n                          v4.0.3)\r\n              MCA errmgr: default_hnp (MCA v2.1.0, API v3.0.0, Component\r\n                          v4.0.3)\r\n              MCA errmgr: default_orted (MCA v2.1.0, API v3.0.0, Component\r\n                          v4.0.3)\r\n                 MCA ess: singleton (MCA v2.1.0, API v3.0.0, Component\r\n                          v4.0.3)\r\n                 MCA ess: env (MCA v2.1.0, API v3.0.0, Component v4.0.3)\r\n                 MCA ess: hnp (MCA v2.1.0, API v3.0.0, Component v4.0.3)\r\n                 MCA ess: tool (MCA v2.1.0, API v3.0.0, Component v4.0.3)\r\n                 MCA ess: pmi (MCA v2.1.0, API v3.0.0, Component v4.0.3)\r\n                 MCA ess: slurm (MCA v2.1.0, API v3.0.0, Component v4.0.3)\r\n               MCA filem: raw (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n             MCA grpcomm: direct (MCA v2.1.0, API v3.0.0, Component v4.0.3)\r\n                 MCA iof: tool (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                 MCA iof: hnp (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                 MCA iof: orted (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                MCA odls: pspawn (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                MCA odls: default (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                 MCA oob: tcp (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                 MCA plm: isolated (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                 MCA plm: slurm (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                 MCA plm: rsh (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                 MCA ras: slurm (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                 MCA ras: gridengine (MCA v2.1.0, API v2.0.0, Component\r\n                          v4.0.3)\r\n                 MCA ras: simulator (MCA v2.1.0, API v2.0.0, Component\r\n                          v4.0.3)\r\n                MCA regx: reverse (MCA v2.1.0, API v1.0.0, Component v4.0.3)\r\n                MCA regx: fwd (MCA v2.1.0, API v1.0.0, Component v4.0.3)\r\n                MCA regx: naive (MCA v2.1.0, API v1.0.0, Component v4.0.3)\r\n               MCA rmaps: mindist (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n               MCA rmaps: round_robin (MCA v2.1.0, API v2.0.0, Component\r\n                          v4.0.3)\r\n               MCA rmaps: ppr (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n               MCA rmaps: resilient (MCA v2.1.0, API v2.0.0, Component\r\n                          v4.0.3)\r\n               MCA rmaps: seq (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n               MCA rmaps: rank_file (MCA v2.1.0, API v2.0.0, Component\r\n                          v4.0.3)\r\n                 MCA rml: oob (MCA v2.1.0, API v3.0.0, Component v4.0.3)\r\n              MCA routed: direct (MCA v2.1.0, API v3.0.0, Component v4.0.3)\r\n              MCA routed: radix (MCA v2.1.0, API v3.0.0, Component v4.0.3)\r\n              MCA routed: binomial (MCA v2.1.0, API v3.0.0, Component v4.0.3)\r\n                 MCA rtc: hwloc (MCA v2.1.0, API v1.0.0, Component v4.0.3)\r\n              MCA schizo: slurm (MCA v2.1.0, API v1.0.0, Component v4.0.3)\r\n              MCA schizo: ompi (MCA v2.1.0, API v1.0.0, Component v4.0.3)\r\n              MCA schizo: orte (MCA v2.1.0, API v1.0.0, Component v4.0.3)\r\n              MCA schizo: flux (MCA v2.1.0, API v1.0.0, Component v4.0.3)\r\n               MCA state: novm (MCA v2.1.0, API v1.0.0, Component v4.0.3)\r\n               MCA state: orted (MCA v2.1.0, API v1.0.0, Component v4.0.3)\r\n               MCA state: hnp (MCA v2.1.0, API v1.0.0, Component v4.0.3)\r\n               MCA state: app (MCA v2.1.0, API v1.0.0, Component v4.0.3)\r\n               MCA state: tool (MCA v2.1.0, API v1.0.0, Component v4.0.3)\r\n                 MCA bml: r2 (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                MCA coll: libnbc (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                MCA coll: sm (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                MCA coll: inter (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                MCA coll: self (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                MCA coll: tuned (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                MCA coll: basic (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                MCA coll: monitoring (MCA v2.1.0, API v2.0.0, Component\r\n                          v4.0.3)\r\n                MCA coll: sync (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                MCA fbtl: posix (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n               MCA fcoll: two_phase (MCA v2.1.0, API v2.0.0, Component\r\n                          v4.0.3)\r\n               MCA fcoll: dynamic (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n               MCA fcoll: individual (MCA v2.1.0, API v2.0.0, Component\r\n                          v4.0.3)\r\n               MCA fcoll: dynamic_gen2 (MCA v2.1.0, API v2.0.0, Component\r\n                          v4.0.3)\r\n               MCA fcoll: vulcan (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                  MCA fs: ufs (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                  MCA io: romio321 (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                  MCA io: ompio (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                 MCA mtl: ofi (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                 MCA mtl: psm2 (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                 MCA mtl: psm (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                 MCA osc: rdma (MCA v2.1.0, API v3.0.0, Component v4.0.3)\r\n                 MCA osc: monitoring (MCA v2.1.0, API v3.0.0, Component\r\n                          v4.0.3)\r\n                 MCA osc: pt2pt (MCA v2.1.0, API v3.0.0, Component v4.0.3)\r\n                 MCA osc: sm (MCA v2.1.0, API v3.0.0, Component v4.0.3)\r\n                 MCA pml: v (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                 MCA pml: monitoring (MCA v2.1.0, API v2.0.0, Component\r\n                          v4.0.3)\r\n                 MCA pml: ob1 (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                 MCA pml: cm (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                 MCA rte: orte (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n            MCA sharedfp: individual (MCA v2.1.0, API v2.0.0, Component\r\n                          v4.0.3)\r\n            MCA sharedfp: lockedfile (MCA v2.1.0, API v2.0.0, Component\r\n                          v4.0.3)\r\n            MCA sharedfp: sm (MCA v2.1.0, API v2.0.0, Component v4.0.3)\r\n                MCA topo: basic (MCA v2.1.0, API v2.2.0, Component v4.0.3)\r\n                MCA topo: treematch (MCA v2.1.0, API v2.2.0, Component\r\n                          v4.0.3)\r\n           MCA vprotocol: pessimist (MCA v2.1.0, API v2.0.0, Component\r\n                          v4.0.3)\r\n", "@camda03 ,\r\nThis issue is not related to tensorflow. Please move to respective respository which helps to resolve the issue.Thanks!", "Please see the ticket below for additional information on this issue.\r\n\r\nhttps://github.com/open-mpi/ompi/issues/10025\r\n\r\nThanks!\r\n\r\nDave"]}, {"number": 54216, "title": "fft2d/fftsg.c needs the math library", "body": "Without this, the tensorflow-lite build using CMake fails for me with undefined references.\r\n\r\nfftsg.c has `#include <math.h>`, but the CMake configuration lacks the link to the math library.\r\n\r\n", "comments": []}, {"number": 54215, "title": "Tensorflow Object detection AI", "body": "0\r\n\r\n\r\nI am using Tensorflow model zoo object detection. SSD MobileNet V2 FPNLite 320x320 is the model I am using to train my model. Everything goes well my model starts training but I receive some weird msgs. I don't why this msg is showing up.\r\n\r\nI think half of my model is training on GPU and then it is switching to CPU but I am not sure.\r\n\r\nHere are the msgs that are showing up.\r\n\r\n2022-01-30 19:30:21.237816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9971 MB memory: -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6 INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',) I0130 19:30:21.241063 140126199379776 mirrored_strategy.py:376] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\r\n\r\nAfter this it is showing me the following msgs.\r\n\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',). I0130 19:30:43.470607 140126199379776 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n\r\nHere is my GPU information.\r\n\r\n![image](https://user-images.githubusercontent.com/43025113/151710543-0dcf2f72-94ec-465f-bb08-f12dfa2815fb.png)\r\n\r\nPlease someone help me with this. I have been struggling for weeks.\r\n", "comments": ["@Annieliaquat ,\r\nWe see that the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose) has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced] or if possible share a colab gist with the issue reported.", "we have the same issues. I am trying to run an object detection model with TensorFlow.     ", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Hi @Annieliaquat ! It seems you are using distribution strategy for your code. Those warning are expected to be coming while running the code in [distribution computing](https://www.tensorflow.org/guide/distributed_training#:~:text=Overview-,tf.,code%20with%20minimal%20code%20changes.). Can you please provide a stand alone code to reproduce this issue?", "> Hi @Annieliaquat ! It seems you are using distribution strategy for your code. Those warning are expected to be coming while running the code in [distribution computing](https://www.tensorflow.org/guide/distributed_training#:~:text=Overview-,tf.,code%20with%20minimal%20code%20changes.). Can you please provide a stand alone code to reproduce this issue?\r\n\r\nThank you so much the problem is solved now.", "@Annieliaquat ,\r\nGlad the issue is resolved for you, please feel free to move this to closed status.", "> @Annieliaquat , Glad the issue is resolved for you, please feel free to move this to closed status.\r\n\r\nCan you also answer me that is Image Data generator is used in Tensorflow object detection API?", "> Hi @Annieliaquat ! It seems you are using distribution strategy for your code. Those warning are expected to be coming while running the code in [distribution computing](https://www.tensorflow.org/guide/distributed_training#:~:text=Overview-,tf.,code%20with%20minimal%20code%20changes.). Can you please provide a stand alone code to reproduce this issue?\r\n\r\nCan you also answer me that is Image Data generator is used in Tensorflow object detection API??", "@Annieliaquat ,\r\nPlease feel free to move this issue to closed status and please submit a new issue from [this link](https://github.com/tensorflow/models/issues/new/choose) and fill in the template, so that we can track the issue there. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54215\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54215\">No</a>\n"]}, {"number": 54214, "title": "Gradient for tf.sparse.reduce_max", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\ntf.sparse.reduce_max do not define grad. So it cannot be used in training step.\r\n\r\n**Will this change the current api? How?**\r\nWon't change current api. Just add grad in tf.sparse.reduce_max\r\n\r\n**Who will benefit with this feature?**\r\nPeople using sparse.reduce_max in training. If they have huge sparse matrix and cannot turn to dense array.\r\n\r\n**Any Other info.**\r\nI am working with pointnet-like model. And it will take a huge sparse matrix. If I turn this sparse matrix to dense, it will take ~60G memory. So I need do global maxpooling. Using tf sparse reduce_max. Unfortunately, it cannot be used in training right now.\r\nThanks", "comments": ["@AmadeusloveIris \r\nCan you please elaborate about your feature and please specify the Use Cases for this feature. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 54213, "title": "Fix sanity build", "body": null, "comments": []}, {"number": 54212, "title": "Disable flaky test", "body": null, "comments": []}, {"number": 54211, "title": "Tensorboard: This site can\u2019t be reached localhost refused to connect.", "body": "Hey everyone! I am training my model, when I use !tensorborad logdir=runs, it shows a link( http://localhost:6006/). When I click on this link it shows this site cant be reached. I don't what's wrong? I tried some solutions suggested at this site. But nothing worked for me.", "comments": ["I am using pytorch for training. And i am training it on google colab.", "Hello, \r\n\r\nYou probably need to open a ssh tunnel to route the 6006 port of the remote server to your localhost 6006 port :\r\nhttps://stackoverflow.com/questions/37987839/how-can-i-run-tensorboard-on-a-remote-server\r\n\r\nAlternatively there also exist a --bind_all option to tensorboard when the machine you are running is not the machine you use to consult, (but you will need to do some port forwarding, and it will be accessible to everyone, so it's mainly useful for local networks that you trust).\r\n", "@faizan1234567 ,\r\nPlease take a look at this link [1](https://github.com/tensorflow/tensorboard/issues/2481) and [2](https://stackoverflow.com/questions/40106949/unable-to-open-tensorboard-in-browser) with the similar error.It helps.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 54210, "title": "Update image_ops_impl.py", "body": "Fixes https://github.com/tensorflow/tensorflow/issues/54116 and https://github.com/tensorflow/tensorflow/issues/54115", "comments": ["@gbaned @rohan100jain I am new to opensource and I see some PyLint error on my PR, can you help me a bit so that I can do the changes if required?"]}, {"number": 54209, "title": "Update image_ops_impl.py", "body": "Fixes https://github.com/tensorflow/tensorflow/issues/54115", "comments": ["Fixes https://github.com/tensorflow/tensorflow/issues/54116 and https://github.com/tensorflow/tensorflow/issues/54115"]}, {"number": 54208, "title": "partially initialized module 'tensorflow' has no attribute 'Tensor' (most likely due to a circular import)", "body": "**System information**\r\n- Running code from: https://github.com/jpiedrafita/ai_number_read/blob/main/numbers.py\r\n\u276fpyhton3 numbers.py\r\n\r\n- OS Platform and Distribution: OSX 10.15.7\r\n\r\n- TensorFlow installed from: pip install tensorflow\r\nAs described in other \"has no attribute\" issues I tried other tf versions using\r\npip install tensorflow==x.x.x --ignore-installed\r\n\r\n- TensorFlow version (use command below):\r\n\r\n\u276f pip show tensorflow\r\nName: tensorflow\r\nVersion: 2.7.0\r\nSummary: TensorFlow is an open source machine learning framework for everyone.\r\nHome-page: https://www.tensorflow.org/\r\nAuthor: Google Inc.\r\nAuthor-email: packages@tensorflow.org\r\nLicense: Apache 2.0\r\nLocation: /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages\r\nRequires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, keras-preprocessing, libclang, numpy, opt-einsum, protobuf, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wheel, wrapt\r\nRequired-by:\r\n\r\n\u276f pip show tensorflow_datasets\r\nName: tensorflow-datasets\r\nVersion: 4.5.0\r\nSummary: tensorflow/datasets is a library of datasets ready to use with TensorFlow.\r\nHome-page: https://github.com/tensorflow/datasets\r\nAuthor: Google Inc.\r\nAuthor-email: packages@tensorflow.org\r\nLicense: Apache 2.0\r\nLocation: /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages\r\nRequires: absl-py, dill, numpy, promise, protobuf, requests, six, tensorflow-metadata, termcolor, tqdm\r\nRequired-by:\r\n\r\n- Python version 3.9.6\r\n\r\n**Describe the current behavior**\r\nConsole error: \r\nhttps://github.com/jpiedrafita/ai_number_read/blob/main/traceback.txt\r\nFile \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow_datasets/core/utils/type_utils.py\", line 49, in <module>\r\n    Tensor = Union[tf.Tensor, tf.SparseTensor, tf.RaggedTensor]\r\nAttributeError: partially initialized module 'tensorflow' has no attribute 'Tensor' (most likely due to a circular import)\r\n\r\nIn my code ther isn't any Tensor reference that could make a circular import.\r\n\r\n**Describe the expected behavior**\r\nSimple console output similar to:\r\n>Resultado: 0.974\r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://github.com/jpiedrafita/ai_number_read/blob/main/numbers.py)\r\n\r\n**Other info / logs**\r\n", "comments": ["@jpiedrafita ,\r\nCan you please confirm whether you have installed tensorflow from this [link](https://www.tensorflow.org/install).If not please try to follow the doc and let us know if you are facing same issue.Thanks!", "Hi @tilakrayal \r\nI installed tensorflow without upgrading pip (21.3.1). So:\r\n\r\n- I uninstalled tensorflow and tensorflow_datasets.\r\n- Then I upgraded pip according to the link (22.0.2).\r\n- I installed tensorflow and tensorflow_datasets using:\r\n```\r\npip install tensorflow\r\npip install tensorflow_datasets\r\n```\r\n- Current versions are: tensorflow 2.7.0 tensorflow_datasets 4.5.2\r\n- Now the [traceback](https://github.com/jpiedrafita/ai_number_read/blob/main/traceback.txt) changed to a different attribute error.", "@jpiedrafita ,\r\nI was facing different issue while executing the mentioned code.Please find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/70e4f71dd0752233472a87ab0b0a772f/untitled208.ipynb).", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54208\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54208\">No</a>\n"]}, {"number": 54207, "title": "No details on the CPU chip AVX requirement, pls give details up front. Not all folks have ivory tower HW.  ", "body": "Your documentation tells of the Nvidia GPU/CUDA requirement but not the CPU chip AVX requirement.   I have spent three days swapping video cards, now to find my dual Xeon(R) CPU  X5450 Dell cannot run your 2.0 version.  There should be a clear grid/listing of requirements and a lookup function.  It will take me a week and $ to build out of stored Dell t5600 with the Sandbridge CPUs.  Why are there no switches to disable advance features to use latest SW.  No all folks have ivory tower HW.  I run multiple old Dells with multiple configurations. I do not care if a job takes 2 days for a POC/hobby projects, just needs to run.  I find it very odd to think/expect a person would load of of this SW onto their main PC/Laptop.  Also, a large amount sugar coating and theory on the YouTube Tensorflow guides  (Josh G. nice detail, grateful you have no tin cup out).  But, there is a disservice in hiding technical details and steps. Do you think non-tech folks going to pick this up, not likely.  FYI..if you do not know structured tables vs non, do not tell them to jump into the pool.\r\n\r\nQuestion- Can you advise if I build from source, will the CPU chip AVX be accounted for?  I am running Tensorflow 1.5 successfully , but not sure is Sahre prject will support that version\r\n\r\nThank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n------------\r\nThanks in advance.\r\n\r\nTH", "comments": ["@tomthumb99 \r\nIn order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose),Please make sure you are using TF v2.4 and later as TF v1.x is no longer actively supported.Please refer [this](https://www.tensorflow.org/install/source) link as well.\r\nThanks!", ">Can you advise if I build from source, will the CPU chip AVX be accounted for?\r\n\r\nAFAIK, that was broken before (the build was failing when AVX was disabled in the build configuration). Not sure whether it was fixed.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54207\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54207\">No</a>\n", "@tomthumb99 Could you please refer to the above [comment  ](https://github.com/tensorflow/tensorflow/issues/54207#issuecomment-1025413560) and let us know the update on that ?Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54207\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54207\">No</a>\n"]}, {"number": 54206, "title": "Is there any way to decrease tensorflow lite invoke time on windows 10 ?  ", "body": "**System information**\r\n- windows 10, x64\r\n- TensorFlow version: 2.7.0\r\n- Python version: 3.9.5\r\n- Bazel version : 3.7.2\r\n- GCC/Compiler version : 11.2.0\r\n- xnnpack : enable\r\n\r\nI run a custom CNN tflite model on tensorflow lite using c++ where  i got invoke time 2.5 second and same tensorflow model version i run on python where i got 1.19 second . As i know c++ is more faster than python then what is the issue ?\r\nNote : because of commercial reason i can't give the code snapshot.\r\n\r\n\r\n\r\n", "comments": ["@sazzad15-1779 ,\r\nThis question is better asked on [TensorFlow Forum](https://discuss.tensorflow.org/) since it is not a bug or feature request. There is also a larger community that reads questions there.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54206\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54206\">No</a>\n"]}, {"number": 54205, "title": "Disable flaky test", "body": null, "comments": []}]