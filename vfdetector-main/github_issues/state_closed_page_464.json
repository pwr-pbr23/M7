[{"number": 39896, "title": "MutableDenseHashTable check key entries before Rebucket when Insert", "body": "MutableDenseHashTable Insert operation should check empty  keys before Rebucket, otherwise too much empty  keys may cause the table too large", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39896) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39896) for more info**.\n\n<!-- need_author_cla -->", "@rangjiaheng  Thank you for your contribution. Can you please sign CLA? Thanks!", "@googlebot I fixed it", "@googlebot I fixed it", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39896) for more info**.\n\n<!-- ok -->", "Sorry, I'll open a new pull request"]}, {"number": 39894, "title": "Keras Mixed Precision Policy and Horovod are incompatible.", "body": "CC: @reedwm @nluehr @tgaddair @cliffwoolley @pkanwar23\r\n\r\nIt seems that Mixed Precision Keras policy is currently in broken state when used combined with Horovod. If you use the test repository, you can reproduce the issue (you will need 2+ GPUs) https://github.com/DEKHTIARJonathan/TF_HVD_Stability_Test.\r\n\r\nThe issues comes by the sequence of operations:\r\n1. set_visible_devices()\r\n2. define Keras Policy\r\n\r\n**Reproducible Test Case:**\r\n\r\n```bash\r\n#!/usr/bin/env bash\r\n\r\nexport HOROVOD_GPU_ALLREDUCE=NCCL\r\nexport HOROVOD_GPU_BROADCAST=NCCL\r\nexport HOROVOD_NCCL_INCLUDE=/usr/include\r\nexport HOROVOD_NCCL_LIB=/usr/lib/x86_64-linux-gnu\r\nexport HOROVOD_NCCL_LINK=SHARED\r\nexport HOROVOD_WITHOUT_PYTORCH=1\r\nexport HOROVOD_WITHOUT_MXNET=1\r\nexport HOROVOD_WITH_TENSORFLOW=1\r\nexport HOROVOD_WITH_MPI=1\r\nexport HOROVOD_BUILD_ARCH_FLAGS=\"-march=sandybridge -mtune=broadwell\"\r\npip uninstall horovod -y\r\npip install --no-cache --no-cache-dir horovod==0.19.3\r\n\r\ngit clone https://github.com/DEKHTIARJonathan/TF_HVD_Stability_Test.git\r\ncd TF_HVD_Stability_Test \r\n\r\npip install -r requirements.txt\r\npytest\r\n```\r\n\r\n**Will give the following result:**\r\n\r\n```bash\r\nplatform linux -- Python 3.6.9, pytest-5.4.2, py-1.8.1, pluggy-0.13.1 -- /usr/bin/python\r\ncachedir: .pytest_cache\r\nrootdir: /workspace, inifile: pytest.ini\r\nplugins: typeguard-2.7.1\r\ncollected 18 items                                                                                                                                                                                           \r\ntest.py::HorovodTest::test_example_00_RN50_Gradient_Tape_HVD_1GPU PASSED                                                         [  5%]\r\ntest.py::HorovodTest::test_example_01_RN50_Gradient_Tape_HVD_AMP_1GPU PASSED                                                     [ 11%]\r\ntest.py::HorovodTest::test_example_02_RN50_Gradient_Tape_HVD_AMP_FP16_All_Reduce_1GPU PASSED                                     [ 16%]\r\ntest.py::HorovodTest::test_example_03_RN50_Gradient_Tape_HVD_2GPUs PASSED                                                        [ 22%]\r\ntest.py::HorovodTest::test_example_04_RN50_Gradient_Tape_HVD_AMP_2GPUs FAILED                                                    [ 27%]        # ======> FAILS\r\ntest.py::HorovodTest::test_example_05_RN50_Gradient_Tape_HVD_AMP_FP16_All_Reduce_2GPUs FAILED                                    [ 33%]        # ======> FAILS\r\ntest.py::HorovodTest::test_example_06_keras_Sequential_CTL_Gradient_Tape_HVD_1GPU PASSED                                         [ 38%]\r\ntest.py::HorovodTest::test_example_07_keras_Sequential_CTL_Gradient_Tape_HVD_AMP_1GPU PASSED                                     [ 44%]\r\ntest.py::HorovodTest::test_example_08_keras_Sequential_CTL_Gradient_Tape_HVD_AMP_FP16_All_Reduce_1GPU PASSED                     [ 50%]\r\ntest.py::HorovodTest::test_example_09_keras_Sequential_CTL_Gradient_Tape_HVD_2GPUs PASSED                                        [ 55%]\r\ntest.py::HorovodTest::test_example_10_keras_Sequential_CTL_Gradient_Tape_HVD_AMP_2GPUs FAILED                                    [ 61%]        # ======> FAILS\r\ntest.py::HorovodTest::test_example_11_keras_Sequential_CTL_Gradient_Tape_HVD_AMP_FP16_All_Reduce_2GPUs FAILED                    [ 66%]        # ======> FAILS\r\ntest.py::HorovodTest::test_example_12_keras_fit_compile_Gradient_Tape_HVD_1GPU PASSED                                            [ 72%]\r\ntest.py::HorovodTest::test_example_13_keras_fit_compile_Gradient_Tape_HVD_AMP_1GPU PASSED                                        [ 77%]\r\ntest.py::HorovodTest::test_example_14_keras_fit_compile_Gradient_Tape_HVD_AMP_FP16_All_Reduce_1GPU PASSED                        [ 83%]\r\ntest.py::HorovodTest::test_example_15_keras_fit_compile_Gradient_Tape_HVD_2GPUs PASSED                                           [ 88%]\r\ntest.py::HorovodTest::test_example_16_keras_fit_compile_Gradient_Tape_HVD_AMP_2GPUs FAILED                                       [ 94%]        # ======> FAILS\r\ntest.py::HorovodTest::test_example_17_keras_fit_compile_Gradient_Tape_HVD_AMP_FP16_All_Reduce_2GPUs FAILED                       [100%]        # ======> FAILS\r\n```\r\n\r\n**If we look at the traceback, the error is quite explicit:**\r\n\r\n```python\r\n[1,1]<stderr>:Traceback (most recent call last):\r\n[1,1]<stderr>:  File \"examples/tf2_FitCompile_GradientTape.py\", line 49, in <module>\r\n[1,1]<stderr>:    policy = mixed_precision.Policy('mixed_float16')\r\n[1,1]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/mixed_precision/experimental/policy.py\", line 349, in __init__\r\n[1,1]<stderr>:    skip_local=True)\r\n[1,1]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/mixed_precision/experimental/device_compatibility_check.py\", line 157, in log_device_compatibility_check\r\n[1,1]<stderr>:    device_attr_list = device_lib.list_local_devices()\r\n[1,1]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/device_lib.py\", line 43, in list_local_devices\r\n[1,1]<stderr>:    _convert(s) for s in _pywrap_device_lib.list_devices(serialized_config)\r\n[1,1]<stderr>:RuntimeError: TensorFlow device (GPU:0) is being mapped to multiple CUDA devices (0 now, and 1 previously), which is not supported. This may be the result of providing different GPU configurations (ConfigProto.gpu_options, for example different visible_device_list) when creating multiple Sessions in the same process. This is not  currently supported, see https://github.com/tensorflow/tensorflow/issues/19083\r\n```\r\n\r\n@reedwm so far I can see that you found a somehow linked issue: https://github.com/tensorflow/tensorflow/commit/f748283ee01059be52da5dada6e2157d9f6732ba\r\nUnfortunately, this is not solve and is something really limiting.\r\n\r\nTo \"hot fix\" the issue, you can just comment these lines: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/mixed_precision/experimental/policy.py#L339-L341\r\n\r\nHowever, I suppose that you may want to fix the issue more \"cleanly\".\r\n\r\n@pkanwar23: one more example why we need the horovod unittests.", "comments": ["I think this is fixed in 2730e4b0bcba80799ddc10f52081927848540f30. Unfortunately, this commit didn't make it into TF 2.2. I commented a very hacky workaround in [this comment](https://github.com/tensorflow/tensorflow/issues/38516#issuecomment-613712149).", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39894\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39894\">No</a>\n"]}, {"number": 39893, "title": "[INTEL MKL] Removing OpenMP dependency from Mkl-dnn supporting threadpool", "body": "", "comments": ["@sshiddib Can you please check @penpornk's comments and keep us posted. Thanks!", "@penpornk @gbaned I tried the failing tests locally in my machine and I could't reproduce the failures.  "]}, {"number": 39892, "title": "TF 2.0 using tf.keras - Custom Loss w/ Multiple Output Model - AttributeError: 'Tensor' object has no attribute 'numpy' raised during training", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Catalina 10.15.4\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.3.0-dev20200526\r\n- Python version: 3.6.9\r\n- (in Google Colab - my available devices are: '/physical_device:CPU:0', '/physical_device:XLA_CPU:0', '/physical_device:XLA_GPU:0', '/physical_device:GPU:0')\r\n\r\n**Describe the current behavior**\r\n\r\nI'm implementing a model for source separation. It requires: \r\n- Two outputs (the time-frequency representation of each source)\r\n- Custom loss function\r\n\r\nThe current behavior is: `AttributeError: 'Tensor' object has no attribute 'numpy'.`\r\nAs suggested in similar #38038, I tried converting my x, y's into tensors, ensuring eager execution, executing the code on tf nightly, but no avail.\r\nDummy code that replicates this and the full log is shown below.\r\n\r\n**Describe the expected behavior**\r\n\r\nMy goal is to implement this loss function (described in this [paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6853860&tag=1)):\r\n<img width=\"344\" alt=\"po-sen_loss_func\" src=\"https://user-images.githubusercontent.com/25238854/82953031-4ec1e800-9f67-11ea-8506-4918e4a6ca8c.png\">\r\n\r\nThe tricky part is that for an output, along with accessing the other output's predictions, I also need to access the other's targets in the loss function. I do this by passing the targets into both x and y params of model.fit() This may not be the problem's cause but I mention it just in case \ud83e\udd37\u200d\u2642\ufe0f\r\n\r\nDoes anyone know how to solve this? I super appreciate it!\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\n!pip install tf_nightly\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import backend as K\r\nfrom tensorflow.keras.layers import Input, SimpleRNN, Dense, Lambda, TimeDistributed\r\nfrom tensorflow.keras.models import Model\r\nimport numpy as np\r\n\r\n\r\nprint('Tensorflow version:', tf.__version__)\r\ntf.config.run_functions_eagerly(True)\r\nprint('Eager execution enabled?', tf.executing_eagerly())\r\n\r\ndef make_model(input_data, features, loss_const, batch_size):\r\n\r\n    input_layer = Input(batch_shape=(batch_size, \r\n                                     input_data.shape[-2], \r\n                                     input_data.shape[-1]),\r\n                        dtype='float32', name='piano_noise_mixed')\r\n    x = SimpleRNN(features // 2, \r\n                  activation='relu', \r\n                  return_sequences=True) (input_layer)\r\n    x = SimpleRNN(features // 2, \r\n                  activation='relu',\r\n                  return_sequences=True) (x)\r\n\r\n    piano_hat = TimeDistributed(Dense(features)) (x)  # source 1 branch\r\n    noise_hat = TimeDistributed(Dense(features)) (x)  # source 2 branch\r\n\r\n    piano_pred = Lambda(lambda y: soft_mask(y, noise_hat, input_layer, \r\n                                            piano_flag=True), \r\n                        name='piano_pred') (piano_hat)\r\n    noise_pred = Lambda(lambda y: soft_mask(y, piano_hat, input_layer,\r\n                                            piano_flag=False), \r\n                        name='noise_pred') (noise_hat)\r\n\r\n    # Two additional 'keras funtional API inputs' for the labels\r\n    piano_label_layer = Input(batch_shape=(batch_size, \r\n                                     input_data.shape[-2], \r\n                                     input_data.shape[-1]),\r\n                              dtype='float32', name='piano_true')\r\n    noise_label_layer = Input(batch_shape=(batch_size, \r\n                                     input_data.shape[-2], \r\n                                     input_data.shape[-1]),\r\n                              dtype='float32', name='noise_true')\r\n    \r\n    print('X shape (inside NN):', input_layer.shape, \r\n          'y1 shape (inside NN):', piano_label_layer.shape, \r\n          'y2 shape (inside NN):', noise_label_layer.shape)\r\n\r\n    model = Model(inputs=[input_layer, piano_label_layer, noise_label_layer],\r\n                  outputs=[piano_pred, noise_pred])\r\n\r\n    model.compile(optimizer='rmsprop',\r\n                  loss={'piano_pred': source_sep_loss(other_pred=noise_pred, \r\n                                           other_true=noise_label_layer,\r\n                                           loss_const=loss_const,\r\n                                           piano_flag=True),\r\n                        'noise_pred': source_sep_loss(other_pred=piano_pred,\r\n                                           other_true=piano_label_layer,\r\n                                           loss_const=loss_const,\r\n                                           piano_flag=False)},\r\n                  run_eagerly=True)\r\n\r\n    return model\r\n\r\ndef source_sep_loss(other_pred, other_true, loss_const, piano_flag=False):\r\n    def loss_func(y_true, y_pred):\r\n        last_dim = y_pred.shape[1] * y_pred.shape[2]\r\n        if piano_flag:  # y_true = piano labels, y_pred = piano pred\r\n            loss = (                \r\n                K.sum(K.reshape(y_pred - y_true, shape=(-1, last_dim)) ** 2, axis=-1) -\r\n                (loss_const * K.sum(K.reshape(y_pred - other_true, shape=(-1, last_dim)) ** 2, axis=-1)) +\r\n                K.sum(K.reshape(other_pred - other_true, shape=(-1, last_dim)) ** 2, axis=-1) -\r\n                (loss_const * K.sum(K.reshape(other_pred - y_true, shape=(-1, last_dim)) ** 2, axis=-1)))\r\n        else:           # y_true = noise labels, y_pred = noise pred\r\n            loss = (\r\n                K.sum(K.reshape(other_pred - other_true, shape=(-1, last_dim)) ** 2, axis=-1) -\r\n                (loss_const * K.sum(K.reshape(other_pred - y_true, shape=(-1, last_dim)) ** 2, axis=-1)) +\r\n                K.sum(K.reshape(y_pred - y_true, shape=(-1, last_dim)) ** 2, axis=-1) -\r\n                (loss_const * K.sum(K.reshape(y_pred - other_true, shape=(-1, last_dim)) ** 2, axis=-1)))\r\n        return loss\r\n    return loss_func\r\n\r\ndef soft_mask(y_hat_self, y_hat_other, x_mixed, piano_flag):\r\n    mask = y_hat_self / (y_hat_self + y_hat_other)\r\n    ones = tf.convert_to_tensor(np.ones(mask.shape).astype('float32'))\r\n    y_tilde_self = mask * x_mixed if (piano_flag) else (ones - mask) * x_mixed\r\n\r\n    return y_tilde_self\r\n\r\n\r\ntotal_samples = 6\r\nbatch_size = 2\r\ntime_steps = 3\r\nfeatures = 4\r\nloss_const = 2\r\nepochs = 10\r\nval_split = 0.25\r\n\r\nX = tf.convert_to_tensor(np.random.rand(total_samples, time_steps, features))\r\ny1 = tf.convert_to_tensor(np.random.rand(total_samples, time_steps, features))\r\ny2 = tf.convert_to_tensor(np.random.rand(total_samples, time_steps, features))\r\nprint('X shape:', X.shape, 'y1 shape:', y1.shape, 'y2 shape:', y2.shape)\r\n\r\nmodel = make_model(X, features, loss_const, batch_size)\r\nprint(model.summary())\r\n\r\nmodel.fit({'piano_noise_mixed': X, 'piano_true': y1, 'noise_true': y2},\r\n          {'piano_pred': y1, 'noise_pred': y2},\r\n          validation_split=val_split,\r\n          epochs=epochs, batch_size=batch_size)\r\n```\r\n\r\n**Other info / logs**\r\n```\r\nRequirement already satisfied: tf_nightly in /usr/local/lib/python3.6/dist-packages (2.3.0.dev20200526)\r\nRequirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.1.2)\r\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (3.2.1)\r\nRequirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (2.10.0)\r\nRequirement already satisfied: tb-nightly<2.4.0a0,>=2.3.0a0 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (2.3.0a20200526)\r\nRequirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (0.2.0)\r\nRequirement already satisfied: tf-estimator-nightly in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (2.3.0.dev2020052101)\r\nRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.12.1)\r\nRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.4.1)\r\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.1.0)\r\nRequirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.6.3)\r\nRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (0.9.0)\r\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.12.0)\r\nRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (3.10.0)\r\nRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.29.0)\r\nRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (0.34.2)\r\nRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.18.4)\r\nRequirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (0.3.3)\r\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (2.23.0)\r\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (1.6.0.post3)\r\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (3.2.2)\r\nRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (46.3.0)\r\nRequirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (1.7.2)\r\nRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (1.0.1)\r\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (0.4.1)\r\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (1.24.3)\r\nRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (3.0.4)\r\nRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (2.9)\r\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (2020.4.5.1)\r\nRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (1.6.0)\r\nRequirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (3.1.1)\r\nRequirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (4.0)\r\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (0.2.8)\r\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (1.3.0)\r\nRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (3.1.0)\r\nRequirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (0.4.8)\r\nRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.4.0a0,>=2.3.0a0->tf_nightly) (3.1.0)\r\nTensorflow version: 2.3.0-dev20200526\r\nEager execution enabled? True\r\nX shape: (6, 3, 4) y1 shape: (6, 3, 4) y2 shape: (6, 3, 4)\r\nX shape (inside NN): (2, 3, 4) y1 shape (inside NN): (2, 3, 4) y2 shape (inside NN): (2, 3, 4)\r\nModel: \"functional_1\"\r\n__________________________________________________________________________________________________\r\nLayer (type)                    Output Shape         Param #     Connected to                     \r\n==================================================================================================\r\npiano_noise_mixed (InputLayer)  [(2, 3, 4)]          0                                            \r\n__________________________________________________________________________________________________\r\nsimple_rnn (SimpleRNN)          (2, 3, 2)            14          piano_noise_mixed[0][0]          \r\n__________________________________________________________________________________________________\r\nsimple_rnn_1 (SimpleRNN)        (2, 3, 2)            10          simple_rnn[0][0]                 \r\n__________________________________________________________________________________________________\r\ntime_distributed (TimeDistribut (2, 3, 4)            12          simple_rnn_1[0][0]               \r\n__________________________________________________________________________________________________\r\ntime_distributed_1 (TimeDistrib (2, 3, 4)            12          simple_rnn_1[0][0]               \r\n__________________________________________________________________________________________________\r\npiano_true (InputLayer)         [(2, 3, 4)]          0                                            \r\n__________________________________________________________________________________________________\r\nnoise_true (InputLayer)         [(2, 3, 4)]          0                                            \r\n__________________________________________________________________________________________________\r\npiano_pred (Lambda)             (2, 3, 4)            0           time_distributed[0][0]           \r\n__________________________________________________________________________________________________\r\nnoise_pred (Lambda)             (2, 3, 4)            0           time_distributed_1[0][0]         \r\n==================================================================================================\r\nTotal params: 48\r\nTrainable params: 48\r\nNon-trainable params: 0\r\n__________________________________________________________________________________________________\r\nNone\r\nEpoch 1/10\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3274: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\r\n  \"Even though the tf.config.experimental_run_functions_eagerly \"\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-1-36baddb059fc> in <module>()\r\n    114           {'piano_pred': y1, 'noise_pred': y2},\r\n    115           validation_split=val_split,\r\n--> 116           epochs=epochs, batch_size=batch_size)\r\n\r\n15 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)\r\n    106   def _method_wrapper(self, *args, **kwargs):\r\n    107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access\r\n--> 108       return method(self, *args, **kwargs)\r\n    109 \r\n    110     # Running inside `run_distribute_coordinator` already.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n   1088                 batch_size=batch_size):\r\n   1089               callbacks.on_train_batch_begin(step)\r\n-> 1090               tmp_logs = train_function(iterator)\r\n   1091               if data_handler.should_sync:\r\n   1092                 context.async_wait()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in train_function(iterator)\r\n    801       def train_function(iterator):\r\n    802         \"\"\"Runs a training execution with one step.\"\"\"\r\n--> 803         return step_function(self, iterator)\r\n    804 \r\n    805     else:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in step_function(model, iterator)\r\n    791 \r\n    792       data = next(iterator)\r\n--> 793       outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n    794       outputs = reduce_per_replica(\r\n    795           outputs, self.distribute_strategy, reduction='first')\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py in run(***failed resolving arguments***)\r\n    967       fn = autograph.tf_convert(\r\n    968           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\r\n--> 969       return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    970 \r\n    971   # TODO(b/151224785): Remove deprecated alias.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py in call_for_each_replica(self, fn, args, kwargs)\r\n   2350       kwargs = {}\r\n   2351     with self._container_strategy().scope():\r\n-> 2352       return self._call_for_each_replica(fn, args, kwargs)\r\n   2353 \r\n   2354   def _call_for_each_replica(self, fn, args, kwargs):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py in _call_for_each_replica(self, fn, args, kwargs)\r\n   2709         self._container_strategy(),\r\n   2710         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\r\n-> 2711       return fn(*args, **kwargs)\r\n   2712 \r\n   2713   def _reduce_to(self, reduce_op, value, destinations, experimental_hints):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py in wrapper(*args, **kwargs)\r\n    273   def wrapper(*args, **kwargs):\r\n    274     with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.UNSPECIFIED):\r\n--> 275       return func(*args, **kwargs)\r\n    276 \r\n    277   if inspect.isfunction(func) or inspect.ismethod(func):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in run_step(data)\r\n    784 \r\n    785       def run_step(data):\r\n--> 786         outputs = model.train_step(data)\r\n    787         # Ensure counter is updated only if `train_step` succeeds.\r\n    788         with ops.control_dependencies(_minimum_control_deps(outputs)):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in train_step(self, data)\r\n    752     # such as loss scaling and gradient clipping.\r\n    753     _minimize(self.distribute_strategy, tape, self.optimizer, loss,\r\n--> 754               self.trainable_variables)\r\n    755 \r\n    756     self.compiled_metrics.update_state(y, y_pred, sample_weight)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _minimize(strategy, tape, optimizer, loss, trainable_variables)\r\n   2672       loss = optimizer.get_scaled_loss(loss)\r\n   2673 \r\n-> 2674   gradients = tape.gradient(loss, trainable_variables)\r\n   2675 \r\n   2676   # Whether to aggregate gradients outside of optimizer. This requires support\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py in gradient(self, target, sources, output_gradients, unconnected_gradients)\r\n   1057         output_gradients=output_gradients,\r\n   1058         sources_raw=flat_sources_raw,\r\n-> 1059         unconnected_gradients=unconnected_gradients)\r\n   1060 \r\n   1061     if not self._persistent:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/imperative_grad.py in imperative_grad(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\r\n     75       output_gradients,\r\n     76       sources_raw,\r\n---> 77       compat.as_str(unconnected_gradients.value))\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py in _gradient_function(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\r\n    154       gradient_name_scope += forward_pass_name_scope + \"/\"\r\n    155     with ops.name_scope(gradient_name_scope):\r\n--> 156       return grad_fn(mock_op, *out_grads)\r\n    157   else:\r\n    158     return grad_fn(mock_op, *out_grads)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py in _SumGrad(op, grad)\r\n    209       # more sense.\r\n    210       output_shape_kept_dims = math_ops.reduced_shape(input_shape,\r\n--> 211                                                       op.inputs[1])\r\n    212     grad = array_ops.reshape(grad, output_shape_kept_dims)\r\n    213   return [array_ops.broadcast_to(grad, input_shape), None]\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py in reduced_shape(input_shape, axes)\r\n   3807   \"\"\"\r\n   3808   if context.executing_eagerly():\r\n-> 3809     input_shape = input_shape.numpy()\r\n   3810     axes = axes.numpy()\r\n   3811     input_shape[axes] = 1\r\n\r\nAttributeError: 'Tensor' object has no attribute 'numpy'\r\n```", "comments": ["Was able to reproduce the issue with [TF v2.2](https://colab.research.google.com/gist/amahendrakar/ab7031d4e9e3311eab41d2d59f29d778/39892.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/12c26d032d116dfb761a927cd4ea6cc6/39892-tf-nightly.ipynb). Please find the attached gist. Thanks!", "I was able to resolve this by: \r\n1) Converting my lambda layers into custom layers.\r\n2) Converting my method from making a tricky nested loss function (I think it's now deprecated) and assigning it to each output in model.compile(), into creating a single loss tensor and passing it into model.add_loss(). \r\n\r\nIt seems that this error appeared when either of these things were as they were before my fix. If anyone wants more specific look at my solution I'll post code.", "> I was able to resolve this by:\r\n> \r\n> 1. Converting my lambda layers into custom layers.\r\n> 2. Converting my method from making a tricky nested loss function (I think it's now deprecated) and assigning it to each output in model.compile(), into creating a single loss tensor and passing it into model.add_loss().\r\n> \r\n> It seems that this error appeared when either of these things were as they were before my fix. If anyone wants more specific look at my solution I'll post code.\r\n\r\nCan you post the solution, thank you. ", "> > I was able to resolve this by:\r\n> > \r\n> > 1. Converting my lambda layers into custom layers.\r\n> > 2. Converting my method from making a tricky nested loss function (I think it's now deprecated) and assigning it to each output in model.compile(), into creating a single loss tensor and passing it into model.add_loss().\r\n> > \r\n> > It seems that this error appeared when either of these things were as they were before my fix. If anyone wants more specific look at my solution I'll post code.\r\n> \r\n> Can you post the solution, thank you.\r\n\r\nHere, don't pass your loss into model.add_loss() if it feels clunky to you, b/c it did for me. Instead concatenate your outputs together which lets you pass your custom loss into model.compile(). Then deal with the outputs in the custom loss function.\r\n\r\n```\r\nclass TimeFreqMasking(Layer):\r\n    # Init is for input-independent variables\r\n    def __init__(self, epsilon, **kwargs):\r\n        super(TimeFreqMasking, self).__init__(**kwargs)\r\n        self.epsilon = epsilon\r\n\r\n    # No build method, b/c passing in multiple inputs to layer (no single shape)\r\n\r\n    def call(self, inputs):\r\n        y_hat_self, y_hat_other, x_mixed = inputs\r\n        mask = tf.abs(y_hat_self) / (tf.abs(y_hat_self) + tf.abs(y_hat_other) + self.epsilon)\r\n        y_tilde_self = mask * x_mixed\r\n        return y_tilde_self\r\n\r\n\r\ndef discrim_loss(y_true, y_pred):\r\n    piano_true, noise_true = tf.split(y_true, num_or_size_splits=2, axis=-1)\r\n    loss_const = y_pred[-1, :, :][0][0]\r\n    piano_pred, noise_pred = tf.split(y_pred[:-1, :, :], num_or_size_splits=2, axis=0)\r\n\r\n    last_dim = piano_pred.shape[1] * piano_pred.shape[2]\r\n    return (\r\n        tf.math.reduce_mean(tf.reshape(noise_pred - noise_true, shape=(-1, last_dim)) ** 2) - \r\n        (loss_const * tf.math.reduce_mean(tf.reshape(noise_pred - piano_true, shape=(-1, last_dim)) ** 2)) +\r\n        tf.math.reduce_mean(tf.reshape(piano_pred - piano_true, shape=(-1, last_dim)) ** 2) -\r\n        (loss_const * tf.math.reduce_mean(tf.reshape(piano_pred - noise_true, shape=(-1, last_dim)) ** 2))\r\n    )\r\n\r\n\r\ndef make_model(features, sequences, epsilon, loss_const):\r\n    input_layer = Input(shape=(sequences, features), name='piano_noise_mixed')\r\n    x = SimpleRNN(features // 2, \r\n                activation='relu', \r\n                return_sequences=True) (input_layer) \r\n    x = SimpleRNN(features // 2, \r\n            activation='relu',\r\n            return_sequences=True) (x)\r\n    piano_hat = TimeDistributed(Dense(features), name='piano_hat') (x)  # source 1 branch\r\n    noise_hat = TimeDistributed(Dense(features), name='noise_hat') (x)  # source 2 branch\r\n    piano_pred = TimeFreqMasking(epsilon=epsilon, \r\n                                name='piano_pred') ((piano_hat, noise_hat, input_layer))\r\n    noise_pred = TimeFreqMasking(epsilon=epsilon, \r\n                                name='noise_pred') ((noise_hat, piano_hat, input_layer))\r\n\r\n    preds_and_gamma = Concatenate(axis=0) ([piano_pred, \r\n                                        noise_pred, \r\n                                        #  loss_const_tensor\r\n                                        tf.broadcast_to(tf.constant(loss_const), [1, sequences, features])\r\n                                        ])\r\n    model = Model(inputs=input_layer, outputs=preds_and_gamma)\r\n    model.compile(optimizer=optimizer, loss=discrim_loss)\r\n    return model\r\n\r\n\r\ndef dummy_generator(num_samples, batch_size, num_seq, num_feat):\r\n    while True:\r\n        for _ in range(0, num_samples, batch_size):\r\n            x, y1, y2 = (np.random.rand(batch_size, num_seq, num_feat),\r\n                        np.random.rand(batch_size, num_seq, num_feat),\r\n                        np.random.rand(batch_size, num_seq, num_feat))\r\n\r\n            yield ([x, np.concatenate((y1, y2), axis=-1)])\r\n\r\n\r\ntotal_samples = 6\r\nbatch_size = 2\r\ntime_steps = 3\r\nfeatures = 4\r\nloss_const = 2\r\nepochs = 10\r\nval_split = 0.25\r\nepsilon = 10 ** (-10)\r\n\r\nmodel = make_model(features, time_steps, epsilon, loss_const)\r\nprint(model.summary())\r\n\r\nnum_val = math.ceil(actual_samples * val_split)\r\nnum_train = total_samples - val_samples\r\ntrain_dataset = dummy_generator(num_train, batch_size, time_steps, features)\r\nval_dataset = dummy_generator(num_val, batch_size, time_steps, features)\r\n\r\nmodel.fit(train_dataset,\r\n                steps_per_epoch=math.ceil(num_train / batch_size),\r\n                epochs=epochs,\r\n                validation_data=val_dataset,\r\n                validation_steps=math.ceil(num_val / batch_size)\r\n\r\n```"]}, {"number": 39891, "title": "TF2.2 ImportError: cannot import name 'dense_features'", "body": "When importing hooks_helper from official, see the following issue pop up.\r\n\r\nTraceback (most recent call last):\r\n  File \"inference/fp32/wide_deep_inference.py\", line 46, in <module>\r\n    from official.utils.logs import hooks_helper\r\n  File \"/nfs/site/home/jojimonv/CIMonitor/Models/new/models/official/utils/logs/hooks_helper.py\", line 29, in <module>\r\n    from official.utils.logs import hooks\r\n  File \"/nfs/site/home/jojimonv/CIMonitor/Models/new/models/official/utils/logs/hooks.py\", line 26, in <module>\r\n    class ExamplesPerSecondHook(tf.estimator.SessionRunHook):\r\n  File \"/ec/pdx/disks/aipg_lab_home_pool_02/jojimonv/tfv2_new/lib/python3.6/site-packages/tensorflow/python/util/lazy_loader.py\", line 62, in __getattr__\r\n    module = self._load()\r\n  File \"/ec/pdx/disks/aipg_lab_home_pool_02/jojimonv/tfv2_new/lib/python3.6/site-packages/tensorflow/python/util/lazy_loader.py\", line 45, in _load\r\n    module = importlib.import_module(self.__name__)\r\n  File \"/usr/lib/python3.6/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"/ec/pdx/disks/aipg_lab_home_pool_02/jojimonv/tfv2_new/lib/python3.6/site-packages/tensorflow_estimator/__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator._api.v1 import estimator\r\n  File \"/ec/pdx/disks/aipg_lab_home_pool_02/jojimonv/tfv2_new/lib/python3.6/site-packages/tensorflow_estimator/_api/v1/estimator/__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator._api.v1.estimator import experimental\r\n  File \"/ec/pdx/disks/aipg_lab_home_pool_02/jojimonv/tfv2_new/lib/python3.6/site-packages/tensorflow_estimator/_api/v1/estimator/experimental/__init__.py\", line 10, in <module>\r\n    from tensorflow_estimator.python.estimator.canned.dnn import dnn_logit_fn_builder\r\n  File \"/ec/pdx/disks/aipg_lab_home_pool_02/jojimonv/tfv2_new/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py\", line 23, in <module>\r\n    from tensorflow.python.feature_column import dense_features\r\nImportError: cannot import name 'dense_features'\r\nRunning Wide_Deep model Inference in Latency mode\r\n", "comments": ["Issue is resolved with installing tf-nightly-estimator", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39891\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39891\">No</a>\n"]}, {"number": 39890, "title": "pip install Eigen:AVX512 build", "body": "Is it possible to pip install TF-Eigen-build with AVX512 support?\r\n\r\nI would like to install TF2 on my server and it seems like packages `tensorflow `and `tensorflow`-cpu are not built with AVX512 enabled because I get the following warning.\r\n\r\n`Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA`\r\n\r\nref: [stakoverflow\r\n](https://stackoverflow.com/questions/62015863/how-to-install-tensorflow-2-x-with-eigen-avx512-support)", "comments": ["You will have to build from source or look for a package provided by community.", "okay. Can you please confirm the following build options?\r\n\r\n`bazel build --config=opt --copt=-mavx512f --copt=-mfma //tensorflow/tools/pip_package:build_pip_package`\r\n\r\n", "@cheers00 \r\n\r\nRequest you to fill [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).Thanks!", "All the `--copt` options are the options you would pass to the compiler if not using Bazel. Cannot known if those are exactly the options you need.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing this. I ended up building tensorflow from source. That seems like the only option.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39890\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39890\">No</a>\n", "@cheers00 how did you pass options to eigen?", "@surak I built it using the following command. hope it helps.\r\n\r\n```\r\nbazel build --cxxopt=-D_GLIBCXX_USE_CXX11_ABI=0 -c opt --copt=-mavx \r\n--copt=-mavx2 --copt=-mfma --copt=-mavx512f --copt=-mavx512pf \r\n--copt=-mavx512cd --copt=-mavx512er \r\n//tensorflow/tools/pip_package:build_pip_package\r\n```"]}, {"number": 39889, "title": "Replace list concatenation with generators for auto control deps", "body": "For processing `switch` ops, `AutomaticControlDependencies` iterates over `_get_resource_inputs(op)` at\r\nhttps://github.com/tensorflow/tensorflow/blob/1a93f37e2614b38b3a12f82c9bc25aea9eda3953/tensorflow/python/framework/auto_control_deps.py#L398\r\n\r\nThis allows to make `_get_resource_inputs` a generator which removes the need to create and concatenate two lists as a return value of the function.", "comments": ["@saxenasaurabh Thanks for approving, looks like CI fails on windows. Should I rebase onto master which will likely resolve the failure?"]}, {"number": 39888, "title": "Incompatible shapes using `sample_weight` in Graph execution", "body": "Works fine in Eager. Code + error below; pasted outputs are from a Colab instance with `tf.__version__ == 2.3.0-dev20200526`, also reproduced in 2.2.0 and on Windows 10. No error in TF 1.14.0 Graph.\r\n\r\n<hr>\r\n\r\n**Attempted debug**: Placing below [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/utils/losses_utils.py#L111) (in local install)\r\n\r\n```python\r\nprint(sample_weight)\r\ntry: print(\"sample_weight =\", K.eval(sample_weight))\r\nexcept: pass\r\nprint(loss, '\\n')\r\n```\r\n\r\nyields:\r\n\r\n```python\r\n# EAGER\r\nTensor(\"ExpandDims:0\", shape=(32, 1), dtype=float32)\r\nTensor(\"mean_squared_error/weighted_loss/value:0\", shape=(), dtype=float32)\r\n\r\nTensor(\"ExpandDims:0\", shape=(32, 1), dtype=float32)\r\nTensor(\"mean_squared_error/weighted_loss/value:0\", shape=(), dtype=float32)\r\n\r\n# GRAPH\r\n1.0\r\nsample_weight = 1.0\r\nTensor(\"loss/conv2d_loss/weighted_loss/Mul:0\", shape=(32, 28, 28), dtype=float32)\r\n\r\nTensor(\"conv2d_sample_weights:0\", shape=(None,), dtype=float32)\r\nsample_weight = [1.]\r\nTensor(\"loss_1/conv2d_loss/weighted_loss/Mul:0\", shape=(32, 28, 28), dtype=float32)\r\n```\r\nGraph handles `sample_weight` tensor differently; also see example at bottom.\r\n\r\n<hr>\r\n\r\n**Reproducible code + Error**:\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Input, Conv2D\r\nfrom tensorflow.keras.models import Model\r\ntf.compat.v1.disable_eager_execution()\r\n\r\nbatch_shape = (32, 28, 28, 1)\r\n\r\nipt = Input(batch_shape=batch_shape)\r\nout = Conv2D(filters=1, kernel_size=(1, 1))(ipt)\r\nmodel = Model(ipt, out)\r\nmodel.compile('adam', 'mse')\r\n\r\nx = y = np.random.randn(*batch_shape)\r\nsw = np.ones(len(x))\r\n\r\nmodel.train_on_batch(x, y, sw)\r\n```\r\n\r\n```python\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in __call__(self, *args, **kwargs)\r\n   1470         ret = tf_session.TF_SessionRunCallable(self._session._session,\r\n   1471                                                self._handle, args,\r\n-> 1472                                                run_metadata_ptr)\r\n   1473         if run_metadata:\r\n   1474           proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\nInvalidArgumentError: Incompatible shapes: [32] vs. [32,28,28]\r\n\t [[{{node training/Adam/gradients/gradients/loss_1/conv2d_loss/weighted_loss/Mul_grad/Mul}}]]\r\n```\r\n\r\n<hr>\r\n\r\n**No error case**: both Graph and Eager work fine if output shape is instead 2D.\r\n\r\n<details>\r\n   <summary><b>Example code</b></summary>\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Input, Conv2D, Dense, Flatten\r\nfrom tensorflow.keras.models import Model\r\n\r\ntf.compat.v1.disable_eager_execution()\r\n\r\nbatch_shape = (32, 28, 28, 1)\r\n\r\nipt = Input(batch_shape=batch_shape)\r\nx   = Conv2D(filters=1, kernel_size=(1, 1))(ipt)\r\nx   = Flatten()(x)\r\nout = Dense(10, activation='softmax')(x)\r\nmodel = Model(ipt, out)\r\nmodel.compile('adam', 'categorical_crossentropy')\r\n\r\nx = np.random.randn(*batch_shape)\r\nn_classes, batch_size = 10, 32\r\nclass_labels = np.random.randint(0, n_classes, batch_size)\r\ny = np.eye(n_classes)[class_labels]\r\nsw = np.random.uniform(0, 2, (len(x),))\r\n\r\nmodel.train_on_batch(x, y, sw)\r\n```\r\n```\r\nsample_weight = 1.0\r\nTensor(\"loss/dense_loss/weighted_loss/Mul:0\", shape=(32,), dtype=float32)\r\nTensor(\"dense_sample_weights:0\", shape=(None,), dtype=float32)\r\nsample_weight = [1.]\r\nTensor(\"loss_1/dense_loss/weighted_loss/Mul:0\", shape=(32,), dtype=float32)\r\n```\r\n</details>\r\n\r\n_However_, `sample_weight` still prints `[1.]`, even though we passed in `np.random.uniform(0, 2, ...)`.", "comments": ["Was able to reproduce the issue with [TF v2.2](https://colab.research.google.com/gist/amahendrakar/f7d49ea4f957b3e5e3688553634d13a2/39888.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/1c69ec8d886adeb6d615ba891b280baa/39888-tf-nightly.ipynb). Please find the attached gist. Thanks!", "Was able to reproduce the issue in TF 2.5. Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/8ac76ed981d3a494f37540d725da8f9b/untitled80.ipynb). Thanks!", "While trying to reproduce your issue in `tf2.6` and `tf-nightly(2.8.0-dev20211012)` facing different error, please find the gist [here](https://colab.research.google.com/gist/chunduriv/e48f0a092faf4fec3c103c1c8e391fe9/39888.ipynb),Thanks!\r\n\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Hi There,\n\n This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! \n\n Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39888\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39888\">No</a>\n"]}, {"number": 39887, "title": "Prefer generator expressions over list comprehensions", "body": "This PR replaces list comprehensions that are only used as input to `any()`, `zip()` or to construct dictionaries with generator expressions. This removes the need to instantiate unnecessary lists if the expresion is only consumed as an iterator and in the case of `any` allows the loop to potentially exit early which can improve performance for long iterations.\r\n\r\nMost of the changes are not in a hot code path so this won't noticably improve performance but since the change don't hurt readability I think they are still useful to include.", "comments": []}, {"number": 39886, "title": "Unexpected behaviour of tf.image.convert_image_dtype", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): tf-nightly\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nConvert a `tf.int32` tensor to `tf.float32` seems underflow. As shown in the below code, I think `c` should be the right result, correct me if I am wrong.\r\n\r\n**Describe the expected behavior**\r\nThe `tf.int32` tensorf should be scaled to `[0, 1]`, as documented.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```python\r\na = tf.reshape(tf.range(0, 12), shape=(3, 4))\r\nprint(a)\r\nprint(tf.reduce_mean(a), '\\n')\r\n\r\nb = tf.image.convert_image_dtype(a, dtype=tf.float32)\r\nprint(b)\r\nprint(tf.reduce_mean(b), '\\n')\r\n\r\nc = a / tf.reduce_max(a)\r\nprint(c)\r\nprint(tf.reduce_mean(c))\r\n\r\n# output\r\ntf.Tensor(\r\n[[ 0  1  2  3]\r\n [ 4  5  6  7]\r\n [ 8  9 10 11]], shape=(3, 4), dtype=int32)\r\ntf.Tensor(5, shape=(), dtype=int32) \r\n\r\ntf.Tensor(\r\n[[0.0000000e+00 4.6566129e-10 9.3132257e-10 1.3969839e-09]\r\n [1.8626451e-09 2.3283064e-09 2.7939677e-09 3.2596290e-09]\r\n [3.7252903e-09 4.1909516e-09 4.6566129e-09 5.1222742e-09]], shape=(3, 4), dtype=float32)\r\ntf.Tensor(2.561137e-09, shape=(), dtype=float32) \r\n\r\ntf.Tensor(\r\n[[0.         0.09090909 0.18181818 0.27272727]\r\n [0.36363636 0.45454545 0.54545455 0.63636364]\r\n [0.72727273 0.81818182 0.90909091 1.        ]], shape=(3, 4), dtype=float64)\r\ntf.Tensor(0.5, shape=(), dtype=float64)\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["I think you are correct. Can you compare the behavior on 1.15, 2.0, 2.1 and 2.2 releases so we can know the range where the regression was introduced?", "> I think you are correct. Can you compare the behavior on 1.15, 2.0, 2.1 and 2.2 releases so we can know the range where the regression was introduced?\r\n\r\nIt seems the behaviour is all in this way from 1.15-2.2... I tried all 1.15-2.2.\r\n\r\n```python\r\n# !pip install tensorflow==1.15\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\n# >>> 1.15.0\r\n\r\nsess = tf.Session()\r\n\r\na = tf.reshape(tf.range(0, 12), shape=(3, 4))\r\nprint(sess.run(a))\r\n\r\nb = tf.image.convert_image_dtype(a, dtype=tf.float32)\r\nprint(sess.run(b))\r\n\r\nc = a / tf.reduce_max(a)\r\nprint(sess.run(c))\r\n\r\n[[ 0  1  2  3]\r\n [ 4  5  6  7]\r\n [ 8  9 10 11]]\r\n[[0.0000000e+00 4.6566129e-10 9.3132257e-10 1.3969839e-09]\r\n [1.8626451e-09 2.3283064e-09 2.7939677e-09 3.2596290e-09]\r\n [3.7252903e-09 4.1909516e-09 4.6566129e-09 5.1222742e-09]]\r\n[[0.         0.09090909 0.18181818 0.27272727]\r\n [0.36363636 0.45454545 0.54545455 0.63636364]\r\n [0.72727273 0.81818182 0.90909091 1.        ]]\r\n```", "In this case, this likely is not a regression but a failure on the API.\r\n\r\nCan you try passing in [`saturate=True`](https://cs.opensource.google/tensorflow/tensorflow/+/master:tensorflow/python/ops/image_ops_impl.py;l=2003-2009;drc=158d128323176a3e4abe2538a85569122c4bfa45)?", "> In this case, this likely is not a regression but a failure on the API.\r\n> \r\n> Can you try passing in [`saturate=True`](https://cs.opensource.google/tensorflow/tensorflow/+/master:tensorflow/python/ops/image_ops_impl.py;l=2003-2009;drc=158d128323176a3e4abe2538a85569122c4bfa45)?\r\n\r\nI tried `saturate=True` with TF 1.15 and 2.2. The issue exists in both version:\r\n\r\n```python\r\n# ---tf 1.15\r\nsess = tf.Session()\r\n\r\na = tf.reshape(tf.range(0, 12), shape=(3, 4))\r\nprint(sess.run(a))\r\n\r\nb = tf.image.convert_image_dtype(a, dtype=tf.float32, saturate=True)\r\nprint(sess.run(b))\r\n\r\nc = a / tf.reduce_max(a)\r\nprint(sess.run(c))\r\n\r\n# --- tf 2.2\r\na = tf.reshape(tf.range(0, 12), shape=(3, 4))\r\nprint(a)\r\n\r\nb = tf.image.convert_image_dtype(a, dtype=tf.float32, saturate=True)\r\nprint(b)\r\n\r\nc = a / tf.reduce_max(a)\r\nprint(c)\r\n```\r\n\r\nThe outputs are the same with attached above.", "Thank you for the triage. This is then a bug that we will have to fix, though we also need to make sure we don't break users that depend on the [existing behavior](https://xkcd.com/1172/)", "> Thank you for the triage. This is then a bug that we will have to fix, though we also need to make sure we don't break users that depend on the [existing behavior](https://xkcd.com/1172/)\r\n\r\nCan you explain the expected behavior? It seems the API only works when the conversion belongs to the same family (e.g. int -> int, float -> float). I also tried something below:\r\n\r\n```python\r\nIn [26]: x = [1, 2, 3]\r\n\r\nIn [27]: tf.image.convert_image_dtype(x, dtype=tf.float32, saturate=True)\r\nOut[27]: <tf.Tensor: shape=(3,), dtype=float32, numpy=array([4.6566129e-10, 9.3132257e-10, 1.3969839e-09], dtype=float32)>\r\n\r\nIn [28]: x = [1.0, 2.0, 3.0]\r\n\r\nIn [29]: tf.image.convert_image_dtype(x, dtype=tf.int32, saturate=True)\r\nOut[29]: <tf.Tensor: shape=(3,), dtype=int32, numpy=array([-2147483648, -2147483648, -2147483648], dtype=int32)>\r\n```", "I'll have to look through documentation and code history to get more details than what's already included in the comments.", "The values are normalized by the MAX value of the input data type (as opposed to the MAX pixel value). In the [example](https://github.com/tensorflow/tensorflow/issues/39886#issue-625195528) you've provided, the values are being normalized by int32's max value (2^32/2-1) which is huge, and therefore the output values are tiny.\r\n\r\nI will update the function's API doc with better explanation and examples to help minimize confusion. I will loop back once it lands.", "Here is the commit that adds better explanation and examples for `convert_image_dtype` function: https://github.com/tensorflow/tensorflow/commit/f577e5a128324f8708f9925d7035560e72bfb98f\r\nIt will be officially available on tensorflow.org with v2.4.0 API doc. (For now, please refer to the docstring.)\r\nI will go ahead and close the issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39886\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39886\">No</a>\n"]}, {"number": 39885, "title": "object of type <class 'numpy.float64'> cannot be safely interpreted as an integer", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution : Linux Ubuntu 18.04\r\n\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.15.0\r\n- Python version: 3.7.4 \r\n\r\n- CUDA/cuDNN version: 10.2 \r\n- GPU model and memory: GeForce GTX 1050\r\n\r\n\r\n\r\n**Describe the current behavior**\r\nhey guys, i'm trying to train an object detection 3 classes model using resnet101 faster rcnn using model_main.py from object detection api,\r\nlabel map : \r\n\r\n```\r\nitem {\r\n  id: 1\r\n  name: 'ooredoo'\r\n  id: 2\r\n  name: 'tt'\r\n  id: 3\r\n  name: 'orange'\r\n}\r\n```\r\n\r\nconfig file  : \r\n\r\n```\r\n# Faster R-CNN with Resnet-101 (v1), configuration for MSCOCO Dataset.\r\n# Users should configure the fine_tune_checkpoint field in the train config as\r\n# well as the label_map_path and input_path fields in the train_input_reader and\r\n# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\r\n# should be configured.\r\n\r\nmodel {\r\n  faster_rcnn {\r\n    num_classes: 3\r\n    image_resizer {\r\n      keep_aspect_ratio_resizer {\r\n        min_dimension: 600\r\n        max_dimension: 1024\r\n      }\r\n    }\r\n    feature_extractor {\r\n      type: 'faster_rcnn_resnet101'\r\n      first_stage_features_stride: 16\r\n    }\r\n    first_stage_anchor_generator {\r\n      grid_anchor_generator {\r\n        scales: [0.25, 0.5, 1.0, 2.0]\r\n        aspect_ratios: [0.5, 1.0, 2.0]\r\n        height_stride: 16\r\n        width_stride: 16\r\n      }\r\n    }\r\n    first_stage_box_predictor_conv_hyperparams {\r\n      op: CONV\r\n      regularizer {\r\n        l2_regularizer {\r\n          weight: 0.0\r\n        }\r\n      }\r\n      initializer {\r\n        truncated_normal_initializer {\r\n          stddev: 0.01\r\n        }\r\n      }\r\n    }\r\n    first_stage_nms_score_threshold: 0.0\r\n    first_stage_nms_iou_threshold: 0.7\r\n    first_stage_max_proposals: 300\r\n    first_stage_localization_loss_weight: 2.0\r\n    first_stage_objectness_loss_weight: 1.0\r\n    initial_crop_size: 14\r\n    maxpool_kernel_size: 2\r\n    maxpool_stride: 2\r\n    second_stage_box_predictor {\r\n      mask_rcnn_box_predictor {\r\n        use_dropout: false\r\n        dropout_keep_probability: 1.0\r\n        fc_hyperparams {\r\n          op: FC\r\n          regularizer {\r\n            l2_regularizer {\r\n              weight: 0.0\r\n            }\r\n          }\r\n          initializer {\r\n            variance_scaling_initializer {\r\n              factor: 1.0\r\n              uniform: true\r\n              mode: FAN_AVG\r\n            }\r\n          }\r\n        }\r\n      }\r\n    }\r\n    second_stage_post_processing {\r\n      batch_non_max_suppression {\r\n        score_threshold: 0.0\r\n        iou_threshold: 0.6\r\n        max_detections_per_class: 100\r\n        max_total_detections: 300\r\n      }\r\n      score_converter: SOFTMAX\r\n    }\r\n    second_stage_localization_loss_weight: 2.0\r\n    second_stage_classification_loss_weight: 1.0\r\n  }\r\n}\r\n\r\ntrain_config: {\r\n  batch_size: 1\r\n  optimizer {\r\n    momentum_optimizer: {\r\n      learning_rate: {\r\n        manual_step_learning_rate {\r\n          initial_learning_rate: 0.0003\r\n          schedule {\r\n            step: 300\r\n            learning_rate: .00003\r\n          }\r\n          schedule {\r\n            step: 600\r\n            learning_rate: .000003\r\n          }\r\n        }\r\n      }\r\n      momentum_optimizer_value: 0.9\r\n    }\r\n    use_moving_average: false\r\n  }\r\n  gradient_clipping_by_norm: 10.0\r\n  fine_tune_checkpoint: \"faster_rcnn_resnet101_coco_2018_01_28/model.ckpt\"\r\n  from_detection_checkpoint: true\r\n  data_augmentation_options {\r\n    random_horizontal_flip {\r\n    }\r\n  }\r\n}\r\n\r\ntrain_input_reader: {\r\n  tf_record_input_reader {\r\n    input_path: \"data/train.record\"\r\n  }\r\n  label_map_path: \"data/comm.pbtxt\"\r\n}\r\n\r\neval_config: {\r\n  num_examples: 22\r\n  # Note: The below line limits the evaluation process to 10 evaluations.\r\n  # Remove the below line to evaluate indefinitely.\r\n  max_evals: 10\r\n}\r\n\r\neval_input_reader: {\r\n  tf_record_input_reader {\r\n    input_path: \"data/test.record\"\r\n  }\r\n  label_map_path: \"data/comm.pbtxt\"\r\n  shuffle: false\r\n  num_readers: 1\r\n}\r\n\r\n```\r\n20-05-26 21:46:32.527504: W tensorflow/core/framework/op_kernel.cc:1639] Invalid argument: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\r\nTraceback (most recent call last):\r\n\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/numpy/core/function_base.py\", line 117, in linspace\r\n    num = operator.index(num)\r\n\r\nTypeError: 'numpy.float64' object cannot be interpreted as an integer\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\n\r\nTraceback (most recent call last):\r\n\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\r\n    ret = func(*args)\r\n\r\n  File \"/home/milos/Documents/research/object_detection/object_detection/metrics/coco_evaluation.py\", line 415, in first_value_func\r\n    self._metrics = self.evaluate()\r\n\r\n  File \"/home/milos/Documents/research/object_detection/object_detection/metrics/coco_evaluation.py\", line 246, in evaluate\r\n    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)\r\n\r\n  File \"/home/milos/Documents/research/object_detection/object_detection/metrics/coco_tools.py\", line 177, in __init__\r\n    cocoeval.COCOeval.__init__(self, groundtruth, detections, iouType=iou_type)\r\n\r\n  File \"/home/milos/.local/lib/python3.7/site-packages/pycocotools/cocoeval.py\", line 76, in __init__\r\n    self.params = Params(iouType=iouType) # parameters\r\n\r\n  File \"/home/milos/.local/lib/python3.7/site-packages/pycocotools/cocoeval.py\", line 527, in __init__\r\n    self.setDetParams()\r\n\r\n  File \"/home/milos/.local/lib/python3.7/site-packages/pycocotools/cocoeval.py\", line 507, in setDetParams\r\n    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\r\n\r\n  File \"<__array_function__ internals>\", line 6, in linspace\r\n\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/numpy/core/function_base.py\", line 121, in linspace\r\n    .format(type(num)))\r\n\r\nTypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\r\n    return fn(*args)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\r\n    target_list, run_metadata)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.OutOfRangeError: End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/evaluation.py\", line 272, in _evaluate_once\r\n    session.run(eval_ops, feed_dict)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 754, in run\r\n    run_metadata=run_metadata)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1259, in run\r\n    run_metadata=run_metadata)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1360, in run\r\n    raise six.reraise(*original_exc_info)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1345, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1418, in run\r\n    run_metadata=run_metadata)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1176, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 956, in run\r\n    run_metadata_ptr)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\r\n    run_metadata)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1384, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.OutOfRangeError: End of sequence\r\n\t [[node IteratorGetNext (defined at /home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\r\n\r\nOriginal stack trace for 'IteratorGetNext':\r\n  File \"model_main.py\", line 111, in <module>\r\n    tf.app.run()\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"model_main.py\", line 107, in main\r\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\r\n    return executor.run()\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 613, in run\r\n    return self.run_local()\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\r\n    saving_listeners=saving_listeners)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1195, in _train_model_default\r\n    saving_listeners)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1494, in _train_with_estimator_spec\r\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 754, in run\r\n    run_metadata=run_metadata)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1259, in run\r\n    run_metadata=run_metadata)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1345, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1426, in run\r\n    run_metadata=run_metadata))\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/basic_session_run_hooks.py\", line 594, in after_run\r\n    if self._save(run_context.session, global_step):\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/basic_session_run_hooks.py\", line 619, in _save\r\n    if l.after_save(session, step):\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 519, in after_save\r\n    self._evaluate(global_step_value)  # updates self.eval_result\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 539, in _evaluate\r\n    self._evaluator.evaluate_and_export())\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 920, in evaluate_and_export\r\n    hooks=self._eval_spec.hooks)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 480, in evaluate\r\n    name=name)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 522, in _actual_eval\r\n    return _evaluate()\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 504, in _evaluate\r\n    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1511, in _evaluate_build_graph\r\n    self._call_model_fn_eval(input_fn, self.config))\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1544, in _call_model_fn_eval\r\n    input_fn, ModeKeys.EVAL)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1025, in _get_features_and_labels_from_input_fn\r\n    self._call_input_fn(input_fn, mode))\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/util.py\", line 65, in parse_input_fn_result\r\n    result = iterator.get_next()\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\", line 426, in get_next\r\n    name=name)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py\", line 2518, in iterator_get_next\r\n    output_shapes=output_shapes, name=name)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\r\n    attrs, op_def, compute_device)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\r\n    op_def=op_def)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\r\n    return fn(*args)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\r\n    target_list, run_metadata)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\r\nTraceback (most recent call last):\r\n\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/numpy/core/function_base.py\", line 117, in linspace\r\n    num = operator.index(num)\r\n\r\nTypeError: 'numpy.float64' object cannot be interpreted as an integer\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\n\r\nTraceback (most recent call last):\r\n\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\r\n    ret = func(*args)\r\n\r\n  File \"/home/milos/Documents/research/object_detection/object_detection/metrics/coco_evaluation.py\", line 415, in first_value_func\r\n    self._metrics = self.evaluate()\r\n\r\n  File \"/home/milos/Documents/research/object_detection/object_detection/metrics/coco_evaluation.py\", line 246, in evaluate\r\n    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)\r\n\r\n  File \"/home/milos/Documents/research/object_detection/object_detection/metrics/coco_tools.py\", line 177, in __init__\r\n    cocoeval.COCOeval.__init__(self, groundtruth, detections, iouType=iou_type)\r\n\r\n  File \"/home/milos/.local/lib/python3.7/site-packages/pycocotools/cocoeval.py\", line 76, in __init__\r\n    self.params = Params(iouType=iouType) # parameters\r\n\r\n  File \"/home/milos/.local/lib/python3.7/site-packages/pycocotools/cocoeval.py\", line 527, in __init__\r\n    self.setDetParams()\r\n\r\n  File \"/home/milos/.local/lib/python3.7/site-packages/pycocotools/cocoeval.py\", line 507, in setDetParams\r\n    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\r\n\r\n  File \"<__array_function__ internals>\", line 6, in linspace\r\n\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/numpy/core/function_base.py\", line 121, in linspace\r\n    .format(type(num)))\r\n\r\nTypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\r\n\r\n\r\n\t [[{{node PyFunc_3}}]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"model_main.py\", line 111, in <module>\r\n    tf.app.run()\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"model_main.py\", line 107, in main\r\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\r\n    return executor.run()\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 613, in run\r\n    return self.run_local()\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\r\n    saving_listeners=saving_listeners)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1195, in _train_model_default\r\n    saving_listeners)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1494, in _train_with_estimator_spec\r\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 754, in run\r\n    run_metadata=run_metadata)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1259, in run\r\n    run_metadata=run_metadata)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1360, in run\r\n    raise six.reraise(*original_exc_info)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/six.py\", line 703, in reraise\r\n    raise value\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1345, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1426, in run\r\n    run_metadata=run_metadata))\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/basic_session_run_hooks.py\", line 594, in after_run\r\n    if self._save(run_context.session, global_step):\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/basic_session_run_hooks.py\", line 619, in _save\r\n    if l.after_save(session, step):\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 519, in after_save\r\n    self._evaluate(global_step_value)  # updates self.eval_result\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 539, in _evaluate\r\n    self._evaluator.evaluate_and_export())\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 920, in evaluate_and_export\r\n    hooks=self._eval_spec.hooks)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 480, in evaluate\r\n    name=name)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 522, in _actual_eval\r\n    return _evaluate()\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _evaluate\r\n    output_dir=self.eval_dir(name))\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1619, in _evaluate_run\r\n    config=self._session_config)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/evaluation.py\", line 272, in _evaluate_once\r\n    session.run(eval_ops, feed_dict)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 861, in __exit__\r\n    self._close_internal(exception_type)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 894, in _close_internal\r\n    h.end(self._coordinated_creator.tf_sess)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/basic_session_run_hooks.py\", line 951, in end\r\n    self._final_ops, feed_dict=self._final_ops_feed_dict)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 956, in run\r\n    run_metadata_ptr)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\r\n    run_metadata)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1384, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\r\nTraceback (most recent call last):\r\n\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/numpy/core/function_base.py\", line 117, in linspace\r\n    num = operator.index(num)\r\n\r\nTypeError: 'numpy.float64' object cannot be interpreted as an integer\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\n\r\nTraceback (most recent call last):\r\n\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\r\n    ret = func(*args)\r\n\r\n  File \"/home/milos/Documents/research/object_detection/object_detection/metrics/coco_evaluation.py\", line 415, in first_value_func\r\n    self._metrics = self.evaluate()\r\n\r\n  File \"/home/milos/Documents/research/object_detection/object_detection/metrics/coco_evaluation.py\", line 246, in evaluate\r\n    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)\r\n\r\n  File \"/home/milos/Documents/research/object_detection/object_detection/metrics/coco_tools.py\", line 177, in __init__\r\n    cocoeval.COCOeval.__init__(self, groundtruth, detections, iouType=iou_type)\r\n\r\n  File \"/home/milos/.local/lib/python3.7/site-packages/pycocotools/cocoeval.py\", line 76, in __init__\r\n    self.params = Params(iouType=iouType) # parameters\r\n\r\n  File \"/home/milos/.local/lib/python3.7/site-packages/pycocotools/cocoeval.py\", line 527, in __init__\r\n    self.setDetParams()\r\n\r\n  File \"/home/milos/.local/lib/python3.7/site-packages/pycocotools/cocoeval.py\", line 507, in setDetParams\r\n    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\r\n\r\n  File \"<__array_function__ internals>\", line 6, in linspace\r\n\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/numpy/core/function_base.py\", line 121, in linspace\r\n    .format(type(num)))\r\n\r\nTypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\r\n\r\n\r\n\t [[node PyFunc_3 (defined at /home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\r\n\r\nOriginal stack trace for 'PyFunc_3':\r\n  File \"model_main.py\", line 111, in <module>\r\n    tf.app.run()\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"model_main.py\", line 107, in main\r\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\r\n    return executor.run()\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 613, in run\r\n    return self.run_local()\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\r\n    saving_listeners=saving_listeners)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1195, in _train_model_default\r\n    saving_listeners)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1494, in _train_with_estimator_spec\r\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 754, in run\r\n    run_metadata=run_metadata)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1259, in run\r\n    run_metadata=run_metadata)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1345, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1426, in run\r\n    run_metadata=run_metadata))\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/basic_session_run_hooks.py\", line 594, in after_run\r\n    if self._save(run_context.session, global_step):\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/basic_session_run_hooks.py\", line 619, in _save\r\n    if l.after_save(session, step):\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 519, in after_save\r\n    self._evaluate(global_step_value)  # updates self.eval_result\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 539, in _evaluate\r\n    self._evaluator.evaluate_and_export())\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 920, in evaluate_and_export\r\n    hooks=self._eval_spec.hooks)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 480, in evaluate\r\n    name=name)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 522, in _actual_eval\r\n    return _evaluate()\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 504, in _evaluate\r\n    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1511, in _evaluate_build_graph\r\n    self._call_model_fn_eval(input_fn, self.config))\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1547, in _call_model_fn_eval\r\n    features, labels, ModeKeys.EVAL, config)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1149, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"/home/milos/Documents/research/object_detection/object_detection/model_lib.py\", line 539, in model_fn\r\n    eval_config, list(category_index.values()), eval_dict)\r\n  File \"/home/milos/Documents/research/object_detection/object_detection/eval_util.py\", line 1034, in get_eval_metric_ops_for_evaluators\r\n    eval_dict))\r\n  File \"/home/milos/Documents/research/object_detection/object_detection/metrics/coco_evaluation.py\", line 425, in get_estimator_eval_metric_ops\r\n    first_value_op = tf.py_func(first_value_func, [], tf.float32)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 513, in py_func\r\n    return py_func_common(func, inp, Tout, stateful, name=name)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 495, in py_func_common\r\n    func=func, inp=inp, Tout=Tout, stateful=stateful, eager=False, name=name)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 318, in _internal_py_func\r\n    input=inp, token=token, Tout=Tout, name=name)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_script_ops.py\", line 170, in py_func\r\n    \"PyFunc\", input=input, token=token, Tout=Tout, name=name)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\r\n    attrs, op_def, compute_device)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\r\n    op_def=op_def)\r\n  File \"/home/milos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nps : using labelImg to csv then to tf records\r\n\r\nthis is the code i'm using for to_csv : \r\n```\r\nimport os\r\nimport glob\r\nimport pandas as pd\r\nimport xml.etree.ElementTree as ET\r\n\r\n\r\ndef xml_to_csv(path):\r\n    xml_list = []\r\n    for xml_file in glob.glob(path + '/*.xml'):\r\n        tree = ET.parse(xml_file)\r\n        root = tree.getroot()\r\n        for member in root.findall('object'):\r\n            value = (root.find('filename').text,\r\n                     int(root.find('size')[0].text),\r\n                     int(root.find('size')[1].text),\r\n                     member[0].text,\r\n                     int(member[4][0].text),\r\n                     int(member[4][1].text),\r\n                     int(member[4][2].text),\r\n                     int(member[4][3].text)\r\n                     )\r\n            xml_list.append(value)\r\n    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\r\n    xml_df = pd.DataFrame(xml_list, columns=column_name)\r\n    return xml_df\r\n\r\n\r\ndef main():\r\n  for directory in ['train','test'] :\r\n    image_path = os.path.join(os.getcwd(), 'images/{}'.format(directory))\r\n    xml_df = xml_to_csv(image_path)\r\n    xml_df.to_csv('data/{}_labels.csv'.format(directory), index=None)\r\n    print('Successfully converted xml to csv.')\r\n\r\n\r\nmain()\r\n```\r\n\r\n\r\ncode to generate tfrecords:\r\n```\r\n\r\n\"\"\"\r\nUsage:\r\n  # From tensorflow/models/\r\n  # Create train data:\r\n  python generate_tfrecord.py --csv_input=data/train_labels.csv  --output_path=train.record\r\n\r\n  # Create test data:\r\n  python generate_tfrecord.py --csv_input=data/test_labels.csv  --output_path=test.record\r\n\"\"\"\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom __future__ import absolute_import\r\n\r\nimport os\r\nimport io\r\nimport pandas as pd\r\nimport tensorflow as tf\r\n\r\nfrom PIL import Image\r\nfrom object_detection.utils import dataset_util\r\nfrom collections import namedtuple, OrderedDict\r\n\r\nflags = tf.app.flags\r\nflags.DEFINE_string('csv_input', '', 'Path to the CSV input')\r\nflags.DEFINE_string('output_path', '', 'Path to output TFRecord')\r\nflags.DEFINE_string('image_dir', '', 'Path to images')\r\nFLAGS = flags.FLAGS\r\n\r\n\r\n# TO-DO replace this with label map\r\ndef class_text_to_int(row_label):\r\n    if row_label == 'ooredoo':\r\n        return 1\r\n    elif row_label == 'tt' :\r\n        return 2\r\n    elif row_label == 'orange' :\r\n        return 3\r\n    else:\r\n        None\r\n\r\n\r\ndef split(df, group):\r\n    data = namedtuple('data', ['filename', 'object'])\r\n    gb = df.groupby(group)\r\n    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\r\n\r\n\r\ndef create_tf_example(group, path):\r\n    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\r\n        encoded_jpg = fid.read()\r\n    encoded_jpg_io = io.BytesIO(encoded_jpg)\r\n    image = Image.open(encoded_jpg_io)\r\n    width, height = image.size\r\n\r\n    filename = group.filename.encode('utf8')\r\n    image_format = b'jpg'\r\n    xmins = []\r\n    xmaxs = []\r\n    ymins = []\r\n    ymaxs = []\r\n    classes_text = []\r\n    classes = []\r\n\r\n    for index, row in group.object.iterrows():\r\n        xmins.append(row['xmin'] / width)\r\n        xmaxs.append(row['xmax'] / width)\r\n        ymins.append(row['ymin'] / height)\r\n        ymaxs.append(row['ymax'] / height)\r\n        classes_text.append(row['class'].encode('utf8'))\r\n        classes.append(class_text_to_int(row['class']))\r\n\r\n    tf_example = tf.train.Example(features=tf.train.Features(feature={\r\n        'image/height': dataset_util.int64_feature(height),\r\n        'image/width': dataset_util.int64_feature(width),\r\n        'image/filename': dataset_util.bytes_feature(filename),\r\n        'image/source_id': dataset_util.bytes_feature(filename),\r\n        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\r\n        'image/format': dataset_util.bytes_feature(image_format),\r\n        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\r\n        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\r\n        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\r\n        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\r\n        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\r\n        'image/object/class/label': dataset_util.int64_list_feature(classes),\r\n    }))\r\n    return tf_example\r\n\r\n\r\ndef main(_):\r\n    writer = tf.python_io.TFRecordWriter(FLAGS.output_path)\r\n    path = os.path.join(FLAGS.image_dir)\r\n    examples = pd.read_csv(FLAGS.csv_input)\r\n    grouped = split(examples, 'filename')\r\n    for group in grouped:\r\n        tf_example = create_tf_example(group, path)\r\n        writer.write(tf_example.SerializeToString())\r\n\r\n    writer.close()\r\n    output_path = os.path.join(os.getcwd(), FLAGS.output_path)\r\n    print('Successfully created the TFRecords: {}'.format(output_path))\r\n\r\n\r\nif __name__ == '__main__':\r\n    tf.app.run()\r\n\r\n```\r\n\r\ni know it's index related and i can't figure out a way to solve it", "comments": ["@TekayaNidham \r\nThis issue is more suitable for TensorFlow Models repo. Please post it on Models repo from [here.](https://github.com/tensorflow/models/issues) Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "downgraded numpy to 1.17", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39885\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39885\">No</a>\n"]}, {"number": 39884, "title": "Be able to specifiy the row split dtypes in a keras Ragged Input layer ", "body": "**System information**\r\n- TensorFlow version (you are using): Nightlies\r\n- Are you willing to contribute it (Yes/No): depends\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nCurrently to create a ragged input we use:\r\n````\r\nq = tf.keras.layers.Input(ragged=True, dtype=tf.int32, shape=(None,), )\r\n````\r\nwe can specify the dtype of the values array but not the one from the row_split array.\r\n\r\n**Will this change the current api? How?**\r\nWe should be able to provide the dtype we want to use for the row_split array as well:\r\n\r\n````\r\nq = tf.keras.layers.Input(ragged=True, dtype=tf.int32, shape=(None,),  row_split_dtype=tf.int32)\r\n````\r\ninstead of the default int64.\r\n\r\n**Who will benefit with this feature?**\r\nUsers with small array with no need for an offset array of 64;\r\n\r\n**Any Other info.**\r\n", "comments": ["Thanks @tanguycdls . At this time, we don't want to add this complicating argument to the main Keras Input API. However, we are working on some refactors that may make this easier in the future. No promises, but we will update this thread if we find that there is a user-friendly way to make the datatype specification possible.", "This should now be possible in the nightlies, by specifying a custom type_spec arg for your input layer.", "Thank you  @tomerk !\r\nI just tried it !\r\n```\r\nfrom tensorflow.keras.layers import Embedding\r\nfrom tensorflow.keras.models import Model\r\nimport tensorflow as tf\r\ninp0 = tf.keras.layers.Input(type_spec=tf.RaggedTensorSpec(shape=(None, None), dtype=tf.float32, row_splits_dtype=tf.int32), name='test')\r\na = Embedding(2, 1)(inp0)\r\nb = tf.reduce_sum(a, axis=0)\r\nm = Model(inp0, b)\r\nm.predict(tf.ragged.constant([[0, 1], [1]], dtype=tf.float32, row_splits_dtype=tf.int32))\r\nm.save('test')\r\n```\r\n\r\nI close the issue "]}, {"number": 39883, "title": "test_fit_with_ModelCheckpoint_with_dir_as_h5_filepath test failure in //tensorflow/python/keras:callbacks_test", "body": "Hello,\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **N/A**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Ubuntu 18.04 x86_64**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): **source** \r\n- TensorFlow version (use command below):  **v2.2.0**\r\n- Python version: **3.6.9**\r\n- Bazel version (if compiling from source): **2.0.0**\r\n- GCC/Compiler version (if compiling from source):  **gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0**\r\n- CUDA/cuDNN version: **N/A**\r\n- GPU model and memory: **N/A**\r\n\r\n**Describe the current behavior**\r\nWhen running the test cases on 2.2.0, I encountered an error in `//tensorflow/python/keras:callbacks_test`\r\n\r\nThe failed test log snippet is:\r\n```\r\nFAIL: test_fit_with_ModelCheckpoint_with_dir_as_h5_filepath (__main__.KerasCallbacksTest)\r\ntest_fit_with_ModelCheckpoint_with_dir_as_h5_filepath (__main__.KerasCallbacksTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/peterbao/.cache/bazel/_bazel_peterbao/c55b467aea9f5b6a0b36d1bc596dae4f/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/keras/callbacks_test.runfiles/org_tensorflow/tensorflow/python/keras/callbacks_test.py\", line 821, in test_fit_with_ModelCheckpoint_with_dir_as_h5_filepath\r\n    model.fit(train_ds, epochs=1, callbacks=[callback])\r\nAssertionError: OSError not raised\r\n``` \r\n\r\n**Describe the expected behavior**\r\n`test_fit_with_ModelCheckpoint_with_dir_as_h5_filepath `  and `//tensorflow/python/keras:callbacks_test` to pass\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nThe test case `test_fit_with_ModelCheckpoint_with_dir_as_h5_filepath` appears to be introduced in https://github.com/tensorflow/tensorflow/commit/50256e69b727e49025020e80ab98d5d05d4c7dcc and seems not changed after that. So I am thinking the test case would still fail on the master. To reproduce the failure, you can run `//tensorflow/python/keras:callbacks_test`.\r\n\r\n**Other info / logs** \r\n\r\nI spent some time looking into the test case , and this is what I noticed,\r\n```\r\n(Pdb) list\r\n1225                self.model.save(filepath, overwrite=True)\r\n1226\r\n1227            self._maybe_remove_file()\r\n1228          except IOError as e:\r\n1229            # `e.errno` appears to be `None` so checking the content of `e.args[0]`.\r\n1230 ->         if 'is a directory' in six.ensure_str(e.args[0]):\r\n1231              raise IOError('Please specify a non-directory filepath for '\r\n1232                            'ModelCheckpoint. Filepath used is an existing '\r\n1233                            'directory: {}'.format(filepath))\r\n1234\r\n1235      def _get_file_path(self, epoch, logs):\r\n(Pdb) p e.args[0]\r\n\"Unable to create file (unable to open file: name = '/tmp/tem49izq6ff/tmplrdc03ul/temp.h5', errno = 21, error message = 'Is a directory', flags = 13, o_flags = 242)\"\r\n```\r\nIt looks like the code above wants an error message to be `is a directory` but the OSError actually has `Is a directory` as the error message. As a result, the more detailed error message is not outputted here and that results `test_fit_with_ModelCheckpoint_with_dir_as_h5_filepath` to be failing.\r\n\r\nBased on this information, I think the following can fix the problem:\r\n```\r\ndiff --git a/tensorflow/python/keras/callbacks.py b/tensorflow/python/keras/callbacks.py\r\nindex bb9e61d01a..bfad1112d7 100644\r\n--- a/tensorflow/python/keras/callbacks.py\r\n+++ b/tensorflow/python/keras/callbacks.py\r\n@@ -1227,7 +1227,7 @@ class ModelCheckpoint(Callback):\r\n         self._maybe_remove_file()\r\n       except IOError as e:\r\n         # `e.errno` appears to be `None` so checking the content of `e.args[0]`.\r\n-        if 'is a directory' in six.ensure_str(e.args[0]):\r\n+        if 'Is a directory' in six.ensure_str(e.args[0]):\r\n           raise IOError('Please specify a non-directory filepath for '\r\n                         'ModelCheckpoint. Filepath used is an existing '\r\n                         'directory: {}'.format(filepath))\r\n```\r\n\r\nLet me know if more information is needed.\r\n\r\nThanks,\r\nPeter", "comments": ["@ruixin-bao\r\nPlease share simple stand alone code for us to replicate the issue faced along with the exact steps before which you encountered this issue", "Hi,\r\n@Saduf2019, thank you for the reply. I encountered this error while running the test cases, so might not have a simple stand alone code. I tried isolating that test case (and its related functions) into the following python file, would that work?\r\n\r\n```\r\nfrom tensorflow.python.keras import keras_parameterized\r\nimport os\r\nfrom tensorflow.python.platform import test\r\nfrom tensorflow.python.data.ops import dataset_ops\r\nfrom tensorflow.python.keras.engine import sequential\r\nfrom tensorflow.python.keras.optimizer_v2 import gradient_descent\r\nfrom tensorflow.python.keras import testing_utils\r\nfrom tensorflow.python import keras\r\n\r\nclass KerasCallbacksTest(keras_parameterized.TestCase):\r\n  def _get_dummy_resource_for_model_checkpoint_testing(self):\r\n\r\n    def get_input_datasets():\r\n      # Simple training input.\r\n      train_input = [[1.]] * 16\r\n      train_label = [[0.]] * 16\r\n      ds = dataset_ops.Dataset.from_tensor_slices((train_input, train_label))\r\n      return ds.batch(8, drop_remainder=True)\r\n\r\n    # Very simple bias model to eliminate randomness.\r\n    optimizer = gradient_descent.SGD(0.1)\r\n    model = sequential.Sequential()\r\n    model.add(testing_utils.Bias(input_shape=(1,)))\r\n    model.compile(loss='mae', optimizer=optimizer, metrics=['mae'])\r\n    train_ds = get_input_datasets()\r\n\r\n    temp_dir = self.get_temp_dir()\r\n    filepath = os.path.join(temp_dir, 'checkpoint.epoch{epoch:02d}.h5')\r\n\r\n    # The filepath shouldn't exist at the beginning.\r\n    self.assertFalse(os.path.exists(filepath))\r\n    callback = keras.callbacks.ModelCheckpoint(\r\n        filepath=filepath, save_weights_only=True)\r\n\r\n    return model, train_ds, callback, filepath\r\n\r\n  def test_fit_with_ModelCheckpoint_with_dir_as_h5_filepath(self):\r\n    (model, train_ds, callback,\r\n     filepath) = self._get_dummy_resource_for_model_checkpoint_testing()\r\n    temp_dir = self.get_temp_dir()\r\n    filepath = os.path.join(temp_dir, 'temp.h5')\r\n\r\n    self.assertFalse(os.path.exists(filepath))\r\n    os.mkdir(filepath)\r\n    self.assertTrue(os.path.exists(filepath))\r\n\r\n    callback = keras.callbacks.ModelCheckpoint(filepath=filepath)\r\n    \r\n    with self.assertRaisesRegexp(IOError, 'Please specify a non-directory '\r\n                                        'filepath for ModelCheckpoint.'):\r\n      model.fit(train_ds, epochs=1, callbacks=[callback])\r\n\r\nif __name__ == '__main__':\r\n  test.main()\r\n```\r\n\r\n> faced along with the exact steps before which you encountered this issue\r\n\r\nI originally encountered this issue after I build TensorFlow 2.2.0 on Ubuntu 18.04 x86 and run its test suite, but that might be a bit time consuming. I think I find a simpler reproducer: \r\n\r\n1: I install TensorFlow 2.2.0 following https://www.tensorflow.org/install/pip\r\n2: I have the above the test case written in a file called `testcase.py`\r\n3: I run `python testcase.py` under a virtual environment\r\n\r\nThe test case then shows the following on my local environment:\r\n```\r\n(venv) peterbao@xxx:~$ python testcase.py \r\nRunning tests under Python 3.6.9: /home/peterbao/venv/bin/python\r\n[ RUN      ] KerasCallbacksTest.test_fit_with_ModelCheckpoint_with_dir_as_h5_filepath\r\nWARNING:tensorflow:From /home/peterbao/venv/lib/python3.6/site-packages/tensorflow/python/keras/testing_utils.py:612: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use `layer.add_weight` method instead.\r\nW0527 05:24:02.982633 139958468568896 deprecation.py:323] From /home/peterbao/venv/lib/python3.6/site-packages/tensorflow/python/keras/testing_utils.py:612: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use `layer.add_weight` method instead.\r\n2020-05-27 05:24:02.988186: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2020-05-27 05:24:02.988473: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\r\n2020-05-27 05:24:02.988672: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tithed1.fyre.ibm.com): /proc/driver/nvidia/version does not exist\r\n2020-05-27 05:24:02.989427: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-05-27 05:24:03.010707: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2199970000 Hz\r\n2020-05-27 05:24:03.012074: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f49f4000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-05-27 05:24:03.012298: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2/2 [==============================] - 0s 6ms/step - loss: 0.9500 - mae: 0.9500\r\n[  FAILED  ] KerasCallbacksTest.test_fit_with_ModelCheckpoint_with_dir_as_h5_filepath\r\n[ RUN      ] KerasCallbacksTest.test_session\r\n[  SKIPPED ] KerasCallbacksTest.test_session\r\n======================================================================\r\nFAIL: test_fit_with_ModelCheckpoint_with_dir_as_h5_filepath (__main__.KerasCallbacksTest)\r\ntest_fit_with_ModelCheckpoint_with_dir_as_h5_filepath (__main__.KerasCallbacksTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"testcase.py\", line 51, in test_fit_with_ModelCheckpoint_with_dir_as_h5_filepath\r\n    model.fit(train_ds, epochs=1, callbacks=[callback])\r\nAssertionError: OSError not raised\r\n\r\n----------------------------------------------------------------------\r\nRan 2 tests in 1.131s\r\n\r\nFAILED (failures=1, skipped=1)\r\n```\r\n\r\nThanks,\r\nPeter", "@ruixin-bao \r\nI ran the code shared and face a different error, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/3fec449ff781573ad1e9ceed7d4eafa2/untitled198.ipynb)", "Hi,\r\n\r\n@Saduf2019, thanks for the reply and providing the gist. I saw the flag error as well when I am running this gist. I took some time to find why that is the case as this test case works for me locally. \r\n\r\nAccording to https://github.com/jupyter/notebook/issues/2746 and its linked stack overflow, it seems that\r\n ```unittest.main looks at sys.argv by default, which is what started IPython, hence the error about the kernel connection file not being a valid attribute.``` \r\n\r\nBy looking at the pdb output, I did see something similar to what the issue above describes:\r\n<img width=\"1613\" alt=\"Screen Shot 2020-05-28 at 10 11 49 AM\" src=\"https://user-images.githubusercontent.com/54991207/83152539-eb04ff80-a0cb-11ea-9b90-f269199562a8.png\">\r\n\r\n\r\nSo I am suspecting that is the issue. However, seems like when I use tensorflow platform's test  to run the test (i.e: `from tensorflow.python.platform import test`), the mentioned workaround in the issue does not work for me. To solve the problem, I switched to use unittest, hopefully it shouldn't change too much of what I try to show. \r\n\r\nI have attached the gist I tried [here](https://colab.research.google.com/drive/1FQPJfqnaHH6PuJpvxMaEHyv1mCK0AEoD#scrollTo=2W8vfkHiilZ6). Let me know if that works for you. \r\n\r\n\r\nThanks,\r\nPeter\r\n", "@ruixin-bao\r\nI need permission to view the gist shared.", "@Saduf2019\r\noops, sorry,  I just learned how to use colab today.\r\ndoes this: https://colab.research.google.com/drive/1FQPJfqnaHH6PuJpvxMaEHyv1mCK0AEoD?usp=sharing work?", "@ruixin-bao \r\nI ran the gist shared and [here](https://colab.sandbox.google.com/gist/Saduf2019/2ae27e7d82ef757c105a123d94eb58d8/untitled207.ipynb) is the error faced.", "@Saduf2019 \r\n\r\nOdd `NameError: name 'unittest' is not defined` looks like an import error. I ran this multiple times yesterday in colab but did not catch this error...  \r\n\r\n[this](https://colab.research.google.com/drive/1kDsQVec4GxyMyv6JkxFeg8-2lu_Pd0kh?usp=sharing) is the updated one with `unittest` imported. Do you mind having another quick check? Thanks", "i am able to replicate the issue faced, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/fabe9e823c30f0b188e8896b0dc60c71/untitled208.ipynb)", "gentle ping : ).\r\n\r\nLooks like https://github.com/tensorflow/tensorflow/commit/42e08300a053cced03292b430d51a1273bb642f0 addresses the problem, wondering if I should close this issue?", "I tested out that https://github.com/tensorflow/tensorflow/commit/42e08300a053cced03292b430d51a1273bb642f0 indeed fixes the issue. Also, from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/BUILD#L520-L536, looks like this test has `no_oss` tag.\r\n\r\n\r\nHence, I am closing this issue. Thanks all for the help provided!\r\n\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39883\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39883\">No</a>\n"]}, {"number": 39882, "title": "Add n-dimensional tensor support for tf.unique and tf.unique_with_counts", "body": "Feature request for tf.unique and tf.unique_with_counts:\r\n1. can apply to n-D tensor\r\n2. can select which axis to apply it\r\n\r\n**System information**\r\n- TensorFlow version : 2.2.0\r\n- Python version : 3.6.9\r\n\r\n", "comments": ["@winnietsang,\r\n**`Multidimensional Support`** is available in [tf.raw_ops.UniqueV2](https://www.tensorflow.org/api_docs/python/tf/raw_ops/UniqueV2) and [tf.raw_ops.UniqueWithCountsV2](https://www.tensorflow.org/api_docs/python/tf/raw_ops/UniqueWithCountsV2). PTAL. Thanks!\r\n ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 39881, "title": "[MLIR] Fix LHLO to affine conversion to use affine.load/stores", "body": "The conversions from LHLO to affine on pointwise binary ops were\r\ngenerating std dialect load/stores instead of affine.load/stores. These\r\nops' memref access functions are identity functions on surrounding loop\r\ninduction variables and as such are always affine. Fix this.\r\n\r\nSigned-off-by: Uday Bondhugula <uday@polymagelabs.com>", "comments": []}, {"number": 39880, "title": "KeyError: 'acc' in multi_worker_fault_tolerance_test", "body": "In TF 2.2.0, it appears that `Key` name has been changed to `accuracy` from `acc` recently which is causing this testcase to fail.\r\n\r\n```\r\n======================================================================\r\nERROR: testFaultToleranceInSyncStrategy_test_fileformat_h5_loadweightsonrestart_False_mode_graph_preemptioncallback_classmainKerasMultiWorkerFaultToleranceTestPreemptionAtBatchBoundarySimulatingCallback_requiredgpus_0_saveweightsonly_False_strategycls_classtensorflowpythondistributecollectiveallreducestrategyCollectiveAllReduceStrategy (__main__.KerasMultiWorkerFaultToleranceTest)\r\ntestFaultToleranceInSyncStrategy_test_fileformat_h5_loadweightsonrestart_False_mode_graph_preemptioncallback_classmainKerasMultiWorkerFaultToleranceTestPreemptionAtBatchBoundarySimulatingCallback_requiredgpus_0_saveweightsonly_False_strategycls_classtensorflowpythondistributecollectiveallreducestrategyCollectiveAllReduceStrategy (__main__.KerasMultiWorkerFaultToleranceTest)\r\ntestFaultToleranceInSyncStrategy_test_fileformat_h5_loadweightsonrestart_False_mode_graph_preemptioncallback_classmainKerasMultiWorkerFaultToleranceTestPreemptionAtBatchBoundarySimulatingCallback_requiredgpus_0_saveweightsonly_False_strategycls_classtensorflowpythondistributecollectiveallreducestrategyCollectiveAllReduceStrategy(file_format='h5', load_weights_on_restart=False, mode='graph', preemption_callback=<class '__main__.KerasMultiWorkerFaultToleranceTest.PreemptionAtBatchBoundarySimulatingCallback'>, required_gpus=0, save_weights_only=False, strategy_cls=<class 'tensorflow.python.distribute.collective_all_reduce_strategy.CollectiveAllReduceStrategy'>)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/testing/parameterized.py\", line 263, in bound_param_test\r\n    test_method(self, **testcase_params)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/test_combinations.py\", line 314, in decorated\r\n    execute_test_method()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/test_combinations.py\", line 297, in execute_test_method\r\n    test_method(**kwargs_to_pass)\r\n  File \"tensorflow/python/keras/distribute/multi_worker_fault_tolerance_test.py\", line 331, in testFaultToleranceInSyncStrategy\r\n    [history['acc'][-1] for history in self._histories])\r\n  File \"tensorflow/python/keras/distribute/multi_worker_fault_tolerance_test.py\", line 331, in <listcomp>\r\n    [history['acc'][-1] for history in self._histories])\r\nKeyError: 'acc'\r\n\r\n```\r\nhttps://github.com/tensorflow/tensorflow/blob/509325e1b12df34e5d06117ac58242de58bd7798/tensorflow/python/keras/distribute/multi_worker_fault_tolerance_test.py#L331\r\n\r\nOn my system here are the `self._histories` contains:\r\n```\r\n-> [history['acc'][-1] for history in self._histories])\r\n(Pdb) pp self._histories\r\n[{'accuracy': [1.0, 1.0, 1.0],\r\n  'loss': [2.2476557890574136, 2.1090187231699624, 1.9728290637334187]},\r\n {'accuracy': [1.0, 1.0, 1.0],\r\n  'loss': [2.2476557890574136, 2.1090187231699624, 1.9728290637334187]},\r\n {'accuracy': [1.0, 1.0], 'loss': [2.1090187231699624, 1.9728290637334187]},\r\n {'accuracy': [1.0, 1.0], 'loss': [2.1090187231699624, 1.9728290637334187]}]\r\n(Pdb)\r\n```\r\nFollowing change fixes this error:\r\n\r\n```\r\ndiff --git a/tensorflow/python/keras/distribute/multi_worker_fault_tolerance_test.py b/tensorflow/python/keras/distribute/multi_worker_fault_tolerance_test.py\r\nindex fa58d2479a..f026ed1cae 100644\r\n--- a/tensorflow/python/keras/distribute/multi_worker_fault_tolerance_test.py\r\n+++ b/tensorflow/python/keras/distribute/multi_worker_fault_tolerance_test.py\r\n@@ -328,17 +328,17 @@ class KerasMultiWorkerFaultToleranceTest(test_base.IndependentWorkerTestBase,\r\n     # Important: the results from preemption interrupted and non-interrupted\r\n     # cases should give the same final results.\r\n     assert_all_elements_are_identical(\r\n-        [history['acc'][-1] for history in self._histories])\r\n+        [history['accuracy'][-1] for history in self._histories])\r\n     assert_all_elements_are_identical(\r\n         [history['loss'][-1] for history in self._histories])\r\n     # The length of `self._histories` would be num_workers * num_runs (3).\r\n     self.assertLen(self._histories, 4)\r\n\r\n     # Results from case 1 should have 3 full epochs.\r\n-    self.assertLen(self._histories[0]['acc'], 3)\r\n+    self.assertLen(self._histories[0]['accuracy'], 3)\r\n     # Results from case 2 should only have 2 full epochs because it restarted at\r\n     # epoch 1.\r\n-    self.assertLen(self._histories[-1]['acc'], 2)\r\n+    self.assertLen(self._histories[-1]['accuracy'], 2)\r\n\r\n\r\n if __name__ == '__main__':\r\n```\r\nPlease let me know if this is an acceptable fix.\r\n\r\nThanks.", "comments": ["@rposts Yes. Recently metric was changed from 'acc' to 'accuracy'. Can you please create a Pull-Request (PR) to update the code? Thanks!\r\n\r\nPlease close this issue. Thanks!", "@jvishnuvardhan - it seems like this testcase is withdrawn from master.  Would you know if there is a corresponding replacement where this patch might apply?", "Closing.  I cannot find this test case on master branch.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39880\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39880\">No</a>\n"]}, {"number": 39879, "title": "The following classes have no ground truth", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution : Linux Ubuntu 18.04\r\n\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.15.0\r\n- Python version: 3.7.4 \r\n\r\n- CUDA/cuDNN version: 10.2 \r\n- GPU model and memory: GeForce GTX 1050\r\n\r\n\r\n\r\n**Describe the current behavior**\r\nhey guys, i'm trying to train an object detection 3 classes model using resnet101 faster rcnn using train.py from legacy folder from object detection api,\r\nthe losses looks very good but when running eval.py i get a very low mAP of the 3rd one only\r\nwith this warning : \r\nobject_detection_evaluation.py:1279] The following classes have no ground truth examples: [1 2]\r\n\r\nlabel map : \r\n\r\n```\r\nitem {\r\n  id: 1\r\n  name: 'ooredoo'\r\n  id: 2\r\n  name: 'tt'\r\n  id: 3\r\n  name: 'orange'\r\n}\r\n```\r\n\r\n\r\nconfig file  : \r\n\r\n```\r\n# Faster R-CNN with Resnet-101 (v1), configuration for MSCOCO Dataset.\r\n# Users should configure the fine_tune_checkpoint field in the train config as\r\n# well as the label_map_path and input_path fields in the train_input_reader and\r\n# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\r\n# should be configured.\r\n\r\nmodel {\r\n  faster_rcnn {\r\n    num_classes: 3\r\n    image_resizer {\r\n      keep_aspect_ratio_resizer {\r\n        min_dimension: 600\r\n        max_dimension: 1024\r\n      }\r\n    }\r\n    feature_extractor {\r\n      type: 'faster_rcnn_resnet101'\r\n      first_stage_features_stride: 16\r\n    }\r\n    first_stage_anchor_generator {\r\n      grid_anchor_generator {\r\n        scales: [0.25, 0.5, 1.0, 2.0]\r\n        aspect_ratios: [0.5, 1.0, 2.0]\r\n        height_stride: 16\r\n        width_stride: 16\r\n      }\r\n    }\r\n    first_stage_box_predictor_conv_hyperparams {\r\n      op: CONV\r\n      regularizer {\r\n        l2_regularizer {\r\n          weight: 0.0\r\n        }\r\n      }\r\n      initializer {\r\n        truncated_normal_initializer {\r\n          stddev: 0.01\r\n        }\r\n      }\r\n    }\r\n    first_stage_nms_score_threshold: 0.0\r\n    first_stage_nms_iou_threshold: 0.7\r\n    first_stage_max_proposals: 300\r\n    first_stage_localization_loss_weight: 2.0\r\n    first_stage_objectness_loss_weight: 1.0\r\n    initial_crop_size: 14\r\n    maxpool_kernel_size: 2\r\n    maxpool_stride: 2\r\n    second_stage_box_predictor {\r\n      mask_rcnn_box_predictor {\r\n        use_dropout: false\r\n        dropout_keep_probability: 1.0\r\n        fc_hyperparams {\r\n          op: FC\r\n          regularizer {\r\n            l2_regularizer {\r\n              weight: 0.0\r\n            }\r\n          }\r\n          initializer {\r\n            variance_scaling_initializer {\r\n              factor: 1.0\r\n              uniform: true\r\n              mode: FAN_AVG\r\n            }\r\n          }\r\n        }\r\n      }\r\n    }\r\n    second_stage_post_processing {\r\n      batch_non_max_suppression {\r\n        score_threshold: 0.0\r\n        iou_threshold: 0.6\r\n        max_detections_per_class: 100\r\n        max_total_detections: 300\r\n      }\r\n      score_converter: SOFTMAX\r\n    }\r\n    second_stage_localization_loss_weight: 2.0\r\n    second_stage_classification_loss_weight: 1.0\r\n  }\r\n}\r\n\r\ntrain_config: {\r\n  batch_size: 1\r\n  optimizer {\r\n    momentum_optimizer: {\r\n      learning_rate: {\r\n        manual_step_learning_rate {\r\n          initial_learning_rate: 0.0003\r\n          schedule {\r\n            step: 300\r\n            learning_rate: .00003\r\n          }\r\n          schedule {\r\n            step: 600\r\n            learning_rate: .000003\r\n          }\r\n        }\r\n      }\r\n      momentum_optimizer_value: 0.9\r\n    }\r\n    use_moving_average: false\r\n  }\r\n  gradient_clipping_by_norm: 10.0\r\n  fine_tune_checkpoint: \"faster_rcnn_resnet101_coco_2018_01_28/model.ckpt\"\r\n  from_detection_checkpoint: true\r\n  data_augmentation_options {\r\n    random_horizontal_flip {\r\n    }\r\n  }\r\n}\r\n\r\ntrain_input_reader: {\r\n  tf_record_input_reader {\r\n    input_path: \"data/train.record\"\r\n  }\r\n  label_map_path: \"data/comm.pbtxt\"\r\n}\r\n\r\neval_config: {\r\n  num_examples: 22\r\n  # Note: The below line limits the evaluation process to 10 evaluations.\r\n  # Remove the below line to evaluate indefinitely.\r\n  max_evals: 10\r\n}\r\n\r\neval_input_reader: {\r\n  tf_record_input_reader {\r\n    input_path: \"data/test.record\"\r\n  }\r\n  label_map_path: \"data/comm.pbtxt\"\r\n  shuffle: false\r\n  num_readers: 1\r\n}\r\n\r\n```\r\n\r\nalready checked https://github.com/tensorflow/models/issues/1936 and https://github.com/tensorflow/models/issues/1696 \r\n \r\nps : using labelImg to csv then to tf records\r\n\r\nthis is the code i'm using for to_csv : \r\n```\r\nimport os\r\nimport glob\r\nimport pandas as pd\r\nimport xml.etree.ElementTree as ET\r\n\r\n\r\ndef xml_to_csv(path):\r\n    xml_list = []\r\n    for xml_file in glob.glob(path + '/*.xml'):\r\n        tree = ET.parse(xml_file)\r\n        root = tree.getroot()\r\n        for member in root.findall('object'):\r\n            value = (root.find('filename').text,\r\n                     int(root.find('size')[0].text),\r\n                     int(root.find('size')[1].text),\r\n                     member[0].text,\r\n                     int(member[4][0].text),\r\n                     int(member[4][1].text),\r\n                     int(member[4][2].text),\r\n                     int(member[4][3].text)\r\n                     )\r\n            xml_list.append(value)\r\n    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\r\n    xml_df = pd.DataFrame(xml_list, columns=column_name)\r\n    return xml_df\r\n\r\n\r\ndef main():\r\n  for directory in ['train','test'] :\r\n    image_path = os.path.join(os.getcwd(), 'images/{}'.format(directory))\r\n    xml_df = xml_to_csv(image_path)\r\n    xml_df.to_csv('data/{}_labels.csv'.format(directory), index=None)\r\n    print('Successfully converted xml to csv.')\r\n\r\n\r\nmain()\r\n```", "comments": ["@TekayaNidham \r\nCan you please share complete indented code such that i can replicate the issue faced, or please share a colab gist such that we could see the error faced.", "code to generate tfrecords:\r\n```\r\n\r\n\"\"\"\r\nUsage:\r\n  # From tensorflow/models/\r\n  # Create train data:\r\n  python generate_tfrecord.py --csv_input=data/train_labels.csv  --output_path=train.record\r\n\r\n  # Create test data:\r\n  python generate_tfrecord.py --csv_input=data/test_labels.csv  --output_path=test.record\r\n\"\"\"\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom __future__ import absolute_import\r\n\r\nimport os\r\nimport io\r\nimport pandas as pd\r\nimport tensorflow as tf\r\n\r\nfrom PIL import Image\r\nfrom object_detection.utils import dataset_util\r\nfrom collections import namedtuple, OrderedDict\r\n\r\nflags = tf.app.flags\r\nflags.DEFINE_string('csv_input', '', 'Path to the CSV input')\r\nflags.DEFINE_string('output_path', '', 'Path to output TFRecord')\r\nflags.DEFINE_string('image_dir', '', 'Path to images')\r\nFLAGS = flags.FLAGS\r\n\r\n\r\n# TO-DO replace this with label map\r\ndef class_text_to_int(row_label):\r\n    if row_label == 'ooredoo':\r\n        return 1\r\n    elif row_label == 'tt' :\r\n        return 2\r\n    elif row_label == 'orange' :\r\n        return 3\r\n    else:\r\n        None\r\n\r\n\r\ndef split(df, group):\r\n    data = namedtuple('data', ['filename', 'object'])\r\n    gb = df.groupby(group)\r\n    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\r\n\r\n\r\ndef create_tf_example(group, path):\r\n    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\r\n        encoded_jpg = fid.read()\r\n    encoded_jpg_io = io.BytesIO(encoded_jpg)\r\n    image = Image.open(encoded_jpg_io)\r\n    width, height = image.size\r\n\r\n    filename = group.filename.encode('utf8')\r\n    image_format = b'jpg'\r\n    xmins = []\r\n    xmaxs = []\r\n    ymins = []\r\n    ymaxs = []\r\n    classes_text = []\r\n    classes = []\r\n\r\n    for index, row in group.object.iterrows():\r\n        xmins.append(row['xmin'] / width)\r\n        xmaxs.append(row['xmax'] / width)\r\n        ymins.append(row['ymin'] / height)\r\n        ymaxs.append(row['ymax'] / height)\r\n        classes_text.append(row['class'].encode('utf8'))\r\n        classes.append(class_text_to_int(row['class']))\r\n\r\n    tf_example = tf.train.Example(features=tf.train.Features(feature={\r\n        'image/height': dataset_util.int64_feature(height),\r\n        'image/width': dataset_util.int64_feature(width),\r\n        'image/filename': dataset_util.bytes_feature(filename),\r\n        'image/source_id': dataset_util.bytes_feature(filename),\r\n        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\r\n        'image/format': dataset_util.bytes_feature(image_format),\r\n        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\r\n        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\r\n        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\r\n        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\r\n        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\r\n        'image/object/class/label': dataset_util.int64_list_feature(classes),\r\n    }))\r\n    return tf_example\r\n\r\n\r\ndef main(_):\r\n    writer = tf.python_io.TFRecordWriter(FLAGS.output_path)\r\n    path = os.path.join(FLAGS.image_dir)\r\n    examples = pd.read_csv(FLAGS.csv_input)\r\n    grouped = split(examples, 'filename')\r\n    for group in grouped:\r\n        tf_example = create_tf_example(group, path)\r\n        writer.write(tf_example.SerializeToString())\r\n\r\n    writer.close()\r\n    output_path = os.path.join(os.getcwd(), FLAGS.output_path)\r\n    print('Successfully created the TFRecords: {}'.format(output_path))\r\n\r\n\r\nif __name__ == '__main__':\r\n    tf.app.run()\r\n\r\n```", "this is what i get when running eval.py : \r\n\r\n_INFO:tensorflow:Detection visualizations written to summary with tag image-0.\r\nI0526 18:22:36.651726 140527797831488 eval_util.py:237] Detection visualizations written to summary with tag image-0.\r\nW0526 18:22:36.653803 140527797831488 object_detection_evaluation.py:335] image b'1.jpg' does not have groundtruth difficult flag specified\r\nINFO:tensorflow:Creating detection visualizations.\r\nI0526 18:22:41.508312 140527797831488 eval_util.py:172] Creating detection visualizations.\r\nINFO:tensorflow:Detection visualizations written to summary with tag image-1.\r\nI0526 18:22:41.540313 140527797831488 eval_util.py:237] Detection visualizations written to summary with tag image-1.\r\nINFO:tensorflow:Creating detection visualizations.\r\nI0526 18:22:44.626757 140527797831488 eval_util.py:172] Creating detection visualizations.\r\nINFO:tensorflow:Detection visualizations written to summary with tag image-2.\r\nI0526 18:22:44.701496 140527797831488 eval_util.py:237] Detection visualizations written to summary with tag image-2.\r\nINFO:tensorflow:Creating detection visualizations.\r\nI0526 18:22:47.727808 140527797831488 eval_util.py:172] Creating detection visualizations.\r\nINFO:tensorflow:Detection visualizations written to summary with tag image-3.\r\nI0526 18:22:47.795775 140527797831488 eval_util.py:237] Detection visualizations written to summary with tag image-3.\r\nINFO:tensorflow:Creating detection visualizations.\r\nI0526 18:22:50.807934 140527797831488 eval_util.py:172] Creating detection visualizations.\r\nINFO:tensorflow:Detection visualizations written to summary with tag image-4.\r\nI0526 18:22:50.882759 140527797831488 eval_util.py:237] Detection visualizations written to summary with tag image-4.\r\nINFO:tensorflow:Creating detection visualizations.\r\nI0526 18:22:53.847764 140527797831488 eval_util.py:172] Creating detection visualizations.\r\nINFO:tensorflow:Detection visualizations written to summary with tag image-5.\r\nI0526 18:22:53.957002 140527797831488 eval_util.py:237] Detection visualizations written to summary with tag image-5.\r\nINFO:tensorflow:Creating detection visualizations.\r\nI0526 18:22:57.017548 140527797831488 eval_util.py:172] Creating detection visualizations.\r\nINFO:tensorflow:Detection visualizations written to summary with tag image-6.\r\nI0526 18:22:57.141085 140527797831488 eval_util.py:237] Detection visualizations written to summary with tag image-6.\r\nINFO:tensorflow:Creating detection visualizations.\r\nI0526 18:23:00.066134 140527797831488 eval_util.py:172] Creating detection visualizations.\r\nINFO:tensorflow:Detection visualizations written to summary with tag image-7.\r\nI0526 18:23:00.121052 140527797831488 eval_util.py:237] Detection visualizations written to summary with tag image-7.\r\nINFO:tensorflow:Creating detection visualizations.\r\nI0526 18:23:03.224129 140527797831488 eval_util.py:172] Creating detection visualizations.\r\nINFO:tensorflow:Detection visualizations written to summary with tag image-8.\r\nI0526 18:23:03.330128 140527797831488 eval_util.py:237] Detection visualizations written to summary with tag image-8.\r\nINFO:tensorflow:Creating detection visualizations.\r\nI0526 18:23:07.910117 140527797831488 eval_util.py:172] Creating detection visualizations.\r\nINFO:tensorflow:Detection visualizations written to summary with tag image-9.\r\nI0526 18:23:08.325047 140527797831488 eval_util.py:237] Detection visualizations written to summary with tag image-9.\r\nINFO:tensorflow:Running eval batches done.\r\nI0526 18:23:53.889015 140527797831488 eval_util.py:370] Running eval batches done.\r\nINFO:tensorflow:# success: 22\r\nI0526 18:23:53.889818 140527797831488 eval_util.py:375] # success: 22\r\nINFO:tensorflow:# skipped: 0\r\nI0526 18:23:53.890330 140527797831488 eval_util.py:376] # skipped: 0\r\nW0526 18:23:53.890964 140527797831488 object_detection_evaluation.py:1279] The following classes have no ground truth examples: [1 2]\r\nI0526 18:23:53.913546 140527797831488 object_detection_evaluation.py:1311] average_precision: 0.285256\r\n/home/milos/Documents/research/object_detection/object_detection/utils/metrics.py:145: RuntimeWarning: invalid value encountered in true_divide\r\n  num_images_correctly_detected_per_class / num_gt_imgs_per_class)\r\nINFO:tensorflow:Writing metrics to tf summary.\r\nI0526 18:23:54.238987 140527797831488 eval_util.py:84] Writing metrics to tf summary.\r\nINFO:tensorflow:Losses/Loss/BoxClassifierLoss/classification_loss: 0.022590\r\nI0526 18:23:54.239214 140527797831488 eval_util.py:91] Losses/Loss/BoxClassifierLoss/classification_loss: 0.022590\r\nINFO:tensorflow:Losses/Loss/BoxClassifierLoss/localization_loss: 0.065883\r\nI0526 18:23:54.239452 140527797831488 eval_util.py:91] Losses/Loss/BoxClassifierLoss/localization_loss: 0.065883\r\nINFO:tensorflow:Losses/Loss/RPNLoss/localization_loss: 0.086048\r\nI0526 18:23:54.239606 140527797831488 eval_util.py:91] Losses/Loss/RPNLoss/localization_loss: 0.086048\r\nINFO:tensorflow:Losses/Loss/RPNLoss/objectness_loss: 0.201416\r\nI0526 18:23:54.239904 140527797831488 eval_util.py:91] Losses/Loss/RPNLoss/objectness_loss: 0.201416\r\nINFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/orange: 0.285256\r\nI0526 18:23:54.240060 140527797831488 eval_util.py:91] PascalBoxes_PerformanceByCategory/AP@0.5IOU/orange: 0.285256\r\nINFO:tensorflow:PascalBoxes_Precision/mAP@0.5IOU: 0.285256\r\nI0526 18:23:54.240170 140527797831488 eval_util.py:91] PascalBoxes_Precision/mAP@0.5IOU: 0.285256_\r\n", "@Saduf2019 all the posted issues with is this error says it's  data related, here's how i prepared my dataset, can't figure out what have i done wrong, did it this way before and it worked fine", "@Saduf2019  https://drive.google.com/file/d/10P5Oc09KADMoWDAjWYx5T2L_7FeoQpEy/view?usp=sharing", "@TekayaNidham \r\nThe gist shared does not replicate the issue, please share it after you run and face the error.", "@Saduf2019 while doing it i ran into another error i solved before by copying object detection folder in my workspace, but on gist didn't seem to work, could you please check it \r\n", "@TekayaNidham  Please post this issue in [tensorflow/models](https://github.com/tensorflow/models/issues) or in stackoverflow as this issue is primarily a models issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39879\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39879\">No</a>\n"]}, {"number": 39878, "title": "MeanSquaredError truncated to 32-bit precision when using 64-bit", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Mint 19.2\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.3.0-dev20200526\r\n- Python version: 3.8.3\r\n- GPU model and memory: RTX 2080 Ti - 11GB\r\n\r\n\r\n**Current Behavior**\r\n When computing the loss using `keras.losses.MeanSquaredError` with data being of `dtype=tf.float64,` the results are consistent with casting to float32 then back to float64. The result of calling the loss function is of `dtype=tf.float64,` but there is an error of about 1e-8. I have observed this behavior in versions 2.1, 2.2, and the nightly build indicated above. I have not tested this with other loss functions, although this may be an issue for them as well. \r\n\r\n**Expected Behavior** \r\nCalling the loss function should return the same results as computing the loss manually in 64-bits when the data is 64-bit. \r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. \r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\n# some sample data \r\nx = tf.convert_to_tensor([[2.1]], dtype=tf.float64)\r\ny_true = tf.square(x)\r\n\r\n# sample output of NN - something not the same as y_true\r\ny_pred = tf.convert_to_tensor([[3.68]], dtype=tf.float64)\r\n\r\n# TF loss\r\nloss = keras.losses.MeanSquaredError()\r\ntf_loss = loss(y_pred, y_true)\r\n\r\n# manually computed loss in 64-bit\r\nman_loss64 = tf.square(y_pred - y_true)\r\n\r\n# manually computed loss, cast to 32 bit, then back to 64\r\nman_loss32 = tf.cast(tf.cast(tf.square(y_pred - y_true), dtype=tf.float32), dtype=tf.float64)\r\n\r\n# difference between loss computations\r\ndiff64 = abs(man_loss64 - tf_loss)\r\ndiff32 = abs(man_loss32 - tf_loss)\r\nprint(f'Difference in 64 bit: {diff64}')\r\nprint(f'Difference in 32 bit: {diff32}')\r\n```\r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["I have tried in colab with TF version 2.1, 2.2 and nightly version(2.3.0-dev20200526) and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/f8f8e21e9e552a87e8f007e941ae1d38/untitled45.ipynb).Thanks!", "I have tried in colab with TF 2.5 and was able to reproduce the issue.Please, find the [gist here](https://colab.research.google.com/gist/Saduf2019/e13a1e93aa24f9af370d05e2d067e60e/untitled589.ipynb).Thanks!", "Hi There,\n\n This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! \n\n Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39878\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39878\">No</a>\n"]}, {"number": 39877, "title": "[INTEL MKL] Threadpool api support for matmuls", "body": "", "comments": ["Will close this PR and submit smaller PR's"]}, {"number": 39876, "title": "tensorflow-lite as shared(dynamic) lib for C/C++ & linux/ubuntu", "body": "Hello\r\n\r\nis there a way to build shared (dynamic) lib for TensorFlow-lite? If so, please share the steps to do so and possibly some simple example with it.\r\n\r\nThank you.", "comments": ["You can build a shared library with the following command.\r\n\r\n```sh\r\nbazel build -c opt //tensorflow/lite:tensorflowlite\r\n```\r\n\r\nPlease see the comments here:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/BUILD#L604-L609\r\n\r\nThis will output the resulting shared library (`.dll`, `.so`, or `.dylib`), which you could dynamically link into your own project. You could also provide the `tensorflow` repository root as an include path so that you could include the `tensorflow/lite/...` headers.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Thank you for your suggestion. Is there a way to generate out this lib (`.dll`, `.so`, or `.dylib`)  as you indicted for ARM64 target (cross-compile)?", "Can you try adding `--config=elinux_aarch64` flag to the build command above?\r\n\r\n    bazel build -c opt --config=elinux_aarch64 //tensorflow/lite:tensorflowlite\r\n\r\nTried this on a Linux machine and it seems to work for me.\r\n\r\n```sh\r\n$ file bazel-bin/tensorflow/lite/libtensorflowlite.so\r\nbazel-bin/tensorflow/lite/libtensorflowlite.so: ELF 64-bit LSB shared object, ARM aarch64, version 1 (GNU/Linux), dynamically linked, BuildID[md5/uuid]=d9af18419c9973a6b552eba0d4f44721, stripped\r\n```\r\n\r\ncc/ @terryheo", "OK. I'll try it but why `--config=elinux_aarch64`?\r\nI did before `--cpu=arm64`, `--cpu=aarch64` or `--cpu=arm64-v8a` ..", "seem unsuccessful\r\n\r\n```\r\n/tensorflow$ bazel build -c opt --config=elinux_aarch64 //tensorflow/lite:tensorflowlite\r\nStarting local Bazel server and connecting to it...\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=192\r\nINFO: Reading rc options for 'build' from /media/nxa18908/work/work/tensorflow/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /media/nxa18908/work/work/tensorflow/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2\r\nINFO: Found applicable config definition build:v2 in file /work/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nERROR: Config value elinux_aarch64 is not defined in any .rc file\r\n(base) /work/tensorflow$\r\n\r\n```", "The build config is defined here, and it was added recently.\r\nhttps://github.com/tensorflow/tensorflow/blob/master/.bazelrc#L76-L79\r\n\r\nWhich version of tensorflow repository are you using?", "I use tag v2.2.0", "I've switched to the latest (master) branch - now it seems building now - where is toolchain taken from (defined). \r\nIt looks it uses arm-gcc-8.3 and how could I change to the latest GCC 9.3.1?", "Please refer to this commit 4961f18733ca3967198393abf419e14476b4a85c to see more details on how the toolchain was configured.\r\n\r\nI think you'll need to update the toolchain archive url under `tensorflow/workspace.bzl`.", "Thanks a lot for your great help!", "Since I am not bazel expert :( it seems defined here within `tensorflow/workspace.bzl`\r\n\r\n```\r\n    tf_http_archive(\r\n        name = \"aarch64_linux_toolchain\",\r\n        build_file = clean_dep(\"//third_party/toolchains/embedded/arm-linux:aarch64-linux-toolchain.BUILD\"),\r\n        sha256 = \"8ce3e7688a47d8cd2d8e8323f147104ae1c8139520eca50ccf8a7fa933002731\",\r\n        strip_prefix = \"gcc-arm-8.3-2019.03-x86_64-aarch64-linux-gnu\",\r\n        urls = [\r\n            \"https://storage.googleapis.com/mirror.tensorflow.org/developer.arm.com/media/Files/downloads/gnu-a/8.3-2019.03/binrel/gcc-arm-8.3-2019.03-x86_64-aarch64-linux-gnu.tar.xz\",\r\n            \"https://developer.arm.com/-/media/Files/downloads/gnu-a/8.3-2019.03/binrel/gcc-arm-8.3-2019.03-x86_64-aarch64-linux-gnu.tar.xz\",\r\n        ],\r\n    )\r\n```", "Can be applied this similarly for label_image example project [label_image](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/label_image)?\r\n\r\n```\r\n(base) /work/tensorflow$ bazel build -c opt --config=elinux_aarch64 //tensorflow/lite/examples/label_image:label_image\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=192\r\nINFO: Reading rc options for 'build' from /media/nxa18908/work/work/tensorflow/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /work/tensorflow/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2\r\nINFO: Found applicable config definition build:v2 in file /work/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:elinux_aarch64 in file /tensorflow/.bazelrc: --config=elinux --cpu=aarch64\r\nINFO: Found applicable config definition build:elinux in file /work/tensorflow/.bazelrc: --crosstool_top=@local_config_embedded_arm//:toolchain --host_crosstool_top=@bazel_tools//tools/cpp:toolchain\r\nINFO: Found applicable config definition build:linux in file /work/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels\r\nINFO: Found applicable config definition build:dynamic_kernels in file /work/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS\r\nDEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = \"1556410077 -0400\"\r\nDEBUG: Call stack for the definition of repository 'io_bazel_rules_docker' which is a git_repository (rule definition at /.cache/bazel/3304ea97a68bfa97c98c7d713a0609dd/external/bazel_tools/tools/build_defs/repo/git.bzl:195:18):\r\n - <builtin>\r\n - /.cache/bazel/3304ea97a68bfa97c98c7d713a0609dd/external/bazel_toolchains/repositories/repositories.bzl:37:9\r\n - /work/tensorflow/WORKSPACE:37:1\r\nWARNING: Download from https://mirror.bazel.build/github.com/Maratyszcza/FP16/archive/4dfe081cf6bcd15db339cf2680b9281b8451eeb3.zip failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nWARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/XNNPACK/archive/b2217ddb5fa74db09d9da1326902269ae18e41ad.zip failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nWARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/pytorch/cpuinfo/archive/6cecd15784fcb6c5c0aa7311c6248879ce2cb8b2.zip failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nWARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/Maratyszcza/pthreadpool/archive/18a7156cb9be8e534acefade42e46d4209600c35.zip failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nWARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/Maratyszcza/psimd/archive/072586a71b55b7f8c584153d223e95687148a900.zip failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nINFO: Analyzed target /tensorflow/lite/examples/label_image:label_image (0 packages loaded, 0 targets configured).\r\nINFO: Found 1 target...\r\nERROR: /work/tensorflow/tensorflow/lite/examples/label_image/BUILD:15:1: undeclared inclusion(s) in rule '/tensorflow/lite/examples/label_image:label_image':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/lite/examples/label_image/label_image.cc':\r\n  'external/com_google_absl/absl/strings/string_view.h'\r\n  'external/com_google_absl/absl/base/internal/throw_delegate.h'\r\nTarget //tensorflow/lite/examples/label_image:label_image failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 3.413s, Critical Path: 3.17s\r\nINFO: 10 processes: 10 local.\r\nFAILED: Build did NOT complete successfully\r\n```", "1) Do you have a reason to use a specific version of GCC? I'd suggest sticking to the provided GCC version.\r\n\r\n2) For fixing the label_image build, you could try editing the `tensorflow/lite/examples/label_image/BUILD` file.\r\n\r\n```diff\r\ndiff --git a/tensorflow/lite/examples/label_image/BUILD b/tensorflow/lite/examples/label_image/BUILD\r\nindex 92bb503e6d..3f4d10cc57 100644\r\n--- a/tensorflow/lite/examples/label_image/BUILD\r\n+++ b/tensorflow/lite/examples/label_image/BUILD\r\n@@ -38,6 +38,8 @@ cc_binary(\r\n         \"//tensorflow/lite/profiling:profiler\",\r\n         \"//tensorflow/lite/tools/evaluation:utils\",\r\n         \"@com_google_absl//absl/memory\",\r\n+        \"@com_google_absl//absl/base\",\r\n+        \"@com_google_absl//absl/strings\",\r\n     ] + select({\r\n         \"//tensorflow:android\": [\r\n             \"//tensorflow/lite/delegates/gpu:delegate\",\r\n```", "1. nope - I'd like to know where to change it :)\r\n2. need to exercise built lib (static, dynamic) with various options and exercise RUY.", "Sure. Could this issue be considered resolved then? Or are you still blocked on something?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39876\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39876\">No</a>\n"]}, {"number": 39875, "title": "autograph for bool logic control incorrect", "body": "tf version: 2.1.0\r\nHW: one gpu\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\n@tf.function\r\ndef check_zero(data):\r\n    tf.print(data)\r\n    if data == 0:\r\n        tf.print(\"check zero yes\")\r\n        return True\r\n    else:\r\n        tf.print(\"check zero no\")\r\n        return False\r\n\r\n@tf.function\r\ndef test_arg(a):\r\n    is_zero = check_zero(a)\r\n    \r\n    if is_zero is True:\r\n        tf.print(\"zero\")\r\n    else:\r\n        tf.print(\"not zero\")\r\n\r\nfor i in range(3):\r\n    test_arg(i)\r\n```\r\n![image](https://user-images.githubusercontent.com/731496/82915054-d711ae80-9fa2-11ea-9f0b-3187d95b7ce8.png)\r\n", "comments": ["if replace\r\n``` python\r\n    if is_zero is True:\r\n```\r\nto\r\n```python\r\nif tf.equal(is_zero, True):\r\n```\r\nthe result will be fine. but the first one seems more friendly for engineer. ", "I think this is because `is` keywords is not implemented in autograph yet? But if I understand correctly, `is` is testing for identity, not equality. So `if is_zero is True:` probably makes sense as `True` is unique. But the other usages of `is` may not be feasible? /cc @mdanatg as this might be related.", "@w19787 \r\nPlease update as per above comment", "+1 to @yongtang 's note\r\n\r\nI recommend using the value directly: `if is_zero:`. You can also use an equality check like `if is_zero == True:`, but there's no obvious advantage to it.\r\n\r\nIndeed, autograph doesn't implement `is` and strictly speaking I'm not sure that it can, judging from the [SO answer](https://stackoverflow.com/questions/27276610/boolean-identity-true-vs-is-true), because the semantics of `a is True` mean \"a is exactly the singleton object True\", in other words `id(a) == id(True)`. Take for example another True-like object:\r\n\r\n```\r\nnp_true = np.array(True)\r\n\r\nbool(np_true)\r\n# True\r\n\r\nnp_true == True\r\n# True\r\n\r\nnp_true is True\r\n# False\r\n```\r\n", "the comments are acceptable. thanks. this issue will be closed.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39875\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39875\">No</a>\n"]}, {"number": 39874, "title": "asserterror when using tf.cond", "body": "Assert error when using tf.cond, \r\nHere is the code stucture, it works fine when I run it eagerly, but get errors when build graph.\r\n\r\n```python\r\n    def kf():\r\n     # some compute\r\n        for t in range(N):\r\n            a, p, pinf = tf.cond(tf.reduce_max(pinf) > tf.constant(1e-8, tf.float64),\r\n                                 lambda: self.kf_init_step(self.data[t], a, p, pinf, self.H[t], self.Q[t]),\r\n                                 lambda: self.kf_step(self.data[t], a, p, pinf, self.H[t], self.Q[t]))\r\n            a_list.append(a)\r\n            p_list.append(p)\r\n            pinf_list.append(pinf)\r\n\r\n\r\n    def kf_init_step(self, y, a, p, pinf, H, Q):\r\n        # some compute\r\n        return a_new, p_new, pinf_new\r\n\r\n    def kf_step(self, y, a, p, pinf, H, Q):\r\n        # some compute\r\n        return a_new, p_new, pinf\r\n```\r\nTrackback:\r\n\r\n```python\r\nTraceback (most recent call last):\r\n  File \"/Users/mac/Documents/bishe/DeepStateCount/DCSSM/run.py\", line 50, in <module>\r\n    dssm.fit(train_ds, epochs=10, callbacks=[checkpoint])\r\n  File \"/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\", line 819, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 235, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 593, in _process_training_inputs\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 706, in _process_inputs\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/data_adapter.py\", line 702, in __init__\r\n    x = standardize_function(x)\r\n  File \"/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 660, in standardize_function\r\n    standardize(dataset, extract_tensors_from_dataset=False)\r\n  File \"/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\", line 2346, in _standardize_user_data\r\n    all_inputs, y_input, dict_inputs = self._build_model_with_inputs(x, y)\r\n  File \"/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\", line 2572, in _build_model_with_inputs\r\n    self._set_inputs(cast_inputs)\r\n  File \"/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\", line 2659, in _set_inputs\r\n    outputs = self(inputs, **kwargs)\r\n  File \"/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 773, in __call__\r\n    outputs = call_fn(cast_inputs, *args, **kwargs)\r\n  File \"/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py\", line 237, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nAssertionError: in converted code:\r\n\r\n    /Users/mac/Documents/bishe/DeepStateCount/DCSSM/DSSM.py:85 call  *\r\n        loglikes = tf.map_fn(lambda x: self.linearloglike(x[0], x[1], x[2]),\r\n    /Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/map_fn.py:268 map_fn\r\n        maximum_iterations=n)\r\n    /Users/mac/Documents/bishe/DeepStateCount/DCSSM/DSSM.py:127 linearloglike  *\r\n        return linearssm.loglikelihood()\r\n    /Users/mac/Documents/bishe/DeepStateCount/DCSSM/LinearSSM.py:92 loglikelihood  *\r\n        filtered = self.kalman_filter()\r\n    /Users/mac/Documents/bishe/DeepStateCount/DCSSM/LinearSSM.py:48 kalman_filter  *\r\n        res = tf.cond(tf.reduce_max(pinf) > tf.constant(1e-8, dtype=tf.float64),\r\n    /Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/control_flow_ops.py:1389 cond_for_tf_v2\r\n        return cond(pred, true_fn=true_fn, false_fn=false_fn, strict=True, name=name)\r\n    /Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py:507 new_func\r\n        return func(*args, **kwargs)\r\n    /Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/control_flow_ops.py:1174 cond\r\n        return cond_v2.cond_v2(pred, true_fn, false_fn, name)\r\n    /Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/cond_v2.py:100 cond_v2\r\n        name=scope)\r\n    /Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/cond_v2.py:219 _build_cond\r\n        _make_indexed_slices_indices_types_match(_COND, [true_graph, false_graph])\r\n    /Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/cond_v2.py:627 _make_indexed_slices_indices_types_match\r\n        assert len(set(outs_per_branch)) == 1, outs_per_branch\r\n\r\n    AssertionError: [1, 3]\r\n```", "comments": ["Please fill in issue template. Also, please post output of `pip list`", "**Have I written custom code** : true\r\n**OS Platform and Distribution**  MacOS Catalina 10.15.4\r\n**TensorFlow installed from** : pip\r\n**TensorFlow version** : v2.1.0\r\n**Describe the current behavior**\r\nAssert error when using tf.cond\r\n\r\n**Describe the expected behavior**\r\nIt should work.\r\n\r\n\r\npip  list output\r\n\r\n```\r\nPackage                Version\r\n---------------------- ------------\r\nabsl-py                0.8.0\r\nappnope                0.1.0\r\nastor                  0.8.0\r\nattrs                  19.1.0\r\nbackcall               0.1.0\r\nbleach                 3.1.0\r\ncachetools             4.0.0\r\ncertifi                2019.11.28\r\nchardet                3.0.4\r\ncloudpickle            1.3.0\r\ncycler                 0.10.0\r\ndecorator              4.4.0\r\ndefusedxml             0.6.0\r\nentrypoints            0.3\r\ngast                   0.2.2\r\ngoogle-auth            1.12.0\r\ngoogle-auth-oauthlib   0.4.1\r\ngoogle-pasta           0.1.7\r\ngrpcio                 1.28.1\r\nh5py                   2.10.0\r\nidna                   2.9\r\nipykernel              5.1.2\r\nipython                7.8.0\r\nipython-genutils       0.2.0\r\nipywidgets             7.5.1\r\njedi                   0.15.1\r\nJinja2                 2.10.1\r\njoblib                 0.14.1\r\njson5                  0.9.4\r\njsonschema             3.0.2\r\njupyter                1.0.0\r\njupyter-client         5.3.3\r\njupyter-console        6.0.0\r\njupyter-core           4.5.0\r\njupyterlab             2.1.0\r\njupyterlab-server      1.1.1\r\nKeras-Applications     1.0.8\r\nKeras-Preprocessing    1.1.0\r\nkiwisolver             1.1.0\r\nlightgbm               2.3.1\r\nMarkdown               3.1.1\r\nMarkupSafe             1.1.1\r\nmatplotlib             3.1.3\r\nmistune                0.8.4\r\nnbconvert              5.6.0\r\nnbformat               4.4.0\r\nnotebook               6.0.1\r\nnumpy                  1.17.2\r\noauthlib               3.1.0\r\nopt-einsum             3.2.0\r\npandas                 0.25.1\r\npandocfilters          1.4.2\r\nparso                  0.5.1\r\npatsy                  0.5.1\r\npexpect                4.7.0\r\npickleshare            0.7.5\r\npip                    20.0.2\r\nprometheus-client      0.7.1\r\nprompt-toolkit         2.0.9\r\nprotobuf               3.9.2\r\nptyprocess             0.6.0\r\npyasn1                 0.4.8\r\npyasn1-modules         0.2.8\r\nPygments               2.4.2\r\npyparsing              2.4.6\r\npyrsistent             0.15.4\r\npython-dateutil        2.8.0\r\npytz                   2019.3\r\npyzmq                  18.1.0\r\nqtconsole              4.5.5\r\nrequests               2.23.0\r\nrequests-oauthlib      1.3.0\r\nrsa                    4.0\r\nscikit-learn           0.22.2.post1\r\nscipy                  1.4.1\r\nSend2Trash             1.5.0\r\nsetuptools             46.1.3\r\nsix                    1.12.0\r\nsklearn                0.0\r\nstatsmodels            0.11.1\r\ntensorboard            2.1.1\r\ntensorflow             2.1.0\r\ntensorflow-estimator   2.1.0\r\ntensorflow-probability 0.9.0\r\ntermcolor              1.1.0\r\nterminado              0.8.2\r\ntestpath               0.4.2\r\ntorch                  1.2.0\r\ntornado                6.0.3\r\ntraitlets              4.3.2\r\nurllib3                1.25.8\r\nwcwidth                0.1.7\r\nwebencodings           0.5.1\r\nWerkzeug               0.16.0\r\nwheel                  0.33.6\r\nwidgetsnbextension     3.5.1\r\nwrapt                  1.11.2\r\nWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\r\nYou should consider upgrading via the '/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/bin/python3.6 -m pip install --upgrade pip' command.\r\n```", "@AngelPone \r\n\r\nCan you share colab link or simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 39873, "title": "Tensorflow see's GPU but only uses xla_cpu and crashes when told to use xla_gpu", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): True (I'm not using a code example but I have not written custom code within Tensorflow)\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ms Windows 10 Home - 10.0.18363\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): TensorFlow 2.2.0 installed using: pip install --upgrade tensorflow\r\n\r\n- TensorFlow version (use command below):\r\nCode: \r\nimport tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\r\nOutput:\r\n2020-05-26 09:27:35.360714: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\nv2.2.0-rc4-8-g2b96f3662b 2.2.0\r\n- Python version: 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)]\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: \r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2019 NVIDIA Corporation\r\nBuilt on Fri_Feb__8_19:08:26_Pacific_Standard_Time_2019\r\nCuda compilation tools, release 10.1, V10.1.105\r\n\r\n- GPU model and memory:\r\nincarnation: 17283739609840781326\r\nphysical_device_desc: \"device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\r\n, name: \"/device:XLA_GPU:0\"\r\ndevice_type: \"XLA_GPU\"\r\nmemory_limit: 17179869184\r\nlocality {\r\n}\r\nincarnation: 2207722455070197847\r\nphysical_device_desc: \"device: XLA_GPU device\"\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nI was training my models when it felt like they were running very slowly. After some digging I noticed that device GPU 0 is type xla_cpu and is not going through my gpu. device xla_gpu is listed but when forcing tensforflow to use it just crashes saying it can't find ptaxs.\r\n\r\n**Describe the expected behavior**\r\nI was hoping that TensorFlow would be able to use my gpu by default.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nI don't think this would be very useful but the error happens on the line with tf.device('/...\r\nif I remove 'with tf.device('/device:XLA_GPU:0'):' everything works but tensorflow use my cpu with xla_cpu\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nI've posted more information here (I think it would be more readable than if I were to just copy and paste it here):\r\nhttps://stackoverflow.com/questions/62009497/tensorflow-sees-gpu-but-only-uses-xla-cpu-and-crashes-when-told-to-use-xla-gpu", "comments": ["Forgot to include cudnn\r\nPS C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.1\\bin> type \"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.1\\include\\cudnn.h\" | findstr \"CUDNN_MAJOR CUDNN_MINOR CUDNN_PATCHLEVEL\"\r\n#define CUDNN_MAJOR 7\r\n#define CUDNN_MINOR 6\r\n#define CUDNN_PATCHLEVEL 5\r\n#define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)", "@Tolure,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here. Thanks!", "Example taken from [tensorflow.org/tutorials/quickstart/beginner](https://www.tensorflow.org/tutorials/quickstart/beginner)\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nmnist = tf.keras.datasets.mnist\r\n\r\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\nx_train, x_test = x_train / 255.0, x_test / 255.0\r\n\r\nmodel = tf.keras.models.Sequential([\r\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\r\n  tf.keras.layers.Dense(128, activation='relu'),\r\n  tf.keras.layers.Dropout(0.2),\r\n  tf.keras.layers.Dense(10)\r\n])\r\n\r\npredictions = model(x_train[:1]).numpy()\r\npredictions\r\n\r\ntf.nn.softmax(predictions).numpy()\r\n\r\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\n\r\nloss_fn(y_train[:1], predictions).numpy()\r\n\r\nmodel.compile(optimizer='adam',\r\n              loss=loss_fn,\r\n              metrics=['accuracy'])\r\n\r\nmodel.fit(x_train, y_train, epochs=5)\r\n\r\nmodel.evaluate(x_test,  y_test, verbose=2)\r\n\r\nprobability_model = tf.keras.Sequential([\r\n  model,\r\n  tf.keras.layers.Softmax()\r\n])\r\n\r\nprobability_model(x_test[:5])\r\n\r\n\r\n```", "Partial Output\r\n```\r\nD:\\PiChess\\Core\\venv\\Scripts\\python.exe D:/PiChess/Core/test2.py\r\n2020-06-02 08:11:16.900320: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-06-02 08:11:54.284505: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2020-06-02 08:11:54.447139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1\r\ncoreClock: 1.62GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s\r\n2020-06-02 08:11:54.447601: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-06-02 08:11:54.470626: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-06-02 08:11:54.499935: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-06-02 08:11:54.506379: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-06-02 08:11:54.530038: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-06-02 08:11:54.546462: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-06-02 08:11:54.646082: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-06-02 08:11:54.673195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-06-02 08:11:54.698883: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2020-06-02 08:11:55.703422: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2c48cc5b0a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-06-02 08:11:55.703839: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-06-02 08:11:55.753110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1\r\ncoreClock: 1.62GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s\r\n2020-06-02 08:11:55.753637: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-06-02 08:11:55.753889: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-06-02 08:11:55.754132: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-06-02 08:11:55.754374: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-06-02 08:11:55.754618: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-06-02 08:11:55.754863: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-06-02 08:11:55.755107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-06-02 08:11:55.756055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-06-02 08:12:08.073083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-06-02 08:12:08.073349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \r\n2020-06-02 08:12:08.073520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \r\n2020-06-02 08:12:08.080176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2990 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2020-06-02 08:12:08.094234: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2c4ca455240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-06-02 08:12:08.094563: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1050 Ti, Compute Capability 6.1\r\n2020-06-02 08:12:08.327212: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\nEpoch 1/5\r\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.2924 - accuracy: 0.9156\r\nEpoch 2/5\r\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.1401 - accuracy: 0.9579\r\nEpoch 3/5\r\n1875/1875 [==============================] - 5s 3ms/step - loss: 0.1042 - accuracy: 0.9686\r\nEpoch 4/5\r\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0857 - accuracy: 0.9740\r\nEpoch 5/5\r\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0734 - accuracy: 0.9768\r\n313/313 - 1s - loss: 0.0740 - accuracy: 0.9789\r\n```\r\nImage taken during model fitting. \r\n\r\n![image](https://user-images.githubusercontent.com/3880648/83519003-3d1d9a80-a4a9-11ea-81cd-0ae09f1e5cb4.png)\r\n", "There are other files in the project. Please let me know if there is another file that you would need to isolate this issue. ", "If this is more than you wanted. I'll gladly trim it back to the method that is causing the issue. ", "For more information. When I start the program and it loads in the first model my GPU doesn't get used but it does something gets loaded into it's dedicated memory. The picture bellow is after a minute or three of the first model being fit. \r\n\r\n![image](https://user-images.githubusercontent.com/3880648/83295031-5201e180-a1bc-11ea-918f-323f80ab96f0.png)\r\n ", "@Tolure,\r\nLooks like you are using custom modules like `DatasetTemplates`, `Markets`, `Services` in your script, because of which I am unable to run the code.\r\n\r\nCould you please trim the code to the part which is causing the issue. Thanks! ", "I've replaced my code in the comments above with code taken from https://www.tensorflow.org/tutorials/quickstart/beginner and my GPU is still not being used. \r\n\r\n", "@Tolure,\r\nThank you for the update. Could you please try the code from [this guide](https://www.tensorflow.org/guide/gpu#logging_device_placement) and let us know if you are able to use the GPU. Thanks!", "Code I ran\r\n```\r\nimport tensorflow as tf\r\n\r\ntf.debugging.set_log_device_placement(True)\r\n\r\n# Create some tensors\r\na = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\r\nb = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\r\nc = tf.matmul(a, b)\r\n\r\nprint(c)\r\n\r\ntf.debugging.set_log_device_placement(True)\r\n\r\n# Place tensors on the CPU\r\nwith tf.device('/CPU:0'):\r\n  a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\r\n  b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\r\n\r\nc = tf.matmul(a, b)\r\nprint(c)\r\n\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\nif gpus:\r\n  # Restrict TensorFlow to only use the first GPU\r\n  try:\r\n    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\r\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\r\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\r\n  except RuntimeError as e:\r\n    # Visible devices must be set before GPUs have been initialized\r\n    print(e)\r\n\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\nif gpus:\r\n  try:\r\n    # Currently, memory growth needs to be the same across GPUs\r\n    for gpu in gpus:\r\n      tf.config.experimental.set_memory_growth(gpu, True)\r\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\r\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\r\n  except RuntimeError as e:\r\n    # Memory growth must be set before GPUs have been initialized\r\n    print(e)\r\n\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\nif gpus:\r\n  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\r\n  try:\r\n    tf.config.experimental.set_virtual_device_configuration(\r\n        gpus[0],\r\n        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\r\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\r\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\r\n  except RuntimeError as e:\r\n    # Virtual devices must be set before GPUs have been initialized\r\n    print(e)\r\n\r\ntf.debugging.set_log_device_placement(True)\r\n\r\ntry:\r\n  # Specify an invalid GPU device\r\n  with tf.device('/device:GPU:2'):\r\n    a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\r\n    b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\r\n    c = tf.matmul(a, b)\r\nexcept RuntimeError as e:\r\n  print(e)\r\n\r\ntf.config.set_soft_device_placement(True)\r\ntf.debugging.set_log_device_placement(True)\r\n\r\n# Creates some tensors\r\na = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\r\nb = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\r\nc = tf.matmul(a, b)\r\n\r\nprint(c)\r\n\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\nif gpus:\r\n  # Create 2 virtual GPUs with 1GB memory each\r\n  try:\r\n    tf.config.experimental.set_virtual_device_configuration(\r\n        gpus[0],\r\n        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024),\r\n         tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\r\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\r\n    print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\r\n  except RuntimeError as e:\r\n    # Virtual devices must be set before GPUs have been initialized\r\n    print(e)\r\n```\r\nOut put of code \r\n\r\n```\r\nD:\\PiChess\\Core\\venv\\Scripts\\python.exe D:/PiChess/Core/test2.py\r\n2020-06-02 13:58:59.203161: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-06-02 13:59:02.276915: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2020-06-02 13:59:02.311070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1\r\ncoreClock: 1.62GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s\r\n2020-06-02 13:59:02.311686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-06-02 13:59:02.317279: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-06-02 13:59:02.322589: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-06-02 13:59:02.324595: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-06-02 13:59:02.330553: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-06-02 13:59:02.334928: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-06-02 13:59:02.348204: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-06-02 13:59:02.349926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-06-02 13:59:02.350804: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2020-06-02 13:59:02.363508: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1b4e6501870 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-06-02 13:59:02.364066: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-06-02 13:59:02.365092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1\r\ncoreClock: 1.62GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s\r\n2020-06-02 13:59:02.365772: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-06-02 13:59:02.366483: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-06-02 13:59:02.366820: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-06-02 13:59:02.367107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-06-02 13:59:02.367375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-06-02 13:59:02.367646: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-06-02 13:59:02.368306: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-06-02 13:59:02.369539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-06-02 13:59:03.273280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-06-02 13:59:03.273644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \r\n2020-06-02 13:59:03.273811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \r\n2020-06-02 13:59:03.275025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2990 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2020-06-02 13:59:03.279696: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1b489739f70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-06-02 13:59:03.280129: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1050 Ti, Compute Capability 6.1\r\n2020-06-02 13:59:03.282716: I tensorflow/core/common_runtime/eager/execute.cc:501] Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0\r\n2020-06-02 13:59:03.283166: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\ntf.Tensor(\r\n[[22. 28.]\r\n [49. 64.]], shape=(2, 2), dtype=float32)\r\ntf.Tensor(\r\n[[22. 28.]\r\n [49. 64.]], shape=(2, 2), dtype=float32)\r\n1 Physical GPUs, 1 Logical GPU\r\nPhysical devices cannot be modified after being initialized\r\nVirtual devices cannot be modified after being initialized\r\ntf.Tensor(\r\n[[22. 28.]\r\n [49. 64.]], shape=(2, 2), dtype=float32)\r\nVirtual devices cannot be modified after being initialized\r\n2020-06-02 13:59:03.870194: I tensorflow/core/common_runtime/eager/execute.cc:501] Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0\r\n\r\nProcess finished with exit code 0\r\n```", "My device with `name: \"/device:GPU:0\"` has the following attribute `physical_device_desc: \"device: XLA_CPU device\"`\r\n\r\nFor a little information that might be relevant. Running the code:\r\n```\r\nfrom tensorflow.python.client import device_lib\r\nprint(device_lib.list_local_devices())\r\n```\r\nOutputs:\r\n```\r\n[name: \"/device:CPU:0\"\r\ndevice_type: \"CPU\"\r\nmemory_limit: 268435456\r\nlocality {\r\n}\r\nincarnation: 3593757145487346910\r\n, name: \"/device:XLA_CPU:0\"\r\ndevice_type: \"XLA_CPU\"\r\nmemory_limit: 17179869184\r\nlocality {\r\n}\r\nincarnation: 15151200481806228159\r\nphysical_device_desc: \"device: XLA_CPU device\"\r\n, name: \"/device:GPU:0\"\r\ndevice_type: \"GPU\"\r\nmemory_limit: 3136264601\r\nlocality {\r\n  bus_id: 1\r\n  links {\r\n  }\r\n}\r\nincarnation: 17283739609840781326\r\nphysical_device_desc: \"device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\r\n, name: \"/device:XLA_GPU:0\"\r\ndevice_type: \"XLA_GPU\"\r\nmemory_limit: 17179869184\r\nlocality {\r\n}\r\nincarnation: 2207722455070197847\r\nphysical_device_desc: \"device: XLA_GPU device\"\r\n]\r\n``` ", "Is there any other information I can provide that could help with this bug?", "What happens if you explicitly set placement on `tf.device('/device:GPU:0')`?\r\nAlso what is your cudnn version?\r\nXLA creates an XLA_GPU device whereas TF creates GPU device.\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39873\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39873\">No</a>\n", "> Is there any other information I can provide that could help with this bug?\r\n\r\nHave you solved this issue? I have the same problem.", "Yeah, same question.", "The following solution worked for me:\r\nconda uninstall tensorflow\r\nconda uninstall  cudatoolkit\r\nconda uninstall tensorflow-gpu\r\n\r\nconda install  tensorflow==2.1.0\r\nconda install cudatoolkit\r\nconda install  tensorflow-gpu\r\n\r\nif it is not working with conda try pip or conda forge\r\n\r\nThere are some conflicts with newer TF and Cuda drivers, and it could be a solution."]}, {"number": 39872, "title": "Mixing XLA and non XLA autograph triggers retracing", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): True\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux (Colab, I'm not sure what the os is)\r\n- TensorFlow installed from (source or binary): Colab\r\n- TensorFlow version (use command below): 2.2.0\r\n\r\n\r\n\r\n**Describe the current behavior**\r\nMixing XLA (experimental_compile) and non XLA functions results in constant retracing\r\n\r\n**Describe the expected behavior**\r\nFunctions inside an XLA function should inherit the option, XLA functions inside non XLA ones shouldn't retrace.\r\n\r\nThis is particularly important when relying on third-party libraries making use of the functionality.\r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://colab.research.google.com/drive/1PrKsKSiKyGjjmX8Itub_BKe-SEihuWMM?usp=sharing\r\n\r\n\r\n", "comments": ["I ran the gist shared and was able to replicate the issue, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/c5ceac8ed5f3bf255ed941125576e151/untitled204.ipynb)", "@allenlavoie Any thoughts?", "Probably outer retracing triggers inner retracing because of this entry for the cache key: https://github.com/tensorflow/tensorflow/blob/5c7469978913e8e9590c60cd2605923d0f53f0be/tensorflow/python/eager/function.py#L2978-L2982\r\n\r\nSo whoever added that might be a good person to check with.", "@rxsang Do we need to put the XLA context id there? Isn't it sufficient to know whether the outer XLA context exists or not?", "@allenlavoie Thanks!\r\nAnd @AdrienCorenflos thanks a lot for the report.", "That's intended for TPU case, as we need to make sure the inner and outer XLA context match. Maybe it could be relaxed for non TPU case.\r\n\r\n> @rxsang Do we need to put the XLA context id there? Isn't it sufficient to know whether the outer XLA context exists or not?\r\n\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39872\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39872\">No</a>\n"]}, {"number": 39871, "title": "\"ImportError: cannot import name tf2\" when doing Object Detection Model Training in Google Cloud", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:-\r\n- TensorFlow installed from (source or binary):pip install\r\n- TensorFlow version (use command below):('v1.15.0-rc3-22-g590d6ee', '1.15.0')\r\n- Python version:2.7.12\r\n- Bazel version (if compiling from source):-\r\n- GCC/Compiler version (if compiling from source):gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\nStarting a training job on google cloud for my object detection dataset. Job stops after ~7 minutes giving this error:\r\n`Traceback (most recent call last):\r\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/model_main.py\", line 26, in <module>\r\n    from object_detection import model_lib\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/model_lib.py\", line 28, in <module>\r\n    from object_detection import exporter as exporter_lib\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/exporter.py\", line 23, in <module>\r\n    from object_detection.builders import model_builder\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/builders/model_builder.py\", line 39, in <module>\r\n    from object_detection.utils import tf_version\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/utils/tf_version.py\", line 17, in <module>\r\n    from tensorflow.python import tf2  # pylint: disable=import-outside-toplevel\r\nImportError: cannot import name tf2`\r\nLocal training however works fine, but is really slow and will take at least a week.\r\n\r\n\r\nAs I'm using tensorflow 1.15 this error should'nt occur...?\r\n\r\n\r\nInstall Tensorflow 1.15 with pip, all other libraries for the API, model repository, pycocotools, protobuf 3.11.4 -> testing the API installation works fine.\r\nCreate dataset including tfrecord files, training pipeline, googlecloud yaml file, ...\r\nRun google cloud training job with:\r\n# in tensorflow/models/research\r\n    gcloud ai-platform jobs submit training balls200_training_260520a     --runtime-version 1.12     --job-dir=gs://200balls_model/train     --packages dist/object_detection-0.1.tar.gz,slim/dist/slim-0.1.tar.gz,tmp/pycocotools/pycocotools-2.0.tar.gz     --module-name object_detection.model_main     --region us-central1     --config /home/ubuntu/Documents/200balls_modeltraining/cloud.yml     --     --model_dir=gs://200balls_model/train     --pipeline_config_path=gs://200balls_model/pipeline.config  \r\n", "comments": ["@sohartma \r\n\r\nThis issue is more suitable for TensorFlow Models repo. Please post it on Models repo from [here.](https://github.com/tensorflow/models/issues) Thanks!", "@ravikyram thanks!", "@sohartma \r\n\r\nCan we close the issue here and track the issue in Models repo. Thanks!", "Closing in favor of https://github.com/tensorflow/models/issues/8572", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39871\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39871\">No</a>\n", "@ravikyram sure!"]}, {"number": 39870, "title": "Issue with fetching of Output Tensor sizes in Model", "body": "Output Size in tfLite Model for few networks are obtained only after the allocation of Tensorflow lite tensors. Could you please explain why it is special with the models like above . When I fetch the output dimensions of each output in the Model before allocation of tensors , I was getting the dimensions as zero.\r\n\r\nExample : - http://storage.googleapis.com/download.tensorflow.org/models/tflite/coco_ssd_mobilenet_v1_1.0_quant_2018_06_29.zip\r\n\r\nOutput Size in tfLite Model for few other networks are obtained only independent of the allocation of Tensorflow lite tensors.  When I fetch the output dimensions of each output in the Model before allocation of tensors , I was getting the proper dimensions. \r\n\r\nExample : -\r\nhttps://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_1.0_224.tgz\r\n\r\nPlease explain the reason of this behaviour based on model\r\n", "comments": ["@pranathibl,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the TensorFlow version you are using. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Hi,\r\n\r\nI have tensor flow interpreter c++ API to fetch the number of dimensions of each Output.\r\n\r\nIt was returning zero before allocation for few models. after allocation, No. of dimensions were proper.\r\n\r\n![Picture15](https://user-images.githubusercontent.com/47776253/84111159-f77e4600-aa43-11ea-8274-c0252621ed43.png)\r\n", "This is intended behavior. Some models, like the SSD one mentioned in the description, have ops that 'decide' the output tensor dimensions when they go through the `Prepare` phase (this is the phase where op kernels will typically initialize any temporary tensors they need, or programmatically determine their output tensor sizes based on params etc).\r\n\r\nIf a model doesn't contain any such ops, the output tensor is available before `AllocateTensors()` (which runs the `Prepare` phase of applicable ops). Otherwise, you have to do this after `AllocateTensors()`."]}, {"number": 39869, "title": "'too many indices for array' exception depending on tensor length when masking a tensor", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows10\r\n- TensorFlow installed from (source or binary): via pip\r\n- TensorFlow version (use command below): tensorflow 2.2.0\r\n- Python version: 3.7.7\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: Nvidia GTX 970\r\n\r\n**Describe the current behavior**\r\nI want to select possible indices based on the value of a tensor. In this case I want to get all possible indices of the tensor, where the entry of the tensor is smaller than some value.\r\n\r\nThough depending solely on the length of a sequence it throws unexpected 'too many indices for array' exceptions.\r\n\r\nHere is the minimal problem, that reproduces the error on my machine\r\n\r\n```\r\n# failing example\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nsentence = tf.constant([2, 92, 79, 378, 12, 2, 1396, 596, 11, 142, 7, 1901, 6, 11, 9, 1263, 21394, 346, 5, 2, 3086, 4])\r\ntarget_vocab_size = 1000\r\npossible_indices = np.arange(len(sentence))[(sentence < target_vocab_size)]\r\n```\r\n\r\nIf I now do nothing but enlarging the tensor, by simply copy pasting its values twice it works.\r\n\r\n```\r\n# working example\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nsentence = tf.constant([2, 92, 79, 378, 12, 2, 1396, 596, 11, 142, 7, 1901, 6, 11, 9, 1263, 21394, 346, 5, 2, 3086, 4,\r\n                        2, 92, 79, 378, 12, 2, 1396, 596, 11, 142, 7, 1901, 6, 11, 9, 1263, 21394, 346, 5, 2, 3086, 4])\r\ntarget_vocab_size = 1000\r\npossible_indices = np.arange(len(sentence))[(sentence < target_vocab_size)]\r\n```\r\n\r\nWhen explicitly calling .numpy() on the mask it also works with the shorter tensor\r\n\r\n```import numpy as np\r\nimport tensorflow as tf\r\n\r\nsentence = tf.constant([2, 92, 79, 378, 12, 2, 1396, 596, 11, 142, 7, 1901, 6, 11, 9, 1263, 21394, 346, 5, 2, 3086, 4])\r\n\r\ntarget_vocab_size = 1000\r\npossible_indices = np.arange(len(sentence))[(sentence < target_vocab_size).numpy()]\r\n```\r\n\r\nWhen replacing tensorflow with numpy all the way it works just fine as well\r\n\r\n```import numpy as np\r\n\r\nsentence = np.array([2, 92, 79, 378, 12, 2, 1396, 596, 11, 142, 7, 1901, 6, 11, 9, 1263, 21394, 346, 5, 2, 3086, 4])\r\ntarget_vocab_size = 1000\r\npossible_indices = np.arange(len(sentence))[(sentence < target_vocab_size)]\r\n```\r\n\r\n\r\n", "comments": ["@raharth \r\nPlease refer to [this link](https://stackoverflow.com/questions/28036812/indexerror-too-many-indices-for-array) and this [link](https://stackoverflow.com/questions/37163047/python-too-many-indices-for-array/37165328) let us know if it helps\r\n\r\n\r\n", "@Saduf2019 \r\n\r\nThanks for the fast reply!\r\n\r\nI have seen that posts but I think it is a different problem.\r\n\r\nIf I run a loop over sentences of different length, it sometimes work sometimes it does not, even though all of them have the same shape (1D tensors). To demonstrate that I have added the code with a tensor of the same shape but a different length. Empirically it works with tensors longer than ~30 entries, but fails with shorter ones.\r\n\r\nIf you run the two first code snippets you should see the problem. The second array breaks the line, but it is still a 1D tensor! (sorry if that was not clear by the way I formatted it)\r\n\r\nIf I simply replace `tf.tensor` by `np.array` it works. If I explicitly call `.numpy()` on the mask it works as well for short and long sequences. So the problem shouldn't be related to the shape of the tensor.", "i am able to replicate this issue, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/d8fccfb3293a1a54dec5ae4361cfba68/untitled198.ipynb), Thanks!", "I can able to reproduce the issue using TF 2.5 version and the issue still exists. Thanks!", "@raharth What is the problem with `.numpy()` method. It works as expected right?  Can you add little more details on what was the problem. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "@jvishnuvardhan It works, yes, but I kind of have emotional trouble to rely on libs that (at least on my end) throw unpredictable and undescriptive errors :) but no for real, it throws a 'too many indices for array' exception depending on array/tensor length if the array is too **short**, so the error message seems to be unrelated to the issue and from the viewpoint of someone just using TF there is no apparent reason why the length of an input tensor that is a constant should lead to such behavior.\r\nThus, I just wanted to report the issue! :)\r\n\r\nIf you know the reason and could explain whats happening I would be highly interested though! ", "Hi @raharth ! I think you were intending to use the above code by[ this way](https://colab.sandbox.google.com/gist/mohantym/a3b8188b9df3d5a94c6a4c1be457443a/untitled198.ipynb#scrollTo=qXWYKxBJrsh6). Attaching relevant threads for reference.[ link1](https://stackoverflow.com/questions/28036812/indexerror-too-many-indices-for-array),[link2](https://stackoverflow.com/questions/47733704/numpy-array-indexerror-too-many-indices-for-array/47733775)", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39869\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39869\">No</a>\n"]}, {"number": 39868, "title": "TFLu: Update RELU", "body": "Current RELU was not bit exact to Convnet\r\n", "comments": ["@petewarden ping for review", "@mansnils can you please check below error \r\n\r\n`tensorflow/lite/micro/kernels/activations.cc:40:48: error: implicit conversion increases floating-point precision: 'float' to 'double' [-Werror,-Wdouble-promotion]\r\n  double real_multiplier = input->params.scale / output->params.scale;\r\n         ~~~~~~~~~~~~~~~   ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~/tensorflow/lite/micro/kernels/activations.cc:40:48: error: implicit conversion increases floating-point precision: 'float' to 'double' [-Werror,-Wdouble-promotion]\r\n  double real_multiplier = input->params.scale / output->params.scale;\r\n         ~~~~~~~~~~~~~~~   ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~/tensorflow/lite/micro/kernels/activations.cc:126:7: note: in instantiation of function template specialization 'tflite::ops::micro::activations::ReluQuantized<signed char>' requested here\r\n      ReluQuantized<int8_t>(input, output, GetTensorData<int8_t>(input),\r\n      ^/tensorflow/lite/micro/kernels/activations.cc:40:48: error: implicit conversion increases floating-point precision: 'float' to 'double' [-Werror,-Wdouble-promotion]\r\n  double real_multiplier = input->params.scale / output->params.scale;\r\n         ~~~~~~~~~~~~~~~   ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~\r\n/tensorflow/lite/micro/kernels/activations.cc:131:7: note: in instantiation of function template specialization 'tflite::ops::micro::activations::ReluQuantized<unsigned char>' requested here\r\n      ReluQuantized<uint8_t>(input, output, GetTensorData<uint8_t>(input),\r\n      ^`", "@rthadur error resolved"]}, {"number": 39867, "title": "MAPELoss description is wrong", "body": "https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/keras/losses.py#L1242\r\n\r\nMAPELoss description is wrong, it's not \r\nloss = 100 * mean(abs(y_true - y_pred) / y_true, axis=-1)\r\nbut may be this:\r\nloss = 100*mean(abs((y_true - y_pred)/y_true, axis=-1))", "comments": ["@squall1988 Looks like only description is not correct as you mentioned. But the formula used in the code is correct. \r\n\r\nAre you interested in raising PR to correct the doc? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 39866, "title": "TFLu: Add support for unknown output dimensions", "body": "Some models (e.g. Convnet) with broadcasting have unspecified output\r\ndimensions for some operators, where the dimensions can be deduced from\r\nthe input dimensions.\r\n\r\n", "comments": ["@mansnils Can you please resolve conflicts? Thanks!\r\n", "@gbaned Conflicts are resolved.", "@njeffrie Yes, that is correct.", "@mansnils can you please check below errors \r\n\r\n`/tensorflow/lite/micro/kernels/add.cc:26:10: fatal error: '/tensorflow/lite/micro/memory_helpers.h' file not found\r\n#include \"/tensorflow/lite/micro/memory_helpers.h\"\r\n         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n1 error generated.\r\n/tensorflow/lite/micro/kernels/mul.cc:24:10: fatal error: '/tensorflow/lite/micro/memory_helpers.h' file not found\r\n#include \"/tensorflow/lite/micro/memory_helpers.h\"\r\n         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n1 error generated.`", "@rthadur Sorry, I forgot to update the bazel files. I added unit tests as well.", "Seems auto-merge is not happening but the changes are now committed so we can close this. Thank you for the PR."]}]